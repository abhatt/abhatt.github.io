<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2022-04-09T22:48:54Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en">
    <id>http://thmatters.wordpress.com/?p=1368</id>
    <link href="https://thmatters.wordpress.com/2022/04/09/theoryfest-2022-registration-now-open-and-travel-grant-applications-due-soon/" rel="alternate" type="text/html"/>
    <title>TheoryFest 2022: Registration now open and travel grant applications due soon!</title>
    <summary>Call for Participation  54th ACM Symposium on Theory of Computing (STOC 2022) – Theory Fest  June 20-24, 2022  Rome, Italy  The 54th ACM Symposium on Theory of Computing (STOC 2022) is sponsored by the ACM Special Interest Group on Algorithms and Computation Theory and will be held in Rome, Italy, Monday June 20 – Friday, […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><strong>Call for Participation </strong></p>



<p><a href="http://acm-stoc.org/stoc2022/" rel="noreferrer noopener" target="_blank"><strong>54th ACM Symposium on Theory of Computing (STOC 2022) – Theory Fest </strong></a></p>



<p><strong>June 20-24, 2022 </strong></p>



<p><strong>Rome, Italy </strong></p>



<p>The 54th ACM Symposium on Theory of Computing (STOC 2022) is sponsored by the ACM Special Interest Group on Algorithms and Computation Theory and will be held in Rome, Italy, Monday June 20 – Friday, June 24, 2022.</p>



<p>STOC 2022 – Theory Fest will feature technical talk sessions, <a href="http://acm-stoc.org/stoc2022/workshops.html" rel="noreferrer noopener" target="_blank">6 workshops</a> with introductory tutorials, poster sessions, social events, and a special joint session with “<a href="https://www.lincei.it/en" rel="noreferrer noopener" target="_blank">Accademia Nazionale dei Lincei</a>”, the oldest and most prestigious Italian academic institution, followed by a reception and a concert at the <a href="https://www.lincei.it/en/corsini-palace" rel="noreferrer noopener" target="_blank">Academy historic site</a>. </p>



<p><strong>Registration</strong></p>



<p>STOC 2022 registration is available <a href="http://acm-stoc.org/stoc2022/registration.html" rel="noreferrer noopener" target="_blank">here</a>.</p>



<p><strong>Early registration deadline: April 30th. </strong></p>



<p><strong>Student Travel Grants </strong></p>



<p>Information for student travel grant applications is available <a href="http://acm-stoc.org/stoc2022/travel-support.html" rel="noreferrer noopener" target="_blank">here</a>. </p>



<p><strong>Application deadline: April 20th.</strong></p>



<p>STOC 2022 is sponsored by Algorand, Amazon, Apple, Google, IOHK, Microsoft, Sapienza University of Rome. </p></div>
    </content>
    <updated>2022-04-09T14:15:44Z</updated>
    <published>2022-04-09T14:15:44Z</published>
    <category term="Deadlines"/>
    <category term="for PhD students"/>
    <category term="TCS Community"/>
    <author>
      <name>shuchic</name>
    </author>
    <source>
      <id>https://thmatters.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://thmatters.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://thmatters.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://thmatters.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://thmatters.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theory Matters</title>
      <updated>2022-04-09T22:47:59Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2022/04/06/summer-visiting-researcher-position-at-boston-college-computer-science-bentos-lab-apply-by-may-31-2022/</id>
    <link href="https://cstheory-jobs.org/2022/04/06/summer-visiting-researcher-position-at-boston-college-computer-science-bentos-lab-apply-by-may-31-2022/" rel="alternate" type="text/html"/>
    <title>Summer visiting researcher position at Boston College, Computer Science, Bento’s Lab (apply by May 31, 2022)</title>
    <summary>We invite applications for multiple visiting scholar positions in any of the following areas: * parallel and distributed algorithms/optimization, convex and non-convex optimization * machine learning, graphical models, information theory * network theory and graph matching * deep learning, robustness in machine learning Start and end dates flexible. Duration up to 4 months. Website: https://academicjobsonline.org/ajo/jobs/21519 […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>We invite applications for multiple visiting scholar positions in any of the following areas:</p>
<p>* parallel and distributed algorithms/optimization, convex and non-convex optimization</p>
<p>* machine learning, graphical models, information theory</p>
<p>* network theory and graph matching</p>
<p>* deep learning, robustness in machine learning</p>
<p>Start and end dates flexible. Duration up to 4 months.</p>
<p>Website: <a href="https://academicjobsonline.org/ajo/jobs/21519">https://academicjobsonline.org/ajo/jobs/21519</a><br/>
Email: visiting@jbento.info</p></div>
    </content>
    <updated>2022-04-06T16:59:14Z</updated>
    <published>2022-04-06T16:59:14Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2022-04-09T22:47:54Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2022/03/31/phd-studentship-at-university-of-liverpool-apply-by-april-18-2022/</id>
    <link href="https://cstheory-jobs.org/2022/03/31/phd-studentship-at-university-of-liverpool-apply-by-april-18-2022/" rel="alternate" type="text/html"/>
    <title>PhD Studentship at University of Liverpool (apply by April 18, 2022)</title>
    <summary>Applications are invited for a 4-year PhD studentship on Game Theory and Computational Social Choice on Blockchain at the University of Liverpool, in collaboration with the blockchain technology company IOHK. The selected candidate will be advised by Aris Filos-Ratsikas and Rahul Savani from the University of Liverpool, and Philip Lazos from IOHK. Website: https://www.findaphd.com/phds/project/game-theory-and-computational-social-choice-on-blockchain-epsrc-cdt-in-distributed-algorithms/?p142348 Email: […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Applications are invited for a 4-year PhD studentship on Game Theory and Computational Social Choice on Blockchain at the University of Liverpool, in collaboration with the blockchain technology company IOHK. The selected candidate will be advised by Aris Filos-Ratsikas and Rahul Savani from the University of Liverpool, and Philip Lazos from IOHK.</p>
<p>Website: <a href="https://www.findaphd.com/phds/project/game-theory-and-computational-social-choice-on-blockchain-epsrc-cdt-in-distributed-algorithms/?p142348">https://www.findaphd.com/phds/project/game-theory-and-computational-social-choice-on-blockchain-epsrc-cdt-in-distributed-algorithms/?p142348</a><br/>
Email: Aris.Filos-Ratsikas@liverpool.ac.uk</p></div>
    </content>
    <updated>2022-03-31T12:26:27Z</updated>
    <published>2022-03-31T12:26:27Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2022-04-09T22:47:54Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://thmatters.wordpress.com/?p=1365</id>
    <link href="https://thmatters.wordpress.com/2022/03/26/call-for-nominations-stoc-test-of-time-award-deadline-apr-30/" rel="alternate" type="text/html"/>
    <title>Call for Nominations: STOC Test of Time Award (Deadline: Apr 30)</title>
    <summary>The 2022 STOC Test of Time Award recognizes papers published in the Proceedings of the Annual ACM Symposium on Theory of Computing. This is the second year of this annual award. There are three awards, targeting the STOC conferences 10, 20, and 30 years prior to the year in which the award is given. While […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><strong>The 2022 STOC Test of Time Award</strong> recognizes papers published in the Proceedings of the Annual ACM Symposium on Theory of Computing. This is the second year of this annual award. There are three awards, targeting the STOC conferences 10, 20, and 30 years prior to the year in which the award is given. While there is a preference for papers in the target years (and nominations from those years are encouraged), in each of these award categories it is also possible to nominate STOC conference papers published up to four conferences earlier than the targeted conference. Thus, the 2022 STOC Test of Time Awards will be for papers presented at the STOC conferences in 2008-2012, 1998-2002, and 1988-1992. The awards, which will be presented at STOC 2022, include a prize of US $500 per author as well as complimentary registration for all authors who attend the conference at which the award is given.</p>



<h2>Nomination Procedure</h2>



<p>Nominations should be sent to <a rel="noreferrer noopener" target="_blank"><strong>stoc22.tot.award@gmail.com</strong></a><strong> </strong>with a subject line of <strong>“STOC Test of Time Award” </strong>no later than <strong>April 30, 2022</strong>. Nominations should contain an explanation of the impact of the nominated paper(s), including references to follow-on work. A nomination may be accompanied by up to three additional endorsement letters, which may be sent by the endorsers directly to the same email address with the same subject line. Self-nominations are disallowed. </p>



<h2>Selection</h2>



<p>The winners will be selected by a committee appointed by the SIGACT Executive Committee. For 2022 the selection committee consists of Toniann Pitassi (Columbia), Satish Rao (Berkeley), Salil Vadhan (Harvard, chair), Avi Wigderson (Institute for Advanced Study). </p>



<p>In selecting the Test of Time Award winners, the Committee will pay particular attention to long-term impact. This impact can come in many forms, including but not limited to:</p>



<ol><li>Opening up a new area of research</li><li>Introducing new techniques</li><li>Solving a problem of lasting importance</li><li>Stimulating advances in other areas of computer science or in other disciplines.</li></ol>



<p>The committee expects to select exactly one paper for each award. However, when circumstances justify it, up to three may be selected. The committee may consider papers that were not explicitly nominated and gather additional input from experts, but formal nominations are extremely helpful in the committee’s deliberations and strongly encouraged.</p></div>
    </content>
    <updated>2022-03-27T01:53:14Z</updated>
    <published>2022-03-27T01:53:14Z</published>
    <category term="awards"/>
    <category term="Deadlines"/>
    <category term="TCS Community"/>
    <author>
      <name>shuchic</name>
    </author>
    <source>
      <id>https://thmatters.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://thmatters.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://thmatters.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://thmatters.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://thmatters.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theory Matters</title>
      <updated>2022-04-09T22:47:57Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2022/03/23/lecturer-in-theoretical-computer-science-at-university-of-auckland-apply-by-may-15-2022/</id>
    <link href="https://cstheory-jobs.org/2022/03/23/lecturer-in-theoretical-computer-science-at-university-of-auckland-apply-by-may-15-2022/" rel="alternate" type="text/html"/>
    <title>Lecturer in Theoretical Computer Science at University of Auckland (apply by May 15, 2022)</title>
    <summary>We seek two early-career top candidates working in any subfield of TCS, preferably in algorithms and data structures, probabilistic computation, quantum and algorithmic information theory, computational biology, and computational complexity. Website: https://jobs.smartrecruiters.com/TheUniversityOfAuckland/743999813405096-lecturer-in-theoretical-computer-science Email: g.russello@auckland.ac.nz</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>We seek two early-career top candidates working in any subfield of TCS, preferably in algorithms and data structures, probabilistic computation, quantum and algorithmic information theory, computational biology, and computational complexity.</p>
<p>Website: <a href="https://jobs.smartrecruiters.com/TheUniversityOfAuckland/743999813405096-lecturer-in-theoretical-computer-science">https://jobs.smartrecruiters.com/TheUniversityOfAuckland/743999813405096-lecturer-in-theoretical-computer-science</a><br/>
Email: g.russello@auckland.ac.nz</p></div>
    </content>
    <updated>2022-03-23T23:12:08Z</updated>
    <published>2022-03-23T23:12:08Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2022-04-09T22:47:59Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2022/03/20/postdoc-at-hamburg-university-of-technology-apply-by-april-8-2022/</id>
    <link href="https://cstheory-jobs.org/2022/03/20/postdoc-at-hamburg-university-of-technology-apply-by-april-8-2022/" rel="alternate" type="text/html"/>
    <title>Postdoc at Hamburg University of Technology (apply by April 8, 2022)</title>
    <summary>The Institute for Algorithms and Complexity at Hamburg University of Technology is seeking a postdoc to work on algorithms for combinatorial optimization and operations research (pay level TV-L 14). These can be approximation algorithms, parameterized algorithms, dynamic algorithms, streaming algorithms, or related. Join our international team to solve some of the most intractable problems! Website: […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Institute for Algorithms and Complexity at Hamburg University of Technology is seeking a postdoc to work on algorithms for combinatorial optimization and operations research (pay level TV-L 14). These can be approximation algorithms, parameterized algorithms, dynamic algorithms, streaming algorithms, or related. Join our international team to solve some of the most intractable problems!</p>
<p>Website: <a href="https://stellenportal.tuhh.de/jobposting/6816c1195abac5e2e9f2c7f1a72506004fd3ead0">https://stellenportal.tuhh.de/jobposting/6816c1195abac5e2e9f2c7f1a72506004fd3ead0</a><br/>
Email: algo@tuhh.de</p></div>
    </content>
    <updated>2022-03-20T20:42:51Z</updated>
    <published>2022-03-20T20:42:51Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2022-04-09T22:47:55Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2022/03/20/ukraine-student-postdoc-senior-research-fellows-at-ben-gurion-university-apply-by-december-6-2022/</id>
    <link href="https://cstheory-jobs.org/2022/03/20/ukraine-student-postdoc-senior-research-fellows-at-ben-gurion-university-apply-by-december-6-2022/" rel="alternate" type="text/html"/>
    <title>Ukraine  Student/ Postdoc/  Senior Research  Fellows at Ben-Gurion University (apply by December 6, 2022)</title>
    <summary>If you are a student/scholar affected by the war in Ukraine, BGU offers an emergency scholarship, furthermore, I also have immediately available funds for those who are interested in doing research in Theoretical computer science or Error-Correcting Codes. Website: https://www.tfaforms.com/399172?fbclid=IwAR1AW_tvfxoC6yA7EXcptO5tr3SjOM0dAgngz6v6WtlMfHr1ghDwXC0MMt4, https://www.cs.bgu.ac.il/~klim/ Email: klimefrem@gmail.com</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>If you are a student/scholar affected by the war in Ukraine, BGU offers an emergency scholarship, furthermore, I also have immediately available funds for those who are interested in doing research in Theoretical computer science or Error-Correcting Codes.</p>
<p>Website: <a href="https://www.tfaforms.com/399172?fbclid=IwAR1AW_tvfxoC6yA7EXcptO5tr3SjOM0dAgngz6v6WtlMfHr1ghDwXC0MMt4">https://www.tfaforms.com/399172?fbclid=IwAR1AW_tvfxoC6yA7EXcptO5tr3SjOM0dAgngz6v6WtlMfHr1ghDwXC0MMt4</a>, <a href="https://www.cs.bgu.ac.il/~klim/">https://www.cs.bgu.ac.il/~klim/</a><br/>
Email: klimefrem@gmail.com</p></div>
    </content>
    <updated>2022-03-20T16:54:04Z</updated>
    <published>2022-03-20T16:54:04Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2022-04-09T22:47:57Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2022/03/16/postdoc-at-sandia-national-labs-apply-by-march-31-2022/</id>
    <link href="https://cstheory-jobs.org/2022/03/16/postdoc-at-sandia-national-labs-apply-by-march-31-2022/" rel="alternate" type="text/html"/>
    <title>Postdoc at Sandia National Labs (apply by March 31, 2022)</title>
    <summary>Sandia Labs is seeking a postdoc to work on quantum or quantum-inspired classical approximation, sublinear, or streaming algorithms, as part of a DOE-funded collaboration among several national labs and universities. We encourage theoretical computer scientists interested in quantum information but without prior expertise to apply. Website: https://far-qc.sandia.gov/job-opportunities/ Email: odparek@sandia.gov</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Sandia Labs is seeking a postdoc to work on quantum or quantum-inspired classical approximation, sublinear, or streaming algorithms, as part of a DOE-funded collaboration among several national labs and universities. We encourage theoretical computer scientists interested in quantum information but without prior expertise to apply.</p>
<p>Website: <a href="https://far-qc.sandia.gov/job-opportunities/">https://far-qc.sandia.gov/job-opportunities/</a><br/>
Email: odparek@sandia.gov</p></div>
    </content>
    <updated>2022-03-16T23:26:53Z</updated>
    <published>2022-03-16T23:26:53Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2022-04-09T22:48:02Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2022/03/13/ukraine-student-senior-research-fellows-at-tel-aviv-university-apply-by-june-1-2022/</id>
    <link href="https://cstheory-jobs.org/2022/03/13/ukraine-student-senior-research-fellows-at-tel-aviv-university-apply-by-june-1-2022/" rel="alternate" type="text/html"/>
    <title>Ukraine student / senior research fellows at Tel Aviv University (apply by June 1, 2022)</title>
    <summary>Tel Aviv University offers emergency scholarship for research students from Ukraine (see attached). Further, I (Gil Cohen) have immediately available senior / students research fellows in theoretical computer science, coding theory, spectral graph theory, and adjacent mathematical branches. Website: https://c1f423b8-ee8e-41b1-a3a7-2cfc865115ec.filesusr.com/ugd/d112fa_4de343bf5b3a410eae40b3853dcef087.pdf Email: coheng@gmail.com</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Tel Aviv University offers emergency scholarship for research students from Ukraine (see attached). Further, I (Gil Cohen) have immediately available senior / students research fellows in theoretical computer science, coding theory, spectral graph theory, and adjacent mathematical branches.</p>
<p>Website: <a href="https://c1f423b8-ee8e-41b1-a3a7-2cfc865115ec.filesusr.com/ugd/d112fa_4de343bf5b3a410eae40b3853dcef087.pdf">https://c1f423b8-ee8e-41b1-a3a7-2cfc865115ec.filesusr.com/ugd/d112fa_4de343bf5b3a410eae40b3853dcef087.pdf</a><br/>
Email: coheng@gmail.com</p></div>
    </content>
    <updated>2022-03-13T11:10:32Z</updated>
    <published>2022-03-13T11:10:32Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2022-04-09T22:47:53Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://thmatters.wordpress.com/?p=1362</id>
    <link href="https://thmatters.wordpress.com/2022/03/11/call-for-nominations-knuth-prize/" rel="alternate" type="text/html"/>
    <title>Call for nominations: Knuth Prize</title>
    <summary>Deadline: March 31, 2022. The Donald E. Knuth Prize for outstanding contributions to the foundations of computer science is awarded for major research accomplishments and contributions to the foundations of computer science over an extended period of time. The Prize is awarded annually by the ACMSpecial Interest Group on Algorithms and Computation Theory (SIGACT) and the IEEETechnical Committee […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><strong>Deadline: March 31, 2022.</strong></p>



<p>The Donald E. Knuth Prize for outstanding contributions to the foundations of computer science is awarded for major research accomplishments and contributions to the foundations of computer science over an extended period of time. The Prize is awarded annually by the <a href="https://urldefense.com/v3/__https://acm.org/__;!!IBzWLUs!FhlJI8zMLEOwnp6yNYlHlUi7BTqdRYKuBcTGlpuO3upUQ3CeNXk5Et-Ykc0qrYCK$" rel="noreferrer noopener" target="_blank">ACM</a><a href="https://urldefense.com/v3/__https://www.sigact.org/__;!!IBzWLUs!FhlJI8zMLEOwnp6yNYlHlUi7BTqdRYKuBcTGlpuO3upUQ3CeNXk5Et-YkRfc620V$" rel="noreferrer noopener" target="_blank">Special Interest Group on Algorithms and Computation Theory</a> (SIGACT) and the <a href="https://urldefense.com/v3/__https://www.ieee.org/__;!!IBzWLUs!FhlJI8zMLEOwnp6yNYlHlUi7BTqdRYKuBcTGlpuO3upUQ3CeNXk5Et-YkSouJjK-$" rel="noreferrer noopener" target="_blank">IEEE</a><a href="https://urldefense.com/v3/__https://tc.computer.org/tcmf/__;!!IBzWLUs!FhlJI8zMLEOwnp6yNYlHlUi7BTqdRYKuBcTGlpuO3upUQ3CeNXk5Et-YkcMUrupP$" rel="noreferrer noopener" target="_blank">Technical Committee on the Mathematical Foundations of Computing</a> (TCMF).</p>



<p><strong>Nomination Procedure.</strong> Anyone in the Theoretical Computer Science community may nominate a candidate. To do so, please send nominations to <strong><a rel="noreferrer noopener" target="_blank">knuth.prize.2022@gmail.com</a></strong> by <strong>March 31, 2022</strong>. The nomination should state the nominee’s name, summarize their contributions in one or two pages, provide a CV for the nominee or a pointer to the nominee’s web page, and give telephone and email contact information for the nominator. Any supporting letters from other members of the community (up to a limit of 5) should be included in the package that the nominator submits. Supporting letters should contain substantial information not in the nomination. Others may endorse the nomination simply by adding their names to the nomination letter. If you have nominated a candidate in past years, you can re-nominate the candidate by sending a message to that effect to the above email address. (You may revise the nominating materials if you so desire.)</p>



<p><strong>Criteria for Selection.</strong> The winner is selected by a Prize Committee consisting of six people appointed by the SIGACT and TCMF Chairs, see below for the composition of the committee.</p>



<p>Previous nominations made or updated in the last 5 years will be considered. Older nominations must be updated for consideration. Note that the Knuth Prize is awarded to a single individual each year. Nominations of groups of researchers will not be considered.</p>



<p>In selecting the Knuth Prize winner, the Committee pays particular attention to a <em>sustained record</em> of high-impact, seminal contributions to the foundations of computer science. The selection may also be based partly on educational accomplishments and contributions such as fundamental textbooks and high-quality students. The award is not given for service to the theoretical computer science community, but service may be included in the citation for a winner if appropriate.</p>



<p>The 2022 prize committee consists of Harold Gabow (U. Colorado), Monika Henzinger (U. Vienna), Kurt Mehlhorn (Max Planck Institute), Dana Randall (Chair, Georgia Tech), Madhu Sudan (Harvard U.), and Andy Yao (Tsinghua U.).</p></div>
    </content>
    <updated>2022-03-11T20:49:39Z</updated>
    <published>2022-03-11T20:49:39Z</published>
    <category term="awards"/>
    <category term="Deadlines"/>
    <category term="TCS Community"/>
    <author>
      <name>shuchic</name>
    </author>
    <source>
      <id>https://thmatters.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://thmatters.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://thmatters.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://thmatters.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://thmatters.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theory Matters</title>
      <updated>2022-04-09T22:47:56Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://thmatters.wordpress.com/?p=1357</id>
    <link href="https://thmatters.wordpress.com/2022/03/11/call-for-nominations-godel-prize/" rel="alternate" type="text/html"/>
    <title>Call for nominations: Godel Prize</title>
    <summary>Deadline for nominations extended to March 31st 2022. https://www.sigact.org/prizes/g%C3%B6del.html The Gödel Prize for outstanding papers in the area of theoretical computer science is sponsored jointly by the European Association for Theoretical Computer Science (EATCS) and the Special Interest Group on Algorithms and Computation Theory of the Association for Computing Machinery (ACM SIGACT). This award is presented annually, with the presentation taking place alternately […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><strong>Deadline for nominations extended to March 31st 2022.</strong></p>



<p><a href="https://urldefense.com/v3/__https://www.sigact.org/prizes/g**Adel.html__;w7Y!!IBzWLUs!EguPGLYWUarkIsJJaLrhDzTZKGjc97LX_FB94NzWMobXbrXlbTKzzky4VPAE-mxj$" rel="noreferrer noopener" target="_blank">https://www.sigact.org/prizes/g%C3%B6del.html</a></p>



<p>The Gödel Prize for outstanding papers in the area of theoretical computer science is sponsored jointly by the European Association for Theoretical Computer Science (EATCS) and the Special Interest Group on Algorithms and Computation Theory of the Association for Computing Machinery (ACM SIGACT). This award is presented annually, with the presentation taking place alternately at the International Colloquium on Automata, Languages, and Programming (ICALP) and the ACM Symposium on Theory of Computing (STOC). The thirtieth Gödel Prize will be awarded at the forty-ninth International Colloquium on Automata, Languages and Programming (ICALP), which will be hybrid, happening both physically and virtually. The physical meeting will take place in Paris, France, July 4–8 2022.</p>



<p>The Prize is named in honor of Kurt Gödel in recognition of his major contributions to mathematical logic and of his interest, discovered in a letter he wrote to John von Neumann shortly before von Neumann’s death, in what has become the famous “P versus NP” question. The Prize includes an award of USD 5,000.</p>



<p><strong>Award Committee</strong></p>



<p>The 2022 Award Committee consists of Samson Abramsky (Chair, University College London), Nikhil Bansal (University of Michigan), Irit Dinur (Weizmann Institute), Anca Muscholl (University of Bordeaux), Ronitt Rubinfeld (Massachusetts Institute of Technology), and David Zuckerman (University of Texas at Austin).</p>



<p><strong>Eligibility</strong></p>



<p>The 2022 Prize rules are given below and they supersede any different interpretation of the generic rule to be found on websites of both SIGACT and EATCS. Any research paper or series of papers by a single author or by a team of authors is deemed eligible if:</p>



<p>• The main results were not published (in either preliminary or final form) in a journal or conference proceedings before January 1, 2009.</p>



<p>• The paper was published in a recognized refereed journal no later than December 31, 2021.<br/>The research work nominated for the award should be in the area of theoretical computer science. Nominations are encouraged from the broadest spectrum of the theoretical computer science community so as to ensure that potential award winning papers are not overlooked. The Award Committee shall have the ultimate authority to decide whether a particular paper is eligible for the Prize.</p>



<p><strong>Nominations</strong></p>



<p>Nominations for the award should be submitted by email to the Award Committee Chair: <a rel="noreferrer noopener" target="_blank">s.abramsky@ucl.ac.uk</a>. Please make sure that the Subject line of all nominations and related messages begin with “Goedel Prize 2022”. To be considered, nominations for the 2022 Prize must be received by March 31, 2022.</p>



<p>A nomination package should include:</p>



<p>• A printable copy (or copies) of the journal paper(s) being nominated, together with a complete citation (or citations) thereof.</p>



<p>• A statement of the date(s) and venue(s) of the first conference or workshop publication(s) of the nominated work(s) or a statement that no such publication has occurred.</p>



<p>• A brief summary of the technical content of the paper(s) and a brief explanation of its significance.</p>



<p>• A support letter or letters signed by at least two members of the scientific community.<br/>Additional support letters may also be received and are generally useful. The nominated paper(s) may be in any language. However, if a nominated publication is not in English, the nomination package must include an extended summary written in English.</p>



<p>Those intending to submit a nomination should contact the Award Committee Chair by email well in advance. The Chair will answer questions about eligibility, encourage coordination among different nominators for the same paper(s), and also accept informal proposals of potential nominees or tentative offers to prepare formal nominations. The committee maintains a database of past nominations for eligible papers, but fresh nominations for the same papers (especially if they highlight new evidence of impact) are always welcome.</p></div>
    </content>
    <updated>2022-03-11T20:47:31Z</updated>
    <published>2022-03-11T20:47:31Z</published>
    <category term="awards"/>
    <category term="Deadlines"/>
    <category term="TCS Community"/>
    <author>
      <name>shuchic</name>
    </author>
    <source>
      <id>https://thmatters.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://thmatters.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://thmatters.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://thmatters.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://thmatters.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theory Matters</title>
      <updated>2022-04-09T22:48:37Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2022/03/11/postdoc-at-utrecht-university-apply-by-april-4-2022/</id>
    <link href="https://cstheory-jobs.org/2022/03/11/postdoc-at-utrecht-university-apply-by-april-4-2022/" rel="alternate" type="text/html"/>
    <title>Postdoc at Utrecht University (apply by April 4, 2022)</title>
    <summary>The ERC starting grant project “Finding Cracks in the Wall of NP-completeness” of PI Jesper Nederlof aims to improve classical algorithms for NP-hard problems. For example: Can the Bellman-Held-Karp dynamic programming algorithm from the 1960’s that solves TSP with n cities in 2^n time be improved to 1.9999^n time? Join the project as a postdoc […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The ERC starting grant project “Finding Cracks in the Wall of NP-completeness” of PI Jesper Nederlof aims to improve classical algorithms for NP-hard problems. For example: Can the Bellman-Held-Karp dynamic programming algorithm from the 1960’s that solves TSP with n cities in 2^n time be improved to 1.9999^n time? Join the project as a postdoc now!</p>
<p>Website: <a href="https://www.uu.nl/en/organisation/working-at-utrecht-university/jobs/postdoc-position-in-algorithmic-theory-10-fte">https://www.uu.nl/en/organisation/working-at-utrecht-university/jobs/postdoc-position-in-algorithmic-theory-10-fte</a><br/>
Email: j.nederlof@uu.nl</p></div>
    </content>
    <updated>2022-03-11T19:49:33Z</updated>
    <published>2022-03-11T19:49:33Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2022-04-09T22:47:53Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2022/03/10/postdoc-and-phd-student-in-graph-algorithms-at-tel-aviv-university-apply-by-april-15-2022/</id>
    <link href="https://cstheory-jobs.org/2022/03/10/postdoc-and-phd-student-in-graph-algorithms-at-tel-aviv-university-apply-by-april-15-2022/" rel="alternate" type="text/html"/>
    <title>Postdoc and PhD student in graph algorithms at Tel Aviv University (apply by April 15, 2022)</title>
    <summary>Applications are invited for postdoc and PhD positions at the group of Shay Solomon, Tel Aviv University, funded by an ERC starting grant. The selected candidates will confront fundamental problems in graph algorithms. Applications will be accepted until the positions are filled (flexible start date). To apply, send a CV and research statement, and arrange […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Applications are invited for postdoc and PhD positions at the group of Shay Solomon, Tel Aviv University, funded by an ERC starting grant.<br/>
The selected candidates will confront fundamental problems in graph algorithms. Applications will be accepted until the positions are filled (flexible start date).<br/>
To apply, send a CV and research statement, and arrange for three letters of recommendation.</p>
<p>Website: <a href="https://sites.google.com/site/soloshay/">https://sites.google.com/site/soloshay/</a><br/>
Email: shayso@tauex.tau.ac.il</p></div>
    </content>
    <updated>2022-03-10T21:00:32Z</updated>
    <published>2022-03-10T21:00:32Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2022-04-09T22:47:44Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2022/03/10/differential-privacy-research-scientist-at-harvard-university-apply-by-april-30-2022/</id>
    <link href="https://cstheory-jobs.org/2022/03/10/differential-privacy-research-scientist-at-harvard-university-apply-by-april-30-2022/" rel="alternate" type="text/html"/>
    <title>Differential Privacy Research Scientist at Harvard University (apply by April 30, 2022)</title>
    <summary>The OpenDP project at Harvard University seeks to hire a Research Scientist to work with faculty directors Gary King and Salil Vadhan and the OpenDP Community to formulate and advance the scientific goals of OpenDP and solve research problems that are needed for its success. Website: https://academicpositions.harvard.edu/postings/11093 Email: opendp@g.harvard.edu</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The OpenDP project at Harvard University seeks to hire a Research Scientist to work with faculty directors Gary King and Salil Vadhan and the OpenDP Community to formulate and advance the scientific goals of OpenDP and solve research problems that are needed for its success.</p>
<p>Website: <a href="https://academicpositions.harvard.edu/postings/11093">https://academicpositions.harvard.edu/postings/11093</a><br/>
Email: opendp@g.harvard.edu</p></div>
    </content>
    <updated>2022-03-10T20:56:55Z</updated>
    <published>2022-03-10T20:56:55Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2022-04-09T22:47:38Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://thmatters.wordpress.com/?p=1354</id>
    <link href="https://thmatters.wordpress.com/2022/03/01/call-for-nominations-sigact-distinguished-service-award/" rel="alternate" type="text/html"/>
    <title>Call for Nominations: SIGACT Distinguished Service Award</title>
    <summary>From the SIGACT executive committee: The Theory community benefits in many ways from the dedicated service, above and beyond the call of duty, of many of its members. Among other contributions, the field’s members underpin the operation of conferences, journals, prizes, funding agencies, and other community activities, help ensure funding for the field, and promote […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>From the SIGACT executive committee:</p>



<p>The Theory community benefits in many ways from the dedicated service, above and beyond the call of duty, of many of its members. Among other contributions, the field’s members underpin the operation of conferences, journals, prizes, funding agencies, and other community activities, help ensure funding for the field, and promote the recognition of the field by external communities. The SIGACT Distinguished Service Award is intended to recognize and promote their contributions, as well as to raise awareness of the need for and importance of such service, for the health of our community. The award is given annually to an individual or group who has made substantial service contributions to the Theoretical Computer Science community.</p>



<p>Eligibility<br/>The award can be given to an individual or a group of individuals, for a single contribution or for a series of contributions over a career. All living individuals are eligible with the exception of the sitting SIGACT Chair, an individual or a group of individuals who nominated a majority of the current selection committee members, or a member of the current selection committee.</p>



<p>Deadline for Nominations<br/>This year’s nomination deadline is March 21, 2022, 11:59 EDT.</p>



<p>Please see the full call at the SIGACT website at <a href="https://www.sigact.org/prizes/service.html" rel="noreferrer noopener" target="_blank">https://www.sigact.org/prizes/service.html</a> for more information.</p>



<p>We are grateful to Paul Beame, Dieter van Melkebeek, and Rebecca Wright (chair) who have kindly agreed to serve as the selection committee.</p></div>
    </content>
    <updated>2022-03-01T17:45:38Z</updated>
    <published>2022-03-01T17:45:38Z</published>
    <category term="awards"/>
    <category term="Deadlines"/>
    <category term="TCS Community"/>
    <author>
      <name>shuchic</name>
    </author>
    <source>
      <id>https://thmatters.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://thmatters.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://thmatters.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://thmatters.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://thmatters.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theory Matters</title>
      <updated>2022-04-09T22:48:50Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://thmatters.wordpress.com/?p=1348</id>
    <link href="https://thmatters.wordpress.com/2022/01/26/theory-fest22-call-for-workshop-proposals/" rel="alternate" type="text/html"/>
    <title>STOC’22: Call for Workshop Proposals</title>
    <summary>The Theory Fest workshops committee is soliciting proposals for workshops. Workshops will be held during the STOC conference week, June 20-24, 2022. The (updated) deadline for submitting proposals is Feb 15, 2022. Details on how to submit a proposal can be found at http://acm-stoc.org/stoc2022/callforworkshops.html.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Theory Fest workshops committee is soliciting proposals for workshops. Workshops will be held during the STOC conference week, June 20-24, 2022. The (updated) deadline for submitting proposals is <strong>Feb 15, 2022</strong>. Details on how to submit a proposal can be found at <a href="http://acm-stoc.org/stoc2022/callforworkshops.html" rel="nofollow">http://acm-stoc.org/stoc2022/callforworkshops.html</a>.</p></div>
    </content>
    <updated>2022-01-26T23:43:17Z</updated>
    <published>2022-01-26T23:43:17Z</published>
    <category term="Deadlines"/>
    <author>
      <name>shuchic</name>
    </author>
    <source>
      <id>https://thmatters.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://thmatters.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://thmatters.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://thmatters.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://thmatters.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theory Matters</title>
      <updated>2022-04-09T22:48:14Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://lucatrevisan.wordpress.com/?p=4597</id>
    <link href="https://lucatrevisan.wordpress.com/2021/12/15/postdoc-positions-2/" rel="alternate" type="text/html"/>
    <title>Postdoc Positions</title>
    <summary>A reminder that I am recruiting for two postdoc positions in my group, and that the strict application deadline is this Friday, December 17. See this previous post for details: https://lucatrevisan.wordpress.com/2021/10/21/postdoc-positions/</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>A reminder that I am recruiting for two postdoc positions in my group, and that the strict application deadline is this Friday, December 17. See this previous post for details: <a href="https://lucatrevisan.wordpress.com/2021/10/21/postdoc-positions/">https://lucatrevisan.wordpress.com/2021/10/21/postdoc-positions/</a></p></div>
    </content>
    <updated>2021-12-15T17:38:30Z</updated>
    <published>2021-12-15T17:38:30Z</published>
    <category term="Milan"/>
    <category term="theory"/>
    <category term="postdoc"/>
    <author>
      <name>luca</name>
    </author>
    <source>
      <id>https://lucatrevisan.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://lucatrevisan.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://lucatrevisan.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://lucatrevisan.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://lucatrevisan.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>"Marge, I agree with you - in theory. In theory, communism works. In theory." -- Homer Simpson</subtitle>
      <title>in   theory</title>
      <updated>2022-04-09T22:47:38Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://lucatrevisan.wordpress.com/?p=4588</id>
    <link href="https://lucatrevisan.wordpress.com/2021/11/10/online-optimization-post-7-matrix-multiplicative-weights-update/" rel="alternate" type="text/html"/>
    <title>Online Optimization Post 7: Matrix Multiplicative Weights Update</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">This is the seventh in a series of posts on online optimization, where we alternate one post explaining a result from the theory of online convex optimization and one post explaining an “application” in computational complexity or combinatorics. The first … <a href="https://lucatrevisan.wordpress.com/2021/11/10/online-optimization-post-7-matrix-multiplicative-weights-update/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>This is the seventh in a series of posts on online optimization, where we alternate one post explaining a result from the theory of online convex optimization and one post explaining an “application” in computational complexity or combinatorics. The first two posts were about the technique of <a href="https://lucatrevisan.wordpress.com/2019/04/24/online-optimization-post-1-multiplicative-weights/">Multiplicative Weights Updates</a> and its application to <a href="https://lucatrevisan.wordpress.com/2019/04/25/online-optimization-post-2-constructing-pseudorandom-sets/">“derandomizing” probabilistic arguments</a> based on combining a Chernoff bound and a union bound. The third and fourth post were about the <a href="https://lucatrevisan.wordpress.com/2019/05/06/online-optimization-post-3-follow-the-regularized-leader/">Follow-the-Regularized-Leader</a> framework, which unifies multiplicative weights and gradient descent, and a <a href="https://lucatrevisan.wordpress.com/2019/05/16/online-optimization-post-4-regularity-lemmas/">“gradient descent view” of the Frieze-Kannan Weak Regularity Lemma</a>. The fifth and sixth post were about the <a href="https://lucatrevisan.wordpress.com/2019/05/20/online-optimization-post-5-bregman-projections-and-mirror-descent/">constrained version of the Follow-the-Regularized-Leader</a> framework, and the <a href="https://lucatrevisan.wordpress.com/2021/10/20/online-optimization-post-6-the-impagliazzo-hard-core-set-lemma/">Impagliazzo Hard-Core Set Lemma</a>. Today we shall see the technique of Matrix Multiplicative Weights Updates.</p>
<p><b>1. Matrix Multiplicative Weights Update </b></p>
<p>In this post we consider the following generalization, introduced and studied by <a href="https://dl.acm.org/doi/10.1145/1250790.1250823">Arora and Kale</a>, of the “learning from expert advice” setting and the multiplicative weights update method. In the “experts” model, we have a repeated game in which, at each time step <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, we have the option of following the advice of one of <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> experts; if we follow the advice of expert <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> at time <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, we incur a loss of <img alt="{\ell_t (i)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell_t+%28i%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, which is unknown to us (although, at time <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> we know the loss functions <img alt="{\ell_1(\cdot),\ldots,\ell_{t-1}(\cdot)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell_1%28%5Ccdot%29%2C%5Cldots%2C%5Cell_%7Bt-1%7D%28%5Ccdot%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>). We are allowed to choose a probabilistic strategy, whereby we follow the advice of expert <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> with probability <img alt="{x_t(i)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_t%28i%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, so that our expected loss at time <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is <img alt="{\sum_{i=1}^n x_t(i) \ell_t(i)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csum_%7Bi%3D1%7D%5En+x_t%28i%29+%5Cell_t%28i%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>.</p>
<p>In the matrix version, instead of choosing an expert <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> we are allowed to choose a unit <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>-dimensional vector <img alt="{v_t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bv_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, and the loss incurred in choosing the vector <img alt="{v_t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bv_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is <img alt="{v_t ^T L_t v_t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bv_t+%5ET+L_t+v_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, where <img alt="{L_t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is an unknown symmetric <img alt="{n\times n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%5Ctimes+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> matrix. We are also allowed to choose a probabilistic strategy, so that with probability <img alt="{x_t(j)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_t%28j%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> we choose the unit vector <img alt="{v_t^{(j)}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bv_t%5E%7B%28j%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, and we incur the expected loss</p>
<p align="center"><img alt="\displaystyle  \sum_j x_t (j) \cdot (v_t^{(j)})^T L_t v_t^{(j)} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_j+x_t+%28j%29+%5Ccdot+%28v_t%5E%7B%28j%29%7D%29%5ET+L_t+v_t%5E%7B%28j%29%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p><span id="more-4588"/></p>
<p>The above expression can also be written as</p>
<p align="center"><img alt="\displaystyle  X_t \bullet L_t " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++X_t+%5Cbullet+L_t+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> where <img alt="{X_t = \sum_j x_t(j) v_t^{(j)}(v_t^{(j)})^T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_t+%3D+%5Csum_j+x_t%28j%29+v_t%5E%7B%28j%29%7D%28v_t%5E%7B%28j%29%7D%29%5ET%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and we used the Frobenius inner product among square matrices defined as <img alt="{A \bullet B = \sum_{i,j} A_{i,j} B_{i,j}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA+%5Cbullet+B+%3D+%5Csum_%7Bi%2Cj%7D+A_%7Bi%2Cj%7D+B_%7Bi%2Cj%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. The matrices <img alt="{X_t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> that can be obtained as convex combinations of rank-1 matrices of the form <img alt="{vv^T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bvv%5ET%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> where <img alt="{v}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bv%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is a unit vector are called <em>density matrices</em> and can be characterized as the set of positive semidefinite matrices whose trace is 1.</p>
<p>It is possible to see the above game as the “quantum version” of the experts settings. A choice of a unit vector <img alt="{v_t^{(j)}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bv_t%5E%7B%28j%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is a <em>pure quantum state</em>, a probability distribution of pure quantum states, described by a density matrix, is a <em>mixed quantum state</em>. If <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is a density matrix describing a mixed quantum state, <img alt="{L}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is a symmetric matrix, and <img alt="{L = \sum_i \lambda_i w_i w_i^T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL+%3D+%5Csum_i+%5Clambda_i+w_i+w_i%5ET%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is the spectral decomposition of <img alt="{L}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> in terms of its eigenvalues <img alt="{\lambda_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and orthonormal eigenvectors <img alt="{w_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, then <img alt="{X \bullet L}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX+%5Cbullet+L%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is the expected outcome of a measurement of <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> in the basis <img alt="{w_1,\ldots,w_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw_1%2C%5Cldots%2Cw_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, and such that <img alt="{\lambda_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is the value of the measurement if the outcome is <img alt="{w_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>.</p>
<p>If you have no idea what the above paragraph means, that is perfectly ok because this view will not be particularly helpful in motivating the algorithm and analysis that we will describe. (Here I am reminded of the joke about the way people from Naples give directions: “How do I get to the post office?”, “Well, you see that road over there? After the a couple of blocks there is a pharmacy, where my uncle used to work, though now he is retired.” “Ok?” “Now, if you turn left after the pharmacy, after a while you get to a square with a big fountain and the church of St. Anthony where my niece got married. It was a beautiful ceremony, but the food at the reception was not great.” “Yes, I know that square”, “Good, don’t go there, the post office is not that way. Now, if you instead take that other road over there …”)</p>
<p>The main point of the above game, and of the Matrix Multiplicative Weights Update (MMWU) algorithm that plays it with bounded regret, is that it provides useful generalizations of the standard “experts” game and of the Multiplicative Weights Update (MWU) algorithm. For example, as we have already seen, MWU can provide a “derandomization” of the Chernoff bound; we will see that MMWU provides a derandomization of the <em>matrix</em> Chernoff bound. MWU can be used to approximate certain Linear Programming problems; MMWU can be used to approximate certain <em>Semidefinite Programming</em> problems.</p>
<p>To define and analyze the MMWU algorithm, we need to introduce certain operations on matrices. We will always work with real-valued symmetric matrices, but everything generalizes to complex-valued Hermitian matrices. If <img alt="{M = \sum_i \lambda_i w_i w_i^T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM+%3D+%5Csum_i+%5Clambda_i+w_i+w_i%5ET%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is a symmetric matrix, <img alt="{\lambda_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> are the eigenvalues of <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, and <img alt="{w_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> are corresponding orthonormal eigenvectors, then we will define a number of operations and functions on <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> that operate on the eigenvalues while leaving the eigenvectors unchanged.</p>
<p>The first operation is <em>matrix exponentiation</em>: we define</p>
<p align="center"><img alt="\displaystyle  e^X := \sum_i e^{\lambda_i} w_i w_i^T " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++e%5EX+%3A%3D+%5Csum_i+e%5E%7B%5Clambda_i%7D+w_i+w_i%5ET+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> The operation always defines a positive definite matrix, and the resulting matrix satisfies a “Taylor expansion”</p>
<p align="center"><img alt="\displaystyle  e^X = \sum_{k=0}^\infty \frac1 {k!} X^k " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++e%5EX+%3D+%5Csum_%7Bk%3D0%7D%5E%5Cinfty+%5Cfrac1+%7Bk%21%7D+X%5Ek+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> Indeed, it is more common to use the above expansion as the definition of the matrix exponential, and then derive the expression in terms of eigenvalues.</p>
<p>We also have the useful bounds</p>
<p align="center"><img alt="\displaystyle  e^X \succeq I + X" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++e%5EX+%5Csucceq+I+%2B+X&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> which is true for every <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and</p>
<p align="center"><img alt="\displaystyle  e^X \preceq I + X +X^2 " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++e%5EX+%5Cpreceq+I+%2B+X+%2BX%5E2+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> which is true for all <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> such that <img alt="{X \preceq I}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX+%5Cpreceq+I%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>.</p>
<p>Analogously, if <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is positive definite, we can define</p>
<p align="center"><img alt="\displaystyle  \log X := \sum_i (\log \lambda_i) \cdot w_i w_i^T " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clog+X+%3A%3D+%5Csum_i+%28%5Clog+%5Clambda_i%29+%5Ccdot+w_i+w_i%5ET+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>and we have a number of identities like <img alt="{\log e^X = X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog+e%5EX+%3D+X%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, <img alt="{\log X^k = k \log X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog+X%5Ek+%3D+k+%5Clog+X%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, <img alt="{e^{k X} = e^k \cdot X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Be%5E%7Bk+X%7D+%3D+e%5Ek+%5Ccdot+X%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, where <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is a scalar. We should be careful, however, not to take the analogy with real numbers too far: for example, if <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> are two symmetric matrices, in general it is not trues that <img alt="{e^{A+B} = e^A \cdot e^B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Be%5E%7BA%2BB%7D+%3D+e%5EA+%5Ccdot+e%5EB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, in fact the above expression is actually always false except when <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> commute, in which case it is trivially true. We have, however, the following extremely useful fact.</p>
<blockquote><p><b>Theorem 1 (Golden-Thompson Inequality)</b> <em> </em></p>
<p><em/></p><em>
<p align="center"><img alt="\displaystyle  {\rm tr}(e^{A+B}) \leq {\rm tr}(e^A \cdot e^B) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7B%5Crm+tr%7D%28e%5E%7BA%2BB%7D%29+%5Cleq+%7B%5Crm+tr%7D%28e%5EA+%5Ccdot+e%5EB%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
</em><p><em/><em> </em></p></blockquote>
<p>The Golden-Thompson inequality will be all we need to generalize to this matrix setting everything we have proved about multiplicative weights. See <a href="https://terrytao.wordpress.com/2010/07/15/the-golden-thompson-inequality/">this post by Terry Tao</a> for a proof.</p>
<p>The <em>Von Neumann entropy</em> of a density matrix <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> with eigenvalues <img alt="{\lambda_1,\cdots,\lambda_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda_1%2C%5Ccdots%2C%5Clambda_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is defined as</p>
<p align="center"><img alt="\displaystyle  S(X) = \sum_i \lambda_i \log \frac 1 {\lambda_i} = - {\rm tr}(X\log X) = - X \bullet \log X " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++S%28X%29+%3D+%5Csum_i+%5Clambda_i+%5Clog+%5Cfrac+1+%7B%5Clambda_i%7D+%3D+-+%7B%5Crm+tr%7D%28X%5Clog+X%29+%3D+-+X+%5Cbullet+%5Clog+X+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> that is, if we view <img alt="{X = \sum_i \lambda_i v_i v_i^T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX+%3D+%5Csum_i+%5Clambda_i+v_i+v_i%5ET%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> as the mixed quantum state in which the pure state <img alt="{v_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bv_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> has probability <img alt="{\lambda_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, then <img alt="{S(X)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is the entropy of the distribution over the pure states. Again, this is not a particularly helpful point of view, and in fact we will be interested in defining <img alt="{S(X)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> not just for density matrices <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> but for arbitrary positive definite matrices, and even positive semidefinite (with the convention that <img alt="{0 \log 0 = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0+%5Clog+0+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, which is used also in the standard definition of entropy of a distribution).</p>
<p>We will be interested in using Von Neumann entropy as a regularizer, and hence we will want to know what is its Bregman divergence. Some calculations show that the Bregman divergence of the Von Neumann entropy, which is called the quantum relative entropy, is</p>
<p align="center"><img alt="\displaystyle  S(X_1|| X_2) = {\rm tr} (X_1 \cdot ( \log X_1 - \log X_2)) + {\rm tr}(X_2) - {\rm tr}(X_1) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++S%28X_1%7C%7C+X_2%29+%3D+%7B%5Crm+tr%7D+%28X_1+%5Ccdot+%28+%5Clog+X_1+-+%5Clog+X_2%29%29+%2B+%7B%5Crm+tr%7D%28X_2%29+-+%7B%5Crm+tr%7D%28X_1%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p align="center"><img alt="\displaystyle  = X_1 \bullet(\log X_1 - \log X_2) + I \bullet (X_2 - X_1) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%3D+X_1+%5Cbullet%28%5Clog+X_1+-+%5Clog+X_2%29+%2B+I+%5Cbullet+%28X_2+-+X_1%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> If <img alt="{X_1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and <img alt="{X_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> are density matrices, the terms <img alt="{{\rm tr}(X_2) - {\rm tr}(X_1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Crm+tr%7D%28X_2%29+-+%7B%5Crm+tr%7D%28X_1%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> cancel out; the above definition is valid for arbitrary positive definite matrices.</p>
<p>We will have to study the minima of various functions that take a matrix as an input, so it is good to understand how to compute the gradient of such functions. For example what is the gradient of the function <img alt="{{\rm tr}(X)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Crm+tr%7D%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>? Working through the definition we see that <img alt="{\nabla {\rm tr}(X) = I}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cnabla+%7B%5Crm+tr%7D%28X%29+%3D+I%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, and indeed we always have that the gradient of the function <img alt="{X \rightarrow A\bullet X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX+%5Crightarrow+A%5Cbullet+X%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> everywhere. Somewhat less obvious is the calculation of the gradient of the Von Neumann entropy, which is</p>
<p align="center"><img alt="\displaystyle  \nabla (X \bullet \log X) = I + \log X " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cnabla+%28X+%5Cbullet+%5Clog+X%29+%3D+I+%2B+%5Clog+X+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p><b>2. Analysis in the Constrained FTRL Framework </b></p>
<p>Suppose that we play that we described above using agile mirror descent and using negative Von Neumann entropy (appropriately scaled) as a regularizer. That is, for some <img alt="{c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> that we will choose later, we use the regularizer</p>
<p align="center"><img alt="\displaystyle  R(X) = c X \bullet \log X" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++R%28X%29+%3D+c+X+%5Cbullet+%5Clog+X&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> which has the Bregman divergence</p>
<p align="center"><img alt="\displaystyle  D(X_1,X_2) = c S(X_1 || X_2) = c X_1 \bullet (\log X_1 - \log X_2) + cI \bullet (X_2 - X_1) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++D%28X_1%2CX_2%29+%3D+c+S%28X_1+%7C%7C+X_2%29+%3D+c+X_1+%5Cbullet+%28%5Clog+X_1+-+%5Clog+X_2%29+%2B+cI+%5Cbullet+%28X_2+-+X_1%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> and our feasible set is the set of density matrices</p>
<p align="center"><img alt="\displaystyle  \Delta := \{ X\in {\mathbb R}^{n\times n} : X \succeq {\bf 0} \wedge {\rm tr}(X) = 1 \} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5CDelta+%3A%3D+%5C%7B+X%5Cin+%7B%5Cmathbb+R%7D%5E%7Bn%5Ctimes+n%7D+%3A+X+%5Csucceq+%7B%5Cbf+0%7D+%5Cwedge+%7B%5Crm+tr%7D%28X%29+%3D+1+%5C%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> To bound the regret, we just have to plug the above definitions into the machinery that we developed <a href="https://lucatrevisan.wordpress.com/2019/05/20/online-optimization-post-5-bregman-projections-and-mirror-descent/">in our fifth post</a>.</p>
<p>At time 1, we play the identity matrix scaled by n, which is a density matrix of maximum Von Neumann entropy <img alt="{\log n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>:</p>
<p align="center"><img alt="\displaystyle  X_1 := \arg\min_{X \in \Delta} R(X) = \frac 1n I " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++X_1+%3A%3D+%5Carg%5Cmin_%7BX+%5Cin+%5CDelta%7D+R%28X%29+%3D+%5Cfrac+1n+I+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> At time <img alt="{t+1\geq 2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%2B1%5Cgeq+2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, we play the matrix <img alt="{X_t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> obtained as</p>
<p align="center"><img alt="\displaystyle  \hat X_{t+1} = \arg\min_{X} D(X,X_{t}) + X\bullet L_{t} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Chat+X_%7Bt%2B1%7D+%3D+%5Carg%5Cmin_%7BX%7D+D%28X%2CX_%7Bt%7D%29+%2B+X%5Cbullet+L_%7Bt%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p align="center"><img alt="\displaystyle  X_{t+1} = \arg\min_{X\in \Delta} D(X,\hat X_{t+1}) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++X_%7Bt%2B1%7D+%3D+%5Carg%5Cmin_%7BX%5Cin+%5CDelta%7D+D%28X%2C%5Chat+X_%7Bt%2B1%7D%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> and recall that we proved that, after <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> steps,</p>
<p align="center"><img alt="\displaystyle  Regret_T(X) \leq D(X,X_1) + \sum_{t=1}^T D(X_t,\hat X_{t+1}) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++Regret_T%28X%29+%5Cleq+D%28X%2CX_1%29+%2B+%5Csum_%7Bt%3D1%7D%5ET+D%28X_t%2C%5Chat+X_%7Bt%2B1%7D%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>If <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is a density matrix with eigenvalues <img alt="{\lambda_1,\ldots,\lambda_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda_1%2C%5Cldots%2C%5Clambda_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, then the first term is</p>
<p align="center"><img alt="\displaystyle  D \left( X, \frac 1n I \right) = c X \bullet (\log X - \log n^{-1} I) = c \sum_i \lambda_i \log \frac n{\lambda_i} = c \log n - c \sum_i \lambda_i \frac 1 {\lambda_i} \leq c\log n " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++D+%5Cleft%28+X%2C+%5Cfrac+1n+I+%5Cright%29+%3D+c+X+%5Cbullet+%28%5Clog+X+-+%5Clog+n%5E%7B-1%7D+I%29+%3D+c+%5Csum_i+%5Clambda_i+%5Clog+%5Cfrac+n%7B%5Clambda_i%7D+%3D+c+%5Clog+n+-+c+%5Csum_i+%5Clambda_i+%5Cfrac+1+%7B%5Clambda_i%7D+%5Cleq+c%5Clog+n+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> To complete the analysis we have to understand <img alt="{\hat X_{t+1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Chat+X_%7Bt%2B1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. We need to compute the gradient <img alt="{X \rightarrow D(X,X_{t}) + X\bullet L_{t} }" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX+%5Crightarrow+D%28X%2CX_%7Bt%7D%29+%2B+X%5Cbullet+L_%7Bt%7D+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and set it to zero. The gradient of <img alt="{X\bullet L_t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%5Cbullet+L_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is just <img alt="{L_t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. The gradient of <img alt="{D(X,X_{t})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%28X%2CX_%7Bt%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is</p>
<p align="center"><img alt="\displaystyle  \nabla D(X,X_t) = c \nabla X \bullet \log X - c \nabla X \bullet \log X_t - \nabla c X \bullet I " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cnabla+D%28X%2CX_t%29+%3D+c+%5Cnabla+X+%5Cbullet+%5Clog+X+-+c+%5Cnabla+X+%5Cbullet+%5Clog+X_t+-+%5Cnabla+c+X+%5Cbullet+I+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p align="center"><img alt="\displaystyle  = cI + c \log X - c \log X_t - cI " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%3D+cI+%2B+c+%5Clog+X+-+c+%5Clog+X_t+-+cI+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> Meaning that we want to solve for</p>
<p align="center"><img alt="\displaystyle  c \log X - c\log X_t + L_t = 0 " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++c+%5Clog+X+-+c%5Clog+X_t+%2B+L_t+%3D+0+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> and <img alt="{\hat X_{t+1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Chat+X_%7Bt%2B1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> satisfies</p>
<p align="center"><img alt="\displaystyle \log X_t - \log \hat X_{t+1} = \frac 1c L_t " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Clog+X_t+-+%5Clog+%5Chat+X_%7Bt%2B1%7D+%3D+%5Cfrac+1c+L_t+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p align="center"><img alt="\displaystyle  \hat X_{t+1} = e^{\log X_t - \frac 1c L_t } " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Chat+X_%7Bt%2B1%7D+%3D+e%5E%7B%5Clog+X_t+-+%5Cfrac+1c+L_t+%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> and we can write</p>
<p align="center"><img alt="\displaystyle  D(X_t,\hat X_{t+1} ) = c \cdot \left( X_t \bullet (\log X_t - \log \hat X_{t+1})\right) + c {\rm tr}( \hat X_{t+1} )" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++D%28X_t%2C%5Chat+X_%7Bt%2B1%7D+%29+%3D+c+%5Ccdot+%5Cleft%28+X_t+%5Cbullet+%28%5Clog+X_t+-+%5Clog+%5Chat+X_%7Bt%2B1%7D%29%5Cright%29+%2B+c+%7B%5Crm+tr%7D%28+%5Chat+X_%7Bt%2B1%7D+%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p align="center"><img alt="\displaystyle  = c \cdot X_t \bullet \frac 1c L_t + c \cdot {\rm tr}(e^{\log X_t - \frac 1c L_t}) + c {\rm tr} \hat X_{t+1} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%3D+c+%5Ccdot+X_t+%5Cbullet+%5Cfrac+1c+L_t+%2B+c+%5Ccdot+%7B%5Crm+tr%7D%28e%5E%7B%5Clog+X_t+-+%5Cfrac+1c+L_t%7D%29+%2B+c+%7B%5Crm+tr%7D+%5Chat+X_%7Bt%2B1%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> Then we can use Golden-Thompson and the fact that <img alt="{e^-\frac 1c L_t \preceq I - \frac 1c L_t + \frac 1{c^2} L^2_t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Be%5E-%5Cfrac+1c+L_t+%5Cpreceq+I+-+%5Cfrac+1c+L_t+%2B+%5Cfrac+1%7Bc%5E2%7D+L%5E2_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, which holds if <img alt="{L_t \preceq cI}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_t+%5Cpreceq+cI%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, to write</p>
<p align="center"><img alt="\displaystyle  {\rm tr}(e^{\log X_t - \frac 1c L_t}) \leq {\rm tr}(e^{\log X_t} \cdot e^{-\frac 1c L_t} ) = X_t \bullet e^{-\frac 1c L_t} \leq X_t \bullet \left( I - \frac 1c L_t + \frac 1{c^2} L^2_t \right) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7B%5Crm+tr%7D%28e%5E%7B%5Clog+X_t+-+%5Cfrac+1c+L_t%7D%29+%5Cleq+%7B%5Crm+tr%7D%28e%5E%7B%5Clog+X_t%7D+%5Ccdot+e%5E%7B-%5Cfrac+1c+L_t%7D+%29+%3D+X_t+%5Cbullet+e%5E%7B-%5Cfrac+1c+L_t%7D+%5Cleq+X_t+%5Cbullet+%5Cleft%28+I+-+%5Cfrac+1c+L_t+%2B+%5Cfrac+1%7Bc%5E2%7D+L%5E2_t+%5Cright%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> Combining everything together we have</p>
<p align="center"><img alt="\displaystyle  D(X_t,\hat X_{t+1} ) \leq \frac 1c X_t \bullet L_t^2 " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++D%28X_t%2C%5Chat+X_%7Bt%2B1%7D+%29+%5Cleq+%5Cfrac+1c+X_t+%5Cbullet+L_t%5E2+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> and so, provided <img alt="{\lambda_{\max} (L_t) \leq c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda_%7B%5Cmax%7D+%28L_t%29+%5Cleq+c%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>,</p>
<p align="center"><img alt="\displaystyle  Regret_T \leq c \log n + \frac 1c \sum_{t=1}^T X_t \bullet L_t^2 " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++Regret_T+%5Cleq+c+%5Clog+n+%2B+%5Cfrac+1c+%5Csum_%7Bt%3D1%7D%5ET+X_t+%5Cbullet+L_t%5E2+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> This is the best bound we can hope for, and it matches Theorem 1 in <a href="https://lucatrevisan.wordpress.com/2019/04/24/online-optimization-post-1-multiplicative-weights/">our first post</a> about the Xultiplicative Weights Update algorithm.</p>
<p>If we have <img alt="{L_t \preceq I}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_t+%5Cpreceq+I%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, we can simplify it to</p>
<p align="center"><img alt="\displaystyle  Regret_T \leq c \log n + \frac T c = 2 \sqrt{T \log n} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++Regret_T+%5Cleq+c+%5Clog+n+%2B+%5Cfrac+T+c+%3D+2+%5Csqrt%7BT+%5Clog+n%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> where the last step comes from optimizing <img alt="{c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>.</p>
<p>We can also write, under the condition <img alt="{L_t \preceq c I}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_t+%5Cpreceq+c+I%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>,</p>
<p align="center"><img alt="\displaystyle  Regret_T (X) \leq c \log n + \frac 1c \sum_{t=1}^T (X_t \bullet |L_t| )||L_t|| " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++Regret_T+%28X%29+%5Cleq+c+%5Clog+n+%2B+%5Cfrac+1c+%5Csum_%7Bt%3D1%7D%5ET+%28X_t+%5Cbullet+%7CL_t%7C+%29%7C%7CL_t%7C%7C+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> where <img alt="{|L_t|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7CL_t%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is the “absolute value” of the matrix <img alt="{L_t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> defined in the following way: if <img alt="{X = \sum_i \lambda_i v_i v_i^T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX+%3D+%5Csum_i+%5Clambda_i+v_i+v_i%5ET%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is a symmetric matrix, then its absolute value is <img alt="{|X| = \sum_i |\lambda_i| \cdot v_i v_i^T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7CX%7C+%3D+%5Csum_i+%7C%5Clambda_i%7C+%5Ccdot+v_i+v_i%5ET%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. Allen-Zhu, Liao and Orecchia state the analysis in this way in their <a href="https://arxiv.org/abs/1506.04838">on generalizations of Matrix Multiplicative Weights</a>.</p>
<p>Our next post will discuss applications at length, but for now let us gain a bit of intuition about the usefulness of these regret bounds. Recall that, for every symmetric matrix <img alt="{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, we have</p>
<p align="center"><img alt="\displaystyle  \lambda_{\min} (M) = \min_{X \rm\ density\ matrix} \ \ X \bullet M " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clambda_%7B%5Cmin%7D+%28M%29+%3D+%5Cmin_%7BX+%5Crm%5C+density%5C+matrix%7D+%5C+%5C+X+%5Cbullet+M+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> and so the regret bound can be reintepreted in the following way: if we let <img alt="{L_1,\ldots,L_T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_1%2C%5Cldots%2CL_T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> be the loss functions used in a game played against a MMWU algorithm, and the algorithm selects density matrices <img alt="{X_1,\ldots,X_T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_1%2C%5Cldots%2CX_T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, then</p>
<p align="center"><img alt="\displaystyle  \sum_{t=1}^T X_t \bullet L_t - \min_{X \rm \ density \ matrix} \ \ X \bullet \sum_{t=1}^T L_t \leq c \log n + \frac 1c \sum_{t=1}^T X_t \bullet L_t^2 " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_%7Bt%3D1%7D%5ET+X_t+%5Cbullet+L_t+-+%5Cmin_%7BX+%5Crm+%5C+density+%5C+matrix%7D+%5C+%5C+X+%5Cbullet+%5Csum_%7Bt%3D1%7D%5ET+L_t+%5Cleq+c+%5Clog+n+%2B+%5Cfrac+1c+%5Csum_%7Bt%3D1%7D%5ET+X_t+%5Cbullet+L_t%5E2+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> that is,</p>
<p align="center"><img alt="\displaystyle  \sum_{t=1}^T X_t \bullet L_t - \lambda_{\min} \left( \sum_{t=1}^T L_t \right) \leq c \log n + \frac 1c \sum_{t=1}^T X_t \bullet L_t^2 " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_%7Bt%3D1%7D%5ET+X_t+%5Cbullet+L_t+-+%5Clambda_%7B%5Cmin%7D+%5Cleft%28+%5Csum_%7Bt%3D1%7D%5ET+L_t+%5Cright%29+%5Cleq+c+%5Clog+n+%2B+%5Cfrac+1c+%5Csum_%7Bt%3D1%7D%5ET+X_t+%5Cbullet+L_t%5E2+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> provided that <img alt="{L_t \preceq cI}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_t+%5Cpreceq+cI%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. For example, switching <img alt="{L_t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> with <img alt="{-L_t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-L_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, we have <a name="main"/></p>
<p><a name="main"/></p><a name="main">
<p align="center"><img alt="\displaystyle   \lambda_{\max} \left( \sum_{t=1}^T L_t \right) \leq \sum_{t=1}^T X_t \bullet L_t + \frac 1c \sum_{t=1}^T X_t \bullet L_t^2 + c\log n \ \ \ \ \ (1)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+++%5Clambda_%7B%5Cmax%7D+%5Cleft%28+%5Csum_%7Bt%3D1%7D%5ET+L_t+%5Cright%29+%5Cleq+%5Csum_%7Bt%3D1%7D%5ET+X_t+%5Cbullet+L_t+%2B+%5Cfrac+1c+%5Csum_%7Bt%3D1%7D%5ET+X_t+%5Cbullet+L_t%5E2+%2B+c%5Clog+n+%5C+%5C+%5C+%5C+%5C+%281%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
</a><p><a name="main"/><a name="main"/> provided that <img alt="{L_t \succeq -cI}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_t+%5Csucceq+-cI%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, which means that if we can choose a sequence of loss matrices that make the MMWU have small loss at each step, then we are guaranteed that the sum of such matrices cannot have any large eigenvalue.</p></div>
    </content>
    <updated>2021-11-10T12:11:57Z</updated>
    <published>2021-11-10T12:11:57Z</published>
    <category term="theory"/>
    <category term="matrix multiplicative weights update"/>
    <category term="online optimization"/>
    <author>
      <name>luca</name>
    </author>
    <source>
      <id>https://lucatrevisan.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://lucatrevisan.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://lucatrevisan.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://lucatrevisan.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://lucatrevisan.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>"Marge, I agree with you - in theory. In theory, communism works. In theory." -- Homer Simpson</subtitle>
      <title>in   theory</title>
      <updated>2022-04-09T22:47:39Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://lucatrevisan.wordpress.com/?p=4576</id>
    <link href="https://lucatrevisan.wordpress.com/2021/10/21/postdoc-positions/" rel="alternate" type="text/html"/>
    <title>Postdoc Positions</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">The call is out for two postdoctoral positions at Bocconi to work in my group (see below for how to apply). If you are interested and you have any questions, feel free to email me (L.Trevisan at Unibocconi dot it) … <a href="https://lucatrevisan.wordpress.com/2021/10/21/postdoc-positions/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The<a href="https://jobmarket.unibocconi.eu/include/dwload.php?a=NTUwXjQ0M2QwY2Y4N2FhMjA2MDcxN2MwMzc3NGZjODM4NGU0Xi9kMC9qb2JtYXJrZXQudW5pYm9jY29uaS5ldS91cGxvYWQvQklEL3Nlc3Npb25fMTM3LTIwMjExMDE4Xmpta19zZXNfZmlsZV5qbWZfXmptZl9maWxlXjM2OQ=="> call is out</a> for two postdoctoral positions at Bocconi to work in my group (see below for how to apply). If you are interested and you have any questions, feel free to email me (L.Trevisan at Unibocconi dot it)</p>



<p>The negotiable start date is September 1st, 2022. Each position is for one year, renewable for a second. The positions offer an internationally competitive salary (up to 65,000 Euro per year, tax-free, plus relocation assistance and travel allowance), in a wonderful location that, at long last, is back to more or less normal life. The application deadline is <strong>December 17, 2021</strong>.</p>



<p>Among the topics that I am interested in are spectral graph theory, average-case complexity, “applications” of semidefinite programming, random processes on networks, approximation algorithms, pseudorandomness and combinatorial constructions.</p>



<p>Bocconi Computer Science is building up a theory group: besides me, we have <a href="https://www.alonrosen.net/">Alon Rosen</a>, <a href="https://elias.ba30.eu/">Marek Elias</a>, a tenured person that will join next Fall, and more hires are on the horizon. Now that traveling is ok again, and considering that Alon and I both have ERC grants, we should expect a big stream of theory visitors coming and going through Bocconi from week-long visits to semester or year long sabbaticals.</p>



<p>To apply, go to <a href="https://www.unibocconi.eu/faculty-postdoc">https://www.unibocconi.eu/faculty-postdoc</a> and look for the position advertised as “BIDSA Informatics”, which looks like this:</p>



<figure class="wp-block-image size-large"><a href="https://lucatrevisan.files.wordpress.com/2021/11/bidsa.png"><img alt="" class="wp-image-4594" src="https://lucatrevisan.files.wordpress.com/2021/11/bidsa.png?w=1024"/></a></figure>



<p>and click on “apply online”. Currently it is the second position from the top in the list</p></div>
    </content>
    <updated>2021-10-21T17:04:44Z</updated>
    <published>2021-10-21T17:04:44Z</published>
    <category term="Milan"/>
    <category term="theory"/>
    <category term="postdoc"/>
    <author>
      <name>luca</name>
    </author>
    <source>
      <id>https://lucatrevisan.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://lucatrevisan.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://lucatrevisan.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://lucatrevisan.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://lucatrevisan.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>"Marge, I agree with you - in theory. In theory, communism works. In theory." -- Homer Simpson</subtitle>
      <title>in   theory</title>
      <updated>2022-04-09T22:47:51Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://lucatrevisan.wordpress.com/?p=4572</id>
    <link href="https://lucatrevisan.wordpress.com/2021/10/20/online-optimization-post-6-the-impagliazzo-hard-core-set-lemma/" rel="alternate" type="text/html"/>
    <title>Online Optimization Post 6: The Impagliazzo Hard-Core Set Lemma</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">(This is the sixth in a series of posts on online optimization techniques and their “applications” to complexity theory, combinatorics and pseudorandomness. The plan for this series of posts is to alternate one post explaining a result from the theory … <a href="https://lucatrevisan.wordpress.com/2021/10/20/online-optimization-post-6-the-impagliazzo-hard-core-set-lemma/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><em>(This is the sixth in a series of posts on online optimization techniques and their “applications” to complexity theory, combinatorics and pseudorandomness. The plan for this series of posts is to alternate one post explaining a result from the theory of online convex optimization and one post explaining an “application.” The first two posts were about the technique of multiplicative weight updates and its application to “derandomizing” probabilistic arguments based on combining a Chernoff bound and a union bound. The third and fourth post were about the Follow-the-Regularized-Leader framework, and how it unifies multiplicative weights and gradient descent, and a “gradient descent view” of the Frieze-Kannan Weak Regularity Lemma. The fifth post was about the constrained version of the Follow-the-Regularized-Leader framework, and today we shall see how to apply that to a proof of the Impagliazzo Hard-Core Lemma.)</em></p>
<p><span id="more-4572"/></p>
<p><b>1. The Impagliazzo Hard-Core Lemma </b></p>
<p>The Impagliazzo Hard-Core Lemma is a striking result in the theory of average-case complexity. Roughly speaking, it says that if <img alt="{g: \{ 0,1 \}^n \rightarrow \{ 0,1 \}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%3A+%5C%7B+0%2C1+%5C%7D%5En+%5Crightarrow+%5C%7B+0%2C1+%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is a function that is “weakly” hard on average for a class <img alt="{\cal F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+F%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> of “efficiently computable” functions <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, that is, if, for some <img alt="{\delta&gt;0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, we have that</p>
<p align="center"><img alt="\displaystyle \forall f \in {\cal F}: \ \ \Pr_{x\sim \{ 0,1\}^n} [f(x) = g(x) ] \leq 1 -\delta " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cforall+f+%5Cin+%7B%5Ccal+F%7D%3A+%5C+%5C+%5CPr_%7Bx%5Csim+%5C%7B+0%2C1%5C%7D%5En%7D+%5Bf%28x%29+%3D+g%28x%29+%5D+%5Cleq+1+-%5Cdelta+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>then there is a subset <img alt="{H\subseteq \{ 0,1 \}^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BH%5Csubseteq+%5C%7B+0%2C1+%5C%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> of cardinality <img alt="{\geq 2\delta 2^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cgeq+2%5Cdelta+2%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> such that <img alt="{g}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is “strongly” hard-on-average on <img alt="{H}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, meaning that</p>
<p align="center"><img alt="\displaystyle \forall f \in {\cal F}: \ \ \Pr_{x\sim H} [f(x) = g(x) ] \leq \frac 12 + \epsilon " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cforall+f+%5Cin+%7B%5Ccal+F%7D%3A+%5C+%5C+%5CPr_%7Bx%5Csim+H%7D+%5Bf%28x%29+%3D+g%28x%29+%5D+%5Cleq+%5Cfrac+12+%2B+%5Cepsilon+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>for a small <img alt="{\epsilon &gt;0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon+%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. Thus, the reason why functions from <img alt="{\cal F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+F%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> make a mistake in predicting <img alt="{g}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> at least a <img alt="{\delta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> fraction of the times is that there is a “hard-core” set <img alt="{H}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> of inputs such that every function from <img alt="{\cal F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+F%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> makes a mistake about 1/2 of the times for the <img alt="{2\delta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> fraction of inputs coming from <img alt="{H}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>.</p>
<p>The result is actually not literally true as stated above, and it is useful to understand a counterexample, in order to motivate the correct statement. Suppose that <img alt="{\cal F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+F%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> contains just <img alt="{1/\delta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%2F%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> functions, and that each function <img alt="{f\in \cal F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%5Cin+%5Ccal+F%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> differs from <img alt="{g}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> in exactly a <img alt="{\delta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> fraction of inputs from <img alt="{\{ 0,1 \}^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B+0%2C1+%5C%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, and that the set of mistakes are <em>disjoint</em>. Thus, for every set <img alt="{H\subseteq \{ 0,1 \}^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BH%5Csubseteq+%5C%7B+0%2C1+%5C%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, no matter its size, there is a function <img alt="{f\in \cal F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%5Cin+%5Ccal+F%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> that agrees with <img alt="{g}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> on at least a <img alt="{1-\delta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1-%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> fraction of inputs from <img alt="{H}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. The reason is that the sets of inputs on which the functions of <img alt="{\cal F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+F%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> differ from <img alt="{g}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> form a partition of <img alt="{\{ 0,1 \}^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B+0%2C1+%5C%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, and so their intersections with <img alt="{H}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> form a partition of <img alt="{H}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. By an averaging argument, one of those intersections must then contain at most <img alt="{\delta |H|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+%7CH%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> elements of <img alt="{H}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>.</p>
<p>In the above example, however, if we choose any three distinct functions <img alt="{f_1,f_2,f_3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_1%2Cf_2%2Cf_3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> from <img alt="{\cal F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+F%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, we have</p>
<p align="center"><img alt="\displaystyle \forall x\in \{ 0,1 \}^n: \ \ \ g(x) = {\rm majority} (f_1(x), f_2(x),f_3(x)) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cforall+x%5Cin+%5C%7B+0%2C1+%5C%7D%5En%3A+%5C+%5C+%5C+g%28x%29+%3D+%7B%5Crm+majority%7D+%28f_1%28x%29%2C+f_2%28x%29%2Cf_3%28x%29%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>So, although <img alt="{g}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is weakly hard on average with respect to <img alt="{\cal F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+F%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, we have that <img alt="{g}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is not even worst-case hard for a slight extension of <img alt="{\cal F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+F%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> in which we allow functions obtained by simple compositions of a small number of functions of <img alt="{\cal F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+F%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>.</p>
<blockquote><p><b>Theorem 1 (Impagliazzo Hard-Core Lemma)</b> <em> Let <img alt="{\cal F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+F%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> be a collection of functions <img alt="{f: \{ 0,1 \}^n \rightarrow \{ 0,1 \}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%3A+%5C%7B+0%2C1+%5C%7D%5En+%5Crightarrow+%5C%7B+0%2C1+%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, let <img alt="{g: \{ 0,1 \}^n \rightarrow \{ 0,1 \}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%3A+%5C%7B+0%2C1+%5C%7D%5En+%5Crightarrow+%5C%7B+0%2C1+%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> a function, and let <img alt="{\epsilon&gt;0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and <img alt="{\delta &gt;0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> be positive reals. Then at least one of the following conditions is true: </em></p>
<ul>
<li>(<img alt="{g}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is not weakly hard-on-average over <img alt="{\{ 0,1 \}^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B+0%2C1+%5C%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> with respect to a slight extension of <img alt="{\cal F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+F%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>) There is a <img alt="{k= O(\epsilon^{-2} \log \delta^{-1} )}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%3D+O%28%5Cepsilon%5E%7B-2%7D+%5Clog+%5Cdelta%5E%7B-1%7D+%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, an integer <img alt="{b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, and <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> functions <img alt="{f_1,\ldots,f_k \in \cal F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_1%2C%5Cldots%2Cf_k+%5Cin+%5Ccal+F%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, such that
<p align="center"><img alt="\displaystyle h(x) := I \{ f_1(x) + \ldots + f_k(x)\geq b \} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+h%28x%29+%3A%3D+I+%5C%7B+f_1%28x%29+%2B+%5Cldots+%2B+f_k%28x%29%5Cgeq+b+%5C%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>satisfies</p>
<p align="center"><img alt="\displaystyle \Pr_{x\in \{ 0,1 \}^n} [ g(x) = h(x) ] \geq 1-\delta " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5CPr_%7Bx%5Cin+%5C%7B+0%2C1+%5C%7D%5En%7D+%5B+g%28x%29+%3D+h%28x%29+%5D+%5Cgeq+1-%5Cdelta+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
</li>
<li>(<img alt="{g}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is strongly hard-on-average over a set <img alt="{H}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> of density <img alt="{2\delta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>) There is a set <img alt="{H\subseteq \{ 0,1 \}^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BH%5Csubseteq+%5C%7B+0%2C1+%5C%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> such that <img alt="{H \geq 2\delta \cdot 2^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BH+%5Cgeq+2%5Cdelta+%5Ccdot+2%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and
<p align="center"><img alt="\displaystyle \forall f\in {\cal F}: \ \ \Pr_{x\in H} [ g(x) = f(x) ] \leq \frac 12 + \epsilon " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cforall+f%5Cin+%7B%5Ccal+F%7D%3A+%5C+%5C+%5CPr_%7Bx%5Cin+H%7D+%5B+g%28x%29+%3D+f%28x%29+%5D+%5Cleq+%5Cfrac+12+%2B+%5Cepsilon+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
</li>
</ul>
</blockquote>
<p>Where <img alt="{I \{ {\rm boolean\ expression} \}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BI+%5C%7B+%7B%5Crm+boolean%5C+expression%7D+%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is equal to <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> or <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> depending on whether the boolean expression is true or false (the letter “<img alt="{I}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BI%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>” stands for “indicator” function of the truth of the expression).</p>
<p><b>2. Proving the Lemma </b></p>
<p>Impagliazzo’s proof had <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> polynomial in both <img alt="{1/\epsilon}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%2F%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and <img alt="{1/\delta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%2F%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, and an alternative proof discovered by Nisan has a stronger bound on <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> of the order of <img alt="{\epsilon^{-2} \log \epsilon^{-1} \delta^{-1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%5E%7B-2%7D+%5Clog+%5Cepsilon%5E%7B-1%7D+%5Cdelta%5E%7B-1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. The proofs of Impagliazzo and Nisan did not immediately give a set of size <img alt="{2\delta2^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5Cdelta2%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> (the set had size <img alt="{\delta 2^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+2%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>), although this could be achieved by iterating their argument. An idea of Holenstein allows to prove the above statement in a more direct way.</p>
<p>Today we will see how to obtain the Impagliazzo Hard-Core Lemma from online optimization, as done by Barak, Hardt and Kale. Their proof achieves all the parameters claimed above, once combined with Holenstein’s ideas.</p>
<p><!--more--></p>
<p>We say that a distribution <img alt="{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> (here “<img alt="{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>” stands for probability <em>measure</em>; we use this letter since we have already used <img alt="{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> last time to denote the Bregman divergence) has min-entropy at least <img alt="{K}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BK%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> if, for every <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, <img alt="{M(x) \leq 2^{-K}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%28x%29+%5Cleq+2%5E%7B-K%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. In other words, the min-entropy of a distribution <img alt="{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> over a sample space <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is defined as</p>
<p align="center"><img alt="\displaystyle H_{\infty} (M) := \min_{x\in X} \log_2 \frac 1 {M(x)} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+H_%7B%5Cinfty%7D+%28M%29+%3A%3D+%5Cmin_%7Bx%5Cin+X%7D+%5Clog_2+%5Cfrac+1+%7BM%28x%29%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>The uniform distribution over a set <img alt="{H}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> has min-entropy <img alt="{\log_2 |H|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog_2+%7CH%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, and all distributions of min-entropy <img alt="{K}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BK%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> can be realized as a convex combination of distributions that are each uniform over a set of size <img alt="{\geq K}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cgeq+K%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, thus uniform distributions over large sets and large-min-entropy distributions are closely-related concepts. We will prove the following version of the hard-core lemma:</p>
<blockquote><p><b>Theorem 2 (Impagliazzo Hard-Core Lemma — Min-Entropy Version)</b> <em> Let <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> be a finite set, <img alt="{\cal F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+F%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> be a collection of functions <img alt="{f: X \rightarrow \{ 0,1 \}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%3A+X+%5Crightarrow+%5C%7B+0%2C1+%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, let <img alt="{g: X \rightarrow \{ 0,1 \}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%3A+X+%5Crightarrow+%5C%7B+0%2C1+%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> a function, and let <img alt="{\epsilon&gt;0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and <img alt="{\delta &gt;0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> be positive reals. Then at least one of the following conditions is true: </em></p>
<ul>
<li>(<img alt="{g}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is not weakly hard-on-average over <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> with respect to <img alt="{\cal F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+F%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>) There is a <img alt="{k= O(\epsilon^{-2} \log \delta^{-1} )}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%3D+O%28%5Cepsilon%5E%7B-2%7D+%5Clog+%5Cdelta%5E%7B-1%7D+%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, an integer <img alt="{b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, and <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> functions <img alt="{f_1,\ldots,f_k \in \cal F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_1%2C%5Cldots%2Cf_k+%5Cin+%5Ccal+F%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, such that
<p align="center"><img alt="\displaystyle h(x) := I \{ f_1(x) + \ldots + f_k(x)\geq b \} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+h%28x%29+%3A%3D+I+%5C%7B+f_1%28x%29+%2B+%5Cldots+%2B+f_k%28x%29%5Cgeq+b+%5C%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>satisfies</p>
<p align="center"><img alt="\displaystyle \Pr_{x\in X} [ g(x) = h(x) ] \geq 1-\delta " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5CPr_%7Bx%5Cin+X%7D+%5B+g%28x%29+%3D+h%28x%29+%5D+%5Cgeq+1-%5Cdelta+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
</li>
<li>(<img alt="{g}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is strongly hard-on-average on a distribution of min-entropy <img alt="{\geq \log_2 2\delta |X|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cgeq+%5Clog_2+2%5Cdelta+%7CX%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>) There is a distribution <img alt="{H}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> of min-entropy <img alt="{\geq \log_2 2\delta|X|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cgeq+%5Clog_2+2%5Cdelta%7CX%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> such that
<p align="center"><img alt="\displaystyle \forall f\in {\cal F}: \ \ \Pr_{x\sim H} [ g(x) = f(x) ] \leq \frac 12 + \epsilon " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cforall+f%5Cin+%7B%5Ccal+F%7D%3A+%5C+%5C+%5CPr_%7Bx%5Csim+H%7D+%5B+g%28x%29+%3D+f%28x%29+%5D+%5Cleq+%5Cfrac+12+%2B+%5Cepsilon+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
</li>
</ul>
</blockquote>
<p>Under minimal assumptions on <img alt="{\cal F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+F%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> (that it contains <img alt="{&lt;&lt; 2^{|X|}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%3C%3C+2%5E%7B%7CX%7C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> functions), the min-entropy version implies the set version, and the min-entropy version can be used as-is to derive most of the interesting consequences of the set version.</p>
<p>Let us restate it one more time.</p>
<blockquote><p><b>Theorem 3 (Impagliazzo Hard-Core Lemma — Min-Entropy Version)</b> <em> Let <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> be a finite set, <img alt="{\cal F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+F%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> be a collection of functions <img alt="{f: X \rightarrow \{ 0,1 \}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%3A+X+%5Crightarrow+%5C%7B+0%2C1+%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, let <img alt="{g: X \rightarrow \{ 0,1 \}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%3A+X+%5Crightarrow+%5C%7B+0%2C1+%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> a function, and let <img alt="{\epsilon&gt;0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and <img alt="{\delta &gt;0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> be positive reals. Suppose that for every distribution <img alt="{H}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> of min-entropy <img alt="{\geq \log_2 2\delta|X|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cgeq+%5Clog_2+2%5Cdelta%7CX%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> we have </em></p>
<p align="center"><img alt="\displaystyle \forall f\in {\cal F}: \ \ \Pr_{x\sim H} [ g(x) = f(x) ] &gt; \frac 12 + \epsilon " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cforall+f%5Cin+%7B%5Ccal+F%7D%3A+%5C+%5C+%5CPr_%7Bx%5Csim+H%7D+%5B+g%28x%29+%3D+f%28x%29+%5D+%3E+%5Cfrac+12+%2B+%5Cepsilon+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>Then there is a <img alt="{k= O(\epsilon^{-2} \log \delta^{-1} )}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%3D+O%28%5Cepsilon%5E%7B-2%7D+%5Clog+%5Cdelta%5E%7B-1%7D+%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, an integer <img alt="{b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, and <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> functions <img alt="{f_1,\ldots,f_k \in \cal F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_1%2C%5Cldots%2Cf_k+%5Cin+%5Ccal+F%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, such that</p>
<p align="center"><img alt="\displaystyle h(x) := I \{ f_1(x) + \ldots + f_k(x)\geq b \} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+h%28x%29+%3A%3D+I+%5C%7B+f_1%28x%29+%2B+%5Cldots+%2B+f_k%28x%29%5Cgeq+b+%5C%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>satisfies</p>
<p align="center"><img alt="\displaystyle \Pr_{x\in X} [ g(x) = h(x) ] \geq 1-\delta " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5CPr_%7Bx%5Cin+X%7D+%5B+g%28x%29+%3D+h%28x%29+%5D+%5Cgeq+1-%5Cdelta+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
</blockquote>
<p>As in previous posts, we are going to think about a game between a “builder” that works toward the construction of <img alt="{h}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bh%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and an “inspector” that looks for defects in the construction. More specifically, at every round <img alt="{i = 1,\ldots,T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi+%3D+1%2C%5Cldots%2CT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, the inspector is going to pick a distribution <img alt="{M_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> of min-entropy <img alt="{\geq \log_2 2\delta|X|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cgeq+%5Clog_2+2%5Cdelta%7CX%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and the builder is going to pick a function <img alt="{f_i\in {\cal F}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_i%5Cin+%7B%5Ccal+F%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. The loss function, that the inspector wants to minimize, is</p>
<p align="center"><img alt="\displaystyle L_i (M) := \mathop{\mathbb P}_{x\sim M} [f_i (x) = g(x)] " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+L_i+%28M%29+%3A%3D+%5Cmathop%7B%5Cmathbb+P%7D_%7Bx%5Csim+M%7D+%5Bf_i+%28x%29+%3D+g%28x%29%5D+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>The inspector runs the agile online mirror descent algorithm with the constraint of picking distributions of the required min-entropy, and using the entropy regularizer; the builder always chooses a function <img alt="{f_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> such that that</p>
<p align="center"><img alt="\displaystyle L_i (M) := \mathop{\mathbb P}_{x\sim M} [f_i (x) = g(x)] &gt; \frac 12 + \epsilon " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+L_i+%28M%29+%3A%3D+%5Cmathop%7B%5Cmathbb+P%7D_%7Bx%5Csim+M%7D+%5Bf_i+%28x%29+%3D+g%28x%29%5D+%3E+%5Cfrac+12+%2B+%5Cepsilon+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>which is always a possible choice given the assumptions of our theorem.</p>
<p>Just by plugging the above setting into the analysis from the previous post, we get that if we play this online game for <img alt="{T = O(\epsilon^{-2} \log \delta^{-1})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT+%3D+O%28%5Cepsilon%5E%7B-2%7D+%5Clog+%5Cdelta%5E%7B-1%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> steps, the builder picks functions <img alt="{f_1,\ldots,f_T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_1%2C%5Cldots%2Cf_T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> such that, <em>for every distribution</em> <img alt="{H}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> of min-entropy <img alt="{\geq \log 2\delta |X|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cgeq+%5Clog+2%5Cdelta+%7CX%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, we have</p>
<p><a name="game"/></p>
<p><a name="game"/></p>
<p><a name="game"/></p>
<p><a name="game"/></p>
<p align="center"><img alt="\displaystyle \Pr_{x\sim H, \ i \sim \{ 1,\ldots,T \} } [ f_i(x) = g(x) ] &gt; \frac 12 \ \ \ \ \ (1)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5CPr_%7Bx%5Csim+H%2C+%5C+i+%5Csim+%5C%7B+1%2C%5Cldots%2CT+%5C%7D+%7D+%5B+f_i%28x%29+%3D+g%28x%29+%5D+%3E+%5Cfrac+12+%5C+%5C+%5C+%5C+%5C+%281%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p><a name="game"/><a name="game"/><a name="game"/><a name="game"/></p>
<p>We will prove that <a href="https://lucatrevisan.wordpress.com/feed/#game">(1)</a> holds in the next section, but we emphasize again that it is just a matter of mechanically using the analysis from the previous post. Impagliazzo’s proof relies, basically, on playing the game using lazy mirror descent with <img alt="{\ell_2^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell_2%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> regularization, and he obtains a guarantee like the one above after <img alt="{T=O(\epsilon^{-2} \delta^{-1})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%3DO%28%5Cepsilon%5E%7B-2%7D+%5Cdelta%5E%7B-1%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> steps.</p>
<p>What do we do with <a href="https://lucatrevisan.wordpress.com/feed/#game">(1)</a>? Impagliazzo’s original reasoning was to define</p>
<p align="center"><img alt="\displaystyle h(x) := majority (f_1(x),\ldots,f_T(x)) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+h%28x%29+%3A%3D+majority+%28f_1%28x%29%2C%5Cldots%2Cf_T%28x%29%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>and to consider the set <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> of “bad” inputs <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> such that <img alt="{h(x) \neq g(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bh%28x%29+%5Cneq+g%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. We have</p>
<p align="center"><img alt="\displaystyle \forall x \in B \ \ \Pr_{i \sim \{ 1,\ldots,T \} } [ f_i(x) = g(x) ] \leq \frac 12 " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cforall+x+%5Cin+B+%5C+%5C+%5CPr_%7Bi+%5Csim+%5C%7B+1%2C%5Cldots%2CT+%5C%7D+%7D+%5B+f_i%28x%29+%3D+g%28x%29+%5D+%5Cleq+%5Cfrac+12+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>and so</p>
<p align="center"><img alt="\displaystyle \Pr_{x\sim B, \ i \sim \{ 1,\ldots,T \} } [ f_i(x) = g(x) ] \leq \frac 12 " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5CPr_%7Bx%5Csim+B%2C+%5C+i+%5Csim+%5C%7B+1%2C%5Cldots%2CT+%5C%7D+%7D+%5B+f_i%28x%29+%3D+g%28x%29+%5D+%5Cleq+%5Cfrac+12+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>The min-entropy of the uniform distribution over <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is <img alt="{\log_2 |B|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog_2+%7CB%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, and this needs to be less than <img alt="{\log_2 2\delta |X|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog_2+2%5Cdelta+%7CX%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, so we conclude that <img alt="{h(x) \neq g(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bh%28x%29+%5Cneq+g%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> happens for at most a <img alt="{2\delta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> fraction of elements of <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>.</p>
<p>This is qualitatively what we promised, but it is off by a factor of 2 from what we stated above. The factor of 2 comes from a subsequent idea of Holenstein. In Holenstein’s analysis, we sort elements of <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> according to</p>
<p align="center"><img alt="\displaystyle \Pr_{i \sim \{ 1,\ldots, T \}} [ f_i(x) = g_i (x) ] " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5CPr_%7Bi+%5Csim+%5C%7B+1%2C%5Cldots%2C+T+%5C%7D%7D+%5B+f_i%28x%29+%3D+g_i+%28x%29+%5D+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>and he lets <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> be the set of <img alt="{2\delta |X|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5Cdelta+%7CX%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> elements of <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> for which the above quantity is smallest, and he shows that if we properly pick an integer <img alt="{b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and define</p>
<p align="center"><img alt="\displaystyle h(x) := I\{ f_1(x) + \cdots + f_T(x) \geq b \} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+h%28x%29+%3A%3D+I%5C%7B+f_1%28x%29+%2B+%5Ccdots+%2B+f_T%28x%29+%5Cgeq+b+%5C%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>then <img alt="{h(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bh%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> will be equal to <img alt="{g(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> for all <img alt="{x\not\in B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%5Cnot%5Cin+B%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and also for at least half the <img alt="{x\in B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%5Cin+B%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, meaning that <img alt="{h(x) = g(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bh%28x%29+%3D+g%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> for at least a <img alt="{1-\delta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1-%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> fraction of the input. Since this is a bit outside the scope of this series of posts, we will not give an exposition of Holenstein’s argument.</p>
<p><b>3. Analysis of the Online Game </b></p>
<p>It remains to show that we can achieve <a href="https://lucatrevisan.wordpress.com/feed/#game">(1)</a> with <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> of the order of <img alt="{\frac 1 {\epsilon^2} \log \frac 1 {\delta}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac+1+%7B%5Cepsilon%5E2%7D+%5Clog+%5Cfrac+1+%7B%5Cdelta%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. As we said, we play a game in which, at every step <img alt="{i=1,\ldots,T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%3D1%2C%5Cldots%2CT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<ul>
<li>The “inspector” player picks a distribution <img alt="{M_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> of min-entropy at least <img alt="{\log_2 2\delta |X|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog_2+2%5Cdelta+%7CX%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, that is, it picks a number <img alt="{\frac 1 {2\delta |X|} \geq M_i(x)\geq 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac+1+%7B2%5Cdelta+%7CX%7C%7D+%5Cgeq+M_i%28x%29%5Cgeq+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> for each <img alt="{x\in X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%5Cin+X%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> such that <img alt="{\sum_x M_i(x) = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csum_x+M_i%28x%29+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>.</li>
<li>The “builder” player picks a function <img alt="{f_i \in {\cal F}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_i+%5Cin+%7B%5Ccal+F%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, whose existence is guaranteed by the assumption of the theorem, such that
<p align="center"><img alt="\displaystyle \Pr_{x\sim M_i} [f_i(x) = g(x) ] \geq \frac 12 +\epsilon " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5CPr_%7Bx%5Csim+M_i%7D+%5Bf_i%28x%29+%3D+g%28x%29+%5D+%5Cgeq+%5Cfrac+12+%2B%5Cepsilon+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>and defines the loss function</p>
<p align="center"><img alt="\displaystyle L_i(M) := \Pr_{x\sim M_i} [f_i(x) = g(x) ] = \sum_{x\in X} M(x) \cdot I\{ f_i(x) = g(x) \} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+L_i%28M%29+%3A%3D+%5CPr_%7Bx%5Csim+M_i%7D+%5Bf_i%28x%29+%3D+g%28x%29+%5D+%3D+%5Csum_%7Bx%5Cin+X%7D+M%28x%29+%5Ccdot+I%5C%7B+f_i%28x%29+%3D+g%28x%29+%5C%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
</li>
<li>The “inspector” is charged the loss <img alt="{L_i(M_i)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_i%28M_i%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>.</li>
</ul>
<p>We analyze what happens if the inspector plays the strategy defined by agile mirror descent with negative entropy regularizer. Namely, we define the regularizer</p>
<p align="center"><img alt="\displaystyle R(M) = c \sum_x M(x) \log M(x) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+R%28M%29+%3D+c+%5Csum_x+M%28x%29+%5Clog+M%28x%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>for a choice of <img alt="{c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> that we will fix later. The corresponding Bregman divergence is</p>
<p align="center"><img alt="\displaystyle D(M,\hat M) = c KL(M,\hat M) = c \cdot \left( \sum_x M(x) \log \frac {M(x)}{\hat M(x)} - \sum_x M(x) + \sum_x \hat M(x) \right) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+D%28M%2C%5Chat+M%29+%3D+c+KL%28M%2C%5Chat+M%29+%3D+c+%5Ccdot+%5Cleft%28+%5Csum_x+M%28x%29+%5Clog+%5Cfrac+%7BM%28x%29%7D%7B%5Chat+M%28x%29%7D+-+%5Csum_x+M%28x%29+%2B+%5Csum_x+%5Chat+M%28x%29+%5Cright%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>and we work over the space <img alt="{\cal K}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+K%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> of distributions of min-entropy <img alt="{\geq \log_2 2\delta |X|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cgeq+%5Clog_2+2%5Cdelta+%7CX%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>.</p>
<p>The agile online mirror descent algorithm is</p>
<p align="center"><img alt="\displaystyle M_1 = \arg\min_{M\in {\cal K}} R(M) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+M_1+%3D+%5Carg%5Cmin_%7BM%5Cin+%7B%5Ccal+K%7D%7D+R%28M%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>so that <img alt="{M_1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is the uniform distribution, and for <img alt="{i\geq 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%5Cgeq+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p align="center"><img alt="\displaystyle \hat M_{i+1} = \arg\min_{M: X \rightarrow {\mathbb R}} \ \ D(M_i,M) + L_i (M) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Chat+M_%7Bi%2B1%7D+%3D+%5Carg%5Cmin_%7BM%3A+X+%5Crightarrow+%7B%5Cmathbb+R%7D%7D+%5C+%5C+D%28M_i%2CM%29+%2B+L_i+%28M%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p align="center"><img alt="\displaystyle M_{i+1} = \arg\min_{M \in {\cal K}} \ \ D(M, \hat M_{i+1} )" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+M_%7Bi%2B1%7D+%3D+%5Carg%5Cmin_%7BM+%5Cin+%7B%5Ccal+K%7D%7D+%5C+%5C+D%28M%2C+%5Chat+M_%7Bi%2B1%7D+%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>Solving the first step of agile online mirror descent, we have</p>
<p align="center"><img alt="\displaystyle \hat M_{i+1} (x) = M_i(x) e^{-\frac 1c I \{ f(x) = g(x) \} } " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Chat+M_%7Bi%2B1%7D+%28x%29+%3D+M_i%28x%29+e%5E%7B-%5Cfrac+1c+I+%5C%7B+f%28x%29+%3D+g%28x%29+%5C%7D+%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>Using the analysis from the previous post, for every distribution <img alt="{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> in <img alt="{\cal K}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+K%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, and every number <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> of steps, we have the regret bound</p>
<p align="center"><img alt="\displaystyle \sum_{i=1}^T L_i(M_i) - L_i(M) \leq D(M,M_1) + \sum_{i=1}^T D(M_i, \hat M_{i+1} ) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Csum_%7Bi%3D1%7D%5ET+L_i%28M_i%29+-+L_i%28M%29+%5Cleq+D%28M%2CM_1%29+%2B+%5Csum_%7Bi%3D1%7D%5ET+D%28M_i%2C+%5Chat+M_%7Bi%2B1%7D+%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>and we can bound</p>
<p align="center"><img alt="\displaystyle D(M,M_1) = c \sum_x M(x) \cdot \ln |X| \cdot M(x) \leq c \ln \frac 1 {2\delta} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+D%28M%2CM_1%29+%3D+c+%5Csum_x+M%28x%29+%5Ccdot+%5Cln+%7CX%7C+%5Ccdot+M%28x%29+%5Cleq+c+%5Cln+%5Cfrac+1+%7B2%5Cdelta%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>and</p>
<p align="center"><img alt="\displaystyle D(M_i,\hat M_{i+1}) = c\cdot \left( \sum_x M_i(x) \ln \frac{M_i(x)}{\hat M_{i+1} (x) } + \sum_x \hat M_{i+1}(x) - M_i(x) \right) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+D%28M_i%2C%5Chat+M_%7Bi%2B1%7D%29+%3D+c%5Ccdot+%5Cleft%28+%5Csum_x+M_i%28x%29+%5Cln+%5Cfrac%7BM_i%28x%29%7D%7B%5Chat+M_%7Bi%2B1%7D+%28x%29+%7D+%2B+%5Csum_x+%5Chat+M_%7Bi%2B1%7D%28x%29+-+M_i%28x%29+%5Cright%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p align="center"><img alt="\displaystyle = c \cdot \sum_x M_i(x) \cdot \left( \frac 1c I\{ f(x) = g(x) \} + e^{-\frac 1 cI \{ f(x) = g(x)\}} -1 \right) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%3D+c+%5Ccdot+%5Csum_x+M_i%28x%29+%5Ccdot+%5Cleft%28+%5Cfrac+1c+I%5C%7B+f%28x%29+%3D+g%28x%29+%5C%7D+%2B+e%5E%7B-%5Cfrac+1+cI+%5C%7B+f%28x%29+%3D+g%28x%29%5C%7D%7D+-1+%5Cright%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p align="center"><img alt="\displaystyle \leq O \left( \frac 1c \right) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cleq+O+%5Cleft%28+%5Cfrac+1c+%5Cright%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>where, in the last step, we used the fact the quantity in parenthesis is either 0 or <img alt="{1/c + e^{-1/c} - 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%2Fc+%2B+e%5E%7B-1%2Fc%7D+-+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> which is <img alt="{O(1/c^2)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%281%2Fc%5E2%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, and that <img alt="{\sum_x M_i(x) = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csum_x+M_i%28x%29+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> because <img alt="{M_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is a distribution.</p>
<p>Overall, the regret is bounded by</p>
<p align="center"><img alt="\displaystyle \sum_{i=1}^T L_i(M_i) - L_i(M) \leq O \left( c\log \frac 1\delta + \frac Tc \right) \leq O \left( \sqrt{T \log \frac 1\delta}\right) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Csum_%7Bi%3D1%7D%5ET+L_i%28M_i%29+-+L_i%28M%29+%5Cleq+O+%5Cleft%28+c%5Clog+%5Cfrac+1%5Cdelta+%2B+%5Cfrac+Tc+%5Cright%29+%5Cleq+O+%5Cleft%28+%5Csqrt%7BT+%5Clog+%5Cfrac+1%5Cdelta%7D%5Cright%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>where the last inequality comes from an optimized choice of <img alt="{c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>.</p>
<p>Recall that we choose the functions <img alt="{f_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> so that <img alt="{L_i(M_i) \geq 1/2 + \epsilon}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_i%28M_i%29+%5Cgeq+1%2F2+%2B+%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> for every <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, so for every <img alt="{M\in {\cal K}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%5Cin+%7B%5Ccal+K%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p align="center"><img alt="\displaystyle \frac 1T \sum_{i=1}^T L_i (M) \geq \frac 12 + \epsilon - O (\left( \sqrt{\frac 1 T \log \frac 1\delta}\right) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cfrac+1T+%5Csum_%7Bi%3D1%7D%5ET+L_i+%28M%29+%5Cgeq+%5Cfrac+12+%2B+%5Cepsilon+-+O+%28%5Cleft%28+%5Csqrt%7B%5Cfrac+1+T+%5Clog+%5Cfrac+1%5Cdelta%7D%5Cright%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>and by choosing <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> of the order of <img alt="{\frac 1 {\epsilon^2} \log \frac 1 \delta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac+1+%7B%5Cepsilon%5E2%7D+%5Clog+%5Cfrac+1+%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> we get</p>
<p align="center"><img alt="\displaystyle \forall M \in {\cal K} : \ \ \ \frac 1T \sum_{i=1}^T L_i (M) &gt; \frac 12 " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cforall+M+%5Cin+%7B%5Ccal+K%7D+%3A+%5C+%5C+%5C+%5Cfrac+1T+%5Csum_%7Bi%3D1%7D%5ET+L_i+%28M%29+%3E+%5Cfrac+12+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>It remains to observe that</p>
<p align="center"><img alt="\displaystyle \frac 1T \sum_{i=1}^T L_i (M) = \frac 1T \sum_{i=1}^T \Pr_{x\sim M} [f_i(x) = g(x) ] = \Pr_{i \sim \{1,\ldots,T\}, \ x\sim M} [ f_i (x) = g(x) ] " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cfrac+1T+%5Csum_%7Bi%3D1%7D%5ET+L_i+%28M%29+%3D+%5Cfrac+1T+%5Csum_%7Bi%3D1%7D%5ET+%5CPr_%7Bx%5Csim+M%7D+%5Bf_i%28x%29+%3D+g%28x%29+%5D+%3D+%5CPr_%7Bi+%5Csim+%5C%7B1%2C%5Cldots%2CT%5C%7D%2C+%5C+x%5Csim+M%7D+%5B+f_i+%28x%29+%3D+g%28x%29+%5D+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>so we have that for every distribution <img alt="{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> of min-entropy at least <img alt="{\log_2 2\delta |X|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog_2+2%5Cdelta+%7CX%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> it holds that</p>
<p align="center"><img alt="\displaystyle \Pr_{i \sim \{1,\ldots,T\}, \ x\sim M} [ f_i (x) = g(x) ]&gt; \frac 12 " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5CPr_%7Bi+%5Csim+%5C%7B1%2C%5Cldots%2CT%5C%7D%2C+%5C+x%5Csim+M%7D+%5B+f_i+%28x%29+%3D+g%28x%29+%5D%3E+%5Cfrac+12+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>which is the statement that we promised and from which the Impagliazzo Hard-Core Lemma follows.</p>
<p><b>4. Some Final Remarks </b></p>
<p>After Impagliazzo circulated a preliminary version of his paper, Nisan had the following idea: consider the game that we define above, in which a builder picks an <img alt="{f\in {\cal F}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%5Cin+%7B%5Ccal+F%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, an inspector picks a distribution <img alt="{M \in {\cal K}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM+%5Cin+%7B%5Ccal+K%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> of the prescribed min-entropy, and the loss for the inspector is given by <img alt="{\Pr [ f(x) = g(x) ]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CPr+%5B+f%28x%29+%3D+g%28x%29+%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. We can think of it as a zero-sum game if we also assign a gain <img alt="{\Pr [ f(x) = g(x)]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CPr+%5B+f%28x%29+%3D+g%28x%29%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> to the builder.</p>
<p>If the builder plays second, there is a strategy that guarantees a gain that is at least <img alt="{1/2 + \epsilon}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%2F2+%2B+%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, and so there must be a mixed strategy, that is, a distribution <img alt="{{\cal DF}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Ccal+DF%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> over functions in <img alt="{\cal F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+F%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, that guarantees such a gain even if the builder plays first. In other words, for all distributions <img alt="{H}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> of the prescribed min-entropy we have</p>
<p align="center"><img alt="\displaystyle \Pr_{x\sim H, f\sim {\cal DF}} [ f(x) = g(x) ] \geq \frac 12 + \epsilon " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5CPr_%7Bx%5Csim+H%2C+f%5Csim+%7B%5Ccal+DF%7D%7D+%5B+f%28x%29+%3D+g%28x%29+%5D+%5Cgeq+%5Cfrac+12+%2B+%5Cepsilon+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>Nisan then observes that we can sample <img alt="{T = \frac 1{\epsilon^2} \log |X|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT+%3D+%5Cfrac+1%7B%5Cepsilon%5E2%7D+%5Clog+%7CX%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> functions <img alt="{f_1,\ldots,f_T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_1%2C%5Cldots%2Cf_T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and have, with high probability</p>
<p align="center"><img alt="\displaystyle \Pr_{x\sim H, i\sim \{1,\ldots,T\}} [ f_i(x) = g(x) ] &gt; \frac 12 " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5CPr_%7Bx%5Csim+H%2C+i%5Csim+%5C%7B1%2C%5Cldots%2CT%5C%7D%7D+%5B+f_i%28x%29+%3D+g%28x%29+%5D+%3E+%5Cfrac+12+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>and the sampling bound on <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> can be improved to order of <img alt="{\frac 1 {\epsilon^2} \log \frac 1{\epsilon \delta}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac+1+%7B%5Cepsilon%5E2%7D+%5Clog+%5Cfrac+1%7B%5Cepsilon+%5Cdelta%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> with the same conclusion.</p>
<p>Basically, what we have been doing today is to come up with an algorithm that finds an approximate solution for the LP that defines the optimal mixed strategy for the game, and to design the algorithm is such a way that the solution is very sparse.</p>
<p>This is a common feature of other applications of online optimization techniques to find “sparse approximations”: one sets up an optimization problem whose objective function measures the “approximation error” of a given solution. The object we want to approximate is the optimum of the optimization problem, and we use variants of mirror descent to prove the existence of a sparse solution that is a good approximation.</p></div>
    </content>
    <updated>2021-10-20T16:49:43Z</updated>
    <published>2021-10-20T16:49:43Z</published>
    <category term="theory"/>
    <category term="Hard-Core Sets"/>
    <category term="online optimization"/>
    <category term="Russell Impagliazzo"/>
    <author>
      <name>luca</name>
    </author>
    <source>
      <id>https://lucatrevisan.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://lucatrevisan.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://lucatrevisan.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://lucatrevisan.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://lucatrevisan.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>"Marge, I agree with you - in theory. In theory, communism works. In theory." -- Homer Simpson</subtitle>
      <title>in   theory</title>
      <updated>2022-04-09T22:47:53Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://lucatrevisan.wordpress.com/?p=4566</id>
    <link href="https://lucatrevisan.wordpress.com/2021/10/12/the-khot-naor-approximation-algorithm-for-3-xor/" rel="alternate" type="text/html"/>
    <title>The Khot-Naor Approximation Algorithm for 3-XOR</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Today I would like to discuss the Khot-Naor approximation algorithm for the 3-XOR problem, and an open question related to it. In 3-XOR, we have a system of linear equations modulo 2, with three variables per equation, that might look … <a href="https://lucatrevisan.wordpress.com/2021/10/12/the-khot-naor-approximation-algorithm-for-3-xor/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Today I would like to discuss the Khot-Naor approximation algorithm for the 3-XOR problem, and an open question related to it.</p>
<p><span id="more-4566"/></p>
<p>In 3-XOR, we have a system of linear equations modulo 2, with three variables per equation, that might look something like</p>
<p align="center"><img alt="\displaystyle  \begin{array}{ll} x_1 + x_2 + x_4 &amp; \equiv 0 \pmod 2\\ x_1 + x_5 + x_6 &amp; \equiv 1 \pmod 2\\ x_2 + x_3 + x_4 &amp; \equiv 1 \pmod 2\\ x_5 + x_3 + x_6 &amp; \equiv 1 \pmod 2 \end{array} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Barray%7D%7Bll%7D+x_1+%2B+x_2+%2B+x_4+%26+%5Cequiv+0+%5Cpmod+2%5C%5C+x_1+%2B+x_5+%2B+x_6+%26+%5Cequiv+1+%5Cpmod+2%5C%5C+x_2+%2B+x_3+%2B+x_4+%26+%5Cequiv+1+%5Cpmod+2%5C%5C+x_5+%2B+x_3+%2B+x_6+%26+%5Cequiv+1+%5Cpmod+2+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>The above system is not satisfiable (if we add up the left-hand sides we get 0, if we add up the right-hand sides we get 1), but it is possible to satisfy <img alt="{3/4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3%2F4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> of the equations, for example by setting all the variables to 1. In Max 3-XOR problem (which we will simply refer to as “3-XOR” from now on), given a system of equations mod 2 with three variables per equation, we want to find an assignment that satisfies as many equations as possible.</p>
<p>Either setting all the variables to zero or setting all the variables to one will satisfy half of the equations, and the interesting question is how much better than 1/2 it is possible to do on a given instance. <a href="https://epubs.siam.org/doi/abs/10.1137/070691140">Khot and Naor</a> provide an algorithm that, given an instance in which it is possible to satisfy an <img alt="{1/2 + \epsilon}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%2F2+%2B+%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> fraction of equations, finds a solution that satisfies at least <img alt="{1/2 + \epsilon \cdot O \left( \sqrt{\frac {\log n} n} \right)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%2F2+%2B+%5Cepsilon+%5Ccdot+O+%5Cleft%28+%5Csqrt%7B%5Cfrac+%7B%5Clog+n%7D+n%7D+%5Cright%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> fraction of equations, where <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is the number of variables. The algorithm is randomized, it runs in polynomial time, and it succeeds with high probability. I believe that it is still the state of the art in terms of worst-case approximation guarantee.</p>
<p>Like the approximation algorithm for sparsest cut in Abelian Cayley graphs implied by the result of Bauer et al. that was the subject of the last two posts, the result of Khot and Naor <em>does not</em> prove a bound on the integrality gap of a relaxation of the problem.</p>
<p>I will describe the Khot-Naor algorithm and describe how it manages to use convex optimization to provide an approximation algorithm, but without establishing an integrality gap bound. I thank my student Lucas Pesenti for explaining the algorithm to me and for thinking together about this problem.</p>
<p>If our 3-XOR instance has <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> equations and <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> variables, then the problem of maximizing the number of satisfied equations can be rewritten as</p>
<p align="center"><img alt="\displaystyle  \frac m2 + \max_{x \in \{ -1 , +1 \}^n} \ \sum_{i,j,k} c_{i,j,k} x_i x_j x_k " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac+m2+%2B+%5Cmax_%7Bx+%5Cin+%5C%7B+-1+%2C+%2B1+%5C%7D%5En%7D+%5C+%5Csum_%7Bi%2Cj%2Ck%7D+c_%7Bi%2Cj%2Ck%7D+x_i+x_j+x_k+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> so that our goal is to approximate the combinatorial optimization problem</p>
<p align="center"><img alt="\displaystyle  \max_{x \in \{ -1 , +1 \}^n} \ \sum_{i,j,k} c_{i,j,k} x_i x_j x_k " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmax_%7Bx+%5Cin+%5C%7B+-1+%2C+%2B1+%5C%7D%5En%7D+%5C+%5Csum_%7Bi%2Cj%2Ck%7D+c_%7Bi%2Cj%2Ck%7D+x_i+x_j+x_k+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> Up to a constant factor loss in the approximation guarantee, Khot and Naor show that the above is equivalent to <a name="tensornorm"/></p>
<p><a name="tensornorm"/></p><a name="tensornorm">
<p align="center"><img alt="\displaystyle   \max_{x,y,z \in \{ -1 , +1 \}^n} \ \sum_{i,j,k} T_{i,j,k} x_i y_j z_k \ \ \ \ \ (1)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+++%5Cmax_%7Bx%2Cy%2Cz+%5Cin+%5C%7B+-1+%2C+%2B1+%5C%7D%5En%7D+%5C+%5Csum_%7Bi%2Cj%2Ck%7D+T_%7Bi%2Cj%2Ck%7D+x_i+y_j+z_k+%5C+%5C+%5C+%5C+%5C+%281%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
</a><p><a name="tensornorm"/><a name="tensornorm"/> where <img alt="{T_{i,j,k}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_%7Bi%2Cj%2Ck%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is a symmetric 3-tensor with entries in <img alt="{\{ -1,0,1\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B+-1%2C0%2C1%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and with <img alt="{O(m)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%28m%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> non-zero entries.</p>
<p>Before continuing, let us recall that if <img alt="{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is an <img alt="{n \times n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn+%5Ctimes+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> matrix, then its <img alt="{\ell_\infty}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell_%5Cinfty%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>-to-<img alt="{\ell_1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> operator norm has the characterization</p>
<p><a name="inftoone"/></p>
<p><a name="inftoone"/></p><a name="inftoone">
<p align="center"><img alt="\displaystyle  || M ||_{\infty \rightarrow 1 } = \max_{x,y \in [-1,1]^n} x^T M y = \max_{x,y \in \{ -1,1 \}^n} x^T M y \ \ \ \ \ (2)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7C%7C+M+%7C%7C_%7B%5Cinfty+%5Crightarrow+1+%7D+%3D+%5Cmax_%7Bx%2Cy+%5Cin+%5B-1%2C1%5D%5En%7D+x%5ET+M+y+%3D+%5Cmax_%7Bx%2Cy+%5Cin+%5C%7B+-1%2C1+%5C%7D%5En%7D+x%5ET+M+y+%5C+%5C+%5C+%5C+%5C+%282%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
</a><p><a name="inftoone"/><a name="inftoone"/></p>
<p>We could also define the “Grothendieck norm” <img alt="{|| M ||_{Grot}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7C%7C+M+%7C%7C_%7BGrot%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> of a matrix as the following natural semidefinite programming relaxation of the <img alt="{\ell_\infty}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell_%5Cinfty%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>-to-<img alt="{\ell_1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> norm:</p>
<p align="center"><img alt="\displaystyle  \begin{array}{lll} \max &amp; \sum_{i,j} M_{i,j} \langle x_i , y_j\rangle \\ {\rm s.t.}\\ &amp; || x_i ||^2 = 1 &amp; i = 1,\ldots,n\\ &amp; ||y_j ||^2 = 1 &amp; i = j,\ldots,n \end{array} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Barray%7D%7Blll%7D+%5Cmax+%26+%5Csum_%7Bi%2Cj%7D+M_%7Bi%2Cj%7D+%5Clangle+x_i+%2C+y_j%5Crangle+%5C%5C+%7B%5Crm+s.t.%7D%5C%5C+%26+%7C%7C+x_i+%7C%7C%5E2+%3D+1+%26+i+%3D+1%2C%5Cldots%2Cn%5C%5C+%26+%7C%7Cy_j+%7C%7C%5E2+%3D+1+%26+i+%3D+j%2C%5Cldots%2Cn+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> where the <img alt="{x_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and <img alt="{y_j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> are arbitrary vectors. The Grothendieck inequality is</p>
<p align="center"><img alt="\displaystyle  || M||_{\infty \rightarrow 1 } \leq || M ||_{Grot} \leq O(1) \cdot || M ||_{\infty \rightarrow 1 }" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7C%7C+M%7C%7C_%7B%5Cinfty+%5Crightarrow+1+%7D+%5Cleq+%7C%7C+M+%7C%7C_%7BGrot%7D+%5Cleq+O%281%29+%5Ccdot+%7C%7C+M+%7C%7C_%7B%5Cinfty+%5Crightarrow+1+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> where the <img alt="{O(1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%281%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is an absolute constant, known to be less than <img alt="{1.8}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1.8%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. Furthermore, the above inequality has a constructive proof, and it leads to a polynomial time constant factor approximation for the problem of finding values <img alt="{x_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and <img alt="{y_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> in <img alt="{\pm 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpm+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> that maximize <a href="https://lucatrevisan.wordpress.com/feed/#inftoone">(2)</a>.</p>
<p>Basically, we can see problem <a href="https://lucatrevisan.wordpress.com/feed/#tensornorm">(1)</a> as the natural generalization of <a href="https://lucatrevisan.wordpress.com/feed/#inftoone">(2)</a> to tensors, and one would like to see a semidefinite programming relaxation of <a href="https://lucatrevisan.wordpress.com/feed/#tensornorm">(1)</a> achieving something resembling the Grothendieck inequality, but with a loss of something like <img alt="{\tilde O(\sqrt n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctilde+O%28%5Csqrt+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. As I mentioned above, this remains an open question, as far as I know.</p>
<p>The idea of Khot and Naor is the following. Suppose that we are given an instance <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> of problem <a href="https://lucatrevisan.wordpress.com/feed/#tensornorm">(1)</a>, and suppose that <img alt="{x^*,y^*,z^*}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%5E%2A%2Cy%5E%2A%2Cz%5E%2A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is an optimal solution, and let us call</p>
<p align="center"><img alt="\displaystyle  \epsilon = \sum_{i,j,k} T_{i,j,k} x^*_i y^*_j z^*_k " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cepsilon+%3D+%5Csum_%7Bi%2Cj%2Ck%7D+T_%7Bi%2Cj%2Ck%7D+x%5E%2A_i+y%5E%2A_j+z%5E%2A_k+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> the value of the optimum (the algorithm will not need to know or guess <img alt="{\epsilon}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>).</p>
<p>The key step is now to see that if we pick a <em>random</em> <img alt="{x \in \{-1,1\}^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx+%5Cin+%5C%7B-1%2C1%5C%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, there is at least a <img alt="{1/n^{O(1)}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%2Fn%5E%7BO%281%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> probability that</p>
<p align="center"><img alt="\displaystyle  \sum_{i,j,k} T_{i,j,k} x_i y^*_j z^*_k \geq \epsilon \cdot \Omega \left(\sqrt{\frac{\log n}{n}} \right) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_%7Bi%2Cj%2Ck%7D+T_%7Bi%2Cj%2Ck%7D+x_i+y%5E%2A_j+z%5E%2A_k+%5Cgeq+%5Cepsilon+%5Ccdot+%5COmega+%5Cleft%28%5Csqrt%7B%5Cfrac%7B%5Clog+n%7D%7Bn%7D%7D+%5Cright%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> This is a bit difficult, but it is really easy to see that with <img alt="{1/n^{O(1)}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%2Fn%5E%7BO%281%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> probability we have <a name="main"/></p>
<p><a name="main"/></p><a name="main">
<p align="center"><img alt="\displaystyle   \sum_{i,j,k} T_{i,j,k} x_i y^*_j z^*_k \geq \epsilon \cdot \Omega \left(\sqrt{\frac{1}{n}} \right) \ \ \ \ \ (3)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+++%5Csum_%7Bi%2Cj%2Ck%7D+T_%7Bi%2Cj%2Ck%7D+x_i+y%5E%2A_j+z%5E%2A_k+%5Cgeq+%5Cepsilon+%5Ccdot+%5COmega+%5Cleft%28%5Csqrt%7B%5Cfrac%7B1%7D%7Bn%7D%7D+%5Cright%29+%5C+%5C+%5C+%5C+%5C+%283%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
</a><p><a name="main"/><a name="main"/> and we can do that by seeing that by defining a vector <img alt="{w}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> such that <img alt="{w_i = \sum_{j,k} T_{i,j,k} y^*_j z^*_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw_i+%3D+%5Csum_%7Bj%2Ck%7D+T_%7Bi%2Cj%2Ck%7D+y%5E%2A_j+z%5E%2A_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, so that</p>
<p align="center"><img alt="\displaystyle  \langle x, w \rangle = \sum_{i,j,k} T_{i,j,k} x_i y^*_j z^*_k" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clangle+x%2C+w+%5Crangle+%3D+%5Csum_%7Bi%2Cj%2Ck%7D+T_%7Bi%2Cj%2Ck%7D+x_i+y%5E%2A_j+z%5E%2A_k&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> So we have</p>
<p align="center"><img alt="\displaystyle  \langle x^*,w \rangle = \epsilon " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clangle+x%5E%2A%2Cw+%5Crangle+%3D+%5Cepsilon+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> which, using Cauchy-Schwarz, gives</p>
<p align="center"><img alt="\displaystyle  || w||^2 \geq \epsilon^2 /n " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7C%7C+w%7C%7C%5E2+%5Cgeq+%5Cepsilon%5E2+%2Fn+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> Now, for a random <img alt="{x\sim \{ -1,1\}^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%5Csim+%5C%7B+-1%2C1%5C%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, we have</p>
<p align="center"><img alt="\displaystyle  \mathop{\mathbb E} \langle x,w \rangle^2 = || w||^2 \geq \epsilon^2 /n " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathop%7B%5Cmathbb+E%7D+%5Clangle+x%2Cw+%5Crangle%5E2+%3D+%7C%7C+w%7C%7C%5E2+%5Cgeq+%5Cepsilon%5E2+%2Fn+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> and</p>
<p align="center"><img alt="\displaystyle  \mathop{\mathbb E} \langle x,w \rangle^4 \leq n^{O(1)} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathop%7B%5Cmathbb+E%7D+%5Clangle+x%2Cw+%5Crangle%5E4+%5Cleq+n%5E%7BO%281%29%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> so by Paley–Zygmund we have, let’s say</p>
<p align="center"><img alt="\displaystyle  \mathop{\mathbb P} \left[ \langle x,w \rangle^2 \geq \frac {\epsilon^2}{2n} \right] \geq \frac 1 {n^{O(1)}} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathop%7B%5Cmathbb+P%7D+%5Cleft%5B+%5Clangle+x%2Cw+%5Crangle%5E2+%5Cgeq+%5Cfrac+%7B%5Cepsilon%5E2%7D%7B2n%7D+%5Cright%5D+%5Cgeq+%5Cfrac+1+%7Bn%5E%7BO%281%29%7D%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> which, together with the definition of <img alt="{w}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and the fact that the distribution of <img alt="{\langle x, w\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clangle+x%2C+w%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is symmetric around zero, gives us the claim <a href="https://lucatrevisan.wordpress.com/feed/#main">(3)</a>.</p>
<p>Now suppose that we have been lucky and that we have found such an <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. We define the matrix</p>
<p align="center"><img alt="\displaystyle  X_{j,k} = \sum_i T_{i,j,k} x_i " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++X_%7Bj%2Ck%7D+%3D+%5Csum_i+T_%7Bi%2Cj%2Ck%7D+x_i+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> and we see that our claim can be written as</p>
<p align="center"><img alt="\displaystyle  y^{*T} X z^* \geq \epsilon \cdot \Omega \left(\sqrt{\frac{1}{n}} \right) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++y%5E%7B%2AT%7D+X+z%5E%2A+%5Cgeq+%5Cepsilon+%5Ccdot+%5COmega+%5Cleft%28%5Csqrt%7B%5Cfrac%7B1%7D%7Bn%7D%7D+%5Cright%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> At this point we just apply the algorithm implied by the Grothendieck inequality to the matrix <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, and we find <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and <img alt="{z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bz%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> in <img alt="{\{ -1,1 \}^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B+-1%2C1+%5C%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> such that</p>
<p align="center"><img alt="\displaystyle  y^T X z \geq \epsilon \cdot \Omega \left(\sqrt{\frac{1}{n}} \right)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++y%5ET+X+z+%5Cgeq+%5Cepsilon+%5Ccdot+%5COmega+%5Cleft%28%5Csqrt%7B%5Cfrac%7B1%7D%7Bn%7D%7D+%5Cright%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> meaning that</p>
<p align="center"><img alt="\displaystyle  \sum_{i,j,k} T_{i,j,k} x_i y_j z_k \geq \epsilon \cdot \Omega \left(\sqrt{\frac{1}{n}}\right) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_%7Bi%2Cj%2Ck%7D+T_%7Bi%2Cj%2Ck%7D+x_i+y_j+z_k+%5Cgeq+%5Cepsilon+%5Ccdot+%5COmega+%5Cleft%28%5Csqrt%7B%5Cfrac%7B1%7D%7Bn%7D%7D%5Cright%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>Summarizing, our algorithm is to pick a random vector <img alt="{x\sim \{-1,1\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%5Csim+%5C%7B-1%2C1%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and to find a constant-factor approximation for the problem <a name="xfixed"/></p>
<p><a name="xfixed"/></p><a name="xfixed">
<p align="center"><img alt="\displaystyle   \max_{y,z \in \{-1,1\}^n} \ \sum_{i,j,k} T_{i,j,k} x_iy_jz_k \ \ \ \ \ (4)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+++%5Cmax_%7By%2Cz+%5Cin+%5C%7B-1%2C1%5C%7D%5En%7D+%5C+%5Csum_%7Bi%2Cj%2Ck%7D+T_%7Bi%2Cj%2Ck%7D+x_iy_jz_k+%5C+%5C+%5C+%5C+%5C+%284%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
</a><p><a name="xfixed"/><a name="xfixed"/> using semidefinite programming. We do that <img alt="{n^{O(1)}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%5E%7BO%281%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> times, and take the best solution.</p>
<p>The analysis can be turned into an upper bound certificate in the following way. For the (suboptimal) analysis using Paley-Zygmund, we only need the entries of the random <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> to be 4-wise independent, and there are distributions on <img alt="{\{-1,1\}^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B-1%2C1%5C%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> where the entries are unbiased and 4-wise independent, and such that the sample space is of size polynomial in <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. Thus, one could write an SDP relaxation of <a href="https://lucatrevisan.wordpress.com/feed/#xfixed">(4)</a> for each <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> in the support of such a distribution, and then take the maximum of these SDPs, multiply it by <img alt="{O(\sqrt n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%28%5Csqrt+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, and it would be a certified upper bound. Such an upper bound, however, would not come from a relaxation of the 3-XOR problem, and I find it really strange that it is not clear how to turn these ideas into a proof that, say, the standard degree-4 sum-of-squares semidefinite programming relaxation of 3-XOR has an integrality gap at most <img alt="{\tilde O(\sqrt n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctilde+O%28%5Csqrt+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>.</p></div>
    </content>
    <updated>2021-10-12T12:55:04Z</updated>
    <published>2021-10-12T12:55:04Z</published>
    <category term="theory"/>
    <category term="3-XOR"/>
    <category term="approximation algorithms"/>
    <category term="semidefinite programming"/>
    <author>
      <name>luca</name>
    </author>
    <source>
      <id>https://lucatrevisan.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://lucatrevisan.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://lucatrevisan.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://lucatrevisan.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://lucatrevisan.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>"Marge, I agree with you - in theory. In theory, communism works. In theory." -- Homer Simpson</subtitle>
      <title>in   theory</title>
      <updated>2022-04-09T22:25:03Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://thmatters.wordpress.com/?p=1343</id>
    <link href="https://thmatters.wordpress.com/2021/10/08/soliciting-information-about-women-in-tcs/" rel="alternate" type="text/html"/>
    <title>Soliciting information about Women in TCS</title>
    <summary>The CATCS is compiling a list of Women in Theoretical Computer Science (WinTCS), hoping to facilitate engagement and opportunities for Women in TCS in the future.  We cordially invite women (broadly defined as anyone who self-identifies as a woman) as well as gender non-conforming TCS researchers to participate the following simple google-form survey to provide […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The CATCS is compiling a list of <em>Women in Theoretical Computer Science (WinTCS)</em>, hoping to facilitate engagement and opportunities for Women in TCS in the future. </p>



<p>We cordially invite women (broadly defined as anyone who self-identifies as a woman) as well as gender non-conforming TCS researchers to participate the following simple <a href="https://docs.google.com/forms/d/e/1FAIpQLSc2LcI0mtUvyKgl34OqbxDVpu0zbYs0fiLmU_5jr2qHybCfMQ/viewform?usp=sf_link" rel="noreferrer noopener" target="_blank">google-form survey</a> to provide your information. </p>



<p>Please submit your information before <strong>Oct. 31, 2021</strong>. After that, information can still be provided through the CATCS website, and will be added to the list monthly. <br/>**Please feel free to share this solicitation broadly within your networks.**</p>



<p>If you have any questions regarding this survey, please feel free to contact us at <a rel="noreferrer noopener" target="_blank">goldner@bu.edu</a> or <a rel="noreferrer noopener" target="_blank">yusuwang@ucsd.edu</a>.  </p>



<p>– Kira Goldner and Yusu Wang (on behalf of the SIGACT CATCS)</p></div>
    </content>
    <updated>2021-10-08T21:56:41Z</updated>
    <published>2021-10-08T21:56:41Z</published>
    <category term="TCS Community"/>
    <author>
      <name>shuchic</name>
    </author>
    <source>
      <id>https://thmatters.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://thmatters.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://thmatters.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://thmatters.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://thmatters.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theory Matters</title>
      <updated>2022-04-09T22:48:32Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://thmatters.wordpress.com/?p=1325</id>
    <link href="https://thmatters.wordpress.com/2021/06/23/tcs-visioning-2020-report-and-slides/" rel="alternate" type="text/html"/>
    <title>TCS Visioning 2020 report and slides</title>
    <summary>In July 2020, the CATCS organized a visioning workshop. We are happy to announce the release of a report and posters based on this workshop. Material produced from this workshop is available and free to use by any member of the TCS community. We gratefully acknowledge financial as well as organizational support by the SIGACT […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>In July 2020, the <a href="https://thmatters.wordpress.com/catcs/">CATCS</a> organized a <a href="https://thmatters.wordpress.com/2020/06/05/tcs-visioning-workshop-call-for-participation/">visioning workshop</a>. We are happy to announce the release of a report and posters based on this workshop. Material produced from this workshop is available and free to use by any member of the TCS community. We gratefully acknowledge financial as well as organizational support by the <a href="https://www.sigact.org/">SIGACT</a> and <a href="https://cra.org/ccc/">CCC</a> for this activity.</p>



<p>We are planning a follow-up event for disseminating the report and posters to funding agencies in the next few months. Details are forthcoming.</p>



<p>TCS Visioning Full Report: <a href="https://thmatters.files.wordpress.com/2021/06/visioning-report.pdf">here</a></p>



<p>Short Report (CCC Quadrennial paper): <a href="https://cra.org/ccc/wp-content/uploads/sites/2/2020/10/Theoretical-Computer-Science_.pdf">here</a></p>



<p>TCS Visioning Slides: <a href="https://thmatters.files.wordpress.com/2021/06/visioning-slides.pptx">in PPT</a> and <a href="https://thmatters.files.wordpress.com/2021/06/visioning-slides-1.pdf">in PDF</a></p></div>
    </content>
    <updated>2021-06-23T16:21:23Z</updated>
    <published>2021-06-23T16:21:23Z</published>
    <category term="reports"/>
    <category term="Visioning"/>
    <author>
      <name>shuchic</name>
    </author>
    <source>
      <id>https://thmatters.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://thmatters.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://thmatters.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://thmatters.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://thmatters.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theory Matters</title>
      <updated>2022-04-09T22:48:06Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://toc4fairness.org/?p=1659</id>
    <link href="https://toc4fairness.org/fair-clustering-with-probabilistic-group-membership/" rel="alternate" type="text/html"/>
    <title>Fair Clustering with Probabilistic Group Membership</title>
    <summary>This post briefly summarizes a NeurIPS-20 paper, Probabilistic Fair Clustering, which I coauthored with Brian Brubach, Leonidas Tsepenekas, and John P. Dickerson. Clustering is possibly the most fundamental problem of ...</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>This post briefly summarizes a NeurIPS-20 paper, <em><a href="https://papers.nips.cc/paper/2020/file/95f2b84de5660ddf45c8a34933a2e66f-Paper.pdf">Probabilistic Fair Clustering</a></em>, which I coauthored with <a href="https://bbrubach.github.io/">Brian Brubach</a>, Leonidas Tsepenekas, and <a href="http://jpdickerson.com/">John P. Dickerson</a>.<br/><br/>Clustering is possibly the most fundamental problem of unsupervised learning. Like many other paradigms of machine learning, there has been a focus on fair variants of clustering. Perhaps the definition which has received the most attention is the group fairness definition of [1]. The notion is based on disparate impact and simply states that each cluster should contain points belonging to the different demographic groups with “appropriate” proportions. A natural interpretation of appropriate would imply that each demographic group appears in close to population-level proportions in each cluster. More specifically, if we were to endow each point with a color <img alt="h \in {\cal H}" class="latex" src="https://s0.wp.com/latex.php?latex=h+%5Cin+%7B%5Ccal+H%7D&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002"/> to designate its group membership and we were to consider the <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002"/>-means clustering objective, then this notion of fair clustering amounts to the following constrained optimization problem:</p>



<p class="has-text-align-center"><img alt="\begin{aligned} &amp; \text{min} \sum_{j \in C_i}  \sum_{i \in \lbrack k\rbrack } d(j,\mu_i)^2 \\ &amp; \text{s.t. }\forall i \in S, \forall h \in \mathcal{H}: l_h |C_i| \leq |C^h_i| \leq u_h |C_i| \end{aligned} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%26+%5Ctext%7Bmin%7D+%5Csum_%7Bj+%5Cin+C_i%7D++%5Csum_%7Bi+%5Cin+%5Clbrack+k%5Crbrack+%7D+d%28j%2C%5Cmu_i%29%5E2+%5C%5C+%26+%5Ctext%7Bs.t.+%7D%5Cforall+i+%5Cin+S%2C+%5Cforall+h+%5Cin+%5Cmathcal%7BH%7D%3A+l_h+%7CC_i%7C+%5Cleq+%7CC%5Eh_i%7C+%5Cleq+u_h+%7CC_i%7C+%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002"/></p>



<p>Here, <img alt="l_h" class="latex" src="https://s0.wp.com/latex.php?latex=l_h&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002"/> and <img alt="u_h" class="latex" src="https://s0.wp.com/latex.php?latex=u_h&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002"/> are the lower and upper pre-set proportionality bounds for color <img alt="h" class="latex" src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002"/>, <img alt="C_i" class="latex" src="https://s0.wp.com/latex.php?latex=C_i&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002"/> denotes the points in cluster <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002"/>, and <img alt="C^h_i" class="latex" src="https://s0.wp.com/latex.php?latex=C%5Eh_i&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002"/> denotes the subset of those points with color <img alt="h" class="latex" src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002"/>. See figure 1 for a comparison between the outputs of color-agnostic and fair clustering.<br/></p>



<div class="wp-block-image is-style-default"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-1735" height="151" src="https://i0.wp.com/toc4fairness.org/wp-content/uploads/2021/05/fig_1.png?resize=800%2C151&amp;ssl=1" width="800"/>Figure 1: The outputs of color-agnostic vs fair clustering. The clusters of the group-fair output have a proportional mixture of both colors whereas the color-agnostic clusters consist of only one color.</figure></div>



<p>If one were to use clustering for market segmentation and targeted advertisement, then the above definition of fair clustering would roughly ensure that each demographic group receives the same exposure to every type of ad. Similarly if we were to cluster news articles and let the source of each article indicate its membership then we could ensure that each cluster has a good mixture of news from different sources [2].</p>



<p>Significant progress has been made in this notion of fair clustering starting from only considering the two color case and under-representation bounds, to the multi-color case with both under- and over-representation bounds [3.4.5]. Scalable methods for larger datasets have also been proposed [6, 7].</p>



<p>Clearly, like the majority of the methods in group-fair supervised learning, it is assumed that the group membership of each point in the dataset is known. This setting conflicts with a common situation in practice where group memberships are either imperfectly known or completely unknown [8,9,10,11,12]. We take the first step in generalizing fair clustering to this setting; specifically, we assume that while we do not know the exact group membership of each point, we instead have a probability distribution over the group memberships. A natural generalization of the previous optimization problem would be the following:</p>



<p class="has-text-align-center"><img alt="\begin{aligned} &amp; \text{min} \sum_{j \in C_i}  \sum_{i \in \lbrack k\rbrack } d(j,\mu_i)^2 \\ &amp; \text{s.t. }\forall i \in S, \forall h \in \mathcal{H}: l_h |C_i| \leq \mathbb{E}|C^h_i| \leq u_h |C_i| \end{aligned} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%26+%5Ctext%7Bmin%7D+%5Csum_%7Bj+%5Cin+C_i%7D++%5Csum_%7Bi+%5Cin+%5Clbrack+k%5Crbrack+%7D+d%28j%2C%5Cmu_i%29%5E2+%5C%5C+%26+%5Ctext%7Bs.t.+%7D%5Cforall+i+%5Cin+S%2C+%5Cforall+h+%5Cin+%5Cmathcal%7BH%7D%3A+l_h+%7CC_i%7C+%5Cleq+%5Cmathbb%7BE%7D%7CC%5Eh_i%7C+%5Cleq+u_h+%7CC_i%7C+%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002"/></p>



<p>Where the proportionality constraints were simply changed to hold in expectation instead of deterministically. Clearly, this constraint reduces to the original constraint when the group memberships are completely known. Figure 2 helps visualize how the input to probabilistic fair clustering looks like and the output we expect.</p>



<p><br/></p>



<div class="wp-block-image"><figure class="aligncenter size-large"><img alt="" class="wp-image-1737" height="210" src="https://i0.wp.com/toc4fairness.org/wp-content/uploads/2021/05/fig_2.png?resize=800%2C210&amp;ssl=1" width="800"/>Figure 2: In the above example, the given set of points in the top row are blue and red with probability almost 1 whereas the bottom are blue and red with probability around 0.6. To maintain almost equal color proportions in expectation probabilistic fair clustering would yield the given clustering.</figure></div>



<p> </p>



<p>Despite the innocuous modification to the constraint, the problem becomes significantly more difficult. In our <a href="https://papers.nips.cc/paper/2020/file/95f2b84de5660ddf45c8a34933a2e66f-Paper.pdf">paper</a>, we consider the center-based clustering objectives of <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002"/>-center, <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002"/>-median, and <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002"/>-means and produce solutions with approximation ratio guarantees for two given cases:</p>



<ul><li><strong>Two-Color Case</strong>: We see that even the two color case is not easy to handle. The key difficulty lies in the rounding method. However, we give a rounding method that maintains the fairness constraint with a worst-case additive violation of 1 matching the deterministic fair clustering case.</li><li><strong>Multi-Color Case with Large Enough Clusters</strong>: At a high level, if the clusters have a sufficiently large size then through a Chernoff bound we can show that independent sampling would result in a deterministic fair clustering instance which we could solve using deterministic fair clustering algorithms. This essentially forms a reduction from the probabilistic to the deterministic instance.</li></ul>



<p>While our solutions perform well empirically, we are left with a collection of problems. For example, guaranteeing that the color proportions are maintained in expectation is not the best constraint one should hope for, since when the colors are realized a cluster could entirely consist of one color. A more preferable constraint would instead bound the probability of obtaining an “unfair” clustering. Moreover, a setting that assumes access to the probability distribution for a given point over all colors could still be assuming too much. A more reasonable setting could instead take a robust-optimization-based approach, where we have the distribution of each point but allow the distribution of each point to belong to an uncertainty set. This effectively allows our probabilistic knowledge to be imperfect as well—as could be the case if, for example, a machine learning model were predicting group membership with a systematic bias against a particular subset of colors. Lastly, being able to handle the multi-color case in an assumption-free manner would also be interesting.</p>



<p><strong>References:</strong></p>



<ol><li>Flavio Chierichetti, Ravi Kumar, Silvio Lattanzi, and Sergei Vassilvitskii. Fair clustering through fairlets. In Advances in Neural Information Processing Systems, 2017.</li><li>Sara Ahmadian, Alessandro Epasto, Ravi Kumar, and Mohammad Mahdian. Clustering without over-representation. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining, 2019.</li><li>Melanie Schmidt, Chris Schwiegelshohn, and Christian Sohler. Fair coresets and streaming algorithms for fair k-means. In the International Workshop on Approximation and Online Algorithms, 2019.</li><li>Ioana O. Bercea, Martin Groß, Samir Khuller, <em>Aounon Kumar</em>, Clemens Rösner, Daniel R. Schmidt, Melanie Schmidt. On the cost of essentially fair clusterings, In the International Conference on Approximation Algorithms for Combinatorial Optimization Problems 2019.</li><li>Suman Bera, Deeparnab Chakrabarty, Nicolas Flores, and Maryam Negahbani. Fair algorithms for clustering. In Advances in Neural Information Processing Systems, 2019.</li><li>Arturs Backurs, Piotr Indyk, Krzysztof Onak, Baruch Schieber, Ali Vakilian, and Tal Wagner. Scalable fair clustering. In the International Conference on Machine Learning, 2019.</li><li>Lingxiao Huang, Shaofeng Jiang, and Nisheeth Vishnoi. Coresets for clustering with fairness constraints. In Advances in Neural Information Processing Systems, 2019.</li><li>Pranjal Awasthi, Matth¨aus Kleindessner, and Jamie Morgenstern. Equalized odds postprocessing under imperfect group information. In the International Conference on Artificial Intelligence and Statistics, 2020.</li><li>Preethi Lahoti, Alex Beutel, Jilin Chen, Kang Lee, Flavien Prost, NithumThain, Xuezhi Wang, and Ed Chi. Fairness without demographics through adversarially reweighted learning. In Advances in Neural InformationProcessing Systems, 2020.</li><li>David Pujol, Ryan McKenna, Satya Kuppam, Michael Hay, AshwinMachanavajjhala, and Gerome Miklau. Fair decision making using privacy-protected data. In Proceedings of the Conference on Fairness, Accountability, and Transparency, 2020.</li><li>Hussein Mozannar, Mesrob Ohannessian, and Nathan Srebro. Fair learning with private demographic data. In the International Conference on Machine Learning, 2020.</li><li>Nathan Kallus, Xiaojie Mao, and Angela Zhou. Assessing algorithmic fairness with unobserved protected class using data combination. Management Science, 2021.</li></ol>



<p/></div>
    </content>
    <updated>2021-05-07T14:09:42Z</updated>
    <published>2021-05-07T14:09:42Z</published>
    <category term="Blog"/>
    <author>
      <name>seyed2357</name>
    </author>
    <source>
      <id>https://toc4fairness.org</id>
      <logo>https://i0.wp.com/toc4fairness.org/wp-content/uploads/2020/10/cropped-favicon.png?fit=32%2C32&amp;ssl=1</logo>
      <link href="https://toc4fairness.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://toc4fairness.org" rel="alternate" type="text/html"/>
      <subtitle>a simons collaboration project</subtitle>
      <title>TOC for Fairness</title>
      <updated>2022-04-09T22:48:02Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.let-all.com/blog/?p=51</id>
    <link href="https://www.let-all.com/blog/2021/05/06/alt-highlights-a-report-on-the-first-alt-mentoring-workshop/" rel="alternate" type="text/html"/>
    <title>ALT Highlights – A Report on the First ALT Mentoring Workshop</title>
    <summary>Welcome to ALT Highlights, a series of blog posts spotlighting various happenings at the recent conference ALT 2021, including plenary talks, tutorials, trends in learning theory, and more! To reach a broad audience, the series will be disseminated as guest posts on different blogs in machine learning and theoretical computer science. This initiative is organized by […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Welcome to ALT Highlights, a series of blog posts spotlighting various happenings at the recent conference <a href="http://algorithmiclearningtheory.org/alt2021/">ALT 2021</a>, including plenary talks, tutorials, trends in learning theory, and more! To reach a broad audience, the series will be disseminated as guest posts on different blogs in machine learning and theoretical computer science. This initiative is organized by the <a href="https://www.let-all.com/">Learning Theory Alliance</a>, and overseen by <a href="http://www.gautamkamath.com/">Gautam Kamath</a>. All posts in ALT Highlights are indexed on the official <a href="https://www.let-all.com/blog/2021/04/20/alt-highlights-2021/">Learning Theory Alliance blog</a>.</p>



<p>This is the fifth post in the series, coverage of the first <a href="https://www.let-all.com/alt.html">ALT Mentoring Workshop</a> organized by the Learning Theory Alliance, written by <a href="https://www.let-all.com/blog/feed/knaggita@ttic.edu">Keziah Naggita</a> and <a href="https://www.comp.nus.edu.sg/~sutanu/">Sutanu Gayen</a>.</p>



<hr class="wp-block-separator"/>



<h2><strong>1 Introduction</strong></h2>



<p class="has-text-align-left has-text-align-justify">The Learning Theory Alliance (Let-All) is an online initiative aimed at developing a supportive learning theory community, founded by (1) <a href="https://www.cs.utexas.edu/~surbhi/" rel="noopener noreferrer" target="_blank">Surbhi Goel</a>, a postdoctoral researcher at Microsoft Research New York, (2) <a href="https://people.eecs.berkeley.edu/~nika/" rel="noopener noreferrer" target="_blank">Nika Haghtalab</a>, an assistant professor at UC Berkeley EECS, (3) and <a href="https://vitercik.github.io" rel="noopener noreferrer" target="_blank">Ellen Vitercik</a>, a Ph.D. Student at CMU; and advised by <a href="https://www.stat.berkeley.edu/~bartlett/" rel="noopener noreferrer" target="_blank">Peter Bartlett</a>, <a href="https://home.ttic.edu/~avrim/" rel="noopener noreferrer" target="_blank">Avrim Blum</a>, <a href="https://people.csail.mit.edu/stefje/" rel="noopener noreferrer" target="_blank">Stefanie Jegelka</a>, <a href="https://www.dpmms.cam.ac.uk/%7Epll28/" rel="noopener noreferrer" target="_blank">Po-Ling Loh</a>, and <a href="http://www.jennwv.com" rel="noopener noreferrer" target="_blank">Jenn Wortman Vaughan</a>. The goal of the alliance is to ensure healthy community growth by fostering inclusive community engagement and encouraging active contributions from researchers at all stages of their careers. Let-All’s efforts towards realizing these goals include a series of ongoing and future activities, such as the first ALT mentoring workshop, coordinating the ALT Highlights blog series, and other upcoming community initiatives. This article reports on  Let-All’s <a href="https://let-all.com/alt.html" rel="noopener noreferrer" target="_blank">first Mentoring Workshop</a>, which was affiliated with the 32<sup>nd</sup> International Conference on Algorithmic Learning Theory.</p>



<p class="has-text-align-left has-text-align-justify">The workshop had two main sessions to cater to the time zone differences of the participants.  These sessions had three main components: an academic program, which included how-to-talks, Ask Me Anythings (AMAs), and presentation dissections; a technical program, which included research talks; and a social program, which included discussion tables and other activities.</p>



<p class="has-text-align-left has-text-align-justify">The workshop participants included students, researchers, and industry professionals, all at different levels of familiarity with learning theory. Because of the ongoing COVID-19 pandemic, the workshop was virtual. It was held on the online platforms Zoom and Gather town, a virtual interactive environment that mimics an in-person workshop setting. For accessibility, the workshop organizers opened up the workshop free of cost to all registered participants. </p>



<h2><strong>2 Program Highlights</strong></h2>



<h3><strong>2.1 Academic Program</strong></h3>



<p class="has-text-align-left has-text-align-justify">To kick off the workshop, one of the organizers began with a welcome lecture: Surbhi in session one and Nika in session two.  They read out the code of conduct and who to contact in case of issues, outlined the workshop’s purpose, and gave attendees demographic information. They explained how participants could navigate the workshop-themed Gather town workspace and then ended the introduction with encouragement for participants to mingle. </p>



<p class="has-text-align-left has-text-align-justify">The <strong><em>How-to-Talks</em></strong> sessions covered writing papers, giving talks, and networking. In Session 1, <a href="https://www.cs.cmu.edu/~praveshk/" rel="noopener noreferrer" target="_blank">Pravesh Kothari</a> talked in great detail about the dos and don’ts of what to add in the abstract, overview, introduction, and appendix when advising participants on how to best structure research papers. He told attendees to always put effort into understanding their intended reader or talk audience.  Pravesh encouraged attendees to consider the expertise and interests of the reader or listener to capture their attention since these highly determine the attention span and interest in the information presented to them.  He strongly recommended attendees watch the <em><a href="https://www.youtube.com/watch?v=vtIzMaLkCaM" rel="noopener noreferrer" target="_blank">Leadership Lab: The Craft of Writing Effectively</a></em> by Larry McEnerney , Director of the University of Chicago Writing Program.<em> </em>In session 2 of the workshop, <a href="https://home.cs.colorado.edu/~raf/" rel="noopener noreferrer" target="_blank">Rafael Frongillo</a>, similar to Pravesh, discussed how to capture the intended audience when one writes a paper, reviews, and talks.</p>



<p class="has-text-align-left has-text-align-justify">In the first <strong><em>networking session</em></strong>, <a href="https://www.cc.gatech.edu/~jabernethy9/" rel="noopener noreferrer" target="_blank">Jacob Abernethy</a> encouraged participants to seek out horizontal and vertical networking, for example, through collaborations, talks, and reach outs. He said that currently, in academia, Ph.D. admissions, faculty hiring, and tenure appointments are heavily risk-averse. Therefore, people seek out candidates based on their network. For this reason, it is crucial for students to network from early on in their careers. He gave great examples of how junior researchers can reach out and forge relationships with other researchers. For example, when you meet academics, faculty/postdocs at events, ask to give a talk at their lab. Jacob also candidly talked about his earlier failures at MIT and how they shaped his journey. He talked about luck and how <a href="https://www.microsoft.com/en-us/research/people/jcl/" rel="noopener noreferrer" target="_blank">John Langford</a>, who was at Toyota Technological Institute at Chicago at the time, took a chance on him that forever changed his life. Jacob, therefore, advised academics to take chances on people as this would change the course of the field. </p>



<p class="has-text-align-left has-text-align-justify"><a href="https://jamiemorgenstern.com" rel="noopener noreferrer" target="_blank">Jamie Morgenstern</a> discussed different networking methods in the <strong><em>second How-to-talks session</em></strong>. She emphasized that for junior researchers, it’s important to attend conferences and to network with others, to advertise their research through talks, and to reach out to faculty for collaboration. To introduce oneself and capture the listener’s attention, Jamie said, for conferences, prepare to do so in two minutes, for social four minutes, bar 12 minutes, and faculty interview 25 minutes. Senior grad students may help introduce the juniors during lunch/poster sessions. Finally, when emailing faculty about research, she said one should avoid discussion about other people’s work and instead should stick to the recipient’s work – “showing deep understanding and possibly open questions which might lead to collaboration.” </p>



<p class="has-text-align-left has-text-align-justify">In both workshop sessions, there were<strong><em> two parallel talk dissections, </em></strong>in which senior faculty members gave both positive and constructive feedback on talks junior researchers presented. In the first session, <a href="https://www.cs.cornell.edu/~rdk/" rel="noopener noreferrer" target="_blank">Bobby Kleinberg</a> discussed <a href="https://www.emilyruthdiana.com" rel="noopener noreferrer" target="_blank">Emily Diana</a>‘s talk titled “Minimax and Lexicographically Fair Learning: Algorithms, Experiments, and Generalization”. He highlighted parts that were impressive, those that needed improvement, and gave general advice on structuring an audience-based presentation. When Bobby suggested including more diagrams than text, a few people made suggestions of free tools including tikz, matcha.io, PowerPoint, and draw.io. In parallel, <a href="http://cseweb.ucsd.edu/~kamalika/" rel="noopener noreferrer" target="_blank">Kamalika Chaudhuri</a> dissected a talk on “Efficient, Noise-Tolerant, and Private Learning via Boosting” by <a href="https://marco.ntime.org" rel="noopener noreferrer" target="_blank">Marco Carmosino</a>. Two main takeaways of this talk dissection were the balance of technical and nontechnical content (e.g., explaining ideas with fun pictures, etc.) and having one main and clear idea as the talk’s takeaway. </p>



<p class="has-text-align-left has-text-align-justify">In the second session, <a href="https://sites.google.com/site/acmonsterqiao/" rel="noopener noreferrer" target="_blank">Mingda Qiao</a> gave a talk titled: “Stronger Calibration Lower Bounds via Sidestepping” which <a href="https://praneethnetrapalli.org" rel="noopener noreferrer" target="_blank">Praneeth Netrapalli</a> dissected. Praneeth remarked that theory folks often jump into the problem straight away without covering much background. In conferences, this might be fine due to time pressure and specific interests. However, in broader settings such as departmental seminars, he advised the speaker to allocate more time to introduce the problem lucidly and concisely. In parallel, <a href="https://sites.google.com/site/marywootters/" rel="noopener noreferrer" target="_blank">Mary Wootters</a> dissected a talk titled “List-Decodable Subspace Recovery: Dimension Independent Error in Polynomial Time” that <a href="http://aineshbakshi.com" rel="noopener noreferrer" target="_blank">Ainesh Bakshi</a> presented. </p>



<p class="has-text-align-left has-text-align-justify">In the first <strong><em>AMA session</em></strong> moderated by <a href="https://www.stat.cmu.edu/~aramdas/" rel="noopener noreferrer" target="_blank">Aaditya Ramdas</a>, <a href="https://web.stanford.edu/~lmackey/" rel="noopener noreferrer" target="_blank">Lester Mackey</a> refreshingly answered several of the attendees’ well-curated questions about what makes strong collaborations, how to get into grad school, and whether or not he ever felt like quitting his Ph.D., among others.  He encouraged students to take classes with professors they are interested in as it makes it easy to ask for a mentorship opportunity. Lester talked about collaborations and imposter syndrome and encouraged attendees to look on the brighter side of things, to remember that we all are working towards one big goal, creating positive changes in the world. Therefore if someone discovers a result before us, we should applaud them, collaborate if possible, and move onto new problems. He said he did not necessarily plan to do a Ph.D. but got into it towards the end of his undergraduate degree due to an internship that made him fall in love with doing research. </p>



<p class="has-text-align-left has-text-align-justify">In the evening, there was an AMA session with <a href="http://people.csail.mit.edu/shafi/" rel="noopener noreferrer" target="_blank">Shafi Goldwasser</a> moderated by Nika. Shafi gave thoughtful and candid answers to attendees’ captivating questions about research, life in academia, collaborations, among others. Shafi told attendees that healthy competition, trust, and overlap of research interest, is crucial for successful research in the early stage of the career. She also asserted that fundamental science is always impactful. She mentioned that the high points of her career were working on problems she was curious about: cryptography, pseudo-randomness, and zero-knowledge proofs. Finally, when asked about what advice she wished she had during the early stage of her career, interestingly Shafi replied: “having good colleagues, good friends at work, very important, most important – having a listening, promoting and supportive cohort of friends rather than an individualistic path as a scholar is priceless.” </p>



<h3><strong>2.2 Technical Program</strong></h3>



<p class="has-text-align-left has-text-align-justify"><strong><em>Two research talks</em></strong> happened in the first session. First, Po-Ling Loh gave a talk titled “Mean estimation for entangled single-sample distributions.” Then <a href="https://web.stanford.edu/~vsharan/" rel="noopener noreferrer" target="_blank">Vatsal Sharan</a> talked about “Sample Amplification: Increasing Dataset Size even when Learning is Impossible”.<br/>Similarly in the second session, <a href="https://www.cohennadav.com" rel="noopener noreferrer" target="_blank">Nadav Cohen</a> gave the first talk about tensor and matrix completion problems and the importance of understanding the theory behind deep learning from theoretical and practical perspectives. After, <a href="https://i.cs.hku.hk/~zhiyi/" rel="noopener noreferrer" target="_blank">Zhiyi Huang</a> gave a talk titled “Setting the Sample Complexity of Single-parameter Revenue Maximization.” </p>



<h3><strong>2.3 Social Program</strong></h3>



<p class="has-text-align-left has-text-align-justify">In both sessions, during the social hours, <a href="https://sites.google.com/view/sumegha-garg/home" rel="noopener noreferrer" target="_blank">Sumegha Garg</a>, <a href="http://sgunasekar.github.io" rel="noopener noreferrer" target="_blank">Suriya Gunasekar</a>, and <a href="https://teddlyk.github.io" rel="noopener noreferrer" target="_blank">Thodoris Lykouris</a> organized the <strong><em>table topics</em></strong> to help attendees meet and interact with senior researchers and professors on different topics. The table topics included the following; starting on ML research, research agendas, ML+X: multidisciplinary research, advisor-advisee relationships, collaborators, communicating research and networking, beyond your institution: internships and research visits, planning after grad school: academia versus industry, Grad school applications, Work ethics, and Open research discussion. </p>



<p class="has-text-align-left has-text-align-justify">The table topics were chaired by; Jacob Abernethy, <a href="https://www.shivani-agarwal.net" rel="noopener noreferrer" target="_blank">Shivani Agarwal</a>, <a href="https://ericbalkanski.com" rel="noopener noreferrer" target="_blank">Eric Balkanski</a>, Peter Bartlett, Avrim Blum, <a href="http://sbubeck.com/" rel="noreferrer noopener" target="_blank">Sébastien Bubeck</a>, Kamalika Chaudhuri, Nadav Cohen, Sumegha Garg, Surbhi Goel, Suriya Gunasekar, Nika Haghtalab,  <a href="https://www.cs.columbia.edu/~djhsu/" rel="noopener noreferrer" target="_blank">Daniel Hsu</a>, <a href="https://www.prateekjain.org" rel="noopener noreferrer" target="_blank">Prateek Jain</a>, <a href="https://www2.eecs.berkeley.edu/Faculty/Homepages/jordan.html" rel="noopener noreferrer" target="_blank">Mike Jordan</a>, <a href="https://homes.cs.washington.edu/~sham/" rel="noopener noreferrer" target="_blank">Sham Kakade</a>, <a href="https://www.microsoft.com/en-us/research/people/adum/" rel="noopener noreferrer" target="_blank">Adam Kalai</a>, Pravesh Kothari, <a href="https://people.cs.umass.edu/~akshay/" rel="noopener noreferrer" target="_blank">Akshay Krishnamurthy</a>, <a href="https://jerryzli.github.io" rel="noopener noreferrer" target="_blank">Jerry Li</a>, Po-Ling Loh, Thodoris Lykouris, <a href="https://www.tau.ac.il/~mansour/" rel="noopener noreferrer" target="_blank">Yishay Mansour</a>, <a href="https://pasin30055.github.io" rel="noopener noreferrer" target="_blank">Pasin Manurangsi</a>, <a href="https://vmuthukumar.ece.gatech.edu" rel="noopener noreferrer" target="_blank">Vidya Muthukumar</a>, Praneeth Netrapalli, <a href="https://wensun.github.io" rel="noopener noreferrer" target="_blank">Wen Sun</a>, <a href="https://www.bowaggoner.com" rel="noopener noreferrer" target="_blank">Bo Waggoner</a>, <a href="https://mzampet.com" rel="noopener noreferrer" target="_blank">Manolis Zampetakis</a>, and <a href="https://cyrilzhang.com/">Cyril Zhang</a>. </p>



<p class="has-text-align-left has-text-align-justify">Lastly, at the end of the two general research talks in sessions one and two of the workshop, attendees assembled on Gather town to close the workshop. The social event included 1:1 social interactions with other attendees, an attempt at forging relationships, and activities like dancing.</p>



<h2><strong>3 Attendance Statistics, Testimonials and Feedback</strong></h2>



<h3><strong>3.1 Participants Statistics</strong></h3>



<p class="has-text-align-left has-text-align-justify">ALT mentoring workshop welcomed talented academics, researchers, and professionals from a wide array of backgrounds. Of the 438 registered to attend the workshop, 197 were new to the learning theory community, 37 attended at least one ALT/COLT conference in the past, and 146 hadn’t attended ALT/COLT but had attended machine learning conferences (STOC, NeurIPS, etc.) as shown in Figure 1. </p>



<p class="has-text-align-left has-text-align-justify">The workshop participants came from different parts of the world, were of different genders, races, and seniority levels. We use Figures 2, 3b, 4a, and 4b to highlight this demographic information about the participants. Some participants chose session one, and others chose session two, a choice driven by their schedules and time zones. The attendance composition is as shown in figure 3a.</p>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-58" height="310" src="https://i0.wp.com/www.let-all.com/blog/wp-content/uploads/2021/05/Screen-Shot-2021-05-04-at-4.34.28-AM.png?resize=515%2C310&amp;ssl=1" width="515"/>Figure 1: Registrants familiarity with the community</figure></div>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-61" height="401" src="https://i0.wp.com/www.let-all.com/blog/wp-content/uploads/2021/05/Screen-Shot-2021-05-04-at-4.34.11-AM-2.png?resize=678%2C401&amp;ssl=1" width="678"/>Figure 2: Career stages of participants</figure></div>



<figure class="wp-block-gallery columns-2 is-cropped"><ul class="blocks-gallery-grid"><li class="blocks-gallery-item"><figure><img alt="" class="wp-image-70" height="414" src="https://i0.wp.com/www.let-all.com/blog/wp-content/uploads/2021/05/Screen-Shot-2021-05-04-at-4.33.54-AM-1.png?resize=678%2C414&amp;ssl=1" width="678"/></figure></li><li class="blocks-gallery-item"><figure><img alt="" class="wp-image-71" height="406" src="https://i0.wp.com/www.let-all.com/blog/wp-content/uploads/2021/05/Screen-Shot-2021-05-04-at-4.35.25-AM-1.png?resize=678%2C406&amp;ssl=1" width="678"/></figure></li></ul>Figure 3: Session preferences (a) and locations of participants (b)</figure>



<figure class="wp-block-gallery aligncenter columns-2 is-cropped"><ul class="blocks-gallery-grid"><li class="blocks-gallery-item"><figure><img alt="" class="wp-image-75" height="404" src="https://i0.wp.com/www.let-all.com/blog/wp-content/uploads/2021/05/Screen-Shot-2021-05-04-at-4.34.57-AM.png?resize=678%2C404&amp;ssl=1" width="678"/></figure></li><li class="blocks-gallery-item"><figure><img alt="" class="wp-image-77" height="404" src="https://i0.wp.com/www.let-all.com/blog/wp-content/uploads/2021/05/Screen-Shot-2021-05-04-at-4.34.42-AM-1.png?resize=678%2C404&amp;ssl=1" width="678"/></figure></li></ul>Figure 4: Race (a) and Gender (b) distribution of participants</figure>



<p/>



<h3><strong>3.2 Testimonials and Feedback</strong></h3>



<p class="has-text-align-left has-text-align-justify">In this section, we give a recount of testimonials from participants who we interviewed after the workshop. We also highlight some of the common themes in feedback from participants.</p>



<p class="has-text-align-left has-text-align-justify">In general, participants loved the content delivered in the sessions. They said it was informative, intuitive, and rare to find. Several participants loved interacting with peers and senior members and wished they had more time and activities to do it. The How-to-talks session (focused on networking skills, structuring papers, talks, and reviews) was the most popular session among attendees. 76.7% of the survey respondents said the session helped them gain new technical skills or hone existing skills, see opportunities in academia and how to use them, and see barriers in academia and ways to overcome them. Figure 5 highlights attendees’ ratings of the skills acquired from the workshop. </p>



<figure class="wp-block-image size-large is-resized is-style-default"><img alt="" class="wp-image-80" height="404" src="https://i0.wp.com/www.let-all.com/blog/wp-content/uploads/2021/05/Screen-Shot-2021-05-04-at-4.35.11-AM.png?resize=678%2C404&amp;ssl=1" width="678"/>Figure 5: Usefulness ratings of skills gained from the workshop</figure>



<p><strong>Below is a recount of the workshop experiences of the interviewed attendees.</strong></p>



<blockquote class="wp-block-quote"><p class="has-text-align-left has-text-align-justify">“My highlight was the How-to-Talks since they provided a lot of more personal information/inputs that you cannot easily find online and which was very valuable. The event helped me to remember and reflect upon which qualities are crucial to becoming a good researcher. I even made a list in a place that I see every day to keep them in mind.” – <em><a href="https://www.michaelaerni.com" rel="noopener noreferrer" target="_blank">Michael Aerni</a>, MSc student at ETH Zurich.</em></p></blockquote>



<blockquote class="wp-block-quote"><p class="has-text-align-left has-text-align-justify">“The workshop highlights for me were the How-to-talks, the AMA session with Lester, and the social tables. The How-to-talks were extremely valuable as they discussed topics such as structuring papers and networking in the community. These are subtle aspects that are not often explicitly talked about in the community. I, therefore, learned a lot from them. The AMA session was refreshingly honest and open. Finally, the social tables were also great as I got to meet and talk to some well-established senior community members like Sebastien Bubeck, Shivani Agarwal, and Akshay Krishnamurthy.” – <em><a href="https://people.eecs.berkeley.edu/~tgautam23/" rel="noopener noreferrer" target="_blank">Tanmay Gautam</a>, a second-year Ph.D. student at UC Berkeley. </em></p></blockquote>



<blockquote class="wp-block-quote"><p class="has-text-align-left has-text-align-justify">“It was awesome to have Lester Mackey answer my questions, indubitably. I learned about staying true to the research questions I genuinely believe in regardless of external opinions and rewards. As an NYU AI School organizer, I can appreciate how much effort went into organizing the workshop. The organizers did a stellar job! I think a version of the same event again would be perfect.” – <em><a href="https://swapneelm.github.io" rel="noopener noreferrer" target="_blank">Swapneel Mehta</a>, a Data Science Ph.D. student at New York University. </em></p></blockquote>



<blockquote class="wp-block-quote"><p class="has-text-align-left has-text-align-justify">“My highlights were getting to talk with senior members of the community. These opportunities rarely come by for someone who lives in a foreign country. For a timid person like myself, I am also thankful for the senior members for helping me (and other participants) breaking the ice and easing us into the conversations. Thanks to this event, I am now more confident in engaging with other researchers.”- <em><a href="http://www.donlapark.cmustat.com" rel="noopener noreferrer" target="_blank">Donlapark Ponnoprat</a>, a Statistics lecturer at Chiang Mai University. </em></p></blockquote>



<blockquote class="wp-block-quote"><p class="has-text-align-left has-text-align-justify">“My main highlights were Dr. Goldwasser’s session with Dr. Haghtalab and the socials. In the socials, I was able to ask professors and senior researchers for advice on varied topics based on the tables. Insights from Dr. Cohen’s lecture on tensor rank and implicit regularisation gave me several pointers to ideas in the literature that I was not aware of as a junior researcher from a slightly different AI specialty. These ideas might be beneficial for my research in the long term. </p><p class="has-text-align-left has-text-align-justify"> I send a sincere thank you to all the organizers. The mentorship workshop was a great event, and it models concrete actions, what it means to foster a welcoming community. It is clear how kind and dedicated folks are here as some researchers even stayed beyond midnight in their time zones to answer questions that attendees had. If an event like this happens again, I am most definitely signing up to come.” – <em><a href="https://github.com/esraa-saleh" rel="noopener noreferrer" target="_blank">Esra’a Saleh</a>, a Masters in Computer Science student at the University of Alberta, affiliated with AMII and RLAI.</em></p></blockquote>



<blockquote class="wp-block-quote"><p class="has-text-align-left has-text-align-justify">“My main takeaway from the event was an inside look at academia. As an undergrad, my only experience in academia has been the little experience I have with my advisory professors. While this is an invaluable experience, this event was nice as it was one of the very few that cater to students, including undergrads, with the intent of bringing them into the academia fold. Getting to know new people and talking to them was extremely interesting, especially during lockdown when connecting with others is a much more valuable commodity.” – <em><a href="https://pages.cs.wisc.edu/~shrey/" rel="noopener noreferrer" target="_blank">Shrey Shah</a>, a penultimate year undergraduate student at the University of Wisconsin-Madison. 
</em></p></blockquote>



<p class="has-text-align-left has-text-align-justify">Several participants enjoyed the workshop sessions and hoped that Let-All holds more similar themed workshops in conferences. Attendees suggested ways for attendees to interact more with each other. Some of the suggestions included the following: ‘beginner-friendly open problems sessions where attendees can collaborate’ – Esra’a Saleh, ‘an icebreaker session at the beginning that encourages attendees to mingle’ – Michael Aerni, and ‘a poster session for participants to present their work’ – Shrey Shah. </p>



<h2><strong>4 Conclusion</strong></h2>



<p class="has-text-align-left has-text-align-justify">The ALT mentorship workshop organized by the Learning Theory Alliance brought together many academics and researchers. It was, and we hope it continues to be, an opportunity for the budding researchers to learn about research and meta-research, forge collaborations, and be inspired. Kudos to the organizers and the Alliance in general for dreaming such a positive vision and then striving to make it a great success! </p>



<p class="has-text-align-left has-text-align-justify"><em>Thanks to <a href="http://www.gautamkamath.com" rel="noreferrer noopener" target="_blank">Gautam Kamath</a>, <a href="https://web.stanford.edu/~mglasgow/" rel="noreferrer noopener" target="_blank">Margalit Glasgow</a>, Surbhi Goel, Nika Haghtalab</em> <em>and Ellen Vitercik for helpful conversations and comments.</em></p></div>
    </content>
    <updated>2021-05-06T15:44:40Z</updated>
    <published>2021-05-06T15:44:40Z</published>
    <category term="ALT Highlights"/>
    <author>
      <name>Keziah</name>
    </author>
    <source>
      <id>https://www.let-all.com/blog</id>
      <logo>https://i0.wp.com/www.let-all.com/blog/wp-content/uploads/2021/04/logo.png?fit=32%2C32&amp;ssl=1</logo>
      <link href="https://www.let-all.com/blog/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://www.let-all.com/blog" rel="alternate" type="text/html"/>
      <title>The Learning Theory Alliance Blog</title>
      <updated>2022-04-09T22:48:17Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.let-all.com/blog/?p=55</id>
    <link href="https://www.let-all.com/blog/2021/05/04/alt-highlights-an-interview-with-the-pc-chairs-of-alt-2021/" rel="alternate" type="text/html"/>
    <title>ALT Highlights – An Interview with the PC Chairs of ALT 2021</title>
    <summary>Welcome to ALT Highlights, a series of blog posts spotlighting various happenings at the recent conference ALT 2021, including plenary talks, tutorials, trends in learning theory, and more! To reach a broad audience, the series will be disseminated as guest posts on different blogs in machine learning and theoretical computer science. This initiative is organized by […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Welcome to ALT Highlights, a series of blog posts spotlighting various happenings at the recent conference <a href="http://algorithmiclearningtheory.org/alt2021/">ALT 2021</a>, including plenary talks, tutorials, trends in learning theory, and more! To reach a broad audience, the series will be disseminated as guest posts on different blogs in machine learning and theoretical computer science. This initiative is organized by the <a href="https://www.let-all.com/">Learning Theory Alliance</a>, and overseen by <a href="http://www.gautamkamath.com/">Gautam Kamath</a>. All posts in ALT Highlights are indexed on the official <a href="https://www.let-all.com/blog/2021/04/20/alt-highlights-2021/">Learning Theory Alliance blog</a>.</p>



<p>This is the fourth post in the series, an interview with ALT 2021 PC Chairs <a href="http://vtaly.net/">Vitaly Feldman</a> and <a href="https://www.cs.huji.ac.il/~katrina/">Katrina Ligett</a>, written by <a href="https://www.comp.nus.edu.sg/~sutanu/">Sutanu Gayen</a> and <a href="https://sites.google.com/view/michal-moshkovitz">Michal Moshkovitz</a>.</p>



<hr class="wp-block-separator"/>



<p>We had the great opportunity to attend <em>The 32nd International Conference on Algorithmic Learning Theory</em>, held online between March 16-19, 2021, and co-chaired by Vitaly Feldman and Katrina Ligett. Vitaly is a research scientist at Apple AI Research and has done foundational works in machine learning and privacy-preserving data analysis. Katrina is an Associate Professor of Computer Science at the Hebrew University of Jerusalem and has done pivotal works in data privacy, algorithmic fairness, algorithmic game theory, and online algorithms. We asked for an interview with them about their experiences and perspectives as co-chairs, to which they kindly agreed. We are happy to share with the readers the excerpts of this interview.</p>



<p class="has-text-align-center"><img src="https://lh4.googleusercontent.com/7RUOfC-v06amphwIhfCYsQNH4jUg82AVsePZcbWO0D40DhSRk-Cf_wnXx9y5RI-qVYz6D-IRAxRzsQ9lWBpraofuggrTYC_sG40GehOCvSrQyZfj1khlMTVqK23NKOZueGcbK_xa" style="width: 225px;"/>           <img height="252" src="https://lh4.googleusercontent.com/lUMmpb6Bcfq3bPljS7jYaF2TFaXRks64--IeslcdR3WzqnCtUETu-ymoOSxm7ys_6eyRFb2mGmd1mCe1boNHdxii0d1_UCthAEJy_eTsWsGQsFKpsV5snZe3Nm9g-QDy0JTnzPKx" width="194"/></p>



<p><strong>How it started</strong></p>



<p>How are chairs and program committees chosen? </p>



<p class="has-text-color" style="color: #0000ff;">Katrina: The chairs are selected by the Association for Algorithmic Learning Theory (AALT) Steering Committee (<a href="http://algorithmiclearningtheory.org/alt-steering-committee/">http://algorithmiclearningtheory.org/alt-steering-committee/</a>), and the chairs then select the program committee members. Vitaly and I brainstormed potential PC member names, solicited additional suggestions, and also considered the lists of people who have served on recent ALT and COLT PCs. In building the PC, we had many considerations in mind, including coverage of research areas, and various metrics of diversity.</p>



<p><strong>The chairs’ role</strong></p>



<p>What are the different tasks a chair has? What is the most difficult task?</p>



<p class="has-text-color" style="color: #0000ff;">Katrina: At a high level, the roles of the PC chairs are to build the PC, oversee the reviewing process and create the conference program. Practically, though, there are a lot of decisions that need to be discussed, emails to be sent, and a lot of organizational aspects to tend to—configuring the reviewing platform, sending reminders, chasing down late reviews, and so on. Vitaly and I have a very, very long joint “to do” list—and luckily, it’s now almost all crossed off! We also had additional responsibilities this year because of the move to the virtual conference format, including selecting the technologies, overseeing the pre-recording process, and much more.</p>



<p class="has-luminous-vivid-orange-color has-text-color">Vitaly: I think the hardest and probably the most time-consuming is making the accept/reject decisions on papers.  For a large fraction of the papers arriving at the decision requires getting a sense of the results; understanding the main points in reviews, author responses and discussion (while calibrating them to the PC members and reviewers); ensuring that each paper is properly discussed by chasing reviewers, asking questions and often soliciting additional opinions. We also needed to come up with a set of criteria for deciding on borderline cases and make sure that these criteria are applied as consistently as possible. At the end it is a rather long and iterative process that luckily for us has converged to a program we are happy with.</p>



<p>How much time do you spend doing chair tasks? How do you balance chairing a conference (a massive amount of work) with all your other commitments? Do you turn down other service items you would generally accept, etc.?</p>



<p class="has-text-color" style="color: #0000ff;">Katrina: It’s difficult to estimate the number of hours, but I think we have been meeting regularly since early June 2020, and we’re only wrapping up our work now, in late March 2021. It’s a much longer-timeframe commitment than serving as a PC member. I actually am chairing a second conference this year, FORC, and together it makes for a pretty serious load. As a result, I have been declining all other conference-related service. I also have a couple of other pretty substantial service commitments, as well, so I just don’t have bandwidth this year for additional PC and Area Chair-type roles.</p>



<p class="has-luminous-vivid-orange-color has-text-color">Vitaly: I agree that it’s hard to tell how much time we spent in total. My rough estimate is that it’s about a month of full-time work. I also had to decline most other service commitments during that period some of which I’d normally accept. Naturally, it also slows down other work so I definitely had to lean more on my collaborators in some of the ongoing projects <img alt="&#x1F642;" class="wp-smiley" src="https://s.w.org/images/core/emoji/13.1.0/72x72/1f642.png" style="height: 1em;"/></p>



<p>Can chairs bring their own personality into the conference? How? </p>



<p class="has-text-color" style="color: #0000ff;">Katrina: One area where the chairs enjoy freedom is in selecting the keynote and tutorial speakers. I’m biased, of course, but I think we chose very well, and all of these speakers (Joelle Pineau, Shay Moran, and Costis Daskalakis) gave excellent talks (they were recorded—check them out if you missed them)! We also were fortunate to be able to work with amazing partners who organized the mentoring workshop (Surbhi Goel, Nika Hagtalab, and Ellen Vitercik) and the Women in ML Theory event (Tosca Lechner and Ruth Urner). These aspects of the conference beyond the papers are a way for the chairs to express their priorities.</p>



<p class="has-luminous-vivid-orange-color has-text-color">Vitaly: The chairs have a lot of freedom in choosing how to run the review process, design the conference program and who else will be involved. So, inevitably, the chairs’ personalities and tastes end up being reflected in the final results. </p>



<p>Does the online conference impact the chair job? How? </p>



<p class="has-text-color" style="color: #0000ff;">Katrina: Typically, the PC chairs build the program, and then many details of organizing and running the conference get handed off to local organization chairs. But this year, since ALT was held virtually, there were many unusual tasks that fell to the PC chairs—not just the obvious ones like choosing the technologies and format and negotiating those contracts, but smaller things like chasing down authors who failed to upload their recordings, and developing instructions for people in various roles to interact with the conference platform.</p>



<p class="has-text-color" style="color: #0000ff;">In addition, COVID times placed strains on many people, which made it more challenging to recruit PC members, and resulted in a higher than usual rate of late reviews and PC drop-outs, which of course left us scrambling.</p>



<p>What motivates you to spend time on a conference service?</p>



<p class="has-text-color" style="color: #0000ff;">Katrina: We all rely on the conference system for our personal professional advancement, and for the advancement of our field as a whole. So we all owe that system our service, of course, according to our abilities, availability, and seniority. Also, it’s fun to get this different perspective on the conference review process and on the field. And it’s an honor to be entrusted with shepherding a conference for a year and hopefully nurturing its growth.</p>



<p class="has-luminous-vivid-orange-color has-text-color">Vitaly: I agree that it’s a mix of (1) contribution to the community I’m a member of and, perhaps, an opportunity to improve some of its processes (2) a learning experience that gives one a higher-level view of the research that is happening and people who do it (3) honor and recognition that come with the job.</p>



<p><strong>Awards </strong></p>



<p>How do you decide which papers were chosen as awards? </p>



<p class="has-luminous-vivid-orange-color has-text-color">Vitaly: A necessary condition for a paper to receive an award is that at least one of the PC members/reviewers assigned to the paper is excited about the results.  So we start by looking at papers with the highest scores (typically all papers that received at least one “strong accept”) and reading their reviews. This allowed us to narrow down the list to a set of 5-6 candidates. From those we selected the winners by learning more about the results and selecting those, we found the most significant and interesting for the community.</p>



<p><strong>The review process</strong></p>



<p>What are your thoughts about the current peer review process in ALT? What are the downsides and advantages? Do you have suggestions for improvement?</p>



<p class="has-luminous-vivid-orange-color has-text-color">Vitaly: It is common that confidence in correctness of the results in a conference submission is based on higher-level sanity checks and general intuition of the reviewers. Naturally, the more interesting and important result the more likely it is to be scrutinized. At this ALT we did not run into a situation where the authors’ reputation affected our confidence in the correctness of the results. In case of concerns about correctness of an interesting result we would ask either an expert on the PC or an external expert to try to verify the result.</p>



<p class="has-luminous-vivid-orange-color has-text-color">ALT currently relies on a traditional theory conference model of reviewing and for a typical submission has several PC members who are experts in the subarea. The reviewing load is also relatively light (8 papers per PC member). So I think that the overall reviewing quality is pretty much as good as it gets in ML (and is similar to COLT). Naturally, the model is not perfect and there is still variation in the quality of individual reviews. This year many more reviewers and PC members were under unusual time pressure due to the pandemic so perhaps the variation was higher than usual.</p>



<p><strong>The future</strong></p>



<p>What are your suggestions for the next chair? </p>



<p class="has-text-color" style="color: #0000ff;">Katrina: Make sure you have a good co-chair. <img alt="&#x1F642;" class="wp-smiley" src="https://s.w.org/images/core/emoji/13.1.0/72x72/1f642.png" style="height: 1em;"/> Vitaly has been a great partner for this process—fun to work with, reliable, always willing to pitch in even on the less-fun tasks, and I have great respect for his technical perspective.</p>



<p class="has-luminous-vivid-orange-color has-text-color">Vitaly: I agree that diversity of perspectives and expertise is useful in several ways. Most notably, it gives the chairs a wider network of people to select the PC from. But I completely agree with Katrina, that the most important thing is the ability of co-chairs to work well together: after all, it’s a lot of work and complicated decisions that need to be made jointly. Here, I couldn’t have asked for more: Katrina is amazing both professionally and personally. Working with her was definitely the highlight of being the ALT co-chair and learned a lot from her in the process as well.</p></div>
    </content>
    <updated>2021-05-04T16:40:08Z</updated>
    <published>2021-05-04T16:40:08Z</published>
    <category term="ALT Highlights"/>
    <author>
      <name>Gautam Kamath</name>
    </author>
    <source>
      <id>https://www.let-all.com/blog</id>
      <logo>https://i0.wp.com/www.let-all.com/blog/wp-content/uploads/2021/04/logo.png?fit=32%2C32&amp;ssl=1</logo>
      <link href="https://www.let-all.com/blog/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://www.let-all.com/blog" rel="alternate" type="text/html"/>
      <title>The Learning Theory Alliance Blog</title>
      <updated>2022-04-09T22:48:21Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.let-all.com/blog/?p=39</id>
    <link href="https://www.let-all.com/blog/2021/04/20/alt-highlights-2021/" rel="alternate" type="text/html"/>
    <title>Introducing ALT Highlights 2021</title>
    <summary>The 32nd International Conference on Algorithmic Learning Theory (ALT 2021) just wrapped up, featuring a wide selection of exciting results at the frontiers of learning theory. The proceedings and all talk recordings are available online for perusal.  Did you miss out on the conference? Don’t have time to go through all the proceedings? Fear not, […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The 32nd International Conference on Algorithmic Learning Theory (<a href="http://algorithmiclearningtheory.org/alt2021/">ALT 2021</a>) just wrapped up, featuring a wide selection of exciting results at the frontiers of learning theory. The <a href="http://proceedings.mlr.press/v132/">proceedings</a> and all <a href="https://www.youtube.com/channel/UC7wMo5OivSnsQJNfZm8zmJQ/videos">talk recordings</a> are available online for perusal. </p>



<p>Did you miss out on the conference? Don’t have time to go through all the proceedings? Fear not, the <a href="https://let-all.com/">Learning Theory Alliance</a> is pleased to bring you ALT Highlights, a series of blog posts spotlighting various happenings at ALT, including plenary talks, tutorials, trends in learning theory, and more!</p>



<p>In order to reach a broad audience in learning theory, we’ll be releasing these posts across a number of different blogs. All content will be linked from this post, so be sure to bookmark this post so you don’t miss anything!</p>



<p>ALT Highlights will be brought to you by an amazing team of junior researchers, written by <a href="https://people.eecs.berkeley.edu/~kush/">Kush Bhatia</a>, <a href="https://www.comp.nus.edu.sg/~sutanu/">Sutanu Gayen</a>, <a href="https://web.stanford.edu/~mglasgow/">Margalit Glasgow</a>, <a href="https://sites.google.com/view/michal-moshkovitz">Michal Moshkovitz</a>, <a href="https://www.ttic.edu/students/">Keziah Naggita</a>, and <a href="https://sites.google.com/site/cyrusrashtchian/">Cyrus Rashtchian</a>, and overseen and edited by <a href="http://www.gautamkamath.com/">Gautam Kamath</a>. </p>



<p>Links to articles:<br/>1. <a href="https://hunch.net/?p=13762948">An Interview with Joelle Pineau</a><br/>2. <a href="https://differentialprivacy.org/alt-highlights/">An Equivalence between Private Learning and Online Learning</a><br/>3. <a href="https://windowsontheory.org/2021/04/30/alt-highlights-equilibrium-computation-and-the-foundations-of-deep-learning/">Equilibrium Computation and the Foundations of Deep Learning</a><br/>4. <a href="https://www.let-all.com/blog/2021/05/04/alt-highlights-an-interview-with-the-pc-chairs-of-alt-2021/">An Interview with the PC Chairs of ALT 2021</a><br/>5. <a href="https://www.let-all.com/blog/2021/05/06/alt-highlights-a-report-on-the-first-alt-mentoring-workshop/">A Report on the First ALT Mentoring Workshop</a><br/>6. <a href="https://blog.simons.berkeley.edu/2021/07/trends-in-machine-learning-theory/">Trends in Machine Learning Theory</a></p></div>
    </content>
    <updated>2021-04-20T16:26:22Z</updated>
    <published>2021-04-20T16:26:22Z</published>
    <category term="ALT Highlights"/>
    <author>
      <name>admin</name>
    </author>
    <source>
      <id>https://www.let-all.com/blog</id>
      <logo>https://i0.wp.com/www.let-all.com/blog/wp-content/uploads/2021/04/logo.png?fit=32%2C32&amp;ssl=1</logo>
      <link href="https://www.let-all.com/blog/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://www.let-all.com/blog" rel="alternate" type="text/html"/>
      <title>The Learning Theory Alliance Blog</title>
      <updated>2022-04-09T22:48:36Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://toc4fairness.org/?p=1551</id>
    <link href="https://toc4fairness.org/videos-up/" rel="alternate" type="text/html"/>
    <title>Videos Up</title>
    <summary>With a bit of a delay, we are starting to upload the videos of our seminar’s talks. The Inaugural Meeting of our seminar was devoted to a wonderful talk by ...</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>With a bit of a delay, we are starting to upload the videos of our seminar’s talks. The <a href="https://toc4fairness.org/inaugural-meeting-toc4fairness-seminar-annette-zimmermann/">Inaugural Meeting</a> of our seminar was devoted to a wonderful talk by Dr. <a href="https://www.annette-zimmermann.com/">Annette Zimmermann</a>.  I highly recommend watching <a href="https://toc4fairness.org/inaugural-meeting-toc4fairness-seminar-annette-zimmermann-2/">the video</a>, and following up with some additional reading (some pointers below).</p>



<p>I won’t try to summarize the talk because I doubt that I can do it justice, but one of the themes (which I fully support) is that it is not enough to consider “fair” implementations of specific tasks. Instead, we (also) want to explore the right task to implement and if it is appropriate to implement any algorithmic task in any specific context. </p>



<p>As a side note, I loved Annette’s statement on ethics,  “if we can choose, we’re on the hook.” For me, it beautifully complements the paradigm that “ought implies can.” In other words, ethical imperatives only exist when the expected action is possible but every choice has ethical implications.   </p>



<hr class="wp-block-separator"/>



<p>Some resources for additional reading.</p>



<p><strong>Resources on exploitation</strong></p>



<p><strong>Introductory / very accessible for an interdisciplinary audience</strong></p>



<p>Nicholas Vrousalis, “Exploitation: A Primer,” <em>Philosophy Compass</em> 13, no. 2 (2018).</p>



<p><strong>Background</strong></p>



<p>G.A. Cohen, “The Labor Theory of Value and the Concept of Exploitation,” <em>Philosophy and Public Affairs</em> 8, no. 4 (1979): 338–360.</p>



<p>Joel Feinberg, <em>Harmless Wrongdoing</em>, Oxford: Oxford University Press (1988).`</p>



<p>Robert E. Goodin, “Exploiting a Situation and Exploiting a Person,” in Andrew Reeve (ed.), <em>Modern Theories of Exploitation</em>, London: Sage (1987), 166–200.</p>



<p>Ruth Sample, <em>Exploitation, What It Is and Why it is Wrong</em>, Lanham, MD: Rowman and Littlefield (2003).</p>



<p>Nicholas Vrousalis, “Exploitation, Vulnerability, and Social Domination,” <em>Philosophy and Public Affairs</em>, 41, no. 2 (2013): 131–157.</p>



<p>Alan Wertheimer, <em>Exploitation</em>, Princeton: Princeton University Press (1996).</p>



<p>Iris Marion Young, “Five Faces of Oppression,” in Thomas Wartenberg (ed.), <em>Rethinking Power</em>, Albany, NY: SUNY Press (1992).</p>



<p><strong>Resource on the political philosophy of AI (for a general audience)</strong></p>



<p>Annette Zimmermann, Elena Di Rosa, Hochan Kim, “<a href="http://bostonreview.net/science-nature-politics/annette-zimmermann-elena-di-rosa-hochan-kim-technology-cant-fix-algorithmic">Technology Can’t Fix Algorithmic Injustice</a>, <em>Boston Review</em> </p></div>
    </content>
    <updated>2021-03-25T22:50:07Z</updated>
    <published>2021-03-25T22:50:07Z</published>
    <category term="Blog"/>
    <author>
      <name>Omer Reingold</name>
    </author>
    <source>
      <id>https://toc4fairness.org</id>
      <logo>https://i0.wp.com/toc4fairness.org/wp-content/uploads/2020/10/cropped-favicon.png?fit=32%2C32&amp;ssl=1</logo>
      <link href="https://toc4fairness.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://toc4fairness.org" rel="alternate" type="text/html"/>
      <subtitle>a simons collaboration project</subtitle>
      <title>TOC for Fairness</title>
      <updated>2022-04-09T22:47:59Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://thmatters.wordpress.com/?p=1318</id>
    <link href="https://thmatters.wordpress.com/2021/02/10/sigact-award-deadlines-for-2021/" rel="alternate" type="text/html"/>
    <title>SIGACT Award deadlines for 2021</title>
    <summary>From the SIGACT executive committee: The deadlines to submit nominations for the Gödel Prize and the SIGACT Distinguished Service Award are coming soon. Calls for nominations for both awards can be found at the links below. Gödel Prize: deadline February 28, 2021. SIGACT Distinguished Service Award: deadline March 8, 2021.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>From the SIGACT executive committee:</p>



<p>The deadlines to submit nominations for the Gödel Prize and the SIGACT Distinguished Service Award are coming soon. Calls for nominations for both awards can be found at the links below.</p>



<ul><li><a href="https://www.sigact.org/prizes/g%C3%B6del/g%C3%B6del_call21.pdf">Gödel Prize</a>: deadline <strong>February 28</strong>, 2021.</li><li><a href="https://sigact.org/prizes/service.html">SIGACT Distinguished Service Award</a>: deadline <strong>March 8</strong>, 2021.</li></ul></div>
    </content>
    <updated>2021-02-10T20:39:50Z</updated>
    <published>2021-02-10T20:39:50Z</published>
    <category term="Uncategorized"/>
    <category term="awards"/>
    <category term="deadlines"/>
    <author>
      <name>shuchic</name>
    </author>
    <source>
      <id>https://thmatters.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://thmatters.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://thmatters.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://thmatters.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://thmatters.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theory Matters</title>
      <updated>2022-04-09T22:48:20Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://toc4fairness.org/?p=1242</id>
    <link href="https://toc4fairness.org/how-to-estimate-the-uncertainty-of-predictions/" rel="alternate" type="text/html"/>
    <title>How to Estimate the Uncertainty of Predictions</title>
    <summary>This is a post about a new paper Online Multivalid Learning: Means, Moments, and Prediction Intervals, that is joint work with Varun Gupta, Christopher Jung, Georgy Noarov, and Mallesh Pai. ...</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p class="has-text-align-center">This is a post about a new paper <em><a href="https://arxiv.org/abs/2101.01739">Online Multivalid Learning: Means, Moments, and Prediction Intervals</a></em>, that is joint work with Varun Gupta, Christopher Jung, Georgy Noarov, and Mallesh Pai.  For those that prefer watching to reading, you can also see <a href="https://youtu.be/8Hy09Ot2tDw">a talk I gave about this</a>. </p>



<p>Suppose you go and train the latest, greatest machine learning architecture to predict something important. Say (to pick an example entirely out of thin air) you are in the midst of a pandemic, and want to predict the severity of patients’ symptoms in 2 days time, so as to triage scarce medical resources. Since you will be using these predictions to make decisions, you would like them to be accurate in various ways: for example, at the very least, you will want your predictions to be calibrated, and you may also want to be able to accurately quantify the uncertainty of your predictions (say with 95% prediction intervals). It is a fast moving situation, and data is coming in dynamically — and you need to make decisions as you go. What can you do? </p>



<p>The first thing you might do is <a href="https://twitter.com/Aaroth/status/1272545845603434497">ask on twitter</a>! What you will find is that the standard tool for quantifying uncertainty in settings like this is <a href="https://jmlr.csail.mit.edu/papers/volume9/shafer08a/shafer08a.pdf">conformal prediction</a>. The conformal prediction literature has a number of elegant techniques for endowing arbitrary point prediction methods with <em>marginal prediction intervals</em>: i.e intervals <img alt="(\ell(x), u(x))" class="latex" src="https://s0.wp.com/latex.php?latex=%28%5Cell%28x%29%2C+u%28x%29%29&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002"/> such that over the randomness of some data distribution over labelled examples <img alt="(x,y)" class="latex" src="https://s0.wp.com/latex.php?latex=%28x%2Cy%29&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002"/>: <img alt="\Pr_{(x,y)}\left[y \in [\ell(x), u(x)]\right] \approx 0.95" class="latex" src="https://s0.wp.com/latex.php?latex=%5CPr_%7B%28x%2Cy%29%7D%5Cleft%5By+%5Cin+%5B%5Cell%28x%29%2C+u%28x%29%5D%5Cright%5D+%5Capprox+0.95&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002"/> These would be 95% marginal prediction intervals — but in general you could pick your favorite coverage probability <img alt="1-\delta" class="latex" src="https://s0.wp.com/latex.php?latex=1-%5Cdelta&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002"/>.  </p>



<p>Conformal prediction has a lot going for it — its tools are very general and flexible, and lead to practical algorithms. But it also has two well known shortcomings:</p>



<ol><li><strong>Strong Assumptions</strong>. Like many tools from statistics and machine learning, conformal prediction methods require that the future look like the past. In particular, they require that the data be drawn i.i.d. from some distribution — or at least be <em>exchangable</em> (i.e. their distribution should be invariant to permutation). This is sometimes the case — but it often is not. In our pandemic scenario, the distribution on patient features might quickly change in unexpected ways as the disease moves between different populations, as might the relationship between features and outcomes, as treatments advance. In other settings in which consequential decisions are being made about people — like lending and hiring decisions — people might intentionally manipulate their features in response to the predictive algorithms you deploy, in an attempt to get the outcome they want. Or you might be trying to predict outcomes in time series data, in which there are explicit dependencies across time. In all of these scenarios, exchangeability is violated.</li><li><strong>Weak Guarantees</strong>. Marginal coverage guarantees are <em>averages over people</em>. 95% marginal coverage means that the true label falls within the predicted interval for 95% of people. It need not mean anything for <em>people like you</em>. For example, if you are part of a demographic group that makes up less than 5% of the population, it is entirely consistent with the guarantees of a 95% marginal prediction interval that labels for people from your demographic group fall outside of their intervals 100% of the time. This can be both an accuracy and a <strong><em>fairness</em> </strong>concern — marginal prediction works well for “typical” members of a population, but not necessarily for everyone else. </li></ol>



<p>What kinds of improvements might we hope for? Lets start with how to strengthen the guarantee:</p>



<p><strong>Multivalidity</strong> Ideally, we would want <em>conditional</em> guarantees — i.e. the promise that for every <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002"/>, that we would have <img alt="\Pr_{y}\left[y \in [\ell(x), u(x)] | x \right] \approx 0.95" class="latex" src="https://s0.wp.com/latex.php?latex=%5CPr_%7By%7D%5Cleft%5By+%5Cin+%5B%5Cell%28x%29%2C+u%28x%29%5D+%7C+x+%5Cright%5D+%5Capprox+0.95&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002"/>. In other words, that somehow for each individual, the prediction interval was valid for them specifically, over the “unrealized” (or unmeasured) randomness of the world. Of course this is too much to hope for. In a rich feature space, we have likely never seen anyone exactly like you before (i.e. with your feature vector <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002"/>). So strictly speaking, we have no information at all about your conditional label distribution. We still have to average over people. But we don’t have to average over everybody. An important idea that has been investigated in <a href="https://arxiv.org/abs/1711.08513">several </a><a href="https://arxiv.org/abs/1711.05144">different </a><a href="https://arxiv.org/abs/1805.12317">contexts </a>in recent years in the theory literature on fairness is that we might articulate a very rich collection of (generally intersecting) demographic groups <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002"/> corresponding to relevant subsets of the data domain, and ask for things that we care about to hold true as averaged over any group <img alt="S \in G" class="latex" src="https://s0.wp.com/latex.php?latex=S+%5Cin+G&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002"/> in the collection. In the case of prediction intervals, this would correspond to asking for something like that simultaneously for every demographic group <img alt="S \in G" class="latex" src="https://s0.wp.com/latex.php?latex=S+%5Cin+G&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002"/>, <img alt="\Pr_{(x,y)}\left[y \in [\ell(x), u(x)] | x \in S \right] \approx 0.95" class="latex" src="https://s0.wp.com/latex.php?latex=%5CPr_%7B%28x%2Cy%29%7D%5Cleft%5By+%5Cin+%5B%5Cell%28x%29%2C+u%28x%29%5D+%7C+x+%5Cin+S+%5Cright%5D+%5Capprox+0.95&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002"/>. Note here that an individual might be a member of many different demographic groups, and can interpret the guarantees of their prediction interval as averages over any of those demographic groups, at their option. This is what we can achieve — at least for any such group that isn’t too small. </p>



<p>And what kinds of assumptions do we need?</p>



<p><strong>Adversarial Data </strong>Actually, its not clear that we need any! Many learning problems which initially appear to require distributional assumptions turn out to be solvable even in the worst case over data sequences — i.e. even if a clever adversary, with full knowledge of your algorithm, and with the intent only to sabotage your learning guarantees, is allowed to adaptively choose data to present to your algorithm. This is the case for <a href="https://academic.oup.com/biomet/article-abstract/85/2/379/298827">calibrated weather prediction</a>, as well as <a href="http://proceedings.mlr.press/v48/syrgkanis16.pdf">general contextual prediction</a>. It turns out to be the case for us as well. Instead of promising coverage probabilities of <img alt="1-\delta + O(1/T)" class="latex" src="https://s0.wp.com/latex.php?latex=1-%5Cdelta+%2B+O%281%2FT%29&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002"/> after <img alt="T" class="latex" src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002"/> rounds <em>on the underlying distribution</em>, as<a href="https://www.stat.cmu.edu/~ryantibs/papers/conformal.pdf"> conformal prediction is able to</a>, we offer <em>empirical</em> coverage rates of <img alt="1-\delta \pm O(1/\sqrt{T})" class="latex" src="https://s0.wp.com/latex.php?latex=1-%5Cdelta+%5Cpm+O%281%2F%5Csqrt%7BT%7D%29&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002"/> (since for us there is no underlying distribution). This kind of guarantee is quite similar to what<a href="https://www.stat.cmu.edu/~ryantibs/papers/conformal.pdf"> conformal prediction guarantees about empirical coverage</a>. </p>



<p><strong>More Generally </strong>Our techniques are not specific to prediction intervals. We can do the same thing for many other distributional quantities. We work this out in the case of predicting label means, and predicting variances of the residuals of arbitrary prediction methods. For mean prediction, this corresponds to an algorithm for providing <a href="https://arxiv.org/abs/1711.08513">multi-calibrated predictions in the sense of Hebert-Johnson et al</a>, in an online adversarial environment. For variances and other higher moments, it corresponds to an online algorithm for making <a href="https://arxiv.org/abs/2008.08037">mean-conditioned moment multicalibrated predictions in the sense of Jung et al</a>.</p>



<p><strong>Techniques</strong> At the risk of boring my one stubbornly remaining reader, let me say a few words about how we do it. We generalize an idea that dates back to an argument that<a href="https://dash.harvard.edu/bitstream/handle/1/3203773/fudenberg_calibrate.pdf"> Fudenberg and Levine first made in 1995</a> — and is closely related to <a href="http://www.ma.huji.ac.il/hart/papers/calib-minmax.pdf">an earlier, beautiful argument by Sergiu Hart</a> — but that I just learned about this summer, and thought was just amazing. It applies broadly to solving any prediction task that would be easy, if only you were facing a known data distribution. This is the case for us. If, for each arriving patient at our hospital, a wizard <em>told us</em> their “true” distribution over outcome severity, we could easily make calibrated predictions by always predicting the mean of this distribution — and we could similarly read off correct 95% coverage intervals from the CDF of the distribution. So what? That’s not the situation we are in, of course. Absent a wizard, we first need to commit to some learning algorithm, and only then will the adversary decide what data to show us. </p>



<p>But lets put our game theory hats on. Suppose we’ve been making predictions for awhile. We can write down some measure of our error so far — say the maximum, over all demographic groups in <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002"/>, of the deviation of our empirical coverage so far from our 95% coverage target.  For the next round, define a zero sum game, in which we (the learner) want to minimize the <em>increase</em> in this measure of error, and the adversary wants to maximize it. The defining feature of zero-sum games is that how well you can do in them is independent of which player has to announce their distribution on play first — this is the celebrated <a href="https://en.wikipedia.org/wiki/Minimax_theorem">Minimax Theorem</a>. So to evaluate how well the learner could do in this game, we can think about the situation involving a Wizard above, in which for each arriving person, before we have to make a prediction for them, we get to observe their true label distribution. Of course in this scenario we can do well, because for all of our goals, our measure of success is based on how well our predictions match observed properties of these distributions. The Minimax theorem tells us that (at least in principle — it doesn’t give us the algorithm), there must therefore also be a learning algorithm that can do just as well, but against an adversary. </p>



<p>The minimax argument is slick, but non-constructive. To actually pin down a concrete algorithm, we need to solve for the equilibrium in the corresponding game. That’s what we spend much of the paper doing, for each of the prediction tasks that we study. For multicalibration, we get a simple, elementary algorithm — but for the prediction interval problem, although we get a polynomial time algorithm, it involves solving a linear program with a separation oracle at each round. Finding more efficient and practical ways to do this strikes me as an important problem. </p>



<p>Finally, I had more fun writing this paper — learning about old techniques from the game theoretic calibration literature — than I’ve had in awhile. I hope a few people enjoy reading it!</p>



<p/>



<p/></div>
    </content>
    <updated>2021-01-15T14:00:00Z</updated>
    <published>2021-01-15T14:00:00Z</published>
    <category term="Blog"/>
    <category term="multicalibration"/>
    <category term="papers"/>
    <category term="subgroup fairness"/>
    <category term="uncertainty"/>
    <author>
      <name>Aaron Roth</name>
    </author>
    <source>
      <id>https://toc4fairness.org</id>
      <logo>https://i0.wp.com/toc4fairness.org/wp-content/uploads/2020/10/cropped-favicon.png?fit=32%2C32&amp;ssl=1</logo>
      <link href="https://toc4fairness.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://toc4fairness.org" rel="alternate" type="text/html"/>
      <subtitle>a simons collaboration project</subtitle>
      <title>TOC for Fairness</title>
      <updated>2022-04-09T22:47:55Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://toc4fairness.org/?p=1276</id>
    <link href="https://toc4fairness.org/launching-toc4fairness/" rel="alternate" type="text/html"/>
    <title>Launching TOC4Fairness</title>
    <summary>I am excited to launch the Simons Foundation’s Collaboration on the Theory of Algorithmic Fairness, funded by the Simons Foundation. This is a large-scale multi-institutional effort to accelerate the (already ...</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I am excited to launch the <a href="https://toc4fairness.org/">Simons Foundation’s Collaboration on the Theory of Algorithmic Fairness</a>, funded by<a href="https://www.simonsfoundation.org/"> the Simons Foundation</a>. This is a large-scale multi-institutional effort to accelerate the (already powerful) impact of TOC on the emerging area of algorithmic fairness. Beyond the ambitious research goals of this project (which we will discuss in future posts), we hope it will play an important role in community building and bridge building to other fields of research. In addition to launching <a href="https://toc4fairness.org/category/blog/">this blog</a> and <a href="https://toc4fairness.org/">our site</a>, we are also launching a <a href="https://toc4fairness.org/category/events/">research seminar</a> that will feature a diverse set of talks. We are very exited to have  <a href="https://toc4fairness.org/inaugural-meeting-toc4fairness-seminar-annette-zimmermann/">Annette Zimmermann</a> as our inaugural speaker (a week from today). </p>



<p>If you want to join our seminar, please email toc4fairness-director@cs.stanford.edu and we will add you to our email list (which we will be careful not to overuse).</p></div>
    </content>
    <updated>2021-01-13T15:45:36Z</updated>
    <published>2021-01-13T15:45:36Z</published>
    <category term="Blog"/>
    <author>
      <name>Omer Reingold</name>
    </author>
    <source>
      <id>https://toc4fairness.org</id>
      <logo>https://i0.wp.com/toc4fairness.org/wp-content/uploads/2020/10/cropped-favicon.png?fit=32%2C32&amp;ssl=1</logo>
      <link href="https://toc4fairness.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://toc4fairness.org" rel="alternate" type="text/html"/>
      <subtitle>a simons collaboration project</subtitle>
      <title>TOC for Fairness</title>
      <updated>2022-04-09T22:47:57Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://mycqstate.wordpress.com/?p=1271</id>
    <link href="https://mycqstate.wordpress.com/2020/11/22/what-it-is-that-we-do/" rel="alternate" type="text/html"/>
    <title>What it is that we do</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">This post is a follow-up on some somewhat off-hand comments that I made earlier regarding the notion of truth in a “proof-based” discipline such as pure mathematics or theoretical computer science. Since the former is easier to circumscribe and also … <a href="https://mycqstate.wordpress.com/2020/11/22/what-it-is-that-we-do/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>This post is a follow-up on some somewhat off-hand comments that I made <a href="https://mycqstate.wordpress.com/2020/09/29/it-happens-to-everyonebut-its-not-fun/">earlier</a> regarding the notion of truth in a “proof-based” discipline such as pure mathematics or theoretical computer science. Since the former is easier to circumscribe and also has a larger literature available on it, for the purposes of the post I will discuss my emerging take on truth in mathematics; what I say applies to TCS as well. (I wasn’t able to find satisfactory writings on the practice of computer science, even more broadly interpreted than just “theory”; any pointers on this are very welcome.) I obviously don’t claim any originality here; I suspect that to some the points I make might be interesting while to others they could feel passé–in the latter case, please help me make progress in the comments!</p>



<div class="wp-block-image"><figure class="alignright size-large is-resized"><a href="https://mycqstate.files.wordpress.com/2020/11/circle.jpg"><img alt="" class="wp-image-1273" height="272" src="https://mycqstate.files.wordpress.com/2020/11/circle.jpg?w=762" width="261"/></a>A <em>circle</em> is a plane figure contained by one line such that all the straight lines falling upon it from one point among those lying within the figure equal one another. (Euclid, Elements, Book I, Definition 15.)</figure></div>



<p>The question is more interesting than it may seem. First, let’s set aside the Platonician answer that mathematics is about proving statements that apply to abstract objects. None of this makes sense: there is no such thing as an abstract object (What is an “abstract circle?” Euclid’s <em>definition</em> of an abstract circle exists, but that definition has nothing abstract; it is plain English—or well, Greek, which is no better). Neither is there anything fundamentally “true” about the statements that mathematicians make about these objects. This last point is made clear in Voevodsky’s retelling of the story that brought him to start his research program on univalent foundations: see in particular the paragraph starting with “The primary challenge that needed to be addressed” <a href="https://www.ias.edu/ideas/2014/voevodsky-origins">here</a>. While a subset of mathematicians has been carefully examining the logical foundations of mathematics and pursuing a program of formalizing these foundations with the goal of automating verification, two facts are historically evident: (1) this formalization has always come <em>after</em> the fact, i.e. first the theorem is proven, and second only is there some attempt at modifying the format of the “proof” so as to reach some abstract “higher standard”; (2) what the higher standard exactly is is a moving target. In other words, mathematicians do whatever it is that they do <em>first</em>, and only <em>after</em> that does some subset of them look back on what has been done and make an attempt to reformulate it in a way that seems more “rigorous” by the standards of the day. And even once this process has been completed (or rather, iterated over a few times), no absolute truth has been obtained; merely, one has gained higher confidence that some set of formal rules can be applied in a certain order to derive one statement for another. In summary, the logical answer “I define as true any statement that can be derived by said rules starting from said axioms” will not satisfy us. (My point is not to criticize this enterprise; only to point that this is not what mathematics is about. I don’t expect any mathematician would disagree.)</p>



<p>Once this point has been cleared we have opened up the possibility for a much richer interpretation of what mathematics is about, what it is that mathematicians do, and what is so special about the role played by the notion of truth in this enterprise.</p>



<h2>The Greeks</h2>



<p>Mathematicians have been around since Greek antiquity. I highly recommend the wonderful book <a href="https://doi.org/10.1017/CBO9780511543296">The Shaping of Deduction in Greek Mathematics</a> by Reviel Netz, a historian at Stanford. The book provides a fantastic historical introduction to the birth of modern mathematics, as practiced in the Western world. In this book Netz gives a detailed account of the practice of Greek mathematics that is based on a sometimes almost comical literal reading of the original texts. Netz is not a mathematician, and he takes the Greek writings at face value, without preconceptions as to any deeper meaning, mathematical or otherwise. To see how fantastic an enterprise this might be I highly recommend taking the time to read through a few paragraphs of Euclid’s elements, see e.g. <a href="https://www.claymath.org/library/historical/euclid/index.html">here</a>. (I wasn’t able to find an online version that has clear figures; Netz’ book contains many reproductions and he spends a great deal of time examining their significance as a companion to the text.) Wait, and they called this a <em>proof</em>? </p>



<div class="wp-block-image"><figure class="alignleft size-large is-resized"><a href="https://mycqstate.files.wordpress.com/2020/11/phil-2017-0007_05.jpg"><img alt="" class="wp-image-1276" height="241" src="https://mycqstate.files.wordpress.com/2020/11/phil-2017-0007_05.jpg?w=1024" width="320"/></a>Netz places a particular emphasis on the role of lettered diagrams such as this one in Greek mathematicians’ proofs. This one is taken from Apollonius, as reproduced in <a href="https://doi.org/10.1515/phil-2017-0007">this book</a>.</figure></div>



<p>What I find most amazing about Netz’ work is that his book makes it absolutely clear that what Greek mathematics did is invent a very special world, with its own set of rules and specifications as to how things should be presented, what counts as valid and what does not, etc; most importantly this set of rules and specifications is absolutely <em>arbitrary</em>. There is nothing <em>universally</em> true about any of the statements made in Euclid’s book ; what there is however, and which is just as important, is a form of <em>self-consistent</em>, <em>self-perpetuating</em> consistency. This is the Greek mathematician’s most important discovery, and most enduring legacy: a system of thought, based on the use of formal rules, such that users of that system of thought can easily and unequivocally agree on the same statements. Netz contrasts this with the political discourse that the Greeks were so famously fond of; while in rhetoric endless arguments can be made in favor or against any given statement, in mathematics once an argument has been made there is no discussing it; either the argument is correct and accepted by all or it is flawed and all will agree on the presence of a flaw. By saying that mathematics does not establish universal truths we do not take away any of the strength of its evident success as a system of thought. </p>



<p>I insist that in the previous sentence by “mathematics” I mean “Greek mathematics.” There is nothing universal about the formal “proof system” used by the Greeks, and in fact that system is arguably quite different from the one used today (contrast a proof in Euclid’s Elements from one in e.g. Kerodon (see figure below); clearly either school would reject the other’s papers!). There is nothing absolutely perfect or even fool-proof about it either; when I write that “either the argument is correct or it is flawed” I do not dismiss the existence of a substantial grey zone in which there might be, and generally is, discussion. (Netz in his presentation makes it plainly obvious that Greek proofs had many “gaps” and that completely arbitrary choices are made as to what is valid and what is not.) The point is that this grey zone is by orders of magnitude smaller than in other disciplines, and this is what makes mathematics special.</p>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><a href="https://mycqstate.files.wordpress.com/2020/11/diagram.jpg"><img alt="" class="wp-image-1278" height="118" src="https://mycqstate.files.wordpress.com/2020/11/diagram.jpg?w=943" width="470"/></a>A lettered diagram taken from the proof of Lemma 3.5.3.11 in <a href="https://kerodon.net/">Kerodon</a>.</figure></div>



<p>Greek mathematics has its limitations. In particular, it seems like they were not able to expand their explorations much beyond geometry; possibly because they did not have a formal way of re-using proofs. Indeed, only propositions from Euclid’s elements were part of the general corpus of “truths” that could be used without justification; any other proof could only appeal to either a statement from the Elements or a statement proved within the same text (as opposed to a statement made by another mathematician). The current system has a much higher level of re-usability, allowing it to much deeper. It is possible that current attempt at formalization will provide yet another layer to this by enabling re-using statements without the mathematician herself even being cognizant of the statement that is being re-used (e.g. the proof assistant would figure out that there is some theorem somewhere that could be useful). </p>



<h2>The moderns</h2>



<div class="wp-block-image"><figure class="alignright size-large is-resized"><a href="https://mycqstate.files.wordpress.com/2020/11/qkd.jpg"><img alt="" class="wp-image-1280" height="420" src="https://mycqstate.files.wordpress.com/2020/11/qkd.jpg?w=831" width="382"/></a>A lettered diagram taken from the proof of security of quantum key distribution in Renner’s <a href="https://arxiv.org/abs/quant-ph/0512258">Ph.D. thesis</a>.</figure></div>



<p>Once one has taken this somewhat distanced look at the practice of Greek mathematicians it becomes clear that there is no reason for contemporary practice to escape similar distanciation. As arbitrary as the rules that govern the former might seem now, just as arbitrary our own rules will seem later. The observation prompts us to re-evaluate the notion of proof and truth as follows: <em>The goal of the mathematical proof is to convince the mathematician; a statement is true whenever the mathematician is convinced.</em> I emphasize that the mathematician in this sentence is a human being, not a machine. <br/><br/>Propositions in Euclid’s elements are true because Euclid’s text convinced all other Greek mathematicians that they were true; the same hold of Voevodsky’s univalent foundations. To speak about my personal experience, the point was carried home vividly about a decade ago at the end of an entire afternoon spent sitting by the sea nearby Marseille in the South of France together with an illustrious French operator algebraist. For the whole afternoon I had been trying to explain, of all things, the Clause-Horne-Shimony-Holt inequality formulated as a nonlocal game—an elementary construction on which half of my research is based (see <a href="https://mycqstate.wordpress.com/2012/10/10/tsirelsons-bound/">this post</a> for example, although we  certainly didn’t get that far). To no avail! Alice, Bob, games, the mathematician would have none of it. How could it be so hard? The message I was trying to carry across is bread and butter to quantum information theorists; moreover the language of functional analysis was not foreign to me either and so I believed I ought to have more than it should take to make the explanations clear; in my mind I had a clear theorem, together with an airtight proof, to communicate. Not so: I ended the afternoon defeated, and the point hammered in: as much as we may think that our language is formal, our reasoning rational, our goals clear, as soon as we step out of our self-referential cocoon we have to face the evidence: not so; there is nothing clear, formal, self-evident, in the mathematical truths we take as such. (If you’re not convinced yet, look at the pictures.)</p>



<p>After having read through the viewpoint of a historian on Greek mathematics, it is interesting to come back to the present and read up on the modern mathematician’s own account of their practice. Having delighted in Hardy’s <a href="https://en.wikipedia.org/wiki/A_Mathematician%27s_Apology">A Mathematician’s Apology</a> in my student years I was naturally attracted to Harris’ explicitly referential book <a href="https://press.princeton.edu/books/hardcover/9780691154237/mathematics-without-apologies">Mathematics Without Apologies</a>. The book aims to provide a personal answer to precisely the same question as Netz’ (“What do pure mathematicians do, and why do they do it?”—first line on back cover), with the essential difference that Harris’ book is written by a contemporary mathematician about the practice of modern mathematics. The perspective taken is thus very different: Harris does not waste a drop of ink to examine the material products of modern mathematics (e.g. printed articles), which naturally from his point of view do not have the least interest besides their mathematical significance; nor does he question the formal system that enables mathematics (he does discuss foundation issues, but these are themselves part of the formal system). </p>



<p>Harris delights in telling us stories about the practice of mathematics from the inside: the way one acquires prestige (he calls it “charisma”), how mathematicians perceive when a mathematical statement is interesting, what drives a mathematician to work on one problem or another, the influence of large research programs such as the Langlands program, etc. Just as Netz, Harris agrees that the proof itself, while an important product of the mathematician’s practice, is not a goal in itself. The goal is to introduce new objects, find relations between them, and build structures that support this exploration (Harris quotes extensively from Grothendieck, a builder of structures if there is any). Crucially the mathematician’s goal is not at all to find <em>truth</em>: her goal is to find <em>beauty</em>. Harris (un-apologetically!) defends the mathematician’s position as playing a privileged and essential role in our (Western) society: mathematics is the rare, if not unique, discipline where thought is valued <em>for itself</em>: not for its consequences or potential applications, nor even for some kind of universal validity or truth that it might reach — for itself, the sheer beauty of it. No apologies. While one might think that the arts are in a similar position, Harris points out that in contemporary discussions about art the notion of beauty has all but disappeared; instead, one talks of society, ecology, politics—all of this is good and important, but it is not about beauty. Mathematics is about exploring the beauty of human thought. This exploration is carried out within the very special, narrow and arbitrary corner that mathematical practice has delineated for itself since the Greeks got us started. And yet does not matter that it is narrow and arbitrary; what matters is that it is purely and uniquely human.</p>



<p>I don’t have a conclusion to give to this post. I suppose it is the kind of digression that one is naturally inclined to make while on <a href="https://mycqstate.wordpress.com/2020/09/20/announcing-a-short-course-in-paris/">sabbatical</a>. (I was delighted to see Harris reference his time at the Institut Henri Poincaré in Paris extensively and spend multiple pages gossiping about Ed Frenkel, then a holder of the same FSMP chair I am now occupying.) Certainly it helps to gain a sense of what it is that one is doing. While these explorations destroyed a number of simple comforting myths about what it is that I do every day, in the end I find the void that lies beneath the surface much more appealing; I feel privileged and comforted in my desire to make use of that privilege.</p>



<h2>Post-scriptum</h2>



<p>In addition to the two books referenced in the post there are a couple articles that I found helpful. I am listing them here because I found such writings non-trivial to come by, and so they might be helpful to anyone interested in the topic. I welcome additional references. </p>



<ul><li>Barton, <a href="https://link.springer.com/article/10.1007/s11858-999-0009-7">Ethnomathematics and Philosophy</a>. This is Barton’s Ph.D. thesis, in which he studies the social emergence of mathematics not as inevitable, but as cultural, yet without negating what is so special about it. .</li><li>Wallet and Neuwirth, <a href="https://hal.archives-ouvertes.fr/hal-01943079/">Enquete sur les modes d’existence des etres mathematiques</a> (unfortunately in French only it seems). The authors build on Netz’ work and others to examine the notion of mathematical proof within Latour’s framework of “modes of existence,” which Latour mostly applied to experimental sciences. </li></ul></div>
    </content>
    <updated>2020-11-22T16:14:00Z</updated>
    <published>2020-11-22T16:14:00Z</published>
    <category term="meta"/>
    <category term="Science"/>
    <category term="Uncategorized"/>
    <category term="meta-mathematics"/>
    <author>
      <name>Thomas</name>
    </author>
    <source>
      <id>https://mycqstate.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://mycqstate.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://mycqstate.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://mycqstate.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://mycqstate.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>In superposition</subtitle>
      <title>MyCQstate</title>
      <updated>2022-04-09T22:48:36Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://mycqstate.wordpress.com/?p=1262</id>
    <link href="https://mycqstate.wordpress.com/2020/11/11/lecture-notes-on-the-mahadev-verification-protocol/" rel="alternate" type="text/html"/>
    <title>Lecture notes on the Mahadev verification protocol</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">As announced earlier I am currently teaching a course on “interactive proofs with quantum devices” in Paris. The course is proceeding apace, even though the recent lockdown order in France means that we had to abandon our beautiful auditorium at … <a href="https://mycqstate.wordpress.com/2020/11/11/lecture-notes-on-the-mahadev-verification-protocol/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div class="wp-block-image"><figure class="alignright size-large is-resized"><a href="https://mycqstate.files.wordpress.com/2020/11/index-1.jpg"><img alt="" class="wp-image-1266" height="206" src="https://mycqstate.files.wordpress.com/2020/11/index-1.jpg?w=1024" width="367"/></a>My street in lockdown </figure></div>



<p>As announced <a href="https://mycqstate.wordpress.com/2020/09/20/announcing-a-short-course-in-paris/">earlier</a> I am currently teaching a course on “interactive proofs with quantum devices” in Paris. The course is proceeding apace, even though the recent lockdown order in France means that we had to abandon our beautiful auditorium at the Institut Henri Poincaré and retreat behind the fanciful Zoom backgrounds whose pretension is a sad reminder of what our summers used to be (Banff, anyone?). A possible upshot is that more may be able to attend the now-online course; if you are interested see the <a href="http://users.cms.caltech.edu/~vidick/teaching/fsmp/">course page</a> for info. (Things are actually fairly good here–in spite of the apparently strict restrictions on daily outings (max 1h, 1km) you can count on the French to bend things their way; most shops are closed but the streets remain quite busy.)</p>



<p>We just finished a sequence of four lectures on the Mahadev “classical verification of quantum computation” protocol. In the process of preparing the lectures I arrived at a presentation of the protocol that is fairly self-contained, so I decided to compile the associated lecture notes as a stand-alone group of 4 lectures that is available <a href="http://users.cms.caltech.edu/~vidick/teaching/fsmp/fsmp_verification.pdf">here</a>. The notes are aimed at beginning graduate students with a first course in quantum computing and in complexity desiring to gain a concrete understanding of the inner workings of the result; the notes are a bit lengthy but this in part because they take the time to introduce related concepts and slowly build up to the main result. Overall, my hope is that these should be relatively easily readable and provide a good technical introduction to the Mahadev result on classical verification, including an almost complete analysis of her protocol (there are a few explicitly declared shortcuts that help simplify the presentation without hiding any important aspects). For additional background you can also consult the full <a href="http://users.cms.caltech.edu/~vidick/teaching/fsmp/fsmp.pdf">10-week notes</a>. Comments on the notes are welcome; I’m afraid they most likely contain numerous typos so if you find any please feel free to correct them directly on the associated <a href="https://www.overleaf.com/9892211158zrwmqnxtvcxm">overleaf document</a>.</p>



<p>The last three lectures of the course will be devoted to the problem of testing under spatial assumptions, building up to an introduction to the proof of MIP* = RE. If all goes well I’ll aim to prepare some stand-alone notes for that part as well.</p></div>
    </content>
    <updated>2020-11-11T15:43:12Z</updated>
    <published>2020-11-11T15:43:12Z</published>
    <category term="Quantum"/>
    <category term="Science"/>
    <category term="teaching"/>
    <category term="Uncategorized"/>
    <category term="lecture notes"/>
    <category term="quantum verification"/>
    <author>
      <name>Thomas</name>
    </author>
    <source>
      <id>https://mycqstate.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://mycqstate.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://mycqstate.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://mycqstate.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://mycqstate.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>In superposition</subtitle>
      <title>MyCQstate</title>
      <updated>2022-04-09T22:48:48Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://mycqstate.wordpress.com/?p=1252</id>
    <link href="https://mycqstate.wordpress.com/2020/09/29/it-happens-to-everyonebut-its-not-fun/" rel="alternate" type="text/html"/>
    <title>It happens to everyone…but it’s not fun</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">A recent post on this blog concerned the posting of our paper MIP*=RE on the arXiv and gave a personal history of the the sequence of works that led to the result. Quite unfortunately (dramatically?) a few weeks after initial … <a href="https://mycqstate.wordpress.com/2020/09/29/it-happens-to-everyonebut-its-not-fun/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><h1/>



<p>A <a href="https://mycqstate.wordpress.com/2020/01/14/a-masters-project/">recent post</a> on this blog concerned the posting of our paper <a href="https://arxiv.org/abs/2001.04383">MIP*=RE</a> on the arXiv and gave a personal history of the the sequence of works that led to the result. Quite unfortunately (dramatically?) a few weeks after initial posting of the paper (and the blog post) John Wright discovered an important error in the proof of a key result in this sequence: my paper <a href="https://doi.org/10.1137/140956622">Three-player entangled XOR games are NP-hard to approximate</a>, published in 2016 in a special issue of the SIAM journal on computing dedicated to selected papers from the FOCS’13 conference. While I did not mention this paper directly in the previous blog post, its main result, a proof of soundness of the Raz-Safra low-degree test against entangled-player strategies, is a key ingredient in the proof of the <a href="https://arxiv.org/abs/1801.03821">quantum low-degree test</a>, itself a key ingredient in the MIP*=RE paper. (Strictly speaking the latter paper relies on an extension of my result to two-player games obtained in a <a href="https://arxiv.org/abs/1710.03062">follow-up</a> with Natarajan. Since that paper re-used the flawed part of my earlier analysis in a black-box manner it is similarly impacted.) So then…?</p>



<h2 id="scientific-aspects">Scientific aspects</h2>



<p>I’ll start with the science. The result MIP*=RE, to the best of our knowledge, remains correct. In order to remove the dependence of the proof on the flawed paper we extended the soundness analysis of Babai, Fortnow and Lund (BFL)’s multilinearity test against entangled provers from my <a href="https://arxiv.org/abs/1207.0550">paper with Ito</a> to the case of multivariate polynomials of low individual degree. (This extension, for the case of classical provers, is already mentioned in the BFL paper.) We just posted a self-contained analysis of that test on the arXiv <a href="https://arxiv.org/abs/2009.12982">here</a> and updated the MIP*=RE paper to account for the replacement (see v2.). The latter paper is currently under review; on this I will simply say that, as for all mathematical works, it is advised to wait until the outcome of the refereeing process is complete before declaring confidence in the validity of the result. For a more in-depth description of the changes made I refer to the introduction of the <a href="https://arxiv.org/abs/2009.12982">new paper</a>.</p>



<p>Our analysis of the “low individual-degree test” mentioned in the preceding paragraph can be used to recover the main result of my SICOMP’16 paper in a weakened form. Since the proof is different and does not directly fix the error I have decided to withdraw the paper from SICOMP. For more details on the error itself and consequences to other works, such as the quantum low-degree test and the quantum games PCP, I refer to the <a href="http://users.cms.caltech.edu/~vidick/errata.pdf">short note</a> I wrote to accompany the withdrawal of the paper. The one-sentence summary is that essentially all subsequent results expressed in terms of “high” complexity classes such as QMA-EXP, NEEXP, etc., still hold, while “scaled-down” results on the hardness of entangled games can only be recovered by allowing a substantial weakening of parameters. In particular, the <a href="https://arxiv.org/abs/1801.03821">quantum low-degree test</a> holds in its scaled-up version (testing exp(n) EPR pairs using poly(n) resources), but the scaled-down version requires polylog(n) communication to test n EPR pairs, instead of O(log n) as claimed.</p>



<h2 id="personal-aspects">Personal aspects</h2>



<p>In addition to notifying researchers in the area of the bug, my goal in writing this blog post is to help me exorcise the demon of having a large mistake in one of my papers. In doing so I was inspired by Scott Aaronson’s <a href="https://www.scottaaronson.com/blog/?p=2854">blog post</a> on a similar topic. (I’ll admit that even just linking explicitly to his post helps reassure myself, a power which I believe was one of Scott’s aims in writing the post. So, thanks Scott, and allow me to pass it on!) The faulty paper is not based on a minor back-of-the-envelope observation; in fact it is one that I was quite proud of. The mistake in it is not small either; it’s a mistake that I cannot find any excuse for having made. Yet here I am: after having spent the past 6 months trying to find an alternative proof, I now strongly believe that the problem cannot be solved using the kind of techniques that I had imagined could do so. Whether the theorem statement is true or not, I don’t know; but at the moment I am unable to prove it. I have to accept that there is a bug.</p>



<p>As painful as it is I realize that I am writing this post from a relatively comfortable position. Who knows if I would have been able to do the same had we not been able to recover a full proof of MIP*=RE. Moreover, after having banged my head against the problem for 6 months straight (COVID helping, walls were never far) I am now able to see my failure in a more positive light: the story I told in the previous blog post is not yet closed; there is an open challenge for me to solve. It is a very personal challenge; having spent the past 6 months delineating it I have accumulated sufficient grounds on which to believe that it is an interesting one. I feel grateful for this.</p>



<p>Getting there wasn’t easy. So, even though I am writing from a place of comfort, I want to share the pain that the whole adventure has caused me. This simple acknowledgment is especially directed at younger readers: so that when it happens to you, you will remember this post and know that you’re not the only one. That it happens to others as well and that it is possible to face, accept, and move away from such errors. Of course you will try to fix it first. Here are some quick tips. While banging your head on the problem, make sure that your understanding increases every day. To start with, do you really understand why there is a mistake? Of course some step doesn’t go through, but what is the simplest form of the incriminated statement that fails? Can you write it down? Can you formulate and prove a weaker form of it? Probe the issue with examples. Try to isolate it as much as you can: take it outside of the paper and formulate an entirely self-contained version of it, stripped of all the baggage. Place it in as many different contexts that you can think of: do you still believe it, does it stand on its own? Again, make sure that you learn. Even if you’re not able to fix the claim, are you exploring a new technique, discovering a new perspective? If it didn’t work yesterday it probably won’t work today either: make sure that you always find something new to inject. When you can no longer do this, it is time to stop. So make sure to set yourself some near-term (how much to think about this on any given day) and long-term (when to admit defeat) limits. Always remember that problems are much more often solved in the shower or while walking the dog than at the desk. Finally, be ready to move on. Realize that as bad as it may seem to you, there are more important things in life. You can’t reduce yourself to this one problem: you’ll be stronger for accepting what happened than trying to bury it at all costs. If you don’t see this by yourself, try to talk about it. Explain the situation you’re in to your close non-academia friends, to your parents; practice on your pet first if it helps. You will realize, as I eventually did (although it took quite a while) that <em>it is ok</em>.</p>



<h2 id="social-aspects">Social aspects</h2>



<p>After the scientific and the personal aspects, let me end with the sociological. This is a semi-tangent but it is a good opportunity to discuss a topic that we scientists, possibly even more so us working in the “hard sciences” (as the French call “proof-based” disciplines), are insufficiently sensitized to. This is the topic of how science is made, and what is the reality of this “absolute truth” that we claim to discover and establish in our mathematical results.</p>



<p>My paper was posted on arXiv in 2013, it was accepted to the FOCS conference and published in its proceedings the same year, and it appeared in the journal SICOMP in 2016. Both publications were refereed. Since its posting the paper has been cited 47 times (google scholar) and its main result is used in an essential way in at least half a dozen papers (my best guess). 7 years later a big hole has been found in the proof. How did the “truth value of my result evolve in the process? Was it always wrong or was there a time where it had truth, in whatever appropriate sense of the word?</p>



<p>I realize that these questions can be given trivial answers—I know what is an axiom and what is a proof system. Yet I am trying to push myself, and my reader, to look a little deeper. An analogy might help. The situation brought to mind a book by French philosopher of science Bruno Latour, called (in its English translation) <a href="https://www.amazon.com/Laboratory-Life-Construction-Scientific-Facts/dp/069102832X">Laboratory Life: The Construction of Scientific Facts</a>. This is a wonderful book, which goes well beyond the classic misconceptions from Popper or even Kuhn; it should be mandatory reading for every scientist. In one of the early chapters of the book Latour makes a detailed study of how subsequent citations can collectively enshrine an initial claim based entirely on the citer’s conscious or unconscious biases in making use of the citation (i.e. in complete independence from any ground “truth” or “importance” of the cited work). An entertaining example of this can be found in <a href="https://journals.sagepub.com/doi/full/10.1177/0306312714535679">this article</a>, which dissects the claim that “The myth from the 1930s that spinach is a rich source of iron was due to misleading information in the original publication: a malpositioned decimal point gave a 10-fold overestimate of iron content.” The example, pursued in great depth in the article, shows very well how one citation at a time the (spoiler: unjustified) claim is given more and more credibility until it eventually becomes a fact: from initial citations written in a tentative tone “according to Z, it could be that…” to more assertive citations “Z has shown that” by more and more well-known researchers in highly-read journals to pure fact (citation above). I highly recommend the article!</p>



<p>It is easy to dismiss this story as being the result of “sloppy” authors misrepresenting a “soft” claim whose truth value is not well-determined in the first place, being a statement about the world rather than about some hypothetical mathematical universe. Yet I believe that it is worth taking the time to examine with an open mind what exactly, if anything, distinguishes a claim about the iron content of spinach from the main “theorem” of my paper. From its initial posting on the arXiv to its presentation in a conference and its journal publication to the multiple citations it received through its use in subsequent works, and including multiple other considerations such as my own credibility (itself the result of so many other considerations) and the results base “believability”, when was the logical statement itself evaluated? Does it matter? Did the unchallenged existence of the result for 7 years impact the course of science? Or was it a mistake that was bound to be discovered and has no lasting consequences?</p>



<p>These are questions for the reader, that can be (and are probably better) asked in other contexts than the limited one of my result. Indeed there is a much broader point to all this, that I only meant to raise in an indirect manner. It is impossible to disregard the fact that our scientific work is grounded in cultural and societal effects, but we may disagree on the impact that this grounding has. We owe it to ourselves and to our readers (broadly interpreted—from colleagues to funding agencies to the broader public) to refuse to hide behind the thin veil of “hard science”, mathematics or logic, and educate ourselves to what it is that we really are doing.</p></div>
    </content>
    <updated>2020-09-29T15:50:43Z</updated>
    <published>2020-09-29T15:50:43Z</published>
    <category term="meta"/>
    <category term="Quantum"/>
    <category term="Science"/>
    <category term="Uncategorized"/>
    <author>
      <name>Thomas</name>
    </author>
    <source>
      <id>https://mycqstate.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://mycqstate.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://mycqstate.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://mycqstate.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://mycqstate.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>In superposition</subtitle>
      <title>MyCQstate</title>
      <updated>2022-04-09T22:48:21Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://mycqstate.wordpress.com/?p=1244</id>
    <link href="https://mycqstate.wordpress.com/2020/09/20/announcing-a-short-course-in-paris/" rel="alternate" type="text/html"/>
    <title>Announcing a short course in Paris</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">This coming academic year I am on sabbatical, in Paris. It’s certainly a funny year to be on sabbatical. (It’s a funny year to be doing anything, isn’t it? Or is “funny” not the appropriate word…Yet I can’t find any … <a href="https://mycqstate.wordpress.com/2020/09/20/announcing-a-short-course-in-paris/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>This coming academic year I am on sabbatical, in Paris. It’s certainly a funny year to be on sabbatical. (It’s a funny year to be doing anything, isn’t it? Or is “funny” not the appropriate word…Yet I can’t find any other way to look at it that doesn’t send me straight into the abyss. So, let it be “funny”—knowing that, no, I’m not actually laughing right now.) On the one hand, I am lucky to have escaped the incessant debates on the format of teaching, how many people per square foot are allowed in each building on campus, what distance I should stay from my students were I to attempt to meet them in person, and so many other similar decisions that have come to take up a larger and larger fraction of our professional lives (not to mention of course the incommensurate challenges that many are facing at the personal and familial level). On the other hand, the situation makes it much harder to meet others and engage in new collaborations, one of the goals of my sabbatical. I’ll see how it plays out; I’ll be sure to write more on this blog as time progresses.</p>



<p>During the sabbatical I am being hosted successively by different French institutions. For the first 6 months I had the good fortune of being awarded a “chair” from the “<a href="https://www.sciencesmaths-paris.fr/en/">Fondation Sciences Mathématiques de Paris</a>” (FSMP), a private foundation which supports, in very general terms, the development of the mathematics community in Paris, from the organization of general-public conferences to the support of research collaborations. My only formal obligation during these 6 months is to give 20 hours of lecture on a theme of my choosing. The goal that I elected for the course is provide an in-depth introduction to two major works in quantum complexity and cryptography of the past few years: first, Mahavev’s 2018 result on <a href="https://arxiv.org/abs/1804.01082">classical verification of quantum computation</a> (a result for which I already shared my enthusiasm <a href="https://mycqstate.wordpress.com/2018/08/06/the-cryptographic-leash/">here</a>); second, my result <a href="https://arxiv.org/abs/2001.04383">MIP*=RE</a> with Ji, Natarajan, Wright and Yuen on the power of quantum multi-prover interactive proof systems, which I mentioned in the <a href="https://mycqstate.wordpress.com/2020/01/14/a-masters-project/">previous post</a>, and its consequences. For more about the course, including a tentative breakdown of lectures and some resources, see the <a href="http://users.cms.caltech.edu/~vidick/teaching/fsmp/">course webpage</a>. </p>



<p>While at the time of writing the course is still scheduled to start as an in-person meeting (to take place in a very large layered amphitheater with ample space for social distancing), there is no telling how the situation, and regulations, will evolve in the near future. To accommodate participants who are unable or prefer not to travel in person, all lectures starting with the first one will be recorded. In addition I will post course materials, including lecture notes, <a href="http://users.cms.caltech.edu/~vidick/teaching/fsmp/">here</a>. The purpose of this post is to advertise the course: participants from everywhere are welcome to watch the recorded videos, read the notes, and write to me with any questions in suggestions. In particular I plan to outsource the proof-reading of the notes via overleaf and I welcome any participant’s interest in helping with that; draft notes for the first lecture are already available <a href="https://www.overleaf.com/2293291658twkjfbtctsdb">here</a>. Anyone is welcome to make direct corrections, or add inline comments pointing to issues that may need my attention.</p>



<p>The program that I chose is ambitious, and we will see how far we get along. My goal is to start slow, so as to remain inclusive with respect to varying backgrounds in computer science, mathematics or physics. At first I will give complete definitions, state and prove simple lemmas, etc., in order to establish common language. As time progresses I expect that things will become a little more high-level, less self-contained, and more technical. Depending on your background and interests, you may find the first few lectures, or the last few ones, more interesting. Teaching the course will certainly be beneficial for me because I believe that there is a strong unity behind the two works I chose to present. I hope to make that unity apparent by presenting them together. Moreover, both works introduce new techniques that leave many avenues open; I hope that a “clean” presentation will help me, and others, build on them. </p>



<p>A side benefit of an “un-necessary” course such as this one is that it contributes to bringing a certain community together. (By “un-necessary” I mean that the course will not be required for any curriculum; if it did not take place, as long as it was replaced by other research-level activities its absence would not be felt.) COIVD-19 unfortunately turns that opportunity into a challenge. It is because of it that I insist–regulations allowing– on having the course take place in person: as much as we are getting used to Zoom, and as well as it may be working as a replacement for many aspects of our interactive lives, from in-person classes to conferences to research collaborations, a scientific event such as this one, with sustained involvement by a small set of participants coming from distant backgrounds, is probably one of the more challenging ones to make work online. I hope it doesn’t come to that. Even if it does, one of the lessons learned from the Spring 2020 semester on quantum computing at the Simons Institute in Berkeley, which was interrupted half-ways due to the pandemic, is that having an initial in-person phase was of great help to cement future online interactions. So, I hope that I am able to lecture on Tuesday; after that, we will see.</p></div>
    </content>
    <updated>2020-09-20T15:19:18Z</updated>
    <published>2020-09-20T15:19:18Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Thomas</name>
    </author>
    <source>
      <id>https://mycqstate.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://mycqstate.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://mycqstate.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://mycqstate.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://mycqstate.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>In superposition</subtitle>
      <title>MyCQstate</title>
      <updated>2022-04-09T22:47:55Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://thmatters.wordpress.com/?p=1312</id>
    <link href="https://thmatters.wordpress.com/2020/06/05/tcs-visioning-workshop-call-for-participation/" rel="alternate" type="text/html"/>
    <title>TCS Visioning Workshop — Call for Participation</title>
    <summary>The CATCS will be hosting a virtual “Visioning Workshop” the week of July 20 in order to identify broad research themes within theoretical computer science (TCS) that have potential for a major impact in the future. The goals are similar to the workshop of the same name in 2008: to package these themes in a […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div>
<p><span class="im">The <a href="https://thmatters.wordpress.com/catcs/">CATCS</a> will be hosting a virtual <strong>“Visioning Workshop”</strong> the <strong>week of </strong></span><strong>July 20</strong> in order to identify broad research themes within theoretical computer science (TCS) that have potential for a major impact in the future. The goals are similar to the <a href="https://thmatters.wordpress.com/visioning-workshop/">workshop of the same name</a> in 2008: to package these themes in a way that can be consumed <span class="im">by the general public, which we would deliver primarily to the Computing Community Consortium and others (e.g. funding agencies) to help them advocate for TCS.</span></p>
<p>While participation in the workshop is primarily through invitation, we have a few slots available for the broader community. If you are interested in participating, please see details of the application process below. The workshop will be organized according to area-wise breakout groups. Each breakout group will have 1-2 leads. Breakout groups will meet for 4-5 hours spread across several days and will be tasked with brainstorming ideas and preparing materials related to their topic. Leads are further expected to participate in plenary sessions held on Monday July 20 and Friday July 24 (4-5 hrs of additional time) where these materials will be discussed.</p>
<p>If you are interested in participating in the workshop, please fill out <a href="https://forms.gle/cdCTsLfUs56CDhKS9">this Google form</a> by <strong>Monday June 15</strong>. On this form, applicants are asked to contribute one or two <span class="im">major results in the last 10 years whose significance can be explained in layperson terms, and one or two major challenges for theory whose significance can be explained in layperson terms. These descriptions </span>can be very brief. We will just use them to select participants and create breakout groups.</p>
</div>
<div/>
<div>(If the embedded link doesn’t work, paste this URL in your browser: <a href="https://forms.gle/cdCTsLfUs56CDhKS9" rel="nofollow">https://forms.gle/cdCTsLfUs56CDhKS9</a>.)</div></div>
    </content>
    <updated>2020-06-05T18:46:13Z</updated>
    <published>2020-06-05T18:46:13Z</published>
    <category term="workshops"/>
    <author>
      <name>shuchic</name>
    </author>
    <source>
      <id>https://thmatters.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://thmatters.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://thmatters.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://thmatters.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://thmatters.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theory Matters</title>
      <updated>2022-04-09T22:48:15Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://mycqstate.wordpress.com/?p=1234</id>
    <link href="https://mycqstate.wordpress.com/2020/01/14/a-masters-project/" rel="alternate" type="text/html"/>
    <title>A Masters project</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">In a previous post I reported on the beautiful recent result by Natarajan and Wright showing the astounding power of multi-prover interactive proofs with quantum provers sharing entanglement: in letters, . In this post I want to report on follow-up … <a href="https://mycqstate.wordpress.com/2020/01/14/a-masters-project/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>In a <a href="https://mycqstate.wordpress.com/2019/04/14/randomness-and-interaction-entanglement-ups-the-game/">previous post</a> I reported on the beautiful <a href="https://arxiv.org/abs/1904.05870">recent result</a> by Natarajan and Wright showing the astounding power of multi-prover interactive proofs with quantum provers sharing entanglement: in letters, <img alt="{\text{NEEXP} \subseteq \text{MIP}^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BNEEXP%7D+%5Csubseteq+%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. In this post I want to report on follow-up work with Ji, Natarajan, Wright, and Yuen, that we just posted to <a href="https://arxiv.org/abs/2001.04383">arXiv</a>. This time however I will tell the story from a personal point of view, with all the caveats that this implies: the “hard science” will be limited (but there could be a hint as to how “science”, to use a big word, “progresses”, to use an ill-defined one), the story is far too long, and it might be mostly of interest to me only. It’s a one-sided story, but that has to be. (In particular below I may at times attribute credit in the form “X had this idea”. This is my recollection only, and it is likely to be inaccurate. Certainly I am ignoring a lot of important threads.) I wrote this because I enjoyed recollecting some of the best moments in the story just as much as some the hardest; it is fun to look back and find meanings in ideas that initially appeared disconnected. Think of it as an example of how different lines of work can come together in unexpected ways; a case for open-ended research. It’s also an antidote against despair that I am preparing for myself: whenever I feel I’ve been stuck on a project for far too long, I’ll come back to this post and ask myself if it’s been 14 years yet — if not, then press on.</p>
<p>It likely comes as a surprise to me only that I am no longer fresh out of the cradle. My academic life started in earnest some 14 years ago, when in the Spring of 2006 I completed my Masters thesis in Computer Science under the supervision of Julia Kempe, at Orsay in France. I had met Julia the previous term: her class on quantum computing was, by far, the best-taught and most exciting course in the Masters program I was attending, and she had gotten me instantly hooked. Julia agreed to supervise my thesis, and suggested that I look into some interesting recent result by Stephanie Wehner that linked the study of entanglement and nonlocality in quantum mechanics to complexity-theoretic questions about interactive proof systems (specifically, this was Stephanie’s <a href="https://arxiv.org/abs/quant-ph/0508201">paper</a> showing that <img alt="{\text{XOR-MIP}^\star \subseteq \text{QIP}(2)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BXOR-MIP%7D%5E%5Cstar+%5Csubseteq+%5Ctext%7BQIP%7D%282%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>).</p>
<p>At the time the topic was very new. It had been initiated the previous year with a beautiful <a href="https://arxiv.org/abs/quant-ph/0404076">paper</a> by Cleve et al. (that I have recommended to many a student since!). It was a perfect fit for me: the mathematical aspects of complexity theory and quantum computing connected to my undergraduate background, while the relative concreteness of quantum mechanics (it is a physical theory after all) spoke to my desire for real-world connection (not “impact” or even “application” — just “connection”). Once I got myself up to speed in the area (which consisted of three papers: the two I already mentioned, together with a <a href="https://arxiv.org/abs/cs/0102013">paper</a> by Kobayashi and Matsumoto where they studied interactive proofs with quantum messages), Julia suggested looking into the the “entangled-prover” class <img alt="{\text{MIP}^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> introduced in the aforementioned paper by Cleve et al. Nothing was known about this class! Nothing besides the trivial inclusion of single-prover interactive proofs, IP, and the containment in…ALL, the trivial class that contains all languages.<br/>
Yet the characterization MIP=NEXP of its classical counterpart by Babai et al. in the 1990s had led to one of the most productive lines of work in complexity of the past few decades, through the PCP theorem and its use from hardness of approximation to efficient cryptographic schemes. Surely, studying <img alt="{\text{MIP}^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> had to be a productive direction? In spite of its well-established connection to classical complexity theory, via the formalism of interactive proofs, this was a real gamble. The study of entanglement from the complexity-theoretic perspective was entirely new, and bound to be fraught with difficulty; very few results were available and the existing lines of works, from the foundations of nonlocality to more recent endeavors in device-independent cryptography, provided little other starting point than strong evidence that even the simplest examples came with many unanswered questions. But my mentor was fearless, and far from a novice in terms of defraying new areas, having done pioneering work in areas ranging from quantum random walks to Hamiltonian complexity through adiabatic computation. Surely this would lead to something?</p>
<p>It certainly did. More sleepless nights than papers, clearly, but then the opposite would only indicate dullness. Julia’s question led to far more unexpected consequences than I, or I believe she, could have imagined at the time. I am writing this post to celebrate, in a personal way, the latest step in 15 years of research by dozens of researchers: today my co-authors and I uploaded to the quant-ph arXiv what we consider a complete characterization of the power of entangled-prover interactive proof systems by proving the equality <img alt="{\text{MIP}^\star = \text{RE}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar+%3D+%5Ctext%7BRE%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, the class of all recursively enumerable languages (a complete problem for RE is the halting problem). Without goign too much into the result itself (if you’re interested, we have a long introduction waiting for you), and since this is a personal blog, I will continue on with some personal thoughts about the path that got us there.</p>
<p>When Julia &amp; I started working on the question, our main source of inspiration were the results by Cleve et al. showing that the nonlocal correlations of entanglement had interesting consequences when seen through the lens of interactive proof systems in complexity theory. Since the EPR paper a lot of work in understanding entanglement had already been accomplished in the Physics community, most notably by Mermin, Peres, Bell, and more recently the works in device-indepent quantum cryptography by Acin, Pironio, Scarani and many others stimulated by Ekert’s proposal for quantum key distribution and Mayers and Yao’s idea for “device-independent cryptography”. By then we certainly knew that “spooky action-at-a-distance” did not entail any faster-than-light communication, and indeed was not really “action-at-a-distance” in the first place but merely “correlation-at-a-distance”. What Cleve et al. recognized is that these “spooky correlations-at-a-distance” were sufficiently special so as to not only give numerically different values in “Bell inequalities”, the tool invented by Bell to evidence nonlocality in quantum mechanics, but also have some potentially profound consequences in complexity theory. In particular, examples such as the “Magic Square game” demonstrated that enough correlation could be gained from entanglement so as to defeat basic proof systems whose soundness relied only on the absence of communication between the provers, an assumption that until then had been wrongly equated with the assumption that any computation performed by the provers could be modeled entirely locally. I think that the fallacy of this implicit assumption came as a surprise to complexity theorists, who may still not have entirely internalized it. Yet the perfect quantum strategy for the Magic Square game provides a very concrete “counter-example” to the soundness of the “clause-vs-variable” game for 3SAT. Indeed this game, a reformulation by Aravind and Cleve-Mermin of a Bell Inequality discovered by Mermin and Peres in 1990, can be easily re-framed as a 3SAT system of equations that is <em>not</em> satisfiable and yet is such that the associated two-player clause-vs-variable game has a <em>perfect</em> quantum strategy. It is this observation, made in the paper by Cleve et al., that gave the first strong hint that the use of entanglement in interactive proof systems could make many classical results in the area go awry.</p>
<p>By importing the study of non-locality into complexity theory Cleve et al. immediately brought it into the realm of asymptotic analysis. Complexity theorists don’t study fixed objects, they study families of objects that tend to have a uniform underlying structure and whose interesting properties manifest themselves “in the limit”. As a result of this new perspective focus shifted from the study of single games or correlations to infinite families thereof. Some of the early successes of this translation include the “unbounded violations” that arose from translating asymptotic separations in communication complexity to the language of Bell inequalities and correlations (e.g. this <a href="https://arxiv.org/abs/1012.5043">paper</a>). These early successes attracted the attention of some physicists working in foundations as well as some mathematical physicists, leading to a productive exploration that combined tools from quantum information, functional analysis and complexity theory.</p>
<p>The initial observations made by Cleve et al. had pointed to <img alt="{\text{MIP}^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> as a possibly interesting complexity class to study. Rather amazingly, nothing was known about it! They had shown that under strong restrictions on the verifier’s predicate (it should be an XOR of two answer bits), a collapse took place: by the work of Hastad, XOR-MIP equals NEXP, but <img alt="{\text{XOR-MIP}^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BXOR-MIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is included in EXP. This seemed very fortuitous (the inclusion is proved via a connection with semidefinite programming that seems tied to the structure of XOR-MIP protocols): could entanglement induce a collapse of the entire, unrestricted class? We thought (at this point mostly Julia thought, because I had no clue) that this ought not to be the case, and so we set ourselves to show that the equality <img alt="{\text{MIP}^\star=\text{NEXP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%3D%5Ctext%7BNEXP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, that would directly parallel Babai et al.’s characterization MIP=NEXP, holds. We tried to show this by introducing techniques to “immunize” games against entanglement: modify an interactive proof system so that its structure makes it “resistant” to the kind of “nonlocal powers” that can be used to defeat the clause-vs-variable game (witness the Magic Square). This was partially successful, and led to one of the papers I am most proud of — I am proud of it because I think it introduced elementary techniques (such as the use of the Cauchy-Schwarz inequality — inside joke — more seriously, basic things such as “prover-switching”, “commutation tests”, etc.) that are now routine manipulations in the area. The paper was a hard sell! It’s good to remember the first rejections we received. They were not unjustified: the main point of criticism was that we were only able to establish a hardness result for exponentially small completeness-soundness gap. A result for such a small gap in the classical setting follows directly from a very elementary analysis based on the Cook-Levin theorem. So then why did we have to write so many pages (and so many applications of Cauchy-Schwarz!) to arrive at basically the same result (with a <img alt="{^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>)?</p>
<p>Eventually we got lucky and the paper was accepted to a conference. But the real problem, of establishing any non-trivial lower bound on the class <img alt="{\text{MIP}^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> with constant (or, in the absence of any parallel repetition theorem, inverse-polynomial) completeness-soundness gap, remained. By that time I had transitioned from a Masters student in France to a graduate student in Berkeley, and the problem (pre-)occupied me during some of the most difficult years of my Ph.D. I fully remember spending my first year entirely thinking about this (oh and sure, that systems class I had to pass to satisfy the Berkeley requirements), and then my second year — yet, getting nowhere. (I checked the arXiv to make sure I’m not making this up: two full years, no posts.) I am forever grateful to my fellow student Anindya De for having taken me out of the cycle of torture by knocking on my door with one of the most interesting questions I have studied, that led me into quantum cryptography and quickly resulted in an enjoyable <a href="https://arxiv.org/abs/0911.4680">paper</a>. It was good to feel productive again! (Though the paper had fun reactions as well: after putting it on the arXiv we quickly heard from experts in the area that we had solved an irrelevant problem, and that we better learn about information theory — which we did, eventually leading to another <a href="https://arxiv.org/abs/0912.5514">paper</a>, etc.) The project had distracted me and I set interactive proofs aside; clearly, I was stuck.</p>
<p>About a year later I visited IQC in Waterloo. I don’t remember in what context the visit took place. What I do remember is a meeting in the office of Tsuyoshi Ito, at the time a postdoctoral scholar at IQC. Tsuyoshi asked me to explain our result with Julia. He then asked a very pointed question: the bedrock for the classical analysis of interactive proof systems is the “linearity test” of Blum-Luby-Rubinfeld (BLR). Is there any sense in which we could devise a quantum version of that test?</p>
<p>What a question! This was great. At first it seemed fruitless: in what sense could one argue that quantum provers apply a “linear function”? Sure, quantum mechanics is linear, but that is besides the point. The linearity is a property of the prover’s answers as a function of their question. So what to make of the quantum state, the inherent randomness, etc.?</p>
<p>It took us a few months to figure it out. Once we got there however, the answer was relatively simple — the prover should be making a question-independent measurement that returns a linear function that it applies to its question in order to obtain the answer returned to the verifier — and it opened the path to our subsequent <a href="https://arxiv.org/abs/1207.0550">paper</a> showing that the inclusion of NEXP in <img alt="{\text{MIP}^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> indeed holds. Tsuyoshi’s question about linearity testing had allowed us to make the connection with PCP techniques; from there to MIP=NEXP there was only one step to make, which is to analyze multi-linearity testing. That step was suggested by my Ph.D. advisor, Umesh Vazirani, who was well aware of the many pathways towards the classical PCP theorem (indeed a lot of the activity that led to the proof of the theorem took place in Berkeley, with many of Umesh’s current or former students making substantial contributions). It took a lot of technical work, yet conceptually a single question from my co-author had sufficed to take me out of a 3-year slumber.</p>
<p>This was in 2012, and I thought we were done. For some reason the converse inclusion, of <img alt="{\text{MIP}^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> in NEXP, seemed to resist our efforts, but surely it couldn’t resist much longer. Navascues et al. had introduced a hierarchy of semidefinite programs that seemed to give the right answer (technically they could only show convergence to a relaxation, the commuting value, but that seemed like a technicality; in particular, the values coincide when restricted to finite-dimensional strategies, which is all we computer scientists cared about). There were no convergence bounds on the hierarchy, yet at the same time commutative SDP hierarchies were being used to obtain very strong results in combinatorial optimization, and it seemed like it would only be a matter of time before someone came up with an analysis of the quantum case. (I had been trying to solve a related “dimension reduction problem” with Oded Regev for years, and we were making no progress; yet it seemed <em>someone</em> ought to!)</p>
<p>In Spring 2014 during an open questions session at a <a href="https://simons.berkeley.edu/workshops/qhc2014-1">workshop</a> at the Simons Institute in Berkeley Dorit Aharonov suggested that I ask the question of the possible inclusion of QMA-EXP, the exponential-sized-proofs analogue of QMA, in <img alt="{\text{MIP}^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. A stronger result than the inclusion of NEXP (under assumptions), wouldn’t it be a more natural “fully quantum” analogue of MIP=NEXP? Dorit’s suggestion was motivated by research on the “quantum PCP theorem”, that aims to establish similar hardness results in the realm of the local Hamiltonian problem; see e.g. <a href="https://mycqstate.wordpress.com/2014/10/31/quantum-pcp-conjectures/">this post</a> for the connection. I had no idea how to approach the question — I also didn’t really believe the answer could be positive — but what can you do, if Dorit asks you something… So I reluctantly went to the board and asked the question. Joe Fitzsimons was in the audience, and he immediately picked it up! Joe had the fantastic ideas of using quantum error-correction, or more specifically secret-sharing, to distribute a quantum proof among the provers. His enthusiasm overcame my skepticism, and we eventually <a href="https://arxiv.org/abs/1409.0260">showed</a> the desired inclusion. Maybe <img alt="{\text{MIP}^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> <em>was</em> bigger than <img alt="{\text{NEXP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BNEXP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> after all.</p>
<p>Our result, however, had a similar deficiency as the one with Julia, in that the completeness-soundness gap was exponentially small. Obtaining a result with a constant gap took 3 years of couple more years of work and the fantastic energy and insights of a Ph.D. student at MIT, Anand Natarajan. Anand is the first person I know of to have had the courage to dive in to the most technical aspects of the analysis of the aforementioned results, while also bringing in the insights of a “true quantum information theorist” that were supported by Anand’s background in Physics and upbringing in the group of Aram Harrow at MIT. (In contrast I think of myself more as a “raw” mathematician; I don’t really understand quantum states other than as psd matrices…not that I understand math either of course; I suppose I’m some kind of a half-baked mish-mash.) Anand had many ideas but one of the most beautiful ones led to what he poetically called the “Pauli braiding test”, a “truly quantum” analogue of the BLR linearity test that amounts to doing <em>two</em> linearity tests in conjugate bases and piecing the results together into a robust test for <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>-qubit entanglement (I wrote about our work on this <a href="https://mycqstate.wordpress.com/2017/06/28/pauli-braiding/">here</a>).</p>
<p>At approximately the same time Zhengfeng Ji had another wonderful idea, that was in some sense orthogonal to our work. (My interpretation of) Zhengfeng’s idea is that one can see an interactive proof system as a computation (verifier-prover-verifier) and use Kitaev’s circuit-to-Hamiltonian construction to transform the entire computation into a “quantum CSP” (in the same sense that the local Hamiltonian problem is a quantum analogue of classical constraint satisfaction problems (CSP)) that could then itself be verified by a quantum multi-prover interactive proof system…with exponential gains in efficiency! Zhengfeng’s result implied an exponential improvement in complexity compared to the result by Julia and myself, showing inclusion of NEEXP, instead of NEXP, in <img alt="{\text{MIP}^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. However, Zhengfeng’s technique suffered from the same exponentially small completeness-soundness gap as we had, so that the best lower bound on <img alt="{\text{MIP}^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> per se remained NEXP.</p>
<p>Both works led to follow-ups. With Natarajan we promoted the Pauli braiding test into a “<a href="https://arxiv.org/abs/1801.03821">quantum low-degree test</a>” that allowed us to show the inclusion of QMA-EXP into <img alt="{\text{MIP}^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, with constant gap, thereby finally answering the question posed by Aharonov 4 years after it was asked. (I should also say that by then all results on <img alt="{\text{MIP}^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> started relying on a sequence of parallel repetition results shown by Bavarian, Yuen, and others; I am skipping this part.) In parallel, with Ji, Fitzsimons, and Yuen we showed that Ji’s compression technique could be “iterated” an arbitrary number of times. In fact, by going back to “first principles” and representing verifiers uniformly as Turing machines we realized that the compression technique could be used iteratively to (up to small caveats) give a new proof of the fact (first <a href="https://arxiv.org/abs/1703.08618">shown</a> by Slofstra using an embedding theorem for finitely presented group) that the zero-gap version of <img alt="{\text{MIP}^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> contains the halting problem. In particular, the entangled value is uncomputable! This was not the first time that uncomputability crops in to a natural problem in quantum computing (e.g. the <a href="https://arxiv.org/abs/1502.04573">spectral gap paper</a>), yet it still surprises when it shows up. Uncomputable! How can anything be uncomputable!</p>
<p>As we were wrapping up our paper Henry Yuen realized that our “iterated compression of interactive proof systems” was likely optimal, in the following sense. Even a mild improvement of the technique, in the form of a slower closing of the completeness-soundness gap through compression, would yield a much stronger result: undecidability of the constant-gap class <img alt="{\text{MIP}^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. It was already known by work of Navascues et al., Fritz, and others, that such a result would have, if not surprising, certainly consequences that seemed like they would be taking us out of our depth. In particular, undecidability of any language in <img alt="{\text{MIP}^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> would imply a negative resolution to a series of equivalent conjectures in functional analysis, from Tsirelson’s problem to Connes’ Embedding Conjecture through Kirchberg’s QWEP conjecture. While we liked our result, I don’t think that we believed it could resolve any conjecture(s) in functional analysis.</p>
<p>So we moved on. At least I moved on, I did some cryptography for a change. But Anand Natarajan and his co-author John Wright did not stop there. They had the last major insight in this story, which underlies their recent STOC best paper described in the previous <a href="https://mycqstate.wordpress.com/2019/04/14/randomness-and-interaction-entanglement-ups-the-game/">post</a>. Briefly, they were able to combine the two lines of work, by Natarajan &amp; myself on low-degree testing and by Ji et al. on compression, to obtain a compression that is specially tailored to the existing <img alt="{\text{MIP}^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> protocol for NEXP and compresses that protocol without reducing its completeness-soundness gap. This then let them show Ji’s result that <img alt="{\text{MIP}^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> contains NEEXP, but this time with constant gap! The result received well-deserved attention. In particular, it is the first in this line of works to not suffer from any caveats (such as a closing gap, or randomized reductions, or some kind of “unfair” tweak on the model that one could attribute the gain in power to), and it implies an unconditional separation between MIP and <img alt="{\text{MIP}^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>.</p>
<p>As they were putting the last touches on their result, suddenly something happened, which is that a path towards a much bigger result opened up. What Natarajan &amp; Wright had achieved is a one-step gapless compression. In our iterated compression paper we had observed that iterated gapless compression would lead to <img alt="{\text{MIP}^\star=\text{RE}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%3D%5Ctext%7BRE%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, implying negative answers to the aforementioned conjectures. So then?</p>
<p>I suppose it took some more work, but in some way all the ideas had been laid out in the previous 15 years of work in the complexity of quantum interactive proof systems; we just had to put it together. And so a decade after the characterization <a href="https://arxiv.org/abs/0907.4737">QIP = PSPACE</a> of single-prover quantum interactive proof systems, we have arrived at a characterization of quantum multiprover interactive proof systems, <img alt="{\text{MIP}^\star = \text{RE}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar+%3D+%5Ctext%7BRE%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. With one author in common between the two papers: congratulations Zhengfeng!</p>
<p>Even though we just posted a paper, in a sense there is much more left to do. I am hopeful that our complexity-theoretic result will attract enough interest from the mathematicians’ community, and especially operator algebraists, for whom CEP is a central problem, that some of them will be willing to devote time to understanding the result. I also recognize that much effort is needed on our own side to make it accessible in the first place! I don’t doubt that eventually complexity theory will not be needed to obtain the purely mathematical consequences; yet I am hopeful that some of the ideas may eventually find their way into the construction of interesting mathematical objects (such as, who knows, a non-hyperlinear group).</p>
<p>That was a good Masters project…thanks Julia!</p></div>
    </content>
    <updated>2020-01-14T01:32:43Z</updated>
    <published>2020-01-14T01:32:43Z</published>
    <category term="meta"/>
    <category term="QPCP"/>
    <category term="Quantum"/>
    <category term="Science"/>
    <category term="interactive proofs"/>
    <category term="qpcp"/>
    <category term="science"/>
    <author>
      <name>Thomas</name>
    </author>
    <source>
      <id>https://mycqstate.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://mycqstate.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://mycqstate.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://mycqstate.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://mycqstate.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>In superposition</subtitle>
      <title>MyCQstate</title>
      <updated>2022-04-09T22:48:02Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://adamdsmith.wordpress.com/?p=602</id>
    <link href="https://adamdsmith.wordpress.com/2019/06/11/tpdp-2019/" rel="alternate" type="text/html"/>
    <title>TPDP 2019</title>
    <summary>The call for submissions for the latest edition of TPDP (Theory and Practice of Differential Privacy) is out! https://tpdp.cse.buffalo.edu/2019/  The workshop covers work on differential privacy (of course), and more generally on rigorous modeling of, and attacks on, statistical data privacy. The intention is to be inclusive. Submissions are due June 21, 2019.</summary>
    <updated>2019-06-11T20:52:53Z</updated>
    <published>2019-06-11T20:52:53Z</published>
    <category term="Conferences"/>
    <category term="theory"/>
    <author>
      <name>adamdsmith</name>
    </author>
    <source>
      <id>https://adamdsmith.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://adamdsmith.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://adamdsmith.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://adamdsmith.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://adamdsmith.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>An inquiry into the Nature and Causes of Stuff</subtitle>
      <title>Oddly Shaped Pegs</title>
      <updated>2022-04-09T22:24:51Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://mycqstate.wordpress.com/?p=1229</id>
    <link href="https://mycqstate.wordpress.com/2019/04/14/randomness-and-interaction-entanglement-ups-the-game/" rel="alternate" type="text/html"/>
    <title>Randomness and interaction? Entanglement ups the game!</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">[05/25/19 Update: Kevin Hartnett has a nice article at Quanta explaining Natarajan &amp; Wright’s result in slightly more layman terms than I’d be able to…see here: Computer Scientists Expand the Frontier of Verifiable Knowledge] The study of entanglement through the … <a href="https://mycqstate.wordpress.com/2019/04/14/randomness-and-interaction-entanglement-ups-the-game/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><em>[05/25/19 Update: Kevin Hartnett has a nice article at Quanta explaining Natarajan &amp; Wright’s result in slightly more layman terms than I’d be able to…see here: <a href="https://www.quantamagazine.org/computer-scientists-expand-the-frontier-of-verifiable-knowledge-20190523/">Computer Scientists Expand the Frontier of Verifiable Knowledge</a>]</em></p>
<p>The study of entanglement through the length of interactive proof systems has been one of the most productive applications of complexity theory to the physical sciences that I know of. Last week Anand Natarajan and John Wright, postdoctoral scholars at Caltech and MIT respectively, added a <a href="https://arxiv.org/abs/1904.05870">major stone</a> to this line of work. Anand &amp; John (hereafter “NW”) establish the following wild claim: it is possible for a classical polynomial-time verifier to decide membership in any language in <em>non-deterministic doubly exponential time</em> by asking questions to two infinitely powerful, but untrusted, provers sharing entanglement. In symbols, NEEXP <img alt="{\subseteq}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csubseteq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> MIP<img alt="{^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>! (The last symbol is for emphasis — no, we don’t have an MIP<img alt="{^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>! class — yet.)</p>
<p>What is amazing about this result is the formidable gap between the complexity of the verifier and the complexity of the language being verified. We know since the 90s that the use of interaction and randomness can greatly expand the power of polynomial-time verifiers, from NP to <a href="https://dl.acm.org/citation.cfm?id=146609">PSPACE</a> (with a single prover) and <a href="https://dl.acm.org/citation.cfm?id=2794945">NEXP</a> (with two provers). As a result of the work of Natarajan and Wright, we now know that yet an additional ingredient, the use of <em>entanglement</em> between the provers, can be leveraged by the verifier — the same verifier as in the previous results, a classical randomized polynomial-time machine — to obtain an exponential increase in its verification power. Randomness and interaction brought us one exponential; entanglement gives us another.</p>
<p>To gain intuition for the result consider first the structure of a classical two-prover one-round interactive proof system for non-deterministic doubly exponential time, with exponential-time verifier. Cutting some corners, such a protocol can be obtained by “scaling up” a standard two-prover protocol for non-deterministic singly exponential time. In the protocol, the verifier would sample a pair of exponential-length questions <img alt="{(X,Y)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28X%2CY%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, send <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> to each prover, receive answers <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, and perform an exponential-time computation that verifies some predicate about <img alt="{(X,Y,A,B)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28X%2CY%2CA%2CB%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>.</p>
<p>How can entanglement help design an <em>exponentially more efficient</em> protocol? At first it may seem like a polynomial-time verifier has no way to even get started: if it can only communicate polynomial-length messages with the provers, how can it leverage their power? And indeed, if the provers are classical, it can’t: it is known that even with a polynomial number of provers, and polynomially many rounds of interaction, a polynomial-time verifier cannot decide any language beyond NEXP.</p>
<p>But the provers in the NW protocol are not classical. They can share entanglement. How can the verifier exploit this to its advantage? The key property that is needed is know as the <em>rigidity</em> of entanglement. In words, rigidity is the idea that by verifying the presence of certain statistical correlations between the provers’ questions and answers the verifier can determine precisely (up to a local change of basis) the quantum state and measurements that the provers must have been using to generate their answers. The most famous example of rigidity is the <em>CHSH game</em>: as already shown by <a href="http://www.numdam.org/item/AIHPA_1988__49_2_215_0/">Werner and Summers</a> in 1982, the CHSH game can only be optimally, or even near-optimally, won by measuring a maximally entangled state using two mutually unbiased bases for each player. No other state or measurements will do, unless they trivially imply an EPR pair and mutually unbiased bases (such as a state that is the tensor product of an EPR pair with an additional entangled state).</p>
<p>Rigidity gives the verifier control over the provers’ use of their entanglement. The simplest use of this is for the verifier to force the provers to share a certain number <img alt="{N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> of EPR pairs and measure them to obtain identical uniformly distributed <img alt="{N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>-bit strings. Such a test for <img alt="{N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> EPR pairs can be constructed from <img alt="{N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> CHSH games. In a <a href="https://arxiv.org/abs/1801.03821">paper</a> with Natarajan we give a more efficient test that only requires questions and answers of length that is poly-logarithmic in <img alt="{N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. Interestingly, the test is built on classical machinery — the low-degree test — that plays a central role in the analysis of some classical multi-prover proof systems for NEXP.</p>
<p>At this point we have made an inch of progress: it is possible for a polynomial-time (in <img alt="{n=\log N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%3D%5Clog+N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>) verifier to “command” two quantum provers sharing entanglement to share <img alt="{N=2^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%3D2%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> EPR pairs, and measure them in identical bases to obtain identical uniformly random <img alt="{N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>-bit strings. What is this useful for? Not much — yet. But here comes the main insight in NW: suppose we could similarly force the provers to generate, not identical uniformly random strings, but a pair of <img alt="{N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>-bit strings <img alt="{(X,Y)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28X%2CY%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> that is distributed as a pair of questions from the verifier in the aforementioned interactive proof system for NEEXP with exponential-time (in <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>) verifier. Then we could use a polynomial-time (in <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>) verifier to “command” the provers to generate their exponentially-long questions <img alt="{(X,Y)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28X%2CY%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> by themselves. The provers would then compute answers <img alt="{(A,B)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28A%2CB%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> as in the NEEXP protocol. Finally, they would prove to the verifier, using a polynomial interaction, that <img alt="{(A,B)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28A%2CB%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is a valid pair of answers to the pair of questions <img alt="{(X,Y)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28X%2CY%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> — indeed, the latter verification is an NEXP problem, hence can be verified using a protocol with polynomial-time verifier.</p>
<p>Sounds crazy? Yes. But they did it! Of course there are many issues with the brief summary above — for example, how does the verifier even know the questions <img alt="{X,Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%2CY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> sampled by the provers? The answer is that it doesn’t need to know the entire question; only that it was sampled correctly, and that the quadruple <img alt="{(X,Y,A,B)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28X%2CY%2CA%2CB%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> satisfies the verification predicate of the exponential-time verifier. This can be verified using a polynomial-time interactive proof.</p>
<p>Diving in, the most interesting insight in the NW construction is what they call “introspection”. What makes multi-prover proof systems powerful is the ability for the verifier to send correlated questions to the provers, in a way such that each prover has only partial information about the other’s question — informally, the verifier plays a variant of prisonner’s dilemma with the provers. In particular, any interesting distribution <img alt="{(X,Y)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28X%2CY%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> will have the property that <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> are not fully correlated. For a concrete example think of the “planes-vs-lines” distribution, where <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is a uniformly random plane and <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> a uniformly random line in <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. The aforementioned test for <img alt="{N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> EPR pairs can be used to force both provers to sample the same uniformly random plane <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. But how does the verifier ensure that one of the provers “forgets” parts of the plane, to only remember a uniformly random line <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> that is contained in it? NW’s insight is that the information present in a quantum state — such as the prover’s half-EPR pairs — can be “erased” by commanding the prover to perform a measurement in the <em>wrong</em> basis — a basis that is mutually unbiased with the basis used by the other prover to obtain its share of the query. Building on this idea, NW develop a battery of delicate tests that provide the verifier the ability to control precisely what information gets distributed to each prover. This allows a polynomial-time verifier to perfectly simulate the local environment that the exponential-time verifier would have created for the provers in a protocol for NEEXP, thus simulating the latter protocol with exponentially less resources.</p>
<p>One of the aspects of the NW result I like best is that they showed how the “history state barrier” could be overcome. Previous works attempting to establish strong lower bounds on the class MIP<img alt="{^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, such as the <a href="https://arxiv.org/abs/1805.12166">paper</a> by Yuen et al., relies on a compression technique that requires the provers to share a history state of the computation performed by a larger protocol. Unfortunately, history states are very non-robust, and as a result such works only succeeded in developing protocols with vanishing completeness-soundness gap. NW entirely bypass the use of history states, and this allows them to maintain a constant gap.</p>
<p>Seven years ago Tsuyoshi Ito and I showed that <a href="https://arxiv.org/abs/1207.0550">MIP<img alt="{}^\star" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7D%5E%5Cstar&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> contains NEXP</a>. At the time, we thought this may be the end of the story — although it seemed challenging, surely someone would eventually prove a matching upper bound. Natarajan and Wright have defeated this expectation by showing that MIP<img alt="{^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> contains NEEXP. What next? NEEEXP? The halting problem? I hope to make this the topic of a future post.</p></div>
    </content>
    <updated>2019-04-14T04:35:25Z</updated>
    <published>2019-04-14T04:35:25Z</published>
    <category term="CHSH"/>
    <category term="QPCP"/>
    <category term="Quantum"/>
    <category term="Uncategorized"/>
    <category term="interactive proofs"/>
    <author>
      <name>Thomas</name>
    </author>
    <source>
      <id>https://mycqstate.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://mycqstate.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://mycqstate.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://mycqstate.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://mycqstate.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>In superposition</subtitle>
      <title>MyCQstate</title>
      <updated>2022-04-09T22:48:15Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://mycqstate.wordpress.com/?p=1226</id>
    <link href="https://mycqstate.wordpress.com/2018/08/06/the-cryptographic-leash/" rel="alternate" type="text/html"/>
    <title>The cryptographic leash</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">This post is meant as a companion to an introductory post I wrote on the blog of Caltech’s IQIM (Institute for Quantum Information and Matter), of which I am a member. The post describes a “summer cluster” on quantum computation … <a href="https://mycqstate.wordpress.com/2018/08/06/the-cryptographic-leash/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>This post is meant as a companion to an introductory post I wrote on the <a href="https://quantumfrontiers.com/">blog</a> of Caltech’s IQIM (<a href="http://iqim.caltech.edu/">Institute for Quantum Information and Matter</a>), of which I am a member. The post describes a “summer cluster” on quantum computation that I co-organized with Andrew Childs, Ignacio Cirac, and Umesh Vazirani at the Simons Institute in Berkeley over the past couple months. The IQIM post also describes one of the highlights of the workshop we organized as part of this program: the recent result by Mahadev on <a href="https://mycqstate.wordpress.com/Users/Thomas/Dropbox/www/myCQstate/verification2-clean.html">classical verification of quantum computation</a>. The present post is a continuation of <a href="https://quantumfrontiers.com/2018/08/05/the-quantum-wave-in-computing/">that one</a>, so that I would encourage you to read it first. In this post my goal is to give additional detail on Mahadev’s result. For the real thing you should of course read the <a href="https://mycqstate.wordpress.com/Users/Thomas/Dropbox/www/myCQstate/verification2-clean.html">paper</a> (you may want to start by watching the author’s <a href="https://simons.berkeley.edu/talks/urmila-mahadev-06-15-18">beautiful talk</a> at our workshop). What follows is my attempt at an introduction, in great part written for the sake of clarifying my own understanding. I am indebted to Urmila for multiple conversations in which she indefatigably answered my questions and cleared my confusions — of course, any remaining inaccuracies in this post are entirely mine.</p>
<p><b>The result </b></p>
<p><a name="the-result"/></p>
<p>Let’s start by recalling Mahadev’s result. She shows that from any quantum computation, specified by a polynomial-size quantum circuit <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, it is possible to efficiently compute a <em>classical-verifier quantum-prover protocol</em>, i.e.~a prescription for the actions of a classical probabilistic polynomial-time verifier interacting with a quantum prover, that has the following properties. For simplicity, assume that <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> produces a deterministic outcome <img alt="{o(C)\in\{0,1\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bo%28C%29%5Cin%5C%7B0%2C1%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> when it is executed on qubits initialized in the state <img alt="{| 0 \rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7C+0+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> (any input can be hard-coded in the circuit). At the end of the protocol, the verifier always makes one of three possible decisions: “reject”; “accept, 0”; “accept, 1”. The <em>completeness</em> property states that for any circuit <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> there is a “honest” behavior for the prover that can be implemented by a polynomial-time quantum device and that will result in the verifier making the decision “accept, <img alt="{o(C)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bo%28C%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>”, where <img alt="{o(C)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bo%28C%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is the correct outcome, with probability <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. The <em>soundness</em> property states that for any behavior of the quantum prover in the protocol, either the probability that the verifier returns the outcome “accept, <img alt="{1-o(C)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1-o%28C%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>” is negligibly small, or the quantum prover has the ability to break a post-quantum cryptographic scheme with non-negligible advantage. Specifically, the proof of the soundness property demonstrates that a prover that manages to mislead the verifier into making the wrong decision (for any circuit) can be turned into an efficient attack on the learning with errors (LWE) problem (with superpolynomial noise ratio).</p>
<p>The fact that the protocol is only sound against computationally bounded provers sets it apart from previous approaches, which increased the power of the verifier by allowing her to dispose of a miniature quantum computer, but established soundness against computationally unbounded provers. The magic of Mahadev’s result is that she manages to leverage this sole assumption, computational boundnedness of the prover, to tie a very tight “leash” around its neck, by purely classical means. My use of the word “leash” is <a href="https://arxiv.org/abs/1209.0448">not innocent</a>: informally, it seems that the cryptographic assumption allows Mahadev to achieve the kind of feats that were previously known, for classical verifiers, in the model where there are two quantum provers sharing entanglement. I am not sure how far the analogy extends, and would like to explore it further; this has already started with a collaboration with Brakerski, Christiano, Mahadev and Vazirani that led to <a href="https://arxiv.org/abs/1804.00640">a single-prover protocol for certifiable randomness expansion</a>. Nevertheless, the main open question left open by Mahadev’s work remains whether the computational assumption is even necessary: could a similar result hold, where the honest prover can perform the required actions in quantum polynomial-time, but the protocol remains sound against arbitrarily powerful provers? (Experts will have recognized that the existence of a protocol where the honest prover is as powerful as PSPACE follows from the classical results that BQP is in PSPACE, and that PSPACE=IP. Unfortunately, we currently don’t expect even a supercharged AWS cloud to be able to implement PSPACE-complete computations.)</p>
<p><b> Encoding computation in ground states </b></p>
<p><a name="encoding-computation-in-ground-states"/></p>
<p>Let’s get to business: how does this work? Fix a quantum circuit <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> that the verifier is interested in. Assume the description of <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> known to both the verifier and the prover. As earlier, assume further that when <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is executed on a state initialized to <img alt="{| 0 \rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7C+0+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> a measurement of the output qubit of the circuit returns either the outcome <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> or the outcome <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, deterministically. The verifier wishes to determine which case holds.</p>
<p>The first step that the verifier performs is a classical polynomial-time reduction from this <em>circuit output decision problem</em> to the following <em>Hamiltonian energy decision problem</em>. In the Hamiltonian energy decision problem the input is the description of a pair of classical polynomial-time randomized circuits. The first circuit, <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, takes as input a random string <img alt="{r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, and returns a string <img alt="{\theta\in\{X,Z\}^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctheta%5Cin%5C%7BX%2CZ%5C%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. The second circuit, <img alt="{V}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BV%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, takes as input a string <img alt="{\theta\in\{X,Z\}^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctheta%5Cin%5C%7BX%2CZ%5C%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> of the kind returned by the first circuit, as well as an <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>-bit string <img alt="{a\in\{0,1\}^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%5Cin%5C%7B0%2C1%5C%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, and returns a “decision bit” <img alt="{b\in \{0,1\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb%5Cin+%5C%7B0%2C1%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. The goal of the verifier is to distinguish between the following two cases. Either there exists an <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>-qubit state <img alt="{\rho}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> such that, when a string <img alt="{\theta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctheta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is sampled according to <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> (choosing a uniformly random <img alt="{r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> as input), the <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> qubits of <img alt="{\rho}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> are measured in the bases specified by <img alt="{\theta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctheta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> (i.e.~the <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>-th qubit is measured in the computational basis in case <img alt="{\theta_i=Z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctheta_i%3DZ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, and in the Hadamard basis in case <img alt="{\theta_i=X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctheta_i%3DX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>), the resulting <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>-bit outcome <img alt="{a}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> satisfies <img alt="{V(\theta,a)=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BV%28%5Ctheta%2Ca%29%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> with probability at least <img alt="{3/4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3%2F4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. Or, for any state <img alt="{\rho}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, the same procedure results in <img alt="{V(\theta,a)=0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BV%28%5Ctheta%2Ca%29%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> with probability at most <img alt="{2/3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%2F3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>.</p>
<p>I called this problem the Hamiltonian energy decision problem because the circuits <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and <img alt="{V}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BV%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> implicitly specify a Hamiltonian, whose minimal energy the verifier aims to approximate. Note that the Hamiltonian is not required to be local, and furthermore it may involve an average of exponentially many terms (as many as there are random strings <img alt="{r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>). The problem is still in QMA, because the verifier is efficient. It is not hard to show that the problem is QMA-hard. What the formulation above buys us, compared to using the usual QMA-complete formulation of the local Hamiltonian problem, is the constant energy gap — which comes at the cost of exponentially many terms and loss of locality. (Open question: I would like to know if it is possible to achieve a constant gap with only one of these caveats: local with exponentially many terms, or nonlocal with polynomially terms.) Of course here we only care that the problem is BQP-hard, and that the witness can be computed by a BQP prover; this is indeed the case. We also don’t really care that there is a constant gap – the soundness of the final protocol could be amplified by other means – but it is convenient that we are able to assume it.</p>
<p>The reduction that achieves this is a combination of Kitaev’s history state construction with some gadgetry from perturbation theory and an amplification trick. The first step reduces the verification that <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> returns outcome <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> (resp. <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>) on input <img alt="{| 0 \rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7C+0+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> to the verification that a local Hamiltonian <img alt="{H}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> (computed from <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>) has ground state energy exponentially close to <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> (resp. at least some positive inverse polynomial). The second step consists in applying perturbation theory to reduce to the case where <img alt="{H}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is a weighted linear combination of terms of the form <img alt="{X_iX_j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_iX_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and <img alt="{Z_iZ_j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BZ_iZ_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, where <img alt="{X_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, <img alt="{Z_j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BZ_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> are the Pauli <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and <img alt="{Z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BZ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> operators on the <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>-th and <img alt="{j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>-th qubit respectively. The final step is an amplification trick, that produces a nonlocal Hamiltonian whose each term is a tensor product of single-qubit <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and <img alt="{Z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BZ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> observables and has ground state energy either less than <img alt="{1/4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%2F4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> or larger than <img alt="{1/3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%2F3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> (when the Hamiltonian is scaled to be non-negative with norm at most <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>).</p>
<p>These steps are fairly standard. The first two are combined in a <a href="https://arxiv.org/abs/1603.06046">paper</a> by Fitzsimons and Morimae to obtain a protocol for “post-hoc” verification of quantum computation: the prover prepares the ground state of an <img alt="{XZ}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BXZ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> local Hamiltonian whose energy encodes the outcome of the computation, and sends it to the verifier one qubit at a time; the verifier only needs to perform single-qubit <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and <img alt="{Z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BZ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> measurements to estimate the energy. The last step, amplification, is described in a <a href="https://arxiv.org/abs/1610.03574">paper</a> with Natarajan, where we use it to obtain a multi-prover interactive proof system for QMA.</p>
<p>For the remainder of this post, I take the reduction for granted and focus on the core of Mahadev’s result, a verification protocol for the following problem: given a Hamiltonian of the form described in the previous paragraph, decide whether the ground state energy of <img alt="{H}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is smaller than <img alt="{1/4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%2F4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, or larger than <img alt="{1/3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%2F3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>.</p>
<p><b> Stitching distributions into a qubit </b></p>
<p><a name="stitching-distributions-into-a-qubit"/></p>
<p>In fact, for the sake of presentation I’ll make one further drastic simplification, which is that the verifier’s goal has been reduced to verifying the existence of a <em>single-qubit</em> state <img alt="{\rho}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, whose existence is claimed by the prover. Specifically, suppose that the prover claims that it has the ability to prepare a state <img alt="{| \psi \rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7C+%5Cpsi+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> such that <img alt="{\langle \psi |X| \psi \rangle = E_X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clangle+%5Cpsi+%7CX%7C+%5Cpsi+%5Crangle+%3D+E_X%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, and <img alt="{\langle \psi |Z| \psi \rangle=E_Z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clangle+%5Cpsi+%7CZ%7C+%5Cpsi+%5Crangle%3DE_Z%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, for real parameters <img alt="{E_X,E_Z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BE_X%2CE_Z%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. In other words, that the Hamiltonian <img alt="{H = \frac{1}{2}(X+Z)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BH+%3D+%5Cfrac%7B1%7D%7B2%7D%28X%2BZ%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> has minimal energy at most <img alt="{\frac{1}{2}(E_X+E_Z)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B1%7D%7B2%7D%28E_X%2BE_Z%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. How can one verify this claim? (Of course we could do it analytically\ldots{}but that approach would break apart as soon as expectation values on larger sets of qubits are considered.)</p>
<p>We could ask the prover to measure in the <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> basis, or the <img alt="{Z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BZ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> basis, repeatedly on identical copies of <img alt="{| \psi \rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7C+%5Cpsi+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, and report the outcomes. But how do we know that all these measurements were performed on the same state, and that the prover didn’t choose e.g. <img alt="{| \psi \rangle=| 1 \rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7C+%5Cpsi+%5Crangle%3D%7C+1+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> to report the <img alt="{Z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BZ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>-basis outcomes, and <img alt="{| \psi \rangle=| - \rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7C+%5Cpsi+%5Crangle%3D%7C+-+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> to report the <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>-basis outcomes? We need to find a way to prevent the prover from measuring a different state depending on the basis it is asked for — as well as to ensure the measurement is performed in the right basis.</p>
<p><b> Committing to a qubit </b></p>
<p><a name="committing-to-a-qubit"/></p>
<p>The key idea in Mahadev’s protocol is to use cryptographic techniques to force the prover to “commit” to the state <img alt="{| \psi \rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7C+%5Cpsi+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> in a way that, once the commitment has been performed, the prover no longer has the liberty to “decide” which measurement it performs on the commited qubit (unless it breaks the cryptographic assumption).</p>
<p>I described the commitment scheme in the companion post <a href="https://quantumfrontiers.com/2018/08/05/the-quantum-wave-in-computing/">here</a>. For convenience, let me quote from that post. Recall that the scheme is based on a pair of trapdoor permutations <img alt="{f_0,f_1:\{0,1\}^n \rightarrow \{0,1\}^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_0%2Cf_1%3A%5C%7B0%2C1%5C%7D%5En+%5Crightarrow+%5C%7B0%2C1%5C%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> that is <em>claw-free</em>. Informally, this means that it is hard to produce any pair <img alt="{(x_0,x_1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28x_0%2Cx_1%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> such that <img alt="{f_0(x_0)=f_1(x_1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_0%28x_0%29%3Df_1%28x_1%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>.</p>
<p>The commitment phase of the protocol works as follows. Starting from a state <img alt="{| \psi \rangle=\alpha| 0 \rangle+\beta| 1 \rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7C+%5Cpsi+%5Crangle%3D%5Calpha%7C+0+%5Crangle%2B%5Cbeta%7C+1+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> of its choice, the prover is supposed to perform the following steps. First, the prover creates a uniform superposition over the common domain of <img alt="{f_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and <img alt="{f_1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. Then it evaluates either function, <img alt="{f_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> or <img alt="{f_1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, in an additional register, by controlling on the qubit of <img alt="{| \psi \rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7C+%5Cpsi+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. Finally, the prover measures the register that contains the image of <img alt="{f_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> or <img alt="{f_1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. This achieves the following sequence of transformations:</p>
<p align="center"><img alt="\displaystyle \begin{array}{rcl} \alpha| 0 \rangle+\beta| 1 \rangle &amp;\mapsto&amp; (\alpha| 0 \rangle + \beta| 1 \rangle) \otimes \Big(2^{-n/2} \sum_{x\in\{0,1\}^n} | x \rangle\Big) \\ &amp;\mapsto &amp; 2^{-n/2} \sum_x \alpha | 0 \rangle| x \rangle| f_0(x) \rangle + \beta | 1 \rangle| f_1(x) \rangle\\ &amp;\mapsto &amp; \big(\alpha| 0 \rangle| x_0 \rangle+\beta| 1 \rangle| x_1 \rangle\big)| y \rangle\;, \end{array} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cbegin%7Barray%7D%7Brcl%7D+%5Calpha%7C+0+%5Crangle%2B%5Cbeta%7C+1+%5Crangle+%26%5Cmapsto%26+%28%5Calpha%7C+0+%5Crangle+%2B+%5Cbeta%7C+1+%5Crangle%29+%5Cotimes+%5CBig%282%5E%7B-n%2F2%7D+%5Csum_%7Bx%5Cin%5C%7B0%2C1%5C%7D%5En%7D+%7C+x+%5Crangle%5CBig%29+%5C%5C+%26%5Cmapsto+%26+2%5E%7B-n%2F2%7D+%5Csum_x+%5Calpha+%7C+0+%5Crangle%7C+x+%5Crangle%7C+f_0%28x%29+%5Crangle+%2B+%5Cbeta+%7C+1+%5Crangle%7C+f_1%28x%29+%5Crangle%5C%5C+%26%5Cmapsto+%26+%5Cbig%28%5Calpha%7C+0+%5Crangle%7C+x_0+%5Crangle%2B%5Cbeta%7C+1+%5Crangle%7C+x_1+%5Crangle%5Cbig%29%7C+y+%5Crangle%5C%3B%2C+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>where <img alt="{y\in\{0,1\}^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%5Cin%5C%7B0%2C1%5C%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is the measured image. The string <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is the prover’s <em>commitment string</em>, that it reports the verifier.</p>
<p>The intuition for this commitment procedure is that it introduces asymmetry between prover and verifier: the prover knows <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> (it had to report it to the verifier) but not <img alt="{x_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and <img alt="{x_1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> (this is the claw-free assumption on the pair <img alt="{(f_0,f_1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28f_0%2Cf_1%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>), which seems to prevent it from recovering the original state <img alt="{| \psi \rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7C+%5Cpsi+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, since it does not have the ability to “uncompute” <img alt="{x_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and <img alt="{x_1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. In contrast, the verifier can use the trapdoor information to recover both preimages.</p>
<p>In a little more detail, how is this used? Note that at this point, from the verifier’s point of view the only information that has been received is the prover’s commitment string <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. In general there are multiple ways a prover could have come up with a value <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>: for example, by selecting an <img alt="{x\in\{0,1\}^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%5Cin%5C%7B0%2C1%5C%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and returning <img alt="{y=f_0(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%3Df_0%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. Or, by directly selecting an arbitrary string <img alt="{y\in\{0,1\}^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%5Cin%5C%7B0%2C1%5C%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. At this stage of the protocol, any of these strategies look fine.</p>
<p>Let’s modify the commitment phase by adding a little test. With some probability, the verifier, upon receiving the commitment string <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, decides to challenge the prover by asking it to report a valid preimage of <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, either under <img alt="{f_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> or under <img alt="{f_1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> (to the prover’s choice). Since both <img alt="{f_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and <img alt="{f_1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> are presumed to be hard to invert, the only way the prover can answer this challenge is if it already “knows” a valid preimage — or at a minimum, if it has a superposition on preimages that it can measure when tested. Thus the fact that the prover is required to succeed in the commitment test, when it is performed, guarantees that after the prover has returned the commitment string <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> we may without loss of generality assume that the prover’s state can be written as</p>
<p><a name="eqdef-psi"/></p>
<p align="center"><a name="eqdef-psi"/><img alt="\displaystyle | \tilde{\psi} \rangle=\tilde{\alpha}| 0,x_0 \rangle| \phi_0 \rangle+\tilde{\beta}| 1,x_1 \rangle| \phi_1 \rangle\;, \ \ \ \ \ (1)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%7C+%5Ctilde%7B%5Cpsi%7D+%5Crangle%3D%5Ctilde%7B%5Calpha%7D%7C+0%2Cx_0+%5Crangle%7C+%5Cphi_0+%5Crangle%2B%5Ctilde%7B%5Cbeta%7D%7C+1%2Cx_1+%5Crangle%7C+%5Cphi_1+%5Crangle%5C%3B%2C+%5C+%5C+%5C+%5C+%5C+%281%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p><a name="eqdef-psi"/></p>
<p>where we have purposefully spelled out the two possible preimages that the prover could return if challenged. Note that aside from the fact that it gives the ability to obtain <img alt="{x_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> or <img alt="{x_1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, this format does not make any assumption on <img alt="{| \tilde{\psi} \rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7C+%5Ctilde%7B%5Cpsi%7D+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>; in particular the register containing the preimage can be entangled with other private registers of the prover.</p>
<p>We have defined a four-message commitment protocol: the verifier sends the security parameters to prover; the prover sends a commitment string <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> back; an optional one-round preimage test is executed. Now is the time to give a first definition for the single qubit to which the prover has “committed” by returning <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. This <em>committed qubit</em> is the state <img alt="{\sigma}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> that we ultimately aim to show has the claimed expectation values under <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and <img alt="{Z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BZ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> measurements.</p>
<p>Let <img alt="{\sigma}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> be the qubit obtained from <img alt="{| \tilde{\psi} \rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7C+%5Ctilde%7B%5Cpsi%7D+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> by erasing <img alt="{x_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and <img alt="{x_1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> (which is possible given knowledge of <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>) and returning the first qubit of the resulting state. (Later we will slightly modify this definition, but it is a good placeholder to get us started.) Note that the verifier does not know the state <img alt="{\sigma}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>; in fact, strictly speaking <img alt="{\sigma}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is not present on the prover’s workspace either. The point is that <img alt="{\sigma}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> exists, and this is all we need. Our remaining task is to find a way for the verifier to extract from the prover measurement outcomes that are distributed as would be a measurement of <img alt="{\sigma}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> in the <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> or <img alt="{Z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BZ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> basis, without the prover having the ability to deviate. If the verifier can do this, for a basis of her choice, she can choose a basis at random, estimate the expectation value, and check the prover’s claim (the values <img alt="{E_X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BE_X%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> or <img alt="{E_Z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BE_Z%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>).</p>
<p>As already mentioned, the key point that we’ll use in order to achieve this is that at the end of the commitment phase, the verifier has obtained some leverage over the prover: given <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and the trapdoor information, the verifier can recover both <img alt="{x_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and <img alt="{x_1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. In contrast, the prover, while it holds the state <img alt="{| \tilde{\psi} \rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7C+%5Ctilde%7B%5Cpsi%7D+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, is not able to freely operate on it. Without the trapdoor, it can no longer uncompute <img alt="{x_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and <img alt="{x_1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> to recover the initial state <img alt="{| \psi \rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7C+%5Cpsi+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, and so it can’t obviously apply, say, the unitary on <img alt="{| \tilde{\psi} \rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7C+%5Ctilde%7B%5Cpsi%7D+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> that would amount to performing a single-qubit rotation on <img alt="{| \psi \rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7C+%5Cpsi+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>.</p>
<p><b> Measuring in the computational basis </b></p>
<p><a name="measuring-in-the-computational-basis"/></p>
<p>We need to explain how the verifier extracts measurement outcomes in the X (Hadamard) or Z (computational) basis from the prover. For each basis there is a small sub-protocol. At the end of the sub-protocol the verifier records a single bit, that it considers is the outcome obtained by a measurement of the committed qubit, <img alt="{\sigma}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, in the corresponding basis. We call this bit the verifier’s “decoded bit” for that basis.</p>
<p>The protocol for extracting the outcome of a measurement in the computational basis is straightforward. Recall that by definition the prover’s state after the commitment phase has ended is the state <img alt="{| \tilde{\psi} \rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7C+%5Ctilde%7B%5Cpsi%7D+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> in <a href="https://mycqstate.wordpress.com/Users/Thomas/Dropbox/www/myCQstate/verification2-clean.html#eqdef-psi">(1)</a>. Moreover, recall that we made a choice of basis for the provers’ space such that when the prover is challenged for a preimage of <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, it measures the first <img alt="{(n+1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28n%2B1%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> qubits of <img alt="{| \tilde{\psi} \rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7C+%5Ctilde%7B%5Cpsi%7D+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> in the computational basis and returns the outcome. Now observe that the first bit of this outcome is <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> with probability <img alt="{|\tilde{\alpha}|^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7C%5Ctilde%7B%5Calpha%7D%7C%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, and <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> with probability <img alt="{|\tilde{\beta}|^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7C%5Ctilde%7B%5Cbeta%7D%7C%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. This is exactly the distribution of the outcome of a measurement of the committed qubit <img alt="{\sigma}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> in the computational basis, by definition! Thus to extract a measurement outcome in the computational basis the verifier simply executes the preimage test and records the first bit returned by the prover as the decoded bit.</p>
<p><b> Measuring in the Hadamard basis </b></p>
<p><a name="measuring-in-the-hadamard-basis"/></p>
<p>Extracting a measurement outcome in the Hadamard basis is more delicate. Recall the form of the prover’s state in <a href="https://mycqstate.wordpress.com/Users/Thomas/Dropbox/www/myCQstate/verification2-clean.html#eqdef-psi">(1)</a>. Given our definition of the committed qubit <img alt="{\sigma}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, the natural way to obtain a measurement of <img alt="{\sigma}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> in the Hadamard basis, starting from <img alt="{| \tilde{\psi} \rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7C+%5Ctilde%7B%5Cpsi%7D+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, is to first erase the register containing <img alt="{x_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and <img alt="{x_1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, and then perform a Hadamard measurement of the first qubit. But even an honest prover cannot accomplish this, as it does not have the trapdoor information that would allow to erase <img alt="{x_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and <img alt="{x_1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> (of course we purposefully set things up this way). What the prover <em>can</em> do, however, is measure all <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> qubits of the register containing <img alt="{x_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and <img alt="{x_1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> in the Hadamard basis. The result of this measurement is an <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>-bit string <img alt="{d\in\{0,1\}^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%5Cin%5C%7B0%2C1%5C%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. The corresponding post-measurement state is, up to global phase,</p>
<p align="center"><img alt="\displaystyle \tilde{\alpha}| 0 \rangle| \phi_0 \rangle+(-1)^{d\cdot(x_0+ x_1)}\tilde{\beta}| 1 \rangle| \phi_1 \rangle\;," class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Ctilde%7B%5Calpha%7D%7C+0+%5Crangle%7C+%5Cphi_0+%5Crangle%2B%28-1%29%5E%7Bd%5Ccdot%28x_0%2B+x_1%29%7D%5Ctilde%7B%5Cbeta%7D%7C+1+%5Crangle%7C+%5Cphi_1+%5Crangle%5C%3B%2C&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>where the addition <img alt="{x_0+x_1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_0%2Bx_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is taken bitwise, modulo <img alt="{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. Observe that this state is almost exactly the committed qubit <img alt="{\sigma}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> — except for a phase flip, <img alt="{Z^{d\cdot(x_0\oplus x_1)}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BZ%5E%7Bd%5Ccdot%28x_0%5Coplus+x_1%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, applied on the first qubit. If the prover measures the remaining qubit in the Hadamard basis, the phase flip leads to a bit flip on the outcome <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> of the measurement. So the verifier can ask the prover to report both <img alt="{d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>; if she recourds the decoded bit <img alt="{b=m\oplus d\cdot (x_0\oplus x_1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb%3Dm%5Coplus+d%5Ccdot+%28x_0%5Coplus+x_1%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> then this bit matches the outcome of a measurement of <img alt="{\sigma}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> in the Hadamard basis.</p>
<p>This completes the description of the measurement sub-protocol for the Hadamard basis. It is clear that a honest prover, performing the actions described above, will induce the verifier into recording the correct outcome. Now of course in general the prover may act in an arbitrary way! It could report any values for <img alt="{(m,d)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28m%2Cd%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>: the verifier accepts any outcomes on faith. How could this possibly work out? There is magic in Mahadev’s proof.</p>
<p><b> Malicious provers </b></p>
<p><a name="malicious-provers"/></p>
<p>Let’s assume, as we already have, that the prover is arbitrary but that, if tested in the commitment phase, it succeeds with certainty. According to the discussion around <a href="https://mycqstate.wordpress.com/Users/Thomas/Dropbox/www/myCQstate/verification2-clean.html#eqdef-psi">(1)</a> this implies that at the end of the commitment phase the prover holds a state of the form <img alt="{| \tilde{\psi} \rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7C+%5Ctilde%7B%5Cpsi%7D+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. Moreover, by definition, when asked for a computational basis measurement the prover measures the first <img alt="{(n+1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28n%2B1%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> qubits of <img alt="{| \tilde{\psi} \rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7C+%5Ctilde%7B%5Cpsi%7D+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> in the computational basis and reports the outcome; the verifier records the first bit as its decoded bit.</p>
<p>As we already argued, our earlier definition of the committed qubit <img alt="{\sigma}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> ensures that the verifier’s decoded bit for the case of a computational basis measurement matches the outcome of a measurement of <img alt="{\sigma}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> in the computational basis. Unfortunately for the case of a Hadamard basis measurement we are in trouble. Since the prover may in principle report an arbitrary pair <img alt="{(m,d)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28m%2Cd%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> there is no chance to argue that this matches (in distribution) the outcome of a measurement of <img alt="{\sigma}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> in the Hadamard basis. To find a state that is consistent with the verifier’s decoded bit in both bases we need to change our definition of the committed qubit to take into account the prover’s action in the case it is asked for a Hadamard measurement.</p>
<p>Recall that the main leverage that the verifier has over the prover is that, while the prover does have the possibility of reporting arbitrary outcomes <img alt="{(m,d)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28m%2Cd%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, it <em>does not</em> have control over the verifier’s decoding, i.e.~the operation <img alt="{b\leftarrow m\oplus (d\cdot(x_0+ x_1))}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb%5Cleftarrow+m%5Coplus+%28d%5Ccdot%28x_0%2B+x_1%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. Let’s work a little bit and spell out the distribution of the verifier’s Hadamard basis decoded bit, <img alt="{b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. Towards this it is convenient to think of the prover in the following way: the prover first applies an arbitrary unitary “attack” <img alt="{U}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> on <img alt="{| \tilde{\psi} \rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7C+%5Ctilde%7B%5Cpsi%7D+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, then “honestly” measures the first <img alt="{(n+1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28n%2B1%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> qubits in the Hadamard basis, and finally reports the <img alt="{(n+1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28n%2B1%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>-bit outcome <img alt="{(m,d)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28m%2Cd%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. An arbitrary <img alt="{(n+1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28n%2B1%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>-bit-outcome measurement can always be expressed in this way. With this setup we can write the probability that the decoded bit is some value <img alt="{b\in\{0,1\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb%5Cin%5C%7B0%2C1%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> as</p>
<p><a name="eqprb-1"/></p>
<p align="center"><a name="eqprb-1"/><img alt="\displaystyle \Pr(b) \,=\, \sum_{d\in\{0,1\}^n} \langle \tilde{\psi} | U^\dagger H \big((X^{d\cdot(x_0+x_1)} | b \rangle\!\langle b |X^{d\cdot(x_0+x_1)}) \otimes | d \rangle\!\langle d |\big)HU| \tilde{\psi} \rangle\;. \ \ \ \ \ (2)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5CPr%28b%29+%5C%2C%3D%5C%2C+%5Csum_%7Bd%5Cin%5C%7B0%2C1%5C%7D%5En%7D+%5Clangle+%5Ctilde%7B%5Cpsi%7D+%7C+U%5E%5Cdagger+H+%5Cbig%28%28X%5E%7Bd%5Ccdot%28x_0%2Bx_1%29%7D+%7C+b+%5Crangle%5C%21%5Clangle+b+%7CX%5E%7Bd%5Ccdot%28x_0%2Bx_1%29%7D%29+%5Cotimes+%7C+d+%5Crangle%5C%21%5Clangle+d+%7C%5Cbig%29HU%7C+%5Ctilde%7B%5Cpsi%7D+%5Crangle%5C%3B.+%5C+%5C+%5C+%5C+%5C+%282%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p><a name="eqprb-1"/></p>
<p>Before we can proceed we should say a little more about the computational assumptions that are placed on the pair of functions <img alt="{(f_0,f_1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28f_0%2Cf_1%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. Earlier we mentioned this pair of functions should be claw-free, but in fact a little more is needed — though all requirements can ultimately be met by a construction based on the Learning With Errors problem. Rather than state the exact assumptions, I will mention two important consequences. The first is that the pair of functions is “collapsing”, a notion introduced by Unruh in his investigations of <a href="https://link.springer.com/chapter/10.1007/978-3-662-49896-5_18">collision-resistance against quantum attacks</a>. In our context this property implies that it is computationally hard to distinguish between an arbitrary superposition over preimages, as in <img alt="{| \tilde{\psi} \rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7C+%5Ctilde%7B%5Cpsi%7D+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, and the “collapsed” state obtained by measuring the control register (the first qubit). The second is that for any <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>-bit string <img alt="{d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> that can be obtained as the outcome of an arbitrary, but computationally efficient, measurement on the collapsed state, the bit <img alt="{d\cdot(x_0+x_1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%5Ccdot%28x_0%2Bx_1%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is computationally indistinguishable from uniform. (This is analogous to a “hardcore bit” property, since <img alt="{x_0+x_1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_0%2Bx_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> encodes information about both preimages simultaneously, and such information should not be accessible if the pair <img alt="{(f_0,f_1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28f_0%2Cf_1%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is claw-free.)</p>
<p>These two assumptions taken together justify the following two modifications to the expression for <img alt="{\Pr(b)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CPr%28b%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> in <a href="https://mycqstate.wordpress.com/Users/Thomas/Dropbox/www/myCQstate/verification2-clean.html#eqprb-1">(2)</a>, that will lead to a computationally indistinguishable distribution. First, we can “collapse” the first <img alt="{(n+1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28n%2B1%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> qubits of <img alt="{| \tilde{\psi} \rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7C+%5Ctilde%7B%5Cpsi%7D+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> by measuring them in the computational basis. Second, we can replace the bit <img alt="{d\cdot(x_0+x_1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%5Ccdot%28x_0%2Bx_1%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> by a uniformly random bit <img alt="{r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. Using that <img alt="{\sum_d | d \rangle\!\langle d |=\ensuremath{\mathop{\rm Id}\nolimits}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csum_d+%7C+d+%5Crangle%5C%21%5Clangle+d+%7C%3D%5Censuremath%7B%5Cmathop%7B%5Crm+Id%7D%5Cnolimits%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, the expression simplifies to</p>
<p><a name="eqprb-3"/></p>
<p align="center"><a name="eqprb-3"/><img alt="\displaystyle {\Pr}^{'}(b) \,=\, \frac{1}{4}\sum_{r\in\{0,1\}} \langle \tilde{\psi} | (Z^r \otimes \ensuremath{\mathop{\rm Id}\nolimits}) (U^\dagger) (Z^r \otimes \ensuremath{\mathop{\rm Id}\nolimits}) H \big( | b \rangle\!\langle b |) \otimes \ensuremath{\mathop{\rm Id}\nolimits}\big) (Z^{r} \otimes \ensuremath{\mathop{\rm Id}\nolimits}) HU (Z^{r} \otimes \ensuremath{\mathop{\rm Id}\nolimits}) | \tilde{\psi} \rangle\;, \ \ \ \ \ (3)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%7B%5CPr%7D%5E%7B%27%7D%28b%29+%5C%2C%3D%5C%2C+%5Cfrac%7B1%7D%7B4%7D%5Csum_%7Br%5Cin%5C%7B0%2C1%5C%7D%7D+%5Clangle+%5Ctilde%7B%5Cpsi%7D+%7C+%28Z%5Er+%5Cotimes+%5Censuremath%7B%5Cmathop%7B%5Crm+Id%7D%5Cnolimits%7D%29+%28U%5E%5Cdagger%29+%28Z%5Er+%5Cotimes+%5Censuremath%7B%5Cmathop%7B%5Crm+Id%7D%5Cnolimits%7D%29+H+%5Cbig%28+%7C+b+%5Crangle%5C%21%5Clangle+b+%7C%29+%5Cotimes+%5Censuremath%7B%5Cmathop%7B%5Crm+Id%7D%5Cnolimits%7D%5Cbig%29+%28Z%5E%7Br%7D+%5Cotimes+%5Censuremath%7B%5Cmathop%7B%5Crm+Id%7D%5Cnolimits%7D%29+HU+%28Z%5E%7Br%7D+%5Cotimes+%5Censuremath%7B%5Cmathop%7B%5Crm+Id%7D%5Cnolimits%7D%29+%7C+%5Ctilde%7B%5Cpsi%7D+%5Crangle%5C%3B%2C+%5C+%5C+%5C+%5C+%5C+%283%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p><a name="eqprb-3"/></p>
<p>where the outermost <img alt="{Z^r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BZ%5Er%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> were inserted thanks to the first assumption (the collapsing property), and the innermost <img alt="{Z^r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BZ%5Er%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> come from commuting <img alt="{X^r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%5Er%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> past the Hadamard. I should clarify that obtaining <a href="https://mycqstate.wordpress.com/Users/Thomas/Dropbox/www/myCQstate/verification2-clean.html#eqprb-3">(3)</a> formally requires more care. In particular, I made use of computational indistinguishability in an expression that involves a quantity that is hard to compute (the parity <img alt="{x_0+x_1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_0%2Bx_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>). This is illegal, and to work around the difficulty Mahadev has to introduce some additional ingenious manipulations that I am skipping here.</p>
<p>Note the key effect that the random <img alt="{Z^r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BZ%5Er%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> operator has in <a href="https://mycqstate.wordpress.com/Users/Thomas/Dropbox/www/myCQstate/verification2-clean.html#eqprb-3">(3)</a>: it effectively trivializes the action of the prover’s “attack” <img alt="{U}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> on the first qubit <em>with respect to the computational basis</em>. Thus the result of this argument is that we have managed to argue that the verifier’s decoded bit <img alt="{b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> associated with the Hadamard basis is <em>computationally indistinguishable</em> from the outcome of a Hadamard measurement on the state</p>
<p align="center"><img alt="\displaystyle \sigma' = \mbox{\rm Tr}_E\big((I \otimes U_I) | \tilde{\psi} \rangle\langle \tilde{\psi} | (I\otimes U_I)^\dagger+ (X\otimes U_X) | \tilde{\psi} \rangle\langle \tilde{\psi} | (X \otimes U_X)^\dagger \big) \;," class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Csigma%27+%3D+%5Cmbox%7B%5Crm+Tr%7D_E%5Cbig%28%28I+%5Cotimes+U_I%29+%7C+%5Ctilde%7B%5Cpsi%7D+%5Crangle%5Clangle+%5Ctilde%7B%5Cpsi%7D+%7C+%28I%5Cotimes+U_I%29%5E%5Cdagger%2B+%28X%5Cotimes+U_X%29+%7C+%5Ctilde%7B%5Cpsi%7D+%5Crangle%5Clangle+%5Ctilde%7B%5Cpsi%7D+%7C+%28X+%5Cotimes+U_X%29%5E%5Cdagger+%5Cbig%29+%5C%3B%2C&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>where we expanded the first qubit of the unitary <img alt="{U}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> as <img alt="{U = I\otimes U_I + X \otimes U_X + Z\otimes U_Z + XZ \otimes U_{XZ}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU+%3D+I%5Cotimes+U_I+%2B+X+%5Cotimes+U_X+%2B+Z%5Cotimes+U_Z+%2B+XZ+%5Cotimes+U_%7BXZ%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, and <img alt="{E}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BE%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> represents all registers except the first qubit. Note that the second term involves an <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> on the first qubit, which has no effect on a measurement in the Hadamard basis. Thus, <img alt="{\sigma'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csigma%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> can be updated to a state <img alt="{\sigma''}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csigma%27%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> where we have “erased” the <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> operator on the first qubit. Moreover, by definition, a measurement of the first (and only) qubit of <img alt="{\sigma''}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csigma%27%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> in the computational basis yields an outcome distributed exactly as it would on <img alt="{\sigma}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. In particular, it is consistent with the verifier’s decoded bit in the computational basis measurement protocol.</p>
<p>We are done! The state <img alt="{\sigma'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csigma%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is a well-defined single-qubit state such that the distribution of decoded bits recorded by the verifier for either basis is computationally indistinguishable from the distribution of outcomes of a measurement of <img alt="{\sigma'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csigma%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> in the same basis. Note that <img alt="{\sigma'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csigma%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> may not “exist” at any point of the protocol. But this is besides the point: as long as <img alt="{\sigma'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csigma%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is a well-defined quantum state, and the verifier correctly records decoded measurement outcomes, this eventually leads to a valid certificate for the prover’s claim that the XZ Hamiltonian that encodes the computation has low enough energy.</p>
<p>Phew. Catch your breath, read this post again (and please do ask for clarifications as needed), and then move on to the beautiful <a href="https://arxiv.org/abs/1804.01082">paper</a>, whose introduction already has more depth than I could provide here, and whose body fills in all the remaining gaps. (This includes how to deal with states that are more than a single qubit, an issue that my presentation of the single-qubit case may make seem more thorny than it is — in fact, it is possible to express the argument given here in a way that makes it relatively straightforward to extend to multiple qubits, though there are some technical issues, explained in Mahadev’s paper.) And then – use the idea to prove something!</p></div>
    </content>
    <updated>2018-08-06T01:35:21Z</updated>
    <published>2018-08-06T01:35:21Z</published>
    <category term="Conferences"/>
    <category term="QCrypto"/>
    <category term="Simons"/>
    <category term="interactive proofs"/>
    <category term="qpip"/>
    <category term="quantum verification"/>
    <author>
      <name>Thomas</name>
    </author>
    <source>
      <id>https://mycqstate.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://mycqstate.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://mycqstate.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://mycqstate.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://mycqstate.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>In superposition</subtitle>
      <title>MyCQstate</title>
      <updated>2022-04-09T22:48:08Z</updated>
    </source>
  </entry>
</feed>
