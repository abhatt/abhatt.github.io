<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2019-02-07T19:22:01Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/017</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/017" rel="alternate" type="text/html"/>
    <title>TR19-017 |  Fourier bounds and pseudorandom generators for product tests | 

	Chin Ho Lee</title>
    <summary>We study the Fourier spectrum of functions $f\colon \{0,1\}^{mk} \to \{-1,0,1\}$ which can be written as a product of $k$ Boolean functions $f_i$ on disjoint $m$-bit inputs.  We prove that for every positive integer $d$,
\[
  \sum_{S \subseteq [mk]: |S|=d} |\hat{f_S}| = O(m)^d .
\]
Our upper bound is tight up to a constant factor in the $O(\cdot)$.  Our proof builds on a new "level-$d$ inequality" that bounds above $\sum_{|S|=d} \hat{f_S}^2$ for any $[0,1]$-valued function $f$ in terms of its expectation, which may be of independent interest.

As a result, we construct pseudorandom generators for such functions with seed length $\tilde O(m + \log(k/\varepsilon))$, which is optimal up to polynomial factors in $\log m$, $\log\log k$ and $\log\log(1/\varepsilon)$.  Our generator in particular works for the well-studied class of combinatorial rectangles, where in addition we allow the bits to be read in any order.  Even for this special case, previous generators have an extra $\tilde O(\log(1/\varepsilon))$ factor in their seed lengths. 

Using Schur-convexity, we also extend our results to functions $f_i$ whose range is $[-1,1]$.</summary>
    <updated>2019-02-07T14:59:22Z</updated>
    <published>2019-02-07T14:59:22Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-02-07T19:20:41Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/016</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/016" rel="alternate" type="text/html"/>
    <title>TR19-016 |  The hardest halfspace | 

	Alexander A. Sherstov</title>
    <summary>We study the approximation of halfspaces $h:\{0,1\}^n\to\{0,1\}$ in the infinity norm by polynomials and rational functions of any given degree.  Our main result is an explicit construction of the "hardest" halfspace, for which we prove polynomial and rational approximation lower bounds that match the trivial upper bounds achievable for all halfspaces.  This completes a lengthy line of work started by Myhill and Kautz (1961).

As an application, we construct a communication problem with essentially the largest possible gap, of $n$ versus $2^{-\Omega(n)},$ between the sign-rank and discrepancy. Equivalently, our problem exhibits a gap of $\log n$ versus $\Omega(n)$ between the communication complexity with unbounded versus weakly unbounded error, improving quadratically on previous constructions and completing a line of work started by Babai, Frankl, and Simon (FOCS 1986). Our results further generalize to the $k$-party number-on-the-forehead model, where we obtain an explicit separation of $\log n$ versus $\Omega(n/4^{n})$ for communication with unbounded versus weakly unbounded error. This gap is a quadratic improvement on previous work and matches the state of the art for number-on-the-forehead lower bounds.</summary>
    <updated>2019-02-07T14:57:13Z</updated>
    <published>2019-02-07T14:57:13Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-02-07T19:20:41Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-971154734717743655</id>
    <link href="https://blog.computationalcomplexity.org/feeds/971154734717743655/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/02/an-immerman-szelepcsenyi-story.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/971154734717743655" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/971154734717743655" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/02/an-immerman-szelepcsenyi-story.html" rel="alternate" type="text/html"/>
    <title>An Immerman-Szelepcsényi Story</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">As a grad student in the late 80's I had the opportunity to witness many great and often surprising theorems in computational complexity. Let me tell you about one of them, the Immerman-Szelepcsényi result that <a href="https://blog.computationalcomplexity.org/2003/06/foundations-of-complexity-lesson-19.html">nondeterministic space is closed under complement</a>. I wish I had the original emails for this story but instead I'm working from memory and apologies if I get some of the details wrong. I'm expanding from a <a href="https://blog.computationalcomplexity.org/2002/08/last-spring-i-saw-copenhagen-great.html">short version</a> from the early days of this blog.<br/>
<br/>
I started my graduate work at UC Berkeley in 1985 and then moved to MIT in the summer of '86, following my advisor Michael Sipser. In the summer of 1987, Neil Immerman, then at Yale, proved his famous result building on his work in <a href="https://en.wikipedia.org/wiki/Descriptive_complexity_theory">descriptive complexity</a> In those days you didn't email papers, he made copies and sent them by US postal mail to several major researchers in complexity including Sipser. But Sipser was away for the summer, I believe in Russia, and the paper sat in his office.<br/>
<br/>
Immerman also sent the paper to a Berkeley professor, probably Manuel Blum, who gave it to one of his students who decided to speak about the result in a student-led seminar. I forgot who was the student, maybe Moni Naor. I was still on the Berkeley email list so I got the talk announcement and went into complexity ecstasy over the news. I asked Moni (or whomever was giving the talk) if he could tell me details and he sent me a nice write-up of the proof. Given the importance of the result, I sent the proof write-up out to the MIT theory email list.<br/>
<br/>
Guess who was on the MIT theory list? Neil Immerman. Neil wrote back with his own explanation of the proof. Neil explained how it came out of descriptive complexity but as a pure write-up of a proof of the theorem, Moni did an excellent job.<br/>
<br/>
We found out about Robert Szelepcsényi when his paper showed up a few months later in the Bulletin of the European Association for Theoretical Computer Science. Szelepcsényi came to the problem from formal languages, whether context-sensitive languages (nondeterministic linear space) was closed under complement. Szelepcsényi, an undergrad in Slovakia at the time, heard about the problem in a class he took. Szelepcsényi's proof was very similar to Immerman. Szelepcsényi's paper took longer to get to US researchers but likely was proven and written about the same time as Immerman.<br/>
<br/>
Even though both papers were <a href="https://doi.org/10.1137/0217058">published</a> <a href="https://doi.org/10.1007/BF00299636">separately</a> we refer to the result as Immerman-Szelepcsényi and is now just some old important theorem you see in introductory theory classes.</div>
    </content>
    <updated>2019-02-07T12:47:00Z</updated>
    <published>2019-02-07T12:47:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>https://plus.google.com/101693130490639305932</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>https://plus.google.com/101693130490639305932</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-02-07T15:45:01Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/015</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/015" rel="alternate" type="text/html"/>
    <title>TR19-015 |  QMA Lower Bounds for Approximate Counting | 

	William Kretschmer</title>
    <summary>We prove a query complexity lower bound for $QMA$ protocols that solve approximate counting: estimating the size of a set given a membership oracle. This gives rise to an oracle $A$ such that $SBP^A \not\subset QMA^A$, resolving an open problem of Aaronson [2]. Our proof uses the polynomial method to derive a lower bound for the $SBQP$ query complexity of the $AND$ of two approximate counting instances. We use Laurent polynomials as a tool in our proof, showing that the "Laurent polynomial method" can be useful even for problems involving ordinary polynomials.</summary>
    <updated>2019-02-07T08:16:08Z</updated>
    <published>2019-02-07T08:16:08Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-02-07T19:20:41Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.02304</id>
    <link href="http://arxiv.org/abs/1902.02304" rel="alternate" type="text/html"/>
    <title>New Amortized Cell-Probe Lower Bounds for Dynamic Problems</title>
    <feedworld_mtime>1549497600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bhattacharya:Sayan.html">Sayan Bhattacharya</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Henzinger:Monika.html">Monika Henzinger</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Neumann:Stefan.html">Stefan Neumann</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.02304">PDF</a><br/><b>Abstract: </b>We build upon the recent papers by Weinstein and Yu (FOCS'16), Larsen
(FOCS'12), and Clifford et al. (FOCS'15) to present a general framework that
gives amortized lower bounds on the update and query times of dynamic data
structures. Using our framework, we present two concrete results.
</p>
<p>(1) For the dynamic polynomial evaluation problem, where the polynomial is
defined over a finite field of size $n^{1+\Omega(1)}$ and has degree $n$, any
dynamic data structure must either have an amortized update time of
$\Omega((\lg n/\lg \lg n)^2)$ or an amortized query time of $\Omega((\lg n/\lg
\lg n)^2)$.
</p>
<p>(2) For the dynamic online matrix vector multiplication problem, where we get
an $n \times n$ matrix whose entires are drawn from a finite field of size
$n^{\Theta(1)}$, any dynamic data structure must either have an amortized
update time of $\Omega((\lg n/\lg \lg n)^2)$ or an amortized query time of
$\Omega(n \cdot (\lg n/\lg \lg n)^2)$.
</p>
<p>For these two problems, the previous works by Larsen (FOCS'12) and Clifford
et al. (FOCS'15) gave the same lower bounds, but only for worst case update and
query times. Our bounds match the highest unconditional lower bounds known till
date for any dynamic problem in the cell-probe model.
</p></div>
    </summary>
    <updated>2019-02-07T02:22:23Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.02258</id>
    <link href="http://arxiv.org/abs/1902.02258" rel="alternate" type="text/html"/>
    <title>Noise in BosonSampling and the threshold of efficient classical simulability</title>
    <feedworld_mtime>1549497600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Valery Shchesnovich <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.02258">PDF</a><br/><b>Abstract: </b>We study the quantum to classical transition in BosonSampling by analysing
how $N$-boson interference is affected by inevitable noise in an experimental
setup. We adopt the Gaussian noise model of Kalai and Kindler and relate it to
realistic experimental imperfections in BosonSampling. We reveal a connection
between noise in BosonSampling and partial distinguishability of bosons, which
allows us to prove efficient classical simulability of the noisy BosonSampling
model, in the non-collision regime, with the noise amplitude $\epsilon =
\Theta(1)$ as $N\to \infty$. On the other hand, using an equivalent
representation of the noise as losses of bosons compensated by random (dark)
counts of detectors, we prove that the noisy BosonSampling model with noise
amplitude $\epsilon=O(1/N)$ is as hard to simulate classically as the ideal
BosonSampling. We find that the ratio of "noise clicks" (lost bosons
compensated by dark counts) to the number of bosons $N$ vanishes as $N\to
\infty$ in the intermediate regime of noise amplitudes $\epsilon = \omega(1/N)$
and conjecture that such a noisy BosonSampling is also hard to simulate
classically. An extension of the Gaussian noise model beyond the no-collision
regime is given, with some of our results preserving their validity. In
general, our results reveal how imperfections (noise) in an experimental setup
cause transition from quantum to classical behaviour in $N$-boson interference
on a linear unitary network when $N\gg 1$.
</p></div>
    </summary>
    <updated>2019-02-07T02:22:03Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-02-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.02253</id>
    <link href="http://arxiv.org/abs/1902.02253" rel="alternate" type="text/html"/>
    <title>Non-cooperatively assembling large structures: a 2D pumping lemma cannot be as powerful as its 1D counterpart</title>
    <feedworld_mtime>1549497600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Meunier:Pierre=Etienne.html">Pierre-Etienne Meunier</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Regnault:Damien.html">Damien Regnault</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.02253">PDF</a><br/><b>Abstract: </b>We show the first asymptotically efficient constructions in the so-called
"noncooperative planar tile assembly" model.
</p>
<p>Algorithmic self-assembly is the study of the local, distributed,
asynchronous algorithms ran by molecules to self-organise, in particular during
crystal growth. The general cooperative model, also called "temperature 2",
uses synchronisation to simulate Turing machines, build shapes using the
smallest possible amount of tile types, and other algorithmic tasks. However,
in the non-cooperative ("temperature 1") model, the growth process is entirely
asynchronous, and mostly relies on geometry. Even though the model looks like a
generalisation of finite automata to two dimensions, its 3D generalisation is
capable of performing arbitrary (Turing) computation, and of universal
simulations, whereby a single 3D non-cooperative tileset can simulate the
dynamics of all possible 3D non-cooperative systems, up to a constant scaling
factor.
</p>
<p>However, it was shown that the original 2D non-cooperative model is not
capable of universal simulations, and the question of its computational power
is still widely open. Here, we show an unexpected result, namely that this
model can reliably grow assemblies of size Omega(n log n) with only n tile
types, which is the first asymptotically efficient positive construction.
</p></div>
    </summary>
    <updated>2019-02-07T02:21:50Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-02-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.02201</id>
    <link href="http://arxiv.org/abs/1902.02201" rel="alternate" type="text/html"/>
    <title>Toward a Dichotomy for Approximation of $H$-coloring</title>
    <feedworld_mtime>1549497600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rafiey:Akbar.html">Akbar Rafiey</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rafiey:Arash.html">Arash Rafiey</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Santos:Thiago.html">Thiago Santos</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.02201">PDF</a><br/><b>Abstract: </b>The minimum cost homomorphism problem (MinHOM) is a natural optimization
problem for homomorphisms to a fixed (di)graph H. Given an input (di)graph G,
with a cost associated with mapping any vertex of G to any vertex of H, one
seeks to minimize the sum of costs of the assignments over all homomorphisms of
G to H.
</p>
<p>The complexity of this problem is well understood [27], and the class of
digraphs H, for which the MinHOM(H) is polynomial time solvable is a small
subset of all digraphs. Therefore, we are interested in the approximation of
MinHOM within a constant factor. Regarding digraphs, MinHOM(H) is not
approximable if H contains a digraph asteroidal triple (DAT). We take a major
step toward a dichotomy classification of approximable cases. We give a
dichotomy classification for approximating the MinHOM(H) when H is a graph. In
the digraphs case, we provide constant factor approximation algorithms for two
important classes of digraphs, namely bi-arc digraphs (digraphs with
min-ordering), and k-arc digraphs (with extended min-ordering). Specifically,
we show that:
</p>
<p>Dichotomy for Graphs: MinHOM(H) has a $2|V(H)|$-approximation algorithm if
graph H admits a conservative majority polymorphims (i.e. H is a bi-arc graph);
otherwise, it is inapproximable;
</p>
<p>MinHOM(H) has a $|V(H)|^2$-approximation algorithm if H is a bi-arc digraph;
</p>
<p>MinHOM(H) has a $|V(H)|^2$-approximation algorithm if H is a k-arc digraph.
</p>
<p>We draw a conclusion, by showing why these results are important in closing
the classification, as well as, providing a road map in achieving such a
classification. Our constant factors depend on the size of H. However, the
implementation of our algorithms provides a much better approximation ratio. It
leaves open to investigate a classification of digraphs H, where MinHOM(H)
admits a constant approximation algorithm that is independent of $|V(H)|$.
</p></div>
    </summary>
    <updated>2019-02-07T02:31:33Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.02187</id>
    <link href="http://arxiv.org/abs/1902.02187" rel="alternate" type="text/html"/>
    <title>Top Tree Compression of Tries</title>
    <feedworld_mtime>1549497600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bille:Philip.html">Philip Bille</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/G=oslash=rtz:Inge_Li.html">Inge Li Gørtz</a>, Paweł Gawrychowski, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Landau:Gad_M=.html">Gad M. Landau</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Weimann:Oren.html">Oren Weimann</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.02187">PDF</a><br/><b>Abstract: </b>We present a compressed representation of tries based on top tree compression
[ICALP 2013] that works on a standard, comparison-based, pointer machine model
of computation and supports efficient prefix search queries. Namely, we show
how to preprocess a set of strings of total length $n$ over an alphabet of size
$\sigma$ into a compressed data structure of worst-case optimal size
$O(n/\log_\sigma n)$ that given a pattern string $P$ of length $m$ determines
if $P$ is a prefix of one of the strings in time $O(\min(m\log \sigma,m + \log
n))$. We show that this query time is in fact optimal regardless of the size of
the data structure.
</p>
<p>Existing solutions either use $\Omega(n)$ space or use word RAM bit tricks
(i.e. do not work on a pointer machine). Our result is the first solution on a
pointer machine that achieves worst-case $o(n)$ space. Along the way, we
develop several interesting data structures that work on a pointer machine and
are of independent interest. These include an optimal data structure for random
access to a grammar-compressed string and an optimal data structure for a
variant of the level ancestor problem.
</p></div>
    </summary>
    <updated>2019-02-07T02:27:55Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.02159</id>
    <link href="http://arxiv.org/abs/1902.02159" rel="alternate" type="text/html"/>
    <title>Firefighting on Trees</title>
    <feedworld_mtime>1549497600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Coupechoux:Pierre.html">Pierre Coupechoux</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Demange:Marc.html">Marc Demange</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Ellison:David.html">David Ellison</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jouve:Bertrand.html">Bertrand Jouve</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.02159">PDF</a><br/><b>Abstract: </b>In the Firefighter problem, introduced by Hartnell in 1995, a fire spreads
through a graph while a player chooses which vertices to protect in order to
contain it. In this paper, we focus on the case of trees and we consider as
well the Fractional Firefighter game where the amount of protection allocated
to a vertex lies between 0 and 1. While most of the work in this area deals
with a constant amount of firefighters available at each turn, we consider
three research questions which arise when including the sequence of
firefighters as part of the instance. We first introduce the online version of
both Firefighter and Fractional Firefighter, in which the number of
firefighters available at each turn is revealed over time. We show that a
greedy algorithm on finite trees is 1/2-competitive for both online versions,
which generalises a result previously known for special cases of Firefighter.
We also show that the optimal competitive ratio of online Firefighter ranges
between 1/2 and the inverse of the golden ratio. Next, given two firefighter
sequences, we discuss sufficient conditions for the existence of an infinite
tree that separates them, in the sense that the fire can be contained with one
sequence but not with the other. To this aim, we study a new purely numerical
game called targeting game. Finally, we give sufficient conditions for the fire
to be contained, expressed as the asymptotic comparison of the number of
firefighters and the size of the tree levels.
</p></div>
    </summary>
    <updated>2019-02-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.02123</id>
    <link href="http://arxiv.org/abs/1902.02123" rel="alternate" type="text/html"/>
    <title>Exact Optimization via Sums of Nonnegative Circuits and Sums of AM/GM Exponentials</title>
    <feedworld_mtime>1549497600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Magron:Victor.html">Victor Magron</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Seidler:Henning.html">Henning Seidler</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wolff:Timo_de.html">Timo de Wolff</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.02123">PDF</a><br/><b>Abstract: </b>We provide two hybrid numeric-symbolic optimization algorithms, computing
exact sums of nonnegative circuits (SONC) and sums of
arithmetic-geometric-exponentials (SAGE) decompositions. Moreover, we provide a
hybrid numeric-symbolic decision algorithm for polynomials lying in the
interior of the SAGE cone. Each framework, inspired by previous contributions
of Parrilo and Peyrl, is a rounding-projection procedure.
</p>
<p>For a polynomial lying in the interior of the SAGE cone, we prove that the
decision algorithm terminates within a number of arithmetic operations, which
is polynomial in the degree and number of terms of the input, and singly
exponential in the number of variables. We also provide experimental
comparisons regarding the implementation of the two optimization algorithms.
</p></div>
    </summary>
    <updated>2019-02-07T02:22:05Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-02-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.01999</id>
    <link href="http://arxiv.org/abs/1902.01999" rel="alternate" type="text/html"/>
    <title>Testing Markov Chains without Hitting</title>
    <feedworld_mtime>1549497600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cherapanamjeri:Yeshwanth.html">Yeshwanth Cherapanamjeri</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bartlett:Peter_L=.html">Peter L. Bartlett</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.01999">PDF</a><br/><b>Abstract: </b>We study the problem of identity testing of markov chains. In this setting,
we are given access to a single trajectory from a markov chain with unknown
transition matrix $Q$ and the goal is to determine whether $Q = P$ for some
known matrix $P$ or $\text{Dist}(P, Q) \geq \epsilon$ where $\text{Dist}$ is
suitably defined. In recent work by Daskalakis, Dikkala and Gravin, 2018, it
was shown that it is possible to distinguish between the two cases provided the
length of the observed trajectory is at least super-linear in the hitting time
of $P$ which may be arbitrarily large.
</p>
<p>In this paper, we propose an algorithm that avoids this dependence on hitting
time thus enabling efficient testing of markov chains even in cases where it is
infeasible to observe every state in the chain. Our algorithm is based on
combining classical ideas from approximation algorithms with techniques for the
spectral analysis of markov chains.
</p></div>
    </summary>
    <updated>2019-02-07T02:26:26Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.01998</id>
    <link href="http://arxiv.org/abs/1902.01998" rel="alternate" type="text/html"/>
    <title>Fast Mean Estimation with Sub-Gaussian Rates</title>
    <feedworld_mtime>1549497600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cherapanamjeri:Yeshwanth.html">Yeshwanth Cherapanamjeri</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Flammarion:Nicolas.html">Nicolas Flammarion</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bartlett:Peter_L=.html">Peter L. Bartlett</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.01998">PDF</a><br/><b>Abstract: </b>We propose an estimator for the mean of a random vector in $\mathbb{R}^d$
that can be computed in time $O(n^4+n^2d)$ for $n$ i.i.d.~samples and that has
error bounds matching the sub-Gaussian case. The only assumptions we make about
the data distribution are that it has finite mean and covariance; in
particular, we make no assumptions about higher-order moments. Like the
polynomial time estimator introduced by Hopkins, 2018, which is based on the
sum-of-squares hierarchy, our estimator achieves optimal statistical efficiency
in this challenging setting, but it has a significantly faster runtime and a
simpler analysis.
</p></div>
    </summary>
    <updated>2019-02-07T02:25:11Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.01960</id>
    <link href="http://arxiv.org/abs/1902.01960" rel="alternate" type="text/html"/>
    <title>On the Hardness and Inapproximability of Recognizing Wheeler Graphs</title>
    <feedworld_mtime>1549497600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gibney:Daniel.html">Daniel Gibney</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Thankachan:Sharma_V=.html">Sharma V. Thankachan</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.01960">PDF</a><br/><b>Abstract: </b>In recent years several compressed indexes based on variants of the
Borrows-Wheeler transformation have been introduced. Some of these index
structures far more complex than a single string, as was originally done with
the FM-index [Ferragina and Manzini, J. ACM 2005]. As such, there has been an
effort to better understand under which conditions such an indexing scheme is
possible. This led to the introduction of Wheeler graphs [Gagie it et al.,
Theor. Comput. Sci., 2017]. A Wheeler graph is a directed graph with edge
labels which satisfies two simple axioms. Wheeler graphs can be indexed in a
way which is space efficient and allows for fast traversal. Gagie et al. showed
that de Bruijn graphs, generalized compressed suffix arrays, and several other
BWT related structures can be represented as Wheeler graphs. Here we answer the
open question of whether or not there exists an efficient algorithm for
recognizing if a graph is a Wheeler graph. We demonstrate:(i) Recognizing if a
graph is a Wheeler graph is NP-complete for any edge label alphabet of size
$\sigma \geq 2$, even for DAGs. It can be solved in linear time for $\sigma
=1$; (ii) An optimization variant called Wheeler Graph Violation (WGV) which
aims to remove the minimum number of edges needed to obtain a Wheeler graph is
APX-hard, even for DAGs. Hence, unless P = NP, there exists constant $C &gt; 1$
such that there is no $C$-approximation algorithm. We show conditioned on the
Unique Games Conjecture, for every constant $C \geq 1$, it is NP-hard to find a
$C$-approximation to WGV; (iii) The Wheeler Subgraph problem (WS) which aims to
find the largest Wheeler subgraph is in APX for $\sigma=O(1)$; (iv) For the
above problems there exist efficient exponential time exact algorithms, relying
on graph isomorphism being computed in strictly sub-exponential time; (v) A
class of graphs where the recognition problem is polynomial time solvable.
</p></div>
    </summary>
    <updated>2019-02-07T02:20:39Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-02-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.01896</id>
    <link href="http://arxiv.org/abs/1902.01896" rel="alternate" type="text/html"/>
    <title>A Composable Coreset for k-Center in Doubling Metrics</title>
    <feedworld_mtime>1549497600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Aghamolaei:Sepideh.html">Sepideh Aghamolaei</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Ghodsi:Mohammad.html">Mohammad Ghodsi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.01896">PDF</a><br/><b>Abstract: </b>A set of points $P$ in a metric space and a constant integer $k$ are given.
The $k$-center problem finds $k$ points as \textit{centers} among $P$, such
that the maximum distance of any point of $P$ to their closest centers $(r)$ is
minimized.
</p>
<p>Doubling metrics are metric spaces in which for any $r$, a ball of radius $r$
can be covered using a constant number of balls of radius $r/2$. Fixed
dimensional Euclidean spaces are doubling metrics. The lower bound on the
approximation factor of $k$-center is $1.822$ in Euclidean spaces, however,
$(1+\epsilon)$-approximation algorithms with exponential dependency on
$\frac{1}{\epsilon}$ and $k$ exist.
</p>
<p>For a given set of sets $P_1,\ldots,P_L$, a \textit{composable coreset}
independently computes subsets $C_1\subset P_1, \ldots, C_L\subset P_L$, such
that $\cup_{i=1}^L C_i$ contains an approximation of a measure of the set
$\cup_{i=1}^L P_i$.
</p>
<p>We introduce a $(1+\epsilon)$-approximation composable coreset for
$k$-center, which in doubling metrics has size sublinear in $|P|$. This results
in a $(2+\epsilon)$-approximation algorithm for $k$-center in MapReduce with a
constant number of rounds in doubling metrics for any $\epsilon&gt;0$ and
sublinear communications, which is based on parametric pruning.
</p>
<p>We prove the exponential nature of the trade-off between the number of
centers $(k)$ and the radius $(r)$, and give a composable coreset for a related
problem called dual clustering. Also, we give a new version of the parametric
pruning algorithm with $O(\frac{nk}{\epsilon})$ running time, $O(n)$ space and
$2+\epsilon$ approximation factor for metric $k$-center.
</p></div>
    </summary>
    <updated>2019-02-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-02-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.01874</id>
    <link href="http://arxiv.org/abs/1902.01874" rel="alternate" type="text/html"/>
    <title>Average-case complexity of a branch-and-bound algorithm for min dominating set</title>
    <feedworld_mtime>1549497600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Denat:Tom.html">Tom Denat</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Harutyunyan:Ararat.html">Ararat Harutyunyan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Paschos:Vangelis_Th=.html">Vangelis Th. Paschos</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.01874">PDF</a><br/><b>Abstract: </b>The average-case complexity of a branch-and-bound algorithms for Minimum
Dominating Set problem in random graphs in the G(n,p) model is studied. We
identify phase transitions between subexponential and exponential average-case
complexities, depending on the growth of the probability p with respect to the
number n of nodes.
</p></div>
    </summary>
    <updated>2019-02-07T02:30:14Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.01873</id>
    <link href="http://arxiv.org/abs/1902.01873" rel="alternate" type="text/html"/>
    <title>Dynamic hierarchies in temporal directed networks</title>
    <feedworld_mtime>1549497600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tatti:Nikolaj.html">Nikolaj Tatti</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.01873">PDF</a><br/><b>Abstract: </b>The outcome of interactions in many real-world systems can be often explained
by a hierarchy between the participants. Discovering hierarchy from a given
directed network can be formulated as follows: partition vertices into levels
such that, ideally, there are only forward edges, that is, edges from upper
levels to lower levels. In practice, the ideal case is impossible, so instead
we minimize some penalty function on the backward edges. One practical option
for such a penalty is agony, where the penalty depends on the severity of the
violation. In this paper we extend the definition of agony to temporal
networks. In this setup we are given a directed network with time stamped
edges, and we allow the rank assignment to vary over time. We propose 2
strategies for controlling the variation of individual ranks. In our first
variant, we penalize the fluctuation of the rankings over time by adding a
penalty directly to the optimization function. In our second variant we allow
the rank change at most once. We show that the first variant can be solved
exactly in polynomial time while the second variant is NP-hard, and in fact
inapproximable. However, we develop an iterative method, where we first fix the
change point and optimize the ranks, and then fix the ranks and optimize the
change points, and reiterate until convergence. We show empirically that the
algorithms are reasonably fast in practice, and that the obtained rankings are
sensible.
</p></div>
    </summary>
    <updated>2019-02-07T02:27:35Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=15634</id>
    <link href="https://rjlipton.wordpress.com/2019/02/06/an-old-but-cool-result/" rel="alternate" type="text/html"/>
    <title>An Old But Cool Result</title>
    <summary>Solving a type of Fermat Equation Leo Moser was a mathematician who worked on a very varied set of problems. He for example raised a question about “worms,” and invented a notation for huge numbers. Today I want to talk about one of his results with a very short proof. No, it is not about […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p/><p>
<font color="#0044cc"><br/>
<em>Solving a type of Fermat Equation</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2019/02/06/an-old-but-cool-result/unknown-117/" rel="attachment wp-att-15639"><img alt="" class="alignright size-full wp-image-15639" src="https://rjlipton.files.wordpress.com/2019/02/unknown.jpeg?w=600"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2"/></td>
</tr>
</tbody>
</table>
<p>
Leo Moser was a <a href="https://en.wikipedia.org/wiki/Leo_Moser">mathematician</a> who worked on a very varied set of problems. He for example raised a question about “worms,” and invented a notation for huge <a href="https://en.wikipedia.org/wiki/Steinhaus-Moser_notation">numbers</a>.</p>
<p>
Today I want to talk about one of his results with a very short proof.</p>
<p>
No, it is not about worms. That is a <a href="https://en.wikipedia.org/wiki/Moser%27s_worm_problem">question</a> in discrete geometry that is still open I believe: “What is the region of smallest area which can accommodate every planar arc of length one?” The region must be able to hold the arc inside but the curve can be moved and rotated to allow it to fit. A disk of diameter <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/> works and has area about <img alt="{ 0.78}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+0.78%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ 0.78}"/>. It is possible to do much better and get around <img alt="{ 0.27}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+0.27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ 0.27}"/>. </p>
<p><a href="https://rjlipton.wordpress.com/2019/02/06/an-old-but-cool-result/worm3/" rel="attachment wp-att-15636"><img alt="" class="aligncenter size-medium wp-image-15636" height="143" src="https://rjlipton.files.wordpress.com/2019/02/worm3.png?w=300&amp;h=143" width="300"/></a></p>
<p>See this <a href="https://www.nada.kth.se/~johanh/snakes.pdf">paper</a> for some additional details.</p>
<p>
No, it is not about a conjecture of Paul Erdős See <a href="https://arxiv.org/pdf/1011.2956.pdf">this</a> for a great paper on this result: </p>
<blockquote><p><b>Theorem 1</b> <em> Suppose that 	</em></p><em>
<p align="center"><img alt="\displaystyle  1^{k} + 2^{k} + \cdots + (m-1)^{k} = m^{k}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++1%5E%7Bk%7D+%2B+2%5E%7Bk%7D+%2B+%5Ccdots+%2B+%28m-1%29%5E%7Bk%7D+%3D+m%5E%7Bk%7D.+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="\displaystyle  1^{k} + 2^{k} + \cdots + (m-1)^{k} = m^{k}. "/></p>
<p>Then any <img alt="{(m,k)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28m%2Ck%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{(m,k)}"/> solution in integers with <img alt="{k \ge 2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk+%5Cge+2%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{k \ge 2}"/> must have 	</p>
<p align="center"><img alt="\displaystyle  m &gt; 10^{10^{6}}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++m+%3E+10%5E%7B10%5E%7B6%7D%7D.+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="\displaystyle  m &gt; 10^{10^{6}}. "/></p>
</em><p><em/>
</p></blockquote>
<p>Erdős conjectured there are no solutions at all. It is easy to check that for <img alt="{k=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k=1}"/> the unique solution is a bit smaller: 	</p>
<p align="center"><img alt="\displaystyle  1 + 2 = 3." class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++1+%2B+2+%3D+3.&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  1 + 2 = 3."/></p>
<p>
</p><p/><h2> The Result </h2><p/>
<p/><p>
Yes, it is about the solution to a natural family of Diophantine equations. This result of Moser comes from an old paper of his. The result can be found on the wonderful blog called <a href="https://www.cut-the-knot.org/arithmetic/algebra/TwoParameterFermat.shtml">cut-the-knot</a> written by Alexander Bogomolny.</p>
<p>
The question considered by Moser is simple to state: </p>
<blockquote><p><b> </b> <em> Consider the equation over the integers <img alt="{x^{a} + y^{b} = z^{c}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%5E%7Ba%7D+%2B+y%5E%7Bb%7D+%3D+z%5E%7Bc%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{x^{a} + y^{b} = z^{c}}"/> where <img alt="{a, b, c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%2C+b%2C+c%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{a, b, c}"/> are fixed values that are relatively prime. Show that there are infinitely many integer solutions. </em>
</p></blockquote>
<p/><p>
The surprise, to me, is that this equation always has integer solutions. I thought about it for a bit and had no idea how to even start.</p>
<p>
The solution is as follows. The initial insight is that the restriction on the exponents implies that there are integers <img alt="{m, n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%2C+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m, n}"/> so that <img alt="{abm + 1 = cn}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Babm+%2B+1+%3D+cn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{abm + 1 = cn}"/>. </p>
<p>
Wait a minute. We must be careful by what we mean by “the values of <img alt="{a,b,c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%2Cb%2Cc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a,b,c}"/> are relatively prime.” We need more than the greatest common divisor (GCD) of <img alt="{a,b,c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%2Cb%2Cc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a,b,c}"/> is <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>. We need that <img alt="{ab}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bab%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ab}"/> and <img alt="{c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c}"/> are relatively prime. Note that <img alt="{6,10,15}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B6%2C10%2C15%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{6,10,15}"/> have GCD equal to <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/> but no matter which of the triple is “<img alt="{c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c}"/>” we cannot find the needed <img alt="{m,n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%2Cn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m,n}"/>: 	</p>
<p align="center"><img alt="\displaystyle  (6\cdot 10,15) &gt; 1, (10\cdot 15, 6)&gt;1, (15,6 \cdot 10) &gt; 1. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%286%5Ccdot+10%2C15%29+%3E+1%2C+%2810%5Ccdot+15%2C+6%29%3E1%2C+%2815%2C6+%5Ccdot+10%29+%3E+1.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  (6\cdot 10,15) &gt; 1, (10\cdot 15, 6)&gt;1, (15,6 \cdot 10) &gt; 1. "/></p>
<p>I thank Subrahmanyam Kalyanasundaram for catching this.</p>
<p>
The next idea is not to look for a single set of solutions but rather to find a parametrized solution. That is try to find expressions for <img alt="{x,y,z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%2Cy%2Cz%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x,y,z}"/> that depend on some variables <img alt="{u,v}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu%2Cv%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u,v}"/> so that for all <img alt="{u,v}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu%2Cv%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u,v}"/> the equation is satisfied. </p>
<p>
Then set 	</p>
<p align="center"><img alt="\displaystyle  x = u^{bm}(u^{abm} + v^{abm})^{bm}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++x+%3D+u%5E%7Bbm%7D%28u%5E%7Babm%7D+%2B+v%5E%7Babm%7D%29%5E%7Bbm%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  x = u^{bm}(u^{abm} + v^{abm})^{bm}. "/></p>
<p align="center"><img alt="\displaystyle  y = v^{am}(u^{abm} + v^{abm})^{am}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++y+%3D+v%5E%7Bam%7D%28u%5E%7Babm%7D+%2B+v%5E%7Babm%7D%29%5E%7Bam%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  y = v^{am}(u^{abm} + v^{abm})^{am}. "/></p>
<p>Note as <img alt="{u,v}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu%2Cv%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u,v}"/> vary over integers the values of <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> and <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y}"/> vary over integers too. The claim is that this is a parameterization of the equation. Let’s see why. We need to figure out what <img alt="{x^{a} + y^{b}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%5E%7Ba%7D+%2B+y%5E%7Bb%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x^{a} + y^{b}}"/> is equal to. It looks a bit nasty but it is not. Let <img alt="{W = u^{abm} + v^{abm}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BW+%3D+u%5E%7Babm%7D+%2B+v%5E%7Babm%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{W = u^{abm} + v^{abm}}"/>. Then 	</p>
<p align="center"><img alt="\displaystyle  x = u^{bm}W^{bm}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++x+%3D+u%5E%7Bbm%7DW%5E%7Bbm%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  x = u^{bm}W^{bm}. "/></p>
<p align="center"><img alt="\displaystyle  y = v^{am}W^{am}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++y+%3D+v%5E%7Bam%7DW%5E%7Bam%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  y = v^{am}W^{am}. "/></p>
<p>So <img alt="{x^{a} + y^{b} }" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%5E%7Ba%7D+%2B+y%5E%7Bb%7D+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x^{a} + y^{b} }"/> is 	</p>
<p align="center"><img alt="\displaystyle  u^{abm} W^{abm} + v^{abm}W^{abm}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++u%5E%7Babm%7D+W%5E%7Babm%7D+%2B+v%5E%7Babm%7DW%5E%7Babm%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  u^{abm} W^{abm} + v^{abm}W^{abm}. "/></p>
<p>Which magically is 	</p>
<p align="center"><img alt="\displaystyle  W^{abm}(u^{abm} + v^{abm}) = W^{abm+1}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++W%5E%7Babm%7D%28u%5E%7Babm%7D+%2B+v%5E%7Babm%7D%29+%3D+W%5E%7Babm%2B1%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  W^{abm}(u^{abm} + v^{abm}) = W^{abm+1}. "/></p>
<p>Thus setting 	</p>
<p align="center"><img alt="\displaystyle  z = W^{n} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++z+%3D+W%5E%7Bn%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  z = W^{n} "/></p>
<p>implies that 	</p>
<p align="center"><img alt="\displaystyle  x^{a} + y^{b} = W^{abm+1} = W^{cn} = (W^{n})^{c} = z^{c}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++x%5E%7Ba%7D+%2B+y%5E%7Bb%7D+%3D+W%5E%7Babm%2B1%7D+%3D+W%5E%7Bcn%7D+%3D+%28W%5E%7Bn%7D%29%5E%7Bc%7D+%3D+z%5E%7Bc%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  x^{a} + y^{b} = W^{abm+1} = W^{cn} = (W^{n})^{c} = z^{c}. "/></p>
<p>Very neat. By the way we do need to note that as <img alt="{u}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u}"/> and <img alt="{v}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bv%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{v}"/> run through integers the values of <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> and <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y}"/> and <img alt="{z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bz%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{z}"/> vary enough to get an infinite number of solutions. A simple growth argument shows that this is true.</p>
<p>
The key trick was to <b>not</b> use a standard idea and apply the binomial theorem and expand 	</p>
<p align="center"><img alt="\displaystyle  (u^{abm} + v^{abm})^{bm}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%28u%5E%7Babm%7D+%2B+v%5E%7Babm%7D%29%5E%7Bbm%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  (u^{abm} + v^{abm})^{bm}. "/></p>
<p>My algebra DNA suggests that expanding such an expression is often a good idea. Here it would lead to a mess. This is a case where using the binomial expansion does not work.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
I really like Moser’s clever solution to the diophantine equation 	</p>
<p align="center"><img alt="\displaystyle  x^{a} + y^{b} = z^{c}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++x%5E%7Ba%7D+%2B+y%5E%7Bb%7D+%3D+z%5E%7Bc%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  x^{a} + y^{b} = z^{c}. "/></p>
<p>Note that it must fail when <img alt="{a=b=c=p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%3Db%3Dc%3Dp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a=b=c=p}"/> for <img alt="{p&gt;2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%3E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p&gt;2}"/> by the famous solution to the original Fermat equation. </p></font></font></div>
    </content>
    <updated>2019-02-06T12:57:11Z</updated>
    <published>2019-02-06T12:57:11Z</published>
    <category term="Oldies"/>
    <category term="Open Problems"/>
    <category term="People"/>
    <category term="Proofs"/>
    <category term="Diophantine"/>
    <category term="Fermat"/>
    <category term="worm problem"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-02-07T19:20:48Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>http://corner.mimuw.edu.pl/?p=1062</id>
    <link href="http://corner.mimuw.edu.pl/?p=1062" rel="alternate" type="text/html"/>
    <title>HALG 2019 - Call For Submissions of Short Contributed Presentations</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">The HALG 2019 conference seeks submissions for contributed presentations. Each presentation is expected to consist of a poster and a short talk (an invitation to the poster). There will be no conference proceedings, hence presenting work already published at a … <a href="http://corner.mimuw.edu.pl/?p=1062">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The HALG 2019 conference seeks submissions for contributed presentations. Each presentation is expected to consist of a poster and a short talk (an invitation to the poster). There will be no conference proceedings, hence presenting work already published at a different venue or journal (or to be submitted there) is welcome.</p>
<p>If you would like to present your results at HALG 2019, please submit their details the abstract of the talk or the contribution of the poster via EasyChair: <a href="https://easychair.org/conferences/?conf=halg2019" rel="noopener noreferrer" target="_blank">https://easychair.org/conferences/?conf=halg2019</a></p>
<p>The abstract should include (when relevant) information where the results have been published/accepted (e.g., conference), and where they are publicly available (e.g., arXiv). All submissions will be reviewed by the program committee, giving priority to new work not formally published yet, and to papers published in 2018 or later.</p>
<p>Submissions deadline: March 15th, 2019.<br/>
Late submissions will be accepted subject to space constraints.</p></div>
    </content>
    <updated>2019-02-06T11:41:10Z</updated>
    <published>2019-02-06T11:41:10Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>sank</name>
    </author>
    <source>
      <id>http://corner.mimuw.edu.pl</id>
      <link href="http://corner.mimuw.edu.pl/?feed=rss2" rel="self" type="application/atom+xml"/>
      <link href="http://corner.mimuw.edu.pl" rel="alternate" type="text/html"/>
      <subtitle>University of Warsaw</subtitle>
      <title>Banach's Algorithmic Corner</title>
      <updated>2019-02-06T23:36:23Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.01832</id>
    <link href="http://arxiv.org/abs/1902.01832" rel="alternate" type="text/html"/>
    <title>Inferring the strength of social ties: a community-driven approach</title>
    <feedworld_mtime>1549411200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rozenshtein:Polina.html">Polina Rozenshtein</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tatti:Nikolaj.html">Nikolaj Tatti</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gionis:Aristides.html">Aristides Gionis</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.01832">PDF</a><br/><b>Abstract: </b>Online social networks are growing and becoming denser. The social
connections of a given person may have very high variability: from close
friends and relatives to acquaintances to people who hardly know. Inferring the
strength of social ties is an important ingredient for modeling the interaction
of users in a network and understanding their behavior. Furthermore, the
problem has applications in computational social science, viral marketing, and
people recommendation.
</p>
<p>In this paper we study the problem of inferring the strength of social ties
in a given network. Our work is motivated by a recent approach [27], which
leverages the strong triadic closure (STC) principle, a hypothesis rooted in
social psychology [13]. To guide our inference process, in addition to the
network structure, we also consider as input a collection of tight communities.
Those are sets of vertices that we expect to be connected via strong ties. Such
communities appear in different situations, e.g., when being part of a
community implies a strong connection to one of the existing members.
</p>
<p>We consider two related problem formalizations that reflect the assumptions
of our setting: small number of STC violations and strong-tie connectivity in
the input communities. We show that both problem formulations are NP-hard. We
also show that one problem formulation is hard to approximate, while for the
second we develop an algorithm with approximation guarantee. We validate the
proposed method on real-world datasets by comparing with baselines that
optimize STC violations and community connectivity separately.
</p></div>
    </summary>
    <updated>2019-02-06T23:22:58Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.01829</id>
    <link href="http://arxiv.org/abs/1902.01829" rel="alternate" type="text/html"/>
    <title>Hierarchical Matrix Operations on GPUs: Matrix-Vector Multiplication and Compression</title>
    <feedworld_mtime>1549411200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Boukaram:Wajih_Halim.html">Wajih Halim Boukaram</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Turkiyyah:George.html">George Turkiyyah</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Keyes:David_E=.html">David E. Keyes</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.01829">PDF</a><br/><b>Abstract: </b>Hierarchical matrices are space and time efficient representations of dense
matrices that exploit the low rank structure of matrix blocks at different
levels of granularity. The hierarchically low rank block partitioning produces
representations that can be stored and operated on in near-linear complexity
instead of the usual polynomial complexity of dense matrices. In this paper, we
present high performance implementations of matrix vector multiplication and
compression operations for the $\mathcal{H}^2$ variant of hierarchical matrices
on GPUs. This variant exploits, in addition to the hierarchical block
partitioning, hierarchical bases for the block representations and results in a
scheme that requires only $O(n)$ storage and $O(n)$ complexity for the mat-vec
and compression kernels. These two operations are at the core of algebraic
operations for hierarchical matrices, the mat-vec being a ubiquitous operation
in numerical algorithms while compression/recompression represents a key
building block for other algebraic operations, which require periodic
recompression during execution. The difficulties in developing efficient GPU
algorithms come primarily from the irregular tree data structures that underlie
the hierarchical representations, and the key to performance is to recast the
computations on flattened trees in ways that allow batched linear algebra
operations to be performed. This requires marshaling the irregularly laid out
data in a way that allows them to be used by the batched routines. Marshaling
operations only involve pointer arithmetic with no data movement and as a
result have minimal overhead. Our numerical results on covariance matrices from
2D and 3D problems from spatial statistics show the high efficiency our
routines achieve---over 550GB/s for the bandwidth-limited mat-vec and over
850GFLOPS/s in sustained performance for the compression on the P100 Pascal
GPU.
</p></div>
    </summary>
    <updated>2019-02-06T23:28:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.01814</id>
    <link href="http://arxiv.org/abs/1902.01814" rel="alternate" type="text/html"/>
    <title>A non-iterative method for robustly computing the intersections between a line and a curve or surface</title>
    <feedworld_mtime>1549411200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/x/Xiao:Xiao.html">Xiao Xiao</a>, Laurent Buse, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cirak:Fehmi.html">Fehmi Cirak</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.01814">PDF</a><br/><b>Abstract: </b>The need to compute the intersections between a line and a high-order curve
or surface arises in a large number of finite element applications. Such
intersection problems are easy to formulate but hard to solve robustly. We
introduce a non-iterative method for computing intersections by solving a
matrix singular value decomposition (SVD) and an eigenvalue problem. That is,
all intersection points and their parametric coordinates are determined in
one-shot using only standard linear algebra techniques available in most
software libraries. As a result, the introduced technique is far more robust
than the widely used Newton-Raphson iteration or its variants. The maximum size
of the considered matrices depends on the polynomial degree $q$ of the shape
functions and is $2q \times 3q$ for curves and $6 q^2 \times 8 q^2$ for
surfaces. The method has its origin in algebraic geometry and has here been
considerably simplified with a view to widely used high-order finite elements.
In addition, the method is derived from a purely linear algebra perspective
without resorting to algebraic geometry terminology. A complete implementation
is available from <a href="http://bitbucket.org/nitro-project/.">this http URL</a>
</p></div>
    </summary>
    <updated>2019-02-06T23:33:26Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-02-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.01765</id>
    <link href="http://arxiv.org/abs/1902.01765" rel="alternate" type="text/html"/>
    <title>The Hardest Halfspace</title>
    <feedworld_mtime>1549411200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sherstov:Alexander_A=.html">Alexander A. Sherstov</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.01765">PDF</a><br/><b>Abstract: </b>We study the approximation of halfspaces $h:\{0,1\}^n\to\{0,1\}$ in the
infinity norm by polynomials and rational functions of any given degree. Our
main result is an explicit construction of the "hardest" halfspace, for which
we prove polynomial and rational approximation lower bounds that match the
trivial upper bounds achievable for all halfspaces. This completes a lengthy
line of work started by Myhill and Kautz (1961).
</p>
<p>As an application, we construct a communication problem that achieves
essentially the largest possible separation, of $O(n)$ versus $2^{-\Omega(n)},$
between the sign-rank and discrepancy. Equivalently, our problem exhibits a gap
of $\log n$ versus $\Omega(n)$ between the communication complexity with
unbounded versus weakly unbounded error, improving quadratically on previous
constructions and completing a line of work started by Babai, Frankl, and Simon
(FOCS 1986). Our results further generalize to the $k$-party
number-on-the-forehead model, where we obtain an explicit separation of $\log
n$ versus $\Omega(n/4^{n})$ for communication with unbounded versus weakly
unbounded error. This gap is a quadratic improvement on previous work and
matches the state of the art for number-on-the-forehead lower bounds.
</p></div>
    </summary>
    <updated>2019-02-06T23:22:21Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-02-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.01745</id>
    <link href="http://arxiv.org/abs/1902.01745" rel="alternate" type="text/html"/>
    <title>Hamiltonicity below Dirac's condition</title>
    <feedworld_mtime>1549411200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jansen:Bart_M=_P=.html">Bart M. P. Jansen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kozma:L=aacute=szl=oacute=.html">László Kozma</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nederlof:Jesper.html">Jesper Nederlof</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.01745">PDF</a><br/><b>Abstract: </b>Dirac's theorem (1952) is a classical result of graph theory, stating that an
$n$-vertex graph ($n \geq 3$) is Hamiltonian if every vertex has degree at
least $n/2$. Both the value $n/2$ and the requirement for every vertex to have
high degree are necessary for the theorem to hold.
</p>
<p>In this work we give efficient algorithms for determining Hamiltonicity when
either of the two conditions are relaxed. More precisely, we show that the
Hamiltonian cycle problem can be solved in time $c^k \cdot n^{O(1)}$, for some
fixed constant $c$, if at least $n-k$ vertices have degree at least $n/2$, or
if all vertices have degree at least $n/2-k$. The running time is, in both
cases, asymptotically optimal, under the exponential-time hypothesis (ETH).
</p>
<p>The results extend the range of tractability of the Hamiltonian cycle
problem, showing that it is fixed-parameter tractable when parameterized below
a natural bound. In addition, for the first parameterization we show that a
kernel with $O(k)$ vertices can be found in polynomial time.
</p></div>
    </summary>
    <updated>2019-02-06T23:32:44Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.01732</id>
    <link href="http://arxiv.org/abs/1902.01732" rel="alternate" type="text/html"/>
    <title>Classifying Convex Bodies by their Contact and Intersection Graphs</title>
    <feedworld_mtime>1549411200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Aamand:Anders.html">Anders Aamand</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Abrahamsen:Mikkel.html">Mikkel Abrahamsen</a>, Jakob Bæk Tejs Knudsen, Peter Michael Reichstein Rasmussen <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.01732">PDF</a><br/><b>Abstract: </b>Suppose that $A$ is a convex body in the plane and that $A_1,\dots,A_n$ are
translates of $A$. Such translates give rise to an intersection graph of $A$,
$G=(V,E)$, with vertices $V=\{1,\dots,n\}$ and edges $E=\{uv\mid A_u\cap
A_v\neq \emptyset\}$. The subgraph $G'=(V, E')$ satisfying that $E'\subset E$
is the set of edges $uv$ for which the interiors of $A_u$ and $A_v$ are
disjoint is a unit distance graph of $A$. If furthermore $G'=G$, i.e., if the
interiors of $A_u$ and $A_v$ are disjoint whenever $u\neq v$, then $G$ is a
contact graph of $A$.
</p>
<p>In this paper we study which pairs of convex bodies have the same contact,
unit distance, or intersection graphs. We say that two convex bodies $A$ and
$B$ are equivalent if there exists a linear transformation $B'$ of $B$ such
that for any slope, the longest line segments with that slope contained in $A$
and $B'$, respectively, are equally long. For a broad class of convex bodies,
including all strictly convex bodies and linear transformations of regular
polygons, we show that the contact graphs of $A$ and $B$ are the same if and
only if $A$ and $B$ are equivalent. We prove the same statement for unit
distance and intersection graphs.
</p></div>
    </summary>
    <updated>2019-02-06T23:33:51Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-02-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.01727</id>
    <link href="http://arxiv.org/abs/1902.01727" rel="alternate" type="text/html"/>
    <title>Discovering bursts revisited: guaranteed optimization of the model parameters</title>
    <feedworld_mtime>1549411200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tatti:Nikolaj.html">Nikolaj Tatti</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.01727">PDF</a><br/><b>Abstract: </b>One of the classic data mining tasks is to discover bursts, time intervals,
where events occur at abnormally high rate. In this paper we revisit
Kleinberg's seminal work, where bursts are discovered by using exponential
distribution with a varying rate parameter: the regions where it is more
advantageous to set the rate higher are deemed bursty. The model depends on two
parameters, the initial rate and the change rate. The initial rate, that is,
the rate that is used when there are no burstiness was set to the average rate
over the whole sequence. The change rate is provided by the user.
</p>
<p>We argue that these choices are suboptimal: it leads to worse likelihood, and
may lead to missing some existing bursts. We propose an alternative problem
setting, where the model parameters are selected by optimizing the likelihood
of the model. While this tweak is trivial from the problem definition point of
view, this changes the optimization problem greatly. To solve the problem in
practice, we propose efficient ($1 + \epsilon$) approximation schemes. Finally,
we demonstrate empirically that with this setting we are able to discover
bursts that would have otherwise be undetected.
</p></div>
    </summary>
    <updated>2019-02-06T23:32:07Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.01704</id>
    <link href="http://arxiv.org/abs/1902.01704" rel="alternate" type="text/html"/>
    <title>A Sequential Importance Sampling Algorithm for Estimating Linear Extensions</title>
    <feedworld_mtime>1549411200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Beichl:Isabel.html">Isabel Beichl</a>, Alathea Jensen, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sullivan:Francis.html">Francis Sullivan</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.01704">PDF</a><br/><b>Abstract: </b>In recent decades, a number of profound theorems concerning approximation of
hard counting problems have appeared. These include estimation of the
permanent, estimating the volume of a convex polyhedron, and counting
(approximately) the number of linear extensions of a partially ordered set. All
of these results have been achieved using probabilistic sampling methods,
specifically Monte Carlo Markov Chain (MCMC) techniques. In each case, a
rapidly mixing Markov chain is defined that is guaranteed to produce, with high
probability, an accurate result after only a polynomial number of operations.
</p>
<p>Although of polynomial complexity, none of these results lead to a practical
computational technique, nor do they claim to. The polynomials are of high
degree and a non-trivial amount of computing is required to get even a single
sample. Our aim in this paper is to present practical Monte Carlo methods for
one of these problems, counting linear extensions. Like related work on
estimating the coefficients of the reliability polynomial, our technique is
based on improving the so-called Knuth counting algorithm by incorporating an
importance function into the node selection technique giving a sequential
importance sampling (SIS) method. We define and report performance on two
importance functions.
</p></div>
    </summary>
    <updated>2019-02-06T23:31:49Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.01701</id>
    <link href="http://arxiv.org/abs/1902.01701" rel="alternate" type="text/html"/>
    <title>Network Resilience Assessment via QoS Degradation Metrics: An Algorithmic Approach</title>
    <feedworld_mtime>1549411200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nguyen:Lan_N=.html">Lan N. Nguyen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Thai:My_T=.html">My T. Thai</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.01701">PDF</a><br/><b>Abstract: </b>This paper focuses on network resilience to perturbation of edge weight.
Other than connectivity, many network applications nowadays rely upon some
measure of network distance between a pair of connected nodes. In these
systems, a metric related to network functionality is associated to each edge.
A pair of nodes only being functional if the weighted, shortest-path distance
between the pair is below a given threshold \texttt{T}. Consequently, a natural
question is on which degree the change of edge weights can damage the network
functionality? With this motivation, we study a new problem, \textit{Quality of
Service Degradation}: given a set of pairs, find a minimum budget to increase
the edge weights which ensures the distance between each pair exceeds
$\mathtt{T}$. We introduce four algorithms with theoretical performance
guarantees for this problem. Each of them has its own strength in trade-off
between effectiveness and running time, which are illustrated both in theory
and comprehensive experimental evaluation.
</p></div>
    </summary>
    <updated>2019-02-06T23:26:52Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.01698</id>
    <link href="http://arxiv.org/abs/1902.01698" rel="alternate" type="text/html"/>
    <title>Stochastic Enumeration with Importance Sampling</title>
    <feedworld_mtime>1549411200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Alathea Jensen <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.01698">PDF</a><br/><b>Abstract: </b>Many hard problems in the computational sciences are equivalent to counting
the leaves of a decision tree, or, more generally, summing a cost function over
the nodes. These problems include calculating the permanent of a matrix,
finding the volume of a convex polyhedron, and counting the number of linear
extensions of a partially ordered set. Many approximation algorithms exist to
estimate such sums. One of the most recent is Stochastic Enumeration (SE),
introduced in 2013 by Rubinstein. In 2015, Vaisman and Kroese provided a
rigorous analysis of the variance of SE, and showed that SE can be extended to
a fully polynomial randomized approximation scheme for certain cost functions
on random trees. We present an algorithm that incorporates an importance
function into SE, and provide theoretical analysis of its efficacy. We also
present the results of numerical experiments to measure the variance of an
application of the algorithm to the problem of counting linear extensions of a
poset, and show that introducing importance sampling results in a significant
reduction of variance as compared to the original version of SE.
</p></div>
    </summary>
    <updated>2019-02-06T23:27:57Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.01691</id>
    <link href="http://arxiv.org/abs/1902.01691" rel="alternate" type="text/html"/>
    <title>Accuracy Evaluation of Overlapping and Multi-resolution Clustering Algorithms on Large Datasets</title>
    <feedworld_mtime>1549411200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lutov:Artem.html">Artem Lutov</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Khayati:Mourad.html">Mourad Khayati</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cudr=eacute==Mauroux:Philippe.html">Philippe Cudré-Mauroux</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.01691">PDF</a><br/><b>Abstract: </b>Performance of clustering algorithms is evaluated with the help of accuracy
metrics. There is a great diversity of clustering algorithms, which are key
components of many data analysis and exploration systems. However, there exist
only few metrics for the accuracy measurement of overlapping and
multi-resolution clustering algorithms on large datasets. In this paper, we
first discuss existing metrics, how they satisfy a set of formal constraints,
and how they can be applied to specific cases. Then, we propose several
optimizations and extensions of these metrics. More specifically, we introduce
a new indexing technique to reduce both the runtime and the memory complexity
of the Mean F1 score evaluation. Our technique can be applied on large datasets
and it is faster on a single CPU than state-of-the-art implementations running
on high-performance servers. In addition, we propose several extensions of the
discussed metrics to improve their effectiveness and satisfaction to formal
constraints without affecting their efficiency. All the metrics discussed in
this paper are implemented in C++ and are available for free as open-source
packages that can be used either as stand-alone tools or as part of a
benchmarking system to compare various clustering algorithms.
</p></div>
    </summary>
    <updated>2019-02-06T23:30:40Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.01668</id>
    <link href="http://arxiv.org/abs/1902.01668" rel="alternate" type="text/html"/>
    <title>Expressive Power of Oblivious Consensus Protocols</title>
    <feedworld_mtime>1549411200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Blondin:Michael.html">Michael Blondin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Esparza:Javier.html">Javier Esparza</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jaax:Stefan.html">Stefan Jaax</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.01668">PDF</a><br/><b>Abstract: </b>Population protocols are a formal model of computation by identical,
anonymous mobile agents interacting in pairs. It has been shown that their
computational power is rather limited: They can only compute the predicates
expressible in Presburger arithmetic. Population protocols are oblivious, in
the sense that their behavior only depends on the number of agents in each
state of the current configuration, and nothing else. Obliviousness has
advantages for applications where agents want to reveal as little as possible
about their trajectories in a computation. We investigate the computational
power of oblivious protocols. We first show that, under a weak assumption,
oblivious protocols can only compute number predicates $\varphi : \mathbb{N}^m
\rightarrow \{0, 1\}$ in NSPACE(n) (with the input written, as usual, in
binary), while all predicates computed by population protocols are in
DSPACE(log n), thus proving an exponential gap. Then we introduce broadcast
consensus protocols, in which agents can also broadcast signals to all other
agents. We prove that they compute all predicates in NSPACE(n), reaching the
theoretical limit for oblivious protocols. Finally, we conduct the first
systematic comparison of different models introduced in the literature
(population protocols, broadcast protocols, community protocols, and mediated
protocols) with respect to their computational power and their privacy
guarantees.
</p></div>
    </summary>
    <updated>2019-02-06T23:20:24Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-02-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.01635</id>
    <link href="http://arxiv.org/abs/1902.01635" rel="alternate" type="text/html"/>
    <title>Randomized Riemannian Preconditioning for Quadratically Constrained Problems</title>
    <feedworld_mtime>1549411200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shustin:Boris.html">Boris Shustin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Avron:Haim.html">Haim Avron</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.01635">PDF</a><br/><b>Abstract: </b>Optimization problem with quadratic equality constraints are prevalent in
machine learning. Indeed, two important examples are Canonical Correlation
Analysis (CCA) and Linear Discriminant Analysis (LDA). Unfortunately, methods
for solving such problems typically involve computing matrix inverses and
decomposition. For the aforementioned problems, these matrices are actually
Gram matrices of input data matrices, and as such the computations are too
expensive for large scale datasets. In this paper, we propose a sketching based
approach for solving CCA and LDA that reduces the cost dependence on the input
size. The proposed algorithms feature randomized preconditioning combined with
Riemannian optimization.
</p></div>
    </summary>
    <updated>2019-02-06T23:22:45Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.01609</id>
    <link href="http://arxiv.org/abs/1902.01609" rel="alternate" type="text/html"/>
    <title>An Optimal Algorithm for Online Freeze-tag</title>
    <feedworld_mtime>1549411200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Josh Brunner, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wellman:Julian.html">Julian Wellman</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.01609">PDF</a><br/><b>Abstract: </b>In the freeze-tag problem, one active robot must wake up many frozen robots.
The robots are considered as points in a metric space, where active robots move
at a constant rate and activate other robots by visiting them. In the
(time-dependent) online variant of the problem, frozen robots are not revealed
until a specified time. Hammar, Nilsson, and Persson have shown that no online
algorithm can achieve a competitive ratio better than $7/3$ for online
freeze-tag, and asked whether there is any $O(1)$-competitive algorithm. In
this paper, we provide a $(1+\sqrt{2})$-competitive algorithm for online
time-dependent freeze-tag, and show that no algorithm can achieve a lower
competitive ratio on every metric space.
</p></div>
    </summary>
    <updated>2019-02-06T23:32:22Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.01543</id>
    <link href="http://arxiv.org/abs/1902.01543" rel="alternate" type="text/html"/>
    <title>Window-based Streaming Graph Partitioning Algorithm</title>
    <feedworld_mtime>1549411200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Md Anwarul kaium Patwary, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Garg:Saurabh.html">Saurabh Garg</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kang:Byeong.html">Byeong Kang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.01543">PDF</a><br/><b>Abstract: </b>In the recent years, the scale of graph datasets has increased to such a
degree that a single machine is not capable of efficiently processing large
graphs. Thereby, efficient graph partitioning is necessary for those large
graph applications. Traditional graph partitioning generally loads the whole
graph data into the memory before performing partitioning; this is not only a
time consuming task but it also creates memory bottlenecks. These issues of
memory limitation and enormous time complexity can be resolved using
stream-based graph partitioning. A streaming graph partitioning algorithm reads
vertices once and assigns that vertex to a partition accordingly. This is also
called an one-pass algorithm. This paper proposes an efficient window-based
streaming graph partitioning algorithm called WStream. The WStream algorithm is
an edge-cut partitioning algorithm, which distributes a vertex among the
partitions. Our results suggest that the WStream algorithm is able to partition
large graph data efficiently while keeping the load balanced across different
partitions, and communication to a minimum. Evaluation results with real
workloads also prove the effectiveness of our proposed algorithm, and it
achieves a significant reduction in load imbalance and edge-cut with different
ranges of dataset.
</p></div>
    </summary>
    <updated>2019-02-06T23:31:36Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.01499</id>
    <link href="http://arxiv.org/abs/1902.01499" rel="alternate" type="text/html"/>
    <title>Differentially Private Release of High-Dimensional Datasets using the Gaussian Copula</title>
    <feedworld_mtime>1549411200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Asghar:Hassan_Jameel.html">Hassan Jameel Asghar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Ding:Ming.html">Ming Ding</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rakotoarivelo:Thierry.html">Thierry Rakotoarivelo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mrabet:Sirine.html">Sirine Mrabet</a>, Mohamed Ali Kaafar <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.01499">PDF</a><br/><b>Abstract: </b>We propose a generic mechanism to efficiently release differentially private
synthetic versions of high-dimensional datasets with high utility. The core
technique in our mechanism is the use of copulas. Specifically, we use the
Gaussian copula to define dependencies of attributes in the input dataset,
whose rows are modelled as samples from an unknown multivariate distribution,
and then sample synthetic records through this copula. Despite the inherently
numerical nature of Gaussian correlations we construct a method that is
applicable to both numerical and categorical attributes alike. Our mechanism is
efficient in that it only takes time proportional to the square of the number
of attributes in the dataset. We propose a differentially private way of
constructing the Gaussian copula without compromising computational efficiency.
Through experiments on three real-world datasets, we show that we can obtain
highly accurate answers to the set of all one-way marginal, and two-and
three-way positive conjunction queries, with 99\% of the query answers having
absolute (fractional) error rates between 0.01 to 3\%. Furthermore, for a
majority of two-way and three-way queries, we outperform independent noise
addition through the well-known Laplace mechanism. In terms of computational
time we demonstrate that our mechanism can output synthetic datasets in around
6 minutes 47 seconds on average with an input dataset of about 200 binary
attributes and more than 32,000 rows, and about 2 hours 30 mins to execute a
much larger dataset of about 700 binary attributes and more than 5 million
rows. To further demonstrate scalability, we ran the mechanism on larger
(artificial) datasets with 1,000 and 2,000 binary attributes (and 5 million
rows) obtaining synthetic outputs in approximately 6 and 19 hours,
respectively.
</p></div>
    </summary>
    <updated>2019-02-06T23:28:52Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.01483</id>
    <link href="http://arxiv.org/abs/1902.01483" rel="alternate" type="text/html"/>
    <title>Discovering Nested Communities</title>
    <feedworld_mtime>1549411200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tatti:Nikolaj.html">Nikolaj Tatti</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gionis:Aristides.html">Aristides Gionis</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.01483">PDF</a><br/><b>Abstract: </b>Finding communities in graphs is one of the most well-studied problems in
data mining and social-network analysis. In many real applications, the
underlying graph does not have a clear community structure. In those cases,
selecting a single community turns out to be a fairly ill-posed problem, as the
optimization criterion has to make a difficult choice between selecting a tight
but small community or a more inclusive but sparser community.
</p>
<p>In order to avoid the problem of selecting only a single community we propose
discovering a sequence of nested communities. More formally, given a graph and
a starting set, our goal is to discover a sequence of communities all
containing the starting set, and each community forming a denser subgraph than
the next. Discovering an optimal sequence of communities is a complex
optimization problem, and hence we divide it into two subproblems: 1) discover
the optimal sequence for a fixed order of graph vertices, a subproblem that we
can solve efficiently, and 2) find a good order. We employ a simple heuristic
for discovering an order and we provide empirical and theoretical evidence that
our order is good.
</p></div>
    </summary>
    <updated>2019-02-06T23:24:50Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.01477</id>
    <link href="http://arxiv.org/abs/1902.01477" rel="alternate" type="text/html"/>
    <title>Faster way to agony: Discovering hierarchies in directed graphs</title>
    <feedworld_mtime>1549411200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tatti:Nikolaj.html">Nikolaj Tatti</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.01477">PDF</a><br/><b>Abstract: </b>Many real-world phenomena exhibit strong hierarchical structure.
Consequently, in many real-world directed social networks vertices do not play
equal role. Instead, vertices form a hierarchy such that the edges appear
mainly from upper levels to lower levels. Discovering hierarchies from such
graphs is a challenging problem that has gained attention. Formally, given a
directed graph, we want to partition vertices into levels such that ideally
there are only edges from upper levels to lower levels. From computational
point of view, the ideal case is when the underlying directed graph is acyclic.
In such case, we can partition the vertices into a hierarchy such that there
are only edges from upper levels to lower edges. In practice, graphs are rarely
acyclic, hence we need to penalize the edges that violate the hierarchy. One
practical approach is agony, where each violating edge is penalized based on
the severity of the violation. The fastest algorithm for computing agony
requires $O(nm^2)$ time. In the paper we present an algorithm for computing
agony that has better theoretical bound, namely $O(m^2)$. We also show that in
practice the obtained bound is pessimistic and that we can use our algorithm to
compute agony for large datasets. Moreover, our algorithm can be used as
any-time algorithm.
</p></div>
    </summary>
    <updated>2019-02-06T23:32:29Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.01454</id>
    <link href="http://arxiv.org/abs/1902.01454" rel="alternate" type="text/html"/>
    <title>External Labeling Techniques: A Taxonomy and Survey</title>
    <feedworld_mtime>1549411200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bekos:Michael_A=.html">Michael A. Bekos</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Niedermann:Benjamin.html">Benjamin Niedermann</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/N=ouml=llenburg:Martin.html">Martin Nöllenburg</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.01454">PDF</a><br/><b>Abstract: </b>External labeling is frequently used for annotating features in graphical
displays and visualizations, such as technical illustrations, anatomical
drawings, or maps, with textual information. Such a labeling connects features
within an illustration by thin leader lines with their labels, which are placed
in the empty space surrounding the image. Over the last twenty years, a large
body of literature in diverse areas of computer science has been published that
investigated many different aspects, models, and algorithms for automatically
placing external labels for a given set of features. This state-of-the-art
report introduces a first unified taxonomy for categorizing the different
results in the literature and then presents a comprehensive survey of the state
of the art, a sketch of the most relevant algorithmic techniques for external
labeling algorithms, as well as a list of open research challenges in this
multidisciplinary research field.
</p></div>
    </summary>
    <updated>2019-02-06T23:34:06Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-02-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.00619</id>
    <link href="http://arxiv.org/abs/1902.00619" rel="alternate" type="text/html"/>
    <title>Parametric FEM for Shape Optimization applied to Golgi Stack</title>
    <feedworld_mtime>1549411200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Xinshi.html">Xinshi Chen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chung:Eric.html">Eric Chung</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.00619">PDF</a><br/><b>Abstract: </b>The thesis is about an application of the shape optimization to the
morphological evolution of Golgi stack. Golgi stack consists of multiple layers
of cisternae. It is an organelle in the biological cells. Inspired by the
Helfrich Model \cite{Helfrich}, which is a model for vesicles typically applied
to biological cells, a new model specially designed for Golgi stack is
developed and then implemented using FEM in this thesis.
</p>
<p>In the Golgi model, each cisternae of the Golgi stack is viewed as a closed
vesicle without topological changes, and our model is adaptable to both
single-vesicle case and multiple-vesicle case. The main idea of the math model
is to minimize the elastic energy(bending energy) of the vesicles, with some
constraints designed regarding the biological properties of Golgi stack. With
these constraints attached to the math model, we could extend this model to an
obstacle-type problem. Hence, in the thesis, not only the simulations of Golgi
stack are shown, but some interesting examples without biological meanings are
also demonstrated. Also, as multiple cisternaes are considered as a whole, this
is also a model handling multiple objects.
</p>
<p>A set of numerical examples is shown to compare with the observed shape of
Golgi stack, so we can lay down some possible explanations to the morphological
performance of trans-Golgi cisternae.
</p></div>
    </summary>
    <updated>2019-02-06T23:33:18Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-02-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=92</id>
    <link href="https://gilkalai.wordpress.com/2019/02/05/extremal-combinatorics-v-posets/" rel="alternate" type="text/html"/>
    <title>Extremal Combinatorics V: POSETS</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">This is the remaining post V on partially ordered sets of my series on extremal combinatorics (I,II,III,IV,VI).  We will talk here about POSETS – partially ordered sets. The study of order is very important in many areas of mathematics starting … <a href="https://gilkalai.wordpress.com/2019/02/05/extremal-combinatorics-v-posets/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><em>This is the remaining post V on partially ordered sets of my series on extremal combinatorics (<a href="https://gilkalai.wordpress.com/2008/05/01/extremal-combinatorics-i/">I</a>,<a href="https://gilkalai.wordpress.com/2008/07/17/extermal-combinatorics-ii-some-geometry-and-number-theory/">II</a>,<a href="https://gilkalai.wordpress.com/2008/09/28/extremal-combinatorics-iii-some-basic-theorems/">III</a>,<a href="https://gilkalai.wordpress.com/2008/10/06/extremal-combinatorics-iv-shifting/">IV</a>,<a href="https://gilkalai.wordpress.com/2009/05/21/extremal-combinatorics-vi-the-frankl-wilson-theorem/">VI</a>). </em></p>
<p>We will talk here about POSETS – partially ordered sets. The study of order is very important in many areas of mathematics starting with the order relation on the integers and reals in algebra and in Euclidean geometry. The set of all subsets of a set can be partially ordered by inclusion and this is a very basic example of posets. While the study of order and posets is a separate area on its own, parts of it are very important in extremal combinatorics and we will give a little taste here.</p>
<p style="text-align: center;"><span style="color: #0000ff;"><strong>Dear readers, please contribute your favorite result or problem on partially ordered sets (or Sorting) in the comment session.</strong></span></p>
<p>A chain <img alt="C \subset P" class="latex" src="https://s0.wp.com/latex.php?latex=C+%5Csubset+P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C \subset P"/> in a POSET is a set of elements so that every two of them are comparable. An antichain $A \subset P$ is a set of elements so that every two distinct elemenאs in <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> are incomparable.  (Antichains are also called independent sets.) An immediate but important Lemma is:</p>
<p><strong>The immediate lemma:</strong> The intersection of a chain <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> and an antichain <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/> contains at most one element. <strong><span style="color: #993366;">Walla!</span></strong></p>
<h3>Dilworth’s theorem</h3>
<p>Dilworth’s theorem (DT): Every finite partially ordered <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> set can be covered by <img alt="a(P)" class="latex" src="https://s0.wp.com/latex.php?latex=a%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a(P)"/> chains.</p>
<p>(By the immediate lemma, at least <img alt="a(P)" class="latex" src="https://s0.wp.com/latex.php?latex=a%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a(P)"/> chains are needed.)</p>
<p>Dual Dilworth theorem: Every partially ordedrd sets can be cover by <img alt="c(P)" class="latex" src="https://s0.wp.com/latex.php?latex=c%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c(P)"/> untichains.</p>
<p>(By the immediate lemma, at least <img alt="c(P)" class="latex" src="https://s0.wp.com/latex.php?latex=c%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c(P)"/> antichains are needed.)</p>
<p>The proof of the dual Dilworth theorem is easy. Note that the set <img alt="A_1=MIN(P)" class="latex" src="https://s0.wp.com/latex.php?latex=A_1%3DMIN%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_1=MIN(P)"/> of minimal elements of <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> is an antichain. Let <img alt="A_k = MIN (P\backslash (A_1 \cup A_2 \cup \dots A_{k-1}))" class="latex" src="https://s0.wp.com/latex.php?latex=A_k+%3D+MIN+%28P%5Cbackslash+%28A_1+%5Ccup+A_2+%5Ccup+%5Cdots+A_%7Bk-1%7D%29%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_k = MIN (P\backslash (A_1 \cup A_2 \cup \dots A_{k-1}))"/>. We need two easy observations. First, <img alt="A_k is an antichain" class="latex" src="https://s0.wp.com/latex.php?latex=A_k+is+an+antichain&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_k is an antichain"/> and second: If <img alt="A_k \ne \emptyset" class="latex" src="https://s0.wp.com/latex.php?latex=A_k+%5Cne+%5Cemptyset&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_k \ne \emptyset"/> then there is a chain with one element from <img alt="A_i: 1 \le i\le k" class="latex" src="https://s0.wp.com/latex.php?latex=A_i%3A+1+%5Cle+i%5Cle+k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_i: 1 \le i\le k"/>. <strong><span style="color: #0000ff;">Walla!</span></strong></p>
<p>The proof of Dilworth theorem is by induction on $|P|$. For the induction step you first consider the case where every antichain of maximal size is either <img alt="MAX(P)" class="latex" src="https://s0.wp.com/latex.php?latex=MAX%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="MAX(P)"/> or <img alt="MIN (P)" class="latex" src="https://s0.wp.com/latex.php?latex=MIN+%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="MIN (P)"/>. In this case you consider a chain with one element in <img alt="MAX(P)" class="latex" src="https://s0.wp.com/latex.php?latex=MAX%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="MAX(P)"/> and one element in <img alt="MIN (P)" class="latex" src="https://s0.wp.com/latex.php?latex=MIN+%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="MIN (P)"/> and delete these elements from <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/>. For the resulting post <img alt="Q" class="latex" src="https://s0.wp.com/latex.php?latex=Q&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Q"/>, <img alt="a(Q)=a(P)-1" class="latex" src="https://s0.wp.com/latex.php?latex=a%28Q%29%3Da%28P%29-1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a(Q)=a(P)-1"/> and we can use the induction hypothesis.</p>
<p>Otherwise there is an antichain <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> of maximum size <img alt="t=a(P)" class="latex" src="https://s0.wp.com/latex.php?latex=t%3Da%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t=a(P)"/> which is not <em>MAX(P)</em> or <em>MIN(P)</em>.  Put <img alt="A=\{a_1,a_2,\dots,a_t\}" class="latex" src="https://s0.wp.com/latex.php?latex=A%3D%5C%7Ba_1%2Ca_2%2C%5Cdots%2Ca_t%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A=\{a_1,a_2,\dots,a_t\}"/>. Let <img alt="P^+" class="latex" src="https://s0.wp.com/latex.php?latex=P%5E%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P^+"/> be the set of elements in <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> which are larger or equal some element in <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/>, and let <img alt="P^-" class="latex" src="https://s0.wp.com/latex.php?latex=P%5E-&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P^-"/> be the set of elements in <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> which are smaller or equal some element in <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/>.</p>
<p>Now,</p>
<ol>
<li><img alt="P^+ \cup P^-=P" class="latex" src="https://s0.wp.com/latex.php?latex=P%5E%2B+%5Ccup+P%5E-%3DP&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P^+ \cup P^-=P"/>. Otherwise we could add an element to <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> to form a larger antichain.</li>
<li><img alt="P^+ \cap P^- = A" class="latex" src="https://s0.wp.com/latex.php?latex=P%5E%2B+%5Ccap+P%5E-+%3D+A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P^+ \cap P^- = A"/>. Otherwise, there will be two elements of <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> which are comparable.</li>
</ol>
<p>So by the induction hypothesis <img alt="P^+" class="latex" src="https://s0.wp.com/latex.php?latex=P%5E%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P^+"/> can be covered by <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t"/> chains <img alt="C_1^+, C_2^+, \dots, C_t^+" class="latex" src="https://s0.wp.com/latex.php?latex=C_1%5E%2B%2C+C_2%5E%2B%2C+%5Cdots%2C+C_t%5E%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_1^+, C_2^+, \dots, C_t^+"/> and <img alt="P^-" class="latex" src="https://s0.wp.com/latex.php?latex=P%5E-&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P^-"/> can be covered by <img alt="a(P" class="latex" src="https://s0.wp.com/latex.php?latex=a%28P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a(P"/>$ chains <img alt="C_1^-, C_2^-, \dots, C_t^-" class="latex" src="https://s0.wp.com/latex.php?latex=C_1%5E-%2C+C_2%5E-%2C+%5Cdots%2C+C_t%5E-&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_1^-, C_2^-, \dots, C_t^-"/>. Bu re-indexing we can assume that both <img alt="C_i^+" class="latex" src="https://s0.wp.com/latex.php?latex=C_i%5E%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_i^+"/> and <img alt="C_i^-" class="latex" src="https://s0.wp.com/latex.php?latex=C_i%5E-&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_i^-"/> contains <img alt="a_i" class="latex" src="https://s0.wp.com/latex.php?latex=a_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_i"/>. It follows that <img alt="a_i" class="latex" src="https://s0.wp.com/latex.php?latex=a_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_i"/> is the minimal element in $C_i^+$ and the maximal element in $C_i^-$ and hence <img alt="C_i=:C_i^+ \cup C_i^-" class="latex" src="https://s0.wp.com/latex.php?latex=C_i%3D%3AC_i%5E%2B+%5Ccup+C_i%5E-&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_i=:C_i^+ \cup C_i^-"/> is a chain. The <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t"/> chains <img alt="C_1, C_2, \dots, C_t" class="latex" src="https://s0.wp.com/latex.php?latex=C_1%2C+C_2%2C+%5Cdots%2C+C_t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_1, C_2, \dots, C_t"/> cover <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/>. <span style="color: #993366;"><strong>Sababa!</strong></span></p>
<p>An <strong>important Corollary</strong> both from Dilworth’s theorem and its dual is that</p>
<p style="text-align: center;"><img alt="a(P) c(P) \ge |P|." class="latex" src="https://s0.wp.com/latex.php?latex=a%28P%29+c%28P%29+%5Cge+%7CP%7C.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a(P) c(P) \ge |P|."/></p>
<h3>Erdos-Szekeres theorem</h3>
<p>The fundamental Erdos Szekeres theorem asserts that if <img alt="n=ab+1" class="latex" src="https://s0.wp.com/latex.php?latex=n%3Dab%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n=ab+1"/> then every sequence <img alt="a_1,a_2,\dots ,a_n" class="latex" src="https://s0.wp.com/latex.php?latex=a_1%2Ca_2%2C%5Cdots+%2Ca_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_1,a_2,\dots ,a_n"/> of different real numbers contains a monotone increasing sequence of length <img alt="a+1" class="latex" src="https://s0.wp.com/latex.php?latex=a%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a+1"/> or a monotone decreasing sequence of length <img alt="b+1" class="latex" src="https://s0.wp.com/latex.php?latex=b%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="b+1"/>.</p>
<p>There are simple proofs. For example, associate to every <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/> a pair <img alt="(I_k,D_k)" class="latex" src="https://s0.wp.com/latex.php?latex=%28I_k%2CD_k%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(I_k,D_k)"/> of integers where  <img alt="I_k" class="latex" src="https://s0.wp.com/latex.php?latex=I_k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="I_k"/> is the maximum length of the increasing subsequence starting with <img alt="a_k" class="latex" src="https://s0.wp.com/latex.php?latex=a_k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_k"/> and <img alt="D_k" class="latex" src="https://s0.wp.com/latex.php?latex=D_k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D_k"/> is the maximum length of the deccreasing subsequence starting with <img alt="a_k" class="latex" src="https://s0.wp.com/latex.php?latex=a_k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_k"/>. The result follows from the easy observation that all these pairs are different.</p>
<p>Both Dilworth’ theorem and its easy dual implies easily (in fact we need only the important corollary) the Erdos Szekeres theorem when we define the following partial order: <img alt="i &lt; k" class="latex" src="https://s0.wp.com/latex.php?latex=i+%3C+k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i &lt; k"/> if both <img alt="i&lt;k" class="latex" src="https://s0.wp.com/latex.php?latex=i%3Ck&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i&lt;k"/> and <img alt="a_i &lt; a_k" class="latex" src="https://s0.wp.com/latex.php?latex=a_i+%3C+a_k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_i &lt; a_k"/>.</p>
<h3>Looking at Sperner’s theorem again</h3>
<p>Sperner’s theorem asserts that the maximal size of an antichain of subsets of an <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> elements set is <img alt="{{n} \choose {[n/2]}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7Bn%7D+%5Cchoose+%7B%5Bn%2F2%5D%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{{n} \choose {[n/2]}}"/>. By Dilworth theorem it follows that we can cover all sets by <img alt="{{n} \choose {[n/2]}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7Bn%7D+%5Cchoose+%7B%5Bn%2F2%5D%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{{n} \choose {[n/2]}}"/> chains (and, of course when we exhibit such a covering it reproves Sperner theorem). A symmetric saturated chain decomposition is a partition of <img alt="P(n)" class="latex" src="https://s0.wp.com/latex.php?latex=P%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P(n)"/> (=all subsets of <img alt="[n]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Bn%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="[n]"/>) to saturated chains where each chain has, for some <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>, sets of sizes $k,k+1,\dots,d-k$. You can build such a decomposition inductively.</p>
<p>Start with a decomposition for <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> for each chain <img alt="C_i" class="latex" src="https://s0.wp.com/latex.php?latex=C_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_i"/> create a new chain <img alt="C'_i" class="latex" src="https://s0.wp.com/latex.php?latex=C%27_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C'_i"/> by adding the element <img alt="n+1" class="latex" src="https://s0.wp.com/latex.php?latex=n%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n+1"/> to every set. And then move the top set in <img alt="C'_i" class="latex" src="https://s0.wp.com/latex.php?latex=C%27_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C'_i"/> to <img alt="C_i" class="latex" src="https://s0.wp.com/latex.php?latex=C_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_i"/>.  <strong>Walla!</strong></p>
<p>This is a beginning of a very beautiful story related also to the Dedekind Problem about  number of antichains in <img alt="P(n)" class="latex" src="https://s0.wp.com/latex.php?latex=P%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P(n)"/>.</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/02/untitledgreene-kleitman2.png"><img alt="" class="alignnone size-full wp-image-16834" height="489" src="https://gilkalai.files.wordpress.com/2019/02/untitledgreene-kleitman2.png?w=640&amp;h=489" width="640"/></a></p>
<p><strong><span style="color: #ff0000;">Curtis Greene and Danny Kleitman</span></strong></p>
<h3>The Greene-Kleitman theorem</h3>
<p>Let <img alt="a_k(P)" class="latex" src="https://s0.wp.com/latex.php?latex=a_k%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_k(P)"/> be the maximum size of the union <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X"/> of <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/> antichains in a poset <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/>. For every chain For every chain <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/> we have <img alt="|C \cap X| \le \min\{|C|,k\}" class="latex" src="https://s0.wp.com/latex.php?latex=%7CC+%5Ccap+X%7C+%5Cle+%5Cmin%5C%7B%7CC%7C%2Ck%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|C \cap X| \le \min\{|C|,k\}"/>. Therefore for a partition of <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> to chains <img alt="C_1,C_2,\dots,C_t" class="latex" src="https://s0.wp.com/latex.php?latex=C_1%2CC_2%2C%5Cdots%2CC_t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_1,C_2,\dots,C_t"/> we   have <img alt="\sum\min\{|C_i|,k\ge |X|" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csum%5Cmin%5C%7B%7CC_i%7C%2Ck%5Cge+%7CX%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sum\min\{|C_i|,k\ge |X|"/>. The <a href="https://www.encyclopediaofmath.org/index.php/Greene-Kleitman_theorem">Greene-Kleitman theorem</a> asserts that there always is a decomposition into chains with <img alt="\sum\min\{|C_i|,k\}=a_k(P)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csum%5Cmin%5C%7B%7CC_i%7C%2Ck%5C%7D%3Da_k%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sum\min\{|C_i|,k\}=a_k(P)"/>.</p>
<h3>The perfect graph theorem.</h3>
<p>What is the relation between the very easy dual Dilworth theorem and the harder Dilworth theorem? As it turns out there is a very general theorem, Lovasz’ perfect graph theorem, that show that,  these two theorems are equivalent.</p>
<p>A graph G is perfect if for every induced subgraph H, the chromatic number equals the clique number. Lovasz’ theorem  (conjectured by Claude Berge) asserts that complements of perfect graphs are perfect. The perfectness of the comparability graph of a poset amounts to the dual Dilworth theorem, and for its complement it is the Dilworth theorem. Lovasz in fact proved that perfectness is equivalent to the relation $\latex \omega(H)\cdot \alpha (H) \ge |H|$ for every induced subgraph H. (For posets this is our important corollary above.)</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/02/kahn-linial-saks.png"><img alt="" class="alignnone size-full wp-image-16832" height="239" src="https://gilkalai.files.wordpress.com/2019/02/kahn-linial-saks.png?w=640&amp;h=239" width="640"/></a></p>
<p><strong><span style="color: #ff0000;">Jeff Kahn and Jake Baron </span></strong><span style="color: #ff0000;">(</span><span style="color: #ff0000;"><a href="http://archive.dimacs.rutgers.edu/DIMACS_highlights/tuza/tuza.html">see here on their 2016 asymptotic solution to Tusza’s conjecture</a></span><span style="color: #ff0000;">),</span><strong><span style="color: #ff0000;"> Mike Saks, and Nati Linial</span></strong></p>
<h3>Startling theorems on POSETS: Kahn-Saks,  Linial-Saks, Linial-Kahn, and Kahn-Saks</h3>
<p>Here  some beautiful and important theorems on posets. An order ideas <img alt="I" class="latex" src="https://s0.wp.com/latex.php?latex=I&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="I"/> of a post is a set of elements so that if <img alt="x in I" class="latex" src="https://s0.wp.com/latex.php?latex=x+in+I&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x in I"/> and <img alt="y &lt; x" class="latex" src="https://s0.wp.com/latex.php?latex=y+%3C+x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y &lt; x"/> then <img alt="y \in I" class="latex" src="https://s0.wp.com/latex.php?latex=y+%5Cin+I&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y \in I"/>.</p>
<p><strong>Theorem (Linial-Saks, 1985):</strong> In every poset <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> there is an element which is contained in more than δ and less than 1-δ order ideas of <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/>.  (<a href="http://www.cs.huji.ac.il/~nati/PAPERS/central_element.pdf">Paper</a>)</p>
<p><strong>Theorem (Kahn-Saks, 1984):</strong> For every Poset <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> which is not a chain there are two incomparable elements <img alt="x,y" class="latex" src="https://s0.wp.com/latex.php?latex=x%2Cy&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x,y"/> such that the number of linear extensions of <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> for which <img alt="x&lt;y" class="latex" src="https://s0.wp.com/latex.php?latex=x%3Cy&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x&lt;y"/> is between 3/11 and 8/11. (<a href="https://link.springer.com/article/10.1007/BF00565647">Paper</a>)</p>
<p>A <a href="http://www.cs.huji.ac.il/~nati/PAPERS/brunn_minkowski.pdf">simpler proof</a> was found in the late 80s by Kahn and Linial and by Karzanov and Khachiyan. It  is  based on the Brunn Minkowski theorem gives a weaker constant <img alt="1/2e" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F2e&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/2e"/> .</p>
<p><strong>Theorem (Kahn-Saks, 1987)</strong>: For every finite distributive lattice <img alt="L" class="latex" src="https://s0.wp.com/latex.php?latex=L&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="L"/> the maximum antichain is of size <img alt="o(|L|)" class="latex" src="https://s0.wp.com/latex.php?latex=o%28%7CL%7C%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="o(|L|)"/>. (<a href="https://core.ac.uk/download/pdf/82629369.pdf">Paper</a>)</p>
<p>Lattices are special types of posets with the property that for every set of elements (pairs <img alt="\{x,y\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7Bx%2Cy%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{x,y\}"/> suffice in the finite case), there is a unique minimal elements above them all (denoted for pairs by <i>x</i> ∧ <i>y</i>) and a unique maximal element (denoted for pairs by <i>x</i> ∨ <i>y</i>) below them all.</p>
<p>A <a href="https://en.wikipedia.org/wiki/Distributive_lattice">distributive lattice</a> ia a lattice that satisfies for every <em>x, y</em> and <em>z</em>, the relation</p>
<p style="text-align: center;"><i>x</i> ∧ (<i>y</i> ∨ <i>z</i>) = (<i>x</i> ∧ <i>y</i>) ∨ (<i>x</i> ∧ <i>z</i>)</p>
<p>Birkhoff’s representation theorem asserts that finite distributive lattices can be represented as order ideals of posets (ordered by inclusion).</p>
<p> </p>
<p> </p></div>
    </content>
    <updated>2019-02-05T11:18:54Z</updated>
    <published>2019-02-05T11:18:54Z</published>
    <category term="Combinatorics"/>
    <category term="Claude Berge"/>
    <category term="Curtis Greene"/>
    <category term="Daniel Kleitman"/>
    <category term="Dilworth's theorem"/>
    <category term="Extremal combinatorics"/>
    <category term="Jeff Kahn"/>
    <category term="Laci Lovasz"/>
    <category term="Mike Saks"/>
    <category term="Nati Linial"/>
    <category term="Posets"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-02-07T19:20:43Z</updated>
    </source>
  </entry>
</feed>
