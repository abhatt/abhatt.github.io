<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2019-01-08T00:42:45Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry>
    <id>https://cstheory.stackexchange.com/q/42171</id>
    <link href="https://cstheory.stackexchange.com/questions/42171/minimum-relevant-variables-in-linear-system-additive-approximation" rel="alternate" type="text/html"/>
    <title>Minimum relevant variables in linear system - additive approximation</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>In the problem <a href="https://en.wikipedia.org/wiki/Minimum_relevant_variables_in_linear_system" rel="nofollow noreferrer">Minimum Relevant Variables in Linear System</a> (Min-RVLS), the input is a linear system, e.g.:</p>

<p><span class="math-container">$$ A x = b $$</span></p>

<p>and the goal is to find a solution <span class="math-container">$x$</span> with as few nonzero variables as possible. </p>

<p>The problem is known to be NP-hard and hard to approximate to within a constant multiplicative factor (see the wikipedia page for details). </p>

<p>My question is: is anything known about <em>additive</em> approximations? In particular: what is the complexity of finding a solution that has at most <span class="math-container">$\text{OPT}+d$</span> nonzero variables, where <span class="math-container">$\text{OPT}$</span> is the smallest number of nonzero variables in a solution, and <span class="math-container">$d$</span> is some constant?</p>

<p>A related problem is: there always exists a solution with at most <span class="math-container">$m$</span> nonzero variables, where <span class="math-container">$m$</span> is the number of constraints (number of rows in <span class="math-container">$A$</span>). What is the complexity of finding a solution that has at most <span class="math-container">$m-d$</span> nonzero variables, for some constant <span class="math-container">$d$</span>?</p></div>
    </summary>
    <updated>2019-01-07T16:08:53Z</updated>
    <published>2019-01-07T16:08:53Z</published>
    <category scheme="https://cstheory.stackexchange.com/tags" term="approximation-algorithms"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="optimization"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="linear-programming"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="approximation-hardness"/>
    <author>
      <name>Erel Segal-Halevi</name>
      <uri>https://cstheory.stackexchange.com/users/9453</uri>
    </author>
    <source>
      <id>https://cstheory.stackexchange.com/feeds/</id>
      <link href="https://cstheory.stackexchange.com/feeds/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory.stackexchange.com/questions" rel="alternate" type="text/html"/>
      <link href="http://www.creativecommons.org/licenses/by-sa/3.0/rdf" rel="license"/>
      <subtitle>most recent 30 from cstheory.stackexchange.com</subtitle>
      <title>Recent Questions - Theoretical Computer Science Stack Exchange</title>
      <updated>2019-01-08T00:32:53Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://cstheory.stackexchange.com/q/42170</id>
    <link href="https://cstheory.stackexchange.com/questions/42170/is-there-exists-a-polynomial-time-algorithm-to-find-a-order-k-subgroup" rel="alternate" type="text/html"/>
    <title>Is there exists a polynomial time algorithm to find a order $k$ subgroup?</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>How to find subgroups ( unique up to isomorphism) of order <span class="math-container">$k$</span> of a group <span class="math-container">$G$</span>, when the input group is given in the <a href="http://mathworld.wolfram.com/MultiplicationTable.html" rel="nofollow noreferrer">explicit</a> form. The idea coming to my mind follows, try all possible subsets of size <span class="math-container">$k$</span> and then check whether they form a subgroup of <span class="math-container">$G$</span> or not which can be checked in polynomial time but overall runtime may not be polynomial in the order of the group <span class="math-container">$G$</span> depending upon the value of <span class="math-container">$k$</span>. What is the fastest known algorithm for the task described above? What if the input group is a <span class="math-container">$p$</span>-group? Is it possible to find an order <span class="math-container">$k$</span> subgroup in polynomial time, when <span class="math-container">$k$</span> is very large? </p></div>
    </summary>
    <updated>2019-01-07T15:37:57Z</updated>
    <published>2019-01-07T15:37:57Z</published>
    <category scheme="https://cstheory.stackexchange.com/tags" term="gr.group-theory"/>
    <author>
      <name>aaaa</name>
      <uri>https://cstheory.stackexchange.com/users/43707</uri>
    </author>
    <source>
      <id>https://cstheory.stackexchange.com/feeds/</id>
      <link href="https://cstheory.stackexchange.com/feeds/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory.stackexchange.com/questions" rel="alternate" type="text/html"/>
      <link href="http://www.creativecommons.org/licenses/by-sa/3.0/rdf" rel="license"/>
      <subtitle>most recent 30 from cstheory.stackexchange.com</subtitle>
      <title>Recent Questions - Theoretical Computer Science Stack Exchange</title>
      <updated>2019-01-08T00:32:53Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://cstheory.stackexchange.com/q/42169</id>
    <link href="https://cstheory.stackexchange.com/questions/42169/optimal-algorithm-to-compare-lines-of-different-files-without-repetition" rel="alternate" type="text/html"/>
    <title>Optimal algorithm to compare lines of different files without repetition</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I have 1600 ASCII files with 1000 lines in each file. Each line has only one entry and is a floating point number e.g. 1.67923.
Let's denote the line1 of file1 with <code>L(1,1)</code>, line2 of file1 with <code>L(1,2)</code> and so forth to ...<code>L(1,1000)</code>. Similarly, line1 of file2 will be <code>L(2,1)</code> and the last line of file1600 will thus be <code>L(1600,1000)</code>.
My task is to come up with a memory efficient algorithm to compare all lines between each file and the lines within each file. Since, I have 1600 files and 1000 lines in each file, it will take approx. <code>10^12</code> calculations. These first comparisons will look like this:</p>

<pre><code>1. {L(1,1)-L(1,2)}, {L(1,1)-L(1,3)},....,{L(1,1)-L(1,1000)}
2. {L(1,1)-L(2,1)}, {L(1,1)-L(2,2)},....,{L(1,1)-L(2,1000)}
3. {L(1,1)-L(3,1)}, {L(1,1)-L(3,2)},....,{L(1,1)-L(3,1000)}
.
.
. 
</code></pre>

<p>Please note that I don't want repetitions i.e <code>{L(1,1)-L(2,1)} = {L(2,1)-L(1,1)}</code>.
I need to code this problem in Fortran but any help on a general scheme as to how the problem needs to be approached will be useful.
Thank you in advance!  </p></div>
    </summary>
    <updated>2019-01-07T15:12:49Z</updated>
    <published>2019-01-07T15:12:49Z</published>
    <category scheme="https://cstheory.stackexchange.com/tags" term="ds.algorithms"/>
    <author>
      <name>Abedin Y. Abedin</name>
      <uri>https://cstheory.stackexchange.com/users/51670</uri>
    </author>
    <source>
      <id>https://cstheory.stackexchange.com/feeds/</id>
      <link href="https://cstheory.stackexchange.com/feeds/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory.stackexchange.com/questions" rel="alternate" type="text/html"/>
      <link href="http://www.creativecommons.org/licenses/by-sa/3.0/rdf" rel="license"/>
      <subtitle>most recent 30 from cstheory.stackexchange.com</subtitle>
      <title>Recent Questions - Theoretical Computer Science Stack Exchange</title>
      <updated>2019-01-08T00:32:53Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://cstheory.stackexchange.com/q/42167</id>
    <link href="https://cstheory.stackexchange.com/questions/42167/decomposition-for-a-certain-class-of-graphs" rel="alternate" type="text/html"/>
    <title>Decomposition for a certain class of graphs</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Suppose a graph, <span class="math-container">$G = (V,E)$</span> is characterized as a lattice/network of cliques as in the picture below. Does there exist some decomposition principle (i.e. on the right) for <span class="math-container">$G$</span>, that yields some special structure that may be used to explain efficiencies experienced with what are supposed to be combinatorial hard problems?</p>

<p><a href="https://i.stack.imgur.com/FTbx8.png" rel="nofollow noreferrer"><img alt="enter image description here" src="https://i.stack.imgur.com/FTbx8.png"/></a></p></div>
    </summary>
    <updated>2019-01-07T06:19:24Z</updated>
    <published>2019-01-07T06:19:24Z</published>
    <category scheme="https://cstheory.stackexchange.com/tags" term="graph-theory"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="graph-algorithms"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="co.combinatorics"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="treewidth"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="integer-lattice"/>
    <author>
      <name>Student</name>
      <uri>https://cstheory.stackexchange.com/users/51578</uri>
    </author>
    <source>
      <id>https://cstheory.stackexchange.com/feeds/</id>
      <link href="https://cstheory.stackexchange.com/feeds/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory.stackexchange.com/questions" rel="alternate" type="text/html"/>
      <link href="http://www.creativecommons.org/licenses/by-sa/3.0/rdf" rel="license"/>
      <subtitle>most recent 30 from cstheory.stackexchange.com</subtitle>
      <title>Recent Questions - Theoretical Computer Science Stack Exchange</title>
      <updated>2019-01-08T00:32:53Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://cstheory.stackexchange.com/q/42166</id>
    <link href="https://cstheory.stackexchange.com/questions/42166/algorithm-for-k-best-non-perfect-bipartite-matchings" rel="alternate" type="text/html"/>
    <title>Algorithm for K-best NON perfect bipartite matchings</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I was reading this great article: <a href="https://core.ac.uk/download/pdf/82129717.pdf" rel="nofollow noreferrer">https://core.ac.uk/download/pdf/82129717.pdf</a></p>

<p>It solves a generalization of the maximum sum assignment problem by finding the k best assignments and not only the best.
However, it only looks at perfect matchings. I'm am especially interested in bipartite matchings.</p>

<p>In particular, for the bipartite graphs, the Theorem 1 p. 161 uses the fact that the matchings are considered perfect.</p>

<p>How can I solve the k-best assignment problem for general bipartite graphs?</p></div>
    </summary>
    <updated>2019-01-06T23:47:08Z</updated>
    <published>2019-01-06T23:47:08Z</published>
    <category scheme="https://cstheory.stackexchange.com/tags" term="graph-algorithms"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="matching"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="bipartite-graphs"/>
    <author>
      <name>Labo</name>
      <uri>https://cstheory.stackexchange.com/users/43172</uri>
    </author>
    <source>
      <id>https://cstheory.stackexchange.com/feeds/</id>
      <link href="https://cstheory.stackexchange.com/feeds/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory.stackexchange.com/questions" rel="alternate" type="text/html"/>
      <link href="http://www.creativecommons.org/licenses/by-sa/3.0/rdf" rel="license"/>
      <subtitle>most recent 30 from cstheory.stackexchange.com</subtitle>
      <title>Recent Questions - Theoretical Computer Science Stack Exchange</title>
      <updated>2019-01-08T00:32:53Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=15562</id>
    <link href="https://rjlipton.wordpress.com/2019/01/06/predictions-for-2019/" rel="alternate" type="text/html"/>
    <title>Predictions For 2019</title>
    <summary>The problem of predicting ‘when’ not just ‘what’ Cropped from Toronto Star source Isaac Asimov was a prolific writer of science fiction and nonfiction. Thirty-five years ago, on the eve of the year 1984, he noted that 35 years had passed since the publication of George Orwell’s 1984. He wrote an exclusive feature for the […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>The problem of predicting ‘when’ not just ‘what’</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2019/01/asimovtorontostar.jpg"><img alt="" class="alignright wp-image-15564" height="167" src="https://rjlipton.files.wordpress.com/2019/01/asimovtorontostar.jpg?w=180&amp;h=167" width="180"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Cropped from Toronto Star <a href="https://www.thestar.com/news/world/2018/12/27/35-years-ago-isaac-asimov-was-asked-by-the-star-to-predict-the-world-of-2019-here-is-what-he-wrote.html">source</a></font></td>
</tr>
</tbody>
</table>
<p>
Isaac Asimov was a prolific writer of science fiction and nonfiction. Thirty-five years ago, on the eve of the year 1984, he noted that 35 years had passed since the publication of George Orwell’s <em>1984</em>. He wrote an exclusive <a href="https://www.thestar.com/news/world/2018/12/27/35-years-ago-isaac-asimov-was-asked-by-the-star-to-predict-the-world-of-2019-here-is-what-he-wrote.html">feature</a> for the Toronto Star newspaper predicting what the world would be like 35 years hence, that is, in 2019.</p>
<p>
Today we give our take on his predictions and make our own for the rest of 2019.</p>
<p>
Asimov’s essay began by presupposing the absence of nuclear holocaust without predicting it. It then focused on two subjects: computerization and use of outer space. On the spectrum of evaluations subtended by this laudatory BBC <a href="https://www.bbc.com/news/technology-46736024">piece</a> and this critical <a href="https://www.thestar.com/news/world/2018/12/27/isaac-asimov-you-were-no-nostradamus.html">column</a> in the Toronto Star itself, we’re closer to the latter. On space he predicted we’d be mining the Moon by now; instead nothing more landed on the Moon until the Chinese <a href="https://en.wikipedia.org/wiki/Chang'e_3">Chang’e 3</a> mission in 2013 and <a href="https://en.wikipedia.org/wiki/Chang'e_4">Chang’e 4</a> happening now. His 35-year span should be lengthened to over a century.</p>
<p>
On computerization and robotics he was mostly right except again for the timespan: he said the transition would be “about over” by 2019 whereas it may be entering its period of greatest flux only now. However, for the end of 1983 we think the “whats” of his predictions were easy. Personal computers had already been around for almost a decade. Computer systems for business were plentiful. The Internet was already a proclaimed goal and the text-based <a href="https://en.wikipedia.org/wiki/Usenet">Usenet</a> was already operating. Asimov’s essay seems to miss how the combination of these three would soon move points of control outward to end-users. </p>
<p>
We still think what he wrote about space and robots will happen. This shows the problem of predictions is not just ‘what’ but ‘when.’ For another instance of being wrong on ‘when’ too soon, Ken told a Harvard Law graduate who visited him in Oxford in 1984 that what we now call <a href="https://en.wikipedia.org/wiki/Deepfake">deepfake</a> videos were imminent. We’ll make the rest of this post more about ‘when’ than ‘what.’</p>
<p>
</p><p/><h2> Predictions in Past Years </h2><p/>
<p/><p>
Here are some predictions that we have made before. Seems we did not make any new predictions last year—oh well—but see <a href="https://rjlipton.wordpress.com/2018/01/02/predictions-we-didnt-make/">this</a>.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <em>No circuit lower bound of <img alt="{1000n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1000n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1000n}"/> or better will be proved for SAT.</em> Well that’s a freebie.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <em>A computer scientist will win a Nobel Prize.</em> No—indeed, less close than other years.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <em>At least five claims that <img alt="{\mathsf{P}=\mathsf{NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D%3D%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{P}=\mathsf{NP}}"/> and five that <img alt="{\mathsf{P} \neq \mathsf{NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D+%5Cneq+%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{P} \neq \mathsf{NP}}"/> will be made.</em> </p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> A “provably” secure crypto-system will be broken. For this one we don’t have to check any claims. We just pocket the ‘yes’ answer. Really, could you ever prove the opposite? How about the <a href="https://cacm.acm.org/magazines/2019/1/233523-imperfect-forward-secrecy/abstract">attack</a> on Diffie-Hellman in the current CACM?</p>
<p>
<img alt="{\bullet}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet}"/> <em>An Earth-sized planet will be detected orbiting within the habitable zone of its single star.</em> The “when” for this one came in 2017 already. We are retiring it.</p>
<p>
<img alt="{\bullet}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet}"/> <em>A Clay problem will be solved, or at least notable progress made.</em> Again we sense that the answer on progress is “no.” This includes saying that nothing substantial seems to have emerged from Sir Michael Atiyah’s <a href="https://aperiodical.com/2018/09/atiyah-riemann-hypothesis-proof-final-thoughts/">claim</a> of proving the Riemann Hypothesis. However, we note <a href="https://gilkalai.wordpress.com/2018/12/25/amazing-karim-adiprasito-proved-the-g-conjecture-for-spheres/">via</a> Gil Kalai’s blog that a longstanding problem called the <img alt="{g}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{g}"/>-conjecture for spheres has been <a href="https://arxiv.org/abs/1812.10454">solved</a> by Karim Adiprasito.</p>
<p>
</p><p/><h2> Predictions This Year </h2><p/>
<p/><p>
We will add some new predictions—it seems unfair to keep repeating sure winners. </p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <em>Deep learning methods will be found able to solve integer factoring.</em> This will place current cryptography is trouble.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <em>Deep learning methods will be found to help prove that factoring is hard.</em></p>
<p>
These may not be as contradictory as they seem. There is a long-known <a href="http://www.cs.sfu.ca/~kabanets/papers/natural-learning-short.pdf">connection</a> between certain learning algorithms and the <a href="https://en.wikipedia.org/wiki/Natural_proof">natural</a> <a href="https://rjlipton.wordpress.com/2009/03/25/whos-afraid-of-natural-proofs/">proofs</a> of Alexander Razborov and Stephen Rudich. The hardness predicate at the core of a natural proof is a classifier to distinguish (succinct) hard Boolean functions from easy ones. There is a duality between upper and lower bounds that in particular leads to the unconditional result that the discrete log problem, which is related to factoring and equally amenable to Peter Shor’s famous polynomial-time quantum algorithm, does not have natural proofs of hardness—because their existence would make discrete log relatively easy. </p>
<p>
Talking about quantum, we predict:</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <em>Quantum supremacy will be proved—finally.</em> But be careful: there is a problem with this whole direction. See the next section.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <em>An algorithm originating in a theoretical model will be enshrined in law.</em> </p>
<p>
There are several near-term opportunities for this. The Supreme Court yesterday agreed to <a href="https://www.cnn.com/2019/01/04/politics/supreme-court-gerrymandering-cases/index.html">hear</a> two cases on partisan gerrymandering, at least one of which promises to codify an algorithmic criterion for excessive vote dilution. Maine adopted a automatic-runoff voting system whose dependence on computer implementation gave grounds for an unsuccessful <a href="https://www.americanthinker.com/blog/2018/11/maine_gop_rep_sues_to_stop_counting_ranked_choice_ballots.html">lawsuit</a>. Algorithmic fairness is a burgeoning area which we <a href="https://rjlipton.wordpress.com/2017/11/20/a-magic-madison-visit/">discussed</a> a year-plus ago. <a href="https://www.sciencemag.org/news/2019/01/can-set-equations-keep-us-census-data-private">Use</a> of differential privacy by the U.S. Census could involve legislation. We distinguish legal provisions from the myriad problematic uses of algorithmic models in public and private <em>policy</em> ranging from credit evaluations to parole decisions to college admissions and much else.</p>
<p>
<img alt="{\bullet}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet}"/> <em>The lines between heuristically solvable and really hard problems will become clearer.</em> We have <a href="https://rjlipton.wordpress.com/2016/07/10/the-world-turned-upside-down/">previously</a> <a href="https://rjlipton.wordpress.com/2014/02/28/practically-pnp/">opined</a> that the great success of SAT solvers in particular renders the <img alt="{\mathsf{P=NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%3DNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{P=NP}}"/> question moot for many purposes. Well, now we say the opposite: SAT solvers will hit a wall.</p>
<p>
</p><p/><h2> Quantum Supremacy and Advantage </h2><p/>
<p/><p>
Ken recently attended a workshop in central New York that aimed to bring together researchers in many fields working on quantum devices. Materials for the workshop led off with the question of building quantum computers and highlighted Gil Kalai’s skeptical position in particular. An <a href="https://rjlipton.wordpress.com/2012/01/30/perpetual-motion-of-the-21st-century/">eight</a>–<a href="https://rjlipton.wordpress.com/2012/02/15/nature-does-not-conspire/">part</a> <a href="https://rjlipton.wordpress.com/2012/06/20/can-you-hear-the-shape-of-a-quantum-computer/">debate</a> between him and Aram Harrow which we hosted in 2012 <a href="https://rjlipton.wordpress.com/2012/03/05/the-quantum-super-pac/">involved</a> also John Preskill and <a href="https://rjlipton.wordpress.com/2012/10/03/quantum-supremacy-or-classical-control/">ended</a> with a discussion of quantum <a href="https://en.wikipedia.org/wiki/Quantum_supremacy">supremacy</a>, a term advanced that year by Preskill. The workshop preferred the term quantum <em>advantage</em>. We interpret these terms as having the following distinction:</p>
<ul>
<li>
(a) Quantum <em>supremacy</em> means that a quantum device can perform general-purpose computations that no classical program or device can emulate in comparably feasible time. <p/>
</li><li>
(b) Quantum <em>advantage</em> means that some particular practical task can be achieved by available quantum devices at lower costs than near-term available classical devices.
</li></ul>
<p>
As theoreticians we tend to think about (a) but many businesses and public-sector organizations would be ecstatic to have (b) in important applications. </p>
<p>
A new angle on (a) was shown by the new construction by Ran Raz and Avishay Tal of an oracle <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/> such that <img alt="{\mathsf{BQP}^A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BBQP%7D%5EA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{BQP}^A}"/> is not in <img alt="{\mathsf{PH}^A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BPH%7D%5EA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{PH}^A}"/>. This was <a href="https://blog.computationalcomplexity.org/2018/12/complexity-year-in-review-2018.html">hailed</a> as the “result of the year” by Lance Fortnow (his second and our first is this <a href="https://eccc.weizmann.ac.il/report/2018/006/">progress</a> on the Unique Games Conjecture), and Scott Aaronson furnished a great <a href="https://www.scottaaronson.com/blog/?p=3827">discussion</a> of its genesis and further ramifications in complexity theory. <a href="https://www.quantamagazine.org/finally-a-problem-that-only-quantum-computers-will-ever-be-able-to-solve-20180621/">Several</a> <a href="https://cacm.acm.org/magazines/2019/1/233514-quantum-leap/fulltext">popular</a> <a href="https://www.thehindu.com/sci-tech/science/quantum-computers-have-an-edge-over-classical-ones-says-the-oracle/article24420375.ece">articles</a> tried to pump this as non-oracle evidence for (a). But there is the over-arching problem:</p>
<blockquote><p><b> </b> <em> We know <img alt="{\mathsf{P \subseteq BPP \subseteq BQP \subseteq PP \subseteq P^{\#P} \subseteq PSPACE}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%5Csubseteq+BPP+%5Csubseteq+BQP+%5Csubseteq+PP+%5Csubseteq+P%5E%7B%5C%23P%7D+%5Csubseteq+PSPACE%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\mathsf{P \subseteq BPP \subseteq BQP \subseteq PP \subseteq P^{\#P} \subseteq PSPACE}}"/> but we don’t know <img alt="{\mathsf{P \neq PSPACE}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%5Cneq+PSPACE%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\mathsf{P \neq PSPACE}}"/>. </em>
</p></blockquote>
<p/><p>
So how are we ever going to be able to <em>prove</em> any form of supremacy? Even if we replace ‘polynomial time’ as our definition of ‘feasible’ by something more concrete, how can we prove that successful classical heuristics <em>do not exist</em>? On a certain practical problem of general import, Ewin Tang, a teenager in Texas advised by Scott, <a href="https://arxiv.org/abs/1807.04271">designed</a> an improved classical algorithm for low-rank matrix completion that <a href="https://www.quantamagazine.org/teenager-finds-classical-alternative-to-quantum-recommendation-algorithm-20180731/">eliminated</a> a previous quantum exponential advantage in the time dependence on the rank parameter. It is not just a case of <em>whether</em> we can prove supremacy, but judging <em>when</em> general quantum computers will be built to realize it.</p>
<p>
Whereas, the <em>when</em> involved in (b) is <em>now</em>. If a quantum device can do something useful now that classical methods are not delivering now, then it does not matter if the latter could be improved at greater hardware and development cost to work a year from now. This has been the gung-ho tenor of many responses to the recently-<a href="https://www.fedscoop.com/trump-signs-national-quantum-initiative-law/">signed</a> National Quantum Initiative Act. We do, however, still need to find and build said devices…</p>
<p>
As for the status of (a), we don’t know any better thought for January than the Janus-like title of this <a href="https://arxiv.org/abs/1807.10749">paper</a> by Igor Markov, Aneeqa Fatima, Sergei Isakov, and Sergio Boixo: </p>
<blockquote><p><b> </b> <em> “Quantum Supremacy Is Both Closer and Farther than It Appears.” </em>
</p></blockquote>
<p>
</p><p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
What are your predictions for 2019? What are the most important matters we’ve left unsaid?</p>
<p>
[added some words to end of intro]</p></font></font></div>
    </content>
    <updated>2019-01-06T19:03:39Z</updated>
    <published>2019-01-06T19:03:39Z</published>
    <category term="All Posts"/>
    <category term="History"/>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="Oldies"/>
    <category term="2018"/>
    <category term="2019"/>
    <category term="Isaac Asimov"/>
    <category term="New Year's"/>
    <category term="predictions"/>
    <category term="quantum advantage"/>
    <category term="quantum supremacy"/>
    <category term="year-in-review"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-01-08T00:28:43Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://cstheory.stackexchange.com/q/42163</id>
    <link href="https://cstheory.stackexchange.com/questions/42163/immutable-space-model" rel="alternate" type="text/html"/>
    <title>Immutable Space Model</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I have heard it said that time is more precious than space because we can reuse space but not time.  What if we treat space with this much reverence?</p>

<h3>What is generally known about models of computation in which space is immutable?</h3>

<p>I would expect such models to initialize each memory cell to some "blank" state and then only allow the writing of some "non-blank" value to each cell at most once.</p>

<p>The study of <a href="https://en.wikipedia.org/wiki/Persistent_data_structure" rel="noreferrer">persistent data structures</a> seems to me like a possible way to answer this question.</p>

<p>I thought of this question while studying functional programming, which highly values immutability.</p></div>
    </summary>
    <updated>2019-01-06T15:37:04Z</updated>
    <published>2019-01-06T15:37:04Z</published>
    <category scheme="https://cstheory.stackexchange.com/tags" term="reference-request"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="ds.data-structures"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="functional-programming"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="space-complexity"/>
    <author>
      <name>Tyson Williams</name>
      <uri>https://cstheory.stackexchange.com/users/3964</uri>
    </author>
    <source>
      <id>https://cstheory.stackexchange.com/feeds/</id>
      <link href="https://cstheory.stackexchange.com/feeds/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory.stackexchange.com/questions" rel="alternate" type="text/html"/>
      <link href="http://www.creativecommons.org/licenses/by-sa/3.0/rdf" rel="license"/>
      <subtitle>most recent 30 from cstheory.stackexchange.com</subtitle>
      <title>Recent Questions - Theoretical Computer Science Stack Exchange</title>
      <updated>2019-01-08T00:32:53Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://cstheory.stackexchange.com/q/42161</id>
    <link href="https://cstheory.stackexchange.com/questions/42161/is-this-partition-problem-strongly-np-complete" rel="alternate" type="text/html"/>
    <title>Is this partition problem strongly NP-complete?</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Some computational problems have variants that appear to be harder. For instance, Graph Automorphism (GA) problem has quasi-polynomial time algorithm ( by Babai's Graph Isomorphism result) while the fixed-point free GA problem is NP-complete. </p>

<p><a href="https://en.wikipedia.org/wiki/Partition_problem" rel="nofollow noreferrer">Partition problem</a> is weakly NP-complete problem since it has pseudo-polynomial time algorithm. I am interested in variants that are strongly NP-complete.</p>

<p>Here is a variant of partition problem:</p>

<p>Restricted partition problem</p>

<p><strong>Input</strong>: Set <span class="math-container">$S$</span> of <span class="math-container">$2N$</span> integers, and a collection <span class="math-container">$P$</span> of pairs from <span class="math-container">$S$</span>, <span class="math-container">$0 \lt |P| \lt N$</span> </p>

<p><strong>Query</strong>: Is there a partition of <span class="math-container">$S$</span> into two equal cardinality parts <span class="math-container">$A$</span> and <span class="math-container">$S-A$</span> such that both parts have the same sum and no pair in <span class="math-container">$P$</span> has both elements in one side of the partition?</p>

<blockquote>
  <p>Is this variant of partition problem NP-complete in the strong sense? </p>
</blockquote>

<p>This was posted first on <a href="https://mathoverflow.net/questions/306039/is-this-partition-problem-strongly-np-complete">Math overflow</a> (I believe the posted answer is incorrect since the proposed dynamic programming algorithm does not take into consideration the cardinality of <span class="math-container">$P$</span>).</p></div>
    </summary>
    <updated>2019-01-06T12:45:42Z</updated>
    <published>2019-01-06T12:45:42Z</published>
    <category scheme="https://cstheory.stackexchange.com/tags" term="cc.complexity-theory"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="partition-problem"/>
    <author>
      <name>Mohammad Al-Turkistany</name>
      <uri>https://cstheory.stackexchange.com/users/495</uri>
    </author>
    <source>
      <id>https://cstheory.stackexchange.com/feeds/</id>
      <link href="https://cstheory.stackexchange.com/feeds/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory.stackexchange.com/questions" rel="alternate" type="text/html"/>
      <link href="http://www.creativecommons.org/licenses/by-sa/3.0/rdf" rel="license"/>
      <subtitle>most recent 30 from cstheory.stackexchange.com</subtitle>
      <title>Recent Questions - Theoretical Computer Science Stack Exchange</title>
      <updated>2019-01-08T00:32:53Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://cstheory.stackexchange.com/q/42160</id>
    <link href="https://cstheory.stackexchange.com/questions/42160/maximize-edges-minus-vertices-in-a-weighted-graph" rel="alternate" type="text/html"/>
    <title>maximize edges minus vertices in a weighted graph</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>for a given weighted vertices and edges graph, we want to find the maximum subgraph. the maximum subgraph is made of some vertices and some edges of the given graph which sum of the edges minus sum of the vertices is maximum. what is the algorithm for this problem? or any help with the code please.</p></div>
    </summary>
    <updated>2019-01-06T11:00:18Z</updated>
    <published>2019-01-06T11:00:18Z</published>
    <category scheme="https://cstheory.stackexchange.com/tags" term="graph-theory"/>
    <author>
      <name>andrew</name>
      <uri>https://cstheory.stackexchange.com/users/51663</uri>
    </author>
    <source>
      <id>https://cstheory.stackexchange.com/feeds/</id>
      <link href="https://cstheory.stackexchange.com/feeds/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory.stackexchange.com/questions" rel="alternate" type="text/html"/>
      <link href="http://www.creativecommons.org/licenses/by-sa/3.0/rdf" rel="license"/>
      <subtitle>most recent 30 from cstheory.stackexchange.com</subtitle>
      <title>Recent Questions - Theoretical Computer Science Stack Exchange</title>
      <updated>2019-01-08T00:32:53Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://cstheory.stackexchange.com/q/42159</id>
    <link href="https://cstheory.stackexchange.com/questions/42159/nusmv-how-to-indicate-the-execution-should-visit-some-states-infinitely-often" rel="alternate" type="text/html"/>
    <title>NuSMV - How to indicate the execution should visit some states infinitely often?</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I have the following kripke structure:</p>

<p><a href="https://i.stack.imgur.com/3xDPG.png" rel="nofollow noreferrer"><img alt="enter image description here" src="https://i.stack.imgur.com/3xDPG.png"/></a></p>

<p>I need my model to follow the LTL constraint that state d will be visited infinitely often:</p>

<pre><code>LTLSPEC  G F (modelState=d)
</code></pre>

<p>This constraint fails due to existence of the loop .... b-&gt;c-&gt;b-&gt;c ......  </p>

<p>Question: What would be a solution to this problem? This may be related to fair traces, but I am not very familiar with that, or how to indicate d as a fair state in NuSMV. </p>

<p>I am learning model checking on my own and I appreciate your help very much.</p></div>
    </summary>
    <updated>2019-01-06T05:47:32Z</updated>
    <published>2019-01-06T05:47:32Z</published>
    <category scheme="https://cstheory.stackexchange.com/tags" term="model-checking"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="formal-methods"/>
    <author>
      <name>Fabiana</name>
      <uri>https://cstheory.stackexchange.com/users/51646</uri>
    </author>
    <source>
      <id>https://cstheory.stackexchange.com/feeds/</id>
      <link href="https://cstheory.stackexchange.com/feeds/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory.stackexchange.com/questions" rel="alternate" type="text/html"/>
      <link href="http://www.creativecommons.org/licenses/by-sa/3.0/rdf" rel="license"/>
      <subtitle>most recent 30 from cstheory.stackexchange.com</subtitle>
      <title>Recent Questions - Theoretical Computer Science Stack Exchange</title>
      <updated>2019-01-08T00:32:53Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://cstheory.stackexchange.com/q/42158</id>
    <link href="https://cstheory.stackexchange.com/questions/42158/best-polynomial-time-approximation-factor-for-np-optimization-problems" rel="alternate" type="text/html"/>
    <title>Best polynomial-time approximation factor for NP-optimization problems</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Let us say that a function <span class="math-container">$f(n)$</span> is the <strong>best approximation factor</strong> for an NP-optimization problem, if both of the following hold:</p>

<ol>
<li><p>There exist a polynomial-time algorithm <span class="math-container">$A,$</span> and an integer <span class="math-container">$n_0$</span>, such that <span class="math-container">$A$</span> provides an <span class="math-container">$f(n)$</span>-approximation for the NP-optimization problem for every instance with size <span class="math-container">$n\geq n_0$</span>. (Note: the role of <span class="math-container">$n_0$</span> is merely to treat potentially deviant small instances, which might make the function "ugly.")</p></li>
<li><p>There is no polynomial-time <span class="math-container">$(1-o(1))f(n)$</span> approximation, unless <span class="math-container">$P=NP$</span>.</p></li>
</ol>

<p>A classic example where such a best approximation is known is the SET COVER problem (for a summary and references see its Wikipedia page): the Greedy Algorithm provides an <span class="math-container">$\ln n$</span> approximation, but there is no  <span class="math-container">$(1-o(1))\ln n$</span> approximation, unless <span class="math-container">$P=NP$</span>.</p>

<p><strong>Questions:</strong></p>

<ol>
<li><p>Which are some other interesting NP-optimization problems for which a best approximation factor, along with its realizing algorithm, are known?  </p></li>
<li><p>Are there any counterexamples, i.e., NP-optimization problems, for which such a best approximation cannot exist, unless <span class="math-container">$P=NP$</span>?</p></li>
</ol></div>
    </summary>
    <updated>2019-01-05T16:54:03Z</updated>
    <published>2019-01-05T16:54:03Z</published>
    <category scheme="https://cstheory.stackexchange.com/tags" term="cc.complexity-theory"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="np-hardness"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="approximation-algorithms"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="approximation-hardness"/>
    <author>
      <name>Andras Farago</name>
      <uri>https://cstheory.stackexchange.com/users/12710</uri>
    </author>
    <source>
      <id>https://cstheory.stackexchange.com/feeds/</id>
      <link href="https://cstheory.stackexchange.com/feeds/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory.stackexchange.com/questions" rel="alternate" type="text/html"/>
      <link href="http://www.creativecommons.org/licenses/by-sa/3.0/rdf" rel="license"/>
      <subtitle>most recent 30 from cstheory.stackexchange.com</subtitle>
      <title>Recent Questions - Theoretical Computer Science Stack Exchange</title>
      <updated>2019-01-08T00:32:53Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://cstheory.stackexchange.com/q/42155</id>
    <link href="https://cstheory.stackexchange.com/questions/42155/why-cant-a-left-recursive-non-deterministic-or-ambiguous-grammar-be-ll1" rel="alternate" type="text/html"/>
    <title>Why can't a left-recursive, non-deterministic, or ambiguous grammar be LL(1)?</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I've learned from several sources that an LL(1) grammar is:</p>

<ol>
<li>unambiguous,</li>
<li>not left-recursive,</li>
<li>and, deterministic (left-factorized).</li>
</ol>

<p>What I can't fully understand is why the above is true for any LL(1) grammar. I know the LL(1) parsing table will have multiple entries at some cells, but what I really want to get is a formal and general (not with an example) proof to the following proposition(s):</p>

<p>A left-recursive (1), non-deterministic (2), or ambiguous (3) grammar is not LL(1).</p></div>
    </summary>
    <updated>2019-01-05T13:29:02Z</updated>
    <published>2019-01-05T13:29:02Z</published>
    <category scheme="https://cstheory.stackexchange.com/tags" term="fl.formal-languages"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="grammars"/>
    <author>
      <name>Mr Geek</name>
      <uri>https://cstheory.stackexchange.com/users/39204</uri>
    </author>
    <source>
      <id>https://cstheory.stackexchange.com/feeds/</id>
      <link href="https://cstheory.stackexchange.com/feeds/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory.stackexchange.com/questions" rel="alternate" type="text/html"/>
      <link href="http://www.creativecommons.org/licenses/by-sa/3.0/rdf" rel="license"/>
      <subtitle>most recent 30 from cstheory.stackexchange.com</subtitle>
      <title>Recent Questions - Theoretical Computer Science Stack Exchange</title>
      <updated>2019-01-08T00:32:53Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://cstheory.stackexchange.com/q/42150</id>
    <link href="https://cstheory.stackexchange.com/questions/42150/prove-that-if-a-is-np-complete-and-b-is-conp-complete-than-axb-is-np-conp-com" rel="alternate" type="text/html"/>
    <title>Prove that if A is NP-complete and B is coNP-complete, than AxB is NP-, coNP-complete</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>AxB means cartesian product of A and B.</p>

<p>May someone help me with this? I even have no idea how to prove that AxB belongs to NP or coNP</p></div>
    </summary>
    <updated>2019-01-04T22:45:04Z</updated>
    <published>2019-01-04T22:45:04Z</published>
    <category scheme="https://cstheory.stackexchange.com/tags" term="cc.complexity-theory"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="np-hardness"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="complexity-classes"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="np-complete"/>
    <author>
      <name>guest</name>
      <uri>https://cstheory.stackexchange.com/users/51651</uri>
    </author>
    <source>
      <id>https://cstheory.stackexchange.com/feeds/</id>
      <link href="https://cstheory.stackexchange.com/feeds/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory.stackexchange.com/questions" rel="alternate" type="text/html"/>
      <link href="http://www.creativecommons.org/licenses/by-sa/3.0/rdf" rel="license"/>
      <subtitle>most recent 30 from cstheory.stackexchange.com</subtitle>
      <title>Recent Questions - Theoretical Computer Science Stack Exchange</title>
      <updated>2019-01-08T00:32:53Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://cstheory.stackexchange.com/q/42148</id>
    <link href="https://cstheory.stackexchange.com/questions/42148/feel-dissatisfied-after-each-submission" rel="alternate" type="text/html"/>
    <title>Feel dissatisfied after each submission</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I am a third year graduate student at a "top-20" university who works on fine-grained complexity (lots of playing with 3-SUM, OV and the usual popular hardness conjectures). I have been fairly productive over the last year or so and have 3 accepted papers and two submitted papers. All of this to say that I am a fairly experienced graduate student and what I am about to describe is not anecdotal.</p>

<p>Every submission brings me more dissatisfaction than satisfaction. Just before I start working on a problem, me and my advisor identify a list of concrete questions that need to be answered. After lots of thinking, we have some very nice non-trivial results which gives me a lot of happiness and satisfaction. As we start to write down all of the results, inevitably, there are some more interesting variants that pop up but are much harder to make progress on. After the initial euphoria point, I feel everything seems to go downhill. There are so many variants that also need to be answered, are clearly in the purview of the problem at hand but I am not able to. By the time we submit the paper, I am so dismayed that results in the paper seem almost trivial. Perhaps this is simply tunnel vision, but I can't overcome the sadness about not being able to answer peripheral questions (although these make for a terrific conclusion section).</p>

<p>This has happened every single time and I am wondering if this is a common feeling. Do other people in theory community feel the same way? I am not sure if this is an academia wide feeling. My fellow graduate students from other areas are over the moon after every submission (but this is just anecdotal).</p>

<p>Edit - I see that there is another soft-question on the front page. I apologize for adding another one. Its holiday season and (only?) after a few drinks, one starts to ponder over these things!</p></div>
    </summary>
    <updated>2019-01-04T17:14:28Z</updated>
    <published>2019-01-04T17:14:28Z</published>
    <category scheme="https://cstheory.stackexchange.com/tags" term="soft-question"/>
    <author>
      <name>karmanaut</name>
      <uri>https://cstheory.stackexchange.com/users/35523</uri>
    </author>
    <source>
      <id>https://cstheory.stackexchange.com/feeds/</id>
      <link href="https://cstheory.stackexchange.com/feeds/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory.stackexchange.com/questions" rel="alternate" type="text/html"/>
      <link href="http://www.creativecommons.org/licenses/by-sa/3.0/rdf" rel="license"/>
      <subtitle>most recent 30 from cstheory.stackexchange.com</subtitle>
      <title>Recent Questions - Theoretical Computer Science Stack Exchange</title>
      <updated>2019-01-08T00:32:53Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://theorydish.blog/?p=1474</id>
    <link href="https://theorydish.blog/2019/01/04/on-pac-analysis-and-deep-neural-networks/" rel="alternate" type="text/html"/>
    <title>On PAC Analysis and Deep Neural Networks</title>
    <summary>Guest post by Amit Daniely and Roy Frostig. For years now—especially since the landmark work of Krishevsky et. al.—learning deep neural networks has been a method of choice in prediction and regression tasks, especially in perceptual domains found in computer vision and natural language processing. How effective might it be for solving theoretical tasks? Specifically, focusing on supervised learning: Can a deep neural network, paired with a stochastic gradient method, be shown to PAC learn any interesting concept class in polynomial time? Depending on assumptions, and on one’s definition of “interesting,” present-day learning theory gives answers ranging from “no, that would solve hard problems,” to, more recently: Theorem: Networks with depth between 2 and ,1 having standard activation functions,2 with weights initialized at random and trained with stochastic gradient descent, learn, in polynomial time, constant degree large margin polynomial thresholds. Learning constant-degree polynomials can also be done simply with a linear predictor over a polynomial embedding, or, in other words, by learning a halfspace. That said, what a linear predictor can do is also essentially the state of the art in PAC learning, so this result pushes neural net learning at least as far as one might hope at first. [...]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><em>Guest post by <a href="http://amitdaniely.com/">Amit Daniely</a> and <a href="https://cs.stanford.edu/~rfrostig/">Roy Frostig</a>.</em></p>
<p>For years now—especially since the landmark work of <a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks">Krishevsky et. al.</a>—learning deep neural networks has been a method of choice in prediction and regression tasks, especially in perceptual domains found in computer vision and natural language processing. How effective might it be for solving <em>theoretical</em> tasks?</p>
<p>Specifically, focusing on supervised learning:</p>
<blockquote><p>Can a deep neural network, paired with a stochastic gradient method, be shown to <a href="https://en.wikipedia.org/wiki/Probably_approximately_correct_learning">PAC learn</a> any interesting concept class in polynomial time?</p></blockquote>
<p>Depending on assumptions, and on one’s definition of “interesting,” present-day learning theory gives answers ranging from “no, that would solve hard problems,” to, more recently:</p>
<blockquote><p><strong>Theorem:</strong> Networks with depth between 2 and <img alt="\log(n)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clog%28n%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\log(n)"/>,<a class="footnoteRef" href="https://theorydish.blog/feed/#fn1" id="fnref1"><sup>1</sup></a> having standard activation functions,<a class="footnoteRef" href="https://theorydish.blog/feed/#fn2" id="fnref2"><sup>2</sup></a> with weights initialized at random and trained with stochastic gradient descent, learn, in polynomial time, constant degree large margin polynomial thresholds.</p></blockquote>
<p>Learning constant-degree polynomials can also be done simply <em>with a linear predictor</em> over a polynomial embedding, or, in other words, by learning a halfspace. That said, what a linear predictor can do is also <em>essentially the state of the art</em> in PAC learning, so this result pushes neural net learning at least as far as one might hope at first. We will return to this point later, and discuss some limitations of PAC analysis once they are more apparent. In this sense, this post will turn out to be as much an overview of some PAC learning theory as it is about neural networks.</p>
<p>Naturally, there is a wide variety of theoretical perspectives on neural network analysis, especially in the past couple of years. Our goal in this post is not to survey or cover any extensive body of work, but simply to summarize our own recent line (from two papers: <a href="https://papers.nips.cc/paper/6427-toward-deeper-understanding-of-neural-networks-the-power-of-initialization-and-a-dual-view-on-expressivity">DFS’16</a> and <a href="https://papers.nips.cc/paper/6836-sgd-learns-the-conjugate-kernel-class-of-the-network">D’17</a>), and to highlight the interaction with PAC learning.</p>
<h2 id="neural-network-learning">Neural network learning</h2>
<p>First, let’s define a learning task. To keep things simple, we’ll focus on binary classification over the boolean cube, without noise. Formally:</p>
<blockquote><p><strong>(Binary classification.)</strong> Given examples of the form <img alt="(x,h^*(x))" class="latex" src="https://s0.wp.com/latex.php?latex=%28x%2Ch%5E%2A%28x%29%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="(x,h^*(x))"/>, where <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="x"/> is sampled from some unknown distribution <img alt="\mathcal D" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal+D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\mathcal D"/> on <img alt="\{\pm 1\}^n" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B%5Cpm+1%5C%7D%5En&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\{\pm 1\}^n"/>, and <img alt="h^*:\{\pm 1\}^n\to\{\pm 1\}" class="latex" src="https://s0.wp.com/latex.php?latex=h%5E%2A%3A%5C%7B%5Cpm+1%5C%7D%5En%5Cto%5C%7B%5Cpm+1%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="h^*:\{\pm 1\}^n\to\{\pm 1\}"/> is some unknown function (the one that we wish to learn), find a function <img alt="h:\{\pm 1\}^n\to\{\pm 1\}" class="latex" src="https://s0.wp.com/latex.php?latex=h%3A%5C%7B%5Cpm+1%5C%7D%5En%5Cto%5C%7B%5Cpm+1%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="h:\{\pm 1\}^n\to\{\pm 1\}"/> whose error, <img alt="\mathrm{Err}(h) = \mathrm{Pr}_{x\sim\mathcal{D}} \left(h(x) \ne h^*(x)\right)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7BErr%7D%28h%29+%3D+%5Cmathrm%7BPr%7D_%7Bx%5Csim%5Cmathcal%7BD%7D%7D+%5Cleft%28h%28x%29+%5Cne+h%5E%2A%28x%29%5Cright%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\mathrm{Err}(h) = \mathrm{Pr}_{x\sim\mathcal{D}} \left(h(x) \ne h^*(x)\right)"/>, is small.</p></blockquote>
<p>Second, define a neural network <img alt="\mathcal N" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal+N&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\mathcal N"/> formally as a directed acyclic graph <img alt="(V, E)" class="latex" src="https://s0.wp.com/latex.php?latex=%28V%2C+E%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="(V, E)"/> whose vertices <img alt="V" class="latex" src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="V"/> are called neurons. Of them, <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="n"/> are input neurons, one is an output neuron, and the rest are called hidden neurons.<a class="footnoteRef" href="https://theorydish.blog/feed/#fn3" id="fnref3"><sup>3</sup></a> A network together with a weight vector <img alt="w = \{w_{uv} : uv \in E\} \cup \{b_v : v \in V \}" class="latex" src="https://s0.wp.com/latex.php?latex=w+%3D+%5C%7Bw_%7Buv%7D+%3A+uv+%5Cin+E%5C%7D+%5Ccup+%5C%7Bb_v+%3A+v+%5Cin+V+%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="w = \{w_{uv} : uv \in E\} \cup \{b_v : v \in V \}"/> defines a predictor <img alt="h_{\mathcal N, w} : \{\pm 1\}^n \to \{\pm 1\}" class="latex" src="https://s0.wp.com/latex.php?latex=h_%7B%5Cmathcal+N%2C+w%7D+%3A+%5C%7B%5Cpm+1%5C%7D%5En+%5Cto+%5C%7B%5Cpm+1%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="h_{\mathcal N, w} : \{\pm 1\}^n \to \{\pm 1\}"/> whose prediction is computed by propagating <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="x"/> forward through the network. Concretely:</p>
<ul>
<li>For an input neuron <img alt="v" class="latex" src="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="v"/>, <img alt="h_{v,w}(x)" class="latex" src="https://s0.wp.com/latex.php?latex=h_%7Bv%2Cw%7D%28x%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="h_{v,w}(x)"/> is the corresponding coordinate in <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="x"/>.</li>
<li>For a hidden neuron <img alt="v" class="latex" src="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="v"/>, define<img alt="h_{v,w}(x) = \sigma\left( \sum_{u \in \mathrm{IN}(v)} w_{uv} h_{u,w}(x) + b_v \right)." class="latex" src="https://s0.wp.com/latex.php?latex=h_%7Bv%2Cw%7D%28x%29+%3D+%5Csigma%5Cleft%28+%5Csum_%7Bu+%5Cin+%5Cmathrm%7BIN%7D%28v%29%7D+w_%7Buv%7D+h_%7Bu%2Cw%7D%28x%29+%2B+b_v+%5Cright%29.&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="h_{v,w}(x) = \sigma\left( \sum_{u \in \mathrm{IN}(v)} w_{uv} h_{u,w}(x) + b_v \right)."/>The scalar weight <img alt="b_v" class="latex" src="https://s0.wp.com/latex.php?latex=b_v&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="b_v"/> is called a “bias.” In this post, the function <img alt="\sigma : \mathbb{R} \to \mathbb{R}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csigma+%3A+%5Cmathbb%7BR%7D+%5Cto+%5Cmathbb%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\sigma : \mathbb{R} \to \mathbb{R}"/> is the ReLU activation <img alt="\sigma(t) = \max\{t, 0\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csigma%28t%29+%3D+%5Cmax%5C%7Bt%2C+0%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\sigma(t) = \max\{t, 0\}"/>, though others are possible as well.</li>
<li>For the output neuron <img alt="o" class="latex" src="https://s0.wp.com/latex.php?latex=o&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="o"/>, we drop the activation: <img alt="h_{o,w}(x) = \sum_{u \in \mathrm{IN}(o)} w_{uo} h_{u,w}(x) + b_o" class="latex" src="https://s0.wp.com/latex.php?latex=h_%7Bo%2Cw%7D%28x%29+%3D+%5Csum_%7Bu+%5Cin+%5Cmathrm%7BIN%7D%28o%29%7D+w_%7Buo%7D+h_%7Bu%2Cw%7D%28x%29+%2B+b_o&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="h_{o,w}(x) = \sum_{u \in \mathrm{IN}(o)} w_{uo} h_{u,w}(x) + b_o"/>.</li>
</ul>
<p>Finally, let <img alt="h_{\mathcal N, w}(x) = h_{o, w}(x)" class="latex" src="https://s0.wp.com/latex.php?latex=h_%7B%5Cmathcal+N%2C+w%7D%28x%29+%3D+h_%7Bo%2C+w%7D%28x%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="h_{\mathcal N, w}(x) = h_{o, w}(x)"/>. This computes a real-valued function, so where we’d like to use it for classification, we do so by thresholding, and abuse the notation <img alt="\mathrm{Err}(h_w)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7BErr%7D%28h_w%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\mathrm{Err}(h_w)"/> to mean <img alt="\mathrm{Err}(\mathrm{sign} \circ h_w)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7BErr%7D%28%5Cmathrm%7Bsign%7D+%5Ccirc+h_w%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\mathrm{Err}(\mathrm{sign} \circ h_w)"/>.</p>
<p>Some intuition for this definition would come from verifying that:</p>
<ul>
<li>Any function <img alt="h : \{\pm 1\}^n \to \{\pm 1\}" class="latex" src="https://s0.wp.com/latex.php?latex=h+%3A+%5C%7B%5Cpm+1%5C%7D%5En+%5Cto+%5C%7B%5Cpm+1%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="h : \{\pm 1\}^n \to \{\pm 1\}"/> can be computed by a network of depth two and <img alt="2^n" class="latex" src="https://s0.wp.com/latex.php?latex=2%5En&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="2^n"/> hidden neurons.</li>
<li>The parity function <img alt="h(x) = \prod_{i=1}^n x_i" class="latex" src="https://s0.wp.com/latex.php?latex=h%28x%29+%3D+%5Cprod_%7Bi%3D1%7D%5En+x_i&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="h(x) = \prod_{i=1}^n x_i"/> can be computed by a network of depth two and <img alt="4n" class="latex" src="https://s0.wp.com/latex.php?latex=4n&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="4n"/> hidden neurons. (NB: this one is a bit more challenging.)</li>
</ul>
<p>In practice, the network architecture (this DAG) is designed based on some domain knowledge, and its design can impact the predictor that’s later selected by SGD. One default architecture, useful in the absence of domain knowledge, is the multi-layer perceptron, comprised of layers of complete bipartite graphs:</p>
<figure><img alt="full_con_net" class="  wp-image-1479 aligncenter" height="426" src="https://theorydish.files.wordpress.com/2019/01/full_con_net.png?w=431&amp;h=426" width="431"/>A toy “fully-connected neural network”, a.k.a. a multi-layer perceptronAnother paradigmatic architecture is a <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">convolutional network</a>:<p/>
</figure>
<figure><img alt="conv_net" class="  wp-image-1478 aligncenter" height="463" src="https://theorydish.files.wordpress.com/2019/01/conv_net.png?w=490&amp;h=463" width="490"/>A toy convolutional neural network</figure>
<p>Convolutional nets capture the notion of spatial input locality in signals such as images and audio.<a class="footnoteRef" href="https://theorydish.blog/feed/#fn4" id="fnref4"><sup>4</sup></a> In the toy example drawn, each clustered triple of neurons is a so-called convolution filter applied to two components below it. In image domains, convolutions filters are two-dimensional and capture responses to spatial 2-D patches of the image or of an intermediate layer.</p>
<p>Training a neural net comprises (i) initialization, and (ii) iterative optimization run until <img alt="\mathrm{sign}(h_w(x)) = h^*(x)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bsign%7D%28h_w%28x%29%29+%3D+h%5E%2A%28x%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\mathrm{sign}(h_w(x)) = h^*(x)"/> for sufficiently many examples <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="x"/>. The initialization step sets the starting values of the weights <img alt="w^0" class="latex" src="https://s0.wp.com/latex.php?latex=w%5E0&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="w^0"/> at random:</p>
<blockquote><p><strong>(Glorot initialization.)</strong> Draw weights <img alt="\{w^0_{uv}\}_{uv\in E}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7Bw%5E0_%7Buv%7D%5C%7D_%7Buv%5Cin+E%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\{w^0_{uv}\}_{uv\in E}"/> from centered Gaussians with variance <img alt="|\mathrm{IN}(v)|^{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cmathrm%7BIN%7D%28v%29%7C%5E%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="|\mathrm{IN}(v)|^{-1}"/> and biases <img alt="\{b^0_{v}\}_{v\in V}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7Bb%5E0_%7Bv%7D%5C%7D_%7Bv%5Cin+V%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\{b^0_{v}\}_{v\in V}"/> from independent standard Gaussians.<a class="footnoteRef" href="https://theorydish.blog/feed/#fn5" id="fnref5"><sup>5</sup></a></p></blockquote>
<p>While other initialization schemes exists, this one is canonical, simple, and, as the reader can verify, satisfies <img alt="\mathbb{E}_{w^0}\left[(h_{v,w^0}(x))^2\right] = 1" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BE%7D_%7Bw%5E0%7D%5Cleft%5B%28h_%7Bv%2Cw%5E0%7D%28x%29%29%5E2%5Cright%5D+%3D+1&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\mathbb{E}_{w^0}\left[(h_{v,w^0}(x))^2\right] = 1"/> for every neuron <img alt="v" class="latex" src="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="v"/> and input <img alt="x \in \{\pm 1\}^n" class="latex" src="https://s0.wp.com/latex.php?latex=x+%5Cin+%5C%7B%5Cpm+1%5C%7D%5En&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="x \in \{\pm 1\}^n"/>.</p>
<p>The optimization step is essentially a local search method from the initial point, using <a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent">stochastic gradient descent</a> (SGD) or a variant thereof.<a class="footnoteRef" href="https://theorydish.blog/feed/#fn6" id="fnref6"><sup>6</sup></a> To apply SGD, we need a function suitable for descent, and we’ll use the commonplace logistic loss <img alt="\ell(z) = \log_2(1+e^{-z})" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell%28z%29+%3D+%5Clog_2%281%2Be%5E%7B-z%7D%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\ell(z) = \log_2(1+e^{-z})"/>, which bounds the zero-one loss <img alt="\ell^{0-1}(z) = \mathbf{1}[z \le 0]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell%5E%7B0-1%7D%28z%29+%3D+%5Cmathbf%7B1%7D%5Bz+%5Cle+0%5D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\ell^{0-1}(z) = \mathbf{1}[z \le 0]"/> from above:</p>
<figure><img alt="losses" class="  wp-image-1480 aligncenter" height="246" src="https://theorydish.files.wordpress.com/2019/01/losses.png?w=329&amp;h=246" width="329"/>The logistic and zero-one losses</figure>
<p> </p>
<p>Define <img alt="L_{\mathcal D}(w) = \mathbb{E}_{x\sim\mathcal D}\left[ \ell(h_w(x)h^*(x)) \right]" class="latex" src="https://s0.wp.com/latex.php?latex=L_%7B%5Cmathcal+D%7D%28w%29+%3D+%5Cmathbb%7BE%7D_%7Bx%5Csim%5Cmathcal+D%7D%5Cleft%5B+%5Cell%28h_w%28x%29h%5E%2A%28x%29%29+%5Cright%5D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="L_{\mathcal D}(w) = \mathbb{E}_{x\sim\mathcal D}\left[ \ell(h_w(x)h^*(x)) \right]"/>. Note that <img alt="\mathrm{Err}(h_w) \le L_{\mathcal D}(w)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7BErr%7D%28h_w%29+%5Cle+L_%7B%5Cmathcal+D%7D%28w%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\mathrm{Err}(h_w) \le L_{\mathcal D}(w)"/>, so finding weights <img alt="w" class="latex" src="https://s0.wp.com/latex.php?latex=w&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="w"/> for which the upper bound <img alt="L_{\mathcal D}" class="latex" src="https://s0.wp.com/latex.php?latex=L_%7B%5Cmathcal+D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="L_{\mathcal D}"/> is small enough implies low error in turn. Meanwhile, <img alt="L_{\mathcal D}" class="latex" src="https://s0.wp.com/latex.php?latex=L_%7B%5Cmathcal+D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="L_{\mathcal D}"/> is amenable to iterative gradient-based minimization.</p>
<p>Given samples from <img alt="\mathcal D" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal+D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\mathcal D"/>, stochastic gradient descent creates an unbiased estimate of the gradient at each step <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="t"/> by drawing a batch of i.i.d. samples <img alt="S_t" class="latex" src="https://s0.wp.com/latex.php?latex=S_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="S_t"/> from <img alt="\mathcal D" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal+D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\mathcal D"/>. The gradient <img alt="\nabla L_{S_t}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cnabla+L_%7BS_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\nabla L_{S_t}"/> at a point <img alt="w" class="latex" src="https://s0.wp.com/latex.php?latex=w&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="w"/> can be computed efficiently by the <a href="https://en.wikipedia.org/wiki/Backpropagation">backpropagation</a> algorithm.</p>
<p>In more complete detail, our prototypical neural network training algorithm is as follows. On input a network <img alt="\mathcal N" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal+N&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\mathcal N"/>, an iteration count <img alt="T" class="latex" src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="T"/>, a batch size <img alt="b" class="latex" src="https://s0.wp.com/latex.php?latex=b&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="b"/>, and a step size <img alt="\eta &gt; 0" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ceta+%3E+0&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\eta &gt; 0"/>:</p>
<p><strong>Algorithm: <em>SGDNN</em></strong></p>
<ol type="1">
<li>Let <img alt="w^0" class="latex" src="https://s0.wp.com/latex.php?latex=w%5E0&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="w^0"/> be random weights sampled per Glorot initialization</li>
<li>For <img alt="t = 1, \ldots, T" class="latex" src="https://s0.wp.com/latex.php?latex=t+%3D+1%2C+%5Cldots%2C+T&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="t = 1, \ldots, T"/>:
<ol type="1">
<li>Sample a batch <img alt="S_{t} = \{(x^t_1, h^*(x^t_1)), \ldots, (x^t_b, h^*(x^t_b))\}" class="latex" src="https://s0.wp.com/latex.php?latex=S_%7Bt%7D+%3D+%5C%7B%28x%5Et_1%2C+h%5E%2A%28x%5Et_1%29%29%2C+%5Cldots%2C+%28x%5Et_b%2C+h%5E%2A%28x%5Et_b%29%29%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="S_{t} = \{(x^t_1, h^*(x^t_1)), \ldots, (x^t_b, h^*(x^t_b))\}"/>, where <img alt="x^t_1, \ldots, x^t_b" class="latex" src="https://s0.wp.com/latex.php?latex=x%5Et_1%2C+%5Cldots%2C+x%5Et_b&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="x^t_1, \ldots, x^t_b"/> are i.i.d. samples from <img alt="\mathcal D" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal+D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\mathcal D"/>.</li>
<li>Update <img alt="w^t \gets w^{t-1} - \eta \nabla L_{S_t}(w^{t-1})" class="latex" src="https://s0.wp.com/latex.php?latex=w%5Et+%5Cgets+w%5E%7Bt-1%7D+-+%5Ceta+%5Cnabla+L_%7BS_t%7D%28w%5E%7Bt-1%7D%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="w^t \gets w^{t-1} - \eta \nabla L_{S_t}(w^{t-1})"/>, where<img alt="L_{S_t}(w^{t-1}) = b^{-1} \sum_{i=1}^b \ell(h_{w}(x^t_i) h^*(x^t_i))" class="latex" src="https://s0.wp.com/latex.php?latex=L_%7BS_t%7D%28w%5E%7Bt-1%7D%29+%3D+b%5E%7B-1%7D+%5Csum_%7Bi%3D1%7D%5Eb+%5Cell%28h_%7Bw%7D%28x%5Et_i%29+h%5E%2A%28x%5Et_i%29%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="L_{S_t}(w^{t-1}) = b^{-1} \sum_{i=1}^b \ell(h_{w}(x^t_i) h^*(x^t_i))"/>.</li>
</ol>
</li>
<li>Output <img alt="w^T" class="latex" src="https://s0.wp.com/latex.php?latex=w%5ET&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="w^T"/></li>
</ol>
<h2 id="pac-learning">PAC learning</h2>
<p>Learning a predictor from example data is a general task, and a hard one in the worst case. We cannot efficiently (i.e. in <img alt="\mathrm{poly}(n)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bpoly%7D%28n%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\mathrm{poly}(n)"/> time) compute, let alone learn, general functions from <img alt="\{\pm 1\}^n" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B%5Cpm+1%5C%7D%5En&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\{\pm 1\}^n"/> to <img alt="\{\pm 1\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B%5Cpm+1%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\{\pm 1\}"/>. In fact, any learning algorithm that is guaranteed to succeed in general (i.e. with any target predictor <img alt="h^*" class="latex" src="https://s0.wp.com/latex.php?latex=h%5E%2A&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="h^*"/> over any data distribution <img alt="\mathcal D" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal+D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\mathcal D"/>) runs, in the worst case, in time exponential in <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="n"/>. This is true even for rather weak definitions of “success,” such as finding a predictor with error less than <img alt="1/2 - 2^{-n/2}" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F2+-+2%5E%7B-n%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="1/2 - 2^{-n/2}"/>, i.e. one that slightly outperforms a random guess.</p>
<p>While it is impossible to efficiently learn general functions under general distributions, it might still be possible to learn efficiently under some assumptions on the target <img alt="h^*" class="latex" src="https://s0.wp.com/latex.php?latex=h%5E%2A&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="h^*"/> or the distribution <img alt="\mathcal D" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal+D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\mathcal D"/>. Charting out such assumptions is the realm of learning theorists: by now, they’ve built up a broad catalog of function classes, and have studied the complexity of learning when the target function is in each such class. Although their primary aim has been to develop theory, the potential guidance for practice is easy to imagine: if one’s application domain happens to be modeled well by one of these easily-learnable function classes, there’s a corresponding learning algorithm to consider as well.</p>
<p>The vanilla PAC model makes no assumptions on the data distribution <img alt="\mathcal D" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal+D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\mathcal D"/>, but it does assume the target <img alt="h^*" class="latex" src="https://s0.wp.com/latex.php?latex=h%5E%2A&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="h^*"/> belongs to some simple, predefined class <img alt="\mathcal H" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal+H&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\mathcal H"/>. Formally, a <em>PAC learning problem</em> is defined by a function class<a class="footnoteRef" href="https://theorydish.blog/feed/#fn7" id="fnref7"><sup>7</sup></a> <img alt="\mathcal H \subset \{\pm 1\}^{\{\pm 1\}^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal+H+%5Csubset+%5C%7B%5Cpm+1%5C%7D%5E%7B%5C%7B%5Cpm+1%5C%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\mathcal H \subset \{\pm 1\}^{\{\pm 1\}^n}"/>. A learning algorithm <img alt="\mathcal A" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal+A&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\mathcal A"/> <em>learns</em> the class <img alt="\mathcal H" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal+H&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\mathcal H"/> if, whenever <img alt="h^* \in \mathcal H" class="latex" src="https://s0.wp.com/latex.php?latex=h%5E%2A+%5Cin+%5Cmathcal+H&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="h^* \in \mathcal H"/>, and provided <img alt="\epsilon &gt; 0" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon+%3E+0&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\epsilon &gt; 0"/>, it runs in time <img alt="\mathrm{poly}(1/\epsilon, n)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bpoly%7D%281%2F%5Cepsilon%2C+n%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\mathrm{poly}(1/\epsilon, n)"/>, and returns a function of error at most <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\epsilon"/>, with probability at least 0.9. Note that:</p>
<ol type="1">
<li>The learning algorithm need not return a function from the learnt class.</li>
<li>The polynomial-time requirement means in particular that the learning algorithm cannot output a complete truth table, as its size would be exponential. Instead, it must output a short description of a hypothesis that can be evaluated in polynomial time.</li>
</ol>
<p>For a taste of the computational learning theory literature, here are some of the function classes studied by theorists over the years:</p>
<ol type="1">
<li><em>Linear thresholds (halfspaces):</em> functions that map a halfspace to 1 and its complement to -1. Formally, functions of the form <img alt="x \mapsto \theta(\langle w, x \rangle)" class="latex" src="https://s0.wp.com/latex.php?latex=x+%5Cmapsto+%5Ctheta%28%5Clangle+w%2C+x+%5Crangle%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="x \mapsto \theta(\langle w, x \rangle)"/> for some <img alt="w \in \mathbb{R}^n" class="latex" src="https://s0.wp.com/latex.php?latex=w+%5Cin+%5Cmathbb%7BR%7D%5En&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="w \in \mathbb{R}^n"/>, where <img alt="\theta(z) = 1" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctheta%28z%29+%3D+1&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\theta(z) = 1"/> when <img alt="z &gt; 0" class="latex" src="https://s0.wp.com/latex.php?latex=z+%3E+0&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="z &gt; 0"/> and <img alt="\theta(z) = -1" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctheta%28z%29+%3D+-1&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\theta(z) = -1"/> when <img alt="z \le 0" class="latex" src="https://s0.wp.com/latex.php?latex=z+%5Cle+0&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="z \le 0"/>.</li>
<li><em>Large-margin linear thresholds:</em> for<img alt="\rho(z) = \begin{cases} 1 &amp; z \ge 1 \\ * &amp; -1 \le z \le 1 \\ -1 &amp; z \le -1 \end{cases}," class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho%28z%29+%3D+%5Cbegin%7Bcases%7D+1+%26+z+%5Cge+1+%5C%5C+%2A+%26+-1+%5Cle+z+%5Cle+1+%5C%5C+-1+%26+z+%5Cle+-1+%5Cend%7Bcases%7D%2C&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\rho(z) = \begin{cases} 1 &amp; z \ge 1 \\ * &amp; -1 \le z \le 1 \\ -1 &amp; z \le -1 \end{cases},"/>the class<img alt="\left\{ h : \{\pm 1\}^n \to \{\pm 1\} \mid h(x) = \rho(\langle w,x \rangle) \text{ with } \|w\|_2^2 \le \mathrm{poly}(n) \right\}." class="latex" src="https://s0.wp.com/latex.php?latex=%5Cleft%5C%7B+h+%3A+%5C%7B%5Cpm+1%5C%7D%5En+%5Cto+%5C%7B%5Cpm+1%5C%7D+%5Cmid+h%28x%29+%3D+%5Crho%28%5Clangle+w%2Cx+%5Crangle%29+%5Ctext%7B+with+%7D+%5C%7Cw%5C%7C_2%5E2+%5Cle+%5Cmathrm%7Bpoly%7D%28n%29+%5Cright%5C%7D.&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\left\{ h : \{\pm 1\}^n \to \{\pm 1\} \mid h(x) = \rho(\langle w,x \rangle) \text{ with } \|w\|_2^2 \le \mathrm{poly}(n) \right\}."/></li>
<li><em>Intersections of halfspaces:</em> functions that map an intersection of polynomially many halfspaces to <img alt="1" class="latex" src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="1"/> and its complement to <img alt="-1" class="latex" src="https://s0.wp.com/latex.php?latex=-1&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="-1"/>.</li>
<li><em>Polynomial threshold functions:</em> thresholds of constant-degree polynomials.</li>
<li><em>Large-margin polynomial threshold functions:</em> the class</li>
</ol>
<p><img alt="\left\{ h : \{\pm 1\}^n \to \{\pm 1\} \mid h(x) = \rho\left( \sum_{A \subset [n], |A| \le O(1)} \alpha_A \prod_{i \in A} x_i \right) \;\text{ with }\; \sum_{A} \alpha^2_A \le \mathrm{poly}(n) \right\}." class="latex" src="https://s0.wp.com/latex.php?latex=%5Cleft%5C%7B+h+%3A+%5C%7B%5Cpm+1%5C%7D%5En+%5Cto+%5C%7B%5Cpm+1%5C%7D+%5Cmid+h%28x%29+%3D+%5Crho%5Cleft%28+%5Csum_%7BA+%5Csubset+%5Bn%5D%2C+%7CA%7C+%5Cle+O%281%29%7D+%5Calpha_A+%5Cprod_%7Bi+%5Cin+A%7D+x_i+%5Cright%29+%5C%3B%5Ctext%7B+with+%7D%5C%3B+%5Csum_%7BA%7D+%5Calpha%5E2_A+%5Cle+%5Cmathrm%7Bpoly%7D%28n%29+%5Cright%5C%7D.&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\left\{ h : \{\pm 1\}^n \to \{\pm 1\} \mid h(x) = \rho\left( \sum_{A \subset [n], |A| \le O(1)} \alpha_A \prod_{i \in A} x_i \right) \;\text{ with }\; \sum_{A} \alpha^2_A \le \mathrm{poly}(n) \right\}."/></p>
<ol type="1">
<li><em>Decision trees</em>, <em>deterministic automata</em>, and <em><a href="https://en.wikipedia.org/wiki/Disjunctive_normal_form">DNF</a> formulas</em> of polynomial size.</li>
<li><em>Monotone conjunctions:</em> functions that, for some <img alt="A \subset [n]" class="latex" src="https://s0.wp.com/latex.php?latex=A+%5Csubset+%5Bn%5D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="A \subset [n]"/> map <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="x"/> to <img alt="1" class="latex" src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="1"/> if <img alt="x_i = 1" class="latex" src="https://s0.wp.com/latex.php?latex=x_i+%3D+1&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="x_i = 1"/> for all <img alt="i \in A" class="latex" src="https://s0.wp.com/latex.php?latex=i+%5Cin+A&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="i \in A"/>, and to <img alt="-1" class="latex" src="https://s0.wp.com/latex.php?latex=-1&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="-1"/> otherwise.</li>
<li><em>Parities:</em> functions of the form <img alt="x \mapsto \prod_{i \in A} x_i" class="latex" src="https://s0.wp.com/latex.php?latex=x+%5Cmapsto+%5Cprod_%7Bi+%5Cin+A%7D+x_i&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="x \mapsto \prod_{i \in A} x_i"/> for some <img alt="A \subset [n]" class="latex" src="https://s0.wp.com/latex.php?latex=A+%5Csubset+%5Bn%5D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="A \subset [n]"/>.</li>
<li><em>Juntas:</em> functions that depend on at most <img alt="\log(n)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clog%28n%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\log(n)"/> variables.</li>
</ol>
<p>Learning theorists look at these function classes and work to distinguish those that are efficiently learnable from those that are <em>hard</em> to learn. They establish hardness results by reduction from other computational problems that are conjectured to be hard, such as random XOR-SAT (though none today are conditioned outright on NP hardness); see for example <a href="https://arxiv.org/abs/1404.3378">these</a> <a href="https://arxiv.org/abs/1505.05800">two</a> results. Meanwhile, halfspaces are learnable by linear programming. Parities, or more generally, <img alt="\mathbb{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\mathbb{F}"/>-linear functions for a field <img alt="\mathbb{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\mathbb{F}"/>, are learnable by Gaussian elimination. In turn, via reductions, many other classes are efficiently learnable. This includes polynomial thresholds, decision lists, and more. To give an idea of what’s known in the literature, here is an artist’s depiction of some of what’s currently known:</p>
<figure><img alt="classes" class=" size-full wp-image-1477 aligncenter" src="https://theorydish.files.wordpress.com/2019/01/classes.png?w=620"/>Learnable and conjectured hard-to-learn function classes</figure>
<p> </p>
<p>At a high-level, the upshot from all of this—and if you take away just one thing from this quick tour of PAC—is that:</p>
<blockquote><p>Barring a small handful of exceptions, all known efficiently learnable classes can be reduced to halfspaces or <img alt="\mathbb{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\mathbb{F}"/>-linear functions.</p></blockquote>
<p>Or, to put it more bluntly, <strong>the state of the art in PAC-learnability is essentially linear prediction</strong>.</p>
<h2 id="pac-analyzing-neural-nets">PAC analyzing neural nets</h2>
<p>Research in algorithms and complexity often follows these steps:</p>
<ol type="1">
<li>define a computational problem,</li>
<li>design an algorithm that solves it, and then</li>
<li>establish bounds on the resource requirements of that algorithm.</li>
</ol>
<p>A bound on the algorithm’s performance forms, in turn, a bound on the <em>computational problem’s</em> inherent complexity.</p>
<p>By contrast, we have already decided on our SGDNN algorithm, and we’d like to attain some grasp on its capabilities. So we’d like to do things in a different order:</p>
<ol type="1">
<li>define an <em>algorithm</em> (done),</li>
<li>design a computational problem to which the algorithm can be applied, and then</li>
<li>establish bounds on the resource requirements of the algorithm in solving the problem.</li>
</ol>
<p>Our computational problem will be a PAC learning problem, corresponding to a function class. For SGDNN, an ambitious function class we might consider is the class of all functions realizable by the network. But if we were to follow this approach, we would run up against the same hardness results mentioned before.</p>
<p>So instead, we’ve established the theorem stated at the top of this post. That is, that SGDNN, over a range of network configurations, learns a class that we <em>already know</em> to be learnable: large margin polynomial thresholds. Restated:</p>
<blockquote><p><strong>Theorem, again:</strong> There is a choice of SGDNN step size <img alt="\eta" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ceta&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\eta"/> and number of steps <img alt="T" class="latex" src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="T"/>, as well as a with parameter <img alt="r" class="latex" src="https://s0.wp.com/latex.php?latex=r&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="r"/>, where <img alt="T, r \le \mathrm{poly}(n/\epsilon)" class="latex" src="https://s0.wp.com/latex.php?latex=T%2C+r+%5Cle+%5Cmathrm%7Bpoly%7D%28n%2F%5Cepsilon%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="T, r \le \mathrm{poly}(n/\epsilon)"/>, such that SGDNN on a multi-layer perceptron of depth between 2 and <img alt="\log(n)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clog%28n%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\log(n)"/>, and of width<a class="footnoteRef" href="https://theorydish.blog/feed/#fn8" id="fnref8"><sup>8</sup></a> <img alt="r" class="latex" src="https://s0.wp.com/latex.php?latex=r&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="r"/>, learns large magin polynomials.</p></blockquote>
<p>How rich are large margin polynomials? They contain disjunctions, conjunctions, DNF and <a href="https://en.wikipedia.org/wiki/Conjunctive_normal_form">CNF</a> formulas with a constant many terms, DNF and CNF formulas with a constant many literals in each term. By corollary, SGDNN can PAC learn these classes as well. And at this point, we’ve covered a considerable fraction of the function classes known to be poly-time PAC learnable by <em>any</em> method.</p>
<p>Exceptions include constant-degree polynomial thresholds with no restriction on the coefficients, decision lists, and parities. It is well known that SGDNN cannot learn parities, and in ongoing work with Vitaly Feldman, we show that SGDNN cannot learn decision lists nor constant-degree polynomial thresholds with unrestricted coefficients. So the picture becomes more clear:</p>
<figure><img alt="classes_nn" class=" size-full wp-image-1476 aligncenter" src="https://theorydish.files.wordpress.com/2019/01/classes_nn.png?w=620"/>Conjectured hard-to-learn classes, known learnable classes, and those known to be learnable by SGDNN.</figure>
<p> </p>
<p>The theorem above runs SGDNN with a multi-layer perceptron. What happens if we change the network architecture? It can be shown then that SGDNN learns a qualitatively different function class. For instance, with convolutional networks, the learnable functions include certain polynomials of <em>super-constant</em> degree.</p>
<h3 id="a-word-on-the-proof">A word on the proof</h3>
<p>The path to the theorem traverses two papers. There’s a corresponding outline for the proof.</p>
<p>The first step is to show that, with high probability, the Glorot random initialization renders the network in a state where the final hidden layer (just before the output node) is rich enough to approximate all large-margin polynomial threshold functions (LMPTs). Namely, every LMPT can be approximated by the network up to some setting of the weights that enter the output neuron (all remaining weights random). The tools for this part of the proof include (i) the connection between kernels and random features, (ii) a characterization of symmetric kernels of the sphere, and (iii) a variety of properties of Hermite polynomials. It’s described in our <a href="https://papers.nips.cc/paper/6427-toward-deeper-understanding-of-neural-networks-the-power-of-initialization-and-a-dual-view-on-expressivity">2016 paper</a>.</p>
<p>An upshot of this correspondence is that if we run SGD <em>only on the top layer</em> of a network, leaving the remaining weights as they were randomly initialized, we learn LMPTs. (Remember when we said that we won’t beat what a linear predictor can do? There it is again.) The second step of the proof, then, is to show that the correspondence continues to hold even if we train all the weights. In the assumed setting (e.g. provided at most logarithmic depth, sufficient width, and so forth), what’s represented in the final hidden layer changes sufficiently slowly that, over the course of SGDNN’s iterations, it <em>remains</em> rich enough to approximate all LMPTs. The final layer does the remaining work of picking out the right LMPT. The argument is in Amit’s <a href="https://papers.nips.cc/paper/6836-sgd-learns-the-conjugate-kernel-class-of-the-network">2017 paper</a>.</p>
<h2 id="pacing-up">PACing up</h2>
<p>To what extent should we be satisfied, knowing that our algorithm of interest (SGDNN) can solve a (computationally) easy problem?</p>
<p>On the positive side, we’ve managed to say something at all about neural network training in the PAC framework. Roughly speaking, some class of non-trivially layered neural networks, trained as they typically are, learns any known learnable function class that isn’t “too sensitive.” It’s also appealing that the function classes vary across different architectures.</p>
<p>On the pessimistic side, we’re confronted to a major limitation on the “function class” perspective, prevalent in PAC analysis and elsewhere in learning theory. All of the classes that SGDNN learns, <em>under the assumptions</em> touched on in this post, are so-called large-margin classes. Large-margin classes are essentially linear predictors over a <em>fixed and data-independent</em> embedding of input examples, as alluded to before. These are inherently “shallow models.”</p>
<p>That seems rather problematic in pursuing any kind of theory for learning layered networks, where the entire working premise is that a deep network uses its hidden layers to learn a representation adapted to the example domain. Our analysis—both its goal and its proof—clash with this intuition: it works out that a “shallow model” can be learned when assumptions imply that “not too much” change takes place in hidden layers. It seems that the representation learning phenomenon is what’s interesting, yet the typical PAC approach, as well as the analysis touched on in this post, all avoid capturing it.</p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1">Here <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="n"/> is the dimension of the instance space.<a href="https://theorydish.blog/feed/#fnref1"><img alt="&#x21A9;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/21a9.png" style="height: 1em;"/></a></li>
<li id="fn2">For instance, ReLU activations, of the form <img alt="x \mapsto \max\{x,0\}" class="latex" src="https://s0.wp.com/latex.php?latex=x+%5Cmapsto+%5Cmax%5C%7Bx%2C0%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="x \mapsto \max\{x,0\}"/>.<a href="https://theorydish.blog/feed/#fnref2"><img alt="&#x21A9;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/21a9.png" style="height: 1em;"/></a></li>
<li id="fn3">Recurrent networks allow for cycles, but in this post we stick to DAGs.<a href="https://theorydish.blog/feed/#fnref3"><img alt="&#x21A9;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/21a9.png" style="height: 1em;"/></a></li>
<li id="fn4">Convolutional networks often also constrain subsets of their weights to be equal; that turns out not to bear much on this post.<a href="https://theorydish.blog/feed/#fnref4"><img alt="&#x21A9;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/21a9.png" style="height: 1em;"/></a></li>
<li id="fn5">Although not essential to the results described, it also simplifies this post to zero the weights on edges incident to the output node as part of the initialization.<a href="https://theorydish.blog/feed/#fnref5"><img alt="&#x21A9;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/21a9.png" style="height: 1em;"/></a></li>
<li id="fn6"><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#Extensions_and_variants">Variants of SGD</a> are used in practice, including algorithms used elsewhere in optimization (e.g. <a href="https://distill.pub/2017/momentum/">SGD with momentum</a>, <a href="http://www.jmlr.org/papers/v12/duchi11a.html">AdaGrad</a>) or techniques developed more specifically for neural nets (e.g. RMSprop, <a href="https://arxiv.org/abs/1412.6980">Adam</a>, <a href="https://arxiv.org/abs/1502.03167">batch norm</a>). We’ll stick to plain SGD.<a href="https://theorydish.blog/feed/#fnref6"><img alt="&#x21A9;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/21a9.png" style="height: 1em;"/></a></li>
<li id="fn7">More accurately, a sequence of function classes <img alt="\mathcal H_n" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal+H_n&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\mathcal H_n"/> for <img alt="n = 1, 2, \ldots" class="latex" src="https://s0.wp.com/latex.php?latex=n+%3D+1%2C+2%2C+%5Cldots&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="n = 1, 2, \ldots"/>.<a href="https://theorydish.blog/feed/#fnref7"><img alt="&#x21A9;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/21a9.png" style="height: 1em;"/></a></li>
<li id="fn8">The width of a multi-layer perceptron is the number of neurons in each hidden layer.<a href="https://theorydish.blog/feed/#fnref8"><img alt="&#x21A9;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/21a9.png" style="height: 1em;"/></a></li>
</ol>
</section></div>
    </content>
    <updated>2019-01-04T15:14:02Z</updated>
    <published>2019-01-04T15:14:02Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>amitdanielymailhujiacil</name>
    </author>
    <source>
      <id>https://theorydish.blog</id>
      <logo>https://theorydish.files.wordpress.com/2017/03/cropped-nightdish1.jpg?w=32</logo>
      <link href="https://theorydish.blog/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://theorydish.blog" rel="alternate" type="text/html"/>
      <link href="https://theorydish.blog/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://theorydish.blog/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Stanford's CS Theory Research Blog</subtitle>
      <title>Theory Dish</title>
      <updated>2019-01-08T00:41:14Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://cstheory.stackexchange.com/q/42145</id>
    <link href="https://cstheory.stackexchange.com/questions/42145/grid-minor-theorem-of-robertson-and-seymour-and-its-algorithmic-applications" rel="alternate" type="text/html"/>
    <title>Grid-Minor Theorem of Robertson and Seymour and its Algorithmic Applications</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Graph-Minor Theorem of Robertson and Seymour [<a href="https://www.sciencedirect.com/science/article/pii/S0095895684710732" rel="nofollow noreferrer">1</a>] states that if graph G has large treewidth, then it contains a large grid as minor. Most approximation results on general classes of graphs with excluded minors make heavy use of Robertson and Seymour’s structure theory for graphs with excluded minors, especially when the treewidth is large (small treewidth usually makes problem to be easily solved by dynamic programming) [<a href="http://chekuri.cs.illinois.edu/talks/NIPS-Tutorial.pdf" rel="nofollow noreferrer">2</a>]. </p>

<p>However, there are some results are trying to avoid using the grid minor theorem. For example, Chekuri and Chuzhoy [<a href="https://arxiv.org/abs/1304.1577" rel="nofollow noreferrer">3</a>] show a framework for using theorems to bypass the well-known Grid-Minor Theorem of Robertson and Seymour in some applications. In particular, this leads to substantially improved parameters in some Erdos-Posa-type results, and faster running times for algorithms for some fi�xed parameter tractable problems.</p>

<p>Do you know any other examples of problems with large treewidth avoid using the grid minor theorem? </p></div>
    </summary>
    <updated>2019-01-04T09:44:58Z</updated>
    <published>2019-01-04T09:44:58Z</published>
    <category scheme="https://cstheory.stackexchange.com/tags" term="graph-algorithms"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="approximation-algorithms"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="treewidth"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="graph-minor"/>
    <author>
      <name>Rupei Xu</name>
      <uri>https://cstheory.stackexchange.com/users/17918</uri>
    </author>
    <source>
      <id>https://cstheory.stackexchange.com/feeds/</id>
      <link href="https://cstheory.stackexchange.com/feeds/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory.stackexchange.com/questions" rel="alternate" type="text/html"/>
      <link href="http://www.creativecommons.org/licenses/by-sa/3.0/rdf" rel="license"/>
      <subtitle>most recent 30 from cstheory.stackexchange.com</subtitle>
      <title>Recent Questions - Theoretical Computer Science Stack Exchange</title>
      <updated>2019-01-08T00:32:53Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://cstheory.stackexchange.com/q/42144</id>
    <link href="https://cstheory.stackexchange.com/questions/42144/maximum-weight-independent-set-on-a-changing-graph" rel="alternate" type="text/html"/>
    <title>Maximum Weight Independent Set on a Changing Graph?</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Suppose I have an optimal solution to the maximum weight independent/stable set problem on an arbitrary graph. If I were to induce a clique among a subset of its vertices (and perhaps add in some additional nodes that are only adjacent to the nodes of the induced clique), does there exist an efficient way in which I use the original optimal solution (i.e. its structure as a starting solution) to find the new optimal maximum weight independent set in the modified graph??</p></div>
    </summary>
    <updated>2019-01-04T07:48:21Z</updated>
    <published>2019-01-04T07:48:21Z</published>
    <category scheme="https://cstheory.stackexchange.com/tags" term="graph-theory"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="graph-algorithms"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="co.combinatorics"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="optimization"/>
    <author>
      <name>Student</name>
      <uri>https://cstheory.stackexchange.com/users/51578</uri>
    </author>
    <source>
      <id>https://cstheory.stackexchange.com/feeds/</id>
      <link href="https://cstheory.stackexchange.com/feeds/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory.stackexchange.com/questions" rel="alternate" type="text/html"/>
      <link href="http://www.creativecommons.org/licenses/by-sa/3.0/rdf" rel="license"/>
      <subtitle>most recent 30 from cstheory.stackexchange.com</subtitle>
      <title>Recent Questions - Theoretical Computer Science Stack Exchange</title>
      <updated>2019-01-08T00:32:53Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=7217</id>
    <link href="https://windowsontheory.org/2019/01/03/quantum-games/" rel="alternate" type="text/html"/>
    <title>Quantum Games</title>
    <summary>Nilin Abrahamsen nilin@mit.edu Daniel Alabi alabid@g.harvard.edu Mitali Bafna mitalibafna@g.harvard.edu Emil Khabiboulline ekhabiboulline@g.harvard.edu Juspreet Sandhu jus065@g.harvard.edu Two-prover one-round (2P-1R) games have been the subject of intensive study in classical complexity theory and quantum information theory. In a 2P-1R game, a verifier sends questions privately to each of two collaborating provers , who then aim to respond […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Nilin Abrahamsen <font face="courier new">nilin@mit.edu</font>
</p><p>Daniel Alabi <font face="courier new">alabid@g.harvard.edu</font>
</p><p>Mitali Bafna <font face="courier new">mitalibafna@g.harvard.edu</font>
</p><p>Emil Khabiboulline <font face="courier new">ekhabiboulline@g.harvard.edu</font>
</p><p>Juspreet Sandhu <font face="courier new">jus065@g.harvard.edu</font>

<br/>
<br/>
Two-prover one-round (2P-1R) games have been the subject of intensive study in classical complexity theory and quantum information theory. In a 2P-1R game, a <em>verifier</em> sends questions privately to each of two collaborating <em>provers</em> , who then aim to respond with a compatible pair of answers without communicating with each other. Sharing quantum entanglement allows the provers to improve their strategy without any communication, illustrating an apparent paradox of the quantum postulates. These notes aim to give an introduction to the role of entanglement in nonlocal games, as they are called in the quantum literature. We see how nonlocal games have rich connections within computer science and quantum physics, giving rise to theorems ranging from hardness of approximation to the resource theory of entanglement.
</p><h2>Introduction</h2>
In these notes we discuss 2-prover 1-round games and the classical complexity of approximating the value of such games in the setting where the provers can share entanglement. That is, given the description of a game, we ask how hard it is to estimate the winning <!--recheck prob-->probability of the best winning strategy of the entangled provers. Let us first formally define games and its relation to the label cover <!--recheck prob-->problem. We write <img alt="{ [n]=\{1,\ldots,n\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Bn%5D%3D%5C%7B1%2C%5Cldots%2Cn%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ [n]=\{1,\ldots,n\}}"/>.
<h4>Definition (Label cover)</h4>
<em> A label cover instance <img alt="{ I=(S,T,\Sigma,\Pi)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+I%3D%28S%2CT%2C%5CSigma%2C%5CPi%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ I=(S,T,\Sigma,\Pi)}"/> consists of variable sets <img alt="{ S=\{s_i\}_{i\in[n]},T=\{t_j\}_{j\in[n]}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+S%3D%5C%7Bs_i%5C%7D_%7Bi%5Cin%5Bn%5D%7D%2CT%3D%5C%7Bt_j%5C%7D_%7Bj%5Cin%5Bn%5D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ S=\{s_i\}_{i\in[n]},T=\{t_j\}_{j\in[n]}}"/>, alphabet set <img alt="{ \Sigma}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5CSigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \Sigma}"/>, and a collection <img alt="{ \Pi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5CPi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \Pi}"/> of constraints of the form <img alt="{ t_j=f_{i,j}(s_i)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+t_j%3Df_%7Bi%2Cj%7D%28s_i%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ t_j=f_{i,j}(s_i)}"/>. Given an assignment (or coloring) <img alt="{ c : S\cup T \rightarrow \Sigma}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+c+%3A+S%5Ccup+T+%5Crightarrow+%5CSigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ c : S\cup T \rightarrow \Sigma}"/> we define its value to be <img alt="{ \omega(c)=\mathbb P_{f_{ij}\sim\Pi}\big(c(t_j)=f_{ij}(c(s_i))\big)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28c%29%3D%5Cmathbb+P_%7Bf_%7Bij%7D%5Csim%5CPi%7D%5Cbig%28c%28t_j%29%3Df_%7Bij%7D%28c%28s_i%29%29%5Cbig%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \omega(c)=\mathbb P_{f_{ij}\sim\Pi}\big(c(t_j)=f_{ij}(c(s_i))\big)}"/>. Define the value of <img alt="{ I}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+I%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ I}"/> to be the maximum over all possible assignments, i.e. <img alt="{ \omega(I) = \max_{c} \omega(c)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28I%29+%3D+%5Cmax_%7Bc%7D+%5Comega%28c%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \omega(I) = \max_{c} \omega(c)}"/>. </em>

<!--ending definition-->

Many familiar computational <!--recheck prob-->problems can be formulated as a label cover, such as <img alt="{ \textsc{3SAT}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Ctextsc%7B3SAT%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \textsc{3SAT}}"/>, <img alt="{ \textsc{3Lin}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Ctextsc%7B3Lin%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \textsc{3Lin}}"/>, and <img alt="{ \textsc{MaxCut}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Ctextsc%7BMaxCut%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \textsc{MaxCut}}"/>.
<figure style="width: 11em; margin: auto;">

<a href="https://windowsontheory.org/?attachment_id=7236"><img alt="" class="attachment-thumbnail size-thumbnail" height="150" src="https://windowsontheory.files.wordpress.com/2019/01/labelcover.png?w=110&amp;h=150" width="110"/></a>
Label cover graph</figure>
<h4>Definition (2-prover 1-round game)</h4>
<em> Let <img alt="{ I = (S,T,\Sigma,\Pi)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+I+%3D+%28S%2CT%2C%5CSigma%2C%5CPi%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ I = (S,T,\Sigma,\Pi)}"/> be a label cover instance. We can then associate the following two-prover one-round game <img alt="{ G(I)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+G%28I%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ G(I)}"/> with <img alt="{ I}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+I%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ I}"/>. Let <img alt="{ P_1,P_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+P_1%2CP_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ P_1,P_2}"/> be two provers who cannot communicate, and let <img alt="{ V}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+V%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ V}"/> be the verifier. Given the label cover instance <img alt="{ I}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+I%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ I}"/>, the verifier uniformly samples a constraint <img alt="{ f_{i,j} \in \Pi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+f_%7Bi%2Cj%7D+%5Cin+%5CPi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ f_{i,j} \in \Pi}"/> and sends <img alt="{ s_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+s_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ s_i}"/> to <img alt="{ P_1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+P_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ P_1}"/> and <img alt="{ t_j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+t_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ t_j}"/> to <img alt="{ P_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+P_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ P_2}"/>. The provers then reply with <img alt="{ a \in \Sigma}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+a+%5Cin+%5CSigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ a \in \Sigma}"/> and <img alt="{ b\in\Sigma}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+b%5Cin%5CSigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ b\in\Sigma}"/> respectively to <img alt="{ V}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+V%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ V}"/>. Finally, <img alt="{ V}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+V%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ V}"/> outputs <img alt="{ 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ 1}"/> if and only if <img alt="{ b = f_{i,j}(a)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+b+%3D+f_%7Bi%2Cj%7D%28a%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ b = f_{i,j}(a)}"/>. </em>

<!--ending definition-->
<figure style="width: 25em; margin: auto;">
 
<a href="https://windowsontheory.org/?attachment_id=7235"><img alt="" class="attachment-thumbnail size-thumbnail" height="104" src="https://windowsontheory.files.wordpress.com/2019/01/game.png?w=150&amp;h=104" width="150"/></a>


The game view of label cover</figure>
Any coloring of the label cover instance corresponds to a deterministic strategy for the corresponding game. Therefore, with an optimal strategy the provers win the game associated to label cover instance <img alt="{ I}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+I%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ I}"/> with <!--recheck prob-->probability <img alt="{ \omega(I)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28I%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \omega(I)}"/>. That is, the value of the game equals that of the label cover instance. However, this is with the assumption that provers can only use deterministic strategies or convex combinations of these (that is, using shared randomness). If the provers share an entangled quantum state, then the provers (who still cannot communicate) can enjoy correlations that allow them to win with a higher <!--recheck prob-->probability than classically. In the quantum literature, these 2P-1R games are known as nonlocal games referring to the fact that the correlations arise without signaling between the provers. We are concerned with the complexity of approximating the winning <!--recheck prob-->probability of this strategy.

We refer to the optimal winning <!--recheck prob-->probability within some class (classical or entangled) of strategies as the classical and quantum value of the game, respectively, and we use the terms quantum strategy and entangled strategy interchangeably.

Fixing different constraint families in the label cover game changes the complexity of finding the (classical and entangled) values of the game. We will show that approximating the entangled value of XOR games, or more generally <em>unique games</em> (to be defined later on), is possible in polynomial time. This is remarkable because a famous conjecture known as the <a href="https://en.wikipedia.org/wiki/Unique_games_conjecture"> <em>unique games conjecture</em> </a> says that approximating the classical value of unique games is NP-hard. In contrast, we will see that for unrestricted edge constraints, it is NP-hard to approximate the entangled value of a nonlocal game. Thus, hardness of approximation of the game’s value, established by the celebrated <em>PCP theorem</em> , still applies in the presence of entanglement. In the quantum world, we have new complexity classes such as QMA (which can be regarded as “quantum NP”), so one may conjecture whether approximating the entangled value of a general game is QMA-hard (the games formulation of the <em>quantum PCP conjecture</em> ). We will indicate progress in this direction but will explicitly demonstrate the NP-hardness result.

Entanglement is often regarded as an expensive resource in quantum information because it is difficult to produce and maintain. Hence, even if sharing entanglement can improve the success <!--recheck prob-->probability of winning a game, the resource consumption may be costly. We will conclude by discussing lower bounds on the number of shared entangled bits required to achieve the optimal value of a game.
<h2>Notation and quantum postulates</h2>
Let us first establish notation and define what is meant by an entangled strategy. In keeping with physics notation we write a column vector as <img alt="{ |{v}\rangle \in\mathbb C^d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%7Bv%7D%5Crangle+%5Cin%5Cmathbb+C%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |{v}\rangle \in\mathbb C^d}"/> and its conjugate-transpose (a row vector) as <img alt="{ \langle{v}| }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Clangle%7Bv%7D%7C+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \langle{v}| }"/> . More generally the conjugate-transpose (Hermitian conjugate) of a matrix <img alt="{ A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ A}"/> is written <img alt="{ A^\dag}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+A%5E%5Cdag%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ A^\dag}"/>. Then <img alt="{ \langle{v}| w\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Clangle%7Bv%7D%7C+w%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \langle{v}| w\rangle}"/> is the inner product of two vectors (a scalar) and <img alt="{ |{v}\rangle \langle{w}| }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%7Bv%7D%5Crangle+%5Clangle%7Bw%7D%7C+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |{v}\rangle \langle{w}| }"/> the outer product (a rank-1 matrix). A matrix <img alt="{ A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ A}"/> is said to be <em>Hermitian</em> if <img alt="{ A^\dag=A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+A%5E%5Cdag%3DA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ A^\dag=A}"/>. A matrix <img alt="{ A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ A}"/> is <em>positive semidefinite</em> , written <img alt="{ A\succeq 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+A%5Csucceq+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ A\succeq 0}"/>, if <img alt="{ A=B^\dag B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+A%3DB%5E%5Cdag+B%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ A=B^\dag B}"/> for some matrix <img alt="{ B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+B%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ B}"/>. We write the identity matrix as <img alt="{ {\mathbb{I}}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7B%5Cmathbb%7BI%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ {\mathbb{I}}}"/>, denote by <img alt="{ Herm(\mathbb{C}^d)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+Herm%28%5Cmathbb%7BC%7D%5Ed%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ Herm(\mathbb{C}^d)}"/> the set of <img alt="{ d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ d}"/>-by-<img alt="{ d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ d}"/> Hermitian matrices.
<h3> Observables, states, and entanglement</h3>
In a quantum theory the <em>observables</em> are Hermitian operators <img alt="{ A\in Herm(\mathbb C^d)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+A%5Cin+Herm%28%5Cmathbb+C%5Ed%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ A\in Herm(\mathbb C^d)}"/> on a vector space <img alt="{ \mathbb C^d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathbb+C%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \mathbb C^d}"/>. It then makes sense to say that a <em>state</em> is a functional <img alt="{ \varphi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cvarphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \varphi}"/> on the set of observables. That is, to specify the state of a physical system means giving a (expected) value for each observable. It turns out states are <em>linear</em> functionals of the observables, and such functionals can be written <img alt="{ \varphi(A)=\langle A,\rho\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cvarphi%28A%29%3D%5Clangle+A%2C%5Crho%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \varphi(A)=\langle A,\rho\rangle}"/> for some <img alt="{ d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ d}"/>-by-<img alt="{ d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ d}"/> matrix <img alt="{ \rho}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \rho}"/>. We call <img alt="{ \rho}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \rho}"/> the density matrix and require moreover that <img alt="{ \rho}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \rho}"/> is positive semidefinite and has trace <img alt="{ 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ 1}"/>. Every density matrix is a convex combination of rank-one projections <img alt="{ |\psi\rangle\langle\psi|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Cpsi%5Crangle%5Clangle%5Cpsi%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |\psi\rangle\langle\psi|}"/> known as pure states. The unit vectors <img alt="{ |\psi\rangle\in\mathbb C^d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Cpsi%5Crangle%5Cin%5Cmathbb+C%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |\psi\rangle\in\mathbb C^d}"/> are also themselves known as pure states.

If the state of one particle is described by a vector in <img alt="{ \mathbb C^d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathbb+C%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \mathbb C^d}"/> (referring here to pure states), then two particles are described by a vector in the tensor product <img alt="{ \mathbb C^d\otimes\mathbb C^d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathbb+C%5Ed%5Cotimes%5Cmathbb+C%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \mathbb C^d\otimes\mathbb C^d}"/>. The two particles are entangled if their state is not in the form of a pure tensor <img alt="{ |\phi\rangle\otimes|\psi\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Cphi%5Crangle%5Cotimes%7C%5Cpsi%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |\phi\rangle\otimes|\psi\rangle}"/>. We also write product states as <img alt="{ |\phi\rangle|\psi\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Cphi%5Crangle%7C%5Cpsi%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |\phi\rangle|\psi\rangle}"/>, omitting the tensor symbol.
<h3> Quantum measurements</h3>
A quantum measurement can be described in terms of a <em>projection-valued measure</em> (PVM).
<!--blockquote--><b>Definition 1 (PVM)</b> <em><a name="measurement"/> A projection-valued measure on vector space <img alt="{ \mathbb C^d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathbb+C%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \mathbb C^d}"/> (where the quantum states live) is a list of projection matrices <img alt="{ A_1,\ldots,A_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+A_1%2C%5Cldots%2CA_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ A_1,\ldots,A_k}"/> on <img alt="{ \mathbb C^d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathbb+C%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \mathbb C^d}"/> such that <img alt="{ A_iA_j=0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+A_iA_j%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ A_iA_j=0}"/> for <img alt="{ i\neq j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+i%5Cneq+j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ i\neq j}"/> and <img alt="{ \sum_i A_i={\mathbb{I}}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Csum_i+A_i%3D%7B%5Cmathbb%7BI%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \sum_i A_i={\mathbb{I}}}"/>. The PVM describes a measurement which, on state <img alt="{ |\psi\rangle\in\mathbb C^d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Cpsi%5Crangle%5Cin%5Cmathbb+C%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |\psi\rangle\in\mathbb C^d}"/> outputs measurement outcome <img alt="{ i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ i}"/> with <!--recheck prob-->probability <img alt="{ \langle\psi| A_i|\psi\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Clangle%5Cpsi%7C+A_i%7C%5Cpsi%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \langle\psi| A_i|\psi\rangle}"/>. The quantum state after obtaining outcome <img alt="{ i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ i}"/> is <img alt="{ \frac1{\|A_i|\psi\rangle\|}A_i|\psi\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cfrac1%7B%5C%7CA_i%7C%5Cpsi%5Crangle%5C%7C%7DA_i%7C%5Cpsi%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \frac1{\|A_i|\psi\rangle\|}A_i|\psi\rangle}"/>. </em><!--/blockquote-->
When the projections are rank-one projections <img alt="{ A_i= |{\beta_i}\rangle \langle{\beta_i}| }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+A_i%3D+%7C%7B%5Cbeta_i%7D%5Crangle+%5Clangle%7B%5Cbeta_i%7D%7C+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ A_i= |{\beta_i}\rangle \langle{\beta_i}| }"/> we say that we measure in the basis <img alt="{ \{ |{\beta_i}\rangle \}_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5C%7B+%7C%7B%5Cbeta_i%7D%5Crangle+%5C%7D_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \{ |{\beta_i}\rangle \}_i}"/>. In this case the <!--recheck prob-->probability of outcome <img alt="{ i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ i}"/> in state <img alt="{ |\psi\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Cpsi%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |\psi\rangle}"/> is <img alt="{ |\langle\beta_i |{\psi}\rangle |^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Clangle%5Cbeta_i+%7C%7B%5Cpsi%7D%5Crangle+%7C%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |\langle\beta_i |{\psi}\rangle |^2}"/>, and the post-measurement state is simply <img alt="{ |{\beta_i}\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cbeta_i%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |{\beta_i}\rangle}"/> .

Applying the measurement <img alt="{ (A_i)_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%28A_i%29_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ (A_i)_i}"/> on the left half of a two-particle state <img alt="{ |{\Psi}\rangle \in\mathbb C^d\otimes\mathbb C^d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5CPsi%7D%5Crangle+%5Cin%5Cmathbb+C%5Ed%5Cotimes%5Cmathbb+C%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |{\Psi}\rangle \in\mathbb C^d\otimes\mathbb C^d}"/> means applying the PVM <img alt="{ (A_i\otimes {\mathbb{I}})_{i}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%28A_i%5Cotimes+%7B%5Cmathbb%7BI%7D%7D%29_%7Bi%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ (A_i\otimes {\mathbb{I}})_{i}}"/> on the two-particle state.
<h3> Quantum strategies for nonlocal games</h3>
We now introduce the notion of a quantum strategy for a nonlocal game. Each prover holds a particle, say with state space <img alt="{ \mathbb C^d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathbb+C%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \mathbb C^d}"/>, and Alices particle may be entangled with Bob’s. The global state is <img alt="{ |{\phi}\rangle _{AB}\in\mathbb C^d\otimes\mathbb C^d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cphi%7D%5Crangle+_%7BAB%7D%5Cin%5Cmathbb+C%5Ed%5Cotimes%5Cmathbb+C%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |{\phi}\rangle _{AB}\in\mathbb C^d\otimes\mathbb C^d}"/>. Each player receives a question from the verifier and then chooses a measurement (a PVM) depending on the question. The player applies the measurement to their own particle and responds to the verifier with their measurement outcome. Hence for Alice we specify <img alt="{ n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ n}"/> PVM’s <img alt="{ A^s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+A%5Es%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ A^s}"/> where <img alt="{ s\in S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+s%5Cin+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ s\in S}"/> is a question, and each PVM is a list <img alt="{ A^s_{a=1},\ldots,A^s_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+A%5Es_%7Ba%3D1%7D%2C%5Cldots%2CA%5Es_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ A^s_{a=1},\ldots,A^s_k}"/>. By definition <a href="https://windowsontheory.org/feed/#measurement">1</a>, given questions <img alt="{ s,t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+s%2Ct%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ s,t}"/> the <!--recheck prob-->probability that Alice outputs <img alt="{ a}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+a%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ a}"/> and Bob outputs <img alt="{ b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+b%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ b}"/> is <a name="Qstrategy"/>

<a name="Qstrategy">
</a><a name="Qstrategy"/>
<p align="center"><a name="Qstrategy"><img alt="\displaystyle  P(a,b|s,t)=\|({\mathbb{I}}\otimes B^t_b)(A^s_a\otimes {\mathbb{I}}) |{\phi}\rangle _{AB}\|^2= \langle{\phi}| A^s_a\otimes B^t_b|\phi\rangle, \ \ \ \ \ (1)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++P%28a%2Cb%7Cs%2Ct%29%3D%5C%7C%28%7B%5Cmathbb%7BI%7D%7D%5Cotimes+B%5Et_b%29%28A%5Es_a%5Cotimes+%7B%5Cmathbb%7BI%7D%7D%29+%7C%7B%5Cphi%7D%5Crangle+_%7BAB%7D%5C%7C%5E2%3D+%5Clangle%7B%5Cphi%7D%7C+A%5Es_a%5Cotimes+B%5Et_b%7C%5Cphi%5Crangle%2C+%5C+%5C+%5C+%5C+%5C+%281%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  P(a,b|s,t)=\|({\mathbb{I}}\otimes B^t_b)(A^s_a\otimes {\mathbb{I}}) |{\phi}\rangle _{AB}\|^2= \langle{\phi}| A^s_a\otimes B^t_b|\phi\rangle, \ \ \ \ \ (1)"/></a></p>
<a name="Qstrategy">
</a><a name="Qstrategy"/> where we have used that squaring a projection leaves it unchanged.
<h2>Quantum strategies beat classical ones</h2>
For any 2P-1R game <img alt="{ G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+G%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ G}"/>, let <img alt="{ \omega(G)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \omega(G)}"/> be the maximum <!--recheck prob-->probability — over the players’ classical strategies — that the verifier accepts and <img alt="{ \omega^*(G)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%2A%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \omega^*(G)}"/> the maximum <!--recheck prob-->probability that the verifier accepts when the provers use qubits such that player 1’s qubits are entangled with those of player 2.

The game of Clauser, Horne, Shimony, and Holt (CHSH) has the property that the provers can increase their chance of winning by sharing an entangled pair of qubits, even when no messages are exchanged between the players. We show that there’s a characterization of the CHSH game’s value <img alt="{ \omega^*(G)=\cos^2(\frac{\pi}{8}) = \frac{1}{2}+\frac{\sqrt{2}}{4}\approx 0.85}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%2A%28G%29%3D%5Ccos%5E2%28%5Cfrac%7B%5Cpi%7D%7B8%7D%29+%3D+%5Cfrac%7B1%7D%7B2%7D%2B%5Cfrac%7B%5Csqrt%7B2%7D%7D%7B4%7D%5Capprox+0.85%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \omega^*(G)=\cos^2(\frac{\pi}{8}) = \frac{1}{2}+\frac{\sqrt{2}}{4}\approx 0.85}"/> which is better than the classical value <img alt="{ \omega(G)\leq \frac{3}{4}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28G%29%5Cleq+%5Cfrac%7B3%7D%7B4%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \omega(G)\leq \frac{3}{4}}"/>. Let us first define XOR games, of which the CHSH game is a special case.
<h4>Definition (XOR game)</h4>
<em> An XOR game is a 2-player classical game (the questions and answers are classical bits) where: </em>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em>
<ol>
 	<li> Questions <img alt="{ (s, t)\in\{0, 1, \ldots, n-1\}^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%28s%2C+t%29%5Cin%5C%7B0%2C+1%2C+%5Cldots%2C+n-1%5C%7D%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ (s, t)\in\{0, 1, \ldots, n-1\}^2}"/> are asked according to some distribution <img alt="{ \Pi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5CPi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \Pi}"/> (e.g. uniform).</li>
 	<li> Answers <img alt="{ a, b\in\{0, 1\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+a%2C+b%5Cin%5C%7B0%2C+1%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ a, b\in\{0, 1\}}"/> are provided by players (call them Alice and Bob).</li>
 	<li> The verifier computes a predicate <img alt="{ V(a, b|s, t) = f_{s, t}(a\oplus b)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+V%28a%2C+b%7Cs%2C+t%29+%3D+f_%7Bs%2C+t%7D%28a%5Coplus+b%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ V(a, b|s, t) = f_{s, t}(a\oplus b)}"/> used to decide acceptance/rejection.</li>
</ol>
</em><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em> </em>

<!--ending definition-->
<h4>Definition (CHSH Game)</h4>
<em> An XOR game with <img alt="{ n=2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+n%3D2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ n=2}"/> where <img alt="{ s, t\in\{0, 1\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+s%2C+t%5Cin%5C%7B0%2C+1%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ s, t\in\{0, 1\}}"/> are independent random bits and <img alt="{ V(a, b | s, t)=1 \Longleftrightarrow a\oplus b = s\wedge t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+V%28a%2C+b+%7C+s%2C+t%29%3D1+%5CLongleftrightarrow+a%5Coplus+b+%3D+s%5Cwedge+t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ V(a, b | s, t)=1 \Longleftrightarrow a\oplus b = s\wedge t}"/>. </em>

<!--ending definition-->

To win the CHSH game, Alice and Bob need to output bits <img alt="{ a}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+a%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ a}"/> (from Alice) and <img alt="{ b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+b%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ b}"/> (from Bob) that disagree if <img alt="{ s=t=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+s%3Dt%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ s=t=1}"/> and agree otherwise.

If Alice and Bob are classical then they can do no better than by always outputting <img alt="{ 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ 0}"/>, say, in which case they win in the three out of four cases when one of the questions is <img alt="{ 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ 0}"/>. Equivalently, <img alt="{ \omega(G)=\frac34}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28G%29%3D%5Cfrac34%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \omega(G)=\frac34}"/> where <img alt="{ G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+G%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ G}"/> is the CHSH game. This is the content of <em>Bell’s inequality</em> :
<h4>Lemma (Bell’s Inequality)</h4>
<em> For any two functions <img alt="{ g, h: \{0, 1\}\rightarrow\{0, 1\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+g%2C+h%3A+%5C%7B0%2C+1%5C%7D%5Crightarrow%5C%7B0%2C+1%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ g, h: \{0, 1\}\rightarrow\{0, 1\}}"/>, we have </em>

<em>
<img alt="{ {\mathop{\mathbb{P}}}_{x, y\in\{0, 1\}}\left[g(x)\oplus h(y) = x\wedge y\right] \leq \frac{3}{4} }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7B%5Cmathop%7B%5Cmathbb%7BP%7D%7D%7D_%7Bx%2C+y%5Cin%5C%7B0%2C+1%5C%7D%7D%5Cleft%5Bg%28x%29%5Coplus+h%28y%29+%3D+x%5Cwedge+y%5Cright%5D+%5Cleq+%5Cfrac%7B3%7D%7B4%7D+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ {\mathop{\mathbb{P}}}_{x, y\in\{0, 1\}}\left[g(x)\oplus h(y) = x\wedge y\right] \leq \frac{3}{4} }"/></em>

<em>
</em><em/><em> where <img alt="{ x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+x%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ x}"/> and <img alt="{ y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+y%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ y}"/> are independent uniformly random bits. </em>

<!--ending lemma-->

<em><br/><b>Proof.</b></em><!-- remove close em after proof--> The <!--recheck prob-->probability of any event is a multiple of <img alt="{ 1/4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+1%2F4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ 1/4}"/> so it suffices to show that <img alt="{ {\mathop{\mathbb{P}}}_{x, y\in\{0, 1\}}\left[g(x)\oplus h(y) = x\wedge y\right]\neq1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7B%5Cmathop%7B%5Cmathbb%7BP%7D%7D%7D_%7Bx%2C+y%5Cin%5C%7B0%2C+1%5C%7D%7D%5Cleft%5Bg%28x%29%5Coplus+h%28y%29+%3D+x%5Cwedge+y%5Cright%5D%5Cneq1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ {\mathop{\mathbb{P}}}_{x, y\in\{0, 1\}}\left[g(x)\oplus h(y) = x\wedge y\right]\neq1}"/>. So assume for contradiction that <img alt="{ g(x)\oplus h(y) = x\wedge y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+g%28x%29%5Coplus+h%28y%29+%3D+x%5Cwedge+y%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ g(x)\oplus h(y) = x\wedge y}"/> for all pairs <img alt="{ x,y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+x%2Cy%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ x,y}"/>. Then we have that <img alt="{ g(0)\oplus h(0) = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+g%280%29%5Coplus+h%280%29+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ g(0)\oplus h(0) = 0}"/> and <img alt="{ g(0)\oplus h(1) = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+g%280%29%5Coplus+h%281%29+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ g(0)\oplus h(1) = 0}"/> which implies that <img alt="{ h(0)=h(1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+h%280%29%3Dh%281%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ h(0)=h(1)}"/>. But then <img alt="{ 0=g(1)\oplus h(0) =g(1)\oplus h(1) = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+0%3Dg%281%29%5Coplus+h%280%29+%3Dg%281%29%5Coplus+h%281%29+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ 0=g(1)\oplus h(0) =g(1)\oplus h(1) = 1}"/> which is a contraction. <!--end proof-->
<div align="right">□</div>
<h3> The strategy</h3>
The entangled strategy for the CHSH game requires that Alice and Bob each hold a qubit, so that their two qubits together are described by a vector in <img alt="{ \mathbb C^2\otimes\mathbb C^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathbb+C%5E2%5Cotimes%5Cmathbb+C%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \mathbb C^2\otimes\mathbb C^2}"/>. The two qubits together are in the state

<img alt="{ |{\phi}\rangle = \frac{1}{\sqrt{2}}\left( |{0}\rangle _A |{0}\rangle _B + |{1}\rangle _A |{1}\rangle _B\right), }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cphi%7D%5Crangle+%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%5Cleft%28+%7C%7B0%7D%5Crangle+_A+%7C%7B0%7D%5Crangle+_B+%2B+%7C%7B1%7D%5Crangle+_A+%7C%7B1%7D%5Crangle+_B%5Cright%29%2C+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |{\phi}\rangle = \frac{1}{\sqrt{2}}\left( |{0}\rangle _A |{0}\rangle _B + |{1}\rangle _A |{1}\rangle _B\right), }"/>

forming what is known as an EPR (Einstein-Podolsky-Rosen) pair. Now for <img alt="{ \theta\in[-\pi, \pi]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Ctheta%5Cin%5B-%5Cpi%2C+%5Cpi%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \theta\in[-\pi, \pi]}"/> define <img alt="{ |{\beta_0(\theta)}\rangle = \cos\theta |{0}\rangle + \sin\theta |{1}\rangle }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cbeta_0%28%5Ctheta%29%7D%5Crangle+%3D+%5Ccos%5Ctheta+%7C%7B0%7D%5Crangle+%2B+%5Csin%5Ctheta+%7C%7B1%7D%5Crangle+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |{\beta_0(\theta)}\rangle = \cos\theta |{0}\rangle + \sin\theta |{1}\rangle }"/> and <img alt="{ |{\beta_1(\theta)}\rangle = -\sin\theta |{0}\rangle + \cos\theta |{1}\rangle }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cbeta_1%28%5Ctheta%29%7D%5Crangle+%3D+-%5Csin%5Ctheta+%7C%7B0%7D%5Crangle+%2B+%5Ccos%5Ctheta+%7C%7B1%7D%5Crangle+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |{\beta_1(\theta)}\rangle = -\sin\theta |{0}\rangle + \cos\theta |{1}\rangle }"/> <!-- \footnote{ $latex { |{\beta_0(\theta)}\rangle }&amp;fg=000000$ is the rotation of $latex { |{0}\rangle}&amp;fg=000000$ by $latex { \theta}&amp;fg=000000$ in the 2-d real plane spanned by $latex { |{0}\rangle}&amp;fg=000000$ and $latex { |{1}\rangle}&amp;fg=000000$ . Similarly, $latex { |{\beta_1(\theta)}\rangle}&amp;fg=000000$ is the rotation of $latex { |{1}\rangle}&amp;fg=000000$ by $latex { \theta}&amp;fg=000000$ in the 2-d real plane spanned by $latex { |{0}\rangle}&amp;fg=000000$ and $latex { |{1}\rangle}&amp;fg=000000$ . }-->.

Now we describe a (quantum) strategy with winning <!--recheck prob-->probability <img alt="{ \cos^2(\frac{\pi}{8})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Ccos%5E2%28%5Cfrac%7B%5Cpi%7D%7B8%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \cos^2(\frac{\pi}{8})}"/>. In each case Alice and Bob respond with their measurement outcome, where subscripts of the measurement basis vectors correspond to the answer to be sent back to the verifier.
<ul>
 	<li> If <img alt="{ s=0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+s%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ s=0}"/>, Alice measures in basis <img alt="{ \{ |{\beta_0(0)}\rangle , |{\beta_1(0)}\rangle \} = \{ |{0}\rangle , |{1}\rangle \}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5C%7B+%7C%7B%5Cbeta_0%280%29%7D%5Crangle+%2C+%7C%7B%5Cbeta_1%280%29%7D%5Crangle+%5C%7D+%3D+%5C%7B+%7C%7B0%7D%5Crangle+%2C+%7C%7B1%7D%5Crangle+%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \{ |{\beta_0(0)}\rangle , |{\beta_1(0)}\rangle \} = \{ |{0}\rangle , |{1}\rangle \}}"/>. If <img alt="{ s=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+s%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ s=1}"/>, Alice measures in <img alt="{ \{ |{\beta_0(\frac{\pi}{4})}\rangle , |{\beta_1(\frac{\pi}{4})}\rangle \}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5C%7B+%7C%7B%5Cbeta_0%28%5Cfrac%7B%5Cpi%7D%7B4%7D%29%7D%5Crangle+%2C+%7C%7B%5Cbeta_1%28%5Cfrac%7B%5Cpi%7D%7B4%7D%29%7D%5Crangle+%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \{ |{\beta_0(\frac{\pi}{4})}\rangle , |{\beta_1(\frac{\pi}{4})}\rangle \}}"/>. Alice answers bit <img alt="{ a = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+a+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ a = 0}"/> if outcome is <img alt="{ \beta_0(\cdot)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cbeta_0%28%5Ccdot%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \beta_0(\cdot)}"/> and answers <img alt="{ a = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+a+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ a = 1}"/> otherwise.</li>
 	<li> If <img alt="{ t=0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+t%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ t=0}"/>, Bob measures in basis <img alt="{ \{ |{\beta_0(\frac{\pi}{8})}\rangle , |{\beta_1(\frac{\pi}{8})}\rangle\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5C%7B+%7C%7B%5Cbeta_0%28%5Cfrac%7B%5Cpi%7D%7B8%7D%29%7D%5Crangle+%2C+%7C%7B%5Cbeta_1%28%5Cfrac%7B%5Cpi%7D%7B8%7D%29%7D%5Crangle%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \{ |{\beta_0(\frac{\pi}{8})}\rangle , |{\beta_1(\frac{\pi}{8})}\rangle\}}"/>. If <img alt="{ t=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+t%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ t=1}"/>, Bob measures in <img alt="{ \{ |{\beta_0(-\frac{\pi}{8})}\rangle , |{\beta_1(-\frac{\pi}{8})}\rangle \}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5C%7B+%7C%7B%5Cbeta_0%28-%5Cfrac%7B%5Cpi%7D%7B8%7D%29%7D%5Crangle+%2C+%7C%7B%5Cbeta_1%28-%5Cfrac%7B%5Cpi%7D%7B8%7D%29%7D%5Crangle+%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \{ |{\beta_0(-\frac{\pi}{8})}\rangle , |{\beta_1(-\frac{\pi}{8})}\rangle \}}"/>.</li>
 	<li> Each player responds with their respective measurement outcome.</li>
</ul>
<!--blockquote--><b>Lemma 2</b> <em><a name="goodstrategy"/> Alice and Bob win the CHSH game with <!--recheck prob-->probability <img alt="{ \cos^2(\frac{\pi}{8})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Ccos%5E2%28%5Cfrac%7B%5Cpi%7D%7B8%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \cos^2(\frac{\pi}{8})}"/>. </em><!--/blockquote-->
<em><br/><b/>Proof.</em><!-- remove close em after proof--> We will show that for each pair of questions <img alt="{ s,t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+s%2Ct%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ s,t}"/> the pair of answers <img alt="{ a,b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+a%2Cb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ a,b}"/> is correct with <!--recheck prob-->probability <img alt="{ \cos^2(\pi/8)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Ccos%5E2%28%5Cpi%2F8%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \cos^2(\pi/8)}"/>. We can split the pairs of questions into the two cases <img alt="{ s\wedge t=0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+s%5Cwedge+t%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ s\wedge t=0}"/> and <img alt="{ s\wedge t=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+s%5Cwedge+t%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ s\wedge t=1}"/>:
<ul>
 	<li> (<img alt="{ s\wedge t=0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+s%5Cwedge+t%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ s\wedge t=0}"/>) The three cases <img alt="{ (s,t)=(0,0),(0,1),(1,0)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%28s%2Ct%29%3D%280%2C0%29%2C%280%2C1%29%2C%281%2C0%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ (s,t)=(0,0),(0,1),(1,0)}"/> are all analogous: in each case Alice an Bob must output the same answer, and in each case Bob’s measurement basis is almost the same as Alice’s except rotated by a small angle <img alt="{ \pm\pi/8}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cpm%5Cpi%2F8%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \pm\pi/8}"/>.
Of the three above cases we consider the one where <img alt="{ s,t=0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+s%2Ct%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ s,t=0}"/> and check that indeed the two measurement outcomes agree with <!--recheck prob-->probability <img alt="{ \cos^2(\pi/8)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Ccos%5E2%28%5Cpi%2F8%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \cos^2(\pi/8)}"/>: When Alice measures her qubit and obtains some bit <img alt="{ a}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+a%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ a}"/>, the shared pair <img alt="{ |{\beta}\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cbeta%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |{\beta}\rangle}"/> collapses to <img alt="{ |{a}\rangle _A |{a}\rangle _B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%7Ba%7D%5Crangle+_A+%7C%7Ba%7D%5Crangle+_B%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |{a}\rangle _A |{a}\rangle _B}"/>. Indeed, since the question was <img alt="{ s=0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+s%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ s=0}"/>, Alice measures her qubit in the basis <img alt="{ \{|0\rangle,|1\rangle\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5C%7B%7C0%5Crangle%2C%7C1%5Crangle%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \{|0\rangle,|1\rangle\}}"/>. This means that Alice applies the measurement <img alt="{ \{|0\rangle\langle 0|\otimes {\mathbb{I}},|1\rangle\langle 1|\otimes {\mathbb{I}}\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5C%7B%7C0%5Crangle%5Clangle+0%7C%5Cotimes+%7B%5Cmathbb%7BI%7D%7D%2C%7C1%5Crangle%5Clangle+1%7C%5Cotimes+%7B%5Cmathbb%7BI%7D%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \{|0\rangle\langle 0|\otimes {\mathbb{I}},|1\rangle\langle 1|\otimes {\mathbb{I}}\}}"/> on the global state. The post-measurement state is the normalization of

<img alt="{ ( |{a}\rangle \langle{a}| \otimes {\mathbb{I}}) |{\phi}\rangle _{AB}=\frac{1}{\sqrt2} |{a}\rangle \overbrace{\langle a |{0}\rangle }^{\delta_{a,0}}\otimes | 0\rangle + |{a}\rangle \overbrace{\langle a |{1}\rangle }^{\delta_{a,1}}\otimes |{1}\rangle =\frac {1}{\sqrt2} |{a}\rangle _A |{a}\rangle _B }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%28+%7C%7Ba%7D%5Crangle+%5Clangle%7Ba%7D%7C+%5Cotimes+%7B%5Cmathbb%7BI%7D%7D%29+%7C%7B%5Cphi%7D%5Crangle+_%7BAB%7D%3D%5Cfrac%7B1%7D%7B%5Csqrt2%7D+%7C%7Ba%7D%5Crangle+%5Coverbrace%7B%5Clangle+a+%7C%7B0%7D%5Crangle+%7D%5E%7B%5Cdelta_%7Ba%2C0%7D%7D%5Cotimes+%7C+0%5Crangle+%2B+%7C%7Ba%7D%5Crangle+%5Coverbrace%7B%5Clangle+a+%7C%7B1%7D%5Crangle+%7D%5E%7B%5Cdelta_%7Ba%2C1%7D%7D%5Cotimes+%7C%7B1%7D%5Crangle+%3D%5Cfrac+%7B1%7D%7B%5Csqrt2%7D+%7C%7Ba%7D%5Crangle+_A+%7C%7Ba%7D%5Crangle+_B+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ ( |{a}\rangle \langle{a}| \otimes {\mathbb{I}}) |{\phi}\rangle _{AB}=\frac{1}{\sqrt2} |{a}\rangle \overbrace{\langle a |{0}\rangle }^{\delta_{a,0}}\otimes | 0\rangle + |{a}\rangle \overbrace{\langle a |{1}\rangle }^{\delta_{a,1}}\otimes |{1}\rangle =\frac {1}{\sqrt2} |{a}\rangle _A |{a}\rangle _B }"/>

because <img alt="{ \langle a |{a'}\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Clangle+a+%7C%7Ba%27%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \langle a |{a'}\rangle}"/> can be viewed as a Kronecker delta of <img alt="{ a}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+a%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ a}"/> and <img alt="{ a'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+a%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ a'}"/>. In particular, Bob is now in the pure state <img alt="{ |{a}\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%7Ba%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |{a}\rangle}"/> .

Because Bob received question <img alt="{ t=0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+t%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ t=0}"/> he measures in the basis <img alt="{ \{ |{\beta_b(\pi/8)}\rangle \}_b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5C%7B+%7C%7B%5Cbeta_b%28%5Cpi%2F8%29%7D%5Crangle+%5C%7D_b%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \{ |{\beta_b(\pi/8)}\rangle \}_b}"/> Therefore his <!--recheck prob-->probability of correctly outputting <img alt="{ b=a}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+b%3Da%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ b=a}"/> is

<img alt="{ {\mathop{\mathbb{P}}}[\text{Bob gets outcome }a] = |\langle\beta_a(\tfrac{\pi}{8}) |{a}\rangle |^2 = \cos^2\left(\frac{\pi}{8}\right) }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7B%5Cmathop%7B%5Cmathbb%7BP%7D%7D%7D%5B%5Ctext%7BBob+gets+outcome+%7Da%5D+%3D+%7C%5Clangle%5Cbeta_a%28%5Ctfrac%7B%5Cpi%7D%7B8%7D%29+%7C%7Ba%7D%5Crangle+%7C%5E2+%3D+%5Ccos%5E2%5Cleft%28%5Cfrac%7B%5Cpi%7D%7B8%7D%5Cright%29+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ {\mathop{\mathbb{P}}}[\text{Bob gets outcome }a] = |\langle\beta_a(\tfrac{\pi}{8}) |{a}\rangle |^2 = \cos^2\left(\frac{\pi}{8}\right) }"/>

<!--end align*--></li>
 	<li> (<img alt="{ s\wedge t=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+s%5Cwedge+t%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ s\wedge t=1}"/>)
Now consider the case <img alt="{ s=1,t=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+s%3D1%2Ct%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ s=1,t=1}"/> where Alice and Bob are supposed to give different answers. Alice measures in basis consisting of <img alt="{ |{\beta_0(\pi/4)}\rangle =\frac{|0\rangle+|1\rangle}{\sqrt2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cbeta_0%28%5Cpi%2F4%29%7D%5Crangle+%3D%5Cfrac%7B%7C0%5Crangle%2B%7C1%5Crangle%7D%7B%5Csqrt2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |{\beta_0(\pi/4)}\rangle =\frac{|0\rangle+|1\rangle}{\sqrt2}}"/> and <img alt="{ |{\beta_1(\pi/4)}\rangle =\frac{-|0\rangle+|1\rangle}{\sqrt2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cbeta_1%28%5Cpi%2F4%29%7D%5Crangle+%3D%5Cfrac%7B-%7C0%5Crangle%2B%7C1%5Crangle%7D%7B%5Csqrt2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |{\beta_1(\pi/4)}\rangle =\frac{-|0\rangle+|1\rangle}{\sqrt2}}"/>. If Alice gets outcome <img alt="{ a}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+a%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ a}"/> then the post-measurement global state is <img alt="{ |{\beta_a(\frac\pi4)}\rangle |{\beta_a(\frac\pi4)}\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cbeta_a%28%5Cfrac%5Cpi4%29%7D%5Crangle+%7C%7B%5Cbeta_a%28%5Cfrac%5Cpi4%29%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |{\beta_a(\frac\pi4)}\rangle |{\beta_a(\frac\pi4)}\rangle}"/> . Therefore when Bob applies the measurement in basis <img alt="{ \{ |{\beta_a(-\frac\pi8)}\rangle \}_a}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5C%7B+%7C%7B%5Cbeta_a%28-%5Cfrac%5Cpi8%29%7D%5Crangle+%5C%7D_a%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \{ |{\beta_a(-\frac\pi8)}\rangle \}_a}"/> he mistakenly outputs <img alt="{ a}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+a%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ a}"/> only with <!--recheck prob-->probability <img alt="{ |\langle\beta_a(\frac\pi4) |{\beta_a(-\frac\pi8)}\rangle |^2=\sin^2(\frac\pi8)=1-\cos^2(\frac\pi8)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Clangle%5Cbeta_a%28%5Cfrac%5Cpi4%29+%7C%7B%5Cbeta_a%28-%5Cfrac%5Cpi8%29%7D%5Crangle+%7C%5E2%3D%5Csin%5E2%28%5Cfrac%5Cpi8%29%3D1-%5Ccos%5E2%28%5Cfrac%5Cpi8%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |\langle\beta_a(\frac\pi4) |{\beta_a(-\frac\pi8)}\rangle |^2=\sin^2(\frac\pi8)=1-\cos^2(\frac\pi8)}"/>.</li>
</ul>
<!--end proof-->
<div align="right">□</div>
Lemma <a href="https://windowsontheory.org/feed/#goodstrategy">2</a> implies a lower bound on the value of the CHSH game.
<h4>Corollary</h4>
<em> <img alt="{ \omega^*(G)\ge\cos^2(\frac\pi8)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%2A%28G%29%5Cge%5Ccos%5E2%28%5Cfrac%5Cpi8%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \omega^*(G)\ge\cos^2(\frac\pi8)}"/> </em>

<!--ending corollary--> 
<br/>It turns out that this lower bound is sharp, that is, the strategy just described is optimal.

<h4>Lemma</h4><em> The value of the CHSH game using a quantum strategy is at most <img alt="{ \frac{1}{2} + \frac{\sqrt{2}}{4} = \cos^2\frac{\pi}{8}\approx 0.85}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cfrac%7B1%7D%7B2%7D+%2B+%5Cfrac%7B%5Csqrt%7B2%7D%7D%7B4%7D+%3D+%5Ccos%5E2%5Cfrac%7B%5Cpi%7D%7B8%7D%5Capprox+0.85%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \frac{1}{2} + \frac{\sqrt{2}}{4} = \cos^2\frac{\pi}{8}\approx 0.85}"/>. </em>

<!--ending lemma-->

<em><b>Proof.</b></em><!-- remove close em after proof-->

We can describe the quantum strategy of Alice and Bob in an XOR game by (i) a shared quantum state <img alt="{ |{\phi}\rangle _{AB}\in\mathbb{C}^d\otimes\mathbb{C}^d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cphi%7D%5Crangle+_%7BAB%7D%5Cin%5Cmathbb%7BC%7D%5Ed%5Cotimes%5Cmathbb%7BC%7D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |{\phi}\rangle _{AB}\in\mathbb{C}^d\otimes\mathbb{C}^d}"/> (note that for the CHSH game, <img alt="{ d=2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+d%3D2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ d=2}"/>); (ii) measurements <img alt="{ \{A^0_s, A^1_s\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5C%7BA%5E0_s%2C+A%5E1_s%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \{A^0_s, A^1_s\}}"/> for every question <img alt="{ s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+s%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ s}"/> sent to Alice; (iii) measurements <img alt="{ \{B^0_t, B^1_t\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5C%7BB%5E0_t%2C+B%5E1_t%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \{B^0_t, B^1_t\}}"/> for every question <img alt="{ t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ t}"/> sent to Bob.

The <!--recheck prob-->probability of answering <img alt="{ (a, b)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%28a%2C+b%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ (a, b)}"/> given questions <img alt="{ (s, t)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%28s%2C+t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ (s, t)}"/> is <img alt="{ \langle{\phi}| A^a_s\otimes B^b_t |{\phi}\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Clangle%7B%5Cphi%7D%7C+A%5Ea_s%5Cotimes+B%5Eb_t+%7C%7B%5Cphi%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \langle{\phi}| A^a_s\otimes B^b_t |{\phi}\rangle}"/> . Now let us write <img alt="{ A_s=A^0_s - A^1_s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+A_s%3DA%5E0_s+-+A%5E1_s%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ A_s=A^0_s - A^1_s}"/> and <img alt="{ B_t=B^0_t - B^1_t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+B_t%3DB%5E0_t+-+B%5E1_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ B_t=B^0_t - B^1_t}"/> so that for any <img alt="{ a, b\in\{0, 1\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+a%2C+b%5Cin%5C%7B0%2C+1%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ a, b\in\{0, 1\}}"/>, we can write

<img alt="{ A_s^a = \frac{{\mathbb{I}} + (-1)^aA_s}{2}, B_t^b = \frac{{\mathbb{I}} + (-1)^bB_t}{2} }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+A_s%5Ea+%3D+%5Cfrac%7B%7B%5Cmathbb%7BI%7D%7D+%2B+%28-1%29%5EaA_s%7D%7B2%7D%2C+B_t%5Eb+%3D+%5Cfrac%7B%7B%5Cmathbb%7BI%7D%7D+%2B+%28-1%29%5EbB_t%7D%7B2%7D+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ A_s^a = \frac{{\mathbb{I}} + (-1)^aA_s}{2}, B_t^b = \frac{{\mathbb{I}} + (-1)^bB_t}{2} }"/>

Note that since the possible outcomes here are finite, <img alt="{ A_s, B_t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+A_s%2C+B_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ A_s, B_t}"/> are Hermitian and we may assume have bounded norm of 1. Furthermore, we assume that <img alt="{ A_s, B_t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+A_s%2C+B_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ A_s, B_t}"/> are <em>observables</em> so that <img alt="{ A_s^2 = B_t^2 = {\mathbb{I}}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+A_s%5E2+%3D+B_t%5E2+%3D+%7B%5Cmathbb%7BI%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ A_s^2 = B_t^2 = {\mathbb{I}}}"/> <!-- \footnote{ We make this assumption since for a fixed $latex { |{\phi}\rangle}&amp;fg=000000$ and $latex { A_s}&amp;fg=000000$, the quantum game value $latex { \omega^*(G)}&amp;fg=000000$ is linear in the $latex { B_t}&amp;fg=000000$ and by convexity the best choice of the matrix would occur at an extreme point of the unit ball of Hermitian matrices. }-->.

Now denoting <img alt="{ f_{s, t}(a\oplus b)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+f_%7Bs%2C+t%7D%28a%5Coplus+b%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ f_{s, t}(a\oplus b)}"/> as the XOR predicate to be computed, we can write the quantum game value as

<img alt="\omega^*(G) = \sup_{ |{\phi}\rangle , \{A_s^a\}, \{B_t^b\}} {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}f_{s, t}(a\oplus b) \langle{\phi}| A^a_s\otimes B^b_t |{\phi}\rangle  \\ = \sup_{ |{\phi}\rangle , \{A_s\}, \{B_t\}} {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}f_{s, t}(a\oplus b) \langle{\phi}| \frac{{\mathbb{I}} + (-1)^aA_s}{2}\otimes  \frac{{\mathbb{I}} + (-1)^bB_t}{2} |{\phi}\rangle  \\ = {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}\frac{f_{s, t}(a\oplus b)}{4} + \sup_{ |{\phi}\rangle , \{A_s\}, \{B_t\}} {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}f_{s, t}(a\oplus b) \langle{\phi}| \frac{{\mathbb{I}} + (-1)^aA_s}{2}\otimes  \frac{{\mathbb{I}} + (-1)^bB_t}{2} |{\phi}\rangle  \\ = {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}\frac{f_{s, t}(a\oplus b)}{4} + \sup_{ |{\phi}\rangle , \{A_s\}, \{B_t\}} {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}\frac{f_{s, t}(a\oplus b)(-1)^{ab}}{4} \langle{\phi}| A_s\otimes B_t |{\phi}\rangle  \\ = {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}\frac{f_{s, t}(a\oplus b)}{4} + \sup_{ |{\phi}\rangle , \{A_s\}, \{B_t\}} {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\frac{f_{s, t}(0) - f_{s,t}(1)}{2} \langle{\phi}| A_s\otimes B_t |{\phi}\rangle  \\ " class="latex" src="https://s0.wp.com/latex.php?latex=%5Comega%5E%2A%28G%29+%3D+%5Csup_%7B+%7C%7B%5Cphi%7D%5Crangle+%2C+%5C%7BA_s%5Ea%5C%7D%2C+%5C%7BB_t%5Eb%5C%7D%7D+%7B%5Cmathop%7B%5Cmathbb%7BE%7D%7D%7D_%7B%28s%2C+t%29%5Csim%5CPi%7D%5Csum_%7Ba%2C+b%7Df_%7Bs%2C+t%7D%28a%5Coplus+b%29+%5Clangle%7B%5Cphi%7D%7C+A%5Ea_s%5Cotimes+B%5Eb_t+%7C%7B%5Cphi%7D%5Crangle++%5C%5C+%3D+%5Csup_%7B+%7C%7B%5Cphi%7D%5Crangle+%2C+%5C%7BA_s%5C%7D%2C+%5C%7BB_t%5C%7D%7D+%7B%5Cmathop%7B%5Cmathbb%7BE%7D%7D%7D_%7B%28s%2C+t%29%5Csim%5CPi%7D%5Csum_%7Ba%2C+b%7Df_%7Bs%2C+t%7D%28a%5Coplus+b%29+%5Clangle%7B%5Cphi%7D%7C+%5Cfrac%7B%7B%5Cmathbb%7BI%7D%7D+%2B+%28-1%29%5EaA_s%7D%7B2%7D%5Cotimes++%5Cfrac%7B%7B%5Cmathbb%7BI%7D%7D+%2B+%28-1%29%5EbB_t%7D%7B2%7D+%7C%7B%5Cphi%7D%5Crangle++%5C%5C+%3D+%7B%5Cmathop%7B%5Cmathbb%7BE%7D%7D%7D_%7B%28s%2C+t%29%5Csim%5CPi%7D%5Csum_%7Ba%2C+b%7D%5Cfrac%7Bf_%7Bs%2C+t%7D%28a%5Coplus+b%29%7D%7B4%7D+%2B+%5Csup_%7B+%7C%7B%5Cphi%7D%5Crangle+%2C+%5C%7BA_s%5C%7D%2C+%5C%7BB_t%5C%7D%7D+%7B%5Cmathop%7B%5Cmathbb%7BE%7D%7D%7D_%7B%28s%2C+t%29%5Csim%5CPi%7D%5Csum_%7Ba%2C+b%7Df_%7Bs%2C+t%7D%28a%5Coplus+b%29+%5Clangle%7B%5Cphi%7D%7C+%5Cfrac%7B%7B%5Cmathbb%7BI%7D%7D+%2B+%28-1%29%5EaA_s%7D%7B2%7D%5Cotimes++%5Cfrac%7B%7B%5Cmathbb%7BI%7D%7D+%2B+%28-1%29%5EbB_t%7D%7B2%7D+%7C%7B%5Cphi%7D%5Crangle++%5C%5C+%3D+%7B%5Cmathop%7B%5Cmathbb%7BE%7D%7D%7D_%7B%28s%2C+t%29%5Csim%5CPi%7D%5Csum_%7Ba%2C+b%7D%5Cfrac%7Bf_%7Bs%2C+t%7D%28a%5Coplus+b%29%7D%7B4%7D+%2B+%5Csup_%7B+%7C%7B%5Cphi%7D%5Crangle+%2C+%5C%7BA_s%5C%7D%2C+%5C%7BB_t%5C%7D%7D+%7B%5Cmathop%7B%5Cmathbb%7BE%7D%7D%7D_%7B%28s%2C+t%29%5Csim%5CPi%7D%5Csum_%7Ba%2C+b%7D%5Cfrac%7Bf_%7Bs%2C+t%7D%28a%5Coplus+b%29%28-1%29%5E%7Bab%7D%7D%7B4%7D+%5Clangle%7B%5Cphi%7D%7C+A_s%5Cotimes+B_t+%7C%7B%5Cphi%7D%5Crangle++%5C%5C+%3D+%7B%5Cmathop%7B%5Cmathbb%7BE%7D%7D%7D_%7B%28s%2C+t%29%5Csim%5CPi%7D%5Csum_%7Ba%2C+b%7D%5Cfrac%7Bf_%7Bs%2C+t%7D%28a%5Coplus+b%29%7D%7B4%7D+%2B+%5Csup_%7B+%7C%7B%5Cphi%7D%5Crangle+%2C+%5C%7BA_s%5C%7D%2C+%5C%7BB_t%5C%7D%7D+%7B%5Cmathop%7B%5Cmathbb%7BE%7D%7D%7D_%7B%28s%2C+t%29%5Csim%5CPi%7D%5Cfrac%7Bf_%7Bs%2C+t%7D%280%29+-+f_%7Bs%2Ct%7D%281%29%7D%7B2%7D+%5Clangle%7B%5Cphi%7D%7C+A_s%5Cotimes+B_t+%7C%7B%5Cphi%7D%5Crangle++%5C%5C+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\omega^*(G) = \sup_{ |{\phi}\rangle , \{A_s^a\}, \{B_t^b\}} {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}f_{s, t}(a\oplus b) \langle{\phi}| A^a_s\otimes B^b_t |{\phi}\rangle  \\ = \sup_{ |{\phi}\rangle , \{A_s\}, \{B_t\}} {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}f_{s, t}(a\oplus b) \langle{\phi}| \frac{{\mathbb{I}} + (-1)^aA_s}{2}\otimes  \frac{{\mathbb{I}} + (-1)^bB_t}{2} |{\phi}\rangle  \\ = {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}\frac{f_{s, t}(a\oplus b)}{4} + \sup_{ |{\phi}\rangle , \{A_s\}, \{B_t\}} {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}f_{s, t}(a\oplus b) \langle{\phi}| \frac{{\mathbb{I}} + (-1)^aA_s}{2}\otimes  \frac{{\mathbb{I}} + (-1)^bB_t}{2} |{\phi}\rangle  \\ = {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}\frac{f_{s, t}(a\oplus b)}{4} + \sup_{ |{\phi}\rangle , \{A_s\}, \{B_t\}} {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}\frac{f_{s, t}(a\oplus b)(-1)^{ab}}{4} \langle{\phi}| A_s\otimes B_t |{\phi}\rangle  \\ = {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}\frac{f_{s, t}(a\oplus b)}{4} + \sup_{ |{\phi}\rangle , \{A_s\}, \{B_t\}} {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\frac{f_{s, t}(0) - f_{s,t}(1)}{2} \langle{\phi}| A_s\otimes B_t |{\phi}\rangle  \\ "/>

where the summation <img alt="{ \sum_{a, b\in\{0, 1\}}\left(\cdot\right)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Csum_%7Ba%2C+b%5Cin%5C%7B0%2C+1%5C%7D%7D%5Cleft%28%5Ccdot%5Cright%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \sum_{a, b\in\{0, 1\}}\left(\cdot\right)}"/> has been evaluated in the last line.

Now note that the first term is independent of the quantum strategy and as a result equals the value of the uniformly random strategy which is 1/2. So we proceed to focus on the second term. Note that for CHSH <img alt="{ f_{s, t}(0) - f_{s,t}(1) = (-1)^{st}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+f_%7Bs%2C+t%7D%280%29+-+f_%7Bs%2Ct%7D%281%29+%3D+%28-1%29%5E%7Bst%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ f_{s, t}(0) - f_{s,t}(1) = (-1)^{st}}"/> simplifying the second term to

<img alt="{ \frac{1}{8}( \langle{\phi}| A_0\otimes B_0 |{\phi}\rangle + \langle{\phi}| A_1\otimes B_0 |{\phi}\rangle + \langle{\phi}| A_0\otimes B_1 |{\phi}\rangle - \langle{\phi}| A_1\otimes B_1 |{\phi}\rangle ). }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cfrac%7B1%7D%7B8%7D%28+%5Clangle%7B%5Cphi%7D%7C+A_0%5Cotimes+B_0+%7C%7B%5Cphi%7D%5Crangle+%2B+%5Clangle%7B%5Cphi%7D%7C+A_1%5Cotimes+B_0+%7C%7B%5Cphi%7D%5Crangle+%2B+%5Clangle%7B%5Cphi%7D%7C+A_0%5Cotimes+B_1+%7C%7B%5Cphi%7D%5Crangle+-+%5Clangle%7B%5Cphi%7D%7C+A_1%5Cotimes+B_1+%7C%7B%5Cphi%7D%5Crangle+%29.+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \frac{1}{8}( \langle{\phi}| A_0\otimes B_0 |{\phi}\rangle + \langle{\phi}| A_1\otimes B_0 |{\phi}\rangle + \langle{\phi}| A_0\otimes B_1 |{\phi}\rangle - \langle{\phi}| A_1\otimes B_1 |{\phi}\rangle ). }"/>

Next, we invoke Tsirelson’s Theorem (See Theorem <a href="https://windowsontheory.org/feed/#thmtsirelson">3</a>) to bound this second term as

<img alt="= \sup_{{\textbf{x}}_s, {\textbf{y}}_t}\frac{1}{8}({\textbf{x}}_0\cdot {\textbf{y}}_0 + {\textbf{x}}_0\cdot {\textbf{y}}_1 + {\textbf{x}}_1\cdot {\textbf{y}}_0 - {\textbf{x}}_1\cdot {\textbf{y}}_1) \\ \leq \sup_{{\textbf{x}}_s, {\textbf{y}}_t}\frac{1}{8}(\|{\textbf{x}}_0\|\|{\textbf{y}}_0 + {\textbf{y}}_1\| + \|{\textbf{x}}_1\|\|{\textbf{y}}_0 - {\textbf{y}}_1\|) \\ \leq \sup_{{\textbf{x}}_s, {\textbf{y}}_t}\frac{\sqrt{2}}{8}\sqrt{2\|{\textbf{y}}_0\|^2 + 2\|{\textbf{y}}_1\|^2} \leq \frac{\sqrt{2}}{4} " class="latex" src="https://s0.wp.com/latex.php?latex=%3D+%5Csup_%7B%7B%5Ctextbf%7Bx%7D%7D_s%2C+%7B%5Ctextbf%7By%7D%7D_t%7D%5Cfrac%7B1%7D%7B8%7D%28%7B%5Ctextbf%7Bx%7D%7D_0%5Ccdot+%7B%5Ctextbf%7By%7D%7D_0+%2B+%7B%5Ctextbf%7Bx%7D%7D_0%5Ccdot+%7B%5Ctextbf%7By%7D%7D_1+%2B+%7B%5Ctextbf%7Bx%7D%7D_1%5Ccdot+%7B%5Ctextbf%7By%7D%7D_0+-+%7B%5Ctextbf%7Bx%7D%7D_1%5Ccdot+%7B%5Ctextbf%7By%7D%7D_1%29+%5C%5C+%5Cleq+%5Csup_%7B%7B%5Ctextbf%7Bx%7D%7D_s%2C+%7B%5Ctextbf%7By%7D%7D_t%7D%5Cfrac%7B1%7D%7B8%7D%28%5C%7C%7B%5Ctextbf%7Bx%7D%7D_0%5C%7C%5C%7C%7B%5Ctextbf%7By%7D%7D_0+%2B+%7B%5Ctextbf%7By%7D%7D_1%5C%7C+%2B+%5C%7C%7B%5Ctextbf%7Bx%7D%7D_1%5C%7C%5C%7C%7B%5Ctextbf%7By%7D%7D_0+-+%7B%5Ctextbf%7By%7D%7D_1%5C%7C%29+%5C%5C+%5Cleq+%5Csup_%7B%7B%5Ctextbf%7Bx%7D%7D_s%2C+%7B%5Ctextbf%7By%7D%7D_t%7D%5Cfrac%7B%5Csqrt%7B2%7D%7D%7B8%7D%5Csqrt%7B2%5C%7C%7B%5Ctextbf%7By%7D%7D_0%5C%7C%5E2+%2B+2%5C%7C%7B%5Ctextbf%7By%7D%7D_1%5C%7C%5E2%7D+%5Cleq+%5Cfrac%7B%5Csqrt%7B2%7D%7D%7B4%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="= \sup_{{\textbf{x}}_s, {\textbf{y}}_t}\frac{1}{8}({\textbf{x}}_0\cdot {\textbf{y}}_0 + {\textbf{x}}_0\cdot {\textbf{y}}_1 + {\textbf{x}}_1\cdot {\textbf{y}}_0 - {\textbf{x}}_1\cdot {\textbf{y}}_1) \\ \leq \sup_{{\textbf{x}}_s, {\textbf{y}}_t}\frac{1}{8}(\|{\textbf{x}}_0\|\|{\textbf{y}}_0 + {\textbf{y}}_1\| + \|{\textbf{x}}_1\|\|{\textbf{y}}_0 - {\textbf{y}}_1\|) \\ \leq \sup_{{\textbf{x}}_s, {\textbf{y}}_t}\frac{\sqrt{2}}{8}\sqrt{2\|{\textbf{y}}_0\|^2 + 2\|{\textbf{y}}_1\|^2} \leq \frac{\sqrt{2}}{4} "/>

where we have used Cauchy-Schwartz and the concavity of the <img alt="{ \sqrt{\cdot}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Csqrt%7B%5Ccdot%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \sqrt{\cdot}}"/> function.

This completes our proof showing the exact characterization of the value (<img alt="{ =\cos^2(\frac{\pi}{8})=\frac{1}{2}+\frac{\sqrt{2}}{4}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%3D%5Ccos%5E2%28%5Cfrac%7B%5Cpi%7D%7B8%7D%29%3D%5Cfrac%7B1%7D%7B2%7D%2B%5Cfrac%7B%5Csqrt%7B2%7D%7D%7B4%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ =\cos^2(\frac{\pi}{8})=\frac{1}{2}+\frac{\sqrt{2}}{4}}"/>) of the CHSH game using a quantum strategy. This proof is an adaptation of the one in [12]. <!--end proof-->
<div align="right">□</div>
<!--blockquote--><b>Theorem 3 (Tsirelson’s Theorem [1])</b> <em><a name="thmtsirelson"/> For any <img alt="{ n\times n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+n%5Ctimes+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ n\times n}"/> matrix <img alt="{ C = (C_{s, t})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+C+%3D+%28C_%7Bs%2C+t%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ C = (C_{s, t})}"/>, the following are equivalent: </em>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em>
<ol>
 	<li> There exist <img alt="{ d\in\mathbb{N}, |{\phi}\rangle \in\mathbb{C}^{d}\otimes\mathbb{C}^{d}, A_s, B_t\in\text{Herm}(\mathbb{C}^d), A_s^2 = B_t^2 = I}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+d%5Cin%5Cmathbb%7BN%7D%2C+%7C%7B%5Cphi%7D%5Crangle+%5Cin%5Cmathbb%7BC%7D%5E%7Bd%7D%5Cotimes%5Cmathbb%7BC%7D%5E%7Bd%7D%2C+A_s%2C+B_t%5Cin%5Ctext%7BHerm%7D%28%5Cmathbb%7BC%7D%5Ed%29%2C+A_s%5E2+%3D+B_t%5E2+%3D+I%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ d\in\mathbb{N}, |{\phi}\rangle \in\mathbb{C}^{d}\otimes\mathbb{C}^{d}, A_s, B_t\in\text{Herm}(\mathbb{C}^d), A_s^2 = B_t^2 = I}"/> such that for any <img alt="{ s, t\in[n]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+s%2C+t%5Cin%5Bn%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ s, t\in[n]}"/> <img alt="{ C_{s, t} = \langle{\phi}| A_s\otimes B_t |{\phi}\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+C_%7Bs%2C+t%7D+%3D+%5Clangle%7B%5Cphi%7D%7C+A_s%5Cotimes+B_t+%7C%7B%5Cphi%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ C_{s, t} = \langle{\phi}| A_s\otimes B_t |{\phi}\rangle}"/> . Further this would imply that <img alt="{ d\leq 2^{\lceil\frac{n+2}{2}\rceil}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+d%5Cleq+2%5E%7B%5Clceil%5Cfrac%7Bn%2B2%7D%7B2%7D%5Crceil%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ d\leq 2^{\lceil\frac{n+2}{2}\rceil}}"/>;</li>
 	<li> There exist real unit vectors <img alt="{ { {\textbf{x}}}_s, { {\textbf{y}}}_t\in{\mathbb{R}}^{n+2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7B%09%7B%5Ctextbf%7Bx%7D%7D%7D_s%2C+%7B%09%7B%5Ctextbf%7By%7D%7D%7D_t%5Cin%7B%5Cmathbb%7BR%7D%7D%5E%7Bn%2B2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ { {\textbf{x}}}_s, { {\textbf{y}}}_t\in{\mathbb{R}}^{n+2}}"/> for <img alt="{ s, t\in [n]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+s%2C+t%5Cin+%5Bn%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ s, t\in [n]}"/> such that <img alt="{ C_{s, t} = { {\textbf{x}}}_s\cdot { {\textbf{y}}}_t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+C_%7Bs%2C+t%7D+%3D+%7B%09%7B%5Ctextbf%7Bx%7D%7D%7D_s%5Ccdot+%7B%09%7B%5Ctextbf%7By%7D%7D%7D_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ C_{s, t} = { {\textbf{x}}}_s\cdot { {\textbf{y}}}_t}"/>;</li>
</ol>
</em><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em> </em><!--/blockquote-->
<h2>Entangled unique games are easy</h2>
The CHSH game provides the first example that the entangled value <img alt="{ \omega^*(G)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%2A%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \omega^*(G)}"/> of a nonlocal game can exceed the classical value <img alt="{ \omega(G)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \omega(G)}"/>. XOR-games like the CHSH game are the special case corresponding to alphabet size <img alt="{ k=2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+k%3D2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ k=2}"/> of the class of <em>unique games</em> :
<h4>Definition (Unique Games)</h4>
<em> A 2-prover 1-round game is called a <em>unique game</em> if its constraints are of the form <img alt="{ b=\pi_{ij}(a)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+b%3D%5Cpi_%7Bij%7D%28a%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ b=\pi_{ij}(a)}"/> where <img alt="{ \pi_{ij}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cpi_%7Bij%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \pi_{ij}}"/> is a permutation of the alphabet <img alt="{ \Sigma}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5CSigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \Sigma}"/> for each edge <img alt="{ i\sim j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+i%5Csim+j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ i\sim j}"/>. </em>

<!--ending definition--> The famous <em>unique games conjecture</em> (UGC) by Khot says that <img alt="{ \omega(G)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \omega(G)}"/> is NP-hard to approximate for unique games. Surprisingly, Kempe et al. showed that a natural semidefinite relaxation for unique games yields an approximation to the entangled value <img alt="{ \omega^*(G)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%2A%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \omega^*(G)}"/> which can be computed in polynomial time. In other words the UGC is false for entangled provers, in contrast to the classical case where the conjecture is open.
<!--blockquote--><br/>Theorem 4 <em><a name="efficientUGC"/> There is an efficient (classical) algorithm which takes a description of a nonlocal game <img alt="{ G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+G%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ G}"/> as its input and outputs <img alt="{ \hat\omega(G)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Chat%5Comega%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \hat\omega(G)}"/> such that </em>

<em>
<img alt="{ 1-6(1-\hat\omega(G))\le\omega^*(G)\le\hat\omega(G) }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+1-6%281-%5Chat%5Comega%28G%29%29%5Cle%5Comega%5E%2A%28G%29%5Cle%5Chat%5Comega%28G%29+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ 1-6(1-\hat\omega(G))\le\omega^*(G)\le\hat\omega(G) }"/></em>

<em>Put differently, if <img alt="{ \omega^*(G)=1-\varepsilon^*}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%2A%28G%29%3D1-%5Cvarepsilon%5E%2A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \omega^*(G)=1-\varepsilon^*}"/> and <img alt="{ \hat\omega(G)=1-\hat\varepsilon}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Chat%5Comega%28G%29%3D1-%5Chat%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \hat\omega(G)=1-\hat\varepsilon}"/>, then</em>

<em><img alt="{ \varepsilon^*\in[\hat\varepsilon,6\hat\varepsilon] }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cvarepsilon%5E%2A%5Cin%5B%5Chat%5Cvarepsilon%2C6%5Chat%5Cvarepsilon%5D+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \varepsilon^*\in[\hat\varepsilon,6\hat\varepsilon] }"/></em>

<em>
</em><em/><em/><em/><em> </em><!--/blockquote-->
<br/>The algorithm of theorem <a href="https://windowsontheory.org/feed/#efficientUGC">4</a> proceeds by relaxing the set of quantum strategies to a larger convex set <img alt="{ \mathcal S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathcal+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \mathcal S}"/> of <em>pseudo-strategies</em> and maximizing over <img alt="{ \mathcal S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathcal+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \mathcal S}"/> instead of actual strategies, a much easier task. In approximation theory one often encounters a collection of hypothetical moments not arising from a distribution, known as a pseudo-distribution. In contrast, our pseudo-strategies are actual conditional <!--recheck prob-->probability distributions on answers (conditional on the questions). What makes <img alt="{ \mathcal S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathcal+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \mathcal S}"/> a set of “pseudo”-strategies rather than actual strategies is that they may enjoy correlations which cannot be achieved without communication.
<h3> Convex relaxation of quantum strategies</h3>
We will define <img alt="{ \mathcal S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathcal+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \mathcal S}"/> to be a class of conditional <!--recheck prob-->probability distributions <img alt="{ \tilde{P}(a,b|s,t)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BP%7D%28a%2Cb%7Cs%2Ct%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \tilde{P}(a,b|s,t)}"/> on answers given questions. We will require that the pseudo-strategies satisfy a positive semidefinite constraint when arranged in matrix form. In particular this matrix has to be symmetric, so we symmetrize the conditional <!--recheck prob-->probability <img alt="{ \tilde{P}(a,b|s,t)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BP%7D%28a%2Cb%7Cs%2Ct%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \tilde{P}(a,b|s,t)}"/> by allowing each of <img alt="{ s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+s%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ s}"/> and <img alt="{ t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ t}"/> to be either a question for Alice or for Bob. That is, we extend the domain of definition for <img alt="{ \tilde{P}(a,b|s,t)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BP%7D%28a%2Cb%7Cs%2Ct%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \tilde{P}(a,b|s,t)}"/> from <img alt="{ \Sigma^2\times S\times T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5CSigma%5E2%5Ctimes+S%5Ctimes+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \Sigma^2\times S\times T}"/> to <img alt="{ \Sigma^2\times (S\cup T)^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5CSigma%5E2%5Ctimes+%28S%5Ccup+T%29%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \Sigma^2\times (S\cup T)^2}"/> where <img alt="{ S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ S}"/> and <img alt="{ T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ T}"/> are the question sets. So each question <img alt="{ s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+s%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ s}"/> and <img alt="{ t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ t}"/> and answer <img alt="{ a}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+a%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ a}"/> and <img alt="{ b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+b%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ b}"/> can be either for Alice or Bob — we indicate this by changing notation from <img alt="{ (s,t)\in S\times T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%28s%2Ct%29%5Cin+S%5Ctimes+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ (s,t)\in S\times T}"/> to <img alt="{ q,q'\in S\cup T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+q%2Cq%27%5Cin+S%5Ccup+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ q,q'\in S\cup T}"/> and for the answers replacing <img alt="{ a,b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+a%2Cb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ a,b}"/> by <img alt="{ c,c'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+c%2Cc%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ c,c'}"/>.

<!--blockquote--><br/>Definition 5 (Block-matrix form) <em><a name="to_matrix"/> Given a function <img alt="{ \tilde{P}=\tilde{P}(\cdot\cdot|\cdot\cdot)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BP%7D%3D%5Ctilde%7BP%7D%28%5Ccdot%5Ccdot%7C%5Ccdot%5Ccdot%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \tilde{P}=\tilde{P}(\cdot\cdot|\cdot\cdot)}"/> defined on <img alt="{ (S\cup T)^2\times \Sigma^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%28S%5Ccup+T%29%5E2%5Ctimes+%5CSigma%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ (S\cup T)^2\times \Sigma^2}"/> with <img alt="{ |S|=|T|=n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7CS%7C%3D%7CT%7C%3Dn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |S|=|T|=n}"/> and <img alt="{ |\Sigma|=k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%5CSigma%7C%3Dk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |\Sigma|=k}"/>, define a <img alt="{ 2nk}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+2nk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ 2nk}"/>-by-<img alt="{ 2nk}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+2nk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ 2nk}"/> matrix <img alt="{ M^{\tilde{P}}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7B%5Ctilde%7BP%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ M^{\tilde{P}}}"/> whose rows are indexed by pairs <img alt="{ (q,c)\in(S\cup T)\times\Sigma}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%28q%2Cc%29%5Cin%28S%5Ccup+T%29%5Ctimes%5CSigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ (q,c)\in(S\cup T)\times\Sigma}"/> and columns by pairs <img alt="{ (q',c')\in (S\cup T)\times\Sigma}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%28q%27%2Cc%27%29%5Cin+%28S%5Ccup+T%29%5Ctimes%5CSigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ (q',c')\in (S\cup T)\times\Sigma}"/>, and whose entries are </em>

<em>
<img alt="{ M^{\tilde{P}}_{(q,c),(q',c')}=\tilde{P}(c,c'|q,q') }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7B%5Ctilde%7BP%7D%7D_%7B%28q%2Cc%29%2C%28q%27%2Cc%27%29%7D%3D%5Ctilde%7BP%7D%28c%2Cc%27%7Cq%2Cq%27%29+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ M^{\tilde{P}}_{(q,c),(q',c')}=\tilde{P}(c,c'|q,q') }"/></em>

<em>
</em><em/><em> In other words <img alt="{ M^{\tilde{P}}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7B%5Ctilde%7BP%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ M^{\tilde{P}}}"/> consists of <img alt="{ k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ k}"/>-by-<img alt="{ k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ k}"/> blocks where the block <img alt="{ M^{\tilde{P}}_{q,q'}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7B%5Ctilde%7BP%7D%7D_%7Bq%2Cq%27%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ M^{\tilde{P}}_{q,q'}}"/> at position <img alt="{ q,q'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+q%2Cq%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ q,q'}"/> contains the entries <img alt="{ \tilde{P}(\cdot\cdot|q,q')}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BP%7D%28%5Ccdot%5Ccdot%7Cq%2Cq%27%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \tilde{P}(\cdot\cdot|q,q')}"/>. </em><!--/blockquote--><br/>
Definition <a href="https://windowsontheory.org/feed/#to_matrix">5</a> is simply a convenient change of notation and we identify <img alt="{ \tilde{P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \tilde{P}}"/> with <img alt="{ M^{\tilde{P}}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7B%5Ctilde%7BP%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ M^{\tilde{P}}}"/>, using either notation depending on the context.
<!--blockquote--><br/>Definition 6 (Pseudo-strategies) <em><a name="Sdef"/> Let <img alt="{ S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ S}"/> and <img alt="{ T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ T}"/> be the question sets for Alice and Bob, respectively. We say that <img alt="{ \tilde{P}=\tilde{P}(\cdot\cdot|\cdot\cdot):\Sigma^2\times (S\cup T)^2\rightarrow[0,1]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BP%7D%3D%5Ctilde%7BP%7D%28%5Ccdot%5Ccdot%7C%5Ccdot%5Ccdot%29%3A%5CSigma%5E2%5Ctimes+%28S%5Ccup+T%29%5E2%5Crightarrow%5B0%2C1%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \tilde{P}=\tilde{P}(\cdot\cdot|\cdot\cdot):\Sigma^2\times (S\cup T)^2\rightarrow[0,1]}"/> (or its matrix form <img alt="{ M^{\tilde{P}}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7B%5Ctilde%7BP%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ M^{\tilde{P}}}"/>) is a pseudo-strategy if: </em>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em>
<ol>
 	<li> <img alt="{ M^{\tilde{P}}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7B%5Ctilde%7BP%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ M^{\tilde{P}}}"/> is positive semidefinite.<a name="positive"/></li>
 	<li> For any pair of questions <img alt="{ q,q'\in S\cup T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+q%2Cq%27%5Cin+S%5Ccup+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ q,q'\in S\cup T}"/>, <img alt="{ \sum_{c,c'=1}^k \tilde{P}(c,c'|q,q')=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Csum_%7Bc%2Cc%27%3D1%7D%5Ek+%5Ctilde%7BP%7D%28c%2Cc%27%7Cq%2Cq%27%29%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \sum_{c,c'=1}^k \tilde{P}(c,c'|q,q')=1}"/>.<a name="sum1"/></li>
 	<li> The blocks <img alt="{ M^{\tilde{P}}_{q,q'}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7B%5Ctilde%7BP%7D%7D_%7Bq%2Cq%27%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ M^{\tilde{P}}_{q,q'}}"/> on the diagonal are themselves diagonal <img alt="{ k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ k}"/>-by-<img alt="{ k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ k}"/> matrices.<a name="diagonal"/></li>
</ol>
</em><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em> </em><!--/blockquote-->
Define the winning <!--recheck prob-->probability or value of a pseudo-strategy as:

<img alt="{ \omega^{\tilde{P}}(G)=\mathbb E_{(s,t)\sim \Pi} \sum_{a,b} \tilde{P}(a,b|s,t)V(a,b|s,t) }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%7B%5Ctilde%7BP%7D%7D%28G%29%3D%5Cmathbb+E_%7B%28s%2Ct%29%5Csim+%5CPi%7D+%5Csum_%7Ba%2Cb%7D+%5Ctilde%7BP%7D%28a%2Cb%7Cs%2Ct%29V%28a%2Cb%7Cs%2Ct%29+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \omega^{\tilde{P}}(G)=\mathbb E_{(s,t)\sim \Pi} \sum_{a,b} \tilde{P}(a,b|s,t)V(a,b|s,t) }"/>

The algorithm outputs the maximum winning <!--recheck prob-->probability:

<img alt="{ \hat\omega(G)=\max_{\tilde{P}\in\mathcal S}\omega^{\tilde{P}}(G) }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Chat%5Comega%28G%29%3D%5Cmax_%7B%5Ctilde%7BP%7D%5Cin%5Cmathcal+S%7D%5Comega%5E%7B%5Ctilde%7BP%7D%7D%28G%29+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \hat\omega(G)=\max_{\tilde{P}\in\mathcal S}\omega^{\tilde{P}}(G) }"/>

over pseudo-strategies <img alt="{ \tilde{P}\in \mathcal S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BP%7D%5Cin+%5Cmathcal+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \tilde{P}\in \mathcal S}"/>. This maximum is efficiently computable using standard semidefinite programming algorithms. As we will see, actual quantum strategies are in <img alt="{ \mathcal S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathcal+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \mathcal S}"/> which immediately implies <img alt="{ \hat\omega(G)\ge\omega^*(G)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Chat%5Comega%28G%29%5Cge%5Comega%5E%2A%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \hat\omega(G)\ge\omega^*(G)}"/>. It then remains to show that the optimal pseudo-strategy can be approximated by an actual entangled strategy, thus bounding the gap from <img alt="{ \omega^*(G)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%2A%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \omega^*(G)}"/> to <img alt="{ \hat\omega(G)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Chat%5Comega%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \hat\omega(G)}"/>.
<h3> Quantum strategies are in <img alt="{ \mathcal S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathcal+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \mathcal S}"/></h3>
Let us establish that <img alt="{ \mathcal S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathcal+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \mathcal S}"/> is indeed a relaxation of the class of quantum strategies, that is, it contains the quantum strategies. So suppose we are given a quantum strategy. By equation <a href="https://windowsontheory.org/feed/#Qstrategy">1</a> the <!--recheck prob-->probability of answers <img alt="{ a}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+a%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ a}"/> and <img alt="{ b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+b%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ b}"/> given questions <img alt="{ s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+s%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ s}"/> and <img alt="{ t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ t}"/> is of the form

<img alt="{ \langle\phi|A^s_a\otimes B^t_b |\phi\rangle=\langle\phi|(A^s_a\otimes {\mathbb{I}})({\mathbb{I}}\otimes B^t_b )|\phi\rangle }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Clangle%5Cphi%7CA%5Es_a%5Cotimes+B%5Et_b+%7C%5Cphi%5Crangle%3D%5Clangle%5Cphi%7C%28A%5Es_a%5Cotimes+%7B%5Cmathbb%7BI%7D%7D%29%28%7B%5Cmathbb%7BI%7D%7D%5Cotimes+B%5Et_b+%29%7C%5Cphi%5Crangle+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \langle\phi|A^s_a\otimes B^t_b |\phi\rangle=\langle\phi|(A^s_a\otimes {\mathbb{I}})({\mathbb{I}}\otimes B^t_b )|\phi\rangle }"/>

for some PVM’s <img alt="{ A^s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+A%5Es%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ A^s}"/> and <img alt="{ B^t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+B%5Et%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ B^t}"/> and some <img alt="{ |\phi\rangle\in\mathbb C^d\otimes\mathbb C^d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Cphi%5Crangle%5Cin%5Cmathbb+C%5Ed%5Cotimes%5Cmathbb+C%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |\phi\rangle\in\mathbb C^d\otimes\mathbb C^d}"/>. This conditional <!--recheck prob-->probability distibution is not immediately in the form of a pseudo-strategy because we cannot evaluate it on pairs of Alice-questions or pairs of Bob-questions. We therefore have to extend it, as follows: Place all the column vectors <img alt="{ A^s_a\otimes {\mathbb{I}}|\phi\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+A%5Es_a%5Cotimes+%7B%5Cmathbb%7BI%7D%7D%7C%5Cphi%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ A^s_a\otimes {\mathbb{I}}|\phi\rangle}"/>, <img alt="{ (s,a)\in S\times \Sigma}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%28s%2Ca%29%5Cin+S%5Ctimes+%5CSigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ (s,a)\in S\times \Sigma}"/> side by side, and then append the vectors <img alt="{ I\otimes B^t_b|\phi\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+I%5Cotimes+B%5Et_b%7C%5Cphi%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ I\otimes B^t_b|\phi\rangle}"/>, resulting in a <img alt="{ d^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+d%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ d^2}"/>-by-<img alt="{ 2nk}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+2nk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ 2nk}"/> matrix <img alt="{ R}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+R%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ R}"/>. We then define <img alt="{ {P}(\cdot\cdot|\cdot\cdot):\Sigma^2\times(S\cup T)^2\rightarrow[0,1]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7BP%7D%28%5Ccdot%5Ccdot%7C%5Ccdot%5Ccdot%29%3A%5CSigma%5E2%5Ctimes%28S%5Ccup+T%29%5E2%5Crightarrow%5B0%2C1%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ {P}(\cdot\cdot|\cdot\cdot):\Sigma^2\times(S\cup T)^2\rightarrow[0,1]}"/> through its matrix form (see the comment below definition <a href="https://windowsontheory.org/feed/#to_matrix">5</a>): <a name="eqMp"/>
<p align="center"><a name="eqMp"><img alt="\displaystyle  M^{P}:=R^\dag R=\begin{pmatrix} (\langle\phi|A^s_a A^{s'}_{a'}\otimes {\mathbb{I}} |\phi\rangle)_{(s,a),(s',a')} (\langle\phi|A^s_a\otimes B^t_b |\phi\rangle)_{(s,a),(t,b)} \\\\ (\langle\phi|B^t_b\otimes A^s_a |\phi\rangle)_{(t,b),(s,a)} (\langle\phi|{\mathbb{I}}\otimes B^t_bB^{t'}_{b'} |\phi\rangle)_{(t,b),(t',b')} \end{pmatrix} \ \ \ \ \ (2)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++M%5E%7BP%7D%3A%3DR%5E%5Cdag+R%3D%5Cbegin%7Bpmatrix%7D+%28%5Clangle%5Cphi%7CA%5Es_a+A%5E%7Bs%27%7D_%7Ba%27%7D%5Cotimes+%7B%5Cmathbb%7BI%7D%7D+%7C%5Cphi%5Crangle%29_%7B%28s%2Ca%29%2C%28s%27%2Ca%27%29%7D+%28%5Clangle%5Cphi%7CA%5Es_a%5Cotimes+B%5Et_b+%7C%5Cphi%5Crangle%29_%7B%28s%2Ca%29%2C%28t%2Cb%29%7D+%5C%5C%5C%5C+%28%5Clangle%5Cphi%7CB%5Et_b%5Cotimes+A%5Es_a+%7C%5Cphi%5Crangle%29_%7B%28t%2Cb%29%2C%28s%2Ca%29%7D+%28%5Clangle%5Cphi%7C%7B%5Cmathbb%7BI%7D%7D%5Cotimes+B%5Et_bB%5E%7Bt%27%7D_%7Bb%27%7D+%7C%5Cphi%5Crangle%29_%7B%28t%2Cb%29%2C%28t%27%2Cb%27%29%7D+%5Cend%7Bpmatrix%7D+%5C+%5C+%5C+%5C+%5C+%282%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  M^{P}:=R^\dag R=\begin{pmatrix} (\langle\phi|A^s_a A^{s'}_{a'}\otimes {\mathbb{I}} |\phi\rangle)_{(s,a),(s',a')} (\langle\phi|A^s_a\otimes B^t_b |\phi\rangle)_{(s,a),(t,b)} \\\\ (\langle\phi|B^t_b\otimes A^s_a |\phi\rangle)_{(t,b),(s,a)} (\langle\phi|{\mathbb{I}}\otimes B^t_bB^{t'}_{b'} |\phi\rangle)_{(t,b),(t',b')} \end{pmatrix} \ \ \ \ \ (2)"/></a></p>
<a name="eqMp">
</a><a name="eqMp"/>
<!--blockquote--><b>Lemma 7</b> <em><a name="relaxation"/> <img alt="{ M^{P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ M^{P}}"/> defined in <a href="https://windowsontheory.org/feed/#eqMp">2</a> is a pseudo-strategy, that is, <img alt="{ M^{P}\in\mathcal S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7BP%7D%5Cin%5Cmathcal+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ M^{P}\in\mathcal S}"/>. </em><!--/blockquote-->
<em><br/>Proof.</em><!-- remove close em after proof--> We verify the conditions in definition <a href="https://windowsontheory.org/feed/#Sdef">6</a>. Condition <a href="https://windowsontheory.org/feed/#positive">1</a> (<img alt="{ M^{P}\succeq0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7BP%7D%5Csucceq0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ M^{P}\succeq0}"/>) holds because it is of the form <img alt="{ R^\dag R}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+R%5E%5Cdag+R%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ R^\dag R}"/>. Condition <a href="https://windowsontheory.org/feed/#sum1">2</a> (Each block <img alt="{ M^{P}_{q,q'}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7BP%7D_%7Bq%2Cq%27%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ M^{P}_{q,q'}}"/> sums to <img alt="{ 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ 1}"/>) holds because PVM’s sum to the identity. Condition <a href="https://windowsontheory.org/feed/#diagonal">3</a> (Diagonal blocks <img alt="{ \tilde M=M^{P}_{qq}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde+M%3DM%5E%7BP%7D_%7Bqq%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \tilde M=M^{P}_{qq}}"/> are diagonal) holds because the projections in the PVM <img alt="{ A^q}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+A%5Eq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ A^q}"/> are mutually orthogonal, hence <img alt="{ \langle{\phi}| A^q_cA^q_{c'} |{\phi}\rangle =0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Clangle%7B%5Cphi%7D%7C+A%5Eq_cA%5Eq_%7Bc%27%7D+%7C%7B%5Cphi%7D%5Crangle+%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \langle{\phi}| A^q_cA^q_{c'} |{\phi}\rangle =0}"/> if <img alt="{ c\neq c'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+c%5Cneq+c%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ c\neq c'}"/>. <!--end proof-->
<div align="right">□</div>
Lemma <a href="https://windowsontheory.org/feed/#relaxation">7</a> means <img alt="{ \hat\omega(G)=\max_{{P}\in \mathcal S}\omega^{P}(G)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Chat%5Comega%28G%29%3D%5Cmax_%7B%7BP%7D%5Cin+%5Cmathcal+S%7D%5Comega%5E%7BP%7D%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \hat\omega(G)=\max_{{P}\in \mathcal S}\omega^{P}(G)}"/> is an (efficiently computable) upper bound for <img alt="{ \omega^*(G)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%2A%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \omega^*(G)}"/>:
<h4>Corollary</h4><em> <img alt="{ \hat\omega\ge \omega^*(G)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Chat%5Comega%5Cge+%5Comega%5E%2A%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \hat\omega\ge \omega^*(G)}"/>. </em>

<!--ending corollary-->

<br/>To finish the proof of theorem <a href="https://windowsontheory.org/feed/#efficientUGC">4</a> we need to show that any pseudo-strategy <img alt="{ \tilde{P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \tilde{P}}"/> can be <em>rounded</em> to an actual quantum strategy with answer <!--recheck prob-->probabilities <img alt="{ {P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ {P}}"/> such that <a name="roundingobjective"/>
<p align="center"><a name="roundingobjective"><img alt="\displaystyle  1-\omega^{P}\le 6(1-\omega^{\tilde P}) \ \ \ \ \ (3)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++1-%5Comega%5E%7BP%7D%5Cle+6%281-%5Comega%5E%7B%5Ctilde+P%7D%29+%5C+%5C+%5C+%5C+%5C+%283%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  1-\omega^{P}\le 6(1-\omega^{\tilde P}) \ \ \ \ \ (3)"/></a></p>
<a name="roundingobjective">
</a><a name="roundingobjective"/> Applying this rounding to the optimal pseudo-strategy implies that

<img alt="{ 1-\omega^*\le 6(1-\hat\omega) }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+1-%5Comega%5E%2A%5Cle+6%281-%5Chat%5Comega%29+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ 1-\omega^*\le 6(1-\hat\omega) }"/>

or <img alt="{ \omega^*\ge 1-6(1-\hat\omega)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%2A%5Cge+1-6%281-%5Chat%5Comega%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \omega^*\ge 1-6(1-\hat\omega)}"/>, which will finish the proof of theorem <a href="https://windowsontheory.org/feed/#efficientUGC">4</a>.

<em><br/><b>Proof.</b></em><!-- remove close em after proof-->[Proof of theorem <a href="https://windowsontheory.org/feed/#efficientUGC">4</a>] Let <img alt="{ \tilde{P}\in\mathcal S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BP%7D%5Cin%5Cmathcal+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \tilde{P}\in\mathcal S}"/> be a pseudo-strategy. We construct a quantum strategy <img alt="{ {P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ {P}}"/> approximating <img alt="{ \tilde{P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \tilde{P}}"/>. Since <img alt="{ M^{\tilde{P}}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7B%5Ctilde%7BP%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ M^{\tilde{P}}}"/> is positive semidefinite we can write

<img alt="{ \tilde M=R^\dag R }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde+M%3DR%5E%5Cdag+R+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \tilde M=R^\dag R }"/>

for <em>some</em> matrix <img alt="{ R\in \mathbb C^{r\times 2nk}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+R%5Cin+%5Cmathbb+C%5E%7Br%5Ctimes+2nk%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ R\in \mathbb C^{r\times 2nk}}"/> and <img alt="{ r\leq 2nk}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+r%5Cleq+2nk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ r\leq 2nk}"/>. Now let us define <img alt="{ 2nk}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+2nk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ 2nk}"/> vectors <img alt="{ |\tilde u^s_a\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Ctilde+u%5Es_a%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |\tilde u^s_a\rangle}"/> and <img alt="{ |\tilde v^t_b\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Ctilde+v%5Et_b%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |\tilde v^t_b\rangle}"/> in <img alt="{ \mathbb C^{r}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathbb+C%5E%7Br%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \mathbb C^{r}}"/>, and let <img alt="{ |{u^s_a}\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%7Bu%5Es_a%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |{u^s_a}\rangle}"/> and <img alt="{ |{v^t_b}\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%7Bv%5Et_b%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |{v^t_b}\rangle}"/> be the same vectors normalized. The strategy is constructed as follows. Alice and Bob share the maximally entangled state

<img alt="{ |\phi\rangle=\frac1{\sqrt r}\sum_{i=1}^r|i\rangle|i\rangle\in\mathbb C^r\otimes\mathbb C^r }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Cphi%5Crangle%3D%5Cfrac1%7B%5Csqrt+r%7D%5Csum_%7Bi%3D1%7D%5Er%7Ci%5Crangle%7Ci%5Crangle%5Cin%5Cmathbb+C%5Er%5Cotimes%5Cmathbb+C%5Er+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |\phi\rangle=\frac1{\sqrt r}\sum_{i=1}^r|i\rangle|i\rangle\in\mathbb C^r\otimes\mathbb C^r }"/>

Before deciding on Alice and Bob’s PVM’s <img alt="{ A^s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+A%5Es%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ A^s}"/> and <img alt="{ B^t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+B%5Et%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ B^t}"/> let us see what this choice of shared state means for the conditional distribution on answers (see equation <a href="https://windowsontheory.org/feed/#Qstrategy">(1)</a>).
<p align="center"> <img alt="\langle\phi| A^s_a\otimes B^t_b|\phi\rangle =\frac1r\sum_{i,j=1}^r\langle i | A^s_a| j\rangle\langle i | B^t_b| j\rangle =\frac1r A^s_a\cdot B^t_b=\frac1r\langle A^s_a,\overline{B^t_b}\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clangle%5Cphi%7C+A%5Es_a%5Cotimes+B%5Et_b%7C%5Cphi%5Crangle+%3D%5Cfrac1r%5Csum_%7Bi%2Cj%3D1%7D%5Er%5Clangle+i+%7C+A%5Es_a%7C+j%5Crangle%5Clangle+i+%7C+B%5Et_b%7C+j%5Crangle+%3D%5Cfrac1r+A%5Es_a%5Ccdot+B%5Et_b%3D%5Cfrac1r%5Clangle+A%5Es_a%2C%5Coverline%7BB%5Et_b%7D%5Crangle&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\langle\phi| A^s_a\otimes B^t_b|\phi\rangle =\frac1r\sum_{i,j=1}^r\langle i | A^s_a| j\rangle\langle i | B^t_b| j\rangle =\frac1r A^s_a\cdot B^t_b=\frac1r\langle A^s_a,\overline{B^t_b}\rangle"/>, (*)</p>
where the bar represents entrywise complex conjugation, <img alt="{ \cdot}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Ccdot%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \cdot}"/> is the entrywise dot product of matrices, and <img alt="{ \langle\:,\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Clangle%5C%3A%2C%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \langle\:,\rangle}"/> the entrywise complex inner product (Hilbert-Schmidt inner product).

We now choose the measurements. Given question <img alt="{ s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+s%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ s}"/>, Alice measures in the PVM <img alt="{ A^s=(A^s_a)_{a=0}^k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+A%5Es%3D%28A%5Es_a%29_%7Ba%3D0%7D%5Ek%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ A^s=(A^s_a)_{a=0}^k}"/> with

<img alt="{ A^s_a= |{u^s_a}\rangle \langle{u^s_a}| \text{ for }a=1,\ldots,k\text{, and }A^s_0={\mathbb{I}}-\sum_{i=1}^k |{u^s_a}\rangle \langle{u^s_a}| }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+A%5Es_a%3D+%7C%7Bu%5Es_a%7D%5Crangle+%5Clangle%7Bu%5Es_a%7D%7C+%5Ctext%7B+for+%7Da%3D1%2C%5Cldots%2Ck%5Ctext%7B%2C+and+%7DA%5Es_0%3D%7B%5Cmathbb%7BI%7D%7D-%5Csum_%7Bi%3D1%7D%5Ek+%7C%7Bu%5Es_a%7D%5Crangle+%5Clangle%7Bu%5Es_a%7D%7C+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ A^s_a= |{u^s_a}\rangle \langle{u^s_a}| \text{ for }a=1,\ldots,k\text{, and }A^s_0={\mathbb{I}}-\sum_{i=1}^k |{u^s_a}\rangle \langle{u^s_a}| }"/>

Similarly, Bob on question <img alt="{ t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ t}"/> applies the PVM <img alt="{ B^t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+B%5Et%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ B^t}"/> with

<img alt="{ B^t_b= |{v^t_b}\rangle \langle{v^t_b}| \text{ for }b=1,\ldots,k\text{, and }B^t_0={\mathbb{I}}-\sum_{i=1}^k |{v^t_b}\rangle \langle{v^t_b}| }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+B%5Et_b%3D+%7C%7Bv%5Et_b%7D%5Crangle+%5Clangle%7Bv%5Et_b%7D%7C+%5Ctext%7B+for+%7Db%3D1%2C%5Cldots%2Ck%5Ctext%7B%2C+and+%7DB%5Et_0%3D%7B%5Cmathbb%7BI%7D%7D-%5Csum_%7Bi%3D1%7D%5Ek+%7C%7Bv%5Et_b%7D%5Crangle+%5Clangle%7Bv%5Et_b%7D%7C+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ B^t_b= |{v^t_b}\rangle \langle{v^t_b}| \text{ for }b=1,\ldots,k\text{, and }B^t_0={\mathbb{I}}-\sum_{i=1}^k |{v^t_b}\rangle \langle{v^t_b}| }"/>

The condition <a href="https://windowsontheory.org/feed/#diagonal">3</a> in definition <a href="https://windowsontheory.org/feed/#Sdef">6</a> ensures that for any question <img alt="{ s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+s%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ s}"/>, the vectors <img alt="{ |{u^s_1}\rangle ,\ldots, |{u^s_1}\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%7Bu%5Es_1%7D%5Crangle+%2C%5Cldots%2C+%7C%7Bu%5Es_1%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |{u^s_1}\rangle ,\ldots, |{u^s_1}\rangle}"/> are orthogonal so that this is a valid PVM.

The measurement outcome “<img alt="0" class="latex" src="https://s0.wp.com/latex.php?latex=0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="0"/>” is interpreted as “fail”, and upon getting this outcome the player attempts the measurement again on their share of a fresh copy of <img alt="{ |\phi\rangle_{AB}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Cphi%5Crangle_%7BAB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |\phi\rangle_{AB}}"/>. This means that the strategy requires many copies of the entangled state to be shared before the game starts. It also leads to the complication of ensuring that with high <!--recheck prob-->probability the players measure the same number of times before outputting their measurement, so that the outputs come from measuring the same entangled state.

By <!--a href="#corr"-->(*)<!--/a-->, at a given round of measurements the conditional distribution of answers is given by

<img alt="{ \langle\phi|A^s_a\otimes B^t_b|\phi\rangle=\frac1r\Big\langle |{u^s_a}\rangle \langle{ u^s_a}| \:,\: |{{v^t_b}\rangle } \langle{ {v^t_b}| }\Big\rangle=\frac1r|\langle {u^s_a}|v^t_b\rangle|^2=\frac1{r|\tilde u^s_a|^2|\tilde v^t_b|^2}\Big(M^{\tilde{P}}_{(s,a),(t,b)}\Big)^2, }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Clangle%5Cphi%7CA%5Es_a%5Cotimes+B%5Et_b%7C%5Cphi%5Crangle%3D%5Cfrac1r%5CBig%5Clangle+%7C%7Bu%5Es_a%7D%5Crangle+%5Clangle%7B+u%5Es_a%7D%7C+%5C%3A%2C%5C%3A+%7C%7B%7Bv%5Et_b%7D%5Crangle+%7D+%5Clangle%7B+%7Bv%5Et_b%7D%7C+%7D%5CBig%5Crangle%3D%5Cfrac1r%7C%5Clangle+%7Bu%5Es_a%7D%7Cv%5Et_b%5Crangle%7C%5E2%3D%5Cfrac1%7Br%7C%5Ctilde+u%5Es_a%7C%5E2%7C%5Ctilde+v%5Et_b%7C%5E2%7D%5CBig%28M%5E%7B%5Ctilde%7BP%7D%7D_%7B%28s%2Ca%29%2C%28t%2Cb%29%7D%5CBig%29%5E2%2C+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \langle\phi|A^s_a\otimes B^t_b|\phi\rangle=\frac1r\Big\langle |{u^s_a}\rangle \langle{ u^s_a}| \:,\: |{{v^t_b}\rangle } \langle{ {v^t_b}| }\Big\rangle=\frac1r|\langle {u^s_a}|v^t_b\rangle|^2=\frac1{r|\tilde u^s_a|^2|\tilde v^t_b|^2}\Big(M^{\tilde{P}}_{(s,a),(t,b)}\Big)^2, }"/>

We wish to relate the LHS to <img alt="{ M^{\tilde{P}}_{(s,a),(t,b)}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7B%5Ctilde%7BP%7D%7D_%7B%28s%2Ca%29%2C%28t%2Cb%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ M^{\tilde{P}}_{(s,a),(t,b)}}"/>, so to handle the factor <img alt="{ \frac1r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cfrac1r%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \frac1r}"/> each prover performs repeated measurements, each time on a fresh copy of <img alt="{ |\phi\rangle_{AB}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Cphi%5Crangle_%7BAB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |\phi\rangle_{AB}}"/>, until getting an outcome <img alt="{ \neq0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cneq0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \neq0}"/>. Moreover, to handle the factor <img alt="{ \frac1{|u^s_a|^2|v^t_b|^2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cfrac1%7B%7Cu%5Es_a%7C%5E2%7Cv%5Et_b%7C%5E2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \frac1{|u^s_a|^2|v^t_b|^2}}"/>, each prover consults public randomness and accepts the answer <img alt="{ a\in[k]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+a%5Cin%5Bk%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ a\in[k]}"/> with <!--recheck prob-->probability <img alt="{ |u^a_s|^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7Cu%5Ea_s%7C%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |u^a_s|^2}"/> and <img alt="{ |v^b_t|^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7Cv%5Eb_t%7C%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |v^b_t|^2}"/> respectively, or rejects and start over depending on the public randomness. Under a few simplifying conditions (more precisely, assuming that the game is <em>uniform</em> meaning that an optimal strategy exists where the marginal distribution on each prover’s answers is uniform), we can let <img alt="{ M^{\tilde{P}}_{(s,a),(t,b)}\le 1/k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7B%5Ctilde%7BP%7D%7D_%7B%28s%2Ca%29%2C%28t%2Cb%29%7D%5Cle+1%2Fk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ M^{\tilde{P}}_{(s,a),(t,b)}\le 1/k}"/> for all <img alt="{ s,a,t,b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+s%2Ca%2Ct%2Cb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ s,a,t,b}"/>, and one can ensure that the conditional <!--recheck prob-->probabilities <img alt="{ {P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ {P}}"/> of the final answers satisfy
<p align="center">
<img alt="\displaystyle 1/k-P(a,b|s,t)\le 3\big(1/k-k(M^{\tilde P}_{(s,a),(t,b)})^2\big),\ \ \ \ \ (4)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+1%2Fk-P%28a%2Cb%7Cs%2Ct%29%5Cle+3%5Cbig%281%2Fk-k%28M%5E%7B%5Ctilde+P%7D_%7B%28s%2Ca%29%2C%28t%2Cb%29%7D%29%5E2%5Cbig%29%2C%5C+%5C+%5C+%5C+%5C+%284%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle 1/k-P(a,b|s,t)\le 3\big(1/k-k(M^{\tilde P}_{(s,a),(t,b)})^2\big),\ \ \ \ \ (4)"/>
<a name="PM"/>

At this stage it is important that we are dealing with a <em>unique game</em> . Indeed, by <a href="https://windowsontheory.org/feed/#PM">(4)</a> we have for every <img alt="{ s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+s%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ s}"/> and <img alt="{ t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ t}"/>,

<img alt="1-\sum_{a=1}^k P(a,\pi_{st}(a)|s,t)=\sum_a \Big(\frac{1}{k}-P(a,\pi_{st}(a)|s,t) \Big) \\ \leq 3\sum_{b=\pi_{st}(a)} \Big(\frac{1}{k}-k(M^{\tilde{P}}_{(s,a),(t,b)})^2 \Big) \\ \leq 6\sum_{b=\pi_{st}(a)}\big(\frac{1}{k}-M^{\tilde{P}}_{(s,a),(t,b)}\big)=6\Big(1-\sum_{b=\pi_{st}(a)} M^{\tilde{P}}_{(s,a),(t,b)}\Big) " class="latex" src="https://s0.wp.com/latex.php?latex=1-%5Csum_%7Ba%3D1%7D%5Ek+P%28a%2C%5Cpi_%7Bst%7D%28a%29%7Cs%2Ct%29%3D%5Csum_a+%5CBig%28%5Cfrac%7B1%7D%7Bk%7D-P%28a%2C%5Cpi_%7Bst%7D%28a%29%7Cs%2Ct%29+%5CBig%29+%5C%5C+%5Cleq+3%5Csum_%7Bb%3D%5Cpi_%7Bst%7D%28a%29%7D+%5CBig%28%5Cfrac%7B1%7D%7Bk%7D-k%28M%5E%7B%5Ctilde%7BP%7D%7D_%7B%28s%2Ca%29%2C%28t%2Cb%29%7D%29%5E2+%5CBig%29+%5C%5C+%5Cleq+6%5Csum_%7Bb%3D%5Cpi_%7Bst%7D%28a%29%7D%5Cbig%28%5Cfrac%7B1%7D%7Bk%7D-M%5E%7B%5Ctilde%7BP%7D%7D_%7B%28s%2Ca%29%2C%28t%2Cb%29%7D%5Cbig%29%3D6%5CBig%281-%5Csum_%7Bb%3D%5Cpi_%7Bst%7D%28a%29%7D+M%5E%7B%5Ctilde%7BP%7D%7D_%7B%28s%2Ca%29%2C%28t%2Cb%29%7D%5CBig%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="1-\sum_{a=1}^k P(a,\pi_{st}(a)|s,t)=\sum_a \Big(\frac{1}{k}-P(a,\pi_{st}(a)|s,t) \Big) \\ \leq 3\sum_{b=\pi_{st}(a)} \Big(\frac{1}{k}-k(M^{\tilde{P}}_{(s,a),(t,b)})^2 \Big) \\ \leq 6\sum_{b=\pi_{st}(a)}\big(\frac{1}{k}-M^{\tilde{P}}_{(s,a),(t,b)}\big)=6\Big(1-\sum_{b=\pi_{st}(a)} M^{\tilde{P}}_{(s,a),(t,b)}\Big) "/>

where the last inequality follows from concavity. Taking the expectation over <img alt="{ s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+s%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ s}"/> and <img alt="{ t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ t}"/> implies the bound <a href="https://windowsontheory.org/feed/#roundingobjective">(3)</a>, thus concluding the proof of theorem <a href="https://windowsontheory.org/feed/#efficientUGC">4</a>.<!--end proof-->
</p><div align="right">□</div>
<h2>General games are hard</h2>
We just saw that a specific class of games becomes easy in the presence of shared entanglement, in that semidefinite programming allows the entangled value <img alt="{ \omega^*}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%2A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \omega^*}"/> to be approximated to within exponential precision in polynomial time. Does this phenomenon hold more generally, so that the value of entangled games can always be efficiently approximated? We answer in the negative, by constructing a game where <img alt="{ \omega^*}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%2A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \omega^*}"/> is NP-hard to approximate to within inverse-polynomial factors. The complexity for 2P-1R entangled games can be strengthened to constant-factor NP-hardness, putting it on par with the classical PCP theorem. This result is used to prove (with some conditions) the games formulation of the quantum PCP theorem, which states that the entangled value of general games is QMA-hard to approximate within a constant factor.
<h3> Formulation of game</h3>
Given any instance <img alt="{ \phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \phi}"/> of a <img alt="{ k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ k}"/>-CSP (constraint satisfaction <!--recheck prob-->problem, where <img alt="{ k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ k}"/> is the number of literals), we can define a clause-vs-variable game <img alt="{ G_\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+G_%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ G_\phi}"/> (see clause-vs-variable figure):
<ol>
 	<li> The referee (verifier) randomly sends a clause to Alice (first prover) and a variable to Bob (second prover).</li>
 	<li> Alice and Bob reply with assignments.</li>
 	<li> The referee accepts if Alice’s assignment satisfies the clause and Bob’s answer is consistent with Alice’s.</li>
</ol>
To show hardness of approximation, we need to go beyond the usual 2-player construction. In particular, in our game [3] one of the players receives an extra dummy question (see subfigure (a)). Mathematically, the result is very similar to introducing another player and having the referee play the 2-player game with two players chosen randomly [4] (see subfigure (b)). In either variation, the quantum phenomenon of <em>monogamy of entanglement</em> , imposing that only two parties can be maximally entangled to one another, is key to establishing hardness. The players do not know where to use their entanglement, which prevents them from coordinating as well as they could in the standard game.
<figure style="width: 25em; margin: auto;">  
<a href="https://windowsontheory.org/?attachment_id=7233"><img alt="" class="attachment-thumbnail size-thumbnail" height="150" src="https://windowsontheory.files.wordpress.com/2019/01/2player.png?w=107&amp;h=150" width="107"/></a>
<a href="https://windowsontheory.org/?attachment_id=7234"><img alt="" class="attachment-thumbnail size-thumbnail" height="150" src="https://windowsontheory.files.wordpress.com/2019/01/3player.png?w=107&amp;h=150" width="107"/></a>


Two variations of a 2-player clause-vs-variable game; new features are in red and shared entanglement is denoted in blue. In the standard game <img alt="{ G_\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+G_%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ G_\phi}"/>, given <img alt="{ k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ k}"/>-CSP <img alt="{ \phi=(C_1,\ldots,C_m)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cphi%3D%28C_1%2C%5Cldots%2CC_m%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \phi=(C_1,\ldots,C_m)}"/> on <img alt="{ n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ n}"/> variables <img alt="{ x_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+x_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ x_i}"/>, (1) the referee R randomly sends a clause <img alt="{ C_j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+C_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ C_j}"/> to Alice A and a literal index <img alt="{ t\in[k]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+t%5Cin%5Bk%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ t\in[k]}"/> to Bob B, (2) A replies with an assignment <img alt="{ (a_1,\ldots,a_k)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%28a_1%2C%5Cldots%2Ca_k%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ (a_1,\ldots,a_k)}"/> and B replies with assignment <img alt="{ b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+b%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ b}"/>, (3) R accepts iff <img alt="{ (a_1,\ldots,a_k)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%28a_1%2C%5Cldots%2Ca_k%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ (a_1,\ldots,a_k)}"/> satisfies <img alt="{ C_j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+C_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ C_j}"/> and <img alt="{ a_t=b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+a_t%3Db%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ a_t=b}"/>. In variation (a), R sends an additional dummy index <img alt="{ l\in[k]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+l%5Cin%5Bk%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ l\in[k]}"/>, so that B replies with an additional assignment <img alt="{ b'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+b%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ b'}"/>, but he does not know which is the right variable. Equivalently, in (b) a third player Charlie C is introduced, but <img alt="{ G_\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+G_%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ G_\phi}"/> is played with two randomly chosen players. Since only parties can be maximally entangled and the players do not know who is playing the game, they cannot coordinate perfectly. </figure>
<h3> NP-hardness of approximating the entangled value</h3>
To prove hardness, we rely on several results from classical complexity theory.
<!--blockquote--><br/>Theorem 8 ([6]) <em> Given an instance of 1-in-3 3SAT (a CSP), it is NP-hard to distinguish whether it is satisfiable or no assignments satisfy more than a constant fraction of clauses. <a name="thmCSP"/> </em><!--/blockquote-->
<!--blockquote--><br/>Theorem 9 ([2]) <em> For a PCP game <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> (emulating the CSP) and its oracularization <img alt="{G'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G'}"/> (transformation to a 2P-1R game), </em>

<p align="center"><em><img alt="\displaystyle  \omega(G)\leq \omega(G')\leq 1-\frac{1-\omega(G)}{3}\,. \ \ \ \ \ (5)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Comega%28G%29%5Cleq+%5Comega%28G%27%29%5Cleq+1-%5Cfrac%7B1-%5Comega%28G%29%7D%7B3%7D%5C%2C.+%5C+%5C+%5C+%5C+%5C+%285%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \omega(G)\leq \omega(G')\leq 1-\frac{1-\omega(G)}{3}\,. \ \ \ \ \ (5)"/></em></p>
<em>
</em><em> <a name="thmMIP"/> </em><!--/blockquote-->
Theorem <a href="https://windowsontheory.org/feed/#thmCSP">8</a> establishes the CSP variant of the classical PCP theorem: distinguishing between <img alt="{ \omega(\phi)=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28%5Cphi%29%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \omega(\phi)=1}"/> and <img alt="{ \omega(\phi)\leq 1/2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28%5Cphi%29%5Cleq+1%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \omega(\phi)\leq 1/2}"/> is NP-hard for some <img alt="{ k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ k}"/>-CSP. Here, <img alt="{ \omega(\phi)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28%5Cphi%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \omega(\phi)}"/> denotes the maximum fraction of clauses that are simultaneously satisfiable. Theorem <a href="https://windowsontheory.org/feed/#thmMIP">9</a> relates the general game <img alt="{ G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+G%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ G}"/> obtained from the CSP to a two-player one-round game <img alt="{ G'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+G%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ G'}"/>, in terms of the value (<!--recheck prob-->probability of winning) the game. The first inequality, equivalently saying <img alt="{ \omega(\phi)\leq \omega(G_\phi)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28%5Cphi%29%5Cleq+%5Comega%28G_%5Cphi%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \omega(\phi)\leq \omega(G_\phi)}"/>, is achieved since the players can answer the questions in the game <img alt="{ G_\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+G_%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ G_\phi}"/> to satisfy the clauses in <img alt="{ \phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \phi}"/>. These theorems together imply that <img alt="{ \omega(G_\phi)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28G_%5Cphi%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \omega(G_\phi)}"/> is NP-hard to approximate to within constant factors.

Allowing the two players to share entanglement can increase the game value to <img alt="{ \omega^*(G_\phi)\geq \omega(G_\phi)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%2A%28G_%5Cphi%29%5Cgeq+%5Comega%28G_%5Cphi%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \omega^*(G_\phi)\geq \omega(G_\phi)}"/>. Classical results do not necessarily carry over, but exploiting monogamy of entanglement allows us to limit the power of entangled strategies. One can show the following lemma, which is weaker than what we have classically.
<!--blockquote--><br/><b>Lemma 10 ([3])</b> <em> There exists a constant <img alt="{c&gt;0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c&gt;0}"/> such that for a CSP <img alt="{\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\phi}"/>, </em>
<p align="center"><em><img alt="\displaystyle  \omega^*(G_\phi)\leq 1 - \frac{c(1-\omega(\phi))^2}{n^2}\,, \ \ \ \ \ (6)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Comega%5E%2A%28G_%5Cphi%29%5Cleq+1+-+%5Cfrac%7Bc%281-%5Comega%28%5Cphi%29%29%5E2%7D%7Bn%5E2%7D%5C%2C%2C+%5C+%5C+%5C+%5C+%5C+%286%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \omega^*(G_\phi)\leq 1 - \frac{c(1-\omega(\phi))^2}{n^2}\,, \ \ \ \ \ (6)"/></em></p>
<em>
</em><em> where <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> is the number of variables. <a name="lemmaIto"/> </em><!--/blockquote-->
Combining Theorem <a href="https://windowsontheory.org/feed/#thmMIP">9</a> and Lemma <a href="https://windowsontheory.org/feed/#lemmaIto">10</a>, we have

<img alt="{ \omega(\phi)\leq \omega^*(G_\phi)\leq 1 - \frac{c(1-\omega(\phi))^2}{n^2}\,. }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28%5Cphi%29%5Cleq+%5Comega%5E%2A%28G_%5Cphi%29%5Cleq+1+-+%5Cfrac%7Bc%281-%5Comega%28%5Cphi%29%29%5E2%7D%7Bn%5E2%7D%5C%2C.+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \omega(\phi)\leq \omega^*(G_\phi)\leq 1 - \frac{c(1-\omega(\phi))^2}{n^2}\,. }"/>

Using Theorem <a href="https://windowsontheory.org/feed/#thmCSP">8</a>, approximating <img alt="{ \omega^*(G_\phi)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%2A%28G_%5Cphi%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \omega^*(G_\phi)}"/> is NP-hard to within inverse polynomial factors. Proving Lemma <a href="https://windowsontheory.org/feed/#lemmaIto">10</a> takes some work in keeping track of approximations. For simplicity, we will show a less quantitative statement and indicate where the approximations come in.
<!--blockquote--><br/>Proposition 11 (adapted from [13]) <em> <img alt="{\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\phi}"/> is satisfiable iff <img alt="{\omega^*(G_\phi)=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Comega%5E%2A%28G_%5Cphi%29%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\omega^*(G_\phi)=1}"/>. <a name="proposition"/> </em><!--/blockquote-->
<h3> Proof of Proposition <a href="https://windowsontheory.org/feed/#proposition">11</a></h3>
The forward direction is straightforward: If <img alt="{ \phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \phi}"/> is satisfiable, then there exists a perfect winning strategy where the questions are answered according to the satisfying assignment.

For the reverse direction, suppose there exists a strategy that succeeds with <!--recheck prob-->probability 1, specified by a shared entangled state <img alt="{ |{\psi}\rangle \in\mathbb{C}^d\otimes\mathbb{C}^d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cpsi%7D%5Crangle+%5Cin%5Cmathbb%7BC%7D%5Ed%5Cotimes%5Cmathbb%7BC%7D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |{\psi}\rangle \in\mathbb{C}^d\otimes\mathbb{C}^d}"/> and measurements <img alt="{ (A^j_{a_1,\ldots,a_k})_{a_1,\ldots,a_k}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%28A%5Ej_%7Ba_1%2C%5Cldots%2Ca_k%7D%29_%7Ba_1%2C%5Cldots%2Ca_k%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ (A^j_{a_1,\ldots,a_k})_{a_1,\ldots,a_k}}"/> for Alice and <img alt="{ (B^{t,l}_{b,b'})_{b,b'}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%28B%5E%7Bt%2Cl%7D_%7Bb%2Cb%27%7D%29_%7Bb%2Cb%27%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ (B^{t,l}_{b,b'})_{b,b'}}"/> for Bob, where the questions <img alt="{ j\in[m]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+j%5Cin%5Bm%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ j\in[m]}"/>, <img alt="{ t,l\in[k]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+t%2Cl%5Cin%5Bk%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ t,l\in[k]}"/> and the answers <img alt="{ a,b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+a%2Cb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ a,b}"/> are from the CSP’s alphabet. Since one of the questions/answers for Bob corresponds to a dummy variable that is irrelevant to the game, trace over the dummy variable to define a new measurement operator <img alt="{ \tilde{B}^t_b=\frac{1}{n}\sum_{l,b'} B^{t,l}_{b,b'}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BB%7D%5Et_b%3D%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bl%2Cb%27%7D+B%5E%7Bt%2Cl%7D_%7Bb%2Cb%27%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \tilde{B}^t_b=\frac{1}{n}\sum_{l,b'} B^{t,l}_{b,b'}}"/>. We can introduce a distribution on assignments to the <img alt="{ n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ n}"/> relevant variables,

<a name="eqpB"/>
<p align="center"><a name="eqpB"><img alt="\displaystyle  p(a_1,\ldots,a_n)=\lVert \mathbb{I} \otimes \tilde{B}^1_{a_1}\cdots\tilde{B}^n_{a_n} |\psi\rangle \rVert^2\,.  \ \ \ \ \ (7)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++p%28a_1%2C%5Cldots%2Ca_n%29%3D%5ClVert+%5Cmathbb%7BI%7D+%5Cotimes+%5Ctilde%7BB%7D%5E1_%7Ba_1%7D%5Ccdots%5Ctilde%7BB%7D%5En_%7Ba_n%7D+%7C%5Cpsi%5Crangle+%5CrVert%5E2%5C%2C.++%5C+%5C+%5C+%5C+%5C+%287%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  p(a_1,\ldots,a_n)=\lVert \mathbb{I} \otimes \tilde{B}^1_{a_1}\cdots\tilde{B}^n_{a_n} |\psi\rangle \rVert^2\,.  \ \ \ \ \ (7)"/></a></p>
<a name="eqpB">
</a><a name="eqpB"/> If we show that the distribution for assignments <img alt="{a_{i_1},\ldots,a_{i_k}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba_%7Bi_1%7D%2C%5Cldots%2Ca_%7Bi_k%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a_{i_1},\ldots,a_{i_k}}"/> on variables <img alt="{x_{i_1},\ldots,x_{i_k}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_%7Bi_1%7D%2C%5Cldots%2Cx_%7Bi_k%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x_{i_1},\ldots,x_{i_k}}"/> in any clause <img alt="{C_j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_j}"/> is <a name="eqpA"/>
<p align="center"><a name="eqpA"><img alt="\displaystyle  p(a_{i_1},\ldots,a_{i_k})= \lVert A^j_{a_{i_1},\ldots,a_{i_k}} \otimes \mathbb{I} |\psi\rangle \rVert^2\,,  \ \ \ \ \ (8)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++p%28a_%7Bi_1%7D%2C%5Cldots%2Ca_%7Bi_k%7D%29%3D+%5ClVert+A%5Ej_%7Ba_%7Bi_1%7D%2C%5Cldots%2Ca_%7Bi_k%7D%7D+%5Cotimes+%5Cmathbb%7BI%7D+%7C%5Cpsi%5Crangle+%5CrVert%5E2%5C%2C%2C++%5C+%5C+%5C+%5C+%5C+%288%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  p(a_{i_1},\ldots,a_{i_k})= \lVert A^j_{a_{i_1},\ldots,a_{i_k}} \otimes \mathbb{I} |\psi\rangle \rVert^2\,,  \ \ \ \ \ (8)"/></a></p>
<a name="eqpA">
</a><a name="eqpA"/> then, since the players win with certainty, <img alt="{\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\phi}"/> has a satisfying assignment. To transform Eq. <a href="https://windowsontheory.org/feed/#eqpB">7</a> to Eq. <a href="https://windowsontheory.org/feed/#eqpA">8</a>, we need a relation between the <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/> and <img alt="{\tilde{B}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctilde%7BB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\tilde{B}}"/> measurement operators and a way to commute the <img alt="{\tilde{B}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctilde%7BB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\tilde{B}}"/> operators.

The success <!--recheck prob-->probability of the players’ strategy is expressed as

<img alt="{ P=\frac{1}{m}\sum_{j\in[m]}\frac{1}{k}\sum_{i\in C_j} \sum_{(a_1,\ldots,a_k)\vdash C_j} \langle{\psi}| A^j_{a_1,\ldots,a_k}\otimes \tilde{B}^i_{a_i} |{\psi}\rangle \,, }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+P%3D%5Cfrac%7B1%7D%7Bm%7D%5Csum_%7Bj%5Cin%5Bm%5D%7D%5Cfrac%7B1%7D%7Bk%7D%5Csum_%7Bi%5Cin+C_j%7D+%5Csum_%7B%28a_1%2C%5Cldots%2Ca_k%29%5Cvdash+C_j%7D+%5Clangle%7B%5Cpsi%7D%7C+A%5Ej_%7Ba_1%2C%5Cldots%2Ca_k%7D%5Cotimes+%5Ctilde%7BB%7D%5Ei_%7Ba_i%7D+%7C%7B%5Cpsi%7D%5Crangle+%5C%2C%2C+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ P=\frac{1}{m}\sum_{j\in[m]}\frac{1}{k}\sum_{i\in C_j} \sum_{(a_1,\ldots,a_k)\vdash C_j} \langle{\psi}| A^j_{a_1,\ldots,a_k}\otimes \tilde{B}^i_{a_i} |{\psi}\rangle \,, }"/>

where <img alt="{ i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ i}"/> is the index of one of the <img alt="{ k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ k}"/> variables on which <img alt="{ C_j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+C_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ C_j}"/> acts, and <img alt="{ (a_1,\ldots,a_k)\vdash C_j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%28a_1%2C%5Cldots%2Ca_k%29%5Cvdash+C_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ (a_1,\ldots,a_k)\vdash C_j}"/> indicates that the assignment satisfies the clause. By positivity and summation to identity of the measurement operators <img alt="{ A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ A}"/> and <img alt="{ \tilde{B}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \tilde{B}}"/>, each term is at most 1; for our hypothesis <img alt="{ P=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+P%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ P=1}"/>, each has to be 1. Hence, using orthogonality of the vectors <img alt="{ {\mathbb{I}}\otimes\tilde{B}^i_{a_i} |{\psi}\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7B%5Cmathbb%7BI%7D%7D%5Cotimes%5Ctilde%7BB%7D%5Ei_%7Ba_i%7D+%7C%7B%5Cpsi%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ {\mathbb{I}}\otimes\tilde{B}^i_{a_i} |{\psi}\rangle}"/> for different <img alt="{ a_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+a_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ a_i}"/>, we have <a name="eqrelation"/>
<p align="center"><a name="eqrelation"><img alt="\displaystyle  \sum_{\substack{(a_{i_1},\ldots,a_{i_k})\vdash C_j \\ a_i=b}} A^j_{a_{i_1},\ldots,a_{i_k}}\otimes \mathbb{I} |\psi\rangle = \mathbb{I} \otimes \tilde{B}^i_{a_i}|\psi\rangle\,,  \ \ \ \ \ (9)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_%7B%5Csubstack%7B%28a_%7Bi_1%7D%2C%5Cldots%2Ca_%7Bi_k%7D%29%5Cvdash+C_j+%5C%5C+a_i%3Db%7D%7D+A%5Ej_%7Ba_%7Bi_1%7D%2C%5Cldots%2Ca_%7Bi_k%7D%7D%5Cotimes+%5Cmathbb%7BI%7D+%7C%5Cpsi%5Crangle+%3D+%5Cmathbb%7BI%7D+%5Cotimes+%5Ctilde%7BB%7D%5Ei_%7Ba_i%7D%7C%5Cpsi%5Crangle%5C%2C%2C++%5C+%5C+%5C+%5C+%5C+%289%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \sum_{\substack{(a_{i_1},\ldots,a_{i_k})\vdash C_j \\ a_i=b}} A^j_{a_{i_1},\ldots,a_{i_k}}\otimes \mathbb{I} |\psi\rangle = \mathbb{I} \otimes \tilde{B}^i_{a_i}|\psi\rangle\,,  \ \ \ \ \ (9)"/></a></p>
<a name="eqrelation">
</a><a name="eqrelation"/> for any <img alt="{ j\in[m]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+j%5Cin%5Bm%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ j\in[m]}"/> and <img alt="{ i\in C_j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+i%5Cin+C_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ i\in C_j}"/>.

We now demonstrate that two different <img alt="{ \tilde{B}^{t_1}_{b_1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BB%7D%5E%7Bt_1%7D_%7Bb_1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \tilde{B}^{t_1}_{b_1}}"/>, <img alt="{ \tilde{B}^{t_2}_{b_2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BB%7D%5E%7Bt_2%7D_%7Bb_2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \tilde{B}^{t_2}_{b_2}}"/> commute, so that Bob can match any satisfied clause/variable.

<img alt="{\mathbb{I}} \otimes \tilde{B}^{t_1}_{b_1} \tilde{B}^{t_2}_{b_2} |{\psi}\rangle =  {\mathbb{I}} \otimes (\frac{1}{n}\sum_{l_1,b_1'} B^{t_1,l_1}_{b_1,b_1'}) (\frac{1}{n}\sum_{l_2,b_2'} B^{t_2,l_2}_{b_2,b_2'}) |{\psi}\rangle \\ = {\mathbb{I}} \otimes (\frac{1}{n}\sum_{t_2,b_1'} B^{t_1,t_2}_{b_1,b_1'}) (\frac{1}{n}\sum_{t_1,b_2'} B^{t_2,t_1}_{b_2,b_2'}) |{\psi}\rangle \\ = {\mathbb{I}} \otimes \frac{1}{n^2}\sum_{t_1,t_2} B^{t_1,t_2}_{b_1,b_2} |{\psi}\rangle \\ = {\mathbb{I}} \otimes \frac{1}{n^2}\sum_{t_1,t_2} B^{t_2,t_1}_{b_2,b_1} |{\psi}\rangle \\ = {\mathbb{I}} \otimes \tilde{B}^{t_2}_{b_2} \tilde{B}^{t_1}_{b_1} |{\psi}\rangle " class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BI%7D%7D+%5Cotimes+%5Ctilde%7BB%7D%5E%7Bt_1%7D_%7Bb_1%7D+%5Ctilde%7BB%7D%5E%7Bt_2%7D_%7Bb_2%7D+%7C%7B%5Cpsi%7D%5Crangle+%3D++%7B%5Cmathbb%7BI%7D%7D+%5Cotimes+%28%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bl_1%2Cb_1%27%7D+B%5E%7Bt_1%2Cl_1%7D_%7Bb_1%2Cb_1%27%7D%29+%28%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bl_2%2Cb_2%27%7D+B%5E%7Bt_2%2Cl_2%7D_%7Bb_2%2Cb_2%27%7D%29+%7C%7B%5Cpsi%7D%5Crangle+%5C%5C+%3D+%7B%5Cmathbb%7BI%7D%7D+%5Cotimes+%28%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bt_2%2Cb_1%27%7D+B%5E%7Bt_1%2Ct_2%7D_%7Bb_1%2Cb_1%27%7D%29+%28%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bt_1%2Cb_2%27%7D+B%5E%7Bt_2%2Ct_1%7D_%7Bb_2%2Cb_2%27%7D%29+%7C%7B%5Cpsi%7D%5Crangle+%5C%5C+%3D+%7B%5Cmathbb%7BI%7D%7D+%5Cotimes+%5Cfrac%7B1%7D%7Bn%5E2%7D%5Csum_%7Bt_1%2Ct_2%7D+B%5E%7Bt_1%2Ct_2%7D_%7Bb_1%2Cb_2%7D+%7C%7B%5Cpsi%7D%5Crangle+%5C%5C+%3D+%7B%5Cmathbb%7BI%7D%7D+%5Cotimes+%5Cfrac%7B1%7D%7Bn%5E2%7D%5Csum_%7Bt_1%2Ct_2%7D+B%5E%7Bt_2%2Ct_1%7D_%7Bb_2%2Cb_1%7D+%7C%7B%5Cpsi%7D%5Crangle+%5C%5C+%3D+%7B%5Cmathbb%7BI%7D%7D+%5Cotimes+%5Ctilde%7BB%7D%5E%7Bt_2%7D_%7Bb_2%7D+%5Ctilde%7BB%7D%5E%7Bt_1%7D_%7Bb_1%7D+%7C%7B%5Cpsi%7D%5Crangle+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathbb{I}} \otimes \tilde{B}^{t_1}_{b_1} \tilde{B}^{t_2}_{b_2} |{\psi}\rangle =  {\mathbb{I}} \otimes (\frac{1}{n}\sum_{l_1,b_1'} B^{t_1,l_1}_{b_1,b_1'}) (\frac{1}{n}\sum_{l_2,b_2'} B^{t_2,l_2}_{b_2,b_2'}) |{\psi}\rangle \\ = {\mathbb{I}} \otimes (\frac{1}{n}\sum_{t_2,b_1'} B^{t_1,t_2}_{b_1,b_1'}) (\frac{1}{n}\sum_{t_1,b_2'} B^{t_2,t_1}_{b_2,b_2'}) |{\psi}\rangle \\ = {\mathbb{I}} \otimes \frac{1}{n^2}\sum_{t_1,t_2} B^{t_1,t_2}_{b_1,b_2} |{\psi}\rangle \\ = {\mathbb{I}} \otimes \frac{1}{n^2}\sum_{t_1,t_2} B^{t_2,t_1}_{b_2,b_1} |{\psi}\rangle \\ = {\mathbb{I}} \otimes \tilde{B}^{t_2}_{b_2} \tilde{B}^{t_1}_{b_1} |{\psi}\rangle "/>

In the second line, we used (<a href="https://windowsontheory.org/feed/#eqrelation">9</a>) to relate the measurements. The third line follows by the orthogonality of <img alt="{ B^{t_1,t_2}_{b_1,b_2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+B%5E%7Bt_1%2Ct_2%7D_%7Bb_1%2Cb_2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ B^{t_1,t_2}_{b_1,b_2}}"/> for different <img alt="{ b_1,b_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+b_1%2Cb_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ b_1,b_2}"/>. For the fourth equation, we simply swap <img alt="{ t_1,t_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+t_1%2Ct_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ t_1,t_2}"/> since the questions are indistinguishable to Bob. Thus, we can see how the dummy variable comes into play. If we had assumed <img alt="{ P=1-\epsilon}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+P%3D1-%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ P=1-\epsilon}"/> and kept track of approximations, we would find <a name="eqcommutation"/>
<p align="center"><a name="eqcommutation"><img alt="\displaystyle  \frac{1}{n^2}\sum_{t_1,b_1}\sum_{t_2,b_2}\lVert \mathbb{I} \otimes (\tilde{B}^{t_1}_{b_1} \tilde{B}^{t_2}_{b_2} - \tilde{B}^{t_2}_{b_2} \tilde{B}^{t_1}_{b_1}) |\psi\rangle \rVert^2 = O(\epsilon)\,.  \ \ \ \ \ (10)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7B1%7D%7Bn%5E2%7D%5Csum_%7Bt_1%2Cb_1%7D%5Csum_%7Bt_2%2Cb_2%7D%5ClVert+%5Cmathbb%7BI%7D+%5Cotimes+%28%5Ctilde%7BB%7D%5E%7Bt_1%7D_%7Bb_1%7D+%5Ctilde%7BB%7D%5E%7Bt_2%7D_%7Bb_2%7D+-+%5Ctilde%7BB%7D%5E%7Bt_2%7D_%7Bb_2%7D+%5Ctilde%7BB%7D%5E%7Bt_1%7D_%7Bb_1%7D%29+%7C%5Cpsi%5Crangle+%5CrVert%5E2+%3D+O%28%5Cepsilon%29%5C%2C.++%5C+%5C+%5C+%5C+%5C+%2810%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \frac{1}{n^2}\sum_{t_1,b_1}\sum_{t_2,b_2}\lVert \mathbb{I} \otimes (\tilde{B}^{t_1}_{b_1} \tilde{B}^{t_2}_{b_2} - \tilde{B}^{t_2}_{b_2} \tilde{B}^{t_1}_{b_1}) |\psi\rangle \rVert^2 = O(\epsilon)\,.  \ \ \ \ \ (10)"/></a></p>
<a name="eqcommutation">
</a><a name="eqcommutation"/> This approximate commutativity results in the hardness of approximation holding only to within inverse poly<img alt="{ (n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ (n)}"/> factors.

Now we are ready to transform Eq. <a href="https://windowsontheory.org/feed/#eqpB">7</a> to Eq. <a href="https://windowsontheory.org/feed/#eqpA">8</a> to conclude the proof.

<img alt="p(a_1,\ldots,a_n)=\lVert {\mathbb{I}} \otimes \tilde{B}^1_{a_1} \ldots \tilde{B}^n_{a_n} |{\psi}\rangle \rVert^2 \\ =\lVert {\mathbb{I}} \otimes \tilde{B}^{i_1}_{a_{i_1}} \ldots \tilde{B}^{i_k}_{a_{i_k}} |{\psi}\rangle \rVert^2 \\ = \lVert A^j_{a_{i_1},\ldots,a_{i_k}} \otimes {\mathbb{I}} |{\psi}\rangle \rVert^2 \\ =p(a_{i_1},\ldots,a_{i_k})\,. " class="latex" src="https://s0.wp.com/latex.php?latex=p%28a_1%2C%5Cldots%2Ca_n%29%3D%5ClVert+%7B%5Cmathbb%7BI%7D%7D+%5Cotimes+%5Ctilde%7BB%7D%5E1_%7Ba_1%7D+%5Cldots+%5Ctilde%7BB%7D%5En_%7Ba_n%7D+%7C%7B%5Cpsi%7D%5Crangle+%5CrVert%5E2+%5C%5C+%3D%5ClVert+%7B%5Cmathbb%7BI%7D%7D+%5Cotimes+%5Ctilde%7BB%7D%5E%7Bi_1%7D_%7Ba_%7Bi_1%7D%7D+%5Cldots+%5Ctilde%7BB%7D%5E%7Bi_k%7D_%7Ba_%7Bi_k%7D%7D+%7C%7B%5Cpsi%7D%5Crangle+%5CrVert%5E2+%5C%5C+%3D+%5ClVert+A%5Ej_%7Ba_%7Bi_1%7D%2C%5Cldots%2Ca_%7Bi_k%7D%7D+%5Cotimes+%7B%5Cmathbb%7BI%7D%7D+%7C%7B%5Cpsi%7D%5Crangle+%5CrVert%5E2+%5C%5C+%3Dp%28a_%7Bi_1%7D%2C%5Cldots%2Ca_%7Bi_k%7D%29%5C%2C.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="p(a_1,\ldots,a_n)=\lVert {\mathbb{I}} \otimes \tilde{B}^1_{a_1} \ldots \tilde{B}^n_{a_n} |{\psi}\rangle \rVert^2 \\ =\lVert {\mathbb{I}} \otimes \tilde{B}^{i_1}_{a_{i_1}} \ldots \tilde{B}^{i_k}_{a_{i_k}} |{\psi}\rangle \rVert^2 \\ = \lVert A^j_{a_{i_1},\ldots,a_{i_k}} \otimes {\mathbb{I}} |{\psi}\rangle \rVert^2 \\ =p(a_{i_1},\ldots,a_{i_k})\,. "/>

In the second line, we used (<a href="https://windowsontheory.org/feed/#eqcommutation">10</a>) to commute the measurement operators, along with their properties of orthogonality and summation to identity. For the third equality, we used (<a href="https://windowsontheory.org/feed/#eqrelation">9</a>) to relate Bob’s measurements to Alice’s, along with orthogonality of <img alt="{ A^j_{a_{i_1,\ldots,i_k}}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+A%5Ej_%7Ba_%7Bi_1%2C%5Cldots%2Ci_k%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ A^j_{a_{i_1,\ldots,i_k}}}"/> for different <img alt="{ a_{i_1,\ldots,i_k}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+a_%7Bi_1%2C%5Cldots%2Ci_k%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ a_{i_1,\ldots,i_k}}"/>. <!--end proof-->
<div align="right">□</div>
<h3> Constant-factor NP-hardness</h3>
The weakness in the above two-player game carries over from the original three-player variant. Thus, to achieve constant-factor NP-hardness of approximation, we could start with a different multiplayer game. Vidick [11] establishes the soundness of the “plane-vs-point” low-degree test (checking that the restriction of a low-degree polynomial to a plane matches its value at some point) in the presence of shared entanglement. <em> Soundness </em>, in the eponymous probabilistically checkable proof (PCP) formulation of the PCP theorem, refers to the verifier accepting a wrong proof with some bounded probability; bounding with a constant maps to constant-factor hardness of approximation. Here, soundness comes from a strong bound on error accumulation, similar to our approximate commutativity, but relies on the players’ Hilbert space being decomposable into three parts (i.e., there being three players). The particular game is constructed by combining the low-degree test with the 3-SAT test (encoding satisfying assignments in a low-degree polynomial), which can be reduced to the three-player QUADEQ test (testing satisfiability of a system of quadratic equations in binary variables, which is NP-complete). By the strong soundness result, the entangled value is NP-hard to approximate to within constant factors. Natarajan et al. [7] show that soundness holds even for two players, using a semidefinite program. They then construct a two-player game in a way similar to what we demonstrated.
<h3> Constant-factor QMA-hardness</h3>
The above can be thought of as the games formulation of the classical PCP theorem holding under shared entanglement. A true quantum PCP theorem states that the entangled value of general games is QMA-hard to approximate to within constant factors. Natarajan et al. [8] establish such a theorem, but under randomized reductions. This requirement stems from the lack of a sufficiently strong QMA-hardness result for local Hamiltonians (the quantum analog of CSPs). The soundness of the two-player low-degree test above is one instrumental component in the proof.
<h2>How much entanglement is needed?</h2>
We now focus on the question of quantifying exactly how much entanglement is needed to play XOR games optimally. As we shall see, the answer depends on the size of the question sets posed to Alice &amp; Bob in the game. The previous bound given by Tsirelson [10] (see table below) is tight for certain families of games, but is not tight for other families of games (such as a generalization of the CHSH game). The reason for this discrepancy is closely tied in with the the properties of the representation of the Observables that form the Optimal Strategy (<img alt="{ |{\psi}\rangle , \{A_{i}\}_{i \in S}, \{B_{j}\}_{j \in T}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cpsi%7D%5Crangle+%2C+%5C%7BA_%7Bi%7D%5C%7D_%7Bi+%5Cin+S%7D%2C+%5C%7BB_%7Bj%7D%5C%7D_%7Bj+%5Cin+T%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |{\psi}\rangle , \{A_{i}\}_{i \in S}, \{B_{j}\}_{j \in T}}"/>). Slofstra [9] shows that if the Observables constitute a Clifford Algebra (that is, the solutions are pair-wise anti-commutative), then the strategy is minimally entangled (uses the least number of entangled bits) iff the strategy is a unique solution to the SDP rounding <!--recheck prob-->problem. As a trivial corollary, if the SDP rounding <!--recheck prob-->problem does not have a unique solution (and a correspondingly unique strategy), then there exists a Non-Clifford optimal strategy that uses (atleast) <img alt="{ |T|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7CT%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |T|}"/> bits of entanglement less than the Clifford strategy. Slofstra further states that minimally entangled <img alt="{ \epsilon}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \epsilon}"/>-optimal strategies may be constructed for XOR games where the optimal strategies have ‘stable’ representations. For the purposes of this post, we will analyze the exact result and merely state the approximate result.
<h3> Main Results</h3>
<h4><u>EXACT</u></h4>
For the exact realm, the table below summarizes Slofstra and Tsirelson’s main results.
<table border="1px">
<tbody>
<tr>
<th>Person</th>
<th> Strategy</th>
<th> Bound(entangled bits)</th>
</tr>
<tr>
<td> Slofstra</td>
<td> (Possibly) Non-Clifford</td>
<td> <img alt="{ \log_{2}(N)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Clog_%7B2%7D%28N%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \log_{2}(N)}"/></td>
</tr>
<tr>
<td> Tsirelson</td>
<td>Clifford</td>
<td><img alt="{ \left \lfloor{\frac{r}{2}}\right \rfloor}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cleft+%5Clfloor%7B%5Cfrac%7Br%7D%7B2%7D%7D%5Cright+%5Crfloor%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \left \lfloor{\frac{r}{2}}\right \rfloor}"/></td>
</tr>
</tbody>
</table>
Here, <img alt="{ r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+r%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ r}"/> is the largest integer such that <img alt="{ \binom{r + 1}{2} &lt; |S| + |T|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cbinom%7Br+%2B+1%7D%7B2%7D+%3C+%7CS%7C+%2B+%7CT%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \binom{r + 1}{2} &lt; |S| + |T|}"/> and corresponds to the maximum-rank of an extremal point in the quantum correlation matrix corresponding to an optimal strategy.
<img alt="{ N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ N}"/> is the minimum dimension of the representations of the Operators (<img alt="{ \{B_{j}\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5C%7BB_%7Bj%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \{B_{j}\}}"/>).
<h4><u>APPROXIMATE</u></h4>
In the approximate realm, the minimum entanglement dimension of the representation of the Operators from an <img alt="{ \epsilon}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \epsilon}"/>-Optimal Strategy is: min(<img alt="{ \mathcal{O}(\epsilon^{\frac{-1}{12}}), 2^{\left \lfloor{\frac{r}{2}}\right \rfloor}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathcal%7BO%7D%28%5Cepsilon%5E%7B%5Cfrac%7B-1%7D%7B12%7D%7D%29%2C+2%5E%7B%5Cleft+%5Clfloor%7B%5Cfrac%7Br%7D%7B2%7D%7D%5Cright+%5Crfloor%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \mathcal{O}(\epsilon^{\frac{-1}{12}}), 2^{\left \lfloor{\frac{r}{2}}\right \rfloor}}"/>).

As we shall see, Slofstra’s theorem allows us to recover Tsirelson’s bound easily by using a fact from Representation Theory about the irreducible representations of Clifford Algebras, but stands as a more general lower bound for solutions that aren’t Clifford.
<h3> Marginals and Solution Algebras</h3>
We’ll begin by introducing 3 key ideas:
i) Degeneracy <img alt="{ \leftrightarrow}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cleftrightarrow%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \leftrightarrow}"/> Non-Degeneracy
ii) Existence of Marginals
iii) Solution Algebra

Once these ideas are defined and their notions made clear, we will be in a position to state the main result and sketch a proof for it.
<h4>Definition (Marginal Strategy)</h4>
<em> Given an Optimal Quantum Strategy (<img alt="{ |{\psi}\rangle , \{A_{i}\}_{i \in S}, \{B_{j}\}_{j \in T}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cpsi%7D%5Crangle+%2C+%5C%7BA_%7Bi%7D%5C%7D_%7Bi+%5Cin+S%7D%2C+%5C%7BB_%7Bj%7D%5C%7D_%7Bj+%5Cin+T%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |{\psi}\rangle , \{A_{i}\}_{i \in S}, \{B_{j}\}_{j \in T}}"/>), a marginal constitutes <img alt="{ \{B_{j}\}_{j \in T}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5C%7BB_%7Bj%7D%5C%7D_%7Bj+%5Cin+T%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \{B_{j}\}_{j \in T}}"/>, and the partial trace of <img alt="{ \psi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cpsi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \psi}"/> with respect to <img alt="{ H_{A}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+H_%7BA%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ H_{A}}"/> (<img alt="{ \rho_{B}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Crho_%7BB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \rho_{B}}"/>). </em>

<!--ending definition--> It is also possible to dualize the definition for obtaining <img alt="{ \{A_{i}\}_{i \in S}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5C%7BA_%7Bi%7D%5C%7D_%7Bi+%5Cin+S%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \{A_{i}\}_{i \in S}}"/> and <img alt="{ \rho_{A}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Crho_%7BA%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \rho_{A}}"/>.
We now define the notion of degeneracy, which is critical when proving the main theorem. The main point to drive home is that a degenerate optimal quantum strategy can be reduced to a unique, non-degenerate optimal quantum strategy.
<h4>Definition (Degenerate Quantum Strategy)</h4>
<em> A quantum strategy (<img alt="{ |{\psi}\rangle , \{A_{i}\}_{i \in S}, \{B_{j}\}_{j \in T}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cpsi%7D%5Crangle+%2C+%5C%7BA_%7Bi%7D%5C%7D_%7Bi+%5Cin+S%7D%2C+%5C%7BB_%7Bj%7D%5C%7D_%7Bj+%5Cin+T%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |{\psi}\rangle , \{A_{i}\}_{i \in S}, \{B_{j}\}_{j \in T}}"/>) is said to be degenerate if <img alt="{ \exists (P \in H_A)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cexists+%28P+%5Cin+H_A%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \exists (P \in H_A)}"/>, <img alt="{ (Q \in H_B)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%28Q+%5Cin+H_B%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ (Q \in H_B)}"/> such that:
i) <img alt="{ P}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+P%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ P}"/> commutes with all <img alt="{ A_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+A_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ A_i}"/> and <img alt="{ (P \otimes {\mathbb{I}}) |{\psi}\rangle = |{\psi}\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%28P+%5Cotimes+%7B%5Cmathbb%7BI%7D%7D%29+%7C%7B%5Cpsi%7D%5Crangle+%3D+%7C%7B%5Cpsi%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ (P \otimes {\mathbb{I}}) |{\psi}\rangle = |{\psi}\rangle}"/>
ii) <img alt="{ Q}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+Q%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ Q}"/> commutes with all <img alt="{ B_j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+B_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ B_j}"/> and <img alt="{ ({\mathbb{I}} \otimes Q) |{\psi}\rangle = |{\psi}\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%28%7B%5Cmathbb%7BI%7D%7D+%5Cotimes+Q%29+%7C%7B%5Cpsi%7D%5Crangle+%3D+%7C%7B%5Cpsi%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ ({\mathbb{I}} \otimes Q) |{\psi}\rangle = |{\psi}\rangle}"/> </em>

<!--ending definition--> Since we can efficiently construct for any degenerate Optimal Quantum Strategy a unique, non-degenerate Optimal Quantum Strategy, we will now assume WLOG that every Optimal Quantum Strategy is non-degenerate (and unique).

We now define the (unique) existence of marginal biases, which correspond to constants for the rows of the quantum correlation matrix (which is a generalization of the classical pay-off). An equivalent statement can be made for columns (<img alt="{ d_{j}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+d_%7Bj%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ d_{j}}"/>) by dualizing the existence of row marginals. These constants can be thought of as representing the (expected) optimum-payoff possible for a set of operator choices by one player, given that the other player’s choice is fixed. Intuitively, this can be seen as “collapsing” the quantum correlation matrix into a column, by summing over the rows (or collapsing into a row, by summing over the columns).
<!--blockquote--><br/><b>Lemma 12 (Existence of Marginals)</b> <em> For all <img alt="{m \times n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm+%5Ctimes+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m \times n}"/> XOR games G, <img alt="{\exists \{c_{i} \geq 0 \hspace{1mm} | \hspace{1mm} i \in |S|\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cexists+%5C%7Bc_%7Bi%7D+%5Cgeq+0+%5Chspace%7B1mm%7D+%7C+%5Chspace%7B1mm%7D+i+%5Cin+%7CS%7C%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\exists \{c_{i} \geq 0 \hspace{1mm} | \hspace{1mm} i \in |S|\}}"/>, such that, if <img alt="{\{u_{i}\}_{i \in |S|}, \{v_{j}\}_{j \in |T|}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7Bu_%7Bi%7D%5C%7D_%7Bi+%5Cin+%7CS%7C%7D%2C+%5C%7Bv_%7Bj%7D%5C%7D_%7Bj+%5Cin+%7CT%7C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{u_{i}\}_{i \in |S|}, \{v_{j}\}_{j \in |T|}}"/> form an <img alt="{\epsilon}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\epsilon}"/>-optimal vector strategy where <img alt="{\epsilon \leq \frac{1}{4(m+n)}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon+%5Cleq+%5Cfrac%7B1%7D%7B4%28m%2Bn%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\epsilon \leq \frac{1}{4(m+n)}}"/>,
<a name="eqmarginale"/></em>
<p align="center"><em><a name="eqmarginale"><img alt="\displaystyle  \|\sum_{j\in|T|}G_{ij}v_{j} - c_{i}u_{i}\| \leq \sqrt{10}(m + n)^{\frac{1}{4}}\epsilon^{\frac{1}{4}}, \forall i  \ \ \ \ \ (11)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5C%7C%5Csum_%7Bj%5Cin%7CT%7C%7DG_%7Bij%7Dv_%7Bj%7D+-+c_%7Bi%7Du_%7Bi%7D%5C%7C+%5Cleq+%5Csqrt%7B10%7D%28m+%2B+n%29%5E%7B%5Cfrac%7B1%7D%7B4%7D%7D%5Cepsilon%5E%7B%5Cfrac%7B1%7D%7B4%7D%7D%2C+%5Cforall+i++%5C+%5C+%5C+%5C+%5C+%2811%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \|\sum_{j\in|T|}G_{ij}v_{j} - c_{i}u_{i}\| \leq \sqrt{10}(m + n)^{\frac{1}{4}}\epsilon^{\frac{1}{4}}, \forall i  \ \ \ \ \ (11)"/></a></em></p>
<em><a name="eqmarginale">
</a></em><em><a name="eqmarginale"/> <a name="lemma"/> </em><!--/blockquote-->
If <img alt="{ \epsilon = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cepsilon+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \epsilon = 0}"/> and our strategy is perfectly optimal, we recover an exact estimation of the marginal biases: <a name="eqmarginal"/>
<p align="center"><a name="eqmarginal"><img alt="\displaystyle  \sum_{j\in|T|}G_{ij}v_{j} = c_{i}u_{i}, \forall i  \ \ \ \ \ (12)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_%7Bj%5Cin%7CT%7C%7DG_%7Bij%7Dv_%7Bj%7D+%3D+c_%7Bi%7Du_%7Bi%7D%2C+%5Cforall+i++%5C+%5C+%5C+%5C+%5C+%2812%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \sum_{j\in|T|}G_{ij}v_{j} = c_{i}u_{i}, \forall i  \ \ \ \ \ (12)"/></a></p>
<a name="eqmarginal">
</a><a name="eqmarginal"/> The proof for the above lemma provided by Slofstra relies on using techniques to analyze the structure of the SDP program that pertains to quantum marginals. In particular, conducting trace analysis on SDP matrices that correspond to using the game matrix as off-diagonal elements leads us to the construction of the desired marginal biases.
It is also critical to note that a dual statement allows us to recover the column biases <img alt="{ d_{j} \geq 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+d_%7Bj%7D+%5Cgeq+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ d_{j} \geq 0}"/>: <a name="eqmarginalc"/>
<p align="center"><a name="eqmarginalc"><img alt="\displaystyle  \sum_{i\in[|S|]}G_{ij}u_{i} = d_{j}v_{j}, \forall j  \ \ \ \ \ (13)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_%7Bi%5Cin%5B%7CS%7C%5D%7DG_%7Bij%7Du_%7Bi%7D+%3D+d_%7Bj%7Dv_%7Bj%7D%2C+%5Cforall+j++%5C+%5C+%5C+%5C+%5C+%2813%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \sum_{i\in[|S|]}G_{ij}u_{i} = d_{j}v_{j}, \forall j  \ \ \ \ \ (13)"/></a></p>
<a name="eqmarginalc">
</a><a name="eqmarginalc"/> We now move on to defining the notion of a solution algebra.
<!--blockquote--><br/>Definition 13 (Solution Algebra) <em> A solution algebra <img alt="{\mathcal{A}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BA%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{A}}"/> consists of self-adjoint (Hermitian) operators <img alt="{X_{j}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_%7Bj%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X_{j}}"/> that satisfy the following predicates:  <a name="eqhermit"/></em>
<p align="center"><em><a name="eqhermit"><img alt="\displaystyle  X_{j}^{2} = \mathbb{I}, \forall 1 \leq j \leq n  \ \ \ \ \ (14)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++X_%7Bj%7D%5E%7B2%7D+%3D+%5Cmathbb%7BI%7D%2C+%5Cforall+1+%5Cleq+j+%5Cleq+n++%5C+%5C+%5C+%5C+%5C+%2814%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  X_{j}^{2} = \mathbb{I}, \forall 1 \leq j \leq n  \ \ \ \ \ (14)"/></a></em></p>
<em><a name="eqhermit">
</a><a name="eqhermit"/> <a name="eqbiasespay"/>
</em>
<p align="center"><em><a name="eqbiasespay"><img alt="\displaystyle  (\sum_{j\in[|T|]}G_{ij}X_{j})^{2} = (c_{i})^{2}\cdot\mathbb{I}, \forall i  \ \ \ \ \ (15)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%28%5Csum_%7Bj%5Cin%5B%7CT%7C%5D%7DG_%7Bij%7DX_%7Bj%7D%29%5E%7B2%7D+%3D+%28c_%7Bi%7D%29%5E%7B2%7D%5Ccdot%5Cmathbb%7BI%7D%2C+%5Cforall+i++%5C+%5C+%5C+%5C+%5C+%2815%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  (\sum_{j\in[|T|]}G_{ij}X_{j})^{2} = (c_{i})^{2}\cdot\mathbb{I}, \forall i  \ \ \ \ \ (15)"/></a></em></p>
<em>
</em><em><a name="eqbiasespay">
</a></em><em><a name="eqbiasespay"/> </em><!--/blockquote-->
The definition above merely enforces the property that our unknown marginal operators be Hermitian <a href="https://windowsontheory.org/feed/#eqhermit">(14)</a> and that they respect the optimal marginal biases (or payoffs) <a href="https://windowsontheory.org/feed/#eqbiasespay">(15)</a> we saw in <a href="https://windowsontheory.org/feed/#eqmarginale">(11)</a>, so that they correspond to being constructed from an optimal vector strategy. These unknown operators will be mapped to operators that are the marginal strategy corresponding to the optimal quantum strategy. This is at the heart of the main theorem we will now state:
<!--blockquote--><b>Theorem 14 (Slofstra, 2010)</b> <em> Given a <img alt="{m \times n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm+%5Ctimes+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m \times n}"/> XOR game G (with no zero rows or columns) and a solution algebra <img alt="{\mathcal{A}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BA%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{A}}"/>, a collection of Linear Operators <img alt="{\{B_{j}\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7BB_%7Bj%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{B_{j}\}}"/> and density matrix <img alt="{\rho}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\rho}"/> are the marginal of an optimal strategy iff the map <img alt="{X_{j} \rightarrow B_{j}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_%7Bj%7D+%5Crightarrow+B_%7Bj%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X_{j} \rightarrow B_{j}}"/> induces a density-matrix representation of <img alt="{\mathcal{A}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BA%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{A}}"/> and <img alt="{\rho}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\rho}"/> commutes with <img alt="{im(\mathcal{A})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bim%28%5Cmathcal%7BA%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{im(\mathcal{A})}"/>. <a name="th20"/> </em><!--/blockquote-->
Put simply, the theorem states that our unknown self-adjoint operators map to an optimal marginal strategy iff the density matrix (traced from the joint Hilbert-Space) commutes with all the mapped operators (<img alt="{ \{B_{j}\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5C%7BB_%7Bj%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \{B_{j}\}}"/>). The result we desire on the lower bound for the number of entangled bits, given a mapping from these indeterminate operators to the marginal of an optimal strategy, comes from a corollary to <a href="https://windowsontheory.org/feed/#th20">(14)</a>.
<!--blockquote--><br/>Corollary 15 <em> Given a <img alt="{m \times n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm+%5Ctimes+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m \times n}"/> XOR game G (with no zero rows or columns) and a solution algebra <img alt="{\mathcal{A}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BA%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{A}}"/> with minimum dimension <img alt="{N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N}"/> among non-zero representations, the strategy for minimum entanglement uses <img alt="{\log_{2}(N)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog_%7B2%7D%28N%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\log_{2}(N)}"/> entangled bits. <a name="co21"/> </em><!--/blockquote-->
The proof for this corollary follows from the eigenspace decomposition of the joint Hilbert Space <img alt="{ H}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+H%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ H}"/> in terms of <img alt="{ \rho}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \rho}"/>, which is preserved by the action of <img alt="{ im(\mathcal{A})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+im%28%5Cmathcal%7BA%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ im(\mathcal{A})}"/>. As a result, each eigenspace decomposes into a finite sum of irreducible representations of <img alt="{ \mathcal{A}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathcal%7BA%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \mathcal{A}}"/>. The minimum entanglement is realized when there is exactly one invariant subspace (with one irreducible representation). The entanglement used by such a representation is <img alt="{ \log_{2}(\text{dim}\,H)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Clog_%7B2%7D%28%5Ctext%7Bdim%7D%5C%2CH%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \log_{2}(\text{dim}\,H)}"/>.
<h3> Proof of Theorem 20</h3>
The rest of the section is dedicated to sketching a brief (but formal) proof for Theorem <a href="https://windowsontheory.org/feed/#th20">(14)</a>, and then using a simple fact about the representations of a Clifford Algebra to show how Slofstra’s result subsumes Tsirelson’s bound.

For this section, <img alt="{ |{\psi}\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cpsi%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |{\psi}\rangle}"/> refers to an arbitrary state in <img alt="{ H = H_{A} \otimes H_{B}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+H+%3D+H_%7BA%7D+%5Cotimes+H_%7BB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ H = H_{A} \otimes H_{B}}"/> (the joint Hilbert space). We can write <img alt="{ |{\psi}\rangle = \sum_{i} |{i}\rangle \lambda |{i}\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cpsi%7D%5Crangle+%3D+%5Csum_%7Bi%7D+%7C%7Bi%7D%5Crangle+%5Clambda+%7C%7Bi%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |{\psi}\rangle = \sum_{i} |{i}\rangle \lambda |{i}\rangle}"/> over some basis <img alt="{ \{{i}\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5C%7B%7Bi%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \{{i}\}}"/>, where <img alt="{ \lambda}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Clambda%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \lambda}"/> is a linear map. Then, the partial trace of <img alt="{ \psi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cpsi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \psi}"/> over <img alt="{ H_{A}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+H_%7BA%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ H_{A}}"/> is given by <img alt="{ \rho = \lambda\lambda^{*}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Crho+%3D+%5Clambda%5Clambda%5E%7B%2A%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \rho = \lambda\lambda^{*}}"/>.
Let <img alt="{ \mathcal{B}_{A}, \mathcal{B}_{B}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathcal%7BB%7D_%7BA%7D%2C+%5Cmathcal%7BB%7D_%7BB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \mathcal{B}_{A}, \mathcal{B}_{B}}"/> denote the algebra generated by <img alt="{ A_{1},..,A_{m}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+A_%7B1%7D%2C..%2CA_%7Bm%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ A_{1},..,A_{m}}"/> and <img alt="{ B_{1},..,B_{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+B_%7B1%7D%2C..%2CB_%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ B_{1},..,B_{n}}"/>. Here, the generating elements are the observables of an optimal quantum strategy.

To arrive at a proof for the theorem, we will rely on 2 additional lemmas which we will not prove but state.
<!--blockquote--><br/>Lemma 16 <em> Given Hermitian operators <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/>, <img alt="{B \in H_{A}, H_{B}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB+%5Cin+H_%7BA%7D%2C+H_%7BB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B \in H_{A}, H_{B}}"/>,
<a name="eqfrob"/></em>
<p align="center"><em><a name="eqfrob"><img alt="\displaystyle  \|(A \otimes \mathbb{I} - \mathbb{I} \otimes B)|\psi\rangle\| \leq \|\lambda\overline{A} - B\lambda\|_{F}  \ \ \ \ \ (16)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5C%7C%28A+%5Cotimes+%5Cmathbb%7BI%7D+-+%5Cmathbb%7BI%7D+%5Cotimes+B%29%7C%5Cpsi%5Crangle%5C%7C+%5Cleq+%5C%7C%5Clambda%5Coverline%7BA%7D+-+B%5Clambda%5C%7C_%7BF%7D++%5C+%5C+%5C+%5C+%5C+%2816%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \|(A \otimes \mathbb{I} - \mathbb{I} \otimes B)|\psi\rangle\| \leq \|\lambda\overline{A} - B\lambda\|_{F}  \ \ \ \ \ (16)"/></a></em></p>
<em><a name="eqfrob">
</a><a name="eqfrob"/> This allows us to conclude that,
<a name="eqcomm"/>
</em>
<p align="center"><em><a name="eqcomm"><img alt="\displaystyle  \|(A \otimes \mathbb{I} - \mathbb{I} \otimes B)|\psi\rangle\| \leq \epsilon \implies \|\rho(B) - B\rho\|_{F} \leq 2\epsilon  \ \ \ \ \ (17)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5C%7C%28A+%5Cotimes+%5Cmathbb%7BI%7D+-+%5Cmathbb%7BI%7D+%5Cotimes+B%29%7C%5Cpsi%5Crangle%5C%7C+%5Cleq+%5Cepsilon+%5Cimplies+%5C%7C%5Crho%28B%29+-+B%5Crho%5C%7C_%7BF%7D+%5Cleq+2%5Cepsilon++%5C+%5C+%5C+%5C+%5C+%2817%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \|(A \otimes \mathbb{I} - \mathbb{I} \otimes B)|\psi\rangle\| \leq \epsilon \implies \|\rho(B) - B\rho\|_{F} \leq 2\epsilon  \ \ \ \ \ (17)"/></a></em></p>
<em>
</em><em><a name="eqcomm">
</a></em><em><a name="eqcomm"/> <a name="lecomm"/> </em><!--/blockquote-->
<!--blockquote--><b>Lemma 17</b> <em> The optimal strategy in question is non-degenerate iff <a name="eqcl1"/></em>
<p align="center"><em><a name="eqcl1"><img alt="\displaystyle  closure(\mathcal{B}_{B}\lambda H_{A}) = closure(\mathcal{B}_{A}\lambda^{*}H_{B}). \\  \ \ \ \ \ (18)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++closure%28%5Cmathcal%7BB%7D_%7BB%7D%5Clambda+H_%7BA%7D%29+%3D+closure%28%5Cmathcal%7BB%7D_%7BA%7D%5Clambda%5E%7B%2A%7DH_%7BB%7D%29.+%5C%5C++%5C+%5C+%5C+%5C+%5C+%2818%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  closure(\mathcal{B}_{B}\lambda H_{A}) = closure(\mathcal{B}_{A}\lambda^{*}H_{B}). \\  \ \ \ \ \ (18)"/></a></em></p>
<em><a name="eqcl1">
</a><a name="eqcl1"/> As a special case:
<a name="eqcl2"/>
</em>
<p align="center"><em><a name="eqcl2"><img alt="\displaystyle  closure(\mathcal{B}_{B}\lambda H_{A}) = H_{B} \leftrightarrow closure(\rho H_{B}) = H_{B}  \ \ \ \ \ (19)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++closure%28%5Cmathcal%7BB%7D_%7BB%7D%5Clambda+H_%7BA%7D%29+%3D+H_%7BB%7D+%5Cleftrightarrow+closure%28%5Crho+H_%7BB%7D%29+%3D+H_%7BB%7D++%5C+%5C+%5C+%5C+%5C+%2819%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  closure(\mathcal{B}_{B}\lambda H_{A}) = H_{B} \leftrightarrow closure(\rho H_{B}) = H_{B}  \ \ \ \ \ (19)"/></a></em></p>
<em>
</em><em><a name="eqcl2">
</a></em><em><a name="eqcl2"/> <a name="lecl"/> </em><!--/blockquote-->
<b> Forward direction </b>:
We use the first lemma to prove commutativity of <img alt="\rho" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\rho"/> with all <img alt="B_{j}" class="latex" src="https://s0.wp.com/latex.php?latex=B_%7Bj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="B_{j}"/>, and we use the second lemma to show that the closure of <img alt="\rho" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\rho"/> is <img alt="{ H_{B}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+H_%7BB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ H_{B}}"/>.
We first show the forward direction:
Suppose we are given an optimal quantum strategy (<img alt="|{\psi}\rangle , \{A_{i}\}_{i \in S}, \{B_{j}\}_{j \in T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%7B%5Cpsi%7D%5Crangle+%2C+%5C%7BA_%7Bi%7D%5C%7D_%7Bi+%5Cin+S%7D%2C+%5C%7BB_%7Bj%7D%5C%7D_%7Bj+%5Cin+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="|{\psi}\rangle , \{A_{i}\}_{i \in S}, \{B_{j}\}_{j \in T}"/>) for a game <img alt="{ G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+G%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ G}"/>. Then, we fix our optimal vector strategy as:
<a name="eqrs"/>
<p align="center"><b><a name="eqrs"><img alt="\displaystyle  u_{i} = (A_{i} \otimes \mathbb{I})|\psi\rangle  \ \ \ \ \ (20)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++u_%7Bi%7D+%3D+%28A_%7Bi%7D+%5Cotimes+%5Cmathbb%7BI%7D%29%7C%5Cpsi%5Crangle++%5C+%5C+%5C+%5C+%5C+%2820%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  u_{i} = (A_{i} \otimes \mathbb{I})|\psi\rangle  \ \ \ \ \ (20)"/></a></b></p>
<b><a name="eqrs">
</a><a name="eqrs"/> <a name="eqcs"/>
</b>
<p align="center"><b><a name="eqcs"><img alt="\displaystyle  v_{j} = (\mathbb{I} \otimes B_{j})|\psi\rangle  \ \ \ \ \ (21)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++v_%7Bj%7D+%3D+%28%5Cmathbb%7BI%7D+%5Cotimes+B_%7Bj%7D%29%7C%5Cpsi%5Crangle++%5C+%5C+%5C+%5C+%5C+%2821%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  v_{j} = (\mathbb{I} \otimes B_{j})|\psi\rangle  \ \ \ \ \ (21)"/></a></b></p>
<a name="eqcs">
</a><a name="eqcs"/>

We can now use Equations <a href="https://windowsontheory.org/feed/#eqmarginale">(11)</a> and <a href="https://windowsontheory.org/feed/#eqmarginalc">(13)</a> to establish our optimal marginal biases to write a relationship between them and <img alt="{ |{\psi}\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cpsi%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |{\psi}\rangle}"/> , and apply Lemma <a href="https://windowsontheory.org/feed/#lecomm">(16)</a> to show commutativity and Lemma <a href="https://windowsontheory.org/feed/#lecl">(17)</a> to show that <img alt="{ im(\mathcal{A})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+im%28%5Cmathcal%7BA%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ im(\mathcal{A})}"/> = cyclic(<img alt="{ B_{j}, \rho}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+B_%7Bj%7D%2C+%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ B_{j}, \rho}"/>).
Using <a href="https://windowsontheory.org/feed/#eqmarginalc">(13)</a> with <a href="https://windowsontheory.org/feed/#eqrs">(20)</a> and <a href="https://windowsontheory.org/feed/#eqcs">(21)</a>, we have:
<a name="eqqs1"/>
<p align="center"><a name="eqqs1"><img alt="\displaystyle  d_{j}(\mathbb{I}\otimes B_{j})|\psi\rangle = \sum_{i}G_{ij}(A_{i}\otimes\mathbb{I})|\psi\rangle  \ \ \ \ \ (22)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++d_%7Bj%7D%28%5Cmathbb%7BI%7D%5Cotimes+B_%7Bj%7D%29%7C%5Cpsi%5Crangle+%3D+%5Csum_%7Bi%7DG_%7Bij%7D%28A_%7Bi%7D%5Cotimes%5Cmathbb%7BI%7D%29%7C%5Cpsi%5Crangle++%5C+%5C+%5C+%5C+%5C+%2822%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  d_{j}(\mathbb{I}\otimes B_{j})|\psi\rangle = \sum_{i}G_{ij}(A_{i}\otimes\mathbb{I})|\psi\rangle  \ \ \ \ \ (22)"/></a></p>
<a name="eqqs1">
</a><a name="eqqs1"/> We can now use <a href="https://windowsontheory.org/feed/#eqcomm">(17)</a> with <img alt="{ \epsilon = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cepsilon+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \epsilon = 0}"/> on <a href="https://windowsontheory.org/feed/#eqqs1">(22)</a> to see that <img alt="{ \rho}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \rho}"/> commutes with every <img alt="{ B_{j}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+B_%7Bj%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ B_{j}}"/>.
Additionally, as the terms in <a href="https://windowsontheory.org/feed/#eqqs1">(22)</a> constitute linear combinations of <img alt="{ A_{i}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+A_%7Bi%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ A_{i}}"/> and <img alt="{ B_{j}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+B_%7Bj%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ B_{j}}"/>, we can compute the closure of their actions on <img alt="{ \lambda H_{A}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Clambda+H_%7BA%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \lambda H_{A}}"/> and <img alt="{ \lambda^{*} H_{B}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Clambda%5E%7B%2A%7D+H_%7BB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \lambda^{*} H_{B}}"/>, which will be equivalent. Therefore, <img alt="{ im(\rho)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+im%28%5Crho%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ im(\rho)}"/> = <img alt="{ H_{B}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+H_%7BB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ H_{B}}"/>, which follows from the special case of <a href="https://windowsontheory.org/feed/#eqcl2">(19)</a>.
For the dual case, we substitute <a href="https://windowsontheory.org/feed/#eqrs">(20)</a> and <a href="https://windowsontheory.org/feed/#eqcs">(21)</a> into <a href="https://windowsontheory.org/feed/#eqmarginal">(12)</a>:
<a name="eqdn"/>
<p align="center"><a name="eqdn"><img alt="\displaystyle  c_{i}(A_{i}\otimes\mathbb{I})|\psi\rangle = \sum_{j}G_{ij}(\mathbb{I}\otimes B_{j})|\psi\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++c_%7Bi%7D%28A_%7Bi%7D%5Cotimes%5Cmathbb%7BI%7D%29%7C%5Cpsi%5Crangle+%3D+%5Csum_%7Bj%7DG_%7Bij%7D%28%5Cmathbb%7BI%7D%5Cotimes+B_%7Bj%7D%29%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle  c_{i}(A_{i}\otimes\mathbb{I})|\psi\rangle = \sum_{j}G_{ij}(\mathbb{I}\otimes B_{j})|\psi\rangle"/> </a></p>
<a name="eqdn"/>

<a name="eqdn">
</a><a name="eqdn"/><a name="eqdn"/> On taking the norm of the above on both sides and using a little algebra, we finally obtain the fact that <img alt="{ \{B_{j}\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5C%7BB_%7Bj%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \{B_{j}\}}"/> satisfy predicate <a href="https://windowsontheory.org/feed/#eqbiasespay">(15)</a> making them the representations of <img alt="{ X_{j}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+X_%7Bj%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ X_{j}}"/>:

<img alt="{ (\sum_{j}G_{ij}B_{j})^{2} = c_{i}^{2}{\mathbb{I}} }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%28%5Csum_%7Bj%7DG_%7Bij%7DB_%7Bj%7D%29%5E%7B2%7D+%3D+c_%7Bi%7D%5E%7B2%7D%7B%5Cmathbb%7BI%7D%7D+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ (\sum_{j}G_{ij}B_{j})^{2} = c_{i}^{2}{\mathbb{I}} }"/>

This shows that the map from <img alt="{ X_{j} \rightarrow B_{j}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+X_%7Bj%7D+%5Crightarrow+B_%7Bj%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ X_{j} \rightarrow B_{j}}"/> computes a density matrix representation of <img alt="{ \mathcal{A}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathcal%7BA%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \mathcal{A}}"/>, where <img alt="{ \rho}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \rho}"/> commutes with all <img alt="{ B_{j}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+B_%7Bj%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ B_{j}}"/>.

<br/><b> Backward Direction </b>:
The proof for the backward direction is much less involved:
If we knew that <img alt="{ \{B_{j}\}, \rho}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5C%7BB_%7Bj%7D%5C%7D%2C+%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \{B_{j}\}, \rho}"/> constituted the cyclic representation of <img alt="{ \mathcal{A}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathcal%7BA%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \mathcal{A}}"/> with commutativity (with <img alt="{ B_{j}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+B_%7Bj%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ B_{j}}"/>), then we can use Lemma <a href="https://windowsontheory.org/feed/#eqcl2">(19)</a> to conclude that the image of <img alt="{ \rho}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \rho}"/> on <img alt="{ H}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+H%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ H}"/> would form a subspace of <img alt="{ \lambda H}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Clambda+H%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \lambda H}"/>. We define:

<img alt="{ \overline{A}_{i} = \frac{\sum_{j}G_{ij}B_{j}}{c_{i}} }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Coverline%7BA%7D_%7Bi%7D+%3D+%5Cfrac%7B%5Csum_%7Bj%7DG_%7Bij%7DB_%7Bj%7D%7D%7Bc_%7Bi%7D%7D+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \overline{A}_{i} = \frac{\sum_{j}G_{ij}B_{j}}{c_{i}} }"/>

allowing us to recover our original marginal biases <img alt="{ c_{i}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+c_%7Bi%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ c_{i}}"/> that satisfy <a href="https://windowsontheory.org/feed/#eqdn">(23)</a> and therefore correspond to the optimal strategy. This shows us that <img alt="{ \{A_{i}\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5C%7BA_%7Bi%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \{A_{i}\}}"/>, <img alt="{ \{B_{j}\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5C%7BB_%7Bj%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \{B_{j}\}}"/> would constitute an optimal quantum strategy. <!--end proof-->
<div align="right">□</div>
Having proved this theorem, we now obtain Corollary <a href="https://windowsontheory.org/feed/#co21">15</a>, which is the main desired result. To see how it subsumes Tsirelson’s result as a special case, we use a simple fact from Representation Theory:
<br/><!--blockquote--><b>Lemma 18</b> <em> For a Clifford Algebra generated by <img alt="{X_{1},..,X_{r}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_%7B1%7D%2C..%2CX_%7Br%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X_{1},..,X_{r}}"/>, there exist one or two irreducible representations of dimension <img alt="{2^{\left \lfloor{\frac{r}{2}}\right \rfloor}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5E%7B%5Cleft+%5Clfloor%7B%5Cfrac%7Br%7D%7B2%7D%7D%5Cright+%5Crfloor%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2^{\left \lfloor{\frac{r}{2}}\right \rfloor}}"/> <a name="lecr"/> </em><!--/blockquote-->
Plugging Lemma <a href="https://windowsontheory.org/feed/#lecr">18</a> into Corollary <a href="https://windowsontheory.org/feed/#co21">15</a>, we simply recover the fact that the number of entangled bits of a solution algebra that is Clifford is <img alt="{ \left \lfloor{\frac{r}{2}}\right \rfloor}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cleft+%5Clfloor%7B%5Cfrac%7Br%7D%7B2%7D%7D%5Cright+%5Crfloor%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \left \lfloor{\frac{r}{2}}\right \rfloor}"/>. However, note that being Clifford means an extra constraint:
<img alt="{ X_{i}X_{j} = -X_{j}X_{i}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+X_%7Bi%7DX_%7Bj%7D+%3D+-X_%7Bj%7DX_%7Bi%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ X_{i}X_{j} = -X_{j}X_{i}}"/>, <img alt="{ \forall i, j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cforall+i%2C+j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \forall i, j}"/>

The constraints on the Solution Algebra <a href="https://windowsontheory.org/feed/#eqhermit">(14)</a>, <a href="https://windowsontheory.org/feed/#eqbiasespay">(15)</a> given by Slofstra do \textit{not} necessarily mean that the solution is Clifford. In fact, when an optimal quantum strategy with minimal entanglement is Clifford, <img alt="{ \{A_{i}\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5C%7BA_%7Bi%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \{A_{i}\}}"/>, <img alt="{ \{B_{j}\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5C%7BB_%7Bj%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \{B_{j}\}}"/> are constructed from a unique set of <img alt="{ \{u_{i}\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5C%7Bu_%7Bi%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \{u_{i}\}}"/>, <img alt="{ \{v_{j}\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5C%7Bv_%7Bj%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \{v_{j}\}}"/>.
To end, we write down a lemma that shows there exist XOR games where the optimal strategy is not unique and for minimal entanglement, a solution generated by a Non-Clifford algebra must be used:
<h4>Lemma (Existence of XOR games with Non-Clifford optimal strategies)</h4>
<em> There exist a family of <img alt="{ m \times n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+m+%5Ctimes+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ m \times n}"/> XOR games <img alt="{ \{G\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5C%7BG%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \{G\}}"/> that correspond to generalizations of the CHSH games (<img alt="{CL_{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BCL_%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{CL_{n}}"/>), such that, the optimal strategy of minimal entanglement is Non-Clifford. </em>

<!--ending lemma-->
<h2>References</h2>
<p>[1] David Avis, Sonoko Moriyama, and Masaki Owari. From bell inequalities to tsirelson’s theorem. IEICE Transactions, 92-A(5):1254–1267, 2009.

</p><p>[2] Lance Fortnow, John Rompel, and Michael Sipser. On the power of multi-prover interactive protocols. Theoretical Computer Science, 134(2):545 – 557, 1994.

</p><p>[3] T. Ito, H. Kobayashi, and K. Matsumoto. Oracularization and Two-Prover One-Round Interactive Proofs against Nonlocal Strategies. ArXiv e-prints, October 2008.

</p><p>[4] J. Kempe, H. Kobayashi, K. Matsumoto, B. Toner, and T. Vidick. Entangled games are hard to approximate. ArXiv e-prints, April 2007.

</p><p>[5] Julia Kempe, Oded Regev, and Ben Toner. Unique games with entangled provers are easy. SIAM Journal on Computing, 39(7):3207– 3229, 2010.

</p><p>[6] S. Khanna, M. Sudan, L. Trevisan, and D. Williamson. The approximability of constraint satisfaction problems. SIAM Journal on Computing, 30(6):1863–1920, 2001.

</p><p>[7] Anand Natarajan and Thomas Vidick. Two-player entangled games are NP-hard. arXiv e-prints, page arXiv:1710.03062, October 2017.

</p><p>[8] Anand Natarajan and Thomas Vidick. Low-degree testing for quantum states, and a quantum entangled games PCP for QMA. arXiv e-prints, page arXiv:1801.03821, January 2018.

</p><p>[9] William Slofstra. Lower bounds on the entanglement needed to play xor non-local games. CoRR, abs/1007.2248, 2010.

</p><p>[10] B.S. Tsirelson. Quantum analogues of the bell inequalities. the case of two spatially separated domains. Journal of Soviet Mathematics, 36(4):557–570, 1987.

</p><p>[11] Thomas Vidick. Three-player entangled XOR games are NP-hard to approximate. arXiv e-prints, page arXiv:1302.1242, February 2013.

</p><p>[12] Thomas Vidick. Cs286.2 lecture 15: Tsirelson’s characterization of xor games. Online, December 2014. Lecture Notes.

</p><p>[13] Thomas Vidick. Cs286.2 lecture 17: Np-hardness of computing <img alt="\omega^*(G)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Comega%5E%2A%28G%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\omega^*(G)"/>. Online, December 2014. Lecture Notes.



</p><p/></div>
    </content>
    <updated>2019-01-04T04:58:48Z</updated>
    <published>2019-01-04T04:58:48Z</published>
    <category term="physics"/>
    <author>
      <name>mitalibafna</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2019-01-07T23:33:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://cstheory.stackexchange.com/q/42140</id>
    <link href="https://cstheory.stackexchange.com/questions/42140/explanation-of-monadic-second-order-logic" rel="alternate" type="text/html"/>
    <title>Explanation of Monadic Second Order Logic [on hold]</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I am reading Wolfgang's Book <a href="https://drona.csa.iisc.ac.in/~deepakd/atc-common/wolfgang-aat.pdf" rel="nofollow noreferrer">Applied Automata Theory </a>, wherein, I came across what Monadic Second Order Logic means. </p>

<blockquote>
  <p>MSO stands for “monadic second-order”:
  Second-order because it allows quantification not only over (first-order) position
  variables but also over (second-order) set variables.
  Monadic because quantification is allowed at most over unary (monadic) relations,
  namely sets.</p>
</blockquote>

<p>I have a fundamental question , how do position variables become first order variables, and how are set variables second order? I am not able to go further, since I cannot wrap my head around this. </p></div>
    </summary>
    <updated>2019-01-03T13:49:09Z</updated>
    <published>2019-01-03T13:49:09Z</published>
    <category scheme="https://cstheory.stackexchange.com/tags" term="lo.logic"/>
    <author>
      <name>GermanShepherd</name>
      <uri>https://cstheory.stackexchange.com/users/30360</uri>
    </author>
    <source>
      <id>https://cstheory.stackexchange.com/feeds/</id>
      <link href="https://cstheory.stackexchange.com/feeds/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory.stackexchange.com/questions" rel="alternate" type="text/html"/>
      <link href="http://www.creativecommons.org/licenses/by-sa/3.0/rdf" rel="license"/>
      <subtitle>most recent 30 from cstheory.stackexchange.com</subtitle>
      <title>Recent Questions - Theoretical Computer Science Stack Exchange</title>
      <updated>2019-01-08T00:32:53Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=16724</id>
    <link href="https://gilkalai.wordpress.com/2019/01/02/jean/" rel="alternate" type="text/html"/>
    <title>Jean</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Jean Bourgain and Joram Lindenstrauss. I was very sad to hear that Jean Bourgain, among the greatest mathematicians of our time, and a dear friend, passed away.  I first met Jean about forty years ago and later we have become … <a href="https://gilkalai.wordpress.com/2019/01/02/jean/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="https://gilkalai.files.wordpress.com/2018/12/Jean-Joram.png"><img alt="" class="alignnone size-full wp-image-16725" height="500" src="https://gilkalai.files.wordpress.com/2018/12/Jean-Joram.png?w=640&amp;h=500" width="640"/></a></p>
<p><span style="color: #ff0000;">Jean Bourgain and Joram Lindenstrauss.</span></p>
<p>I was very sad to hear that Jean Bourgain, among the greatest mathematicians of our time, and a dear friend, passed away.  I first met Jean about forty years ago and later we have become friends and collaborators.  In the 80s and 90s Jean used to visit Israel quite often and had close collaboration with the Banach space Israeli community, and with the Ergodic theory community,  and with the Harmonic analysis community, and the PDE community, and later also with the combinatorics, probability,  algebra, number theory,  and theoretical computer science communities.  I always admired his immense mathematical powers and his deep devotion to mathematics.</p>
<p>You can read about Jean Bourgain in Terry Tao’s <a href="https://terrytao.wordpress.com/2018/12/29/jean-bourgain/">beautiful obituary post</a>.  I was also moved by Svetlana Jitomirskaya’s beautiful <a href="https://www.facebook.com/photo.php?fbid=10106557607678501&amp;set=a.10102850768938051&amp;type=3&amp;theater">facebook post</a>. Some of Jean’s contributions to combinatorics (which formed a small portion of his interests) are mentioned in <a href="https://gilkalai.wordpress.com/tag/jean-bourgain/">several posts </a>over my blog (and my lecture below). I will try to come back to these mathematical topics at a later post and here I post a few pictures of Jean over the years. Here is the moving <a href="https://www.ias.edu/news/2018/bourgain-obituary-notice">IAS obituary notice</a>. See also Ryan O’Donnell’s <a href="https://terrytao.wordpress.com/2018/12/29/jean-bourgain/#comment-509792">moving comment</a>. And here is a MathOverflow question <a href="https://mathoverflow.net/questions/319893/jean-bourgains-relatively-lesser-known-significant-contributions">Jean Bourgains relatively lesser known significant contributions</a>.</p>
<p> </p>
<p/>
<p><span style="color: #ff0000;"><strong>My 2016 lecture “Questions for Jean Bourgain” about questions that I (and some colleagues) asked Jean Bourgain over the years, mainly in the areas of combinatorics and combinatorial aspects of convexity.</strong></span></p>
<p><span id="more-16724"/></p>
<p><a href="https://gilkalai.files.wordpress.com/2019/01/SvetlanaonJean.png"><img alt="" class="alignnone size-full wp-image-16740" src="https://gilkalai.files.wordpress.com/2019/01/SvetlanaonJean.png?w=640"/></a></p>
<p class="_14f3 _14f5 _5pbw _5vra" id="js_6s"><span style="color: #0000ff;"><strong><span class="fwn fcg"><span class="fwb fcg">Svetlana Jitomirskaya:</span></span></strong></span></p>
<p>Вечности заложник<br/>
У времени в плену</p>
<p>Eternity’s ambassador<br/>
held captive by the time…</p>
<p>He was truly a gift from God to humanity and yet unparalleled in his kindness, humbleness, and generosity.</p>
<p>It is an enormous loss</p>
<p>February 28, 1954 – December 22, 2018</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/01/KFBT.jpg"><img alt="" class="alignnone size-full wp-image-16742" height="439" src="https://gilkalai.files.wordpress.com/2019/01/KFBT.jpg?w=640&amp;h=439" width="640"/></a></p>
<p>Hermann K<em>ö</em>nig,Tadeusz Figiel, Jean Bourgain, and Lior Tzafriri  (<a href="http://www.math.kent.edu/~mtackett/mathweb/pictures/banach.html">Banach Center Photo Archive</a>)</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/01/JeanRussell.jpg"><img alt="" class="alignnone size-full wp-image-16747" height="454" src="https://gilkalai.files.wordpress.com/2019/01/JeanRussell.jpg?w=640&amp;h=454" width="640"/></a></p>
<p>With <span dir="ltr">Russell Impagliazzo </span>(picture taken from the IAS obituary)</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/01/JB.jpg"><img alt="" class="alignnone size-full wp-image-16743" height="489" src="https://gilkalai.files.wordpress.com/2019/01/JB.jpg?w=640&amp;h=489" width="640"/></a></p>
<p>An early picture near the blackboard</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/01/AlexJeanPeter.png"><img alt="" class="alignnone size-full wp-image-16755" src="https://gilkalai.files.wordpress.com/2019/01/AlexJeanPeter.png?w=640"/></a></p>
<p>Alex Gamburd, Jean Bourgain, and Peter Sarnak.</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/01/crafoord-day.jpg"><img alt="" class="alignnone size-full wp-image-16744" src="https://gilkalai.files.wordpress.com/2019/01/crafoord-day.jpg?w=640"/></a></p>
<p>Crafoord day, Lund 2012 Carlos Kenig, Ben Green, Jean, Terry Tao, me, and Michael Christ.</p>
<p> </p>
<p><a href="https://gilkalai.files.wordpress.com/2019/01/jeangil88.png"><img alt="" class="alignnone size-full wp-image-16741" height="470" src="https://gilkalai.files.wordpress.com/2019/01/jeangil88.png?w=640&amp;h=470" width="640"/></a></p>
<p>At IHES, 1989</p>
<h3>Pictures of early version of our first joint work (around 1990) with Izzy Katznelson, Jeff Kahn and Nati Linial.</h3>
<p>The initial approach had a 22 page long proof and my copy has a dense (Hebrew) handwritten explanation all the way to page 15.</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/01/BKKKL2.png"><img alt="" class="alignnone size-full wp-image-16738" height="325" src="https://gilkalai.files.wordpress.com/2019/01/BKKKL2.png?w=640&amp;h=325" width="640"/></a></p>
<p> </p>
<p style="text-align: center;"><span style="color: #ff0000;">Part of Page 6</span></p>
<p><a href="https://gilkalai.files.wordpress.com/2019/01/BKKK3.png"><img alt="" class="alignnone size-full wp-image-16739" height="399" src="https://gilkalai.files.wordpress.com/2019/01/BKKK3.png?w=640&amp;h=399" width="640"/></a></p>
<p style="text-align: center;"><span style="color: #ff0000;">Part of page 19</span></p>
<p>At the end we found a shortcut to the problem itself, but both Jean and I have felt over the years that the deeper methods developed initially by Jean may have further important use.</p></div>
    </content>
    <updated>2019-01-02T19:09:52Z</updated>
    <published>2019-01-02T19:09:52Z</published>
    <category term="Algebra and Number Theory"/>
    <category term="Analysis"/>
    <category term="Combinatorics"/>
    <category term="Computer Science and Optimization"/>
    <category term="Convexity"/>
    <category term="Obituary"/>
    <category term="Jean Bourgain"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-01-07T23:27:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://cstheory.stackexchange.com/q/42135</id>
    <link href="https://cstheory.stackexchange.com/questions/42135/strong-seeded-randomness-extractors-with-low-entropy-loss" rel="alternate" type="text/html"/>
    <title>Strong seeded randomness extractors with low entropy loss</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I would like to implement a strong seeded randomness extractor for flat sources as a part of my project. </p>

<p>Most of the literature on seeded extractors is concentrated on minimizing seed length. However, low entropy loss is crucial for my construction. What are the known extractors with minimal entropy loss? How efficient is the extractor in practice? </p>

<p>Is there a lower bound on the entropy loss for strong seeded extractors? </p>

<p>Are there any implementations of extractors that I can use off the shelf?</p></div>
    </summary>
    <updated>2019-01-02T16:48:50Z</updated>
    <published>2019-01-02T16:48:50Z</published>
    <category scheme="https://cstheory.stackexchange.com/tags" term="lower-bounds"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="randomness"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="pseudorandomness"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="extractors"/>
    <author>
      <name>satya</name>
      <uri>https://cstheory.stackexchange.com/users/51635</uri>
    </author>
    <source>
      <id>https://cstheory.stackexchange.com/feeds/</id>
      <link href="https://cstheory.stackexchange.com/feeds/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory.stackexchange.com/questions" rel="alternate" type="text/html"/>
      <link href="http://www.creativecommons.org/licenses/by-sa/3.0/rdf" rel="license"/>
      <subtitle>most recent 30 from cstheory.stackexchange.com</subtitle>
      <title>Recent Questions - Theoretical Computer Science Stack Exchange</title>
      <updated>2019-01-08T00:32:53Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2018/12/31/linkage</id>
    <link href="https://11011110.github.io/blog/2018/12/31/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage for the end of the year</title>
    <summary>LaTeX, the game (, G+, via). It should be an even higher level to get the commutative diagram to format in Wikipedia’s lobotomized version of LaTeX.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><ul>
  <li>
    <p><a href="https://twitter.com/trannosaurusma/status/959423514485841925?s=21">LaTeX, the game</a> (<span style="white-space: nowrap;"><a href="https://mathstodon.xyz/@11011110/101252368314388741"/>,</span> <a href="https://plus.google.com/100003628603413742554/posts/BAwHG7Tnc2N">G+</a>, <a href="https://mathstodon.xyz/@ejk/101201955004129570">via</a>). It should be an even higher level to get the commutative diagram to format in Wikipedia’s lobotomized version of LaTeX.</p>
  </li>
  <li>
    <p><a href="http://aperiodical.com/2018/12/byrnes-euclid-recreated-for-the-web/">Byrne’s Euclid recreated for the web</a> (<span style="white-space: nowrap;"><a href="https://mathstodon.xyz/@11011110/101259384727886209"/>,</span> <a href="https://plus.google.com/100003628603413742554/posts/4Z1pWdmcWui">G+</a>, <a href="https://plus.google.com/+Aperiodical/posts/KdfBH9YMFMV">via</a>, <a href="https://www.metafilter.com/178260/Byrnes-Euclid">also via</a>. Beautiful three-color figures, hard-to-read old-faſhioned orthography, and all. I have the Taſchen reprint in my office, but I prefer the Dover Heath edition for actually uſing the books rather than looking pretty.</p>
  </li>
  <li>
    <p><a href="https://www.theengineer.co.uk/electric-eel-hydrogel-battery/">Electric eel inspires biocompatible hydrogel battery</a> (<span style="white-space: nowrap;"><a href="https://mathstodon.xyz/@11011110/101264841241151850"/>,</span> <a href="https://plus.google.com/100003628603413742554/posts/EioURA7NEmH">G+</a>, <a href="https://www.nature.com/articles/nature24670">original paper</a>, <a href="https://news.umich.edu/electricity-eel-style-soft-power-cells-could-run-tomorrow-s-implantables/">see also</a>). The part that caught my attention is that they’re using a Miura fold to simultaneously align and press together many pairs of droplets of four types (salty, fresh water, or two kinds of charge-selective hydrogel), creating an origami-activated electrical discharge.</p>
  </li>
  <li>
    <p><a href="https://www.quantamagazine.org/in-the-universe-of-equations-virtually-all-are-prime-20181210/">In the universe of equations, virtually all are prime</a> (<span style="white-space: nowrap;"><a href="https://mathstodon.xyz/@11011110/101270526352782325"/>,</span> <a href="https://plus.google.com/100003628603413742554/posts/d7hvGtho5FJ">G+</a>, <a href="https://plus.google.com/+QuantamagazineOrgNews/posts/9e2bRyNfyeF">via</a>, <a href="https://arxiv.org/abs/1810.13360">original paper</a>). Choose a polynomial’s coefficients randomly and independently from your favorite nontrivial distribution. Then it should be irreducible with high probability for polynomials of high enough degree. This was previously conjectured for the uniform distribution on  by Odlyzko and Poonen; now Breuillard and Varjú have proven that it follows from a form of the Riemann hypothesis.</p>
  </li>
  <li>
    <p>A tricky Sudoku (<span style="white-space: nowrap;"><a href="https://mathstodon.xyz/@11011110/101277538292220348"/>,</span> <a href="https://plus.google.com/100003628603413742554/posts/NDeATkTyEKT">G+</a>):</p>

    <p style="text-align: center;"><img alt="A sudoku puzzle" src="https://11011110.github.io/blog/assets/2018/sudoku.svg"/></p>
  </li>
  <li>
    <p><a href="https://www.chronicle.com/article/In-Talks-With-Elsevier-UCLA/245311">UCLA suggests that its faculty refrain from publishing with or reviewing for Elsevier while negotiations are ongoing</a> (<span style="white-space: nowrap;"><a href="https://mathstodon.xyz/@11011110/101281900329465390"/>,</span> <a href="https://plus.google.com/100003628603413742554/posts/E4KAhwXct6y">G+</a>). For those willing to take a longer-term stand, there’s always <a href="http://thecostofknowledge.com/">thecostofknowledge.com</a>.</p>
  </li>
  <li>
    <p><a href="https://suomela.github.io/snowflake/">A161330 Snowflake</a> (<span style="white-space: nowrap;"><a href="https://mathstodon.xyz/@11011110/101293131395532694"/>,</span> <a href="https://plus.google.com/100003628603413742554/posts/N1gsDwSmjrX">G+</a>, <a href="https://plus.google.com/+JukkaSuomela/posts/b7rngpsTaVc">via</a>). An animated holiday greeting from <a href="https://twitter.com/JukkaSuomela">Jukka Suomela</a> based on <a href="https://oeis.org/A161330">integer sequence A161330</a>.</p>
  </li>
  <li>
    <p><a href="https://mathstodon.xyz/@unknown/101273978649098365">Festive two-to-one star dissection</a> (<span style="white-space: nowrap;"><a href="https://mathstodon.xyz/@11011110/101298812633911915"/>,</span> <a href="https://plus.google.com/100003628603413742554/posts/Bf3kWzhc9Yh">G+</a>). A Christmas greeting from <a href="https://mathstodon.xyz/@unknown/">@unknown@mathstodon.xyz</a>.</p>
  </li>
  <li>
    <p><a href="https://www.youtube.com/watch?v=uNJ7riiPHOY">Journeys of women in mathematics</a> (<span style="white-space: nowrap;"><a href="https://mathstodon.xyz/@11011110/101311027456154189"/>,</span> <a href="https://plus.google.com/100003628603413742554/posts/5CXnPF36FMz">G+</a>, <a href="https://blogs.scientificamerican.com/roots-of-unity/women-mathematicians-in-their-own-words/">via</a>). A 20-minute documentary profiling three women mathematicians from developing countries: Neela Nataraj of IIT Bombay in India, Aminatou Pecha Nijahouo from Cameroon, and Carolina Araujo at IMPA in Brazil, with brief quotes from many more.</p>
  </li>
  <li>
    <p><a href="https://wikiedu.org/blog/2018/12/20/three-things-i-learned-as-a-wiki-scholar/">Three things i learned as a Wiki scholar</a> (<span style="white-space: nowrap;"><a href="https://mathstodon.xyz/@11011110/101314727270253883"/>,</span> <a href="https://plus.google.com/100003628603413742554/posts/hmWXq3eDTqf">G+</a>, <a href="https://en.wikipedia.org/wiki/Wikipedia_talk:WikiProject_Women_in_Red">via</a>). Historian Rachel Boyle on some cultural differences between academia and Wikipedia.</p>
  </li>
  <li>
    <p><a href="https://commons.wikimedia.org/wiki/File:Mendocino_Beacon_Building.jpg">Mendocino Beacon Building</a> (<span style="white-space: nowrap;"><a href="https://mathstodon.xyz/@11011110/101320263516053157"/>,</span> <a href="https://plus.google.com/100003628603413742554/posts/ik4GHTux6wN">G+</a>). It feels like I haven’t been taking and posting enough photos. So here’s a cell phone shot that I took to illustrate the Wikipedia article on the <em><a href="https://en.wikipedia.org/wiki/Mendocino_Beacon">Mendocino Beacon</a></em>. The <em>Beacon</em> hasn’t actually lived there for nearly 20 years, but their old sign still hangs on the building.</p>
  </li>
  <li>
    <p><em><a href="http://algorithms.wtf/">Algorithms</a></em> (<span style="white-space: nowrap;"><a href="https://mathstodon.xyz/@11011110/101327166193790839"/>,</span> <a href="https://plus.google.com/100003628603413742554/posts/Vsin2Hxwpaj">G+</a>, <a href="https://3dpancakes.typepad.com/ernie/2018/12/steal-this-book-1.html">via</a>). Jeff Erickson’s open-licensed algorithms text is finally more-or-less complete and available in prepublication form.</p>
  </li>
  <li>
    <p><a href="https://wyss.harvard.edu/studying-aliens-of-the-deep/">Using unfolded polyhedra to catch and later release deep-sea creatures without harming them</a> (<span style="white-space: nowrap;"><a href="https://mathstodon.xyz/@11011110/101332999043783606"/>,</span> <a href="https://plus.google.com/100003628603413742554/posts/j42xnNxs7nW">G+</a>, <a href="https://news.ycombinator.com/item?id=18769435">via</a>).</p>
  </li>
  <li>
    <p><a href="https://plus.google.com/100003628603413742554/posts/WSizeQTqrZH">In which I say goodbye to Google+</a> (<span style="white-space: nowrap;"><a href="https://mathstodon.xyz/@11011110/101338372532836995"/>).</span></p>
  </li>
</ul></div>
    </content>
    <updated>2018-12-31T16:41:00Z</updated>
    <published>2018-12-31T16:41:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-01-03T05:47:41Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://cstheory.stackexchange.com/q/42122</id>
    <link href="https://cstheory.stackexchange.com/questions/42122/what-to-do-as-a-theoretical-computer-science-phd-student-in-a-free-time" rel="alternate" type="text/html"/>
    <title>What to do as a Theoretical computer science PhD student in a free time?</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I am a mid-stage theoretical computer science student. Although I have a busy schedule, I still have a one or one a half hour in a day which I devote to reading and solving the question given Jeff Erickson's lecture note etc. I am doing this thing from many months and wondering. Is this a right thing for me to do in free time as now I am a Ph.D. student not an undergraduate student. Now why I do this to become more strong in an algorithm, discrete maths etc part. Another thing which seems more valuable to me is to read more and more research paper of my research domain as my goal after my Ph.D. is to publish more quality research papers in the field related to my current field. I am wondering which one is better or suggest anything else which may be more valuable to me keeping my future perspective in mind.</p>

<p><strong>Question:</strong> What to do as a Theoretical computer science PhD student in free time? I am wondering what star experienced researchers do in their time ( assuming they have a free time ).</p>

<p>Some of my free time I also spent on watching video lecture of workshops related to my field.</p>

<p>After looking at all the comments and answers, I have to edit my question. I think, I have not been able to convey what I was trying to ask. My question was how to sharp my technical skills in the free time for a better future. It has nothing to do with my personal life or some one's personal space. I was here for the various possibilities and opinions of users, who have experience in theoretical computer science. Let me clarify my question further, I was to trying to ask in the free time what is more significant to do " continue to think about the research problem at hand or do the problems related to maths or algorithms " and so on. Looking at the comments have made me realise that definitely I need to improve my writing skills also. </p></div>
    </summary>
    <updated>2018-12-31T12:15:55Z</updated>
    <published>2018-12-31T12:15:55Z</published>
    <category scheme="https://cstheory.stackexchange.com/tags" term="soft-question"/>
    <author>
      <name>A_Theory</name>
      <uri>https://cstheory.stackexchange.com/users/49003</uri>
    </author>
    <source>
      <id>https://cstheory.stackexchange.com/feeds/</id>
      <link href="https://cstheory.stackexchange.com/feeds/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory.stackexchange.com/questions" rel="alternate" type="text/html"/>
      <link href="http://www.creativecommons.org/licenses/by-sa/3.0/rdf" rel="license"/>
      <subtitle>most recent 30 from cstheory.stackexchange.com</subtitle>
      <title>Recent Questions - Theoretical Computer Science Stack Exchange</title>
      <updated>2019-01-08T00:32:53Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://cstheory.stackexchange.com/q/42120</id>
    <link href="https://cstheory.stackexchange.com/questions/42120/is-a-binary-sequence-computable-iff-the-kolmogorov-complexity-of-its-initial-seg" rel="alternate" type="text/html"/>
    <title>Is a binary sequence computable iff the Kolmogorov complexity of its initial segments is bounded?</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><strong>Disclaimer:</strong> I am mostly unfamiliar with theoretical computer science, making it hard for me to navigate literature in the field. I ask the following out of curiosity.</p>

<p><strong>Background/Motivation:</strong> Coming from information theory, I recently learned about a connection of entropy and Kolmogorov complexity: Loosely speaking, entropy of a random variable is the expected rate at which the Kolmogorov complexity of a long sample sequence increases per sample. <a href="http://www.cs-114.org/wp-content/uploads/2015/01/Elements_of_Information_Theory_Elements.pdf" rel="nofollow noreferrer">[Elements of Information Theory, p. 154]</a> Kolmogorov complexity can therefore capture the notion of entropy, but it is more general than that. Hereby, and in the following, whenever I write complexity, I implicitly refer to the complexity given the length of the output.</p>

<p>For non-zero entropy, the Kolmogorov complexity of initial segments of an infinite sequence of samples from a random variable is therefore unbounded. I was wondering whether this is equivalent to the fact that an infinite sequence of samples is uncomputable. This led me to the hypothesis in the title: Is a binary sequence computable if and only if the Kolmogorov complexity of its initial segments is bounded?</p>

<p>If the hypothesis was true, then computability could be understood as an indicator that the "amount of information" in a sequence is finite. In some sense, the initial segment complexities would allow a more finely graded characterization of infinite sequences than just "computable" and "uncomputable". We could get a notion of "information content" and "information rate" of infinite sequences by analyzing the size of the bound or, in the unbounded case, the rate/type of growth, as in the entropy case above. My question boils down to whether "computable" and "uncomputable" are regions on this scale.</p>

<p>If the hypothesis is true, I'd be interested in whether this perspective is useful for TCS research. If yes, are there references elaborating this idea? If not, why not?</p>

<p><strong>What I found in literature:</strong> It is shown that a sequence is Martin-Löf random iff there is a constant <span class="math-container">$c$</span> so that there are infinitely many initial segments with complexity greater than <span class="math-container">$n - c$</span> where <span class="math-container">$n$</span> is the segment length. <a href="https://arxiv.org/pdf/math/0110086.pdf" rel="nofollow noreferrer">[Randomness, p. 18]</a></p>

<p>This means that random sequences have unbounded initial segment complexity. Since they are not computable, the hypothesis is true at least for this case. If I am not mistaken, a similar argument could even be made for a weaker form of randomness, since Mises-Wald-Church random sequences cannot have initial segment complexity of O(log n). <a href="https://www.math.uni-heidelberg.de/logic/merkle/ps/JCSS-stoch.pdf" rel="nofollow noreferrer">[The complexity of stochastic sequences]</a></p>

<p><strong>What's missing for a proof:</strong></p>

<p><span class="math-container">$\Leftarrow$</span>:
Assume a sequence is computable. We know that a program <code>generate_bit(n)</code> exists that generates any bit of the sequence. Now, we can build a program <code>generate_initial_segment(n) = concat(map(1..n, generate_bit))</code> that, given the segment length <span class="math-container">$n$</span>, generates the initial segment up to position n by invoking <code>generate_bit</code> <span class="math-container">$n$</span> times and concatenating the results. The Kolmogorov complexity of this task is therefore bounded by the length of this program. ☐</p>

<p><span class="math-container">$\Rightarrow$</span>: I struggle to prove/disprove this direction, namely: If initial segment complexity is bounded, is a sequence always computable?</p>

<p>Update: The last two pages of <a href="https://www.sciencedirect.com/science/article/pii/S0019995869905385/pdf?md5=5ff60459e171a92caef1156280e1ce2c&amp;pid=1-s2.0-S0019995869905385-main.pdf" rel="nofollow noreferrer">A variant of the Kolmogorov concept of complexity</a> prove this direction.</p></div>
    </summary>
    <updated>2018-12-31T09:22:03Z</updated>
    <published>2018-12-31T09:22:03Z</published>
    <category scheme="https://cstheory.stackexchange.com/tags" term="computability"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="it.information-theory"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="kolmogorov-complexity"/>
    <author>
      <name>Julius Kunze</name>
      <uri>https://cstheory.stackexchange.com/users/51614</uri>
    </author>
    <source>
      <id>https://cstheory.stackexchange.com/feeds/</id>
      <link href="https://cstheory.stackexchange.com/feeds/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory.stackexchange.com/questions" rel="alternate" type="text/html"/>
      <link href="http://www.creativecommons.org/licenses/by-sa/3.0/rdf" rel="license"/>
      <subtitle>most recent 30 from cstheory.stackexchange.com</subtitle>
      <title>Recent Questions - Theoretical Computer Science Stack Exchange</title>
      <updated>2019-01-08T00:32:53Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:typepad.com,2003:post-6a00d83452383469e2022ad3ca27b2200b</id>
    <link href="https://3dpancakes.typepad.com/ernie/2018/12/steal-this-book-1.html" rel="alternate" type="text/html"/>
    <link href="https://3dpancakes.typepad.com/ernie/2018/12/steal-this-book-1.html" rel="replies" type="text/html"/>
    <title>Steal This Book!</title>
    <summary>Today I'm finally releasing a final (or more honestly, “final”) pre-publication draft of my Algorithms textbook under a CC-BY license. This 448-page textbook evolved out of a subset of the algorithms lecture notes I've been maintaining for about 20 years....</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p><a class="asset-img-link" href="https://3dpancakes.typepad.com/.a/6a00d83452383469e2022ad3aa81d3200d-popup"><img alt="BookCover" class="asset  asset-image at-xid-6a00d83452383469e2022ad3aa81d3200d img-responsive" src="https://3dpancakes.typepad.com/.a/6a00d83452383469e2022ad3aa81d3200d-320wi" style="display: block; margin-left: auto; margin-right: auto;" title="BookCover"/></a><br/>Today I'm <em>finally</em> releasing a final (or more honestly, “final”) pre-publication draft of my <em>Algorithms</em> textbook under a CC-BY license. This 448-page textbook evolved out of a subset of the algorithms lecture notes I've been maintaining for about 20 years.</p>
<p>There are still a few more steps before this becomes an actual paper book—most notably an index—but I wanted to get this out the door this year. I expect to publish the actual paper book in a few weeks; it will also be licensed CC-BY.</p>
<p>Meanwhile, I've set up an issue-tracker on Github where anyone can report errors or provide other feedback.</p>
<p>The book site also includes copies of the lecture notes that I left out of the book (because I wanted a finite book in a finite amount of time), along with a complete archive of old homeworks, exams, lab handouts, and the like.</p>
<p>Enjoy!</p>
<ul>
<li>Official book site: <a href="http://jeffe.cs.illinois.edu/teaching/algorithms/">http://jeffe.cs.illinois.edu/teaching/algorithms/</a></li>
<li>Mnemonic shortcut: <a href="http://algorithms.wtf">http://algorithms.wtf</a></li>
<li><strong>Please report errors:</strong> <a href="https://github.com/jeffgerickson/algorithms">https://github.com/jeffgerickson/algorithms</a></li>
<li>Archival copy: <a href="https://archive.org/details/Algorithms-Jeff-Erickson">https://archive.org/details/Algorithms-Jeff-Erickson</a></li>
</ul></div>
    </content>
    <updated>2018-12-29T22:50:59Z</updated>
    <published>2018-12-29T22:50:59Z</published>
    <category term="Algorithms"/>
    <category term="Books"/>
    <category term="Writing"/>
    <author>
      <name>Jeff Erickson</name>
    </author>
    <source>
      <id>tag:typepad.com,2003:weblog-6686</id>
      <link href="https://3dpancakes.typepad.com/ernie/atom.xml" rel="self" type="application/atom+xml"/>
      <link href="https://3dpancakes.typepad.com/ernie/" rel="alternate" type="text/html"/>
      <subtitle>Let Σ be a combinatorial surface with n vertices, genus g, and b boundaries.  Amen.</subtitle>
      <title>Ernie's 3D Pancakes</title>
      <updated>2018-12-29T22:50:59Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://agtb.wordpress.com/?p=3371</id>
    <link href="https://agtb.wordpress.com/2018/12/28/sigecom-test-of-time-award/" rel="alternate" type="text/html"/>
    <title>SIGecom Test of Time Award</title>
    <summary>The SIGecom Test of Time Award recognizes the author or authors of an influential paper or series of papers published between ten and twenty-five years ago that has significantly impacted research or applications exemplifying the interplay of economics and computation. To be eligible, a paper or series of papers must be on a topic in […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div>The SIGecom Test of Time Award recognizes the author or authors of an influential paper or series of papers published between ten and twenty-five years ago that has significantly impacted research or applications exemplifying the interplay of economics and computation.</div>
<div/>
<p/>
<div>To be eligible, a paper or series of papers must be on a topic in the intersection of economics and computation, including topics in electronic commerce, and must have been first published, in preliminary or final form, in an archival journal or conference proceedings no less than ten years and no more than twenty-five years before the year the award is conferred. Papers for which all authors are deceased at the time the Award Committee makes its decision are not eligible for the award.</div>
<div/>
<p/>
<div>The 2019 SIGecom Test of Time Award will be given for papers published no earlier than 1994 and no later than 2009. Nominations are due by February 20th, 2019, and must be made by email to the Award Committee (<a href="mailto:sigecom-awards-tot@acm.org" rel="noopener" target="_blank">sigecom-awards-tot@acm.org</a>) with “ACM SIGecom Test of Time Award” in the subject.</div>
<div/>
<p/>
<div>Any member of SIGecom may submit a nomination. Self-nomination is not allowed. Nominations must include the following, preferably in a single PDF file:</div>
<div/>
<p/>
<div>1. Bibliographic data for the paper or series of papers demonstrating publication, in preliminary or final form, at least ten years and at most twenty-five years before the award year.</div>
<div/>
<p/>
<div>2. An endorsement letter by the nominator of no more than two pages describing the content of the paper or series of papers and the lasting contribution, significance, and impact of the work.</div>
<div/>
<p/>
<div>3. The names, email addresses, and affiliations of at least two and at most three other endorsers. Endorsers, like the nominator, may not be authors of the paper or papers under consideration.</div>
<div/>
<p/>
<div>4. A one-sentence statement that describes the contribution of the paper or series of papers.</div>
<div/>
<p/>
<div>The additional endorsers should send letters directly to the Award Committee (<a href="mailto:sigecom-awards-tot@acm.org" rel="noopener" target="_blank">sigecom-awards-tot@acm.org</a>) by the same deadline. Each letter should specify the relationship of the endorser to nominees and describe, in 500 words or fewer, the lasting contribution, significance, and impact of the paper or papers.</div>
<div/>
<p/>
<div>An unsuccessful nomination can be reconsidered for three award cycles, with the option of updating the original nomination to reflect additional impact. Subsequently, a new nomination must be provided. All matters relating to the selection process that are not specified here are left to the discretion of the Award Committee.</div>
<div/>
<p/>
<div>The award, conferred annually at the ACM Conference on Economics and Computation, includes a plaque and complimentary conference registration for each winner and an honorarium of $1,000 to be shared among the winners. The award may not be given if the nominations are judged not to meet the standards of the award.</div>
<div/>
<p/>
<div>It is expected that at least one of the nominated authors, if selected for the award, will attend the next ACM Conference on Economics and Computation on June 24-28, 2019, in Phoenix, AZ, USA, to accept the award and give a presentation on the work. The award includes complimentary registration but does not cover travel expenses to attend the conference.</div>
<div/>
<p/>
<div>The Award Committee welcomes questions from anyone considering or intending to submit a nomination. The Award Committee is happy to provide feedback on informal proposals for potential nominees, should it be needed.</div>
<div/>
<p/>
<div>On behalf of the 2019 Award Committee:</div>
<div/>
<p/>
<div>Nikhil Devanur</div>
<div>Robert Kleinberg</div>
<div>Tim Roughgarden (Chair)</div>
<div><a href="mailto:sigecom-awards-tot@acm.org" rel="noopener" target="_blank">sigecom-awards-tot@acm.org</a></div></div>
    </content>
    <updated>2018-12-28T20:52:18Z</updated>
    <published>2018-12-28T20:52:18Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>timroughgarden</name>
    </author>
    <source>
      <id>https://agtb.wordpress.com</id>
      <logo>https://secure.gravatar.com/blavatar/52ef314e11e379febf97d1a97547f4cd?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fbuttonw-com.png</logo>
      <link href="https://agtb.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://agtb.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://agtb.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://agtb.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Computation, Economics, and Game Theory</subtitle>
      <title>Turing's Invisible Hand</title>
      <updated>2019-01-07T23:27:02Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=15551</id>
    <link href="https://rjlipton.wordpress.com/2018/12/27/acm-great-results/" rel="alternate" type="text/html"/>
    <title>ACM Great Results</title>
    <summary>A Puck-ish take on promised technological advances Wikimedia Commons source Knecht Ruprecht accompanies Santa Claus in Germany. He brings gifts to good children but lumps of coal to naughty ones. He is regarded more generally as the German counterpart to England’s Robin Goodfellow, aka. Puck. The Simpsons’ dog “Santa’s Little Helper” is named “Knecht Ruprecht” […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>A Puck-ish take on promised technological advances</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2018/12/KnechtRuprecht.jpg"><img alt="" class="alignright wp-image-15552" height="189" src="https://rjlipton.files.wordpress.com/2018/12/KnechtRuprecht.jpg?w=189&amp;h=189" width="189"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Wikimedia Commons <a href="https://commons.wikimedia.org/wiki/File:Das_festliche_Jahr_img398_(Ruprecht).jpg">source</a></font></td>
</tr>
</tbody>
</table>
<p>
Knecht Ruprecht accompanies Santa Claus in Germany. He brings gifts to good children but lumps of coal to naughty ones. He is regarded more generally as the German counterpart to England’s Robin Goodfellow, aka. <a href="https://en.wikipedia.org/wiki/Puck_(folklore)">Puck</a>. The Simpsons’ <a href="https://en.wikipedia.org/wiki/Santa's_Little_Helper">dog</a> “Santa’s Little Helper” is named “Knecht Ruprecht” in the show’s German edition.</p>
<p>
Today we do a nice-or-naughty riff on technological gifts suggested by yesterday’s ACM TechNews mailing.<br/>
<span id="more-15551"/></p>
<p>
The ACM mailings highlight the achievements of the whole field: from quantum to everything else. We thought it might be fun to be a bit puckish ourselves and deliver some “coal” to ACM. The stories can be sometimes a bit much. We hope that all involved are in good spirits and accept the “coal” as a holiday-inspired gift—with some echo of the general discussion about naughty-or-nice effects of tech advances.</p>
<p>
</p><p/><h2> Our Versions of the Stories </h2><p/>
<p>
</p><p>
Here are some that could be reported in the near future. The originals are <a href="https://technews.acm.org/archives.cfm?fo=2018-12-dec/dec-26-2018.html">here</a>.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <i>Real-Time Readouts of Thinking in Faculty</i>. <br/>
Mighty News<br/>
December 19, 2018<br/>
Researchers from a university consortium have developed an open source system delivering fast, precise neural decoding and real-time readouts of where CS faculty think they are. The neural decoding software decrypts hippocampal spatiotemporal patterns detected from tetrode recordings without requiring spike sorting, an error-prone computational process. Implementing this software on a graphical processing unit (GPU) chip demonstrated a 20- to 50-fold upgrade in decoding and analysis speed over conventional multicore central processing unit (CPU) chips. This builds on work previous done on rats as reported by ACM previously. The lab director says that the CS faculty work presented many challenges beyond that required for rats. The applications—she says—are immense. Faculty currently cannot always tell where they are, and the new system could help them get to classes on time.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <i>A Robotic Hand Able To Type At Desktop Keyboard At 20 Words Per Minute</i>.<br/>
New Yolk Times<br/>
December 19, 2018 <br/>
Researchers at Can’t-Abridge University have for the first time taught a robotic hand to type on a normal keyboard. The researchers claim that their system can type at rates in excess of 20 words per minute. They say, “this could change the way that computers interact with others.” The system, which now weighs about 500 pounds, could be reduced in size and cost in the future. That the robot sometimes destroys the keys by hitting them too hard continues to be a challenge.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <i>How AI Spotted Every Solar Panel in the U.S.</i><br/>
Pretty Big Solar NewsHour<br/>
December 19, 2018<br/>
Engineers at the University of St. Anford have located every solar panel in the contiguous U.S. via a network built around a deep learning computer model called Inception. The network completed this task in less than a month, ascertaining that regions with more sun exposure had greater solar panel adoption than areas with less average sunlight. DeepSolar also learned that adoption was higher in locations of increasing average household income. Unbelievable—who would have guessed this?</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <i>An Amoeba Just Found an Entirely New Way to Write Articles</i>. <br/>
ScienceAlarm <br/>
December 21, 2018<br/>
Researchers at Knockout University in Japan gave an assistant professorship to a “true slime mold” amoeba, and found as the papers-per-year target increased from four to eight, the single-celled organism only needed a linear amount of more time to generate minimum publishable units. This is part of an ongoing project on using lower-level organisms to do research. The project previously used graduate students. The leader of the multiple institution project said that using amoebae could reduce the costs of writing up research by up to 50%. He also said that the amoeba sometimes made various grammar errors, but that the project was attempting to fix this issue.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <i>A Quantum Computer Just Found an Entirely Old Way to Visit Cities</i>. <br/>
ScienceAllure <br/>
December 21, 2018<br/>
Researchers at TKO University in Japan gave the Traveling Salesman Problem (TPS) to a vast array of noisy astronomical scale quantum (NASQ) processors, and found that as the cities increased from four to eight, the system only needed a linear amount of more time to determine a single reasonable route. This was fresh off its success at factoring numbers higher than 291,311 = 523*557 that it didn’t even <a href="https://en.wikipedia.org/wiki/Integer_factorization_records#Records_for_efforts_by_quantum_computers">know</a> it was factoring. TPS is an optimization problem requiring a computer to look at a list of cities and determine the shortest route in which each city is visited exactly once. The team said their results “may lead to the development of quantum algorithms for problems on as many as ten cities.” </p>
<p/><p/>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2018/12/SantasLittleHelperOrlando.jpg"><img alt="" class="aligncenter size-medium wp-image-15555" height="148" src="https://rjlipton.files.wordpress.com/2018/12/SantasLittleHelperOrlando.jpg?w=300&amp;h=148" width="300"/></a>
</td>
</tr>
<tr>
<td class="caption alignright">
<font size="-2">Modified from <a href="https://www.flickr.com/photos/jared422/11839818825">source</a><br/>
</font>
</td>
</tr>
</tbody></table>
<p><img alt="{\bullet}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet}"/> <i>Programming Proteins to Pair Precisely</i>.<br/>
C++ News<br/>
December 19, 2018<br/>
The <b>std::pair</b> construct in C++ is a common annoyance because human programmers frequently forget its implicit presence when iterating over maps or inserting into sets. This necessitates the re-typing of millions of lines of source code per annum. Absent the development of a robotic hand able to type at a desktop keyboard at 20 words per minute, software companies can improve productivity by optimizing the nutritional intake of programmers. Nanosoft has partnered with CodeURIKA to provide protein-rich drinks worldwide, after a study of electronic sweatshops found that proteins minimize both syntactic and semantic bugs better over the long term than sugars and PEDs. </p>
<p>
<img alt="{\bullet}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet}"/> <i>Room for Improvement? New Hotelier Tests an Algorithmic System</i>.<br/>
Wallbanger Street Journal<br/>
December 19, 2018<br/>
The Lite House hotelier is experimenting with an algorithmic pricing system to set different room rates for guests who arrive in self-driving cars. Once customers book for the first time at a standard rate, they fill out a questionnaire of 200 questions to specify how often they will need the car, how frequently they visit the hotel bar, and other details. The hotelier then activates a key to drive the car into an appropriate space. The optimized use of vertical space and savings from not hiring car valets will enable conference participants who are not staying at the hotel to park there at a rate low enough to include in the conference registration fee. A spokesman said, “Most of the big hotel operating companies are not focused on their conference guests,” while Lite House’s algorithmic rate-setting “is next-generation.”</p>
<p>
<img alt="{\bullet}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet}"/> <i>Companies Use VR to Train Employees for Difficult Customers</i>.<br/>
ESPN Technology Review<br/>
December 20, 2018.<br/>
Major corporations like Wallstore, ChippedPot, and Horizon are using virtual reality (VR) to prepare employees for potentially difficult situations on the job. For example, Horizon has more than 1,600 stores in the U.S. whose front-line employees participate in a digital scenario in which a customer asks to use the bathroom. In a “Harry Potter-Style Photos for Muggles” twist, researchers have developed software that can animate the central character in a photograph while leaving the rest of the image untouched. Its skeleton can then be animated to create the sense of movement, solving the problem of pose estimation for a limited set of circumstances in which bathroom requests occur. </p>
<p>
<img alt="{\bullet}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet}"/> <i>New Attack Intercepts Keystrokes Via Digital Watches</i>.<br/>
TubeNet<br/>
December 19, 2018<br/>
A team of researchers from Burning Man University has developed a new side-channel attack that exploits the heat generated by people wearing Orange Digital Watches while working on their PCs. Heat amplifies the watches’ ability to detect keystrokes from both hands. Videos known to generate large amounts of heat include comic videos and videos on carpet cleaning. The attack becomes more adept at guessing correct keys as the user gets hotter, as it amasses more key presses from graphic libraries. </p>
<p/><p><br/>
There are some other items, including one particularly chilling, that we chose not to parody.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Will the next year’s advances in AI and other areas of tech be anything like we imagine? Will they bring humanity more gifts than lumps of coal?</p>
<p/></font></font></div>
    </content>
    <updated>2018-12-28T01:39:40Z</updated>
    <published>2018-12-28T01:39:40Z</published>
    <category term="All Posts"/>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="ACM"/>
    <category term="ACM TechNews"/>
    <category term="AI"/>
    <category term="Christmas"/>
    <category term="gifts"/>
    <category term="Knecht Ruprecht"/>
    <category term="tech"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-01-08T00:28:44Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2018/12/27/motorcycle-graphs-eventual</id>
    <link href="https://11011110.github.io/blog/2018/12/27/motorcycle-graphs-eventual.html" rel="alternate" type="text/html"/>
    <title>Motorcycle graphs and the eventual fate of sparse Life</title>
    <summary>The motorcycle graph is a geometric structure devised by Jeff Erickson as a simplified model for the behavior of straight skeletons, motivated by the light cycle game in the movie Tron. Its initial data consists of a set of points in the plane (the motorcycles), each with an initial velocity. The motorcycles leave a trail behind them as they move, and a motorcycle crashes (stopping the growth of its trail) when it hits the trail of another motorcycle.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The <a href="http://jeffe.cs.illinois.edu/open/cycles.html">motorcycle graph</a> is a geometric structure devised by Jeff Erickson as a simplified model for the behavior of <a href="https://en.wikipedia.org/wiki/Straight_skeleton">straight skeletons</a>, motivated by the light cycle game in the movie Tron. Its initial data consists of a set of points in the plane (the motorcycles), each with an initial velocity. The motorcycles leave a trail behind them as they move, and a motorcycle crashes (stopping the growth of its trail) when it hits the trail of another motorcycle.</p>

<p style="text-align: center;"><img alt="A motorcycle graph" src="https://11011110.github.io/blog/assets/2018/motorcycle-graph.svg"/></p>

<p>The motorcycles can be constrained in various ways, and one of these constrained variants is much older. It’s the <a href="https://en.wikipedia.org/wiki/Gilbert_tessellation">Gilbert tessellation</a>, a motorcycle graph in which the motorcycles start out in pairs traveling in opposite directions, all at the same speed, with a random initial placement for the pairs. Edgar Gilbert wrote about it in 1967, as a model for the growth of <a href="https://en.wikipedia.org/wiki/Acicular_(crystal_habit)">acicular (needle-shaped) crystals</a> and similar systems.</p>

<p style="text-align: center;"><a href="https://commons.wikimedia.org/wiki/File:Gilbert_tessellation.svg"><img alt="A Gilbert tessellation, by Claudio Rocchini" src="https://11011110.github.io/blog/assets/2018/Gilbert-tessellation.svg"/></a></p>

<p>One obvious difference between the Gilbert tessellation and more general types of motorcycle graph is that all the Gilbert tessellation cells are convex polygons. More general motorcycle graphs leave degree-one vertices at the starting position of each motorcycle, but this is hidden by the way the Gilbert graph starts motorcycles in pairs. If we constrain the motorcycles even more, to travel in axis-parallel directions, the polygons become rectangles.</p>

<p style="text-align: center;"><a href="https://commons.wikimedia.org/wiki/File:Gilbert_tessellation_axis.svg"><img alt="Axis-aligned Gilbert tessellation subdivides the plane into rectangles, by Claudio Rocchini" src="https://11011110.github.io/blog/assets/2018/Gilbert-rectangles.svg"/></a></p>

<p>In my paper “<a href="https://arxiv.org/abs/0911.2890">Growth and decay in life-like cellular automata</a>” I noticed that the <a href="https://en.wikipedia.org/wiki/Life-like_cellular_automaton">Life-like cellular automaton</a> rule B017/S1 has a very simple <a href="https://en.wikipedia.org/wiki/Replicator_(cellular_automaton)">replicator</a> consisting of two orthogonally-adjacent live cells, and that initial fields consisting of very sparse randomly placed live cells become dominated by rows and columns of these replicators. Here’s an example for an initial random fill density of 1%, the lowest I can go in <a href="http://golly.sourceforge.net/">Golly</a>.</p>

<p style="text-align: center;"><img alt="Replicator chaos in B017/S1" src="https://11011110.github.io/blog/assets/2018/b017s1.png"/></p>

<p>Although I didn’t notice it at the time, this looks very similar to the rectangular Gilbert tessellation! I think that’s not a coincidence. With a fill density of , the most common constellation (connected group of live cells) of the initial configuration will be a single live cell, with density (number of constellations per unit area) approximately  . But the isolated cells all die off immediately. The second most common constellations,  with density , have two live cells. If the two cells are diagonally adjacent, they form a small oscillator, and if they are orthogonally adjacent, they form a replicator. The replicators will then grow either horizontally or vertically in both directions until they run into something, usually (but not always) another replicator. When two replicators collide, they tend to form a stable blob that blocks both of them. The one that was there first will usually (but not always) have copies of itself on both sides of the blob, so its line of copies stays more or less unchanged in place. The replicator that arrives second will usually (but not always) be blocked by the first replicator, and stay on one side of the collision point. And when replicators are bounded on both sides by stable blobs, they usually (but not always) turn into stable oscillators, continuing to fill the line they have already marked out. If all of the usual things always happened, we would get a Gilbert tessellation; instead, we get something that looks a lot like a Gilbert tessellation but with typically a constant number of oscillators in its rectangles and with occasional other differences from the expected behavior.</p>

<p>Could this happen for sparse initial conditions of <a href="https://en.wikipedia.org/wiki/Conway%27s_Game_of_Life">Conway’s Game of Life</a>? Maybe!</p>

<p>In a sequence of papers from 1998 to his 2010 “<a href="https://doi.org/10.1007/978-1-84996-217-9_20">Emergent Complexity in Conway’s Game of Life</a>”, Nick Gotts has explored the behavior of random Life initial conditions, in the limit as the fill density  goes to zero. We don’t know what happens to these patterns in the long term, but we can say something rigorous about their behavior in the short and medium terms. Here, by “short term” I mean what happens after a constant number of steps, and by “medium term” I mean a number of steps that’s polynomial in  with a small-enough exponent.</p>

<p>Initially, near most points of the plane, the nearest objects will be isolated cells, spaced  units from each other (the inverse square root of their density). However, these immediately die off. So in the short term, the nearest objects will usually be “blonks” (blinkers and blocks, generated from initial constellations of three live cells), with density  and spacing . More widely scattered are gliders, either generated directly from constellations of five initial live cells, or from <a href="http://www.conwaylife.com/wiki/R-pentomino">R pentominos</a> which create a bounded number of gliders before stabilizing. Both possibilities give the gliders density . Even more widely scattered, at density , are the simplest patterns that produce infinite growth rather than stability or simple motion: the <a href="http://www.conwaylife.com/wiki/Block-laying_switch_engine">block-laying switch engines</a>, generated from initial constellations of ten live cells. These are puffer trains rather than replicators: they have a single live head that lays down a trail of blocks as it moves.</p>

<p>If the field stayed like this throughout the medium term, things would be boring. The gliders and switch engines would typically crash into blonks in  steps, in most cases stopping their motion. And so one might expect that at numbers of steps with higher exponents, most points would have only stable or low-period debris as their nearest live pattern. Occasionally there would be a trail of a crashed and dead switch engine but these would be very far apart, at a typical distance , compared to their typical length of . So from a high-level point of view, these trails would just look like randomly placed line segments rather than forming anything like a motorcycle graph or Gilbert tessellation.</p>

<p>However, what Gotts discovered is that something much more complicated and confusing happens. The gliders (with short-term density ) start crashing into blonks, but when they do they sometimes produce one or more new gliders. Those gliders, in turn, might crash into something else and produce even more gliders, perhaps including some that return to the previous crash site. Gotts defines a “standard collision sequence” to be a sequence of events of this type, involving a single initial glider and a widely scattered collection of blonks. There are finitely many different standard collision sequences that involve a given number  of initial blonks. Any one of these sequences can happen to a given glider with a probability that tends to a constant as the number of time steps goes to , the expected time for any glider to complete its collision sequence in the absence of interactions with the crash debris of other gliders.</p>

<p>But the crash debris starts to add up, preventing this analysis from actually staying valid all the way to that limiting point. In particular, some standard collision sequences can produce infinite growth patterns like the block-laying switch engine. If we ignored interactions with other gliders and just considered standard collision sequences, it would appear that the density of switch engines constructed in this way would approach  as the number of time steps went to , and therefore that the density of blocks in switch engine trails would approach , much more dense than the density of initial blonks. That can’t happen, and our analysis breaks down. What’s less clear and not rigorously proven is exactly how it breaks down.</p>

<p>One possibility for the breakdown is the following. Switch engines or other puffer engines start being produced in increasing density by standard collision sequences, and they start growing trails of blocks behind them. As their trails grow and the typical distance between the puffers shrinks, at some point these two distances cross over, and the trails become longer than the typical distance. This crossover distance is well below the  distance one would expect a puffer to travel before hitting an initial blonk. Once this happens, most puffers will crash into the trail of another puffer, and their trails will divide up space into something resembling a motorcycle graph. (It’s not a Gilbert tessellation, because each puffer starts out moving in a single direction.) The cells of this graph prevent anything else from moving across it, leading to eventual stabilization.</p>

<p>Another possibility is that some other pattern (perhaps initial or perhaps produced by a standard collision sequence) does something quickly enough to disrupt the creation of a motorcycle graph before it happens, or breaks through it after it is constructed. We don’t know what these patterns might look like, but we also don’t know that they don’t exist. Life patterns can do complicated things. Because so much is still unknown, what Gotts actually proves is more cautious: either infinite-growth patterns created from collision sequences eventually cause the total population to be significantly denser than its original density, or the infinite-growth patterns created through standard collision sequences will themselves become more dense than they were in the initial field.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/101316148318254282"/>, <a href="https://plus.google.com/100003628603413742554/posts/ehARHPdEkde">G+</a>)</p></div>
    </content>
    <updated>2018-12-27T17:24:00Z</updated>
    <published>2018-12-27T17:24:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-01-03T05:47:41Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://cstheory.stackexchange.com/q/42104</id>
    <link href="https://cstheory.stackexchange.com/questions/42104/does-a-given-regular-language-contain-an-infinite-prefix-free-subset" rel="alternate" type="text/html"/>
    <title>Does a given regular language contain an infinite prefix-free subset?</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>A set of words over a finite alphabet is <em>prefix-free</em> if there are no two distinct words where one is a prefix of the other.</p>

<p>The question is: </p>

<p><strong>What is the complexity of checking whether a regular language given as an NFA contains an infinite prefix-free subset?</strong></p>

<p><strong>Answer (due to Mikhail Rudoy, here below)</strong>: It can be done in polynomial time, and I think in even in NL. </p>

<p>Paraphrasing Mikhail's answer, let <span class="math-container">$(\Sigma,q_0,F,\delta)$</span> be the input NFA in the normal form (no epsilon transitions, trim), and let <span class="math-container">$L[p,r]$</span> (resp. <span class="math-container">$L[p,R]$</span>) be the language obtained by having state <span class="math-container">$r$</span> as initial state and <span class="math-container">$\{s\}$</span> as final state (resp. state <span class="math-container">$r$</span> as inital and the set <span class="math-container">$S$</span> as final). For a word <span class="math-container">$u$</span> let <span class="math-container">$u^\omega$</span> be the infinite word obtained by iterating <span class="math-container">$u$</span>.</p>

<p>The following are equivalent:</p>

<ol>
<li>The language <span class="math-container">$L[q_0,F]$</span> contains an infinite prefix-free subset.</li>
<li><span class="math-container">$\exists q \in Q$</span>, <span class="math-container">$\exists u \in L[q,q]$</span> <span class="math-container">$\exists v \in L[q,F]$</span> so that <span class="math-container">$v$</span> is not a prefix of <span class="math-container">$u^\omega$</span>.</li>
<li><span class="math-container">$\exists q \in Q$</span> <span class="math-container">$L[q,q] \neq \emptyset$</span> <span class="math-container">$\forall u \in L[q,q]$</span> <span class="math-container">$\exists v \in L[q,F]$</span> so that <span class="math-container">$v$</span> is not a prefix of <span class="math-container">$u^\omega$</span>.</li>
</ol>

<p>Proof:</p>

<p>3<span class="math-container">$\Rightarrow$</span>2 trivial.</p>

<p>For 2<span class="math-container">$\Rightarrow$</span>1, it suffices to see that for any <span class="math-container">$w \in L[q_0,q]$</span> we have that <span class="math-container">$w (u^{|v|})^* v$</span> is an infinite prefix-free subset of <span class="math-container">$L[q_0,F]$</span>.</p>

<p>Finally, 1<span class="math-container">$\Rightarrow$</span>3 is the "correctness" proof in Mikhail's answer.</p></div>
    </summary>
    <updated>2018-12-27T15:03:12Z</updated>
    <published>2018-12-27T15:03:12Z</published>
    <category scheme="https://cstheory.stackexchange.com/tags" term="fl.formal-languages"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="automata-theory"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="prefix-free-code"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="nfa"/>
    <author>
      <name>Googlo</name>
      <uri>https://cstheory.stackexchange.com/users/49964</uri>
    </author>
    <source>
      <id>https://cstheory.stackexchange.com/feeds/</id>
      <link href="https://cstheory.stackexchange.com/feeds/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory.stackexchange.com/questions" rel="alternate" type="text/html"/>
      <link href="http://www.creativecommons.org/licenses/by-sa/3.0/rdf" rel="license"/>
      <subtitle>most recent 30 from cstheory.stackexchange.com</subtitle>
      <title>Recent Questions - Theoretical Computer Science Stack Exchange</title>
      <updated>2019-01-08T00:32:53Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=16645</id>
    <link href="https://gilkalai.wordpress.com/2018/12/25/amazing-karim-adiprasito-proved-the-g-conjecture-for-spheres/" rel="alternate" type="text/html"/>
    <title>Amazing: Karim Adiprasito proved the g-conjecture for spheres!</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Karim in his youth with a fan Congratulations, Karim! Update: Here is the link to the paper From the arXive, Dec 26, 2018. (Link will be added tomorrow.) COMBINATORIAL LEFSCHETZ THEOREMS BEYOND POSITIVITY by Karim Adiprasito Abstract: Consider a simplicial complex … <a href="https://gilkalai.wordpress.com/2018/12/25/amazing-karim-adiprasito-proved-the-g-conjecture-for-spheres/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="https://gilkalai.files.wordpress.com/2015/01/gilkarim.jpg"><img alt="" class="alignnone size-full wp-image-12390" height="853" src="https://gilkalai.files.wordpress.com/2015/01/gilkarim.jpg?w=640&amp;h=853" width="640"/></a></p>
<p style="text-align: center;"><span style="color: #ff0000;">Karim in his youth with a fan</span></p>
<p>Congratulations, Karim!</p>
<p><strong>Update</strong>: <a href="https://arxiv.org/abs/1812.10454">Here is the link to the paper</a></p>
<p><em>From the arXive, Dec 26, 2018. (Link will be added tomorrow.)</em></p>
<p>COMBINATORIAL LEFSCHETZ THEOREMS BEYOND POSITIVITY</p>
<p>by Karim Adiprasito</p>
<p><strong>Abstract:</strong> Consider a simplicial complex that allows for an embedding into <img alt="\mathbb R^d" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb R^d"/>. How many faces of dimension <img alt="d/2" class="latex" src="https://s0.wp.com/latex.php?latex=d%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d/2"/> or higher can it have? How dense can they be?</p>
<p>This basic question goes back to Descartes. Using it and other fundamental combinatorial<br/>
problems, we will introduce a version of the Kähler package beyond positivity,<br/>
allowing us to prove the Lefschetz theorem for toric varieties even when the ample<br/>
cone is empty. A particular focus lies on replacing the Hodge-Riemann relations by a<br/>
non-degeneracy relation at torus-invariant subspaces, allowing us to state and prove a<br/>
generalization of the theorems of Hall and Laman in the setting of toric varieties. Of<br/>
the many applications, we highlight two main applications, one because it is the most<br/>
well-known, the other because it provided the most guiding light.</p>
<p>(1) We fully characterize the possible face numbers of simplicial spheres, resolving the<br/>
so called <em>g</em>-conjecture of McMullen in full generality and generalizing Stanley’s<br/>
earlier proof for simplicial polytopes.</p>
<p>(2) We prove that for a simplicial complex <em>K</em> that embeds into <img alt="\mathbb R^{2d}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5E%7B2d%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb R^{2d}"/>, the number of <em>d</em>-dimensional simplices exceeds the number of <em>(d − 1)</em>-dimensional simplices by a factor of at most <em>d + 2</em>. This generalizes a result of Descartes, and resolves the Grünbaum-Kalai-Sarkaria conjecture.</p>
<p>_______</p>
<p>(GK:) A few further comments. Probably the <em>g</em>-conjecture for spheres is the single problem I knock my head against the most. It is great to see it settled and it is even greater to see it settled by my friend and colleague Karim Adiprasito.</p>
<p>To the three ingredients of the standard conjectures (See also the <a href="https://gilkalai.wordpress.com/2018/12/24/icm-2018-rio-4-huh-balog-morris-wormald/">previous post</a>), Poincare duality <strong>(PD</strong>), Hard Lefschetz (<strong>HL</strong>) and Hodge-Riemann (<strong>HR</strong>), Karim adds the <strong>Hall-Laman relations</strong>. Very roughly, the Hall-Laman relations  substitute<strong> (HR)</strong> and apply genericity (rather than definiteness) toward <strong>(HL)</strong>.</p>
<p>(We still need a good acronym for Hall-Laman, maybe <strong>(AHL)</strong>.)</p>
<p>One very nice feature of Karim’s proof is that <strong>vertex decomposable</strong> spheres play a special role in the path toward the proof. Those were introduced by Provan and Billera in the context of the Hirsch conjecture.</p>
<p>We have devoted <a href="https://gilkalai.wordpress.com/tag/g-conjecture/">plenty of posts</a> to the <em>g</em>-conjecture for spheres, and mentioned it in <a href="https://gilkalai.wordpress.com/page/2/?s=g-conjecture">even more posts</a>.  For an introduction to the conjecture see <a href="https://gilkalai.wordpress.com/2009/04/02/eran-nevo-the-g-conjecture-i/">Eran Nevo introductory post</a>, and the post <a href="https://gilkalai.wordpress.com/2009/04/04/how-the-g-conjecture-came-about/" rel="bookmark">How the g-Conjecture Came About</a>. There is also plenty left to be done <a href="https://gilkalai.wordpress.com/2018/06/20/beyond-the-g-conjecture-algebraic-combinatorics-of-cellular-spaces-i/">beyond the g-conjecture</a>.</p>
<p><span style="color: #0000ff;">Merry X-mas and Happy new year 2019 to all our readers.</span></p></div>
    </content>
    <updated>2018-12-25T14:38:23Z</updated>
    <published>2018-12-25T14:38:23Z</published>
    <category term="Combinatorics"/>
    <category term="Updates"/>
    <category term="g-conjecture"/>
    <category term="Karim Adiprasito"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-01-07T23:27:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=16429</id>
    <link href="https://gilkalai.wordpress.com/2018/12/24/icm-2018-rio-4-huh-balog-morris-wormald/" rel="alternate" type="text/html"/>
    <title>ICM 2018 Rio (4): Huh; Balog &amp; Morris; Wormald</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">  This is my fourth report from ICM2018. (I plan one more.)  As I already mentioned, Combinatorics  was very nicely represented at ICM2018.  The combinatorics session itself was great, and there were quite a few other sessions and other lectures … <a href="https://gilkalai.wordpress.com/2018/12/24/icm-2018-rio-4-huh-balog-morris-wormald/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p> </p>
<p>This is my fourth report from ICM2018. (I plan one more.)  As I already mentioned, Combinatorics  was very nicely represented at ICM2018.  The combinatorics session itself was great, and there were quite a few other sessions and other lectures related to combinatorics. I also met quite a few combinatorialists. As I mentioned in my <a href="https://gilkalai.wordpress.com/2012/11/17/a-few-mathematical-snapshots-from-india-icm2010/">ICM 2010 post</a>, one thing that I enjoyed was to unexpectedly meet some old friends and this also happened in Rio (maybe a little less compared to Hyderabad as I learned to expect the unexpected). I also had an irrational expectation to unexpectedly meet the <em>same</em> people that I met unexpectedly in India. It was a pleasure meeting  Tadeusz Januszkiewicz again   but I was irrationally disappointed not to bump again into <a href="http://www-ma4.upc.edu/~oserra">Oriol Serra</a> and Anna Llado whom I had met  by surprise in Hyderabad.</p>
<p>This post will be about the Monday afternoon Session in combinatorics. Let me mention that the <a href="https://www.youtube.com/channel/UCnMLdlOoLICBNcEzjMLOc7w">ICM 2018 You Tube channel</a> now contains high quality videos for plenary and invited talks (as well as discussion panels, public lectures, and various other activities). This is a valuable resource! Here is the <a href="https://www.youtube.com/playlist?list=PLOrjUJw2wOmVE7DUBxr4CFu4TNhiJM8Hj">combinatorics session playlist</a>, and the <a href="https://www.youtube.com/playlist?list=PLOrjUJw2wOmWQ9pIGF1ObG4Ag472sg2hm">CS session</a>, and the <a href="https://www.youtube.com/playlist?list=PLOrjUJw2wOmXn3FrOaMN7ZVNqsY_fWDHw">probability and statistics</a> session, and the <a href="https://www.youtube.com/playlist?list=PLOrjUJw2wOmW5F1S9OGR6esa9XpTOTq6e">plenary lectures</a>, and the <a href="https://www.youtube.com/playlist?list=PLOrjUJw2wOmWTsHKdFtIP7H2zsvwI0Uq4">public lectures</a>. Also, here is the most recent version of my ICM paper <a href="https://gilkalai.files.wordpress.com/2018/12/icm-draft-Dec-2018.pdf">THREE PUZZLES ON MATHEMATICS, COMPUTATION, AND GAMES</a>. Last minute corrections and comments are most welcome.</p>
<h1>Monday’s afternoon combinatorics</h1>
<p>The Monday afternoon combinatorics session featured three lectures that knocked my socks off. The talks were great and I was in a perfect position to enjoy them as I knew something about the problems and some related results  and yet each lecture surprised me.  The three talks were <span class="watch-title" dir="ltr" id="eow-title" title="Combinatorial applications of the Hodge&#x2013;Riemann relations &#x2013; June Huh &#x2013; ICM2018"><a href="https://youtu.be/ceGEZdjnxRw">Combinatorial applications of the Hodge–Riemann relations</a> </span>by June Huh, <span class="watch-title" dir="ltr" title="The method of hypergraph containers &#x2013; J&#xF3;zsef Balogh &amp; Robert Morris &#x2013; ICM2018"><a href="https://www.youtube.com/watch?v=y1zH5Hq24OA">The method of hypergraph containers</a> by József Balogh &amp; Robert Morris,  </span><span class="watch-title" dir="ltr" id="eow-title" title="Asymptotic enumeration of graphs with given degree sequence &#x2013; Nicholas Wormald &#x2013; ICM2018"><a href="https://www.youtube.com/watch?v=fNisXEdZhlQ">Asymptotic enumeration of graphs with given degree sequence</a> by Nicholas Wormald. Bella Bollobas chaired the session and gave a very nice and thoughtful introduction to each of the four speakers.</span></p>
<p><span class="watch-title" dir="ltr" id="eow-title" title="Asymptotic enumeration of graphs with given degree sequence &#x2013; Nicholas Wormald &#x2013; ICM2018"> </span></p>
<h2>June Huh, and the Lefschetz package in combinatorics</h2>
<p/>
<blockquote><p><strong><span style="color: #ff0000;">June Huh: The standard conjectures are both ubiquitous and fundamental</span></strong></p></blockquote>
<p class="watch-title-container"><a href="https://youtu.be/ceGEZdjnxRw"><span class="watch-title" dir="ltr" id="eow-title" title="Combinatorial applications of the Hodge&#x2013;Riemann relations &#x2013; June Huh &#x2013; ICM2018">Combinatorial applications of the Hodge–Riemann relations</span></a></p>
<p>June Huh talked about a mysterious package of conjectures (PD), (HL) and (HR), referred to as the standard conjectures,  for certain algebras associated with geometric and combinatorial objects. PD stands for the Poincare Duality, and it asserts that certain vector spaces <img alt="A_i" class="latex" src="https://s0.wp.com/latex.php?latex=A_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_i"/> and <img alt="A_{d-i}" class="latex" src="https://s0.wp.com/latex.php?latex=A_%7Bd-i%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_{d-i}"/> are dual. HD stands for Hard Lefschetz and it asserts that certain linear maps <img alt="\phi_k" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cphi_k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\phi_k"/> from <img alt="A_k" class="latex" src="https://s0.wp.com/latex.php?latex=A_k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_k"/> to <img alt="A_k+1" class="latex" src="https://s0.wp.com/latex.php?latex=A_k%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_k+1"/>  have the property that their composition from <img alt="A_i" class="latex" src="https://s0.wp.com/latex.php?latex=A_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_i"/> all the way to <img alt="A_{d-i}" class="latex" src="https://s0.wp.com/latex.php?latex=A_%7Bd-i%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_{d-i}"/> is an injection. (HR) stands for Hodge Riemann relations. (PD) and (HD) imply that a certain bilinear form  is nondegenerate and (HR) is a stronger statement that this form is definite!</p>
<p>June started with some startling applications of the Hard-Lefschetz theorem in combinatorics pioneered by Stanley. He then mentioned a startling new application with Wang: Consider <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> points spanning a <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/>-dimensional space.  Let <img alt="w_i" class="latex" src="https://s0.wp.com/latex.php?latex=w_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="w_i"/> be the number of flats of dimension <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/> spanned by the point.  Motzkin  conjectured in 1936 and proved over the reals that  <img alt="w_1 \le w_d" class="latex" src="https://s0.wp.com/latex.php?latex=w_1+%5Cle+w_d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="w_1 \le w_d"/>. The planar case follows from the classic Erdos deBruijn theorem. Hu and Wang used {HL} to prove <img alt="w_i \le w_d-i" class="latex" src="https://s0.wp.com/latex.php?latex=w_i+%5Cle+w_d-i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="w_i \le w_d-i"/>, <img alt="i \le [d/2]" class="latex" src="https://s0.wp.com/latex.php?latex=i+%5Cle+%5Bd%2F2%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i \le [d/2]"/> which was conjectured by Dowling and Wilson.</p>
<p>Next came applications of (HR), starting with Huh’s proof of the log concavity of coefficients of chromatic polynomials for graphs (Read conjecture ) and the far-reaching extension by Adiprasito-Huh-Kats to general matroids (Rota’s conjecture). We mentioned the Adiprasito-Huh-Katz solution of the Rota-Heron conjecture in <a href="https://gilkalai.wordpress.com/2018/12/12/nima-anari-kuikui-liu-shayan-oveis-gharan-and-cynthia-vinzant-solved-the-mihail-vazirani-conjecture/">the previous post</a> and in <a href="https://gilkalai.wordpress.com/2015/08/14/updates-and-plans-iii/">this one</a>.</p>
<p>Here is the link to the ICM paper by June Huh: <a href="https://arxiv.org/abs/1711.11176">Combinatorial applications of the Hodge-Riemann relations</a>.</p>
<p> </p>
<h2>József Balogh and Rob Morris and the container method</h2>
<p/>
<p><span class="watch-title" dir="ltr" title="The method of hypergraph containers &#x2013; J&#xF3;zsef Balogh &amp; Robert Morris &#x2013; ICM2018"><a href="https://www.youtube.com/watch?v=y1zH5Hq24OA">The method of hypergraph containers</a> </span></p>
<p>The container theorem for hypergraphs is one of the most important tools in extremal combinatorics with many applications also to random graphs and hypergraphs, additive combinatorics, discrete geometry, and more.</p>
<p>Rob Morris explained the container theorem for triangle-free graphs. It asserts that there is a collection <img alt="\cal C" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ccal+C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\cal C"/> of graphs on <img alt="n vertices" class="latex" src="https://s0.wp.com/latex.php?latex=n+vertices&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n vertices"/> with the following three properties:</p>
<p>(1) Every graph in the collection contains <img alt="o(n^3)" class="latex" src="https://s0.wp.com/latex.php?latex=o%28n%5E3%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="o(n^3)"/> triangles,</p>
<p>(2) The number of graphs in the collection is <img alt="n^{C \cdot 3/2}" class="latex" src="https://s0.wp.com/latex.php?latex=n%5E%7BC+%5Ccdot+3%2F2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n^{C \cdot 3/2}"/>,</p>
<p>(3) Each triangle free graph is contained in a graph in the collection.</p>
<p>Rob explained the origins of this theorem, how it follows from a container theorem for 3-uniform hypergraphs,   and how the later extends to the very general and important container theorem for <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-uniform hypergraphs that was achieved in 2012 independently by Saxton and Thomason (Here is the link to <a href="https://arxiv.org/abs/1204.6595">their paper</a>), and by Balogh, Morris, and Samotij (Here is a link to <a href="https://arxiv.org/abs/1204.6530">their paper</a>).</p>
<p>Jozsef Balogh described two consequences of the container theorem to additive combinatorics and to discrete geometry. Let me describe the result in discrete geometry by Balogh and Solymosi. The (4,3) problem ask for the size $\alpha (n)$ of the largest subset of points in general position (no three on a line) that can always be found in a planar configuration of <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> points with the property that no four points lie on a line. The container method is used to show (surprisingly!) that <img alt="\alpha(n)=n^{5/6+o(1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Calpha%28n%29%3Dn%5E%7B5%2F6%2Bo%281%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\alpha(n)=n^{5/6+o(1)}"/> .</p>
<p>For a recent beautiful application to <img alt="(p,q)" class="latex" src="https://s0.wp.com/latex.php?latex=%28p%2Cq%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(p,q)"/>-Helly type theorems see <a href="https://arxiv.org/abs/1809.06451">A new lower bound on Hadwiger-Debrunner numbers in the plane</a> by Chaya Keller and Shakhar Smorodinsky.</p>
<p>Here is a link to the ICM survey paper: <a href="https://arxiv.org/abs/1801.04584">The method of hypergraph containers</a>, by József Balogh, Robert Morris, and Wojciech Samotij</p>
<p>(In a previous post  <a href="https://gilkalai.wordpress.com/2015/01/20/midrasha-mathematicae-18-in-and-around-combinatorics/" rel="bookmark">Midrasha Mathematicae #18: In And Around Combinatorics, </a>we gave links to a series of lectures Wojiech Samotij: Toward the hypergraph “container” theorem (4 lectures) <a href="https://www.youtube.com/watch?v=SpAyBN4rccU">Video 1, </a><a href="http://youtu.be/N6rP1yUcE0M">video 2</a> <a href="https://www.youtube.com/watch?v=cSFfKhcyN14">video 3</a> <a href="https://www.youtube.com/watch?v=efVlsmiws-I">video 4</a>.)</p>
<h2>Nick Wormald and counting regular graphs.</h2>
<p/>
<p><span class="watch-title" dir="ltr" id="eow-title" title="Asymptotic enumeration of graphs with given degree sequence &#x2013; Nicholas Wormald &#x2013; ICM2018"><a href="https://www.youtube.com/watch?v=fNisXEdZhlQ">Asymptotic enumeration of graphs with given degree sequence</a></span></p>
<p>How many <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-regular graphs are there? This is a very central problem in combinatorics and Nick Wormald was quite interested in its solution ever since his Ph. D.  The talk describes the early history of the problem, the early works by Wormald and McKay from the 90s,  the recent breakthrough by Antia Liebenau and Nick Wormald,  the techniques involved in the old and new proofs and some related results.</p>
<p>A good place to start is with Read’s 1958 formula for the number <img alt="g_3(n)" class="latex" src="https://s0.wp.com/latex.php?latex=g_3%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g_3(n)"/> of 3-regular graphs with n labelled vertices</p>
<p><img alt="g_3(n) \sim (3n)! e^{-2}/(3n/2)!288^{n/2}." class="latex" src="https://s0.wp.com/latex.php?latex=g_3%28n%29+%5Csim+%283n%29%21+e%5E%7B-2%7D%2F%283n%2F2%29%21288%5E%7Bn%2F2%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g_3(n) \sim (3n)! e^{-2}/(3n/2)!288^{n/2}."/></p>
<p>Following an important model of Bollobas for creating regular graphs, general formulas were developed for low degrees, By McKay, McKay and Wormald, and others that depend on the probability of a random graph in Bollobas’ model to be simple. (See pictures below). Some results were proven also for the high degree regime and McKay and Wormald gave in 1990 and 1997 unified conjectural formulas for the number of <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/>-regular graphs for a wide range of parameters. Moreover these conjectures extend to a large range of vectors of degree sequences.</p>
<p>In 2017 Anita Liebenau and Nick Wormald proved all these conjectures!!! (<a href="https://arxiv.org/abs/1702.08373">Here is a link to the paper</a>.)</p>
<p>The formula for the behavior of the number of <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/>-regular graphs with <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> vertices is remarkably elegant</p>
<p><img alt="e^{1/4}\sqrt{2}d^d(n-1-d)^{n-1-d}(n-1)^{-(n-1)}{{n-1} \choose {d}}^n" class="latex" src="https://s0.wp.com/latex.php?latex=e%5E%7B1%2F4%7D%5Csqrt%7B2%7Dd%5Ed%28n-1-d%29%5E%7Bn-1-d%7D%28n-1%29%5E%7B-%28n-1%29%7D%7B%7Bn-1%7D+%5Cchoose+%7Bd%7D%7D%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="e^{1/4}\sqrt{2}d^d(n-1-d)^{n-1-d}(n-1)^{-(n-1)}{{n-1} \choose {d}}^n"/>.</p>
<p>The full result is very general, and the method extends further in various directions.</p>
<p>Here is the link to paper: <a href="https://arxiv.org/abs/1702.08373">Asymptotic enumeration of graphs by degree sequence, and the degree sequence of a random graph</a>, by Anita Liebenau and Nick Wormald.</p>
<h3>A bit psychedelic pictures</h3>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/IMG_2149.jpg"><img alt="" class="alignnone size-medium wp-image-16681" height="225" src="https://gilkalai.files.wordpress.com/2018/12/IMG_2149.jpg?w=300&amp;h=225" width="300"/></a>    <a href="https://gilkalai.files.wordpress.com/2018/12/IMG_2150.jpg"><img alt="" class="alignnone size-medium wp-image-16682" height="225" src="https://gilkalai.files.wordpress.com/2018/12/IMG_2150.jpg?w=300&amp;h=225" width="300"/></a></p>
<p>With Nick Wormald and Yoshi Kohayakawa just before my lecture.</p>
<h2>Some important pictures from the Session</h2>
<h3>Bela Bollobas</h3>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/bela.png"><img alt="" class="alignnone size-full wp-image-16650" src="https://gilkalai.files.wordpress.com/2018/12/bela.png?w=640"/></a></p>
<p><span style="color: #ff0000;">Bela Bollobas served as the session chair</span></p>
<h3>Nick Wormald on enumeration of regular graphs</h3>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/W2.png"><img alt="" class="alignnone size-full wp-image-16660" height="406" src="https://gilkalai.files.wordpress.com/2018/12/W2.png?w=640&amp;h=406" width="640"/></a></p>
<p><span style="color: #ff0000;">Read’s formula and Bollobas model.</span></p>
<p><img alt="" class="alignnone size-full wp-image-16661" height="368" src="https://gilkalai.files.wordpress.com/2018/12/W3.png?w=640&amp;h=368" width="640"/></p>
<p><span style="color: #ff0000;">Formulas by McKay and McKay-Wormald (above and below)</span></p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/W4.png"><img alt="" class="alignnone size-full wp-image-16662" height="352" src="https://gilkalai.files.wordpress.com/2018/12/W4.png?w=640&amp;h=352" width="640"/></a></p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/W5.png"><img alt="" class="alignnone size-full wp-image-16663" height="370" src="https://gilkalai.files.wordpress.com/2018/12/W5.png?w=640&amp;h=370" width="640"/></a></p>
<p><span style="color: #ff0000;">General conjectures (above and below)</span></p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/W6.png"><img alt="" class="alignnone size-full wp-image-16664" height="365" src="https://gilkalai.files.wordpress.com/2018/12/W6.png?w=640&amp;h=365" width="640"/></a></p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/W7.png"><img alt="" class="alignnone size-full wp-image-16665" height="353" src="https://gilkalai.files.wordpress.com/2018/12/W7.png?w=640&amp;h=353" width="640"/></a></p>
<p><span style="color: #ff0000;">The Theorem by Liebenau and Wormald (above and below)</span></p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/W8.png"><img alt="" class="alignnone size-full wp-image-16666" height="356" src="https://gilkalai.files.wordpress.com/2018/12/W8.png?w=640&amp;h=356" width="640"/></a></p>
<p> </p>
<h3>Balogh and Morris on containers</h3>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/containers1.png"><img alt="" class="alignnone size-full wp-image-16614" height="360" src="https://gilkalai.files.wordpress.com/2018/12/containers1.png?w=640&amp;h=360" width="640"/></a></p>
<p><span style="color: #ff0000;">The Container theorem for triangle-free graphs</span></p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/containers2.png"><img alt="" class="alignnone size-full wp-image-16615" height="360" src="https://gilkalai.files.wordpress.com/2018/12/containers2.png?w=640&amp;h=360" width="640"/></a></p>
<p><span style="color: #ff0000;">The hypergraph container theorem for 3-uniform hypergraphs</span></p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/container3.png"><img alt="" class="alignnone size-full wp-image-16616" height="360" src="https://gilkalai.files.wordpress.com/2018/12/container3.png?w=640&amp;h=360" width="640"/></a></p>
<p><span style="color: #ff0000;">The hypergraph container theorem in full generality.</span></p>
<p> </p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/container4.png"><img alt="" class="alignnone size-full wp-image-16653" height="371" src="https://gilkalai.files.wordpress.com/2018/12/container4.png?w=640&amp;h=371" width="640"/></a></p>
<p><span style="color: #ff0000;">An application for the number of subsets of integers without k-term arithmetic progressions.</span></p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/containers5.png"><img alt="" class="alignnone size-full wp-image-16654" height="348" src="https://gilkalai.files.wordpress.com/2018/12/containers5.png?w=640&amp;h=348" width="640"/></a></p>
<p><span style="color: #ff0000;">What was known and expected on the (4,3) problem (above) and the new breakthrough (below)</span></p>
<p> </p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/containers6.png"><img alt="" class="alignnone size-full wp-image-16655" height="368" src="https://gilkalai.files.wordpress.com/2018/12/containers6.png?w=640&amp;h=368" width="640"/></a></p>
<p> </p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/containers7.png"><img alt="" class="alignnone size-full wp-image-16656" height="360" src="https://gilkalai.files.wordpress.com/2018/12/containers7.png?w=640&amp;h=360" width="640"/></a></p>
<p><span style="color: #ff0000;">Applications of the container method</span></p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/container8.png"><img alt="" class="alignnone size-full wp-image-16690" height="332" src="https://gilkalai.files.wordpress.com/2018/12/container8.png?w=640&amp;h=332" width="640"/></a></p>
<h3>June Huh on the standard conjectures</h3>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/icm2018-huh1.png"><img alt="" class="alignnone size-full wp-image-16607" height="360" src="https://gilkalai.files.wordpress.com/2018/12/icm2018-huh1.png?w=640&amp;h=360" width="640"/></a></p>
<p><span style="color: #ff0000;">Five seemingly unrelated mathematical objects</span></p>
<p> </p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/icm2018-huh3.png"><img alt="" class="alignnone size-full wp-image-16609" height="360" src="https://gilkalai.files.wordpress.com/2018/12/icm2018-huh3.png?w=640&amp;h=360" width="640"/></a></p>
<p><span style="color: #ff0000;">Poincare duality (PD), Hard Lefschetz (HL), and Hodge Riemann (HR).</span></p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/icm-huh5.png"><img alt="" class="alignnone size-full wp-image-16610" height="360" src="https://gilkalai.files.wordpress.com/2018/12/icm-huh5.png?w=640&amp;h=360" width="640"/></a></p>
<p><span style="color: #ff0000;">A 1964 letter from Serre to Grothendieck on young Bombieri</span></p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/icm-huh6.png"><img alt="" class="alignnone size-full wp-image-16611" height="360" src="https://gilkalai.files.wordpress.com/2018/12/icm-huh6.png?w=640&amp;h=360" width="640"/></a></p>
<p><span style="color: #ff0000;">The algebraic setting for the standard conjectures. </span></p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/icm2018-huh9.png"><img alt="" class="alignnone size-full wp-image-16612" height="360" src="https://gilkalai.files.wordpress.com/2018/12/icm2018-huh9.png?w=640&amp;h=360" width="640"/></a></p>
<p><span style="color: #ff0000;">Five cases were the standard conjectures are known and the original open case.</span></p></div>
    </content>
    <updated>2018-12-24T20:00:59Z</updated>
    <published>2018-12-24T20:00:59Z</published>
    <category term="Combinatorics"/>
    <category term="ICM2018"/>
    <category term="Anita Libenau"/>
    <category term="J&#xF3;zef Balogh"/>
    <category term="June Huh"/>
    <category term="Nick Wormald"/>
    <category term="Rob Morris"/>
    <category term="Wojtek Samotij"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-01-07T23:27:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=7021</id>
    <link href="https://windowsontheory.org/2018/12/23/introduction-to-quantum-walks/" rel="alternate" type="text/html"/>
    <title>Introduction to Quantum Walks</title>
    <summary>author: Beatrice Nash Abstract In this blog post, we give a broad overview of quantum walks and some quantum walks-based algorithms, including traversal of the glued trees graph, search, and element distinctness [3; 7; 1]. Quantum walks can be viewed as a model for quantum computation, providing an advantage over classical and other non-quantum walks […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><hr class="wp-block-separator"/>



<p>author: Beatrice Nash</p>



<p>Abstract</p>



<p>In this blog post, we give a broad overview of quantum walks and some quantum walks-based algorithms, including traversal of the glued trees graph, search, and element distinctness [3; 7; 1]. Quantum walks can be viewed as a model for quantum computation, providing an advantage over classical and other non-quantum walks based algorithms for certain applications.</p>



<h1>Continuous time quantum walks</h1>



<p>We begin our discussion of quantum walks by introducing the quantum analog of the continuous random walk. First, we review the behavior of the classical continuous random walk in order to develop the definition of the continuous quantum walk.</p>



<p>Take a graph <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/> with vertices <img alt="V" class="latex" src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="V"/> and edges <img alt="E" class="latex" src="https://s0.wp.com/latex.php?latex=E&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="E"/>. The adjacency matrix <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> of <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/> is defined as follows:</p>



<p><img alt="A_{i,j} = \begin{cases} 1 \quad &amp;\text{if   } (i,j) \in E \\ 0 \quad &amp;\text{otherwise}. \end{cases}" class="latex" src="https://s0.wp.com/latex.php?latex=A_%7Bi%2Cj%7D+%3D+%5Cbegin%7Bcases%7D+1+%5Cquad+%26%5Ctext%7Bif+++%7D+%28i%2Cj%29+%5Cin+E+%5C%5C+0+%5Cquad+%26%5Ctext%7Botherwise%7D.+%5Cend%7Bcases%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_{i,j} = \begin{cases} 1 \quad &amp;\text{if   } (i,j) \in E \\ 0 \quad &amp;\text{otherwise}. \end{cases}"/></p>



<p>And the Laplacian <img alt="L" class="latex" src="https://s0.wp.com/latex.php?latex=L&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="L"/> is given by:</p>



<p><img alt="L_{i,j} = \begin{cases} -\text{degree}(i) \quad &amp;\text{if   }  i = j \\ 1 \quad &amp;\text{if   } (i,j) \in E \\ 0 \quad &amp;\text{otherwise}. \end{cases}" class="latex" src="https://s0.wp.com/latex.php?latex=L_%7Bi%2Cj%7D+%3D+%5Cbegin%7Bcases%7D+-%5Ctext%7Bdegree%7D%28i%29+%5Cquad+%26%5Ctext%7Bif+++%7D++i+%3D+j+%5C%5C+1+%5Cquad+%26%5Ctext%7Bif+++%7D+%28i%2Cj%29+%5Cin+E+%5C%5C+0+%5Cquad+%26%5Ctext%7Botherwise%7D.+%5Cend%7Bcases%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="L_{i,j} = \begin{cases} -\text{degree}(i) \quad &amp;\text{if   }  i = j \\ 1 \quad &amp;\text{if   } (i,j) \in E \\ 0 \quad &amp;\text{otherwise}. \end{cases}"/></p>



<p>The Laplacian determines the behavior of the classical continuous random walk, which is described by a length <img alt="|V|" class="latex" src="https://s0.wp.com/latex.php?latex=%7CV%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|V|"/> vector of probabilities, <strong>p</strong>(t). The <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/>th entry of <strong>p</strong>(t) represents the probability of being at vertex <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/> at time <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t"/>. <strong>p</strong>(t) is given by the following differential equation:</p>



<p><img alt="\begin{aligned} \frac{\text{d}}{\text{dt}} \text{p}_{i}(\text{t}) = \underset{(i,j) \in E}{\sum} L_{i,j} \text{p}_{j}(\text{t}),\end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cfrac%7B%5Ctext%7Bd%7D%7D%7B%5Ctext%7Bdt%7D%7D+%5Ctext%7Bp%7D_%7Bi%7D%28%5Ctext%7Bt%7D%29+%3D+%5Cunderset%7B%28i%2Cj%29+%5Cin+E%7D%7B%5Csum%7D+L_%7Bi%2Cj%7D+%5Ctext%7Bp%7D_%7Bj%7D%28%5Ctext%7Bt%7D%29%2C%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \frac{\text{d}}{\text{dt}} \text{p}_{i}(\text{t}) = \underset{(i,j) \in E}{\sum} L_{i,j} \text{p}_{j}(\text{t}),\end{aligned}"/></p>



<p>which gives the solution <img alt="\textbf{p}(t) = e^{Lt}\textbf{p}(0)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctextbf%7Bp%7D%28t%29+%3D+e%5E%7BLt%7D%5Ctextbf%7Bp%7D%280%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\textbf{p}(t) = e^{Lt}\textbf{p}(0)"/>.</p>



<p>Recalling the Schrödinger equation <img alt="i \frac{\text{d}}{\text{dt}} \left|\psi\right&gt;= H \left|\psi\right&gt;" class="latex" src="https://s0.wp.com/latex.php?latex=i+%5Cfrac%7B%5Ctext%7Bd%7D%7D%7B%5Ctext%7Bdt%7D%7D+%5Cleft%7C%5Cpsi%5Cright%3E%3D+H+%5Cleft%7C%5Cpsi%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i \frac{\text{d}}{\text{dt}} \left|\psi\right&gt;= H \left|\psi\right&gt;"/>, one can see that by inserting a factor of <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/> on the left hand side of the equation for <strong>p</strong>(t) above, the Laplacian can be treated as a Hamiltonian. One can see that the Laplacian preserves the normalization of the state of the system. Then, the solution to the differential equation:</p>



<p><img alt="\begin{aligned} i \frac{\text{d}}{\text{dt}} \psi_{i}(\text{t}) = \underset{(i,j) \in E}{\sum} L_{i,j} \psi_{j}(\text{t})\end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+i+%5Cfrac%7B%5Ctext%7Bd%7D%7D%7B%5Ctext%7Bdt%7D%7D+%5Cpsi_%7Bi%7D%28%5Ctext%7Bt%7D%29+%3D+%5Cunderset%7B%28i%2Cj%29+%5Cin+E%7D%7B%5Csum%7D+L_%7Bi%2Cj%7D+%5Cpsi_%7Bj%7D%28%5Ctext%7Bt%7D%29%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} i \frac{\text{d}}{\text{dt}} \psi_{i}(\text{t}) = \underset{(i,j) \in E}{\sum} L_{i,j} \psi_{j}(\text{t})\end{aligned}"/>,</p>



<p>which is <img alt="\left|\psi(t)\right&gt; = e^{-iLt} \left|\psi(0)\right&gt;" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cleft%7C%5Cpsi%28t%29%5Cright%3E+%3D+e%5E%7B-iLt%7D+%5Cleft%7C%5Cpsi%280%29%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\left|\psi(t)\right&gt; = e^{-iLt} \left|\psi(0)\right&gt;"/>, determines the behavior of the quantum analog of the continuous random walk defined previously. A general quantum walk does not necessarily have to be defined by the Laplacian; it can be defined by any operator which “respects the structure of the graph,” that is, only allows transitions to between neighboring vertices in the graph or remain stationary [7]. To get a sense of how the behavior of the quantum walk differs from the classical one, we first discuss the example of the continuous time quantum walk on the line, before moving on to the discrete case.</p>



<h2>Continuous time quantum walk on the line</h2>



<p>An important example of the continuous time quantum walk is that defined on the infinite line. The eigenstates of the Laplacian operator for the graph representing the infinite line are the momentum states with eigenvalues <img alt="2(\text{cos}(p) - 1)" class="latex" src="https://s0.wp.com/latex.php?latex=2%28%5Ctext%7Bcos%7D%28p%29+-+1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2(\text{cos}(p) - 1)"/>, for <img alt="p" class="latex" src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p"/> in range <img alt="[-\pi,\pi]" class="latex" src="https://s0.wp.com/latex.php?latex=%5B-%5Cpi%2C%5Cpi%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="[-\pi,\pi]"/>. This can be seen by representing the momentum states in terms of the position states and applying the Laplacian operator:</p>



<p><img alt="\begin{aligned} \left|p\right&gt; &amp;= \underset{x}{\sum} e^{ipx} \left|x\right&gt; \\ L\left|p\right&gt; &amp;= \underset{x}{\sum} e^{ipx} \left|x+1\right&gt;+ e^{ipx} \left|x-1\right&gt; - 2e^{ipx} \left|x\right&gt; \\ &amp;= \underset{x}{\sum} (e^{ip} + e^{-ip} - 2) e^{ipx} \left|x\right&gt; \\ &amp;= 2(\text{cos}(p) - 1) \left|p\right&gt;.\end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cleft%7Cp%5Cright%3E+%26%3D+%5Cunderset%7Bx%7D%7B%5Csum%7D+e%5E%7Bipx%7D+%5Cleft%7Cx%5Cright%3E+%5C%5C+L%5Cleft%7Cp%5Cright%3E+%26%3D+%5Cunderset%7Bx%7D%7B%5Csum%7D+e%5E%7Bipx%7D+%5Cleft%7Cx%2B1%5Cright%3E%2B+e%5E%7Bipx%7D+%5Cleft%7Cx-1%5Cright%3E+-+2e%5E%7Bipx%7D+%5Cleft%7Cx%5Cright%3E+%5C%5C+%26%3D+%5Cunderset%7Bx%7D%7B%5Csum%7D+%28e%5E%7Bip%7D+%2B+e%5E%7B-ip%7D+-+2%29+e%5E%7Bipx%7D+%5Cleft%7Cx%5Cright%3E+%5C%5C+%26%3D+2%28%5Ctext%7Bcos%7D%28p%29+-+1%29+%5Cleft%7Cp%5Cright%3E.%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \left|p\right&gt; &amp;= \underset{x}{\sum} e^{ipx} \left|x\right&gt; \\ L\left|p\right&gt; &amp;= \underset{x}{\sum} e^{ipx} \left|x+1\right&gt;+ e^{ipx} \left|x-1\right&gt; - 2e^{ipx} \left|x\right&gt; \\ &amp;= \underset{x}{\sum} (e^{ip} + e^{-ip} - 2) e^{ipx} \left|x\right&gt; \\ &amp;= 2(\text{cos}(p) - 1) \left|p\right&gt;.\end{aligned}"/></p>



<p>Hence the probability distribution at time <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t"/>, <img alt="p(x,t) = |\left&lt; x\right| e^{-iLt} \left|\psi(0)\right&gt; | ^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=p%28x%2Ct%29+%3D+%7C%5Cleft%3C+x%5Cright%7C+e%5E%7B-iLt%7D+%5Cleft%7C%5Cpsi%280%29%5Cright%3E+%7C+%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p(x,t) = |\left&lt; x\right| e^{-iLt} \left|\psi(0)\right&gt; | ^{2}"/>, with initial position <img alt="\left|\psi(0)\right&gt; = \left|0\right&gt;" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cleft%7C%5Cpsi%280%29%5Cright%3E+%3D+%5Cleft%7C0%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\left|\psi(0)\right&gt; = \left|0\right&gt;"/> is given by:</p>



<p><img alt="\begin{aligned} |\left&lt; x\right| e^{-iLt} \left|0\right&gt; | ^{2} &amp;=  \bigg| \frac{1}{2\pi} \int_{-\pi}^{\pi} e^{-2it(\text{cos}p - 1)} \left&lt; x|p\right&gt; \text{d}p \bigg|^{2} \\ &amp;= \bigg| \frac{1}{2\pi} \int_{-\pi}^{\pi} e^{-2it(\text{cos}p - 1)} e^{ipx} \text{d}p \bigg|^{2} \\ &amp;= | J_{x}(2t) |^{2}.\end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7C%5Cleft%3C+x%5Cright%7C+e%5E%7B-iLt%7D+%5Cleft%7C0%5Cright%3E+%7C+%5E%7B2%7D+%26%3D++%5Cbigg%7C+%5Cfrac%7B1%7D%7B2%5Cpi%7D+%5Cint_%7B-%5Cpi%7D%5E%7B%5Cpi%7D+e%5E%7B-2it%28%5Ctext%7Bcos%7Dp+-+1%29%7D+%5Cleft%3C+x%7Cp%5Cright%3E+%5Ctext%7Bd%7Dp+%5Cbigg%7C%5E%7B2%7D+%5C%5C+%26%3D+%5Cbigg%7C+%5Cfrac%7B1%7D%7B2%5Cpi%7D+%5Cint_%7B-%5Cpi%7D%5E%7B%5Cpi%7D+e%5E%7B-2it%28%5Ctext%7Bcos%7Dp+-+1%29%7D+e%5E%7Bipx%7D+%5Ctext%7Bd%7Dp+%5Cbigg%7C%5E%7B2%7D+%5C%5C+%26%3D+%7C+J_%7Bx%7D%282t%29+%7C%5E%7B2%7D.%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} |\left&lt; x\right| e^{-iLt} \left|0\right&gt; | ^{2} &amp;=  \bigg| \frac{1}{2\pi} \int_{-\pi}^{\pi} e^{-2it(\text{cos}p - 1)} \left&lt; x|p\right&gt; \text{d}p \bigg|^{2} \\ &amp;= \bigg| \frac{1}{2\pi} \int_{-\pi}^{\pi} e^{-2it(\text{cos}p - 1)} e^{ipx} \text{d}p \bigg|^{2} \\ &amp;= | J_{x}(2t) |^{2}.\end{aligned}"/></p>



<figure class="wp-block-image is-resized"><img alt="" class="wp-image-7071" src="https://windowsontheory.files.wordpress.com/2018/12/quantum-1.png?w=451" width="451"/>Figure 1.a) Probability distribution for continuous time quantum walk on the infinite line at time <img alt="t = 80" class="latex" src="https://s0.wp.com/latex.php?latex=t+%3D+80&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t = 80"/>.</figure>



<figure class="wp-block-image is-resized"><img alt="" class="wp-image-7073" height="300" src="https://windowsontheory.files.wordpress.com/2018/12/classical-1.png?w=451&amp;h=300" width="451"/><br/>Figure 1.b) Approximate probability<br/> distribution of the continuous time random walk on the infinite line at<br/> time <img alt="t=30" class="latex" src="https://s0.wp.com/latex.php?latex=t%3D30&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t=30"/>.<br/></figure>



<p>While the probability distribution for the classical continuous time<br/> random walk on the same graph approaches, for large <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t"/>, <img alt="\frac{1}{\sqrt{4\pi t}} e^{\frac{-x^{2}}{4t}}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B%5Csqrt%7B4%5Cpi+t%7D%7D+e%5E%7B%5Cfrac%7B-x%5E%7B2%7D%7D%7B4t%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\frac{1}{\sqrt{4\pi t}} e^{\frac{-x^{2}}{4t}}"/>, or a Gaussian of width <img alt="2\sqrt{t}" class="latex" src="https://s0.wp.com/latex.php?latex=2%5Csqrt%7Bt%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2\sqrt{t}"/>. One can see that the quantum walk has its largest peaks at the extrema, with oscillations in between that decrease in amplitude as one approaches the starting position at <img alt="x=0" class="latex" src="https://s0.wp.com/latex.php?latex=x%3D0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x=0"/>. This is due to the destructive interference between states of different phases that does not occur in the classical case. The probability distribution of the classical walk, on the other hand, has no oscillations and instead a single peak centered at <img alt="x=0" class="latex" src="https://s0.wp.com/latex.php?latex=x%3D0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x=0"/>, which widens and flattens as <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t"/> increases.</p>



<h2>Walk on the glued trees graph</h2>



<p>A <em>glued tree</em> is a graph obtained by taking two binary trees of equal height and connecting each of the leaves of one of the trees to exactly two leaves of the other tree so that each node that was a leaf in one of the original trees now has degree exactly <img alt="3" class="latex" src="https://s0.wp.com/latex.php?latex=3&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="3"/>. An example of such a graph is shown in Figure 2.</p>



<figure class="wp-block-image"><img alt="" class="wp-image-7077" src="https://windowsontheory.files.wordpress.com/2018/12/glued-1.png?w=1024"/>Figure 2: An example of a glued tree graph, from [2].</figure>



<p>The time for the quantum walk on this graph to reach the right root from the left one is exponentially faster than in the classical case. Consider the classical random walk on this graph. While in the left tree, the probability of transitioning to a node in the level one to the right is twice that of transitioning to a node in the level one to the left. However, while in the right tree, the opposite is true. Therefore, one can see that in the middle of the graph, the walk will get lost, as, locally, there is no way to determine which node is part of which tree. It will instead get stuck in the cycles of identical nodes and will have exponentially small probability of reaching the right node.</p>



<p>To construct a continuous time quantum walk on this graph, we consider the graph in terms of <em>columns</em>. One can visualize the columns of Figure 2 as consisting of all the nodes equidistant from the entrance and exit nodes. If each tree is height <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>, then we label the columns <img alt="0,1,\text{...},2n,2n+1" class="latex" src="https://s0.wp.com/latex.php?latex=0%2C1%2C%5Ctext%7B...%7D%2C2n%2C2n%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="0,1,\text{...},2n,2n+1"/>, where column <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/> contains the nodes with shortest path of length <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/> from the leftmost root node. We describe the state of each column as a superposition of the states of each node in that column. The number of nodes in column <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/>, <img alt="N_{i}" class="latex" src="https://s0.wp.com/latex.php?latex=N_%7Bi%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N_{i}"/>, will be <img alt="2^{i}" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7Bi%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{i}"/> for <img alt="i \in [0,n]" class="latex" src="https://s0.wp.com/latex.php?latex=i+%5Cin+%5B0%2Cn%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i \in [0,n]"/> and <img alt="2^{2n+1-i}" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7B2n%2B1-i%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{2n+1-i}"/> for <img alt="i \in [n+1,2n+1]" class="latex" src="https://s0.wp.com/latex.php?latex=i+%5Cin+%5Bn%2B1%2C2n%2B1%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i \in [n+1,2n+1]"/>. Then, we can define the state <img alt="\left|\text{col} \; i\right&gt;" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cleft%7C%5Ctext%7Bcol%7D+%5C%3B+i%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\left|\text{col} \; i\right&gt;"/> as:</p>



<p><img alt="\begin{aligned} \left|\text{col} \; i\right&gt; = \frac{1}{\sqrt{N_{i}}} \underset{j \in \text{col} \; i}{\sum} \left|j\right&gt;.\end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cleft%7C%5Ctext%7Bcol%7D+%5C%3B+i%5Cright%3E+%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7BN_%7Bi%7D%7D%7D+%5Cunderset%7Bj+%5Cin+%5Ctext%7Bcol%7D+%5C%3B+i%7D%7B%5Csum%7D+%5Cleft%7Cj%5Cright%3E.%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \left|\text{col} \; i\right&gt; = \frac{1}{\sqrt{N_{i}}} \underset{j \in \text{col} \; i}{\sum} \left|j\right&gt;.\end{aligned}"/></p>



<p>The factor of <img alt="\frac{1}{\sqrt{N_{i}}} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B%5Csqrt%7BN_%7Bi%7D%7D%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\frac{1}{\sqrt{N_{i}}} "/>latex  ensures that the state is normalized. Since the adjacency matrix <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> of the glued tree is Hermitian, then we can treat <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> as the Hamiltonian of the system determining the behavior of the quantum walk. By acting on this state with the adjacency matrix operator <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/>, we get the result (for <img alt="i \in [1,n-1]" class="latex" src="https://s0.wp.com/latex.php?latex=i+%5Cin+%5B1%2Cn-1%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i \in [1,n-1]"/>):</p>



<p><img alt="\begin{aligned} A\left|\text{col} \; i\right&gt;  &amp;= 2\frac{\sqrt{N_{i-1}}}{\sqrt{N_{i}}} \left|\text{col} \; i-1\right&gt; + \frac{\sqrt{N_{i+1}}}{\sqrt{N_{i}}} \left|\text{col} \; i+1\right&gt; \\ &amp;= \sqrt{2} \left|\text{col} \; i-1\right&gt; + \sqrt{2} \left|\text{col} \; i+1\right&gt;.\end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+A%5Cleft%7C%5Ctext%7Bcol%7D+%5C%3B+i%5Cright%3E++%26%3D+2%5Cfrac%7B%5Csqrt%7BN_%7Bi-1%7D%7D%7D%7B%5Csqrt%7BN_%7Bi%7D%7D%7D+%5Cleft%7C%5Ctext%7Bcol%7D+%5C%3B+i-1%5Cright%3E+%2B+%5Cfrac%7B%5Csqrt%7BN_%7Bi%2B1%7D%7D%7D%7B%5Csqrt%7BN_%7Bi%7D%7D%7D+%5Cleft%7C%5Ctext%7Bcol%7D+%5C%3B+i%2B1%5Cright%3E+%5C%5C+%26%3D+%5Csqrt%7B2%7D+%5Cleft%7C%5Ctext%7Bcol%7D+%5C%3B+i-1%5Cright%3E+%2B+%5Csqrt%7B2%7D+%5Cleft%7C%5Ctext%7Bcol%7D+%5C%3B+i%2B1%5Cright%3E.%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} A\left|\text{col} \; i\right&gt;  &amp;= 2\frac{\sqrt{N_{i-1}}}{\sqrt{N_{i}}} \left|\text{col} \; i-1\right&gt; + \frac{\sqrt{N_{i+1}}}{\sqrt{N_{i}}} \left|\text{col} \; i+1\right&gt; \\ &amp;= \sqrt{2} \left|\text{col} \; i-1\right&gt; + \sqrt{2} \left|\text{col} \; i+1\right&gt;.\end{aligned}"/><br/></p>



<p>Then for <img alt="i \in [n+2,2n]" class="latex" src="https://s0.wp.com/latex.php?latex=i+%5Cin+%5Bn%2B2%2C2n%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i \in [n+2,2n]"/>, we get the same result, because of symmetry.<br/></p>



<p>For <img alt="i = n" class="latex" src="https://s0.wp.com/latex.php?latex=i+%3D+n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i = n"/>:</p>



<p><img alt="\begin{aligned} A\left|\text{col} \; n\right&gt; = \sqrt{2} \left|\text{col} \;n-1\right&gt; + 2 \left|\text{col} \; n\right&gt;.\end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+A%5Cleft%7C%5Ctext%7Bcol%7D+%5C%3B+n%5Cright%3E+%3D+%5Csqrt%7B2%7D+%5Cleft%7C%5Ctext%7Bcol%7D+%5C%3Bn-1%5Cright%3E+%2B+2+%5Cleft%7C%5Ctext%7Bcol%7D+%5C%3B+n%5Cright%3E.%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} A\left|\text{col} \; n\right&gt; = \sqrt{2} \left|\text{col} \;n-1\right&gt; + 2 \left|\text{col} \; n\right&gt;.\end{aligned}"/></p>



<p>The case of <img alt="i = n+1" class="latex" src="https://s0.wp.com/latex.php?latex=i+%3D+n%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i = n+1"/> is symmetric. One can see that the walk on this graph is equivalent to the quantum walk on the finite line with nodes corresponding to the columns. All of the edges, excluding that between columns <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> and <img alt="n+1" class="latex" src="https://s0.wp.com/latex.php?latex=n%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n+1"/>, have weight <img alt="\sqrt{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csqrt%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sqrt{2}"/>. The edge between column <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> and <img alt="n+1" class="latex" src="https://s0.wp.com/latex.php?latex=n%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n+1"/> has weight <img alt="2" class="latex" src="https://s0.wp.com/latex.php?latex=2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2"/>.</p>



<p>The probability distribution of the quantum walk on this line can be roughly approximated using the infinite line. In the case of the infinite line, the probability distribution can be seen as a wave propagating with speed linear in the time <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t"/>. Thus, in time linear in <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>, the probability that the state is measured at distance <img alt="2n+1" class="latex" src="https://s0.wp.com/latex.php?latex=2n%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2n+1"/> from the starting state is <img alt="\frac{1}{\text{poly} \; n}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B%5Ctext%7Bpoly%7D+%5C%3B+n%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\frac{1}{\text{poly} \; n}"/>. In [3] it is shown that the fact that the line is finite and has a single differently weighted edge from the others (that between <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> and <img alt="n+1" class="latex" src="https://s0.wp.com/latex.php?latex=n%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n+1"/>) does not change the fact that in polynomial time, the quantum walk will travel from the left root node to the right one, although in this case there is no limiting distribution as the peaks oscillate. This was the first result that gives an exponential speed up over the classical case using quantum walks.</p>



<figure class="wp-block-image is-resized"><img alt="" class="wp-image-7082" height="291" src="https://windowsontheory.files.wordpress.com/2018/12/glued-tree-1.png?w=451&amp;h=291" width="451"/>Figure 3: Although the quantum walk on the glued trees graph does not have a limiting distribution, this is an example of the resulting probability distribution at time <img alt="t=30" class="latex" src="https://s0.wp.com/latex.php?latex=t%3D30&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t=30"/> for a <img alt="n=4" class="latex" src="https://s0.wp.com/latex.php?latex=n%3D4&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n=4"/> column glued tree graph.  The x-axis corresponds to the columns.  One can see that the probability of being at the columns at either extremes is significantly larger than that of being in the middle of the graph. In contrast, the classical random walk takes exponential time to ever reach the exit root node.</figure>



<h1>Discrete time quantum walks</h1>



<p>In this section, we will first give an introduction to the discrete quantum walk, including the discrete quantum walk on the line and the Markov chain quantum walk, as defined in [7]. Next, we discuss how Grover search can be viewed as a quantum walk algorithm, which leads us into Ambainis’s quantum-walks based algorithm from [1] for the element distinctness problem, which gives a speed up over classical and other quantum non-walks based algorithms.</p>



<p>The discrete time quantum walk is defined by two operators: the <em>coin flip</em> operator, and the <em>shift</em> operator. The coin flip operator <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/> determines the direction of the walk, while the shift operator <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S"/> makes the transition to the new state conditioned on the result of the coin flip. The Hilbert space governing the walk is <img alt="\mathcal{H} = \mathcal{H}{C} \otimes \mathcal{H}{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D+%3D+%5Cmathcal%7BH%7D%7BC%7D+%5Cotimes+%5Cmathcal%7BH%7D%7BS%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{H} = \mathcal{H}{C} \otimes \mathcal{H}{S}"/>, where <img alt="\mathcal{H}{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D%7BC%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{H}{C}"/> corresponds to the space associated with the result of the coin flip operator, and <img alt="\mathcal{H}{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D%7BS%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{H}{S}"/> corresponds to the locations in the graph on which the walk is defined.</p>



<p>For example, consider the discrete time walk on the infinite line. Since there are two possible directions (left or right), then the Hilbert space associated with the coin flip operator is two dimensional. In the unbiased case, the coin flip is the Hadamard operator,</p>



<p><img alt="\begin{aligned} H = \frac{1}{\sqrt{2}} \begin{bmatrix} 1 &amp; 1 \\ 1 &amp; -1  \end{bmatrix},\end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+H+%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D+%5Cbegin%7Bbmatrix%7D+1+%26+1+%5C%5C+1+%26+-1++%5Cend%7Bbmatrix%7D%2C%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} H = \frac{1}{\sqrt{2}} \begin{bmatrix} 1 &amp; 1 \\ 1 &amp; -1  \end{bmatrix},\end{aligned}"/></p>



<p>and shift operator that produces the transition from state <img alt="\left|j\right&gt;" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cleft%7Cj%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\left|j\right&gt;"/> to <img alt="\left|j+1\right&gt;" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cleft%7Cj%2B1%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\left|j+1\right&gt;"/> or <img alt="\left|j-1\right&gt;" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cleft%7Cj-1%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\left|j-1\right&gt;"/>,<br/> conditioned on the result of the coin flip, is <img alt="S = \left|0\right&gt;\left&lt; 0\right| \otimes \underset{j}{\sum} \left|j+1\right&gt; \left&lt; j\right| + \left|1\right&gt;\left&lt; 1\right| \otimes \underset{j}{\sum} \left|j - 1\right&gt; \left&lt; j\right|" class="latex" src="https://s0.wp.com/latex.php?latex=S+%3D+%5Cleft%7C0%5Cright%3E%5Cleft%3C+0%5Cright%7C+%5Cotimes+%5Cunderset%7Bj%7D%7B%5Csum%7D+%5Cleft%7Cj%2B1%5Cright%3E+%5Cleft%3C+j%5Cright%7C+%2B+%5Cleft%7C1%5Cright%3E%5Cleft%3C+1%5Cright%7C+%5Cotimes+%5Cunderset%7Bj%7D%7B%5Csum%7D+%5Cleft%7Cj+-+1%5Cright%3E+%5Cleft%3C+j%5Cright%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S = \left|0\right&gt;\left&lt; 0\right| \otimes \underset{j}{\sum} \left|j+1\right&gt; \left&lt; j\right| + \left|1\right&gt;\left&lt; 1\right| \otimes \underset{j}{\sum} \left|j - 1\right&gt; \left&lt; j\right|"/>.</p>



<p>Each step of the walk is determined by an application of the unitary<br/> operator <img alt="U = S \cdot (H \otimes I)" class="latex" src="https://s0.wp.com/latex.php?latex=U+%3D+S+%5Ccdot+%28H+%5Cotimes+I%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U = S \cdot (H \otimes I)"/>. If the walk starts at position<br/> <img alt="\left|x\right&gt;" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cleft%7Cx%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\left|x\right&gt;"/>, then measuring the state after one application of <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/> gives <img alt="\left|x+1\right&gt;" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cleft%7Cx%2B1%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\left|x+1\right&gt;"/> with probability <img alt="\frac{1}{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\frac{1}{2}"/> and <img alt="\left|x-1\right&gt;" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cleft%7Cx-1%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\left|x-1\right&gt;"/> with probability <img alt="\frac{1}{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\frac{1}{2}"/>. This is exactly the same as the case of the classical random walk on the infinite line; the difference between the two walks becomes apparent after a few steps.</p>



<p>For example, the result of the walk starting at state <img alt="\left|\psi(0)\right&gt; = \left|0\right&gt;\left|0\right&gt;" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cleft%7C%5Cpsi%280%29%5Cright%3E+%3D+%5Cleft%7C0%5Cright%3E%5Cleft%7C0%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\left|\psi(0)\right&gt; = \left|0\right&gt;\left|0\right&gt;"/> after 4 steps gives:</p>



<p><img alt="\begin{aligned} \left|\psi(1)\right&gt; &amp;= \frac{1}{\sqrt{2}}\left( \left|0\right&gt;\left|1\right&gt; + \left|1\right&gt;\left|-1\right&gt; \right) \\ \left|\psi(2)\right&gt; &amp;= \frac{1}{2}\left( \left|0\right&gt;\left|2\right&gt; + \left|1\right&gt;\left|0\right&gt; + \left|0\right&gt;\left|0\right&gt; - \left|1\right&gt;\left|-2\right&gt; \right) \\ \left|\psi(3)\right&gt; &amp;= \frac{1}{2\sqrt{2}}\left(\left|0\right&gt;\left|3\right&gt; + \left|1\right&gt;\left|1\right&gt; + 2\left|0\right&gt;\left|1\right&gt; -\left|0\right&gt;\left|-1\right&gt; + \left|1\right&gt;\left|-3\right&gt; \right) \\ \left|\psi(4)\right&gt; &amp;=  \frac{1}{4} (\left|0\right&gt;\left|4\right&gt; + \left|1\right&gt;\left|2\right&gt; + 3\left|0\right&gt;\left|2\right&gt; + \left|1\right&gt;\left|0\right&gt; -\left|0\right&gt;\left|0\right&gt; -\left|1\right&gt;\left|-2\right&gt; +\left|0\right&gt;\left|-2\right&gt;-\left|1\right&gt;\left|-4\right&gt;).\end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cleft%7C%5Cpsi%281%29%5Cright%3E+%26%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%5Cleft%28+%5Cleft%7C0%5Cright%3E%5Cleft%7C1%5Cright%3E+%2B+%5Cleft%7C1%5Cright%3E%5Cleft%7C-1%5Cright%3E+%5Cright%29+%5C%5C+%5Cleft%7C%5Cpsi%282%29%5Cright%3E+%26%3D+%5Cfrac%7B1%7D%7B2%7D%5Cleft%28+%5Cleft%7C0%5Cright%3E%5Cleft%7C2%5Cright%3E+%2B+%5Cleft%7C1%5Cright%3E%5Cleft%7C0%5Cright%3E+%2B+%5Cleft%7C0%5Cright%3E%5Cleft%7C0%5Cright%3E+-+%5Cleft%7C1%5Cright%3E%5Cleft%7C-2%5Cright%3E+%5Cright%29+%5C%5C+%5Cleft%7C%5Cpsi%283%29%5Cright%3E+%26%3D+%5Cfrac%7B1%7D%7B2%5Csqrt%7B2%7D%7D%5Cleft%28%5Cleft%7C0%5Cright%3E%5Cleft%7C3%5Cright%3E+%2B+%5Cleft%7C1%5Cright%3E%5Cleft%7C1%5Cright%3E+%2B+2%5Cleft%7C0%5Cright%3E%5Cleft%7C1%5Cright%3E+-%5Cleft%7C0%5Cright%3E%5Cleft%7C-1%5Cright%3E+%2B+%5Cleft%7C1%5Cright%3E%5Cleft%7C-3%5Cright%3E+%5Cright%29+%5C%5C+%5Cleft%7C%5Cpsi%284%29%5Cright%3E+%26%3D++%5Cfrac%7B1%7D%7B4%7D+%28%5Cleft%7C0%5Cright%3E%5Cleft%7C4%5Cright%3E+%2B+%5Cleft%7C1%5Cright%3E%5Cleft%7C2%5Cright%3E+%2B+3%5Cleft%7C0%5Cright%3E%5Cleft%7C2%5Cright%3E+%2B+%5Cleft%7C1%5Cright%3E%5Cleft%7C0%5Cright%3E+-%5Cleft%7C0%5Cright%3E%5Cleft%7C0%5Cright%3E+-%5Cleft%7C1%5Cright%3E%5Cleft%7C-2%5Cright%3E+%2B%5Cleft%7C0%5Cright%3E%5Cleft%7C-2%5Cright%3E-%5Cleft%7C1%5Cright%3E%5Cleft%7C-4%5Cright%3E%29.%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \left|\psi(1)\right&gt; &amp;= \frac{1}{\sqrt{2}}\left( \left|0\right&gt;\left|1\right&gt; + \left|1\right&gt;\left|-1\right&gt; \right) \\ \left|\psi(2)\right&gt; &amp;= \frac{1}{2}\left( \left|0\right&gt;\left|2\right&gt; + \left|1\right&gt;\left|0\right&gt; + \left|0\right&gt;\left|0\right&gt; - \left|1\right&gt;\left|-2\right&gt; \right) \\ \left|\psi(3)\right&gt; &amp;= \frac{1}{2\sqrt{2}}\left(\left|0\right&gt;\left|3\right&gt; + \left|1\right&gt;\left|1\right&gt; + 2\left|0\right&gt;\left|1\right&gt; -\left|0\right&gt;\left|-1\right&gt; + \left|1\right&gt;\left|-3\right&gt; \right) \\ \left|\psi(4)\right&gt; &amp;=  \frac{1}{4} (\left|0\right&gt;\left|4\right&gt; + \left|1\right&gt;\left|2\right&gt; + 3\left|0\right&gt;\left|2\right&gt; + \left|1\right&gt;\left|0\right&gt; -\left|0\right&gt;\left|0\right&gt; -\left|1\right&gt;\left|-2\right&gt; +\left|0\right&gt;\left|-2\right&gt;-\left|1\right&gt;\left|-4\right&gt;).\end{aligned}"/></p>



<p>One can see that the distribution is becoming increasingly skewed<br/> towards the right, while in the classical case the distribution will be<br/> symmetric around the starting position. This is due to the destructive<br/> interference discussed earlier. The distribution after <img alt="t = 20" class="latex" src="https://s0.wp.com/latex.php?latex=t+%3D+20&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t = 20"/> time<br/> steps is shown in Figure 4.</p>



<figure class="wp-block-image is-resized"><img alt="" class="wp-image-7090" height="291" src="https://windowsontheory.files.wordpress.com/2018/12/discrete.png?w=451&amp;h=291" width="451"/>Figure 4: Distribution at time <img alt="t = 20" class="latex" src="https://s0.wp.com/latex.php?latex=t+%3D+20&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t = 20"/>, with <img alt="20" class="latex" src="https://s0.wp.com/latex.php?latex=20&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="20"/> on the x-axis corresponding to position <img alt="0" class="latex" src="https://s0.wp.com/latex.php?latex=0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="0"/>.</figure>



<p>Now, consider the walk starting at state <img alt="\left|\psi(0)\right&gt; = -\left|1\right&gt;\left|0\right&gt;" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cleft%7C%5Cpsi%280%29%5Cright%3E+%3D+-%5Cleft%7C1%5Cright%3E%5Cleft%7C0%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\left|\psi(0)\right&gt; = -\left|1\right&gt;\left|0\right&gt;"/>:</p>



<p><img alt="\begin{aligned}\left|\psi(1)\right&gt; &amp;= \frac{1}{\sqrt{2}}\left( -\left|0\right&gt;\left|1\right&gt; + \left|1\right&gt;\left|-1\right&gt; \right) \\ \left|\psi(2)\right&gt; &amp;= \frac{1}{2}\left( -\left|0\right&gt;\left|2\right&gt; - \left|1\right&gt;\left|0\right&gt; + \left|0\right&gt;\left|0\right&gt; - \left|1\right&gt;\left|-2\right&gt; \right) \\ \left|\psi(3)\right&gt; &amp;= \frac{1}{2\sqrt{2}}\left(-\left|0\right&gt;\left|3\right&gt; - \left|1\right&gt;\left|1\right&gt; + 2\left|1\right&gt;\left|-1\right&gt; - \left|0\right&gt;\left|-1\right&gt; + \left|1\right&gt;\left|-3\right&gt; \right) \\ \left|\psi(4)\right&gt; &amp;=  \frac{1}{4} (-\left|0\right&gt;\left|4\right&gt; -\left|1\right&gt;\left|2\right&gt; - \left|0\right&gt;\left|2\right&gt; + \left|1\right&gt;\left|0\right&gt; + \left|0\right&gt;\left|0\right&gt; -3\left|1\right&gt;\left|-2\right&gt; + \left|0\right&gt;\left|-2\right&gt; - \left|1\right&gt;\left|-4\right&gt;).\end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D%5Cleft%7C%5Cpsi%281%29%5Cright%3E+%26%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%5Cleft%28+-%5Cleft%7C0%5Cright%3E%5Cleft%7C1%5Cright%3E+%2B+%5Cleft%7C1%5Cright%3E%5Cleft%7C-1%5Cright%3E+%5Cright%29+%5C%5C+%5Cleft%7C%5Cpsi%282%29%5Cright%3E+%26%3D+%5Cfrac%7B1%7D%7B2%7D%5Cleft%28+-%5Cleft%7C0%5Cright%3E%5Cleft%7C2%5Cright%3E+-+%5Cleft%7C1%5Cright%3E%5Cleft%7C0%5Cright%3E+%2B+%5Cleft%7C0%5Cright%3E%5Cleft%7C0%5Cright%3E+-+%5Cleft%7C1%5Cright%3E%5Cleft%7C-2%5Cright%3E+%5Cright%29+%5C%5C+%5Cleft%7C%5Cpsi%283%29%5Cright%3E+%26%3D+%5Cfrac%7B1%7D%7B2%5Csqrt%7B2%7D%7D%5Cleft%28-%5Cleft%7C0%5Cright%3E%5Cleft%7C3%5Cright%3E+-+%5Cleft%7C1%5Cright%3E%5Cleft%7C1%5Cright%3E+%2B+2%5Cleft%7C1%5Cright%3E%5Cleft%7C-1%5Cright%3E+-+%5Cleft%7C0%5Cright%3E%5Cleft%7C-1%5Cright%3E+%2B+%5Cleft%7C1%5Cright%3E%5Cleft%7C-3%5Cright%3E+%5Cright%29+%5C%5C+%5Cleft%7C%5Cpsi%284%29%5Cright%3E+%26%3D++%5Cfrac%7B1%7D%7B4%7D+%28-%5Cleft%7C0%5Cright%3E%5Cleft%7C4%5Cright%3E+-%5Cleft%7C1%5Cright%3E%5Cleft%7C2%5Cright%3E+-+%5Cleft%7C0%5Cright%3E%5Cleft%7C2%5Cright%3E+%2B+%5Cleft%7C1%5Cright%3E%5Cleft%7C0%5Cright%3E+%2B+%5Cleft%7C0%5Cright%3E%5Cleft%7C0%5Cright%3E+-3%5Cleft%7C1%5Cright%3E%5Cleft%7C-2%5Cright%3E+%2B+%5Cleft%7C0%5Cright%3E%5Cleft%7C-2%5Cright%3E+-+%5Cleft%7C1%5Cright%3E%5Cleft%7C-4%5Cright%3E%29.%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned}\left|\psi(1)\right&gt; &amp;= \frac{1}{\sqrt{2}}\left( -\left|0\right&gt;\left|1\right&gt; + \left|1\right&gt;\left|-1\right&gt; \right) \\ \left|\psi(2)\right&gt; &amp;= \frac{1}{2}\left( -\left|0\right&gt;\left|2\right&gt; - \left|1\right&gt;\left|0\right&gt; + \left|0\right&gt;\left|0\right&gt; - \left|1\right&gt;\left|-2\right&gt; \right) \\ \left|\psi(3)\right&gt; &amp;= \frac{1}{2\sqrt{2}}\left(-\left|0\right&gt;\left|3\right&gt; - \left|1\right&gt;\left|1\right&gt; + 2\left|1\right&gt;\left|-1\right&gt; - \left|0\right&gt;\left|-1\right&gt; + \left|1\right&gt;\left|-3\right&gt; \right) \\ \left|\psi(4)\right&gt; &amp;=  \frac{1}{4} (-\left|0\right&gt;\left|4\right&gt; -\left|1\right&gt;\left|2\right&gt; - \left|0\right&gt;\left|2\right&gt; + \left|1\right&gt;\left|0\right&gt; + \left|0\right&gt;\left|0\right&gt; -3\left|1\right&gt;\left|-2\right&gt; + \left|0\right&gt;\left|-2\right&gt; - \left|1\right&gt;\left|-4\right&gt;).\end{aligned}"/></p>



<p><br/> This distribution given by this walk is the mirror image of the first.<br/> To generate a symmetric distribution, consider the start state <img alt="\left|\psi(0)\right&gt; = \frac{1}{\sqrt{2}}(\left|0\right&gt; -i\left|1\right&gt;)\left|0\right&gt;" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cleft%7C%5Cpsi%280%29%5Cright%3E+%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%28%5Cleft%7C0%5Cright%3E+-i%5Cleft%7C1%5Cright%3E%29%5Cleft%7C0%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\left|\psi(0)\right&gt; = \frac{1}{\sqrt{2}}(\left|0\right&gt; -i\left|1\right&gt;)\left|0\right&gt;"/>. The resulting distribution after <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t"/> steps will be <img alt="p(x,t) = \frac{1}{2} p_{0}(x,t) + \frac{1}{2} p_{1}(x,t)" class="latex" src="https://s0.wp.com/latex.php?latex=p%28x%2Ct%29+%3D+%5Cfrac%7B1%7D%7B2%7D+p_%7B0%7D%28x%2Ct%29+%2B+%5Cfrac%7B1%7D%7B2%7D+p_%7B1%7D%28x%2Ct%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p(x,t) = \frac{1}{2} p_{0}(x,t) + \frac{1}{2} p_{1}(x,t)"/>, where <img alt="p_{0}(x,t)" class="latex" src="https://s0.wp.com/latex.php?latex=p_%7B0%7D%28x%2Ct%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p_{0}(x,t)"/> is the probability distribution after <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t"/> steps resulting from the start state <img alt="\psi(0) = \left|0\right&gt;\left|0\right&gt;" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpsi%280%29+%3D+%5Cleft%7C0%5Cright%3E%5Cleft%7C0%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\psi(0) = \left|0\right&gt;\left|0\right&gt;"/> and <img alt="p_{1}(x,t)" class="latex" src="https://s0.wp.com/latex.php?latex=p_%7B1%7D%28x%2Ct%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p_{1}(x,t)"/> is the probability distribution after <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t"/> steps resulting from the start state <img alt="\psi(0) = -\left|1\right&gt;\left|0\right&gt;" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpsi%280%29+%3D+-%5Cleft%7C1%5Cright%3E%5Cleft%7C0%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\psi(0) = -\left|1\right&gt;\left|0\right&gt;"/>. The result will be symmetric, with peaks near the extrema, as we saw in the continuous case.</p>



<h2>Markov chain quantum walk</h2>



<p>A reversible, ergodic Markov chain with <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> states can be represented by a <img alt="n \times n" class="latex" src="https://s0.wp.com/latex.php?latex=n+%5Ctimes+n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n \times n"/> transition matrix <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> with <img alt="P_{j,i}" class="latex" src="https://s0.wp.com/latex.php?latex=P_%7Bj%2Ci%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P_{j,i}"/> equal to the probability of transitioning from state <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/> to state <img alt="j" class="latex" src="https://s0.wp.com/latex.php?latex=j&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="j"/> and <img alt="P = P^{*}" class="latex" src="https://s0.wp.com/latex.php?latex=P+%3D+P%5E%7B%2A%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P = P^{*}"/>. Then, <img alt="p_{0}P" class="latex" src="https://s0.wp.com/latex.php?latex=p_%7B0%7DP&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p_{0}P"/>, where <img alt="p_{0}" class="latex" src="https://s0.wp.com/latex.php?latex=p_%7B0%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p_{0}"/> is an initial probability distribution over the states, gives the distribution after one step.<br/>Since <img alt="\sum_{j} P_{i,j} = 1" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csum_%7Bj%7D+P_%7Bi%2Cj%7D+%3D+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sum_{j} P_{i,j} = 1"/> for all <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/>, <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> is stochastic and thus preserves normalization.</p>



<p>There are multiple ways to define a discrete quantum walk, depending on the properties of the transition matrix and the graph on which it is defined (overview provided in [4]). Here we look at the quantum walk on a Markov chain as given in [2]. For the quantum walk on this graph, we define state <img alt="\left|i\right&gt;\left|j\right&gt;" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cleft%7Ci%5Cright%3E%5Cleft%7Cj%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\left|i\right&gt;\left|j\right&gt;"/> as the state that represents currently being at position <img alt="j" class="latex" src="https://s0.wp.com/latex.php?latex=j&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="j"/> and facing in the direction of <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/>. Then, we define the state <img alt="\left|\psi_{j}\right&gt;" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cleft%7C%5Cpsi_%7Bj%7D%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\left|\psi_{j}\right&gt;"/> as a superposition of the states associated with position <img alt="j" class="latex" src="https://s0.wp.com/latex.php?latex=j&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="j"/>:</p>



<p><img alt="\begin{aligned} \left|\psi_{i}\right&gt; = \underset{j}{\sum} \sqrt{P_{j,i}} \left|i\right&gt;\left|j\right&gt;.\end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cleft%7C%5Cpsi_%7Bi%7D%5Cright%3E+%3D+%5Cunderset%7Bj%7D%7B%5Csum%7D+%5Csqrt%7BP_%7Bj%2Ci%7D%7D+%5Cleft%7Ci%5Cright%3E%5Cleft%7Cj%5Cright%3E.%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \left|\psi_{i}\right&gt; = \underset{j}{\sum} \sqrt{P_{j,i}} \left|i\right&gt;\left|j\right&gt;.\end{aligned}"/></p>



<p>The unitary operator,</p>



<p><img alt="D = 2 \underset{i}{\sum} \left|\psi_{i}\right&gt;\left&lt; \psi_{i}\right| - I" class="latex" src="https://s0.wp.com/latex.php?latex=D+%3D+2+%5Cunderset%7Bi%7D%7B%5Csum%7D+%5Cleft%7C%5Cpsi_%7Bi%7D%5Cright%3E%5Cleft%3C+%5Cpsi_%7Bi%7D%5Cright%7C+-+I&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D = 2 \underset{i}{\sum} \left|\psi_{i}\right&gt;\left&lt; \psi_{i}\right| - I"/>,</p>



<p>acts as a coin flip for the walk on this graph. Since <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> is reversible, we can let the shift operator be the unitary <img alt="SWAP" class="latex" src="https://s0.wp.com/latex.php?latex=SWAP&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="SWAP"/> operator:</p>



<p><img alt="SWAP = \underset{i,j}{\sum} \left|i,j\right&gt;\left&lt; j,i\right|" class="latex" src="https://s0.wp.com/latex.php?latex=SWAP+%3D+%5Cunderset%7Bi%2Cj%7D%7B%5Csum%7D+%5Cleft%7Ci%2Cj%5Cright%3E%5Cleft%3C+j%2Ci%5Cright%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="SWAP = \underset{i,j}{\sum} \left|i,j\right&gt;\left&lt; j,i\right|"/>.</p>



<p>A quantum walk can also be defined for a non-reversible Markov chain using a pair of reflection operators (the coin flip operator is an example of a reflection operator). This corresponds to the construction given in [7].</p>



<h2>Search as a quantum walk algorithm</h2>



<p>Given a black box function <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> and a set of inputs <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S"/> with <img alt="|S| = N" class="latex" src="https://s0.wp.com/latex.php?latex=%7CS%7C+%3D+N&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|S| = N"/>, say we want to find whether an input <img alt="x \in S" class="latex" src="https://s0.wp.com/latex.php?latex=x+%5Cin+S&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x \in S"/> exists for which <img alt="f(x)" class="latex" src="https://s0.wp.com/latex.php?latex=f%28x%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f(x)"/> equals some output value. We refer to the set of inputs <img alt="M" class="latex" src="https://s0.wp.com/latex.php?latex=M&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="M"/> for which this is true as marked. Classically, this requires <img alt="O(N/|M|)" class="latex" src="https://s0.wp.com/latex.php?latex=O%28N%2F%7CM%7C%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(N/|M|)"/> queries, for nonempty <img alt="M" class="latex" src="https://s0.wp.com/latex.php?latex=M&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="M"/>. Using the Grover search algorithm, this problem requires <img alt="O(\sqrt{N/|M|})" class="latex" src="https://s0.wp.com/latex.php?latex=O%28%5Csqrt%7BN%2F%7CM%7C%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(\sqrt{N/|M|})"/> quantum queries. In this section, we give a quantum walks based algorithm that also solves this problem in <img alt="O(\sqrt{N/|M|})" class="latex" src="https://s0.wp.com/latex.php?latex=O%28%5Csqrt%7BN%2F%7CM%7C%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(\sqrt{N/|M|})"/> time. If we define a doubly stochastic matrix <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> with uniform transitions, then we can construct a new transition matrix <img alt="P'" class="latex" src="https://s0.wp.com/latex.php?latex=P%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P'"/> from <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> as:</p>



<p><img alt="P_{i,j}' = \begin{cases} \frac{1}{N-1} \quad &amp;\text{if } i \neq j \text{ and } i \notin M \\0 \quad &amp;\text{if } i = j \text{ and } i \notin M \\ 1 \quad &amp;\text{if } i = j \text{ and } i \in M \\ 0 \quad &amp;\text{if } i \neq j \text{ and } i \in M. \end{cases}" class="latex" src="https://s0.wp.com/latex.php?latex=P_%7Bi%2Cj%7D%27+%3D+%5Cbegin%7Bcases%7D+%5Cfrac%7B1%7D%7BN-1%7D+%5Cquad+%26%5Ctext%7Bif+%7D+i+%5Cneq+j+%5Ctext%7B+and+%7D+i+%5Cnotin+M+%5C%5C0+%5Cquad+%26%5Ctext%7Bif+%7D+i+%3D+j+%5Ctext%7B+and+%7D+i+%5Cnotin+M+%5C%5C+1+%5Cquad+%26%5Ctext%7Bif+%7D+i+%3D+j+%5Ctext%7B+and+%7D+i+%5Cin+M+%5C%5C+0+%5Cquad+%26%5Ctext%7Bif+%7D+i+%5Cneq+j+%5Ctext%7B+and+%7D+i+%5Cin+M.+%5Cend%7Bcases%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P_{i,j}' = \begin{cases} \frac{1}{N-1} \quad &amp;\text{if } i \neq j \text{ and } i \notin M \\0 \quad &amp;\text{if } i = j \text{ and } i \notin M \\ 1 \quad &amp;\text{if } i = j \text{ and } i \in M \\ 0 \quad &amp;\text{if } i \neq j \text{ and } i \in M. \end{cases}"/></p>



<p>Then, when the state of the first register is unmarked, the operator <img alt="D" class="latex" src="https://s0.wp.com/latex.php?latex=D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D"/> defined in the previous section acts as a diffusion over its neighbors. When the state in the first register is marked, then <img alt="D" class="latex" src="https://s0.wp.com/latex.php?latex=D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D"/> will act as the operator <img alt="-I" class="latex" src="https://s0.wp.com/latex.php?latex=-I&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="-I"/>, and the walk stops, as a marked state has been reached. This requires two queries to the black box function: one to check whether the input is marked, and then another to uncompute. By rearranging the order of the columns in <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> so that the columns corresponding to the non-marked elements come before the columns corresponding to the marked elements, we get:</p>



<p><img alt="\begin{aligned} P' = \begin{pmatrix} P_{0} &amp; 0 \\ P_{1} &amp; I \end{pmatrix},\end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+P%27+%3D+%5Cbegin%7Bpmatrix%7D+P_%7B0%7D+%26+0+%5C%5C+P_%7B1%7D+%26+I+%5Cend%7Bpmatrix%7D%2C%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} P' = \begin{pmatrix} P_{0} &amp; 0 \\ P_{1} &amp; I \end{pmatrix},\end{aligned}"/></p>



<p>where <img alt="P_{0}" class="latex" src="https://s0.wp.com/latex.php?latex=P_%7B0%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P_{0}"/> gives the transitions between non-marked elements and <img alt="P_{1}" class="latex" src="https://s0.wp.com/latex.php?latex=P_%7B1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P_{1}"/> gives the transitions from non-marked to marked elements.</p>



<p>We now look at the hitting time of the classical random walk. Assume<br/> that there is zero probability of starting at a marked vertex. Then, we<br/> can write the starting distribution <img alt="p" class="latex" src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p"/>, where the last <img alt="|M|" class="latex" src="https://s0.wp.com/latex.php?latex=%7CM%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|M|"/> elements of <img alt="p" class="latex" src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p"/>, corresponding to the marked elements, are zero, as<br/> <img alt="p = \underset{\lambda}{\sum} \alpha_{\lambda} \left|\lambda\right&gt;" class="latex" src="https://s0.wp.com/latex.php?latex=p+%3D+%5Cunderset%7B%5Clambda%7D%7B%5Csum%7D+%5Calpha_%7B%5Clambda%7D+%5Cleft%7C%5Clambda%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p = \underset{\lambda}{\sum} \alpha_{\lambda} \left|\lambda\right&gt;"/>, where <img alt="\lambda" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda"/> are the eigenvalues of <img alt="P_{0}" class="latex" src="https://s0.wp.com/latex.php?latex=P_%7B0%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P_{0}"/>, and <img alt="\left|\lambda\right&gt;" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cleft%7C%5Clambda%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\left|\lambda\right&gt;"/> are the corresponding eigenvectors, with the last <img alt="|M|" class="latex" src="https://s0.wp.com/latex.php?latex=%7CM%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|M|"/> entries zero. Let <img alt="\lambda^{}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda%5E%7B%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda^{}"/> be the principal (largest) eigenvalue. Then, the probability that, after <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t"/> steps, a marked element has not yet been reached will be <img alt="\sum (P_{0}^{t}p)_{i} \leq \lambda^{*t}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csum+%28P_%7B0%7D%5E%7Bt%7Dp%29_%7Bi%7D+%5Cleq+%5Clambda%5E%7B%2At%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sum (P_{0}^{t}p)_{i} \leq \lambda^{*t}"/>. Then, the<br/> probability that a marked element has been reached in that time will be<br/> <img alt="\geq 1 - \lambda^{t} \geq 1 - t \lambda^{*}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cgeq+1+-+%5Clambda%5E%7Bt%7D+%5Cgeq+1+-+t+%5Clambda%5E%7B%2A%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\geq 1 - \lambda^{t} \geq 1 - t \lambda^{*}"/>. Setting<br/> <img alt="t = \frac{1}{1-\lambda^{*}}" class="latex" src="https://s0.wp.com/latex.php?latex=t+%3D+%5Cfrac%7B1%7D%7B1-%5Clambda%5E%7B%2A%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t = \frac{1}{1-\lambda^{*}}"/> gives probability <img alt="\Omega(1)" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega(1)"/> that a marked element will be reached in that time.</p>



<p>The eigenvalues of <img alt="P_{0}" class="latex" src="https://s0.wp.com/latex.php?latex=P_%7B0%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P_{0}"/> will be <img alt="\frac{N-|M|-1}{N-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cfrac%7BN-%7CM%7C-1%7D%7BN-1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\frac{N-|M|-1}{N-1}"/> and<br/> <img alt="\frac{-1}{N-|M|-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B-1%7D%7BN-%7CM%7C-1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\frac{-1}{N-|M|-1}"/>. Then, the classical hitting time will be:</p>



<p><img alt="\begin{aligned} t &amp;= \frac{1}{1-\lambda^{*}} \\ &amp;= \frac{1}{1-\frac{N-|M|-1}{N-1}} \\ &amp;= O\left(\frac{N}{|M|}\right).\end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+t+%26%3D+%5Cfrac%7B1%7D%7B1-%5Clambda%5E%7B%2A%7D%7D+%5C%5C+%26%3D+%5Cfrac%7B1%7D%7B1-%5Cfrac%7BN-%7CM%7C-1%7D%7BN-1%7D%7D+%5C%5C+%26%3D+O%5Cleft%28%5Cfrac%7BN%7D%7B%7CM%7C%7D%5Cright%29.%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} t &amp;= \frac{1}{1-\lambda^{*}} \\ &amp;= \frac{1}{1-\frac{N-|M|-1}{N-1}} \\ &amp;= O\left(\frac{N}{|M|}\right).\end{aligned}"/></p>



<p>It can be showed that for a walk defined by a Markov chain, the<br/> classical hitting time will be <img alt="O(\frac{1}{\delta \epsilon})" class="latex" src="https://s0.wp.com/latex.php?latex=O%28%5Cfrac%7B1%7D%7B%5Cdelta+%5Cepsilon%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(\frac{1}{\delta \epsilon})"/>, where <img alt="\delta = 1 - \lambda^{*}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdelta+%3D+1+-+%5Clambda%5E%7B%2A%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\delta = 1 - \lambda^{*}"/>, the <em>spectral gap</em>, and <img alt="\epsilon \leq \frac{|M|}{N}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon+%5Cleq+%5Cfrac%7B%7CM%7C%7D%7BN%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon \leq \frac{|M|}{N}"/> [2].</p>



<p>Magniez <em>et al</em> proved in [6] that for a reversible, ergodic<br/> Markov chain, the quantum hitting time for a walk on this chain is<br/> within a factor of the square root of the classical hitting time. Since<br/> the walk on this input acts as a walk on a reversible Markov chain until<br/> a marked element is reached, then this is also true for a walk defined<br/> by our transition matrix <img alt="P'" class="latex" src="https://s0.wp.com/latex.php?latex=P%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P'"/>. This arises from the fact that the<br/> spectral gap of the matrix describing the quantum walk corresponding to<br/> stochastic matrix <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> is quadratically larger than the spectral gap of<br/> the matrix describing the classical random walk corresponding to <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/>, the proof of which is given in [2]. Thus, the quantum hitting time<br/> is <img alt="O(\sqrt{N/|M|})" class="latex" src="https://s0.wp.com/latex.php?latex=O%28%5Csqrt%7BN%2F%7CM%7C%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(\sqrt{N/|M|})"/>, which exactly matches the quantum query complexity of Grover search.</p>



<h2>Element distinctness problem</h2>



<p>Now, we describe Ambainis’s algorithm given in [1] for solving<br/> the <em>element distinctness problem</em> in <img alt="O(N^{\frac{2}{3}})" class="latex" src="https://s0.wp.com/latex.php?latex=O%28N%5E%7B%5Cfrac%7B2%7D%7B3%7D%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(N^{\frac{2}{3}})"/> time, which<br/> produces a speed up over the classical algorithm, which requires <img alt="O(N)" class="latex" src="https://s0.wp.com/latex.php?latex=O%28N%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(N)"/> queries, and also over other known quantum algorithms that do not make use of quantum walks, which require <img alt="O(N^{\frac{3}{4}})" class="latex" src="https://s0.wp.com/latex.php?latex=O%28N%5E%7B%5Cfrac%7B3%7D%7B4%7D%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(N^{\frac{3}{4}})"/> queries. The element distinctness problem is defined as follows: given a function <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> on a size <img alt="N" class="latex" src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N"/> set of inputs</p>



<p><img alt="S=\{x_{1}" class="latex" src="https://s0.wp.com/latex.php?latex=S%3D%5C%7Bx_%7B1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S=\{x_{1}"/>,…,<img alt="x_{N}\}" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7BN%7D%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{N}\}"/>,</p>



<p>determine whether there exists a pair <img alt="x_{1},\; x_{2} \in S" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7B1%7D%2C%5C%3B+x_%7B2%7D+%5Cin+S&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{1},\; x_{2} \in S"/> for which <img alt="f(x_{1}) = f(x_{2})" class="latex" src="https://s0.wp.com/latex.php?latex=f%28x_%7B1%7D%29+%3D+f%28x_%7B2%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f(x_{1}) = f(x_{2})"/>.  As in the search problem defined in the previous section, this is a decision problem; we are not concerned with finding the values of these pairs, only whether at least one exists.</p>



<p>The algorithm is similar to the search algorithm described in the previous section, except we define the walk on a <em>Hamming graph</em>. A Hamming graph <img alt="H(N,m)" class="latex" src="https://s0.wp.com/latex.php?latex=H%28N%2Cm%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H(N,m)"/> is defined as follows: each vertex <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/> corresponds to an <img alt="m" class="latex" src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m"/>-tuple, (<img alt="i_{1}" class="latex" src="https://s0.wp.com/latex.php?latex=i_%7B1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i_{1}"/>,…,<img alt="i_{m}" class="latex" src="https://s0.wp.com/latex.php?latex=i_%7Bm%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i_{m}"/>), where <img alt="i_{k} \in S" class="latex" src="https://s0.wp.com/latex.php?latex=i_%7Bk%7D+%5Cin+S&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i_{k} \in S"/> for all <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/> and repetition is allowed (that is, <img alt="i_{k}" class="latex" src="https://s0.wp.com/latex.php?latex=i_%7Bk%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i_{k}"/> may equal <img alt="i_{j}" class="latex" src="https://s0.wp.com/latex.php?latex=i_%7Bj%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i_{j}"/> for <img alt="k \neq j" class="latex" src="https://s0.wp.com/latex.php?latex=k+%5Cneq+j&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k \neq j"/>), and <img alt="m" class="latex" src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m"/> is a parameter we will choose. Edges will exist between vertices that differ in exactly one coordinate (order matters in this graph). We describe the state of each vertex as:</p>



<p><img alt="\left|i \right&gt;=| i_{1},i_{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cleft%7Ci+%5Cright%3E%3D%7C+i_%7B1%7D%2Ci_%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\left|i \right&gt;=| i_{1},i_{2}"/>,…,<img alt="i_{m},f(i_{1})" class="latex" src="https://s0.wp.com/latex.php?latex=i_%7Bm%7D%2Cf%28i_%7B1%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i_{m},f(i_{1})"/>,…,<img alt="f(i_{m})&gt;" class="latex" src="https://s0.wp.com/latex.php?latex=f%28i_%7Bm%7D%29%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f(i_{m})&gt;"/></p>



<p>Then, moving along each edge that replaces the <img alt="j" class="latex" src="https://s0.wp.com/latex.php?latex=j&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="j"/>th coordinate with <img alt="x_{k}" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7Bk%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{k}"/> such that <img alt="i_{j} \neq x_{k}" class="latex" src="https://s0.wp.com/latex.php?latex=i_%7Bj%7D+%5Cneq+x_%7Bk%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i_{j} \neq x_{k}"/>  requires two queries to the black box function to erase <img alt="f(i_{j})" class="latex" src="https://s0.wp.com/latex.php?latex=f%28i_%7Bj%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f(i_{j})"/> and compute <img alt="f(x_{k})" class="latex" src="https://s0.wp.com/latex.php?latex=f%28x_%7Bk%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f(x_{k})"/>. In the case, the marked vertices will be those that contain some <img alt="f(i_{k}) = f(i_{j})" class="latex" src="https://s0.wp.com/latex.php?latex=f%28i_%7Bk%7D%29+%3D+f%28i_%7Bj%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f(i_{k}) = f(i_{j})"/> for <img alt="i_{j} \neq i_{k}" class="latex" src="https://s0.wp.com/latex.php?latex=i_%7Bj%7D+%5Cneq+i_%7Bk%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i_{j} \neq i_{k}"/>. Since the function values are stored in the description of the state, then no additional queries to the black box are required to check if in a marked state.</p>



<p>The transition matrix is given by <img alt="P = \frac{1}{m(n-1)} \underset{i \in [1,m]}{\sum} (J - I)^{(i)}" class="latex" src="https://s0.wp.com/latex.php?latex=P+%3D+%5Cfrac%7B1%7D%7Bm%28n-1%29%7D+%5Cunderset%7Bi+%5Cin+%5B1%2Cm%5D%7D%7B%5Csum%7D+%28J+-+I%29%5E%7B%28i%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P = \frac{1}{m(n-1)} \underset{i \in [1,m]}{\sum} (J - I)^{(i)}"/>. <img alt="J" class="latex" src="https://s0.wp.com/latex.php?latex=J&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="J"/> is the <img alt="n \times n" class="latex" src="https://s0.wp.com/latex.php?latex=n+%5Ctimes+n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n \times n"/> all one matrix, and the superscript <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/> denotes the operator acting on the <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/>th coordinate. The factor of <img alt="\frac{1}{m(n-1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7Bm%28n-1%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\frac{1}{m(n-1)}"/> normalizes the degree, since the graph is regular. We can compute the spectral gap of this graph to be <img alt="\frac{n}{m(n-1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cfrac%7Bn%7D%7Bm%28n-1%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\frac{n}{m(n-1)}"/> (for details of this computation, see [2]). Then, noting that that the fraction of marked vertices, <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon"/>, is<br/> <img alt="\geq \frac{m(m-1)(n-2)^{m-2}}{n^{m}}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cgeq+%5Cfrac%7Bm%28m-1%29%28n-2%29%5E%7Bm-2%7D%7D%7Bn%5E%7Bm%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\geq \frac{m(m-1)(n-2)^{m-2}}{n^{m}}"/>, classically, the query complexity is <img alt="m + O(\frac{1}{\delta \epsilon}) = m + O(\frac{n^{2}}{m})" class="latex" src="https://s0.wp.com/latex.php?latex=m+%2B+O%28%5Cfrac%7B1%7D%7B%5Cdelta+%5Cepsilon%7D%29+%3D+m+%2B+O%28%5Cfrac%7Bn%5E%7B2%7D%7D%7Bm%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m + O(\frac{1}{\delta \epsilon}) = m + O(\frac{n^{2}}{m})"/>, where <img alt="m" class="latex" src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m"/> is the queries required to construct the initial state. Setting the parameters equal to minimize with respect to <img alt="m" class="latex" src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m"/> gives classical query complexity <img alt="O(N)" class="latex" src="https://s0.wp.com/latex.php?latex=O%28N%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(N)"/>, as expected.</p>



<p>Then in the quantum case, <img alt="m" class="latex" src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m"/> queries are still required to set up the state. <img alt="O(\frac{n}{\sqrt{m}})" class="latex" src="https://s0.wp.com/latex.php?latex=O%28%5Cfrac%7Bn%7D%7B%5Csqrt%7Bm%7D%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(\frac{n}{\sqrt{m}})"/> queries are required to perform the walk until a marked state is reached, by [6]. Setting parameters equal gives <img alt="O(N^{\frac{2}{3}})" class="latex" src="https://s0.wp.com/latex.php?latex=O%28N%5E%7B%5Cfrac%7B2%7D%7B3%7D%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(N^{\frac{2}{3}})"/> queries, as desired.</p>



<p>[1] Ambainis, A. Quantum walk algorithm for element distinctness, SIAM Journal on Computing 37(1):210-239 (2007). arXiv:quant-ph/0311001</p>



<p>[2] Childs, A. Lecture Notes on Quantum Algorithms (2017). <a href="https://www.cs.umd.edu/&#xA0;amchilds/qa/qa.pdf" rel="nofollow">https://www.cs.umd.edu/ amchilds/qa/qa.pdf</a></p>



<p>[3] Childs, A., Farhi, E. Gutmann, S. An example of the difference between<br/> quantum and classical random walks. Journal of Quantum Information<br/> Processing, 1:35, 2002. Also quant-ph/0103020.</p>



<p>[4] Godsil, C., Hanmeng, Z. Discrete-Time Quantum Walks and Graph Structures<br/> (2018). arXiv:1701.04474</p>



<p>[5] Kempe, J. Quantum random walks: an introductory overview, Contemporary<br/> Physics, Vol. 44 (4) (2003) 307:327. arXiv:quant-ph/0303081</p>



<p>[6] Magniez, F., Nayak, A., Richter, P.C. et al. On the hitting times of<br/> quantum versus random walks, Algorithmica (2012) 63:91.<br/> <a href="https://doi.org/10.1007/s00453-011-9521-6" rel="nofollow">https://doi.org/10.1007/s00453-011-9521-6</a></p>



<p>[7] Szegedy, M. Quantum Speed-up of Markov Chain Based Algorithms, 45th<br/> Annual IEEE Symposium on Foundations of Computer Science (2004).<br/> <a href="https://ieeexplore.ieee.org/abstract/document/1366222" rel="nofollow">https://ieeexplore.ieee.org/abstract/document/1366222</a></p>



<p>[8] Portugal, R. <em>Quantum Walks and Search Algorithms</em>. Springer, New York, NY (2013).</p>



<p/></div>
    </content>
    <updated>2018-12-23T17:45:32Z</updated>
    <published>2018-12-23T17:45:32Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>beanash</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2019-01-07T23:33:01Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=6939</id>
    <link href="https://windowsontheory.org/2018/12/22/towards-quantum-pcp-a-proof-of-the-nlets-theorem/" rel="alternate" type="text/html"/>
    <title>Towards Quantum PCP: A Proof of the NLETS Theorem</title>
    <summary>By Abhijit Mudigonda, Richard Wang, and Lisa Yang This is part of a series of blog posts for CS 229r: Physics and Computation. In this post, we will talk about progress made towards resolving the quantum PCP conjecture. We’ll briefly talk about the progression from the quantum PCP conjecture to the NLTS conjecture to the […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>By Abhijit Mudigonda, Richard Wang, and Lisa Yang</p>



<p><i>This is part of a series of blog posts for <a href="https://www.boazbarak.org/fall18seminar/">CS 229r: Physics and Computation</a>. In this post, we will talk about progress made towards resolving the quantum PCP conjecture. We’ll briefly talk about the progression from the quantum PCP conjecture to the NLTS conjecture to the NLETS theorem, and then settle on providing a proof of the NLETS theorem. This new proof, due to Nirkhe, Vazirani, and Yuen, makes it clear that the Hamiltonian family used to resolve the NLETS theorem cannot help us in resolving the NLTS conjecture.</i></p>



<h2>Introduction</h2>
<p>We are all too familiar with <b>NP</b> problems. Consider now an upgrade to <b>NP</b> problems, where an omniscient prover (we’ll call this prover Merlin) can send a polynomial-sized proof to a <b>BPP</b> (<a href="https://complexityzoo.uwaterloo.ca/Petting_Zoo#BPP">bounded-error probabilistic polynomial-time</a>) verifier (and we’ll call this verifier Arthur). Now, we have more decision problems in another complexity class, <b>MA</b> (<a href="https://complexityzoo.uwaterloo.ca/Petting_Zoo#MA">Merlin-Arthur</a>). Consider again, the analogue in the quantum realm where now the prover sends over qubits instead and the verifier is in <b>BQP</b> (<a href="https://complexityzoo.uwaterloo.ca/Complexity_Zoo:B#bqp">bounded-error quantum polynomial-time</a>). And now we have <b>QMA</b> (<a href="https://complexityzoo.uwaterloo.ca/Complexity_Zoo:Q#qma">quantum Merlin-Arthur</a>).</p>

<p>We can show that there is a hierarchy to these classes, where <b>NP</b> <img alt="\subseteq " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csubseteq+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\subseteq "/> <b>MA</b> <img alt="\subseteq " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csubseteq+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\subseteq "/> <b>QMA</b>.</p>

<p>Our goal is to talk about progress towards a <b>quantum PCP theorem</b> (and since nobody has proved it in the positive or negative, we’ll refer to it as a quantum PCP <i>conjecture</i> for now), so it might be a good idea to first talk about the PCP theorem. Suppose we take a Boolean formula, and we want to verify that it is satisfiable. Then someone comes along and presents us with a certificate — in this case, a satisfying assignment — and we can check in polynomial time that either this is indeed a satisfying assignment to the formula (a correct certificate) or it is not (an incorrect certificate).</p>

<p>But this requires that we check the entire certificate that is presented to us. Now, in comes the <b>PCP Theorem</b> (for <i>probabilistically checkable proofs</i>), which tells us that a certificate can be presented to us such that we can read a constant number of bits from the certificate, and have two things guaranteed: one, if this certificate is correct, then we will never think that it is incorrect even if we are not reading the entire certificate, and two, if we are presented with an incorrect certificate, we will reject it with high probability [<a href="https://windowsontheory.org/feed/#arora2009computational">1</a>].</p>

<p>In short, one formulation of the PCP theorem tells us that, puzzingly, we might not need to read the entirety of a proof in order to be convinced with high probability that it is a good proof or a bad proof. But a natural question arises, which is to ask: is there a quantum analogue of the PCP theorem?</p>

<h2>Progress</h2>

<p>The answer is, we’re still not sure. But to make progress towards resolving this question, we will present the work of <a href="https://arxiv.org/pdf/1802.07419.pdf">Nirkhe, Vazirani, and Yuen</a> in providing an alternate proof of an earlier result of <a href="https://arxiv.org/pdf/1510.02082.pdf">Eldar and Harrow</a> on the NLETS theorem.

</p><p>Before we state the quantum PCP conjecture, it would be helpful to review information about local Hamiltonians and the <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-local Hamiltonian problem. <a href="https://windowsontheory.org/2018/12/20/quantum-hamiltonian-complexity/">A previous blog post by Ben Edelman</a> covers these topics. Now, let’s state the quantum PCP conjecture:</p>

<p><b>(<i>Quantum PCP Conjecture</i>)</b>: It is QMA-hard to decide whether a given local Hamiltonian <img alt="H = H_{1} + ... + H_{m} " class="latex" src="https://s0.wp.com/latex.php?latex=H+%3D+H_%7B1%7D+%2B+...+%2B+H_%7Bm%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H = H_{1} + ... + H_{m} "/> (where each <img alt="||H_{i}|| \leq 1" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%7CH_%7Bi%7D%7C%7C+%5Cleq+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="||H_{i}|| \leq 1"/>) has ground state energy at most <img alt="a " class="latex" src="https://s0.wp.com/latex.php?latex=a+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a "/> or at least <img alt="b " class="latex" src="https://s0.wp.com/latex.php?latex=b+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="b "/> when <img alt="b-a \geq c||H|| " class="latex" src="https://s0.wp.com/latex.php?latex=b-a+%5Cgeq+c%7C%7CH%7C%7C+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="b-a \geq c||H|| "/> for some universal constant <img alt="c &gt; 0" class="latex" src="https://s0.wp.com/latex.php?latex=c+%3E+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c &gt; 0"/>.</p>

<p>Recall that MAX-<img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-SAT being NP-hard corresponds to the <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-local Hamiltonian problem being QMA-hard when <img alt="b-a \geq 1/poly(n)" class="latex" src="https://s0.wp.com/latex.php?latex=b-a+%5Cgeq+1%2Fpoly%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="b-a \geq 1/poly(n)"/>. (We can refer to <a href="https://www.cs.cmu.edu/~odonnell/quantum15/lecture24.pdf">Theorem 4.1 in these scribed notes of Ryan O’Donnell’s lecture</a>, and more specifically to  <a href="https://arxiv.org/pdf/quant-ph/0406180.pdf">Kempe-Kitaev-Regev’s original paper</a> for proof of this fact.) The quantum PCP conjecture asks if this is still the case when the gap is <img alt="c||H||" class="latex" src="https://s0.wp.com/latex.php?latex=c%7C%7CH%7C%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c||H||"/>.</p>

<p>Going back to the PCP theorem, an implication of the PCP theorem is that it is NP-hard to approximate certain problems to within some factor. Just like its classical analogue, the qPCP conjecture can be seen as stating that it is QMA-hard to approximate the ground state energy to a factor better than <img alt="c||H||" class="latex" src="https://s0.wp.com/latex.php?latex=c%7C%7CH%7C%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c||H||"/>.</p>

<h3>Reformulation: NLTS conjecture</h3>
<p>Let’s make the observation that, taking <img alt="a " class="latex" src="https://s0.wp.com/latex.php?latex=a+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a "/> to be the ground state energy, the qPCP conjecture sort of says that there exists a family of Hamiltonians for which there is no trivial state (a state generated by a low depth circuit) such that the energy is at most <img alt="c||H|| " class="latex" src="https://s0.wp.com/latex.php?latex=c%7C%7CH%7C%7C+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c||H|| "/> above the ground state energy.</p>

<p>Freedman and Hastings came up with an easier goal called the <b>No Low-Energy Trivial States conjecture</b>, or <b>NLTS conjecture</b>. We expect that ground states of local Hamiltonians are sufficiently hard to describe (if NP <img alt="\neq " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cneq+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\neq "/> QMA). So low-energy states might not be generated by a quantum circuit of constant depth. More formally:</p>

<p><b>(<i>NLTS Conjecture</i>)</b>: <i>There exists a universal constant <img alt="\epsilon &gt; 0 " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon+%3E+0+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon &gt; 0 "/> and a family of local Hamiltonians <img alt="\{H^{(n)}\}_{n=1}^{\infty} " class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7BH%5E%7B%28n%29%7D%5C%7D_%7Bn%3D1%7D%5E%7B%5Cinfty%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{H^{(n)}\}_{n=1}^{\infty} "/> where <img alt="H^{(n)} " class="latex" src="https://s0.wp.com/latex.php?latex=H%5E%7B%28n%29%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H^{(n)} "/> acts on <img alt="n " class="latex" src="https://s0.wp.com/latex.php?latex=n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n "/> particles and consists of <img alt="m_{n} " class="latex" src="https://s0.wp.com/latex.php?latex=m_%7Bn%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m_{n} "/> local terms, s.t. any family of states <img alt="\{|\psi_{n}\rangle\} " class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B%7C%5Cpsi_%7Bn%7D%5Crangle%5C%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{|\psi_{n}\rangle\} "/> satisfying <img alt="\langle \psi_{n} | H^{(n)} | \psi_{n}\rangle \leq \epsilon||H^{(n)}|| + \lambda_{min}(H^{(n)}) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Clangle+%5Cpsi_%7Bn%7D+%7C+H%5E%7B%28n%29%7D+%7C+%5Cpsi_%7Bn%7D%5Crangle+%5Cleq+%5Cepsilon%7C%7CH%5E%7B%28n%29%7D%7C%7C+%2B+%5Clambda_%7Bmin%7D%28H%5E%7B%28n%29%7D%29+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\langle \psi_{n} | H^{(n)} | \psi_{n}\rangle \leq \epsilon||H^{(n)}|| + \lambda_{min}(H^{(n)}) "/> requires circuit depth that grows faster than any constant.</i></p>

<p>To reiterate, if we did have such a family of NLTS Hamiltonians, then it we wouldn’t be able to give “easy proofs” for the minimal energy of a Hamiltonian, because we couldn’t just give a small circuit which produced a low energy state.</p>

<h2>Progress: NLETS theorem</h2>
<p><img alt="\epsilon " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon "/>-error states are states that differ from the ground state in at most <img alt="\epsilon n " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon+n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon n "/> qubits. Now, consider <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon"/>-error states (which “agree” with the ground state on most qubits). Then for bounded-degree local Hamiltonians (analogously in the classical case, those where each variable participates in a bounded number of clauses), these states are also low energy. So any theorem which applies to low energy states (such as the NLTS conjecture), should also apply to states with <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon"/>-error (as in the NLETS theorem).</p>

<p>To define low-error states more formally:</p>

<p><b>Definition 2.1</b> (<img alt="\epsilon " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon "/>-error states): <i>Let <img alt="\rho, \sigma \in D((\mathbb{C}^{d})^{\otimes n}) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho%2C+%5Csigma+%5Cin+D%28%28%5Cmathbb%7BC%7D%5E%7Bd%7D%29%5E%7B%5Cotimes+n%7D%29+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho, \sigma \in D((\mathbb{C}^{d})^{\otimes n}) "/> (the space of positive semidefinite operators of trace norm equal to 1 on <img alt="(\mathbb{C}^{d})^{\otimes n}" class="latex" src="https://s0.wp.com/latex.php?latex=%28%5Cmathbb%7BC%7D%5E%7Bd%7D%29%5E%7B%5Cotimes+n%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(\mathbb{C}^{d})^{\otimes n}"/>). Let <img alt="H " class="latex" src="https://s0.wp.com/latex.php?latex=H+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H "/> be a local Hamiltonian acting on <img alt="(\mathbb{C}^{d})^{\otimes n}" class="latex" src="https://s0.wp.com/latex.php?latex=%28%5Cmathbb%7BC%7D%5E%7Bd%7D%29%5E%7B%5Cotimes+n%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(\mathbb{C}^{d})^{\otimes n}"/>. Then:</i></p>

<p/><ul>
    <li><img alt="\sigma " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csigma+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sigma "/> is an <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon"/>-error state of <img alt="\rho " class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho "/> if <img alt="\exists S \subseteq [n] " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cexists+S+%5Csubseteq+%5Bn%5D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\exists S \subseteq [n] "/> of size at most <img alt="\epsilon n " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon+n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon n "/> s.t. <img alt="\text{Tr}_{S}(\rho) = \text{Tr}_{S}(\sigma)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctext%7BTr%7D_%7BS%7D%28%5Crho%29+%3D+%5Ctext%7BTr%7D_%7BS%7D%28%5Csigma%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\text{Tr}_{S}(\rho) = \text{Tr}_{S}(\sigma)"/>.</li>
    <li><img alt="\sigma " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csigma+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sigma "/> is an <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon"/>-error state for <img alt="H " class="latex" src="https://s0.wp.com/latex.php?latex=H+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H "/> if <img alt="\exists \rho " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cexists+%5Crho+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\exists \rho "/> s.t. <img alt="\text{Tr}(H\rho) = \lambda_{min}(H) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctext%7BTr%7D%28H%5Crho%29+%3D+%5Clambda_%7Bmin%7D%28H%29+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\text{Tr}(H\rho) = \lambda_{min}(H) "/> and <img alt="\sigma " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csigma+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sigma "/> is an <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon"/>-error state for <img alt="\rho" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho"/>.</li>
</ul><p/>

<p>Here, see that <img alt="\text{Tr}_{S} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctext%7BTr%7D_%7BS%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\text{Tr}_{S} "/> is just the partial trace on some subset of integers <img alt="S " class="latex" src="https://s0.wp.com/latex.php?latex=S+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S "/>, like we’re tracing out or “disregarding” some subset of <img alt="n " class="latex" src="https://s0.wp.com/latex.php?latex=n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n "/> qubits.</p>

<p>In 2017, Eldar and Harrow showed the following result which is the NLETS theorem.</p>

<p><b>Theorem 1</b> (NLETS Theorem): <i>There exists a family of 16-local Hamiltonians <img alt="\{H^{(n)}\} " class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7BH%5E%7B%28n%29%7D%5C%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{H^{(n)}\} "/> s.t. any family of <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon"/>-error states <img alt="\{|\Phi_{n}\rangle\} " class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B%7C%5CPhi_%7Bn%7D%5Crangle%5C%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{|\Phi_{n}\rangle\} "/> for <img alt="\{H^{(n)}\} " class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7BH%5E%7B%28n%29%7D%5C%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{H^{(n)}\} "/> requires circuit depth <img alt="\Omega(\log n) " class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega%28%5Clog+n%29+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega(\log n) "/> where <img alt="\epsilon = 10^{-9}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon+%3D+10%5E%7B-9%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon = 10^{-9}"/>.</i></p>

<p>In the next two sections, we will provide background for an alternate proof of the NLETS theorem due to Nirkhe, Vazirani, and Yuen. After this, we will explain why the proof of NLETS cannot be used to prove NLTS, since the local Hamiltonian family we construct for NLETS can be linearized. Nirkhe, Vazirani, and Yuen’s proof of NLETS makes use of the Feynman-Kitaev clock Hamiltonian corresponding to the circuit generating the cat state (Eldar and Harrow make use of the Tillich-Zemor hypergraph product construction; refer to section 8 of <a href="https://arxiv.org/pdf/1510.02082.pdf">their paper</a>). What is this circuit? It is this one:</p>



<div class="wp-block-image"><figure class="aligncenter is-resized"><img alt="" class="wp-image-6977" height="210" src="https://windowsontheory.files.wordpress.com/2018/12/cat_state.png?w=326&amp;h=210" width="326"/>Image from [2]</figure></div>



<p>First, we apply the Hadamard gate (drawn as <img alt="\boxed{H}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cboxed%7BH%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\boxed{H}"/>) which maps the first qubit <img alt="|0\rangle \rightarrow \frac{|0\rangle + |1\rangle}{\sqrt{2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7C0%5Crangle+%5Crightarrow+%5Cfrac%7B%7C0%5Crangle+%2B+%7C1%5Crangle%7D%7B%5Csqrt%7B2%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|0\rangle \rightarrow \frac{|0\rangle + |1\rangle}{\sqrt{2}}"/>. Then we can think of the CNOT gates (drawn as <img alt="\bullet-\oplus" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbullet-%5Coplus&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\bullet-\oplus"/>) as propagating whatever happens to the first qubit to the rest of the qubits. If we had the first qubit mapping to 0, then the rest of the qubits map to 0, and likewise for 1. This generates the cat state <img alt="|\textsf{CAT}_{n}\rangle = \frac{|0\rangle^{\otimes n} + |1\rangle^{\otimes n}}{\sqrt{2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Ctextsf%7BCAT%7D_%7Bn%7D%5Crangle+%3D+%5Cfrac%7B%7C0%5Crangle%5E%7B%5Cotimes+n%7D+%2B+%7C1%5Crangle%5E%7B%5Cotimes+n%7D%7D%7B%5Csqrt%7B2%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\textsf{CAT}_{n}\rangle = \frac{|0\rangle^{\otimes n} + |1\rangle^{\otimes n}}{\sqrt{2}}"/>, which is highly entangled.</p>

<p>Why do we want a highly entangled state? Roughly our intuition for using the cat state is this: if the ground state of a Hamiltonian is highly entangled, then any quantum circuit which generates it has non-trivial depth. So if our goal is to show the existence of local Hamiltonians which have low energy or low error states that need deep circuits to generate, it makes sense to use a highly entangled state like the cat state.</p>

<h2>Quantum circuits</h2>



<div class="wp-block-image"><figure class="aligncenter is-resized"><img alt="" class="wp-image-6978" height="221" src="https://windowsontheory.files.wordpress.com/2018/12/operators.png?w=446&amp;h=221" width="446"/>Image from [2]</figure></div>



<p>(We’ll write that the state of a qudit – a generalization of a qubit to more than two dimensions, and in this case <img alt="q " class="latex" src="https://s0.wp.com/latex.php?latex=q+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="q "/> dimensions – is a vector in <img alt="\mathbb{C}^{q}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BC%7D%5E%7Bq%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb{C}^{q}"/>. In our diagram above, we’ll see 4 qudits, labelled appropriately.)</p>

<p>Let’s briefly cover the definitions for the quantum circuits we’ll be using.</p>

<p>Let <img alt="U " class="latex" src="https://s0.wp.com/latex.php?latex=U+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U "/> be a unitary operator acting on a system of <img alt="n " class="latex" src="https://s0.wp.com/latex.php?latex=n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n "/> qudits (in other words, acting on <img alt="(\mathbb{C}^{q})^{\otimes n}" class="latex" src="https://s0.wp.com/latex.php?latex=%28%5Cmathbb%7BC%7D%5E%7Bq%7D%29%5E%7B%5Cotimes+n%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(\mathbb{C}^{q})^{\otimes n}"/>), where <img alt="U = U_{m} \hdots U_{1}" class="latex" src="https://s0.wp.com/latex.php?latex=U+%3D+U_%7Bm%7D+%5Chdots+U_%7B1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U = U_{m} \hdots U_{1}"/>. Here, each <img alt="U_{i} " class="latex" src="https://s0.wp.com/latex.php?latex=U_%7Bi%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U_{i} "/> is a unitary operator (a gate) acting on at most two qudits, and <img alt="U " class="latex" src="https://s0.wp.com/latex.php?latex=U+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U "/> is a product of <img alt="m " class="latex" src="https://s0.wp.com/latex.php?latex=m+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m "/> such operators.</p>

<p>If there exists a partition <img alt="U " class="latex" src="https://s0.wp.com/latex.php?latex=U+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U "/> into products of non-overlapping two-qudit unitaries (we call these layers and denote them as <img alt="L_{i} = \bigotimes_{j}U_{ij}" class="latex" src="https://s0.wp.com/latex.php?latex=L_%7Bi%7D+%3D+%5Cbigotimes_%7Bj%7DU_%7Bij%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="L_{i} = \bigotimes_{j}U_{ij}"/>, where each <img alt="U_{j} " class="latex" src="https://s0.wp.com/latex.php?latex=U_%7Bj%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U_{j} "/> here is in layer <img alt="L_{i}" class="latex" src="https://s0.wp.com/latex.php?latex=L_%7Bi%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="L_{i}"/>) such that <img alt="U = L_{d} \hdots L_{1} " class="latex" src="https://s0.wp.com/latex.php?latex=U+%3D+L_%7Bd%7D+%5Chdots+L_%7B1%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U = L_{d} \hdots L_{1} "/> then we say <img alt="U " class="latex" src="https://s0.wp.com/latex.php?latex=U+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U "/> has <img alt="d " class="latex" src="https://s0.wp.com/latex.php?latex=d+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d "/> layers.</p>

<p>In other words, <img alt="U " class="latex" src="https://s0.wp.com/latex.php?latex=U+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U "/> has size <img alt="m " class="latex" src="https://s0.wp.com/latex.php?latex=m+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m "/> and circuit depth <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/>.</p>

<h3>Lightcones, effect zones, shadow zones</h3>
<p>Consider <img alt="U = L_{d} \hdots L_{1} " class="latex" src="https://s0.wp.com/latex.php?latex=U+%3D+L_%7Bd%7D+%5Chdots+L_%7B1%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U = L_{d} \hdots L_{1} "/> and <img alt="A " class="latex" src="https://s0.wp.com/latex.php?latex=A+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A "/> an operator.</p>

<p>For <img alt="j &lt; d " class="latex" src="https://s0.wp.com/latex.php?latex=j+%3C+d+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="j &lt; d "/> define <img alt="K^{(j)} " class="latex" src="https://s0.wp.com/latex.php?latex=K%5E%7B%28j%29%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K^{(j)} "/> as the gates in layer <img alt="j " class="latex" src="https://s0.wp.com/latex.php?latex=j+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="j "/> whose supports overlap that of any gate in <img alt="K^{(j+1)}" class="latex" src="https://s0.wp.com/latex.php?latex=K%5E%7B%28j%2B1%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K^{(j+1)}"/>, …, <img alt="K^{(d)} " class="latex" src="https://s0.wp.com/latex.php?latex=K%5E%7B%28d%29%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K^{(d)} "/> or with <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/>.</p>

<p><b>Definition 3.1</b> (lightcone): <i>The <i>lightcone</i> of <img alt="A " class="latex" src="https://s0.wp.com/latex.php?latex=A+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A "/> with respect to <img alt="U " class="latex" src="https://s0.wp.com/latex.php?latex=U+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U "/> is the union of <img alt="K^{(j)}" class="latex" src="https://s0.wp.com/latex.php?latex=K%5E%7B%28j%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K^{(j)}"/>: <img alt="K_{U} \triangleq \bigcup_{j} K^{(j)}" class="latex" src="https://s0.wp.com/latex.php?latex=K_%7BU%7D+%5Ctriangleq+%5Cbigcup_%7Bj%7D+K%5E%7B%28j%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K_{U} \triangleq \bigcup_{j} K^{(j)}"/>.</i></p>

<p>So we can think of the lightcone as the set of gates spreading out of <img alt="A " class="latex" src="https://s0.wp.com/latex.php?latex=A+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A "/> all the way to the first layer of the circuit. In our diagram, the lightcone of <img alt="A " class="latex" src="https://s0.wp.com/latex.php?latex=A+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A "/> is the dash-dotted region. We have <img alt="K^{(3)} = \varnothing" class="latex" src="https://s0.wp.com/latex.php?latex=K%5E%7B%283%29%7D+%3D+%5Cvarnothing&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K^{(3)} = \varnothing"/>, <img alt="K^{(2)} = \{U_{21}\}" class="latex" src="https://s0.wp.com/latex.php?latex=K%5E%7B%282%29%7D+%3D+%5C%7BU_%7B21%7D%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K^{(2)} = \{U_{21}\}"/>, and <img alt="K^{(1)} = \{U_{11}, U_{12}\}" class="latex" src="https://s0.wp.com/latex.php?latex=K%5E%7B%281%29%7D+%3D+%5C%7BU_%7B11%7D%2C+U_%7B12%7D%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K^{(1)} = \{U_{11}, U_{12}\}"/>.</p>

<p>We also want a definition for what comes back from the lightcone: the set of gates from the first layer (the widest part of the cone) back to the last layer.</p>

<p>Define <img alt="E^{(1)} = K^{(1)}" class="latex" src="https://s0.wp.com/latex.php?latex=E%5E%7B%281%29%7D+%3D+K%5E%7B%281%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="E^{(1)} = K^{(1)}"/>. For <img alt="j \geq 2" class="latex" src="https://s0.wp.com/latex.php?latex=j+%5Cgeq+2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="j \geq 2"/>, let <img alt="E^{(j)} " class="latex" src="https://s0.wp.com/latex.php?latex=E%5E%7B%28j%29%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="E^{(j)} "/> be the set of gates whose supports overlap with any gate in <img alt="E^{(j-1)}" class="latex" src="https://s0.wp.com/latex.php?latex=E%5E%7B%28j-1%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="E^{(j-1)}"/>.</p>

<p><b>Definition 3.2</b> (effect zone): <i>The <i>effect zone</i> of <img alt="A " class="latex" src="https://s0.wp.com/latex.php?latex=A+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A "/> with respect to <img alt="U " class="latex" src="https://s0.wp.com/latex.php?latex=U+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U "/> is the union <img alt="E_{U}(A) \triangleq \bigcup_{j} E^{(j)}" class="latex" src="https://s0.wp.com/latex.php?latex=E_%7BU%7D%28A%29+%5Ctriangleq+%5Cbigcup_%7Bj%7D+E%5E%7B%28j%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="E_{U}(A) \triangleq \bigcup_{j} E^{(j)}"/>.</i></p>

<p>In our diagram, see that <img alt="E^{(1)} = \{U_{11}, U_{12}\}" class="latex" src="https://s0.wp.com/latex.php?latex=E%5E%7B%281%29%7D+%3D+%5C%7BU_%7B11%7D%2C+U_%7B12%7D%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="E^{(1)} = \{U_{11}, U_{12}\}"/>, <img alt="E^{(2)} = \{U_{21}\}" class="latex" src="https://s0.wp.com/latex.php?latex=E%5E%7B%282%29%7D+%3D+%5C%7BU_%7B21%7D%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="E^{(2)} = \{U_{21}\}"/>, and <img alt="E^{(3)} = \{U_{31}\}" class="latex" src="https://s0.wp.com/latex.php?latex=E%5E%7B%283%29%7D+%3D+%5C%7BU_%7B31%7D%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="E^{(3)} = \{U_{31}\}"/>. The effect zone of <img alt="A " class="latex" src="https://s0.wp.com/latex.php?latex=A+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A "/> is the dotted region.</p>

<p><b>Definition 3.3</b> (shadow of the effect zone): <i>The <i>shadow of the effect zone</i> <img alt="W_{U}(A) " class="latex" src="https://s0.wp.com/latex.php?latex=W_%7BU%7D%28A%29+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="W_{U}(A) "/> of <img alt="A " class="latex" src="https://s0.wp.com/latex.php?latex=A+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A "/> with respect to <img alt="U " class="latex" src="https://s0.wp.com/latex.php?latex=U+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U "/> is the set of qudits acted on by the gates in the effect zone.</i></p>

<p>In our diagram, the first three qudits are effected by gates in the effect zone. So <img alt="W_{U}(A) = \{1, 2, 3\}" class="latex" src="https://s0.wp.com/latex.php?latex=W_%7BU%7D%28A%29+%3D+%5C%7B1%2C+2%2C+3%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="W_{U}(A) = \{1, 2, 3\}"/>.</p>

<p>Given all of these definitions, we make the following claim which will be important later, in a proof of a generalization of NLETS.</p>

<p><b><a id="claim3"/>Claim 3.1</b> (Disjoint lightcones): <i>Let <img alt="U " class="latex" src="https://s0.wp.com/latex.php?latex=U+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U "/> be a circuit and <img alt="A, B " class="latex" src="https://s0.wp.com/latex.php?latex=A%2C+B+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A, B "/> operators. If the qudits <img alt="B " class="latex" src="https://s0.wp.com/latex.php?latex=B+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B "/> acts on are disjoint from <img alt="W_{U}(A)" class="latex" src="https://s0.wp.com/latex.php?latex=W_%7BU%7D%28A%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="W_{U}(A)"/>, then the lightcones of <img alt="A " class="latex" src="https://s0.wp.com/latex.php?latex=A+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A "/> and <img alt="B " class="latex" src="https://s0.wp.com/latex.php?latex=B+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B "/> in <img alt="U " class="latex" src="https://s0.wp.com/latex.php?latex=U+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U "/> are disjoint.</i></p>

<h2>Toward the Feynman-Kitaev clock</h2>
<p>Now we’ll give some definitions that will become necessary when we make use of the Feynman-Kitaev Hamiltonian in our later proofs.</p>

<p>Let’s define a unary clock. It will basically help us determine whatever happened at any time little <img alt="t " class="latex" src="https://s0.wp.com/latex.php?latex=t+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t "/> along the total time big <img alt="T" class="latex" src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T"/>. Let <img alt="|\textsf{unary}(t, T)\rangle = |0\rangle^{\otimes(T-t)} \otimes |1\rangle^{\otimes t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Ctextsf%7Bunary%7D%28t%2C+T%29%5Crangle+%3D+%7C0%5Crangle%5E%7B%5Cotimes%28T-t%29%7D+%5Cotimes+%7C1%5Crangle%5E%7B%5Cotimes+t%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\textsf{unary}(t, T)\rangle = |0\rangle^{\otimes(T-t)} \otimes |1\rangle^{\otimes t}"/>. For our purposes today, we won’t worry about higher dimensional clocks. So we’ll write <img alt="|\textsf{clock}_{k}(t, T)\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Ctextsf%7Bclock%7D_%7Bk%7D%28t%2C+T%29%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\textsf{clock}_{k}(t, T)\rangle"/>, but we’ll really only consider the case where <img alt="k = 1" class="latex" src="https://s0.wp.com/latex.php?latex=k+%3D+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k = 1"/>, which corresponds to <img alt="|\textsf{unary}(t, T)\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Ctextsf%7Bunary%7D%28t%2C+T%29%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\textsf{unary}(t, T)\rangle"/>. For simplicity’s sake, we will henceforth just write <img alt="|\textsf{unary}(t)\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Ctextsf%7Bunary%7D%28t%29%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\textsf{unary}(t)\rangle"/>.</p>

<p>Our goal is to construct something a little similar to the tableaux in the Cook-Levin theorem, so we also want to define a history state:</p>

<p><b>Definition 4.1</b> (History state): <i>Let <img alt="C " class="latex" src="https://s0.wp.com/latex.php?latex=C+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C "/> be a quantum circuit that acts on a witness register and an ancilla register. Let <img alt="C_{1}, ..., C_{T} " class="latex" src="https://s0.wp.com/latex.php?latex=C_%7B1%7D%2C+...%2C+C_%7BT%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_{1}, ..., C_{T} "/> denote the sequence of two-local gates in <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/>. Then for all <img alt="k \in \mathbb{N}" class="latex" src="https://s0.wp.com/latex.php?latex=k+%5Cin+%5Cmathbb%7BN%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k \in \mathbb{N}"/>, a state <img alt="|\Psi\rangle " class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5CPsi%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\Psi\rangle "/> is a <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-dimensional history state of <img alt="C " class="latex" src="https://s0.wp.com/latex.php?latex=C+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C "/> if:</i></p>

<div style="text-align: center;"><p><img alt="\begin{aligned}|\Psi\rangle = \frac{1}{\sqrt{T+1}}\sum_{t=0}^{T}|\textsf{clock}_{k}(t, T)\rangle \otimes |\psi_{t}\rangle\end{aligned} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D%7C%5CPsi%5Crangle+%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7BT%2B1%7D%7D%5Csum_%7Bt%3D0%7D%5E%7BT%7D%7C%5Ctextsf%7Bclock%7D_%7Bk%7D%28t%2C+T%29%5Crangle+%5Cotimes+%7C%5Cpsi_%7Bt%7D%5Crangle%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned}|\Psi\rangle = \frac{1}{\sqrt{T+1}}\sum_{t=0}^{T}|\textsf{clock}_{k}(t, T)\rangle \otimes |\psi_{t}\rangle\end{aligned} "/></p></div>

<p>where we have the clock state to keep track of time and <img alt="\psi_{t} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpsi_%7Bt%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\psi_{t} "/> is some state such that <img alt="|\psi_{t}\rangle = C_{t}|\psi_{t-1}\rangle " class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi_%7Bt%7D%5Crangle+%3D+C_%7Bt%7D%7C%5Cpsi_%7Bt-1%7D%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi_{t}\rangle = C_{t}|\psi_{t-1}\rangle "/> and <img alt="|\psi_{0}\rangle = |\xi\rangle_{witness} \otimes |0\rangle_{ancilla}" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi_%7B0%7D%5Crangle+%3D+%7C%5Cxi%5Crangle_%7Bwitness%7D+%5Cotimes+%7C0%5Crangle_%7Bancilla%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi_{0}\rangle = |\xi\rangle_{witness} \otimes |0\rangle_{ancilla}"/>. With this construction, we should be able to make a measurement to get back the state at time <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t"/>.</p>

<h2>Proof of NLETS</h2>
<p>We provide a proof of (a simplified case of) the NLETS theorem proved by Nirkhe, Vazirani, and Yuen in [<a href="https://windowsontheory.org/feed/#nirkhe2018approximate">2</a>].</p>

<p><b>Theorem 2</b> (NLETS): <i>There exists a family of <img alt="3" class="latex" src="https://s0.wp.com/latex.php?latex=3&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="3"/>-local Hamiltonians <img alt="\{H^{(n)}\} " class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7BH%5E%7B%28n%29%7D%5C%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{H^{(n)}\} "/> on a line (Each Hamiltonian <img alt="H^{(n)} " class="latex" src="https://s0.wp.com/latex.php?latex=H%5E%7B%28n%29%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H^{(n)} "/> can be defined on <img alt="n " class="latex" src="https://s0.wp.com/latex.php?latex=n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n "/> particles arranged on a line such that each local Hamiltonian acts on a particle and its two neighbors) such that for all <img alt="n \in \mathbb{N}" class="latex" src="https://s0.wp.com/latex.php?latex=n+%5Cin+%5Cmathbb%7BN%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n \in \mathbb{N}"/>, the circuit depth of any <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon"/>-error ground state for <img alt="H^{(n)} " class="latex" src="https://s0.wp.com/latex.php?latex=H%5E%7B%28n%29%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H^{(n)} "/> is at least logarithmic in <img alt="n " class="latex" src="https://s0.wp.com/latex.php?latex=n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n "/>.</i></p>

<p>First, we’ll show the circuit lower bound.  Then we’ll explain why these Hamiltonians can act on particles on a line and what this implies about the potential of these techniques for proving NLTS.</p>

<p><i>Proof</i>: We will use the <b>Feynman-Kitaev clock construction</b> to construct a <img alt="5" class="latex" src="https://s0.wp.com/latex.php?latex=5&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="5"/>-local Hamiltonian <img alt="\mathcal{H}^{(n)} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D%5E%7B%28n%29%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{H}^{(n)} "/> for the circuit <img alt="C_n" class="latex" src="https://s0.wp.com/latex.php?latex=C_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_n"/>: <img alt="|0^n\rangle \to |\textsf{CAT}_n\rangle " class="latex" src="https://s0.wp.com/latex.php?latex=%7C0%5En%5Crangle+%5Cto+%7C%5Ctextsf%7BCAT%7D_n%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|0^n\rangle \to |\textsf{CAT}_n\rangle "/>.</p>

<p>Fix <img alt="n \in \mathbb{N} " class="latex" src="https://s0.wp.com/latex.php?latex=n+%5Cin+%5Cmathbb%7BN%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n \in \mathbb{N} "/> and let <img alt="C_n " class="latex" src="https://s0.wp.com/latex.php?latex=C_n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_n "/> have size <img alt="T" class="latex" src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T"/>.  The Hamiltonian <img alt="\mathcal{H} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{H} "/> acts on <img alt="T+n " class="latex" src="https://s0.wp.com/latex.php?latex=T%2Bn+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T+n "/> qubits and consists of several local terms depending on <img alt="C_n" class="latex" src="https://s0.wp.com/latex.php?latex=C_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_n"/>:</p>

<div style="text-align: center;"><p><img alt="\begin{aligned}\mathcal{H} = H_{in} + \sum_{t=1}^T H_t + H_{out} + H_{stab}\end{aligned} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D%5Cmathcal%7BH%7D+%3D+H_%7Bin%7D+%2B+%5Csum_%7Bt%3D1%7D%5ET+H_t+%2B+H_%7Bout%7D+%2B+H_%7Bstab%7D%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned}\mathcal{H} = H_{in} + \sum_{t=1}^T H_t + H_{out} + H_{stab}\end{aligned} "/></p></div>

<p>We can think of a <img alt="T+n " class="latex" src="https://s0.wp.com/latex.php?latex=T%2Bn+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T+n "/> qubit state as representing a <img alt="T " class="latex" src="https://s0.wp.com/latex.php?latex=T+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T "/> step computation on <img alt="n " class="latex" src="https://s0.wp.com/latex.php?latex=n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n "/> qubits (i.e. for each time <img alt="t \in [0,T]" class="latex" src="https://s0.wp.com/latex.php?latex=t+%5Cin+%5B0%2CT%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t \in [0,T]"/>, we have a <img alt="n " class="latex" src="https://s0.wp.com/latex.php?latex=n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n "/> bit computation state <img alt="\textsf{state}_t " class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctextsf%7Bstate%7D_t+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\textsf{state}_t "/> of <img alt="C_n" class="latex" src="https://s0.wp.com/latex.php?latex=C_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_n"/>).  Intuitively, a <img alt="T+n " class="latex" src="https://s0.wp.com/latex.php?latex=T%2Bn+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T+n "/> qubit state has energy <img alt="0 " class="latex" src="https://s0.wp.com/latex.php?latex=0+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="0 "/> with respect to <img alt="\mathcal{H} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{H} "/> iff it is the history state of <img alt="C_n" class="latex" src="https://s0.wp.com/latex.php?latex=C_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_n"/>.  This is because <img alt="H_{in} " class="latex" src="https://s0.wp.com/latex.php?latex=H_%7Bin%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H_{in} "/> checks that at time <img alt="t=0" class="latex" src="https://s0.wp.com/latex.php?latex=t%3D0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t=0"/>, <img alt="\textsf{state}_0 " class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctextsf%7Bstate%7D_0+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\textsf{state}_0 "/> consists of the input <img alt="|0\rangle^n " class="latex" src="https://s0.wp.com/latex.php?latex=%7C0%5Crangle%5En+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|0\rangle^n "/> to <img alt="C_n" class="latex" src="https://s0.wp.com/latex.php?latex=C_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_n"/>.  Each <img alt="H_t " class="latex" src="https://s0.wp.com/latex.php?latex=H_t+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H_t "/> checks that <img alt="\textsf{state}_{t} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctextsf%7Bstate%7D_%7Bt%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\textsf{state}_{t} "/> proceed correctly from <img alt="\textsf{state}_{t-1} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctextsf%7Bstate%7D_%7Bt-1%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\textsf{state}_{t-1} "/> (i.e. that the <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t"/>th gate of <img alt="C_n " class="latex" src="https://s0.wp.com/latex.php?latex=C_n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_n "/> is applied correctly).  Then <img alt="H_{out} " class="latex" src="https://s0.wp.com/latex.php?latex=H_%7Bout%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H_{out} "/> checks that at time <img alt="t=T" class="latex" src="https://s0.wp.com/latex.php?latex=t%3DT&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t=T"/>, the output is <img alt="1" class="latex" src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1"/>.  Finally, <img alt="H_{stab} " class="latex" src="https://s0.wp.com/latex.php?latex=H_%7Bstab%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H_{stab} "/> checks that the <img alt="T+n " class="latex" src="https://s0.wp.com/latex.php?latex=T%2Bn+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T+n "/> qubit state is a superposition only over states where the first <img alt="T " class="latex" src="https://s0.wp.com/latex.php?latex=T+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T "/> qubits represent “correct times” (i.e. a unary clock state where time <img alt="t " class="latex" src="https://s0.wp.com/latex.php?latex=t+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t "/> is represented by <img alt="T-t " class="latex" src="https://s0.wp.com/latex.php?latex=T-t+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T-t "/> zeros followed by <img alt="t " class="latex" src="https://s0.wp.com/latex.php?latex=t+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t "/> ones).</p>

<p>Therefore, <img alt="\mathcal{H} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{H} "/> has a unique ground state, the history state of <img alt="C_n|0^n\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=C_n%7C0%5En%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_n|0^n\rangle"/>, with energy <img alt="0" class="latex" src="https://s0.wp.com/latex.php?latex=0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="0"/>:</p>

<div style="text-align: center;"><p><img alt="\begin{aligned}|\Psi\rangle = \frac{1}{\sqrt{n+1}}\sum_{t=0}^n |\textsf{unary}(t)\rangle\otimes |\psi_t\rangle = \frac{1}{\sqrt{n+1}}\sum_{t=0}^n |\textsf{unary}(t)\rangle\otimes|\textsf{CAT}_{t}\rangle\otimes |0\rangle^{\otimes (n-t)}\end{aligned} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D%7C%5CPsi%5Crangle+%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7Bn%2B1%7D%7D%5Csum_%7Bt%3D0%7D%5En+%7C%5Ctextsf%7Bunary%7D%28t%29%5Crangle%5Cotimes+%7C%5Cpsi_t%5Crangle+%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7Bn%2B1%7D%7D%5Csum_%7Bt%3D0%7D%5En+%7C%5Ctextsf%7Bunary%7D%28t%29%5Crangle%5Cotimes%7C%5Ctextsf%7BCAT%7D_%7Bt%7D%5Crangle%5Cotimes+%7C0%5Crangle%5E%7B%5Cotimes+%28n-t%29%7D%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned}|\Psi\rangle = \frac{1}{\sqrt{n+1}}\sum_{t=0}^n |\textsf{unary}(t)\rangle\otimes |\psi_t\rangle = \frac{1}{\sqrt{n+1}}\sum_{t=0}^n |\textsf{unary}(t)\rangle\otimes|\textsf{CAT}_{t}\rangle\otimes |0\rangle^{\otimes (n-t)}\end{aligned} "/></p></div>

<p>Later we will show how to transform <img alt="\mathcal{H} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{H} "/> into a Hamiltonian <img alt="H " class="latex" src="https://s0.wp.com/latex.php?latex=H+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H "/> on <img alt="n " class="latex" src="https://s0.wp.com/latex.php?latex=n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n "/> qutrits on a line.  Intuitively, the structure of <img alt="C_n " class="latex" src="https://s0.wp.com/latex.php?latex=C_n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_n "/> allows us to fuse the <img alt="T=n " class="latex" src="https://s0.wp.com/latex.php?latex=T%3Dn+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T=n "/> time qubits and <img alt="n " class="latex" src="https://s0.wp.com/latex.php?latex=n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n "/> state qubits and represent unused state qubits by <img alt="2" class="latex" src="https://s0.wp.com/latex.php?latex=2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2"/>.  For the Hamiltonian <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/>, the ground state becomes</p>

<div style="text-align: center;"><p><img alt="\begin{aligned}|\Psi\rangle = \frac{1}{\sqrt{n+1}}\sum_{t=0}^n |\psi_t\rangle = \sum_{t=0}^n |\textsf{CAT}_{t}\rangle\otimes|2\rangle^{\otimes(n-t)}\end{aligned} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D%7C%5CPsi%5Crangle+%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7Bn%2B1%7D%7D%5Csum_%7Bt%3D0%7D%5En+%7C%5Cpsi_t%5Crangle+%3D+%5Csum_%7Bt%3D0%7D%5En+%7C%5Ctextsf%7BCAT%7D_%7Bt%7D%5Crangle%5Cotimes%7C2%5Crangle%5E%7B%5Cotimes%28n-t%29%7D%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned}|\Psi\rangle = \frac{1}{\sqrt{n+1}}\sum_{t=0}^n |\psi_t\rangle = \sum_{t=0}^n |\textsf{CAT}_{t}\rangle\otimes|2\rangle^{\otimes(n-t)}\end{aligned} "/></p></div>

<p>For the rest of this proof, we work with respect to <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/>.</p>

<p>Let <img alt="\sigma " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csigma+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sigma "/> be an <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon"/>-error state and let <img alt="S \subseteq [n] " class="latex" src="https://s0.wp.com/latex.php?latex=S+%5Csubseteq+%5Bn%5D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S \subseteq [n] "/> be the subset of qutrits such that <img alt="\text{Tr}_S(\sigma) = \text{Tr}_S(|\Psi\rangle\langle\Psi|)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctext%7BTr%7D_S%28%5Csigma%29+%3D+%5Ctext%7BTr%7D_S%28%7C%5CPsi%5Crangle%5Clangle%5CPsi%7C%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\text{Tr}_S(\sigma) = \text{Tr}_S(|\Psi\rangle\langle\Psi|)"/>.  We define two projection operators which, when applied to <img alt="\sigma " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csigma+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sigma "/> alone, produce nontrivial measurements, but when applied to <img alt="\sigma " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csigma+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sigma "/> together, produce trivial measurements.</p>

<p><b>Definition 5.1</b>: <i>For any <img alt="i\in[n]" class="latex" src="https://s0.wp.com/latex.php?latex=i%5Cin%5Bn%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i\in[n]"/>, the projection operator</i></p>

<div style="text-align: center;"><p><img alt="\begin{aligned}A_i = |0\rangle\langle 0|_i \end{aligned} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7DA_i+%3D+%7C0%5Crangle%5Clangle+0%7C_i+%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned}A_i = |0\rangle\langle 0|_i \end{aligned} "/></p></div>

<p><i>projects onto the subspace spanned by <img alt="0 " class="latex" src="https://s0.wp.com/latex.php?latex=0+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="0 "/> on the <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/>th qutrit.</i></p>

<p><i>For any <img alt="j\in[n]" class="latex" src="https://s0.wp.com/latex.php?latex=j%5Cin%5Bn%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="j\in[n]"/>, the projection operator</i></p>

<div style="text-align: center;"><p><img alt="\begin{aligned} B_j = |1\rangle\langle 1|_i\end{aligned} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+B_j+%3D+%7C1%5Crangle%5Clangle+1%7C_i%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} B_j = |1\rangle\langle 1|_i\end{aligned} "/></p></div>

<p><i>projects onto the subspace spanned by <img alt="1 " class="latex" src="https://s0.wp.com/latex.php?latex=1+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1 "/> on the <img alt="j" class="latex" src="https://s0.wp.com/latex.php?latex=j&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="j"/>th qutrit.</i></p>

<p><b>Claim 5.1</b>:
<i>For <img alt="i\not\in S" class="latex" src="https://s0.wp.com/latex.php?latex=i%5Cnot%5Cin+S&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i\not\in S"/>, <img alt="\text{Tr}(A_i\sigma) = \frac{1}{2} + \frac{-i}{2(n+1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctext%7BTr%7D%28A_i%5Csigma%29+%3D+%5Cfrac%7B1%7D%7B2%7D+%2B+%5Cfrac%7B-i%7D%7B2%28n%2B1%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\text{Tr}(A_i\sigma) = \frac{1}{2} + \frac{-i}{2(n+1)}"/>.  For <img alt="j\not\in S" class="latex" src="https://s0.wp.com/latex.php?latex=j%5Cnot%5Cin+S&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="j\not\in S"/>, <img alt="\text{Tr}(B_j\sigma) = \frac{1}{2} + \frac{-j}{2(n+1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctext%7BTr%7D%28B_j%5Csigma%29+%3D+%5Cfrac%7B1%7D%7B2%7D+%2B+%5Cfrac%7B-j%7D%7B2%28n%2B1%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\text{Tr}(B_j\sigma) = \frac{1}{2} + \frac{-j}{2(n+1)}"/>.  Note that these values are positive for any <img alt="i,j\in [n]" class="latex" src="https://s0.wp.com/latex.php?latex=i%2Cj%5Cin+%5Bn%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i,j\in [n]"/>.</i></p>

<p><i>Proof</i>: If <img alt="i \not\in S" class="latex" src="https://s0.wp.com/latex.php?latex=i+%5Cnot%5Cin+S&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i \not\in S"/>, then measurements on the <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/>th qutrit are the same for <img alt="\sigma " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csigma+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sigma "/> and <img alt="|\Psi\rangle\langle\Psi|" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5CPsi%5Crangle%5Clangle%5CPsi%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\Psi\rangle\langle\Psi|"/>.</p>

<div style="text-align: center;"><p><img alt="\begin{aligned}     \text{Tr}(A_i\sigma) &amp;= \text{Tr}(A_i|\Psi\rangle\langle\Psi|)\\     &amp;= \text{Tr}\left(A_i \frac{1}{n+1}\sum_{t,t'}|\psi_t\rangle\langle\psi_{t'}|\right)\\     &amp;= \frac{1}{n+1}\sum_{t,t'} \text{Tr}(A_i|\psi_t\rangle\langle\psi_{t'}|)   \end{aligned} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+++++%5Ctext%7BTr%7D%28A_i%5Csigma%29+%26%3D+%5Ctext%7BTr%7D%28A_i%7C%5CPsi%5Crangle%5Clangle%5CPsi%7C%29%5C%5C+++++%26%3D+%5Ctext%7BTr%7D%5Cleft%28A_i+%5Cfrac%7B1%7D%7Bn%2B1%7D%5Csum_%7Bt%2Ct%27%7D%7C%5Cpsi_t%5Crangle%5Clangle%5Cpsi_%7Bt%27%7D%7C%5Cright%29%5C%5C+++++%26%3D+%5Cfrac%7B1%7D%7Bn%2B1%7D%5Csum_%7Bt%2Ct%27%7D+%5Ctext%7BTr%7D%28A_i%7C%5Cpsi_t%5Crangle%5Clangle%5Cpsi_%7Bt%27%7D%7C%29+++%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned}     \text{Tr}(A_i\sigma) &amp;= \text{Tr}(A_i|\Psi\rangle\langle\Psi|)\\     &amp;= \text{Tr}\left(A_i \frac{1}{n+1}\sum_{t,t'}|\psi_t\rangle\langle\psi_{t'}|\right)\\     &amp;= \frac{1}{n+1}\sum_{t,t'} \text{Tr}(A_i|\psi_t\rangle\langle\psi_{t'}|)   \end{aligned} "/></p></div>

<p>If <img alt="t=t'" class="latex" src="https://s0.wp.com/latex.php?latex=t%3Dt%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t=t'"/>, then any <img alt="n " class="latex" src="https://s0.wp.com/latex.php?latex=n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n "/> qutrit pure state cannot have nonzero weight in both <img alt="\psi_t " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpsi_t+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\psi_t "/> and <img alt="\psi_{t'} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpsi_%7Bt%27%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\psi_{t'} "/> (every pure state ends in some number of <img alt="2" class="latex" src="https://s0.wp.com/latex.php?latex=2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2"/>s which tells which <img alt="\psi_t " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpsi_t+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\psi_t "/> (if any) it can be a part of). Therefore,</p>

<div style="text-align: center;"><p><img alt="\begin{aligned}     \text{Tr}(A_i\sigma) = \frac{1}{n+1}\sum_{t} \text{Tr}(A_i|\psi_t\rangle\langle\psi_{t}|) = \frac{1}{n+1}\sum_t \langle \psi_t|A_i|\psi_t\rangle \enspace. \end{aligned} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+++++%5Ctext%7BTr%7D%28A_i%5Csigma%29+%3D+%5Cfrac%7B1%7D%7Bn%2B1%7D%5Csum_%7Bt%7D+%5Ctext%7BTr%7D%28A_i%7C%5Cpsi_t%5Crangle%5Clangle%5Cpsi_%7Bt%7D%7C%29+%3D+%5Cfrac%7B1%7D%7Bn%2B1%7D%5Csum_t+%5Clangle+%5Cpsi_t%7CA_i%7C%5Cpsi_t%5Crangle+%5Censpace.+%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned}     \text{Tr}(A_i\sigma) = \frac{1}{n+1}\sum_{t} \text{Tr}(A_i|\psi_t\rangle\langle\psi_{t}|) = \frac{1}{n+1}\sum_t \langle \psi_t|A_i|\psi_t\rangle \enspace. \end{aligned} "/></p></div>

<p>If <img alt="i \le t" class="latex" src="https://s0.wp.com/latex.php?latex=i+%5Cle+t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i \le t"/>, then projecting onto the <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/>th qutrit gives <img alt="0 " class="latex" src="https://s0.wp.com/latex.php?latex=0+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="0 "/> with probability <img alt="1/2" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/2"/>. Therefore, <img alt="\text{Tr}(A_i\sigma) = \frac{1}{n+1}\left(\frac{n-i+1}{2}\right) = \frac{1}{2} + \frac{-i}{2(n+1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctext%7BTr%7D%28A_i%5Csigma%29+%3D+%5Cfrac%7B1%7D%7Bn%2B1%7D%5Cleft%28%5Cfrac%7Bn-i%2B1%7D%7B2%7D%5Cright%29+%3D+%5Cfrac%7B1%7D%7B2%7D+%2B+%5Cfrac%7B-i%7D%7B2%28n%2B1%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\text{Tr}(A_i\sigma) = \frac{1}{n+1}\left(\frac{n-i+1}{2}\right) = \frac{1}{2} + \frac{-i}{2(n+1)}"/>.</p>

<p>Similarly, <img alt="\text{Tr}(B_j\sigma) = \frac{1}{2} + \frac{-j}{2(n+1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctext%7BTr%7D%28B_j%5Csigma%29+%3D+%5Cfrac%7B1%7D%7B2%7D+%2B+%5Cfrac%7B-j%7D%7B2%28n%2B1%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\text{Tr}(B_j\sigma) = \frac{1}{2} + \frac{-j}{2(n+1)}"/>. <img alt="\square " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\square "/></p>

<p><b>Claim 5.2</b>: <i>For <img alt="i,j \not\in S " class="latex" src="https://s0.wp.com/latex.php?latex=i%2Cj+%5Cnot%5Cin+S+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i,j \not\in S "/> such that <img alt="i &lt; j" class="latex" src="https://s0.wp.com/latex.php?latex=i+%3C+j&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i &lt; j"/>, <img alt="\text{Tr}(A_i \otimes B_j \sigma) = 0" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctext%7BTr%7D%28A_i+%5Cotimes+B_j+%5Csigma%29+%3D+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\text{Tr}(A_i \otimes B_j \sigma) = 0"/>.</i></p>

<p><i>Proof</i>:
As before, we can calculate</p>

<div style="text-align: center;"><p><img alt="\begin{aligned} \text{Tr}(A_i \otimes B_j \sigma) &amp;= \text{Tr}(A_i \otimes B_j |\Psi\rangle \langle\Psi|) = \frac{1}{n+1}\sum_t \langle\psi_t|A_i\otimes B_j|\psi_t\rangle \end{aligned} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Ctext%7BTr%7D%28A_i+%5Cotimes+B_j+%5Csigma%29+%26%3D+%5Ctext%7BTr%7D%28A_i+%5Cotimes+B_j+%7C%5CPsi%5Crangle+%5Clangle%5CPsi%7C%29+%3D+%5Cfrac%7B1%7D%7Bn%2B1%7D%5Csum_t+%5Clangle%5Cpsi_t%7CA_i%5Cotimes+B_j%7C%5Cpsi_t%5Crangle+%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \text{Tr}(A_i \otimes B_j \sigma) &amp;= \text{Tr}(A_i \otimes B_j |\Psi\rangle \langle\Psi|) = \frac{1}{n+1}\sum_t \langle\psi_t|A_i\otimes B_j|\psi_t\rangle \end{aligned} "/></p></div>

<p>If <img alt="j &gt; t" class="latex" src="https://s0.wp.com/latex.php?latex=j+%3E+t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="j &gt; t"/>, then the <img alt="j" class="latex" src="https://s0.wp.com/latex.php?latex=j&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="j"/>th qutrit of <img alt="\psi_t " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpsi_t+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\psi_t "/> is <img alt="2 " class="latex" src="https://s0.wp.com/latex.php?latex=2+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2 "/> so <img alt="B_j|\psi_t\rangle = 0" class="latex" src="https://s0.wp.com/latex.php?latex=B_j%7C%5Cpsi_t%5Crangle+%3D+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B_j|\psi_t\rangle = 0"/>. If <img alt="j \le t" class="latex" src="https://s0.wp.com/latex.php?latex=j+%5Cle+t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="j \le t"/>, then <img alt="A_i \otimes B_j|\psi_t\rangle = 0 " class="latex" src="https://s0.wp.com/latex.php?latex=A_i+%5Cotimes+B_j%7C%5Cpsi_t%5Crangle+%3D+0+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_i \otimes B_j|\psi_t\rangle = 0 "/> because the first <img alt="t " class="latex" src="https://s0.wp.com/latex.php?latex=t+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t "/> qutrits of <img alt="|\psi_t\rangle " class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi_t%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi_t\rangle "/> contain the <img alt="|\textsf{CAT}_{t}\rangle " class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Ctextsf%7BCAT%7D_%7Bt%7D%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\textsf{CAT}_{t}\rangle "/> state so under any measurement, the <img alt="i " class="latex" src="https://s0.wp.com/latex.php?latex=i+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i "/> and <img alt="j" class="latex" src="https://s0.wp.com/latex.php?latex=j&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="j"/>th qutrits must be the same. <img alt="\square " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\square "/></p>

<p>Now we use these claims to prove a circuit lower bound.  Let <img alt="U " class="latex" src="https://s0.wp.com/latex.php?latex=U+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U "/> be a circuit generating (a state with density matrix) <img alt="\sigma" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csigma&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sigma"/>.  Let <img alt="d " class="latex" src="https://s0.wp.com/latex.php?latex=d+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d "/> be the depth of <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/>.</p>

<p>Consider some <img alt="i\not\in S" class="latex" src="https://s0.wp.com/latex.php?latex=i%5Cnot%5Cin+S&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i\not\in S"/>.  For any operator acting on the <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/>th qutrit, its lightcone consists of at most <img alt="2^d " class="latex" src="https://s0.wp.com/latex.php?latex=2%5Ed+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^d "/> gates so its effect zone consists of at most <img alt="2^{2d} " class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7B2d%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{2d} "/> gates which act on at most <img alt="2^{2d+1} " class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7B2d%2B1%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{2d+1} "/> qudits (called the shadow of the effect zone).</p>

<p>Assume towards contradiction that <img alt="2^{2d+1} &lt; n-\epsilon n" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7B2d%2B1%7D+%3C+n-%5Cepsilon+n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{2d+1} &lt; n-\epsilon n"/>. Then the shadow of any operator acting only on the <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/>th qutrit has size at most <img alt="2^{2d+1} \le n - |S| " class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7B2d%2B1%7D+%5Cle+n+-+%7CS%7C+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{2d+1} \le n - |S| "/> since <img alt="|S| \le \epsilon n" class="latex" src="https://s0.wp.com/latex.php?latex=%7CS%7C+%5Cle+%5Cepsilon+n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|S| \le \epsilon n"/>.  So there is some <img alt="j " class="latex" src="https://s0.wp.com/latex.php?latex=j+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="j "/> outside of the shadow which is in the complement of <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S"/>.  By <a href="https://windowsontheory.org/feed/#claim3">Claim 3.1</a>, we have found two indices <img alt="i,j " class="latex" src="https://s0.wp.com/latex.php?latex=i%2Cj+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i,j "/> such that any pair of operators acting on <img alt="i " class="latex" src="https://s0.wp.com/latex.php?latex=i+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i "/> and <img alt="j " class="latex" src="https://s0.wp.com/latex.php?latex=j+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="j "/> have disjoint lightcones in <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/>. WLOG let <img alt="i &lt; j" class="latex" src="https://s0.wp.com/latex.php?latex=i+%3C+j&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i &lt; j"/>.  The lightcones of <img alt="A_i,B_j " class="latex" src="https://s0.wp.com/latex.php?latex=A_i%2CB_j+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_i,B_j "/> are disjoint which implies
<img alt="\begin{aligned}\text{Tr}(A_i \otimes B_j \sigma) = \text{Tr}(A_i \sigma)\cdot\text{Tr}(B_j \sigma).\end{aligned} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D%5Ctext%7BTr%7D%28A_i+%5Cotimes+B_j+%5Csigma%29+%3D+%5Ctext%7BTr%7D%28A_i+%5Csigma%29%5Ccdot%5Ctext%7BTr%7D%28B_j+%5Csigma%29.%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned}\text{Tr}(A_i \otimes B_j \sigma) = \text{Tr}(A_i \sigma)\cdot\text{Tr}(B_j \sigma).\end{aligned} "/></p>

<p>By the two claims above, we get a contradiction.</p>

<p>Therefore, <img alt="2^{2d+1} \ge n-\epsilon n" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7B2d%2B1%7D+%5Cge+n-%5Cepsilon+n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{2d+1} \ge n-\epsilon n"/>.  We can take any constant epsilon: letting <img alt="\epsilon = 1/2" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon+%3D+1%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon = 1/2"/>, we get</p>

<div style="text-align: center;"><p><img alt="\begin{aligned}d \ge \frac{1}{2}\left(\log \frac{n}{2} - 1\right)\end{aligned} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7Dd+%5Cge+%5Cfrac%7B1%7D%7B2%7D%5Cleft%28%5Clog+%5Cfrac%7Bn%7D%7B2%7D+-+1%5Cright%29%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned}d \ge \frac{1}{2}\left(\log \frac{n}{2} - 1\right)\end{aligned} "/></p></div>

<p><img alt="\square " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\square "/></p>

<p>This analysis relies crucially on the fact that any <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon"/>-error state matches the groundstate on most qudits.  However, NLTS is concerned with states which may differ from the groundstate on many qudits, as long as they have low energy.</p>

<p><b>Remark 2.1</b>: <i>The paper of Nirkhe, Vazirani, and Yuen [<a href="https://windowsontheory.org/feed/#nirkhe2018approximate">2</a>] actually proves more:
</i></p><ul><i>
    </i><li><i>A more general lower bound: logarithmic lower bound on the circuit depth of any <img alt="\delta" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdelta&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\delta"/>-approximate (<img alt="\delta " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdelta+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\delta "/> far in L1 norm) <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon"/>-noisy state (probability distribution over <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon"/>-error states).</i></li><i>
    </i><li><i>Assuming QCMA <img alt="\neq " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cneq+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\neq "/> QMA (QCMA takes a <img alt="m " class="latex" src="https://s0.wp.com/latex.php?latex=m+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m "/> bit witness string instead of a <img alt="m " class="latex" src="https://s0.wp.com/latex.php?latex=m+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m "/> qubit state as witness), they show a superpolynomial lower bound (on the circuit depth of any <img alt="\delta" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdelta&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\delta"/>-approximate <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon"/>-noisy state).</i></li><i>
    </i><li><i>“Approximate qLWC codes”, using techniques from their superpolynomial lower bound.</i></li><i>
</i></ul><p/>

<h2>Back to NLTS – Tempering our Optimism</h2>

<p>So far, we’ve shown a local Hamiltonian family for which all low-error (in “Hamming distance”) states require logarithmic quantum circuit depth to compute, thus resolving the NLETS conjecture. Now, let’s try to tie this back into the NLTS conjecture. Since it’s been a while, let’s recall the statement of the conjecture:</p>

<p><b>Conjecture</b> (NLTS): <i>There exists a universal constant <img alt="\epsilon &gt; 0 " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon+%3E+0+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon &gt; 0 "/> and a family of local Hamiltonians <img alt="\{H^{(n)}\}_{n=1}^{\infty} " class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7BH%5E%7B%28n%29%7D%5C%7D_%7Bn%3D1%7D%5E%7B%5Cinfty%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{H^{(n)}\}_{n=1}^{\infty} "/> where <img alt="H^{(n)} " class="latex" src="https://s0.wp.com/latex.php?latex=H%5E%7B%28n%29%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H^{(n)} "/> acts on <img alt="n " class="latex" src="https://s0.wp.com/latex.php?latex=n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n "/> particles and consists of <img alt="m_{n} " class="latex" src="https://s0.wp.com/latex.php?latex=m_%7Bn%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m_{n} "/> local terms, s.t. any family of states <img alt="\{|\psi_{n}\rangle\} " class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B%7C%5Cpsi_%7Bn%7D%5Crangle%5C%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{|\psi_{n}\rangle\} "/> satisfying <img alt="\langle \psi_{n} | H^{(n)} | \psi_{n}\rangle \leq \epsilon||H^{(n)}|| + \lambda_{min}(H^{(n)}) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Clangle+%5Cpsi_%7Bn%7D+%7C+H%5E%7B%28n%29%7D+%7C+%5Cpsi_%7Bn%7D%5Crangle+%5Cleq+%5Cepsilon%7C%7CH%5E%7B%28n%29%7D%7C%7C+%2B+%5Clambda_%7Bmin%7D%28H%5E%7B%28n%29%7D%29+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\langle \psi_{n} | H^{(n)} | \psi_{n}\rangle \leq \epsilon||H^{(n)}|| + \lambda_{min}(H^{(n)}) "/> requires circuit depth that grows faster than any constant.</i></p>

<p>In order to resolve the NLTS conjecture, it thus suffices to exhibit a local Hamiltonian family for which all low-energy states require logarithmic quantum circuit depth to compute. We might wonder if the local Hamiltonian family we used to resolve NLETS, which has “hard ground states”, might also have hard low-energy states. Unfortunately, as we shall show, this cannot be the case. We will start by showing that Hamiltonian families that lie on constant-dimensional lattices (in a sense that we will make precise momentarily) cannot possibly be used to resolve NLTS,  and then show that the Hamiltonian family we used to prove NLTS can be linearized (made to lie on a one-dimensional lattice!).</p>

<h3>The Woes of Constant-Dimensional Lattices</h3>
<p><b>Definition 6.1</b>: <i>A local Hamiltonian <img alt="H " class="latex" src="https://s0.wp.com/latex.php?latex=H+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H "/> acting on <img alt="n " class="latex" src="https://s0.wp.com/latex.php?latex=n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n "/> qubits is said to <b>lie on a graph <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/></b> if there is an injection of qubits into vertices of the graph such that the set of qubits in any interaction term correspond to a connected component in the graph</i>.</p>

<p><b>Theorem 2</b>: <i>If <img alt="(H^{(n)}) " class="latex" src="https://s0.wp.com/latex.php?latex=%28H%5E%7B%28n%29%7D%29+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(H^{(n)}) "/> is a local Hamiltonian family that lies on an <img alt="O(1)" class="latex" src="https://s0.wp.com/latex.php?latex=O%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(1)"/>-dimensional lattice, then <img alt="(H^{(n)}) " class="latex" src="https://s0.wp.com/latex.php?latex=%28H%5E%7B%28n%29%7D%29+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(H^{(n)}) "/> has a family of low-energy states with low circuit complexity. In particular, if <img alt="H " class="latex" src="https://s0.wp.com/latex.php?latex=H+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H "/> is a local Hamiltonian on a <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/>-dimensional lattice acting on <img alt="n " class="latex" src="https://s0.wp.com/latex.php?latex=n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n "/> qubits for large enough <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>, then for any <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon"/>, there exists a state <img alt="|\psi\rangle " class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi\rangle "/> that can be generated by a circuit of constant depth and such that <img alt="\langle \psi | H | \psi \rangle \leq H_0 + \epsilon ||H|| " class="latex" src="https://s0.wp.com/latex.php?latex=%5Clangle+%5Cpsi+%7C+H+%7C+%5Cpsi+%5Crangle+%5Cleq+H_0+%2B+%5Cepsilon+%7C%7CH%7C%7C+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\langle \psi | H | \psi \rangle \leq H_0 + \epsilon ||H|| "/> where <img alt="H_0 " class="latex" src="https://s0.wp.com/latex.php?latex=H_0+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H_0 "/> is the ground-state energy.</i></p>

<p><i>Proof</i>: In what follows, we’ll omit some of the more annoying computational details in the interest of communicating the high-level idea.</p>

<p>Start by partitioning the <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/>-dimensional lattice (the one that <img alt="H^(n) " class="latex" src="https://s0.wp.com/latex.php?latex=H%5E%28n%29+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H^(n) "/> lives on) into hypercubes of side length <img alt="L" class="latex" src="https://s0.wp.com/latex.php?latex=L&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="L"/>. We can “restrict” <img alt="H^{(n)} " class="latex" src="https://s0.wp.com/latex.php?latex=H%5E%7B%28n%29%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H^{(n)} "/> to a given hypercube (let’s call it <img alt="\rho" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho"/>) by throwing away all local terms containing a qubit not in <img alt="\rho" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho"/>. This gives us a well-defined Hamiltonian <img alt="H_{\rho} " class="latex" src="https://s0.wp.com/latex.php?latex=H_%7B%5Crho%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H_{\rho} "/> on the qubits in <img alt="\rho" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho"/>. Define <img alt="|\phi_{\rho}\rangle " class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cphi_%7B%5Crho%7D%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\phi_{\rho}\rangle "/> to be the <img alt="L^d" class="latex" src="https://s0.wp.com/latex.php?latex=L%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="L^d"/>-qubit ground state of <img alt="H_{\rho}" class="latex" src="https://s0.wp.com/latex.php?latex=H_%7B%5Crho%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H_{\rho}"/>, and define</p>

<div style="text-align: center;"><p><img alt="\begin{aligned}|\phi\rangle := \bigotimes_{\text{hypercubes } \rho} |\phi_{\rho}\rangle\end{aligned} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D%7C%5Cphi%5Crangle+%3A%3D+%5Cbigotimes_%7B%5Ctext%7Bhypercubes+%7D+%5Crho%7D+%7C%5Cphi_%7B%5Crho%7D%5Crangle%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned}|\phi\rangle := \bigotimes_{\text{hypercubes } \rho} |\phi_{\rho}\rangle\end{aligned} "/></p></div>

<p>where <img alt="|\phi\rangle " class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cphi%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\phi\rangle "/> is an <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>-qubit state. Each <img alt="|\phi_{\rho}\rangle " class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cphi_%7B%5Crho%7D%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\phi_{\rho}\rangle "/> can be generated by a circuit with at most <img alt="2^{L^d} " class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7BL%5Ed%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{L^d} "/> gates, hence at most <img alt="2^{L^d} " class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7BL%5Ed%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{L^d} "/> depth. Then, <img alt="|\phi\rangle " class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cphi%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\phi\rangle "/> can be generated by putting all of these individual circuits in parallel – this doesn’t violate any sort of no-cloning condition because the individual circuits act on disjoint sets of qubits. Therefore, <img alt="|\phi\rangle " class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cphi%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\phi\rangle "/> can be generated by a circuit of depth at most <img alt="2^{L^d}" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7BL%5Ed%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{L^d}"/>. <img alt="L " class="latex" src="https://s0.wp.com/latex.php?latex=L+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="L "/> and <img alt="d " class="latex" src="https://s0.wp.com/latex.php?latex=d+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d "/> are both constants, so <img alt="|\phi\rangle " class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cphi%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\phi\rangle "/> can be generated by a constant-depth circuit.</p>

<p>We claim that, for the right choice of <img alt="L" class="latex" src="https://s0.wp.com/latex.php?latex=L&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="L"/>, <img alt="|\phi\rangle " class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cphi%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\phi\rangle "/> is also a low-energy state. Intuitively, this is true because <img alt="\phi " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cphi+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\phi "/> can only be “worse” than a true ground state of <img alt="H^{(n)} " class="latex" src="https://s0.wp.com/latex.php?latex=H%5E%7B%28n%29%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H^{(n)} "/> on local Hamiltonian terms that do not lie entirely within a single hypercube (i.e. the boundary terms), and by choosing <img alt="L " class="latex" src="https://s0.wp.com/latex.php?latex=L+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="L "/> appropriately we can make this a vanishingly small fraction of the local terms of <img alt="H^{(n)}" class="latex" src="https://s0.wp.com/latex.php?latex=H%5E%7B%28n%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H^{(n)}"/>. Let’s work this out explicitly.</p>

<p>Each hypercube has surface area <img alt="2dL^{d-1}" class="latex" src="https://s0.wp.com/latex.php?latex=2dL%5E%7Bd-1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2dL^{d-1}"/>, and there are <img alt="n/L^d " class="latex" src="https://s0.wp.com/latex.php?latex=n%2FL%5Ed+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n/L^d "/> hypercubes in the lattice. Thus, the total number of qubits on boundaries is at most <img alt="2d\frac{n}{L}" class="latex" src="https://s0.wp.com/latex.php?latex=2d%5Cfrac%7Bn%7D%7BL%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2d\frac{n}{L}"/>. The number of size <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-connected components containing a given point in a <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/>-dimensional lattice is a function of <img alt="k " class="latex" src="https://s0.wp.com/latex.php?latex=k+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k "/> and <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/>. Both of these are constants. Therefore, the number of size <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-connected components containing a given vertex, and hence the number of local Hamiltonian terms containing a given qubit, is constant. Thus, the total number of violated local Hamiltonian terms is at most <img alt="O(\frac{n}{L})" class="latex" src="https://s0.wp.com/latex.php?latex=O%28%5Cfrac%7Bn%7D%7BL%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(\frac{n}{L})"/>. Taking <img alt="L " class="latex" src="https://s0.wp.com/latex.php?latex=L+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="L "/> to be <img alt="\frac{1}{\epsilon}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B%5Cepsilon%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\frac{1}{\epsilon}"/>, we get the desired bound. Note that to be fully rigorous, we need to justify that the boundary terms don’t blow up the energy, but this is left as an exercise for the reader. <img alt="\square " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\square "/></p>

<h3>Linearizing the Hamiltonian</h3>
<p>Now that we have shown that Hamiltonians that live on constant-dimensional lattices cannot be used to prove NLTS, we will put the final nail in the coffin by showing that our NLETS Hamiltonian (the Feynman-Kitaev clock Hamiltonian <img alt="\mathcal{H} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{H} "/> on the circuit <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/>) can be made to lie on a line (a <img alt="1" class="latex" src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1"/>-dimensional lattice). To do so, we will need to understand the details of <img alt="\mathcal{H} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{H} "/> a bit better.</p>

<p><b><a id="prop6">Proposition 6.1</a></b>: <i><img alt="\mathcal{H} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{H} "/> for the circuit <img alt="C " class="latex" src="https://s0.wp.com/latex.php?latex=C+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C "/> is <img alt="5" class="latex" src="https://s0.wp.com/latex.php?latex=5&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="5"/>-local.</i></p>

<p><i>Proof</i>: Recall that we defined</p>

<div style="text-align: center;"><p><img alt="\begin{aligned}\mathcal{H} := H_{in} + \sum_{t=1}^T H_t+  H_{stab}\end{aligned} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D%5Cmathcal%7BH%7D+%3A%3D+H_%7Bin%7D+%2B+%5Csum_%7Bt%3D1%7D%5ET+H_t%2B++H_%7Bstab%7D%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned}\mathcal{H} := H_{in} + \sum_{t=1}^T H_t+  H_{stab}\end{aligned} "/></p></div>

<p>Let’s go through the right-hand-side term-by-term. We will use <img alt="|\mathsf{time}(t)\rangle " class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cmathsf%7Btime%7D%28t%29%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\mathsf{time}(t)\rangle "/> to denote the <img alt="t^{\text{th}} " class="latex" src="https://s0.wp.com/latex.php?latex=t%5E%7B%5Ctext%7Bth%7D%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t^{\text{th}} "/> qubit of the time register and <img alt="|\mathsf{state}(s)\rangle " class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cmathsf%7Bstate%7D%28s%29%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\mathsf{state}(s)\rangle "/> to denote the <img alt="s^{\text{th}} " class="latex" src="https://s0.wp.com/latex.php?latex=s%5E%7B%5Ctext%7Bth%7D%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s^{\text{th}} "/> qubit of the state register.</p>

<p>
  </p><ul>
    <li><img alt="H_{in} " class="latex" src="https://s0.wp.com/latex.php?latex=H_%7Bin%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H_{in} "/> needs to serially access the qubit pairs

    <img alt="\begin{aligned}|\mathsf{time}(0)\rangle\otimes\textsf{state}(s) \end{aligned} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D%7C%5Cmathsf%7Btime%7D%280%29%5Crangle%5Cotimes%5Ctextsf%7Bstate%7D%28s%29+%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned}|\mathsf{time}(0)\rangle\otimes\textsf{state}(s) \end{aligned} "/>

    for all <img alt="s " class="latex" src="https://s0.wp.com/latex.php?latex=s+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s "/> and ensure that they are all set to <img alt="|0\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7C0%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|0\rangle"/>. Thus, <img alt="H_{in} " class="latex" src="https://s0.wp.com/latex.php?latex=H_%7Bin%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H_{in} "/> is <img alt="2" class="latex" src="https://s0.wp.com/latex.php?latex=2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2"/>-local.</li>
    <li>Each <img alt="H_t " class="latex" src="https://s0.wp.com/latex.php?latex=H_t+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H_t "/> term needs to access the states <img alt="|\textsf{time}(t-1)\rangle, |\textsf{time}(t)\rangle, |\textsf{time}(t+1)\rangle, |\textsf{state}(s)\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Ctextsf%7Btime%7D%28t-1%29%5Crangle%2C+%7C%5Ctextsf%7Btime%7D%28t%29%5Crangle%2C+%7C%5Ctextsf%7Btime%7D%28t%2B1%29%5Crangle%2C+%7C%5Ctextsf%7Bstate%7D%28s%29%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\textsf{time}(t-1)\rangle, |\textsf{time}(t)\rangle, |\textsf{time}(t+1)\rangle, |\textsf{state}(s)\rangle"/>, and  <img alt="|\textsf{state}(t)\rangle " class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Ctextsf%7Bstate%7D%28t%29%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\textsf{state}(t)\rangle "/> and ensure that the state transitions are correct. Thus, <img alt="H_{t} " class="latex" src="https://s0.wp.com/latex.php?latex=H_%7Bt%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H_{t} "/> is <img alt="5" class="latex" src="https://s0.wp.com/latex.php?latex=5&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="5"/>-local.</li>
    <li><img alt="H_{stab} " class="latex" src="https://s0.wp.com/latex.php?latex=H_%7Bstab%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H_{stab} "/> needs to access the states

    <img alt="\begin{aligned}|\textsf{time}(t)\rangle \otimes |\textsf{time}(t+1)\rangle \end{aligned} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D%7C%5Ctextsf%7Btime%7D%28t%29%5Crangle+%5Cotimes+%7C%5Ctextsf%7Btime%7D%28t%2B1%29%5Crangle+%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned}|\textsf{time}(t)\rangle \otimes |\textsf{time}(t+1)\rangle \end{aligned} "/>

    and ensure that the progression of the time register is correct. Thus, <img alt="H_{stab} " class="latex" src="https://s0.wp.com/latex.php?latex=H_%7Bstab%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H_{stab} "/> is <img alt="2" class="latex" src="https://s0.wp.com/latex.php?latex=2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2"/>-local. <img alt="\square " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\square "/></li>
  </ul>
<p/>


<p>Now, we follow an approach of [<a href="https://windowsontheory.org/feed/#aharonov2017">3</a>] to embed <img alt="\mathcal{H} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{H} "/> into a line.</p>

<p><b>Theorem 3</b>: <i>The Feynman-Kitaev clock Hamiltonian <img alt="H " class="latex" src="https://s0.wp.com/latex.php?latex=H+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H "/> can be manipulated into a <img alt="3" class="latex" src="https://s0.wp.com/latex.php?latex=3&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="3"/>-local Hamiltonian acting on qutrits on a line.</i></p>

<p><i>Proof</i>: Rather than having <img alt="\mathcal{H} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{H} "/> act on <img alt="2n " class="latex" src="https://s0.wp.com/latex.php?latex=2n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2n "/> total qubits (<img alt="n " class="latex" src="https://s0.wp.com/latex.php?latex=n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n "/> time qubits and <img alt="n " class="latex" src="https://s0.wp.com/latex.php?latex=n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n "/> state qubits), let’s fuse each <img alt="|\textsf{time}(i)\rangle " class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Ctextsf%7Btime%7D%28i%29%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\textsf{time}(i)\rangle "/> and <img alt="|\textsf{state}(i)\rangle " class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Ctextsf%7Bstate%7D%28i%29%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\textsf{state}(i)\rangle "/> pair into a single qudit of dimension <img alt="4" class="latex" src="https://s0.wp.com/latex.php?latex=4&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="4"/>. If we view <img alt="\mathcal{H} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{H} "/> as acting on the space of particles <img alt="|\textsf{time}(i)\rangle \otimes |\textsf{state}(i)\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Ctextsf%7Btime%7D%28i%29%5Crangle+%5Cotimes+%7C%5Ctextsf%7Bstate%7D%28i%29%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\textsf{time}(i)\rangle \otimes |\textsf{state}(i)\rangle"/>, we observe that, following <a href="https://windowsontheory.org/feed/#prop6">Proposition 6.1</a>, each local term needs to check at most the particles corresponding to times <img alt="t-1" class="latex" src="https://s0.wp.com/latex.php?latex=t-1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t-1"/>, <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t"/>, and <img alt="t+1" class="latex" src="https://s0.wp.com/latex.php?latex=t%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t+1"/>. Therefore, <img alt="\mathcal{H} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{H} "/> is <img alt="3" class="latex" src="https://s0.wp.com/latex.php?latex=3&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="3"/>-local and on a line, as desired.</p>



<figure class="wp-block-image"><img alt="" class="wp-image-6979" src="https://windowsontheory.files.wordpress.com/2018/12/qutrits.png?w=600"/>Image from [2]</figure>



<p>To see that we can have <img alt="\mathcal{H} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{H} "/> act on particles of dimension <img alt="3 " class="latex" src="https://s0.wp.com/latex.php?latex=3+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="3 "/> (qutrits) rather than particles of dimension <img alt="4" class="latex" src="https://s0.wp.com/latex.php?latex=4&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="4"/>, note that the degree of freedom corresponding to <img alt="|\textsf{time}(t)\rangle \otimes |\textsf{state}(t)\rangle = |0\rangle \otimes |1\rangle " class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Ctextsf%7Btime%7D%28t%29%5Crangle+%5Cotimes+%7C%5Ctextsf%7Bstate%7D%28t%29%5Crangle+%3D+%7C0%5Crangle+%5Cotimes+%7C1%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\textsf{time}(t)\rangle \otimes |\textsf{state}(t)\rangle = |0\rangle \otimes |1\rangle "/> is unused, as the <img alt="t^{\text{th}} " class="latex" src="https://s0.wp.com/latex.php?latex=t%5E%7B%5Ctext%7Bth%7D%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t^{\text{th}} "/> qubit of the state is never nonzero until timestamp <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t"/>. Thus, we can take the vectors</p>

<div style="text-align: center;"><p><img alt="\begin{aligned} |0\rangle := |1\rangle\otimes|0\rangle, |1\rangle := |1\rangle\otimes|1\rangle, |2\rangle := |0\rangle\otimes|0\rangle \end{aligned} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7C0%5Crangle+%3A%3D+%7C1%5Crangle%5Cotimes%7C0%5Crangle%2C+%7C1%5Crangle+%3A%3D+%7C1%5Crangle%5Cotimes%7C1%5Crangle%2C+%7C2%5Crangle+%3A%3D+%7C0%5Crangle%5Cotimes%7C0%5Crangle+%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} |0\rangle := |1\rangle\otimes|0\rangle, |1\rangle := |1\rangle\otimes|1\rangle, |2\rangle := |0\rangle\otimes|0\rangle \end{aligned} "/></p></div>

<p>as a basis for each qutrit.</p>

<p>Even though we’ve shown that the clock Hamiltonian for our original circuit cannot be used to prove NLTS (which is still weaker than the original Quantum PCP conjecture) this does not necessarily rule out the use of this approach for other “hard” circuits which might then allow us to prove NLTS. Furthermore, NLETS is independently interesting, as the notion of being low “Hamming distance” away from vectors is exactly what is used in error-correcting codes.</p>

<h1>References</h1>
<ul>
<li><a id="arora2009computational">[1]</a> Sanjeev Arora and Boaz Barak. <i>Computational complexity: a modern approach.</i> Cambridge University Press, 2009.</li>
<li><a id="nirkhe2018approximate">[2]</a> Chinmay Nirkhe, Umesh Vazirani,  and Henry Yuen. Approximate low-weight check codes and circuit lower bounds for noisy ground states. <i>arXiv preprint arXiv:1802.07419</i>, 2018.</li>
<li><a id="aharonov2017">[3]</a> Dorit Aharonov, Wim van Dam, Julia Kempe, Zeph Landau, Seth Lloyd, and Oded Regev. Adiabatic quantum computation is equivalent to standard quantum computation. <i>SIAM J. Comput.</i>, 2007.</li></ul></div>
    </content>
    <updated>2018-12-23T01:45:21Z</updated>
    <published>2018-12-23T01:45:21Z</published>
    <category term="physics"/>
    <author>
      <name>richardmwang</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2019-01-07T23:32:58Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=6948</id>
    <link href="https://windowsontheory.org/2018/12/22/quantum-approximate-optimization-algorithm-and-applications/" rel="alternate" type="text/html"/>
    <title>Quantum Approximate Optimization Algorithm and Applications</title>
    <summary>Motivation   Quantum computers have demonstrated great potential for solving certain problems more efficiently than their classical counterpart. Algorithms based on the quantum Fourier transform (QFT) such as Shor’s algorithm offer an exponential speed-up, while amplitude-amplification algorithms such as Grover’s search algorithm provide us with a polynomial speedup. The concept of “quantum supremacy” (quantum computers […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><h2>Motivation</h2>
<p> </p>
<p>Quantum computers have demonstrated great potential for solving certain problems more efficiently than their classical counterpart. Algorithms based on the quantum Fourier transform (QFT) such as Shor’s algorithm offer an exponential speed-up, while amplitude-amplification algorithms such as Grover’s search algorithm provide us with a polynomial speedup. The concept of “quantum supremacy” (quantum computers outperforming classical computers) has been explored for three general groups of problems:</p>
<ol>
<li>Structured problems, such as factoring and discrete logarithm. Out quantum computer takes advantage of the structure of these classes of problems to offer an exponential speedup compared to the best known classical alternative. While these speedups are the most promising, they require a large number of resources and are cannot be feasibly implemented in the near future.</li>
<li>Quantum Simulations, originally proposed by Richard Feynman in the late 80s was thought to be the first motivation behind exploring quantum computation. Due to the fact that the space of all possible states of the system scales exponentially with the addition of a new element (eg. an atom), complex systems are very difficult to simulate classically. It has been shown that we can use a quantum computer to tackle interesting problems in quantum chemistry and chemical engineering. Furthermore, there are results on sampling the output of random quantum circuits which have been used for “quantum supremacy experiments”.</li>
<li>General constraint satisfaction and optimization problems. Since these problems are NP-hard it is widely believed that we cannot gain an exponential speedup using a quantum computer, however, we can obtain quadratic speedup but utilizing a variation of Grover’s algorithm.</li>
</ol>
<p>While these quantum algorithms are very exciting, they are beyond the capabilities of our near-term quantum computers; for example, any useful application of Shor’s factoring algorithm requires anywhere between tens of thousands to millions of qubits with error correction compared to quantum devices with hundreds of qubits that we might have available in the next few years.</p>
<p>Recently there has been increasing interest in hybrid classical-quantum algorithms among the community. The general idea behind this approach is to supplement the noisy intermediate-scale quantum (NISQ) devices with classical computers. In this blog post, we discuss the Quantum Approximate Optimization Algorithm (QAOA), which is a hybrid algorithm, alongside some of its applications.</p>
<h2>Introduction</h2>
<p>QAOA is used for optimizing combinatorial problems. Let’s assume a problem with <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> bits and <img alt="m" class="latex" src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m"/> clauses. Each clause is a constraint on a subset of the bits which satisfies a certain assignment. We can define a cost function as follows:</p>
<p><img alt="C(z)=\sum_{\alpha=1}^m C_\alpha (z) " class="latex" src="https://s0.wp.com/latex.php?latex=C%28z%29%3D%5Csum_%7B%5Calpha%3D1%7D%5Em+C_%5Calpha+%28z%29+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C(z)=\sum_{\alpha=1}^m C_\alpha (z) "/></p>
<p>where <img alt="z=z_1z_2...z_n" class="latex" src="https://s0.wp.com/latex.php?latex=z%3Dz_1z_2...z_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="z=z_1z_2...z_n"/> is the bit string. In this article we consider a minimization problem, therefore we want <img alt="C_\alpha(z)=0" class="latex" src="https://s0.wp.com/latex.php?latex=C_%5Calpha%28z%29%3D0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_\alpha(z)=0"/> if <img alt="z" class="latex" src="https://s0.wp.com/latex.php?latex=z&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="z"/> satisfies clause <img alt="\alpha" class="latex" src="https://s0.wp.com/latex.php?latex=%5Calpha&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\alpha"/> and 1 otherwise. Note that in the case of a maximization problem we only need to switch the value assigned to a satisfactory clause to 1. Our objective is to find a (qu)bit string that minimizes (or maximizes) our cost function.</p>
<p>At a higher level, we start with a quantum state in a uniform superposition of all possible inputs <img alt="z" class="latex" src="https://s0.wp.com/latex.php?latex=z&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="z"/>. This can be accomplished with <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> qubits which span a space of size <img alt="2^n" class="latex" src="https://s0.wp.com/latex.php?latex=2%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^n"/>. Our goal is to come up with a series of operations that would evolve our initial quantum state into a superposition of states in which the valid solutions would have a significantly higher probability than other states. In manner, upon sampling the quantum state we are likely to get the correct solution with high probability. QAOA uses the cost function to construct a set of operations that would be able to efficiently map the unifrom superposition state into the desired quantum state. These operators involve single qubits rotations around the x-axis, and multiqubit rotations around the z-axis of our qubits.</p>
<p>Now let’s discuss the details of QAOA. For this algorithm we assume that our quantum computer works in the computation basis of <img alt="\left |0 \right &gt; , \left | 1 \right &gt; " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cleft+%7C0+%5Cright+%3E+%2C+%5Cleft+%7C+1+%5Cright+%3E+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\left |0 \right &gt; , \left | 1 \right &gt; "/>. We start by setting our initial state to a uniform superposition over computational basis states:</p>
<p><img alt="\left |s \right &gt; = \frac{1}{\sqrt{2^n}}\sum_{z \in \{0,1\}^n} \left |z \right &gt; " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cleft+%7Cs+%5Cright+%3E+%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%5En%7D%7D%5Csum_%7Bz+%5Cin+%5C%7B0%2C1%5C%7D%5En%7D+%5Cleft+%7Cz+%5Cright+%3E+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\left |s \right &gt; = \frac{1}{\sqrt{2^n}}\sum_{z \in \{0,1\}^n} \left |z \right &gt; "/></p>
<p>Next, we define a unitary operator using the cost function as follows:</p>
<p><img alt="U(\hat{C},\gamma) = e^{i\gamma \hat{C}}= \prod_{\alpha = 1}^m e^{-i\gamma \hat{C}_\alpha}&#xA0;" class="latex" src="https://s0.wp.com/latex.php?latex=U%28%5Chat%7BC%7D%2C%5Cgamma%29+%3D+e%5E%7Bi%5Cgamma+%5Chat%7BC%7D%7D%3D+%5Cprod_%7B%5Calpha+%3D+1%7D%5Em+e%5E%7B-i%5Cgamma+%5Chat%7BC%7D_%5Calpha%7D%C2%A0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U(\hat{C},\gamma) = e^{i\gamma \hat{C}}= \prod_{\alpha = 1}^m e^{-i\gamma \hat{C}_\alpha}&#xA0;"/></p>
<p>Here we convert every clause <img alt="C_\alpha" class="latex" src="https://s0.wp.com/latex.php?latex=C_%5Calpha&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_\alpha"/> to a Hamiltonian <img alt="\hat{C_\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Chat%7BC_%5Calpha%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\hat{C_\alpha}"/> consisting of Pauli Z ($\sigma^z$) operators. Just as a review, the two Pauli operators (X and Z) used in this blog post are representated as follows:</p>
<p><img alt="\sigma^x = \begin{pmatrix}&#xA0;&#xA0;&#xA0; 0 &amp; 1 \\&#xA0;&#xA0;&#xA0; 1 &amp; 0 \\\end{pmatrix} \: \: \: \:  \sigma^z = \begin{pmatrix}&#xA0;&#xA0;&#xA0; 1 &amp; 0 \\&#xA0;&#xA0;&#xA0; 0 &amp; -1 \\\end{pmatrix} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csigma%5Ex+%3D+%5Cbegin%7Bpmatrix%7D%C2%A0%C2%A0%C2%A0+0+%26+1+%5C%5C%C2%A0%C2%A0%C2%A0+1+%26+0+%5C%5C%5Cend%7Bpmatrix%7D+%5C%3A+%5C%3A+%5C%3A+%5C%3A++%5Csigma%5Ez+%3D+%5Cbegin%7Bpmatrix%7D%C2%A0%C2%A0%C2%A0+1+%26+0+%5C%5C%C2%A0%C2%A0%C2%A0+0+%26+-1+%5C%5C%5Cend%7Bpmatrix%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sigma^x = \begin{pmatrix}&#xA0;&#xA0;&#xA0; 0 &amp; 1 \\&#xA0;&#xA0;&#xA0; 1 &amp; 0 \\\end{pmatrix} \: \: \: \:  \sigma^z = \begin{pmatrix}&#xA0;&#xA0;&#xA0; 1 &amp; 0 \\&#xA0;&#xA0;&#xA0; 0 &amp; -1 \\\end{pmatrix} "/></p>
<p>For example if <img alt="C_\alpha=x \oplus y" class="latex" src="https://s0.wp.com/latex.php?latex=C_%5Calpha%3Dx+%5Coplus+y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_\alpha=x \oplus y"/> we can map the clause to <img alt="\hat{C_\alpha}=\frac{1}{2}(1+\sigma^z_x \sigma^z_y)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Chat%7BC_%5Calpha%7D%3D%5Cfrac%7B1%7D%7B2%7D%281%2B%5Csigma%5Ez_x+%5Csigma%5Ez_y%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\hat{C_\alpha}=\frac{1}{2}(1+\sigma^z_x \sigma^z_y)"/> for a minimization problem. If <img alt="x=\left |0 \right &gt; &#xA0;" class="latex" src="https://s0.wp.com/latex.php?latex=x%3D%5Cleft+%7C0+%5Cright+%3E+%C2%A0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x=\left |0 \right &gt; &#xA0;"/> , then <img alt="\sigma^z_x" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csigma%5Ez_x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sigma^z_x"/> will return a value of 1, and if <img alt="x=\left |1 \right &gt; " class="latex" src="https://s0.wp.com/latex.php?latex=x%3D%5Cleft+%7C1+%5Cright+%3E+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x=\left |1 \right &gt; "/> the operator will return -1. The same applies to qubit <img alt="y" class="latex" src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y"/> as well. Therefore it is not hard to see that if <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/> and <img alt="y" class="latex" src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y"/> have the same value, then the operator <img alt="\hat{C_\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Chat%7BC_%5Calpha%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\hat{C_\alpha}"/> as defined above will result in a 1, and it’ll result in 0 otherwise. Furthermore, since <img alt="\hat{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Chat%7BC%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\hat{C}"/> has integer eigenvalues we can restrict the angle <img alt="\gamma" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cgamma&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\gamma"/> to lie in <img alt="[0,2\pi]" class="latex" src="https://s0.wp.com/latex.php?latex=%5B0%2C2%5Cpi%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="[0,2\pi]"/>.</p>
<p>Next, we define the admixing Hamiltonian:</p>
<p><img alt="B=\sum_{j=1}^n \sigma^x_j " class="latex" src="https://s0.wp.com/latex.php?latex=B%3D%5Csum_%7Bj%3D1%7D%5En+%5Csigma%5Ex_j+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B=\sum_{j=1}^n \sigma^x_j "/></p>
<p>and use it to define a unitary operator which consists of a product of commuting one qubit operations:</p>
<p><img alt="U(B,\beta) = e^{-i\beta B}= \prod_{j=1}^n e^{-i \beta \sigma_j^x}&#xA0;&#xA0;" class="latex" src="https://s0.wp.com/latex.php?latex=U%28B%2C%5Cbeta%29+%3D+e%5E%7B-i%5Cbeta+B%7D%3D+%5Cprod_%7Bj%3D1%7D%5En+e%5E%7B-i+%5Cbeta+%5Csigma_j%5Ex%7D%C2%A0%C2%A0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U(B,\beta) = e^{-i\beta B}= \prod_{j=1}^n e^{-i \beta \sigma_j^x}&#xA0;&#xA0;"/></p>
<p>where <img alt="\beta \in [0,\pi]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbeta+%5Cin+%5B0%2C%5Cpi%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\beta \in [0,\pi]"/>. It’s easy to see that <img alt="U(\Hat{C},\gamma)" class="latex" src="https://s0.wp.com/latex.php?latex=U%28%5CHat%7BC%7D%2C%5Cgamma%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U(\Hat{C},\gamma)"/> couples 2 or more qubits, while <img alt="U(B,\beta)" class="latex" src="https://s0.wp.com/latex.php?latex=U%28B%2C%5Cbeta%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U(B,\beta)"/> performs a single qubit rotation on the qubits in our system. Using these unitaries and our initial state we define a QAOA angle-dependent “ansatz” state as follows:</p>
<p><img alt="\left | &#xA0;\boldsymbol{\gamma},\boldsymbol{\beta} \right &gt;= U(B,\beta_p)U(\Hat{C},\gamma_p)...U(B,\beta_1)U(\Hat{C},\gamma_1) \left |s \right &gt; " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cleft+%7C+%C2%A0%5Cboldsymbol%7B%5Cgamma%7D%2C%5Cboldsymbol%7B%5Cbeta%7D+%5Cright+%3E%3D+U%28B%2C%5Cbeta_p%29U%28%5CHat%7BC%7D%2C%5Cgamma_p%29...U%28B%2C%5Cbeta_1%29U%28%5CHat%7BC%7D%2C%5Cgamma_1%29+%5Cleft+%7Cs+%5Cright+%3E+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\left | &#xA0;\boldsymbol{\gamma},\boldsymbol{\beta} \right &gt;= U(B,\beta_p)U(\Hat{C},\gamma_p)...U(B,\beta_1)U(\Hat{C},\gamma_1) \left |s \right &gt; "/></p>
<p>Here <img alt="p\geq 1" class="latex" src="https://s0.wp.com/latex.php?latex=p%5Cgeq+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p\geq 1"/> is the “depth” of our QAOA circuit, and <img alt="\boldsymbol{\gamma}=(\gamma_p,...,\gamma_1)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cboldsymbol%7B%5Cgamma%7D%3D%28%5Cgamma_p%2C...%2C%5Cgamma_1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\boldsymbol{\gamma}=(\gamma_p,...,\gamma_1)"/>, <img alt="\boldsymbol{\beta}=(\beta_p,...,\beta_1)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cboldsymbol%7B%5Cbeta%7D%3D%28%5Cbeta_p%2C...%2C%5Cbeta_1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\boldsymbol{\beta}=(\beta_p,...,\beta_1)"/> are each a vector of length <img alt="p" class="latex" src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p"/> controlling the angles for each layer. In the worst case scenario this state can be produce by a quantum circuit of depth <img alt="mp+p" class="latex" src="https://s0.wp.com/latex.php?latex=mp%2Bp&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="mp+p"/>, however by taking advantage of the structure of the instance we can further reduce the number of layers required. Let <img alt="F_p" class="latex" src="https://s0.wp.com/latex.php?latex=F_p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="F_p"/> be the expectation of <img alt="\hat{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Chat%7BC%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\hat{C}"/> in our ansatz:</p>
<p><img alt="F_p(\boldsymbol{\gamma},\boldsymbol{\beta})=\left &lt; \boldsymbol{\gamma},\boldsymbol{\beta} \right | \hat{C} \left | \boldsymbol{\gamma},\boldsymbol{\beta} \right &gt;  " class="latex" src="https://s0.wp.com/latex.php?latex=F_p%28%5Cboldsymbol%7B%5Cgamma%7D%2C%5Cboldsymbol%7B%5Cbeta%7D%29%3D%5Cleft+%3C+%5Cboldsymbol%7B%5Cgamma%7D%2C%5Cboldsymbol%7B%5Cbeta%7D+%5Cright+%7C+%5Chat%7BC%7D+%5Cleft+%7C+%5Cboldsymbol%7B%5Cgamma%7D%2C%5Cboldsymbol%7B%5Cbeta%7D+%5Cright+%3E++&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="F_p(\boldsymbol{\gamma},\boldsymbol{\beta})=\left &lt; \boldsymbol{\gamma},\boldsymbol{\beta} \right | \hat{C} \left | \boldsymbol{\gamma},\boldsymbol{\beta} \right &gt;  "/></p>
<p>and let <img alt="M_p" class="latex" src="https://s0.wp.com/latex.php?latex=M_p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="M_p"/> be the minimum of <img alt="F_p" class="latex" src="https://s0.wp.com/latex.php?latex=F_p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="F_p"/> over angles,</p>
<p><img alt="M_p=\min_{\boldsymbol{\gamma},\boldsymbol{\beta}} F_p(\boldsymbol{\gamma},\boldsymbol{\beta}).  " class="latex" src="https://s0.wp.com/latex.php?latex=M_p%3D%5Cmin_%7B%5Cboldsymbol%7B%5Cgamma%7D%2C%5Cboldsymbol%7B%5Cbeta%7D%7D+F_p%28%5Cboldsymbol%7B%5Cgamma%7D%2C%5Cboldsymbol%7B%5Cbeta%7D%29.++&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="M_p=\min_{\boldsymbol{\gamma},\boldsymbol{\beta}} F_p(\boldsymbol{\gamma},\boldsymbol{\beta}).  "/></p>
<p>Note that minimization at <img alt="p-1" class="latex" src="https://s0.wp.com/latex.php?latex=p-1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p-1"/> layers can be viewed as a constrained minimization at <img alt="p" class="latex" src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p"/> layers, therefore</p>
<p><img alt="M_p \leq M_{p-1}  " class="latex" src="https://s0.wp.com/latex.php?latex=M_p+%5Cleq+M_%7Bp-1%7D++&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="M_p \leq M_{p-1}  "/></p>
<p>Using an adiabatic approach [1] We can show that</p>
<p><img alt="\lim_{p \rightarrow \infty} M_p = \min_z C(z) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Clim_%7Bp+%5Crightarrow+%5Cinfty%7D+M_p+%3D+%5Cmin_z+C%28z%29+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lim_{p \rightarrow \infty} M_p = \min_z C(z) "/></p>
<p>Based on these results our QAOA algorithm will look like the following:</p>
<ul>
<li> c: pick a <img alt="p" class="latex" src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p"/></li>
<li>c: choose a set of angles <img alt="(\Vec{\gamma}_0,\Vec{\beta}_0)" class="latex" src="https://s0.wp.com/latex.php?latex=%28%5CVec%7B%5Cgamma%7D_0%2C%5CVec%7B%5Cbeta%7D_0%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(\Vec{\gamma}_0,\Vec{\beta}_0)"/></li>
<li>q: prepare <img alt="\left | \Vec{\gamma},\Vec{\beta} \right &gt; &#xA0;" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cleft+%7C+%5CVec%7B%5Cgamma%7D%2C%5CVec%7B%5Cbeta%7D+%5Cright+%3E+%C2%A0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\left | \Vec{\gamma},\Vec{\beta} \right &gt; &#xA0;"/></li>
<li>q: compute <img alt="F_p" class="latex" src="https://s0.wp.com/latex.php?latex=F_p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="F_p"/></li>
<li>c: perform gradient descend/ascend on <img alt="F_p" class="latex" src="https://s0.wp.com/latex.php?latex=F_p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="F_p"/> and get a new set of angles <img alt="(\Vec{\gamma},\Vec{\beta})" class="latex" src="https://s0.wp.com/latex.php?latex=%28%5CVec%7B%5Cgamma%7D%2C%5CVec%7B%5Cbeta%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(\Vec{\gamma},\Vec{\beta})"/></li>
<li>repeat from step 3 till convergence</li>
<li>report the measurement result of <img alt="\left | \Vec{\gamma},\Vec{\beta} \right &gt; &#xA0;" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cleft+%7C+%5CVec%7B%5Cgamma%7D%2C%5CVec%7B%5Cbeta%7D+%5Cright+%3E+%C2%A0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\left | \Vec{\gamma},\Vec{\beta} \right &gt; &#xA0;"/> in computational basis</li>
</ul>
<p>If <img alt="p" class="latex" src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p"/> does not asymptotically grow with <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> <img alt="F_p(\Vec{\gamma},\Vec{\beta})" class="latex" src="https://s0.wp.com/latex.php?latex=F_p%28%5CVec%7B%5Cgamma%7D%2C%5CVec%7B%5Cbeta%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="F_p(\Vec{\gamma},\Vec{\beta})"/> can be efficiently computed in <img alt="O(m^2+mn)" class="latex" src="https://s0.wp.com/latex.php?latex=O%28m%5E2%2Bmn%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(m^2+mn)"/></p>
<h2>Application: MaxCut</h2>
<p>In this section we apply the QAOA algorithm to the MaxCut problem with bounded degree. MaxCut is an NP-hard problem that asks for a subset <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S"/> of the vertex set such that the number of edges between <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S"/> and the complementary subset is as large as possible. While QAOA does not offer a theoretical guarantee to solve MaxCut in polynomial time, it offers a path to utilizing NISQ devices for tackling such optimization problems and discuss patterns in such problems that can be used for reducing the number of steps required.</p>
<p>For this section, let’s assume <img alt="p=O(1)" class="latex" src="https://s0.wp.com/latex.php?latex=p%3DO%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p=O(1)"/>, and we have a graph with <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> vertices and an edge set <img alt="\{&lt;jk&gt;\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B%3Cjk%3E%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{&lt;jk&gt;\}"/> of size <img alt="m" class="latex" src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m"/>. We can construct a cost function to be maximized as follows:</p>
<p><img alt="C = \sum_{&lt;jk&gt;} C_{&lt;jk&gt;} " class="latex" src="https://s0.wp.com/latex.php?latex=C+%3D+%5Csum_%7B%3Cjk%3E%7D+C_%7B%3Cjk%3E%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C = \sum_{&lt;jk&gt;} C_{&lt;jk&gt;} "/></p>
<p><img alt="C_{&lt;jk&gt;} = \frac{1}{2} (1-\sigma^z_j \sigma^z_k)  " class="latex" src="https://s0.wp.com/latex.php?latex=C_%7B%3Cjk%3E%7D+%3D+%5Cfrac%7B1%7D%7B2%7D+%281-%5Csigma%5Ez_j+%5Csigma%5Ez_k%29++&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_{&lt;jk&gt;} = \frac{1}{2} (1-\sigma^z_j \sigma^z_k)  "/></p>
<p>We can the compute the angle dependent cost of our ansatz as follows:</p>
<p><img alt="F_p(\Vec{\gamma},\Vec{\beta})=\sum_{&lt;jk&gt;}\left &lt;{s} \right | U^\dagger(C,\gamma_1)...U^\dagger(B,\beta_p) C_{&lt;jk&gt;}U(B,\beta_p) ... U(C,\gamma_1) \left |s \right &gt;  " class="latex" src="https://s0.wp.com/latex.php?latex=F_p%28%5CVec%7B%5Cgamma%7D%2C%5CVec%7B%5Cbeta%7D%29%3D%5Csum_%7B%3Cjk%3E%7D%5Cleft+%3C%7Bs%7D+%5Cright+%7C+U%5E%5Cdagger%28C%2C%5Cgamma_1%29...U%5E%5Cdagger%28B%2C%5Cbeta_p%29+C_%7B%3Cjk%3E%7DU%28B%2C%5Cbeta_p%29+...+U%28C%2C%5Cgamma_1%29+%5Cleft+%7Cs+%5Cright+%3E++&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="F_p(\Vec{\gamma},\Vec{\beta})=\sum_{&lt;jk&gt;}\left &lt;{s} \right | U^\dagger(C,\gamma_1)...U^\dagger(B,\beta_p) C_{&lt;jk&gt;}U(B,\beta_p) ... U(C,\gamma_1) \left |s \right &gt;  "/></p>
<p>Let’s consider the operation associated with some edge <img alt="&lt;jk&gt;" class="latex" src="https://s0.wp.com/latex.php?latex=%3Cjk%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="&lt;jk&gt;"/>:</p>
<p><img alt="U ^\dagger(C,\gamma_1)...U^\dagger(B,\beta_p) C_{&lt;jk&gt;}U(B,\beta_p) ... U(C,\gamma_1)  " class="latex" src="https://s0.wp.com/latex.php?latex=U+%5E%5Cdagger%28C%2C%5Cgamma_1%29...U%5E%5Cdagger%28B%2C%5Cbeta_p%29+C_%7B%3Cjk%3E%7DU%28B%2C%5Cbeta_p%29+...+U%28C%2C%5Cgamma_1%29++&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U ^\dagger(C,\gamma_1)...U^\dagger(B,\beta_p) C_{&lt;jk&gt;}U(B,\beta_p) ... U(C,\gamma_1)  "/></p>
<p>Since QAOA consists of local operations, we may take advantage by thinking about the problem in terms of subproblems (or subgraphs) involving certain nodes. This property will allow us to simplify our clauses even further depending on the desired depth <img alt="p" class="latex" src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p"/> of our quantum circuit, therefore decreasing the amount of resources necessary to implement the algorithm.</p>
<p>The operator <img alt="C_{&lt;jk&gt;}" class="latex" src="https://s0.wp.com/latex.php?latex=C_%7B%3Cjk%3E%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_{&lt;jk&gt;}"/> includes qubits (nodes) <img alt="j" class="latex" src="https://s0.wp.com/latex.php?latex=j&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="j"/> and <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>, therefore the sequence of operators above will only involve qubits that are at most distance <img alt="p" class="latex" src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p"/> away from qubits <img alt="j" class="latex" src="https://s0.wp.com/latex.php?latex=j&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="j"/> and <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>. Let’s consider the example of <img alt="p=1" class="latex" src="https://s0.wp.com/latex.php?latex=p%3D1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p=1"/>:</p>
<p><img alt="\rightarrow U^\dagger(C,\gamma_1)e^{i\beta_1(\sigma^x_j + \sigma^x_k)} C_{&lt;jk&gt;} e^{-i\beta_1(\sigma^x_j + \sigma^x_k)} U(C,\gamma_1).  " class="latex" src="https://s0.wp.com/latex.php?latex=%5Crightarrow+U%5E%5Cdagger%28C%2C%5Cgamma_1%29e%5E%7Bi%5Cbeta_1%28%5Csigma%5Ex_j+%2B+%5Csigma%5Ex_k%29%7D+C_%7B%3Cjk%3E%7D+e%5E%7B-i%5Cbeta_1%28%5Csigma%5Ex_j+%2B+%5Csigma%5Ex_k%29%7D+U%28C%2C%5Cgamma_1%29.++&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rightarrow U^\dagger(C,\gamma_1)e^{i\beta_1(\sigma^x_j + \sigma^x_k)} C_{&lt;jk&gt;} e^{-i\beta_1(\sigma^x_j + \sigma^x_k)} U(C,\gamma_1).  "/></p>
<p>It’s easy to see that any factor of <img alt="U(C,\gamma_1)" class="latex" src="https://s0.wp.com/latex.php?latex=U%28C%2C%5Cgamma_1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U(C,\gamma_1)"/> that does not depend on <img alt="j" class="latex" src="https://s0.wp.com/latex.php?latex=j&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="j"/> or <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/> will commute through and cancel out. Since the degree is bounded, each subgraph contains a number of qubits that is independent of <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>, which allows for the evaluation of <img alt="F_p" class="latex" src="https://s0.wp.com/latex.php?latex=F_p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="F_p"/> in terms of subsystems of size independent of <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>.</p>
<p>For an subgraph <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/> define:</p>
<p><img alt="C_G=\sum_{&lt;l l^\prime&gt;} C_{&lt;l l^\prime&gt;}&#xA0; \: \: \: \: U(C_G,\gamma)=e^{-i \gamma C_G} " class="latex" src="https://s0.wp.com/latex.php?latex=C_G%3D%5Csum_%7B%3Cl+l%5E%5Cprime%3E%7D+C_%7B%3Cl+l%5E%5Cprime%3E%7D%C2%A0+%5C%3A+%5C%3A+%5C%3A+%5C%3A+U%28C_G%2C%5Cgamma%29%3De%5E%7B-i+%5Cgamma+C_G%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_G=\sum_{&lt;l l^\prime&gt;} C_{&lt;l l^\prime&gt;}&#xA0; \: \: \: \: U(C_G,\gamma)=e^{-i \gamma C_G} "/></p>
<p><img alt="B_G = \sum_{j \in G} \sigma^x_j&#xA0; \: \: \: \: U(B_G,\beta) = e^{-i \beta B_G} " class="latex" src="https://s0.wp.com/latex.php?latex=B_G+%3D+%5Csum_%7Bj+%5Cin+G%7D+%5Csigma%5Ex_j%C2%A0+%5C%3A+%5C%3A+%5C%3A+%5C%3A+U%28B_G%2C%5Cbeta%29+%3D+e%5E%7B-i+%5Cbeta+B_G%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B_G = \sum_{j \in G} \sigma^x_j&#xA0; \: \: \: \: U(B_G,\beta) = e^{-i \beta B_G} "/></p>
<p><img alt="\left | s,G \right &gt; &#xA0;&#xA0;= \prod_{l \in G} \left |+ \right &gt; _l  " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cleft+%7C+s%2CG+%5Cright+%3E+%C2%A0%C2%A0%3D+%5Cprod_%7Bl+%5Cin+G%7D+%5Cleft+%7C%2B+%5Cright+%3E+_l++&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\left | s,G \right &gt; &#xA0;&#xA0;= \prod_{l \in G} \left |+ \right &gt; _l  "/></p>
<p>We can define our total cost as a sum over the cost of each subgraph:</p>
<p><img alt="f_g(\Vec{\gamma},\Vec{\beta})=\left &lt; s,g(j,k) \right |&#xA0; U ^\dagger(C_{g(j,k)},\gamma_1)...U^\dagger(B_{g(j,k)},\beta_p) C_{&lt;jk&gt;}U(B_{g(j,k)},\beta_p) ... U(C_{g(j,k)},\gamma_1) \left |s,g(j,k) \right &gt;  " class="latex" src="https://s0.wp.com/latex.php?latex=f_g%28%5CVec%7B%5Cgamma%7D%2C%5CVec%7B%5Cbeta%7D%29%3D%5Cleft+%3C+s%2Cg%28j%2Ck%29+%5Cright+%7C%C2%A0+U+%5E%5Cdagger%28C_%7Bg%28j%2Ck%29%7D%2C%5Cgamma_1%29...U%5E%5Cdagger%28B_%7Bg%28j%2Ck%29%7D%2C%5Cbeta_p%29+C_%7B%3Cjk%3E%7DU%28B_%7Bg%28j%2Ck%29%7D%2C%5Cbeta_p%29+...+U%28C_%7Bg%28j%2Ck%29%7D%2C%5Cgamma_1%29+%5Cleft+%7Cs%2Cg%28j%2Ck%29+%5Cright+%3E++&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f_g(\Vec{\gamma},\Vec{\beta})=\left &lt; s,g(j,k) \right |&#xA0; U ^\dagger(C_{g(j,k)},\gamma_1)...U^\dagger(B_{g(j,k)},\beta_p) C_{&lt;jk&gt;}U(B_{g(j,k)},\beta_p) ... U(C_{g(j,k)},\gamma_1) \left |s,g(j,k) \right &gt;  "/></p>
<p>where <img alt="g(j,k)" class="latex" src="https://s0.wp.com/latex.php?latex=g%28j%2Ck%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g(j,k)"/> is a subgraph of type <img alt="g" class="latex" src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g"/> and “…” is used to omit the sequence of angle depending unitaries constructed using the elements of <img alt="\Vec{\gamma}" class="latex" src="https://s0.wp.com/latex.php?latex=%5CVec%7B%5Cgamma%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Vec{\gamma}"/> and <img alt="\Vec{\beta}" class="latex" src="https://s0.wp.com/latex.php?latex=%5CVec%7B%5Cbeta%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Vec{\beta}"/>. <img alt="F_p" class="latex" src="https://s0.wp.com/latex.php?latex=F_p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="F_p"/> is then</p>
<p><img alt="F_p(\Vec{\gamma},\Vec{\beta})=\sum_g w_g f_g(\Vec{\gamma},\Vec{\beta})  " class="latex" src="https://s0.wp.com/latex.php?latex=F_p%28%5CVec%7B%5Cgamma%7D%2C%5CVec%7B%5Cbeta%7D%29%3D%5Csum_g+w_g+f_g%28%5CVec%7B%5Cgamma%7D%2C%5CVec%7B%5Cbeta%7D%29++&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="F_p(\Vec{\gamma},\Vec{\beta})=\sum_g w_g f_g(\Vec{\gamma},\Vec{\beta})  "/></p>
<p>where <img alt="w_g" class="latex" src="https://s0.wp.com/latex.php?latex=w_g&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="w_g"/> is the number of occurrence of the subgraph <img alt="g" class="latex" src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g"/> in the original edge sum. The function <img alt="f_g" class="latex" src="https://s0.wp.com/latex.php?latex=f_g&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f_g"/> does not depend on <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> and <img alt="m" class="latex" src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m"/>, and the only dependence on these variables comes through the weights <img alt="w_g" class="latex" src="https://s0.wp.com/latex.php?latex=w_g&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="w_g"/> from the original graph. The maximum number of qubits that can appear in our sequence of operators comes when the subgraph is a tree. For a graph with maximum degree <img alt="v" class="latex" src="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="v"/>, the number of qubits in this tree is</p>
<p><img alt="q_{tree}=2[\frac{(v-1)^{p+1}-1}{(v-1)-1}]  " class="latex" src="https://s0.wp.com/latex.php?latex=q_%7Btree%7D%3D2%5B%5Cfrac%7B%28v-1%29%5E%7Bp%2B1%7D-1%7D%7B%28v-1%29-1%7D%5D++&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="q_{tree}=2[\frac{(v-1)^{p+1}-1}{(v-1)-1}]  "/></p>
<p>(or <img alt="2p+2" class="latex" src="https://s0.wp.com/latex.php?latex=2p%2B2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2p+2"/> if <img alt="v=2" class="latex" src="https://s0.wp.com/latex.php?latex=v%3D2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="v=2"/>), which is independent of <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> and <img alt="m" class="latex" src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m"/>. Therefore we can see that for constant <img alt="p" class="latex" src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p"/> <img alt="F_p" class="latex" src="https://s0.wp.com/latex.php?latex=F_p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="F_p"/> can be efficiently computed.</p>
<p>Next, let’s consider the spread of C measured in the state <img alt="\left | \Vec{\gamma},\Vec{\beta} \right &gt; &#xA0;" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cleft+%7C+%5CVec%7B%5Cgamma%7D%2C%5CVec%7B%5Cbeta%7D+%5Cright+%3E+%C2%A0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\left | \Vec{\gamma},\Vec{\beta} \right &gt; &#xA0;"/>.</p>
<p><img alt="\left &lt;\Vec{\gamma},\Vec{\beta} \right | C^2\left |\Vec{\gamma},\Vec{\beta}\right &gt; &#xA0;-\left &lt; \Vec{\gamma},\Vec{\beta} \right | C \left | \Vec{\gamma},\Vec{\beta} \right &gt; ^2 \leq 2[\frac{(v-1)^{2p+2}-1}{(v-1)-1}].m  " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cleft+%3C%5CVec%7B%5Cgamma%7D%2C%5CVec%7B%5Cbeta%7D+%5Cright+%7C+C%5E2%5Cleft+%7C%5CVec%7B%5Cgamma%7D%2C%5CVec%7B%5Cbeta%7D%5Cright+%3E+%C2%A0-%5Cleft+%3C+%5CVec%7B%5Cgamma%7D%2C%5CVec%7B%5Cbeta%7D+%5Cright+%7C+C+%5Cleft+%7C+%5CVec%7B%5Cgamma%7D%2C%5CVec%7B%5Cbeta%7D+%5Cright+%3E+%5E2+%5Cleq+2%5B%5Cfrac%7B%28v-1%29%5E%7B2p%2B2%7D-1%7D%7B%28v-1%29-1%7D%5D.m++&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\left &lt;\Vec{\gamma},\Vec{\beta} \right | C^2\left |\Vec{\gamma},\Vec{\beta}\right &gt; &#xA0;-\left &lt; \Vec{\gamma},\Vec{\beta} \right | C \left | \Vec{\gamma},\Vec{\beta} \right &gt; ^2 \leq 2[\frac{(v-1)^{2p+2}-1}{(v-1)-1}].m  "/></p>
<p>For fixed <img alt="v" class="latex" src="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="v"/> and <img alt="p" class="latex" src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p"/> we see that the standard deviation of <img alt="C(z)" class="latex" src="https://s0.wp.com/latex.php?latex=C%28z%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C(z)"/> is upper-bounded by <img alt="O(\sqrt{m})" class="latex" src="https://s0.wp.com/latex.php?latex=O%28%5Csqrt%7Bm%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(\sqrt{m})"/>. Using this fact and the appropriate probability bounds we can see that the result of measuring the cost function of the state <img alt="\left | \vec{\gamma_{opt}},vec{\beta_{opt}} \right &gt; &#xA0;" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cleft+%7C+%5Cvec%7B%5Cgamma_%7Bopt%7D%7D%2Cvec%7B%5Cbeta_%7Bopt%7D%7D+%5Cright+%3E+%C2%A0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\left | \vec{\gamma_{opt}},vec{\beta_{opt}} \right &gt; &#xA0;"/> will be very close to the intended value of <img alt="F_p(\vec{\gamma_{opt}},\vec{\beta_{opt}})" class="latex" src="https://s0.wp.com/latex.php?latex=F_p%28%5Cvec%7B%5Cgamma_%7Bopt%7D%7D%2C%5Cvec%7B%5Cbeta_%7Bopt%7D%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="F_p(\vec{\gamma_{opt}},\vec{\beta_{opt}})"/> which bounds the uncertainty present in quantum measurement.</p>
<h2>Bibliography</h2>
<p>[1] E. Farhi, J. Goldstone, and S. Gutmann, “A Quantum Approximate Optimization Algorithm,” 2014.</p>
<p>[2] J. S. Otterbach, et. al, “Unsupervised Machine Learning on a Hybrid Quantum Computer,” 2017.</p></div>
    </content>
    <updated>2018-12-22T23:36:23Z</updated>
    <published>2018-12-22T23:36:23Z</published>
    <category term="physics"/>
    <author>
      <name>karamlou</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2019-01-07T23:33:03Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2018/12/22/circles-crossing-equal</id>
    <link href="https://11011110.github.io/blog/2018/12/22/circles-crossing-equal.html" rel="alternate" type="text/html"/>
    <title>Circles crossing at equal angles</title>
    <summary>Let , , , and be four circles, with pairs , , , and crossing at equal angles (and no crossings among the other two pairs). Then it turns out that the two curvy quadrilaterals forming the inside and outside boundaries of the union of disks each have a circle through their four vertices:</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Let , , , and  be four circles, with pairs , , , and  crossing at equal angles (and no crossings among the other two pairs). Then it turns out that the two curvy quadrilaterals forming the inside and outside boundaries of the union of disks each have a circle through their four vertices:</p>

<p style="text-align: center;"><img alt="Four circles crossing at equal angles, and the two circles through their crossing points" src="https://11011110.github.io/blog/assets/2018/4circle-45.svg"/></p>

<p>The proof of the theorem is not difficult, once you notice that it’s invariant under Möbius transformations: the four given circles and their crossing angles transform to another four circles with the same crossing angles, preserving any cocircularities among the eight crossing points.
So start by finding a Möbius transformation that makes two opposite circles  and  become the same size as each other. Because of the equality of crossing angles, both of the other two circles must have centers on the perpendicular bisector to line . There’s still a one-dimensional family of Möbius transformations remaining that preserves the position of  and  but moves the other circles along this bisector; use this remaining degree of freedom to move the other two circles so that their centers are equidistant from line . Then, because of the equality of crossing angles, circles  and  must have the same radii. So we have transformed the input to a position where the circles are centered at the vertices of a rhombus with opposite pairs having the same radius. By symmetry, the crossing points must lie on two rectangles, and the four corners of each rectangle are cocircular.</p>

<p style="text-align: center;"><img alt="Four circles crossing at equal angles at the corners of a rhombus, and the two rectangles through their crossing points" src="https://11011110.github.io/blog/assets/2018/4circle-rect.svg"/></p>

<p>This can be extended to some configurations of circles where the opposite pairs cross each other rather than staying disjoint, but you have to be more careful about what happens when more than two circles cross at one point, and about determining which of the two supplementary angles at each crossing to use as the crossing angle of the two circles. If you’re not careful, you get situations like the one below  where two degenerate circles (the coordinate axes) are crossed at equal angles by two more circles, but where the eight crossings do not form another two circles.</p>

<p style="text-align: center;"><img alt="Two degenerate circles (the coordinate axes) and two circles that cross them at equal angles, without forming two more sets of four cocircular points" src="https://11011110.github.io/blog/assets/2018/4circle-bad.svg"/></p>

<p>Maybe the easiest way to state the more general result is that if a non-self-crossing quadrilateral with circular-arc sides has four equal interior angles at its vertices, then it is <a href="https://en.wikipedia.org/wiki/Cyclic_quadrilateral">cyclic</a>.
I used a special case of this, for right-angled quadrilaterals, in my paper “A Möbius-invariant power diagram and its applications to soap bubbles and planar Lombardi drawing” (<a href="https://doi.org/10.1007/s00454-014-9627-0"><em>Discrete Comput. Geom.</em> 2014</a>).
This formulation also works for the special case when all four angles are zero, which was used in a mesh generation algorithm by Bern, Mitchell, and Ruppert (“Linear-size nonobtuse triangulation of polygons”, <a href="https://doi.org/10.1007/BF02570715"><em>Discrete Comput. Geom.</em> 1995</a>).</p>

<p style="text-align: center;"><img alt="A chain of four tangent circles and a fifth circle through their four points of tangency" src="https://11011110.github.io/blog/assets/2018/4circle-cusp.svg"/></p>

<p>I don’t know whether this theorem has appeared previously, but it’s obviously related to <a href="https://11011110.github.io/blog/2006/03/22/miquels-six-circles.html">Miquel’s six-circle theorem</a>, which takes five circles (without assumption about angles) and produces a sixth in a configuration closely resembling what you get from the four given circles and two produced circles of this theorem.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/101287137001551762"/>, <a href="https://plus.google.com/100003628603413742554/posts/9p3Hza4hGE1">G+</a>)</p></div>
    </content>
    <updated>2018-12-22T14:39:00Z</updated>
    <published>2018-12-22T14:39:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-01-03T05:47:41Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=15529</id>
    <link href="https://rjlipton.wordpress.com/2018/12/21/explanations-and-explorations/" rel="alternate" type="text/html"/>
    <title>Explanations and Explorations</title>
    <summary>Comparing proofs for the Jaccard metric BetterExplained source Kalid Azad is the founder of the website Better Explained. It is devoted to explaining mathematical concepts. He also has written two books. Today we discuss how some proofs provide a concise explanation whereas others promote exploration of related concepts. Azad’s site has a rich page titled, […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><font color="#0044cc"><br/>
<em>Comparing proofs for the Jaccard metric</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2018/12/KalidAzad.jpg"><img alt="" class="alignright wp-image-15530" height="158" src="https://rjlipton.files.wordpress.com/2018/12/KalidAzad.jpg?w=142&amp;h=158" width="142"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">BetterExplained <a href="https://betterexplained.com/about/">source</a></font></td>
</tr>
</tbody>
</table>
<p>
Kalid Azad is the founder of the <a href="https://betterexplained.com/">website</a> <em>Better Explained</em>. It is devoted to explaining mathematical concepts. He also has written <a href="https://betterexplained.com/ebook/math/">two</a> <a href="https://www.amazon.com/gp/product/B017ZXWY3U/">books</a>. </p>
<p>
Today we discuss how some proofs provide a concise <em>explanation</em> whereas others promote <em>exploration</em> of related concepts.<br/>
<span id="more-15529"/></p>
<p>
Azad’s site has a rich <a href="https://betterexplained.com/articles/proofs-vs-explanations/">page</a> titled, “Math Proofs vs. Explanations (aka Nutrition vs. Taste).” It argues that the best <em>explanations</em> start with an analogy to a relation that readers already understand. Even if the connection is not sharp, it can be refined once the reader’s attention is solid. This is opposed to a formal proof in which every step is sharp and correct but intuition is wanting.</p>
<p>
To this we add the role proofs can play in <em>exploration</em>. If you have one proof of a theorem that you understand, there is value in seeking other proofs that use other ideas. Usually we think of ideas as coming first—as thoughts we refine into a proof. The advantage of starting with a proof is already having certitude and sharpness—you know a recipe that works and now can try varying and augmenting it. </p>
<p>
</p><p/><h2> Jaccard Distance as Example </h2><p/>
<p/><p>
Azad’s page gives examples of proofs for the Pythagorean Theorem and for <img alt="{e^{i\theta} = \cos(\theta) + i\sin(\theta)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Be%5E%7Bi%5Ctheta%7D+%3D+%5Ccos%28%5Ctheta%29+%2B+i%5Csin%28%5Ctheta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{e^{i\theta} = \cos(\theta) + i\sin(\theta)}"/>. It then quotes from William Thurston’s <a href="http://arxiv.org/abs/math/9404236">essay</a> “On Proofs and Progress in Mathematics,” which we once <a href="https://rjlipton.wordpress.com/2014/09/18/lets-mention-foundations/">mentioned</a>. We will use the example of Jaccard distance <img alt="{J_\delta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BJ_%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{J_\delta}"/> from our previous <a href="https://rjlipton.wordpress.com/2018/12/14/explaining-the-jaccard-metric/">post</a>. We start with this definition: </p>
<p align="center"><img alt="\displaystyle  J_\delta(A,B) = \frac{|A \;\Delta\; B|}{|A \cup B|}, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++J_%5Cdelta%28A%2CB%29+%3D+%5Cfrac%7B%7CA+%5C%3B%5CDelta%5C%3B+B%7C%7D%7B%7CA+%5Ccup+B%7C%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  J_\delta(A,B) = \frac{|A \;\Delta\; B|}{|A \cup B|}, "/></p>
<p>now using <img alt="{\Delta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CDelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Delta}"/> for the symmetric difference <img alt="{(A \cup B) \setminus (A \cap B)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28A+%5Ccup+B%29+%5Csetminus+%28A+%5Ccap+B%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(A \cup B) \setminus (A \cap B)}"/>. So the triangle inequality becomes, for any finite sets <img alt="{A,B,C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%2CB%2CC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A,B,C}"/>: <a name="triangle"/></p><a name="triangle">
<p align="center"><img alt="\displaystyle  \frac{|A \;\Delta\; C|}{|A \cup C|} \leq \frac{|A \;\Delta\; B|}{|A \cup B|} + \frac{|B \;\Delta\; C|}{|B \cup C|}. \ \ \ \ \ (1)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7B%7CA+%5C%3B%5CDelta%5C%3B+C%7C%7D%7B%7CA+%5Ccup+C%7C%7D+%5Cleq+%5Cfrac%7B%7CA+%5C%3B%5CDelta%5C%3B+B%7C%7D%7B%7CA+%5Ccup+B%7C%7D+%2B+%5Cfrac%7B%7CB+%5C%3B%5CDelta%5C%3B+C%7C%7D%7B%7CB+%5Ccup+C%7C%7D.+%5C+%5C+%5C+%5C+%5C+%281%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \frac{|A \;\Delta\; C|}{|A \cup C|} \leq \frac{|A \;\Delta\; B|}{|A \cup B|} + \frac{|B \;\Delta\; C|}{|B \cup C|}. \ \ \ \ \ (1)"/></p>
</a><p><a name="triangle"/> We think the proof we gave in the last post is simple and direct and intuitive but maybe not explorative. It first connects the solid understanding that without the denominators this would be the well-known triangle inequality for Hamming distance. To reprise, it considers <img alt="{A,C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%2CC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A,C}"/> fixed and varies <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B}"/> to arrive at that simpler fact in three steps:</p>
<ol>
<li>
If <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B}"/> contains <img alt="{b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{b}"/> elements not in <img alt="{A \cup C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA+%5Ccup+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A \cup C}"/> then removing them subtracts <img alt="{b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{b}"/> from both right-hand numerators and both right-hand denominators. Since those fractions are each <img alt="{&lt; 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%3C+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{&lt; 1}"/> (else <a href="https://rjlipton.wordpress.com/feed/#triangle">1</a> would be immediately true), the right-hand side goes down. <p/>
</li><li>
Then we have <img alt="{B \subseteq A \cup C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB+%5Csubseteq+A+%5Ccup+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B \subseteq A \cup C}"/> and can replace the denominators by <img alt="{|A \cup C|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7CA+%5Ccup+C%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|A \cup C|}"/> without increasing the right-hand side. <p/>
</li><li>
Now we have a common denominator and a statement equivalent to the known truth about Hamming distance. Since undoing the first two steps to restore the original <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B}"/> can only increase the right-hand side, (<a href="https://rjlipton.wordpress.com/feed/#triangle">1</a>) is proved in all cases.
</li></ol>
<p>
This reasoning readily extends to nonnegative measures <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/> on <img alt="{A,B,C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%2CB%2CC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A,B,C}"/> besides simple counting, provided the removal of elements from <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B}"/> makes the same additive-or-proportional change to <img alt="{f(A \;\Delta\; B)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28A+%5C%3B%5CDelta%5C%3B+B%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(A \;\Delta\; B)}"/> as it does to <img alt="{f(A \cup B)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28A+%5Ccup+B%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(A \cup B)}"/>, and likewise for the other fraction. </p>
<p>
</p><p/><h2> Three Snapshot Proofs </h2><p/>
<p/><p>
The first short proof should join the pantheon of half-page journal papers. Under fair use, here it is in one screenshot:</p>
<p><a href="https://rjlipton.files.wordpress.com/2018/12/GilbertProof1972b.png"><img alt="" class="aligncenter wp-image-15547" height="410" src="https://rjlipton.files.wordpress.com/2018/12/GilbertProof1972b.png?w=295&amp;h=410" width="295"/></a></p>
<p>
Perhaps this is <i>too</i> short. We think this proof would have been more satisfying if a few more lines of calculation had been added. Let us divide the region <img alt="{T_1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T_1}"/> into its inner part <img alt="{T_{1i}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_%7B1i%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T_{1i}}"/> and outer part <img alt="{T_{1o}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_%7B1o%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T_{1o}}"/> and do likewise for <img alt="{T_2,T_3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_2%2CT_3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T_2,T_3}"/>. Then it seems the intent was: </p>
<p align="center"><img alt="\displaystyle  \begin{array}{rcl}  d(S_1,S_3) &amp;=&amp; 1 - \frac{|S_1 \cap S_3|}{|S_1 \cup S_3|}  = 1 - \frac{|T_{2i}| + |V|}{|U| - |T_{2o}|}\\ &amp;\leq&amp; 1 - \frac{|V|}{|U|} = \frac{|U| - |V|}{|U|} = \frac{|T_1| + |T_2| + |T_3|}{|U|}\\ &amp;\leq&amp; \frac{|T_1| + |T_2|}{|U|} + \frac{|T_2| + |T_3|}{|U|}\\ &amp;\leq&amp; \frac{|T_1| + |T_2|}{|U| - |T_{3o}|} + \frac{|T_2| + |T_3|}{|U| - |T_{1o}|} = d(S_1,S_2) + d(S_2,S_3). \end{array} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Barray%7D%7Brcl%7D++d%28S_1%2CS_3%29+%26%3D%26+1+-+%5Cfrac%7B%7CS_1+%5Ccap+S_3%7C%7D%7B%7CS_1+%5Ccup+S_3%7C%7D++%3D+1+-+%5Cfrac%7B%7CT_%7B2i%7D%7C+%2B+%7CV%7C%7D%7B%7CU%7C+-+%7CT_%7B2o%7D%7C%7D%5C%5C+%26%5Cleq%26+1+-+%5Cfrac%7B%7CV%7C%7D%7B%7CU%7C%7D+%3D+%5Cfrac%7B%7CU%7C+-+%7CV%7C%7D%7B%7CU%7C%7D+%3D+%5Cfrac%7B%7CT_1%7C+%2B+%7CT_2%7C+%2B+%7CT_3%7C%7D%7B%7CU%7C%7D%5C%5C+%26%5Cleq%26+%5Cfrac%7B%7CT_1%7C+%2B+%7CT_2%7C%7D%7B%7CU%7C%7D+%2B+%5Cfrac%7B%7CT_2%7C+%2B+%7CT_3%7C%7D%7B%7CU%7C%7D%5C%5C+%26%5Cleq%26+%5Cfrac%7B%7CT_1%7C+%2B+%7CT_2%7C%7D%7B%7CU%7C+-+%7CT_%7B3o%7D%7C%7D+%2B+%5Cfrac%7B%7CT_2%7C+%2B+%7CT_3%7C%7D%7B%7CU%7C+-+%7CT_%7B1o%7D%7C%7D+%3D+d%28S_1%2CS_2%29+%2B+d%28S_2%2CS_3%29.+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \begin{array}{rcl}  d(S_1,S_3) &amp;=&amp; 1 - \frac{|S_1 \cap S_3|}{|S_1 \cup S_3|}  = 1 - \frac{|T_{2i}| + |V|}{|U| - |T_{2o}|}\\ &amp;\leq&amp; 1 - \frac{|V|}{|U|} = \frac{|U| - |V|}{|U|} = \frac{|T_1| + |T_2| + |T_3|}{|U|}\\ &amp;\leq&amp; \frac{|T_1| + |T_2|}{|U|} + \frac{|T_2| + |T_3|}{|U|}\\ &amp;\leq&amp; \frac{|T_1| + |T_2|}{|U| - |T_{3o}|} + \frac{|T_2| + |T_3|}{|U| - |T_{1o}|} = d(S_1,S_2) + d(S_2,S_3). \end{array} "/></p>
<p>The end uses the symmetric-difference definition of <img alt="{J_{\delta}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BJ_%7B%5Cdelta%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{J_{\delta}}"/>, so perhaps fully expanding this paper’s intent would have been longer. One can also begin with that definition to get a shorter calculation, but it skips over the <img alt="{1 - \frac{|V|}{|U|}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1+-+%5Cfrac%7B%7CV%7C%7D%7B%7CU%7C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1 - \frac{|V|}{|U|}}"/> step. Indeed, it does not mention <img alt="{V}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BV%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{V}"/> at all, so it was not intended. The proof by Artur Grygorian and Ionut Iacob in a short <a href="https://www.tandfonline.com/doi/abs/10.1080/07468342.2018.1526020">paper</a> in last October’s <em>College J. Math.</em> strikes us as a similar-style proof. </p>
<p>
The second proof comes from a MathOverflow <a href="https://mathoverflow.net/q/315845">thread</a>. It assigns a variable to each region of the Venn diagram, forms the fractions, and cross-multiplies to obtain “the following monstrosity”:</p>
<p>
<a href="https://rjlipton.files.wordpress.com/2018/12/JaccardEquation.jpg"><img alt="" class="aligncenter wp-image-15532" height="232" src="https://rjlipton.files.wordpress.com/2018/12/JaccardEquation.jpg?w=400&amp;h=232" width="400"/></a></p>
<p>
The fact that no coefficient is negative completes the proof. This is clear from a computer algebra system, but what about <em>why</em> no negative term appears? </p>
<p>
We have realized since the last post that the second of two proofs given in the 2016 <a href="https://arxiv.org/pdf/1612.02696.pdf">paper</a> by Sven Kosub, which we linked in that post, is really equivalent to ours. This is easier to see if one just presumes <img alt="{f(\emptyset) = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28%5Cemptyset%29+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(\emptyset) = 0}"/> in the following:</p>
<p><a href="https://rjlipton.files.wordpress.com/2018/12/KosubProof.png"><img alt="" class="aligncenter wp-image-15533" height="360" src="https://rjlipton.files.wordpress.com/2018/12/KosubProof.png?w=500&amp;h=360" width="500"/></a></p>
<p>
Here <em>sub-modularity</em> is a standard property for which Kosub cites the equivalent condition that whenever <img alt="{B \subseteq D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB+%5Csubseteq+D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B \subseteq D}"/> and <img alt="{x \notin D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx+%5Cnotin+D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x \notin D}"/>, </p>
<p align="center"><img alt="\displaystyle  f(B \cup\{x\}) - f(B) \geq f(D \cup \{x\}) - f(D). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++f%28B+%5Ccup%5C%7Bx%5C%7D%29+-+f%28B%29+%5Cgeq+f%28D+%5Ccup+%5C%7Bx%5C%7D%29+-+f%28D%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  f(B \cup\{x\}) - f(B) \geq f(D \cup \{x\}) - f(D). "/></p>
<p>This suffices for step 1 of our earlier proof, first taking <img alt="{D = A \cup B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD+%3D+A+%5Ccup+B%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D = A \cup B}"/> then <img alt="{D = B \cup C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD+%3D+B+%5Ccup+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D = B \cup C}"/>; the rest of that proof needs only that <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/> is monotone (and implicitly <img alt="{f(\emptyset) = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28%5Cemptyset%29+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(\emptyset) = 0}"/>). </p>
<p>
</p><p/><h2> A Magical Proof </h2><p/>
<p/><p>
Now we look at proofs that add ideas. The first one still strikes us as clean and magical. We are computer scientists so it is natural to think of finite sets as binary-valued vectors of length <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>. They have a <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/> in position <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/> precisely when <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/> is in the set. Of course <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> is the size of the “universe.” </p>
<p>
Now let <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X}"/> be such a non-zero vector. The key is to use a probabilistic proof. We will show that we can relate the Jaccard distance to the outcome of a simple random experiment. The experiment once selected leads to a simple proof—it only requires the union bound. Recall this is the fact that 	</p>
<p align="center"><img alt="\displaystyle  P[E_{1} \vee E_{2}] \le P[E_{1}] +P[E_{2}], " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++P%5BE_%7B1%7D+%5Cvee+E_%7B2%7D%5D+%5Cle+P%5BE_%7B1%7D%5D+%2BP%5BE_%7B2%7D%5D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  P[E_{1} \vee E_{2}] \le P[E_{1}] +P[E_{2}], "/></p>
<p>for any two events <img alt="{E_{1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BE_%7B1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{E_{1}}"/> and <img alt="{E_{2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BE_%7B2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{E_{2}}"/>. </p>
<p>
The cool idea is to look at the permutations of the vector <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X}"/>. For a permutation <img alt="{\pi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\pi}"/> let us define <img alt="{\pi(X)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\pi(X)}"/> to be 	</p>
<p align="center"><img alt="\displaystyle  x_{\pi(1)},\cdots,x_{\pi(n)}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++x_%7B%5Cpi%281%29%7D%2C%5Ccdots%2Cx_%7B%5Cpi%28n%29%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  x_{\pi(1)},\cdots,x_{\pi(n)}. "/></p>
<p>Let <img alt="{\mathsf{first}(X)=i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7Bfirst%7D%28X%29%3Di%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{first}(X)=i}"/> provided <img alt="{x_{i}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_%7Bi%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x_{i}}"/> is the first value that is equal to <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>. Of course since <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X}"/> is non-empty it follows that this is well defined. </p>
<p>
Note <img alt="{\mathsf{first}(\pi(X))}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7Bfirst%7D%28%5Cpi%28X%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{first}(\pi(X))}"/> is a random variable that depends on the choice of the permutation <img alt="{\pi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\pi}"/>. The key is to see that the probability that <img alt="{\mathsf{first}(\pi(X))=\mathsf{first}(\pi(Y))}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7Bfirst%7D%28%5Cpi%28X%29%29%3D%5Cmathsf%7Bfirst%7D%28%5Cpi%28Y%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{first}(\pi(X))=\mathsf{first}(\pi(Y))}"/> when we average over all permutations uniformly is equal to 	</p>
<p align="center"><img alt="\displaystyle  \frac{|X \cap Y|}{|X \cup Y|}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7B%7CX+%5Ccap+Y%7C%7D%7B%7CX+%5Ccup+Y%7C%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \frac{|X \cap Y|}{|X \cup Y|}. "/></p>
<p>This follows by noting that there are <img alt="{|XY|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7CXY%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|XY|}"/> ways to select the same <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/> and there are <img alt="{|X \cup Y|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7CX+%5Ccup+Y%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|X \cup Y|}"/> total ways to select an <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/>. Complementing gives us that the probability of <img alt="{\mathsf{first}(\pi(X)) \neq \mathsf{first}(\pi(Y))}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7Bfirst%7D%28%5Cpi%28X%29%29+%5Cneq+%5Cmathsf%7Bfirst%7D%28%5Cpi%28Y%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{first}(\pi(X)) \neq \mathsf{first}(\pi(Y))}"/> equals <img alt="{J_\delta(X,Y)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BJ_%5Cdelta%28X%2CY%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{J_\delta(X,Y)}"/>.</p>
<p>
Now hark back to our sets <img alt="{A,B,C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%2CB%2CC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A,B,C}"/>. The event </p>
<p align="center"><img alt="\displaystyle  \mathsf{first}(\pi(A)) \neq \mathsf{first}(\pi(C)) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathsf%7Bfirst%7D%28%5Cpi%28A%29%29+%5Cneq+%5Cmathsf%7Bfirst%7D%28%5Cpi%28C%29%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \mathsf{first}(\pi(A)) \neq \mathsf{first}(\pi(C)) "/></p>
<p>is subsumed by the disjunction of events </p>
<p align="center"><img alt="\displaystyle  \mathsf{first}(\pi(A)) \neq \mathsf{first}(\pi(B)) \vee \mathsf{first}(\pi(B)) \neq \mathsf{first}(\pi(C)) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathsf%7Bfirst%7D%28%5Cpi%28A%29%29+%5Cneq+%5Cmathsf%7Bfirst%7D%28%5Cpi%28B%29%29+%5Cvee+%5Cmathsf%7Bfirst%7D%28%5Cpi%28B%29%29+%5Cneq+%5Cmathsf%7Bfirst%7D%28%5Cpi%28C%29%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \mathsf{first}(\pi(A)) \neq \mathsf{first}(\pi(B)) \vee \mathsf{first}(\pi(B)) \neq \mathsf{first}(\pi(C)) "/></p>
<p>regardless of what <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B}"/> is. By the simple union bound, the probability of the first event is at most the sum of the probabilities of the latter two events. We have thus proved </p>
<p align="center"><img alt="\displaystyle  J_\delta(A,C) \leq J_\delta(A,B) + J_\delta(B,C). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++J_%5Cdelta%28A%2CC%29+%5Cleq+J_%5Cdelta%28A%2CB%29+%2B+J_%5Cdelta%28B%2CC%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  J_\delta(A,C) \leq J_\delta(A,B) + J_\delta(B,C). "/></p>
<p>
The last step is the same as in the proof that Hamming distance is a metric. What does the randomized view gain us? It gains a nice interpretation of <img alt="{J_\delta(A,B)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BJ_%5Cdelta%28A%2CB%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{J_\delta(A,B)}"/> as the probability that <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/> and <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B}"/> hash to different values under the <em>min-hash</em> function <img alt="{\mathsf{first}\circ\pi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7Bfirst%7D%5Ccirc%5Cpi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{first}\circ\pi}"/> for random <img alt="{\pi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\pi}"/>. Min-hashing is used all the time—see this <a href="http://infolab.stanford.edu/~ullman/mmds/ch3.pdf">book chapter</a> by Jure Leskovec, Anand Rajaraman, and Jeffrey Ullman, with this proof in section 3.3.3. 		 </p>
<p/><h2> A Gradient Idea </h2><p/>
<p/><p>
Atri Rudra suggested to us the “game” of adjusting <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B}"/> one element at a time to walk it toward an extreme value. The sets <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/> and <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> can be adjusted too. We start by assuming the triangle inequality (<a href="https://rjlipton.wordpress.com/feed/#triangle">1</a>) is false and make moves that can only keep it that way, until we reach a case where it is obviously true. </p>
<p>
Step 1 of our proof already plays this game by removing from <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B}"/> any elements not in <img alt="{A \cup C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA+%5Ccup+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A \cup C}"/>. So we really start the game with <img alt="{B \subseteq A \cup C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB+%5Csubseteq+A+%5Ccup+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B \subseteq A \cup C}"/> and we want to walk it to <img alt="{B = A \cup C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB+%3D+A+%5Ccup+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B = A \cup C}"/>. Simply replacing the denominators <img alt="{|A \cup B|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7CA+%5Ccup+B%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|A \cup B|}"/> and <img alt="{|B \cup C|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7CB+%5Ccup+C%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|B \cup C|}"/> in (<a href="https://rjlipton.wordpress.com/feed/#triangle">1</a>) by <img alt="{|A \cup C|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7CA+%5Ccup+C%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|A \cup C|}"/> was good in step 2 of the proof but is not a legal move in this game. </p>
<p>
What we can do legally is add elements from <img alt="{A \cap C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA+%5Ccap+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A \cap C}"/> to <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B}"/>: those leave the denominators unchanged but lower the numerators <img alt="{|A \;\Delta\; B|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7CA+%5C%3B%5CDelta%5C%3B+B%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|A \;\Delta\; B|}"/> and <img alt="{|B \;\Delta\; C|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7CB+%5C%3B%5CDelta%5C%3B+C%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|B \;\Delta\; C|}"/>. The interesting case is when we want to add to <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B}"/> an element from <img alt="{A \setminus C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA+%5Csetminus+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A \setminus C}"/> or from <img alt="{C \setminus A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC+%5Csetminus+A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C \setminus A}"/>. The former add decreases the numerator <img alt="{|A \;\Delta\; B|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7CA+%5C%3B%5CDelta%5C%3B+B%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|A \;\Delta\; B|}"/> and increases the denominator <img alt="{|B \cup C|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7CB+%5Ccup+C%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|B \cup C|}"/> while leaving <img alt="{A \cup B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA+%5Ccup+B%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A \cup B}"/> unchanged, but it <em>increases</em> the numerator <img alt="{|B \;\Delta\; C|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7CB+%5C%3B%5CDelta%5C%3B+C%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|B \;\Delta\; C|}"/>. Let us abstract the right-hand side of (<a href="https://rjlipton.wordpress.com/feed/#triangle">1</a>) to <img alt="{\frac{p}{q} + \frac{r}{s}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7Bp%7D%7Bq%7D+%2B+%5Cfrac%7Br%7D%7Bs%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\frac{p}{q} + \frac{r}{s}}"/>. Then the former add converts it to </p>
<p align="center"><img alt="\displaystyle  \frac{p-1}{q} + \frac{r+1}{s+1} \qquad\text{and the latter add to}\qquad \frac{p+1}{q+1} + \frac{r-1}{s}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7Bp-1%7D%7Bq%7D+%2B+%5Cfrac%7Br%2B1%7D%7Bs%2B1%7D+%5Cqquad%5Ctext%7Band+the+latter+add+to%7D%5Cqquad+%5Cfrac%7Bp%2B1%7D%7Bq%2B1%7D+%2B+%5Cfrac%7Br-1%7D%7Bs%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \frac{p-1}{q} + \frac{r+1}{s+1} \qquad\text{and the latter add to}\qquad \frac{p+1}{q+1} + \frac{r-1}{s}. "/></p>
<p>If <em>both</em> moves increase the right-hand side, then we must have </p>
<p align="center"><img alt="\displaystyle  \frac{p}{q} + \frac{r}{s} &lt; \frac{p-1}{q} + \frac{r+1}{s+1}, \quad\text{so}\quad \frac{1}{q} &lt; \frac{r+1}{s+1} - \frac{r}{s} = \frac{s-r}{s(s+1)} &lt; \frac{1}{s+1}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7Bp%7D%7Bq%7D+%2B+%5Cfrac%7Br%7D%7Bs%7D+%3C+%5Cfrac%7Bp-1%7D%7Bq%7D+%2B+%5Cfrac%7Br%2B1%7D%7Bs%2B1%7D%2C+%5Cquad%5Ctext%7Bso%7D%5Cquad+%5Cfrac%7B1%7D%7Bq%7D+%3C+%5Cfrac%7Br%2B1%7D%7Bs%2B1%7D+-+%5Cfrac%7Br%7D%7Bs%7D+%3D+%5Cfrac%7Bs-r%7D%7Bs%28s%2B1%29%7D+%3C+%5Cfrac%7B1%7D%7Bs%2B1%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \frac{p}{q} + \frac{r}{s} &lt; \frac{p-1}{q} + \frac{r+1}{s+1}, \quad\text{so}\quad \frac{1}{q} &lt; \frac{r+1}{s+1} - \frac{r}{s} = \frac{s-r}{s(s+1)} &lt; \frac{1}{s+1}. "/></p>
<p>And from </p>
<p align="center"><img alt="\displaystyle  \frac{p}{q} + \frac{r}{s} &lt; \frac{p+1}{q+1} + \frac{r-1}{s}, \quad\text{we get}\quad \frac{1}{s} &lt; \frac{1}{q+1}\;. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7Bp%7D%7Bq%7D+%2B+%5Cfrac%7Br%7D%7Bs%7D+%3C+%5Cfrac%7Bp%2B1%7D%7Bq%2B1%7D+%2B+%5Cfrac%7Br-1%7D%7Bs%7D%2C+%5Cquad%5Ctext%7Bwe+get%7D%5Cquad+%5Cfrac%7B1%7D%7Bs%7D+%3C+%5Cfrac%7B1%7D%7Bq%2B1%7D%5C%3B.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \frac{p}{q} + \frac{r}{s} &lt; \frac{p+1}{q+1} + \frac{r-1}{s}, \quad\text{we get}\quad \frac{1}{s} &lt; \frac{1}{q+1}\;. "/></p>
<p>But cross-multiplying gives the contradiction <img alt="{q+ 1 &lt; s &lt; s+1 &lt; q}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq%2B+1+%3C+s+%3C+s%2B1+%3C+q%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q+ 1 &lt; s &lt; s+1 &lt; q}"/>. So one or both moves must always be possible. This grows <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B}"/> to include either all of <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/> or all of <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/>. The rest of the argument to gobble up all of <img alt="{A \cup C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA+%5Ccup+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A \cup C}"/> we leave to you, dear readers.</p>
<p>
Compared to the above proofs, this is tedious. But it captures some tensions among the sizes of <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/>, <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B}"/>, and <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> that may inform intuitions about Jaccard similarity under changes in the sets. </p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Which proof do you like best for explanation and which for creative impulse? </p>
<p>
This is our <img alt="{801^{st}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B801%5E%7Bst%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{801^{st}}"/> post. We intended this discussion as number 800 but were surprised to find the simple proof by reduction to triangle for Hamming distance (steps numbered 1-2-3 above). Are we really the first to write it down, with acknowledgment also to Kosub?</p>
<p>
[some typo fixes]</p></font></font></div>
    </content>
    <updated>2018-12-22T01:59:19Z</updated>
    <published>2018-12-22T01:59:19Z</published>
    <category term="All Posts"/>
    <category term="History"/>
    <category term="Ideas"/>
    <category term="Proofs"/>
    <category term="trick"/>
    <category term="Better Explained"/>
    <category term="explanations"/>
    <category term="exploration"/>
    <category term="ideas"/>
    <category term="Jaccard metric"/>
    <category term="Kalid Azad"/>
    <category term="triangle inequality"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-01-08T00:28:44Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=6524</id>
    <link href="https://windowsontheory.org/2018/12/20/tensor-networks-matrix-product-states-dmrg/" rel="alternate" type="text/html"/>
    <title>Tensor Networks, Matrix Product States and Density Matrix Renormalization Group</title>
    <summary>In this note, we introduce the notions of tensor networks and matrix product states (MPS). These objects are particularly useful in describing quantum states of low entanglement.

We then discuss how to efficiently compute the ground states of the Hamiltonians of 1D quantum systems (using classical computers). The density matrix renormalization group (DMRG), due to White (1992, 1993), is arguably the most successful heuristic for this problem. We describe it in the language of tensor networks and MPS.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><strong>by Fred Zhang</strong></p>
<p><em>This is the second installment of a three-part series of posts on quantum Hamiltonian complexity based on lectures given by the authors in <a href="https://www.boazbarak.org/fall18seminar/">Boaz and Tselil’s seminar</a>. For the basic definitions of local Hamiltonians, see <a href="https://windowsontheory.org/2018/12/20/quantum-hamiltonian-complexity/">Ben’s first post</a>. Also check out <a href="https://windowsontheory.org/2018/12/18/a-1d-area-law-for-gapped-local-hamiltonians/">Boriana and Prayaag’s followup note</a> on area laws.</em></p>
<p>This post introduces tensor networks and matrix product states (MPS). These are useful linear-algebraic objects for describing quantum states of low entanglement.</p>
<p>We then discuss how to efficiently compute the ground states of the Hamiltonians of <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{1}"/>D quantum systems (using classical computers). The density matrix renormalization group (DMRG), due to White (1992, 1993), is arguably the most successful heuristic for this problem. We describe it in the language of tensor networks and MPS.</p>
<p><b>1. Introduction </b></p>
<p class="p1">We are interested in computing the ground state—the minimum eigenvector—of a quantum Hamiltonian, a <img alt="2^n \times 2^n" class="latex" src="https://s0.wp.com/latex.php?latex=2%5En+%5Ctimes+2%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^n \times 2^n"/> complex matrix that governs the evolution of a quantum system of <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> qubits. We restrict our attention to the local Hamiltonian, where the matrix is a sum of Hamiltonians each acting only on <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/> qubits.  In the previous article, we discussed some hardness results. Namely, a local Hamiltonian can be used to encode SAT instances, and we further gave a proof that computing the ground state is QMA-Complete.</p>
<p>Despite the hardness results, physicists have come up with a variety of heuristics for solving this problem. If quantum interactions occur locally, we would hope that its ground state has low entanglement and thus admits a succinct classical representation. Further, we hope to find such a representation efficiently, using classical computers.</p>
<p>In this note, we will see <i>tensor networks</i> and <i>matrix product states</i> that formalize the idea of succinctly representing quantum states of low entanglement. As a side remark for the theoretical computer scientists here, one motivation to study tensor network is that it provides a powerful visual tool for thinking about linear algebra. It turns indices into edges in a graph and summations over indices into contractions of edges. In particular, we will soon see that the most useful inequality in TCS and mathematics can be drawn as a cute tensor network.</p>
<p/><div class="wp-caption aligncenter" id="attachment_6535" style="width: 276px;"><a href="https://windowsontheory.files.wordpress.com/2018/12/note0x.png"><img alt="" class="wp-image-6535 size-full" src="https://windowsontheory.files.wordpress.com/2018/12/note0x.png?w=600"/></a><p class="wp-caption-text">Guess what this is?</p></div><p/>
<p>In the end, we will discuss the density matrix renormalization group (DMRG), which has established itself as “the most powerful tool for treating 1D quantum systems” over the last decade [<a href="https://windowsontheory.org/feed/#Xfehske2007computational">FSW07</a>]. For many 1D systems that arise from practice, the heuristic efficiently finds an (approximate) ground state in its matrix product state, specified only by a small number of parameters.</p>
<p><b>2. Tensor Networks </b></p>
<p>Now let us discuss our first subject, <i>tensor networks</i>. If you have not seen <i>tensors</i> before, it is a generalization of matrices. In computer scientists’ language, a matrix is a two-dimensional array, and a tensor is a multi-dimensional array. In other words, if we think of a matrix as a square, then a 3 dimensional tensor looks like a cube. Formally, a (complex) n dimensional tensor <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{T}"/> maps <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> indices to complex values, namely, to its entries:</p>
<p align="center"><img alt="\displaystyle T : [d_1] \times [d_2] \times \cdots \times [d_n] \rightarrow \mathbb{C}." class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+T+%3A+%5Bd_1%5D+%5Ctimes+%5Bd_2%5D+%5Ctimes+%5Ccdots+%5Ctimes+%5Bd_n%5D+%5Crightarrow+%5Cmathbb%7BC%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle T : [d_1] \times [d_2] \times \cdots \times [d_n] \rightarrow \mathbb{C}."/></p>
<p>The simplest tensor network is a graphical notation for a tensor. For an <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{n}"/>-dimensional tensor <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/>, we draw a star graph and label the center as <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> and the edges as the indices. To evaluate this tensor network, we put values on the edges, <i>i.e.</i>, indices, and then the tensor network would spit out its entry specified by the indices.</p>
<p/><div class="wp-caption aligncenter" id="attachment_6550" style="width: 170px;"><a href="https://windowsontheory.files.wordpress.com/2018/12/note2x.png"><img alt="" class="wp-image-6550 size-full" src="https://windowsontheory.files.wordpress.com/2018/12/note2x.png?w=600"/></a><p class="wp-caption-text">A simple tensor network of 4 dimensions <a name="figsimp-1"/></p></div><p/>
<p/><div class="wp-caption aligncenter" id="attachment_6551" style="width: 354px;"><a href="https://windowsontheory.files.wordpress.com/2018/12/note3x.png"><img alt="" class="wp-image-6551 size-full" src="https://windowsontheory.files.wordpress.com/2018/12/note3x.png?w=600"/></a><p class="wp-caption-text">Evaluating a simple tensor network, <img alt="{T(1,5,3,1)=1/\sqrt{2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%281%2C5%2C3%2C1%29%3D1%2F%5Csqrt%7B2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T(1,5,3,1)=1/\sqrt{2}}"/>. The numbers are chosen arbitrarily.<a name="figsimp-2"/></p></div><p/>
<p>Notice that the degree of the center is the number of indices. Hence, a tensor network of degree <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/> is a vector, and that of degree <img alt="{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2}"/> is a matrix, and so forth.<a name="figsimple-tn"/></p>
<p/><div class="wp-caption aligncenter" id="attachment_6574" style="width: 34px;"><a href="https://windowsontheory.files.wordpress.com/2018/12/note6x.png"><img alt="" class="wp-image-6574 size-full" src="https://windowsontheory.files.wordpress.com/2018/12/note6x.png?w=600"/></a><p class="wp-caption-text">A vector</p></div><p/>
<p/><div class="wp-caption aligncenter" id="attachment_6575" style="width: 106px;"><a href="https://windowsontheory.files.wordpress.com/2018/12/note7x.png"><img alt="" class="wp-image-6575 size-full" src="https://windowsontheory.files.wordpress.com/2018/12/note7x.png?w=600"/></a><p class="wp-caption-text">A matrix</p></div><p/>
<p/><div class="wp-caption aligncenter" id="attachment_6576" style="width: 158px;"><a href="https://windowsontheory.files.wordpress.com/2018/12/note8x.png"><img alt="" class="wp-image-6576 size-full" src="https://windowsontheory.files.wordpress.com/2018/12/note8x.png?w=600"/></a><p class="wp-caption-text">A 3d tensor</p></div><p/>
<p>How is this related to quantum information? For the sake of genearlity we will deal with qudits in <img alt="{\mathbb{C}^d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BC%7D%5Ed%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{\mathbb{C}^d}"/>, instead of qubits in <img alt="{\mathbb{C}^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BC%7D%5E2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{\mathbb{C}^2}"/>. Now recall that a quantum state <img alt="{|\psi_n\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7C%5Cpsi_n%5Crangle%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{|\psi_n\rangle}"/> of <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{n}"/> qudits can be encoded as an <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> dimensional tensor. It can be written as</p>
<p style="text-align: center;"><img alt="|\psi_n\rangle = \displaystyle\sum_{i_1,\cdots,i_n = 0}^{d-1} T(i_1,\cdots, i_n) |i_1,\cdots, i_n \rangle." class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi_n%5Crangle+%3D+%5Cdisplaystyle%5Csum_%7Bi_1%2C%5Ccdots%2Ci_n+%3D+0%7D%5E%7Bd-1%7D+T%28i_1%2C%5Ccdots%2C+i_n%29+%7Ci_1%2C%5Ccdots%2C+i_n+%5Crangle.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi_n\rangle = \displaystyle\sum_{i_1,\cdots,i_n = 0}^{d-1} T(i_1,\cdots, i_n) |i_1,\cdots, i_n \rangle."/></p>
<p>It is easy to see that all the information, namely, the amplitudes, is just the tensor <img alt="T" class="latex" src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T"/>. In the later sections, we will see more powerful examples of using tensor networks to represent a quantum state.</p>
<p>So far our discussion is focused merely on these little pictures. The power of tensor networks come from its composition rules, which allow us to join two simple tensor networks together and impose rich internal structures.</p>
<p><b> 2.1. Composition Rules </b></p>
<p>We introduce two ways of joining two simple tensor networks. Roughly speaking, they correspond to multiplication and summation, and I will give the definitions by showing examples, instead of stating them in the full formalism</p>
<p><strong>Rule #1: Tensor Product.</strong> The product rule allows us to put two tensor networks together and view them as a whole. The resulting tensor is the tensor product of the two if we think of them as vectors. More concretely, consider the following picture.</p>
<p/><div class="wp-caption aligncenter" id="attachment_6564" style="width: 364px;"><a href="https://windowsontheory.files.wordpress.com/2018/12/note10x.png"><img alt="" class="wp-image-6564 size-full" src="https://windowsontheory.files.wordpress.com/2018/12/note10x.png?w=600"/></a><p class="wp-caption-text">This is viewed as a single tensor network <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> of 7 edges<span> </span>.<a name="figtp"/></p></div><p/>
<p>The definition of this joint tensor <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{T}"/> is</p>
<p style="text-align: center;"><img alt="T(i_1,i_2,\cdots, i_7) = T_1(i_1,i_2,i_3,i_4) T_2(i_5,i_6,i_7)." class="latex" src="https://s0.wp.com/latex.php?latex=T%28i_1%2Ci_2%2C%5Ccdots%2C+i_7%29+%3D+T_1%28i_1%2Ci_2%2Ci_3%2Ci_4%29+T_2%28i_5%2Ci_6%2Ci_7%29.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T(i_1,i_2,\cdots, i_7) = T_1(i_1,i_2,i_3,i_4) T_2(i_5,i_6,i_7)."/></p>
<p><strong>Rule #2: Edge Contractions</strong>. At this moment, we can only make up disconnected tensor networks. Edge contractions allow us to link two tensor networks. Suppose we have two <img alt="{3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{3}"/> dimensional tensor networks. Contracting two edges, one from each, gives us a tensor network of <img alt="{4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{4}"/> <i>free edges</i>. This now corresponds a tensor of <img alt="{4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{4}"/> dimensions.</p>
<p/><div class="wp-caption aligncenter" id="attachment_6579" style="width: 310px;"><a href="https://windowsontheory.files.wordpress.com/2018/12/note12x.png"><img alt="" class="size-medium wp-image-6579" height="116" src="https://windowsontheory.files.wordpress.com/2018/12/note12x.png?w=300&amp;h=116" width="300"/></a><p class="wp-caption-text">Two 3d tensors</p></div><p/>
<p/><div class="wp-caption aligncenter" id="attachment_6563" style="width: 310px;"><a href="https://windowsontheory.files.wordpress.com/2018/12/note13x.png"><img alt="" class="size-medium wp-image-6563" height="116" src="https://windowsontheory.files.wordpress.com/2018/12/note13x.png?w=300&amp;h=116" width="300"/></a><p class="wp-caption-text">Join two tensor networks by contracting an edge</p></div><p/>
<p>We name the contracted edge as <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/>. The definition of <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> is</p>
<p style="text-align: center;"><img alt="\displaystyle T(i_1,i_2,j_1,j_2) =\sum_k T_1(i_1,i_2, k) T_2(j_1,j_2, k)." class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+T%28i_1%2Ci_2%2Cj_1%2Cj_2%29+%3D%5Csum_k+T_1%28i_1%2Ci_2%2C+k%29+T_2%28j_1%2Cj_2%2C+k%29.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle T(i_1,i_2,j_1,j_2) =\sum_k T_1(i_1,i_2, k) T_2(j_1,j_2, k)."/></p>
<p><b> 2.2. Useful Examples </b></p>
<p>Before we move on, let’s take some examples. Keep in mind that the degree of the vertex determines the number of indices (dimensions of this tensor).</p>
<p/><div class="wp-caption aligncenter" id="attachment_6584" style="width: 127px;"><img alt="note15x" class="alignnone size-full wp-image-6584" src="https://windowsontheory.files.wordpress.com/2018/12/note15x.png?w=600"/><p class="wp-caption-text">vector inner product <img alt="{\langle u,v \rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clangle+u%2Cv+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\langle u,v \rangle}"/></p></div><p/>
<p/><div class="wp-caption aligncenter" id="attachment_6585" style="width: 178px;"><img alt="note16x" class="alignnone size-full wp-image-6585" src="https://windowsontheory.files.wordpress.com/2018/12/note16x.png?w=600"/><p class="wp-caption-text">Matrix inner product</p></div><p/>
<p>Here, one needs to remember that an edge between two tensor nodes is a summation over the index corresponding to the edge. For example, in the vector inner product picture, <img alt="{\langle u,v\rangle = \sum_i u_i \cdot v_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clangle+u%2Cv%5Crangle+%3D+%5Csum_i+u_i+%5Ccdot+v_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\langle u,v\rangle = \sum_i u_i \cdot v_i}"/>, where edge is labeled as <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/>. Now you would realize that this picture</p>
<p><img alt="" class="wp-image-6535 size-full aligncenter" src="https://windowsontheory.files.wordpress.com/2018/12/note0x.png?w=600"/></p>
<p>is the famous</p>
<p style="text-align: center;"><img alt="\langle u,v \rangle^2 \leq \|u\|^2 \|v\|^2. \quad\quad (\text{Cauchy-Schwarz inequality}) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Clangle+u%2Cv+%5Crangle%5E2+%5Cleq+%5C%7Cu%5C%7C%5E2+%5C%7Cv%5C%7C%5E2.+%5Cquad%5Cquad+%28%5Ctext%7BCauchy-Schwarz+inequality%7D%29+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\langle u,v \rangle^2 \leq \|u\|^2 \|v\|^2. \quad\quad (\text{Cauchy-Schwarz inequality}) "/></p>
<p>For us, the most important building block is matrix multiplication. Let <img alt="{H=MN}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BH%3DMN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{H=MN}"/>. By definition</p>
<p style="text-align: center;"><img alt="H(i,j) = \sum_k M(i,k) N(k, j). " class="latex" src="https://s0.wp.com/latex.php?latex=H%28i%2Cj%29+%3D+%5Csum_k+M%28i%2Ck%29+N%28k%2C+j%29.+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H(i,j) = \sum_k M(i,k) N(k, j). "/></p>
<p>This is precisely encoded in the picture below.</p>
<p/><div class="wp-caption aligncenter" id="attachment_6587" style="width: 276px;"><img alt="note20x.png" class="alignnone size-full wp-image-6587" src="https://windowsontheory.files.wordpress.com/2018/12/note20x.png?w=600"/><p class="wp-caption-text">Matrix multiplication, <img alt="{MN}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BMN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{MN}"/>.<span style="background-color: #ffffff; color: #3d596d; font-size: 16px;"> </span><a name="figmat-mul" style="color: #3d596d; font-size: 16px;"/><span style="background-color: #ffffff; color: #3d596d; font-size: 16px;"> </span></p></div><p/>
<p>We are ready to talk about matrix product states. In the language of tensor network, a matrix product state is the following picture.</p>
<p/><div class="wp-caption aligncenter" id="attachment_6588" style="width: 590px;"><img alt="note21x" class="alignnone size-full wp-image-6588" src="https://windowsontheory.files.wordpress.com/2018/12/note21x.png?w=600"/><p class="wp-caption-text">A matrix product state.</p></div><p/>
<p>As the degrees indicate, the two boundary vertices <img alt="{A_1,A_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_1%2CA_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_1,A_n}"/> represent matrices and the internal vertices represent <img alt="{3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{3}"/>-dimensional tensors. We can view each matrix as a set of (column) vectors and each <img alt="{3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{3}"/>-dimensional tensor as a stack of matrices. Then each one of the free edges picks out a vector or a matrix, and the contracted edges multiply them together which gives out a scalar. If this confused you, move on to the next section. I will introduce the formal definition of matrix product states, and you will see that it is just the picture above.</p>
<p><b>3. Matrix Product States </b></p>
<p>Before giving the definition, let’s talk about how matrix product state (MPS) naturally arises from the study of quantum states with low entanglement. Matrix product state can be viewed as a generalization of <i>product state</i>—(pure) quantum state with no entanglement. Let’s consider a simple product state <img alt="{|\psi\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7C%5Cpsi%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|\psi\rangle}"/> of <img alt="{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2}"/> qubits. It can be factorized: <a name="eqnmps0"/></p>
<p align="center"><a name="eqnmps0"/><img alt="\displaystyle |\psi\rangle = \left(\sum_{i=0}^1 \alpha_1^i\ |i\rangle \right)\left(\sum_{j=0}^1 \alpha_2^j \ |j\rangle\right)\nonumber = \sum_{i,j=0}^1 \alpha_1^i \alpha_2^j\ |ij\rangle \ \ \ \ \ (1)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%7C%5Cpsi%5Crangle+%3D+%5Cleft%28%5Csum_%7Bi%3D0%7D%5E1+%5Calpha_1%5Ei%5C+%7Ci%5Crangle+%5Cright%29%5Cleft%28%5Csum_%7Bj%3D0%7D%5E1+%5Calpha_2%5Ej+%5C+%7Cj%5Crangle%5Cright%29%5Cnonumber+%3D+%5Csum_%7Bi%2Cj%3D0%7D%5E1+%5Calpha_1%5Ei+%5Calpha_2%5Ej%5C+%7Cij%5Crangle+%5C+%5C+%5C+%5C+%5C+%281%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle |\psi\rangle = \left(\sum_{i=0}^1 \alpha_1^i\ |i\rangle \right)\left(\sum_{j=0}^1 \alpha_2^j \ |j\rangle\right)\nonumber = \sum_{i,j=0}^1 \alpha_1^i \alpha_2^j\ |ij\rangle \ \ \ \ \ (1)"/></p>
<p><a name="eqnmps0"/><br/>
<a name="eqnmps0"/> This state is described by <img alt="{4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{4}"/> complex scalars <img alt="{\left\{\alpha_1^0,\alpha_1^1,\alpha_2^0,\alpha_2^1\right\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cleft%5C%7B%5Calpha_1%5E0%2C%5Calpha_1%5E1%2C%5Calpha_2%5E0%2C%5Calpha_2%5E1%5Cright%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\left\{\alpha_1^0,\alpha_1^1,\alpha_2^0,\alpha_2^1\right\}}"/>, and there is nothing quantum about it. However, if the state has entanglement among its qubits, then we know that it is impossible to be factorized and thereby written as (<a href="https://windowsontheory.org/feed/#eqnmps0">1</a>). MPS generalizes the form of (<a href="https://windowsontheory.org/feed/#eqnmps0">1</a>) by replacing the scalars with matrices and vectors.</p>
<p>More formally, a matrix product state starts with the following setup. For an <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>-qudit system, we associate</p>
<ul>
<li>a qudit in <img alt="{\{1,n\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B1%2Cn%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{1,n\}}"/> with <img alt="{d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d}"/> vectors <img alt="{\left\{A_1^{j_1}\right\}, \left\{A_n^{j_n}\right\} \in \mathbb{R}^D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cleft%5C%7BA_1%5E%7Bj_1%7D%5Cright%5C%7D%2C+%5Cleft%5C%7BA_n%5E%7Bj_n%7D%5Cright%5C%7D+%5Cin+%5Cmathbb%7BR%7D%5ED%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\left\{A_1^{j_1}\right\}, \left\{A_n^{j_n}\right\} \in \mathbb{R}^D}"/>; and</li>
<li>a qudit <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/> in <img alt="{\{2,3,\cdots, n-1\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B2%2C3%2C%5Ccdots%2C+n-1%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{2,3,\cdots, n-1\}}"/> with <img alt="{d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d}"/> matrices <img alt="{\left\{A_i^{j_i}\right\}\in \mathbb{R}^{D\times D}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cleft%5C%7BA_i%5E%7Bj_i%7D%5Cright%5C%7D%5Cin+%5Cmathbb%7BR%7D%5E%7BD%5Ctimes+D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\left\{A_i^{j_i}\right\}\in \mathbb{R}^{D\times D}}"/>.</li>
</ul>
<p>Here, <img alt="{j_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bj_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{j_i}"/> range from <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/> to <img alt="{d-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d-1}"/>, and <img alt="{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D}"/> is called <i>bond dimension</i>. One can think of the set of vectors as a <img alt="{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D}"/> by <img alt="{d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d}"/> matrix and the set of matrices as a <img alt="{d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d}"/> by <img alt="{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D}"/> by <img alt="{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D}"/> three-dimensional tensor. Then let them correspond to the vertices in MPS picture. With this setup, a quantum state is in matrix product state if it can be written as</p>
<p style="text-align: center;"><img alt="|\psi\rangle = \sum_{j_1,\cdots,j_n=1}^n A_1^{j_1} A_2^{j_2} \cdots A_n^{j_n} |j_1 j_2\cdots j_n\rangle." class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle+%3D+%5Csum_%7Bj_1%2C%5Ccdots%2Cj_n%3D1%7D%5En+A_1%5E%7Bj_1%7D+A_2%5E%7Bj_2%7D+%5Ccdots+A_n%5E%7Bj_n%7D+%7Cj_1+j_2%5Ccdots+j_n%5Crangle.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi\rangle = \sum_{j_1,\cdots,j_n=1}^n A_1^{j_1} A_2^{j_2} \cdots A_n^{j_n} |j_1 j_2\cdots j_n\rangle."/></p>
<p>It is important to keep in mind that <img alt="{A_1^{j_1},A_n^{j_n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_1%5E%7Bj_1%7D%2CA_n%5E%7Bj_n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_1^{j_1},A_n^{j_n}}"/> are two vectors, and the other inner terms are matrices, and we get a scalar from the product. Thus, this represents the tensor <img alt="{T(j_1,j_2,\cdots, j_n) = A_1^{j_1} A_2^{j_2} \cdots A_n^{j_n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%28j_1%2Cj_2%2C%5Ccdots%2C+j_n%29+%3D+A_1%5E%7Bj_1%7D+A_2%5E%7Bj_2%7D+%5Ccdots+A_n%5E%7Bj_n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T(j_1,j_2,\cdots, j_n) = A_1^{j_1} A_2^{j_2} \cdots A_n^{j_n}}"/>.</p>
<p>Now back to the picture,</p>
<p/><div class="wp-caption aligncenter" id="attachment_6588" style="width: 590px;"><img alt="note21x" class="alignnone size-full wp-image-6588" src="https://windowsontheory.files.wordpress.com/2018/12/note21x.png?w=600"/><p class="wp-caption-text">MPS</p></div><p/>
<p>notice that each amplitude <img alt="{ A_1^{j_1} A_2^{j_2} \cdots A_n^{j_n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+A_1%5E%7Bj_1%7D+A_2%5E%7Bj_2%7D+%5Ccdots+A_n%5E%7Bj_n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ A_1^{j_1} A_2^{j_2} \cdots A_n^{j_n}}"/> from the equation above is an output of the tensor in the picture, where the free edges take values <img alt="{j_1, j_2 ,\cdots, j_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bj_1%2C+j_2+%2C%5Ccdots%2C+j_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{j_1, j_2 ,\cdots, j_n}"/>. Also, as discussed earlier, the contracted edges in MPS tensor network correspond to matrix and vector multiplications, so the tensor <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> is precisely represented by the picture.</p>
<p>The complexity of the MPS is closely related to the bond dimension <img alt="{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D}"/>. In particular, the number of parameters in this model is <img alt="{O(ndD^2)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%28ndD%5E2%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{O(ndD^2)}"/>. We would expect that with higher <img alt="{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D}"/>, we may describe quantum states of more entanglement. In other words, the representation power of an MPS increases with <img alt="{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D}"/>. In principle, one can represent any quantum state as an MPS; however, <img alt="{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D}"/> can be exponentially large. See, <i>e.g.</i>, Section 4.1.3 of~\cite{schollwock2011density} for a proof. On the other extreme, the product state example shows that if <img alt="{D=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D=1}"/>, one can represent and <i>only</i> represent unentangled states. To summarize, here is the picture you should keep in mind.</p>
<p/><div class="wp-caption alignnone" id="attachment_6594" style="width: 776px;"><img alt="note33x" class="alignnone size-full wp-image-6594" src="https://windowsontheory.files.wordpress.com/2018/12/note33x.png?w=600"/><p class="wp-caption-text">Representation power of MPS increases with bond dimension D.</p></div><p/>
<p><a name="figpower"/></p>
<p> </p>
<p><b>4. Density Matrix Renormalization Group </b></p>
<p>We are now ready to describe Density Matrix Renormalization Group, proposed originally in [<a href="https://windowsontheory.org/feed/#XPhysRevLett.69.2863">Whi92</a>, <a href="https://windowsontheory.org/feed/#XPhysRevB.48.10345">Whi93</a>]. As mentioned earlier, it does not come with provable guarantees. In fact, one can construct artificial hard instances such that the algorithm get stuck at certain local minima [<a href="https://windowsontheory.org/feed/#Xschuch2008computational">SCV08</a>]. However, it has remained one of the most successful heuristics for <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>D systems. We refer the readers to [<a href="https://windowsontheory.org/feed/#Xschollwock2011density">Sch11</a>] for a complete survey.</p>
<p>DMRG is a simple alternating minimization scheme for computing the ground state of a <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>D Hamiltonian. We start with an arbitrary MPS. Then each step we optimize over the set of matrices <img alt="{\left\{A_i^{j_i}\right\}_{j_i=0}^d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cleft%5C%7BA_i%5E%7Bj_i%7D%5Cright%5C%7D_%7Bj_i%3D0%7D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\left\{A_i^{j_i}\right\}_{j_i=0}^d}"/> associated with site <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/>, while fixing everything else, and iterate until convergence. (You may wonder if one can simultaneously optimize over multiple sites. It turns out that it is an NP-hard problem<span class="LinLibertineT-tlf-ot-1x-x-90"> </span><span class="cite"><span class="LinLibertineT-tlf-ot-1x-x-90">[</span><a href="https://windowsontheory.org/feed/#XPhysRevLett.97.260501">Eis06</a><span class="LinLibertineT-tlf-ot-1x-x-90">]</span></span>.)</p>
<p>Formally, the Hamiltonian problem can be phrased as a eigenvalue problem given a Hermitian matrix <img alt="{H}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{H}"/>, and thus we want to optimize over all <img alt="{|\psi\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7C%5Cpsi%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|\psi\rangle}"/> in MPS of a fixed bond dimension <img alt="{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D}"/> <a name="eqnham"/></p>
<p style="text-align: center;"><img alt="\min_{|\psi\rangle}\frac{\langle \psi| H | \psi \rangle}{\langle \psi ||\psi \rangle}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmin_%7B%7C%5Cpsi%5Crangle%7D%5Cfrac%7B%5Clangle+%5Cpsi%7C+H+%7C+%5Cpsi+%5Crangle%7D%7B%5Clangle+%5Cpsi+%7C%7C%5Cpsi+%5Crangle%7D.+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\min_{|\psi\rangle}\frac{\langle \psi| H | \psi \rangle}{\langle \psi ||\psi \rangle}. "/></p>
<p>Here, we assume that the input Hamiltonian is in the product form. In particular, it means that it can be written as a tensor network as</p>
<p/><div class="wp-caption aligncenter" id="attachment_6596" style="width: 430px;"><img alt="note36x" class="alignnone size-full wp-image-6596" src="https://windowsontheory.files.wordpress.com/2018/12/note36x.png?w=600"/><p class="wp-caption-text">Input <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>D Hamiltonian is of the particular product form.</p></div><p/>
<p>so the numerator of the optimization objective looks like</p>
<p><img alt="note37x" class=" size-full wp-image-6597 aligncenter" src="https://windowsontheory.files.wordpress.com/2018/12/note37x.png?w=600"/><a name="figdmrg1"/></p>
<p>The DMRG works with the Langrangian of the objective. For some <img alt="{\lambda&gt;0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\lambda&gt;0}"/>, we will consider <a name="eqndmrg2"/></p>
<p align="center"><a name="eqndmrg2"/><img alt="\displaystyle \min_{|\psi\rangle}\,\, {\langle \psi| H | \psi \rangle} - \lambda {\langle \psi ||\psi \rangle}. \ \ \ \ \ (2)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmin_%7B%7C%5Cpsi%5Crangle%7D%5C%2C%5C%2C+%7B%5Clangle+%5Cpsi%7C+H+%7C+%5Cpsi+%5Crangle%7D+-+%5Clambda+%7B%5Clangle+%5Cpsi+%7C%7C%5Cpsi+%5Crangle%7D.+%5C+%5C+%5C+%5C+%5C+%282%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \min_{|\psi\rangle}\,\, {\langle \psi| H | \psi \rangle} - \lambda {\langle \psi ||\psi \rangle}. \ \ \ \ \ (2)"/></p>
<p><a name="eqndmrg2"/><br/>
<a name="eqndmrg2"/>DMRG optimizes over the set of matrices associated with one qudit. Both terms in (<a href="https://windowsontheory.org/feed/#eqndmrg2">2</a>) are quadratic in this set of matrices.</p>
<p/><div class="wp-caption aligncenter" id="attachment_6598" style="width: 919px;"><img alt="note39x" class="alignnone size-full wp-image-6598" src="https://windowsontheory.files.wordpress.com/2018/12/note39x.png?w=600"/><p class="wp-caption-text">The Langrangian <img alt="{{\langle \psi| H | \psi \rangle} - \lambda {\langle \psi ||\psi \rangle}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Clangle+%5Cpsi%7C+H+%7C+%5Cpsi+%5Crangle%7D+-+%5Clambda+%7B%5Clangle+%5Cpsi+%7C%7C%5Cpsi+%5Crangle%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{\langle \psi| H | \psi \rangle} - \lambda {\langle \psi ||\psi \rangle}}"/> as a tensor network.</p></div><p/>
<p>Now to optimize over the set of parameters associated with one site, calculus tells you to set the (partial) derivative to <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/>, and the derivative of a quadratic thing is linear. Without going through any algebra, we can guess that the derivative of  with respect to a particular site, say the second one, is the same picture except removing the second site on one side.</p>
<p/><div class="wp-caption alignnone" id="attachment_6599" style="width: 919px;"><img alt="note40x" class="alignnone size-full wp-image-6599" src="https://windowsontheory.files.wordpress.com/2018/12/note40x.png?w=600"/><p class="wp-caption-text">The derivative that we set to <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/> and solve.</p></div><p/>
<p>Notice that the unknown is still there, on the bottom side of each term. The trick of DMRG is to view the rest of the network as a linear map applied to the unknown.</p>
<p><img alt="note41x" class="alignnone size-full wp-image-6600" src="https://windowsontheory.files.wordpress.com/2018/12/note41x.png?w=600"/></p>
<p>Given <img alt="{H'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BH%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{H'}"/> and <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B}"/>, we now have a clean numerical linear algebra problem of solving</p>
<p align="center"><img alt="\displaystyle H'x = \lambda Bx. \ \ \ \ \ (3)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+H%27x+%3D+%5Clambda+Bx.+%5C+%5C+%5C+%5C+%5C+%283%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle H'x = \lambda Bx. \ \ \ \ \ (3)"/></p>
<p>This is called a generalized eigenvalue problem, and it is well studied. Importantly, for <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>D systems, <img alt="{H'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BH%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{H'}"/> is typically very sparse, which enables very fast solvers in practice. Finally, DMRG sweeps over the sites one after another and stops until convergence is achieved.</p>
<p><b>5. Concluding Remarks </b></p>
<p class="noindent">Our presentation of tensor networks and MPS roughly follows <span class="cite">[<a href="https://windowsontheory.org/feed/#Xgharibian2015quantum">GHLS15</a>]</span>, a nice introductory survey on quantum Hamiltonian complexity.</p>
<p>The notion of tensor networks extends well beyond 1D systems, and a generalization of MPS is called tensor product state. It leads to algorithms for higher dimensional quantum systems. One may read <span class="cite">[<a href="https://windowsontheory.org/feed/#Xcirac2009renormalization">CV09</a>]</span> for a comprehensive survey.</p>
<p>Tensor network has been interacting with other concepts. Within physics, it has been used in quantum error correction <span class="cite">[<a href="https://windowsontheory.org/feed/#Xferris2014tensor">FP14</a>, <a href="https://windowsontheory.org/feed/#Xpastawski2015holographic">PYHP15</a>]</span>, conformal field theory <span class="cite">[<a href="https://windowsontheory.org/feed/#Xorus2014advances">Orú14</a>]</span>, and statistical mechanics <span class="cite">[<a href="https://windowsontheory.org/feed/#XPhysRevLett.115.180405">EV15</a>]</span>. In TCS , we have found its connections with Holographic algorithms <span class="cite">[<a href="https://windowsontheory.org/feed/#Xvaliant2008holographic">Val08</a>, <a href="https://windowsontheory.org/feed/#Xcai2016complete">CGW16</a>]</span>, arithmetic complexity <span class="cite">[<a href="https://windowsontheory.org/feed/#Xbeaudry2007complexity">BH07</a>, <a href="https://windowsontheory.org/feed/#Xcapelli2016arithmetic">CDM16</a>, <a href="https://windowsontheory.org/feed/#Xaustrin19">AKK19</a>]</span>, and spectral algorithms <span class="cite">[<a href="https://windowsontheory.org/feed/#Xmoitra2018spectral">MW18</a>]</span>. In machine learning, it has been applied to probabilistic graphical models <span class="cite">[<a href="https://windowsontheory.org/feed/10.1093/imaiai/iay009">RS18</a>]</span>, tensor decomposition <span class="cite">[<a href="https://windowsontheory.org/feed/#Xcichocki2016low">CLO16</a>]</span>, and quantum machine learning <span class="cite">[<a href="https://windowsontheory.org/feed/#X10.1088/2058-9565/aaea94">HPM18</a>]</span>.</p>
<p>For DMRG, we have only given a rough outline, with many details omitted, such as how to set <img alt="{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D}"/> and <img alt="{\lambda}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\lambda}"/> and how to obtain the Hamiltonian in the matrix product form, and how to compute the linear maps <img alt="{H'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BH%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{H'}"/> and <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B}"/> for each iteration. An interested reader may read <span class="cite">[<a href="https://windowsontheory.org/feed/#Xschollwock2005density">Sch05</a>, <a href="https://windowsontheory.org/feed/#Xschollwock2011density">Sch11</a>]</span>.</p>
<p><strong>References</strong></p>
<p class="bibitem"><span class="biblabel">[AKK19] <span class="bibsp">   </span></span><a id="Xaustrin19"/>Per Austrin, Peeri Kaski, and Kaie Kubjas. Tensor network complexity of multilinear maps. In <span class="LinLibertineTI-tlf-ot-1x-x-109">Proceedings of the 2019 Conference on Innovations in Theoretical Computer Science</span>. ACM, 2019.</p>
<p class="bibitem"><span class="biblabel">[BH07] <span class="bibsp">   </span></span><a id="Xbeaudry2007complexity"/>Martin Beaudry and Markus Holzer. The complexity of tensor circuit evaluation. <span class="LinLibertineTI-tlf-ot-1x-x-109">Computational</span> <span class="LinLibertineTI-tlf-ot-1x-x-109">Complexity</span>, 16(1):60, 2007.</p>
<p class="bibitem"><span class="biblabel">[CDM16] <span class="bibsp">   </span></span><a id="Xcapelli2016arithmetic"/>Florent Capelli, Arnaud Durand, and Stefan Mengel. e arithmetic complexity of tensor contraction. <span class="LinLibertineTI-tlf-ot-1x-x-109">eory of Computing Systems</span>, 58(4):506{527, 2016.</p>
<p class="bibitem"><span class="biblabel">[CGW16] <span class="bibsp">   </span></span><a id="Xcai2016complete"/>Jin-Yi Cai, Heng Guo, and Tyson Williams. A complete dichotomy rises from the capture of vanishing signatures. <span class="LinLibertineTI-tlf-ot-1x-x-109">SIAM Journal on Computing</span>, 45(5):1671{1728, 2016.</p>
<p class="bibitem"><span class="biblabel">[CLO16] <span class="bibsp">   </span></span><a id="Xcichocki2016low"/>Andrzej Cichocki, Namgil Lee, Ivan V Oseledets, A-H Phan, Qibin Zhao, and D Mandic. Low-rank tensor networks for dimensionality reduction and large-scale optimization problems: Perspectives and challenges part 1. <span class="LinLibertineTI-tlf-ot-1x-x-109">arXiv preprint arXiv:1609.00893</span>, 2016.</p>
<p class="bibitem"><span class="biblabel">[CV09] <span class="bibsp">   </span></span><a id="Xcirac2009renormalization"/>J Ignacio Cirac and Frank Verstraete. Renormalization and tensor product states in spin chains and laices. <span class="LinLibertineTI-tlf-ot-1x-x-109">Journal of Physics A: Mathematical and Theoretical</span>, 42(50):504004, 2009.</p>
<p class="bibitem"><span class="biblabel">[Eis06] <span class="bibsp">   </span></span><a id="XPhysRevLett.97.260501"/>Jens Eisert. Computational difficulty of global variations in the density matrix renormalization group. <span class="LinLibertineTI-tlf-ot-1x-x-109">Phys. Rev. Le.</span>, 97:260501, Dec 2006.</p>
<p class="bibitem"><span class="biblabel">[EV15] <span class="bibsp">   </span></span><a id="XPhysRevLett.115.180405"/>G. Evenbly and G. Vidal. Tensor network renormalization. <span class="LinLibertineTI-tlf-ot-1x-x-109">Phys. Rev. Le.</span>, 115:180405, Oct 2015.</p>
<p class="bibitem"><span class="biblabel">[FP14] <span class="bibsp">   </span></span><a id="Xferris2014tensor"/>Andrew J Ferris and David Poulin. Tensor networks and quantum error correction. <span class="LinLibertineTI-tlf-ot-1x-x-109">Phys. Rev.</span> <span class="LinLibertineTI-tlf-ot-1x-x-109">Le.</span>, 113(3):030501, 2014.</p>
<p class="bibitem"><span class="biblabel">[FSW07] <span class="bibsp">   </span></span><a id="Xfehske2007computational"/>Holger Fehske, Ralf Schneider, and Alexander Weie. <span class="LinLibertineTI-tlf-ot-1x-x-109">Computational Many-Particle Physics</span>. Springer, 2007.</p>
<p class="bibitem"><span class="biblabel">[GHLS15] <span class="bibsp">   </span></span><a id="Xgharibian2015quantum"/>Sevag Gharibian, Yichen Huang, Zeph Landau, and Seung Woo Shin. Quantum Hamiltonian complexity. <span class="LinLibertineTI-tlf-ot-1x-x-109">Foundations and Trends in Theoretical Computer Science</span>, 10(3):159, 2015.</p>
<p class="bibitem"><span class="biblabel">[HPM18]<span class="bibsp">   </span></span><a id="X10.1088/2058-9565/aaea94"/>William James Huggins, Piyush Patil, Bradley Mitchell, K Birgia Whaley, and Miles Stoudenmire. Towards quantum machine learning with tensor networks. Qu<span class="LinLibertineTI-tlf-ot-1x-x-109">antum Science and</span> <span class="LinLibertineTI-tlf-ot-1x-x-109">Technology</span>, 2018.</p>
<p class="bibitem"><span class="biblabel">[MW18] <span class="bibsp">   </span></span><a id="Xmoitra2018spectral"/>Ankur Moitra and Alexander S Wein. Spectral methods from tensor networks. <span class="LinLibertineTI-tlf-ot-1x-x-109">arXiv preprint</span> <span class="LinLibertineTI-tlf-ot-1x-x-109">arXiv:1811.00944</span>, 2018.</p>
<p class="bibitem"><span class="biblabel">[Orú14] <span class="bibsp">   </span></span><a id="Xorus2014advances"/>Román Orús. Advances on tensor network theory: symmetries, fermions, entanglement, and holography. <span class="LinLibertineTI-tlf-ot-1x-x-109">e European Physical Journal B</span>, 87(11):280, 2014.</p>
<p class="bibitem"><span class="biblabel">[PYHP15] <span class="bibsp">   </span></span><a id="Xpastawski2015holographic"/>Fernando Pastawski, Beni Yoshida, Daniel Harlow, and John Preskill. Holographic quantum error-correcting codes: Toy models for the bulk/boundary correspondence. <span class="LinLibertineTI-tlf-ot-1x-x-109">Journal of High Energy</span> <span class="LinLibertineTI-tlf-ot-1x-x-109">Physics</span>, 2015(6):149, 2015.</p>
<p class="bibitem"><span class="biblabel">[RS18] <span class="bibsp">   </span></span><a id="Xdoi:10.1093/imaiai/iay009"/>Elina Robeva and Anna Seigal. Duality of graphical models and tensor networks. <span class="LinLibertineTI-tlf-ot-1x-x-109">Information</span> <span class="LinLibertineTI-tlf-ot-1x-x-109">and Inference: A Journal of the IMA</span>, 2018.</p>
<p class="bibitem"><span class="biblabel">[Sch05] <span class="bibsp">   </span></span><a id="Xschollwock2005density"/>Ulrich Schollwöck. The density-matrix renormalization group. <span class="LinLibertineTI-tlf-ot-1x-x-109">Rev. Mod. Phys.</span>, 77(1):259, 2005.</p>
<p class="bibitem"><span class="biblabel">[Sch11] <span class="bibsp">   </span></span><a id="Xschollwock2011density"/>Ulrich Schollwöck. The density-matrix renormalization group in the age of matrix product states. <span class="LinLibertineTI-tlf-ot-1x-x-109">Annals of Physics</span>, 326(1):96, 2011.</p>
<p class="bibitem"><span class="biblabel">[SCV08] <span class="bibsp">   </span></span><a id="Xschuch2008computational"/>Norbert Schuch, Ignacio Cirac, and Frank Verstraete. Computational difficulty of finding matrix product ground states. <span class="LinLibertineTI-tlf-ot-1x-x-109">Phys. Rev. Le.</span>, 100(25):250501, 2008.</p>
<p class="bibitem"><span class="biblabel">[Val08] <span class="bibsp">   </span></span><a id="Xvaliant2008holographic"/>Leslie G Valiant. Holographic algorithms. <span class="LinLibertineTI-tlf-ot-1x-x-109">SIAM Journal on Computing</span>, 37(5):1565, 2008.</p>
<p class="bibitem"><span class="biblabel">[Whi92] <span class="bibsp">   </span></span><a id="XPhysRevLett.69.2863"/>Steven R. White. Density matrix formulation for quantum renormalization groups. <span class="LinLibertineTI-tlf-ot-1x-x-109">Phys. Rev.</span> <span class="LinLibertineTI-tlf-ot-1x-x-109">Le.</span>, 69:2863, Nov 1992.</p>
<p class="bibitem"><span class="biblabel">[Whi93] <span class="bibsp">   </span></span><a id="XPhysRevB.48.10345"/>Steven R. White. Density-matrix algorithms for quantum renormalization groups. <span class="LinLibertineTI-tlf-ot-1x-x-109">Phys. Rev.</span> <span class="LinLibertineTI-tlf-ot-1x-x-109">B</span>, 48:10345, Oct 1993.</p></div>
    </content>
    <updated>2018-12-20T21:59:13Z</updated>
    <published>2018-12-20T21:59:13Z</published>
    <category term="physics"/>
    <category term="cs229r"/>
    <author>
      <name>Fred Zhang</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2019-01-07T23:33:01Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=6720</id>
    <link href="https://windowsontheory.org/2018/12/20/efficient-preparation-of-thermal-states-of-quantum-systems-natural-or-artificial/" rel="alternate" type="text/html"/>
    <title>Efficient preparation of thermal states of quantum systems: natural or artificial</title>
    <summary>Cross-posted from https://wsmoses.com/blog/2018/12/18/boaz/ Lecturer: Aram Harrow Scribes: Sinho Chewi, William S. Moses, Tasha Schoenstein, Ary Swaminathan November 9, 2018 Outline Sampling from thermal states was one of the first and (initially) most important uses of computers. In this blog post, we will discuss both classical and quantum Gibbs distributions, also known as thermal equilibrium states. We […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><article class="post-content"><p>Cross-posted from <a href="https://wsmoses.com/blog/2018/12/18/boaz/">https://wsmoses.com/blog/2018/12/18/boaz/</a></p><p>Lecturer: Aram Harrow</p><p>Scribes: Sinho Chewi, <a href="http://wsmoses.com">William S. Moses,</a> Tasha Schoenstein, Ary Swaminathan</p><p>November 9, 2018</p></article><p><br/></p><article class="post-content"><h3 id="outline">Outline</h3><p>Sampling from thermal states was one of the first and (initially) most important uses of computers. In this blog post, we will discuss both classical and quantum Gibbs distributions, also known as thermal equilibrium states. We will then discuss Markov chains that have Gibbs distributions as stationary distributions. This leads into a discussion of the equivalence of mixing in time (i.e. the Markov chain quickly equilibrates over time) and mixing in space (i.e. sites that are far apart have small correlation). For the classical case, this equivalence is known. After discussing what is known classically, we will discuss difficulties that arise in the quantum case, including (approximate) Quantum Markov states and the equivalence of mixing in the quantum case.</p><h1 id="gibbs-distributions">Gibbs distributions</h1><p>We have already learned about phase transitions in a <a href="https://windowsontheory.org/feed/https_//windowsontheory.org/2018/09/15/statistical-physics-an-introduction-in-two-parts/">previous blog post</a>, but they are important, so we will review them again. The <strong>Gibbs</strong> or <strong>thermal distribution</strong> is defined as follows: Suppose that we have an <strong>energy function</strong> <img alt="E : {\{0,1\}}^n \to {\mathbb R}" class="latex" src="https://s0.wp.com/latex.php?latex=E+%3A+%7B%5C%7B0%2C1%5C%7D%7D%5En+%5Cto+%7B%5Cmathbb+R%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="E : {\{0,1\}}^n \to {\mathbb R}"/> , which takes <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> -bit strings to real numbers. Usually, <img alt="E = \sum_{i=1}^m E_i" class="latex" src="https://s0.wp.com/latex.php?latex=E+%3D+%5Csum_%7Bi%3D1%7D%5Em+E_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="E = \sum_{i=1}^m E_i"/> , where each <img alt="E_i" class="latex" src="https://s0.wp.com/latex.php?latex=E_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="E_i"/> term depends only on a few bits. For example, the energy might be the number of unsatisfied clauses in a 3-SAT formula, or it may arise from the Ising model. The Gibbs distribution is</p><p><span style="display: block;"> <img alt="p(x) = \frac{\exp\{-E(x)/T\}}{Z}" class="latex" src="https://s0.wp.com/latex.php?latex=p%28x%29+%3D+%5Cfrac%7B%5Cexp%5C%7B-E%28x%29%2FT%5C%7D%7D%7BZ%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p(x) = \frac{\exp\{-E(x)/T\}}{Z}"/> </span></p><p>where the normalization factor in the denominator, also called the <strong>partition function</strong>, is <img alt="Z = \sum_{x \in {\{0,1\}}^n} \exp\{-E(x)/T\}" class="latex" src="https://s0.wp.com/latex.php?latex=Z+%3D+%5Csum_%7Bx+%5Cin+%7B%5C%7B0%2C1%5C%7D%7D%5En%7D+%5Cexp%5C%7B-E%28x%29%2FT%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Z = \sum_{x \in {\{0,1\}}^n} \exp\{-E(x)/T\}"/> . Another, perhaps more operational, way to define the Gibbs distribution is:</p><p><span style="display: block;"> <img alt="p = \;\mathrm{arg\,max}_{q \in {\mathcal{P}}({\{0,1\}}^n)} H(q)~\text{subject to the constraint}~ \langle{q,E}\rangle = \bar{E}." class="latex" src="https://s0.wp.com/latex.php?latex=p+%3D+%5C%3B%5Cmathrm%7Barg%5C%2Cmax%7D_%7Bq+%5Cin+%7B%5Cmathcal%7BP%7D%7D%28%7B%5C%7B0%2C1%5C%7D%7D%5En%29%7D+H%28q%29%7E%5Ctext%7Bsubject+to+the+constraint%7D%7E+%5Clangle%7Bq%2CE%7D%5Crangle+%3D+%5Cbar%7BE%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p = \;\mathrm{arg\,max}_{q \in {\mathcal{P}}({\{0,1\}}^n)} H(q)~\text{subject to the constraint}~ \langle{q,E}\rangle = \bar{E}."/> </span></p><p>In this expression, <img alt="{\mathcal{P}}({\{0,1\}}^n)" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BP%7D%7D%28%7B%5C%7B0%2C1%5C%7D%7D%5En%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{\mathcal{P}}({\{0,1\}}^n)"/> is the set of probability distributions on <img alt="{\{0,1\}}^n" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B0%2C1%5C%7D%7D%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{\{0,1\}}^n"/> , <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> is the Shannon entropy, and <img alt="\bar E" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbar+E&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\bar E"/> is a constant representing the average energy. We are thinking of probability distributions and <img alt="E" class="latex" src="https://s0.wp.com/latex.php?latex=E&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="E"/> as vectors of size <img alt="2^n" class="latex" src="https://s0.wp.com/latex.php?latex=2%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^n"/> . It turns out that if we solve this optimization problem, then the Gibbs distribution is the unique solution.</p><h2 id="uses-of-gibbs-distributions">Uses of Gibbs distributions</h2><p>Why is it useful to work with Gibbs distributions?</p><ul><li><p>Gibbs distributions arise naturally in statistical physics systems, such as constraint satisfaction problems (CSPs), the Ising model, and spin glasses. One approach to deal with Gibbs distributions is through <a href="https://windowsontheory.org/feed/https_//windowsontheory.org/2018/10/20/belief-propagation-and-the-stochastic-block-model/">belief propagation</a> (BP), which yields exact inference on tree graphical models and sometimes phase transition predictions on loopy graphs. Instead, we will focus on a different approach, namely, <em>sampling</em> from the Gibbs distribution.</p></li><li><p>If we want to minimize <img alt="E" class="latex" src="https://s0.wp.com/latex.php?latex=E&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="E"/> (say, to find a 3-SAT solution), we can use <strong>simulated annealing</strong>. The idea of annealing is that we want to produce a crystal; a crystal is the lowest energy configuration of molecules. If we heat up the substance to a liquid and then cool it quickly, we will not get a nice crystal, because little bits of the material will point in different directions. In order to form a crystal, we need to cool the system slowly.</p><p>In computer science terms, we take a sample from a high temperature because sampling is generally easier at a higher temperature than at a lower temperature. We then use that sample as the starting point for an equilibration process at a slightly lower temperature, and repeat this procedure. If we reach zero temperature, then we are sampling from the minimizers of <img alt="E" class="latex" src="https://s0.wp.com/latex.php?latex=E&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="E"/> . In practice, the system will usually stop mixing before we get to zero temperature, but this is a good heuristic. You can think of this process as gradient descent, with some additional randomness.</p></li><li><p>Gibbs distributions are used to simulate physical systems.</p></li><li><p>Gibbs distributions are used in Bayesian inference due to the Hammersley-Clifford theorem, which will be discussed next.</p></li><li><p>Gibbs distributions are also connected to multiplicative weights for linear programming (not discussed in this blog post).</p></li></ul><h2 id="bayesian-inference--the-hammersley-clifford-theorem">Bayesian inference &amp; the Hammersley-Clifford theorem</h2><p>In order to present the Hammersley-Clifford theorem, we must first discuss Markov networks. For this part, we will generalize our setup to a finite alphabet <img alt="\Sigma" class="latex" src="https://s0.wp.com/latex.php?latex=%5CSigma&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Sigma"/> , so the energy function is now a function <img alt="\Sigma^n \to \mathbb R" class="latex" src="https://s0.wp.com/latex.php?latex=%5CSigma%5En+%5Cto+%5Cmathbb+R&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Sigma^n \to \mathbb R"/> .</p><h3 id="markov-chains">Markov chains</h3><p>First, let us recall the idea of a <strong>Markov chain</strong> with variables <img alt="X_1" class="latex" src="https://s0.wp.com/latex.php?latex=X_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X_1"/> , <img alt="X_2" class="latex" src="https://s0.wp.com/latex.php?latex=X_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X_2"/> , <img alt="X_3" class="latex" src="https://s0.wp.com/latex.php?latex=X_3&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X_3"/> .</p></article>


<figure class="wp-block-image"><img alt="" class="wp-image-6784" src="https://windowsontheory.files.wordpress.com/2018/12/p1.png?w=600"/></figure>



<p>The random variables <img alt="X_1" class="latex" src="https://s0.wp.com/latex.php?latex=X_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X_1"/> , <img alt="X_2" class="latex" src="https://s0.wp.com/latex.php?latex=X_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X_2"/> , <img alt="X_3" class="latex" src="https://s0.wp.com/latex.php?latex=X_3&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X_3"/> form a Markov chain if their joint distribution can be written in a factored way: <img alt="p(x_1,x_2,x_3) = p_{1,2}(x_1,x_2)p_{3 \mid 2}(x_3 \mid x_2)" class="latex" src="https://s0.wp.com/latex.php?latex=p%28x_1%2Cx_2%2Cx_3%29+%3D+p_%7B1%2C2%7D%28x_1%2Cx_2%29p_%7B3+%5Cmid+2%7D%28x_3+%5Cmid+x_2%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p(x_1,x_2,x_3) = p_{1,2}(x_1,x_2)p_{3 \mid 2}(x_3 \mid x_2)"/> . For example, imagine that <img alt="X_1" class="latex" src="https://s0.wp.com/latex.php?latex=X_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X_1"/> , <img alt="X_2" class="latex" src="https://s0.wp.com/latex.php?latex=X_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X_2"/> , <img alt="X_3" class="latex" src="https://s0.wp.com/latex.php?latex=X_3&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X_3"/> represent the weather on Monday, Tuesday, and Wednesday respectively. These random variables form a Markov chain if, conditioned on the weather on Tuesday, we have all of the information we need to forecast the weather on Wednesday. Another way to say this is that conditioned on the weather on Tuesday, then the weather on Monday and the weather on Wednesday are <strong>conditionally independent</strong>. Note that the weather on Monday and the weather on Wednesday are <em>not</em> independent; there can be correlations, but these correlations are mediated through the weather on Tuesday. It is important to note that the definition of a Markov chain is symmetric with respect to going forwards or backwards in time, so we can also write the conditional independence condition as <img alt="p(x_1,x_2,x_3) = p_{2,3}(x_2,x_3) p_{1 \mid 2}(x_1 \mid x_2)" class="latex" src="https://s0.wp.com/latex.php?latex=p%28x_1%2Cx_2%2Cx_3%29+%3D+p_%7B2%2C3%7D%28x_2%2Cx_3%29+p_%7B1+%5Cmid+2%7D%28x_1+%5Cmid+x_2%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p(x_1,x_2,x_3) = p_{2,3}(x_2,x_3) p_{1 \mid 2}(x_1 \mid x_2)"/> .</p>



<p>The conditional independence condition can also be written as <img alt="p_{1,3 \mid 2}(x_1, x_3 \mid x_2) = p_{1 \mid 2}(x_1 \mid x_2) p_{3 \mid 2}(x_3 \mid x_2)." class="latex" src="https://s0.wp.com/latex.php?latex=p_%7B1%2C3+%5Cmid+2%7D%28x_1%2C+x_3+%5Cmid+x_2%29+%3D+p_%7B1+%5Cmid+2%7D%28x_1+%5Cmid+x_2%29+p_%7B3+%5Cmid+2%7D%28x_3+%5Cmid+x_2%29.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p_{1,3 \mid 2}(x_1, x_3 \mid x_2) = p_{1 \mid 2}(x_1 \mid x_2) p_{3 \mid 2}(x_3 \mid x_2)."/> Recall that for two random variables <img alt="X_1" class="latex" src="https://s0.wp.com/latex.php?latex=X_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X_1"/> and <img alt="X_2" class="latex" src="https://s0.wp.com/latex.php?latex=X_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X_2"/> with joint distribution <img alt="p" class="latex" src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p"/> , they are independent, i.e., <img alt="p(x_1,x_2) = p_1(x_1) p_2(x_2)" class="latex" src="https://s0.wp.com/latex.php?latex=p%28x_1%2Cx_2%29+%3D+p_1%28x_1%29+p_2%28x_2%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p(x_1,x_2) = p_1(x_1) p_2(x_2)"/> , if and only if <img alt="I(X_1; X_2) = 0" class="latex" src="https://s0.wp.com/latex.php?latex=I%28X_1%3B+X_2%29+%3D+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="I(X_1; X_2) = 0"/> , where <img alt="I" class="latex" src="https://s0.wp.com/latex.php?latex=I&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="I"/> here denotes the mutual information. Similarly, conditional independence is equivalent to the <strong>conditional mutual information</strong> <img alt="I(X_1; X_3 \mid X_2)" class="latex" src="https://s0.wp.com/latex.php?latex=I%28X_1%3B+X_3+%5Cmid+X_2%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="I(X_1; X_3 \mid X_2)"/> equaling zero. This quantity is defined as <img alt="I(X_1;X_3 \mid X_2) = H(X_1 \mid X_2) + H(X_3 \mid X_2) - H(X_1, X_3 \mid X_2)" class="latex" src="https://s0.wp.com/latex.php?latex=I%28X_1%3BX_3+%5Cmid+X_2%29+%3D+H%28X_1+%5Cmid+X_2%29+%2B+H%28X_3+%5Cmid+X_2%29+-+H%28X_1%2C+X_3+%5Cmid+X_2%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="I(X_1;X_3 \mid X_2) = H(X_1 \mid X_2) + H(X_3 \mid X_2) - H(X_1, X_3 \mid X_2)"/> .</p>



<p>Keep in mind that conditional independence is characterized in two equivalent ways: via an algebraic condition on the distributions, and via mutual information.</p>



<h3 id="markov-networks">Markov networks</h3>



<p>A <strong>Markov network</strong> is like a Markov chain, but with more random variables and a more interesting structure. Imagine that we have a graph, where each node is associated with a random variable and the edges encode possible correlations. A Markov network has the property that if we take any disjoint collection of nodes <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> , <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> , and <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/> such that <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> and <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/> are fully separated by <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> (that is, any path from <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> to <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/> must go through <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> , or alternatively, removing <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> leaves <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> and <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/> disconnected), then <img alt="I(X_A; X_C \mid X_B) = 0" class="latex" src="https://s0.wp.com/latex.php?latex=I%28X_A%3B+X_C+%5Cmid+X_B%29+%3D+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="I(X_A; X_C \mid X_B) = 0"/> . The notation <img alt="X_A" class="latex" src="https://s0.wp.com/latex.php?latex=X_A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X_A"/> here means the collection of random variables associated with the nodes in <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> .</p>



<figure class="wp-block-image"><img alt="" class="wp-image-6785" src="https://windowsontheory.files.wordpress.com/2018/12/p2.png?w=600"/></figure>



<p>For example:</p>



<p>Here, if <img alt="A=\{1,5,6\}" class="latex" src="https://s0.wp.com/latex.php?latex=A%3D%5C%7B1%2C5%2C6%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A=\{1,5,6\}"/> , <img alt="B=\{2,7\}" class="latex" src="https://s0.wp.com/latex.php?latex=B%3D%5C%7B2%2C7%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B=\{2,7\}"/> , and <img alt="C=\{3,4\}" class="latex" src="https://s0.wp.com/latex.php?latex=C%3D%5C%7B3%2C4%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C=\{3,4\}"/> , then <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> separates <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> and <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/> .</p>



<p>A Markov network is also called a <strong>graphical model</strong> or a <strong>Markov random field</strong>; and yet another name for them is <em>Gibbs distribution</em>, which is the content of the following theorem:</p>



<p><strong>Theorem 1</strong> (Hammersley-Clifford Theorem): <em>Let <img alt="p" class="latex" src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p"/> be a strictly positive distribution on <img alt="\Sigma^n" class="latex" src="https://s0.wp.com/latex.php?latex=%5CSigma%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Sigma^n"/> . Then, <img alt="p" class="latex" src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p"/> can be represented as a Markov network with respect to a graph <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/> if and only if <img alt="p" class="latex" src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p"/> can be expressed as a Gibbs distribution <img alt="p(x) \propto \exp\{-\sum_{C \in {\mathcal{C}}(G)} E_C(x_C)\}" class="latex" src="https://s0.wp.com/latex.php?latex=p%28x%29+%5Cpropto+%5Cexp%5C%7B-%5Csum_%7BC+%5Cin+%7B%5Cmathcal%7BC%7D%7D%28G%29%7D+E_C%28x_C%29%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p(x) \propto \exp\{-\sum_{C \in {\mathcal{C}}(G)} E_C(x_C)\}"/> , where <img alt="{\mathcal{C}}(G)" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BC%7D%7D%28G%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{\mathcal{C}}(G)"/> is the set of cliques (fully connected subsets) of <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/> . </em></p>



<p>This theorem says that Markov networks are the same as Gibbs states, <em>with the same notion of locality</em>.</p>



<p>The Hammersley-Clifford theorem implies an area law for mutual information; we will explain what this is and sketch why this is true. Divide a system into two disjoint pieces <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> and <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> . We want to know about the mutual information between <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> and <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> , <img alt="I(A;B)" class="latex" src="https://s0.wp.com/latex.php?latex=I%28A%3BB%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="I(A;B)"/> . The Hammersley-Clifford theorem gives us a bound which depends only on the size of the boundary <img alt="\partial" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpartial&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\partial"/> between these sets. For simplicity, assume <img alt="\partial \subseteq B" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpartial+%5Csubseteq+B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\partial \subseteq B"/> . Also, assume that the interactions have bounded range; then, the Hammersley-Clifford theorem tells us that <img alt="I(A; B \mid \partial) = 0" class="latex" src="https://s0.wp.com/latex.php?latex=I%28A%3B+B+%5Cmid+%5Cpartial%29+%3D+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="I(A; B \mid \partial) = 0"/> .</p>



<p>Now, we will use the fact <img alt="I(A; B \mid \partial) = I(A; B,\partial) - I(A; \partial)" class="latex" src="https://s0.wp.com/latex.php?latex=I%28A%3B+B+%5Cmid+%5Cpartial%29+%3D+I%28A%3B+B%2C%5Cpartial%29+-+I%28A%3B+%5Cpartial%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="I(A; B \mid \partial) = I(A; B,\partial) - I(A; \partial)"/> . We can see this by writing out the expressions, but the intuition is that the term on the left asks about how much <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> knows about <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> , having already known about <img alt="\partial" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpartial&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\partial"/> . This equals how much <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> knows about <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> and <img alt="\partial" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpartial&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\partial"/> combined, minus how much <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> knows about <img alt="\partial" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpartial&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\partial"/> alone. In this case, since we said <img alt="\partial \subseteq B" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpartial+%5Csubseteq+B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\partial \subseteq B"/> , then <img alt="I(A; B)" class="latex" src="https://s0.wp.com/latex.php?latex=I%28A%3B+B%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="I(A; B)"/> is the same as <img alt="I(A; B, \partial)" class="latex" src="https://s0.wp.com/latex.php?latex=I%28A%3B+B%2C+%5Cpartial%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="I(A; B, \partial)"/> . In general, however, we have an upper bound:</p>



<p> <img alt="I(A;B) \le I(A; B, \partial) = I(A; \partial) + I(A;B \mid \partial) \le H(\partial) \le |\partial| \log |\Sigma|" class="latex" src="https://s0.wp.com/latex.php?latex=I%28A%3BB%29+%5Cle+I%28A%3B+B%2C+%5Cpartial%29+%3D+I%28A%3B+%5Cpartial%29+%2B+I%28A%3BB+%5Cmid+%5Cpartial%29+%5Cle+H%28%5Cpartial%29+%5Cle+%7C%5Cpartial%7C+%5Clog+%7C%5CSigma%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="I(A;B) \le I(A; B, \partial) = I(A; \partial) + I(A;B \mid \partial) \le H(\partial) \le |\partial| \log |\Sigma|"/> </p>



<p>In this calculation, we have used <img alt="I(A; \partial) = H(\partial) - H(\partial \mid A)" class="latex" src="https://s0.wp.com/latex.php?latex=I%28A%3B+%5Cpartial%29+%3D+H%28%5Cpartial%29+-+H%28%5Cpartial+%5Cmid+A%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="I(A; \partial) = H(\partial) - H(\partial \mid A)"/> (the information between <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> and <img alt="\partial" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpartial&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\partial"/> is the amount by which the entropy of <img alt="\partial" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpartial&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\partial"/> gets reduced once we know <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> ) and <img alt="H(\partial \mid A) \ge 0" class="latex" src="https://s0.wp.com/latex.php?latex=H%28%5Cpartial+%5Cmid+A%29+%5Cge+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H(\partial \mid A) \ge 0"/> (which is true classically).</p>



<p>Since the mutual information only scales with the <em>surface area</em> of the boundary and not with the area of the two regions <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> and <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> , this is known as an <em>area law</em> <a href="https://windowsontheory.org/feed/#gharibian">[1]</a>.</p>



<h3 id="relationship-to-bayesian-inference">Relationship to Bayesian inference</h3>



<p>In Bayesian inference, we have a model for a system which can be very complicated. The model represents our assumptions on how parts of the system are causally related to the rest of the system. We have some observations, and we want to sample from a distribution conditionally on the fixed observations. Sampling from a conditional distribution is not the same as sampling from the original distribution, but we can still formally represent the conditional distribution as a Markov network. Therefore, sampling from Markov networks is a broadly useful task.</p>



<p>As an example of a complicated Bayesian model, consider a <em>hierarchical Bayesian model</em> <a href="https://windowsontheory.org/feed/#keener">[2]</a>. Bayesian statistics requires choosing a prior distribution, and when there is a natural parameterized family of priors that a statistician can use, it may make sense to introduce a distribution over the priors; this is known as <em>introducing a hyperparameter</em>, and inference in the resulting hierarchical model (including computation of the posterior distribution) is frequently intractable. However, it is still desirable to work with these models because they are often more accurate than models in which the prior is handpicked by a statistician.</p>



<h1 id="sampling-from-gibbs-distributions">Sampling from Gibbs distributions</h1>



<p>The task of sampling from an arbitrary Gibbs distribution is MA-complete <a href="https://windowsontheory.org/feed/#crosson_making_2010">[3]</a>, and it is not hard to see that at low enough temperatures this problem is at least NP-hard. So, how do we sample from these distributions?</p>



<p>This section will discuss Monte Carlo Markov chain (MCMC) methods, namely the Metropolis-Hastings algorithm and Glauber dynamics. Readers familiar with these methods may wish to skip to the discussion of <a href="https://windowsontheory.org/feed/#scn_mixing_in_time">mixing in time</a>. For readers who wish to build more intuition about Markov chains before proceeding, see the <a href="https://windowsontheory.org/feed/#scn_appendix">Appendix</a>, where the simple example of the random walk on a cycle is treated in detail.</p>



<h2 id="monte-carlo-markov-chain-mcmc-methods">Monte Carlo Markov chain (MCMC) methods</h2>



<p>The general approach is to use a Markov chain. Let <img alt="\Omega=\Sigma^n" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega%3D%5CSigma%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega=\Sigma^n"/> be the possible states of the system. Effectively, a Markov chain is a way of doing a random walk over <img alt="\Omega" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega"/> .</p>



<figure class="wp-block-image"><img alt="" class="wp-image-6786" src="https://windowsontheory.files.wordpress.com/2018/12/p3.png?w=600"/></figure>



<p>The transition probabilities of the Markov chain are<sup><a href="https://windowsontheory.org/feed/#fn_1">1</a></sup> <img alt="{\mathbb P}\{X(t+1) = y \mid X(t) = x\} = T_{y,x}." class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb+P%7D%5C%7BX%28t%2B1%29+%3D+y+%5Cmid+X%28t%29+%3D+x%5C%7D+%3D+T_%7By%2Cx%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{\mathbb P}\{X(t+1) = y \mid X(t) = x\} = T_{y,x}."/> Here, <img alt="T" class="latex" src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T"/> is the <strong>transition probability matrix</strong>. The column at index <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/> of <img alt="T" class="latex" src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T"/> is the probability distribution of the next state of the Markov chain, if the current state is <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/> . The row at index <img alt="y" class="latex" src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y"/> is a row of probability values which give the probabilities of jumping into state <img alt="y" class="latex" src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y"/> from every other state. It has the properties that its entries are non-negative and for every <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/> , <img alt="\sum_{y \in \Omega} T_{y,x} = 1" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csum_%7By+%5Cin+%5COmega%7D+T_%7By%2Cx%7D+%3D+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sum_{y \in \Omega} T_{y,x} = 1"/> . These properties say that <img alt="T" class="latex" src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T"/> is a (column) <strong>stochastic matrix</strong>.</p>



<p>Suppose we start at a state <img alt="x(0)" class="latex" src="https://s0.wp.com/latex.php?latex=x%280%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x(0)"/> ; or, more generally, we will start with a distribution <img alt="p" class="latex" src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p"/> over <img alt="\Omega" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega"/> . If we move according to the chain once, the distribution will be <img alt="Tp" class="latex" src="https://s0.wp.com/latex.php?latex=Tp&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Tp"/> . If we move agian, the distribution will be <img alt="T^2 p" class="latex" src="https://s0.wp.com/latex.php?latex=T%5E2+p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T^2 p"/> . In general, after <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t"/> movements, the distribution is <img alt="T^t p" class="latex" src="https://s0.wp.com/latex.php?latex=T%5Et+p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T^t p"/> . So, we can express the dynamics of the chain as matrix-vector multiplication.</p>



<p>It is worth mentioning that if we are simulating the chain on a computer and we are manipulating <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> -bit numbers, then these probability vectors are of size <img alt="2^n" class="latex" src="https://s0.wp.com/latex.php?latex=2%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^n"/> so it becomes impractical to store the entire probability distributions.</p>



<p>The justification for our algorithms is the following theorem.</p>



<p><strong>Theorem 2</strong> (Perron-Frobenius Theorem): <em>If <img alt="T" class="latex" src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T"/> is a stochastic aperiodic matrix, then one of the eigenvalues is <img alt="1" class="latex" src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1"/> , and all other eigenvalues have magnitude strictly less than <img alt="1" class="latex" src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1"/> . There is a unique probability distribution <img alt="\pi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\pi"/> such that <img alt="T\pi = \pi" class="latex" src="https://s0.wp.com/latex.php?latex=T%5Cpi+%3D+%5Cpi&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T\pi = \pi"/> . </em></p>



<p>The theorem implies that <img alt="T^t p" class="latex" src="https://s0.wp.com/latex.php?latex=T%5Et+p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T^t p"/> will converge to the stationary distribution <img alt="\pi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\pi"/> as <img alt="t\to\infty" class="latex" src="https://s0.wp.com/latex.php?latex=t%5Cto%5Cinfty&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t\to\infty"/> . So, if we want to sample from a distribution, this provides a method of doing so: cook up a Markov chain that equilibrates to the desired distribution, and then run the Markov chain until convergence. <em>A priori</em>, it is not obvious how we can design the Markov chain. At first, our problem was to sample from a probability distribution (a vector), and now we have changed the problem to designing an entire matrix, which does not appear to make our task easier.</p>



<p>Now, the question becomes: how does one come up with Markov chains that give you the desired stationary distribution?</p>



<h2 id="metropolis-hastings-algorithm">Metropolis-Hastings algorithm</h2>



<p>The first algorithm we will introduce is the <strong>Metropolis-Hastings algorithm</strong>. One more desirable feature of a Markov chain is that it satisfies <strong>detailed balance</strong>, which says <img alt="\pi_x T_{y,x} = \pi_y T_{x,y}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi_x+T_%7By%2Cx%7D+%3D+%5Cpi_y+T_%7Bx%2Cy%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\pi_x T_{y,x} = \pi_y T_{x,y}"/> for all <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/> and <img alt="y" class="latex" src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y"/> . This condition says that if we pick a point with probability according to the stationary distribution and transition, the probability of picking <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/> and then moving to <img alt="y" class="latex" src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y"/> should be the same as picking <img alt="y" class="latex" src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y"/> and then moving to <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/> .</p>



<p>For a Markov chain in equilibrium, the total amount of probability flowing out of <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/> must equal the total amount of probability flowing into <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/> . For example, the United States might export products to Europe and import from China. Detailed balance says that the flow along each edge must balance, which is a more demanding condition. In the example with country trade deficits, we are requiring that all bilateral trade deficits must be zero.</p>



<p>Mathematically, detailed balance implies that <img alt="T" class="latex" src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T"/> can be transformed, via similarity transformations, into a symmetric matrix. The Metropolis-Hastings algorithm says that we should choose <img alt="T" class="latex" src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T"/> with the property <img alt="\frac{T_{x,y}}{T_{y,x}} = \frac{\pi_x}{\pi_y}." class="latex" src="https://s0.wp.com/latex.php?latex=%5Cfrac%7BT_%7Bx%2Cy%7D%7D%7BT_%7By%2Cx%7D%7D+%3D+%5Cfrac%7B%5Cpi_x%7D%7B%5Cpi_y%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\frac{T_{x,y}}{T_{y,x}} = \frac{\pi_x}{\pi_y}."/> Suppose that we have an underlying graph on our state space, and suppose that we are at a state <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/> . The algorithm chooses a random neighbor, say <img alt="y" class="latex" src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y"/> , and then accepts or rejects this move with some probability. If the move is accepted, then we move to <img alt="y" class="latex" src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y"/> and continue the algorithm from there. Otherwise, if the move is rejected, then we stay at <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/> . We are free to choose any underlying graph (as long as it is connected and has a self-loop), and then we will tune the acceptance probability so that detailed balance holds.</p>



<p>Look at the trial move <img alt="x\to y" class="latex" src="https://s0.wp.com/latex.php?latex=x%5Cto+y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x\to y"/> . One way we can accomplish detailed balance is by looking at the ratio <img alt="\pi_y/\pi_x" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi_y%2F%5Cpi_x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\pi_y/\pi_x"/> . If <img alt="\pi_y/\pi_x \ge 1" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi_y%2F%5Cpi_x+%5Cge+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\pi_y/\pi_x \ge 1"/> , then always accept the move. If <img alt="\pi_y/\pi_x &lt; 1 " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi_y%2F%5Cpi_x+%3C+1+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\pi_y/\pi_x &lt; 1 "/> , then accept the move with probability <img alt="\pi_x/\pi_y" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi_x%2F%5Cpi_y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\pi_x/\pi_y"/> .</p>



<p>To get an idea for how the algorithm works, suppose that our underlying graph is <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/> -regular. Then, for neighbors <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/> and <img alt="y" class="latex" src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y"/> ,</p>



<p> <img alt="\begin{aligned}T_{y,x} &amp;= \min\Bigl\{1, \frac{\pi_y}{\pi_x}\Bigr\} \frac{1}{d}, \\ T_{x,y} &amp;= \min\Bigl\{1, \frac{\pi_x}{\pi_y}\Bigr\} \frac{1}{d}\;\end{aligned} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7DT_%7By%2Cx%7D+%26%3D+%5Cmin%5CBigl%5C%7B1%2C+%5Cfrac%7B%5Cpi_y%7D%7B%5Cpi_x%7D%5CBigr%5C%7D+%5Cfrac%7B1%7D%7Bd%7D%2C+%5C%5C+T_%7Bx%2Cy%7D+%26%3D+%5Cmin%5CBigl%5C%7B1%2C+%5Cfrac%7B%5Cpi_x%7D%7B%5Cpi_y%7D%5CBigr%5C%7D+%5Cfrac%7B1%7D%7Bd%7D%5C%3B%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned}T_{y,x} &amp;= \min\Bigl\{1, \frac{\pi_y}{\pi_x}\Bigr\} \frac{1}{d}, \\ T_{x,y} &amp;= \min\Bigl\{1, \frac{\pi_x}{\pi_y}\Bigr\} \frac{1}{d}\;\end{aligned} "/> </p>



<p><strong>Claim</strong>: <img alt="T_{y,x} \pi_x = \frac{1}{d} \min\{\pi_x,\pi_y\}," class="latex" src="https://s0.wp.com/latex.php?latex=T_%7By%2Cx%7D+%5Cpi_x+%3D+%5Cfrac%7B1%7D%7Bd%7D+%5Cmin%5C%7B%5Cpi_x%2C%5Cpi_y%5C%7D%2C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T_{y,x} \pi_x = \frac{1}{d} \min\{\pi_x,\pi_y\},"/> which is manifestly symmetric in <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/> and <img alt="y" class="latex" src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y"/> ; thus, we have reversibility. This is the basic idea of the Metropolis-Hastings algorithm.</p>



<p>How does it work for a Gibbs distribution <img alt="\pi_x = \exp\{-E(x)/T\}/Z" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi_x+%3D+%5Cexp%5C%7B-E%28x%29%2FT%5C%7D%2FZ&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\pi_x = \exp\{-E(x)/T\}/Z"/> , where the energy function might, for example, count the number of violated clauses in a 3-SAT formula? In this case, we might be a little worried. The numerator of <img alt="\pi_x" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi_x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\pi_x"/> is pretty easy to compute (we can count how many violated constraints there are), but the denominator is hard to compute. In general, it is #P-hard to compute the denominator, because as <img alt="T" class="latex" src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T"/> drops to <img alt="0" class="latex" src="https://s0.wp.com/latex.php?latex=0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="0"/> , the partition function in this case approaches the number of 3-SAT solutions. So, how do we calculate the ratios <img alt="\pi_y/\pi_x" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi_y%2F%5Cpi_x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\pi_y/\pi_x"/> that the algorithm requires? We’re able to do this because the ratio does not depend on <img alt="Z" class="latex" src="https://s0.wp.com/latex.php?latex=Z&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Z"/> :</p>



<p> <img alt="\frac{\pi_y}{\pi_x} = \exp \frac{E(x)-E(y)}{T}." class="latex" src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B%5Cpi_y%7D%7B%5Cpi_x%7D+%3D+%5Cexp+%5Cfrac%7BE%28x%29-E%28y%29%7D%7BT%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\frac{\pi_y}{\pi_x} = \exp \frac{E(x)-E(y)}{T}."/> </p>



<p>Suppose that the energy is a sum of local terms, and the underlying graph corresponds to modifying one site at at a time. What this means is that the graph is <img alt="\Omega = {\{0,1\}}^n" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega+%3D+%7B%5C%7B0%2C1%5C%7D%7D%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega = {\{0,1\}}^n"/> and the edges in the graph correspond to flipping exactly one bit. In this case, it becomes very easy to evaluate the computations needed for the algorithm; in fact, we can even do them in parallel.</p>



<p>How do we choose the underlying graph? The key idea is that we do not want the majority of our moves to be rejected. A good example to keep in mind is the <strong>Ising model</strong>, where the configurations are <img alt="x \in {\{0,1\}}^n" class="latex" src="https://s0.wp.com/latex.php?latex=x+%5Cin+%7B%5C%7B0%2C1%5C%7D%7D%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x \in {\{0,1\}}^n"/> and the energy is <img alt="E(x) = -\sum_{i,j=1}^n J_{i,j} x_i x_j" class="latex" src="https://s0.wp.com/latex.php?latex=E%28x%29+%3D+-%5Csum_%7Bi%2Cj%3D1%7D%5En+J_%7Bi%2Cj%7D+x_i+x_j&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="E(x) = -\sum_{i,j=1}^n J_{i,j} x_i x_j"/> . If <img alt="J_{i,j} \ge 0" class="latex" src="https://s0.wp.com/latex.php?latex=J_%7Bi%2Cj%7D+%5Cge+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="J_{i,j} \ge 0"/> for all <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/> , <img alt="j" class="latex" src="https://s0.wp.com/latex.php?latex=j&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="j"/> , then we say that the model is <strong>ferromagnetic</strong> (we obtain lower energy by making the sites agree with each other). Of course, an <strong>antiferromagnetic</strong> model is just the opposite of this.</p>



<p>Assume that the bits are laid out in a square and <img alt="J_{i,j} = J" class="latex" src="https://s0.wp.com/latex.php?latex=J_%7Bi%2Cj%7D+%3D+J&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="J_{i,j} = J"/> if <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/> and <img alt="j" class="latex" src="https://s0.wp.com/latex.php?latex=j&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="j"/> are neighbors on the square, and <img alt="J_{i,j} = 0" class="latex" src="https://s0.wp.com/latex.php?latex=J_%7Bi%2Cj%7D+%3D+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="J_{i,j} = 0"/> if they are not. As we vary the quantity <img alt="J/T" class="latex" src="https://s0.wp.com/latex.php?latex=J%2FT&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="J/T"/> , we observe a <em>phase transition</em>. If <img alt="J/T" class="latex" src="https://s0.wp.com/latex.php?latex=J%2FT&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="J/T"/> is small, then the coupling between the random variables is weak and the different parts of the system are almost independent; we call this the <strong>disordered phase</strong>. If <img alt="J/T" class="latex" src="https://s0.wp.com/latex.php?latex=J%2FT&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="J/T"/> is large, then the spins want to align in the same direction and the Gibbs distribution will look almost like the following: with probability <img alt="1/2" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/2"/> , all spins are <img alt="+" class="latex" src="https://s0.wp.com/latex.php?latex=%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="+"/> , and with probability <img alt="1/2" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/2"/> , all spins are <img alt="-" class="latex" src="https://s0.wp.com/latex.php?latex=-&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="-"/> ; we call this the <strong>ordered phase</strong>.</p>



<p>In the disordered phase, when the spins do not need to align so closely, the Metropolis-Hastings algorithm will work well. In the ordered phase, the algorithm is doomed. Indeed, suppose that most of the spins are <img alt="+" class="latex" src="https://s0.wp.com/latex.php?latex=%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="+"/> . As time proceeds, any <img alt="-" class="latex" src="https://s0.wp.com/latex.php?latex=-&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="-"/> s will switch to <img alt="+" class="latex" src="https://s0.wp.com/latex.php?latex=%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="+"/> . There may be islands of <img alt="-" class="latex" src="https://s0.wp.com/latex.php?latex=-&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="-"/> spins initially, but it will be energetically favorable for these islands to shrink over time. Therefore, there will be an exponentially small chance for the system to switch to a configuration with mostly <img alt="-" class="latex" src="https://s0.wp.com/latex.php?latex=-&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="-"/> ’s, and thus the chain takes exponentially long to mix. Here, people are interested in understanding the <em>autocorrelation time</em>, because the goal is to run the chain for some time, get one sample, run the chain for some more time, get another sample, etc.</p>



<h2 id="glauber-dynamics">Glauber dynamics</h2>



<p>This next method (<strong>Glauber dynamics</strong>) is essentially the same as Metropolis-Hastings, but this is not immediately obvious. We are at a state <img alt="x = (x_1,\dotsc,x_n) \in \Sigma^n" class="latex" src="https://s0.wp.com/latex.php?latex=x+%3D+%28x_1%2C%5Cdotsc%2Cx_n%29+%5Cin+%5CSigma%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x = (x_1,\dotsc,x_n) \in \Sigma^n"/> . (For the Metropolis-Hastings algorithm, we could be walking on a state space without a product structure. However, Glauber dynamics requires a product structure.) Then, we update <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/> to <img alt="(x_1,\dotsc,x_{i-1},x_i',x_{i+1},\dotsc,x_n)" class="latex" src="https://s0.wp.com/latex.php?latex=%28x_1%2C%5Cdotsc%2Cx_%7Bi-1%7D%2Cx_i%27%2Cx_%7Bi%2B1%7D%2C%5Cdotsc%2Cx_n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(x_1,\dotsc,x_{i-1},x_i',x_{i+1},\dotsc,x_n)"/> with chance <img alt="\pi_{i\mid -i}(x_i' \mid x_1,\dotsc,x_{i-1},x_{i+1},\dotsc,x_n)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi_%7Bi%5Cmid+-i%7D%28x_i%27+%5Cmid+x_1%2C%5Cdotsc%2Cx_%7Bi-1%7D%2Cx_%7Bi%2B1%7D%2C%5Cdotsc%2Cx_n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\pi_{i\mid -i}(x_i' \mid x_1,\dotsc,x_{i-1},x_{i+1},\dotsc,x_n)"/> . In other words, we hold all other bits fixed, and conditioned on those other bits, we resample the <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/> th bit. Like Metropolis-Hastings, <img alt="\pi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\pi"/> is stationary for this chain.</p>



<p>It is not obvious that these conditional distributions can be computed efficiently, but it is possible since normalizing the conditional distribution only requires summing over the possible configurations for a single random variable. On a Markov network, the conditional probability is <img alt="\pi_{i \mid N(i)}(x_i' \mid x_{N(i)})" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi_%7Bi+%5Cmid+N%28i%29%7D%28x_i%27+%5Cmid+x_%7BN%28i%29%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\pi_{i \mid N(i)}(x_i' \mid x_{N(i)})"/> , where <img alt="N(i)" class="latex" src="https://s0.wp.com/latex.php?latex=N%28i%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N(i)"/> denotes the set of neighbors of <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/> . This makes the computation a constant-sized calculation (i.e., does not depend on the size of the system).</p>



<p>For example, in the Ising model, suppose we are at state <img alt="x \in {\{\pm 1\}}^n" class="latex" src="https://s0.wp.com/latex.php?latex=x+%5Cin+%7B%5C%7B%5Cpm+1%5C%7D%7D%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x \in {\{\pm 1\}}^n"/> . In Glauber dynamics, we pick a vertex <img alt="i \in [n]" class="latex" src="https://s0.wp.com/latex.php?latex=i+%5Cin+%5Bn%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i \in [n]"/> u.a.r. and update it to <img alt="+" class="latex" src="https://s0.wp.com/latex.php?latex=%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="+"/> with probability <img alt="p_{i \mid N(i)}(+ \mid x_{N(i)}) = \frac{\exp(T^{-1}\sum_{j\in N(i)} x_j)}{\exp(-T^{-1} \sum_{j\in N(i)} x_j) + \exp(T^{-1} \sum_{j\in N(i)} x_j)}." class="latex" src="https://s0.wp.com/latex.php?latex=p_%7Bi+%5Cmid+N%28i%29%7D%28%2B+%5Cmid+x_%7BN%28i%29%7D%29+%3D+%5Cfrac%7B%5Cexp%28T%5E%7B-1%7D%5Csum_%7Bj%5Cin+N%28i%29%7D+x_j%29%7D%7B%5Cexp%28-T%5E%7B-1%7D+%5Csum_%7Bj%5Cin+N%28i%29%7D+x_j%29+%2B+%5Cexp%28T%5E%7B-1%7D+%5Csum_%7Bj%5Cin+N%28i%29%7D+x_j%29%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p_{i \mid N(i)}(+ \mid x_{N(i)}) = \frac{\exp(T^{-1}\sum_{j\in N(i)} x_j)}{\exp(-T^{-1} \sum_{j\in N(i)} x_j) + \exp(T^{-1} \sum_{j\in N(i)} x_j)}."/></p>



<h1 id="scn:mixing_in_time">Mixing in time</h1>



<p>Mixing in time means that the dynamics will equilibrate rapidly. It turns out that this is equivalent to mixing in space, which means that <img alt="\pi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\pi"/> itself has decaying correlations. For example, the Ising model at low temperature has a lot of long-range correlations, but at high temperature it does not. For the high temperature regime, we can prove that mixing in time occurs. We will prove this for the ferromagnetic Ising model. The result is known more generally, but the proofs are much easier for the Ising model.</p>



<p>People have known about the Metropolis-Hastings algorithm since the 1950s, but only recently have researchers been able to prove convergence guarantees for the 2D Ising model. There is a large gap between theory and practice, but in some situations we can prove that the algorithm works.</p>



<p>Sampling from the distribution is roughly equivalent to estimating the partition function (sampling-counting equivalence). There have been many papers addressing tasks such as estimating the non-negative permanent, the number of colorings of a graph, etc.<sup><a href="https://windowsontheory.org/feed/#fn_2">2</a></sup> A dominant way of accomplishing these tasks is proving that the Metropolis-Hastings algorithm converges for these problems. It is easy to find algorithms for these problems that converge to Gibbs distributions, but the convergence may take exponential time.</p>



<p>We will look at the situation when the energy function looks like the Ising model, in the sense that the interactions are local and reflect the structure of some underlying space. Also, assume that the interactions are of size <img alt="O(1)" class="latex" src="https://s0.wp.com/latex.php?latex=O%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(1)"/> and that the scaling comes from the size of the system. When can we expect that our algorithms work? There are two main cases when we can argue that there should be rapid mixing.</p>



<ul><li>High temperature regime: The system is very disordered, and in the limit as the temperature approaches infinity, we get the uniform distribution.</li><li>One-dimension: In 1D, we can exactly compute the partition function using dynamic programming. Before, we mentioned that if there are a sea of <img alt="+" class="latex" src="https://s0.wp.com/latex.php?latex=%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="+"/> s and an island of <img alt="-" class="latex" src="https://s0.wp.com/latex.php?latex=-&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="-"/> s, then it is energetically favorable for the island to shrink; note that this is no longer true in 1D. In a way, 1D systems are more “boring” because they cannot exhibit arbitrarily long-range correlations.</li></ul>



<p>In this part of the blog post, we will try to be more proof-oriented. We will start by explaining why it is plausible that high temperature means that the chain will mix rapidly in time.</p>



<h2 id="coupling-method">Coupling method</h2>



<p>One method of proving rates of convergence for Markov chains is by analzying the spectral gap. Another method is the <strong>coupling method</strong>.</p>



<p>The idea behind the coupling method is to start with two configurations <img alt="X(0),Y(0) \in \Omega" class="latex" src="https://s0.wp.com/latex.php?latex=X%280%29%2CY%280%29+%5Cin+%5COmega&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X(0),Y(0) \in \Omega"/> . We want each one to evolve under the Markov chain.</p>



<figure class="wp-block-image"><img alt="" class="wp-image-6787" src="https://windowsontheory.files.wordpress.com/2018/12/p4.png?w=600"/></figure>



<p>The key part is that there is still some freedom with respect to what the dynamics looks like. In particular, we are allowed to correlate the <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X"/> and <img alt="Y" class="latex" src="https://s0.wp.com/latex.php?latex=Y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y"/> processes. Thus, we are defining a joint transition probability <img alt="{\mathbb P}\{X(1)=x(1),Y(1)=y(1) \mid X(0),Y(0)\}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb+P%7D%5C%7BX%281%29%3Dx%281%29%2CY%281%29%3Dy%281%29+%5Cmid+X%280%29%2CY%280%29%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{\mathbb P}\{X(1)=x(1),Y(1)=y(1) \mid X(0),Y(0)\}"/> . We want to design the process such that <img alt="X(1)" class="latex" src="https://s0.wp.com/latex.php?latex=X%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X(1)"/> and <img alt="Y(1)" class="latex" src="https://s0.wp.com/latex.php?latex=Y%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y(1)"/> are closer together than <img alt="X(0)" class="latex" src="https://s0.wp.com/latex.php?latex=X%280%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X(0)"/> and <img alt="Y(0)" class="latex" src="https://s0.wp.com/latex.php?latex=Y%280%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y(0)"/> . Imagine that we have two particles bouncing around. Each particle follows the dynamics of <img alt="T" class="latex" src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T"/> , but they are correlated so that they drift together, and once they meet, they stick together. It turns out that the mixing time can be upper bounded by the time it takes for the particles to meet each other.</p>



<p>Assume we have some sort of distance function <img alt="\;\mathrm{dist}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%3B%5Cmathrm%7Bdist%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\;\mathrm{dist}"/> on the underlying space and we can prove that <img alt="\;\mathrm{\mathbb E}\;\mathrm{dist}(X(1),Y(1)) \le \exp(-\alpha) \;\mathrm{dist}(X(0),Y(0))" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%3B%5Cmathrm%7B%5Cmathbb+E%7D%5C%3B%5Cmathrm%7Bdist%7D%28X%281%29%2CY%281%29%29+%5Cle+%5Cexp%28-%5Calpha%29+%5C%3B%5Cmathrm%7Bdist%7D%28X%280%29%2CY%280%29%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\;\mathrm{\mathbb E}\;\mathrm{dist}(X(1),Y(1)) \le \exp(-\alpha) \;\mathrm{dist}(X(0),Y(0))"/> . Then, it turns out that the mixing time <img alt="t_{\rm mix}(\epsilon)" class="latex" src="https://s0.wp.com/latex.php?latex=t_%7B%5Crm+mix%7D%28%5Cepsilon%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t_{\rm mix}(\epsilon)"/> , i.e. the time required to get within <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon"/> of the stationary distribution, is upper bounded as</p>



<p> <img alt="t_{\rm mix}(\epsilon) \le \frac{\log\{(\;\mathrm{diam}\Omega)/\epsilon\}}{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=t_%7B%5Crm+mix%7D%28%5Cepsilon%29+%5Cle+%5Cfrac%7B%5Clog%5C%7B%28%5C%3B%5Cmathrm%7Bdiam%7D%5COmega%29%2F%5Cepsilon%5C%7D%7D%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t_{\rm mix}(\epsilon) \le \frac{\log\{(\;\mathrm{diam}\Omega)/\epsilon\}}{\alpha}"/> </p>



<p>Initially, the two particles can be <img alt="\;\mathrm{diam}\Omega" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%3B%5Cmathrm%7Bdiam%7D%5COmega&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\;\mathrm{diam}\Omega"/> apart, but the expected distance is exponentially shrinking as we run the coupling, so the mixing time is logarithmic in the diameter.</p>



<p>The distance between probability distributions is defined as follows. Let <img alt="p" class="latex" src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p"/> and <img alt="q" class="latex" src="https://s0.wp.com/latex.php?latex=q&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="q"/> be two probability distributions on <img alt="\Omega" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega"/> . Then, the metric is:<sup><a href="https://windowsontheory.org/feed/#fn_3">3</a></sup></p>



<p> <img alt="\frac{1}{2} \|p-q\|_1 = \frac{1}{2}\sum_{x \in \Omega}|p(x)-q(x)| = \min_{\substack{(X,Y) \sim r \in {\mathcal{P}}(\Omega \times \Omega) \\ r_1 = p \\ r_2 = q}} {\mathbb P}_r\{X \ne Y\}." class="latex" src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B2%7D+%5C%7Cp-q%5C%7C_1+%3D+%5Cfrac%7B1%7D%7B2%7D%5Csum_%7Bx+%5Cin+%5COmega%7D%7Cp%28x%29-q%28x%29%7C+%3D+%5Cmin_%7B%5Csubstack%7B%28X%2CY%29+%5Csim+r+%5Cin+%7B%5Cmathcal%7BP%7D%7D%28%5COmega+%5Ctimes+%5COmega%29+%5C%5C+r_1+%3D+p+%5C%5C+r_2+%3D+q%7D%7D+%7B%5Cmathbb+P%7D_r%5C%7BX+%5Cne+Y%5C%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\frac{1}{2} \|p-q\|_1 = \frac{1}{2}\sum_{x \in \Omega}|p(x)-q(x)| = \min_{\substack{(X,Y) \sim r \in {\mathcal{P}}(\Omega \times \Omega) \\ r_1 = p \\ r_2 = q}} {\mathbb P}_r\{X \ne Y\}."/> </p>



<p>In this expression, <img alt="r_1" class="latex" src="https://s0.wp.com/latex.php?latex=r_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="r_1"/> and <img alt="r_2" class="latex" src="https://s0.wp.com/latex.php?latex=r_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="r_2"/> denote the first and second marginals of <img alt="r" class="latex" src="https://s0.wp.com/latex.php?latex=r&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="r"/> respectively. The minimum is taken over all <em>couplings</em> of <img alt="p" class="latex" src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p"/> and <img alt="q" class="latex" src="https://s0.wp.com/latex.php?latex=q&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="q"/> . This is the correct way to measure the distance between distributions. To give some intuition for this quantity, the quantity on the right represents the best <em>test</em> to distinguish the two distributions. If <img alt="p" class="latex" src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p"/> and <img alt="q" class="latex" src="https://s0.wp.com/latex.php?latex=q&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="q"/> are the same, we can take a coupling in which <img alt="X \sim p" class="latex" src="https://s0.wp.com/latex.php?latex=X+%5Csim+p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X \sim p"/> and <img alt="Y \sim q" class="latex" src="https://s0.wp.com/latex.php?latex=Y+%5Csim+q&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y \sim q"/> are always identical. If <img alt="p" class="latex" src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p"/> and <img alt="q" class="latex" src="https://s0.wp.com/latex.php?latex=q&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="q"/> have disjoint supports, then no matter what coupling we use, <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X"/> and <img alt="Y" class="latex" src="https://s0.wp.com/latex.php?latex=Y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y"/> will never be equal.</p>



<p>It suffices to consider when <img alt="X(0)" class="latex" src="https://s0.wp.com/latex.php?latex=X%280%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X(0)"/> and <img alt="Y(0)" class="latex" src="https://s0.wp.com/latex.php?latex=Y%280%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y(0)"/> are neighbors, i.e. at distance <img alt="1" class="latex" src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1"/> apart. This is because if we have <img alt="X(0)" class="latex" src="https://s0.wp.com/latex.php?latex=X%280%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X(0)"/> and <img alt="Y(0)" class="latex" src="https://s0.wp.com/latex.php?latex=Y%280%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y(0)"/> far apart, then we could look at the path between them and reduce to the case when they are neighbors. Formally, this is known as <em>path coupling</em>. The formal statement is in Theorem 12.3 of <a href="https://windowsontheory.org/feed/#nature">[4]</a>:</p>



<p><strong>Theorem 3</strong>: <em>Let <img alt="\Gamma" class="latex" src="https://s0.wp.com/latex.php?latex=%5CGamma&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Gamma"/> be a connected weighted graph on the state space, where no edge has weight less than <img alt="d_{\min}" class="latex" src="https://s0.wp.com/latex.php?latex=d_%7B%5Cmin%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d_{\min}"/> . Let <img alt="d(C,C')" class="latex" src="https://s0.wp.com/latex.php?latex=d%28C%2CC%27%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d(C,C')"/> be the length of the shortest path from <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/> to <img alt="C'" class="latex" src="https://s0.wp.com/latex.php?latex=C%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C'"/> in <img alt="\Gamma" class="latex" src="https://s0.wp.com/latex.php?latex=%5CGamma&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Gamma"/> and let <img alt="d_{\max} = \max_{C,C' \in \Omega} d(C,C')" class="latex" src="https://s0.wp.com/latex.php?latex=d_%7B%5Cmax%7D+%3D+%5Cmax_%7BC%2CC%27+%5Cin+%5COmega%7D+d%28C%2CC%27%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d_{\max} = \max_{C,C' \in \Omega} d(C,C')"/> be the diameter of <img alt="\Gamma" class="latex" src="https://s0.wp.com/latex.php?latex=%5CGamma&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Gamma"/> . Suppose there is a coupling such that for some <img alt="\delta &gt; 0" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdelta+%3E+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\delta &gt; 0"/> </em>,</p>



<p> <img alt="\;\mathrm{\mathbb E}\bigl[d\bigl(X(1),Y(1)\bigr) \bigm\vert \bigl(X(0),Y(0)\bigr) = (C,C')\bigr] \le (1-\delta)d(C,C')" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%3B%5Cmathrm%7B%5Cmathbb+E%7D%5Cbigl%5Bd%5Cbigl%28X%281%29%2CY%281%29%5Cbigr%29+%5Cbigm%5Cvert+%5Cbigl%28X%280%29%2CY%280%29%5Cbigr%29+%3D+%28C%2CC%27%29%5Cbigr%5D+%5Cle+%281-%5Cdelta%29d%28C%2CC%27%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\;\mathrm{\mathbb E}\bigl[d\bigl(X(1),Y(1)\bigr) \bigm\vert \bigl(X(0),Y(0)\bigr) = (C,C')\bigr] \le (1-\delta)d(C,C')"/> </p>



<p><em>for all neighboring pairs <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/> , <img alt="C'" class="latex" src="https://s0.wp.com/latex.php?latex=C%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C'"/> , i.e., those pairs connected by an edge in <img alt="\Gamma" class="latex" src="https://s0.wp.com/latex.php?latex=%5CGamma&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Gamma"/> . Then, the mixing time is bounded by </em></p>



<p> <img alt="t_{\rm mix}(\epsilon) \le \frac{\log(\epsilon^{-1}d_{\max}/d_{\min})}{\delta}." class="latex" src="https://s0.wp.com/latex.php?latex=t_%7B%5Crm+mix%7D%28%5Cepsilon%29+%5Cle+%5Cfrac%7B%5Clog%28%5Cepsilon%5E%7B-1%7Dd_%7B%5Cmax%7D%2Fd_%7B%5Cmin%7D%29%7D%7B%5Cdelta%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t_{\rm mix}(\epsilon) \le \frac{\log(\epsilon^{-1}d_{\max}/d_{\min})}{\delta}."/> </p>



<h2 id="glauber-dynamics-at-high-temperature">Glauber dynamics at high temperature</h2>



<p>Recall that in Glauber dynamics, we pick a site <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/> randomly and then update the site conditioned on its neighbors. The first way we will couple together <img alt="X(1)" class="latex" src="https://s0.wp.com/latex.php?latex=X%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X(1)"/> and <img alt="Y(1)" class="latex" src="https://s0.wp.com/latex.php?latex=Y%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y(1)"/> is by picking the <em>same</em> site for both of them.</p>



<ol><li>Pick a random <img alt="i \in [n]" class="latex" src="https://s0.wp.com/latex.php?latex=i+%5Cin+%5Bn%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i \in [n]"/> .</li><li>If <img alt="{X(0)}_{N(i)} = {Y(0)}_{N(i)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%280%29%7D_%7BN%28i%29%7D+%3D+%7BY%280%29%7D_%7BN%28i%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{X(0)}_{N(i)} = {Y(0)}_{N(i)}"/> , then set <img alt="{X(1)}_i = {Y(1)}_i" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%281%29%7D_i+%3D+%7BY%281%29%7D_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{X(1)}_i = {Y(1)}_i"/> (if the neighborhoods of the two points agree, then update them the same way). Otherwise, update them using the best possible coupling, i.e., pick a coupling for <img alt="({X(1)}_i, {Y(1)}_i)" class="latex" src="https://s0.wp.com/latex.php?latex=%28%7BX%281%29%7D_i%2C+%7BY%281%29%7D_i%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="({X(1)}_i, {Y(1)}_i)"/> which minimizes <img alt="{\mathbb P}\{ {X(1)}_i \ne {Y(1)}_i \}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb+P%7D%5C%7B+%7BX%281%29%7D_i+%5Cne+%7BY%281%29%7D_i+%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{\mathbb P}\{ {X(1)}_i \ne {Y(1)}_i \}"/> .</li></ol>



<p>So if <img alt="X(0) = Y(0)" class="latex" src="https://s0.wp.com/latex.php?latex=X%280%29+%3D+Y%280%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X(0) = Y(0)"/> , then the points will never drift apart. The reason why analyzing this coupling is non-trivial is because there is a chance that the distance between the two points can <em>increase</em>.</p>



<p>Assume that the degree of the graph is <img alt="\Delta" class="latex" src="https://s0.wp.com/latex.php?latex=%5CDelta&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Delta"/> . Suppose that <img alt="\;\mathrm{dist}(X(0),Y(0)) = 1" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%3B%5Cmathrm%7Bdist%7D%28X%280%29%2CY%280%29%29+%3D+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\;\mathrm{dist}(X(0),Y(0)) = 1"/> , that is, there is a single <img alt="a" class="latex" src="https://s0.wp.com/latex.php?latex=a&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a"/> such that <img alt="{X(0)}_a \ne {Y(0)}_a" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%280%29%7D_a+%5Cne+%7BY%280%29%7D_a&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{X(0)}_a \ne {Y(0)}_a"/> . What will happen to <img alt="X(1)" class="latex" src="https://s0.wp.com/latex.php?latex=X%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X(1)"/> and <img alt="Y(1)" class="latex" src="https://s0.wp.com/latex.php?latex=Y%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y(1)"/> ? We start by picking a random <img alt="i \in [n]" class="latex" src="https://s0.wp.com/latex.php?latex=i+%5Cin+%5Bn%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i \in [n]"/> . There are three cases:</p>



<ol><li><img alt="i \notin (\{a\} \cup N(a))" class="latex" src="https://s0.wp.com/latex.php?latex=i+%5Cnotin+%28%5C%7Ba%5C%7D+%5Ccup+N%28a%29%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i \notin (\{a\} \cup N(a))"/> (with probability <img alt="1 - (\Delta + 1)/n" class="latex" src="https://s0.wp.com/latex.php?latex=1+-+%28%5CDelta+%2B+1%29%2Fn&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1 - (\Delta + 1)/n"/> ): Nothing changes; <img alt="X(0)" class="latex" src="https://s0.wp.com/latex.php?latex=X%280%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X(0)"/> and <img alt="Y(0)" class="latex" src="https://s0.wp.com/latex.php?latex=Y%280%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y(0)"/> agree at <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/> , and <img alt="X(1)" class="latex" src="https://s0.wp.com/latex.php?latex=X%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X(1)"/> and <img alt="Y(1)" class="latex" src="https://s0.wp.com/latex.php?latex=Y%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y(1)"/> will also agree at <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/> . The distance remains at <img alt="1" class="latex" src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1"/> .</li><li><img alt="i = a" class="latex" src="https://s0.wp.com/latex.php?latex=i+%3D+a&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i = a"/> (with probability <img alt="1/n" class="latex" src="https://s0.wp.com/latex.php?latex=1%2Fn&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/n"/> ): We picked the one spot in which the two configurations differ. The neighborhoods of <img alt="a" class="latex" src="https://s0.wp.com/latex.php?latex=a&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a"/> are the same for <img alt="X(0)" class="latex" src="https://s0.wp.com/latex.php?latex=X%280%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X(0)"/> and <img alt="Y(0)" class="latex" src="https://s0.wp.com/latex.php?latex=Y%280%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y(0)"/> , so we update in the same way for both processes, and the distance drops to <img alt="0" class="latex" src="https://s0.wp.com/latex.php?latex=0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="0"/> .</li><li><img alt="i \in N(a)" class="latex" src="https://s0.wp.com/latex.php?latex=i+%5Cin+N%28a%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i \in N(a)"/> (with probability <img alt="\Delta/n" class="latex" src="https://s0.wp.com/latex.php?latex=%5CDelta%2Fn&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Delta/n"/> ): We could have different updates. Here, we have to use the high temperature assumption, which says that if we change one bit, the probability of a configuration cannot change too much.In the Ising model, <img alt="E(x) = \sum_{i,j=1}^n J_{i,j} x_i x_j" class="latex" src="https://s0.wp.com/latex.php?latex=E%28x%29+%3D+%5Csum_%7Bi%2Cj%3D1%7D%5En+J_%7Bi%2Cj%7D+x_i+x_j&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="E(x) = \sum_{i,j=1}^n J_{i,j} x_i x_j"/> . Changing <img alt="a" class="latex" src="https://s0.wp.com/latex.php?latex=a&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a"/> can bias the energy by at most <img alt="\Delta\max_i J_{i,a}" class="latex" src="https://s0.wp.com/latex.php?latex=%5CDelta%5Cmax_i+J_%7Bi%2Ca%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Delta\max_i J_{i,a}"/> , so the expected distance afterwards is <img alt="1 + O(\max_{i,j=1}^n J_{i,j}/T)" class="latex" src="https://s0.wp.com/latex.php?latex=1+%2B+O%28%5Cmax_%7Bi%2Cj%3D1%7D%5En+J_%7Bi%2Cj%7D%2FT%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1 + O(\max_{i,j=1}^n J_{i,j}/T)"/> .</li></ol>



<p>Adding these cases up to get the overall expected distance gives</p>



<p> <img alt="\;\mathrm{\mathbb E}\;\mathrm{dist}\bigl(X(1), Y(1)\bigr) = 1-\frac{1}{n} + \underbrace{O\Bigl(\frac{\Delta J_{\max}}{T}\Bigr)}_{\le 1}\frac{1}{n} = 1 - \frac{c}{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%3B%5Cmathrm%7B%5Cmathbb+E%7D%5C%3B%5Cmathrm%7Bdist%7D%5Cbigl%28X%281%29%2C+Y%281%29%5Cbigr%29+%3D+1-%5Cfrac%7B1%7D%7Bn%7D+%2B+%5Cunderbrace%7BO%5CBigl%28%5Cfrac%7B%5CDelta+J_%7B%5Cmax%7D%7D%7BT%7D%5CBigr%29%7D_%7B%5Cle+1%7D%5Cfrac%7B1%7D%7Bn%7D+%3D+1+-+%5Cfrac%7Bc%7D%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\;\mathrm{\mathbb E}\;\mathrm{dist}\bigl(X(1), Y(1)\bigr) = 1-\frac{1}{n} + \underbrace{O\Bigl(\frac{\Delta J_{\max}}{T}\Bigr)}_{\le 1}\frac{1}{n} = 1 - \frac{c}{n}"/> </p>



<p>for <img alt="T" class="latex" src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T"/> large enough, so the expected distance will shrink. This argument also tells us how large the temperature must be, which is important for applications. This gives us <img alt="t_{\rm mix}(\epsilon) = O\Bigl(n\log\frac{n}{\epsilon}\Bigr)." class="latex" src="https://s0.wp.com/latex.php?latex=t_%7B%5Crm+mix%7D%28%5Cepsilon%29+%3D+O%5CBigl%28n%5Clog%5Cfrac%7Bn%7D%7B%5Cepsilon%7D%5CBigr%29.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t_{\rm mix}(\epsilon) = O\Bigl(n\log\frac{n}{\epsilon}\Bigr)."/> Notice that this is the same dependence as the coupon collector problem. Therefore, in the high temperature regime, the system behaves qualitatively as if there are no correlations.</p>



<h2 id="temporal-and-spatial-mixing-equivalence">Temporal and spatial mixing equivalence</h2>



<p>The analysis of Glauber dynamics at high temperature is already a version of the equivalence between mixing in time and mixing in space. It says that if the correlations even with the immediate neighbors of a node are weak, then Glauber dynamics rapidly mixes.</p>



<p>Now, we want to consider the situation in which there can be strong correlations between immediate neighbors, but weak correlation with far away sites. We want to show that spatial mixing implies temporal mixing.</p>



<p>We will give a few definitions of correlation decay. (Note: The definitions of correlation decay below are not exactly the ones from Aram’s lecture. These definitions are from <a href="https://windowsontheory.org/feed/#martinelli1">[5]</a> and <a href="https://windowsontheory.org/feed/#martinelli2">[6]</a>.)</p>



<p>For non-empty <img alt="W \subseteq V" class="latex" src="https://s0.wp.com/latex.php?latex=W+%5Csubseteq+V&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="W \subseteq V"/> and <img alt="\tau \in \Sigma^{V\setminus W}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctau+%5Cin+%5CSigma%5E%7BV%5Csetminus+W%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\tau \in \Sigma^{V\setminus W}"/> , let <img alt="\mu_W^\tau" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmu_W%5E%5Ctau&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mu_W^\tau"/> be the distribution of the spins in <img alt="W" class="latex" src="https://s0.wp.com/latex.php?latex=W&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="W"/> conditional on the spins in <img alt="V \setminus W" class="latex" src="https://s0.wp.com/latex.php?latex=V+%5Csetminus+W&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="V \setminus W"/> being fixed to <img alt="\tau" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctau&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\tau"/> . For <img alt="\Delta \subseteq W" class="latex" src="https://s0.wp.com/latex.php?latex=%5CDelta+%5Csubseteq+W&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Delta \subseteq W"/> , let <img alt="\mu_{W,\Delta}^\tau" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmu_%7BW%2C%5CDelta%7D%5E%5Ctau&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mu_{W,\Delta}^\tau"/> be the marginal of <img alt="\mu_W^\tau" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmu_W%5E%5Ctau&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mu_W^\tau"/> on the spins in <img alt="\Delta" class="latex" src="https://s0.wp.com/latex.php?latex=%5CDelta&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Delta"/> . We will assume that the interactions between the spins have finite range <img alt="r &gt; 0" class="latex" src="https://s0.wp.com/latex.php?latex=r+%3E+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="r &gt; 0"/> , and <img alt="\partial_r W" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpartial_r+W&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\partial_r W"/> denotes the <img alt="r" class="latex" src="https://s0.wp.com/latex.php?latex=r&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="r"/> -boundary of <img alt="W" class="latex" src="https://s0.wp.com/latex.php?latex=W&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="W"/> , i.e., <img alt="\{v \in V \setminus W : \;\mathrm{dist}(v,W) \le r\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7Bv+%5Cin+V+%5Csetminus+W+%3A+%5C%3B%5Cmathrm%7Bdist%7D%28v%2CW%29+%5Cle+r%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{v \in V \setminus W : \;\mathrm{dist}(v,W) \le r\}"/> .</p>



<ul><li>(<strong>Weak decay of correlations</strong>) Weak spatial mixing holds for <img alt="W" class="latex" src="https://s0.wp.com/latex.php?latex=W&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="W"/> if there exist constants <img alt="C, \xi &gt; 0" class="latex" src="https://s0.wp.com/latex.php?latex=C%2C+%5Cxi+%3E+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C, \xi &gt; 0"/> such that for any subset <img alt="\Delta \subseteq W" class="latex" src="https://s0.wp.com/latex.php?latex=%5CDelta+%5Csubseteq+W&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Delta \subseteq W"/> , <img alt="\sup_{\tau,\tau' \in \Sigma^{V\setminus W}}\|\mu_{W,\Delta}^\tau - \mu_{W,\Delta}^{\tau'}\|_1 \le C\sum_{x\in\Delta, \; y \in \partial_r W} \exp\Bigl(- \frac{\;\mathrm{dist}(x,y)}{\xi}\Bigr)." class="latex" src="https://s0.wp.com/latex.php?latex=%5Csup_%7B%5Ctau%2C%5Ctau%27+%5Cin+%5CSigma%5E%7BV%5Csetminus+W%7D%7D%5C%7C%5Cmu_%7BW%2C%5CDelta%7D%5E%5Ctau+-+%5Cmu_%7BW%2C%5CDelta%7D%5E%7B%5Ctau%27%7D%5C%7C_1+%5Cle+C%5Csum_%7Bx%5Cin%5CDelta%2C+%5C%3B+y+%5Cin+%5Cpartial_r+W%7D+%5Cexp%5CBigl%28-+%5Cfrac%7B%5C%3B%5Cmathrm%7Bdist%7D%28x%2Cy%29%7D%7B%5Cxi%7D%5CBigr%29.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sup_{\tau,\tau' \in \Sigma^{V\setminus W}}\|\mu_{W,\Delta}^\tau - \mu_{W,\Delta}^{\tau'}\|_1 \le C\sum_{x\in\Delta, \; y \in \partial_r W} \exp\Bigl(- \frac{\;\mathrm{dist}(x,y)}{\xi}\Bigr)."/></li><li>(<strong>Strong decay of correlations</strong>) Strong spatial mixing holds for <img alt="W" class="latex" src="https://s0.wp.com/latex.php?latex=W&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="W"/> if there exist constants <img alt="C,\xi &gt; 0" class="latex" src="https://s0.wp.com/latex.php?latex=C%2C%5Cxi+%3E+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C,\xi &gt; 0"/> such that for every <img alt="\Delta \subseteq W" class="latex" src="https://s0.wp.com/latex.php?latex=%5CDelta+%5Csubseteq+W&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Delta \subseteq W"/> and every <img alt="\tau,\tau' \in \Sigma^{V\setminus W}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctau%2C%5Ctau%27+%5Cin+%5CSigma%5E%7BV%5Csetminus+W%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\tau,\tau' \in \Sigma^{V\setminus W}"/> differing only at site <img alt="y \in V\setminus W" class="latex" src="https://s0.wp.com/latex.php?latex=y+%5Cin+V%5Csetminus+W&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y \in V\setminus W"/> , <img alt="\|\mu_{W,\Delta}^\tau - \mu_{W,\Delta}^{\tau'}\|_1 \le C\exp\Bigl(-\frac{\;\mathrm{dist}(y,\Delta)}{\xi}\Bigr)." class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7C%5Cmu_%7BW%2C%5CDelta%7D%5E%5Ctau+-+%5Cmu_%7BW%2C%5CDelta%7D%5E%7B%5Ctau%27%7D%5C%7C_1+%5Cle+C%5Cexp%5CBigl%28-%5Cfrac%7B%5C%3B%5Cmathrm%7Bdist%7D%28y%2C%5CDelta%29%7D%7B%5Cxi%7D%5CBigr%29.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\|\mu_{W,\Delta}^\tau - \mu_{W,\Delta}^{\tau'}\|_1 \le C\exp\Bigl(-\frac{\;\mathrm{dist}(y,\Delta)}{\xi}\Bigr)."/></li><li>(<strong>Strong decay of correlations</strong>) Strong spatial mixing in the <em>truncated</em> sense holds for <img alt="V" class="latex" src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="V"/> if there exist <img alt="n, \xi &gt; 0" class="latex" src="https://s0.wp.com/latex.php?latex=n%2C+%5Cxi+%3E+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n, \xi &gt; 0"/> such that for all functions <img alt="f, g : \Omega \to {\mathbb R}" class="latex" src="https://s0.wp.com/latex.php?latex=f%2C+g+%3A+%5COmega+%5Cto+%7B%5Cmathbb+R%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f, g : \Omega \to {\mathbb R}"/> which depend only on the sites at <img alt="\Lambda_f" class="latex" src="https://s0.wp.com/latex.php?latex=%5CLambda_f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Lambda_f"/> and <img alt="\Lambda_g" class="latex" src="https://s0.wp.com/latex.php?latex=%5CLambda_g&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Lambda_g"/> respectively and such that <img alt="\;\mathrm{dist}(\Lambda_f,\Lambda_g) \ge n" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%3B%5Cmathrm%7Bdist%7D%28%5CLambda_f%2C%5CLambda_g%29+%5Cge+n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\;\mathrm{dist}(\Lambda_f,\Lambda_g) \ge n"/> , <img alt="\sup_{\tau \in \Sigma^{V\setminus W}} \;\mathrm{cov}_{\mu_W^\tau}(f, g) \le |\Lambda_f||\Lambda_g|\|f\|_\infty \|g\|_\infty \exp\Bigl(-\frac{d(\Lambda_f,\Lambda_g)}{\xi}\Bigr)." class="latex" src="https://s0.wp.com/latex.php?latex=%5Csup_%7B%5Ctau+%5Cin+%5CSigma%5E%7BV%5Csetminus+W%7D%7D+%5C%3B%5Cmathrm%7Bcov%7D_%7B%5Cmu_W%5E%5Ctau%7D%28f%2C+g%29+%5Cle+%7C%5CLambda_f%7C%7C%5CLambda_g%7C%5C%7Cf%5C%7C_%5Cinfty+%5C%7Cg%5C%7C_%5Cinfty+%5Cexp%5CBigl%28-%5Cfrac%7Bd%28%5CLambda_f%2C%5CLambda_g%29%7D%7B%5Cxi%7D%5CBigr%29.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sup_{\tau \in \Sigma^{V\setminus W}} \;\mathrm{cov}_{\mu_W^\tau}(f, g) \le |\Lambda_f||\Lambda_g|\|f\|_\infty \|g\|_\infty \exp\Bigl(-\frac{d(\Lambda_f,\Lambda_g)}{\xi}\Bigr)."/></li></ul>



<p>Here, <img alt="\xi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cxi&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\xi"/> is the <strong>correlation length</strong> (in physics, it is the characteristic length scale of a system). In the disordered phase, the correlation length is a constant independent of system size. For our purposes, the main consequence of these definitions is that the effective interaction range of each spin is <img alt="O(\xi)" class="latex" src="https://s0.wp.com/latex.php?latex=O%28%5Cxi%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(\xi)"/> . For the Ising model, there is a key simplification due to <em>monotonicity</em>. Namely, the ferromagnetic Ising model has the nice property (which is not true for other models) that if we flip a sign from <img alt="-" class="latex" src="https://s0.wp.com/latex.php?latex=-&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="-"/> to <img alt="+" class="latex" src="https://s0.wp.com/latex.php?latex=%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="+"/> , this only makes <img alt="+" class="latex" src="https://s0.wp.com/latex.php?latex=%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="+"/> more likely everywhere. This is because the spins want to agree. There are a lot of boundary conditions to consider, but here, due to monotonicity, we only need to consider two: all of the spins are <img alt="-" class="latex" src="https://s0.wp.com/latex.php?latex=-&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="-"/> , and all of the spins are <img alt="+" class="latex" src="https://s0.wp.com/latex.php?latex=%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="+"/> . All <img alt="+" class="latex" src="https://s0.wp.com/latex.php?latex=%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="+"/> spins will give the highest probability of a <img alt="+" class="latex" src="https://s0.wp.com/latex.php?latex=%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="+"/> spin, and all <img alt="-" class="latex" src="https://s0.wp.com/latex.php?latex=-&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="-"/> spin will give the lowest probability of a <img alt="+" class="latex" src="https://s0.wp.com/latex.php?latex=%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="+"/> spin. This monotonicity property is generally not required for time-space mixing equivalence to hold, but it greatly simplifies proofs.</p>



<p>It is a very non-obvious fact that all of these notions of spatial mixing are equivalent. We will sketch a proof that strong correlation decay implies that <img alt="t_{\rm mix} = O(n\log n)" class="latex" src="https://s0.wp.com/latex.php?latex=t_%7B%5Crm+mix%7D+%3D+O%28n%5Clog+n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t_{\rm mix} = O(n\log n)"/> .</p>



<p>The idea is to use another coupling argument. Let <img alt="X(0), Y(0) \in {\{\pm 1\}}^V" class="latex" src="https://s0.wp.com/latex.php?latex=X%280%29%2C+Y%280%29+%5Cin+%7B%5C%7B%5Cpm+1%5C%7D%7D%5EV&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X(0), Y(0) \in {\{\pm 1\}}^V"/> differ in one coordinate, i.e., <img alt="{X(0)}_a \ne {Y(0)}_a" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%280%29%7D_a+%5Cne+%7BY%280%29%7D_a&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{X(0)}_a \ne {Y(0)}_a"/> and <img alt="{X(0)}_i = {Y(0)}_i" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%280%29%7D_i+%3D+%7BY%280%29%7D_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{X(0)}_i = {Y(0)}_i"/> for <img alt="i \ne a" class="latex" src="https://s0.wp.com/latex.php?latex=i+%5Cne+a&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i \ne a"/> . We want to argue that the expected distance between the processes will decrease. The proof uses a generalization of Glauber dynamics called <strong>block Glauber dynamics</strong>. In Glauber dynamics, we take a single spin and resample it conditioned on its neighbors. In block Glauber dynamics, we take an <img alt="L\times L" class="latex" src="https://s0.wp.com/latex.php?latex=L%5Ctimes+L&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="L\times L"/> box and resample it conditioned on its neighbors. There is an argument, called <em>canonical paths</em>, which can be used to show that if block Glauber dynamics mixes, then regular Glauber dynamics also mixes (slightly more slowly; we lose a <img alt="\;\mathrm{poly}(L)" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%3B%5Cmathrm%7Bpoly%7D%28L%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\;\mathrm{poly}(L)"/> factor, but anyway <img alt="L" class="latex" src="https://s0.wp.com/latex.php?latex=L&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="L"/> will be a large constant) so analyzing block Glauber dynamics is fine.</p>



<p>If <img alt="a" class="latex" src="https://s0.wp.com/latex.php?latex=a&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a"/> lies in the box, then the expected change in distance is <img alt="-L^2/n" class="latex" src="https://s0.wp.com/latex.php?latex=-L%5E2%2Fn&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="-L^2/n"/> . If <img alt="a" class="latex" src="https://s0.wp.com/latex.php?latex=a&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a"/> is far away from the box, then there is no change. If <img alt="a" class="latex" src="https://s0.wp.com/latex.php?latex=a&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a"/> is in the boundary of the box, then it is possible for the distance to increase. However, strong spatial mixing allows us to control the influence of a single site, so the expected change in distance is bounded by <img alt="O(L\xi^2/n)" class="latex" src="https://s0.wp.com/latex.php?latex=O%28L%5Cxi%5E2%2Fn%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(L\xi^2/n)"/> . Now, since <img alt="\xi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cxi&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\xi"/> is a constant, if we choose <img alt="L" class="latex" src="https://s0.wp.com/latex.php?latex=L&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="L"/> sufficiently large, then we will have the same situation as in the high temperature case: the expected distance will exponentially shrink over time.</p>



<h1 id="quantum-systems">Quantum systems</h1>



<p>The quantum version of Markov chains has many more difficulties. The first difficulty is that the Hammersley-Clifford theorem (which we have been relying on throughout this blog post) fails.</p>



<h2 id="notation">Notation</h2>



<p>To properly discuss what we mean, let’s set up some notation. Readers already familiar with density matrices, quantum entropy, and quantum mutual information may wish to skip to the next subsection. Most of the time we discuss quantum objects here, we’ll be using density matricies, often denoted <img alt="\rho" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho"/> . A density matrix can be thought of as an extension to regular quantum states <img alt="|{\psi}\rangle " class="latex" src="https://s0.wp.com/latex.php?latex=%7C%7B%5Cpsi%7D%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|{\psi}\rangle "/> , where there is some classical source of uncertainty.</p>



<p>A density matrix is a positive semidefinite matrix with trace <img alt="1" class="latex" src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1"/> . This extends the notion of a classical probability distribution; in the quantum setting, a classical probability distribution <img alt="p" class="latex" src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p"/> (thought of as a vector whose entries sum to <img alt="1" class="latex" src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1"/> ) is represented as the density matrix <img alt="\;\mathrm{diag}(p)" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%3B%5Cmathrm%7Bdiag%7D%28p%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\;\mathrm{diag}(p)"/> .</p>



<p>For example, we can consider a situation in which there is a <img alt="1/2" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/2"/> probability that we started with the quantum state <img alt="|{\psi}\rangle " class="latex" src="https://s0.wp.com/latex.php?latex=%7C%7B%5Cpsi%7D%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|{\psi}\rangle "/> and a <img alt="1/2" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/2"/> probability that we started with the quantum state <img alt="|{\phi}\rangle " class="latex" src="https://s0.wp.com/latex.php?latex=%7C%7B%5Cphi%7D%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|{\phi}\rangle "/> . This would be denoted as follows:</p>



<p> <img alt="\rho = \frac{1}{2} |{\psi}\rangle \langle{\psi}| + \frac{1}{2} |{\phi}\rangle \langle{\phi}| " class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho+%3D+%5Cfrac%7B1%7D%7B2%7D+%7C%7B%5Cpsi%7D%5Crangle+%5Clangle%7B%5Cpsi%7D%7C+%2B+%5Cfrac%7B1%7D%7B2%7D+%7C%7B%5Cphi%7D%5Crangle+%5Clangle%7B%5Cphi%7D%7C+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho = \frac{1}{2} |{\psi}\rangle \langle{\psi}| + \frac{1}{2} |{\phi}\rangle \langle{\phi}| "/> </p>



<p>Density matricies are generally useful for a lot of tasks, but for our purposes a density matrix will be used to discuss both the classical and quantum “uncertainty” we have about what state we have.</p>



<p>Now let’s also talk about a second important piece of notation: the tensor product. Often when discussing quantum states, it is important to discuss multiple quantum states simultaneously. For example, Alice has one system <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> and Bob has another system <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> . However, these systems might be entangled, meaning that the results of the two systems are correlated.</p>



<p>For instance, let us consider the following state:</p>



<p> <img alt="|{\psi}\rangle = \frac{1}{\sqrt{2}}\left( |{+}\rangle _A |{+}\rangle _B + |{-}\rangle _A |{-}\rangle _B \right)" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%7B%5Cpsi%7D%5Crangle+%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%5Cleft%28+%7C%7B%2B%7D%5Crangle+_A+%7C%7B%2B%7D%5Crangle+_B+%2B+%7C%7B-%7D%5Crangle+_A+%7C%7B-%7D%5Crangle+_B+%5Cright%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|{\psi}\rangle = \frac{1}{\sqrt{2}}\left( |{+}\rangle _A |{+}\rangle _B + |{-}\rangle _A |{-}\rangle _B \right)"/> </p>



<p>This particular state has the property that Alice and Bob will always both measure <img alt="+" class="latex" src="https://s0.wp.com/latex.php?latex=%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="+"/> or they will both measure <img alt="-" class="latex" src="https://s0.wp.com/latex.php?latex=-&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="-"/> . The notation for tensors is often ambiguous in the literature as there are many ways of specifying tensors. For instance, above we used subscripts to explicitly denote which particle was in system <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> and which was in system <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> . One may also choose to simply use the index of the system as below. The symbol <img alt="\otimes" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cotimes&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\otimes"/> is used to denote a tensor between states (where it is assumed that the first state is system <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> and the second, system <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> ). Gradually folks may shorten the notation as follows:</p>



<p> <img alt="\begin{aligned} |{\psi}\rangle &amp;= \frac{1}{\sqrt{2}}\left( |{+}\rangle |{+}\rangle + |{-}\rangle |{-}\rangle \right)\\ |{\psi}\rangle &amp;= \frac{1}{\sqrt{2}}\left( |{++}\rangle + |{--}\rangle \right)\\ |{\psi}\rangle &amp;= \frac{1}{\sqrt{2}} \begin{pmatrix} 1\\0 \end{pmatrix} \otimes \begin{pmatrix} 0\\1 \end{pmatrix} \end{aligned} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7C%7B%5Cpsi%7D%5Crangle+%26%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%5Cleft%28+%7C%7B%2B%7D%5Crangle+%7C%7B%2B%7D%5Crangle+%2B+%7C%7B-%7D%5Crangle+%7C%7B-%7D%5Crangle+%5Cright%29%5C%5C+%7C%7B%5Cpsi%7D%5Crangle+%26%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%5Cleft%28+%7C%7B%2B%2B%7D%5Crangle+%2B+%7C%7B--%7D%5Crangle+%5Cright%29%5C%5C+%7C%7B%5Cpsi%7D%5Crangle+%26%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D+%5Cbegin%7Bpmatrix%7D+1%5C%5C0+%5Cend%7Bpmatrix%7D+%5Cotimes+%5Cbegin%7Bpmatrix%7D+0%5C%5C1+%5Cend%7Bpmatrix%7D+%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} |{\psi}\rangle &amp;= \frac{1}{\sqrt{2}}\left( |{+}\rangle |{+}\rangle + |{-}\rangle |{-}\rangle \right)\\ |{\psi}\rangle &amp;= \frac{1}{\sqrt{2}}\left( |{++}\rangle + |{--}\rangle \right)\\ |{\psi}\rangle &amp;= \frac{1}{\sqrt{2}} \begin{pmatrix} 1\\0 \end{pmatrix} \otimes \begin{pmatrix} 0\\1 \end{pmatrix} \end{aligned} "/> </p>



<p>These are all notations for the same state. Let’s now talk about this state in the context of a density matrix. The density matrix of this state is as follows:</p>



<p> <img alt="\begin{aligned} \rho_{A,B} &amp;= \frac{1}{2} \left( |{++}\rangle + |{--}\rangle \right) \left( \langle{++}| + \langle{--}| \right)\\ \rho_{A,B} &amp;= \frac{1}{2} \left( |{++}\rangle \langle{++}| + |{--}\rangle \langle{++}| + |{++}\rangle \langle{--}| + |{--}\rangle \langle{--}| \right) \\ \rho_{A,B} &amp;= \frac{1}{2} \begin{pmatrix} 1&amp;0&amp;0&amp;1\\0&amp;0&amp;0&amp;0\\0&amp;0&amp;0&amp;0\\1&amp;0&amp;0&amp;1 \end{pmatrix}\end{aligned} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Crho_%7BA%2CB%7D+%26%3D+%5Cfrac%7B1%7D%7B2%7D+%5Cleft%28+%7C%7B%2B%2B%7D%5Crangle+%2B+%7C%7B--%7D%5Crangle+%5Cright%29+%5Cleft%28+%5Clangle%7B%2B%2B%7D%7C+%2B+%5Clangle%7B--%7D%7C+%5Cright%29%5C%5C+%5Crho_%7BA%2CB%7D+%26%3D+%5Cfrac%7B1%7D%7B2%7D+%5Cleft%28+%7C%7B%2B%2B%7D%5Crangle+%5Clangle%7B%2B%2B%7D%7C+%2B+%7C%7B--%7D%5Crangle+%5Clangle%7B%2B%2B%7D%7C+%2B+%7C%7B%2B%2B%7D%5Crangle+%5Clangle%7B--%7D%7C+%2B+%7C%7B--%7D%5Crangle+%5Clangle%7B--%7D%7C+%5Cright%29+%5C%5C+%5Crho_%7BA%2CB%7D+%26%3D+%5Cfrac%7B1%7D%7B2%7D+%5Cbegin%7Bpmatrix%7D+1%260%260%261%5C%5C0%260%260%260%5C%5C0%260%260%260%5C%5C1%260%260%261+%5Cend%7Bpmatrix%7D%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \rho_{A,B} &amp;= \frac{1}{2} \left( |{++}\rangle + |{--}\rangle \right) \left( \langle{++}| + \langle{--}| \right)\\ \rho_{A,B} &amp;= \frac{1}{2} \left( |{++}\rangle \langle{++}| + |{--}\rangle \langle{++}| + |{++}\rangle \langle{--}| + |{--}\rangle \langle{--}| \right) \\ \rho_{A,B} &amp;= \frac{1}{2} \begin{pmatrix} 1&amp;0&amp;0&amp;1\\0&amp;0&amp;0&amp;0\\0&amp;0&amp;0&amp;0\\1&amp;0&amp;0&amp;1 \end{pmatrix}\end{aligned} "/> </p>



<p>Writing the density matrix <img alt="\rho" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho"/> as <img alt="\rho_{A,B}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho_%7BA%2CB%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho_{A,B}"/> makes explicit that this is the density matrix over systems <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> and <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> .</p>



<p>A crucial operation that one will often perform using density matricies is the partial trace. The partial trace is a way of allowing us to consider only a smaller part of the larger part of the system, while taking into account the influence of the larger system around it.</p>



<p>Here’s an example: Suppose Bob wants to know what his state is. However, Bob really doesn’t care about Alice’s system and just wants to know what the density matrix for his system is. Bob’s density matrix is simply the following density matrix (a 50% chance of being in <img alt="|{+}\rangle " class="latex" src="https://s0.wp.com/latex.php?latex=%7C%7B%2B%7D%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|{+}\rangle "/> and a 50% chance of being in <img alt="|{-}\rangle " class="latex" src="https://s0.wp.com/latex.php?latex=%7C%7B-%7D%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|{-}\rangle "/> ).</p>



<p> <img alt="\begin{aligned} \rho_{B} &amp;= \frac{1}{2} \left( |{+}\rangle \langle{+}| + |{-}\rangle \langle{-}| \right) \end{aligned} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Crho_%7BB%7D+%26%3D+%5Cfrac%7B1%7D%7B2%7D+%5Cleft%28+%7C%7B%2B%7D%5Crangle+%5Clangle%7B%2B%7D%7C+%2B+%7C%7B-%7D%5Crangle+%5Clangle%7B-%7D%7C+%5Cright%29+%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \rho_{B} &amp;= \frac{1}{2} \left( |{+}\rangle \langle{+}| + |{-}\rangle \langle{-}| \right) \end{aligned} "/> </p>



<p>More explicitly, we could write the following:</p>



<p> <img alt="\begin{aligned} \rho_{B} &amp;= \frac{1}{2} \left( |{+}\rangle _B \langle{+}| _B + |{-}\rangle _B \langle{-}| _B \right) \end{aligned} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Crho_%7BB%7D+%26%3D+%5Cfrac%7B1%7D%7B2%7D+%5Cleft%28+%7C%7B%2B%7D%5Crangle+_B+%5Clangle%7B%2B%7D%7C+_B+%2B+%7C%7B-%7D%5Crangle+_B+%5Clangle%7B-%7D%7C+_B+%5Cright%29+%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \rho_{B} &amp;= \frac{1}{2} \left( |{+}\rangle _B \langle{+}| _B + |{-}\rangle _B \langle{-}| _B \right) \end{aligned} "/> </p>



<p>The partial trace is an operation that will let us take our original density matrix <img alt="\rho_{A,B}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho_%7BA%2CB%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho_{A,B}"/> and generates a new density matrix <img alt="\rho_B" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho_B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho_B"/> that ignores system <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> . This is specifically called the partial trace over <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> , or <img alt="\;\mathrm{tr}_A" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%3B%5Cmathrm%7Btr%7D_A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\;\mathrm{tr}_A"/> .</p>



<p>So how do we do this? We simply sum over the state <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> (effectively taking a trace, but only along one axis):</p>



<p> <img alt="\begin{aligned} \;\mathrm{tr}_A \rho_{A,B} &amp;= \sum_i \langle{i}| _A \frac{1}{2} \left( |{++}\rangle \langle{++}| + |{--}\rangle \langle{++}| + |{++}\rangle \langle{--}| + |{--}\rangle \langle{--}| \right) |{i}\rangle _A\end{aligned} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5C%3B%5Cmathrm%7Btr%7D_A+%5Crho_%7BA%2CB%7D+%26%3D+%5Csum_i+%5Clangle%7Bi%7D%7C+_A+%5Cfrac%7B1%7D%7B2%7D+%5Cleft%28+%7C%7B%2B%2B%7D%5Crangle+%5Clangle%7B%2B%2B%7D%7C+%2B+%7C%7B--%7D%5Crangle+%5Clangle%7B%2B%2B%7D%7C+%2B+%7C%7B%2B%2B%7D%5Crangle+%5Clangle%7B--%7D%7C+%2B+%7C%7B--%7D%5Crangle+%5Clangle%7B--%7D%7C+%5Cright%29+%7C%7Bi%7D%5Crangle+_A%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \;\mathrm{tr}_A \rho_{A,B} &amp;= \sum_i \langle{i}| _A \frac{1}{2} \left( |{++}\rangle \langle{++}| + |{--}\rangle \langle{++}| + |{++}\rangle \langle{--}| + |{--}\rangle \langle{--}| \right) |{i}\rangle _A\end{aligned} "/> </p>



<p>This is easier to evaluate using certain choices of notation:</p>



<p> <img alt="\begin{aligned} \;\mathrm{tr}_A \rho_{A,B} &amp;= \langle{+}| _A \frac{1}{2} \left( |{++}\rangle \langle{++}| + |{--}\rangle \langle{++}| + |{++}\rangle \langle{--}| + |{--}\rangle \langle{--}| \right) |{+}\rangle _A \\&amp;\qquad {}+ \langle{-}| _A \frac{1}{2} \left( |{++}\rangle \langle{++}| + |{--}\rangle \langle{++}| + |{++}\rangle \langle{--}| + |{--}\rangle \langle{--}| \right) |{-}\rangle _A\\ &amp;= \frac{1}{2} \left( |{+}\rangle _B \langle{++}| + |{+}\rangle _B \langle{--}| \right) |{+}\rangle _A + \frac{1}{2} \left( |{-}\rangle _B \langle{++}| + |{-}\rangle _B \langle{--}| \right) |{-}\rangle _A\\ &amp;= \frac{1}{2} \left( |{+}\rangle _B \langle{+}| _B \right) + \frac{1}{2} \left( |{-}\rangle _B \langle{-}| _B \right) = \frac{1}{2} \left( |{+}\rangle _B \langle{+}| _B + |{-}\rangle _B \langle{-}| _B \right) = \rho_B\end{aligned} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5C%3B%5Cmathrm%7Btr%7D_A+%5Crho_%7BA%2CB%7D+%26%3D+%5Clangle%7B%2B%7D%7C+_A+%5Cfrac%7B1%7D%7B2%7D+%5Cleft%28+%7C%7B%2B%2B%7D%5Crangle+%5Clangle%7B%2B%2B%7D%7C+%2B+%7C%7B--%7D%5Crangle+%5Clangle%7B%2B%2B%7D%7C+%2B+%7C%7B%2B%2B%7D%5Crangle+%5Clangle%7B--%7D%7C+%2B+%7C%7B--%7D%5Crangle+%5Clangle%7B--%7D%7C+%5Cright%29+%7C%7B%2B%7D%5Crangle+_A+%5C%5C%26%5Cqquad+%7B%7D%2B+%5Clangle%7B-%7D%7C+_A+%5Cfrac%7B1%7D%7B2%7D+%5Cleft%28+%7C%7B%2B%2B%7D%5Crangle+%5Clangle%7B%2B%2B%7D%7C+%2B+%7C%7B--%7D%5Crangle+%5Clangle%7B%2B%2B%7D%7C+%2B+%7C%7B%2B%2B%7D%5Crangle+%5Clangle%7B--%7D%7C+%2B+%7C%7B--%7D%5Crangle+%5Clangle%7B--%7D%7C+%5Cright%29+%7C%7B-%7D%5Crangle+_A%5C%5C+%26%3D+%5Cfrac%7B1%7D%7B2%7D+%5Cleft%28+%7C%7B%2B%7D%5Crangle+_B+%5Clangle%7B%2B%2B%7D%7C+%2B+%7C%7B%2B%7D%5Crangle+_B+%5Clangle%7B--%7D%7C+%5Cright%29+%7C%7B%2B%7D%5Crangle+_A+%2B+%5Cfrac%7B1%7D%7B2%7D+%5Cleft%28+%7C%7B-%7D%5Crangle+_B+%5Clangle%7B%2B%2B%7D%7C+%2B+%7C%7B-%7D%5Crangle+_B+%5Clangle%7B--%7D%7C+%5Cright%29+%7C%7B-%7D%5Crangle+_A%5C%5C+%26%3D+%5Cfrac%7B1%7D%7B2%7D+%5Cleft%28+%7C%7B%2B%7D%5Crangle+_B+%5Clangle%7B%2B%7D%7C+_B+%5Cright%29+%2B+%5Cfrac%7B1%7D%7B2%7D+%5Cleft%28+%7C%7B-%7D%5Crangle+_B+%5Clangle%7B-%7D%7C+_B+%5Cright%29+%3D+%5Cfrac%7B1%7D%7B2%7D+%5Cleft%28+%7C%7B%2B%7D%5Crangle+_B+%5Clangle%7B%2B%7D%7C+_B+%2B+%7C%7B-%7D%5Crangle+_B+%5Clangle%7B-%7D%7C+_B+%5Cright%29+%3D+%5Crho_B%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \;\mathrm{tr}_A \rho_{A,B} &amp;= \langle{+}| _A \frac{1}{2} \left( |{++}\rangle \langle{++}| + |{--}\rangle \langle{++}| + |{++}\rangle \langle{--}| + |{--}\rangle \langle{--}| \right) |{+}\rangle _A \\&amp;\qquad {}+ \langle{-}| _A \frac{1}{2} \left( |{++}\rangle \langle{++}| + |{--}\rangle \langle{++}| + |{++}\rangle \langle{--}| + |{--}\rangle \langle{--}| \right) |{-}\rangle _A\\ &amp;= \frac{1}{2} \left( |{+}\rangle _B \langle{++}| + |{+}\rangle _B \langle{--}| \right) |{+}\rangle _A + \frac{1}{2} \left( |{-}\rangle _B \langle{++}| + |{-}\rangle _B \langle{--}| \right) |{-}\rangle _A\\ &amp;= \frac{1}{2} \left( |{+}\rangle _B \langle{+}| _B \right) + \frac{1}{2} \left( |{-}\rangle _B \langle{-}| _B \right) = \frac{1}{2} \left( |{+}\rangle _B \langle{+}| _B + |{-}\rangle _B \langle{-}| _B \right) = \rho_B\end{aligned} "/> </p>



<p>This gives us the answer that we had expected.</p>



<p>We now have all of the tools we need to talk about quantum entropy. Intuitively, entropy can be thought of as the amount of uncertainty we have for our system, or equivalently the amount of information it takes to define our system. The entropy for a quantum system <img alt="\rho" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho"/> is defined as follows:</p>



<p> <img alt="\begin{aligned} H(\rho) &amp;= -\;\mathrm{tr}(\rho \log_2 \rho)\end{aligned} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+H%28%5Crho%29+%26%3D+-%5C%3B%5Cmathrm%7Btr%7D%28%5Crho+%5Clog_2+%5Crho%29%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} H(\rho) &amp;= -\;\mathrm{tr}(\rho \log_2 \rho)\end{aligned} "/> </p>



<p>Note that here we use the shorthand <img alt="\rho_B" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho_B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho_B"/> to denote <img alt="\;\mathrm{tr}_A \rho_{A,B}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%3B%5Cmathrm%7Btr%7D_A+%5Crho_%7BA%2CB%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\;\mathrm{tr}_A \rho_{A,B}"/> . Here, writing <img alt="\;\mathrm{tr}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%3B%5Cmathrm%7Btr%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\;\mathrm{tr}"/> without the subscript indicates that this is the full or normal trace that one might expect (or equivalently performing the partial trace over all systems). We can now define the conditional entropy of a system as follows:</p>



<p> <img alt="\begin{aligned} {H(A \mid B)}_\rho &amp;= H(\rho_{A,B}) - H(\rho_B)\end{aligned} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7BH%28A+%5Cmid+B%29%7D_%5Crho+%26%3D+H%28%5Crho_%7BA%2CB%7D%29+-+H%28%5Crho_B%29%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} {H(A \mid B)}_\rho &amp;= H(\rho_{A,B}) - H(\rho_B)\end{aligned} "/> </p>



<p>This definition intuitively makes sense since we can think of conditional entropy as the amount of information it takes to describe our joint system <img alt="(A,B)" class="latex" src="https://s0.wp.com/latex.php?latex=%28A%2CB%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(A,B)"/> , given that we already know what <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> is.</p>



<p>We can now discuss quantum mutual information, the amount of information that measuring system <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> will provide you about system <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> . Like the classical case, this is defined as follows:</p>



<p> <img alt="\begin{aligned} {I(A;B)}_\rho &amp;= {H(A,B)}_\rho - {H(A\mid B)}_\rho - {H(B\mid A)}_\rho\end{aligned} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7BI%28A%3BB%29%7D_%5Crho+%26%3D+%7BH%28A%2CB%29%7D_%5Crho+-+%7BH%28A%5Cmid+B%29%7D_%5Crho+-+%7BH%28B%5Cmid+A%29%7D_%5Crho%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} {I(A;B)}_\rho &amp;= {H(A,B)}_\rho - {H(A\mid B)}_\rho - {H(B\mid A)}_\rho\end{aligned} "/> </p>



<p>We can now finally discuss <strong>quantum mutual information (QCMI)</strong>, defined as follows: <img alt="{I(A;B \mid C)}_\rho = {I(A;B,C)}_\rho - {I(A;C)}_\rho" class="latex" src="https://s0.wp.com/latex.php?latex=%7BI%28A%3BB+%5Cmid+C%29%7D_%5Crho+%3D+%7BI%28A%3BB%2CC%29%7D_%5Crho+-+%7BI%28A%3BC%29%7D_%5Crho&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{I(A;B \mid C)}_\rho = {I(A;B,C)}_\rho - {I(A;C)}_\rho"/> . With some algebraic simplifications, one can arrive at the expression:</p>



<p> <img alt="\begin{aligned} {I(A;B \mid C)}_\rho &amp;= {H(A,C)}_\rho + {H(B,C)}_\rho - {H(A,B,C)}_\rho - {H(C)}_\rho.\end{aligned} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7BI%28A%3BB+%5Cmid+C%29%7D_%5Crho+%26%3D+%7BH%28A%2CC%29%7D_%5Crho+%2B+%7BH%28B%2CC%29%7D_%5Crho+-+%7BH%28A%2CB%2CC%29%7D_%5Crho+-+%7BH%28C%29%7D_%5Crho.%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} {I(A;B \mid C)}_\rho &amp;= {H(A,C)}_\rho + {H(B,C)}_\rho - {H(A,B,C)}_\rho - {H(C)}_\rho.\end{aligned} "/> </p>



<p>The QCMI equals <img alt="0" class="latex" src="https://s0.wp.com/latex.php?latex=0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="0"/> if and only if <img alt="\rho" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho"/> is a <strong>quantum Markov state</strong>. Classically, the entropic characterization of conditional independence corresponds to an algebraic characterization.</p>



<h2 id="recovery-maps">Recovery Maps</h2>



<p>Here, the algebraic characterization is more grueling. We have</p>



<p> <img alt="\rho_{ABC} = \exp(\log \rho_{AB} + \log \rho_{BC} - \log \rho_B)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho_%7BABC%7D+%3D+%5Cexp%28%5Clog+%5Crho_%7BAB%7D+%2B+%5Clog+%5Crho_%7BBC%7D+-+%5Clog+%5Crho_B%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho_{ABC} = \exp(\log \rho_{AB} + \log \rho_{BC} - \log \rho_B)"/> </p>



<p>Equivalently,</p>



<p> <img alt="\rho_{ABC} = \rho_{AB}^{1/2} \rho_B^{-1/2} \rho_{BC}\rho_B^{-1/2} \rho_{AB}^{1/2} = R_{B\to AB}(\rho_{BC})" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho_%7BABC%7D+%3D+%5Crho_%7BAB%7D%5E%7B1%2F2%7D+%5Crho_B%5E%7B-1%2F2%7D+%5Crho_%7BBC%7D%5Crho_B%5E%7B-1%2F2%7D+%5Crho_%7BAB%7D%5E%7B1%2F2%7D+%3D+R_%7BB%5Cto+AB%7D%28%5Crho_%7BBC%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho_{ABC} = \rho_{AB}^{1/2} \rho_B^{-1/2} \rho_{BC}\rho_B^{-1/2} \rho_{AB}^{1/2} = R_{B\to AB}(\rho_{BC})"/> </p>



<p>Here, <img alt="R_{B\to AB}" class="latex" src="https://s0.wp.com/latex.php?latex=R_%7BB%5Cto+AB%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R_{B\to AB}"/> is called the <strong>Petz recovery map</strong>,<sup><a href="https://windowsontheory.org/feed/#fn_4">4</a></sup> <img alt="\rho_{B\to AB}(X) = \rho_{AB}^{1/2} \rho_B^{-1/2} X\rho_B^{-1/2} \rho_{AB}^{1/2}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho_%7BB%5Cto+AB%7D%28X%29+%3D+%5Crho_%7BAB%7D%5E%7B1%2F2%7D+%5Crho_B%5E%7B-1%2F2%7D+X%5Crho_B%5E%7B-1%2F2%7D+%5Crho_%7BAB%7D%5E%7B1%2F2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho_{B\to AB}(X) = \rho_{AB}^{1/2} \rho_B^{-1/2} X\rho_B^{-1/2} \rho_{AB}^{1/2}"/> . One can think of a recovery may as a way that we can reconstruct the entire system <img alt="A, B" class="latex" src="https://s0.wp.com/latex.php?latex=A%2C+B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A, B"/> using just system <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> . It is not obvious that this is a quantum channel, but it is.</p>



<p>Suppose <img alt="\rho" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho"/> is a probability distribution, so <img alt="\rho =\;\mathrm{diag}(p)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho+%3D%5C%3B%5Cmathrm%7Bdiag%7D%28p%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho =\;\mathrm{diag}(p)"/> for some vector <img alt="p" class="latex" src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p"/> . Then, all of the density matrices are diagonal and commuting. Then, the recovery map means that we divide by <img alt="p_B" class="latex" src="https://s0.wp.com/latex.php?latex=p_B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p_B"/> and multiply by <img alt="p_{AB}" class="latex" src="https://s0.wp.com/latex.php?latex=p_%7BAB%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p_{AB}"/> , i.e., multiply by <img alt="p_{A \mid B}" class="latex" src="https://s0.wp.com/latex.php?latex=p_%7BA+%5Cmid+B%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p_{A \mid B}"/> . This is the natural thing to do if we lost our information about <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> and were trying to figure out what <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> was based on our knowledge of <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> . This is why <img alt="R_{B\to A,B}" class="latex" src="https://s0.wp.com/latex.php?latex=R_%7BB%5Cto+A%2CB%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R_{B\to A,B}"/> is known as a <em>recovery</em> map, and it is used to discuss conditional distributions in the quantum setting. In the classical case, if we start with <img alt="B, C" class="latex" src="https://s0.wp.com/latex.php?latex=B%2C+C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B, C"/> , look only at <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> , and use this to reconstruct <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> , then we would have the whole state in a Markov chain. That is why this is a plausible quantum version of being a Markov chain.</p>



<p>However, quantum Gibbs states are not, in general, quantum Markov chains. The failure of this statement to hold is related to <em>topological order</em>, which is similar to the degrees of freedom that show up in error correcting codes.</p>



<h2 id="quantum-markov-networks">Quantum Markov Networks</h2>



<p>Here, we will formally define a quantum Markov network. The reference for this is <a href="https://windowsontheory.org/feed/#leifer">[7]</a>.</p>



<p>Let <img alt="G = (V, E)" class="latex" src="https://s0.wp.com/latex.php?latex=G+%3D+%28V%2C+E%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G = (V, E)"/> be a finite graph. We associate with each vertex <img alt="v \in V" class="latex" src="https://s0.wp.com/latex.php?latex=v+%5Cin+V&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="v \in V"/> a Hilbert space <img alt="{\mathcal{H}}_v" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BH%7D%7D_v&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{\mathcal{H}}_v"/> and we consider a density matrix <img alt="\rho_V" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho_V&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho_V"/> acting on <img alt="\bigotimes_{v\in V} {\mathcal{H}}_v" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbigotimes_%7Bv%5Cin+V%7D+%7B%5Cmathcal%7BH%7D%7D_v&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\bigotimes_{v\in V} {\mathcal{H}}_v"/> . Then, <img alt="(G, \rho_V)" class="latex" src="https://s0.wp.com/latex.php?latex=%28G%2C+%5Crho_V%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(G, \rho_V)"/> is a <strong>quantum Markov network</strong> if for all <img alt="U\subseteq V" class="latex" src="https://s0.wp.com/latex.php?latex=U%5Csubseteq+V&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U\subseteq V"/> , <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/> is conditionally independent of <img alt="V \setminus (U \cup \partial U)" class="latex" src="https://s0.wp.com/latex.php?latex=V+%5Csetminus+%28U+%5Ccup+%5Cpartial+U%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="V \setminus (U \cup \partial U)"/> given <img alt="\partial U" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpartial+U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\partial U"/> , where the conditional independence statement is w.r.t. <img alt="\rho_V" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho_V&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho_V"/> and means that the corresponding QCMI satisfies <img alt="{I(U; V\setminus (U \cup \partial U) \mid \partial U)}_{\rho_V} = 0" class="latex" src="https://s0.wp.com/latex.php?latex=%7BI%28U%3B+V%5Csetminus+%28U+%5Ccup+%5Cpartial+U%29+%5Cmid+%5Cpartial+U%29%7D_%7B%5Crho_V%7D+%3D+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{I(U; V\setminus (U \cup \partial U) \mid \partial U)}_{\rho_V} = 0"/> .</p>



<p>A quantum Markov network is called <strong>positive</strong> if <img alt="\rho_V" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho_V&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho_V"/> has full rank. (Recall that in the statement of the Hammersley-Clifford Theorem, , it is assumed that the distribution is strictly positive.)</p>



<p>Now, consider the following example. First, we introduce the Pauli matrices</p>



<p> <img alt="\begin{aligned} \sigma^x := \begin{bmatrix} 0 &amp; 1 \\ 1 &amp; 0 \end{bmatrix}, \qquad \sigma^z := \begin{bmatrix} 1 &amp; 0 \\ 0 &amp; -1 \end{bmatrix}, \qquad \sigma^y := \begin{bmatrix} 0 &amp; -i \\ i &amp; 0 \end{bmatrix}.\end{aligned} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Csigma%5Ex+%3A%3D+%5Cbegin%7Bbmatrix%7D+0+%26+1+%5C%5C+1+%26+0+%5Cend%7Bbmatrix%7D%2C+%5Cqquad+%5Csigma%5Ez+%3A%3D+%5Cbegin%7Bbmatrix%7D+1+%26+0+%5C%5C+0+%26+-1+%5Cend%7Bbmatrix%7D%2C+%5Cqquad+%5Csigma%5Ey+%3A%3D+%5Cbegin%7Bbmatrix%7D+0+%26+-i+%5C%5C+i+%26+0+%5Cend%7Bbmatrix%7D.%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \sigma^x := \begin{bmatrix} 0 &amp; 1 \\ 1 &amp; 0 \end{bmatrix}, \qquad \sigma^z := \begin{bmatrix} 1 &amp; 0 \\ 0 &amp; -1 \end{bmatrix}, \qquad \sigma^y := \begin{bmatrix} 0 &amp; -i \\ i &amp; 0 \end{bmatrix}.\end{aligned} "/> </p>



<p>We define a Hamiltonian on three qubits <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> , <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> , <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/> by</p>



<p> <img alt="H := (\sigma_A^x \sigma_B^x + \sigma_A^y \sigma_B^y + \sigma_A^z \sigma_B^z) I_C + I_A (\sigma_B^x \sigma_C^x + \sigma_B^y \sigma_C^y + \sigma_B^z \sigma_C^z)" class="latex" src="https://s0.wp.com/latex.php?latex=H+%3A%3D+%28%5Csigma_A%5Ex+%5Csigma_B%5Ex+%2B+%5Csigma_A%5Ey+%5Csigma_B%5Ey+%2B+%5Csigma_A%5Ez+%5Csigma_B%5Ez%29+I_C+%2B+I_A+%28%5Csigma_B%5Ex+%5Csigma_C%5Ex+%2B+%5Csigma_B%5Ey+%5Csigma_C%5Ey+%2B+%5Csigma_B%5Ez+%5Csigma_C%5Ez%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H := (\sigma_A^x \sigma_B^x + \sigma_A^y \sigma_B^y + \sigma_A^z \sigma_B^z) I_C + I_A (\sigma_B^x \sigma_C^x + \sigma_B^y \sigma_C^y + \sigma_B^z \sigma_C^z)"/> </p>



<p>(Juxtaposition in the above expression signifies the tensor product as discussed before.) Finally, for <img alt="\beta &gt; 0" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbeta+%3E+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\beta &gt; 0"/> , we define the Gibbs state</p>



<p> <img alt="\rho_{A,B,C}(\beta) := \frac{1}{Z(\beta)} \exp(-\beta H)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho_%7BA%2CB%2CC%7D%28%5Cbeta%29+%3A%3D+%5Cfrac%7B1%7D%7BZ%28%5Cbeta%29%7D+%5Cexp%28-%5Cbeta+H%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho_{A,B,C}(\beta) := \frac{1}{Z(\beta)} \exp(-\beta H)"/> </p>



<p>The Hamiltonian here has local terms which correspond to interactions <img alt="(A,B)" class="latex" src="https://s0.wp.com/latex.php?latex=%28A%2CB%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(A,B)"/> , <img alt="(B, C)" class="latex" src="https://s0.wp.com/latex.php?latex=%28B%2C+C%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(B, C)"/> . However, it can be shown that the QCMI between <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> and <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/> conditioned on <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> w.r.t. <img alt="\rho_{A,B,C}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho_%7BA%2CB%2CC%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho_{A,B,C}"/> is non-zero, which means that this is not a quantum Markov network w.r.t. the line graph <img alt="A \leftrightarrow B \leftrightarrow C" class="latex" src="https://s0.wp.com/latex.php?latex=A+%5Cleftrightarrow+B+%5Cleftrightarrow+C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A \leftrightarrow B \leftrightarrow C"/> . This demonstrates the failure of the Hammersley-Clifford Theorem in the quantum setting.</p>



<h2 id="important-results">Important Results</h2>



<p>We will briefly discuss the results of two papers.</p>



<ol><li><a href="https://windowsontheory.org/feed/#brandao1">[8]</a> This paper shows that mixing in space implies mixing in time in the quantum case. However, the result of the paper only applies to commuting Hamiltonians. For commuting Hamiltonians, it turns out that quantum Gibbs states are quantum Markov networks. They use a version of Glauber dynamics, which can be simulated on a quantum computer but are also plausible dynamics for a physical system in nature. This is a difficult paper to read, but it is worth digesting if you want to work in the field.</li><li><a href="https://windowsontheory.org/feed/#brandao2">[9]</a> This second paper is much easier and more general, covering non-commuting Hamiltonians, but it requires more conditions. They give a method of preparing the Gibbs state which can run on a quantum computer, but the dynamics are not plausible as a physical system because they are too complicated. The more complicated dynamics allows them to make the proof work. The paper also uses QCMI.They have two assumptions. The first assumption looks like mixing in space (weak correlation decay). The second assumption is that the state looks approximately like a quantum Markov network (this is definitely not met in general). A very important paper in this space is a recent breakthrough (<a href="https://windowsontheory.org/feed/#fawzi">[10]</a>) which characterizes quantum Markov chains. They show that if the QCMI is bounded by <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon"/> , then the recovery map <img alt="R_{B\to A,B}(\rho_{BC})" class="latex" src="https://s0.wp.com/latex.php?latex=R_%7BB%5Cto+A%2CB%7D%28%5Crho_%7BBC%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R_{B\to A,B}(\rho_{BC})"/> is <img alt="\epsilon'" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon'"/> -close to <img alt="\rho_{ABC}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho_%7BABC%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho_{ABC}"/> , i.e., low QCMI implies that the recovery map works well. This is trivial to prove classically, but very difficult in the quantum world.The algorithm in <a href="https://windowsontheory.org/feed/#brandao2">[9]</a> is very elegant. Essentially, we take the entire system and punch out constant-sized boxes. If we can reconstruct the region outside of the boxes, then we can use the recovery maps to reconstruct the regions inside of the boxes, and the boxes are far apart enough so they are almost independent. For this argument, we must assume that the QCMI decays exponentially. Whenever we have exponential decay, we get a correlation decay that sets the size of the boxes. It is very difficult to condition on quantum states, but recovery maps provide a sense in which it is meaningful to do so. The paper gives an efficient method of preparing Gibbs states and simulating quantum systems on quantum computers.</li></ol>



<h1 id="additional-reading">Additional reading</h1>



<p>The standard treatment of information theory is <a href="https://windowsontheory.org/feed/#info">[11]</a>. This book contains definitions and properties of entropy, conditional entropy, mutual information, and conditional mutual information.</p>



<p>To see a treatment of the subject of Markov chains from the perspective of probability theory, see <a href="https://windowsontheory.org/feed/#durrett1">[12]</a> or the mathematically more sophisticated counterpart <a href="https://windowsontheory.org/feed/#durrett2">[13]</a>. An introduction to coupling can be found in <a href="https://windowsontheory.org/feed/#mitzenmacher">[14]</a>, as well as <a href="https://windowsontheory.org/feed/#nature">[4]</a> (the latter also contains an exposition to spatial mixing). The connection between Markov chain mixing and the so-called <em>logarithmic Sobolev inequality</em> is described in <a href="https://windowsontheory.org/feed/#cesi">[15]</a>.</p>



<h1 id="scn:appendix">Appendix: Intuition for Markov chains</h1>



<h2 id="random-walk-on-the-cycle">Random walk on the cycle</h2>



<p>We have <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> points on the cycle, <img alt="0,1,\dotsc,n-1" class="latex" src="https://s0.wp.com/latex.php?latex=0%2C1%2C%5Cdotsc%2Cn-1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="0,1,\dotsc,n-1"/> . At each step, we move left or right with probability <img alt="1/2" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/2"/> . We can write the transition matrix as</p>



<p> <img alt="T = \frac{S + S^{-1}}{2}" class="latex" src="https://s0.wp.com/latex.php?latex=T+%3D+%5Cfrac%7BS+%2B+S%5E%7B-1%7D%7D%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T = \frac{S + S^{-1}}{2}"/> </p>



<p>where <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S"/> is the shift operator <img alt="S |{x}\rangle = |{x+1 \bmod n}\rangle " class="latex" src="https://s0.wp.com/latex.php?latex=S+%7C%7Bx%7D%5Crangle+%3D+%7C%7Bx%2B1+%5Cbmod+n%7D%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S |{x}\rangle = |{x+1 \bmod n}\rangle "/> . The matrix <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S"/> is diagonalized by the Fourier transform. Define, for <img alt="k=0,1,\dotsc,n-1" class="latex" src="https://s0.wp.com/latex.php?latex=k%3D0%2C1%2C%5Cdotsc%2Cn-1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k=0,1,\dotsc,n-1"/> ,</p>



<p> <img alt="|{\tilde k}\rangle = \frac{1}{\sqrt n} \sum_{x=0}^{n-1} \exp\Bigl( \frac{2\pi i k x}{n} \Bigr) |{x}\rangle " class="latex" src="https://s0.wp.com/latex.php?latex=%7C%7B%5Ctilde+k%7D%5Crangle+%3D+%5Cfrac%7B1%7D%7B%5Csqrt+n%7D+%5Csum_%7Bx%3D0%7D%5E%7Bn-1%7D+%5Cexp%5CBigl%28+%5Cfrac%7B2%5Cpi+i+k+x%7D%7Bn%7D+%5CBigr%29+%7C%7Bx%7D%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|{\tilde k}\rangle = \frac{1}{\sqrt n} \sum_{x=0}^{n-1} \exp\Bigl( \frac{2\pi i k x}{n} \Bigr) |{x}\rangle "/> </p>



<p>We have the same amount of amplitude at every point, but there is a varying phase which depends on <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/> . If <img alt="k = 0" class="latex" src="https://s0.wp.com/latex.php?latex=k+%3D+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k = 0"/> , we get the all-ones vector. If <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/> is small, then the phase is slowly varying. If <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/> is large, then the phase is rapidly varying. Look at what happens after we apply the shift operator:</p>



<p> <img alt="\begin{aligned} S |{\tilde k}\rangle &amp;= \frac{1}{\sqrt n} \sum_{x=0}^{n-1} \exp\Bigl( \frac{2\pi i k x}{n} \Bigr) |{x+1 \bmod n}\rangle \\ &amp;= \frac{1}{\sqrt n} \sum_{x=1}^n \exp\Bigl( \frac{2\pi i k (x-1)}{n} \Bigr) |{x \bmod n}\rangle = \exp\Bigl(- \frac{2\pi i k}{n} \Bigr) |{\tilde k}\rangle .\end{aligned} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+S+%7C%7B%5Ctilde+k%7D%5Crangle+%26%3D+%5Cfrac%7B1%7D%7B%5Csqrt+n%7D+%5Csum_%7Bx%3D0%7D%5E%7Bn-1%7D+%5Cexp%5CBigl%28+%5Cfrac%7B2%5Cpi+i+k+x%7D%7Bn%7D+%5CBigr%29+%7C%7Bx%2B1+%5Cbmod+n%7D%5Crangle+%5C%5C+%26%3D+%5Cfrac%7B1%7D%7B%5Csqrt+n%7D+%5Csum_%7Bx%3D1%7D%5En+%5Cexp%5CBigl%28+%5Cfrac%7B2%5Cpi+i+k+%28x-1%29%7D%7Bn%7D+%5CBigr%29+%7C%7Bx+%5Cbmod+n%7D%5Crangle+%3D+%5Cexp%5CBigl%28-+%5Cfrac%7B2%5Cpi+i+k%7D%7Bn%7D+%5CBigr%29+%7C%7B%5Ctilde+k%7D%5Crangle+.%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} S |{\tilde k}\rangle &amp;= \frac{1}{\sqrt n} \sum_{x=0}^{n-1} \exp\Bigl( \frac{2\pi i k x}{n} \Bigr) |{x+1 \bmod n}\rangle \\ &amp;= \frac{1}{\sqrt n} \sum_{x=1}^n \exp\Bigl( \frac{2\pi i k (x-1)}{n} \Bigr) |{x \bmod n}\rangle = \exp\Bigl(- \frac{2\pi i k}{n} \Bigr) |{\tilde k}\rangle .\end{aligned} "/> </p>



<p>After the shift, we pick up an additional phase based on how rapidly the phase is varying. From this, we get:</p>



<p> <img alt="\begin{aligned} T |{\tilde{k}}\rangle &amp;= \frac{\exp(2\pi i k / n) + \exp(-2\pi i k / n)}{2} |{\tilde{k}}\rangle = \cos\Bigl(\frac{2\pi k}{n}\Bigr) |{\tilde{k}}\rangle .\end{aligned} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+T+%7C%7B%5Ctilde%7Bk%7D%7D%5Crangle+%26%3D+%5Cfrac%7B%5Cexp%282%5Cpi+i+k+%2F+n%29+%2B+%5Cexp%28-2%5Cpi+i+k+%2F+n%29%7D%7B2%7D+%7C%7B%5Ctilde%7Bk%7D%7D%5Crangle+%3D+%5Ccos%5CBigl%28%5Cfrac%7B2%5Cpi+k%7D%7Bn%7D%5CBigr%29+%7C%7B%5Ctilde%7Bk%7D%7D%5Crangle+.%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} T |{\tilde{k}}\rangle &amp;= \frac{\exp(2\pi i k / n) + \exp(-2\pi i k / n)}{2} |{\tilde{k}}\rangle = \cos\Bigl(\frac{2\pi k}{n}\Bigr) |{\tilde{k}}\rangle .\end{aligned} "/> </p>



<p>The eigenvalues are</p>



<p> <img alt="\lambda_k = \cos \frac{2\pi k}{n}, \qquad k=0,1,\dotsc,n-1." class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda_k+%3D+%5Ccos+%5Cfrac%7B2%5Cpi+k%7D%7Bn%7D%2C+%5Cqquad+k%3D0%2C1%2C%5Cdotsc%2Cn-1.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda_k = \cos \frac{2\pi k}{n}, \qquad k=0,1,\dotsc,n-1."/> </p>



<p>Only <img alt="k = 0" class="latex" src="https://s0.wp.com/latex.php?latex=k+%3D+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k = 0"/> will give me an eigenvalue of <img alt="1" class="latex" src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1"/> .</p>



<p>How do we analyze <img alt="T^t |{p}\rangle " class="latex" src="https://s0.wp.com/latex.php?latex=T%5Et+%7C%7Bp%7D%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T^t |{p}\rangle "/> ? We should Fourier transform the distribution.</p>



<p> <img alt="\begin{aligned} T^t |{p}\rangle = T^t \sum_{k=0}^{n-1} p_k |{\tilde{k}}\rangle = \sum_{k=0}^{n-1} p_k \lambda_k^t |{\tilde k}\rangle .\end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+T%5Et+%7C%7Bp%7D%5Crangle+%3D+T%5Et+%5Csum_%7Bk%3D0%7D%5E%7Bn-1%7D+p_k+%7C%7B%5Ctilde%7Bk%7D%7D%5Crangle+%3D+%5Csum_%7Bk%3D0%7D%5E%7Bn-1%7D+p_k+%5Clambda_k%5Et+%7C%7B%5Ctilde+k%7D%5Crangle+.%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} T^t |{p}\rangle = T^t \sum_{k=0}^{n-1} p_k |{\tilde{k}}\rangle = \sum_{k=0}^{n-1} p_k \lambda_k^t |{\tilde k}\rangle .\end{aligned}"/> </p>



<p>If <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> is odd, then as <img alt="t\rightarrow\infty" class="latex" src="https://s0.wp.com/latex.php?latex=t%5Crightarrow%5Cinfty&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t\rightarrow\infty"/> , <img alt="\lambda_k^t \to 0" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda_k%5Et+%5Cto+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda_k^t \to 0"/> for all <img alt="k=1,\dotsc,n-1" class="latex" src="https://s0.wp.com/latex.php?latex=k%3D1%2C%5Cdotsc%2Cn-1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k=1,\dotsc,n-1"/> , so <img alt="T^t \to |{\pi}\rangle \langle{1_n}| " class="latex" src="https://s0.wp.com/latex.php?latex=T%5Et+%5Cto+%7C%7B%5Cpi%7D%5Crangle+%5Clangle%7B1_n%7D%7C+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T^t \to |{\pi}\rangle \langle{1_n}| "/> . Whatever you put into this operator, you get <img alt="\pi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\pi"/> out.</p>



<h2 id="spectral-gap">Spectral gap</h2>



<p>The example of the random walk on the cycle shows that there is generally a unique stationary distribution and suggests that the speed of convergence is determined by how close the other eigenvalues are to <img alt="1" class="latex" src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1"/> . Specifically, suppose for simplicity that the eigenvalues of <img alt="T" class="latex" src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T"/> are <img alt="1 = \lambda_0 \ge \lambda_1\ge\cdots \ge 0" class="latex" src="https://s0.wp.com/latex.php?latex=1+%3D+%5Clambda_0+%5Cge+%5Clambda_1%5Cge%5Ccdots+%5Cge+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1 = \lambda_0 \ge \lambda_1\ge\cdots \ge 0"/> (real and positive). Then, the convergence time is on the order of <img alt="\sim 1/(1-\lambda_1)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csim+1%2F%281-%5Clambda_1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sim 1/(1-\lambda_1)"/> .</p>



<p>Typically, the distance of the eigenvalues from <img alt="1" class="latex" src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1"/> reflects the size of the physical system. Even from the simple example, we can get some physical intuition from this. If <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/> is small, then the spectral gap is <img alt="\cos(2\pi k/n) = 1-O(k^2/n^2)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ccos%282%5Cpi+k%2Fn%29+%3D+1-O%28k%5E2%2Fn%5E2%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\cos(2\pi k/n) = 1-O(k^2/n^2)"/> . Thus, the convergence time is <img alt="\sim 1/(1-\lambda_1) \sim n^2" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csim+1%2F%281-%5Clambda_1%29+%5Csim+n%5E2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sim 1/(1-\lambda_1) \sim n^2"/> , which is indeed the convergence time for a random walk on a cycle.</p>



<h2 id="references">References</h2>



<hr class="wp-block-separator"/>



<ol><li>S. Gharibian, Y. Huang, Z. Landau, and S. W. Shin, “Quantum Hamiltonian complexity,” <em>Found. Trends Theor. Comput. Sci.</em>, vol. 10, no. 3, pp. front matter, 159–282, 2014. </li><li>R. W. Keener, <em>Theoretical statistics</em>. Springer, New York, 2010, p. xviii+538. </li><li>E. Crosson, D. Bacon, and K. R. Brown, “Making Classical Ground State Spin Computing Fault-Tolerant,” <em>Physical Review E</em>, vol. 82, no. 3, Sep. 2010. </li><li>C. Moore and S. Mertens, <em>The nature of computation</em>. Oxford University Press, Oxford, 2011, p. xviii+985. </li><li>F. Martinelli, “Lectures on Glauber dynamics for discrete spin models,” in <em>Lectures on probability theory and statistics (Saint-Flour, 1997)</em>, vol. 1717, Springer, Berlin, 1999, pp. 93–191. </li><li>F. Martinelli and E. Olivieri, “Finite volume mixing conditions for lattice spin systems and exponential approach to equilibrium of Glauber dynamics,” in <em>Cellular automata and cooperative systems (Les Houches, 1992)</em>, vol. 396, Kluwer Acad. Publ., Dordrecht, 1993, pp. 473–490. </li><li>M. S. Leifer and D. Poulin, “Quantum graphical models and belief propagation,” <em>Ann. Physics</em>, vol. 323, no. 8, pp. 1899–1946, 2008. </li><li>M. J. Kastoryano and F. G. S. L. Brandão, “Quantum Gibbs samplers: the commuting case,” <em>Comm. Math. Phys.</em>, vol. 344, no. 3, pp. 915–957, 2016. </li><li>F. G. S. L. Brandão and M. J. Kastoryano, “Finite correlation length implies efficient preparation of quantum thermal states,” <em>ArXiv e-prints</em>, Sep. 2016. </li><li>O. Fawzi and R. Renner, “Quantum conditional mutual information and approximate Markov chains,” <em>Comm. Math. Phys.</em>, vol. 340, no. 2, pp. 575–611, 2015. </li><li>T. M. Cover and J. A. Thomas, <em>Elements of information theory</em>, Second. Wiley-Interscience [John Wiley &amp; Sons], Hoboken, NJ, 2006, p. xxiv+748. </li><li>R. Durrett, <em>Essentials of stochastic processes</em>. Springer, Cham, 2016, p. ix+275. </li><li>R. Durrett, <em>Probability: theory and examples</em>, Fourth., vol. 31. Cambridge University Press, Cambridge, 2010, p. x+428. </li><li>M. Mitzenmacher and E. Upfal, <em>Probability and computing</em>, Second. Cambridge University Press, Cambridge, 2017, p. xx+467. </li><li>F. Cesi, “Quasi-factorization of the entropy and logarithmic Sobolev inequalities for Gibbs random fields,” <em>Probab. Theory Related Fields</em>, vol. 120, no. 4, pp. 569–584, 2001. </li></ol>



<hr class="wp-block-separator"/>



<ol><li>This is the opposite of the probabilists’ convention, i.e., the transition probability matrix that we define here is the <em>transpose</em> of the one usually found in most probability theory textbooks. <a href="https://windowsontheory.org/feed/#fnref_1"><img alt="&#x21A9;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/21a9.png" style="height: 1em;"/></a></li><li>As a side note, it may be a good research question to investigate to what extent quantum algorithms can be used to compute summations whose terms are possibly negative. In quantum Monte Carlo, the quantum Hamiltonian is converted to a classical energy function; this conversion always works, but sometimes you end up with complex energies, which is terrible for estimating the partition function because terms can cancel each other out. <a href="https://windowsontheory.org/feed/#fnref_2"><img alt="&#x21A9;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/21a9.png" style="height: 1em;"/></a></li><li>You may recognize this as the total variation norm. <a href="https://windowsontheory.org/feed/#fnref_3"><img alt="&#x21A9;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/21a9.png" style="height: 1em;"/></a></li><li>Petz wrote about quantum relative entropy in 1991, way before it was cool. <a href="https://windowsontheory.org/feed/#fnref_4"><img alt="&#x21A9;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/21a9.png" style="height: 1em;"/></a></li></ol></div>
    </content>
    <updated>2018-12-20T21:57:08Z</updated>
    <published>2018-12-20T21:57:08Z</published>
    <category term="Uncategorized"/>
    <category term="physics"/>
    <author>
      <name>wsmoses</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2019-01-07T23:33:02Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=6778</id>
    <link href="https://windowsontheory.org/2018/12/20/theory-blog-aggregator-up/" rel="alternate" type="text/html"/>
    <title>Theory Blog Aggregator Up!</title>
    <summary>The Theory of Computing Blog Aggregator is now back online at a new website: http://cstheory-feed.org/ . There is also a twitter feed at https://twitter.com/cstheory . See this blog post by Suresh Venkatasubramanian (who, together with Arnab Bhattacharyya, is responsible for the aggregator’s revival – thank you!!) for more details. This is a good opportunity to […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The <strong>Theory of Computing Blog Aggregator</strong> is now back online at a new website: <a href="http://cstheory-feed.org/" rel="nofollow">http://cstheory-feed.org/</a> . There is also a twitter feed at <a href="https://twitter.com/cstheory" rel="nofollow">https://twitter.com/cstheory</a> .</p>
<p>See <a href="http://blog.geomblog.org/2018/12/the-theorycs-blog-aggregator-reborn.html">this blog post</a> by Suresh Venkatasubramanian (who, together with Arnab Bhattacharyya, is responsible for the aggregator’s revival – thank you!!) for more details. This is a good opportunity to thank Arvind Narayanan who created the software to run it and maintained it all these years.</p>
<p>If you don’t want to rely on the aggregator to follow windows on theory, you can use the <strong>“Follow Blog by email”</strong> button on our side bar, and join the 590 other happy customers who don’t need to wait to the feed to get the <a href="https://windowsontheory.org/category/physics/">latest lecture notes</a> from our physics and computation seminar.</p></div>
    </content>
    <updated>2018-12-20T21:50:02Z</updated>
    <published>2018-12-20T21:50:02Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>windowsontheory</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2019-01-07T23:33:03Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=6358</id>
    <link href="https://windowsontheory.org/2018/12/20/quantum-hamiltonian-complexity/" rel="alternate" type="text/html"/>
    <title>What is Quantum Hamiltonian Complexity?</title>
    <summary>by Ben Edelman This is the first installment of a three-part series of posts on quantum Hamiltonian complexity based on lectures given the authors in Boaz and Tselil’s seminar. The second installment is here, and the third installment is here. Quantum Hamiltonian complexity is a growing area of study that has important ramifications for both […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><strong>by Ben Edelman</strong></p>
<p><em>This is the first installment of a three-part series of posts on quantum Hamiltonian complexity based on lectures given the authors in <a href="https://www.boazbarak.org/fall18seminar/">Boaz and Tselil’s seminar</a>. The second installment is <a href="https://windowsontheory.org/2018/12/20/tensor-networks-matrix-product-states-dmrg/">here</a>, and the third installment is <a href="https://windowsontheory.org/2018/12/18/a-1d-area-law-for-gapped-local-hamiltonians/">here</a>.</em></p>
<p>Quantum Hamiltonian complexity is a growing area of study that has important ramifications for both physics and computation. Our hope is that these three posts will provide an accessible (and incomplete) preview of the subject for readers who know the basics of theoretical computer science and quantum information. Much of the material is adapted from an <a href="https://arxiv.org/abs/1401.3916">excellent survey by Gharibian et al.</a>.</p>
<p>In a nutshell, quantum Hamiltonian complexity is the study of the <em>local Hamiltonian problem</em>. Why is this problem important enough to justify the existence of an entire subfield? To illustrate why, here are two informal characterizations of it:</p>
<ol>
<li>To a <strong>physicist</strong>, the local Hamiltonian problem is a formalization of the difficulty of simulating and understanding many-particle quantum systems. There are deep connections between the complexity of this problem and the amount of quantum entanglement in a system. In practical terms, physicists would love to be able to solve this problem on a regular basis, and they’ve developed a rich theory of heuristics to that end.</li>
<li>To a <strong>computer scientist</strong>, local Hamiltonian problem is the quantum version of constraint satisfaction problems. Any CSP can be written as a local Hamiltonian problem; and just as constraint satisfaction is the prototypical NP-complete problem by the Cook-Levin theorem, the local Hamiltonian problem plays the equivalent role for QMA (a quantum analogue of NP) by the “quantum Cook-Levin theorem.” The connections to classical complexity go on… there is even a <a href="https://arxiv.org/pdf/1309.7495.pdf">quantum PCP conjecture</a>!</li>
</ol>
<p>But let’s take a step back and start at the beginning. To make sure we understand what a quantum Hamiltonian is and why it is important, it will be instructive to briefly rehash some of the <a href="https://windowsontheory.org/2018/09/15/statistical-physics-an-introduction-in-two-parts/">fundamentals of classical statistical mechanics</a>.</p>
<h2>Classical energy and ground states</h2>
<p>In the classical world, a physical system can be in any one of various states <img alt="x \in \mathcal{X}" class="latex" src="https://s0.wp.com/latex.php?latex=x+%5Cin+%5Cmathcal%7BX%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x \in \mathcal{X}"/>, each of which is a vector, with different coordinates representing different particles. Every state of the system has an <em>energy</em>, given by an energy function <img alt="E: \mathcal{X} \to \mathbb{R}" class="latex" src="https://s0.wp.com/latex.php?latex=E%3A+%5Cmathcal%7BX%7D+%5Cto+%5Cmathbb%7BR%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="E: \mathcal{X} \to \mathbb{R}"/>. For example, in the classic Ising model of ferromagnetism, <img alt="\mathcal{X} = \{\pm 1\}^n" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BX%7D+%3D+%5C%7B%5Cpm+1%5C%7D%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{X} = \{\pm 1\}^n"/>. Each coordinate <img alt="x_i" class="latex" src="https://s0.wp.com/latex.php?latex=x_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_i"/> represents the spin of atom <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/>, and atoms <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/> and <img alt="j" class="latex" src="https://s0.wp.com/latex.php?latex=j&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="j"/> interact with each other whenever <img alt="(i,j)" class="latex" src="https://s0.wp.com/latex.php?latex=%28i%2Cj%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(i,j)"/> is an edge in a graph <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/>, which is usually a low-dimensional lattice. Energy for this system is defined as <img alt="E(x) = \sum_{(i,j) \in G}-x_i x_j" class="latex" src="https://s0.wp.com/latex.php?latex=E%28x%29+%3D+%5Csum_%7B%28i%2Cj%29+%5Cin+G%7D-x_i+x_j&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="E(x) = \sum_{(i,j) \in G}-x_i x_j"/>.</p>
<p>Suppose we ignore our system for a long time, letting it interact with its external environment until, in the limit, it reaches thermal equilibrium at temperature <img alt="T" class="latex" src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T"/>. Then the probability the system is in state <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/> is given by Boltzmann’s distribution: <img alt="\Pr[x] = \frac{e^{-\beta E(x)}}{Z}" class="latex" src="https://s0.wp.com/latex.php?latex=%5CPr%5Bx%5D+%3D+%5Cfrac%7Be%5E%7B-%5Cbeta+E%28x%29%7D%7D%7BZ%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Pr[x] = \frac{e^{-\beta E(x)}}{Z}"/>, where <img alt="\beta \propto 1/T" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbeta+%5Cpropto+1%2FT&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\beta \propto 1/T"/> and <img alt="Z" class="latex" src="https://s0.wp.com/latex.php?latex=Z&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Z"/> is the partition function required to normalize the probabilities. As the temperature tends to infinity, this distribution will approach the uniform distribution over <img alt="\mathcal{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BX%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{X}"/>, and as the temperature tends to absolute zero, the distribution will approach the uniform distribution over the states with minimum energy. We call these minimum energy states <em>ground states</em>, and we call their energy the <em>ground state energy</em>. If we want to calculate something about a system, then it is often crucial to know the ground states and ground state energy of the system. Going back to our example, the Ising model has two ground states whenever <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/> is connected. These are the states <img alt="(+1,+1,\ldots,+1)" class="latex" src="https://s0.wp.com/latex.php?latex=%28%2B1%2C%2B1%2C%5Cldots%2C%2B1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(+1,+1,\ldots,+1)"/> and <img alt="(-1,-1,\ldots,-1)" class="latex" src="https://s0.wp.com/latex.php?latex=%28-1%2C-1%2C%5Cldots%2C-1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(-1,-1,\ldots,-1)"/> in which all atoms have the same spin. The ground state energy is <img alt="-|\{i,j:(i,j) \in G\}|" class="latex" src="https://s0.wp.com/latex.php?latex=-%7C%5C%7Bi%2Cj%3A%28i%2Cj%29+%5Cin+G%5C%7D%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="-|\{i,j:(i,j) \in G\}|"/>.</p>
<h2>Quantum Hamiltonians</h2>
<p>A quantum Hamiltonian is essentially the quantum analogue of the classical energy function. Unlike with classical systems, when a quantum system is in a given <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>-qubit state <img alt="\left|\psi\right\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cleft%7C%5Cpsi%5Cright%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\left|\psi\right\rangle"/>, it doesn’t have a determinate energy. Instead, when we measure the energy, the value we obtain may be probabilistic and will correspond to one of the eigenvalues of the observable matrix for energy. This Hermitian matrix, denoted <img alt="H \in (\mathbb{C}^2)^{\otimes n} \times (\mathbb{C}^2)^{\otimes n}" class="latex" src="https://s0.wp.com/latex.php?latex=H+%5Cin+%28%5Cmathbb%7BC%7D%5E2%29%5E%7B%5Cotimes+n%7D+%5Ctimes+%28%5Cmathbb%7BC%7D%5E2%29%5E%7B%5Cotimes+n%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H \in (\mathbb{C}^2)^{\otimes n} \times (\mathbb{C}^2)^{\otimes n}"/>, is the quantum Hamiltonian, and just as the energy function characterizes a classical system, the Hamiltonian characterizes a quantum system. For a given eigenvector <img alt="|\lambda_i\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Clambda_i%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\lambda_i\rangle"/> of <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> with eigenvalue <img alt="\lambda_i" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda_i"/>, when we measure the energy of <img alt="|\psi\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi\rangle"/> we obtain the result <img alt="\lambda_i" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda_i"/> with probability <img alt="\langle\psi|\lambda_i\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clangle%5Cpsi%7C%5Clambda_i%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\langle\psi|\lambda_i\rangle"/>, and the system collapses to the state <img alt="|\lambda_i\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Clambda_i%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\lambda_i\rangle"/> (assuming the eigenvalue <img alt="\lambda_i" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda_i"/> has multiplicity 1). Thus, the ground state and ground state energy of a quantum system with eigenvalue <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> are the minimum eigenvalue <img alt="\lambda_0" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda_0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda_0"/> of <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> and the corresponding eigenvector <img alt="|\lambda_0\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Clambda_0%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\lambda_0\rangle"/>.</p>
<p>The Boltzmann distribution also has a quantum analogue. A quantum system at thermal equilibrium will be in the following mixed state: <img alt="\rho_{\text{eq}} = \frac{e^{-\beta H}}{Z}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho_%7B%5Ctext%7Beq%7D%7D+%3D+%5Cfrac%7Be%5E%7B-%5Cbeta+H%7D%7D%7BZ%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho_{\text{eq}} = \frac{e^{-\beta H}}{Z}"/>. As the temperature approaches absolute zero, <img alt="\rho_{\text{eq}}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho_%7B%5Ctext%7Beq%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho_{\text{eq}}"/> will approach a superposition over the ground states.</p>
<p>Not only does the Hamiltonian tell us the energy of a system, it also describes the time evolution of the system (as long as it is closed). Schrödinger’s equation states that <img alt="-i \hbar \frac{d|\psi\rangle}{dt} = H|\psi\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=-i+%5Chbar+%5Cfrac%7Bd%7C%5Cpsi%5Crangle%7D%7Bdt%7D+%3D+H%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="-i \hbar \frac{d|\psi\rangle}{dt} = H|\psi\rangle"/>, where <img alt="\hbar" class="latex" src="https://s0.wp.com/latex.php?latex=%5Chbar&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\hbar"/> is Planck’s constant and <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t"/> is time. Thus, if a closed system is in the state <img alt="|\psi\rangle_0" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle_0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi\rangle_0"/> at time 0, its state at time <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t"/> will be <img alt="|\psi\rangle_t = e^{-itH/\hbar}|\psi\rangle_0" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle_t+%3D+e%5E%7B-itH%2F%5Chbar%7D%7C%5Cpsi%5Crangle_0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi\rangle_t = e^{-itH/\hbar}|\psi\rangle_0"/>. Since <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> is Hermitian, <img alt="e^{-itH/\hbar}" class="latex" src="https://s0.wp.com/latex.php?latex=e%5E%7B-itH%2F%5Chbar%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="e^{-itH/\hbar}"/> is unitary, which is another way of saying that quantum mechanical states are subject to unitary evolution.</p>
<h1>The Local Hamiltonian problem</h1>
<p>As we have seen, understanding the Hamiltonian of a quantum system is crucial for understanding both the system’s equilibrium behavior and its time evolution. There are a huge variety of questions physicists are interested in asking about systems, all of which boil down to questions about equilibrium behavior, time evolution, or both. There is a single problem that captures the complexity of many of these questions, in the sense that most of the questions can’t be answered without solving it. This is the problem of estimating the ground state energy of the Hamiltonian. Especially in condensed matter physics, this problem is ubiquitous.</p>
<p>Formally, we will study the following promise problem: (note: this will not be our final formulation)</p>
<hr/>
<p><strong>The “Hamiltonian Problem”</strong></p>
<p>Given a Hermitian matrix <img alt="H \in (\mathbb{C}^2)^{\otimes n} \times (\mathbb{C}^2)^{\otimes n}" class="latex" src="https://s0.wp.com/latex.php?latex=H+%5Cin+%28%5Cmathbb%7BC%7D%5E2%29%5E%7B%5Cotimes+n%7D+%5Ctimes+%28%5Cmathbb%7BC%7D%5E2%29%5E%7B%5Cotimes+n%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H \in (\mathbb{C}^2)^{\otimes n} \times (\mathbb{C}^2)^{\otimes n}"/> and non-negative reals <img alt="a, b" class="latex" src="https://s0.wp.com/latex.php?latex=a%2C+b&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a, b"/> with <img alt="b \geq a+1" class="latex" src="https://s0.wp.com/latex.php?latex=b+%5Cgeq+a%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="b \geq a+1"/>,</p>
<ul>
<li>If <img alt="\lambda_0(H) \leq a" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda_0%28H%29+%5Cleq+a&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda_0(H) \leq a"/>, output YES<p/>
</li>
<li>
<p>If <img alt="\lambda_0(H) \geq b" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda_0%28H%29+%5Cgeq+b&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda_0(H) \geq b"/>, output NO</p>
</li>
</ul>
<hr/>
<p>One issue with this definition is that the input includes an enormous <img alt="2^n \times 2^n" class="latex" src="https://s0.wp.com/latex.php?latex=2%5En+%5Ctimes+2%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^n \times 2^n"/> matrix. For a reasonable-sized system, there’d be no use in even trying to solve this problem through classical computation, and how to deal with it in the quantum computing setting is far from obvious. Luckily, physicists have found that in real-life systems, interactions tend to be <em>local</em>, and if we consider the special case of <em>local Hamiltonians</em>, the input for the problem is of reasonable size.</p>
<p/><div class="wp-caption aligncenter" id="attachment_6361" style="width: 295px;"><img alt="circle_diagram0" class="aligncenter size-medium wp-image-6361" height="300" src="https://windowsontheory.files.wordpress.com/2018/12/circle_diagram0.png?w=285&amp;h=300" width="285"/><p class="wp-caption-text">Hamiltonians are too big to work with. What if we restrict our focus to local Hamiltonians?</p></div><p/>
<p>A <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-local Hamiltonian is a Hamiltonian that is decomposed into a sum of terms, each of which represents a Hamiltonian acting on a <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-unit subset of the <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> qubits in the system. In other words, <img alt="H = \sum_i (H_i)_{S_i} \otimes I_{[n]\backslash S_i}" class="latex" src="https://s0.wp.com/latex.php?latex=H+%3D+%5Csum_i+%28H_i%29_%7BS_i%7D+%5Cotimes+I_%7B%5Bn%5D%5Cbackslash+S_i%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H = \sum_i (H_i)_{S_i} \otimes I_{[n]\backslash S_i}"/>, where each <img alt="S_i" class="latex" src="https://s0.wp.com/latex.php?latex=S_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S_i"/> is a subset of <img alt="[n]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Bn%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="[n]"/> of size <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>. For brevity’s sake, we abuse notation and write <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> as <img alt="\sum_i H_i" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csum_i+H_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sum_i H_i"/>. We can think of the <img alt="H_i" class="latex" src="https://s0.wp.com/latex.php?latex=H_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H_i"/>’s as local constraints, and the ground state as the state that simultaneously satisfies the constraints to the maximal possible extent. Here, then, is the new-and-improved problem definition:</p>
<hr/>
<p><strong><img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-Local Hamiltonian Problem</strong></p>
<p>Given a Hamiltonian <img alt="H \in (\mathbb{C}^2)^{\otimes n} \times (\mathbb{C}^2)^{\otimes n}" class="latex" src="https://s0.wp.com/latex.php?latex=H+%5Cin+%28%5Cmathbb%7BC%7D%5E2%29%5E%7B%5Cotimes+n%7D+%5Ctimes+%28%5Cmathbb%7BC%7D%5E2%29%5E%7B%5Cotimes+n%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H \in (\mathbb{C}^2)^{\otimes n} \times (\mathbb{C}^2)^{\otimes n}"/> specified as a collection of <img alt="r" class="latex" src="https://s0.wp.com/latex.php?latex=r&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="r"/> local interactions <img alt="\{H_i\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7BH_i%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{H_i\}"/>, and non-negative reals <img alt="a, b" class="latex" src="https://s0.wp.com/latex.php?latex=a%2C+b&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a, b"/> with <img alt="b \geq a+1" class="latex" src="https://s0.wp.com/latex.php?latex=b+%5Cgeq+a%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="b \geq a+1"/>,</p>
<ul>
<li>If <img alt="\lambda_0(H) \leq a" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda_0%28H%29+%5Cleq+a&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda_0(H) \leq a"/>, output YES</li>
<li>If <img alt="\lambda_0(H) \geq b" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda_0%28H%29+%5Cgeq+b&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda_0(H) \geq b"/>, output NO</li>
</ul>
<hr/>
<p>Presuming the matrices <img alt="\{H_i\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7BH_i%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{H_i\}"/> and the reals <img alt="a, b" class="latex" src="https://s0.wp.com/latex.php?latex=a%2C+b&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a, b"/> are specified to polynomial precision, then the input size is polynomial in <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>, since <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/> is a constant and each of the matrices <img alt="H_i" class="latex" src="https://s0.wp.com/latex.php?latex=H_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H_i"/> has <img alt="2^k \cdot 2^k" class="latex" src="https://s0.wp.com/latex.php?latex=2%5Ek+%5Ccdot+2%5Ek&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^k \cdot 2^k"/> entries. Thus, not only is our new problem physically realistic, it is also a problem we might hope to attack with classical computation. However, we will later see that in fact this problem is likely hard even for quantum computers. The remaining installments in this series of notes will deal with further restrictions of the class of Hamiltonians for which the local Hamiltonian problem may be tractable.</p>
<h2>Computer science motivation</h2>
<p>As we mentioned in the intro, the <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-local Hamiltonian problem (henceforth denoted <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-LH) doesn’t just have myriad applications in physics—it is also important from a computer science perspective because it is a quantum generalization of constraint satisfiability (you may have noticed that quantum analogues of classical concepts are a running theme). Specifically, <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-CSP is a special case of <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-LH.</p>
<p>Suppose we have a <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-CSP instance <img alt="\varphi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cvarphi&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\varphi"/>, and we want to turn it into a <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-LH instance. A clause <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/> with constituent variables <img alt="x_1, \ldots, x_k" class="latex" src="https://s0.wp.com/latex.php?latex=x_1%2C+%5Cldots%2C+x_k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_1, \ldots, x_k"/> becomes a <img alt="2^k \times 2^k" class="latex" src="https://s0.wp.com/latex.php?latex=2%5Ek+%5Ctimes+2%5Ek&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^k \times 2^k"/> diagonal <img alt="\{0,1\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{0,1\}"/> matrix <img alt="H_C" class="latex" src="https://s0.wp.com/latex.php?latex=H_C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H_C"/> acting on the qubits <img alt="|x_1\rangle,\ldots,|x_k\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7Cx_1%5Crangle%2C%5Cldots%2C%7Cx_k%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|x_1\rangle,\ldots,|x_k\rangle"/>. Note that the rows and columns of this matrix are indexed by the assignment vectors <img alt="x \in \{0,1\}^k" class="latex" src="https://s0.wp.com/latex.php?latex=x+%5Cin+%5C%7B0%2C1%5C%7D%5Ek&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x \in \{0,1\}^k"/>. Formally, <img alt="H_C" class="latex" src="https://s0.wp.com/latex.php?latex=H_C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H_C"/> encodes the truth table of <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/> in the following manner: <img alt="(H_C)_{x,x} = 1 - C(x)" class="latex" src="https://s0.wp.com/latex.php?latex=%28H_C%29_%7Bx%2Cx%7D+%3D+1+-+C%28x%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(H_C)_{x,x} = 1 - C(x)"/>. Another way of stating this is <img alt="H_C = \sum_{x \in \{0,1\}^k\text{ s.t. }C(x)=0}|x\rangle\langle{x}|" class="latex" src="https://s0.wp.com/latex.php?latex=H_C+%3D+%5Csum_%7Bx+%5Cin+%5C%7B0%2C1%5C%7D%5Ek%5Ctext%7B+s.t.+%7DC%28x%29%3D0%7D%7Cx%5Crangle%5Clangle%7Bx%7D%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H_C = \sum_{x \in \{0,1\}^k\text{ s.t. }C(x)=0}|x\rangle\langle{x}|"/>.</p>
<p>Informally, <img alt="H_C" class="latex" src="https://s0.wp.com/latex.php?latex=H_C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H_C"/> takes the clauses of <img alt="\varphi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cvarphi&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\varphi"/> and turns them into local quantum interactions. We’ve constructed <img alt="H_C" class="latex" src="https://s0.wp.com/latex.php?latex=H_C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H_C"/> so that it has two eigenvalues: 0 and 1. The eigenspace corresponding to 0 is spanned by the set of computational basis vectors <img alt="|x\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7Cx%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|x\rangle"/> that satisfy <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/>, and the eigenspace corresponding to 1 is spanned by the computational basis vectors that don’t satisfy <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/>. In effect, when we consider <img alt="H_C" class="latex" src="https://s0.wp.com/latex.php?latex=H_C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H_C"/> as a term of <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/>, we are giving an energy penalty to any variable assignment that doesn’t satisfy <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/>. <img alt="H = \sum_{C}H_C" class="latex" src="https://s0.wp.com/latex.php?latex=H+%3D+%5Csum_%7BC%7DH_C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H = \sum_{C}H_C"/> will have the eigenvalue 0 (in other words, a ground state energy of 0) if and only if there is some assignment of the variables <img alt="x_1,\ldots,x_n" class="latex" src="https://s0.wp.com/latex.php?latex=x_1%2C%5Cldots%2Cx_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_1,\ldots,x_n"/> that satisfies all of the clauses (in other words, iff <img alt="\varphi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cvarphi&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\varphi"/> is satisfiable). Otherwise, the ground state energy of <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> will be at least 1, so determining whether <img alt="\varphi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cvarphi&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\varphi"/> is satisfiable is equivalent to solving <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-LH with inputs <img alt="a = 0" class="latex" src="https://s0.wp.com/latex.php?latex=a+%3D+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a = 0"/>, and <img alt="b = 1" class="latex" src="https://s0.wp.com/latex.php?latex=b+%3D+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="b = 1"/>. (In fact, <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-LH generalizes MAX-<img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-CSP, since the ground state energy of <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> is exactly the number of clauses minus the maximum number of satisfiable clauses.)</p>
<p><span id="more-6358"/></p>
<p><!--more--></p>
<p><!--more--></p>
<p>Let’s work through an example. Consider the following 2-SAT formula:</p>
<p><img alt="\varphi(x_1,x_2,x_3) = (x_1 \vee x_2) \wedge (\overline{x_1} \vee x_3)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cvarphi%28x_1%2Cx_2%2Cx_3%29+%3D+%28x_1+%5Cvee+x_2%29+%5Cwedge+%28%5Coverline%7Bx_1%7D+%5Cvee+x_3%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\varphi(x_1,x_2,x_3) = (x_1 \vee x_2) \wedge (\overline{x_1} \vee x_3)"/></p>
<p>The truth table for the first clause <img alt="C_1 = (x_1 \vee x_2)" class="latex" src="https://s0.wp.com/latex.php?latex=C_1+%3D+%28x_1+%5Cvee+x_2%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_1 = (x_1 \vee x_2)"/> is:</p>
<table>
<tbody>
<tr>
<th style="text-align: center;"> <img alt="x_1" class="latex" src="https://s0.wp.com/latex.php?latex=x_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_1"/></th>
<th style="text-align: center;"> <img alt="x_2" class="latex" src="https://s0.wp.com/latex.php?latex=x_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_2"/></th>
<th style="text-align: center;"> <img alt="x_1 \vee x_2" class="latex" src="https://s0.wp.com/latex.php?latex=x_1+%5Cvee+x_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_1 \vee x_2"/></th>
</tr>
<tr>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
</tr>
<tr>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
</tr>
<tr>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
</tr>
<tr>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
</tr>
</tbody>
</table>
<p>So <img alt="H_1" class="latex" src="https://s0.wp.com/latex.php?latex=H_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H_1"/> is the following matrix:</p>
<p><img alt="H_1 = \begin{pmatrix} 1 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 \end{pmatrix}" class="latex" src="https://s0.wp.com/latex.php?latex=H_1+%3D+%5Cbegin%7Bpmatrix%7D+1+%26+0+%26+0+%26+0+%5C%5C+0+%26+0+%26+0+%26+0+%5C%5C+0+%26+0+%26+0+%26+0+%5C%5C+0+%26+0+%26+0+%26+0+%5Cend%7Bpmatrix%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H_1 = \begin{pmatrix} 1 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 \end{pmatrix}"/></p>
<p>We also have</p>
<p><img alt="H_2 = \begin{pmatrix} 0 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 \end{pmatrix}" class="latex" src="https://s0.wp.com/latex.php?latex=H_2+%3D+%5Cbegin%7Bpmatrix%7D+0+%26+0+%26+0+%26+0+%5C%5C+0+%26+0+%26+0+%26+0+%5C%5C+0+%26+0+%26+1+%26+0+%5C%5C+0+%26+0+%26+0+%26+0+%5Cend%7Bpmatrix%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H_2 = \begin{pmatrix} 0 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 \end{pmatrix}"/></p>
<p>Then,<br/>
<img alt="\begin{aligned} H &amp;= (H_1)_{1,2} \otimes I_{3} + (H_2)_{1,3} \otimes I_{2} \\ &amp;= \begin{pmatrix} 1&amp;&amp;&amp;&amp;&amp;&amp;&amp; \\ &amp;1&amp;&amp;&amp;&amp;&amp;&amp; \\ &amp;&amp;0&amp;&amp;&amp;&amp;&amp; \\ &amp;&amp;&amp;0&amp;&amp;&amp;&amp; \\ &amp;&amp;&amp;&amp;0&amp;&amp;&amp; \\ &amp;&amp;&amp;&amp;&amp;0&amp;&amp; \\ &amp;&amp;&amp;&amp;&amp;&amp;0&amp; \\ &amp;&amp;&amp;&amp;&amp;&amp;&amp;0 \end{pmatrix} + \begin{pmatrix} 0&amp;&amp;&amp;&amp;&amp;&amp;&amp; \\ &amp;0&amp;&amp;&amp;&amp;&amp;&amp; \\ &amp;&amp;0&amp;&amp;&amp;&amp;&amp; \\ &amp;&amp;&amp;0&amp;&amp;&amp;&amp; \\ &amp;&amp;&amp;&amp;1&amp;&amp;&amp; \\ &amp;&amp;&amp;&amp;&amp;0&amp;&amp; \\ &amp;&amp;&amp;&amp;&amp;&amp;1&amp; \\ &amp;&amp;&amp;&amp;&amp;&amp;&amp;0 \end{pmatrix} \\ &amp;= \begin{pmatrix} 1&amp;&amp;&amp;&amp;&amp;&amp;&amp; \\ &amp;1&amp;&amp;&amp;&amp;&amp;&amp; \\ &amp;&amp;0&amp;&amp;&amp;&amp;&amp; \\ &amp;&amp;&amp;0&amp;&amp;&amp;&amp; \\ &amp;&amp;&amp;&amp;1&amp;&amp;&amp; \\ &amp;&amp;&amp;&amp;&amp;0&amp;&amp; \\ &amp;&amp;&amp;&amp;&amp;&amp;1&amp; \\ &amp;&amp;&amp;&amp;&amp;&amp;&amp;0 \end{pmatrix}\end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+H+%26%3D+%28H_1%29_%7B1%2C2%7D+%5Cotimes+I_%7B3%7D+%2B+%28H_2%29_%7B1%2C3%7D+%5Cotimes+I_%7B2%7D+%5C%5C+%26%3D+%5Cbegin%7Bpmatrix%7D+1%26%26%26%26%26%26%26+%5C%5C+%261%26%26%26%26%26%26+%5C%5C+%26%260%26%26%26%26%26+%5C%5C+%26%26%260%26%26%26%26+%5C%5C+%26%26%26%260%26%26%26+%5C%5C+%26%26%26%26%260%26%26+%5C%5C+%26%26%26%26%26%260%26+%5C%5C+%26%26%26%26%26%26%260+%5Cend%7Bpmatrix%7D+%2B+%5Cbegin%7Bpmatrix%7D+0%26%26%26%26%26%26%26+%5C%5C+%260%26%26%26%26%26%26+%5C%5C+%26%260%26%26%26%26%26+%5C%5C+%26%26%260%26%26%26%26+%5C%5C+%26%26%26%261%26%26%26+%5C%5C+%26%26%26%26%260%26%26+%5C%5C+%26%26%26%26%26%261%26+%5C%5C+%26%26%26%26%26%26%260+%5Cend%7Bpmatrix%7D+%5C%5C+%26%3D+%5Cbegin%7Bpmatrix%7D+1%26%26%26%26%26%26%26+%5C%5C+%261%26%26%26%26%26%26+%5C%5C+%26%260%26%26%26%26%26+%5C%5C+%26%26%260%26%26%26%26+%5C%5C+%26%26%26%261%26%26%26+%5C%5C+%26%26%26%26%260%26%26+%5C%5C+%26%26%26%26%26%261%26+%5C%5C+%26%26%26%26%26%26%260+%5Cend%7Bpmatrix%7D%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} H &amp;= (H_1)_{1,2} \otimes I_{3} + (H_2)_{1,3} \otimes I_{2} \\ &amp;= \begin{pmatrix} 1&amp;&amp;&amp;&amp;&amp;&amp;&amp; \\ &amp;1&amp;&amp;&amp;&amp;&amp;&amp; \\ &amp;&amp;0&amp;&amp;&amp;&amp;&amp; \\ &amp;&amp;&amp;0&amp;&amp;&amp;&amp; \\ &amp;&amp;&amp;&amp;0&amp;&amp;&amp; \\ &amp;&amp;&amp;&amp;&amp;0&amp;&amp; \\ &amp;&amp;&amp;&amp;&amp;&amp;0&amp; \\ &amp;&amp;&amp;&amp;&amp;&amp;&amp;0 \end{pmatrix} + \begin{pmatrix} 0&amp;&amp;&amp;&amp;&amp;&amp;&amp; \\ &amp;0&amp;&amp;&amp;&amp;&amp;&amp; \\ &amp;&amp;0&amp;&amp;&amp;&amp;&amp; \\ &amp;&amp;&amp;0&amp;&amp;&amp;&amp; \\ &amp;&amp;&amp;&amp;1&amp;&amp;&amp; \\ &amp;&amp;&amp;&amp;&amp;0&amp;&amp; \\ &amp;&amp;&amp;&amp;&amp;&amp;1&amp; \\ &amp;&amp;&amp;&amp;&amp;&amp;&amp;0 \end{pmatrix} \\ &amp;= \begin{pmatrix} 1&amp;&amp;&amp;&amp;&amp;&amp;&amp; \\ &amp;1&amp;&amp;&amp;&amp;&amp;&amp; \\ &amp;&amp;0&amp;&amp;&amp;&amp;&amp; \\ &amp;&amp;&amp;0&amp;&amp;&amp;&amp; \\ &amp;&amp;&amp;&amp;1&amp;&amp;&amp; \\ &amp;&amp;&amp;&amp;&amp;0&amp;&amp; \\ &amp;&amp;&amp;&amp;&amp;&amp;1&amp; \\ &amp;&amp;&amp;&amp;&amp;&amp;&amp;0 \end{pmatrix}\end{aligned}"/></p>
<p><img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> has diagonal entries that are zero, so it has 0 as an eigenvalue. We can therefore conclude that <img alt="\varphi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cvarphi&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\varphi"/> is satisfiable. (In this example it was easy to write out <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> and see that it has zeros on the diagonal, but when <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> is large, <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> becomes exponentially big, so we can’t just compute it explicitly and look through its diagonal entries.)</p>
<h1>Quantum Cook-Levin Theorem</h1>
<p>We’ve seen that any <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-CSP problem can be thought of as a <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-LH problem (with a diagonal Hamiltonian matrix). And the analogy can be drawn even further. One reason <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-CSP is so useful is that it (and in particular 3-SAT) is NP-complete, according to the Cook-Levin Theorem. 3-SAT captures the difficulty of classical efficiently verifiable computation. It may not come as a surprise, then, that <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-LH captures the difficulty of <em>quantum</em> efficiently verifiable computation. This result is the “quantum Cook-Levin theorem”, but before we see it we need to define the complexity class QMA, the quantum analogue of NP.</p>
<p>Because quantum computation is probabilistic, QMA is more precisely the quantum analogue of MA (Merlin Arthur), which allows the verifier to have a chance of error:</p>
<hr/>
<p><strong>MA</strong></p>
<p><img alt="L \in \text{MA}" class="latex" src="https://s0.wp.com/latex.php?latex=L+%5Cin+%5Ctext%7BMA%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="L \in \text{MA}"/> iff there exists a probabilistic poly-time verifier <img alt="V" class="latex" src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="V"/> and a polynomial <img alt="p(n)" class="latex" src="https://s0.wp.com/latex.php?latex=p%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p(n)"/> such that</p>
<ul>
<li><img alt="\forall x \in L, \exists y \in \{0,1\}^{p(n)},\quad \Pr[V(x,y) = 1] \geq \frac{2}{3}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cforall+x+%5Cin+L%2C+%5Cexists+y+%5Cin+%5C%7B0%2C1%5C%7D%5E%7Bp%28n%29%7D%2C%5Cquad+%5CPr%5BV%28x%2Cy%29+%3D+1%5D+%5Cgeq+%5Cfrac%7B2%7D%7B3%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\forall x \in L, \exists y \in \{0,1\}^{p(n)},\quad \Pr[V(x,y) = 1] \geq \frac{2}{3}"/><p/>
</li>
<li>
<p><img alt="\forall x \notin L" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cforall+x+%5Cnotin+L&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\forall x \notin L"/>, <img alt="\forall |y\rangle \in \{0,1\}^{p(n)},\quad \Pr[V(x,y) = 1] \leq \frac{1}{3}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cforall+%7Cy%5Crangle+%5Cin+%5C%7B0%2C1%5C%7D%5E%7Bp%28n%29%7D%2C%5Cquad+%5CPr%5BV%28x%2Cy%29+%3D+1%5D+%5Cleq+%5Cfrac%7B1%7D%7B3%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\forall |y\rangle \in \{0,1\}^{p(n)},\quad \Pr[V(x,y) = 1] \leq \frac{1}{3}"/></p>
</li>
</ul>
<hr/>
<p>For QMA, the verifier is a quantum computer and the witness is a quantum state. Moreover, we’re interested in the complexity of promise problems:</p>
<hr/>
<p><strong>QMA</strong></p>
<p>A promise problem <img alt="L = L_{yes} \cup L_{no} \in \text{QMA}" class="latex" src="https://s0.wp.com/latex.php?latex=L+%3D+L_%7Byes%7D+%5Ccup+L_%7Bno%7D+%5Cin+%5Ctext%7BQMA%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="L = L_{yes} \cup L_{no} \in \text{QMA}"/> iff there exists a quantum poly-time verifier <img alt="V" class="latex" src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="V"/> and a polynomial <img alt="p" class="latex" src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p"/> such that</p>
<ul>
<li><img alt="\forall x \in L_{yes}, \exists |y\rangle \in (\mathbb{C}^2)^{\otimes p(|x|)},\quad \Pr[V(|x\rangle|y\rangle) = 1] \geq \frac{2}{3}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cforall+x+%5Cin+L_%7Byes%7D%2C+%5Cexists+%7Cy%5Crangle+%5Cin+%28%5Cmathbb%7BC%7D%5E2%29%5E%7B%5Cotimes+p%28%7Cx%7C%29%7D%2C%5Cquad+%5CPr%5BV%28%7Cx%5Crangle%7Cy%5Crangle%29+%3D+1%5D+%5Cgeq+%5Cfrac%7B2%7D%7B3%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\forall x \in L_{yes}, \exists |y\rangle \in (\mathbb{C}^2)^{\otimes p(|x|)},\quad \Pr[V(|x\rangle|y\rangle) = 1] \geq \frac{2}{3}"/><p/>
</li>
<li>
<p><img alt="\forall x \notin L_{no}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cforall+x+%5Cnotin+L_%7Bno%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\forall x \notin L_{no}"/>, <img alt="\forall |y\rangle \in (\mathbb{C}^2)^{\otimes p(|x|)},\quad \Pr[V(|x\rangle|y\rangle) = 1] \leq \frac{1}{3}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cforall+%7Cy%5Crangle+%5Cin+%28%5Cmathbb%7BC%7D%5E2%29%5E%7B%5Cotimes+p%28%7Cx%7C%29%7D%2C%5Cquad+%5CPr%5BV%28%7Cx%5Crangle%7Cy%5Crangle%29+%3D+1%5D+%5Cleq+%5Cfrac%7B1%7D%7B3%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\forall |y\rangle \in (\mathbb{C}^2)^{\otimes p(|x|)},\quad \Pr[V(|x\rangle|y\rangle) = 1] \leq \frac{1}{3}"/></p>
</li>
</ul>
<hr/>
<p>A problem is QMA-complete if it is in QMA and if any problem in QMA can be reduced to it in polynomial time. In 2002, Kitaev proved that <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-LH is QMA-complete for all <img alt="k \geq 5" class="latex" src="https://s0.wp.com/latex.php?latex=k+%5Cgeq+5&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k \geq 5"/>. This was the first time a natural problem was shown to be QMA-complete. In 2003 Kempe and Regev proved that 3-LH is QMA-complete, and finally in 2006 Kempe, Kitaev and Regev proved that 2-LH is QMA complete, achieving the best possible result unless P = QMA. (3-SAT is NP-complete but 2-SAT is in P, so it may seem curious that 2-LH is QMA-complete. But in fact, this isn’t too surprising, because as we mentioned earlier, <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-LH corresponds to MAX-<img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-SAT, and MAX-2-SAT is NP-complete.)</p>
<hr/>
<p><strong>“Quantum Cook-Levin Theorem”</strong></p>
<p>The 2-local Hamiltonian problem is QMA-complete.</p>
<hr/>
<p><em>A very sketchy proof sketch.    </em>This theorem is called the quantum Cook-Levin theorem not just because of the result, but also because the proof is along the same lines as the proof of the Cook-Levin theorem.</p>
<p>Recall that in the proof of the Cook-Levin theorem, we start with a verifier Turing machine that takes as input <img alt="(x,y)" class="latex" src="https://s0.wp.com/latex.php?latex=%28x%2Cy%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(x,y)"/> and, in time <img alt="p(n)" class="latex" src="https://s0.wp.com/latex.php?latex=p%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p(n)"/> accepts iff <img alt="y" class="latex" src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y"/> is a valid witness for <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/> being in the language. We then devise (for each <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>) a 3-SAT formula such that any satisfying solution to the instance must be an encoding of a valid history of the Turing machine from start to finish on the input <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/>. The constraints must guarantee that (a) the input indeed starts with <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/>, (b) at every time step <img alt="t \in [1,p(n)]" class="latex" src="https://s0.wp.com/latex.php?latex=t+%5Cin+%5B1%2Cp%28n%29%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t \in [1,p(n)]"/> the state of the machine correctly follows from its state at time <img alt="t-1" class="latex" src="https://s0.wp.com/latex.php?latex=t-1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t-1"/>, and that (c) the final state of the machine indicates acceptance. The constraints for (a) and (c) are trivial, and the reason we can do (b) is because Turing machines compute <em>locally</em>.</p>
<p>For our quantum Cook-Levin proof, we follow the same template. Given a quantum circuit, we construct a local Hamiltonian that has ground energy below some constant only if there is a quantum encoding of the circuit that includes the proper (a) initial state, (b) intermediate computation, and (c) final state. As before, (a) and (c) are easy, because the parts of the initial and final states we need to ‘inspect’ (with the local terms of the Hamiltonian) are essentially classical. But when we try to compute local constraints for (b), we run into a big problem: entanglement.</p>
<p>Consider some step of the computation. This will consist of applying a quantum gate <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/> to a state <img alt="|\psi\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi\rangle"/> to obtain <img alt="|\psi'\rangle = U|\psi\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%27%5Crangle+%3D+U%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi'\rangle = U|\psi\rangle"/>. Even assuming we’ve already written down constraints to verify that <img alt="|\psi\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi\rangle"/> is correct, it is non-trivial to write down constraints to verify that <img alt="|\psi'\rangle = U|\psi\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%27%5Crangle+%3D+U%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi'\rangle = U|\psi\rangle"/> because <img alt="|\psi'\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%27%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi'\rangle"/> may differ from <img alt="U|\psi\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=U%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U|\psi\rangle"/> in a highly <em>non-local</em> way if there is entanglement between far-flung qubits. For example, suppose for the sake of illustration that <img alt="|\psi\rangle = \frac{1}{\sqrt{2}}(|00\rangle + |11\rangle)" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle+%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%28%7C00%5Crangle+%2B+%7C11%5Crangle%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi\rangle = \frac{1}{\sqrt{2}}(|00\rangle + |11\rangle)"/> and <img alt="U = I" class="latex" src="https://s0.wp.com/latex.php?latex=U+%3D+I&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U = I"/>. And suppose we want to check that <img alt="|\psi'\rangle = \frac{1}{\sqrt{2}}(|00\rangle + |11\rangle)" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%27%5Crangle+%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%28%7C00%5Crangle+%2B+%7C11%5Crangle%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi'\rangle = \frac{1}{\sqrt{2}}(|00\rangle + |11\rangle)"/> with 1-local constraints. Unfortunately, there is no way to distinguish <img alt="\frac{1}{\sqrt{2}}(|00\rangle + |11\rangle)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%28%7C00%5Crangle+%2B+%7C11%5Crangle%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\frac{1}{\sqrt{2}}(|00\rangle + |11\rangle)"/> from <img alt="\frac{1}{\sqrt{2}}(|00\rangle - |11\rangle)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%28%7C00%5Crangle+-+%7C11%5Crangle%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\frac{1}{\sqrt{2}}(|00\rangle - |11\rangle)"/> by looking at one qubit at a time: the reduced density matrix of either state for either qubit is the same: <img alt="I" class="latex" src="https://s0.wp.com/latex.php?latex=I&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="I"/>/2. There are examples like this that apply for <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-local constraints for any <img alt="k &gt;1" class="latex" src="https://s0.wp.com/latex.php?latex=k+%3E1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k &gt;1"/>, so we can’t even verify the ‘trivial’ gate <img alt="I" class="latex" src="https://s0.wp.com/latex.php?latex=I&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="I"/>, let alone gates that actually change the state. It would seem that we are stuck.</p>
<p>Luckily, although quantum superposition makes this problem more difficult, we can actually use superposition in a clever manner in order to surmount the difficulty. Instead of encoding the states <img alt="|\psi\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi\rangle"/> and <img alt="|\psi'\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%27%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi'\rangle"/> separately, we can put them in superposition in a way that will allow us to verify that <img alt="|\psi'\rangle = U|\psi\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%27%5Crangle+%3D+U%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi'\rangle = U|\psi\rangle"/>. Suppose again that <img alt="U = I" class="latex" src="https://s0.wp.com/latex.php?latex=U+%3D+I&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U = I"/>, so we want to check that <img alt="|\psi'\rangle = |\psi\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%27%5Crangle+%3D+%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi'\rangle = |\psi\rangle"/>. Let <img alt="|\eta\rangle = \frac{1}{\sqrt{2}}(|\psi\rangle|0\rangle + |\psi'\rangle|1\rangle)" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Ceta%5Crangle+%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%28%7C%5Cpsi%5Crangle%7C0%5Crangle+%2B+%7C%5Cpsi%27%5Crangle%7C1%5Crangle%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\eta\rangle = \frac{1}{\sqrt{2}}(|\psi\rangle|0\rangle + |\psi'\rangle|1\rangle)"/>. Then, just by looking at the last qubit of <img alt="|\eta\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Ceta%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\eta\rangle"/>, we can tell how close <img alt="|\psi'\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%27%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi'\rangle"/> is to <img alt="|\psi\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi\rangle"/>: the reduced density matrix of the last qubit contains information about the angle between <img alt="|\psi\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi\rangle"/> and <img alt="|\psi'\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%27%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi'\rangle"/>:</p>
<p><img alt="\begin{pmatrix} 1 &amp; \langle\psi|\psi'\rangle \\ \langle\psi|\psi'\rangle &amp; 1 \end{pmatrix}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Bpmatrix%7D+1+%26+%5Clangle%5Cpsi%7C%5Cpsi%27%5Crangle+%5C%5C+%5Clangle%5Cpsi%7C%5Cpsi%27%5Crangle+%26+1+%5Cend%7Bpmatrix%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{pmatrix} 1 &amp; \langle\psi|\psi'\rangle \\ \langle\psi|\psi'\rangle &amp; 1 \end{pmatrix}"/></p>
<p>The challenge is to describe a <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-local Hamiltonian <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> that has a state with energy below some parameter <img alt="a" class="latex" src="https://s0.wp.com/latex.php?latex=a&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a"/> whenever <img alt="y" class="latex" src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y"/> is a valid witness for <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/>, and otherwise has no state with energy below <img alt="b&gt;a" class="latex" src="https://s0.wp.com/latex.php?latex=b%3Ea&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="b&gt;a"/>. We won’t cover the details here, but the crucial idea is that when <img alt="y" class="latex" src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y"/> is a valid witness for <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/>, the following ‘witness state’ (which is a superposition of the states of the quantum computer over all the time steps) will have low energy for a carefully-devised <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/>:</p>
<p><img alt="|\eta\rangle = \frac{1}{p(n)}\sum_{t=0}^{p(n)}(U_t\cdots U_1|\psi_0\rangle)\otimes|t\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Ceta%5Crangle+%3D+%5Cfrac%7B1%7D%7Bp%28n%29%7D%5Csum_%7Bt%3D0%7D%5E%7Bp%28n%29%7D%28U_t%5Ccdots+U_1%7C%5Cpsi_0%5Crangle%29%5Cotimes%7Ct%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\eta\rangle = \frac{1}{p(n)}\sum_{t=0}^{p(n)}(U_t\cdots U_1|\psi_0\rangle)\otimes|t\rangle"/></p>
<p>where <img alt="|\psi_0\rangle = |x\rangle|y\rangle|0\rangle^{\otimes m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi_0%5Crangle+%3D+%7Cx%5Crangle%7Cy%5Crangle%7C0%5Crangle%5E%7B%5Cotimes+m%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi_0\rangle = |x\rangle|y\rangle|0\rangle^{\otimes m}"/> is the initial state of the computation, and <img alt="|t\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ct%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|t\rangle"/> is called the “clock register”. Note that because the size of the clock register is logarithmic in <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>, we actually need to use <img alt="\log(n)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clog%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\log(n)"/>-local constraints. For 5-local constraints to suffice, the witness state will need to be a little more complicated (the proof for 2-local constraints is even more difficult). Even for the case of <img alt="\log(n)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clog%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\log(n)"/>-LH, the complete proof must demonstrate that no state besides the witness state has low energy.</p>
<p style="text-align: right;">□</p>
<h1>Roadmap</h1>
<p>The upshot is that 2-LH is the canonical QMA-complete problem. This is a beautiful result from a quantum complexity theory perspective, but from a physics perspective it is very bad news. The QMA-completeness of the local Hamiltonian problem means that (presuming BQP <img alt="\neq" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cneq&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\neq"/> QMA) we can’t solve 2-LH, and we couldn’t even solve it with a quantum computer. Because of the central importance of finding the ground energy, this in turn means that <em>almost anything a physicist would like to compute about a system is intractable</em>.</p>
<p>So is all hope lost? No! Just as we started out wanting to understand Hamiltonians in general and restricted our focus to <em>local</em> Hamiltonians, the approach the physics community has taken is to focus on even more restricted classes of Hamiltonians that still capture interesting physical systems. One route is to restrict the topology of the system encoded by the Hamiltonian: for example, in many physics models, the particles form a low-dimensional lattice and the only interactions between them are 2-local interactions along edges. Even this isn’t enough, though: the problem remains QMA-hard on many simple topologies like lattices (for example, 2-LH on the 2-D lattice is QMA-complete, and 2-LH on even the 1-D lattice is QMA-complete when instead of qubits we are dealing with 8-dimensional qudits). So we add a further restriction, which is to focus on <em>gapped</em> Hamiltonians: these are Hamiltonians for which there is a constant gap between the ground energy and the second-lowest energy.</p>
<p/><div class="wp-caption aligncenter" id="attachment_6405" style="width: 392px;"><img alt="circle_diagram1.png" class="  wp-image-6405 aligncenter" height="336" src="https://windowsontheory.files.wordpress.com/2018/12/circle_diagram1.png?w=382&amp;h=336" width="382"/><p class="wp-caption-text">Even local Hamiltonians are intractable in general. Gapped Hamiltonians on low-dimensional lattices, though, may be tractable.</p></div><p/>
<p>Thus, in the notes to follow, we will focus our energies on trying to solve the gapped local Hamiltonian problem for 1-D and 2-D lattices. The reason there is hope in these settings is that entanglement is (or is conjectured to be) limited by ‘area laws’. In the next post, Fred Zhang will describe a diagrammatic language (‘tensor networks’) for thinking about low-entanglement quantum states, and he’ll show how physicists solve the local Hamiltonian problem for gapped 1-D systems.</p></div>
    </content>
    <updated>2018-12-20T21:15:11Z</updated>
    <published>2018-12-20T21:15:11Z</published>
    <category term="physics"/>
    <category term="cs229r"/>
    <category term="quantum hamiltonian complexity"/>
    <author>
      <name>benedelman</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2019-01-07T23:32:58Z</updated>
    </source>
  </entry>
</feed>
