<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2019-02-03T09:21:30Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=15616</id>
    <link href="https://rjlipton.wordpress.com/2019/02/03/a-strange-horizon/" rel="alternate" type="text/html"/>
    <title>A Strange Horizon</title>
    <summary>Data science of many things including citations Amazon India source Paul Allison is an emeritus professor of sociology at the University of Pennsylvania and the founder and president of the company Statistical Horizons. They provides short courses and seminars for statistical training. Today we have a short seminar on statistics and horizons of effectiveness. Our […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><font color="#0044cc"><br/>
<em>Data science of many things including citations</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2019/02/03/a-strange-horizon/allisonamazon/" rel="attachment wp-att-15619"><img alt="" class="alignright wp-image-15619" height="200" src="https://rjlipton.files.wordpress.com/2019/02/allisonamazon.jpg?w=133&amp;h=200" width="133"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Amazon India <a href="https://www.amazon.in/l/B001H6KWN6">source</a></font></td>
</tr>
</tbody>
</table>
<p>
Paul Allison is an emeritus professor of sociology at the University of Pennsylvania and the founder and president of the company <a href="https://statisticalhorizons.com/">Statistical Horizons</a>. They provides short courses and seminars for statistical training. </p>
<p>
Today we have a short seminar on statistics and horizons of effectiveness. </p>
<p>
Our first topic is about citations. Did we say citations? What are we in research more interested in than citations? Allison co-wrote a paper on a <a href="https://en.wikipedia.org/wiki/Lotka's_law">“law”</a> claimed by Alfred Lotka about how the number of citations behaves. Full details in a moment, but two upshots are: </p>
<ul>
<li>
Over half of the papers are contributed by a few highly prolific authors. <p/>
</li><li>
One-shot authors are roughly <img alt="{61\%}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B61%5C%25%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{61\%}"/> of the population but account for only a tiny proportion of the literature.
</li></ul>
<p>
</p><p/><h2> Allison’s Paper </h2><p/>
<p>Allison co-wrote his <a href="https://statisticalhorizons.com/wp-content/uploads/AllisonEtAl.SSS76.pdf">paper</a>, “Lotka’s Law: A Problem in Its Interpretation and Application,” with Derek de Solla Price, Belver Griffith, Michael Moravcsik, and John Stewart in 1976. Lotka’s law, which is related to George Zipf’s famous <a href="https://en.wikipedia.org/wiki/Zipf's_law">law</a>, alleges that over any time period in any scientific or literary field, the number <img alt="{a(n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a(n)}"/> of authors with <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> contributions obeys </p>
<p align="center"><img alt="\displaystyle  a(n) = \frac{C}{n^2}, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++a%28n%29+%3D+%5Cfrac%7BC%7D%7Bn%5E2%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  a(n) = \frac{C}{n^2}, "/></p>
<p>where <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> is independent of <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>. This suggests a maximum of <img alt="{n_{max} = \sqrt{C}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn_%7Bmax%7D+%3D+%5Csqrt%7BC%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n_{max} = \sqrt{C}}"/> on the range of <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>, since higher <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> give <img alt="{a(n) &lt; 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%28n%29+%3C+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a(n) &lt; 1}"/>, but there is also a probabilistic interpretation: The law says that the total number of papers at <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> is <img alt="{C/n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%2Fn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C/n}"/>, and that gives a positive constant expectation even when <img alt="{n_{max}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn_%7Bmax%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n_{max}}"/> varies as <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/>. Both cases yield that out of the total number <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> of papers, which has <img alt="{T = \Theta(C\log(C))}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT+%3D+%5CTheta%28C%5Clog%28C%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T = \Theta(C\log(C))}"/>, over half of them are contributed by a vanishing percentage of highly prolific authors. Meanwhile, one-shot authors are roughly <img alt="{6/\pi^2 \approx 61\%}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B6%2F%5Cpi%5E2+%5Capprox+61%5C%25%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{6/\pi^2 \approx 61\%}"/> of the population but account for only a <img alt="{1/\log(T)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%2F%5Clog%28T%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1/\log(T)}"/> proportion of the literature.</p>
<p>
However, the paper also remarks on a third case, namely making <img alt="{n_{max}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn_%7Bmax%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n_{max}}"/> a fixed constant—since human time is finite in any field. This puts a sharper <em>horizon</em> on Lotka’s Law and changes the inferences made as the horizon is approached. The paper shows how the <img alt="{n_{max}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn_%7Bmax%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n_{max}}"/> factor intrudes on other inferences they would like to draw, even between the former two cases. And never mind <a href="http://www.revistadestatistica.ro/index.php/the-power-of-lotkas-law-through-the-eyes-of-r/">more</a>–<a href="https://rjlipton.wordpress.com/feed/www.fosareh.net/fa/files/pdf/Osareh-mostafavi-collnet[1].doc">recent</a> <a href="http://www.collnet.de/Berlin-2008/LarsenWIS2008llc.pdf">evidence</a> of <a href="http://www.librarywaves.com/index.php/lw/article/download/51/45/">breakdowns</a> in Lotka’s law. </p>
<p>
</p><p/><h2> Horizons </h2><p/>
<p/><p>
We have mentioned de Solla Price <a href="https://rjlipton.wordpress.com/2012/09/29/why-we-lose-sleep-some-nights/">before</a> in regard to his founding <a href="https://en.wikipedia.org/wiki/Scientometrics">scientometrics</a>. In practice this is mainly concerned with citation analysis and other productivity metrics, but its widely-quoted definition, “the science of measuring and analyzing science,” strikes us as broader. We feel there should be a component for measuring limitations of the effectiveness of the science one is practicing.</p>
<p>
Now of course in statistics there are longstanding measures of statistical <a href="https://en.wikipedia.org/wiki/Power_(statistics)">power</a> and experiment acuity and of <em>noise</em> in general. Nevertheless, the cascading “(non-)reproducibility crisis” argues that more needs to be addressed. The development of software tools to counter “<a href="https://en.wikipedia.org/wiki/Data_dredging">p-hacking</a>” exemplifies a new layer of scientific modeling to do so—which could be called introspective modeling. </p>
<p>
I will exemplify with two “horizons” that are apparent in my own statistical chess research. One involves estimating the Elo rating of “perfect play.” The other involves the level of skill at which my data may cease to be effective. The former has captured popular imagination—it was among the first questions posed to me by Judit Polgar in a broadcast during the 2016 world championship match—but the latter is my concern in practice. We will see that these may be the same horizon, approached either by looking down from the stars or up from the road. </p>
<p>
I am not the first to do this kind of work or face the issue of its resolving power. Matej Guid, Artiz Perez, and Ivan Bratko made it the sole topic of a 2008 followup <a href="https://pdfs.semanticscholar.org/fcdc/9fb1e88c40de12ad9481f0d580f803bc1582.pdf">paper</a> to their 2006 <a href="https://en.chessbase.com/news/2006/world_champions2006.pdf">study</a> of all games in world championship matches. But their indicators strike me as weak. Most simply, they do not try to estimate where their horizon <em>is</em>, just argue that their results are not wholly beyond it. We will try to do more—but speculatively. The first step is rock-solid—it is a big surprise I found last month.</p>
<p>
</p><p/><h2> More Data, More Resolution </h2><p/>
<p/><p>
I use strong chess programs to take two main kinds of data. My full model uses programs in an analysis mode that evaluates all available moves to the same degree of thoroughness and takes roughly 4–6 hours per game. My quicker “screening” tests use programs in their normal playing mode, which gives full shrift only to what’s considered the best move, but shaves the time down to 10–15 minutes. For my AAAI 2011 <a href="https://cse.buffalo.edu/~regan/papers/pdf/ReHa11c.pdf">paper</a> with Guy Haworth, I used over 400,000 positions from 5,700 games at rating levels from Elo 1600 to 2700 only, all run on my office and home PCs. Below Elo 2000 the available data was so scant that noise is evident in the paper’s table.</p>
<p>
Since then, many more games by lower-rated players are being archived—much thanks to the greater availability of chessboards that automatically record moves in the standard <a href="https://en.wikipedia.org/wiki/Portable_Game_Notation">PGN</a> format, and to an upswell in tournaments, for youth in particular. Last year, thanks to the great free bandwidth granted by my university’s Center for Computational Research (<a href="http://www.buffalo.edu/ccr.html">CCR</a>), I took data in the quicker mode from over 10,600,000 moves from just over 400,000 game-sides (counting White and Black separately) in every tournament compiled by <a href="https://en.chessbase.com/">ChessBase</a> as well as some posted only by The Week in Chess (<a href="http://theweekinchess.com/">TWIC</a>) or provided directly by the World Chess Federation (FIDE). My two main test quantities are:</p>
<ul>
<li>
The percentage of the computer’s best move being the one the player chose (“MM%”). <p/>
</li><li>
The average error judged by the computer per move, scaling down large differences (“ASD”).
</li></ul>
<p>
My 2011 paper found strong linear relations of these quantities to the players’ rating, and great ASD fits on a 3-million-move data set are shown graphically in this <a href="https://rjlipton.wordpress.com/2016/11/30/when-data-serves-turkey/">post</a>. With MM% and my new 2018 data, here is what I see when I limit to the 1600–2700 range, grouping in “buckets” of 25 Elo points. All screenshots are taken with Andrew Que’s Polynomial Regression <a href="http://polynomialregression.drque.net/online.php">applet</a>. They all show data taken with Stockfish 9 run to search depth at least 20 and breadth at least 200 million nodes; the similar data for the chess program Komodo 11.3 gives similar results.</p>
<p><a href="https://rjlipton.wordpress.com/2019/02/03/a-strange-horizon/linearmmpfitpart/" rel="attachment wp-att-15620"><img alt="" class="aligncenter wp-image-15620" height="285" src="https://rjlipton.files.wordpress.com/2019/02/linearmmpfitpart.png?w=450&amp;h=285" width="450"/></a></p>
<p>
Even with vastly more data, there still does not appear any reason to reject the simple hypothesis that the relation to rating is linear. Not only is <img alt="{R^2 &gt; 0.99}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%5E2+%3E+0.99%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R^2 &gt; 0.99}"/>, the quality of fit is terrific. The noise under Elo 2000 is minimal.</p>
<p>
But now I have over 14,000 moves in individual buckets clear down to the FIDE minimum 1000 rating; only the 2750 bucket with 11,923 moves and the 2800-level bucket with 6,340 (from just a handful of the world’s elite players) lag behind. When those buckets are added, here is what we see:</p>
<p><a href="https://rjlipton.wordpress.com/2019/02/03/a-strange-horizon/linearmmpfita/" rel="attachment wp-att-15622"><img alt="" class="aligncenter wp-image-15622" height="285" src="https://rjlipton.files.wordpress.com/2019/02/linearmmpfita.png?w=450&amp;h=285" width="450"/></a></p>
<p>
The linear hypothesis is notably less tenable. Instead, a quadratic polynomial fits supremely well:</p>
<p>
<a href="https://rjlipton.wordpress.com/2019/02/03/a-strange-horizon/quadraticmmpfita/" rel="attachment wp-att-15623"><img alt="" class="aligncenter wp-image-15623" height="285" src="https://rjlipton.files.wordpress.com/2019/02/quadraticmmpfita.png?w=450&amp;h=285" width="450"/></a></p>
<p>
Thus it seems I must admit a <em>nonlinearity</em> into my chess model. This may not be just about slightly improving my model’s application to players at the ends of the rating spectrum. Philosophically, nonlinearity can be a game-changer: the way Newtonian physics is fine for flying jets all around the globe but finding your neighbor’s house via <a href="http://physicscentral.com/explore/writers/will.cfm">GPS</a> absolutely requires Einstein. </p>
<p>
</p><p/><h2> The Horizon Issue </h2><p/>
<p/><p>
Let us flip the axes so that <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X}"/> is MM% and <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y}"/> is rating. Then the intercept of <img alt="{X = 100\%}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX+%3D+100%5C%25%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X = 100\%}"/> would give the rating of perfect agreement with the computer. Well, here is what we see:</p>
<p>
<a href="https://rjlipton.wordpress.com/2019/02/03/a-strange-horizon/quadraticmmpfitflipext/" rel="attachment wp-att-15624"><img alt="" class="aligncenter wp-image-15624" height="285" src="https://rjlipton.files.wordpress.com/2019/02/quadraticmmpfitflipext.png?w=450&amp;h=285" width="450"/></a></p>
<p>
Having the rating of perfect agreement be about 1950—which is a amateur A-level in the US—is ludicrous. The greater import is how the increase stops at Elo 3000 with matching just under 75%. The serious implication I draw is that this helps locate the horizon of effectiveness of the data and my methods based on it. Meanwhile, I’ve had the sense from applications that my full model based on smaller higher-quality data is coherent up to about 3100 but cannot tell differences above that. </p>
<p>
Indeed, there is a corroborating indicator of this horizon: The top chess programs, or even different (major) versions of the same program, don’t even match <em>each other</em> over 75% with regularity. Moreover, the <em>same program</em> will fairly often change to a different move when left running for more time or to a greater search depth. If it didn’t change, it wouldn’t improve. Thus my tests, which have no foreknowledge of how long a program used to cheat was running and on how powerful hardware, cannot expect to register positives at a higher rate. The natural agreement rates for human players range from about 35% for novices to upwards of 60% for world champions. </p>
<p>
</p><p/><h2> The Average-Error Case </h2><p/>
<p/><p>
The fit to average scaled error-per-move (ASD) shows the other side of the horizon issue. The ASD measure is more tightly correlated to rating—as the graphs in the above-mentioned <a href="https://rjlipton.wordpress.com/2016/11/30/when-data-serves-turkey/">post</a> suffice to indicate. Here is the corresponding graph on the new data, again with flipped axes:</p>
<p>
<a href="https://rjlipton.wordpress.com/2019/02/03/a-strange-horizon/linearasdfit/" rel="attachment wp-att-15625"><img alt="" class="aligncenter wp-image-15625" height="285" src="https://rjlipton.files.wordpress.com/2019/02/linearasdfit.png?w=450&amp;h=285" width="450"/></a></p>
<p>
Only under 1250 Elo does perfect linearity seem to be countermanded. The issue, however, is at the other end. Committing asymptotically zero error seems to be a more acute indicator of perfection than 100% agreement with a strong program. However, the <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y}"/>-intercept there is given as a rating under 3300, whereas computer programs have been reliably <a href="http://www.computerchess.org.uk/ccrl/404/">rated</a> above 3400, and very recently over 3500. Thus we’d appear to have computers rated higher than perfection.</p>
<p>
One can move from the above indication of my setup losing mojo before 3000 to allege that it is insufficient for fair judgment of human players above 2500, say, so that the intercept is not valid. My counter-argument is that the same intercept is also a robust extrapolation from the range 1500 to 2500 where the linear fit is nearly perfect and the computer’s sufficiency for authoritative judgment of the players is beyond doubt. </p>
<p>
Nevertheless, the above “game-changer” for the move-matching percentage suggests the same for ASD. A quadratic fit to ASD produces the following results:</p>
<p>
<a href="https://rjlipton.wordpress.com/2019/02/03/a-strange-horizon/quadraticasdfitnw/" rel="attachment wp-att-15626"><img alt="" class="aligncenter wp-image-15626" height="285" src="https://rjlipton.files.wordpress.com/2019/02/quadraticasdfitnw.png?w=450&amp;h=285" width="450"/></a></p>
<p>
Now the <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y}"/>-intercept at <img alt="{X = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X = 0}"/> is within error bars of 3500, in agreement with the 3475 figure currently used in my full model and less starkly under the measured ratings.</p>
<p>
</p><p/><h2> One More Riff </h2><p/>
<p/><p>
Let us think of move-matching for a given rating <img alt="{R}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R}"/> as a flip of a biased coin with heads probability <img alt="{p = p_R}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp+%3D+p_R%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p = p_R}"/>. If we plot <img alt="{R}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R}"/> not against <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> but against <img alt="{p\cdot p(1-p)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%5Ccdot+p%281-p%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p\cdot p(1-p)}"/>, we recover a nearly perfect linear fit (the plot shows <img alt="{4p^2 (1-p)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B4p%5E2+%281-p%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{4p^2 (1-p)}"/>):</p>
<p>
<a href="https://rjlipton.wordpress.com/2019/02/03/a-strange-horizon/ppqfit/" rel="attachment wp-att-15627"><img alt="" class="aligncenter wp-image-15627" height="285" src="https://rjlipton.files.wordpress.com/2019/02/ppqfit.png?w=450&amp;h=285" width="450"/></a></p>
<p>
Well, <img alt="{p(1-p)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%281-p%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p(1-p)}"/> is the variance of one coin flip. Why should multiplying <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> by this variance recover a linear fit in the <em>mean</em>? Only multiplying <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> by the square root of <img alt="{p(1-p)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%281-p%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p(1-p)}"/> still leaves a significantly non-linear plot. </p>
<p>
Recovering <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> from <img alt="{p^2(1-p)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%5E2%281-p%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p^2(1-p)}"/> needs solving a cubic equation. The maximum value is at <img alt="{p = \frac{2}{3}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp+%3D+%5Cfrac%7B2%7D%7B3%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p = \frac{2}{3}}"/> and is <img alt="{\frac{4}{27}.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B4%7D%7B27%7D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\frac{4}{27}.}"/> Multiplying by <img alt="{4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{4}"/> as in the plot makes <img alt="{\frac{16}{27} \approx 0.592593}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B16%7D%7B27%7D+%5Capprox+0.592593%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\frac{16}{27} \approx 0.592593}"/> the maximum solvable value. This regression line associates this to a rating of only 2860. This suggests a tangibly lower horizon. It also seems contradicted by the fact of Magnus Carlsen maintaining a rating over 2860 from January 2013 through June 2015, yet his engine agreement did not approach 66.7%.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
We’ve connected the horizon of perfect play to whether the fundamental relationship of rating to agreement with strong computer programs is linear, quadratic, or indirectly cubic. Which relationship is true? What further tests may best ascertain the range of effectiveness of inferences from these data?</p>
<p/></font></font></div>
    </content>
    <updated>2019-02-03T06:37:57Z</updated>
    <published>2019-02-03T06:37:57Z</published>
    <category term="All Posts"/>
    <category term="chess"/>
    <category term="detection"/>
    <category term="Ideas"/>
    <category term="Teaching"/>
    <category term="Alfred Lotka"/>
    <category term="Derek de Solla Price"/>
    <category term="horizons"/>
    <category term="linear regression"/>
    <category term="nonlinearity"/>
    <category term="Paul Allison"/>
    <category term="statistics"/>
    <author>
      <name>KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-02-03T09:20:36Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://theorydish.blog/?p=1490</id>
    <link href="https://theorydish.blog/2019/02/02/stoca-workshop/" rel="alternate" type="text/html"/>
    <title>STOCA workshop</title>
    <summary>For the past few months, we, the STOC 2019 PC, have enjoyed the privilege of reading and discussing a lot of exciting submissions. On Sunday and Monday we will reject most of them. After that, on Tuesday February 5th, we will celebrate with a 1-day workshop hosted at Google. Here is the official website for registration (free!) and other useful infromation: https://sites.google.com/view/stoca19/home</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>For the past few months, we, the STOC 2019 PC, have enjoyed the privilege of reading and discussing a lot of exciting submissions. On Sunday and Monday we will reject most of them. After that, on <strong>Tuesday February 5th</strong>, we will celebrate with a 1-day workshop hosted at Google.</p>
<p>Here is the official website for registration (free!) and other useful infromation:<br/>
<a href="https://sites.google.com/view/stoca19/home">https://sites.google.com/view/stoca19/home</a></p></div>
    </content>
    <updated>2019-02-03T05:31:05Z</updated>
    <published>2019-02-03T05:31:05Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>aviad.rubinstein</name>
    </author>
    <source>
      <id>https://theorydish.blog</id>
      <logo>https://theorydish.files.wordpress.com/2017/03/cropped-nightdish1.jpg?w=32</logo>
      <link href="https://theorydish.blog/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://theorydish.blog" rel="alternate" type="text/html"/>
      <link href="https://theorydish.blog/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://theorydish.blog/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Stanford's CS Theory Research Blog</subtitle>
      <title>Theory Dish</title>
      <updated>2019-02-03T09:21:15Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=16779</id>
    <link href="https://gilkalai.wordpress.com/2019/02/02/konstantin-tikhomrov-the-probability-that-a-bernoulli-matrix-is-singular/" rel="alternate" type="text/html"/>
    <title>Konstantin Tikhomirov: The Probability that a Bernoulli Matrix is Singular</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Konstantin Tikhomirov An old problem in combinatorial random matrix theory is cracked! Singularity of random Bernoulli matrices by Konstantin Tikhomirov Abstract: For each , let be an n×n random matrix with independent ±1 entries. We show that P( is singular}=, … <a href="https://gilkalai.wordpress.com/2019/02/02/konstantin-tikhomrov-the-probability-that-a-bernoulli-matrix-is-singular/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="https://gilkalai.files.wordpress.com/2019/02/tikhomirov.jpg"><img alt="" class="alignnone size-full wp-image-16826" src="https://gilkalai.files.wordpress.com/2019/02/tikhomirov.jpg?w=640"/></a></p>
<p><span style="color: #ff0000;"><strong>Konstantin Tikhomirov</strong></span></p>
<p>An old problem in combinatorial random matrix theory is cracked!</p>
<p><a href="https://arxiv.org/abs/1812.09016"><strong>Singularity of random Bernoulli matrices</strong></a> by <strong>Konstantin Tikhomirov</strong></p>
<p><strong>Abstract</strong>: For each <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>, let <img alt="M_n" class="latex" src="https://s0.wp.com/latex.php?latex=M_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="M_n"/> be an <em>n</em>×<em>n</em> random matrix with independent ±1 entries. We show that</p>
<p style="text-align: center;">P(<img alt="M_n" class="latex" src="https://s0.wp.com/latex.php?latex=M_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="M_n"/> is singular}=<img alt="(1/2+o_n(1))^n" class="latex" src="https://s0.wp.com/latex.php?latex=%281%2F2%2Bo_n%281%29%29%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(1/2+o_n(1))^n"/>,</p>
<p>which settles an old problem. Some generalizations are considered.</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/02/komlos.jpg"><img alt="" class="alignnone size-full wp-image-16821" src="https://gilkalai.files.wordpress.com/2019/02/komlos.jpg?w=640"/></a></p>
<p><span style="color: #ff0000;"><b>János Komlós</b></span></p>
<h3>Background and discussion</h3>
<p>What is the probability <img alt="s(n)" class="latex" src="https://s0.wp.com/latex.php?latex=s%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s(n)"/> that a random n by n matrix with <img alt="\pm 1" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpm+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\pm 1"/> entries is singular? Well, it can be singular if either two rows are identical, or if two columns are identical. This happens with probability</p>
<p style="text-align: center;"><img alt="n(n-1)(1+0(1)) \cdot 2^{-n}" class="latex" src="https://s0.wp.com/latex.php?latex=n%28n-1%29%281%2B0%281%29%29+%5Ccdot+2%5E%7B-n%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n(n-1)(1+0(1)) \cdot 2^{-n}"/>.</p>
<p>Are there other more dominant reasons for singularity? Are most <img alt="\pm 1" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpm+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\pm 1"/> matrices nonsingular as <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> tends to infinity? The first results in this direction are by Janos Komlos who first proved in 1968 that <img alt="s(n)=o(1)" class="latex" src="https://s0.wp.com/latex.php?latex=s%28n%29%3Do%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s(n)=o(1)"/> and later that <img alt="s(n)=O(1/\sqrt n)" class="latex" src="https://s0.wp.com/latex.php?latex=s%28n%29%3DO%281%2F%5Csqrt+n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s(n)=O(1/\sqrt n)"/>. A major breakthrough came in 1995 when  <a href="http://www.ams.org/journals/jams/1995-08-01/S0894-0347-1995-1260107-2/home.html">Kahn , Komlos, and Szemeredi proved</a> that <img alt="s(n) \le 0.999^n" class="latex" src="https://s0.wp.com/latex.php?latex=s%28n%29+%5Cle+0.999%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s(n) \le 0.999^n"/>. Terry Tao and Van Vu improved in 2006 the constant to 0.939 and then to (3/4+o(1)) and the, now broken, world record from 2010 was <img alt="(1/\sqrt 2)+o(1))^n" class="latex" src="https://s0.wp.com/latex.php?latex=%281%2F%5Csqrt+2%29%2Bo%281%29%29%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(1/\sqrt 2)+o(1))^n"/>  by Jean Bourgain, Van Vu and Philip Wood. Congratulations Konstantin!</p>
<p>If you want to tease the Gods of Mathematics you can try to prove that <img alt="s(n) =n(n-1)(1+o(1)) \cdot 2^{-n}" class="latex" src="https://s0.wp.com/latex.php?latex=s%28n%29+%3Dn%28n-1%29%281%2Bo%281%29%29+%5Ccdot+2%5E%7B-n%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s(n) =n(n-1)(1+o(1)) \cdot 2^{-n}"/>? and, as suggested in the Kahn-Komlós-Szemerédi paper,  even prove an expansion  <img alt="s(n) = 2{{n} \choose {2}}(\frac{1}{2})^{n}+2{{n}\choose {4}} (\frac{3}{8})^n\cdots" class="latex" src="https://s0.wp.com/latex.php?latex=s%28n%29+%3D+2%7B%7Bn%7D+%5Cchoose+%7B2%7D%7D%28%5Cfrac%7B1%7D%7B2%7D%29%5E%7Bn%7D%2B2%7B%7Bn%7D%5Cchoose+%7B4%7D%7D+%28%5Cfrac%7B3%7D%7B8%7D%29%5En%5Ccdots&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s(n) = 2{{n} \choose {2}}(\frac{1}{2})^{n}+2{{n}\choose {4}} (\frac{3}{8})^n\cdots"/> based on dependencies between <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-tuples of rows and columns.</p>
<p>Let me mention that  <a href="https://arxiv.org/abs/math/0505156">Kevin Costello, Tao, and Vu, proved in 2005</a> that  random symmetric matrices are almost surely non-singular.  This is related to beautiful mathematics. <a href="https://arxiv.org/abs/0804.2362"> Tao and Vu also proved</a> that the probability for vanishing of the permanent of a Bernoulli matrix is <img alt="o(1)" class="latex" src="https://s0.wp.com/latex.php?latex=o%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="o(1)"/>. I am not sure what is the proven behavior for permanents and one may expect that vanishing of the permanent occurs in probability which is super exponentially small. (Perhaps <img alt="C/\sqrt {n!}" class="latex" src="https://s0.wp.com/latex.php?latex=C%2F%5Csqrt+%7Bn%21%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C/\sqrt {n!}"/>.)</p>
<p>Here are related posts on Tao’s blog What’s New. <a href="https://terrytao.wordpress.com/2007/12/05/milliman-lecture-ii-additive-combinatorics-and-random-matrices/">A post on Tao’s Milliman’s lecture on the additive combinatorics and random matrices</a>; <a href="https://terrytao.wordpress.com/2008/04/16/on-the-permanent-of-a-random-bernoulli-matrix/">On the permamnent of random Bernoulli matrix</a>;</p>
<h3>Determinants and the guaranteed cancellation phenomenon</h3>
<p>The value of the determinant of a Bernoulli matrix is the sum of <em>n!</em> ±1 terms. So we can guess that the expected value will be around <img alt="\sqrt {n!}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csqrt+%7Bn%21%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sqrt {n!}"/>, and with high probability it is near the expected value. There is something special about the determinant which we can call the <strong>Guaranteed Cancellation Phenomenon (GCP)</strong>. The value of the determinant of a Bernoulli  matrix is at most <img alt="n^{n/2}" class="latex" src="https://s0.wp.com/latex.php?latex=n%5E%7Bn%2F2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n^{n/2}"/> which is not that much larger than <img alt="\sqrt {n!}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csqrt+%7Bn%21%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sqrt {n!}"/>. (GCP applies to matrices with real or complex variables with rows with prescribed  <img alt="\ell_2" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\ell_2"/> norms.)  Guaranteed cancellation is a very interesting mathematical phenomenon in various contexts. (For example, the prime number theorem and the Riemann hypothesis are about guaranteed cancellation.) The determinant itself is a polynomial of degree <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> with <img alt="n^2" class="latex" src="https://s0.wp.com/latex.php?latex=n%5E2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n^2"/> variables , and GCP for determinants was one of the starting points in a paper that I wrote with Leonard Schulman on <a href="https://arxiv.org/abs/1804.04828">quasi-random multilinear polynomials</a>. (For other examples of GCP see also this <a href="https://mathoverflow.net/questions/59530/horst-kn%C3%B6rrers-permutation-cancellation-problem">MO question</a> and various posts  on Mobius randomness.) Maybe it is time to ask on MathOverflow for a list of places were GCP  is expected or proven.)</p>
<p>Sperner, the Littlewood-Offord problem, and additive combinatorics</p>
<p>The determinant of a <img alt="\pm 1" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpm+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\pm 1"/> matrix is the signed sum of <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> minors. It follows from Sperner’s theorem that if <img alt="m" class="latex" src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m"/> of these minors are non-zero then the probability that the sum vanishes is <img alt="O(1/\sqrt m)" class="latex" src="https://s0.wp.com/latex.php?latex=O%281%2F%5Csqrt+m%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(1/\sqrt m)"/>. This is the idea behind Komlos’ second proof. The relevant general question (backward <a href="https://en.wikipedia.org/wiki/Littlewood%E2%80%93Offord_problem">Littlewood Offord</a>  problem) which is of much independent interest is “Under which conditions on a sequence <img alt="a_1,a_2, \dots, a_n" class="latex" src="https://s0.wp.com/latex.php?latex=a_1%2Ca_2%2C+%5Cdots%2C+a_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_1,a_2, \dots, a_n"/> we can guarantee that the probability that a signed sum of the sequence vanished (or has a small absolute value) is small.” The famous Erdos-Moser conjecture (solved on the nose by Stanley using the Hard Lefschetz theorem, sharpening a result by Sárközy and Szemerédi) asserts that if the elements of the sequence are distinct then the larger vanishing probability is attained by the sequence of integers between <em>-[n/2]</em> and +<em>[n/2]</em>. In this case (like for any arithmetic progression) the vanishing probability is <img alt="n^{-3/2}" class="latex" src="https://s0.wp.com/latex.php?latex=n%5E%7B-3%2F2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n^{-3/2}"/>.  Kahn, Komlos and Szemeredi relied on (and extended)  a theory by  Gábor Halász for guaranteeing that the vanishing probability is small (exponentially small) and, of course, much work is needed to prove that Halász-type conditions are satisfied.</p>
<p>I was excited by the 2005 solution for symmetric matrices also because it involved a quadratic version of Littlewood-Offord type results which are of much independent interest. I think that there are many interesting remaining open problems.</p>
<p> </p></div>
    </content>
    <updated>2019-02-02T18:37:12Z</updated>
    <published>2019-02-02T18:37:12Z</published>
    <category term="Combinatorics"/>
    <category term="Probability"/>
    <category term="Konstantin Tikhomirov"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-02-03T09:20:32Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-6555947.post-2316741109895040253</id>
    <link href="http://blog.geomblog.org/feeds/2316741109895040253/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://blog.geomblog.org/2019/02/more-fat-blogging.html#comment-form" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/6555947/posts/default/2316741109895040253" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/6555947/posts/default/2316741109895040253" rel="self" type="application/atom+xml"/>
    <link href="http://feedproxy.google.com/~r/TheGeomblog/~3/SO5XVo9kvXw/more-fat-blogging.html" rel="alternate" type="text/html"/>
    <title>More FAT* blogging</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Session 3: <a href="https://algorithmicfairness.wordpress.com/2019/01/30/fat-papers-profiling-and-representation/">Representation and Profiling</a><br/><br/>Session 4: <a href="https://algorithmicfairness.wordpress.com/2019/02/01/fat-papers-fairness-methods/">Fairness methods. </a><img alt="" height="1" src="http://feeds.feedburner.com/~r/TheGeomblog/~4/SO5XVo9kvXw" width="1"/></div>
    </content>
    <updated>2019-02-02T07:46:00Z</updated>
    <published>2019-02-02T07:46:00Z</published>
    <category scheme="http://www.blogger.com/atom/ns#" term="conf-blogs"/>
    <category scheme="http://www.blogger.com/atom/ns#" term="fat*"/><feedburner:origlink xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0">http://blog.geomblog.org/2019/02/more-fat-blogging.html</feedburner:origlink>
    <author>
      <name>Suresh Venkatasubramanian</name>
      <email>noreply@blogger.com</email>
      <uri>https://plus.google.com/112165457714968997350</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-6555947</id>
      <category term="research"/>
      <category term="community"/>
      <category term="miscellaneous"/>
      <category term="soda"/>
      <category term="conferences"/>
      <category term="data-mining"/>
      <category term="socg"/>
      <category term="blogosphere"/>
      <category term="publishing"/>
      <category term="clustering"/>
      <category term="teaching"/>
      <category term="jobs"/>
      <category term="funding"/>
      <category term="humor"/>
      <category term="awards"/>
      <category term="outreach"/>
      <category term="stoc"/>
      <category term="cs.CG"/>
      <category term="focs"/>
      <category term="nsf"/>
      <category term="reviewing"/>
      <category term="socg-2010"/>
      <category term="fairness"/>
      <category term="academy"/>
      <category term="latex"/>
      <category term="stoc2017"/>
      <category term="theoryfest"/>
      <category term="workshops"/>
      <category term="acm"/>
      <category term="conf-blogs"/>
      <category term="writing"/>
      <category term="cs.DS"/>
      <category term="cs.LG"/>
      <category term="geometry"/>
      <category term="p-vs-nc"/>
      <category term="advising"/>
      <category term="sabbatical"/>
      <category term="simons foundation"/>
      <category term="announcement"/>
      <category term="big-data"/>
      <category term="deadline"/>
      <category term="jeff phillips"/>
      <category term="streaming"/>
      <category term="books"/>
      <category term="large-data"/>
      <category term="p-vs-np"/>
      <category term="cra"/>
      <category term="cstheory"/>
      <category term="focs2010"/>
      <category term="icdm"/>
      <category term="math.PR"/>
      <category term="memorial"/>
      <category term="personal"/>
      <category term="posters"/>
      <category term="potd"/>
      <category term="rajeev motwani"/>
      <category term="shonan"/>
      <category term="socg2012"/>
      <category term="software"/>
      <category term="stoc2012"/>
      <category term="GIA"/>
      <category term="SDM"/>
      <category term="alenex"/>
      <category term="alenex2011"/>
      <category term="arxiv"/>
      <category term="career"/>
      <category term="complexity"/>
      <category term="cs.CC"/>
      <category term="deolalikar"/>
      <category term="distributions"/>
      <category term="madalgo"/>
      <category term="nips"/>
      <category term="sdm2011"/>
      <category term="shape"/>
      <category term="talks"/>
      <category term="technology"/>
      <category term="theory.SE"/>
      <category term="travel"/>
      <category term="video"/>
      <category term="8f-cg"/>
      <category term="DBR"/>
      <category term="ICS"/>
      <category term="LISPI"/>
      <category term="acceptances"/>
      <category term="bibtex"/>
      <category term="bregman"/>
      <category term="cfp"/>
      <category term="clustering-book"/>
      <category term="column"/>
      <category term="combinatorial geometry"/>
      <category term="current-distance"/>
      <category term="ecml-pkdd"/>
      <category term="empirical"/>
      <category term="esa"/>
      <category term="fat*"/>
      <category term="focs2012"/>
      <category term="focs2014"/>
      <category term="fwcg"/>
      <category term="game theory"/>
      <category term="godel"/>
      <category term="graphs"/>
      <category term="implementation"/>
      <category term="journals"/>
      <category term="kernels"/>
      <category term="misc"/>
      <category term="models"/>
      <category term="obituary"/>
      <category term="productivity"/>
      <category term="programming"/>
      <category term="society"/>
      <category term="soda2011"/>
      <category term="topology"/>
      <category term="turing"/>
      <category term="tv"/>
      <category term="women-in-theory"/>
      <category term=".02"/>
      <category term="IMA"/>
      <category term="MOOC"/>
      <category term="PPAD"/>
      <category term="accountability"/>
      <category term="active-learning"/>
      <category term="aggregator"/>
      <category term="algorithms"/>
      <category term="ams"/>
      <category term="analco"/>
      <category term="barriers"/>
      <category term="beamer"/>
      <category term="blogging"/>
      <category term="candes"/>
      <category term="civil rights"/>
      <category term="classification"/>
      <category term="coding-theory"/>
      <category term="coffee"/>
      <category term="conjecture"/>
      <category term="cosmos"/>
      <category term="counting"/>
      <category term="cricket"/>
      <category term="cs.DC"/>
      <category term="dagstuhl"/>
      <category term="databuse"/>
      <category term="dimacs"/>
      <category term="dimensionality-reduction"/>
      <category term="distributed-learning"/>
      <category term="double-blind review"/>
      <category term="duality"/>
      <category term="eda"/>
      <category term="embarrassing"/>
      <category term="expanders"/>
      <category term="experiments"/>
      <category term="fake-news"/>
      <category term="fatml"/>
      <category term="fellowships"/>
      <category term="focs2013"/>
      <category term="fonts"/>
      <category term="gct"/>
      <category term="ggplot"/>
      <category term="gpu"/>
      <category term="graph minors"/>
      <category term="gt.game-theory"/>
      <category term="guest-post"/>
      <category term="guitar"/>
      <category term="hangouts"/>
      <category term="hirsch"/>
      <category term="history"/>
      <category term="ipe"/>
      <category term="ita"/>
      <category term="jmm"/>
      <category term="k-12"/>
      <category term="knuth"/>
      <category term="machine-learning"/>
      <category term="massive"/>
      <category term="math.ST"/>
      <category term="media"/>
      <category term="memes"/>
      <category term="metoo"/>
      <category term="metrics"/>
      <category term="morris"/>
      <category term="movies"/>
      <category term="multicore"/>
      <category term="music"/>
      <category term="narrative"/>
      <category term="networks"/>
      <category term="nih"/>
      <category term="parallelism"/>
      <category term="partha niyogi"/>
      <category term="polymath"/>
      <category term="polymath research"/>
      <category term="polytopes"/>
      <category term="postdocs"/>
      <category term="privacy"/>
      <category term="quant-ph"/>
      <category term="quantum"/>
      <category term="randomness"/>
      <category term="review"/>
      <category term="sampling"/>
      <category term="seminars"/>
      <category term="social-networking"/>
      <category term="soda2014"/>
      <category term="students"/>
      <category term="sublinear"/>
      <category term="submissions"/>
      <category term="summer-school"/>
      <category term="superbowl"/>
      <category term="surveys"/>
      <category term="svn"/>
      <category term="television"/>
      <category term="traffic"/>
      <category term="twitter"/>
      <category term="utah"/>
      <category term="wads"/>
      <category term="white elephant"/>
      <category term="xkcd"/>
      <author>
        <name>Suresh Venkatasubramanian</name>
        <email>noreply@blogger.com</email>
      </author>
      <link href="http://blog.geomblog.org/" rel="alternate" type="text/html"/>
      <link href="http://www.blogger.com/feeds/6555947/posts/default?alt=atom&amp;start-index=26&amp;max-results=25&amp;redirect=false" rel="next" type="application/atom+xml"/>
      <link href="http://feeds.feedburner.com/TheGeomblog" rel="self" type="application/atom+xml"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <subtitle>Ruminations on computational geometry, algorithms, theoretical computer science and life</subtitle>
      <title>The Geomblog</title>
      <updated>2019-02-02T07:46:06Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1901.11477</id>
    <link href="http://arxiv.org/abs/1901.11477" rel="alternate" type="text/html"/>
    <title>Text line Segmentation in Compressed Representation of Handwritten Document using Tunneling Algorithm</title>
    <feedworld_mtime>1549065600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/R:Amarnath.html">Amarnath R</a>, P Nagabhushan <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1901.11477">PDF</a><br/><b>Abstract: </b>In this research work, we perform text line segmentation directly in
compressed representation of an unconstrained handwritten document image. In
this relation, we make use of text line terminal points which is the current
state-of-the-art. The terminal points spotted along both margins (left and
right) of a document image for every text line are considered as source and
target respectively. The tunneling algorithm uses a single agent (or robot) to
identify the coordinate positions in the compressed representation to perform
text-line segmentation of the document. The agent starts at a source point and
progressively tunnels a path routing in between two adjacent text lines and
reaches the probable target. The agent's navigation path from source to the
target bypassing obstacles, if any, results in segregating the two adjacent
text lines. However, the target point would be known only when the agent
reaches the destination; this is applicable for all source points and
henceforth we could analyze the correspondence between source and target nodes.
Artificial Intelligence in Expert systems, dynamic programming and greedy
strategies are employed for every search space while tunneling. An exhaustive
experimentation is carried out on various benchmark datasets including ICDAR13
and the performances are reported.
</p></div>
    </summary>
    <updated>2019-02-02T23:32:10Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1901.11453</id>
    <link href="http://arxiv.org/abs/1901.11453" rel="alternate" type="text/html"/>
    <title>The SuperM-Tree: Indexing metric spaces with sized objects</title>
    <feedworld_mtime>1549065600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bachmann:J=ouml=rg_P=.html">Jörg P. Bachmann</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1901.11453">PDF</a><br/><b>Abstract: </b>A common approach to implementing similarity search applications is the usage
of distance functions, where small distances indicate high similarity. In the
case of metric distance functions, metric index structures can be used to
accelerate nearest neighbor queries. On the other hand, many applications ask
for approximate subsequences or subsets, e.g. searching for a similar partial
sequence of a gene, for a similar scene in a movie, or for a similar object in
a picture which is represented by a set of multidimensional features. Metric
index structures such as the M-Tree cannot be utilized for these tasks because
of the symmetry of the metric distance functions. In this work, we propose the
SuperM-Tree as an extension of the M-Tree where approximate subsequence and
subset queries become nearest neighbor queries. In order to do this, we
introduce metric subset spaces as a generalized concept of metric spaces.
Various metric distance functions can be extended to metric subset distance
functions, e.g. the Euclidean distance (on windows), the Hausdorff distance (on
subsets), the Edit distance and the Dog-Keeper distance (on subsequences). We
show that these examples subsume the applications mentioned above.
</p></div>
    </summary>
    <updated>2019-02-02T23:32:06Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1901.11343</id>
    <link href="http://arxiv.org/abs/1901.11343" rel="alternate" type="text/html"/>
    <title>Algorithmic counting of nonequivalent compact Huffman codes</title>
    <feedworld_mtime>1549065600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Elsholtz:Christian.html">Christian Elsholtz</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Heuberger:Clemens.html">Clemens Heuberger</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Krenn:Daniel.html">Daniel Krenn</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1901.11343">PDF</a><br/><b>Abstract: </b>It is known that the following five counting problems lead to the same
integer sequence~$f_t(n)$: the number of nonequivalent compact Huffman codes of
length~$n$ over an alphabet of $t$ letters, the number of `nonequivalent'
canonical rooted $t$-ary trees (level-greedy trees) with $n$~leaves, the number
of `proper' words, the number of bounded degree sequences, and the number of
ways of writing $1= \frac{1}{t^{x_1}}+ \dots + \frac{1}{t^{x_n}}$ with integers
$0 \leq x_1 \leq x_2 \leq \dots \leq x_n$. In this work, we show that one can
compute this sequence for \textbf{all} $n&lt;N$ with essentially one power series
division. In total we need at most $N^{1+\varepsilon}$ additions and
multiplications of integers of $cN$ bits, $c&lt;1$, or $N^{2+\varepsilon}$ bit
operations, respectively. This improves an earlier bound by Even and Lempel who
needed $O(N^3)$ operations in the integer ring or $O(N^4)$ bit operations,
respectively.
</p></div>
    </summary>
    <updated>2019-02-02T23:21:31Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-02-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1901.11305</id>
    <link href="http://arxiv.org/abs/1901.11305" rel="alternate" type="text/html"/>
    <title>Quasi-Linear-Time Algorithm for Longest Common Circular Factor</title>
    <feedworld_mtime>1549065600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Alzamel:Mai.html">Mai Alzamel</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Crochemore:Maxime.html">Maxime Crochemore</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Iliopoulos:Costas_S=.html">Costas S. Iliopoulos</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kociumaka:Tomasz.html">Tomasz Kociumaka</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Radoszewski:Jakub.html">Jakub Radoszewski</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rytter:Wojciech.html">Wojciech Rytter</a>, Juliusz Straszyński, Tomasz Waleń, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zuba:Wiktor.html">Wiktor Zuba</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1901.11305">PDF</a><br/><b>Abstract: </b>We introduce the Longest Common Circular Factor (LCCF) problem in which,
given strings $S$ and $T$ of length $n$, we are to compute the longest factor
of $S$ whose cyclic shift occurs as a factor of $T$. It is a new similarity
measure, an extension of the classic Longest Common Factor. We show how to
solve the LCCF problem in $O(n \log^5 n)$ time.
</p></div>
    </summary>
    <updated>2019-02-02T23:22:49Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1901.11285</id>
    <link href="http://arxiv.org/abs/1901.11285" rel="alternate" type="text/html"/>
    <title>Reachability in High Treewidth Graphs</title>
    <feedworld_mtime>1549065600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jain:Rahul.html">Rahul Jain</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tewari:Raghunath.html">Raghunath Tewari</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1901.11285">PDF</a><br/><b>Abstract: </b>Reachability is the problem of deciding whether there is a path from one
vertex to the other in the graph. Standard graph traversal algorithms such as
DFS and BFS take linear time to decide reachability however their space
complexity is also linear. On the other hand, Savitch's algorithm takes
quasipolynomial time although the space bound is $O(\log^2 n)$. Here, we study
space efficient algorithms for deciding reachability that runs simultaneously
in polynomial time.
</p>
<p>In this paper, we show that given an $n$ vertex directed graph of treewidth
$w$ along with its tree decomposition, there exists an algorithm running in
polynomial time and $O(w\log n)$ space, that solves reachability in the graph.
</p></div>
    </summary>
    <updated>2019-02-02T23:21:09Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-02-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1901.11260</id>
    <link href="http://arxiv.org/abs/1901.11260" rel="alternate" type="text/html"/>
    <title>Multistage Knapsack</title>
    <feedworld_mtime>1549065600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bampis:Evripidis.html">Evripidis Bampis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Escoffier:Bruno.html">Bruno Escoffier</a>, Alexandre Teiller <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1901.11260">PDF</a><br/><b>Abstract: </b>Many systems have to be maintained while the underlying constraints, costs
and/or profits change over time. Although the state of a system may evolve
during time, a non-negligible transition cost is incured for transitioning from
one state to another. In order to model such situations, Gupta et al. (ICALP
2014) and Eisenstat et al. (ICALP 2014) introduced a multistage model where the
input is a sequence of instances (one for each time step), and the goal is to
find a sequence of solutions (one for each time step) that are both (i) near
optimal for each time step and (ii) as stable as possible. We focus on the
multistage version of the Knapsack problem where we are given a time horizon
t=1,2,...,T, and a sequence of knapsack instances I_1,I_2,...,I_T, one for each
time step, defined on a set of n objects. In every time step t we have to
choose a feasible knapsack S_t of I_t, which gives a knapsack profit. To
measure the stability/similarity of two consecutive solutions S_t and S_{t+1},
we identify the objects for which the decision, to be picked or not, remains
the same in S_t and S_{t+1}, giving a transition profit. We are asked to
produce a sequence of solutions S_1,S_2,...,S_T so that the total knapsack
profit plus the overall transition profit is maximized.
</p>
<p>We propose a PTAS for the Multistage Knapsack problem. Then, we prove that
there is no FPTAS for the problem even in the case where T=2, unless P=NP.
Furthermore, we give a pseudopolynomial time algorithm for the case where the
number of steps is bounded by a fixed constant and we show that otherwise the
problem remains NP-hard even in the case where all the weights, profits and
capacities are 0 or 1.
</p></div>
    </summary>
    <updated>2019-02-02T23:21:53Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1901.11082</id>
    <link href="http://arxiv.org/abs/1901.11082" rel="alternate" type="text/html"/>
    <title>DDSL: Deep Differentiable Simplex Layer for Learning Geometric Signals</title>
    <feedworld_mtime>1549065600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Chiyu "Max" Jiang, Dana Lynn Ona Lansigan, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Marcus:Philip.html">Philip Marcus</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nie=szlig=ner:Matthias.html">Matthias Nießner</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1901.11082">PDF</a><br/><b>Abstract: </b>We present a Deep Differentiable Simplex Layer (DDSL) for neural networks for
geometric deep learning. The DDSL is a differentiable layer compatible with
deep neural networks for bridging simplex mesh-based geometry representations
(point clouds, line mesh, triangular mesh, tetrahedral mesh) with raster images
(e.g., 2D/3D grids). The DDSL uses Non-Uniform Fourier Transform (NUFT) to
perform differentiable, efficient, anti-aliased rasterization of simplex-based
signals. We present a complete theoretical framework for the process as well as
an efficient backpropagation algorithm. Compared to previous differentiable
renderers and rasterizers, the DDSL generalizes to arbitrary simplex degrees
and dimensions. In particular, we explore its applications to 2D shapes and
illustrate two applications of this method: (1) mesh editing and optimization
guided by neural network outputs, and (2) using DDSL for a differentiable
rasterization loss to facilitate end-to-end training of polygon generators. We
are able to validate the effectiveness of gradient-based shape optimization
with the example of airfoil optimization, and using the differentiable
rasterization loss to facilitate end-to-end training, we surpass state of the
art for polygonal image segmentation given ground-truth bounding boxes.
</p></div>
    </summary>
    <updated>2019-02-02T23:32:18Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-02-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1901.11023</id>
    <link href="http://arxiv.org/abs/1901.11023" rel="alternate" type="text/html"/>
    <title>The Semialgebraic Orbit Problem</title>
    <feedworld_mtime>1549065600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Almagor:Shaull.html">Shaull Almagor</a>, Joël Oukanine, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Worrell:James.html">James Worrell</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1901.11023">PDF</a><br/><b>Abstract: </b>The Semialgebraic Orbit Problem is a fundamental reachability question that
arises in the analysis of discrete-time linear dynamical systems such as
automata, Markov chains, recurrence sequences, and linear while loops. An
instance of the problem comprises a dimension $d\in\mathbb{N}$, a square matrix
$A\in\mathbb{Q}^{d\times d}$, and semialgebraic source and target sets
$S,T\subseteq \mathbb{R}^d$. The question is whether there exists $x\in S$ and
$n\in\mathbb{N}$ such that $A^nx \in T$. The main result of this paper is that
the Semialgebraic Orbit Problem is decidable for dimension $d\leq 3$. Our
decision procedure relies on separation bounds for algebraic numbers as well as
a classical result of transcendental number theory---Baker's theorem on linear
forms in logarithms of algebraic numbers. We moreover argue that our main
result represents a natural limit to what can be decided (with respect to
reachability) about the orbit of a single matrix. On the one hand,
semialgebraic sets are arguably the largest general class of subsets of
$\mathbb{R}^d$ for which membership is decidable. On the other hand, previous
work has shown that in dimension $d=4$, giving a decision procedure for the
special case of the Orbit Problem with singleton source set $S$ and polytope
target set $T$ would entail major breakthroughs in Diophantine approximation.
</p></div>
    </summary>
    <updated>2019-02-02T23:20:43Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-02-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=7467</id>
    <link href="https://windowsontheory.org/2019/02/01/black-holes-a-complexity-theory-perspective/" rel="alternate" type="text/html"/>
    <title>Black Holes, a Complexity Theory perspective</title>
    <summary>Guest post by Chi-Ning Chou and Parth Mehta from the physics and computation seminar. Abstract The firewall paradox (introduced here) is a bewitching thought experiment that mandates a deeper understanding of our reality. As luck would have it, QFT predictions seem sound, GR calculations appear valid, and semi-classical approximations look reasonable: no one is willing […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Guest post by Chi-Ning Chou and Parth Mehta from <a href="https://www.boazbarak.org/fall18seminar/">the physics and computation seminar</a>.</p>
<h3>Abstract</h3>
<p>The firewall paradox (introduced <em>here</em>) is a bewitching thought experiment that mandates a deeper understanding of our reality. As luck would have it, QFT predictions seem sound, GR calculations appear valid, and semi-classical approximations look reasonable: no one is willing to budge! To save Alice from burning in the miserable firewall, therefore, we must come up with a radically new proposal. This blog post aims to map what seems to be a hard, physics dilemma into a Computer Science problem that we can, using the grace of a lazy programmer, show to be hard to solve. In particular, we present an overview of the Harlow-Hayden decoding task and show how it maps the Firewall Paradox to a hard computation on a quantum computer. We end by rigorously defining quantum circuit complexity, Aaronson’s improved proof, AdS/CFT correspondence, and some fascinating homework (open) problems.</p>
<h2>Why all the fuss?</h2>
<p>Have you ever confessed to yourself that you don’t quite understand Black Hole complementarity well? In the past decade or so, physicists realized they did not grasp the concept thoroughly either. The firewall paradox is a natural result of bewildered physicists trying to make sense of reality. Thus far, no satisfying physical explanation reaches people’s consensus. Nevertheless, Daniel Harlow and Patrick Hayden [HH13] proposed a tempting solution to the firewall paradox using Computational Complexity (CC). Concretely, they showed the following.</p>
<p style="text-align: center;"><img alt="\text{A conjecture in CC is true}\Rightarrow\text{Firewalls do not exist}." class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctext%7BA+conjecture+in+CC+is+true%7D%5CRightarrow%5Ctext%7BFirewalls+do+not+exist%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\text{A conjecture in CC is true}\Rightarrow\text{Firewalls do not exist}."/></p>
<p>We elaborate on this deep connection throughout this post.</p>
<h3>Problem Solving: Physics v.s. Computer Science</h3>
<p>The notion of a `conjecture’ has different implications for either field. In Physics, a wrong conjecture often delights physicists since there is more work left to do and better theory required to explain the physical phenomenon under study. For complexity theorists, however, if, say, the famous <img alt="\mathbf{P}\neq\mathbf{NP}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BP%7D%5Cneq%5Cmathbf%7BNP%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{P}\neq\mathbf{NP}"/> is proved to be false, a few consequences follow. First, the authors of the proof win a million dollars (See the <a href="http://www.claymath.org/millennium-problems/p-vs-np-problem" rel="noopener" target="_blank">Millennium problems</a>.). Second, such a result would break almost all the foundations of computational complexity and cryptography. That is, refuting an (important) conjecture in computational complexity is tantamount to resulting in real-world catastrophes! Below in Table 1 is a short summary.</p>
<table style="border: 1px solid black; border-collapse: collapse;">
<tbody>
<tr style="border: 1px solid black;">
<td style="border: 1px solid black;"/>
<td style="border: 1px solid black;">Theoretical Physics</td>
<td style="border: 1px solid black;">Theoretical Computer Science</td>
</tr>
<tr style="border: 1px solid black;">
<td style="border: 1px solid black;">Object</td>
<td style="border: 1px solid black;">Are the mathematical models for our physical world correct?</td>
<td style="border: 1px solid black;">Is our intuition about the mathematical models we defined correct?</td>
</tr>
<tr style="border: 1px solid black;">
<td style="border: 1px solid black;">Consequences of disproving</td>
<td style="border: 1px solid black;">After few days/months/years, physicists will come up with a new model and try to falsify it.</td>
<td style="border: 1px solid black;">The belief system of complexity theorists collapses. Some super algorithms might show up and shake the world.</td>
</tr>
<tr style="border: 1px solid black;">
<td style="border: 1px solid black;">How to prove/disprove</td>
<td style="border: 1px solid black;">Checking mathematical consistency, doing both thought and empirical experiments.</td>
<td style="border: 1px solid black;">Using fancy mathematics or designing super algorithms.</td>
</tr>
</tbody>
</table>
<p style="text-align: center;">Table 1: “Conjecture”, as used in Physics and Computer Science.</p>
<p>We labour above to convince the reader about these differences because the Harlow-Hayden decoding task has vital implications for both, Physics and Computer Science. The connections between Black Holes and Computational Complexity can be thought of as a new <em>testbench</em> for physical models.</p>
<h2>Reckless review: Quantum Information</h2>
<h3>Gates</h3>
<p>In Quantum Computation, gates are unitary operators. Some common gates used in the Quantum Information literature are as follows:</p>
<ul>
<li>
<div>Single-qubit: Pauli matrices (<em>i.e.,</em> <img alt="X,Y,Z" class="latex" src="https://s0.wp.com/latex.php?latex=X%2CY%2CZ&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X,Y,Z"/>), phase operator <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/>, Hadamard matrix <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/>.</div>
</li>
<li>
<div>Two-qubit: CNOT, Toffoli, CZ.</div>
</li>
</ul>
<p>For more details, please refer to [NC02]. Interestingly enough, singe-qubit and two-qubit gates are sufficient to construct any <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>-qubit gates! Such a set of operators is said to be <em>universal</em>. For example, <img alt="\{\text{Toffoli},H,P\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B%5Ctext%7BToffoli%7D%2CH%2CP%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{\text{Toffoli},H,P\}"/> and <img alt="\{\text{CNOT},G\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B%5Ctext%7BCNOT%7D%2CG%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{\text{CNOT},G\}"/> are universal for almost every single-qubit operator. Furthermore, Kitaev and Solovay gave a <em>qualitative</em> version of the universality theorem by showing that getting an <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon"/> approximation to an <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>-qubit operator in trace norm, only <img alt="O(\log^21/\epsilon)" class="latex" src="https://s0.wp.com/latex.php?latex=O%28%5Clog%5E21%2F%5Cepsilon%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(\log^21/\epsilon)"/> gates are needed. A final remark on unitary operators: an <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>-qubit operator is actually a matrix of size <img alt="2^n" class="latex" src="https://s0.wp.com/latex.php?latex=2%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^n"/> by <img alt="2^n" class="latex" src="https://s0.wp.com/latex.php?latex=2%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^n"/>. Namely, it requires <img alt="2^{2n}-2^n" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7B2n%7D-2%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{2n}-2^n"/> complex numbers to describe an <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>-qubit operator. (Note the difference between <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> and <img alt="2^n" class="latex" src="https://s0.wp.com/latex.php?latex=2%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^n"/>.)</p>
<h3>Quantum circuits</h3>
<p>A quantum circuit <img alt="\mathcal{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{C}"/> has inputs consisting of <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>-qubits, potentially with <img alt="m" class="latex" src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m"/> <em><a href="https://en.wikipedia.org/wiki/Ancilla_bit" rel="noopener" target="_blank">ancilla bits</a></em>. The computation is done by interior gates from some universal gate set, <em>e.g., </em><img alt="\{\text{Toffoli},H,P\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B%5Ctext%7BToffoli%7D%2CH%2CP%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{\text{Toffoli},H,P\}"/>. The outputs are <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> qubits with potentially <img alt="m" class="latex" src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m"/> bits of garbage. See the following example of quantum circuit for the <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>-qubit Hadamard operator <img alt="H_n| x\rangle=\sum_{y\in\{0,1\}^n}(-1)^{\langle x,y\rangle}|y\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=H_n%7C+x%5Crangle%3D%5Csum_%7By%5Cin%5C%7B0%2C1%5C%7D%5En%7D%28-1%29%5E%7B%5Clangle+x%2Cy%5Crangle%7D%7Cy%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H_n| x\rangle=\sum_{y\in\{0,1\}^n}(-1)^{\langle x,y\rangle}|y\rangle"/> in Figure 1.</p>
<div class="wp-caption aligncenter" id="attachment_7472" style="width: 413px;"><img alt="hadamard" class="alignnone  wp-image-7472" height="266" src="https://windowsontheory.files.wordpress.com/2019/02/hadamard-e1549002349573.png?w=403&amp;h=266" width="403"/><p class="wp-caption-text">Figure 1: A quantum circuit for the n-qubit Hadamard operator.</p></div>
<p>Similarly, the size of a quantum circuit is defined as the number of interior gates. In Figure 1 for example, the size of the circuit is <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>.</p>
<h3>Quantum circuit complexity: <strong>BQP/poly</strong></h3>
<p>Let <img alt="f:\{0,1\}^n\rightarrow\{0,1\}" class="latex" src="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D%5En%5Crightarrow%5C%7B0%2C1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f:\{0,1\}^n\rightarrow\{0,1\}"/> be a boolean function. Define its quantum circuit complexity as the size of the smallest quantum circuit <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/> such that for any <img alt="x\in\{0,1\}^n" class="latex" src="https://s0.wp.com/latex.php?latex=x%5Cin%5C%7B0%2C1%5C%7D%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x\in\{0,1\}^n"/></p>
<p style="text-align: center;"><img alt="\Pr\left[\mathcal{M}_1(C|x\rangle)=f(x)\right]\geq\frac{2}{3}." class="latex" src="https://s0.wp.com/latex.php?latex=%5CPr%5Cleft%5B%5Cmathcal%7BM%7D_1%28C%7Cx%5Crangle%29%3Df%28x%29%5Cright%5D%5Cgeq%5Cfrac%7B2%7D%7B3%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Pr\left[\mathcal{M}_1(C|x\rangle)=f(x)\right]\geq\frac{2}{3}."/></p>
<p>Let <img alt="\mathbf{BQSIZE}[s(n)]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BBQSIZE%7D%5Bs%28n%29%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{BQSIZE}[s(n)]"/> denote the class of boolean functions of quantum circuit complexity at most <img alt="s(n)" class="latex" src="https://s0.wp.com/latex.php?latex=s%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s(n)"/>. The complexity class <img alt="\mathbf{BQP/poly}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BBQP%2Fpoly%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{BQP/poly}"/> is defined as <img alt="\cup_{c\in\mathbb{N}}\mathbf{BQSIZE}[n^c]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ccup_%7Bc%5Cin%5Cmathbb%7BN%7D%7D%5Cmathbf%7BBQSIZE%7D%5Bn%5Ec%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\cup_{c\in\mathbb{N}}\mathbf{BQSIZE}[n^c]"/>. It immediately follows from definition that <img alt="\mathbf{P/poly}\subseteq\mathbf{BQP/poly}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BP%2Fpoly%7D%5Csubseteq%5Cmathbf%7BBQP%2Fpoly%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{P/poly}\subseteq\mathbf{BQP/poly}"/>. As proving lower bound for <img alt="\mathbf{P/poly}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BP%2Fpoly%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{P/poly}"/> (<em>i.e.,</em> finding a problem that is not in <img alt="\mathbf{P/poly}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BP%2Fpoly%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{P/poly}"/>) is a long-standing extremely difficult problem, it is believed to be hard to prove lower bound against <img alt="\mathbf{BQP/poly}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BBQP%2Fpoly%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{BQP/poly}"/>.</p>
<h3>Uniform quantum circuit complexity: BQP</h3>
<p>As <img alt="\mathbf{BQP/poly}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BBQP%2Fpoly%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{BQP/poly}"/> is too powerful to work with, one might want to define a weaker version of the quantum complexity measure. A natural choice is considering a <em>uniform</em> computational model.</p>
<p>In the classical setting, a uniform computational model is defined using a Turing machine. However, it is not clear how to define the corresponding version, a quantum Turing machine. One way to do so is via <em>uniform circuits</em>, defined as follows. We say a circuit family <img alt="\mathcal{C}=\{C_n\}_{n\in\mathbb{N}}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D%3D%5C%7BC_n%5C%7D_%7Bn%5Cin%5Cmathbb%7BN%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{C}=\{C_n\}_{n\in\mathbb{N}}"/> is <img alt="\mathbf{P}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BP%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{P}"/>-uniform if there exists a polynomial time Turing machine such that on input <img alt="1^n" class="latex" src="https://s0.wp.com/latex.php?latex=1%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1^n"/>, it outputs <img alt="C_n" class="latex" src="https://s0.wp.com/latex.php?latex=C_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_n"/>.</p>
<p>Let <img alt="f:\{0,1\}^n\rightarrow\{0,1\}" class="latex" src="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D%5En%5Crightarrow%5C%7B0%2C1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f:\{0,1\}^n\rightarrow\{0,1\}"/> be a boolean function. Define its uniform quantum circuit complexity as the size of the smallest <strong>uniform</strong> quantum circuit <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/> such that for any <img alt="x\in\{0,1\}^n" class="latex" src="https://s0.wp.com/latex.php?latex=x%5Cin%5C%7B0%2C1%5C%7D%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x\in\{0,1\}^n"/></p>
<p style="text-align: center;"><img alt="\Pr\left[\mathcal{M}_1(C|x\rangle)=f(x)\right]\geq\frac{2}{3}." class="latex" src="https://s0.wp.com/latex.php?latex=%5CPr%5Cleft%5B%5Cmathcal%7BM%7D_1%28C%7Cx%5Crangle%29%3Df%28x%29%5Cright%5D%5Cgeq%5Cfrac%7B2%7D%7B3%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Pr\left[\mathcal{M}_1(C|x\rangle)=f(x)\right]\geq\frac{2}{3}."/></p>
<p>Let <img alt="\mathbf{BQTIME}[s(n)]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BBQTIME%7D%5Bs%28n%29%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{BQTIME}[s(n)]"/> denote the class of boolean functions of quantum circuit complexity at most <img alt="s(n)" class="latex" src="https://s0.wp.com/latex.php?latex=s%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s(n)"/>. The complexity class <img alt="\mathbf{BQP}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BBQP%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{BQP}"/> is defined as <img alt="\cup_{c\in\mathbb{N}}\mathbf{BQTIME}[n^c]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ccup_%7Bc%5Cin%5Cmathbb%7BN%7D%7D%5Cmathbf%7BBQTIME%7D%5Bn%5Ec%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\cup_{c\in\mathbb{N}}\mathbf{BQTIME}[n^c]"/>. It immediately follows from definition that <img alt="\mathbf{P}\subseteq\mathbf{BPP}\subseteq\mathbf{BQP}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BP%7D%5Csubseteq%5Cmathbf%7BBPP%7D%5Csubseteq%5Cmathbf%7BBQP%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{P}\subseteq\mathbf{BPP}\subseteq\mathbf{BQP}"/>.</p>
<h3>Unitary complexity: C(U)</h3>
<p>Let <img alt="U\in\mathbb{C}^{2^n\times2^n}" class="latex" src="https://s0.wp.com/latex.php?latex=U%5Cin%5Cmathbb%7BC%7D%5E%7B2%5En%5Ctimes2%5En%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U\in\mathbb{C}^{2^n\times2^n}"/> be an unitary matrix. Define <img alt="C(U)" class="latex" src="https://s0.wp.com/latex.php?latex=C%28U%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C(U)"/> be the smallest quantum circuit <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/> such that</p>
<p style="text-align: center;"><img alt="\|C-U\|_{\infty}\leq\frac{1}{3}." class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7CC-U%5C%7C_%7B%5Cinfty%7D%5Cleq%5Cfrac%7B1%7D%7B3%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\|C-U\|_{\infty}\leq\frac{1}{3}."/></p>
<p>This unitary complexity can be thought of as a relaxation of the quantum circuit complexity. The reason is that here a unitary matrix <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/> might not compute a boolean function. Thus, proving a lower bound for <img alt="\mathbf{BQSIZE}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BBQSIZE%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{BQSIZE}"/> implies a lower bound for unitary complexity while the converse is not clear. Namely, proving a super-polynomial lower bound for the unitary complexity might be an easier task.</p>
<p>However, no non-trivial<sup>1</sup> lower bound for the unitary complexity is known and there is, unfortunately, no formal <em>barrier result</em> explaining why this is difficult to prove.</p>
<h3>Warm-up: Gottesman-Knill</h3>
<p>We defined quantum circuits above, and we hope you find them exotic – at least start-up investors do. But given how fundamental quantum circuits are to the Harlow-Hayden decoding task, we ask: is it possible to efficiently (classically) simulate a quantum circuit made up of a restricted but non-trivial set of quantum gates? We show below a restricted variant of the popular Gottesman-Knill Theorem:</p>
<blockquote><p><strong>Theorem (Gottesman-Knill).<br/>
</strong><span style="color: #4b4f53; background-color: #ffffff;">1. Given: Clifford circuit <img alt="\mathcal{C}: |\alpha_1\rangle\otimes \cdots \otimes |\alpha_n\rangle \rightarrow \{|0\rangle,|1\rangle\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D%3A+%7C%5Calpha_1%5Crangle%5Cotimes+%5Ccdots+%5Cotimes+%7C%5Calpha_n%5Crangle+%5Crightarrow+%5C%7B%7C0%5Crangle%2C%7C1%5Crangle%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{C}: |\alpha_1\rangle\otimes \cdots \otimes |\alpha_n\rangle \rightarrow \{|0\rangle,|1\rangle\}"/> made up of gates <img alt="\{CNOT, P, H\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7BCNOT%2C+P%2C+H%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{CNOT, P, H\}"/>, where <img alt="\mathcal{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{C}"/> is measured on its first output line.<br/>
</span><span style="color: #4b4f53; background-color: #ffffff;">2.Task: Show that it is possible to (classically) efficiently sample the output distribution of <img alt="\mathcal{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{C}"/>.</span></p></blockquote>
<p><em>Proof:</em></p>
<p><img alt="\Pr(0) = \langle{\psi_0|\mathcal{C}^{\dag}(|0\rangle}\langle0|)\mathcal{C}|\psi_0\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%5CPr%280%29+%3D+%5Clangle%7B%5Cpsi_0%7C%5Cmathcal%7BC%7D%5E%7B%5Cdag%7D%28%7C0%5Crangle%7D%5Clangle0%7C%29%5Cmathcal%7BC%7D%7C%5Cpsi_0%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Pr(0) = \langle{\psi_0|\mathcal{C}^{\dag}(|0\rangle}\langle0|)\mathcal{C}|\psi_0\rangle"/> where <img alt="|\psi_0\rangle = |\alpha_1\rangle\otimes \cdots \otimes |\alpha_n\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi_0%5Crangle+%3D+%7C%5Calpha_1%5Crangle%5Cotimes+%5Ccdots+%5Cotimes+%7C%5Calpha_n%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi_0\rangle = |\alpha_1\rangle\otimes \cdots \otimes |\alpha_n\rangle"/>. Since the projector can be written as <img alt="|0\rangle\langle0|= \frac{I + Z}{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7C0%5Crangle%5Clangle0%7C%3D+%5Cfrac%7BI+%2B+Z%7D%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|0\rangle\langle0|= \frac{I + Z}{2}"/>, we get</p>
<p style="text-align: center;"><img alt="\Pr(0) = \langle\psi_0|\mathcal{C}^{\dag}(\frac{I + Z}{2})\mathcal{C}|\psi_0\rangle =\frac{1}{2}[1 + \langle\psi_0|\mathcal{C}^{\dag}Z_1\mathcal{C}|\psi_0\rangle]" class="latex" src="https://s0.wp.com/latex.php?latex=%5CPr%280%29+%3D+%5Clangle%5Cpsi_0%7C%5Cmathcal%7BC%7D%5E%7B%5Cdag%7D%28%5Cfrac%7BI+%2B+Z%7D%7B2%7D%29%5Cmathcal%7BC%7D%7C%5Cpsi_0%5Crangle+%3D%5Cfrac%7B1%7D%7B2%7D%5B1+%2B+%5Clangle%5Cpsi_0%7C%5Cmathcal%7BC%7D%5E%7B%5Cdag%7DZ_1%5Cmathcal%7BC%7D%7C%5Cpsi_0%5Crangle%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Pr(0) = \langle\psi_0|\mathcal{C}^{\dag}(\frac{I + Z}{2})\mathcal{C}|\psi_0\rangle =\frac{1}{2}[1 + \langle\psi_0|\mathcal{C}^{\dag}Z_1\mathcal{C}|\psi_0\rangle]"/></p>
<p>where <img alt="Z_1 = Z \otimes I\cdots \otimes I" class="latex" src="https://s0.wp.com/latex.php?latex=Z_1+%3D+Z+%5Cotimes+I%5Ccdots+%5Cotimes+I&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Z_1 = Z \otimes I\cdots \otimes I"/> since we only measure the first output line of <img alt="\mathcal{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{C}"/>. At first glance, <img alt="\langle\psi_0|\mathcal{C}^{\dag}Z_1\mathcal{C}|\psi_0\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clangle%5Cpsi_0%7C%5Cmathcal%7BC%7D%5E%7B%5Cdag%7DZ_1%5Cmathcal%7BC%7D%7C%5Cpsi_0%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\langle\psi_0|\mathcal{C}^{\dag}Z_1\mathcal{C}|\psi_0\rangle"/> might look like a monstrous computation to perform since, in general, the operator in the middle is a <img alt="2^n\times 2^n" class="latex" src="https://s0.wp.com/latex.php?latex=2%5En%5Ctimes+2%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^n\times 2^n"/> matrix, so the calculating the inner product would require exponential time classically. However, recognizing that Clifford gates are normalizers of the Pauli Group on <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> qubits, note that <img alt="\mathcal{C}^{\dag}Z_1\mathcal{C} = P_1 \otimes \cdots \otimes P_n" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D%5E%7B%5Cdag%7DZ_1%5Cmathcal%7BC%7D+%3D+P_1+%5Cotimes+%5Ccdots+%5Cotimes+P_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{C}^{\dag}Z_1\mathcal{C} = P_1 \otimes \cdots \otimes P_n"/> where <img alt="P_i" class="latex" src="https://s0.wp.com/latex.php?latex=P_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P_i"/> is some Pauli matrix. It is straightforward to show that these update rules can be computed efficiently. We thus have</p>
<p><img alt="\langle\psi_0|\mathcal{C}^{\dag}Z_1\mathcal{C}|\psi_0\rangle = \langle\psi_0|P_1 \otimes \cdots \otimes P_n|\psi_0\rangle = \prod_{i = 1}^{n} \langle\alpha_i|P_i|\alpha_i\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clangle%5Cpsi_0%7C%5Cmathcal%7BC%7D%5E%7B%5Cdag%7DZ_1%5Cmathcal%7BC%7D%7C%5Cpsi_0%5Crangle+%3D+%5Clangle%5Cpsi_0%7CP_1+%5Cotimes+%5Ccdots+%5Cotimes+P_n%7C%5Cpsi_0%5Crangle+%3D+%5Cprod_%7Bi+%3D+1%7D%5E%7Bn%7D+%5Clangle%5Calpha_i%7CP_i%7C%5Calpha_i%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\langle\psi_0|\mathcal{C}^{\dag}Z_1\mathcal{C}|\psi_0\rangle = \langle\psi_0|P_1 \otimes \cdots \otimes P_n|\psi_0\rangle = \prod_{i = 1}^{n} \langle\alpha_i|P_i|\alpha_i\rangle"/></p>
<p>which is a product of <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> terms. We have thus reduced the (exponentially large) burden of computing a giant <img alt="2^n\times 2^n" class="latex" src="https://s0.wp.com/latex.php?latex=2%5En%5Ctimes+2%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^n\times 2^n"/> matrix<br/>
to computing <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> matrices size <img alt="2\times 2" class="latex" src="https://s0.wp.com/latex.php?latex=2%5Ctimes+2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2\times 2"/>, so we can sample the output distribution efficiently.</p>
<h2>The Firewall paradox and the Harlow-Hayden decoding task</h2>
<h3>Physics to CS</h3>
<div class="wp-caption aligncenter" id="attachment_7468" style="width: 411px;"><img alt="bh" class="alignnone  wp-image-7468" height="417" src="https://windowsontheory.files.wordpress.com/2019/02/bh.png?w=401&amp;h=417" width="401"/><p class="wp-caption-text">Figure 2: A cartoon representing drama (no pun intended) near the Black Hole.</p></div>
<p>All of the black hole physics covered in the previous blog post leads to the moment (we hope) you have been waiting for: a charming resolution of the firewall paradox. Consider the interior of an old, rusty black hole <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> that has radiated away more than half of its matter. Let <img alt="R" class="latex" src="https://s0.wp.com/latex.php?latex=R&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R"/> be the old Hawking radiation, and let <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> represent the fresh Hawking radiation coming right out of the boundary of the Black Hole. Alice is our canonical Ph.D. student who is brave enough to risk her life for physics. Since <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> is a giant information scrambler, we expect to find entanglement between <img alt="R" class="latex" src="https://s0.wp.com/latex.php?latex=R&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R"/> and <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> with overwhelming probability. We know from QFT that there are bell pairs straddling the event horizon of the black hole, so <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> and <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> should be maximally entangled. But this is a problem because <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> cannot be entangled with both <img alt="R" class="latex" src="https://s0.wp.com/latex.php?latex=R&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R"/> and <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/>! The AMPS argument shows that if Alice is able to distill a bell pair between <img alt="R" class="latex" src="https://s0.wp.com/latex.php?latex=R&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R"/> and <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/>, then we should see a firewall of photons at the event horizon, thus violating the no-drama postulate. See Figure 2 for more intuition about the set up. (Note that the <img alt="\cup" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ccup&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\cup"/>‘s represent Bell Pairs, as consistent with the 3D-Quon Language) If we take Black Hole complimentary seriously, then we have an answer! If Alice does not distill a Bell pair between <img alt="R" class="latex" src="https://s0.wp.com/latex.php?latex=R&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R"/> and <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/>, then nothing really happens. However, if Alice does manage to distill the entanglement between <img alt="R" class="latex" src="https://s0.wp.com/latex.php?latex=R&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R"/> and <img alt="B " class="latex" src="https://s0.wp.com/latex.php?latex=B+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B "/>, then we witness a firewall. Is not this answer so very unsatisfactory? Why should the existence of a firewall depend on Alice’s ability to distill entanglement? What is so special about this decoding task?<br/>
The H-H decoding task answers precisely this question. Intuitively, it says that if Alice manages to distill a Bell pair between <img alt="R" class="latex" src="https://s0.wp.com/latex.php?latex=R&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R"/> and <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/>, she could also invert a one-way function, a task we believe is very hard to perform! We conjecture that Alice would take exponential time to decode the entanglement, so the Black Hole would disappear long before Alice even makes a dent in the problem! Before we provide an in depth resolution of the paradox through the H-H decoding, let us (as good philosophers do) briefly review assumptions:</p>
<ol>
<li>The Black Hole <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> can be modelled by a finite collection of qubits, say <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> qubits.</li>
<li>Alice is told that the initial state of <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> is the product basis <img alt="|0\rangle^{\otimes n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7C0%5Crangle%5E%7B%5Cotimes+n%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|0\rangle^{\otimes n}"/>.</li>
<li>Black Hole dynamics are assumed to be unitary, so Alice need not worry about some spooky M-theory that may claim to evolve <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> in a non-unitary fashion.</li>
<li><img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> is a giant information scrambler, represented by some random circuit <img alt="\mathcal{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{C}"/>.</li>
<li>Fresh radiation <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> is a single qubit, w.l.o.g., since any additional qubits could be made a part of <img alt="R" class="latex" src="https://s0.wp.com/latex.php?latex=R&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R"/>.</li>
<li><img alt="|\psi\rangle_{RBH}" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle_%7BRBH%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi\rangle_{RBH}"/> is not Haar-Random. Mini-exercise: prove that if <img alt="|\psi\rangle_{RBH}" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle_%7BRBH%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi\rangle_{RBH}"/> is Haar-Random, our job becomes easy because the circuit complexity of the H-H decoding task grows exponentially with <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>, the size of <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/>.</li>
<li>Alice has access only to circuit <img alt="\mathcal{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{C}"/> and <img alt="R, B" class="latex" src="https://s0.wp.com/latex.php?latex=R%2C+B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R, B"/> but not <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/>. Trivial Mini-exercise: prove that if Alice has access to <img alt="R,B,H, \mathcal{C}" class="latex" src="https://s0.wp.com/latex.php?latex=R%2CB%2CH%2C+%5Cmathcal%7BC%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R,B,H, \mathcal{C}"/>, then it is easy to distill the entanglement between <img alt="R" class="latex" src="https://s0.wp.com/latex.php?latex=R&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R"/> and <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/>.</li>
<li>Alice may be an intellectual Goddess who just knows which unitary to apply, or, more realistically, someone who has exponential time to prepare before the Black Hole forms. Of crucial importance therefore is the circuit complexity of the unitary Alice applies to distill the Bell pair, not so much the process of finding the unitary.</li>
</ol>
<h3>Distilling the B-R Bell pair</h3>
<p>Let us jump into the definition of the <em>Harlow-Hayden decoding task</em>.</p>
<p><strong>Definition (Harlow-Hayden decoding task).</strong><br/>
Given a (polynomial-size) quantum circuit <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/> as input such that <img alt="|\psi\rangle_{RBH}=C|0^n\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle_%7BRBH%7D%3DC%7C0%5En%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi\rangle_{RBH}=C|0^n\rangle"/> where <img alt="R,B,H" class="latex" src="https://s0.wp.com/latex.php?latex=R%2CB%2CH&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R,B,H"/> are three disjoint part of the <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> qubits. Furthermore, it is guaranteed that there exists a unitary operator <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/> acting only on the qubits in <img alt="R" class="latex" src="https://s0.wp.com/latex.php?latex=R&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R"/> such that after applying <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/>, the rightmost bit of <img alt="R" class="latex" src="https://s0.wp.com/latex.php?latex=R&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R"/> and the leftmost bit of <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> forms a bell pair <img alt="\frac{|00\rangle+|11\rangle}{\sqrt{2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B%7C00%5Crangle%2B%7C11%5Crangle%7D%7B%5Csqrt%7B2%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\frac{|00\rangle+|11\rangle}{\sqrt{2}}"/>. The goal of the Harlow-Hayden decoding task is then to find a quantum circuit for such U on the qubits in <img alt="R" class="latex" src="https://s0.wp.com/latex.php?latex=R&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R"/>. See Figure 3.</p>
<div class="wp-caption aligncenter" id="attachment_7474" style="width: 410px;"><img alt="hhd" class="alignnone  wp-image-7474" height="238" src="https://windowsontheory.files.wordpress.com/2019/02/hhd.png?w=400&amp;h=238" width="400"/><p class="wp-caption-text">Figure 3: The Harlow-Hayden decoding task.</p></div>
<p>A necessary condition for the firewall paradox to make sense is that the Harlow-Hayden decoding task should be <em>easy</em>. If Alice cannot distill the entanglement efficiently, the black hole will evaporate before Alice is ready to witness the firewall!</p>
<p>To refute the firewall paradox, Harlow and Hayden proved the following theorem.</p>
<blockquote><p><strong>Theorem 1.<br/>
</strong>If the Harlow-Hayden decoding task can be done in <img alt="\mathbf{BQP/poly}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BBQP%2Fpoly%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{BQP/poly}"/>, then <img alt="\mathbf{SZK}\subseteq\mathbf{BQP/poly}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BSZK%7D%5Csubseteq%5Cmathbf%7BBQP%2Fpoly%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{SZK}\subseteq\mathbf{BQP/poly}"/>.<strong><br/>
</strong></p></blockquote>
<p>We won’t formally define the complexity class <img alt="\mathbf{SZK}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BSZK%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{SZK}"/>. However, it is important to know that the foundation of the lattice-based cryptography, a promising <em>quantum-secure</em> crypto framework, is based on the hardness of some problem in <img alt="\mathbf{SZK}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BSZK%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{SZK}"/>. If <img alt="\mathbf{SZK}\subseteq\mathbf{BQP/poly}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BSZK%7D%5Csubseteq%5Cmathbf%7BBQP%2Fpoly%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{SZK}\subseteq\mathbf{BQP/poly}"/>, then all lattice-based cryptosystems can be broken by polynomial time quantum algorithm!</p>
<p>Instead of a proof for Theorem 1, which is more involved, we give a proof for an improvement of the Harlow-Hayden theorem due to Scott Aaronson. (Aaronson also showed that there might not even exist quantum-secure cryptography if the Harlow-Hayden decoding task can be efficiently solved!)</p>
<h2>Aaronson’s improvement</h2>
<p>In Aaronson’s lecture notes [Aar16], he showed the following improvement on Theorem 1.</p>
<blockquote><p><strong>Theorem 2.</strong><br/>
If the Harlow-Hayden decoding task can be done in <img alt="\mathbf{BQP/poly}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BBQP%2Fpoly%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{BQP/poly}"/>, then quantum-secure injective one-way function does not exist.</p></blockquote>
<p>Before formally defining a one way function, it is paramount to understand its impact: modern cryptosystems are built from some variant of a one-way function. Intuitively, primitives that have the one-way property are (i) easy to implement (<em>e.g.,</em> encrypt) but (ii) hard to invert (<em>e.g.,</em> be attacked). As a result, if there is no quantum-secure injective one-way function, then that is strong evidence that quantum-secure cryptography might not exist.</p>
<p>Now, let us formally define what quantum-secure injective one-way function is and give a formal proof for Theorem 2.</p>
<blockquote><p><strong>Definition 1 (Quantum-secure injective one-way function).<br/>
</strong>A boolean function <img alt="f:\{0,1\}^n\rightarrow\{0,1\}^m" class="latex" src="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D%5En%5Crightarrow%5C%7B0%2C1%5C%7D%5Em&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f:\{0,1\}^n\rightarrow\{0,1\}^m"/> is a quantum-secure injective one-way function if</p>
<ul>
<li><img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> is injective,</li>
<li><img alt="f\in\mathbf{BQP/poly}" class="latex" src="https://s0.wp.com/latex.php?latex=f%5Cin%5Cmathbf%7BBQP%2Fpoly%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f\in\mathbf{BQP/poly}"/>, and</li>
<li>for any polynomial time quantum algorithm <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/></li>
</ul>
<div style="text-align: center;"><img alt="\Pr_{x\in\{0,1\}^n}[f(x)=f(A(f(x)))]\leq\frac{1}{\text{poly}(n)}." class="latex" src="https://s0.wp.com/latex.php?latex=%5CPr_%7Bx%5Cin%5C%7B0%2C1%5C%7D%5En%7D%5Bf%28x%29%3Df%28A%28f%28x%29%29%29%5D%5Cleq%5Cfrac%7B1%7D%7B%5Ctext%7Bpoly%7D%28n%29%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Pr_{x\in\{0,1\}^n}[f(x)=f(A(f(x)))]\leq\frac{1}{\text{poly}(n)}."/></div>
</blockquote>
<p>Note that since <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> is injective, the last condition can actually be phrased as <img alt="x=A(f(x))" class="latex" src="https://s0.wp.com/latex.php?latex=x%3DA%28f%28x%29%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x=A(f(x))"/>. Also, the condition should be read as “on input <img alt="f(x)" class="latex" src="https://s0.wp.com/latex.php?latex=f%28x%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f(x)"/>, the quantum algorithm <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> outputs <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/>”, namely, <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> inverts <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/>.</p>
<div><em>Proof:</em></div>
<div/>
<p>Suppose the Harlow-Hayden decoding task is in <img alt="\mathbf{BQP/poly}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BBQP%2Fpoly%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{BQP/poly}"/>, we are going to show that for any injective <img alt="f:\{0,1\}^n\rightarrow\{0,1\}^m" class="latex" src="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D%5En%5Crightarrow%5C%7B0%2C1%5C%7D%5Em&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f:\{0,1\}^n\rightarrow\{0,1\}^m"/> computable by some polynomial size quantum circuit, there is a polynomial time quantum algorithm that inverts <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/>. Namely, <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> is not a quantum-secure injective one-way function.To get an efficient inverting algorithm for <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/>, let us first prepare a special circuit <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/> from <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> and treat it as an input to the Harlow-Hayden decoding task. The circuit <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/> will simply map the <img alt="|0^{m+2+n}\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7C0%5E%7Bm%2B2%2Bn%7D%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|0^{m+2+n}\rangle"/> to the following state</p>
<p style="text-align: center;"><img alt="\frac{1}{\sqrt{2^{m+2+n}}}\sum_{x\in\{0,1\}^n}\left(|x,0^{m-n},0\rangle_R|0\rangle_B+|f(x),1\rangle_R|1\rangle_B\right)|x\rangle_H." class="latex" src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B%5Csqrt%7B2%5E%7Bm%2B2%2Bn%7D%7D%7D%5Csum_%7Bx%5Cin%5C%7B0%2C1%5C%7D%5En%7D%5Cleft%28%7Cx%2C0%5E%7Bm-n%7D%2C0%5Crangle_R%7C0%5Crangle_B%2B%7Cf%28x%29%2C1%5Crangle_R%7C1%5Crangle_B%5Cright%29%7Cx%5Crangle_H.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\frac{1}{\sqrt{2^{m+2+n}}}\sum_{x\in\{0,1\}^n}\left(|x,0^{m-n},0\rangle_R|0\rangle_B+|f(x),1\rangle_R|1\rangle_B\right)|x\rangle_H."/></p>
<p>Note that as <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> has a polynomial size quantum circuit, the circuit <img alt="\mathcal{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{C}"/> can also be implemented in polynomial size.Next, the easiness of the Harlow-Hayden decoding task guarantees us the existence of a unitary operation <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/> on the qubits in <img alt="R" class="latex" src="https://s0.wp.com/latex.php?latex=R&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R"/> such that for any <img alt="x\in\{0,1\}^n" class="latex" src="https://s0.wp.com/latex.php?latex=x%5Cin%5C%7B0%2C1%5C%7D%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x\in\{0,1\}^n"/></p>
<p style="text-align: center;"><img alt="U\left(\frac{|x,0^{m-n},0\rangle_R+|f(x),1\rangle_R}{\sqrt{2}}\right) = |\phi_x\rangle_R\left(\frac{|0\rangle+|1\rangle}{\sqrt{2}}\right)" class="latex" src="https://s0.wp.com/latex.php?latex=U%5Cleft%28%5Cfrac%7B%7Cx%2C0%5E%7Bm-n%7D%2C0%5Crangle_R%2B%7Cf%28x%29%2C1%5Crangle_R%7D%7B%5Csqrt%7B2%7D%7D%5Cright%29+%3D+%7C%5Cphi_x%5Crangle_R%5Cleft%28%5Cfrac%7B%7C0%5Crangle%2B%7C1%5Crangle%7D%7B%5Csqrt%7B2%7D%7D%5Cright%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U\left(\frac{|x,0^{m-n},0\rangle_R+|f(x),1\rangle_R}{\sqrt{2}}\right) = |\phi_x\rangle_R\left(\frac{|0\rangle+|1\rangle}{\sqrt{2}}\right)"/></p>
<p>for some state <img alt="|\phi_x\rangle_R" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cphi_x%5Crangle_R&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\phi_x\rangle_R"/>. By restricting <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/> on the first <img alt="m" class="latex" src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m"/> qubits, one can get unitary operators <img alt="V" class="latex" src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="V"/> and <img alt="W" class="latex" src="https://s0.wp.com/latex.php?latex=W&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="W"/> such that for all <img alt="x\in\{0,1\}^n" class="latex" src="https://s0.wp.com/latex.php?latex=x%5Cin%5C%7B0%2C1%5C%7D%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x\in\{0,1\}^n"/>,</p>
<p style="text-align: center;"><img alt="V|x,0^{m-n}\rangle=|\phi_x\rangle\text{ and }W|f(x)\rangle=|\phi_x\rangle." class="latex" src="https://s0.wp.com/latex.php?latex=V%7Cx%2C0%5E%7Bm-n%7D%5Crangle%3D%7C%5Cphi_x%5Crangle%5Ctext%7B+and+%7DW%7Cf%28x%29%5Crangle%3D%7C%5Cphi_x%5Crangle.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="V|x,0^{m-n}\rangle=|\phi_x\rangle\text{ and }W|f(x)\rangle=|\phi_x\rangle."/></p>
<p>Thus, <img alt="V^\dagger W" class="latex" src="https://s0.wp.com/latex.php?latex=V%5E%5Cdagger+W&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="V^\dagger W"/> inverts <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> because for any <img alt="x\in\{0,1\}^n" class="latex" src="https://s0.wp.com/latex.php?latex=x%5Cin%5C%7B0%2C1%5C%7D%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x\in\{0,1\}^n"/>,</p>
<p style="text-align: center;"><img alt="V^\dagger W|f(x)\rangle=|x,0^{m-n}\rangle." class="latex" src="https://s0.wp.com/latex.php?latex=V%5E%5Cdagger+W%7Cf%28x%29%5Crangle%3D%7Cx%2C0%5E%7Bm-n%7D%5Crangle.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="V^\dagger W|f(x)\rangle=|x,0^{m-n}\rangle."/></p>
<p>Furthermore, as we are guaranteed that the Harlow-Hayden decoding task is in <img alt="\mathbf{BQP/poly}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BBQP%2Fpoly%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{BQP/poly}"/>, <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/> as well as <img alt="V" class="latex" src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="V"/> and <img alt="W" class="latex" src="https://s0.wp.com/latex.php?latex=W&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="W"/> all have polynomial size quantum circuits! Namely, <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> can be efficiently inverted by a quantum algorithm and thus <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> is not a quantum-secure injective one-way function.</p>
<h2>What’s next?</h2>
<p>The Harlow-Hayden decoding task as well as the Aaronson’s improvement can be interpreted as (strong) evidence that distilling the B-R Bell pair is hard (in the worst-case<sup>2</sup>). One might hope for an <em>average-case</em> hardness for the Harlow-Hayden decoding task and thus infer that <em>most</em> black holes are difficult to distill. However, even if such average-case hardness results existed, physicists would still remain dissatisfied! The foremost grievance a physicist may have is the lack of a coherent causal framework to model reality. That is, what happens if, in the<br/>
very small but non-zero chance, a black hole is easy to distill? Does that mean that a firewall exists in such black hole? How can a unifying theory explain such situation coherently? An ideal theory for theoretical physicists should work for <em>every</em> black hole instead of for <em>most</em> black holes! Second, physicists seem to dislike the abstract, process-theoretic approach undertaken by computer scientists. Here, we have completely ignored talking about the internal dynamics of a black hole or even a full description of its evolving Hilbert space. They would, for instance, like to see a <em>differential equation</em> that captures the difficulty of distilling a black hole throughout its evolution. Resolutions to the firewall paradox or effort towards building a theory of quantum gravity should be somewhat <em>explicit</em> in the sense that one can really instantiate some (toy) examples from the theory and see how the system evolves and examine whether this fits the real experience from the world. In other words, a theory with a black box (<em>i.e.,</em> a complexity conjecture) might not be regarded as a resolution.</p>
<h3>Homework</h3>
<ol>
<li>What powers would Alice need to ensure that she can efficiently distill the B-R bell pair. What if we assume <img alt="\mathbf{P = PSPACE}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BP+%3D+PSPACE%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{P = PSPACE}"/>?</li>
<li>Can we show that the decoding is hard on average, rather than for the worst case?</li>
<li>What are some similar deep connections between black holes and complexity theory?</li>
<li>For people interested in the quantum complexity theory, there are many open problems regarding the quantum circuit complexity: consider the <em>unitary synthesis problem</em><sup>3</sup> proposed by Scott Aaronson [Aar16].</li>
<li>Another interesting problem is connecting the difficulty of proving quantum circuit lower bounds to other complexity problem such as classical circuit lower bounds or cryptographic assumptions.</li>
</ol>
<h2>Footnotes</h2>
<p><sup>1</sup>Non-trivial here means the unitary matrix <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/> is explicit in the sense that given <img alt="i,j\in[2^n]]" class="latex" src="https://s0.wp.com/latex.php?latex=i%2Cj%5Cin%5B2%5En%5D%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i,j\in[2^n]]"/>, one can efficiently compute <img alt="U_{ij}" class="latex" src="https://s0.wp.com/latex.php?latex=U_%7Bij%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U_{ij}"/>.<br/>
<sup>2</sup>Hard in worst-case means that there does not exist efficient algorithm that works on <em>every</em> input. Another hardness notion is hard on <em>average</em>, by which we mean there does not exist efficient algorithm the works for <em>most</em> of the input. Showing average-case hardness is in general a more difficult task than proving worst-case hardness.<br/>
<sup>3</sup>Does the following hold: for any unitary matrix <img alt="U\in\mathbb{C}^{2^n\times2^n}" class="latex" src="https://s0.wp.com/latex.php?latex=U%5Cin%5Cmathbb%7BC%7D%5E%7B2%5En%5Ctimes2%5En%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U\in\mathbb{C}^{2^n\times2^n}"/>, there exists a classical oracle <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> such that <img alt="C^A(U)=n^{O(1)}" class="latex" src="https://s0.wp.com/latex.php?latex=C%5EA%28U%29%3Dn%5E%7BO%281%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C^A(U)=n^{O(1)}"/> where <img alt="C^A(U)" class="latex" src="https://s0.wp.com/latex.php?latex=C%5EA%28U%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C^A(U)"/> is the minimum size of quantum circuit that approximates <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/> with oracle access to <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/>.</p>
<h2>References</h2>
<div>[Aar16] Scott Aaronson. The complexity of quantum states and transformations: from quantum money to black holes. <em>arXiv preprint arXiv:1607.05256</em>, 2016.</div>
<div/>
<div>[HH13] Daniel Harlow and Patrick Hayden. Quantum computation vs. firewalls.</div>
<div><em>Journal of High Energy Physics</em>, 2013(6):85, 2013.</div>
<div/>
<div>[NC02] Michael A Nielsen and Isaac Chuang. Quantum computation and quantum information, 2002.</div></div>
    </content>
    <updated>2019-02-01T05:44:24Z</updated>
    <published>2019-02-01T05:44:24Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Chi-Ning Chou</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2019-02-03T09:20:54Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/01/31/linkage</id>
    <link href="https://11011110.github.io/blog/2019/01/31/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>As usual, follow me on Mathstodon to see these as I post them rather than two weeks later.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>As usual, follow <a href="https://mathstodon.xyz/@11011110">me</a> on <a href="https://mathstodon.xyz">Mathstodon</a> to see these as I post them rather than two weeks later.</p>

<ul>
  <li>
    <p><a href="https://montrealgazette.com/news/organizers-fear-visa-issues-may-push-ai-conferences-to-avoid-canada">Half of the 200 people who needed visas to attend one of the satellite workshops of NeurIPS 2018 in Montreal were unable to get them in time</a> (<a href="https://mathstodon.xyz/@11011110/101429260698057077"/>, <a href="https://www.wired.com/story/canada-welcome">see also</a>), making it more likely that future conferences depending on international attendance will avoid Canada.</p>
  </li>
  <li>
    <p>This is not a cinnamon bun (<a href="https://mathstodon.xyz/@11011110/101438594980314031"/>). It’s actually a 160 million year old fossil snail shell from Madagascar, roughly the size of a large fist (or cinnamon bun). I don’t think it’s particularly rare or valuable; I picked it up because I liked its shape.</p>

    <p style="text-align: center;"><img alt="Fossil gastropod" src="https://www.ics.uci.edu/~eppstein/pix/gastropod/gastropod-m.jpg" style="border-style: solid; border-color: black;"/></p>
  </li>
  <li>
    <p><a href="https://www.ics.uci.edu/~nmamano/knightstour.html">Web site for generating knight’s tours of oversized chessboards with approximately-minimum numbers of bends and crossings</a> (<a href="https://mathstodon.xyz/@11011110/101445919833908876"/>). For background on how it works, see the short paper by Besa, Johnson, Mamano, and Osegueda (all UCI students) in <a href="https://doi.org/10.1007/978-3-030-04414-5"><em>Graph Drawing 2018</em></a> pp. 661–663 – unfortunately I don’t know of a non-paywalled link.</p>
  </li>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/Besse_Day">Besse Beulah Day</a> (<a href="https://mathstodon.xyz/@11011110/101451632049375948"/>), in the 1940s, was one of the first to apply the design of experiments to engineering, after previously having learned to use the technique in forestry. Jacqueline Telford wrote about her briefly in <a href="https://www.jhuapl.edu/techdigest/TD/td2703/telford.pdf">a 2007 survey</a>. Searching for the phrase “Besse Day, working at” finds that Telford’s account of Day’s work has been plagiarized by at least six other works. It’s a form of fame, I guess, to be copied so much.</p>
  </li>
  <li>
    <p><a href="https://theconversation.com/how-one-german-city-developed-and-then-lost-generations-of-math-geniuses-106750">The slow rise and rapid fall of Göttingen as the world capital of mathematics</a> (<a href="https://mathstodon.xyz/@11011110/101457036274744941"/>).</p>
  </li>
  <li>
    <p><a href="https://www.quantamagazine.org/carolina-araujo-is-building-a-network-of-women-in-mathematics-20190122/">An interview with Brazilian mathematician Carolina Araujo</a> (<a href="https://mathstodon.xyz/@11011110/101464602401203371"/>) on the gender gap in mathematics and what still needs to be done to close it.</p>
  </li>
  <li>
    <p><a href="https://doi.org/10.1038/s42256-018-0002-3">If you sample enough times from an unknown distribution over an unknown finite subset of , can you (with high probability) produce a finite set of measure at least ?</a> (<a href="https://mathstodon.xyz/@11011110/101470101768702252"/>, <a href="https://twitter.com/johncarlosbaez/status/1083055024119308288">via</a>, <a href="https://www.metafilter.com/178941/Learnability-can-be-undecidable">via2</a>). Your set does not need to consist only of the points you’ve sampled! You can do it if   for finite  but not otherwise.</p>
  </li>
  <li>
    <p><a href="https://agtb.wordpress.com/2019/01/22/guest-post-like-a-swarm-of-locusts-vijay-vazirani/">Vijay Vazirani on the flocking behavior of theoretical computer scientists</a> (<a href="https://mathstodon.xyz/@11011110/101472666044751626"/>). Vijay’s post also includes an announcement for a semester-long <a href="https://simons.berkeley.edu/programs/market2019">program on online and matching-based market design</a> at the Simons Institute in Berkeley.</p>
  </li>
  <li>
    <p>The view from my desk (<a href="https://mathstodon.xyz/@11011110/101478744747251421"/>). Actually my office has lots of windows with a nice view of a well-used plaza, outdoor coffee shop, trees, and distant mountains. But to see that, I have to get up and go over to one of the windows. If I stay at my desk and look up at the window, I see this interesting geometric pattern instead.</p>

    <p style="text-align: center;"><img alt="UC Irvine's CalIT2 building from Donald Bren Hall, room 4082" src="https://www.ics.uci.edu/~eppstein/pix/deskview/deskview-m.jpg" style="border-style: solid; border-color: black;"/></p>
  </li>
  <li>
    <p><a href="https://scholar.social/@GerardWestendorp/101478161346333486">Gerard Westendorp made a snowdecahedron</a> but <a href="https://scholar.social/@GerardWestendorp/101483814063002454">global warming melted it</a>.</p>
  </li>
  <li>
    <p><a href="http://homepages.gac.edu/~jsiehler/games/blocks-start.html">Online sliding block puzzles</a> (<a href="https://mathstodon.xyz/@jsiehler/101472426764291238"/>) by
Jacob Siehler. The goal is to swap the positions of two colored blocks. Even the easy ones are non-obvious.</p>
  </li>
  <li>
    <p>Cute proof of <a href="https://en.wikipedia.org/wiki/Sperner%27s_theorem">Sperner’s theorem</a> (<a href="https://mathstodon.xyz/@11011110/101495343260074941"/>) from a talk by R. P. Stanley: represent subsets of  by strings of<br/>
 parentheses, “)” in position  if  is in the set, “(” otherwise. In each string, flip the first unmatched “(”, grouping the subsets into chains like (()(( – )()(( – )())( – )())). Each chain touches the middle level once, and any other antichain at most once, so the middle level is the biggest antichain.</p>
  </li>
  <li>
    <p>Two triangles in a convex point set can cross or overlap in eight configurations, colorfully named the taco, mariposa, bat, nested, crossing, ears, swords, and david by “<a href="https://www.combinatorics.org/ojs/index.php/eljc/article/view/v26i1p8">More Turán-Type Theorems for Triangles in Convex Point Sets</a>”, a new paper in <em>Elect. J. Comb.</em> by Aronov, Dujmović, Morin, Ooms, and Schultz (<a href="https://mathstodon.xyz/@11011110/101507914773539844"/>). For 246 of the 256 subsets of configurations, they find near-max families of triangles avoiding the subset. The remaining 8 subsets are equivalent to “tripod packing”, which is less well-understood but the subject of another newly published paper, “<a href="https://doi.org/10.1007/s00454-018-0012-2">New Results on Tripod Packings</a>” (<em>Discrete Comput. Geom.</em>, by Östergård and Pöllänen). The tripod problem has a complicated history of independent rediscovery, not all of which was known to Östergård and Pöllänen, so see the <em>EJC</em> paper for a more thorough survey.</p>
  </li>
  <li>
    <p><a href="https://mathvis.academic.wlu.edu/2017/07/13/creating-a-3d-printable-lorenz-attractor/">Creating a 3D-printable Lorenz attractor</a> (<a href="https://mathstodon.xyz/@11011110/101514403573957983"/>). From Elizabeth Denne’s <a href="https://mathvis.academic.wlu.edu">“Visions in Math” blog</a> which, sadly, seems to have gone on hiatus after publishing this in 2017.</p>
  </li>
</ul></div>
    </content>
    <updated>2019-01-31T21:27:00Z</updated>
    <published>2019-01-31T21:27:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-02-01T06:51:08Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-5538403199779655367</id>
    <link href="https://blog.computationalcomplexity.org/feeds/5538403199779655367/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/01/phish-before-turkey.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/5538403199779655367" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/5538403199779655367" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/01/phish-before-turkey.html" rel="alternate" type="text/html"/>
    <title>Phish Before Turkey</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">The Chronicle of Higher Education recently published a story <a href="https://www.chronicle.com/article/Phishing-Scheme-Targets/245535">Phishing Scheme Targets Professors’ Desire to Please Their Deans — All for $500 in Gift Cards</a>. The same thing happened to me last fall.<br/>
<br/>
Twas the day before Thanksgiving and an email went out to most of the faculty in my department.<br/>
<blockquote class="tr_bq">
<b>From: </b>Lance Fortnow &lt;lancefortnow@yahoo.com&gt;<br/>
<b>Sent: </b>Wednesday, November 21, 2018 1:45 PM<br/>
<b>To: </b>[name deleted]<br/>
<b>Subject:</b> </blockquote>
<blockquote class="tr_bq">
Hello,are you available?</blockquote>
At the time I was in New Jersey visiting family. lancefortnow@yahoo.com is not my email. I do own fortnow@yahoo.com but don't email there, I rarely check it.<br/>
<br/>
Some faculty checked with me to see if this is real. One faculty called me to see what I wanted. Once I found out what was happening I sent a message to my entire faculty to ignore those emails.<br/>
<br/>
Some faculty did reply to see what I want. The response:<br/>
<blockquote class="tr_bq">
i need you to help me get an Amazon gifts card from the store,i will reimburse you back when i get to the office.</blockquote>
One of our security faculty decided to follow up and replied "Sure! Let me get them for you. Could you provide more more information? e.g., amount and #cards. I can bring them on Monday." The reply:<br/>
<blockquote class="tr_bq">
The amount i want is $100 each in two (2) piece so that will make it a total of $200 l'll be reimbursing back to you.i need physical cards which you are going to get from the store. When you get them,just scratch it and take a picture of them and attach it to the email then send it to me here ok</blockquote>
<div>
He went a few more rounds before the phisher just stopped responding.</div>
<div>
<br/></div>
<div>
A week later, a different faculty member came to my office and said I wanted to see him but he's been out of town. I said it was nice to see him but I didn't ask to talk to him and we figured out the confusion was the phishing email.</div>
<div>
<br/></div>
<div>
Someone went through the trouble of creating a fake email address in my name, looking up the email addresses of the faculty in the department and individually emailing each of them, without realizing computer science professors won't fall for a gift card phishing attack. Or at least none of them admitted falling for it.</div></div>
    </content>
    <updated>2019-01-31T16:46:00Z</updated>
    <published>2019-01-31T16:46:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>https://plus.google.com/101693130490639305932</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>https://plus.google.com/101693130490639305932</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-02-02T20:39:23Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/013</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/013" rel="alternate" type="text/html"/>
    <title>TR19-013 |  CSPs with Global Modular Constraints: Algorithms and Hardness via Polynomial Representations | 

	Joshua Brakensiek, 

	Sivakanth Gopi, 

	Venkatesan Guruswami</title>
    <summary>We study the complexity of Boolean constraint satisfaction problems (CSPs) when the assignment must have Hamming weight in some congruence class modulo $M$, for various choices of the modulus $M$. Due to the known classification of tractable Boolean CSPs, this mainly reduces to the study of three cases: 2SAT, HornSAT, and LIN-MOD2 (linear equations mod $2$). We classify the moduli $M$ for which these respective problems are polynomial time solvable, and when they are not (assuming the ETH). Our study reveals that this modular constraint lends a surprising richness to these classic, well-studied problems, with interesting broader connections to complexity theory and coding theory. The HornSAT case is connected to the covering complexity of polynomials representing the NAND function mod $M$. The LIN-MOD2 case is tied to the sparsity of polynomials representing the OR function mod $M$, which in turn has connections to modular weight distribution properties of linear codes and locally decodable codes. In both cases, the analysis of our algorithm as well as the hardness reduction rely on these polynomial representations, highlighting an interesting algebraic common ground between hard cases for our algorithms and the gadgets which show hardness. These new complexity measures of polynomial representations merit further study.

The inspiration for our study comes from a recent work by Nägele, Sudakov, and Zenklusen on submodular minimization with a global congruence constraint. Our algorithm for HornSAT has strong similarities to their algorithm, and in particular identical kind of set systems arise in both cases. Our connection to polynomial representations leads to a simpler analysis of such set systems, and also sheds light on (but does not resolve) the complexity of submodular minimization with a congruency requirement modulo a composite $M$.</summary>
    <updated>2019-01-31T15:15:39Z</updated>
    <published>2019-01-31T15:15:39Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-02-03T09:20:29Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=7426</id>
    <link href="https://windowsontheory.org/2019/01/30/black-hole-paradoxes-a-conservative-yet-radical-journey/" rel="alternate" type="text/html"/>
    <title>Black hole paradoxes: A conservative yet radical journey</title>
    <summary>Guest post by Abhishek Anand and Noah Miller from the physics and computation seminar. In 2013, Harlow and Hayden drew an unexpected connection between theoretical computer science and theoretical physics as they proposed a potential resolution to the famous black hole Firewall paradox using computational complexity arguments. This blog post attempts to lay out the […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Guest post by Abhishek Anand and Noah Miller from <a href="https://www.boazbarak.org/fall18seminar/">the physics and computation seminar</a>.</p>



<p>In 2013, Harlow and Hayden drew an unexpected connection between theoretical computer science and theoretical physics as they proposed a potential resolution to the famous black hole Firewall paradox using computational complexity arguments. This blog post attempts to lay out the Firewall paradox and other peculiar (at first) properties associated with black holes that make them such intriguing objects to study. This post is inspired by Scott Aaronson’s [1] and Daniel Harlow’s [2] excellent notes on the same topic. The notes accompanying <a href="https://windowsontheory.org/2019/01/20/the-firewall-paradox-in-context/">this post</a> provides a thorough and self-contained introduction to theoretical physics from a CS perspective. Furthermore, for a quick and intuitive summary of the Firewall paradox and it’s link to computational complexity, refer to <a href="https://windowsontheory.org/2018/08/22/black-holes-paradoxes-and-computational-complexity/">this</a> blog post by Professor Barak last summer.</p>



<h2>Black holes and conservative radicalism</h2>



<p>Black holes are fascinating objects. Very briefly, they are regions of spacetime where the matter-energy density is so high and hence, where the gravitational effects are so strong that no particle (not even light!) can escape from it. More specifically, we define a particular distance called the “Schwarzschild radius” and anything that enters within the Schwarzschild radius, (also known as the “event horizon,”) cannot ever escape from the black hole. General relativity predicts that this particle is bound to hit the “singularity,” where spacetime curvature becomes infinite. In the truest sense of the word, they represent the “edge cases” of our Universe. Hence, perhaps, it is fitting that physicists believe that through thought experiments at these edges cases, they can investigate the true behavior of the laws that govern our Universe.</p>



<p>Once you know that such an object exists, many questions arise: what would it look it from the outside? Could we already be within the event horizon of a future black hole? How much information does it store? Would something special be happening at the Schwarzschild radius? How would the singularity manifest physically?</p>



<p>The journey of trying to answer these questions can aptly be described by the term “radical conservatism.” This is a phrase that has become quite popular in the physics community. A “radical conservative” would be someone that tries to modify as few laws of physics as possible (that’s the conservative part) and through their dogmatic refusal to modify these laws and go wherever their reasoning leads (that’s the radical part) is able to derive amazing things. We radically use the given system of beliefs to lead to certain conclusions (sometimes paradoxes!) and then conservatively update the system of beliefs to resolve the created paradox and iterate. We shall go through a few such cycles and end at the Firewall paradox. Let’s begin with the first problem: how much information does a black hole store?</p>



<h2>Entropy of a black hole</h2>



<p>A black hole is a physical object. Hence, it could be able to store some information. But how much? In other words, what should the entropy of a black hole be? There are two simple ways of looking at this problem:</p>



<ul><li><strong>0:</strong> The no-hair theorem postulates that an outside observer can measure a small number of quantities which completely characterize the black hole. There’s the mass of the black hole, which is its most important quantity. Interestingly, if the star was spinning before it collapsed, the black hole will also have some angular momentum, and its equator will bulge out a bit. Hence, the black hole is also characterized by an angular momentum vector. Also, if the object had some net charge, the black hole would also have that net charge. This means that if two black holes were created due to a book and a pizza, respectively, with the same mass, charge and angular momentum, there would settle down to the “same” black hole with no observable difference. If an outside observer knows these quantities, they will now know everything about the black hole. So, in this view, we should expect for the entropy of a black hole to be 0.</li><li><strong>Unbounded:</strong> But maybe that’s not entirely fair. After all, the contents of the star should somehow be contained in the singularity, hidden behind the horizon. As we saw above, all of the specific details of the star from before the collapse do not have any effect on the properties of the resulting black hole. The only stuff that matters it the total mass, total angular momentum, and the total charge. That leaves an infinite number of possible objects that could all have produced the same black hole: a pizza or a book or a PlayStation and so on. So actually, perhaps, we should expect the entropy of a black hole to be unbounded.</li></ul>



<p>The first answer troubled Jacob Bekenstein. He was a firm believer in the Second Law of Thermodynamics: the total entropy of an isolated system can never decrease over time. However, if the entropy of a black hole is 0, it provides with a way to reduce the entropy of any system: just dump objects with non-zero entropy into the black hole. </p>



<p>Bekenstein drew connections between the area of the black hole and its entropy. For example, the way in which a black hole’s area could only increase (according to classical general relativity) seemed reminiscent of entropy. Moreover, when two black holes merge, the area of the final black hole will always exceed the sum of the areas of the two original black holes This is surprising as for two spheres, the area/radius of the merged sphere, is always less than the sum of the areas/radii of two individual spheres: </p>



<p><img alt="(r_1^3 + r_2^3)^{\frac{1}{3}} &lt; r_1 + r_2" class="latex" src="https://s0.wp.com/latex.php?latex=%28r_1%5E3+%2B+r_2%5E3%29%5E%7B%5Cfrac%7B1%7D%7B3%7D%7D+%3C+r_1+%2B+r_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(r_1^3 + r_2^3)^{\frac{1}{3}} &lt; r_1 + r_2"/></p>



<p> Most things we’re used to, like a box of gas, have an entropy that scales linearly with its volume. However, black holes are not like most things. He predicted that entropy of a black hole should be proportional to its area, A and not its volume. We now believe that Bekenstein was right and it turns out that the entropy of the black hole can be written as:</p>



<p><img alt="S=\frac{kA}{4l^2_p}" class="latex" src="https://s0.wp.com/latex.php?latex=S%3D%5Cfrac%7BkA%7D%7B4l%5E2_p%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S=\frac{kA}{4l^2_p}"/></p>



<p>where <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/> is Boltzmann constant and <img alt="l_p" class="latex" src="https://s0.wp.com/latex.php?latex=l_p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="l_p"/> is the Planck-length, a length scale where physicists believe quantum mechanics breaks down and a quantum theory of gravity will be required. Interestingly, it seems as though the entropy of the black hole is (one-fourth times) the number of Planck-length-sized squares it would take to tile the horizon area. (Perhaps, the microstates of the black hole are “stored” on the horizon?) Using “natural units” where we set all constants to 1, we can write this as<br/> </p>



<p><img alt="S=\frac{A}{4}" class="latex" src="https://s0.wp.com/latex.php?latex=S%3D%5Cfrac%7BA%7D%7B4%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S=\frac{A}{4}"/></p>



<p>which is very pretty. Even though this number of not infinite, it is very large. Here are some numerical estimates from [2]. The entropy of the universe (minus all the black holes) mostly comes from cosmic microwave background radiation and is about <img alt="10^{87}" class="latex" src="https://s0.wp.com/latex.php?latex=10%5E%7B87%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="10^{87}"/> in some units. Meanwhile, in the same units, the entropy of a solar mass black hole is <img alt="10^{78}" class="latex" src="https://s0.wp.com/latex.php?latex=10%5E%7B78%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="10^{78}"/>. The entropy of our sun, as it is now, is a much smaller <img alt="10^{60}" class="latex" src="https://s0.wp.com/latex.php?latex=10%5E%7B60%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="10^{60}"/>. The entropy of the supermassive black hole in the center of our galaxy is <img alt="10^{88}" class="latex" src="https://s0.wp.com/latex.php?latex=10%5E%7B88%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="10^{88}"/>, <strong>larger than the rest of the universe combined </strong>(minus black holes). The entropy of any of the largest known supermassive black holes would be <img alt="10^{96}" class="latex" src="https://s0.wp.com/latex.php?latex=10%5E%7B96%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="10^{96}"/>. Hence, there is a simple “argument” which suggests that black holes are the most efficient information storage devices in the universe: if you wanted to store a lot of information in a region smaller than a black hole horizon, it would probably have to be so dense that it would just be a black hole anyway.</p>



<p>However, this resolution to “maintain” the second law of thermodynamics leads to a radical conclusion: if a black hole has non-zero entropy, it must have a non-zero temperature and hence, must emit thermal radiation. This troubled Hawking.</p>



<h2>Hawking radiation and black hole evaporation</h2>



<p>Hawking did a semi-classical computation looking at energy fluctuations near the horizon and actually found that black holes do radiate! They emit energy in the form of very low-energy particles. This is a unique feature of what happens to black holes when you take quantum field theory into account and is very surprising. However, the Hawking radiation from any actually existing black hole is far too weak to have been detected experimentally.</p>



<p>One simplified way to understand the Hawking radiation is by thinking about highly coupled modes (think “particles”) being formed continuously near the horizon. As this formation must conserve the conservation of energy, one of these particles has negative energy and one of the particles has the same energy but with a positive sign and hence, they are maximally entangled (if you know the energy of one of the particles, you know the energy of the other one): we will be referring to this as short-range entanglement. The one with negative energy falls into the black hole while the one with positive energy comes out as Hawking radiation. The maximally-entangled state of the modes looks like:</p>



<p><img alt="\sum_{\mathbf{k}} f(\mathbf{k}) |\mathbf{k}\rangle_{\rm in} |\mathbf{k}\rangle_{\rm out} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csum_%7B%5Cmathbf%7Bk%7D%7D+f%28%5Cmathbf%7Bk%7D%29+%7C%5Cmathbf%7Bk%7D%5Crangle_%7B%5Crm+in%7D+%7C%5Cmathbf%7Bk%7D%5Crangle_%7B%5Crm+out%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sum_{\mathbf{k}} f(\mathbf{k}) |\mathbf{k}\rangle_{\rm in} |\mathbf{k}\rangle_{\rm out} "/></p>



<p>Here is a cartoon that represents the process:</p>



<ul class="wp-block-gallery columns-1 is-cropped"><li class="blocks-gallery-item"><figure><img alt="" class="wp-image-7431" src="https://windowsontheory.files.wordpress.com/2019/01/partnermode2.png?w=600"/>A cartoon of the Hawking partner modes. The shaded region shows the width of the Gaussian wavepackets. The outgoing mode redshifts and spreads.</figure></li></ul>



<p>Because energetic particles are leaving the black hole and negative energy particles are adding to it, the black hole itself will actually shrink, which would never happen classically! And, eventually a black-hole will disappear. In fact, the time of evaporation of the black hole scales polynomially in the radius of the black hole, as <img alt="R^3" class="latex" src="https://s0.wp.com/latex.php?latex=R%5E3&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R^3"/>. The black holes that we know about are simply too big and would be shrinking too slowly. A stellar-mass black hole would take <img alt="10^{67}" class="latex" src="https://s0.wp.com/latex.php?latex=10%5E%7B67%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="10^{67}"/> years to disappear from Hawking radiation.</p>



<p>However, the fact that black holes disappear does not play nicely with another core belief in physics: reversibility.</p>



<h2>Unitary evolution and thermal radiation</h2>



<p>A core tenet of quantum mechanics is <em>unitary evolution</em>: every operation that happens to a quantum state must be reversible (invertible). That is: if we know the final state and the set and order of operations performed, we should be able to invert the operations and get back the initial state. No information is lost. However, something weird happens with an evaporating black hole. First, let us quickly review pure and mixed quantum states. A <em>pure state</em> is a quantum state that can be described by a single ket vector while a mixed state represents a classical (probabilistic) mixture of pure states and can be expressed using density matrices. For example, in both, the pure state <img alt="|\psi\langle = |1\rangle + |0\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Clangle+%3D+%7C1%5Crangle+%2B+%7C0%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi\langle = |1\rangle + |0\rangle"/> and mixed state <img alt="\rho = |1\rangle\langle1| +  |0\rangle\langle0|" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho+%3D+%7C1%5Crangle%5Clangle1%7C+%2B++%7C0%5Crangle%5Clangle0%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho = |1\rangle\langle1| +  |0\rangle\langle0|"/> would one measure <img alt="1" class="latex" src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1"/> half the time and <img alt="0" class="latex" src="https://s0.wp.com/latex.php?latex=0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="0"/> 50% half the time. However, in the later one would not observe any quantum effects (think interference patterns of the double-slit experiment).</p>



<p>People outside of the black hole will not be able to measure the objects (quantum degrees of freedom) that are inside the black hole. They will only be able to perform measurements on a subset of the information: the one available outside of the event horizon. So, the state they would measure would be a mixed state. A simple example to explain what this means is that if the state of the particles near the horizon is:</p>



<p><img alt="|\Psi\rangle_{init} = \frac{|0\rangle_A|0\rangle_B +|1\rangle_A|1\rangle_B} {\sqrt{2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5CPsi%5Crangle_%7Binit%7D+%3D+%5Cfrac%7B%7C0%5Crangle_A%7C0%5Crangle_B+%2B%7C1%5Crangle_A%7C1%5Crangle_B%7D+%7B%5Csqrt%7B2%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\Psi\rangle_{init} = \frac{|0\rangle_A|0\rangle_B +|1\rangle_A|1\rangle_B} {\sqrt{2}}"/></p>



<p>tracing over the qubit A leaves us with the state and density matrix:</p>



<p><br/> <img alt="|\Psi\rangle_{obs} = \frac{|0\rangle_{B}\langle0| + |1\rangle_{B}\langle1|}{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5CPsi%5Crangle_%7Bobs%7D+%3D+%5Cfrac%7B%7C0%5Crangle_%7BB%7D%5Clangle0%7C+%2B+%7C1%5Crangle_%7BB%7D%5Clangle1%7C%7D%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\Psi\rangle_{obs} = \frac{|0\rangle_{B}\langle0| + |1\rangle_{B}\langle1|}{2}"/>,</p>



<p><img alt="\rho_{obs} = \frac{1}{2} \begin{pmatrix} 1 &amp; 0 \\ 0 &amp; 1 \end{pmatrix}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho_%7Bobs%7D+%3D+%5Cfrac%7B1%7D%7B2%7D+%5Cbegin%7Bpmatrix%7D+1+%26+0+%5C%5C+0+%26+1+%5Cend%7Bpmatrix%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho_{obs} = \frac{1}{2} \begin{pmatrix} 1 &amp; 0 \\ 0 &amp; 1 \end{pmatrix}"/></p>



<p>which is a classical mixed state (50% of times results in 1 and 50% of times results in 0). The non-diagonal entries of the density matrix encode the “quantum inference” of the quantum state. Here, are they are, in some sense we have lost the “quantum” aspect of the information.</p>



<p>In fact, Hawking went and traced over the field degrees of freedom that were hidden behind the event horizon, and found something surprising: the mixed state was thermal! It acted “as if” it is being emitted by some object with temperature “T” which does not depend on what formed the black hole and solely depends on the mass of the black hole. Now, we have the information paradox:</p>



<ul><li><strong>Physics perspective</strong>: Now, once the black hole evaporates, we are left with this mixed thermal there is no way to precisely reconstruct the initial state that formed the black hole: the black hole has taken away information! Once the black hole is gone, the information of what went into the black hole is gone for good. Nobody living in the post-black-hole universe could figure out exactly what went into the black hole, even if they had full knowledge of the radiation. Another way to derive a contradiction is that the process of black hole evaporation when combined with the disappearance of the black hole, imply that a pure state has evolved into a mixed state, something which is impossible via unitary time evolution! Pure states only become mixed states whenever we decide to perform a partial trace; they never become mixed because of Schrodinger’s equation which governs the evolution of quantum states.</li><li><strong>CS perspective: </strong>We live in a world where only invertible functions are allowed. However, we are given this exotic function – the black hole – which seems to be a genuine random one-to-many function. There is no way to determine the input deterministically given the output of the function.</li></ul>



<p>What gives? If the process of black hole evaporation is truly “non-unitary,” it would be a first for physics. We have no way to make sense of quantum mechanics without the assumption of unitary operations and reversibility; hence, it does not seem very conservative to get ride of it. </p>



<p>Physicists don’t know exactly how information is conserved, but they think that if they assume that it does, it will help them figure out something about quantum gravity. Most physicists believe that the process of black hole evaporation should indeed be unitary. The information of what went into the black hole is being released via the radiation in way too subtle for us to currently understand. What does this mean?</p>



<ul><li><strong>Physics perspective</strong>: Somehow, after the black hole is gone, the final state we observe, after tracing over the degrees of freedom taken away by the black hole, is pure and encodes all information about what went inside the black hole. That is: <img alt="Tr_{inside} (|\Psi\rangle_{init}\langle\Psi|) = pure" class="latex" src="https://s0.wp.com/latex.php?latex=Tr_%7Binside%7D+%28%7C%5CPsi%5Crangle_%7Binit%7D%5Clangle%5CPsi%7C%29+%3D+pure&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Tr_{inside} (|\Psi\rangle_{init}\langle\Psi|) = pure"/></li><li><strong>CS perspective</strong>: Somehow, the exotic black hole function seems random but actually is pseudo-random as well as injective and given the output and enough time, we can decode it and determine the input (think hash functions!).</li></ul>



<p>However, this causes yet another unwanted consequence: the violation of the no-cloning theorem!</p>



<h2>Xeroxing problem and black hole complementarity</h2>



<p>The no-cloning theorem simply states that an arbitrary quantum state cannot be copied. In other words, if you have one qubit representing some initial state, no matter what operations you do, you cannot end up with two qubits with the same state you started with. How do our assumptions violate this?</p>



<p>Say you are outside the black hole and send in a qubit with some information (input to the function). You collect the radiation corresponding to the qubit (output of the function) that came out. Now you decode this radiation (output) to determine the state of infalling matter (input). Aha! You have violated the no-cloning theorem as you have two copies of the same state: one inside and one outside the black hole.</p>



<p>So wait, again, what gives?</p>



<p>One possible resolution is to postulate that the inside of the black hole just does not exist. However, that doesn’t seem very conservative. According to Einstein’s theory of relativity, locally speaking, there is nothing particularly special about the horizon: hence, one should be able to cross the horizon and move towards the singularity peacefully.</p>



<p>The crucial observation is that for the person who jumped into the black hole, the outside universe may as well not exist; they can not escape. Extending this further, perhaps, somebody on the outside does not believe the interior of the black hole exists and somebody on the inside does not believe the exterior exists and they are both right. This hypothesis, formulated in the early 1990s, has been given the name of <em>Black Hole Complementarity.</em> The word “complementarity” comes from the fact that two observers give different yet complementary views of the world.</p>



<p>In this view, according to someone on the outside, instead of entering the black hole at some finite time, the infalling observer will instead be stopped at some region very close to the horizon, which is quite hot when you get up close. Then, the Hawking radiation coming off of the horizon will hit the observer on its way out, carrying the information about them which has been plastered on the horizon. So the outside observer, who is free to collect this radiation, should be able to reconstruct all the information about the person who went in. Of course, that person will have burned up near the horizon and will be dead.</p>



<p>And from the infalling observer’s perspective, however, they were able to pass peacefully through the black hole and sail on to the singularity. So from their perspective, they live, while from the outside it looks like they died. However, no contradiction can be reached, because nobody has access to both realities.</p>



<p>But why is that? Couldn’t the outside observer see the infalling observer die and then rocket themselves straight into the black hole themselves to meet the alive person once again before they hit the singularity, thus producing a contradiction?</p>



<p>The core idea is that it must take some time for the infalling observer to “thermalize” (equilibriate) on the horizon: enough time for the infalling observer to reach the singularity and hence become completely inaccessible. Calculations do show this to be true. In fact, we can already sense a taste of complexity theory even in this argument: we are assuming that some process is slower than some other process.</p>



<p>In summary, according to the BHC worldview, the information outside the horizon is redundant with the information inside the horizon.</p>



<p>But, in 2012, a new paradox, the Firewall paradox, was introduced by AMPS [3]. This paradox seems to be immune to BHC: the paradox exists even if we assume everything we have discussed till now. The physics principle we violate, in this case, is the monogamy of entanglement.</p>



<h2>Monogamy of entanglement and Page time</h2>



<p>Before we state the Firewall paradox, we must introduce two key concepts.</p>



<h3>Monogamy of entanglement</h3>



<p>Monogamy of entanglement is a statement about the maximum entanglement a particle can share with other particles. More precisely, if two particles A and B are maximally entangled with each other, they cannot be at all entanglement with a third particle C. Two maximally entangled particles have saturated both of their “entanglement quotas\”. In order for them to have correlations with other particles, they must decrease their entanglement with each other.</p>



<p>Monogamy of entanglement can be understood as a static version of the no-cloning theorem. Here is a short proof sketch of why polygamy of entanglement implies the violation of no-cloning theorem.</p>



<p>Let’s take a short detour to explain quantum teleportation:</p>



<p>Say you have three particles A, B, and C with A and B maximally entangled (Bell pair), and C is an arbitrary quantum state:</p>



<p><img alt="|\Phi^+\rangle_{AB} = \frac{1}{\sqrt{2}} (|0\rangle_A \otimes |0\rangle_{B} + |1\rangle_A \otimes |1\rangle_{B})" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5CPhi%5E%2B%5Crangle_%7BAB%7D+%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D+%28%7C0%5Crangle_A+%5Cotimes+%7C0%5Crangle_%7BB%7D+%2B+%7C1%5Crangle_A+%5Cotimes+%7C1%5Crangle_%7BB%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\Phi^+\rangle_{AB} = \frac{1}{\sqrt{2}} (|0\rangle_A \otimes |0\rangle_{B} + |1\rangle_A \otimes |1\rangle_{B})"/></p>



<p><img alt="|\psi\rangle_C = \alpha |0\rangle_C + \beta|1\rangle_C" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle_C+%3D+%5Calpha+%7C0%5Crangle_C+%2B+%5Cbeta%7C1%5Crangle_C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi\rangle_C = \alpha |0\rangle_C + \beta|1\rangle_C"/></p>



<p>We can write their total state as:</p>



<p><img alt="|\psi \rangle_{C}\otimes |\Phi ^{+}\rangle_{AB}=(\alpha |0\rangle_{C}+\beta |1\rangle_{C})\otimes {\frac {1}{\sqrt {2}}}(|0\rangle_{A}\otimes |0\rangle_{B}+|1\rangle_{A}\otimes |1\rangle_{B})" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi+%5Crangle_%7BC%7D%5Cotimes+%7C%5CPhi+%5E%7B%2B%7D%5Crangle_%7BAB%7D%3D%28%5Calpha+%7C0%5Crangle_%7BC%7D%2B%5Cbeta+%7C1%5Crangle_%7BC%7D%29%5Cotimes+%7B%5Cfrac+%7B1%7D%7B%5Csqrt+%7B2%7D%7D%7D%28%7C0%5Crangle_%7BA%7D%5Cotimes+%7C0%5Crangle_%7BB%7D%2B%7C1%5Crangle_%7BA%7D%5Cotimes+%7C1%5Crangle_%7BB%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi \rangle_{C}\otimes |\Phi ^{+}\rangle_{AB}=(\alpha |0\rangle_{C}+\beta |1\rangle_{C})\otimes {\frac {1}{\sqrt {2}}}(|0\rangle_{A}\otimes |0\rangle_{B}+|1\rangle_{A}\otimes |1\rangle_{B})"/></p>



<p>Re-arranging and pairing A and C, the state simplifies to:</p>



<p><img alt="|\psi \rangle {C}\otimes \ |\Phi ^{+}\rangle {AB}\ = \frac {1}{2}{\Big \lbrack }\ |\Phi ^{+}\rangle {AC}\otimes (\alpha |0\rangle {B}+\beta |1\rangle {B})\ +\ |\Phi ^{-}\rangle {AC}\otimes (\alpha |0\rangle {B}-\beta |1\rangle {B})\ +\ |\Psi ^{+}\rangle {AC}\otimes (\beta |0\rangle {B}+\alpha |1\rangle {B})\ +\ |\Psi ^{-}\rangle {AC}\otimes (\beta |0\rangle {B}-\alpha |1\rangle {B}){\Big \rbrack }" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi+%5Crangle+%7BC%7D%5Cotimes+%5C+%7C%5CPhi+%5E%7B%2B%7D%5Crangle+%7BAB%7D%5C+%3D+%5Cfrac+%7B1%7D%7B2%7D%7B%5CBig+%5Clbrack+%7D%5C+%7C%5CPhi+%5E%7B%2B%7D%5Crangle+%7BAC%7D%5Cotimes+%28%5Calpha+%7C0%5Crangle+%7BB%7D%2B%5Cbeta+%7C1%5Crangle+%7BB%7D%29%5C+%2B%5C+%7C%5CPhi+%5E%7B-%7D%5Crangle+%7BAC%7D%5Cotimes+%28%5Calpha+%7C0%5Crangle+%7BB%7D-%5Cbeta+%7C1%5Crangle+%7BB%7D%29%5C+%2B%5C+%7C%5CPsi+%5E%7B%2B%7D%5Crangle+%7BAC%7D%5Cotimes+%28%5Cbeta+%7C0%5Crangle+%7BB%7D%2B%5Calpha+%7C1%5Crangle+%7BB%7D%29%5C+%2B%5C+%7C%5CPsi+%5E%7B-%7D%5Crangle+%7BAC%7D%5Cotimes+%28%5Cbeta+%7C0%5Crangle+%7BB%7D-%5Calpha+%7C1%5Crangle+%7BB%7D%29%7B%5CBig+%5Crbrack+%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi \rangle {C}\otimes \ |\Phi ^{+}\rangle {AB}\ = \frac {1}{2}{\Big \lbrack }\ |\Phi ^{+}\rangle {AC}\otimes (\alpha |0\rangle {B}+\beta |1\rangle {B})\ +\ |\Phi ^{-}\rangle {AC}\otimes (\alpha |0\rangle {B}-\beta |1\rangle {B})\ +\ |\Psi ^{+}\rangle {AC}\otimes (\beta |0\rangle {B}+\alpha |1\rangle {B})\ +\ |\Psi ^{-}\rangle {AC}\otimes (\beta |0\rangle {B}-\alpha |1\rangle {B}){\Big \rbrack }"/></p>



<p>which means that if one does a Bell pair measurement on A and C, based on the measurement outcome, we know exactly which state B is projected to and by using rotations can make the state of B equal to the initial state of C. Hence, we teleported quantum information from C to B.</p>



<p>Now, assume that A was maximally entangled to both B and D. Then by doing the same procedure, we could teleport quantum information from C to both B and D and hence, violate the no-cloning theorem!</p>



<h3>Page time</h3>



<p>Named after Don Page, the “Page time” refers to the time when the black hole has emitted enough of its energy in the form of Hawking radiation that its entropy has (approximately) halved. Now the question is, what’s so special about the Page time?</p>



<p>First note that the rank of the density matrix is closely related to its purity (or mixedness). For example, a completely mixed state is the diagonal matrix:</p>



<p><img alt="\rho_{obs} = \frac{1}{4} \begin{pmatrix} 1 &amp; 0 &amp; 0 &amp; 0\\ 0 &amp; 1 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 1 \end{pmatrix}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho_%7Bobs%7D+%3D+%5Cfrac%7B1%7D%7B4%7D+%5Cbegin%7Bpmatrix%7D+1+%26+0+%26+0+%26+0%5C%5C+0+%26+1+%26+0+%26+0+%5C%5C+0+%26+0+%26+1+%26+0+%5C%5C+0+%26+0+%26+0+%26+1+%5Cend%7Bpmatrix%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho_{obs} = \frac{1}{4} \begin{pmatrix} 1 &amp; 0 &amp; 0 &amp; 0\\ 0 &amp; 1 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 1 \end{pmatrix}"/></p>



<p>which has maximal rank (<img alt="2^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{2}"/>). Furthermore, a completely pure state <img alt="|\Psi\rangle \langle\Psi|" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5CPsi%5Crangle+%5Clangle%5CPsi%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\Psi\rangle \langle\Psi|"/> can always be represented as (if we just change the basis and make the first column/row represent <img alt="|\Psi\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5CPsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\Psi\rangle"/>):</p>



<p><img alt="\rho_{obs} =  \begin{pmatrix} 1 &amp; 0 &amp; 0 &amp; 0\\ 0 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0  \end{pmatrix}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho_%7Bobs%7D+%3D++%5Cbegin%7Bpmatrix%7D+1+%26+0+%26+0+%26+0%5C%5C+0+%26+0+%26+0+%26+0+%5C%5C+0+%26+0+%26+0+%26+0+%5C%5C+0+%26+0+%26+0+%26+0++%5Cend%7Bpmatrix%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho_{obs} =  \begin{pmatrix} 1 &amp; 0 &amp; 0 &amp; 0\\ 0 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0  \end{pmatrix}"/><br/></p>



<p>which has rank 1.</p>



<p>Imagine we have watched a black hole form and begin emitting Hawking radiation. Say we start collecting this radiation. The density matrix of the radiation will have the form:</p>



<p><img alt="\rho_{obs} = \sum_{i=1}^{2^{n-k}} p_i |\Psi\rangle_{i}\langle\Psi|" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho_%7Bobs%7D+%3D+%5Csum_%7Bi%3D1%7D%5E%7B2%5E%7Bn-k%7D%7D+p_i+%7C%5CPsi%5Crangle_%7Bi%7D%5Clangle%5CPsi%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho_{obs} = \sum_{i=1}^{2^{n-k}} p_i |\Psi\rangle_{i}\langle\Psi|"/></p>



<p>where <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> is the total number of qubits in our initial state, <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/> is the number of qubits outside (in form of radiation), and <img alt="p_i" class="latex" src="https://s0.wp.com/latex.php?latex=p_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p_i"/> is the probability of each state. We are simply tracing over the degrees of freedom inside the black hole (as there are <img alt="n-k" class="latex" src="https://s0.wp.com/latex.php?latex=n-k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n-k"/> degrees inside the black hole, dimensionality of this space is <img alt="2^{n-k}" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7Bn-k%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{n-k}"/>).</p>



<p>Don Page proposed the following graph of what he thought entanglement entropy of this density matrix should look like. It is fittingly called the “Page curve.”</p>



<figure class="wp-block-image"><img alt="" class="wp-image-7432" src="https://windowsontheory.files.wordpress.com/2019/01/pagecurve.png?w=600"/>The Page Curve</figure>



<ul><li>If <img alt="k&lt;\frac{n}{2}" class="latex" src="https://s0.wp.com/latex.php?latex=k%3C%5Cfrac%7Bn%7D%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k&lt;\frac{n}{2}"/>, rank(<img alt="\rho" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho"/>) = <img alt="2^{k}" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7Bk%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{k}"/>, as there are enough terms in the sum to get a maximally ranked matrix. And hence, we get maximally mixed states. In the beginning, the radiation we collect at early times will still remain heavily entangled with the degrees of freedom near the black hole, and as such the state will look mixed to us because we can not yet observe all the complicated entanglement. As more and more information leaves the black hole in the form of Hawking radiation, we are “tracing out” fewer and fewer of the near-horizon degrees of freedom. The dimension of our density matrix grows bigger and bigger, and because the outgoing radiation is still so entangled with the near-horizon degrees of freedom, the density matrix will still have off-diagonal terms which are essentially zero. Hence, the state entropy increases linearly.</li><li>But if <img alt="k&gt;\frac{n}{2}" class="latex" src="https://s0.wp.com/latex.php?latex=k%3E%5Cfrac%7Bn%7D%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k&gt;\frac{n}{2}"/>, by the same argument, rank(<img alt="\rho" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho"/>) = <img alt="2^{n-k} &lt; 2^{k}" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7Bn-k%7D+%3C+2%5E%7Bk%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{n-k} &lt; 2^{k}"/>. Hence, the density matrix becomes more and more pure. Once the black hole’s entropy has reduced by half, the dimension of the Hilbert space we are tracing out finally becomes smaller than the dimension of the Hilbert space we are not tracing out. The off-diagonal terms spring into our density matrix, growing in size and number as the black hole continues to shrink. Finally, once the black hole is gone, we can easily see that all the resulting radiation is in a pure state.</li></ul>



<p>The entanglement entropy of the outgoing radiation finally starts decreasing, as we are finally able to start seeing entanglements between all this seemingly random radiation we have painstakingly collected. Some people like to say that if one could calculate the Page curve from first principles, the information paradox would be solved. Now we are ready to state the firewall paradox.</p>



<h2>The Firewall Paradox</h2>



<p>Say Alice collects all the Hawking radiation coming out of a black hole. At maybe, about <img alt="1.5" class="latex" src="https://s0.wp.com/latex.php?latex=1.5&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1.5"/> times the Page time, Alice is now able to see significant entanglement in all the radiation she has collected. Alice then dives into the black hole and sees an outgoing Hawking mode escaping. Given the Page curve, we know that knowing this outgoing mode must decrease the entropy of our observed mixed state. In other words, it must make our observed density matrix purer. And hence, be entangled with the particles we have already collected.</p>



<p>(Another way to think about this: let’s say that a random quantum circuit at the horizon scrambles the information in a non-trivial yet injective way in order for radiation particles to encode the information regarding what went inside the black hole. The output qubits of the circuit must be highly entangled due to the random circuit.)</p>



<ul class="wp-block-gallery columns-1 is-cropped"><li class="blocks-gallery-item"><figure><img class="wp-image-7455" src="https://windowsontheory.files.wordpress.com/2019/01/alice2-1.png?w=796"/>Alice diving into the black hole after the Page time to see the outgoing mode emerge.</figure></li></ul>



<p>However, given our discussion on Hawking radiation about short-range entanglement, the outgoing mode must be maximally entangled with an in-falling partner mode. This contradicts monogamy of entanglement! The outgoing mode cannot be entangled both with the radiation Alice has already collected and also maximally entangled with the nearby infalling mode!</p>



<p>So, to summarize, what did we do? We started with the existence of black holes and through our game of conservative radicalism, modified how physics works around them in order to make sure the following dear Physics principles are not violated by these special objects:</p>



<ul><li>Second Law of Thermodynamics</li><li>Objects with entropy emit thermal radiation</li><li>Unitary evolution and reversibility</li><li>No-cloning theorem</li><li>Monogamy of entanglement</li></ul>



<p>And finally, ended with the Firewall paradox.</p>



<p>So, for the last time in this blog post, what gives?</p>



<ul><li><strong>Firewall solution:</strong> The first solution to the paradox is the existence of a <em>firewall</em> at the horizon. The only way to not have the short-range entanglement discussed is if there is very high energy density at the horizon. However, this violates the “no-drama” theorem and Einstein’s equivalence principle of general relativity which states that locally there should be nothing special about the horizon. If firewalls did exist, an actual wall of fire could randomly appear out of nowhere in front of us right now if a future black hole would have its horizon near us. Hence, this solution is not very popular.</li><li><strong>Remnant solution:</strong> One possible resolution would be that the black hole never “poofs” but some quantum gravity effect we do not yet understand stabilizes it instead, allowing for some Planck-sized object to stick around? Such an object would be called a “remnant.” The so-called “remnant solution” to the information paradox is not a very popular one. People don’t like the idea of a very tiny, low-mass object holding an absurdly large amount of information.</li><li><strong>No unitary evolution:</strong> Perhaps, black holes are special objects which actually lose information! This would mean that black hole physics (the quantum theory of gravity) would be considerably different compared to quantum field theory.</li><li><strong>Computational complexity solution?</strong>: Can anyone ever observe this violation? And if not, does that resolve the paradox? This will be covered in our next blog post by Parth and Chi-Ning.</li></ul>



<h2>References</h2>



<ol><li>Scott Aaronson. The complexity of quantum states and transformations: from quantum money to black holes.arXiv preprintarXiv:1607.05256, 2016.</li><li>Daniel Harlow. Jerusalem lectures on black holes and quantum information. Reviews of Modern Physics, 88(1):015002, 2016.</li><li>Ahmed Almheiri, Donald Marolf, Joseph Polchinski, and JamesSully. Black holes: complementarity or firewalls? Journal of HighEnergy Physics, 2013(2):62, 2013.</li></ol></div>
    </content>
    <updated>2019-01-30T05:58:42Z</updated>
    <published>2019-01-30T05:58:42Z</published>
    <category term="physics"/>
    <category term="cs229r"/>
    <category term="quantum"/>
    <author>
      <name>bishk97</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2019-02-03T09:20:55Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://theorydish.blog/?p=1483</id>
    <link href="https://theorydish.blog/2019/01/29/deadline-approaching-2019-godel-prize/" rel="alternate" type="text/html"/>
    <title>Deadline approaching – 2019 Gödel Prize</title>
    <summary>A reminder that the February 15th deadline is approaching (see https://theorydish.blog/2018/12/18/2019-godel-prize/). It is safe to assume that the paper you are excited about was not nominated by others. Also, from personal experience, it is a great feeling to know that your nomination succeeded. Worse case, your (moderately) hard work you will earn you the privilege to complain about the committee’s stupidity (which, again from personal experience, could be satisfying as well 😉 )</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>A reminder that the February 15th deadline is approaching (see <a href="https://theorydish.blog/2018/12/18/2019-godel-prize/" rel="nofollow">https://theorydish.blog/2018/12/18/2019-godel-prize/</a>). It is safe to assume that the paper you are excited about was not nominated by others. Also, from personal experience, it is a great feeling to know that your nomination succeeded. Worse case, your (moderately) hard work you will earn you the privilege to complain about the committee’s stupidity (which, again from personal experience, could be satisfying as well <img alt="&#x1F609;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f609.png" style="height: 1em;"/> )</p></div>
    </content>
    <updated>2019-01-29T23:25:08Z</updated>
    <published>2019-01-29T23:25:08Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Omer Reingold</name>
    </author>
    <source>
      <id>https://theorydish.blog</id>
      <logo>https://theorydish.files.wordpress.com/2017/03/cropped-nightdish1.jpg?w=32</logo>
      <link href="https://theorydish.blog/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://theorydish.blog" rel="alternate" type="text/html"/>
      <link href="https://theorydish.blog/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://theorydish.blog/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Stanford's CS Theory Research Blog</subtitle>
      <title>Theory Dish</title>
      <updated>2019-02-03T09:21:15Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=15603</id>
    <link href="https://rjlipton.wordpress.com/2019/01/29/primes-and-polynomials/" rel="alternate" type="text/html"/>
    <title>Primes And Polynomials</title>
    <summary>A result on the prime divisors of polynomial values Cropped from source Issai Schur was a mathematician who obtained his doctorate over a hundred years ago. He was a student of the great group theorist Ferdinand Frobenius. Schur worked in various areas and proved many deep results, including some theorems in basic number theory. Today […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><font color="#0044cc"><br/>
<em>A result on the prime divisors of polynomial values</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2019/01/issaischur.jpg"><img alt="" class="alignright wp-image-15604" height="180" src="https://rjlipton.files.wordpress.com/2019/01/issaischur.jpg?w=120&amp;h=180" width="120"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Cropped from <a href="https://books.google.com/books?id=XLNJDylP53QC&amp;pg=PA89&amp;lpg=PA89&amp;dq=Issai+Schur:+Ramanujan%E2%80%99s+German+Contemporary&amp;source=bl&amp;ots=JwM2fktiyS&amp;sig=ACfU3U0kPjUEsHm3z5xtZTpLYjEW89mc5Q&amp;hl=en&amp;sa=X&amp;ved=2ahUKEwiG5pftg5TgAhWCiOAKHZTXAlEQ6AEwC3oECAQQAQ#v=onepage&amp;q=Issai%20Schur%3A%20Ramanujan%E2%80%99s%20German%20Contemporary&amp;f=false">source</a></font></td>
</tr>
</tbody>
</table>
<p>
Issai Schur was a mathematician who obtained his doctorate over a hundred years ago. He was a student of the great group theorist Ferdinand Frobenius. Schur worked in various areas and proved many deep results, including some theorems in basic number theory.</p>
<p>
Today we discuss a nice lemma due to Schur. Actually, it’s a theorem.<br/>
<span id="more-15603"/></p>
<p>
There are many things named after Schur. Wikipedia has compiled a <a href="https://en.wikipedia.org/wiki/List_of_things_named_after_Issai_Schur">list</a> of them:</p>
<blockquote><p><b> </b> <em> <i>Frobenius-Schur indicator Herz-Schur multiplier Jordan-Schur theorem Lehmer-Schur algorithm Schur algebra Schur class Schur complement method Schur complement Schur decomposition Schur functor Schur index Schur multiplier Schur number Schur orthogonality relations Schur polynomial Schur product theorem Schur test Schur-convex function Schur-Horn theorem Schur-Weyl duality Schur-Zassenhaus theorem Schur’s inequality Schur’s lemma (from Riemannian geometry) Schur’s lemma Schur’s property Schur’s theorem</i> </em>
</p></blockquote>
<p/><p>
This lists two Schur lemmas. But when you click on Wikipedia’s “Schur’s lemma” <a href="https://en.wikipedia.org/wiki/Schur's_lemma_(disambiguation)">page</a>, there are three Schur lemmas. No, wait—there are four, including one called “Schur’s test.” But the result we are interested in is classed as a <em>theorem</em>. Wikipedia’s single <a href="https://en.wikipedia.org/wiki/Schur's_theorem">page</a> for “Schur’s theorem” lists not just <em>five</em> but <em>six</em> Schur’s theorems. This is one higher than the count eventually reached in Monty Python’s famous “Spanish Inquisition” <a href="http://www.montypython.net/scripts/spanish.php">skit</a>. We want the sixth one, which is quite useful—like a lemma.</p>
<p>
</p><p/><h2> The Result </h2><p/>
<p/><p>
Here is Schur’s lemma—no, theorem—published in 1912.</p>
<blockquote><p><b>Theorem 1</b> <em> Let <img alt="{f(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{f(x)}"/> be a non-constant polynomial with integer coefficients. Then <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{f}"/> has infinitely many prime divisors. </em>
</p></blockquote>
<p/><p>
Here <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/> has infinitely many prime divisors means that the number of primes that arise as divisors of the values <img alt="{f(n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(n)}"/> as <img alt="{n=0,1,2,3,\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%3D0%2C1%2C2%2C3%2C%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n=0,1,2,3,\dots}"/> is infinite. Note, this works even if the polynomial is reducible or contains some trivial factors. Thus 	</p>
<p align="center"><img alt="\displaystyle  f(x) = 10x^{3} + 100, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++f%28x%29+%3D+10x%5E%7B3%7D+%2B+100%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  f(x) = 10x^{3} + 100, "/></p>
<p>is fine. As is <img alt="{x^{2}-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%5E%7B2%7D-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x^{2}-1}"/>.</p>
<p>
Schur’s theorem is quite fun, even just to prove. Here is a nice version from a <a href="https://pdfs.semanticscholar.org/5eb7/4363199754164fdf7bbc77925a98c1eb435b.pdf">paper</a> by Ram Murty, whose work on extensions of Euclid’s famous proof of the infinitude of primes we <a href="https://rjlipton.wordpress.com/2018/07/11/you-cannot-do-that/">covered</a> last summer. We follow Murty’s proof.</p>
<p>
<em>Proof:</em>  Suppose <img alt="{f(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(x)}"/> is an integral polynomial of least degree for which the statement fails, 	</p>
<p align="center"><img alt="\displaystyle  f(x) = a_{n}x^{n} + a_{n-1}x^{n-1} + \cdots + a_{1}x + a_{0}, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++f%28x%29+%3D+a_%7Bn%7Dx%5E%7Bn%7D+%2B+a_%7Bn-1%7Dx%5E%7Bn-1%7D+%2B+%5Ccdots+%2B+a_%7B1%7Dx+%2B+a_%7B0%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  f(x) = a_{n}x^{n} + a_{n-1}x^{n-1} + \cdots + a_{1}x + a_{0}, "/></p>
<p>where <img alt="{a_n &gt; 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba_n+%3E+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a_n &gt; 0}"/>. If <img alt="{a_{0}=0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba_%7B0%7D%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a_{0}=0}"/>, then <img alt="{f(x)/x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29%2Fx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(x)/x}"/> is an integral polynomial of lower degree for which it must fail, so we have <img alt="{a_{0}\neq 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba_%7B0%7D%5Cneq+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a_{0}\neq 0}"/>. By hypothesis, <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/> has only finitely many prime divisors, which we can represent as <img alt="{p_{1}, \dots, p_{r}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_%7B1%7D%2C+%5Cdots%2C+p_%7Br%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p_{1}, \dots, p_{r}}"/>. For each natural number <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m}"/>, define <img alt="{P = a_0 \cdot p_1 \cdots p_r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP+%3D+a_0+%5Ccdot+p_1+%5Ccdots+p_r%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{P = a_0 \cdot p_1 \cdots p_r}"/> and </p>
<p align="center"><img alt="\displaystyle  Q_{m} = f(P^{m}). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++Q_%7Bm%7D+%3D+f%28P%5E%7Bm%7D%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  Q_{m} = f(P^{m}). "/></p>
<p>Now <img alt="{P &gt; 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP+%3E+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{P &gt; 1}"/> because <img alt="{f(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(x)}"/> can take the value <img alt="{+1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{+1}"/> or <img alt="{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-1}"/> only finitely often, and all sufficiently large <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m}"/> give <img alt="{Q_m &gt; 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BQ_m+%3E+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Q_m &gt; 1}"/> for the same reason. Because <img alt="{P}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{P}"/> includes <img alt="{a_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a_0}"/> as a factor, <img alt="{Q_m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BQ_m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Q_m}"/> is divisible by <img alt="{a_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a_0}"/>, giving </p>
<p align="center"><img alt="\displaystyle  f(P^m) = a_0(K + 1) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++f%28P%5Em%29+%3D+a_0%28K+%2B+1%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  f(P^m) = a_0(K + 1) "/></p>
<p>for some integer <img alt="{K}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BK%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{K}"/> that by choice of <img alt="{P}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{P}"/> is divisible by all of <img alt="{p_1,\dots,p_r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_1%2C%5Cdots%2Cp_r%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p_1,\dots,p_r}"/>. But then as in Euclid’s proof, <img alt="{K+1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BK%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{K+1}"/> is co-prime to all those primes, so it must furnish a prime divisor of <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/> that is not among them. This is a contradiction. <img alt="\Box" class="latex" src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Box"/></p>
<p>
This proof was simple but clever. Here is a concrete version for the polynomial <img alt="{x^{2} + a}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%5E%7B2%7D+%2B+a%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x^{2} + a}"/>, which may help in understanding the proof: Say <img alt="{f(x)=x^{2} + a}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29%3Dx%5E%7B2%7D+%2B+a%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(x)=x^{2} + a}"/> is divisible by only <img alt="{p_{1},\dots,p_{r}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_%7B1%7D%2C%5Cdots%2Cp_%7Br%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p_{1},\dots,p_{r}}"/> say. Let <img alt="{P=p_{1} \cdots p_{r}.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP%3Dp_%7B1%7D+%5Ccdots+p_%7Br%7D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{P=p_{1} \cdots p_{r}.}"/> The trick is to look at 	</p>
<p align="center"><img alt="\displaystyle  f(aPt) = (aPt)^{2} + a = ag(t), " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++f%28aPt%29+%3D+%28aPt%29%5E%7B2%7D+%2B+a+%3D+ag%28t%29%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  f(aPt) = (aPt)^{2} + a = ag(t), "/></p>
<p>where 	</p>
<p align="center"><img alt="\displaystyle  g(t) = a(Pt)^{2} + 1. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++g%28t%29+%3D+a%28Pt%29%5E%7B2%7D+%2B+1.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  g(t) = a(Pt)^{2} + 1. "/></p>
<p>For some <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> large enough there exists a prime <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> that divides <img alt="{g(n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{g(n)}"/>. But this prime divides <img alt="{f(aPn)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28aPn%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(aPn)}"/> and so <img alt="{p = p_{i}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp+%3D+p_%7Bi%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p = p_{i}}"/> for some <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/>. But then <img alt="{g(n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{g(n)}"/> modulo <img alt="{p_{i}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_%7Bi%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p_{i}}"/> is equal to <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/> which is a contradiction.</p>
<p>
</p><p/><h2> An Application </h2><p/>
<p/><p>
As the proof hints, Schur’s theorem is a proper extension of Euclid’s, which is just the case <img alt="{f(x) = x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29+%3D+x%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(x) = x}"/>. Here is a less-obvious application:</p>
<blockquote><p><b>Theorem 2</b> <em> Suppose that <img alt="{f(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{f(x)}"/> is a polynomial with integer coefficients. Assume that <img alt="{f(n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28n%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{f(n)}"/> is a perfect square for all integers <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n}"/> large enough. Then <img alt="{f(x)=g(x)^{2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29%3Dg%28x%29%5E%7B2%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{f(x)=g(x)^{2}}"/> for some polynomial <img alt="{g(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%28x%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{g(x)}"/>. </em>
</p></blockquote>
<p/><p>
There are many proofs of this theorem. One uses the famous Hilbert Irreducibility theorem, which we also <a href="https://rjlipton.wordpress.com/2018/06/08/hilberts-irreducibility-theorem/">discussed</a> last summer. Another proof uses Schur’s lemma and the fact that if <img alt="{f(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(x)}"/> and <img alt="{g(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{g(x)}"/> are products of irreducible integer polynomials that are collectively distinct then the ideal generated by <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/> and <img alt="{g}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{g}"/> contains a positive integer—namely, their <a href="https://en.wikipedia.org/wiki/Resultant">resultant</a> <img alt="{R(f,g)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%28f%2Cg%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R(f,g)}"/>. Again following Murty’s paper: </p>
<p>
<em>Proof:</em>  We can factor <img alt="{f(x)=g(x)^{2}h(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29%3Dg%28x%29%5E%7B2%7Dh%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(x)=g(x)^{2}h(x)}"/>, where <img alt="{h(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bh%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{h(x)}"/> is a product of irreducible integer polynomials, and the goal is to show that <img alt="{h(x) = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bh%28x%29+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{h(x) = 1}"/>. If <img alt="{h}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bh%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{h}"/> has positive degree, then by Schur’s theorem, there are infinitely many prime divisors <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> of <img alt="{h}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bh%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{h}"/>. The square-freeness of <img alt="{h}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bh%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{h}"/> implies that it shares no factors with its derivative <img alt="{h'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bh%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{h'}"/>, so <img alt="{r = R(h,h') &gt; 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br+%3D+R%28h%2Ch%27%29+%3E+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r = R(h,h') &gt; 0}"/>. We need only take <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> dividing <img alt="{h(n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bh%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{h(n)}"/> for some <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> large enough that <img alt="{f(n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(n)}"/> is a perfect square but such that <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> does not divide <img alt="{r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r}"/>. Then the order of <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> dividing <img alt="{f(n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(n)}"/> must be even, which implies that the order of <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> dividing <img alt="{h}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bh%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{h}"/> must be even. So <img alt="{p^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p^2}"/> divides <img alt="{h(n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bh%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{h(n)}"/>.</p>
<p>
By a similar token, since <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> divides <img alt="{h(n+p)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bh%28n%2Bp%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{h(n+p)}"/> as well and <img alt="{f(n+p)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28n%2Bp%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(n+p)}"/> is a perfect square, we get that <img alt="{p^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p^2}"/> divides <img alt="{h(n+p)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bh%28n%2Bp%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{h(n+p)}"/>.  Now <img alt="{h(n+p)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bh%28n%2Bp%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{h(n+p)}"/> is congruent to <img alt="{h(n) + ph'(n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bh%28n%29+%2B+ph%27%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{h(n) + ph'(n)}"/> modulo <img alt="{p^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p^2}"/>, and since <img alt="{p^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p^2}"/> divides <img alt="{h(n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bh%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{h(n)}"/> from before, it follows that <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> divides <img alt="{h'(n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bh%27%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{h'(n)}"/>. Since <img alt="{r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r}"/> belongs to the ideal generated by <img alt="{h}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bh%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{h}"/> and <img alt="{h'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bh%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{h'}"/> in <img alt="{\mathbb{Z}[x]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BZ%7D%5Bx%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathbb{Z}[x]}"/>, <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> divides <img alt="{r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r}"/> too, but this contradicts the choice of <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/>. So <img alt="{h(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bh%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{h(x)}"/> must be a constant. Since the notion of “irreducible” with <img alt="{\mathbb{Z}[x]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BZ%7D%5Bx%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathbb{Z}[x]}"/> applies to constants, any square dividing <img alt="{h}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bh%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{h}"/> is already part of <img alt="{g(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{g(x)}"/>, so <img alt="{h}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bh%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{h}"/> must be a product of distinct primes. This forestalls <img alt="{p^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p^2}"/> dividing <img alt="{h}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bh%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{h}"/> in the above, so we must have <img alt="{h = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bh+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{h = 1}"/>. <img alt="\Box" class="latex" src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Box"/></p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
We did mention Schur’s long list of things named after him. Did people name things after others more often years ago? Or is naming them still common-place?</p>
<p>
[fixed last proof]</p></font></font></div>
    </content>
    <updated>2019-01-29T22:45:22Z</updated>
    <published>2019-01-29T22:45:22Z</published>
    <category term="All Posts"/>
    <category term="History"/>
    <category term="Oldies"/>
    <category term="primes"/>
    <category term="Proofs"/>
    <category term="Results"/>
    <category term="David Hilbert"/>
    <category term="Euclid's argument"/>
    <category term="Issai Schur"/>
    <category term="polynomials"/>
    <category term="Ram Murty"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-02-03T09:20:36Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/01/29/simplifying-task-milestone</id>
    <link href="https://11011110.github.io/blog/2019/01/29/simplifying-task-milestone.html" rel="alternate" type="text/html"/>
    <title>Simplifying task-milestone diagrams</title>
    <summary>In my graph algorithms class last week, I covered critical path scheduling, as motivation for the linear-time algorithms for computing shortest and longest paths in directed acyclic graphs. In this scheduling problem, you are given a system of tasks, each with a predicted time to perform it, and constraints that some tasks should be done before others. Assuming that you have enough people working together to perform tasks in parallel, how quickly can you get everything done?</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>In my graph algorithms class last week, I covered critical path scheduling, as motivation for the linear-time algorithms for computing shortest and longest paths in directed acyclic graphs. In this scheduling problem, you are given a system of tasks, each with a predicted time to perform it, and constraints that some tasks should be done before others. Assuming that you have enough people working together to perform tasks in parallel, how quickly can you get everything done?</p>

<p>An optimal solution can be found by scheduling each task to start at a time given by the longest sequence of tasks leading up to it such that each consecutive pair in the sequence must be performed sequentially. The total length of the resulting schedule equals the length of the <a href="https://en.wikipedia.org/wiki/Critical_path_method">critical path</a>, the longest sequence of sequential tasks in the whole system. The example below could represent subtasks of a software project: design, implement, and test the software (A, B, and C), develop test cases (D), and document the results (E). Its critical path could be one of ABC, DE, AE, or DC, depending on the lengths of each task.</p>

<p style="text-align: center;"><img alt="Five tasks with ordering constraints" src="https://11011110.github.io/blog/assets/2019/pert1.svg"/></p>

<p>It’s easy enough to solve this problem directly, but to convert it to a path problem we need to have lengths on edges rather than times on vertices. It’s also convenient to have a single starting vertex for all the paths.
Therefore, <a href="https://en.wikipedia.org/wiki/Critical_path_method">Wikipedia’s article on the critical path method</a> uses a different kind of graph, which I’ll call a “task-milestone diagram” to distinguish it from the one above.
In this diagram, the vertices represent milestones, single points in time. The tasks to be performed are represented by edges, and the time to perform a task becomes the length of its edge. The goal of the scheduling problem now becomes one of choosing a time for each milestone, with enough time between pairs of milestones to perform each task.
The longest-path schedule, in which we place each milestone at a time given by the longest path to it from the start milestone, solves this problem optimally.</p>

<p>To convert a system of tasks and ordering constraints (without milestones) into an equivalent task-milestone diagram, make two new milestones for each task, one for when it starts and one for when it ends. Turn each task into an edge between its two milestones. Transform each ordering constraint (saying that task X should be performed earlier than task Y) into a length-zero edge from the end of task X to the beginning of task Y. Add two more milestones, for the start and end of the whole project. And add more length-zero edges from the project start to the start of each task that has no predecessors, and from the end of each task that has no successors to the project end milestone.</p>

<p style="text-align: center;"><img alt="Expanding each task vertex into two milestone vertices connected by a task edge" src="https://11011110.github.io/blog/assets/2019/pert2.svg"/></p>

<p>In the resulting graph, the paths from the start to the end milestone consist of the same sequences of tasks as we had before: ABC, DE, AE, or DC, separated by length-zero edges.
And for computational purposes the expansion doesn’t blow up the input size enough to cause any problems. But if we want to use this diagram for visualizing the resulting schedule, it’s a little confusing because of all of those extra length-zero edges. They don’t really represent tasks; they’re just there to make sure that the paths connect the tasks in the correct order. Do we really need so many of them?</p>

<p>There are a couple of simple rules that can be used to reduce the number of length-zero edges:</p>

<ul>
  <li>If two vertices both have only zero-length edges going out of them, and both have the same set of outgoing neighbors, they can be merged into a single vertex. Symmetrically, if two vertices both have only zero-length edges coming into them, and both have the same set of incoming neighbors, they can be merged.</li>
  <li>If a vertex has only one edge going out of it, of length zero, it can be merged with its outgoing neighbor. Symmetrically, if a vertex has only one edge coming into it, of length zero, it can be merged with its incoming neighbor.</li>
</ul>

<p>For instance, the first rule will merge the milestones for the starts of tasks A and D, and the second rule will merge the resulting vertex into the start vertex. Repeatedly applying these rules produces the following simplified graph. Note that its start-to-end paths, ABC, DE, AE, and DC, are exactly the same as the potential critical paths that we started with.</p>

<p style="text-align: center;"><img alt="Path-preserving simplification of the task-milestone diagram" src="https://11011110.github.io/blog/assets/2019/pert3.svg"/></p>

<p>If we assume that the task edges all have non-negative length (as they do in the scheduling application) and that we only care about longest paths, there are even more simplifications that we can perform. These ones might change the set of all paths in the graph (as identified by their sequences of tasks) but they preserve the identities of the longest paths:</p>

<ul>
  <li>
    <p>If a zero-length edge goes from task X to task Y, and the graph contains another path between the same two tasks, remove the edge.</p>
  </li>
  <li>
    <p>If a zero-length edge goes from task X to Y, every other edge into Y or out of X has length zero, and every incoming neighbor of task Y has a path to every outgoing neighbor of task X, then merge X and Y into a single vertex.</p>
  </li>
</ul>

<p>In our example, the bottom edge meets the conditions of the second rule. Applying that rule produces an even simpler task-milestone diagram:</p>

<p style="text-align: center;"><img alt="Additional simplification preserving longest paths" src="https://11011110.github.io/blog/assets/2019/pert4.svg"/></p>

<p>Our example has no instances of the first rule, but when it is used it removes paths from the graph. The removed paths can never be longest paths, because any path through the removed edge can be made longer by replacing that edge by a different path from X to Y.
When we perform the second rule, we may introduce new paths that were not already present, from a predecessor of Y, through the merged vertex, to a successor of X. For instance, the new graph has a path through only the two tasks AC, which was not one of the four paths we started with. But because these new paths replace portions of existing paths by two length-zero edges, they can never be the longest path, and the resulting compacted diagram can safely be used for scheduling.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/101502692118389818">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2019-01-29T16:22:00Z</updated>
    <published>2019-01-29T16:22:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-02-01T06:51:08Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-6555947.post-6062056358171439265</id>
    <link href="http://blog.geomblog.org/feeds/6062056358171439265/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://blog.geomblog.org/2019/01/fat-session-2-systems-and-measurement.html#comment-form" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/6555947/posts/default/6062056358171439265" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/6555947/posts/default/6062056358171439265" rel="self" type="application/atom+xml"/>
    <link href="http://feedproxy.google.com/~r/TheGeomblog/~3/G-UqSGr3bSg/fat-session-2-systems-and-measurement.html" rel="alternate" type="text/html"/>
    <title>FAT* Session 2: Systems and Measurement.</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Building systems that have fairness properties and monitoring systems that do A/B testing on us.<br/><br/><a href="https://algorithmicfairness.wordpress.com/2019/01/28/fat-papers-systems-and-measurement/">Session 2 of FAT*</a>: my opinionated summary.<img alt="" height="1" src="http://feeds.feedburner.com/~r/TheGeomblog/~4/G-UqSGr3bSg" width="1"/></div>
    </content>
    <updated>2019-01-29T06:48:00Z</updated>
    <published>2019-01-29T06:48:00Z</published><feedburner:origlink xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0">http://blog.geomblog.org/2019/01/fat-session-2-systems-and-measurement.html</feedburner:origlink>
    <author>
      <name>Suresh Venkatasubramanian</name>
      <email>noreply@blogger.com</email>
      <uri>https://plus.google.com/112165457714968997350</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-6555947</id>
      <category term="research"/>
      <category term="community"/>
      <category term="miscellaneous"/>
      <category term="soda"/>
      <category term="conferences"/>
      <category term="data-mining"/>
      <category term="socg"/>
      <category term="blogosphere"/>
      <category term="publishing"/>
      <category term="clustering"/>
      <category term="teaching"/>
      <category term="jobs"/>
      <category term="funding"/>
      <category term="humor"/>
      <category term="awards"/>
      <category term="outreach"/>
      <category term="stoc"/>
      <category term="cs.CG"/>
      <category term="focs"/>
      <category term="nsf"/>
      <category term="reviewing"/>
      <category term="socg-2010"/>
      <category term="fairness"/>
      <category term="academy"/>
      <category term="latex"/>
      <category term="stoc2017"/>
      <category term="theoryfest"/>
      <category term="workshops"/>
      <category term="acm"/>
      <category term="conf-blogs"/>
      <category term="writing"/>
      <category term="cs.DS"/>
      <category term="cs.LG"/>
      <category term="geometry"/>
      <category term="p-vs-nc"/>
      <category term="advising"/>
      <category term="sabbatical"/>
      <category term="simons foundation"/>
      <category term="announcement"/>
      <category term="big-data"/>
      <category term="deadline"/>
      <category term="jeff phillips"/>
      <category term="streaming"/>
      <category term="books"/>
      <category term="large-data"/>
      <category term="p-vs-np"/>
      <category term="cra"/>
      <category term="cstheory"/>
      <category term="focs2010"/>
      <category term="icdm"/>
      <category term="math.PR"/>
      <category term="memorial"/>
      <category term="personal"/>
      <category term="posters"/>
      <category term="potd"/>
      <category term="rajeev motwani"/>
      <category term="shonan"/>
      <category term="socg2012"/>
      <category term="software"/>
      <category term="stoc2012"/>
      <category term="GIA"/>
      <category term="SDM"/>
      <category term="alenex"/>
      <category term="alenex2011"/>
      <category term="arxiv"/>
      <category term="career"/>
      <category term="complexity"/>
      <category term="cs.CC"/>
      <category term="deolalikar"/>
      <category term="distributions"/>
      <category term="madalgo"/>
      <category term="nips"/>
      <category term="sdm2011"/>
      <category term="shape"/>
      <category term="talks"/>
      <category term="technology"/>
      <category term="theory.SE"/>
      <category term="travel"/>
      <category term="video"/>
      <category term="8f-cg"/>
      <category term="DBR"/>
      <category term="ICS"/>
      <category term="LISPI"/>
      <category term="acceptances"/>
      <category term="bibtex"/>
      <category term="bregman"/>
      <category term="cfp"/>
      <category term="clustering-book"/>
      <category term="column"/>
      <category term="combinatorial geometry"/>
      <category term="current-distance"/>
      <category term="ecml-pkdd"/>
      <category term="empirical"/>
      <category term="esa"/>
      <category term="fat*"/>
      <category term="focs2012"/>
      <category term="focs2014"/>
      <category term="fwcg"/>
      <category term="game theory"/>
      <category term="godel"/>
      <category term="graphs"/>
      <category term="implementation"/>
      <category term="journals"/>
      <category term="kernels"/>
      <category term="misc"/>
      <category term="models"/>
      <category term="obituary"/>
      <category term="productivity"/>
      <category term="programming"/>
      <category term="society"/>
      <category term="soda2011"/>
      <category term="topology"/>
      <category term="turing"/>
      <category term="tv"/>
      <category term="women-in-theory"/>
      <category term=".02"/>
      <category term="IMA"/>
      <category term="MOOC"/>
      <category term="PPAD"/>
      <category term="accountability"/>
      <category term="active-learning"/>
      <category term="aggregator"/>
      <category term="algorithms"/>
      <category term="ams"/>
      <category term="analco"/>
      <category term="barriers"/>
      <category term="beamer"/>
      <category term="blogging"/>
      <category term="candes"/>
      <category term="civil rights"/>
      <category term="classification"/>
      <category term="coding-theory"/>
      <category term="coffee"/>
      <category term="conjecture"/>
      <category term="cosmos"/>
      <category term="counting"/>
      <category term="cricket"/>
      <category term="cs.DC"/>
      <category term="dagstuhl"/>
      <category term="databuse"/>
      <category term="dimacs"/>
      <category term="dimensionality-reduction"/>
      <category term="distributed-learning"/>
      <category term="double-blind review"/>
      <category term="duality"/>
      <category term="eda"/>
      <category term="embarrassing"/>
      <category term="expanders"/>
      <category term="experiments"/>
      <category term="fake-news"/>
      <category term="fatml"/>
      <category term="fellowships"/>
      <category term="focs2013"/>
      <category term="fonts"/>
      <category term="gct"/>
      <category term="ggplot"/>
      <category term="gpu"/>
      <category term="graph minors"/>
      <category term="gt.game-theory"/>
      <category term="guest-post"/>
      <category term="guitar"/>
      <category term="hangouts"/>
      <category term="hirsch"/>
      <category term="history"/>
      <category term="ipe"/>
      <category term="ita"/>
      <category term="jmm"/>
      <category term="k-12"/>
      <category term="knuth"/>
      <category term="machine-learning"/>
      <category term="massive"/>
      <category term="math.ST"/>
      <category term="media"/>
      <category term="memes"/>
      <category term="metoo"/>
      <category term="metrics"/>
      <category term="morris"/>
      <category term="movies"/>
      <category term="multicore"/>
      <category term="music"/>
      <category term="narrative"/>
      <category term="networks"/>
      <category term="nih"/>
      <category term="parallelism"/>
      <category term="partha niyogi"/>
      <category term="polymath"/>
      <category term="polymath research"/>
      <category term="polytopes"/>
      <category term="postdocs"/>
      <category term="privacy"/>
      <category term="quant-ph"/>
      <category term="quantum"/>
      <category term="randomness"/>
      <category term="review"/>
      <category term="sampling"/>
      <category term="seminars"/>
      <category term="social-networking"/>
      <category term="soda2014"/>
      <category term="students"/>
      <category term="sublinear"/>
      <category term="submissions"/>
      <category term="summer-school"/>
      <category term="superbowl"/>
      <category term="surveys"/>
      <category term="svn"/>
      <category term="television"/>
      <category term="traffic"/>
      <category term="twitter"/>
      <category term="utah"/>
      <category term="wads"/>
      <category term="white elephant"/>
      <category term="xkcd"/>
      <author>
        <name>Suresh Venkatasubramanian</name>
        <email>noreply@blogger.com</email>
      </author>
      <link href="http://blog.geomblog.org/" rel="alternate" type="text/html"/>
      <link href="http://www.blogger.com/feeds/6555947/posts/default?alt=atom&amp;start-index=26&amp;max-results=25&amp;redirect=false" rel="next" type="application/atom+xml"/>
      <link href="http://feeds.feedburner.com/TheGeomblog" rel="self" type="application/atom+xml"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <subtitle>Ruminations on computational geometry, algorithms, theoretical computer science and life</subtitle>
      <title>The Geomblog</title>
      <updated>2019-02-02T07:46:06Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://tcsplus.wordpress.com/?p=334</id>
    <link href="https://tcsplus.wordpress.com/2019/01/28/tcs-talk-wednesday-february-6-ran-canetti-bu-and-tau/" rel="alternate" type="text/html"/>
    <title>TCS+ talk: Wednesday, February 6 — Ran Canetti, BU and TAU</title>
    <summary>The new season of TCS+ is about to start! Our first talk for Spring will take place next Wednesday, February 6th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 18:00 UTC). Ran Canetti from BU and TAU will speak about “Fully Bideniable Interactive Encryption” (abstract below). Please make sure you […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The new season of TCS+ is about to start! Our first talk for Spring will take place next Wednesday, February 6th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 18:00 UTC). <strong>Ran Canetti</strong> from BU and TAU will speak about “<em>Fully Bideniable Interactive Encryption</em>” (abstract below).</p>
<p>Please make sure you reserve a spot for your group to join us live by signing up on <a href="https://sites.google.com/site/plustcs/livetalk/live-seat-reservation">the online form</a>. As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/site/plustcs/suggest">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/site/plustcs/">the website</a>.</p>
<blockquote><p>Abstract: While standard encryption guarantees secrecy of the encrypted plaintext only against an attacker that has no knowledge of the communicating parties’ keys and randomness of encryption, deniable encryption [Canetti et al., Crypto’96] provides the additional guarantee that the plaintext remains secret even in face of entities that attempt to coerce (or bribe) the communicating parties to expose their internal states, including the plaintexts, keys and randomness. To achieve this guarantee, deniable encryption equips the parties with faking algorithms which allow them to generate fake keys and randomness that make the ciphertext appear consistent with any plaintext of the parties’ choice. To date, however, only partial results were known: Either deniability against coercing only the sender, or against coercing only the receiver [Sahai-Waters, STOC ‘14] or schemes satisfying weaker notions of deniability [O’Neil et al., Crypto ‘11].</p>
<p>In this paper we present the first fully bideniable interactive encryption scheme, thus resolving the 20-years-old open problem. Our scheme also provides an additional and new guarantee: Even if the sender claims that one plaintext was used and the receiver claims a different one, the adversary has no way of figuring out who is lying – the sender, the receiver, or both. This property, which we call off-the-record deniability, is useful when the parties don’t have means to agree on what fake plaintext to claim, or when one party defects against the other. Our protocol has three messages, which is optimal [Bendlin et al., Asiacrypt’11], and needs a globally available reference string. We assume subexponential indistinguishability obfuscation (IO) and one-way functions.</p>
<p>Joint work with Sunoo Park and Oxana Poburinnaya.</p></blockquote>
<p> </p></div>
    </content>
    <updated>2019-01-28T16:23:59Z</updated>
    <published>2019-01-28T16:23:59Z</published>
    <category term="Announcements"/>
    <author>
      <name>plustcs</name>
    </author>
    <source>
      <id>https://tcsplus.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://tcsplus.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://tcsplus.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://tcsplus.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://tcsplus.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A carbon-free dissemination of ideas across the globe.</subtitle>
      <title>TCS+</title>
      <updated>2019-02-03T09:21:10Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2019/01/28/first-airoyoung-phd-school/</id>
    <link href="https://cstheory-events.org/2019/01/28/first-airoyoung-phd-school/" rel="alternate" type="text/html"/>
    <title>First AIROYoung PhD School</title>
    <summary>March 26-29, 2019 Rome, Italy https://workshop.airoyoung.org/2019#phd-school This is a three-days PhD School with theoretical classes and lab sessions on cutting-edge topics arising in Optimization and Simulation</summary>
    <updated>2019-01-28T11:59:55Z</updated>
    <published>2019-01-28T11:59:55Z</published>
    <category term="school"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2019-02-03T09:21:14Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-6555947.post-8169216749697822290</id>
    <link href="http://blog.geomblog.org/feeds/8169216749697822290/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://blog.geomblog.org/2019/01/fat-blogging.html#comment-form" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/6555947/posts/default/8169216749697822290" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/6555947/posts/default/8169216749697822290" rel="self" type="application/atom+xml"/>
    <link href="http://feedproxy.google.com/~r/TheGeomblog/~3/TROyy-Os39k/fat-blogging.html" rel="alternate" type="text/html"/>
    <title>FAT* blogging</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">I'll be blogging about each session of papers from the FAT* Conference. So as not to clutter your feed, the posts will be housed at the fairness blog that I co-write along with Sorelle Friedler and Carlos Scheidegger.<br/><br/>The first post is on <a href="https://algorithmicfairness.wordpress.com/2019/01/27/fat-papers-framing-and-abstraction/">Session 1: Framing and Abstraction</a>.<img alt="" height="1" src="http://feeds.feedburner.com/~r/TheGeomblog/~4/TROyy-Os39k" width="1"/></div>
    </content>
    <updated>2019-01-28T04:09:00Z</updated>
    <published>2019-01-28T04:09:00Z</published>
    <category scheme="http://www.blogger.com/atom/ns#" term="conf-blogs"/>
    <category scheme="http://www.blogger.com/atom/ns#" term="fat*"/><feedburner:origlink xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0">http://blog.geomblog.org/2019/01/fat-blogging.html</feedburner:origlink>
    <author>
      <name>Suresh Venkatasubramanian</name>
      <email>noreply@blogger.com</email>
      <uri>https://plus.google.com/112165457714968997350</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-6555947</id>
      <category term="research"/>
      <category term="community"/>
      <category term="miscellaneous"/>
      <category term="soda"/>
      <category term="conferences"/>
      <category term="data-mining"/>
      <category term="socg"/>
      <category term="blogosphere"/>
      <category term="publishing"/>
      <category term="clustering"/>
      <category term="teaching"/>
      <category term="jobs"/>
      <category term="funding"/>
      <category term="humor"/>
      <category term="awards"/>
      <category term="outreach"/>
      <category term="stoc"/>
      <category term="cs.CG"/>
      <category term="focs"/>
      <category term="nsf"/>
      <category term="reviewing"/>
      <category term="socg-2010"/>
      <category term="fairness"/>
      <category term="academy"/>
      <category term="latex"/>
      <category term="stoc2017"/>
      <category term="theoryfest"/>
      <category term="workshops"/>
      <category term="acm"/>
      <category term="conf-blogs"/>
      <category term="writing"/>
      <category term="cs.DS"/>
      <category term="cs.LG"/>
      <category term="geometry"/>
      <category term="p-vs-nc"/>
      <category term="advising"/>
      <category term="sabbatical"/>
      <category term="simons foundation"/>
      <category term="announcement"/>
      <category term="big-data"/>
      <category term="deadline"/>
      <category term="jeff phillips"/>
      <category term="streaming"/>
      <category term="books"/>
      <category term="large-data"/>
      <category term="p-vs-np"/>
      <category term="cra"/>
      <category term="cstheory"/>
      <category term="focs2010"/>
      <category term="icdm"/>
      <category term="math.PR"/>
      <category term="memorial"/>
      <category term="personal"/>
      <category term="posters"/>
      <category term="potd"/>
      <category term="rajeev motwani"/>
      <category term="shonan"/>
      <category term="socg2012"/>
      <category term="software"/>
      <category term="stoc2012"/>
      <category term="GIA"/>
      <category term="SDM"/>
      <category term="alenex"/>
      <category term="alenex2011"/>
      <category term="arxiv"/>
      <category term="career"/>
      <category term="complexity"/>
      <category term="cs.CC"/>
      <category term="deolalikar"/>
      <category term="distributions"/>
      <category term="madalgo"/>
      <category term="nips"/>
      <category term="sdm2011"/>
      <category term="shape"/>
      <category term="talks"/>
      <category term="technology"/>
      <category term="theory.SE"/>
      <category term="travel"/>
      <category term="video"/>
      <category term="8f-cg"/>
      <category term="DBR"/>
      <category term="ICS"/>
      <category term="LISPI"/>
      <category term="acceptances"/>
      <category term="bibtex"/>
      <category term="bregman"/>
      <category term="cfp"/>
      <category term="clustering-book"/>
      <category term="column"/>
      <category term="combinatorial geometry"/>
      <category term="current-distance"/>
      <category term="ecml-pkdd"/>
      <category term="empirical"/>
      <category term="esa"/>
      <category term="fat*"/>
      <category term="focs2012"/>
      <category term="focs2014"/>
      <category term="fwcg"/>
      <category term="game theory"/>
      <category term="godel"/>
      <category term="graphs"/>
      <category term="implementation"/>
      <category term="journals"/>
      <category term="kernels"/>
      <category term="misc"/>
      <category term="models"/>
      <category term="obituary"/>
      <category term="productivity"/>
      <category term="programming"/>
      <category term="society"/>
      <category term="soda2011"/>
      <category term="topology"/>
      <category term="turing"/>
      <category term="tv"/>
      <category term="women-in-theory"/>
      <category term=".02"/>
      <category term="IMA"/>
      <category term="MOOC"/>
      <category term="PPAD"/>
      <category term="accountability"/>
      <category term="active-learning"/>
      <category term="aggregator"/>
      <category term="algorithms"/>
      <category term="ams"/>
      <category term="analco"/>
      <category term="barriers"/>
      <category term="beamer"/>
      <category term="blogging"/>
      <category term="candes"/>
      <category term="civil rights"/>
      <category term="classification"/>
      <category term="coding-theory"/>
      <category term="coffee"/>
      <category term="conjecture"/>
      <category term="cosmos"/>
      <category term="counting"/>
      <category term="cricket"/>
      <category term="cs.DC"/>
      <category term="dagstuhl"/>
      <category term="databuse"/>
      <category term="dimacs"/>
      <category term="dimensionality-reduction"/>
      <category term="distributed-learning"/>
      <category term="double-blind review"/>
      <category term="duality"/>
      <category term="eda"/>
      <category term="embarrassing"/>
      <category term="expanders"/>
      <category term="experiments"/>
      <category term="fake-news"/>
      <category term="fatml"/>
      <category term="fellowships"/>
      <category term="focs2013"/>
      <category term="fonts"/>
      <category term="gct"/>
      <category term="ggplot"/>
      <category term="gpu"/>
      <category term="graph minors"/>
      <category term="gt.game-theory"/>
      <category term="guest-post"/>
      <category term="guitar"/>
      <category term="hangouts"/>
      <category term="hirsch"/>
      <category term="history"/>
      <category term="ipe"/>
      <category term="ita"/>
      <category term="jmm"/>
      <category term="k-12"/>
      <category term="knuth"/>
      <category term="machine-learning"/>
      <category term="massive"/>
      <category term="math.ST"/>
      <category term="media"/>
      <category term="memes"/>
      <category term="metoo"/>
      <category term="metrics"/>
      <category term="morris"/>
      <category term="movies"/>
      <category term="multicore"/>
      <category term="music"/>
      <category term="narrative"/>
      <category term="networks"/>
      <category term="nih"/>
      <category term="parallelism"/>
      <category term="partha niyogi"/>
      <category term="polymath"/>
      <category term="polymath research"/>
      <category term="polytopes"/>
      <category term="postdocs"/>
      <category term="privacy"/>
      <category term="quant-ph"/>
      <category term="quantum"/>
      <category term="randomness"/>
      <category term="review"/>
      <category term="sampling"/>
      <category term="seminars"/>
      <category term="social-networking"/>
      <category term="soda2014"/>
      <category term="students"/>
      <category term="sublinear"/>
      <category term="submissions"/>
      <category term="summer-school"/>
      <category term="superbowl"/>
      <category term="surveys"/>
      <category term="svn"/>
      <category term="television"/>
      <category term="traffic"/>
      <category term="twitter"/>
      <category term="utah"/>
      <category term="wads"/>
      <category term="white elephant"/>
      <category term="xkcd"/>
      <author>
        <name>Suresh Venkatasubramanian</name>
        <email>noreply@blogger.com</email>
      </author>
      <link href="http://blog.geomblog.org/" rel="alternate" type="text/html"/>
      <link href="http://www.blogger.com/feeds/6555947/posts/default?alt=atom&amp;start-index=26&amp;max-results=25&amp;redirect=false" rel="next" type="application/atom+xml"/>
      <link href="http://feeds.feedburner.com/TheGeomblog" rel="self" type="application/atom+xml"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <subtitle>Ruminations on computational geometry, algorithms, theoretical computer science and life</subtitle>
      <title>The Geomblog</title>
      <updated>2019-02-02T07:46:06Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://emanueleviola.wordpress.com/?p=600</id>
    <link href="https://emanueleviola.wordpress.com/2019/01/27/selling-your-town-to-the-marijuana-industry/" rel="alternate" type="text/html"/>
    <title>Selling your town to the marijuana industry</title>
    <summary>I vowed to quit with marijuana, but I just can’t.  It’s addictive. We can go back to 2016, when voters were hit with legalese that can only be described as a trap.  Basically, under the mask of legalizing the consumption of marijuana, the ballot question was really about opening recreational pot shops around the corner.  […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p style="text-align: justify;">I vowed to quit with marijuana, but I just can’t.  It’s addictive.</p>
<p style="text-align: justify;">We can go back to 2016, when voters were hit with legalese that can only be described as a trap.  Basically, under the mask of legalizing the consumption of marijuana, the ballot question was really about opening recreational pot shops around the corner.  No doubt many, many people voted for legalization without knowledge of this and with no desire to have pot shops in their town.  What exultation must have come from the lawyers working for the industry, when their masterstroke made it to the fine print:</p>
<h3 style="text-align: justify;">A town voting to legalize marijuana <del>may</del> MUST open pot shops.</h3>
<p style="text-align: justify;">At the same time, the administration of Newton changed.  Councilors who liked the place the way it is and wanted to protect it lost to others who wanted it more vibrant.  The new councilors and the new mayor sided with the marijuana industry.</p>
<p style="text-align: justify;">The way in which they eventually won is sinister.  The context was that everybody in Newton wants at least some restriction on the number of marijuana stores.  But don’t take my word for this claim: even the pro-pot councilors believe so, and in fact almost unanimously they put a question on the ballot about restricting the number of stores.  At the same time, many people in Newton wanted zero stores.  In another masterstroke of the saga, the councilors were able to put one group against the other.  They added another question about having zero stores, following a massive, grassroots petition which however should have put the question at a different time. Then they forced the people who wanted zero stores to vote against restricting the number of stores. This is genius.  Also, if it isn’t illegal I believe it should be.  And in perfect coup style, media outlets censored several pieces explaining the situation to the voters. The end result was what the administration had always wanted: no restriction on the number of stores. Ignore the alarms of the doctors, the police officers, and the people.  What do they know about what’s best for Newton? The bottom line is that the revenue will do good things for the city! Oh yes, the revenue.  Newton has 1 billion dollars in deficit.  You read well, 1 billion.  For decades we will have a fraction of the city budget wiped out to repay that. I guess they can say we are so desperately in debt that we should rake in every penny we can zone in town.  But I think a more accurate perspective is that even in their wildest dreams, cannabis sales won’t make a dent in that.  And maybe they should spend a couple of minutes thinking about the dozens of other ways we can bring money to the city without bringing the drugs.</p>
<p style="text-align: justify;">Executing their sophisticated plan cost in the neighborhood of $100k, mostly spent on a political strategy group which helped win the election.  To add insult to injury, key members of this marijuana combine, including the political strategists and those who funded them, don’t live in Newton but in towns where recreational pot stores are banned.  The marijuana combine is effectively carving out suburban Boston in areas where it’s good to live and areas where it’s good to sell pot.</p>
<p style="text-align: justify;">As is well known, nobody has any problem with legalizing marijuana consumption.  Moreover, there is absolutely no problem with buying this stuff over the internet, or stocking up at out-of-the-way stores.  Well, absolutely no problem except one.  The money wouldn’t go into the pockets of X, Y, and Z.</p></div>
    </content>
    <updated>2019-01-28T01:31:42Z</updated>
    <published>2019-01-28T01:31:42Z</published>
    <category term="Uncategorized"/>
    <category term="marijuana"/>
    <author>
      <name>Emanuele</name>
    </author>
    <source>
      <id>https://emanueleviola.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://emanueleviola.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://emanueleviola.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://emanueleviola.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://emanueleviola.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>By Emanuele Viola</subtitle>
      <title>Thoughts</title>
      <updated>2019-02-03T09:21:02Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/012</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/012" rel="alternate" type="text/html"/>
    <title>TR19-012 |  Multi-pseudodeterministic algorithms | 

	Oded Goldreich</title>
    <summary>In this work, dedicated to Shafi Goldwasser, we consider a relaxation of the notion of pseudodeterministic algorithms, which was put forward by Gat and Goldwasser ({\em ECCC}, TR11--136, 2011). 


Pseudodeterministic algorithms are randomized algorithms that solve search problems by almost always providing the same canonical solution (per each input). 
Multi-pseudodeterministic algorithms relax the former notion by allowing the algorithms to output one of a bounded number  of canonical solutions (per each input). 
We show that efficient multi-seudodeterministic algorithms can solve natural problems that are not solveable by efficient pseudodeterministic algorithms, present a composition theorem regarding multi-pseudodeterministic algorithms,
and relate them to other known notions.</summary>
    <updated>2019-01-27T17:25:14Z</updated>
    <published>2019-01-27T17:25:14Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-02-03T09:20:29Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/011</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/011" rel="alternate" type="text/html"/>
    <title>TR19-011 |  Sampling Graphs without Forbidden Subgraphs and Almost-Explicit Unbalanced Expanders | 

	Benny Applebaum, 

	Eliran Kachlon</title>
    <summary>We initiate the study of the following hypergraph sampling problem: Sample a $d$-uniform hypergraph over $n$ vertices and $m$ hyperedges from some pseudorandom distribution $\mathcal{G}$ conditioned on not having some small predefined $t$-size hypergraph $H$ as a subgraph. The algorithm should run in $\mathrm{poly}(n)$-time even when the size of the subgraph $H$ is super-constant.

We solve the problem by carefully designing a sampling algorithm for $k$-wise independent hypergraphs $\mathcal{G}$ that supports efficient testing for subgraph-freeness. We use our algorithm to obtain the first probabilistic construction of constant-degree polynomially-unbalanced expander graphs whose failure probability is negligible in $n$ (i.e., $n^{-\omega(1)}$). In particular, given constants $d&gt;c$, we output a bipartite graph that has $n$ left nodes, $n^c$ right nodes with right-degree of $d$ so that any right set of size at most $n^{\Omega(1)}$ expands by factor of $\Omega(d)$. This result is extended to the setting of unique expansion as well.

We argue that such an ``almost-explicit'' construction can be employed in many useful settings, and present applications in coding theory (batch codes and LDPC codes), pseudorandomness (low-bias generators and randomness extractors) and cryptography. Notably, we show that our constructions yield a collection of polynomial-stretch locally-computable cryptographic pseudorandom generators based on Goldreich's one-wayness assumption resolving a long-standing open problem.</summary>
    <updated>2019-01-27T17:16:23Z</updated>
    <published>2019-01-27T17:16:23Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-02-03T09:20:29Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/010</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/010" rel="alternate" type="text/html"/>
    <title>TR19-010 |   Stoquastic PCP vs. Randomness | 

	Alex Bredariol Grilo, 

	Dorit Aharonov</title>
    <summary>The derandomization of MA, the probabilistic version of NP, is a long standing open question. In this work, we connect this problem to a variant of another major problem: the quantum PCP conjecture. Our connection goes through the surprising quantum characterization of MA by Bravyi and Terhal. They proved the MA-completeness of the problem of deciding whether the groundenergy of a uniform stoquastic local Hamiltonian is zero or inverse polynomial. We show that the gapped version of this problem, i.e. deciding if a given uniform stoquastic local Hamiltonian is frustration-free or has energy at least some constant $\varepsilon$, is in NP. Thus, if there exists a gap-amplification procedure for uniform stoquastic Local Hamiltonians (in analogy to the gap amplification procedure for constraint satisfaction problems in the original PCP theorem), then MA = NP (and vice versa). Furthermore, if this gap amplification procedure exhibits some additional (natural) properties, then P = RP. We feel this work opens up a rich set of new directions to explore, which might lead to progress on both quantum PCP and derandomization. As a small side result, we also show that deciding if commuting stoquastic Hamiltonian is frustration free is in NP.</summary>
    <updated>2019-01-27T12:32:57Z</updated>
    <published>2019-01-27T12:32:57Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-02-03T09:20:29Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/009</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/009" rel="alternate" type="text/html"/>
    <title>TR19-009 |  The Fine-Grained Complexity of Strengthenings of First-Order Logic | 

	Jiawei Gao, 

	Russell Impagliazzo</title>
    <summary>The class of model checking for first-order formulas on sparse graphs has a complete problem with respect to fine-grained reductions, Orthogonal Vectors (OV) [GIKW17]. This paper studies extensions of this class or more lenient parameterizations. We consider classes obtained by allowing function symbols;
first-order on ordered structures; adding various notions of transitive closure operations; and stratifications of first-order properties by quantifier depth and variable complexity, rather than number of quantifiers. For some of these classes, OV is still a complete problem, in that significant improvement for the entire class is equivalent to significant improvement for OV algorithms.  For these classes, we can also use the improved OV algorithm of [AWY16, CW16] to get moderate improvements on algorithms for the entire class. For other classes, we show that model checking becomes harder than for first-order, under well-studied conjectures such as SETH.  For other classes, we show hardness follows from weaker assumptions than SETH. 

Surprisingly, whether an extension increases the complexity of model checking seems independent of whether it increases the expressive power of the logic. For example, adding function symbols does not change which problems are expressible by first-order, but does increase the time for model checking under SETH. On the other hand, adding an ordering does not change the fine-grained complexity
of model checking, although it increases the logic's expressive power.</summary>
    <updated>2019-01-27T12:24:10Z</updated>
    <published>2019-01-27T12:24:10Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-02-03T09:20:29Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-25562705.post-2559156841800187715</id>
    <link href="http://aaronsadventures.blogspot.com/feeds/2559156841800187715/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=25562705&amp;postID=2559156841800187715" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/25562705/posts/default/2559156841800187715" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/25562705/posts/default/2559156841800187715" rel="self" type="application/atom+xml"/>
    <link href="http://aaronsadventures.blogspot.com/2019/01/discussion-of-unfairness-in-machine.html" rel="alternate" type="text/html"/>
    <title>Algorithmic Unfairness Without Any Bias Baked In</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Discussion of (un)fairness in machine learning hit mainstream political discourse this week, when Representative Alexandria Ocasio-Cortez discussed the possibility of algorithmic bias, and was clumsily "called out" by Ryan Saavedra on twitter: <br/><center><blockquote class="twitter-tweet"><div dir="ltr" lang="en">Socialist Rep. Alexandria Ocasio-Cortez (D-NY) claims that algorithms, which are driven by math, are racist <a href="https://t.co/X2veVvAU1H">pic.twitter.com/X2veVvAU1H</a>— Ryan Saavedra (@RealSaavedra) <a href="https://twitter.com/RealSaavedra/status/1087627739861897216?ref_src=twsrc%5Etfw">January 22, 2019</a></div></blockquote></center>It was gratifying to see the number of responses pointing out how wrong he was --- awareness of algorithmic bias has clearly become pervasive! But most of the pushback focused on the possibility of bias being "baked in" by the designer of the algorithm, or because of latent bias embedded in the data, or both:  <br/><center><blockquote class="twitter-tweet"><div dir="ltr" lang="en">You know algorithms are written by people right? And that the data they are trained on is made and selected by people? And that the problems algorithms solve are decided...again...by people? And that people can be and many times are racist? Ok now you do the math</div>— kade (@onekade) <a href="https://twitter.com/onekade/status/1087853353000939521?ref_src=twsrc%5Etfw">January 22, 2019</a></blockquote></center>Bias in the data is certainly a problem, especially when labels are gathered by human beings. But its far from being the only problem. In this post, I want to walk through a very simple example in which the algorithm designer is being entirely reasonable, there are no human beings injecting bias into the labels, and yet the resulting outcome is "unfair".   Here is the (toy) scenario -- the specifics aren't important. High school students are applying to college, and each student has some innate "talent" $I$, which we will imagine is normally distributed, with mean 100 and standard deviation 15: $I \sim N(100,15)$. The college would like to admit students who are sufficiently talented --- say one standard deviation above the mean (so, it would like to admit students with $I \geq 115$). The problem is that talent isn't directly observable. Instead, the college can observe <i>grades</i> $g$ and <i>SAT scores $s$</i>, which are a noisy estimate of talent. For simplicity, lets imagine that both grades and SAT scores are independently and normally distributed, centered at a student's talent level, and also with standard deviation 15: $g \sim N(I, 15)$, $s \sim N(I, 15)$.<br/><br/>In this scenario, the college has a simple, optimal decision rule: It should run a linear regression to try and predict student talent from grades and SAT scores, and then it should admit the students whose <i>predicted </i>talent is at least 115. This is indeed "driven by math" --- since we assumed everything was normally distributed here, this turns out to correspond to the Bayesian optimal decision rule for the college.<br/><br/>Ok. Now lets suppose there are two populations of students, which we will call Reds and Blues. Reds are the majority population, and Blues are a small minority population --- the Blues's only make up about 1% of the student body. But the Reds and the Blues are no different when it comes to talent: they both have the same talent distribution, as described above. And there is no bias baked into the grading or the exams: both the Reds and the Blues also have exactly the same grade and exam score distributions, as described above.<br/><br/>But there is one difference: the Blues have a bit more money than the Reds, so they each take the SAT twice, and report only the highest of the two scores to the college. This results in a small but noticeable bump in their average SAT scores, compared to the Reds. Here are the grades and exam scores for the two populations, plotted:<br/><div class="separator" style="clear: both; text-align: center;"><a href="https://1.bp.blogspot.com/-B7-EMI0LIZ8/XEzQO2OBAsI/AAAAAAAAQ3o/PFO_wd6igLgwpA5OCQ1Ux0N7B9A5s3mcACLcBGAs/s1600/gradesexams.png" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="261" src="https://1.bp.blogspot.com/-B7-EMI0LIZ8/XEzQO2OBAsI/AAAAAAAAQ3o/PFO_wd6igLgwpA5OCQ1Ux0N7B9A5s3mcACLcBGAs/s400/gradesexams.png" width="400"/></a></div><div class="separator" style="clear: both; text-align: center;"/>So what is the effect of this when we use our reasonable inference procedure? First, lets consider what happens when we learn two different regression models: one for the Blues, and a different one for the Reds. We don't see much difference:<br/><br/>The Red classifier makes errors approximately 11% of the time. The Blue classifier does about the same --- it makes errors about 10.4% of the time. This makes sense: the Blues artificially inflated their SAT score distribution without increasing their talent, and the classifier picked up on this and corrected for it. In fact, it is even a little more accurate!<br/><br/>And since we are interested in fairness, lets think about the <i>false negative rate</i> of our classifiers. "False Negatives" in this setting are the people who are qualified to attend the college ($I &gt; 115$), but whom the college mistakenly rejects. These are really the people who have come to harm as a result of the classifier's mistakes. And the False Negative <i>Rate</i> is the probability that a randomly selected qualified person is mistakenly rejected from college --- i.e. the probability that a randomly selected student is harmed by the classifier. We should want that the false negative rates are approximately equal across the two populations: this would mean that the burden of harm caused by the classifier's mistakes is not disproportionately borne by one population over the other. This is one reason why the difference between false negative rates across different populations has become a standard fairness metric in algorithmic fairness --- <a href="http://papers.nips.cc/paper/6373-equality-of-opportunity-in-supervised-learning">sometimes referred to as "equal opportunity."</a><br/><br/>So how do we fare on this metric? Not so badly! The Blue model has a false negative rate of 50% on the blues, and the Red model has a false negative rate of 47% on the reds --- so the difference between these two is a satisfyingly small 3%.<br/><br/>But you might reasonably object: because we have learned separate models for the Blues and the Reds, we are <i>explicitly </i>making admissions decisions as a function of a student's color! This might sound like a form of discrimination, baked in by the algorithm designer --- and if the two populations represent e.g. racial groups, then its explicitly illegal in a number of settings, including lending.<br/><br/>So what happens if we don't allow our classifier to see group membership, and just train one classifier on the whole student body? The gap in false negative rates between the two populations balloons to 12.5%, and the overall error rate ticks up. This means if you are a qualified member of the Red population, you are substantially more likely to be mistakenly rejected by our classifier than if you are a qualified member of the Blue population.<br/><br/>What happened? There wasn't any malice anywhere in this data pipeline. Its just that the Red population was much larger than the Blue population, so when we trained a classifier to minimize its average error over the entire student body, it naturally fit the Red population --- which contributed much more to the <i>average</i>. But this means that the classifier was no longer compensating for the artificially inflated SAT scores of the Blues, and so was making a disproportionate number of errors on them --- all in their favor.<br/><br/><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="https://4.bp.blogspot.com/-W3rfiRIJUC0/XEzciybyBfI/AAAAAAAAQ4A/lmABxaYed28K77up20emGgc3TMr8D05QQCLcBGAs/s1600/classifier.png" style="margin-left: auto; margin-right: auto;"><img border="0" height="262" src="https://4.bp.blogspot.com/-W3rfiRIJUC0/XEzciybyBfI/AAAAAAAAQ4A/lmABxaYed28K77up20emGgc3TMr8D05QQCLcBGAs/s400/classifier.png" width="400"/></a></td></tr><tr><td class="tr-caption" style="text-align: center;">The combined admissions rule takes everyone above the black line. Since the Blues are shifted up relative to the Reds, they are admitted at a disproportionately higher rate. </td></tr></tbody></table><div class="separator" style="clear: both; text-align: center;"/><br/><br/>This is the kind of thing that happens <i>all the time</i>: whenever there are two populations that have different feature distributions, learning a single classifier (that is prohibited from discriminating based on population) will fit the bigger of the two populations, simply because they contribute more to average error. Depending on the nature of the distribution difference, this can be either to the benefit or the detriment of the minority population. And not only does this not involve any explicit human bias, either on the part of the algorithm designer or the data gathering process, <i>it is exacerbated if we artificially force the algorithm to be group blind</i>. Well intentioned "fairness" regulations prohibiting decision makers form taking sensitive attributes into account can actually make things less fair and less accurate at the same time.<br/><br/><br/><br/><br/></div>
    </content>
    <updated>2019-01-26T22:19:00Z</updated>
    <published>2019-01-26T22:19:00Z</published>
    <author>
      <name>Aaron Roth</name>
      <email>noreply@blogger.com</email>
      <uri>https://plus.google.com/111805394598997130229</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-25562705</id>
      <category term="game theory"/>
      <category term="news"/>
      <author>
        <name>Aaron Roth</name>
        <email>noreply@blogger.com</email>
      </author>
      <link href="http://aaronsadventures.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/25562705/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://aaronsadventures.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/25562705/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <title>Adventures in Computation</title>
      <updated>2019-01-28T13:54:32Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=7420</id>
    <link href="https://windowsontheory.org/2019/01/26/introduction-to-amp-and-the-replica-trick/" rel="alternate" type="text/html"/>
    <title>Introduction to AMP and the Replica Trick</title>
    <summary>(This post from the lecture by Yueqi Sheng) In this post, we will talk about detecting phase transitions using Approximate-Message-Passing (AMP), which is an extension of Belief-Propagation to “dense” models. We will also discuss the Replica Symmetric trick, which is a heuristic method of analyzing phase transitions. We focus on the Rademacher spiked Wigner model (defined below), […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><em>(This post from the lecture by <span class="qu"><span class="gD">Yueqi </span></span><span class="qu"><span class="gD">Sheng)</span></span></em></p>
<p>In this post, we will talk about detecting phase transitions using<br/>
Approximate-Message-Passing (AMP), which is an extension of<br/>
Belief-Propagation to “dense” models. We will also discuss the Replica<br/>
Symmetric trick, which is a heuristic method of analyzing phase<br/>
transitions. We focus on the Rademacher spiked Wigner model (defined<br/>
below), and show how both these methods yield the same phrase transition<br/>
in this setting.</p>
<p>The Rademacher spiked Wigner model (RSW) is the following. We are given<br/>
observations <img alt="Y = \frac{\lambda}{n}xx^T + \frac{1}{\sqrt{n}}W" class="latex" src="https://s0.wp.com/latex.php?latex=Y+%3D+%5Cfrac%7B%5Clambda%7D%7Bn%7Dxx%5ET+%2B+%5Cfrac%7B1%7D%7B%5Csqrt%7Bn%7D%7DW&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y = \frac{\lambda}{n}xx^T + \frac{1}{\sqrt{n}}W"/> where<br/>
<img alt="x \in \{\pm 1\}^n" class="latex" src="https://s0.wp.com/latex.php?latex=x+%5Cin+%5C%7B%5Cpm+1%5C%7D%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x \in \{\pm 1\}^n"/> (sampled uniformly) is the true signal and <img alt="W" class="latex" src="https://s0.wp.com/latex.php?latex=W&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="W"/> is a<br/>
Gaussian-Orthogonal-Ensemble (GOE) matrix:<br/>
<img alt="W_{i, j} \sim \mathbb{N}(0, 1)" class="latex" src="https://s0.wp.com/latex.php?latex=W_%7Bi%2C+j%7D+%5Csim+%5Cmathbb%7BN%7D%280%2C+1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="W_{i, j} \sim \mathbb{N}(0, 1)"/> for <img alt="i \neq j" class="latex" src="https://s0.wp.com/latex.php?latex=i+%5Cneq+j&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i \neq j"/> and<br/>
<img alt="W_{i, i} \sim \mathbb{N}(0, 2)" class="latex" src="https://s0.wp.com/latex.php?latex=W_%7Bi%2C+i%7D+%5Csim+%5Cmathbb%7BN%7D%280%2C+2%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="W_{i, i} \sim \mathbb{N}(0, 2)"/>. Here <img alt="\lambda" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda"/> is the signal to noise<br/>
ratio. The goal is to approximately recover <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/>.</p>
<p>The question here is: how small can <img alt="\lambda" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda"/> be such that it is<br/>
impossible to recover anything reasonably correlated with the<br/>
ground-truth <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/>? And what do the approximate-message-passing algorithm<br/>
(or the replica method) have to say about this?</p>
<p>To answer the first question, one can think of the task here is to<br/>
distinguish <img alt="Y \sim \frac{\lambda}{n}xx^T + \frac{1}{\sqrt{n}}W" class="latex" src="https://s0.wp.com/latex.php?latex=Y+%5Csim+%5Cfrac%7B%5Clambda%7D%7Bn%7Dxx%5ET+%2B+%5Cfrac%7B1%7D%7B%5Csqrt%7Bn%7D%7DW&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y \sim \frac{\lambda}{n}xx^T + \frac{1}{\sqrt{n}}W"/> vs<br/>
<img alt="Y \sim W" class="latex" src="https://s0.wp.com/latex.php?latex=Y+%5Csim+W&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y \sim W"/>. One approach to distinguishing these distributions is to<br/>
look at the spectrum of the observation matrix <img alt="Y" class="latex" src="https://s0.wp.com/latex.php?latex=Y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y"/>. (In fact, it turns<br/>
out that this is an asymptotically optimal distinguisher [1]). The spectrum of <img alt="Y" class="latex" src="https://s0.wp.com/latex.php?latex=Y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y"/> behaves as ([2]):</p>
<ul>
<li>When <img alt="\lambda \leq 1" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda+%5Cleq+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda \leq 1"/>, the empirical distribution of eigenvalues in<br/>
spiked model still follows the semicircle law, with the top<br/>
eigenvalues <img alt="\approx 2" class="latex" src="https://s0.wp.com/latex.php?latex=%5Capprox+2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\approx 2"/><p/>
</li>
<li>
<p>When <img alt="\lambda &gt; 1" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda+%3E+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda &gt; 1"/>, we start to see an eigenvalue <img alt="&gt; 2" class="latex" src="https://s0.wp.com/latex.php?latex=%3E+2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="&gt; 2"/> in the<br/>
planted model.</p>
</li>
</ul>
<h1>Approximate message passing</h1>
<p>This section approximately follows the exposition in [3].</p>
<p>First, note that in the Rademacher spiked Wigner model, the posterior<br/>
distribution of the signal <img alt="\sigma" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csigma&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sigma"/> conditioned on the observation <img alt="Y" class="latex" src="https://s0.wp.com/latex.php?latex=Y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y"/><br/>
is: <img alt="\Pr[\sigma | Y] \propto \Pr[Y | \sigma] \propto \prod_{i \neq j} \exp(\lambda Y_{i, j} \sigma_i \sigma_j /2 )" class="latex" src="https://s0.wp.com/latex.php?latex=%5CPr%5B%5Csigma+%7C+Y%5D+%5Cpropto+%5CPr%5BY+%7C+%5Csigma%5D+%5Cpropto+%5Cprod_%7Bi+%5Cneq+j%7D+%5Cexp%28%5Clambda+Y_%7Bi%2C+j%7D+%5Csigma_i+%5Csigma_j+%2F2+%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Pr[\sigma | Y] \propto \Pr[Y | \sigma] \propto \prod_{i \neq j} \exp(\lambda Y_{i, j} \sigma_i \sigma_j /2 )"/> This<br/>
defines a graphical-model (or “factor-graph”), over which we can perform<br/>
Belief-Propogation to infer the posterior distribution of <img alt="\sigma" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csigma&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sigma"/>.<br/>
However, in this case the factor-graph is dense (the distribution is a<br/>
product of potentials <img alt="\exp(\lambda Y_{i, j} \sigma_i\sigma_j)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cexp%28%5Clambda+Y_%7Bi%2C+j%7D+%5Csigma_i%5Csigma_j%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\exp(\lambda Y_{i, j} \sigma_i\sigma_j)"/> for all<br/>
pairs of <img alt="i, j" class="latex" src="https://s0.wp.com/latex.php?latex=i%2C+j&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i, j"/>).</p>
<p>In the previous <a href="https://windowsontheory.org/2018/10/20/belief-propagation-and-the-stochastic-block-model/">blog post</a>, we saw belief propagation works great when the underlying interaction<br/>
graph is sparse. Intuitively, this is because <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/> is locally tree like,<br/>
which allows us to assume each messages are independent random<br/>
variables. In dense model, this no longer holds. One can think of dense<br/>
model as each node receive a weak signal from all its neighbors.</p>
<p>In the dense model setting, a class of algorithms called Approximate<br/>
message passing (AMP) is proposed as an alternative of BP. We will<br/>
define AMP for RWM in terms of its state evolution.</p>
<h2>State evolution of AMP for Rademacher spiked Wigner model</h2>
<p>Recall that in BP, we wish to infer the posterior distributon of<br/>
<img alt="\sigma" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csigma&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sigma"/>, and the messages we pass between nodes correspond to marginal<br/>
probability distribution over values on nodes. In our setting, since the<br/>
distributions are over <img alt="\{\pm 1\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B%5Cpm+1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{\pm 1\}"/>, we can represent distributions by<br/>
their expected values. Let <img alt="m^t_{u \to v} \in [-1, 1]" class="latex" src="https://s0.wp.com/latex.php?latex=m%5Et_%7Bu+%5Cto+v%7D+%5Cin+%5B-1%2C+1%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m^t_{u \to v} \in [-1, 1]"/> denote the<br/>
message from <img alt="u" class="latex" src="https://s0.wp.com/latex.php?latex=u&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="u"/> to <img alt="v" class="latex" src="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="v"/> at time <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t"/>. That is, <img alt="m_{u \to v}" class="latex" src="https://s0.wp.com/latex.php?latex=m_%7Bu+%5Cto+v%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m_{u \to v}"/> corresponds<br/>
to the expected value <img alt="{{\mathbb{E}}}[\sigma_u]" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb%7BE%7D%7D%7D%5B%5Csigma_u%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{{\mathbb{E}}}[\sigma_u]"/>.</p>
<p>To derive the BP update rules, we want to compute the expectation<br/>
<img alt="{{\mathbb{E}}}[\sigma_v]" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb%7BE%7D%7D%7D%5B%5Csigma_v%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{{\mathbb{E}}}[\sigma_v]"/> of a node <img alt="v" class="latex" src="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="v"/>, given the<br/>
messages <img alt="{{\mathbb{E}}}[\sigma_u]" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb%7BE%7D%7D%7D%5B%5Csigma_u%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{{\mathbb{E}}}[\sigma_u]"/> for <img alt="u \neq v" class="latex" src="https://s0.wp.com/latex.php?latex=u+%5Cneq+v&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="u \neq v"/>. We can<br/>
do this using the posterior distribution of the RWM, <img alt="\Pr[\sigma | Y]" class="latex" src="https://s0.wp.com/latex.php?latex=%5CPr%5B%5Csigma+%7C+Y%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Pr[\sigma | Y]"/>,<br/>
which we computed above.<br/>
<img alt="\displaystyle \Pr[\sigma_v = 1 | Y, \{\sigma_u\}_{u \neq v}] = \frac{ \prod_u \exp(\lambda Y_{u, v} \sigma_u) - \prod_u \exp(-\lambda Y_{u, v} \sigma_u) }{ \prod_u \exp(\lambda Y_{u, v} \sigma_u) + \prod_u \exp(-\lambda Y_{u, v} \sigma_u) }" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5CPr%5B%5Csigma_v+%3D+1+%7C+Y%2C+%5C%7B%5Csigma_u%5C%7D_%7Bu+%5Cneq+v%7D%5D+%3D+%5Cfrac%7B+%5Cprod_u+%5Cexp%28%5Clambda+Y_%7Bu%2C+v%7D+%5Csigma_u%29+-+%5Cprod_u+%5Cexp%28-%5Clambda+Y_%7Bu%2C+v%7D+%5Csigma_u%29+%7D%7B+%5Cprod_u+%5Cexp%28%5Clambda+Y_%7Bu%2C+v%7D+%5Csigma_u%29+%2B+%5Cprod_u+%5Cexp%28-%5Clambda+Y_%7Bu%2C+v%7D+%5Csigma_u%29+%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle \Pr[\sigma_v = 1 | Y, \{\sigma_u\}_{u \neq v}] = \frac{ \prod_u \exp(\lambda Y_{u, v} \sigma_u) - \prod_u \exp(-\lambda Y_{u, v} \sigma_u) }{ \prod_u \exp(\lambda Y_{u, v} \sigma_u) + \prod_u \exp(-\lambda Y_{u, v} \sigma_u) }"/></p>
<p>And similarly for <img alt="\Pr[\sigma_v = -1 | Y, \{\sigma_u\}_{u \neq v}]" class="latex" src="https://s0.wp.com/latex.php?latex=%5CPr%5B%5Csigma_v+%3D+-1+%7C+Y%2C+%5C%7B%5Csigma_u%5C%7D_%7Bu+%5Cneq+v%7D%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Pr[\sigma_v = -1 | Y, \{\sigma_u\}_{u \neq v}]"/>.<br/>
From the above, we can take expectations over <img alt="\sigma_u" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csigma_u&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sigma_u"/>, and express<br/>
<img alt="{{\mathbb{E}}}[\sigma_v]" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb%7BE%7D%7D%7D%5B%5Csigma_v%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{{\mathbb{E}}}[\sigma_v]"/> in terms of<br/>
<img alt="\{{{\mathbb{E}}}[\sigma_u]\}_{u \neq v}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B%7B%7B%5Cmathbb%7BE%7D%7D%7D%5B%5Csigma_u%5D%5C%7D_%7Bu+%5Cneq+v%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{{{\mathbb{E}}}[\sigma_u]\}_{u \neq v}"/>. Doing this (and<br/>
using the heuristic assumption that the distribution of <img alt="\sigma" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csigma&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sigma"/> is a<br/>
product distribution), we find that the BP state update can be written<br/>
as:<br/>
<img alt="m^{t}_{u \to v} = f(\sum_{w \neq v}f^{-1}(A_{w, u} m^{t - 1}_{w \to u}))" class="latex" src="https://s0.wp.com/latex.php?latex=m%5E%7Bt%7D_%7Bu+%5Cto+v%7D+%3D+f%28%5Csum_%7Bw+%5Cneq+v%7Df%5E%7B-1%7D%28A_%7Bw%2C+u%7D+m%5E%7Bt+-+1%7D_%7Bw+%5Cto+u%7D%29%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m^{t}_{u \to v} = f(\sum_{w \neq v}f^{-1}(A_{w, u} m^{t - 1}_{w \to u}))"/><br/>
where the interaction matrix <img alt="A_{w, u} = \lambda Y_{w, u}" class="latex" src="https://s0.wp.com/latex.php?latex=A_%7Bw%2C+u%7D+%3D+%5Clambda+Y_%7Bw%2C+u%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_{w, u} = \lambda Y_{w, u}"/>, and<br/>
<img alt="f(x) = tanh(x) = \frac{\exp(x) - \exp(-x)}{\exp(x) + \exp(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=f%28x%29+%3D+tanh%28x%29+%3D+%5Cfrac%7B%5Cexp%28x%29+-+%5Cexp%28-x%29%7D%7B%5Cexp%28x%29+%2B+%5Cexp%28x%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f(x) = tanh(x) = \frac{\exp(x) - \exp(-x)}{\exp(x) + \exp(x)}"/>.</p>
<p>Now, Taylor expanding <img alt="f^{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=f%5E%7B-1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f^{-1}"/> around <img alt="0" class="latex" src="https://s0.wp.com/latex.php?latex=0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="0"/>, we find<br/>
<img alt="m^{t}_{u \to v} = f\left( (\sum_{w \neq v} A_{w, u} m^{t - 1}_{w \to u}) + O(1/\sqrt{n}) \right)" class="latex" src="https://s0.wp.com/latex.php?latex=m%5E%7Bt%7D_%7Bu+%5Cto+v%7D+%3D+f%5Cleft%28+%28%5Csum_%7Bw+%5Cneq+v%7D+A_%7Bw%2C+u%7D+m%5E%7Bt+-+1%7D_%7Bw+%5Cto+u%7D%29+%2B+O%281%2F%5Csqrt%7Bn%7D%29+%5Cright%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m^{t}_{u \to v} = f\left( (\sum_{w \neq v} A_{w, u} m^{t - 1}_{w \to u}) + O(1/\sqrt{n}) \right)"/><br/>
since the terms <img alt="A_{w, u}" class="latex" src="https://s0.wp.com/latex.php?latex=A_%7Bw%2C+u%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_{w, u}"/> are of order <img alt="O(1/\sqrt{n})" class="latex" src="https://s0.wp.com/latex.php?latex=O%281%2F%5Csqrt%7Bn%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(1/\sqrt{n})"/>.</p>
<p>At this point, we could try dropping the “non-backtracking” condition<br/>
<img alt="w \neq v" class="latex" src="https://s0.wp.com/latex.php?latex=w+%5Cneq+v&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="w \neq v"/> from the above sum (since the node <img alt="v" class="latex" src="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="v"/> contributes at most<br/>
<img alt="O(1/\sqrt{n})" class="latex" src="https://s0.wp.com/latex.php?latex=O%281%2F%5Csqrt%7Bn%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(1/\sqrt{n})"/> to the sum anyway), to get the state update:<br/>
<img alt="m^{t}_{u} = f\left( \sum_{w} A_{w, u} m^{t - 1}_{w}) \right)" class="latex" src="https://s0.wp.com/latex.php?latex=m%5E%7Bt%7D_%7Bu%7D+%3D+f%5Cleft%28+%5Csum_%7Bw%7D+A_%7Bw%2C+u%7D+m%5E%7Bt+-+1%7D_%7Bw%7D%29+%5Cright%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m^{t}_{u} = f\left( \sum_{w} A_{w, u} m^{t - 1}_{w}) \right)"/> (note the messages no longer<br/>
depend on receiver – so we write <img alt="m_u" class="latex" src="https://s0.wp.com/latex.php?latex=m_u&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m_u"/> in place of <img alt="m_{u \to v}" class="latex" src="https://s0.wp.com/latex.php?latex=m_%7Bu+%5Cto+v%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m_{u \to v}"/>).<br/>
However, this simplification turns out not to work for estimating the<br/>
signal. The problem is that the “backtracking” terms which we added<br/>
amplify over two iterations.</p>
<p>In AMP, we simply perform the above procedure, except we add a<br/>
correction term to account for the backtracking issue above. Given <img alt="u" class="latex" src="https://s0.wp.com/latex.php?latex=u&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="u"/>,<br/>
for all <img alt="v" class="latex" src="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="v"/>, the AMP update is:<br/>
<img alt="m^{t}_{u \to v} = m^{t}_u = f(\sum_{w}A_{w, u} m^{t - 1}_{w}) + [\text{some correction term}]" class="latex" src="https://s0.wp.com/latex.php?latex=m%5E%7Bt%7D_%7Bu+%5Cto+v%7D+%3D+m%5E%7Bt%7D_u+%3D+f%28%5Csum_%7Bw%7DA_%7Bw%2C+u%7D+m%5E%7Bt+-+1%7D_%7Bw%7D%29+%2B+%5B%5Ctext%7Bsome+correction+term%7D%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m^{t}_{u \to v} = m^{t}_u = f(\sum_{w}A_{w, u} m^{t - 1}_{w}) + [\text{some correction term}]"/></p>
<p>The correction term corresponds to error introduced by the backtracking<br/>
terms. Suppose everything is good until step <img alt="t - 2" class="latex" src="https://s0.wp.com/latex.php?latex=t+-+2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t - 2"/>. We will examine<br/>
the influence of backtracking term to a node <img alt="v" class="latex" src="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="v"/> through length 2 loops.<br/>
At time <img alt="t - 1" class="latex" src="https://s0.wp.com/latex.php?latex=t+-+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t - 1"/>, <img alt="v" class="latex" src="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="v"/> exert <img alt="Y_{v, u}m^{t - 2}_v" class="latex" src="https://s0.wp.com/latex.php?latex=Y_%7Bv%2C+u%7Dm%5E%7Bt+-+2%7D_v&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y_{v, u}m^{t - 2}_v"/> additional influence to<br/>
each of it’s neighbor <img alt="u" class="latex" src="https://s0.wp.com/latex.php?latex=u&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="u"/>. At time <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t"/>, <img alt="v" class="latex" src="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="v"/> receive roughly<br/>
<img alt="Y_{u, v}^2m^{t - 2}_v" class="latex" src="https://s0.wp.com/latex.php?latex=Y_%7Bu%2C+v%7D%5E2m%5E%7Bt+-+2%7D_v&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y_{u, v}^2m^{t - 2}_v"/>. Since <img alt="Y_{u, v}^2" class="latex" src="https://s0.wp.com/latex.php?latex=Y_%7Bu%2C+v%7D%5E2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y_{u, v}^2"/> has magnitude<br/>
<img alt="\approx \frac{1}{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Capprox+%5Cfrac%7B1%7D%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\approx \frac{1}{n}"/> and we need to sum over all of <img alt="v" class="latex" src="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="v"/>’s neighbors,<br/>
this error term is to large to ignore. To characterize the exact form of<br/>
correction, we simply do a taylor expansion</p>
<p><img alt="m^{t}_v = \sum_{u}f(Y_{u, v}m^{t - 1}_u) = \sum_{u}f(Y_{u, v} \left(\sum_{w}f(Y_{w, u}m^{t - 2}_w) - f(Y_{u, v}m^{t - 2}_w)\right) )\\ \approx \sum_u f(Y_{u, v} m^{t - 1}_u) - Y_{u, v}f'(m^{t - 1}_u)m^{t - 2}_v\\ \approx \sum_u f(Y_{u, v} m^{t - 1}_u) - \frac{1}{n}\sum_{u}f'(m^{t - 1}_u)m^{t - 2}_v" class="latex" src="https://s0.wp.com/latex.php?latex=m%5E%7Bt%7D_v+%3D+%5Csum_%7Bu%7Df%28Y_%7Bu%2C+v%7Dm%5E%7Bt+-+1%7D_u%29+%3D+%5Csum_%7Bu%7Df%28Y_%7Bu%2C+v%7D+%5Cleft%28%5Csum_%7Bw%7Df%28Y_%7Bw%2C+u%7Dm%5E%7Bt+-+2%7D_w%29+-+f%28Y_%7Bu%2C+v%7Dm%5E%7Bt+-+2%7D_w%29%5Cright%29+%29%5C%5C+%5Capprox+%5Csum_u+f%28Y_%7Bu%2C+v%7D+m%5E%7Bt+-+1%7D_u%29+-+Y_%7Bu%2C+v%7Df%27%28m%5E%7Bt+-+1%7D_u%29m%5E%7Bt+-+2%7D_v%5C%5C+%5Capprox+%5Csum_u+f%28Y_%7Bu%2C+v%7D+m%5E%7Bt+-+1%7D_u%29+-+%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bu%7Df%27%28m%5E%7Bt+-+1%7D_u%29m%5E%7Bt+-+2%7D_v&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m^{t}_v = \sum_{u}f(Y_{u, v}m^{t - 1}_u) = \sum_{u}f(Y_{u, v} \left(\sum_{w}f(Y_{w, u}m^{t - 2}_w) - f(Y_{u, v}m^{t - 2}_w)\right) )\\ \approx \sum_u f(Y_{u, v} m^{t - 1}_u) - Y_{u, v}f'(m^{t - 1}_u)m^{t - 2}_v\\ \approx \sum_u f(Y_{u, v} m^{t - 1}_u) - \frac{1}{n}\sum_{u}f'(m^{t - 1}_u)m^{t - 2}_v"/></p>
<h2>State evolution of AMP</h2>
<p>In this section we attempt to obtain the phase transition of Rademacher<br/>
spiked Wigner model via looking at <img alt="m^{\infty}" class="latex" src="https://s0.wp.com/latex.php?latex=m%5E%7B%5Cinfty%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m^{\infty}"/>.</p>
<p>We assume that each message could be written as a sum of signal term and<br/>
noise term. <img alt="m^t = \mu_t x + \sigma_t g" class="latex" src="https://s0.wp.com/latex.php?latex=m%5Et+%3D+%5Cmu_t+x+%2B+%5Csigma_t+g&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m^t = \mu_t x + \sigma_t g"/> where<br/>
<img alt="g \sim \mathbb{N}(0, I)" class="latex" src="https://s0.wp.com/latex.php?latex=g+%5Csim+%5Cmathbb%7BN%7D%280%2C+I%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g \sim \mathbb{N}(0, I)"/>. To the dynamics of AMP (and find its phase<br/>
transition), we need to look at how the signal <img alt="\mu_t" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmu_t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mu_t"/> and noise<br/>
<img alt="\sigma_t" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csigma_t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sigma_t"/> evolves with <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t"/>.</p>
<p>We do the following simplification: ignore the correction term and<br/>
assume each time we obtain an independent noise <img alt="g" class="latex" src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g"/>.</p>
<p><img alt="m^{t} = Yf(m^{t - 1}) = (\frac{\lambda}{n}x^Tx + \frac{1}{\sqrt{n}}W)f(m^{t - 1}) = \frac{\lambda}{n} &lt; f(m^{t - 1}), x &gt; x + \frac{1}{\sqrt{n}} Wf(m^{t - 1})" class="latex" src="https://s0.wp.com/latex.php?latex=m%5E%7Bt%7D+%3D+Yf%28m%5E%7Bt+-+1%7D%29+%3D+%28%5Cfrac%7B%5Clambda%7D%7Bn%7Dx%5ETx+%2B+%5Cfrac%7B1%7D%7B%5Csqrt%7Bn%7D%7DW%29f%28m%5E%7Bt+-+1%7D%29+%3D+%5Cfrac%7B%5Clambda%7D%7Bn%7D+%3C+f%28m%5E%7Bt+-+1%7D%29%2C+x+%3E+x+%2B+%5Cfrac%7B1%7D%7B%5Csqrt%7Bn%7D%7D+Wf%28m%5E%7Bt+-+1%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m^{t} = Yf(m^{t - 1}) = (\frac{\lambda}{n}x^Tx + \frac{1}{\sqrt{n}}W)f(m^{t - 1}) = \frac{\lambda}{n} &lt; f(m^{t - 1}), x &gt; x + \frac{1}{\sqrt{n}} Wf(m^{t - 1})"/></p>
<p>Here, we see that <img alt="\mu_t = \frac{\lambda}{n}&lt; f(m^{t - 1}), x&gt;" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmu_t+%3D+%5Cfrac%7B%5Clambda%7D%7Bn%7D%3C+f%28m%5E%7Bt+-+1%7D%29%2C+x%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mu_t = \frac{\lambda}{n}&lt; f(m^{t - 1}), x&gt;"/><br/>
and <img alt="\sigma_t = \frac{1}{\sqrt{n}}Wf(m^{t - 1})" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csigma_t+%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7Bn%7D%7DWf%28m%5E%7Bt+-+1%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sigma_t = \frac{1}{\sqrt{n}}Wf(m^{t - 1})"/>.</p>
<p><em>Note that <img alt="\mu_{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmu_%7Bt%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mu_{t}"/> is essentially proportional to overlap between<br/>
ground truth and current belief</em>, since the function <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> keeps the<br/>
magnitude of the current beliefs bounded.</p>
<p><img alt="\frac{\lambda}{n} &lt;f(m^{t - 1}), x&gt;= \frac{\lambda}{n} &lt;f(\mu_{t - 1}x + \sigma_{t - 1}g), x&gt; \approx\lambda {{\mathbb{E}}}_{X \sim unif(\pm 1), G\sim \mathbb{N}(0, 1)}[X f(\mu_{t - 1}X + \sigma_{t - 1}G)] = \lambda {{\mathbb{E}}}_G[f(\mu_{t - 1} + \sigma_{t - 1}G)]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B%5Clambda%7D%7Bn%7D+%3Cf%28m%5E%7Bt+-+1%7D%29%2C+x%3E%3D+%5Cfrac%7B%5Clambda%7D%7Bn%7D+%3Cf%28%5Cmu_%7Bt+-+1%7Dx+%2B+%5Csigma_%7Bt+-+1%7Dg%29%2C+x%3E+%5Capprox%5Clambda+%7B%7B%5Cmathbb%7BE%7D%7D%7D_%7BX+%5Csim+unif%28%5Cpm+1%29%2C+G%5Csim+%5Cmathbb%7BN%7D%280%2C+1%29%7D%5BX+f%28%5Cmu_%7Bt+-+1%7DX+%2B+%5Csigma_%7Bt+-+1%7DG%29%5D+%3D+%5Clambda+%7B%7B%5Cmathbb%7BE%7D%7D%7D_G%5Bf%28%5Cmu_%7Bt+-+1%7D+%2B+%5Csigma_%7Bt+-+1%7DG%29%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\frac{\lambda}{n} &lt;f(m^{t - 1}), x&gt;= \frac{\lambda}{n} &lt;f(\mu_{t - 1}x + \sigma_{t - 1}g), x&gt; \approx\lambda {{\mathbb{E}}}_{X \sim unif(\pm 1), G\sim \mathbb{N}(0, 1)}[X f(\mu_{t - 1}X + \sigma_{t - 1}G)] = \lambda {{\mathbb{E}}}_G[f(\mu_{t - 1} + \sigma_{t - 1}G)]"/></p>
<p>For the noise term, each coordinate of <img alt="\sigma_t" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csigma_t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sigma_t"/> is a gaussian random<br/>
variable with <img alt="0" class="latex" src="https://s0.wp.com/latex.php?latex=0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="0"/> mean and variance</p>
<p><img alt="\frac{1}{n} \sum_v f(m^{t - 1})_v^2 \approx {{\mathbb{E}}}_{X, G}[f(\mu_{t - 1}X + \sigma_{t - 1}G)^2] = {{\mathbb{E}}}_{G}[f(\mu_{t - 1} + \sigma_{t - 1}G)^2]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7Bn%7D+%5Csum_v+f%28m%5E%7Bt+-+1%7D%29_v%5E2+%5Capprox+%7B%7B%5Cmathbb%7BE%7D%7D%7D_%7BX%2C+G%7D%5Bf%28%5Cmu_%7Bt+-+1%7DX+%2B+%5Csigma_%7Bt+-+1%7DG%29%5E2%5D+%3D+%7B%7B%5Cmathbb%7BE%7D%7D%7D_%7BG%7D%5Bf%28%5Cmu_%7Bt+-+1%7D+%2B+%5Csigma_%7Bt+-+1%7DG%29%5E2%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\frac{1}{n} \sum_v f(m^{t - 1})_v^2 \approx {{\mathbb{E}}}_{X, G}[f(\mu_{t - 1}X + \sigma_{t - 1}G)^2] = {{\mathbb{E}}}_{G}[f(\mu_{t - 1} + \sigma_{t - 1}G)^2]"/></p>
<p>It was shown in [4] that we can introduce a new<br/>
parameter <img alt="\gamma_t" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cgamma_t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\gamma_t"/> s.t.<br/>
<img alt="\gamma_t = \lambda^2 {{\mathbb{E}}}[f(\gamma_{t - 1} + \sqrt{\gamma_{t - 1}}G)]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cgamma_t+%3D+%5Clambda%5E2+%7B%7B%5Cmathbb%7BE%7D%7D%7D%5Bf%28%5Cgamma_%7Bt+-+1%7D+%2B+%5Csqrt%7B%5Cgamma_%7Bt+-+1%7D%7DG%29%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\gamma_t = \lambda^2 {{\mathbb{E}}}[f(\gamma_{t - 1} + \sqrt{\gamma_{t - 1}}G)]"/><br/>
As <img alt="t \to \infty" class="latex" src="https://s0.wp.com/latex.php?latex=t+%5Cto+%5Cinfty&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t \to \infty"/>, turns out <img alt="\mu_t = \frac{\gamma_t}{\lambda}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmu_t+%3D+%5Cfrac%7B%5Cgamma_t%7D%7B%5Clambda%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mu_t = \frac{\gamma_t}{\lambda}"/> and<br/>
<img alt="\sigma_t^2 = \frac{\sigma_t}{\lambda^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csigma_t%5E2+%3D+%5Cfrac%7B%5Csigma_t%7D%7B%5Clambda%5E2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sigma_t^2 = \frac{\sigma_t}{\lambda^2}"/>. To study the behavior of<br/>
<img alt="m^t" class="latex" src="https://s0.wp.com/latex.php?latex=m%5Et&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m^t"/> as <img alt="t \to \infty" class="latex" src="https://s0.wp.com/latex.php?latex=t+%5Cto+%5Cinfty&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t \to \infty"/>, it is enough to track the evolution of<br/>
<img alt="\gamma_t" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cgamma_t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\gamma_t"/>.</p>
<p>This heuristic analysis of AMP actually gives a phase transition at<br/>
<img alt="\lambda = 1" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda+%3D+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda = 1"/> (in fact, the analysis of AMP can be done rigorously as in [5]):</p>
<ul>
<li>For <img alt="\lambda &lt; 1" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda+%3C+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda &lt; 1"/>: If <img alt="\gamma_t \approx 0" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cgamma_t+%5Capprox+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\gamma_t \approx 0"/>, <img alt="|\gamma_t + \sqrt{\gamma_t}G| &lt; 1" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cgamma_t+%2B+%5Csqrt%7B%5Cgamma_t%7DG%7C+%3C+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\gamma_t + \sqrt{\gamma_t}G| &lt; 1"/> w.h.p., thus we have <img alt="\gamma_{t + 1} \approx \lambda^2 (\gamma_t) &lt; \gamma_t" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cgamma_%7Bt+%2B+1%7D+%5Capprox+%5Clambda%5E2+%28%5Cgamma_t%29+%3C+%5Cgamma_t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\gamma_{t + 1} \approx \lambda^2 (\gamma_t) &lt; \gamma_t"/>. Taking <img alt="t \to \infty" class="latex" src="https://s0.wp.com/latex.php?latex=t+%5Cto+%5Cinfty&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t \to \infty"/>, we have <img alt="\gamma_{\infty} = 0" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cgamma_%7B%5Cinfty%7D+%3D+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\gamma_{\infty} = 0"/>, which means there AMP solution has no overlap with the ground truth.<p/>
</li>
<li>
<p>For <img alt="\lambda &gt; 1" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda+%3E+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda &gt; 1"/>: In this case, AMP’s solution has some correlation with the ground truth.</p>
</li>
</ul>
<p><img alt="screenshot 2019-01-26 13.49.39" class="alignnone size-full wp-image-7422" src="https://windowsontheory.files.wordpress.com/2019/01/screenshot-2019-01-26-13.49.39.png?w=600"/></p>
<p>(Figure from [6])</p>
<h1>Replica symmetry trick</h1>
<p>Another way of obtaining the phase transition is via a non-rigorous<br/>
analytic method called the replica method. Although non-rigorous, this<br/>
method from statistical physics has been used to predict the fixed point<br/>
of many message passing algorithms and has the advantage of being easy<br/>
to simulate. In our case, we will see that we obtain the same phase<br/>
transition temperature as AMP above. The method is non-rigorous due to<br/>
several assumptions made during the computation.</p>
<h2>Outline of replica method</h2>
<p>Recall that we are interested in minizing the free energy of a given<br/>
system <img alt="f(\beta, Y) = \frac{1}{\beta n} \log Z(\beta, Y)" class="latex" src="https://s0.wp.com/latex.php?latex=f%28%5Cbeta%2C+Y%29+%3D+%5Cfrac%7B1%7D%7B%5Cbeta+n%7D+%5Clog+Z%28%5Cbeta%2C+Y%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f(\beta, Y) = \frac{1}{\beta n} \log Z(\beta, Y)"/> where <img alt="Z" class="latex" src="https://s0.wp.com/latex.php?latex=Z&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Z"/> is<br/>
the partition function as before:<br/>
<img alt="Z(\beta, Y) = \sum_{x \in \{\pm 1\}^n} exp(-\beta H(Y, x))" class="latex" src="https://s0.wp.com/latex.php?latex=Z%28%5Cbeta%2C+Y%29+%3D+%5Csum_%7Bx+%5Cin+%5C%7B%5Cpm+1%5C%7D%5En%7D+exp%28-%5Cbeta+H%28Y%2C+x%29%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Z(\beta, Y) = \sum_{x \in \{\pm 1\}^n} exp(-\beta H(Y, x))"/> and<br/>
<img alt="H(Y, x) = -&lt;Y, x^Tx&gt; = -xYx^T = -\sum_{i, j} Y_{i, j}x_ix_j" class="latex" src="https://s0.wp.com/latex.php?latex=H%28Y%2C+x%29+%3D+-%3CY%2C+x%5ETx%3E+%3D+-xYx%5ET+%3D+-%5Csum_%7Bi%2C+j%7D+Y_%7Bi%2C+j%7Dx_ix_j&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H(Y, x) = -&lt;Y, x^Tx&gt; = -xYx^T = -\sum_{i, j} Y_{i, j}x_ix_j"/>.</p>
<p>In replica method, <img alt="Y" class="latex" src="https://s0.wp.com/latex.php?latex=Y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y"/> is not fixed but a random variable. The<br/>
assumption is that as <img alt="n \to \infty" class="latex" src="https://s0.wp.com/latex.php?latex=n+%5Cto+%5Cinfty&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n \to \infty"/>, free energy doesn’t vary with <img alt="Y" class="latex" src="https://s0.wp.com/latex.php?latex=Y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y"/><br/>
too much, so we will look at the mean of <img alt="f_Y" class="latex" src="https://s0.wp.com/latex.php?latex=f_Y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f_Y"/> to approximate free<br/>
energy of the system.</p>
<p><img alt="f(\beta) = \lim_{n \to \infty}\frac{1}{\beta n}{{\mathbb{E}}}_{Y}[\log Z(\beta, Y)]" class="latex" src="https://s0.wp.com/latex.php?latex=f%28%5Cbeta%29+%3D+%5Clim_%7Bn+%5Cto+%5Cinfty%7D%5Cfrac%7B1%7D%7B%5Cbeta+n%7D%7B%7B%5Cmathbb%7BE%7D%7D%7D_%7BY%7D%5B%5Clog+Z%28%5Cbeta%2C+Y%29%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f(\beta) = \lim_{n \to \infty}\frac{1}{\beta n}{{\mathbb{E}}}_{Y}[\log Z(\beta, Y)]"/></p>
<p><img alt="f(\beta)" class="latex" src="https://s0.wp.com/latex.php?latex=f%28%5Cbeta%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f(\beta)"/> is called the free energy density and the goal now is to<br/>
compute the free energy density as a function of only <img alt="\beta" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbeta&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\beta"/> , the<br/>
temperature of the system.</p>
<p>The <strong>replica method</strong> is first proposed as a simplification of the<br/>
computation of <img alt="f(\beta)" class="latex" src="https://s0.wp.com/latex.php?latex=f%28%5Cbeta%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f(\beta)"/></p>
<p>It is a generally hard problem to compute <img alt="f(\beta)" class="latex" src="https://s0.wp.com/latex.php?latex=f%28%5Cbeta%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f(\beta)"/> in a clear way. A<br/>
naive attempt of approximate <img alt="f(\beta)" class="latex" src="https://s0.wp.com/latex.php?latex=f%28%5Cbeta%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f(\beta)"/> is to simply pull the log out<br/>
<img alt="g(\beta) = \frac{1}{\beta n}\log {{\mathbb{E}}}_Y[Z(\beta, Y)]" class="latex" src="https://s0.wp.com/latex.php?latex=g%28%5Cbeta%29+%3D+%5Cfrac%7B1%7D%7B%5Cbeta+n%7D%5Clog+%7B%7B%5Cmathbb%7BE%7D%7D%7D_Y%5BZ%28%5Cbeta%2C+Y%29%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g(\beta) = \frac{1}{\beta n}\log {{\mathbb{E}}}_Y[Z(\beta, Y)]"/><br/>
Unfortunately <img alt="g(\beta)" class="latex" src="https://s0.wp.com/latex.php?latex=g%28%5Cbeta%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g(\beta)"/> and <img alt="f(\beta)" class="latex" src="https://s0.wp.com/latex.php?latex=f%28%5Cbeta%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f(\beta)"/> are quite different quantities,<br/>
at least when temperature is low. Intuitively, <img alt="f(\beta)" class="latex" src="https://s0.wp.com/latex.php?latex=f%28%5Cbeta%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f(\beta)"/> is looking at<br/>
system with a fixed <img alt="Y" class="latex" src="https://s0.wp.com/latex.php?latex=Y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y"/> while in <img alt="g(\beta)" class="latex" src="https://s0.wp.com/latex.php?latex=g%28%5Cbeta%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g(\beta)"/>, <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/> and <img alt="Y" class="latex" src="https://s0.wp.com/latex.php?latex=Y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y"/> are allowed to<br/>
fluctuate together. When the temperature is high, <img alt="Y" class="latex" src="https://s0.wp.com/latex.php?latex=Y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y"/> doesn’t play a big<br/>
roll in system thus they could be close. However, when temperature is<br/>
low, there could be a problems. Let <img alt="\beta \to \infty" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbeta+%5Cto+%5Cinfty&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\beta \to \infty"/>,<br/>
<img alt="f(\beta) \approx \int_Y (\beta x_Y Y x_Y)\mu(Y) dY" class="latex" src="https://s0.wp.com/latex.php?latex=f%28%5Cbeta%29+%5Capprox+%5Cint_Y+%28%5Cbeta+x_Y+Y+x_Y%29%5Cmu%28Y%29+dY&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f(\beta) \approx \int_Y (\beta x_Y Y x_Y)\mu(Y) dY"/>,<br/>
<img alt="g(\beta) \approx \log \int_Y exp(\beta x_J Y x_Y)\mu(Y)dY \approx \beta x^* Yx^*" class="latex" src="https://s0.wp.com/latex.php?latex=g%28%5Cbeta%29+%5Capprox+%5Clog+%5Cint_Y+exp%28%5Cbeta+x_J+Y+x_Y%29%5Cmu%28Y%29dY+%5Capprox+%5Cbeta+x%5E%2A+Yx%5E%2A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g(\beta) \approx \log \int_Y exp(\beta x_J Y x_Y)\mu(Y)dY \approx \beta x^* Yx^*"/>.</p>
<p>While <img alt="{{\mathbb{E}}}_X[\log(f(X))]" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb%7BE%7D%7D%7D_X%5B%5Clog%28f%28X%29%29%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{{\mathbb{E}}}_X[\log(f(X))]"/> is hard to compute,<br/>
<img alt="{{\mathbb{E}}}[f(X)^r]" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb%7BE%7D%7D%7D%5Bf%28X%29%5Er%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{{\mathbb{E}}}[f(X)^r]"/> is a much easier quantity. The<br/>
replica trick starts from rewriting <img alt="f(\beta)" class="latex" src="https://s0.wp.com/latex.php?latex=f%28%5Cbeta%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f(\beta)"/> with moments of <img alt="Z" class="latex" src="https://s0.wp.com/latex.php?latex=Z&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Z"/>:<br/>
Recall that <img alt="x^r \approx 1 + r \log x" class="latex" src="https://s0.wp.com/latex.php?latex=x%5Er+%5Capprox+1+%2B+r+%5Clog+x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x^r \approx 1 + r \log x"/> for <img alt="r \approx 0" class="latex" src="https://s0.wp.com/latex.php?latex=r+%5Capprox+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="r \approx 0"/> and<br/>
<img alt="\ln(1 + x)\approx x" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cln%281+%2B+x%29%5Capprox+x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\ln(1 + x)\approx x"/>, using this we can rewrite <img alt="f(x)" class="latex" src="https://s0.wp.com/latex.php?latex=f%28x%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f(x)"/> in the following<br/>
way:</p>
<p><strong>Claim 1.</strong> <em>Let <img alt="f_r(\beta) = \frac{1}{r \beta n}\ln[{{\mathbb{E}}}_Y[Z(\beta, Y)^r]]" class="latex" src="https://s0.wp.com/latex.php?latex=f_r%28%5Cbeta%29+%3D+%5Cfrac%7B1%7D%7Br+%5Cbeta+n%7D%5Cln%5B%7B%7B%5Cmathbb%7BE%7D%7D%7D_Y%5BZ%28%5Cbeta%2C+Y%29%5Er%5D%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f_r(\beta) = \frac{1}{r \beta n}\ln[{{\mathbb{E}}}_Y[Z(\beta, Y)^r]]"/></em><br/>
<em>Then, <img alt="f(\beta) = \lim_{r \to 0}f_r(\beta)" class="latex" src="https://s0.wp.com/latex.php?latex=f%28%5Cbeta%29+%3D+%5Clim_%7Br+%5Cto+0%7Df_r%28%5Cbeta%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f(\beta) = \lim_{r \to 0}f_r(\beta)"/></em></p>
<p>The idea of replica method is quite simple</p>
<ul>
<li>Define a function <img alt="f(r, \beta)" class="latex" src="https://s0.wp.com/latex.php?latex=f%28r%2C+%5Cbeta%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f(r, \beta)"/> for <img alt="r \in \mathbb{Z}_+" class="latex" src="https://s0.wp.com/latex.php?latex=r+%5Cin+%5Cmathbb%7BZ%7D_%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="r \in \mathbb{Z}_+"/> s.t. <img alt="f(r, \beta) = f_r(\beta)" class="latex" src="https://s0.wp.com/latex.php?latex=f%28r%2C+%5Cbeta%29+%3D+f_r%28%5Cbeta%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f(r, \beta) = f_r(\beta)"/> for all such <img alt="r" class="latex" src="https://s0.wp.com/latex.php?latex=r&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="r"/>.<p/>
</li>
<li>
<p>Extend <img alt="f(r, \beta)" class="latex" src="https://s0.wp.com/latex.php?latex=f%28r%2C+%5Cbeta%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f(r, \beta)"/> analytically to all <img alt="r \in {{\mathbb{R}}}_+" class="latex" src="https://s0.wp.com/latex.php?latex=r+%5Cin+%7B%7B%5Cmathbb%7BR%7D%7D%7D_%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="r \in {{\mathbb{R}}}_+"/> and take the limit of <img alt="r \to 0" class="latex" src="https://s0.wp.com/latex.php?latex=r+%5Cto+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="r \to 0"/>.</p>
</li>
</ul>
<p>The second step may sound crazy, but for some unexplained reason, it has<br/>
been surprisingly effective at making correct predictions.</p>
<p>The term replica comes from the way used to compute<br/>
<img alt="{{\mathbb{E}}}[Z^r]" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb%7BE%7D%7D%7D%5BZ%5Er%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{{\mathbb{E}}}[Z^r]"/> in Claim 1. We expand the <img alt="r" class="latex" src="https://s0.wp.com/latex.php?latex=r&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="r"/>-th moment<br/>
in terms of <img alt="r" class="latex" src="https://s0.wp.com/latex.php?latex=r&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="r"/> replicas of the system</p>
<p><img alt="Z(\beta, Y)^r = (\sum_x exp(-\beta H(Y, x)))^r = \sum_{x^1, \cdots, x^r} \Pi_{k = 1}^r exp(-\beta H(Y, x^i))" class="latex" src="https://s0.wp.com/latex.php?latex=Z%28%5Cbeta%2C+Y%29%5Er+%3D+%28%5Csum_x+exp%28-%5Cbeta+H%28Y%2C+x%29%29%29%5Er+%3D+%5Csum_%7Bx%5E1%2C+%5Ccdots%2C+x%5Er%7D+%5CPi_%7Bk+%3D+1%7D%5Er+exp%28-%5Cbeta+H%28Y%2C+x%5Ei%29%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Z(\beta, Y)^r = (\sum_x exp(-\beta H(Y, x)))^r = \sum_{x^1, \cdots, x^r} \Pi_{k = 1}^r exp(-\beta H(Y, x^i))"/></p>
<h2>For Rademacher spiked Wigner model</h2>
<p>In this section, we will see how one can apply the replica trick to<br/>
obtain phase transition in the Rademacher spiked Wigner model. Recall<br/>
that given a hidden <img alt="a \in \{\pm 1\}^n" class="latex" src="https://s0.wp.com/latex.php?latex=a+%5Cin+%5C%7B%5Cpm+1%5C%7D%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a \in \{\pm 1\}^n"/>, the observable<br/>
<img alt="Y = \frac{\lambda}{n}a^Ta + \frac{1}{\sqrt n} W" class="latex" src="https://s0.wp.com/latex.php?latex=Y+%3D+%5Cfrac%7B%5Clambda%7D%7Bn%7Da%5ETa+%2B+%5Cfrac%7B1%7D%7B%5Csqrt+n%7D+W&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y = \frac{\lambda}{n}a^Ta + \frac{1}{\sqrt n} W"/> where<br/>
<img alt="W_{i, j} \sim \mathcal{N}(0, 1)" class="latex" src="https://s0.wp.com/latex.php?latex=W_%7Bi%2C+j%7D+%5Csim+%5Cmathcal%7BN%7D%280%2C+1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="W_{i, j} \sim \mathcal{N}(0, 1)"/> and <img alt="W_{i, i} \sim \mathcal{N}(0, 2)" class="latex" src="https://s0.wp.com/latex.php?latex=W_%7Bi%2C+i%7D+%5Csim+%5Cmathcal%7BN%7D%280%2C+2%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="W_{i, i} \sim \mathcal{N}(0, 2)"/>.<br/>
We are interested in finding the smallest <img alt="\lambda" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda"/> where we can still<br/>
recover a solution with some correlation to the ground truth <img alt="a" class="latex" src="https://s0.wp.com/latex.php?latex=a&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a"/>. <em>Note<br/>
that <img alt="\{W_{i, i}\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7BW_%7Bi%2C+i%7D%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{W_{i, i}\}"/> is not so important here as <img alt="x_i^2" class="latex" src="https://s0.wp.com/latex.php?latex=x_i%5E2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_i^2"/> doesn’t carry<br/>
any information in this case.</em></p>
<p>Given by the posterior <img alt="{{\mathbb{P}}}[x|Y]" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb%7BP%7D%7D%7D%5Bx%7CY%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{{\mathbb{P}}}[x|Y]"/>, the system we<br/>
set up corresponding to Rademacher spiked Wigner model is the following:</p>
<ul>
<li>the system consists of <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> particles and the interactions between<br/>
each particle are give by <img alt="Y" class="latex" src="https://s0.wp.com/latex.php?latex=Y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y"/><p/>
</li>
<li>
<p>the signal to noise ratio <img alt="\lambda" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda"/> as the inverse temperature<br/>
<img alt="\beta" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbeta&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\beta"/>.</p>
</li>
</ul>
<p>Following the steps above, we begin by computing<br/>
<img alt="f(r, \beta) = \frac{1}{r\beta n}\ln{{\mathbb{E}}}_Y[Z^r]" class="latex" src="https://s0.wp.com/latex.php?latex=f%28r%2C+%5Cbeta%29+%3D+%5Cfrac%7B1%7D%7Br%5Cbeta+n%7D%5Cln%7B%7B%5Cmathbb%7BE%7D%7D%7D_Y%5BZ%5Er%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f(r, \beta) = \frac{1}{r\beta n}\ln{{\mathbb{E}}}_Y[Z^r]"/><br/>
for <img alt="r \in \mathbb{Z}_+" class="latex" src="https://s0.wp.com/latex.php?latex=r+%5Cin+%5Cmathbb%7BZ%7D_%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="r \in \mathbb{Z}_+"/>: Denote <img alt="X^k = (x^k)^Tx^k" class="latex" src="https://s0.wp.com/latex.php?latex=X%5Ek+%3D+%28x%5Ek%29%5ETx%5Ek&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X^k = (x^k)^Tx^k"/> where <img alt="x^k" class="latex" src="https://s0.wp.com/latex.php?latex=x%5Ek&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x^k"/> is the<br/>
<img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>th replica of the system.</p>
<p><img alt="{{\mathbb{E}}}_Y[Z^r] = \int_Y \sum_{x^1, \cdots, x^r} exp(\beta \sum_k &lt;Y, X^k&gt; \mu(Y) dY\\ = \int_Y \sum_{x^1, \cdots, x^r} exp(\beta &lt;Y, \sum_k X^k&gt;) \mu(Y) dY" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb%7BE%7D%7D%7D_Y%5BZ%5Er%5D+%3D+%5Cint_Y+%5Csum_%7Bx%5E1%2C+%5Ccdots%2C+x%5Er%7D+exp%28%5Cbeta+%5Csum_k+%3CY%2C+X%5Ek%3E+%5Cmu%28Y%29+dY%5C%5C+%3D+%5Cint_Y+%5Csum_%7Bx%5E1%2C+%5Ccdots%2C+x%5Er%7D+exp%28%5Cbeta+%3CY%2C+%5Csum_k+X%5Ek%3E%29+%5Cmu%28Y%29+dY&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{{\mathbb{E}}}_Y[Z^r] = \int_Y \sum_{x^1, \cdots, x^r} exp(\beta \sum_k &lt;Y, X^k&gt; \mu(Y) dY\\ = \int_Y \sum_{x^1, \cdots, x^r} exp(\beta &lt;Y, \sum_k X^k&gt;) \mu(Y) dY"/></p>
<p>We then simplify the above expression with a technical claim.</p>
<p><strong>Claim 2.</strong><em> Let <img alt="Y = A + \frac{1}{\sqrt{n}}W" class="latex" src="https://s0.wp.com/latex.php?latex=Y+%3D+A+%2B+%5Cfrac%7B1%7D%7B%5Csqrt%7Bn%7D%7DW&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y = A + \frac{1}{\sqrt{n}}W"/> where <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> is a fixed matrix and</em><br/>
<em><img alt="W" class="latex" src="https://s0.wp.com/latex.php?latex=W&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="W"/> is the GOE matrix defined as above. Then,</em><br/>
<em><img alt="\int_Y exp(\beta&lt;Y, X&gt;) \mu(Y) dY = exp(\frac{\beta^2}{n}{{\|{X}\|_{F}}}^2 + \frac{\beta}{2} &lt;A, X&gt;)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cint_Y+exp%28%5Cbeta%3CY%2C+X%3E%29+%5Cmu%28Y%29+dY+%3D+exp%28%5Cfrac%7B%5Cbeta%5E2%7D%7Bn%7D%7B%7B%5C%7C%7BX%7D%5C%7C_%7BF%7D%7D%7D%5E2+%2B+%5Cfrac%7B%5Cbeta%7D%7B2%7D+%3CA%2C+X%3E%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\int_Y exp(\beta&lt;Y, X&gt;) \mu(Y) dY = exp(\frac{\beta^2}{n}{{\|{X}\|_{F}}}^2 + \frac{\beta}{2} &lt;A, X&gt;)"/></em><br/>
<em>for some constant <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/> depending on distribution of <img alt="Y" class="latex" src="https://s0.wp.com/latex.php?latex=Y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y"/>.</em></p>
<p>Denote <img alt="X = \sum_k X^k" class="latex" src="https://s0.wp.com/latex.php?latex=X+%3D+%5Csum_k+X%5Ek&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X = \sum_k X^k"/>. Apply Claim 2 with<br/>
<img alt="A = \frac{\beta}{n}a^Ta" class="latex" src="https://s0.wp.com/latex.php?latex=A+%3D+%5Cfrac%7B%5Cbeta%7D%7Bn%7Da%5ETa&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A = \frac{\beta}{n}a^Ta"/>, we have<br/>
<img alt="{{\mathbb{E}}}_Y[Z^r] = \sum_{x^1, \cdots, x^r} exp(\frac{\beta^2}{n}{{\|{X}\|_{F}}}^2 + \frac{\beta^2}{2n} &lt;a^Ta, X&gt;)" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb%7BE%7D%7D%7D_Y%5BZ%5Er%5D+%3D+%5Csum_%7Bx%5E1%2C+%5Ccdots%2C+x%5Er%7D+exp%28%5Cfrac%7B%5Cbeta%5E2%7D%7Bn%7D%7B%7B%5C%7C%7BX%7D%5C%7C_%7BF%7D%7D%7D%5E2+%2B+%5Cfrac%7B%5Cbeta%5E2%7D%7B2n%7D+%3Ca%5ETa%2C+X%3E%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{{\mathbb{E}}}_Y[Z^r] = \sum_{x^1, \cdots, x^r} exp(\frac{\beta^2}{n}{{\|{X}\|_{F}}}^2 + \frac{\beta^2}{2n} &lt;a^Ta, X&gt;)"/><br/>
To understand the term inside exponent better, we can rewrite the inner<br/>
sum in terms of overlap between replicas:</p>
<p><img alt="{{\|{X}\|_{F}}}^2 = \sum_{i, j}X_{i, j}^2 = \sum_{i, j}(\sum_{k = 1}^r x^k_ix^k_j)^2 =\sum_{i, j}(\sum_{k = 1}^r x^k_ix^k_j)(\sum_{l = 1}^r x^l_ix^l_j)\\ = \sum_{k, l} (\sum_{i = 1}^n x^k_ix^{l}_i)^2 = \sum_{k, l} &lt;x^k, x^l&gt;^2" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5C%7C%7BX%7D%5C%7C_%7BF%7D%7D%7D%5E2+%3D+%5Csum_%7Bi%2C+j%7DX_%7Bi%2C+j%7D%5E2+%3D+%5Csum_%7Bi%2C+j%7D%28%5Csum_%7Bk+%3D+1%7D%5Er+x%5Ek_ix%5Ek_j%29%5E2+%3D%5Csum_%7Bi%2C+j%7D%28%5Csum_%7Bk+%3D+1%7D%5Er+x%5Ek_ix%5Ek_j%29%28%5Csum_%7Bl+%3D+1%7D%5Er+x%5El_ix%5El_j%29%5C%5C+%3D+%5Csum_%7Bk%2C+l%7D+%28%5Csum_%7Bi+%3D+1%7D%5En+x%5Ek_ix%5E%7Bl%7D_i%29%5E2+%3D+%5Csum_%7Bk%2C+l%7D+%3Cx%5Ek%2C+x%5El%3E%5E2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{{\|{X}\|_{F}}}^2 = \sum_{i, j}X_{i, j}^2 = \sum_{i, j}(\sum_{k = 1}^r x^k_ix^k_j)^2 =\sum_{i, j}(\sum_{k = 1}^r x^k_ix^k_j)(\sum_{l = 1}^r x^l_ix^l_j)\\ = \sum_{k, l} (\sum_{i = 1}^n x^k_ix^{l}_i)^2 = \sum_{k, l} &lt;x^k, x^l&gt;^2"/></p>
<p>where the last equality follows from rearranging and switch the inner<br/>
and outer summations.</p>
<p>Using a similar trick, we can view the other term as</p>
<p><img alt="&lt;a^Ta, X&gt; = \sum_{i, j}\sum_{k = 1}^rx^k_ix^k_ja_ia_j = \sum_{k = 1}^r (\sum_{i = 1}^n a_ix^k_i)^2 = \sum_{k}&lt;a, x^k&gt;^2" class="latex" src="https://s0.wp.com/latex.php?latex=%3Ca%5ETa%2C+X%3E+%3D+%5Csum_%7Bi%2C+j%7D%5Csum_%7Bk+%3D+1%7D%5Erx%5Ek_ix%5Ek_ja_ia_j+%3D+%5Csum_%7Bk+%3D+1%7D%5Er+%28%5Csum_%7Bi+%3D+1%7D%5En+a_ix%5Ek_i%29%5E2+%3D+%5Csum_%7Bk%7D%3Ca%2C+x%5Ek%3E%5E2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="&lt;a^Ta, X&gt; = \sum_{i, j}\sum_{k = 1}^rx^k_ix^k_ja_ia_j = \sum_{k = 1}^r (\sum_{i = 1}^n a_ix^k_i)^2 = \sum_{k}&lt;a, x^k&gt;^2"/></p>
<p>Note that <img alt="Q_{k, l} = &lt;x^k, x^l&gt;" class="latex" src="https://s0.wp.com/latex.php?latex=Q_%7Bk%2C+l%7D+%3D+%3Cx%5Ek%2C+x%5El%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Q_{k, l} = &lt;x^k, x^l&gt;"/> represents overlaps between the<br/>
<img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/> and <img alt="l" class="latex" src="https://s0.wp.com/latex.php?latex=l&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="l"/>th replicas and <img alt="Q_k = &lt;a, x^k&gt;" class="latex" src="https://s0.wp.com/latex.php?latex=Q_k+%3D+%3Ca%2C+x%5Ek%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Q_k = &lt;a, x^k&gt;"/> represents the<br/>
overlaps between the <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>th replica and the ground truth vector.</p>
<p>In the end, we get for any integer <img alt="r" class="latex" src="https://s0.wp.com/latex.php?latex=r&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="r"/>, (Equation 1):</p>
<p><img alt="\displaystyle f(r, \beta) = \frac{1}{r\beta n}\ln(\sum_{x^1, \cdots, x^r} exp(\frac{\beta^2}{n}\sum_{k, l}Q_{k, l}^2 + \frac{\beta^2}{2n}\sum_k Q_k^2)) \label{e:1}\\ = \frac{1}{r\beta n} \ln(\sum_{Q}\nu_{x^k}(Q)exp(\frac{\beta^2}{n}\sum_{k, l}Q_{k, l}^2 + \frac{\beta^2}{2n}\sum_k Q_k^2))" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+f%28r%2C+%5Cbeta%29+%3D+%5Cfrac%7B1%7D%7Br%5Cbeta+n%7D%5Cln%28%5Csum_%7Bx%5E1%2C+%5Ccdots%2C+x%5Er%7D+exp%28%5Cfrac%7B%5Cbeta%5E2%7D%7Bn%7D%5Csum_%7Bk%2C+l%7DQ_%7Bk%2C+l%7D%5E2+%2B+%5Cfrac%7B%5Cbeta%5E2%7D%7B2n%7D%5Csum_k+Q_k%5E2%29%29+%5Clabel%7Be%3A1%7D%5C%5C+%3D+%5Cfrac%7B1%7D%7Br%5Cbeta+n%7D+%5Cln%28%5Csum_%7BQ%7D%5Cnu_%7Bx%5Ek%7D%28Q%29exp%28%5Cfrac%7B%5Cbeta%5E2%7D%7Bn%7D%5Csum_%7Bk%2C+l%7DQ_%7Bk%2C+l%7D%5E2+%2B+%5Cfrac%7B%5Cbeta%5E2%7D%7B2n%7D%5Csum_k+Q_k%5E2%29%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle f(r, \beta) = \frac{1}{r\beta n}\ln(\sum_{x^1, \cdots, x^r} exp(\frac{\beta^2}{n}\sum_{k, l}Q_{k, l}^2 + \frac{\beta^2}{2n}\sum_k Q_k^2)) \label{e:1}\\ = \frac{1}{r\beta n} \ln(\sum_{Q}\nu_{x^k}(Q)exp(\frac{\beta^2}{n}\sum_{k, l}Q_{k, l}^2 + \frac{\beta^2}{2n}\sum_k Q_k^2))"/></p>
<p>Our goal becomes to approximate this quantity. Intuitively, if we think<br/>
of <img alt="Q_{k, l}" class="latex" src="https://s0.wp.com/latex.php?latex=Q_%7Bk%2C+l%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Q_{k, l}"/> as indices on a <img alt="(r + 1) \times (r + 1)" class="latex" src="https://s0.wp.com/latex.php?latex=%28r+%2B+1%29+%5Ctimes+%28r+%2B+1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(r + 1) \times (r + 1)"/> matrices, <img alt="Q" class="latex" src="https://s0.wp.com/latex.php?latex=Q&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Q"/>,<br/>
with <img alt="Q(i,i) = 1" class="latex" src="https://s0.wp.com/latex.php?latex=Q%28i%2Ci%29+%3D+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Q(i,i) = 1"/>, then <img alt="Q" class="latex" src="https://s0.wp.com/latex.php?latex=Q&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Q"/> is the average of <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> i.i.d matrices. So we<br/>
expect <img alt="Q_{j, k} \in [\pm \frac{1}{n}]" class="latex" src="https://s0.wp.com/latex.php?latex=Q_%7Bj%2C+k%7D+%5Cin+%5B%5Cpm+%5Cfrac%7B1%7D%7Bn%7D%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Q_{j, k} \in [\pm \frac{1}{n}]"/> for <img alt="j \neq k" class="latex" src="https://s0.wp.com/latex.php?latex=j+%5Cneq+k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="j \neq k"/> w.h.p. In the<br/>
remaining part, We find the correct <img alt="Q" class="latex" src="https://s0.wp.com/latex.php?latex=Q&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Q"/> via rewriting Equation 1.</p>
<p>Observe that by introducing a new variable <img alt="Z_{k, l}" class="latex" src="https://s0.wp.com/latex.php?latex=Z_%7Bk%2C+l%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Z_{k, l}"/> for <img alt="k \neq l" class="latex" src="https://s0.wp.com/latex.php?latex=k+%5Cneq+l&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k \neq l"/> and<br/>
using the property of gaussian intergal (Equation 4):</p>
<p><img alt="\label{e:4} exp(\frac{\beta^2}{n}Q_{k, l}^2) = \sqrt{\frac{n}{4\pi}}\int_{Z_{k, l}} exp(-\frac{n}{4}Z_{k, l}^2 + \beta Q_{k, l}Z_{k, l})dZ_k" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clabel%7Be%3A4%7D+exp%28%5Cfrac%7B%5Cbeta%5E2%7D%7Bn%7DQ_%7Bk%2C+l%7D%5E2%29+%3D+%5Csqrt%7B%5Cfrac%7Bn%7D%7B4%5Cpi%7D%7D%5Cint_%7BZ_%7Bk%2C+l%7D%7D+exp%28-%5Cfrac%7Bn%7D%7B4%7DZ_%7Bk%2C+l%7D%5E2+%2B+%5Cbeta+Q_%7Bk%2C+l%7DZ_%7Bk%2C+l%7D%29dZ_k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\label{e:4} exp(\frac{\beta^2}{n}Q_{k, l}^2) = \sqrt{\frac{n}{4\pi}}\int_{Z_{k, l}} exp(-\frac{n}{4}Z_{k, l}^2 + \beta Q_{k, l}Z_{k, l})dZ_k"/></p>
<p><img alt="\exp(\frac{\beta^2}{2n}Q_k^2) = \sqrt{\frac{1}{8\pi n}}\int_{Z_k}exp(-(2n)Z_k^2 + 2\beta Q_{k}Z_k)dZ_k" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cexp%28%5Cfrac%7B%5Cbeta%5E2%7D%7B2n%7DQ_k%5E2%29+%3D+%5Csqrt%7B%5Cfrac%7B1%7D%7B8%5Cpi+n%7D%7D%5Cint_%7BZ_k%7Dexp%28-%282n%29Z_k%5E2+%2B+2%5Cbeta+Q_%7Bk%7DZ_k%29dZ_k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\exp(\frac{\beta^2}{2n}Q_k^2) = \sqrt{\frac{1}{8\pi n}}\int_{Z_k}exp(-(2n)Z_k^2 + 2\beta Q_{k}Z_k)dZ_k"/><br/>
Replace each <img alt="exp(\frac{\beta^2}{n}Q_{k, l}^2)" class="latex" src="https://s0.wp.com/latex.php?latex=exp%28%5Cfrac%7B%5Cbeta%5E2%7D%7Bn%7DQ_%7Bk%2C+l%7D%5E2%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="exp(\frac{\beta^2}{n}Q_{k, l}^2)"/> by a such integral, we<br/>
have (Equation 2):</p>
<p><img alt="\begin{gathered} {{\mathbb{E}}}[Z^r] = \sum_{x^1, \cdots, x^r} exp(\frac{\beta^2}{n}\sum_{k, l}Q_{k, l}^2 + \frac{\beta^2}{2n}\sum_k Q_k^2) \label{e:2}\\ = C\sum_{x^1, \cdots, x^r} \exp(\beta^2 n)\int_{Z_{k, l}}exp(-\frac{n}{4}\sum_{k \neq l}Z_{k, l}^2 - \frac{n}{2}\sum_k Z_k^2 + \beta \sum_{k \neq l}Y_{k, l}Q_{k, l} + 2\beta\sum_kZ_k Q_k) dZ \\ =C\exp(\beta^n) \int_{Y_{k, l}}exp(-\frac{n}{4}\sum_{k \neq l}Y_{k, l}^2 - \frac{n}{2}\sum_k Z_k^2 + \ln(\sum_{x_1,\cdots, x_r}exp(\beta \sum_{k\neq l}Y_{k, l}Q_{k, l} + 2\beta\sum_kY_k Q_k)) dY \label{e:2}\end{gathered}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Bgathered%7D+%7B%7B%5Cmathbb%7BE%7D%7D%7D%5BZ%5Er%5D+%3D+%5Csum_%7Bx%5E1%2C+%5Ccdots%2C+x%5Er%7D+exp%28%5Cfrac%7B%5Cbeta%5E2%7D%7Bn%7D%5Csum_%7Bk%2C+l%7DQ_%7Bk%2C+l%7D%5E2+%2B+%5Cfrac%7B%5Cbeta%5E2%7D%7B2n%7D%5Csum_k+Q_k%5E2%29+%5Clabel%7Be%3A2%7D%5C%5C+%3D+C%5Csum_%7Bx%5E1%2C+%5Ccdots%2C+x%5Er%7D+%5Cexp%28%5Cbeta%5E2+n%29%5Cint_%7BZ_%7Bk%2C+l%7D%7Dexp%28-%5Cfrac%7Bn%7D%7B4%7D%5Csum_%7Bk+%5Cneq+l%7DZ_%7Bk%2C+l%7D%5E2+-+%5Cfrac%7Bn%7D%7B2%7D%5Csum_k+Z_k%5E2+%2B+%5Cbeta+%5Csum_%7Bk+%5Cneq+l%7DY_%7Bk%2C+l%7DQ_%7Bk%2C+l%7D+%2B+2%5Cbeta%5Csum_kZ_k+Q_k%29+dZ+%5C%5C+%3DC%5Cexp%28%5Cbeta%5En%29+%5Cint_%7BY_%7Bk%2C+l%7D%7Dexp%28-%5Cfrac%7Bn%7D%7B4%7D%5Csum_%7Bk+%5Cneq+l%7DY_%7Bk%2C+l%7D%5E2+-+%5Cfrac%7Bn%7D%7B2%7D%5Csum_k+Z_k%5E2+%2B+%5Cln%28%5Csum_%7Bx_1%2C%5Ccdots%2C+x_r%7Dexp%28%5Cbeta+%5Csum_%7Bk%5Cneq+l%7DY_%7Bk%2C+l%7DQ_%7Bk%2C+l%7D+%2B+2%5Cbeta%5Csum_kY_k+Q_k%29%29+dY+%5Clabel%7Be%3A2%7D%5Cend%7Bgathered%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{gathered} {{\mathbb{E}}}[Z^r] = \sum_{x^1, \cdots, x^r} exp(\frac{\beta^2}{n}\sum_{k, l}Q_{k, l}^2 + \frac{\beta^2}{2n}\sum_k Q_k^2) \label{e:2}\\ = C\sum_{x^1, \cdots, x^r} \exp(\beta^2 n)\int_{Z_{k, l}}exp(-\frac{n}{4}\sum_{k \neq l}Z_{k, l}^2 - \frac{n}{2}\sum_k Z_k^2 + \beta \sum_{k \neq l}Y_{k, l}Q_{k, l} + 2\beta\sum_kZ_k Q_k) dZ \\ =C\exp(\beta^n) \int_{Y_{k, l}}exp(-\frac{n}{4}\sum_{k \neq l}Y_{k, l}^2 - \frac{n}{2}\sum_k Z_k^2 + \ln(\sum_{x_1,\cdots, x_r}exp(\beta \sum_{k\neq l}Y_{k, l}Q_{k, l} + 2\beta\sum_kY_k Q_k)) dY \label{e:2}\end{gathered}"/></p>
<p>where <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/> is the constant given by introducing gaussian intergals.</p>
<p>To compute the integral in (Equation 2), we need to cheat a little bit and take<br/>
<img alt="n \to \infty" class="latex" src="https://s0.wp.com/latex.php?latex=n+%5Cto+%5Cinfty&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n \to \infty"/> before letting <img alt="r \to 0" class="latex" src="https://s0.wp.com/latex.php?latex=r+%5Cto+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="r \to 0"/>. Note that free energy density<br/>
is defined as<br/>
<img alt="f(\beta) = \lim_{n \to \infty}\lim_{r \to 0}\frac{1}{r\beta n}\ln {{\mathbb{E}}}_Y[Z(\beta, Y)^r]" class="latex" src="https://s0.wp.com/latex.php?latex=f%28%5Cbeta%29+%3D+%5Clim_%7Bn+%5Cto+%5Cinfty%7D%5Clim_%7Br+%5Cto+0%7D%5Cfrac%7B1%7D%7Br%5Cbeta+n%7D%5Cln+%7B%7B%5Cmathbb%7BE%7D%7D%7D_Y%5BZ%28%5Cbeta%2C+Y%29%5Er%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f(\beta) = \lim_{n \to \infty}\lim_{r \to 0}\frac{1}{r\beta n}\ln {{\mathbb{E}}}_Y[Z(\beta, Y)^r]"/><br/>
This is the second assumption made in the replica method and it is<br/>
commonly believed that switching the order is okay here. Physically,<br/>
this is plausible because we believe intrinsic physical quantities<br/>
should not depend on the system size.</p>
<p>Now the <a href="https://en.wikipedia.org/wiki/Laplace%27s_method">Laplace method</a> tells us when <img alt="n \to \infty" class="latex" src="https://s0.wp.com/latex.php?latex=n+%5Cto+%5Cinfty&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n \to \infty"/>, the integral in (Equation 2) is dominated by the max of the exponent.</p>
<p><strong>Theorem 1 (Laplace Method).</strong> <em>Let <img alt="h(x): {{\mathbb{R}}}^n \to {{\mathbb{R}}}" class="latex" src="https://s0.wp.com/latex.php?latex=h%28x%29%3A+%7B%7B%5Cmathbb%7BR%7D%7D%7D%5En+%5Cto+%7B%7B%5Cmathbb%7BR%7D%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h(x): {{\mathbb{R}}}^n \to {{\mathbb{R}}}"/>, </em><em>then </em></p>
<p><em><img alt="\int e^{nh(x)} \approx e^{nh(x^*)}(\frac{2\pi}{n})^{\frac{d}{2}}\frac{1}{\sqrt{det(H)}}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cint+e%5E%7Bnh%28x%29%7D+%5Capprox+e%5E%7Bnh%28x%5E%2A%29%7D%28%5Cfrac%7B2%5Cpi%7D%7Bn%7D%29%5E%7B%5Cfrac%7Bd%7D%7B2%7D%7D%5Cfrac%7B1%7D%7B%5Csqrt%7Bdet%28H%29%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\int e^{nh(x)} \approx e^{nh(x^*)}(\frac{2\pi}{n})^{\frac{d}{2}}\frac{1}{\sqrt{det(H)}}"/></em></p>
<p><em>where <img alt="x^* = argmax_x \{h(x)\}" class="latex" src="https://s0.wp.com/latex.php?latex=x%5E%2A+%3D+argmax_x+%5C%7Bh%28x%29%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x^* = argmax_x \{h(x)\}"/> and <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> is the Hessian of <img alt="h" class="latex" src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h"/> evaluated at the point <img alt="x^*" class="latex" src="https://s0.wp.com/latex.php?latex=x%5E%2A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x^*"/>.</em></p>
<p>Fix a pair of <img alt="k, l" class="latex" src="https://s0.wp.com/latex.php?latex=k%2C+l&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k, l"/> and apply Laplace method with<br/>
<img alt="h(Z_{k, l}) = -\frac{1}{2}\sum_{0 \leq k &lt; l \leq r}Z_{k, l}^2 + \frac{1}{n}\ln(\sum_{x_1,\cdots, x_r}exp(\beta \sum_{k \neq l}Z_{k, l}Q_{k, l} + 2\beta\sum_kZ_k Q_k))" class="latex" src="https://s0.wp.com/latex.php?latex=h%28Z_%7Bk%2C+l%7D%29+%3D+-%5Cfrac%7B1%7D%7B2%7D%5Csum_%7B0+%5Cleq+k+%3C+l+%5Cleq+r%7DZ_%7Bk%2C+l%7D%5E2+%2B+%5Cfrac%7B1%7D%7Bn%7D%5Cln%28%5Csum_%7Bx_1%2C%5Ccdots%2C+x_r%7Dexp%28%5Cbeta+%5Csum_%7Bk+%5Cneq+l%7DZ_%7Bk%2C+l%7DQ_%7Bk%2C+l%7D+%2B+2%5Cbeta%5Csum_kZ_k+Q_k%29%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h(Z_{k, l}) = -\frac{1}{2}\sum_{0 \leq k &lt; l \leq r}Z_{k, l}^2 + \frac{1}{n}\ln(\sum_{x_1,\cdots, x_r}exp(\beta \sum_{k \neq l}Z_{k, l}Q_{k, l} + 2\beta\sum_kZ_k Q_k))"/><br/>
what’s left to do is to find the critical point of <img alt="h" class="latex" src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h"/>. Taking the<br/>
derivatives gives<br/>
<img alt="-Y_{k, l} + \frac{A(Z_{k, l})\beta Q_{k, l}}{n A(Z_{k, l})} = 0" class="latex" src="https://s0.wp.com/latex.php?latex=-Y_%7Bk%2C+l%7D+%2B+%5Cfrac%7BA%28Z_%7Bk%2C+l%7D%29%5Cbeta+Q_%7Bk%2C+l%7D%7D%7Bn+A%28Z_%7Bk%2C+l%7D%29%7D+%3D+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="-Y_{k, l} + \frac{A(Z_{k, l})\beta Q_{k, l}}{n A(Z_{k, l})} = 0"/><br/>
where<br/>
<img alt="A(Z_{k, l}) = \sum_{x_1,\cdots, x_r}exp(\beta \sum_{k \neq l}Z_{k, l}Q_{k, l} + \beta\sum_kY_k Q_k)" class="latex" src="https://s0.wp.com/latex.php?latex=A%28Z_%7Bk%2C+l%7D%29+%3D+%5Csum_%7Bx_1%2C%5Ccdots%2C+x_r%7Dexp%28%5Cbeta+%5Csum_%7Bk+%5Cneq+l%7DZ_%7Bk%2C+l%7DQ_%7Bk%2C+l%7D+%2B+%5Cbeta%5Csum_kY_k+Q_k%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A(Z_{k, l}) = \sum_{x_1,\cdots, x_r}exp(\beta \sum_{k \neq l}Z_{k, l}Q_{k, l} + \beta\sum_kY_k Q_k)"/>.</p>
<p>We now need to find a saddle point of <img alt="h" class="latex" src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h"/> where the hessian is PSD. To<br/>
do that, we choose to assume the order of the replicas does not matter,<br/>
which is refer to as the replica symmetry case. <sup id="fnref-7420-1"><a class="jetpack-footnote" href="https://windowsontheory.org/feed/#fn-7420-1">1</a></sup> One simplest form<br/>
of <img alt="Y" class="latex" src="https://s0.wp.com/latex.php?latex=Y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y"/> is the following: <img alt="\forall k, l &gt; 0" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cforall+k%2C+l+%3E+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\forall k, l &gt; 0"/>, <img alt="Z_{k, l} = y" class="latex" src="https://s0.wp.com/latex.php?latex=Z_%7Bk%2C+l%7D+%3D+y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Z_{k, l} = y"/> and<br/>
<img alt="Z_{k} = y" class="latex" src="https://s0.wp.com/latex.php?latex=Z_%7Bk%7D+%3D+y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Z_{k} = y"/> for some <img alt="y" class="latex" src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y"/>. This also implies that <img alt="Q_{k, l} = q" class="latex" src="https://s0.wp.com/latex.php?latex=Q_%7Bk%2C+l%7D+%3D+q&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Q_{k, l} = q"/> for some<br/>
<img alt="q" class="latex" src="https://s0.wp.com/latex.php?latex=q&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="q"/> and <img alt="y =\frac{\beta}{n} q" class="latex" src="https://s0.wp.com/latex.php?latex=y+%3D%5Cfrac%7B%5Cbeta%7D%7Bn%7D+q&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y =\frac{\beta}{n} q"/></p>
<p>Plug this back in to Equation 2 gives: (Equation 3)</p>
<p><img alt="\label{e:3} {{\mathbb{E}}}[Z^r] = C\exp(\beta n)\exp(-\frac{n}{2}(\frac{r^2 - r}{2})y^2 - \frac{n^2}{2} + \ln(\sum_{x^i}\exp(y\beta\sum_{k \neq l}Q_{k, l} + 2y\beta \sum_k Q_k))" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clabel%7Be%3A3%7D+%7B%7B%5Cmathbb%7BE%7D%7D%7D%5BZ%5Er%5D+%3D+C%5Cexp%28%5Cbeta+n%29%5Cexp%28-%5Cfrac%7Bn%7D%7B2%7D%28%5Cfrac%7Br%5E2+-+r%7D%7B2%7D%29y%5E2+-+%5Cfrac%7Bn%5E2%7D%7B2%7D+%2B+%5Cln%28%5Csum_%7Bx%5Ei%7D%5Cexp%28y%5Cbeta%5Csum_%7Bk+%5Cneq+l%7DQ_%7Bk%2C+l%7D+%2B+2y%5Cbeta+%5Csum_k+Q_k%29%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\label{e:3} {{\mathbb{E}}}[Z^r] = C\exp(\beta n)\exp(-\frac{n}{2}(\frac{r^2 - r}{2})y^2 - \frac{n^2}{2} + \ln(\sum_{x^i}\exp(y\beta\sum_{k \neq l}Q_{k, l} + 2y\beta \sum_k Q_k))"/></p>
<p>To obtain <img alt="f(r, \beta)" class="latex" src="https://s0.wp.com/latex.php?latex=f%28r%2C+%5Cbeta%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f(r, \beta)"/>, we only need to deal with the last term in<br/>
(Equation 3) as <img alt="r \to 0" class="latex" src="https://s0.wp.com/latex.php?latex=r+%5Cto+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="r \to 0"/>. Using the fact that <img alt="Q_{k, l} = y" class="latex" src="https://s0.wp.com/latex.php?latex=Q_%7Bk%2C+l%7D+%3D+y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Q_{k, l} = y"/> for all<br/>
<img alt="k, l" class="latex" src="https://s0.wp.com/latex.php?latex=k%2C+l&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k, l"/> and using the same trick of introducing new gaussain integral as<br/>
in (Equation 4) we have<br/>
<img alt="\lim_{r \to 0}\frac{1}{r}\ln(\sum_{x^i}\exp(y\beta\sum_{k \neq l}Q_{k, l} + n\beta \sum_k Q_k)) = -\beta + {{\mathbb{E}}}_{z \sim \mathcal{N}(0, 1)}[\log(2cosh(y\beta + \sqrt{y\beta}z))]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clim_%7Br+%5Cto+0%7D%5Cfrac%7B1%7D%7Br%7D%5Cln%28%5Csum_%7Bx%5Ei%7D%5Cexp%28y%5Cbeta%5Csum_%7Bk+%5Cneq+l%7DQ_%7Bk%2C+l%7D+%2B+n%5Cbeta+%5Csum_k+Q_k%29%29+%3D+-%5Cbeta+%2B+%7B%7B%5Cmathbb%7BE%7D%7D%7D_%7Bz+%5Csim+%5Cmathcal%7BN%7D%280%2C+1%29%7D%5B%5Clog%282cosh%28y%5Cbeta+%2B+%5Csqrt%7By%5Cbeta%7Dz%29%29%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lim_{r \to 0}\frac{1}{r}\ln(\sum_{x^i}\exp(y\beta\sum_{k \neq l}Q_{k, l} + n\beta \sum_k Q_k)) = -\beta + {{\mathbb{E}}}_{z \sim \mathcal{N}(0, 1)}[\log(2cosh(y\beta + \sqrt{y\beta}z))]"/></p>
<p>Using the fact that we want the solution to minimizes free energy,<br/>
taking the derivative of the current <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> w.r.t. <img alt="y" class="latex" src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y"/> gives<br/>
<img alt="\frac{y}{\beta} = n{{\mathbb{E}}}_z[tanh(y\beta + \sqrt{y\beta}z)]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cfrac%7By%7D%7B%5Cbeta%7D+%3D+n%7B%7B%5Cmathbb%7BE%7D%7D%7D_z%5Btanh%28y%5Cbeta+%2B+%5Csqrt%7By%5Cbeta%7Dz%29%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\frac{y}{\beta} = n{{\mathbb{E}}}_z[tanh(y\beta + \sqrt{y\beta}z)]"/><br/>
which matches the fixed point of AMP. Plug in <img alt="q" class="latex" src="https://s0.wp.com/latex.php?latex=q&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="q"/> and <img alt="y" class="latex" src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y"/> will give us<br/>
<img alt="f(\beta)" class="latex" src="https://s0.wp.com/latex.php?latex=f%28%5Cbeta%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f(\beta)"/>. The curve of <img alt="f(\beta)" class="latex" src="https://s0.wp.com/latex.php?latex=f%28%5Cbeta%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f(\beta)"/> looks like the Figure below, where<br/>
the solid line is the curve of <img alt="f(\beta)" class="latex" src="https://s0.wp.com/latex.php?latex=f%28%5Cbeta%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f(\beta)"/> with the given <img alt="q" class="latex" src="https://s0.wp.com/latex.php?latex=q&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="q"/> and the<br/>
dotted line is the curve given by setting all variables <img alt="0" class="latex" src="https://s0.wp.com/latex.php?latex=0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="0"/>.</p>
<p><img alt="screenshot 2019-01-26 13.54.49" class="alignnone size-full wp-image-7423" src="https://windowsontheory.files.wordpress.com/2019/01/screenshot-2019-01-26-13.54.49.png?w=600"/></p>
<p> </p>
<p><strong>References</strong></p>
<div>[1] Amelia Perry, Alexander S Wein, Afonso S Bandeira, and Ankur Moitra. Optimality and sub-optimality of pca for spiked random matrices and synchronization.</div>
<div>arXiv preprint arXiv:1609.05573, 2016.</div>
<div/>
<div>[2] D. Feral and S. Pech e. The Largest Eigenvalue of Rank One Deformation of Large Wigner Matrices. Communications in Mathematical Physics, 272:185–228, May 2007.</div>
<div/>
<div>[3] Afonso S Bandeira, Amelia Perry, and Alexander S Wein. Notes on computational-to-statistical gaps: predictions using statistical physics. arXiv preprint arXiv:1803.11132, 2018.</div>
<div/>
<div>[4] Yash Deshpande, Emmanuel Abbe, and Andrea Montanari. Asymptotic mutual information for thebinary stochastic block model. In</div>
<div>Information Theory (ISIT), 2016 IEEE International Symposium on, pages 185–189. IEEE, 2016.</div>
<div/>
<div>[5] Adel Javanmard and Andrea Montanari. State evolution for general approximate message passing algorithms, with applications to spatial coupling. Information and Inference: A Journal of the IMA, 2(2):115–144, 2013.</div>
<div/>
<div>[6] A. Perry, A. S. Wein, and A. S. Bandeira. Statistical limits of spiked tensor models.</div>
<div>ArXiv e-prints, December 2016.</div>
<div class="footnotes">
<hr/>
<ol>
<li id="fn-7420-1">
Turns out for this problem, replica symmetry is the only case. We<br/>
will not talk about replica symmetry breaking here, which<br/>
intuitively means we partition replicas into groups and re-curse. <a href="https://windowsontheory.org/feed/#fnref-7420-1">↩</a>
</li>
</ol>
</div></div>
    </content>
    <updated>2019-01-26T19:10:18Z</updated>
    <published>2019-01-26T19:10:18Z</published>
    <category term="physics"/>
    <author>
      <name>preetum</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2019-02-03T09:20:56Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=7413</id>
    <link href="https://windowsontheory.org/2019/01/25/quantum-circuits-and-their-role-in-demonstrating-quantum-supremacy/" rel="alternate" type="text/html"/>
    <title>Quantum circuits and their role in demonstrating quantum supremacy</title>
    <summary>There’s a lot of discussion and (possibly well-deserved) hype nowadays about quantum computation and its potential for computation at speeds we simply can’t reach with the classical computers we’re used to today. The excitement about this has been building for years, even decades, but it’s only very recently that we’ve really been approaching a solid […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>There’s a lot of discussion and (possibly well-deserved) hype nowadays about quantum computation and its potential for computation at speeds we simply can’t reach with the classical computers we’re used to today. The excitement about this has been building for years, even decades, but it’s only very recently that we’ve really been approaching a solid proof that quantum computers do have an <a href="https://en.wikipedia.org/wiki/Quantum_supremacy">advantage</a> over classical computers. </p>



<p>What’s rather tricky about showing such a result is that, rather than a direct argument about the capability of quantum computers, what we really need to demonstrate is the incapability of classical computers to achieve tasks that can be done with quantum computers. </p>



<p>One of the major leaps forward in demonstrating quantum supremacy was taken by Terhal and DiVincenzo in their 2008 paper “<a href="https://arxiv.org/abs/quant-ph/0205133">Adaptive quantum computation, constant depth quantum circuits and arthur-merlin games</a>“. Their approach was to appeal to a complexity-theoretic argument: they gave evidence that there exists a certain class of quantum circuits that cannot be simulated classically by proving that if a classical simulation existed, certain complexity classes strongly believed to be distinct would collapse to the same class. While this doesn’t quite provide a proof of quantum supremacy – since the statement about the distinction between complexity classes upon which it hinges is not a proven fact – because the complexity statement appears overwhelmingly likely to be true, so too does the proposed existence of non-classically-simulatable quantum circuits. The Terhal and DiVincenzo paper is a complex and highly technical one, but in this post I hope to explain a little bit and give some intuition for the major points. </p>



<p>Now, let’s start at the beginning. What is a <a href="https://en.wikipedia.org/wiki/Quantum_circuit">quantum circuit</a>? I’m going to go ahead and assume you already know what a <a href="https://en.wikipedia.org/wiki/Circuit_(computer_science)">classical circuit</a> is – the extension to a quantum circuit is rather straightforward: it’s a circuit in which all gates are <a href="https://en.wikipedia.org/wiki/Quantum_logic_gate">quantum gates</a>, where a quantum gate can be thought of as a classical gate whose output is, rather than a deterministic function of the inputs, instead a probability distribution over all possible outputs given the size of the inputs. For example, given two single-bit inputs, a classical AND gate outputs 0 or 1 deterministically given the inputs. A quantum AND gate on the analogous single-<a href="https://en.wikipedia.org/wiki/Qubit">qubit</a> inputs would output 0 with some probability <img alt="p" class="latex" src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p"/> and 1 with some probability <img alt="1-p" class="latex" src="https://s0.wp.com/latex.php?latex=1-p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1-p"/>. Similarly, a classical AND gate on two 4-bit inputs outputs the bitwise AND, while the quantum analog has associated with it a 4-qubit output: some probability distribution over all 4-bit binary strings. A priori there is no particular string that is the “output” of the computation by the quantum gate; it’s only after taking a <a href="https://en.wikipedia.org/wiki/Measurement_in_quantum_mechanics">quantum measurement</a> of the output that we get an actual string that we can think of as the outcome of the computation done by the gate. The actual string we “observe” upon taking the measurement follows the probability distribution computed by the gate on its inputs. In this way, a quantum circuit can then be thought of as producing, via a sequence of probabilistic classical gates (i.e., quantum gates) some probability distribution over possible outputs given the input lengths. It’s not hard to see that in this way, we can compose circuits: suppose we have a quantum circuit <img alt="c_1" class="latex" src="https://s0.wp.com/latex.php?latex=c_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c_1"/> and another quantum circuit <img alt="c_2" class="latex" src="https://s0.wp.com/latex.php?latex=c_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c_2"/>. Let <img alt="c_1" class="latex" src="https://s0.wp.com/latex.php?latex=c_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c_1"/> have an input of <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> qubits and an output of <img alt="m" class="latex" src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m"/> qubits; suppose we measure <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/> of the output qubits of <img alt="c_1" class="latex" src="https://s0.wp.com/latex.php?latex=c_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c_1"/> – then we can feed the remaining <img alt="m-k" class="latex" src="https://s0.wp.com/latex.php?latex=m-k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m-k"/> unmeasured qubits as inputs into <img alt="c_2" class="latex" src="https://s0.wp.com/latex.php?latex=c_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c_2"/>(assuming that those <img alt="m-k" class="latex" src="https://s0.wp.com/latex.php?latex=m-k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m-k"/> qubits do indeed constitute a valid input to <img alt="c_2" class="latex" src="https://s0.wp.com/latex.php?latex=c_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c_2"/>). </p>



<p>Consider, then, the following sort of quantum circuit: it’s a composition of <img alt="N" class="latex" src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N"/> quantum circuits, such that after each <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/>-th circuit we take a measurement some of its output qubits (so that the remaining unmeasured qubits become inputs to the <img alt="(i+1)" class="latex" src="https://s0.wp.com/latex.php?latex=%28i%2B1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(i+1)"/>-th circuit), and then the structure of the <img alt="(i+1)" class="latex" src="https://s0.wp.com/latex.php?latex=%28i%2B1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(i+1)"/>-th circuit is dependent on this measurement. That is, it’s as though, given a quantum circuit, we’re checking every so often at intermediate layers over the course of the circuit’s computation what the value of some of the variables are (leaving the rest to keep going along through the circuit to undergo more computational processing), and based on what we measure is the current computed value, the remainder of the circuit “adapts” in a way determined by that measurement. Aptly enough, this is called an “adaptive circuit”. But since the “downstream” structure of the circuit depends on the outcomes of all the measurements made “upstream”, each adaptive circuit actually comprises a family of circuits, each of which is specified by the sequence of intermediate measurement outcomes. That is, we can alternatively characterize an adaptive circuit as a set of ordinary quantum circuits that is parameterized by a list of measurement outcomes. Terhal and DiVincenzo call this way of viewing an adaptive circuit, as a family of circuits parametrized by a sequence of measurement values, a “non-adaptive circuit” – since we replace the idea that the circuit “adapts” to intermediate measurements with the idea that there are just many regular circuits, one for each possible sequence of measurements. It’s this non-adaptive circuit concept that’ll be our main object of study going forward.</p>



<h2>Simulating quantum circuits</h2>



<p>Now, the result we wanted to demonstrate about quantum circuits had to do with their efficient simulatability by classical circuits – and so we should establish some notion of what we mean when we talk about an “efficient simulation”. </p>



<p>Terhal and DiVincenzo offer the following notion of a classical simulation – which in their paper they call an “efficient density computation”: consider a quantum circuit with some output of length <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> qubits. Recall that to actually obtain an output value, we need to take a measurement of the circuit output – imagine doing this in disjoint subsets of cubits at a time. That is, we can break up the <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> qubits into <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/> disjoint subsets and consider the entire output measurement as a process of taking <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/> measurements, subset by subset. An efficient density computation exists if there’s a classical procedure for computing, in time polynomial in the width and depth of the quantum circuit, the conditional probability distribution over the set of possible measurement outcomes of a particular subset of qubits, given any subset of the <img alt="k-1" class="latex" src="https://s0.wp.com/latex.php?latex=k-1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k-1"/> other measurement outcomes. Intuitively, this is a good notion of what a classical simulation should consist of, or at least what data it should contain, since if you know the conditional probabilities given any (possibly empty) subset of the other measurements, you can just flip coins for the outputs according to the conditional probabilities as a way of actually exhibiting a “working” simulation.</p>



<p>It’s with this notion of simulation, along with our concept of an adaptive quantum circuit as a family of regular circuits parameterized by a sequence of intermediate measurement outcomes, we may now arrive at the main result of Terhal and DiVincenzo’s paper. Recall that what we wanted to show from the very beginning is that there exists some quantum circuit that can’t be simulated classically. The argument for this proceeds like a proof by contradiction: suppose the contrary, and that all quantum circuits can be simulated classically. We want to show that we can find, then, a quantum circuit which, if it were possible to be simulated classically (as per our assumption), we’d wind up with some strange consequences that we believe are false, leading us to conclude that those circuits probably can’t be simulated classically.</p>



<p>Thus, we shall now exhibit such a quantum circuit whose classical simulatability leads (as far as we believe) to a contradiction. Consider a special case of adaptive quantum circuits, considered as a parameterized family of regular circuits, in which the circuit’s output distribution is independent of the intermediate measurement outcomes; that is, the case in which the entire family of circuits corresponding to an adaptive circuit is logically the same – that is, is the same logical circuit on input qubits independent of intermediate measurements. I’d like to point out, just for clarification’s sake, the subtlety here, which makes this consideration non-redundant, and not simply a reduction of an adaptive quantum circuit (again, thought of as a family) to a single fixed circuit (i.e., a family of one): the situation in which the family is reduced to a single fixed circuit occurs when the<em> structure of the circuit</em> is independent of the intermediate measurement outcomes. If the structure were independent of the measurements, then no matter what we observed in the measurements, we’d get the same circuit – hence a trivial family of one. What we’re considering instead is the case in which the <em>structure</em> of the circuit is still dependent on the intermediate measurements (and so the circuit is still adaptive), but where the <em>distribution over the possible outputs of the circuit</em> is identical no matter what the intermediate measurements are. In this case, the circuit can still be considered as a parameterized and in general non-trivial family of circuits, but for which each member produces the same distribution over outputs – hence, a family of potentially <em>structurally</em> different circuits, but which are <em>logically</em> identical.</p>



<p>Suppose there’s some set of such circuits that’s universal – that is, that’s sufficient to implement all polynomial-time quantum computations. (This is a reasonable assumption to make, since there do in fact exist <a href="https://en.wikipedia.org/wiki/Quantum_logic_gate\#Universal_quantum_gates">universal quantum gate sets.</a> But now if a simulation of the kind we defined (an efficient density computation) existed for every circuit in this set, then we could calculate the outcome probability of any polynomial-depth quantum circuit, since any polynomial-depth quantum circuit could be realized as some composition of circuits in this universal set (and in particular as a composition of particular family members of each adaptive circuit in the universal set), and an efficient density computation, as we mentioned above, precisely gives us a way to compute the output distribution. </p>



<p>But now here is where our believed contradiction lies: </p>



<p><em>Theorem:</em> Suppose there exists a universal set of adaptive quantum circuits whose output distributions are independent of intermediate measurements. If there is an efficient density computation for each family member of each adaptive circuit in this universal set, then for the polynomial hierarchy PH we have PH = BPP = BQP. </p>



<p>The proof goes something like this: if we can do our desired efficient density computations (as we assumed, for the sake of contradiction, we could for all quantum circuits), this is equivalent to being able to determine the acceptance probability of a quantum computation, which was shown in the paper “<a href="https://arxiv.org/abs/quant-ph/9812056">Determining Acceptance Possibility for a Quantum Computation is Hard for the Polynomial Hierarchy”</a> by Fenner, Green, Homer and Pruim to be equivalent to the class <img alt="\text{coC=P}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctext%7BcoC%3DP%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\text{coC=P}"/>. Thus, we have that <img alt="\text{coC=P} \subseteq \text{BPP}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctext%7BcoC%3DP%7D+%5Csubseteq+%5Ctext%7BBPP%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\text{coC=P} \subseteq \text{BPP}"/>. But it’s known that <img alt="\text{PH} \subseteq \text{BPP}^{\text{coC=P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctext%7BPH%7D+%5Csubseteq+%5Ctext%7BBPP%7D%5E%7B%5Ctext%7BcoC%3DP%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\text{PH} \subseteq \text{BPP}^{\text{coC=P}}"/> and so <img alt="\text{PH} \subseteq \text{BPP}^{\text{BPP}} = \text{BPP}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctext%7BPH%7D+%5Csubseteq+%5Ctext%7BBPP%7D%5E%7B%5Ctext%7BBPP%7D%7D+%3D+%5Ctext%7BBPP%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\text{PH} \subseteq \text{BPP}^{\text{BPP}} = \text{BPP}"/>. That is, we have <img alt="\text{PH} = \text{BPP} = \text{BQP}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctext%7BPH%7D+%3D+%5Ctext%7BBPP%7D+%3D+%5Ctext%7BBQP%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\text{PH} = \text{BPP} = \text{BQP}"/>, and so the polynomial hierarchy would collapse to <img alt="\Sigma^P_2" class="latex" src="https://s0.wp.com/latex.php?latex=%5CSigma%5EP_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Sigma^P_2"/> since <img alt="\text{BPP} \subseteq \Sigma^P_2" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctext%7BBPP%7D+%5Csubseteq+%5CSigma%5EP_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\text{BPP} \subseteq \Sigma^P_2"/> (for more on these more obscure complexity classes, see <a href="https://complexityzoo.uwaterloo.ca/Complexity_Zoo">here</a>). Again, this is our “contradiction”: while it hasn’t been quite proven, it is widely believed, with strong supporting evidence, that the polynomial hierarchy does not collapse as would be the case if all quantum circuits were classically simulatable. Thus this provides a strong argument that not all quantum circuits are classically simulatable, which was precisely what we were looking to demonstrate.</p>



<h2>Conclusion</h2>



<p>Terhal and DiVincenzo actually go even further and show that there is a certain class of constant-depth quantum circuits that are unlikely to be simulatable by classical circuits – this, indeed, seems to provide even stronger evidence for quantum supremacy. This argument, which is somewhat more complex, uses the idea of teleportation and focuses on a particular class of circuits implementable by a certain restricted set of quantum gates. If you’re interested, I highly recommend reading their paper, where this is explained. </p>



<h2>Recommended reading</h2>



<ul><li>Terhal, Barbara and David DiVincenzo.  “Adptive quantum computation, constant depth quantum circuits and arthur-merlin games.” <em>Quantum Info. Comput.</em> 4, 2 (2004); 134-145.</li><li>Bravyil, Sergey, David Gosset, and Robert König. “Quantum advantage with shallow circuits.” <em>Science</em> 362, 6412 (2018); 308-311.</li><li>Harrow, Aram Wettroth and Ashley Montanaro. “Quantum computational supremacy.” <em>Nature</em> 549 (2017): 203-209.</li><li>Boixo, Sergio et. al. “Characterizing quantum supremacy in near-term devices.” <em>Nature Physics</em> 14 (2018); 595-600.</li></ul>



<h2>References</h2>



<p>\begin{enumerate}</p>



<ul><li>Terhal, Barbara and David DiVincenzo.  “Adptive quantum computation, constant depth quantum circuits and arthur-merlin games.” <em>Quantum Info. Comput.</em> 4, 2 (2004); 134-145.</li><li>Fenner, Stephen et. al. “Determining Acceptance Possibility for a Quantum Computation is Hard for the Polynomial Hierarchy.” <a href="https://arxiv.org/abs/quant-ph/9812056" rel="nofollow">https://arxiv.org/abs/quant-ph/9812056</a>. (1998).</li><li>Bravyil, Sergey, David Gosset, and Robert König. “Quantum advantage with shallow circuits.” <em>Science</em> 362, 6412 (2018); 308-311.</li></ul></div>
    </content>
    <updated>2019-01-25T23:42:09Z</updated>
    <published>2019-01-25T23:42:09Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>hksorens</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2019-02-03T09:20:56Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/01/25/postdoc-at-uc-san-diego-apply-by-march-1-2019/</id>
    <link href="https://cstheory-jobs.org/2019/01/25/postdoc-at-uc-san-diego-apply-by-march-1-2019/" rel="alternate" type="text/html"/>
    <title>postdoc at UC San Diego (apply by March 1, 2019)</title>
    <summary>We are looking for strong theory candidates working in the areas of machine learning, optimization, high dimensional statistics, privacy, fairness, and broadly interpreted data science. The postdoc is part of the Data Science fellows program at UCSD. Website: http://dsfellows.ucsd.edu/ Email: shachar.lovett@gmail.com</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>We are looking for strong theory candidates working in the areas of machine learning, optimization, high dimensional statistics, privacy, fairness, and broadly interpreted data science. The postdoc is part of the Data Science fellows program at UCSD.</p>
<p>Website: <a href="http://dsfellows.ucsd.edu/">http://dsfellows.ucsd.edu/</a><br/>
Email: shachar.lovett@gmail.com</p></div>
    </content>
    <updated>2019-01-25T19:46:17Z</updated>
    <published>2019-01-25T19:46:17Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-02-03T09:20:38Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=7411</id>
    <link href="https://windowsontheory.org/2019/01/25/looking-a-postdoc-opportunity/" rel="alternate" type="text/html"/>
    <title>Looking a postdoc opportunity?</title>
    <summary>This is the season that people are applying for postdoc positions. Unlike student and faculty hiring, which each have a fairly fixed schedule, postdoc availability can change from time to time, with new opportunities opening up all the time. So, I encourage everyone looking for a postdoc position to periodically check out https://cstheory-jobs.org/ . (For […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>This is the season that people are applying for postdoc positions. Unlike student and faculty hiring, which each have a fairly fixed schedule, postdoc availability can change from time to time, with new opportunities opening up all the time. So, I encourage everyone looking for a postdoc position to periodically check out <a href="https://cstheory-jobs.org/">https://cstheory-jobs.org/</a> . </p>



<p>(For example, a new ad was just posted on Wednesday by <a href="https://cstheory-jobs.org/2019/01/23/postdoctoral-fellow-at-carnegie-mellon-university-apply-by-february-28-2019/">Venkat Guruswami and Pravesh Kothari </a> )</p></div>
    </content>
    <updated>2019-01-25T17:51:37Z</updated>
    <published>2019-01-25T17:51:37Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>windowsontheory</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2019-02-03T09:20:56Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-7382539649899855346</id>
    <link href="https://blog.computationalcomplexity.org/feeds/7382539649899855346/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/01/the-paradigm-shift-in-fintech.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7382539649899855346" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7382539649899855346" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/01/the-paradigm-shift-in-fintech.html" rel="alternate" type="text/html"/>
    <title>The Paradigm Shift in FinTech Computation and the need for a Computational Toolkit (Guest Post by Evangelos Georgiadis)</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">The Paradigm Shift in FinTech Computation and the need for a Computational Toolkit<br/>
<br/>
(Guest Post by <a href="http://www.mathcognify.com/">Evangelos Georgiadis</a>)<br/>
<br/>
We are experiencing a paradigm shift in finance as we are entering the era of algorithmic FinTech computation. (**And another yet to come. See **Future** below.)  This era is marked by a shift in the role played by the theoretical computer scientist. In the not so distant past, the (financial) economist had the ultimate stamp of approval  for how to study financial models, pricing models, mechanism design, etc. The economist was the ultimate gatekeeper of ideas and models, whereas the main role of the computer scientist was to turn these ideas or models into working code; in a sense, an obedient beaver/engineer. (In finance, the theoretical computer scientist more often than not wears the hat of the quant.)<br/>
<br/>
In today's era, the role of the theoretical computer scientist has been elevated from the obedient engineer to the creative architect not only of models and mechanism designs but also of entire ecosystems. One example is blockchain based ecosystems. In the light of this promotion from obedient engineer to architect, we might need to re-hash the notion of 'sharing blame', as originally and elegantly voiced in <a href="https://www.technologyreview.com/s/408851/on-quants/">On Quants</a> by Professor Daniel W. Stroock, when things go wrong.)<br/>
<br/>
The role change is also coupled by a shift in emphasis of computation that in turn necessitates a deeper understanding of (what this author would refer to as) distributed yet pragmatic complexity based crypto systems' that attempt to redefine 'trust' in terms of distributed computation.<br/>
<br/>
This change necessitates an ability to think in terms of approximation (and lower/upper bounds)  or other good-enough solutions that work on all inputs,  rather than merely easy instances of  problem types that usually lead to clean, exact formulas or solutions.  Additionally, looking through the lens of approximation algorithms enables a different and often more insightful metric for dealing with intrinsically hard problems (for which often no exact or clean solutions exist.) Computer Scientists are trained in this way; however, financial economists are not.   Might the economists actually get in the way?<br/>
<br/>
Our tentative response: The economists are valuable and the solution to the dilemma is to equip them with the right 'computational toolkit'. Ideally, such a toolkit comprises computational tools and algorithms that enable automation of certain computational tasks which otherwise would necessitate more granular understanding at the level of a theoretical computer scientist (or mathematician)<br/>
OR be too cumbersome to perform by hand even for the expert.<br/>
<br/>
Essentially, a toolkit even for the theoretical computer scientist that frees her from clerical work and enables computation to scale from clean cases, such as n=1, to pathological (yet far more realistic) cases, such as n=100000, all the way to the advanced and rather important (agnostic case or) symbolic case when n=k -- without much pain or agony.<br/>
<br/>
The existence of such a toolkit would in turn do justice to the definition of FinTech Computation, which entails applying advanced computational techniques not necessarily information techniques) to financial computation. in fact, this author is part of building such an infrastructure solution which<br/>
necessitates the underlying programming language [R-E-CAS-T] to have intrinsic hybrid capabilities -- symbolic as well as numeric.<br/>
<br/>
One step towards this  "automation" conquest is shown in <a href="https://arxiv.org/pdf/1808.05255v2.pdf">A combinatorial-probabilistic analysis of bitcoin attacks</a> with Doron Zeilberger.  The work illustrates an algorithmic risk analysis of the bitcoin protocol via symbolic computation, as opposed to the meticulous, yet more laborious by hand conquest shown by the European duo in <a href="https://arxiv.org/abs/1702.02867">Double spend races</a> Heavy usage of the "Wilf-Zeilberger algorithmic proof theory" one of the cornerstones in applied symbolic computation, enabled automated recurrence discovery and algorithmic derivation of higher-order asymptotics. For example, in terms of asymptotics tools: the ability to internalize a very dense body of mathematics, such as the G.D. Birkhoff and W.J. Trjitzinsky method, symbolically, automates the process of computing asymptotics of solutions of recurrence equations; a swiss army knife for any user.<br/>
<br/>
&lt;**Future**&gt;<br/>
<br/>
What does the future entail for FinTech Computation ?<br/>
<br/>
[My two <a href="https://en.bitcoin.it/wiki/Satoshi_(unit)">satoshis</a> on this]<br/>
<br/>
Where are we headed in terms of type of computation ?<br/>
<br/>
Blockchain based systems, even though some of us (including this author) have noticed fundamental flaws, seem to still have momentum, at least, judging from recent news articles about companies becoming blockchain technology friendly.  Ranging from (of course) exchanges such as our friends at <a href="https://www.binance.com/en">Binance</a> and <a href="https://www.bitmex.com/">BitMEX</a>, we have major smartphone makers such as <a href="https://www.bloomberg.com/news/articles/2018-04-15/samsung-jumps-on-blockchain-bandwagon-to-manage-its-supply-chain">Samsung</a>, <a href="https://www.bloomberg.com/news/articles/2018-03-21/huawei-said-to-be-in-talks-to-build-blockchain-ready-smartphone">Huawei</a>, and <a href="https://www.cnbc.com/2018/10/23/htc-launches-blockchain-phone-exodus-1-to-be-sold-in-cryptocurrency.html">HTC</a>. The favorable sentiment towards blockchain technology is shared even amongst top tier U.S. banks.<br/>
 Can one deduce success or failure momentum from the citation count distribution of the paper that laid grounds to this technology ? <a href="https://bitcoin.org/bitcoin.pdf">Bitcoin: A Peer-to-Peer Electronic Cash System</a>)<br/>
<br/>
If we look at crypto(currencies), one of many challenges for these blockchain based systems is the high maintenance cost.  Certainly in terms of energy consumption when it comes to the process of mining -- whether Proof-of-Work (PoW) is replaced by Proof-of-Stake (PoS) or some other more energy efficient consensus variant. (This author is aware of various types of optimizations that have been used.)<br/>
A few questions that have bugged this author every since ...<br/>
<br/>
a) Is there a natural way to formalize the notion of energy consumption for consensus mechanisms?<br/>
<br/>
b) What about formalizing an energy-efficient mechanism design ?)<br/>
<br/>
(The idea of savings when PoW is replaced by PoS as intended by our friends at the <a href="https://spectrum.ieee.org/computing/networks/ethereum-plans-to-cut-its-absurd-energy-consumption-by-99-percent">Ethereum Foundation</a> has been around for some time but the point of this author is, the value of 0.99*X (where X is a <a href="https://link.springer.com/chapter/10.1007/978-1-4684-6686-7_28">supernatural number</a>  [a la Don E. Knuth style]), is still a big quantity; too big for an environmentalist ?)<br/>
<br/>
So, what comes next ?<br/>
<br/>
[... the satoshis are still on the table.]<br/>
<br/>
Daniel Kane has brought to my attention that quantum computation -- the seemingly next paradigm shift in which again the role of TCS seem  inextricably interwoven --  may lead to blockchain based systems being replaced by less expensive (at least in terms of energy consumption) quantum based systems. (Crypto might get replaced by Quantum (money). :-)) One such pioneering approach is masterfully articulated by Daniel Kane in "<a href="https://arxiv.org/abs/1809.05925">Quantum Money from Modular Forms</a>.</div>
    </content>
    <updated>2019-01-25T16:44:00Z</updated>
    <published>2019-01-25T16:44:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>https://plus.google.com/101693130490639305932</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-02-02T20:39:23Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/01/24/faculty-at-uc-san-diego-apply-by-february-15-2019/</id>
    <link href="https://cstheory-jobs.org/2019/01/24/faculty-at-uc-san-diego-apply-by-february-15-2019/" rel="alternate" type="text/html"/>
    <title>faculty at UC San Diego (apply by February 15, 2019)</title>
    <summary>Apply to be an Assistant Professor, with a focus on Algorithmic Approaches to Socially Innovative Product Architectures and Business Models. This is a joint search by the Computer Science department and the Rady business school. Website: https://apol-recruit.ucsd.edu/JPF01987 Email: slovett@ucsd.edu</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Apply to be an Assistant Professor, with a focus on Algorithmic Approaches to Socially Innovative Product Architectures and Business Models. This is a joint search by the Computer Science department and the Rady business school.</p>
<p>Website: <a href="https://apol-recruit.ucsd.edu/JPF01987">https://apol-recruit.ucsd.edu/JPF01987</a><br/>
Email: slovett@ucsd.edu</p></div>
    </content>
    <updated>2019-01-24T18:10:56Z</updated>
    <published>2019-01-24T18:10:56Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-02-03T09:20:38Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-7530001663397385709</id>
    <link href="https://blog.computationalcomplexity.org/feeds/7530001663397385709/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/01/machine-learning-and-wind-turbines.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7530001663397385709" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7530001663397385709" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/01/machine-learning-and-wind-turbines.html" rel="alternate" type="text/html"/>
    <title>Machine Learning and Wind Turbines</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div class="separator" style="clear: both; text-align: center;">
<a href="https://3.bp.blogspot.com/-IwXAr_ptgYo/XEYxZWFiAzI/AAAAAAABmPw/6t_lphNZigA3sXSix1MpcmKNANZFiGkawCLcBGAs/s1600/Turbines.png" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="180" src="https://3.bp.blogspot.com/-IwXAr_ptgYo/XEYxZWFiAzI/AAAAAAABmPw/6t_lphNZigA3sXSix1MpcmKNANZFiGkawCLcBGAs/s320/Turbines.png" width="320"/></a></div>
<br/>
My daughter Molly spent six weeks on an environmental program in China last summer. When she got back she had to do a report on machine learning and wind turbines used for clean energy generation. What does machine learning have to do with wind turbines? Plenty it turns out and it tell us a lot about the future of programming.<br/>
<br/>
Sudden changes in wind can cause damage to the blades of the turbine. Maintenance is very expensive especially for turbines in the sea and a broken turbine generates no electricity. To catch these changes ahead of time you can mount a Lidar on top of the turbine.<br/>
<br/>
<div class="separator" style="clear: both; text-align: center;">
<a href="https://4.bp.blogspot.com/-9LFv8FGZNG8/XEYxYFyCYDI/AAAAAAABmPs/TLY7-bfPWhMWjRLl8Jn9ixXrTBa_sAk7ACLcBGAs/s1600/Turbine%2BLidar.jpg" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="180" src="https://4.bp.blogspot.com/-9LFv8FGZNG8/XEYxYFyCYDI/AAAAAAABmPs/TLY7-bfPWhMWjRLl8Jn9ixXrTBa_sAk7ACLcBGAs/s320/Turbine%2BLidar.jpg" width="320"/></a></div>
<br/>
The Lidar can detect wind gusts from about 100 meters ahead, giving about 10 seconds to react. In that time you can rotate the blades, or the whole turbine itself to minimize any damage. Here's a <a href="https://www.youtube.com/watch?v=j5zLp6UuC70">video</a> describing the situation.<br/>
<br/>
<center>

</center>
<br/>
How do you do the computations to convert the Lidar data into accurate representations of wind gusts and then how to best adjust for them? You could imagine some complex fluid dynamics computation, which gets even more complex when you several wind turbines in front of each other. Instead you can use the massive amount of data you have collected by sensors on the turbine and the Lidar information and train a neural network. Training takes a long time but a trained network can quickly determine a good course of action. Now neural networks can always make mistakes but unlike self-driving cars, a mistake won't kill anyone, just possibly cause more damage. Since on average you can save considerable maintenance costs, using ML here is a big win.<br/>
<br/>
I've obviously over simplified the above but I really like this example. This is not an ML solution to a standard AI question like image recognition or playing chess. Rather we are using ML to make a difficult computation tractable mostly by using ML on available data and that changes how we think about programming complex tasks.</div>
    </content>
    <updated>2019-01-24T13:58:00Z</updated>
    <published>2019-01-24T13:58:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>https://plus.google.com/101693130490639305932</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>https://plus.google.com/101693130490639305932</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-02-02T20:39:23Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>http://corner.mimuw.edu.pl/?p=1054</id>
    <link href="http://corner.mimuw.edu.pl/?p=1054" rel="alternate" type="text/html"/>
    <title>Prophet inequality and auction design</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Suppose you want to sell a car and there are 10 agents willing to buy it. You are not sure how much they could pay but for each of them you know a probability distribution of how high the offer … <a href="http://corner.mimuw.edu.pl/?p=1054">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Suppose you want to sell a car and there are 10 agents willing to buy it. You are not sure how much they could pay but for each of them you know a probability distribution of how high the offer will be. For example, a car salon would always pay 10K  but some person might offer 5K or 15K with equal probability. The best you could do is to first negotiate with all of them and then pick the highest bid. Unfortunately, you cannot do so - after seeing each offer you must irrevocably choose either to sell the car or to refuse the offer. What is the best strategy to maximize your revenue in this case?</p>
<p>In turns out that this is a well-studied optimization problem with a simple strategy that guarantees you can (on expectation) earn at least half as much as a hypothetical prophet, who knows all the bids in advance. This result is known as the prophet inequality. What is more surprising, this strategy would work even if you are a car retailer and want to sell five cars. Moreover, you might want to have some constraints, for example you do not want to sell two cars to buyers from the same city, or have multiple kinds of cars with different evaluations, and you can always guarantee an expected revenue comparable to the one of the prophets.</p>
<p>This problem not only exploits beautiful math but also has important applications in internet ad display. Actually, whenever you type a query into a web search engine, the ad system performs this kind of car-selling game with the ad suppliers, who offer different bids for their ad to be displayed to you.</p>
<p>Here is a link to our recent work with new developments in this theory: <a href="http://ieee-focs.org/FOCS-2018-Papers/pdfs/59f790.pdf">http://ieee-focs.org/FOCS-2018-Papers/pdfs/59f790.pdf</a></p>
<p>Michał Włodarczyk</p></div>
    </content>
    <updated>2019-01-24T10:21:58Z</updated>
    <published>2019-01-24T10:21:58Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Renata Czarniecka</name>
    </author>
    <source>
      <id>http://corner.mimuw.edu.pl</id>
      <link href="http://corner.mimuw.edu.pl/?feed=rss2" rel="self" type="application/atom+xml"/>
      <link href="http://corner.mimuw.edu.pl" rel="alternate" type="text/html"/>
      <subtitle>University of Warsaw</subtitle>
      <title>Banach's Algorithmic Corner</title>
      <updated>2019-02-02T23:33:52Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/01/23/postdoctoral-fellow-at-carnegie-mellon-university-apply-by-february-28-2019/</id>
    <link href="https://cstheory-jobs.org/2019/01/23/postdoctoral-fellow-at-carnegie-mellon-university-apply-by-february-28-2019/" rel="alternate" type="text/html"/>
    <title>Postdoctoral Fellow at Carnegie Mellon University (apply by February 28, 2019)</title>
    <summary>Postdoctoral Position at the computer science department, CMU. Hosted by Venkatesan Gurusawami and Pravesh Kothari. Start Date: Fall 2019 (Flexible) Application Deadline: Feb 28, 2019 (earlier applications encouraged). To apply, send CV, a research statement and arrange for 2 letters of recommendation to be set to be sent to bcook@cs.cmu.edu with subject line mentioning “CMU […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Postdoctoral Position at the computer science department, CMU. Hosted by Venkatesan Gurusawami and Pravesh Kothari. Start Date: Fall 2019 (Flexible)<br/>
Application Deadline: Feb 28, 2019 (earlier applications encouraged).</p>
<p>To apply, send CV, a research statement and arrange for 2 letters of recommendation to be set to be sent to bcook@cs.cmu.edu with subject line mentioning “CMU theory postdoc.”</p>
<p>Website: <a href="https://www.cs.princeton.edu/~kothari/theory-postdoc.html">https://www.cs.princeton.edu/~kothari/theory-postdoc.html</a><br/>
Email: kothari@cs.princeton.edu</p></div>
    </content>
    <updated>2019-01-23T22:24:07Z</updated>
    <published>2019-01-23T22:24:07Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-02-03T09:20:38Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/01/22/postdoc-at-charles-university-in-prague-apply-by-february-28-2019-2/</id>
    <link href="https://cstheory-jobs.org/2019/01/22/postdoc-at-charles-university-in-prague-apply-by-february-28-2019-2/" rel="alternate" type="text/html"/>
    <title>Postdoc at Charles University in Prague (apply by February 28, 2019)</title>
    <summary>Several one‐year post‐doc positions are available at the Computer Science Institute of Charles University, with a possibility of one-year extension. The positions are in areas of algorithms, cryptography, computational complexity, combinatorics and graph theory. Starting date is in Fall 2019, and can be negotiated. Website: https://iuuk.mff.cuni.cz/~koucky/iuuk-postdocs.html Email: koucky@iuuk.mff.cuni.cz</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Several one‐year post‐doc positions are available at the Computer Science Institute of Charles University, with a possibility of one-year extension. The positions are in areas of algorithms, cryptography, computational complexity, combinatorics and graph theory. Starting date is in Fall 2019, and can be negotiated.</p>
<p>Website: <a href="https://iuuk.mff.cuni.cz/~koucky/iuuk-postdocs.html">https://iuuk.mff.cuni.cz/~koucky/iuuk-postdocs.html</a><br/>
Email: koucky@iuuk.mff.cuni.cz</p></div>
    </content>
    <updated>2019-01-22T12:38:31Z</updated>
    <published>2019-01-22T12:38:31Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-02-03T09:20:38Z</updated>
    </source>
  </entry>
</feed>
