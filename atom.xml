<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2019-11-29T16:21:45Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16420</id>
    <link href="https://rjlipton.wordpress.com/2019/11/29/predicating-predictivity/" rel="alternate" type="text/html"/>
    <title>Predicating Predictivity</title>
    <summary>Plus predicaments of error modeling Cropped from Bacon Sandwich source Sir David Spiegelhalter is a British statistician. He is a strong voice for the public understanding of statistics. His work extends to all walks of life, including risk, coincidences, murder, and sex. Today we talk about extending one of his inventions. His invention has to […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><span style="color: #0044cc;"><br/>
<em>Plus predicaments of error modeling</em><br/>
</span></p>
<table class="image alignright">
<tbody>
<tr>
<td><a href="https://rjlipton.wordpress.com/2019/11/29/predicating-predictivity/spiegelhalterbacon/" rel="attachment wp-att-16422"><img alt="" class="alignright wp-image-16422" height="168" src="https://rjlipton.files.wordpress.com/2019/11/spiegelhalterbacon.jpg?w=200&amp;h=168" width="200"/></a></td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Cropped from Bacon Sandwich <a href="https://www.youtube.com/watch?v=4szyEbU94ig">source</a></font></td>
</tr>
</tbody>
</table>
<p>
Sir David Spiegelhalter is a British statistician. He is a strong voice for the public understanding of statistics. His work extends to all walks of life, including <a href="https://www.regulation.org.uk/library/2017-Spiegelhalter-Risk_and_Uncertainty_Communication.pdf">risk</a>, <a href="https://understandinguncertainty.org/coincidences">coincidences</a>, <a href="https://www.spectator.co.uk/2019/04/i-could-have-stopped-harold-shipmans-killing-spree-and-saved-175-lives/">murder</a>, and <a href="https://www.ft.com/content/f8793aaa-dfa1-11e4-a06a-00144feab7de">sex</a>.</p>
<p>
Today we talk about extending one of his inventions.</p>
<p>
His invention has to do with grading the performance of people and models that make predictions. A <b>scoring rule</b> grades how often predictions are right. But it may not tell how difficult the situations are. It is easy to look good with predictions when they start with a high chance of success. A weather forecaster predicting sunny-versus-rainy will be right more often in Las Vegas than in Boston. Quoting this FiveThirtyEight <a href="https://fivethirtyeight.com/features/which-city-has-the-most-unpredictable-weather/">item</a>:</p>
<blockquote><p><b> </b> <em> If you want to have an easy life as a weather forecaster, you should get a job in Las Vegas, Phoenix or Los Angeles. Predict that it won’t rain in one of those cities, and you’ll be right about 90 percent of the time. </em>
</p></blockquote>
<p/><p>
In a 1986 <a href="https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.4780050506">paper</a>, for a particular scoring rule <a href="https://www.semanticscholar.org/paper/VERIFICATION-OF-FORECASTS-EXPRESSED-IN-TERMS-OF-Brier/feee6551179612b9691f021b583d8a99b81b9b86">defined</a> by Glenn Brier in 1950, Spiegelhalter worked out how to equalize the forecaster grading. He applied his <b>Z-test</b> not to weather like Brier did but to medical prognoses and clinical trials. </p>
<p>
What I am doing with a small group of graduate students in Buffalo is trying to turn Spiegelhalter’s kind of Z-test around once more. If a forecaster fares poorly, we will try to flag not the model but the behavior of the subjects being modeled. In weather we would want to tell when Mother Nature, not the models, has gone off the rails. Well, we are actually looking for ways to tell when a human being has left the bounds of human predictability for reasons that are inhuman—such as cheating with a computer at chess. And maybe it can shed more light on whether our computers can possibly cheat with quantum mechanics.</p>
<p>
</p><p/><h2> Prediction Scores </h2><p/>
<p/><p>
Let’s consider situations <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t}"/> in which the number <img alt="{\ell = \ell_t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell+%3D+%5Cell_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\ell = \ell_t}"/> is usually more than <img alt="{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2}"/>, that is, usually more than “rain” or “no rain.” The forecaster lays down projections <img alt="{\vec{q} = \vec{q}_t = (q_1,\dots,q_\ell)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cvec%7Bq%7D+%3D+%5Cvec%7Bq%7D_t+%3D+%28q_1%2C%5Cdots%2Cq_%5Cell%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\vec{q} = \vec{q}_t = (q_1,\dots,q_\ell)}"/> for the chance of each outcome. If outcome <img alt="{r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r}"/> happens, then the <em>Brier score</em> for that forecast is <a name="Brier"/></p><a name="Brier">
<p align="center"><img alt="\displaystyle  B^{\vec{q}}(r) = (1 - q_r)^2 + \sum_{j \neq r} q_j^2. \ \ \ \ \ (1)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++B%5E%7B%5Cvec%7Bq%7D%7D%28r%29+%3D+%281+-+q_r%29%5E2+%2B+%5Csum_%7Bj+%5Cneq+r%7D+q_j%5E2.+%5C+%5C+%5C+%5C+%5C+%281%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  B^{\vec{q}}(r) = (1 - q_r)^2 + \sum_{j \neq r} q_j^2. \ \ \ \ \ (1)"/></p>
</a><p><a name="Brier"/> If the forecaster was certain that <img alt="{r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r}"/> would happen and so put <img alt="{q_r = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq_r+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q_r = 1}"/>, all other <img alt="{q_j = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq_j+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q_j = 0}"/>, then the score would be zero. Thus lower is better for the Brier score. </p>
<p>
If you put any probability <img alt="{q_r &lt; 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq_r+%3C+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q_r &lt; 1}"/> on the outcome that happened, then you get penalized both for the difference and for the remaining probability which you put on outcomes that did not happen. It is possible to <em>decompose</em> the score in another way that changes the emphasis: </p>
<p align="center"><img alt="\displaystyle  B^{\vec{q}}(r) = 1 + Q - 2q_r \qquad\text{where}\qquad Q = \sum_{j=1}^\ell q_j^2. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++B%5E%7B%5Cvec%7Bq%7D%7D%28r%29+%3D+1+%2B+Q+-+2q_r+%5Cqquad%5Ctext%7Bwhere%7D%5Cqquad+Q+%3D+%5Csum_%7Bj%3D1%7D%5E%5Cell+q_j%5E2.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  B^{\vec{q}}(r) = 1 + Q - 2q_r \qquad\text{where}\qquad Q = \sum_{j=1}^\ell q_j^2. "/></p>
<p>Then <img alt="{Q}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BQ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Q}"/> is a fixed measure of how you spread your forecasts around, while all the variability in your score comes from how much stock you placed in the outcome that happened. The worst case is having put <img alt="{q_r = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq_r+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q_r = 0}"/>, whereupon your Brier penalty is <img alt="{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2}"/>. We would like our forecasts always to be perfect, but reality gives us situations that are inherently nondeterministic—with unknown “true probabilities” <img alt="{\vec{p}_t = (p_1,\dots,p_\ell)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cvec%7Bp%7D_t+%3D+%28p_1%2C%5Cdots%2Cp_%5Cell%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\vec{p}_t = (p_1,\dots,p_\ell)}"/>. The vital point is that the forecaster should not try to hit <img alt="{r = r_t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br+%3D+r_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r = r_t}"/> on the nose at every time <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t}"/> but rather to match the true probabilities. Once we postulate <img alt="{\vec{p}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cvec%7Bp%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\vec{p}}"/>, the <em>expected Brier score</em> is </p>
<p align="center"><img alt="\displaystyle  \begin{array}{rcl}  \mathsf{E}_{\vec{p}}[B^{\vec{q}}] &amp;=&amp; \sum_{i=1}^\ell p_i B^{\vec{q}}(i)\\ &amp;=&amp; \sum_{i=1}^\ell p_i (1 - 2q_i + Q)\\ &amp;=&amp; 1 + Q - 2\sum_{i=1}^\ell p_i q_i. \end{array} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Barray%7D%7Brcl%7D++%5Cmathsf%7BE%7D_%7B%5Cvec%7Bp%7D%7D%5BB%5E%7B%5Cvec%7Bq%7D%7D%5D+%26%3D%26+%5Csum_%7Bi%3D1%7D%5E%5Cell+p_i+B%5E%7B%5Cvec%7Bq%7D%7D%28i%29%5C%5C+%26%3D%26+%5Csum_%7Bi%3D1%7D%5E%5Cell+p_i+%281+-+2q_i+%2B+Q%29%5C%5C+%26%3D%26+1+%2B+Q+-+2%5Csum_%7Bi%3D1%7D%5E%5Cell+p_i+q_i.+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \begin{array}{rcl}  \mathsf{E}_{\vec{p}}[B^{\vec{q}}] &amp;=&amp; \sum_{i=1}^\ell p_i B^{\vec{q}}(i)\\ &amp;=&amp; \sum_{i=1}^\ell p_i (1 - 2q_i + Q)\\ &amp;=&amp; 1 + Q - 2\sum_{i=1}^\ell p_i q_i. \end{array} "/></p>
<p>This is uniquely minimized by setting <img alt="{q_i = p_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq_i+%3D+p_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q_i = p_i}"/> for each <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/>, which defines <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B}"/> as a <b>strictly proper</b> scoring rule. Without the second term <img alt="{\sum_{j \neq r} q_j^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csum_%7Bj+%5Cneq+r%7D+q_j%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\sum_{j \neq r} q_j^2}"/> in (<a href="https://rjlipton.wordpress.com/feed/#Brier">1</a>) the rule would not be proper for <img alt="{\ell &gt; 2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell+%3E+2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\ell &gt; 2}"/>. When <img alt="{\vec{q} = \vec{p}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cvec%7Bq%7D+%3D+%5Cvec%7Bp%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\vec{q} = \vec{p}}"/>, <img alt="{Q}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BQ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Q}"/> becomes equal to <img alt="{P = \sum_{j=1}^\ell p_j^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP+%3D+%5Csum_%7Bj%3D1%7D%5E%5Cell+p_j%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{P = \sum_{j=1}^\ell p_j^2}"/>. Thus <img alt="{P}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{P}"/> represents an unavoidable prediction penalty from the intrinsic variance. If all <img alt="{p_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p_i}"/> are equal, <img alt="{p_i = \frac{1}{\ell}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_i+%3D+%5Cfrac%7B1%7D%7B%5Cell%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p_i = \frac{1}{\ell}}"/>, then the expected score cannot be less than <img alt="{1 - \frac{1}{\ell}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1+-+%5Cfrac%7B1%7D%7B%5Cell%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1 - \frac{1}{\ell}}"/>. </p>
<p>
A second example, the log-likelihood prediction scoring rule, is in the original <a href="https://cse.buffalo.edu/~regan/GLL/wspiegelhalterLong.pdf">draft</a> of this post.</p>
<p/><h2> Spiegelhalter’s Z </h2><p/>
<p/><p>
Spiegelhalter’s <img alt="{z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bz%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{z}"/>-score neatly drops out the unavoidable penalty term by taking the difference of the score with the expectation. Schematically it is defined as </p>
<p align="center"><img alt="\displaystyle  \mathsf{Z}[B] = \frac{B - \mathsf{E}[B]}{\sqrt{\mathsf{Var}[B]}}, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathsf%7BZ%7D%5BB%5D+%3D+%5Cfrac%7BB+-+%5Cmathsf%7BE%7D%5BB%5D%7D%7B%5Csqrt%7B%5Cmathsf%7BVar%7D%5BB%5D%7D%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \mathsf{Z}[B] = \frac{B - \mathsf{E}[B]}{\sqrt{\mathsf{Var}[B]}}, "/></p>
<p>where <img alt="{\mathsf{Var}[B]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BVar%7D%5BB%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{Var}[B]}"/> means the projected variance <img alt="{\mathsf{E}_{\vec{p}}[B^2] - (\mathsf{E}_{\vec{p}}[B])^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BE%7D_%7B%5Cvec%7Bp%7D%7D%5BB%5E2%5D+-+%28%5Cmathsf%7BE%7D_%7B%5Cvec%7Bp%7D%7D%5BB%5D%29%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{E}_{\vec{p}}[B^2] - (\mathsf{E}_{\vec{p}}[B])^2}"/>. However, here is where it is important to notate the whole series of forecasting situations <img alt="{t = 1,\dots,T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt+%3D+1%2C%5Cdots%2CT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t = 1,\dots,T}"/> with outcomes <img alt="{r_t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r_t}"/> for each <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t}"/>. The actual statistic is <a name="ZB"/></p><a name="ZB">
<p align="center"><img alt="\displaystyle  \mathsf{Z}_{\vec{p}}[B^{\vec{q}}] = \frac{\sum_{t=1}^T B^{\vec{q}_t}(r_t) - \mathsf{E}_{\vec{p}_t}[B^{\vec{q}_t}]}{\sqrt{\sum_{t=1}^T \mathsf{Var}_{\vec{p}_t}[B^{\vec{q}_t}]}}. \ \ \ \ \ (2)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathsf%7BZ%7D_%7B%5Cvec%7Bp%7D%7D%5BB%5E%7B%5Cvec%7Bq%7D%7D%5D+%3D+%5Cfrac%7B%5Csum_%7Bt%3D1%7D%5ET+B%5E%7B%5Cvec%7Bq%7D_t%7D%28r_t%29+-+%5Cmathsf%7BE%7D_%7B%5Cvec%7Bp%7D_t%7D%5BB%5E%7B%5Cvec%7Bq%7D_t%7D%5D%7D%7B%5Csqrt%7B%5Csum_%7Bt%3D1%7D%5ET+%5Cmathsf%7BVar%7D_%7B%5Cvec%7Bp%7D_t%7D%5BB%5E%7B%5Cvec%7Bq%7D_t%7D%5D%7D%7D.+%5C+%5C+%5C+%5C+%5C+%282%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \mathsf{Z}_{\vec{p}}[B^{\vec{q}}] = \frac{\sum_{t=1}^T B^{\vec{q}_t}(r_t) - \mathsf{E}_{\vec{p}_t}[B^{\vec{q}_t}]}{\sqrt{\sum_{t=1}^T \mathsf{Var}_{\vec{p}_t}[B^{\vec{q}_t}]}}. \ \ \ \ \ (2)"/></p>
</a><p><a name="ZB"/> The denominator presumes that the forecast situations are independent so that the variances add. The numerator expands to be </p>
<p align="center"><img alt="\displaystyle  \sum_{t=1}^T \left(2\sum_{i=1}^{\ell_t} p_{i,t} q_{i,t}\right) - 2q_{r,t}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_%7Bt%3D1%7D%5ET+%5Cleft%282%5Csum_%7Bi%3D1%7D%5E%7B%5Cell_t%7D+p_%7Bi%2Ct%7D+q_%7Bi%2Ct%7D%5Cright%29+-+2q_%7Br%2Ct%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \sum_{t=1}^T \left(2\sum_{i=1}^{\ell_t} p_{i,t} q_{i,t}\right) - 2q_{r,t}. "/></p>
<p>The original application is a confidence test of the “null hypothesis” that the projections <img alt="{\vec{q}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cvec%7Bq%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\vec{q}}"/> are good. Thus we plug in <img alt="{p_{i,t} = q_{i,t}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_%7Bi%2Ct%7D+%3D+q_%7Bi%2Ct%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p_{i,t} = q_{i,t}}"/> for all <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t}"/> and <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/> so that we test </p>
<p align="center"><img alt="\displaystyle  \mathsf{Z}_{\vec{q}}[B^{\vec{q}}] = 2\frac{\sum_{t=1}^T \left(\sum_{i=1}^{\ell_t} q_{i,t}^2 \right) - q_{r,t}}{\sqrt{\sum_{t=1}^T \mathsf{Var}_{\vec{q}_t}[B^{\vec{q}_t}]}}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathsf%7BZ%7D_%7B%5Cvec%7Bq%7D%7D%5BB%5E%7B%5Cvec%7Bq%7D%7D%5D+%3D+2%5Cfrac%7B%5Csum_%7Bt%3D1%7D%5ET+%5Cleft%28%5Csum_%7Bi%3D1%7D%5E%7B%5Cell_t%7D+q_%7Bi%2Ct%7D%5E2+%5Cright%29+-+q_%7Br%2Ct%7D%7D%7B%5Csqrt%7B%5Csum_%7Bt%3D1%7D%5ET+%5Cmathsf%7BVar%7D_%7B%5Cvec%7Bq%7D_t%7D%5BB%5E%7B%5Cvec%7Bq%7D_t%7D%5D%7D%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \mathsf{Z}_{\vec{q}}[B^{\vec{q}}] = 2\frac{\sum_{t=1}^T \left(\sum_{i=1}^{\ell_t} q_{i,t}^2 \right) - q_{r,t}}{\sqrt{\sum_{t=1}^T \mathsf{Var}_{\vec{q}_t}[B^{\vec{q}_t}]}}. "/></p>
<p>To illustrate, suppose we do ten independent trials of an event with four outcomes whose true probabilities are <img alt="{(0.1,0.2,0.3,0.4)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%280.1%2C0.2%2C0.3%2C0.4%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(0.1,0.2,0.3,0.4)}"/>. The sum in parentheses is <img alt="{10(0.01 + 0.04 + 0.09 + 0.16) = 3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B10%280.01+%2B+0.04+%2B+0.09+%2B+0.16%29+%3D+3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{10(0.01 + 0.04 + 0.09 + 0.16) = 3}"/>. If the outcomes conform exactly to these probabilities then <img alt="{q_{r,t}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq_%7Br%2Ct%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q_{r,t}}"/> equals <img alt="{0.1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0.1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0.1}"/> once, <img alt="{0.2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0.2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0.2}"/> twice, <img alt="{0.3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0.3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0.3}"/> three times, and <img alt="{0.4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0.4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0.4}"/> four times. This exactly cancels the <img alt="{3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{3}"/>, so <img alt="{\vec{q} = \vec{p}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cvec%7Bq%7D+%3D+%5Cvec%7Bp%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\vec{q} = \vec{p}}"/> makes <img alt="{\mathsf{Z}_{\vec{q}}[B^{\vec{q}}] = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BZ%7D_%7B%5Cvec%7Bq%7D%7D%5BB%5E%7B%5Cvec%7Bq%7D%7D%5D+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{Z}_{\vec{q}}[B^{\vec{q}}] = 0}"/>, as expected. Most trials will give a nonzero numerator, but the denominator scales so in the long run, the Spiegelhalter <img alt="{Z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BZ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Z}"/> of a true model will go to <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/>.</p>
<p>
A high <img alt="{Z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BZ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Z}"/>, on the other hand—highly positive or highly negative—indicates that the forecasting is way off. That (<a href="https://rjlipton.wordpress.com/feed/#ZB">2</a>) is an aggregate statistic over independent trials justifies treating the <img alt="{Z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BZ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Z}"/>-values as <a href="https://en.wikipedia.org/wiki/Standard_score">standard</a> <a href="https://en.wikipedia.org/wiki/Z-test">scores</a>. This applies also to <img alt="{Z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BZ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Z}"/>-tests made similarly from other scoring rules besides the Brier score. The test thus becomes a verdict on the model. High <img alt="{Z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BZ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Z}"/>-values on certain subsets of the data may reveal biases. </p>
<p>
Our idea is the opposite. Suppose we know that the forecasts are true, or suppose they have biases that are known and correctable over moderately large data sets. We may then be able to fit <img alt="{\mathsf{Z}[B]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BZ%7D%5BB%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{Z}[B]}"/> as an unbiased estimator (of zero) over large training sets. Then it can become a judgment of whether the data has become unnatural. </p>
<p>
</p><p/><h2> Why This Z? </h2><p/>
<p/><p>
As I have detailed in <a href="https://rjlipton.wordpress.com/2019/08/15/predicting-chess-and-horses/">numerous</a> <a href="https://rjlipton.wordpress.com/2013/09/17/littlewoods-law/">posts</a> <a href="https://rjlipton.wordpress.com/2018/10/18/london-calling/">on</a> <a href="https://rjlipton.wordpress.com/2013/07/27/thirteen-sigma/">this</a> <a href="https://rjlipton.wordpress.com/2011/10/12/empirical-humility/">blog</a>, my system for detecting cheating with computers at chess already provides several statistical <img alt="{z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bz%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{z}"/>-scores. Why would I want another one?</p>
<p>
The motive involves the presence of multiple strong chess-playing programs, each with its own quirks and distribution of values for moves. They are used in two different ways:</p>
<ol>
<li>
As inputs telling the relative values <img alt="{v_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bv_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{v_i}"/> of moves <img alt="{m_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m_i}"/>, which my model converts into its probability projections <img alt="{q_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q_i}"/>. <p/>
</li><li>
As output predicates telling how often the player chose the move recommended by a specific program and/or quantifying the magnitude of error for different played moves.
</li></ol>
<p>
Having multiple engines helps point 1. My intent to blend the <em>values</em> <img alt="{v_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bv_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{v_i}"/> from different engines has been blunted by issues I discussed <a href="https://rjlipton.wordpress.com/2018/09/07/sliding-scale-problems/">here</a>, so that I now have to train my model separately (and expensively) for each (new version of each) program. I can then blend the <img alt="{q_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q_i}"/>, but the point 2 remains at issue: My tests measure concordance with a specific program. Originally the program Rybka 3 was primary and Houdini 4B secondary, now Stockfish 7 is primary and Komodo 10.0 secondary—until I update to their latest versions. The second engine is supposed to confirm a positive result from the first one—which legislates that my model is not trying to detect exactly which program was used.</p>
<p>
Nevertheless, my results often vary between testing engines. The engines <a href="https://rjlipton.wordpress.com/2014/12/28/the-new-chess-world-champion/">compete</a> against each other and may be crafted to disagree on certain kinds of moves. They agree with each other barely 75–80% in my tests. I would like to factor these differences out. </p>
<p>
The Spiegelhalter <img alt="{Z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BZ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Z}"/>-test appeals because its reference is not to a particular chess program, but to the prediction quality of my model itself—which per point 1 can be informed by many programs in concert. It gives a way to <em>predicate predictivity</em>. A high value will attest that the sequence of played moves falls outside the range of predictability for human players of the same rated skill level. </p>
<p>
</p><p/><h2> The Method </h2><p/>
<p/><p>
To harness <img alt="{\mathsf{Z}[F]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BZ%7D%5BF%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{Z}[F]}"/> for some scoring rule <img alt="{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F}"/>, we need to quantify the nature of my model’s <img alt="{q_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q_i}"/> projections. In fact, my model has a clear bias toward conservatism in judging the frequency of particular non-optimal moves. This is discussed in my August <a href="https://rjlipton.wordpress.com/2019/08/15/predicting-chess-and-horses/">post</a> on my model upgrade and shown graphically in an appended <a href="https://cse.buffalo.edu/~regan/chess/computer/ModelTradeoffs.png">note</a> on why the conservative setting of a “gradient” parameter is needed to preserve dynamical stability. The fitting offsets this in a way that creates an opposite bias elsewhere. I hope to correct both biases at the same stroke by a specific means of modeling how the <img alt="{q_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q_i}"/> err with respect to the postulated true probabilities <img alt="{p_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p_i}"/>.</p>
<p>
We postulate an original source of error terms <img alt="{\epsilon_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\epsilon_i}"/> all <a href="https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables">i.i.d.</a> as <img alt="{\mathcal{N}(0,\delta^2)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BN%7D%280%2C%5Cdelta%5E2%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{N}(0,\delta^2)}"/>, where <img alt="{\delta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\delta}"/> governs the magnitude of Gaussian noise. This noise can be <em>transformed</em> and related in various ways, e.g.:</p>
<ol>
<li>
<img alt="{q_i = p_i \pm \epsilon_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq_i+%3D+p_i+%5Cpm+%5Cepsilon_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q_i = p_i \pm \epsilon_i}"/>, <p/>
</li><li>
<img alt="{q_i = p_i(1 \pm \epsilon_i)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq_i+%3D+p_i%281+%5Cpm+%5Cepsilon_i%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q_i = p_i(1 \pm \epsilon_i)}"/>, <p/>
</li><li>
<img alt="{\frac{1}{q_i} = \frac{1}{p_i} \pm \epsilon_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B1%7D%7Bq_i%7D+%3D+%5Cfrac%7B1%7D%7Bp_i%7D+%5Cpm+%5Cepsilon_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\frac{1}{q_i} = \frac{1}{p_i} \pm \epsilon_i}"/>, <p/>
</li><li>
<img alt="{\log(\frac{1}{q_i}) = \log(\frac{1}{p_i}) \pm \epsilon_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog%28%5Cfrac%7B1%7D%7Bq_i%7D%29+%3D+%5Clog%28%5Cfrac%7B1%7D%7Bp_i%7D%29+%5Cpm+%5Cepsilon_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\log(\frac{1}{q_i}) = \log(\frac{1}{p_i}) \pm \epsilon_i}"/>, <p/>
</li><li>
<img alt="{\log(\frac{1}{q_i}) = \log(\frac{1}{p_i})(1 \pm \epsilon_i)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog%28%5Cfrac%7B1%7D%7Bq_i%7D%29+%3D+%5Clog%28%5Cfrac%7B1%7D%7Bp_i%7D%29%281+%5Cpm+%5Cepsilon_i%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\log(\frac{1}{q_i}) = \log(\frac{1}{p_i})(1 \pm \epsilon_i)}"/>, <p/>
</li><li>
<img alt="{\ln(\frac{q_i}{1 - q_i}) = \ln(\frac{p_i}{1 - p_i}) \pm \epsilon_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cln%28%5Cfrac%7Bq_i%7D%7B1+-+q_i%7D%29+%3D+%5Cln%28%5Cfrac%7Bp_i%7D%7B1+-+p_i%7D%29+%5Cpm+%5Cepsilon_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\ln(\frac{q_i}{1 - q_i}) = \ln(\frac{p_i}{1 - p_i}) \pm \epsilon_i}"/>.
</li></ol>
<p>
There are further forms to consider and it is not yet clear from data within my model which one most applies. We would be interested in examples where these representations have been employed and in observations about their natures. </p>
<p>
Given any error terms, we can write each <img alt="{p_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p_i}"/> as a function of <img alt="{q_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q_i}"/> and <img alt="{\epsilon_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\epsilon_i}"/>. One issue is having at most <img alt="{\ell-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\ell-1}"/> degrees of freedom among <img alt="{\epsilon_1,\dots,\epsilon_\ell}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon_1%2C%5Cdots%2C%5Cepsilon_%5Cell%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\epsilon_1,\dots,\epsilon_\ell}"/>, owing to the constraint that the <img alt="{q_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q_i}"/> as well as <img alt="{p_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p_i}"/> sum to <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>. We handle this by choosing some fixed <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/> as the “pivot” and using the constraints to eliminate <img alt="{p_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p_k}"/> and <img alt="{q_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q_k}"/>, leaving the other error terms free. In all cases, the proposed method of defining what we notate as <img alt="{\mathsf{Z}_{\vec{q},\vec{\epsilon}}[F]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BZ%7D_%7B%5Cvec%7Bq%7D%2C%5Cvec%7B%5Cepsilon%7D%7D%5BF%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{Z}_{\vec{q},\vec{\epsilon}}[F]}"/> is:</p>
<ul>
<li>
Substitute the terms with <img alt="{q_i,\epsilon_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq_i%2C%5Cepsilon_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q_i,\epsilon_i}"/> for each free <img alt="{p_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p_i}"/> into <img alt="{\mathsf{Z}_{\vec{p}}[F^{\vec{q}}]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BZ%7D_%7B%5Cvec%7Bp%7D%7D%5BF%5E%7B%5Cvec%7Bq%7D%7D%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{Z}_{\vec{p}}[F^{\vec{q}}]}"/>. <p/>
</li><li>
Compute the expectation over <img alt="{\epsilon_i \sim \mathcal{N}(0,\delta^2)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon_i+%5Csim+%5Cmathcal%7BN%7D%280%2C%5Cdelta%5E2%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\epsilon_i \sim \mathcal{N}(0,\delta^2)}"/> for the numerator and denominator of (<a href="https://rjlipton.wordpress.com/feed/#ZB">2</a>), separately. <p/>
</li><li>
Holding the other previously-fitted model parameters in place, fit <img alt="{\delta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\delta}"/> so that <img alt="{\mathsf{Z}_{\vec{q},\vec{\epsilon}}[F]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BZ%7D_%7B%5Cvec%7Bq%7D%2C%5Cvec%7B%5Cepsilon%7D%7D%5BF%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{Z}_{\vec{q},\vec{\epsilon}}[F]}"/> is zero over the training set (or sets, for each level of Elo rating <img alt="{R}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R}"/>, so <img alt="{\delta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\delta}"/> becomes a function of <img alt="{R}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R}"/>).
</li></ul>
<p>
If the resulting <img alt="{Z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BZ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Z}"/>-scores parameterized by <img alt="{\delta_R}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta_R%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\delta_R}"/> make sense, the last step will be adjusting them to conform to normal distribution, via the resampling process mentioned recently <a href="https://rjlipton.wordpress.com/2019/08/20/our-trip-to-monte-carlo/">here</a> and earlier <a href="https://rjlipton.wordpress.com/2011/10/12/empirical-humility/">here</a>. We are not there yet. But observations from Spiegelhalter tests with <img alt="{\vec{q} = \vec{p}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cvec%7Bq%7D+%3D+%5Cvec%7Bp%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\vec{q} = \vec{p}}"/> (equivalently, with <img alt="{\delta_R}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta_R%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\delta_R}"/> fixed to zero) suggest that the resulting single, authoritative, “pure” predictivity test may rival the sharpness of my current tests involving specific chess porgrams.</p>
<p>
</p><p/><h2> Error Quirks and Queries </h2><p/>
<p/><p>
To see a key wrinkle, consider the first error form. It is symmetrical: <img alt="{p_i = q_i \pm \epsilon_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_i+%3D+q_i+%5Cpm+%5Cepsilon_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p_i = q_i \pm \epsilon_i}"/>. When we substitute <img alt="{q_i + \epsilon_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq_i+%2B+%5Cepsilon_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q_i + \epsilon_i}"/> for <img alt="{p_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p_i}"/> and take <img alt="{\mathsf{E}_{\epsilon_i \sim \mathcal{N}(0,\delta^2)}[\cdots]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BE%7D_%7B%5Cepsilon_i+%5Csim+%5Cmathcal%7BN%7D%280%2C%5Cdelta%5E2%29%7D%5B%5Ccdots%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{E}_{\epsilon_i \sim \mathcal{N}(0,\delta^2)}[\cdots]}"/>, the symmetry of <img alt="{\epsilon_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\epsilon_i}"/> around <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/> makes it drop out of the numerator of (<a href="https://rjlipton.wordpress.com/feed/#ZB">2</a>), and out of everything in the denominator except one place where <img alt="{p_i^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_i%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p_i^2}"/> becomes <img alt="{(q_i^2 + 2\epsilon q_i + \epsilon_i^2)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28q_i%5E2+%2B+2%5Cepsilon+q_i+%2B+%5Cepsilon_i%5E2%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(q_i^2 + 2\epsilon q_i + \epsilon_i^2)}"/>. There is hence nothing for <img alt="{\delta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\delta}"/> to fit and we are basically left with the original Spiegelhalter <img alt="{Z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BZ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Z}"/>. </p>
<p>
In the second form, however, we get <img alt="{p_i = q_i \cdot \frac{1}{1 + \epsilon_i}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_i+%3D+q_i+%5Ccdot+%5Cfrac%7B1%7D%7B1+%2B+%5Cepsilon_i%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p_i = q_i \cdot \frac{1}{1 + \epsilon_i}}"/>. If we presume <img alt="{\delta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\delta}"/> small enough to make the distribution of <img alt="{\mathcal{N}(0,\delta^2)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BN%7D%280%2C%5Cdelta%5E2%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{N}(0,\delta^2)}"/> outside <img alt="{(-1,1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28-1%2C1%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(-1,1)}"/> negligible, then we can use the series expansion to approximate </p>
<p align="center"><img alt="\displaystyle  p_i \approx q_i(1 - \epsilon_i + \epsilon_i^2 - \epsilon_i^3 + \epsilon_i^4). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++p_i+%5Capprox+q_i%281+-+%5Cepsilon_i+%2B+%5Cepsilon_i%5E2+-+%5Cepsilon_i%5E3+%2B+%5Cepsilon_i%5E4%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  p_i \approx q_i(1 - \epsilon_i + \epsilon_i^2 - \epsilon_i^3 + \epsilon_i^4). "/></p>
<p>Under normal expectation, the odd-power terms drop out (so their signs don’t matter) and we get </p>
<p align="center"><img alt="\displaystyle  \mathsf{E}_{\epsilon_i \sim \mathcal{N}(0,\delta^2)}[q_i(1 - \epsilon_i + \epsilon_i^2 - \epsilon_i^3 + \epsilon_i^4)] = q_i(1 + \delta^2 + 3\delta^4). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathsf%7BE%7D_%7B%5Cepsilon_i+%5Csim+%5Cmathcal%7BN%7D%280%2C%5Cdelta%5E2%29%7D%5Bq_i%281+-+%5Cepsilon_i+%2B+%5Cepsilon_i%5E2+-+%5Cepsilon_i%5E3+%2B+%5Cepsilon_i%5E4%29%5D+%3D+q_i%281+%2B+%5Cdelta%5E2+%2B+3%5Cdelta%5E4%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \mathsf{E}_{\epsilon_i \sim \mathcal{N}(0,\delta^2)}[q_i(1 - \epsilon_i + \epsilon_i^2 - \epsilon_i^3 + \epsilon_i^4)] = q_i(1 + \delta^2 + 3\delta^4). "/></p>
<p>This credits <img alt="{p_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p_i}"/> as being greater than <img alt="{q_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q_i}"/>. Provided the projections for the substituted indices <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/> were generally slightly conservative, this has hope of correcting them.</p>
<p>
Already, however, we have traipsed over some pitfalls of methodology. One is that the normal expectation </p>
<p align="center"><img alt="\displaystyle  \mathsf{E}_{\epsilon \sim \mathcal{N}(0,\delta^2)}[\frac{1}{1+\epsilon}] = +\infty, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathsf%7BE%7D_%7B%5Cepsilon+%5Csim+%5Cmathcal%7BN%7D%280%2C%5Cdelta%5E2%29%7D%5B%5Cfrac%7B1%7D%7B1%2B%5Cepsilon%7D%5D+%3D+%2B%5Cinfty%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \mathsf{E}_{\epsilon \sim \mathcal{N}(0,\delta^2)}[\frac{1}{1+\epsilon}] = +\infty, "/></p>
<p>regardless of how small <img alt="{\delta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\delta}"/> is. For any <img alt="{\delta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\delta}"/>, regions around the pole <img alt="{\epsilon = -1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon+%3D+-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\epsilon = -1}"/> get some fixed finite probability. Another is the simple paradox of our second form saying:</p>
<blockquote><p><b> </b> <em> <img alt="{q_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq_i%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{q_i}"/> is an unbiased estimator of <img alt="{p_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_i%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{p_i}"/>, but <img alt="{p_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_i%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{p_i}"/> is not an unbiased (or even finite) estimator of <img alt="{q_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq_i%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{q_i}"/>. </em>
</p></blockquote>
<p/><p>
A third curiosity comes from the fourth error form. It gives <img alt="{q_i = p_i e^{\epsilon_i}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq_i+%3D+p_i+e%5E%7B%5Cepsilon_i%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q_i = p_i e^{\epsilon_i}}"/>, so <img alt="{p_i = q_i e^{-\epsilon_i}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_i+%3D+q_i+e%5E%7B-%5Cepsilon_i%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p_i = q_i e^{-\epsilon_i}}"/>. We have </p>
<p align="center"><img alt="\displaystyle  \mathsf{E}_{\epsilon \sim \mathcal{N}(0,\delta^2)}[e^{b\epsilon}] = e^{0.5b^2 \delta^2} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathsf%7BE%7D_%7B%5Cepsilon+%5Csim+%5Cmathcal%7BN%7D%280%2C%5Cdelta%5E2%29%7D%5Be%5E%7Bb%5Cepsilon%7D%5D+%3D+e%5E%7B0.5b%5E2+%5Cdelta%5E2%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \mathsf{E}_{\epsilon \sim \mathcal{N}(0,\delta^2)}[e^{b\epsilon}] = e^{0.5b^2 \delta^2} "/></p>
<p>exactly, without approximation. Again the sign of <img alt="{\epsilon_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\epsilon_i}"/> does not matter. So we get </p>
<p align="center"><img alt="\displaystyle  \mathsf{E}_{\vec{\epsilon}}[p_i] = q_i e^{0.5\delta^2} &gt; q_i. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathsf%7BE%7D_%7B%5Cvec%7B%5Cepsilon%7D%7D%5Bp_i%5D+%3D+q_i+e%5E%7B0.5%5Cdelta%5E2%7D+%3E+q_i.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \mathsf{E}_{\vec{\epsilon}}[p_i] = q_i e^{0.5\delta^2} &gt; q_i. "/></p>
<p>But by the original fourth equation we get </p>
<p align="center"><img alt="\displaystyle  \mathsf{E}_{\vec{\epsilon}}[q_i] = p_i e^{0.5\delta^2} &gt; p_i. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathsf%7BE%7D_%7B%5Cvec%7B%5Cepsilon%7D%7D%5Bq_i%5D+%3D+p_i+e%5E%7B0.5%5Cdelta%5E2%7D+%3E+p_i.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \mathsf{E}_{\vec{\epsilon}}[q_i] = p_i e^{0.5\delta^2} &gt; p_i. "/></p>
<p>So we have <img alt="{\mathsf{E}[q_i] &gt; p_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BE%7D%5Bq_i%5D+%3E+p_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{E}[q_i] &gt; p_i}"/> and <img alt="{\mathsf{E}[p_i] &gt; q_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BE%7D%5Bp_i%5D+%3E+q_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{E}[p_i] &gt; q_i}"/>, with both expectations being over the same noise terms. This is like the famous Lake Wobegon <a href="https://trustedadvisor.com/trustmatters/lake-wobegon-syndrome-believing-were-all-above-average">syndrome</a>. What it indicates is the need for care in where and how to apply these error representations.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Have you seen this idea of directly testing (un)predictability in the literature? Might it improve the currently much-debated statistical tests for quantum supremacy?</p>
<p>
Which error model seems most likely to apply? Where have the paradoxes in our last section been noted?</p>
<p/></div>
    </content>
    <updated>2019-11-29T14:35:27Z</updated>
    <published>2019-11-29T14:35:27Z</published>
    <category term="All Posts"/>
    <category term="chess"/>
    <category term="detection"/>
    <category term="Ideas"/>
    <category term="cheating"/>
    <category term="David Spiegelhalter"/>
    <category term="predictability"/>
    <category term="predictive modeling"/>
    <category term="statistics"/>
    <author>
      <name>KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-11-29T16:20:41Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>http://corner.mimuw.edu.pl/?p=1093</id>
    <link href="http://corner.mimuw.edu.pl/?p=1093" rel="alternate" type="text/html"/>
    <title>Call for Invited Talk Nominations: HALG 2020</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">5th Highlights of Algorithms conference (HALG 2020) ETH Zurich, June 3-5, 2020​http://2020.highlightsofalgorithms.org/ The HALG 2020 conference seeks high-quality nominations for invited talks that will highlight recent advances in algorithmic research. Similarly to previous years, there are two categories of invited talks: A. survey … <a href="http://corner.mimuw.edu.pl/?p=1093">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>

5th Highlights of Algorithms conference (HALG 2020)</p>



<p>ETH Zurich, June 3-5, 2020<br/>​<br/><a href="http://2020.highlightsofalgorithms.org/" rel="noreferrer noopener" target="_blank">http://2020.highlightsofalgorithms.org/</a></p>



<p/>



<p>The HALG 2020 conference seeks high-quality nominations for invited talks that will highlight recent advances in algorithmic research. Similarly to previous years, there are two categories of invited talks:</p>



<p>A. survey (60 minutes): a survey of an algorithmic topic that has seen exciting developments in last couple of years.</p>



<p>B. paper (30 minutes): a significant algorithmic result appearing in a paper in 2019 or later.</p>



<p>To nominate, please email <a href="mailto:halg2020.nominations@gmail.com" rel="noreferrer noopener" target="_blank">halg2020.nominations@gmail.com</a> the following information:</p>



<ol><li>Basic details: speaker name + topic (for survey talk) or paper’s title, authors, conference/arxiv + preferable speaker (for paper talk).</li><li>Brief justification: Focus on the benefits to the audience, e.g., quality of results, importance/relevance of topic, clarity of talk, speaker’s presentation skills.</li></ol>



<p>All nominations will be reviewed by the Program Committee (PC) to select speakers that will be invited to the conference.</p>



<p>Nominations deadline: December 20, 2020 (for full consideration).</p></div>
    </content>
    <updated>2019-11-29T13:30:10Z</updated>
    <published>2019-11-29T13:30:10Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>sank</name>
    </author>
    <source>
      <id>http://corner.mimuw.edu.pl</id>
      <link href="http://corner.mimuw.edu.pl/?feed=rss2" rel="self" type="application/atom+xml"/>
      <link href="http://corner.mimuw.edu.pl" rel="alternate" type="text/html"/>
      <subtitle>University of Warsaw</subtitle>
      <title>Banach's Algorithmic Corner</title>
      <updated>2019-11-29T14:21:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/11/28/tenure-track-professor-at-university-of-british-columbia-apply-by-december-15-2019/</id>
    <link href="https://cstheory-jobs.org/2019/11/28/tenure-track-professor-at-university-of-british-columbia-apply-by-december-15-2019/" rel="alternate" type="text/html"/>
    <title>Tenure-Track Professor at University of British Columbia (apply by December 15, 2019)</title>
    <summary>The Department of Computer Science at the University of British Columbia is inviting applications for at least three positions at the rank of Assistant Professor. We invite applications from candidates of outstanding scientific talent in all areas of computer science. Appointment at a higher rank will be considered for an applicant of exceptional qualifications. Website: […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Department of Computer Science at the University of British Columbia is inviting applications for at least three positions at the rank of Assistant Professor. We invite applications from candidates of outstanding scientific talent in all areas of computer science. Appointment at a higher rank will be considered for an applicant of exceptional qualifications.</p>
<p>Website: <a href="https://www.cs.ubc.ca/our-department/employment/faculty-sessional-positions/tenure-track-faculty-positions-research-stre-0">https://www.cs.ubc.ca/our-department/employment/faculty-sessional-positions/tenure-track-faculty-positions-research-stre-0</a><br/>
Email: research-recruiting-chair@cs.ubc.ca</p></div>
    </content>
    <updated>2019-11-28T23:16:33Z</updated>
    <published>2019-11-28T23:16:33Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-11-29T16:20:45Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/172</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/172" rel="alternate" type="text/html"/>
    <title>TR19-172 |  Schur Polynomials do not have small formulas if the Determinant doesn&amp;#39;t!  | 

	Chandra Kanta Mohapatra, 

	Mrinal Kumar, 

	Nutan Limaye, 

	Srikanth Srinivasan, 

	Prasad Chaugule, 

	Adrian She</title>
    <summary>Schur Polynomials are families of symmetric polynomials that have been
classically studied in Combinatorics and Algebra alike. They play a central
role in the study of Symmetric functions, in Representation theory [Sta99], in
Schubert calculus [LM10] as well as in Enumerative combinatorics [Gas96, Sta84,
Sta99]. In recent years, they have also shown up in various incarnations in
Computer Science, e.g, Quantum computation [HRTS00, OW15] and Geometric
complexity theory [IP17].
  However, unlike some other families of symmetric polynomials like the
Elementary Symmetric polynomials, the Power Symmetric polynomials and the
Complete Homogeneous Symmetric polynomials, the computational complexity of
syntactically computing Schur polynomials has not been studied much. In
particular, it is not known whether Schur polynomials can be computed
efficiently by algebraic formulas. In this work, we address this question, and
show that unless \emph{every} polynomial with a small algebraic branching
program (ABP) has a small algebraic formula, there are Schur polynomials that
cannot be computed by algebraic formula of polynomial size. In other words,
unless the algebraic complexity class $\mathrm{VBP}$ is equal to the complexity
class $\mathrm{VF}$, there exist Schur polynomials which do not have polynomial
size algebraic formulas.
  As a consequence of our proof, we also show that computing the determinant of
certain \emph{generalized} Vandermonde matrices is essentially as hard as
computing the general symbolic determinant. To the best of our knowledge, these
are one of the first hardness results of this kind for families of polynomials
which are not \emph{multilinear}. A key ingredient of our proof is the study of
composition of \emph{well behaved} algebraically independent polynomials with a homogeneous polynomial, and might be of independent interest.</summary>
    <updated>2019-11-28T06:40:42Z</updated>
    <published>2019-11-28T06:40:42Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-11-29T16:20:31Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://tcsplus.wordpress.com/?p=381</id>
    <link href="https://tcsplus.wordpress.com/2019/11/27/tcs-talk-wednesday-december-4-nihar-shah-cmu/" rel="alternate" type="text/html"/>
    <title>TCS+ talk: Wednesday, December 4 — Nihar Shah, CMU</title>
    <summary>The next TCS+ talk, and last of the Fall season, will take place this coming Wednesday, December 4th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 18:00 UTC). Nihar Shah from CMU will speak about “Battling Demons in Peer Review” (abstract below). Please make sure you reserve a spot for your group […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The next TCS+ talk, and last of the Fall season, will take place this coming Wednesday, December 4th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 18:00 UTC). <strong>Nihar Shah</strong> from CMU will speak about “<em>Battling Demons in Peer Review</em>” (abstract below).</p>
<p>Please make sure you reserve a spot for your group to join us live by signing up on <a href="https://sites.google.com/site/plustcs/livetalk/live-seat-reservation">the online form</a>. As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/site/plustcs/suggest">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/site/plustcs/">the website</a>.</p>
<blockquote><p>Abstract: Peer review is the backbone of scholarly research. It is however faced with a number of challenges (or “demons”) which cause unfairness to authors, and degrade the overall quality of the process. This talk will present principled and practical approaches to battle these demons in peer review:</p>
<ol>
<li>Subjectivity: How to ensure that all papers are judged by the same yardstick?</li>
<li>Mis-calibration: How to use ratings in presence of arbitrary or adversarial mis-calibration?</li>
<li>Bias: How to rigorously test for existence of (gender/fame/race/…) biases in peer review?</li>
<li>Strategic behavior: How to insulate peer review from strategic behavior of author-reviewers?</li>
<li>Noise: How to assign reviewers to papers to simultaneously ensure fair and accurate evaluations in the presence of review noise?</li>
</ol>
<p>The work uses tools from social choice theory, statistics and learning theory, information theory, game theory and decision theory. No prior knowledge on these topics will be assumed.</p></blockquote>
<p>Bio:<br/>
<em><a href="http://cs.cmu.edu/~nihars">Nihar B. Shah</a> is an Assistant Professor in the Machine Learning and Computer Science departments at Carnegie Mellon University (CMU). His research interests include statistics, machine learning, information theory, and game theory, with a focus on applications to learning from people. He is a recipient of the the 2017 David J. Sakrison memorial prize from EECS Berkeley for a “truly outstanding and innovative PhD thesis”, the Microsoft Research PhD Fellowship 2014-16, the Berkeley Fellowship 2011-13, the IEEE Data Storage Best Paper and Best Student Paper Awards for the years 2011/2012, and the SVC Aiya Medal 2010, and has supervised the Best Student Paper at AAMAS 2019.</em></p></div>
    </content>
    <updated>2019-11-28T01:56:48Z</updated>
    <published>2019-11-28T01:56:48Z</published>
    <category term="Announcements"/>
    <author>
      <name>plustcs</name>
    </author>
    <source>
      <id>https://tcsplus.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://tcsplus.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://tcsplus.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://tcsplus.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://tcsplus.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A carbon-free dissemination of ideas across the globe.</subtitle>
      <title>TCS+</title>
      <updated>2019-11-29T16:21:15Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.12350</id>
    <link href="http://arxiv.org/abs/1911.12350" rel="alternate" type="text/html"/>
    <title>Single Machine Batch Scheduling to Minimize the Weighted Number of Tardy Jobs</title>
    <feedworld_mtime>1574899200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hermelin:Danny.html">Danny Hermelin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mnich:Matthias.html">Matthias Mnich</a>, Simon Omlor <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.12350">PDF</a><br/><b>Abstract: </b>The $1|B,r_j|\sum w_jU_j$ scheduling problem takes as input a batch setup
time $\Delta$ and a set of $n$ jobs, each having a processing time, a release
date, a weight, and a due date; the task is to find a sequence of batches that
minimizes the weighted number of tardy jobs. This problem was introduced by
Hochbaum and Landy in 1994; as a wide generalization of {\sc Knapsack}, it is
$\mathsf{NP}$-hard.
</p>
<p>In this work we provide a multivariate complexity analysis of the
$1|B,r_j|\sum w_jU_j$ problem with respect to several natural parameters. That
is, we establish a thorough classification into fixed-parameter tractable and
$\mathsf{W}[1]$-hard problems, for parameter combinations of (i) $\#p$ =
distinct number of processing times, (ii) $\#w$ = number of distinct weights,
(iii) $\#d$ = number of distinct due dates, (iv) $\#r$ = number of distinct
release dates, and (v) $b$ = batch sizes. Thereby, we significantly extend the
work of Hermelin et al. (2018) who analyzed the parameterized complexity of the
non-batch variant of this problem without release dates.
</p>
<p>As one of our key results, we prove that $1|B,r_j|\sum w_jU_j$ is
$\mathsf{W}[1]$-hard parameterized by the number of distinct processing times
and distinct due dates. To the best of our knowledge, these are the first
parameterized intractability results for scheduling problems with few distinct
processing times. Further, we show that $1|B,r_j|\sum w_jU_j$ is
fixed-parameter tractable with respect to parameter $\#p+\#d+\#r$ and with
respect to parameter $\#w+\#d$ if there is just a single release date. Both
results hold even if the number of jobs per batch is limited by some integer
$b$.
</p></div>
    </summary>
    <updated>2019-11-28T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.12242</id>
    <link href="http://arxiv.org/abs/1911.12242" rel="alternate" type="text/html"/>
    <title>An adaptive algorithm for quantum circuit simulation</title>
    <feedworld_mtime>1574899200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schutski:Roman.html">Roman Schutski</a>, Danil Lykov, Ivan Oseledets <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.12242">PDF</a><br/><b>Abstract: </b>Efficient simulation of quantum computers is essential for the development
and validation of near-term quantum devices and the research on quantum
algorithms. Up to date, two main approaches to simulation were in use, based on
either full state or single amplitude evaluation. We propose an algorithm that
efficiently interpolates between these two possibilities. Our approach
elucidates the connection between quantum circuit simulation and partial
evaluation of expressions in tensor algebra.
</p></div>
    </summary>
    <updated>2019-11-28T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-11-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.12138</id>
    <link href="http://arxiv.org/abs/1911.12138" rel="alternate" type="text/html"/>
    <title>Scheduling with Non-Renewable Resources: Minimizing the Sum of Completion Times</title>
    <feedworld_mtime>1574899200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/B=eacute=rczi:Krist=oacute=f.html">Kristóf Bérczi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kir=aacute=ly:Tam=aacute=s.html">Tamás Király</a>, Simon Omlor <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.12138">PDF</a><br/><b>Abstract: </b>The paper considers single-machine scheduling problems with a non-renewable
resource. In this setting, we are given a set jobs, each of which is
characterized by a processing time, a weight, and the job also has some
resource requirement. At fixed points in time, a certain amount of the resource
is made available to be consumed by the jobs. The goal is to assign the jobs
non-preemptively to time slots on the machine, so that at any time their
resource requirement does not exceed the available amounts of resources. The
objective that we consider here is the minimization of the sum of weighted
completion times.
</p>
<p>We give polynomial approximation algorithms and complexity results for single
scheduling machine problems. In particular, we show strong NP-hardness of the
case of unit resource requirements and weights ($1|rm=1,a_j=1|\sum C_j$), thus
answering an open question of Gy\"orgyi and Kis. We also prove that the
schedule corresponding to the Shortest Processing Time First ordering provides
a $3/2$-approximation for the same problem. We give simple constant factor
approximations and a more complicated PTAS for the case of $0$ processing times
($1|rm=1,p_j=0|\sum w_jC_j$). We close the paper by proposing a new variant of
the problem in which the resource arrival times are unknown. A
$4$-approximation is presented for this variant, together with an
$(4-\varepsilon)$-inapproximability result.
</p></div>
    </summary>
    <updated>2019-11-28T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.12125</id>
    <link href="http://arxiv.org/abs/1911.12125" rel="alternate" type="text/html"/>
    <title>Online Hashing with Efficient Updating of Binary Codes</title>
    <feedworld_mtime>1574899200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Weng:Zhenyu.html">Zhenyu Weng</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhu:Yuesheng.html">Yuesheng Zhu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.12125">PDF</a><br/><b>Abstract: </b>Online hashing methods are efficient in learning the hash functions from the
streaming data. However, when the hash functions change, the binary codes for
the database have to be recomputed to guarantee the retrieval accuracy.
Recomputing the binary codes by accumulating the whole database brings a
timeliness challenge to the online retrieval process. In this paper, we propose
a novel online hashing framework to update the binary codes efficiently without
accumulating the whole database. In our framework, the hash functions are fixed
and the projection functions are introduced to learn online from the streaming
data. Therefore, inefficient updating of the binary codes by accumulating the
whole database can be transformed to efficient updating of the binary codes by
projecting the binary codes into another binary space. The queries and the
binary code database are projected asymmetrically to further improve the
retrieval accuracy. The experiments on two multi-label image databases
demonstrate the effectiveness and the efficiency of our method for multi-label
image retrieval.
</p></div>
    </summary>
    <updated>2019-11-28T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.12074</id>
    <link href="http://arxiv.org/abs/1911.12074" rel="alternate" type="text/html"/>
    <title>Expected dispersion of uniformly distributed points</title>
    <feedworld_mtime>1574899200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hinrichs:Aicke.html">Aicke Hinrichs</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Krieg:David.html">David Krieg</a>, Robert Kunsch, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rudolf:Daniel.html">Daniel Rudolf</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.12074">PDF</a><br/><b>Abstract: </b>The dispersion of a point set in $[0,1]^d$ is the volume of the largest axis
parallel box inside the unit cube that does not intersect with the point set.
We study the expected dispersion with respect to a random set of $n$ points
determined by an i.i.d.\ sequence of uniformly distributed random variables.
Depending on the number of points $n$ and the dimension $d$ we provide an upper
and lower bound of the expected dispersion. In particular, we show that the
minimal number of points required to achieve an expected dispersion less than
$\varepsilon\in(0,1)$ depends linearly on the dimension $d$.
</p></div>
    </summary>
    <updated>2019-11-28T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-11-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.12003</id>
    <link href="http://arxiv.org/abs/1911.12003" rel="alternate" type="text/html"/>
    <title>Measuring similarity between two mixture trees using mixture distance metric and algorithms</title>
    <feedworld_mtime>1574899200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Justie Su-Tzu Juan, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Yi=Ching.html">Yi-Ching Chen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lin:Chen=Hui.html">Chen-Hui Lin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Shu=Chuan.html">Shu-Chuan Chen</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.12003">PDF</a><br/><b>Abstract: </b>Ancestral mixture model, proposed by Chen and Lindsay (2006), is an important
model to build a hierarchical tree from high dimensional binary sequences.
Mixture trees created from ancestral mixture models involve in the inferred
evolutionary relationships among various biological species. Moreover, it
contains the information of time when the species mutates. Tree comparison
metric, an essential issue in bioinformatics, is to measure the similarity
between trees. However, to our knowledge, the approach to the comparison
between two mixture trees is still under development. In this paper, we propose
a new metric, named mixture distance metric, to measure the similarity of two
mixture trees. It uniquely considers the factor of evolutionary times between
trees. In addition, we also further develop two algorithms to compute the
mixture distance between two mixture trees. One requires O(n^2) and the other
requires O(nh) computation time with O(n) preprocessing time, where n denotes
the number of leaves in the two mixture trees, and h denotes the minimum height
of these two trees.
</p></div>
    </summary>
    <updated>2019-11-28T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.11962</id>
    <link href="http://arxiv.org/abs/1911.11962" rel="alternate" type="text/html"/>
    <title>Approximating Permanent of Random Matrices with Vanishing Mean: Made Better and Simpler</title>
    <feedworld_mtime>1574899200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Ji:Zhengfeng.html">Zhengfeng Ji</a>, Zhihan Jin, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lu:Pinyan.html">Pinyan Lu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.11962">PDF</a><br/><b>Abstract: </b>The algorithm and complexity of approximating the permanent of a matrix is an
extensively studied topic. Recently, its connection with quantum supremacy and
more specifically BosonSampling draws special attention to the average-case
approximation problem of the permanent of random matrices with zero or small
mean value for each entry. Eldar and Mehraban (FOCS 2018) gave a
quasi-polynomial time algorithm for random matrices with mean at least
$1/\mathbf{\mathrm{polyloglog}} (n)$. In this paper, we improve the result by
designing a deterministic quasi-polynomial time algorithm and a PTAS for random
matrices with mean at least $1/\mathbf{\mathrm{polylog}}(n)$. We note that if
it can be further improved to $1/\mathbf{\mathrm{poly}}(n)$, it will disprove a
central conjecture for quantum supremacy.
</p>
<p>Our algorithm is also much simpler and has a better and flexible trade-off
for running time. The running time can be quasi-polynomial in both $n$ and
$1/\epsilon$, or PTAS (polynomial in $n$ but exponential in $1/\epsilon$),
where $\epsilon$ is the approximation parameter.
</p></div>
    </summary>
    <updated>2019-11-28T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.11868</id>
    <link href="http://arxiv.org/abs/1911.11868" rel="alternate" type="text/html"/>
    <title>Matrix Decompositions and Sparse Graph Regularity</title>
    <feedworld_mtime>1574899200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bodwin:Greg.html">Greg Bodwin</a>, Santosh Vempala <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.11868">PDF</a><br/><b>Abstract: </b>We introduce and study a matrix decomposition that is a common generalization
of the singular value decomposition (SVD), cut decomposition, CUR
decomposition, and others. For any given set of pairs $P \subseteq \mathbb{R}^m
\times \mathbb{R}^n$ and matrix $A \in \mathbb{R}^{m \times n}$, we write $A$
as a weighted sum of rank one matrices formed by some pairs in $P$. The
resulting projection value decomposition (PVD) inherits several useful
properties of the SVD; for example, the decomposition can be obtained by
greedily peeling off rank one matrices, and the norm of the coefficients of the
decomposition is the Frobenius norm of the matrix. Perhaps most interesting is
that, in analogy with low-rank approximation from SVD, truncating the
decomposition gives matrix approximations of small error.
</p>
<p>When applied to the adjacency matrices of graphs, the PVD lets us derive the
weak regularity lemma of Frieze and Kannan as well as Szemeredi's strong
regularity lemma. Whereas these regularity lemmas in their usual forms are
nontrivial only for dense graphs on $\Omega(n^2)$ edges, our generalization
implies extensions to a new class of sparse graphs which we call cut
pseudorandom, which are roughly those with small leading coefficients in the
appropriate PVD. It turns out that cut pseudorandomness unifies several
important pseudorandomness concepts in prior work: we show that $L_p$ upper
regularity and a version of low threshold rank are both special cases, thus
implying weak and strong regularity lemmas for these graph classes where only
weak ones were previously known.
</p></div>
    </summary>
    <updated>2019-11-28T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.11852</id>
    <link href="http://arxiv.org/abs/1911.11852" rel="alternate" type="text/html"/>
    <title>Rule Designs for Optimal Online Game Matchmaking</title>
    <feedworld_mtime>1574899200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Mingkuan Xu, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yu:Yang.html">Yang Yu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wu:Chenye.html">Chenye Wu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.11852">PDF</a><br/><b>Abstract: </b>Online games are the most popular form of entertainment among youngsters as
well as elders. Recognized as e-Sports, they may become an official part of the
Olympic Games by 2020. However, a long waiting time for matchmaking will
largely affect players' experiences. We examine different matchmaking
mechanisms for 2v2 games. By casting the mechanisms into a queueing theoretic
framework, we decompose the rule design process into a sequence of decision
making problems, and derive the optimal mechanism with minimum expected waiting
time. We further the result by exploring additional static as well as dynamic
rule designs' impacts. In the static setting, we consider the game allows
players to choose sides before the battle. In the dynamic setting, we consider
the game offers multiple zones for players of different skill levels. In both
settings, we examine the value of choice-free players. Closed form expressions
for the expected waiting time in different settings illuminate the guidelines
for online game rule designs.
</p></div>
    </summary>
    <updated>2019-11-28T23:20:30Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-11-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.11847</id>
    <link href="http://arxiv.org/abs/1911.11847" rel="alternate" type="text/html"/>
    <title>Faster Algorithms for Parametric Global Minimum Cut Problems</title>
    <feedworld_mtime>1574899200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Aissi:Hassene.html">Hassene Aissi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/McCormick:S=_Thomas.html">S. Thomas McCormick</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/q/Queyranne:Maurice.html">Maurice Queyranne</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.11847">PDF</a><br/><b>Abstract: </b>The parametric global minimum cut problem concerns a graph $G = (V,E)$ where
the cost of each edge is an affine function of a parameter $\mu \in
\mathbb{R}^d$ for some fixed dimension $d$. We consider the problems of finding
the next breakpoint in a given direction, and finding a parameter value with
maximum minimum cut value. We develop strongly polynomial algorithms for these
problems that are faster than a naive application of Megiddo's parametric
search technique. Our results indicate that the next breakpoint problem is
easier than the max value problem.
</p></div>
    </summary>
    <updated>2019-11-28T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.11838</id>
    <link href="http://arxiv.org/abs/1911.11838" rel="alternate" type="text/html"/>
    <title>Robustly Clustering a Mixture of Gaussians</title>
    <feedworld_mtime>1574899200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jia:He.html">He Jia</a>, Santosh Vempala <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.11838">PDF</a><br/><b>Abstract: </b>We give an efficient algorithm for robustly clustering of a mixture of
arbitrary Gaussians, a central open problem in the theory of computationally
efficient robust estimation, assuming only that for each pair of component
Gaussians, their means are well-separated or their covariances are
well-separated.
</p></div>
    </summary>
    <updated>2019-11-28T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.11793</id>
    <link href="http://arxiv.org/abs/1911.11793" rel="alternate" type="text/html"/>
    <title>A Quadratic Lower Bound for Algebraic Branching Programs</title>
    <feedworld_mtime>1574899200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chatterjee:Prerona.html">Prerona Chatterjee</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kumar:Mrinal.html">Mrinal Kumar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/She:Adrian.html">Adrian She</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Volk:Ben_Lee.html">Ben Lee Volk</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.11793">PDF</a><br/><b>Abstract: </b>We show that any Algebraic Branching Program (ABP) computing the polynomial
$\sum_{i = 1}^n x_i^n$ has at least $\Omega(n^2)$ vertices. This improves upon
the lower bound of $\Omega(n\log n)$, which follows from the classical result
of Baur and Strassen [Str73, BS83], and extends the results in [K19], which
showed a quadratic lower bound for \emph{homogeneous} ABPs computing the same
polynomial.
</p>
<p>Our proof relies on a notion of depth reduction which is reminiscent of
similar statements in the context of matrix rigidity, and shows that any small
enough ABP computing the polynomial $\sum_{i=1}^n x_i^n$ can be depth reduced
to essentially a homogeneous ABP of the same size which computes the polynomial
$\sum_{i = 1}^n x_i^n + \epsilon(x_1, \ldots, x_n)$, for a structured "error
polynomial" $\epsilon(x_1, \ldots, x_n)$. To complete the proof, we then
observe that the lower bound in [K19] is robust enough and continues to hold
for all polynomials $\sum_{i = 1}^n x_i^n + \epsilon(x_1, \ldots, x_n)$, where
$\epsilon(x_1, \ldots, x_n)$ has the appropriate structure.
</p></div>
    </summary>
    <updated>2019-11-28T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-11-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.09890</id>
    <link href="http://arxiv.org/abs/1911.09890" rel="alternate" type="text/html"/>
    <title>Degree-Bounded Generalized Polymatroids and Approximating the Metric Many-Visits TSP</title>
    <feedworld_mtime>1574899200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/B=eacute=rczi:Krist=oacute=f.html">Kristóf Bérczi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Berger:Andr=eacute=.html">André Berger</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mnich:Matthias.html">Matthias Mnich</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vincze:Roland.html">Roland Vincze</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.09890">PDF</a><br/><b>Abstract: </b>In the Bounded Degree Matroid Basis Problem, we are given a matroid and a
hypergraph on the same ground set, together with costs for the elements of that
set as well as lower and upper bounds $f(\varepsilon)$ and $g(\varepsilon)$ for
each hyperedge $\varepsilon$. The objective is to find a minimum-cost basis $B$
such that $f(\varepsilon) \leq |B \cap \varepsilon| \leq g(\varepsilon)$ for
each hyperedge $\varepsilon$. Kir\'aly et al. (Combinatorica, 2012) provided an
algorithm that finds a basis of cost at most the optimum value which violates
the lower and upper bounds by at most $2 \Delta-1$, where $\Delta$ is the
maximum degree of the hypergraph. When only lower or only upper bounds are
present for each hyperedge, this additive error is decreased to $\Delta-1$.
</p>
<p>We consider an extension of the matroid basis problem to generalized
polymatroids, or g-polymatroids, and additionally allow element multiplicities.
The Bounded Degree g-polymatroid Element Problem with Multiplicities takes as
input a g-polymatroid $Q(p,b)$ instead of a matroid, and besides the lower and
upper bounds, each hyperedge $\varepsilon$ has element multiplicities
$m_\varepsilon$. Building on the approach of Kir\'aly et al., we provide an
algorithm for finding a solution of cost at most the optimum value, having the
same additive approximation guarantee.
</p>
<p>As an application, we develop a $1.5$-approximation for the metric
Many-Visits TSP, where the goal is to find a minimum-cost tour that visits each
city $v$ a positive $r(v)$ number of times. Our approach combines our algorithm
for the Bounded Degree g-polymatroid Element Problem with Multiplicities with
the principle of Christofides' algorithm from 1976 for the (single-visit)
metric TSP, whose approximation guarantee it matches.
</p></div>
    </summary>
    <updated>2019-11-28T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/11/27/faculty-asst-and-assoc-prof-at-university-of-washington-apply-by-december-15-2019/</id>
    <link href="https://cstheory-jobs.org/2019/11/27/faculty-asst-and-assoc-prof-at-university-of-washington-apply-by-december-15-2019/" rel="alternate" type="text/html"/>
    <title>Faculty (Asst. and Assoc. Prof) at University of Washington (apply by December 15, 2019)</title>
    <summary>This year we have a targeted search in all areas of quantum computing, with a particular emphasis on quantum algorithms and quantum complexity theory. Website: https://apply.interfolio.com/64708 Email: jrl@cs.washington.edu</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>This year we have a targeted search in all areas of quantum computing, with a particular emphasis on quantum algorithms and quantum complexity theory.</p>
<p>Website: <a href="https://apply.interfolio.com/64708">https://apply.interfolio.com/64708</a><br/>
Email: jrl@cs.washington.edu</p></div>
    </content>
    <updated>2019-11-27T22:00:37Z</updated>
    <published>2019-11-27T22:00:37Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-11-29T16:20:45Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=7585</id>
    <link href="https://windowsontheory.org/2019/11/27/halg-2020-call-for-nominations-guest-post-by-yossi-azar/" rel="alternate" type="text/html"/>
    <title>HALG 2020 call for nominations (guest post by Yossi Azar)</title>
    <summary>[Guest post by Yossi Azar – I attended HALG once and enjoyed it quite a lot; I highly recommend people make such nominations –Boaz] Call for Invited Talk Nominations :5th Highlights of Algorithms conference (HALG 2020) ETH Zurich, June 3-5, 2020​http://2020.highlightsofalgorithms.org/ The HALG 2020 conference seeks high-quality nominations for invited talks that will highlight recent advances in algorithmic research. […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><em>[Guest post by Yossi Azar – I attended HALG once and enjoyed it quite a lot; I highly recommend people make such nominations –Boaz]</em></p>



<h3><strong>Call for Invited Talk Nominations</strong> :<strong>5th Highlights of Algorithms conference (HALG 2020)</strong></h3>



<p>ETH Zurich, June 3-5, 2020<br/>​<br/><a href="http://2020.highlightsofalgorithms.org/" rel="noreferrer noopener" target="_blank">http://2020.highlightsofalgorithms.org/</a></p>



<p/>



<p>The HALG 2020 conference seeks high-quality nominations for invited talks that will highlight recent advances in algorithmic research. Similarly to previous years, there are two categories of invited talks:</p>



<p>A. survey (60 minutes): a survey of an algorithmic topic that has seen exciting developments in last couple of years.</p>



<p>B. paper (30 minutes): a significant algorithmic result appearing in a paper in 2019 or later.</p>



<p>To nominate, please email <a href="mailto:halg2020.nominations@gmail.com" rel="noreferrer noopener" target="_blank">halg2020.nominations@gmail.com</a> the following information:</p>



<ol><li>Basic details: speaker name + topic (for survey talk) or paper’s title, authors, conference/arxiv + preferable speaker (for paper talk).</li><li>Brief justification: Focus on the benefits to the audience, e.g., quality of results, importance/relevance of topic, clarity of talk, speaker’s presentation skills.</li></ol>



<p>All nominations will be reviewed by the Program Committee (PC) to select speakers that will be invited to the conference.</p>



<p>Nominations deadline: <strong>December 20, 2020 </strong>(for full consideration).</p></div>
    </content>
    <updated>2019-11-27T18:42:42Z</updated>
    <published>2019-11-27T18:42:42Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2019-11-29T16:20:59Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://agtb.wordpress.com/?p=3451</id>
    <link href="https://agtb.wordpress.com/2019/11/27/new-book-introduction-to-multi-armed-bandits-by-alex-slivkins/" rel="alternate" type="text/html"/>
    <title>New Book: Introduction to Multi-Armed Bandits by Alex Slivkins</title>
    <summary>Here’s Alex’s announcement of his new book, which I am very excited about, and many in our community would no doubt find extremely useful (there’s even an open version on arXiv!): I am pleased to announce Introduction to multi-armed bandits, a broad and accessible introduction to the area which emphasizes connections to operations research, game […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Here’s Alex’s announcement of his new book, which I am very excited about, and many in our community would no doubt find extremely useful (there’s even an open version on arXiv!):</p>
<hr/>
<p>I am pleased to announce <a href="https://www.nowpublishers.com/article/Details/MAL-068">Introduction to multi-armed bandits</a>, a broad and accessible introduction to the area which emphasizes connections to operations research, game theory, and mechanism design. The said connections have generated a considerable amount of interest (and publications) in the Economics and Computation community.</p>
<p>The book is teachable by design: each chapter corresponds to one week of my class. Each chapter handles one big direction in the literature on bandits, covers the first-order concepts and results on a technical level, and provides a detailed literature review for further exploration. There are no prerequisites other than a certain level of mathematical maturity.</p>
<p>The chapters are as follows: stochastic bandits; lower bounds; Bayesian bandits and Thompson Sampling; Lipschitz Bandits; full feedback and adversarial costs; adversarial bandits; linear costs and semi-bandits; contextual bandits; bandits and games; bandits with knapsacks; bandits and incentives.</p>
<p>The book is also <a href="https://arxiv.org/abs/1904.07272">available on arxiv</a> (in a plain-format version).</p>
<p>Aleksandrs Slivkins<br/>
Microsoft Research NYC</p></div>
    </content>
    <updated>2019-11-27T17:44:13Z</updated>
    <published>2019-11-27T17:44:13Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Yannai A. Gonczarowski</name>
    </author>
    <source>
      <id>https://agtb.wordpress.com</id>
      <logo>https://secure.gravatar.com/blavatar/52ef314e11e379febf97d1a97547f4cd?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fbuttonw-com.png</logo>
      <link href="https://agtb.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://agtb.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://agtb.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://agtb.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Computation, Economics, and Game Theory</subtitle>
      <title>Turing's Invisible Hand</title>
      <updated>2019-11-29T16:20:37Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/11/27/recoloring-infinite-paths</id>
    <link href="https://11011110.github.io/blog/2019/11/27/recoloring-infinite-paths.html" rel="alternate" type="text/html"/>
    <title>Recoloring infinite paths</title>
    <summary>Suppose you have a uniformly random 3-coloring of a doubly-infinite path graph. This can be generated by choosing any one vertex, choosing any one of the three colors for it, and then propagating the coloring outwards from it, choosing one of the two available colors for each successive vertex. It’s convenient to imagine the three colors as being represented by the three numbers 0, 1, and 2 mod 3. Now perform the following process, repeatedly: change the color of every cell whose two neighbors both have the color that is one plus its color (mod 3). In other words, the middle vertex of a triple of vertices that is colored 1–0–1 changes to color 2, the middle vertex of 2–1–2 changes to 0, and the middle vertex of 0–2–0 changes to 1. What does this do to the coloring?</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Suppose you have a uniformly random 3-coloring of a doubly-infinite path graph. This can be generated by choosing any one vertex, choosing any one of the three colors for it, and then propagating the coloring outwards from it, choosing one of the two available colors for each successive vertex. It’s convenient to imagine the three colors as being represented by the three numbers 0, 1, and 2 mod 3. Now perform the following process, repeatedly: change the color of every cell whose two neighbors both have the color that is one plus its color (mod 3). In other words, the middle vertex of a triple of vertices that is colored 1–0–1 changes to color 2, the middle vertex of 2–1–2 changes to 0, and the middle vertex of 0–2–0 changes to 1. What does this do to the coloring?</p>

<p>You might think that it stays uniformly random, but it doesn’t. What happens is that you get increasingly large 2-colored regions, whose typical size is proportional to the square root of the number of recoloring steps, separated by triples of vertices that use all three colors. Within each 2-colored region, each recoloring step changes one of the two colors to the third color. The 3-colored triples form the boundaries between these regions and move leftwards or rightwards (depending on the ordering of their three colors). When two boundaries moving in opposite directions collide, they annihilate each other, leaving a larger 2-colored region.</p>

<p>I think the easiest way to see this is to use height functions for colorings. As described in <a href="https://11011110.github.io/blog/2019/11/25/reconfiguring-3-colorings.html">my previous post</a>, a height function is a mapping from the vertices to integers (the heights of the vertices), so that taking the height of each vertex mod 3 gives its color, and such that neighboring vertices have heights that differ by . It’s easy to construct these for colorings of the infinite path, again by starting from an arbitrary choice of height for a single arbitrarily-chosen vertex and propagating outwards. More strongly, for infinite bipartite graphs, the existence of height functions is equivalent to the non-existence of certain special graph homomorphisms to a six-cycle, as described for the finite case in my previous post. However in the infinite case the existence of height functions does not ensure the connectivity of the space of 3-colorings; for instance there is no way to change the infinite periodic 3-coloring …0–1–2–0–1–2… into anything else.</p>

<p>In terms of height functions, what’s happening in each recoloring step is that the height increases by two at each of its local minima. You can think of the height function as giving the height of a pile of particles over each vertex; then each recoloring step adds a particle wherever it can sit in place without rolling downhill.</p>

<p style="text-align: center;"><img alt="Particle deposition view of Rule 184" src="https://11011110.github.io/blog/assets/2019/rule-184-deposition.svg"/></p>

<p>The image above is one I drew several years ago for the Wikipedia article on <a href="https://en.wikipedia.org/wiki/Rule_184">cellular automaton rule 184</a>. This cellular automaton has two states per cell (which we might as well think of as 1 and 0), and it acts by repeatedly swapping the states of pairs of consecutive cells containing the pattern 10. In the figure, the 1’s and 0’s translate to pieces of surface boundary that slope downwards or upwards (respectively), so a 10 pattern is a local minimum of the surface, and filling it in gives a 10 instead.</p>

<p>Rule 184 has an amazing variety of seemingly-unrelated interpretations; for instance, you can think of the cells of the automaton as a gridlocked highway, and the cells with 1’s in them as the cars of a traffic jam (perhaps <a href="https://www.latimes.com/california/story/2019-11-27/how-405-freeway-gridlock-became-the-iconic-image-of-l-a-thanksgiving">stuck in traffic for their Thanksgiving Day travels</a>). When a 1 has an open space ahead of it (a 0 cell) it moves forward, and otherwise it stays in place. This seemingly basic model displays a lot of the same features of real traffic such as freely flowing traffic when the total number of vehicles is small but waves of stop-and-go motion when the number of vehicles is high. It forms the basis for many more-sophisticated models of traffic flow.</p>

<p>But it is a different interpretation of Rule 184 that works best for understanding the question I started with, of what happens to a random coloring under recoloring operations. These operations are exactly what happens when you apply Rule 184 to the height function of a random coloring. But you can also view Rule 184 as describing a system of two kinds of particles, left-moving ones (11 patterns) and right-moving ones (00 patterns), separated by empty space (alternating 0’s and 1’s), that annihilate each other when they collide. In terms of the coloring, these particles are just the triples of vertices colored with three colors, and the parts of the cellular automaton with no particles are the 2-colored regions. The uniformly random coloring that we started with has the convenient property that particles of both types are equally likely. A right-moving particle will survive to step  if, in every prefix of the random sequence of particles to the right of it of length proportional to , there are more right-moving particles than left-moving particles. A standard calculation on random walks shows that this survival probability is , and this is also the density of remaining particles after  steps.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/103212704886997345">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2019-11-27T16:11:00Z</updated>
    <published>2019-11-27T16:11:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-11-28T00:29:07Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/171</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/171" rel="alternate" type="text/html"/>
    <title>TR19-171 |  Improved bounds on the AN-complexity of multilinear functions | 

	Oded Goldreich</title>
    <summary>We consider arithmetic circuits with arbitrary large (multi-linear) gates for computing multi-linear functions. An adequate complexity measure for such circuits is the maximum between the arity of the gates and their number. 
This model and the corresponding complexity measure were introduced by Goldreich and Wigderson (ECCC, TR13-043, 2013), and is called the AN-complexity.

The AN-complexity of a multi-linear function yields an upper bound on the size of depth-three Boolean circuits for computing the function, and it is not clear whether or not significantly smaller depth-three Boolean functions exist. Specifically, the depth-three size of Boolean circuits is at most exponential in the AN-complexity of the function. Hence, proving linear lower bounds on the AN-complexity of explicit multi-linear function is a essential step towards proving that depth-three Boolean circuits for these functions requires exponential size.

In this work we present explicit multi-linear functions that require depth-two multi-linear circuits of almost linear AN-complexity. Specifically, for every $\epsilon&gt;0$, we show an explicit $\poly(1/\epsilon)$-linear function $f:\{0,1\}^{\poly(1/\epsilon)\cdot n}\to\{0,1\}$ such that any depth-two circuit (with general multi-linear gates) that computes $f$ must use gates of arity at least $n^{1-\epsilon}$. This improves over a corresponding lower bound of $\tildeOM(n^{2/3})$ that was known for an explicit tri-linear function
(Goldreich and Tal, Computational Complexity, 2018), but leaves open the problem of showing similar AN-complexity lower bounds for multi-linear circuits of larger depth. 

A key aspect in our proof is considering many (extremely skewed) random restrictions, and contrasting the sum of the values of the original function and the circuit (which supposedly computes it) taken over a (carefully chosen) subset of these random restrictions. We show that if the original circuit has too low AN-complexity, then these two sums cannot be equal, which yields a contradiction.</summary>
    <updated>2019-11-27T14:53:19Z</updated>
    <published>2019-11-27T14:53:19Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-11-29T16:20:31Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/170</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/170" rel="alternate" type="text/html"/>
    <title>TR19-170 |  A Quadratic Lower Bound for  Algebraic Branching Programs | 

	Prerona Chatterjee, 

	Mrinal Kumar, 

	Adrian She, 

	Ben Lee Volk</title>
    <summary>We show that any Algebraic Branching Program (ABP) computing the polynomial $\sum_{i = 1}^n x_i^n$ has at least $\Omega(n^2)$ vertices. This improves upon the lower bound of $\Omega(n\log n)$, which follows from the classical result of Baur and Strassen [Str73, BS83], and extends the results by Kumar [Kum19], which showed a quadratic lower bound  for $\text{homogeneous}$ ABPs computing the same polynomial.

Our proof relies on a notion of depth reduction which is reminiscent of similar statements in the context of matrix rigidity, and shows that any small enough ABP computing the polynomial $\sum_{i=1}^n x_i^n$ can be depth reduced to essentially a homogeneous ABP of the same size which computes the polynomial $\sum_{i = 1}^n x_i^n + \varepsilon(\mathbf{x})$, for a structured ``error polynomial'' $\varepsilon(\mathbf{x})$. To complete the proof, we then observe that the lower bound in [Kum19] is robust enough and continues to hold for all polynomials $\sum_{i = 1}^n x_i^n + \varepsilon(\mathbf{x})$, where  $\varepsilon(\mathbf{x})$ has the appropriate structure.</summary>
    <updated>2019-11-27T10:09:19Z</updated>
    <published>2019-11-27T10:09:19Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-11-29T16:20:31Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://agtb.wordpress.com/?p=3448</id>
    <link href="https://agtb.wordpress.com/2019/11/27/youngec-workshop-in-tel-aviv-31-12-19-2-1-20/" rel="alternate" type="text/html"/>
    <title>YoungEC Workshop in Tel-Aviv, 31/12/19-2/1/20</title>
    <summary>The “Young” Workshop on Economics and Computation (YoungEC) will be held in Tel-Aviv University, Israel, during December 31st, 2019 to January 2nd, 2020. The list of speakers includes a small number of established central figures in the field together with a larger number of bright rising stars worldwide. The workshop is now open for registration.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The <a href="https://www.cs.tau.ac.il/~mfeldman/youngec19/index.php">“Young” Workshop on Economics and Computation (YoungEC)</a> will be held in Tel-Aviv University, Israel, during December 31st, 2019 to January 2nd, 2020. The <a href="https://www.cs.tau.ac.il/~mfeldman/youngec19/participants.php">list of speakers</a> includes a small number of established central figures in the field together with a larger number of bright rising stars worldwide.</p>
<p>The workshop is now open for <a href="https://www.cs.tau.ac.il/~mfeldman/youngec19/registration.php">registration</a>.</p></div>
    </content>
    <updated>2019-11-27T08:49:26Z</updated>
    <published>2019-11-27T08:49:26Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>algorithmicgametheory</name>
    </author>
    <source>
      <id>https://agtb.wordpress.com</id>
      <logo>https://secure.gravatar.com/blavatar/52ef314e11e379febf97d1a97547f4cd?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fbuttonw-com.png</logo>
      <link href="https://agtb.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://agtb.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://agtb.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://agtb.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Computation, Economics, and Game Theory</subtitle>
      <title>Turing's Invisible Hand</title>
      <updated>2019-11-29T16:20:37Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/11/27/tenure-track-assistant-professor-at-university-of-victoria-apply-by-december-1-2019/</id>
    <link href="https://cstheory-jobs.org/2019/11/27/tenure-track-assistant-professor-at-university-of-victoria-apply-by-december-1-2019/" rel="alternate" type="text/html"/>
    <title>Tenure-track assistant professor at University of Victoria (apply by December 1, 2019)</title>
    <summary>The Department of Computer Science at the University of Victoria is seeking applicants for two positions at the rank of Assistant Professor with eligibility for tenure and with an anticipated start date of July 1, 2020. We are particularly seeking candidates in the areas of Graphics, Systems, AI and Theory. Website: https://www.uvic.ca/engineering/computerscience/people/employment-opportunities/ Email: search@csc.uvic.ca</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Department of Computer Science at the University of Victoria is seeking applicants for two positions at the rank of Assistant Professor with eligibility for tenure and with an anticipated start date of July 1, 2020. We are particularly seeking candidates in the areas of Graphics, Systems, AI and Theory.</p>
<p>Website: <a href="https://www.uvic.ca/engineering/computerscience/people/employment-opportunities/">https://www.uvic.ca/engineering/computerscience/people/employment-opportunities/</a><br/>
Email: search@csc.uvic.ca</p></div>
    </content>
    <updated>2019-11-27T05:40:09Z</updated>
    <published>2019-11-27T05:40:09Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-11-29T16:20:45Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/11/26/assistant-professor-at-university-of-california-san-diego-apply-by-january-15-2020/</id>
    <link href="https://cstheory-jobs.org/2019/11/26/assistant-professor-at-university-of-california-san-diego-apply-by-january-15-2020/" rel="alternate" type="text/html"/>
    <title>Assistant Professor  at University of California – San Diego (apply by January 15, 2020)</title>
    <summary>The UC San Diego Department of Computer Science and Engineering (CSE) invites applications for multiple tenure-track faculty positions at Assistant Professor rank. The department is looking for exceptional candidates in all areas of Computer Science and Engineering. A Ph.D. or advancement to candidacy in Computer Science &amp; Engineering or related disciplines is required at the […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The UC San Diego Department of Computer Science and Engineering (CSE) invites applications for multiple tenure-track faculty positions at Assistant Professor rank. The department is looking for exceptional candidates in all areas of Computer Science and Engineering. A Ph.D. or advancement to candidacy in Computer Science &amp; Engineering or related disciplines is required at the time of application.</p>
<p>Website: <a href="https://apol-recruit.ucsd.edu/JPF02337">https://apol-recruit.ucsd.edu/JPF02337</a><br/>
Email: nherrera@eng.ucsd.edu</p></div>
    </content>
    <updated>2019-11-26T23:19:25Z</updated>
    <published>2019-11-26T23:19:25Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-11-29T16:20:45Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/11/26/postdoc-at-boston-college-apply-by-january-15-2020/</id>
    <link href="https://cstheory-jobs.org/2019/11/26/postdoc-at-boston-college-apply-by-january-15-2020/" rel="alternate" type="text/html"/>
    <title>Postdoc at Boston College (apply by January 15, 2020)</title>
    <summary>Applications are invited for a postdoc position hosted by Hsin-Hao Su at Boston College. Areas of specific interests include but not limited to distributed graph algorithms, local algorithms, dynamic graph algorithms, gossip algorithms, and MPC algorithms. To apply, please send the materials indicated in the link to Hsin-Hao Su by January 15, 2020. Website: https://sites.google.com/site/distributedhsinhao/postdoc […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Applications are invited for a postdoc position hosted by Hsin-Hao Su at Boston College. Areas of specific interests include but not limited to distributed graph algorithms, local algorithms, dynamic graph algorithms, gossip algorithms, and MPC algorithms.</p>
<p>To apply, please send the materials indicated in the link to Hsin-Hao Su by January 15, 2020.</p>
<p>Website: <a href="https://sites.google.com/site/distributedhsinhao/postdoc">https://sites.google.com/site/distributedhsinhao/postdoc</a><br/>
Email: suhx@bc.edu</p></div>
    </content>
    <updated>2019-11-26T21:08:13Z</updated>
    <published>2019-11-26T21:08:13Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-11-29T16:20:45Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4432</id>
    <link href="https://www.scottaaronson.com/blog/?p=4432" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4432#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4432" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Guest post by Greg Kuperberg: Archimedes’ other principle and quantum supremacy</title>
    <summary xml:lang="en-US">Scott’s Introduction: Happy Thanksgiving! Please join me in giving thanks for the beautiful post below, by friend-of-the-blog Greg Kuperberg, which tells a mathematical story that stretches from the 200s BC all the way to Google’s quantum supremacy result last month. Archimedes’ other principle and quantum supremacy by Greg Kuperberg Note: UC Davis is hiring in […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p><strong>Scott’s Introduction:</strong> Happy Thanksgiving!  Please join me in giving thanks for the beautiful post below, by friend-of-the-blog <a href="https://www.math.ucdavis.edu/~greg/">Greg Kuperberg</a>, which tells a mathematical story that stretches from the 200s BC all the way to Google’s quantum supremacy result last month.</p>



<h2>Archimedes’ other principle and quantum supremacy</h2>



<p>by Greg Kuperberg</p>



<p><strong>Note:</strong> UC Davis is <a href="https://recruit.ucdavis.edu/JPF03248">hiring in CS theory</a>! Scott offered me free ad space if I wrote a guest post, so here we are.  The position is in all areas of CS theory, including QC theory although the search is not limited to that.</p>



<p>In this post, I wear the hat of a pure mathematician in a box provided by Archimedes.  I thus set aside what everyone else thinks is important about Google’s 53-qubit quantum supremacy experiment, that it is a dramatic milestone in quantum computing technology.  That’s only news about the physical world, whose significance pales in comparison to the Platonic world of mathematical objects.  In my happy world, I like quantum supremacy as a demonstration of a beautiful coincidence in mathematics that has been known for more than 2000 years in a special case. The single-qubit case was discovered by Archimedes, duh.  As Scott mentions in <a href="https://www.amazon.com/Quantum-Computing-since-Democritus-Aaronson/dp/0521199565/ref=sr_1_1?keywords=quantum+computing+since+democritus&amp;qid=1574801358&amp;sr=8-1"><em>Quantum Computing Since Democritus</em></a>, Bill Wootters stated the general result in a <a href="https://link.springer.com/article/10.1007/BF01883491">1990 paper</a>, but Wootters credits a <a href="https://link.springer.com/article/10.1007/BF01019475">1974 paper</a> by the Czech physicist Stanislav Sýkora.  I learned of it in the substantially more general context of symplectic geometric that mathematicians developed independently between Sýkora’s prescient paper and Wootters’ more widely known citation.  Much as I would like to clobber you with highly abstract mathematics, I will wait for some other time.</p>



<p>Suppose that you pick a pure state \(|\psi\rangle\) in the Hilbert space \(\mathbb{C}^d\) of a \(d\)-dimensional qudit, and then make many copies and fully measure each one, so that you sample many times from some distribution \(\mu\) on the \(d\) outcomes.  You can think of such a distribution \(\mu\) as a classical randomized state on a digit of size \(d\).  The set of all randomized states on a \(d\)-digit makes a \((d-1)\)-dimensional simplex \(\Delta^{d-1}\) in the orthant \(\mathbb{R}_{\ge 0}^d\).  The coincidence is that if \(|\psi\rangle\) is uniformly random in the unit sphere in \(\mathbb{C}^d\), then \(\mu\) is uniformly random in \(\Delta^{d-1}\).  I will call it the Born map, since it expresses the Born rule of quantum mechanics that amplitudes yield probabilities.  Here is a diagram of the Born map of a qutrit, except with the laughable simplification of the 5-sphere in \(\mathbb{C}^3\) drawn as a 2-sphere. </p>



<figure class="wp-block-image"><img alt="" src="https://www.scottaaronson.com/f1-qutrit.png"/></figure>



<p>If you pretend to be a bad probability student, then you might not be surprised by this coincidence, because you might suppose that all probability distributions are uniform other than treacherous exceptions to your intuition.  However, the principle is certainly not true for a “rebit” (a qubit with real amplitudes) or for higher-dimensional “redits.”  With real amplitudes, the probability density goes to infinity at the sides of the simplex \(\Delta^{d-1}\) and is even more favored at the corners.  It also doesn’t work for mixed qudit states; the projection then favors the middle of \(\Delta^{d-1}\). </p>



<h3>Archimedes’ theorem</h3>



<p> The theorem of Archimedes is that a natural projection from the unit sphere to a circumscribing vertical cylinder preserves area.  The projection is the second one that you might think of: Project radially from a vertical axis rather than radially in all three directions.  Since Archimedes was a remarkably prescient mathematician, he was looking ahead to the Bloch sphere of pure qubit states \(|\psi\rangle\langle\psi|\) written in density operator form.  If you measure \(|\psi\rangle\langle\psi|\) in the computational basis, you get a randomized bit state \(\mu\) somewhere on the interval from guaranteed 0 to guaranteed 1. </p>



<figure class="wp-block-image"><img alt="" src="https://www.scottaaronson.com/f2-bloch.png"/></figure>



<p>This transformation from a quantum state to a classical randomized state is a linear projection to a vertical axis.  It is the same as Archimedes’ projection, except without the angle information.  It doesn’t preserve dimension, but it does preserve measure (area or length, whatever) up to a factor of \(2\pi\).  In particular, it takes a uniformly random \(|\psi\rangle\langle\psi|\) to a uniformly random \(\mu\).</p>



<p>Archimedes’ projection is also known as the Lambert cylindrical map of the world.  This is the map that squishes Greenland along with the top of North America and Eurasia to give them proportionate area. </p>



<figure class="wp-block-image"><img alt="" src="https://www.scottaaronson.com/f3-lambert.jpg"/></figure>



<p>(I forgive Lambert if he didn’t give prior credit to Archimedes.  There was no Internet back then to easily find out who did what first.)  Here is a calculus-based proof of Archimedes’ theorem: In spherical coordinates, imagine an annular strip on the sphere at a polar angle of \(\theta\).  (The polar angle is the angle from vertical in spherical coordinates, as depicted in red in the Bloch sphere diagram.)   The strip has a radius of \(\sin\theta\), which makes it shorter than its unit radius friend on the cylinder.  But it’s also tilted from vertical by an angle of \(\frac{\pi}2-\theta\), which makes it wider by a factor of \(1/(\sin \theta)\) than the height of its projection onto the \(z\) axis.  The two factors exactly cancel out, making the area of the strip exactly proportional to the length of its projection onto the \(z\) axis.  This is a coincidence which is special to the 2-sphere in 3 dimensions.  As a corollary, we get that the surface area of a unit sphere is \(4\pi\), the same as an open cylinder with radius 1 and height 2.  If you want to step through this in even more detail, Scott mentioned to me an <a href="https://www.youtube.com/watch?v=GNcFjFmqEc8">action video</a> which is vastly spiffier than anything that I could ever make.</p>



<p>The projection of the Bloch sphere onto an interval also shows what goes wrong if you try this with a rebit.  The pure rebit states — again expressed in density operator form \(|\psi\rangle\langle\psi|\) are a great circle in the Bloch sphere.  If you linearly project a circle onto an interval, then the length of the circle is clearly bunched up at the ends of the interval and the projected measure on the interval is not uniform. </p>



<h3>Sýkora’s generalization</h3>



<p> It is a neat coincidence that the Born map of a qubit preserves measure, but a proof that relies on Archimedes’ theorem seems to depend on the special geometry of the Bloch sphere of a qubit.  That the higher-dimensional Born map also preserves measure is downright eerie.  Scott challenged me to write an intuitive explanation.  I  remembered two different (but similar) proofs, neither of which is original to me. Scott and I disagree as to which proof is nicer.</p>



<p>As a first step of the first proof, it is easy to show that the Born map \(p = |z|^2\) for a single amplitude \(z\) preserves measure as a function from the complex plane \(\mathbb{C}\) to the ray \(\mathbb{R}_{\ge 0}\).  The region in the complex numbers \(\mathbb{C}\) where the length of \(z\) is between \(a\) and \(b\), or \(a \le |z| \le b\), is \(\pi(b^2 – a^2)\).  The corresponding interval for the probability is \(a^2 \le p \le b^2\), which thus has length \(b^2-a^2\).  That’s all, we’ve proved it!  More precisely, the area of any circularly symmetric region in \(\mathbb{C}\) is \(\pi\) times the length of its projection onto \(\mathbb{R}_{\ge 0}\). </p>



<figure class="wp-block-image"><img alt="" src="https://www.scottaaronson.com/f4-washer.png"/></figure>



<p>The second step is to show the same thing for the Born map from the \(d\)-qudit Hilbert space \(\mathbb{C}^d\) to the \(d\)-digit orthant \(\mathbb{R}_{\ge 0}^d\), again without unit normalization.  It’s also measure-preserving, up to a factor of \(\pi^d\) this time, because it’s the same thing in each coordinate separately.  To be precise, the volume ratio holds for any region in \(\mathbb{C}^d\) that is invariant under separately rotating each of the \(d\) phases. (Because you can approximate any such region with a union of products of thin annuli.)</p>



<p>The third and final step is the paint principle for comparing surface areas.  If you paint the hoods of two cars with the same thin layer of paint and you used the same volume of paint for each one, then you can conclude that the two car hoods have nearly same area.  In our case, the Born map takes the region \[ 1 \le |z_0|^2 + |z_1|^2 + \cdots + |z_{d-1}|^2 \le 1+\epsilon \] in \(\mathbb{C}^d\) to the region \[ 1 \le p_0 + p_1 + \cdots + p_{d-1} \le 1+\epsilon \] in the orthant \(\mathbb{R}_{\ge 0}^d\).  The former is the unit sphere \(S^{2d-1}\) in \(\mathbb{C}^d\) painted to a thickness of roughly \(\epsilon/2\).  The latter is the probability simplex \(\Delta^{n-1}\) painted to a thickness of exactly \(\epsilon\). Taking the limit \(\epsilon \to 0\), the Born map from \(S^{2d-1}\) to \(\Delta^{n-1}\) preserves measure up to a factor of \(2\pi^n\).</p>



<p>You might wonder “why” this argument works even if you accept that it does work.  The key is that the exponent 2 appears in two different ways: as the dimension of the complex numbers, and as the exponent used to set probabilities and define spheres.  If we try the same argument with real amplitudes, then the volume between “spheres” of radius \(a\) and \(b\) is just \(2(b-a)\), which does not match the length \(b^2-a^2\).  The Born map for a single real amplitude is the parabola \(p = x^2\), which clearly distorts length since it is not linear.  The higher-dimensional real Born map similarly distorts volumes, whether or not you restrict to unit-length states.</p>



<p>If you’re a bitter-ender who still wants Archimedes’ theorem for real amplitudes, then you might consider the variant formula \(p = |x|\) to obtain a probability \(p\) from a “quantum amplitude” \(x\).  Then the “Born” map does preserve measure, but for the trivial reason that \(x = \pm p\) is not really a quantum amplitude, it is a probability with a vestigial sign.  Also the unit “sphere” in \(\mathbb{R}^d\) is not really a sphere in this theory, it is a hyperoctahedron.  The only “unitary” operators that preserve the unit hyperoctahedron are signed permutation matrices.  You can only use them for reversible classical computing or symbolic dynamics; they don’t have the strength of true quantum computing or quantum mechanics.</p>



<p>The fact that the Born map preserves measure also yields a bonus calculation of the volume of the unit ball in \(2d\) real dimensions, if we interpret that as \(d\) complex dimensions.  The ball \[ |z_0|^2 + |z_1|^2 + \cdots + |z_{d-1}|^2 \le 1 \] in \(\mathbb{C}^d\) is sent to a different simplex \[ p_0 + p_1 + \cdots + p_{d-1} \le 1 \] in \(\mathbb{R}_{\ge 0}^d\).  If we recall that the volume of a \(d\)-dimensional pyramid is \(\frac1d\) times base times height and calculate by induction on \(d\), we get that this simplex has volume \(\frac1{d!}\).  Thus, the volume of the \(2d\)-dimensional unit ball is \(\frac{\pi^d}{d!}\).</p>



<p>You might ask whether the volume of a \(d\)-dimensional unit ball is always \(\frac{\pi^{d/2}}{(d/2)!}\) for both \(d\) even and odd.  The answer is yes if we interpret factorials using the gamma function formula \(x! = \Gamma(x+1)\) and look up that \(\frac12! = \Gamma(\frac32) = \frac{\sqrt{\pi}}2\).  The gamma function was discovered by Euler as a solution to the question of defining fractional factorials, but the notation \(\Gamma(x)\) and the cumbersome shift by 1 is due to Legendre.  Although Wikipedia says that no one knows why Legendre defined it this way, I wonder if his goal was to do what the Catholic church later did for itself in 1978: It put a Pole at the origin.</p>



<p>(Scott wanted to censor this joke. In response, I express my loyalty to my nation of birth by quoting the opening of the Polish national anthem: “Poland has not yet died, so long as we still live!”  I thought at first that Stanislav Sýkora is Polish since Stanisław and Sikora are both common Polish names, but his name has Czech spelling and he is Czech. Well, the Czechs are cool too.)</p>



<p>Sýkora’s 1974 proof of the generalized Archimedes’ theorem is different from this one.  He calculates multivariate moments of the space of unit states \(S^{2d-1} \subseteq \mathbb{C}^d\), and confirms that they match the moments in the probability simplex \(\Delta^{d-1}\).  There are inevitably various proofs of this result, and I will give another one. </p>



<h3>Another proof, and quantum supremacy</h3>



<p>There is a well-known and very useful algorithm to generate a random point on the unit sphere in either \(\mathbb{R}^d\) or \(\mathbb{C}^d\), and a similar algorithm to generate a random point in a simplex.  In the former algorithm, we make each real coordinate \(x\) into an independent Gaussian random variable with density proportional to \(e^{-x^2}\;dx\), and then rescale the result to unit length.  Since the exponents combine as \[ e^{-x_0^2}e^{-x_1^2}\cdots e^{-x_{d-1}^2} =       e^{-(x_0^2 + x_1^2 + \cdots + x_{d-1}^2)}, \] we learn that the total exponent is spherically symmetric.  Therefore after rescaling, the result is a uniformly random point on the unit sphere \(S^{d-1} \subseteq \mathbb{R}^d\).  Similarly, the other algorithm generates a point in the orthant \(\mathbb{R}_{\ge 0}^d\) by making each real coordinate \(p \ge 0\) an independent random variable with exponential distribution \(e^{-p}\;dp\).  This time we rescale the vector until its sum is 1.  This algorithm likewise produces a uniformly random point in the simplex \(\Delta^{d-1} \subseteq \mathbb{R}_{\ge 0}^d\) because the total exponent of the product \[ e^{-p_0}e^{-p_1}\cdots e^{-p_{d-1}} =       e^{-(p_0 + p_1 + \cdots + p_{d-1})} \] only depends on the sum of the coordinates.  Wootters describes both of these algorithms in his 1990 paper, but instead of relating them to give his own proof of the generalized Archimedes’ theorem, he cites Sýkora.</p>



<p>The gist of the proof is that the Born map takes the Gaussian algorithm to the exponential algorithm.  Explicitly, the Gaussian probability density for a single complex amplitude \[ z = x+iy = re^{i\theta} \] can be converted from Cartesian to polar coordinate as follows: \[ \frac{e^{-|z|^2}\;dx\;dy}{\pi} = \frac{e^{-r^2}r\;dr\;d\theta}{\pi}. \] I have included the factor of \(r\) that is naturally present in an area integral in polar coordinates.  We will need it, and it is another way to see that the theorem relies on the fact that the complex numbers are two-dimensional.  To complete the proof, we substitute \(p = r^2\) and remember that \(dp = 2r\;dr\), and then integrate over \(\theta\) (trivially, since the integrand does not depend on \(\theta\)).  The density simplifies to \(e^{-p}\;dp\), which is exactly the exponential distribution for a real variable \(p \ge 0\).  Since the Born map takes the Gaussian algorithm to the exponential algorithm, and since each algorithm produces a uniformly random point, the Born map must preserve uniform measure.  (Scott likes this proof better because it is algorithmic, and because it is probabilistic.)</p>



<p>Now about quantum supremacy.  You might think that a random chosen quantum circuit on \(n\) qubits produces a nearly uniformly random quantum state \(|\psi\rangle\) in their joint Hilbert space, but it’s not quite not that simple.  When \(n=53\), or otherwise as \(n \to \infty\), a manageable random circuit is not nearly creative enough to either reach or approximate most of the unit states in the colossal Hilbert space of dimension \(d = 2^n\).  The state \(|\psi\rangle\) that you get from (say) a polynomial-sized circuit resembles a fully random state in various statistical and computational respects, both proven and conjectured.  As a result, if you measure the qubits in the computational basis, you get a randomized state on \(n\) bits that resembles a uniformly random point in \(\Delta^{2^n-1}\).</p>



<p>If you choose \(d\) probabilities, and if each one is an independent exponential random variable, then the law of large numbers says that the sum (which you use for rescaling) is close to \(d\) when \(d\) is large. When \(d\) is really big like \(2^{53}\), a histogram of the probabilities of the bit strings of a supremacy experiment looks like an exponential curve \(f(p) \propto e^{-pd}\).  In a sense, the statistical distribution of the bit strings is almost the same almost every time, independent of which random quantum circuit you choose to generate them.  The catch is that the position of any given bit string does depend on the circuit and is highly scrambled.  I picture it in my mind like this: </p>



<figure class="wp-block-image"><img alt="" src="https://www.scottaaronson.com/f5-samples.png"/></figure>



<p>

It is thought to be computationally intractable to calculate where each bit string lands on this exponential curve, or even where just one of them does.  (The exponential curve is attenuated by noise in the actual experiment, but it’s the same principle.)  That is one reason that random quantum circuits are supreme.</p>



<p/></div>
    </content>
    <updated>2019-11-26T20:50:50Z</updated>
    <published>2019-11-26T20:50:50Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Quantum"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2019-11-27T22:08:42Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/11/26/postdoctoral-fellowships-at-umass-amherst-apply-by-december-1-2019/</id>
    <link href="https://cstheory-jobs.org/2019/11/26/postdoctoral-fellowships-at-umass-amherst-apply-by-december-1-2019/" rel="alternate" type="text/html"/>
    <title>Postdoctoral Fellowships at UMass Amherst (apply by December 1, 2019)</title>
    <summary>The UMass Amherst TRIPODS Institute for Theoretical Foundations of Data Science invites applications for postdoctoral fellowships. Research areas of interest include: algorithms and computational models for processing massive data sets; statistical performance and data acquisition in interactive data collection; model robustness, approximate inference and uncertainty quantification. Website: https://www.cics.umass.edu/job/postdoctoral-research-associate-tripods-institute-theoretical-foundations-data-science Email: mcgregor@cs.umass.edu</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The UMass Amherst TRIPODS Institute for Theoretical Foundations of Data Science invites applications for postdoctoral fellowships. Research areas of interest include: algorithms and computational models for processing massive data sets; statistical performance and data acquisition in interactive data collection; model robustness, approximate inference and uncertainty quantification.</p>
<p>Website: <a href="https://www.cics.umass.edu/job/postdoctoral-research-associate-tripods-institute-theoretical-foundations-data-science">https://www.cics.umass.edu/job/postdoctoral-research-associate-tripods-institute-theoretical-foundations-data-science</a><br/>
Email: mcgregor@cs.umass.edu</p></div>
    </content>
    <updated>2019-11-26T16:48:00Z</updated>
    <published>2019-11-26T16:48:00Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-11-29T16:20:45Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2019/11/26/quantum-computer-science-school-2020/</id>
    <link href="https://cstheory-events.org/2019/11/26/quantum-computer-science-school-2020/" rel="alternate" type="text/html"/>
    <title>Quantum Computer Science School 2020</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">January 14-16, 2020 University of Technology Sydney, Australia http://conference.iiis.tsinghua.edu.cn/QCSS2020/ The Quantum Computer Science School 2020 will consist of three days of lectures and academic activities, targeting at senior undergraduates and graduate students in Australian and Asian universities. The lecturers are Mingsheng Ying, Luming Duan, Michael Bremner, Troy Lee, and Ran Duan, and the topics include … <a class="more-link" href="https://cstheory-events.org/2019/11/26/quantum-computer-science-school-2020/">Continue reading <span class="screen-reader-text">Quantum Computer Science School 2020</span></a></div>
    </summary>
    <updated>2019-11-26T01:06:34Z</updated>
    <published>2019-11-26T01:06:34Z</published>
    <category term="school"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2019-11-29T16:21:27Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/11/25/reconfiguring-3-colorings</id>
    <link href="https://11011110.github.io/blog/2019/11/25/reconfiguring-3-colorings.html" rel="alternate" type="text/html"/>
    <title>Reconfiguring 3-colorings</title>
    <summary>I talked briefly about how to get from one 3-coloring of a grid graph to another by changing one vertex color at a time, in a recent blog post about analogous problems for origami folding patterns. It turns out that this problem of reconfiguring 3-colorings has been treated in much greater generality in the 2007 doctoral dissertation of Luis Cereceda, “Mixing graph colourings”, as I discovered when I read the dissertation in the process of writing a new Wikipedia article on Cereceda’s conjecture, the conjecture that the space of -colorings of -degenerate graphs (under moves that change the color of one vertex at a time) has at most quadratic diameter. Here’s an illustration from the new article showing the space of 3-colorings of a path graph:</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I talked briefly about how to get from one 3-coloring of a grid graph to another by changing one vertex color at a time, in <a href="https://11011110.github.io/blog/2019/10/16/from-one-fold.html">a recent blog post about analogous problems for origami folding patterns</a>. It turns out that this problem of reconfiguring 3-colorings has been treated in much greater generality in the 2007 doctoral dissertation of Luis Cereceda, “<a href="http://etheses.lse.ac.uk/131/">Mixing graph colourings</a>”, as I discovered when I read the dissertation in the process of writing a new Wikipedia article on <a href="https://en.wikipedia.org/wiki/Cereceda%27s_conjecture">Cereceda’s conjecture</a>, the conjecture that the space of -colorings of -degenerate graphs (under moves that change the color of one vertex at a time) has at most quadratic diameter. Here’s an illustration from the new article showing the space of 3-colorings of a path graph:</p>

<p style="text-align: center;"><img alt="The space of 3-colorings of a path graph" src="https://11011110.github.io/blog/assets/2019/path-3-colorings.svg"/></p>

<p>Cereceda proved that the following properties of a graph are equivalent:</p>

<ul>
  <li>It has a connected space of 3-colorings.</li>
  <li>Every 3-coloring has a height function.</li>
  <li>It is bipartite and is not “pinchable” to a 6-cycle</li>
</ul>

<p>If we consider the three colors to be used for 3-colorings to be the numbers 0, 1, and 2 (mod 3) then a height function can be defined as an assignment of integers (not mod 3) to the vertices, such that taking them mod 3 produces the given coloring, and such that adjacent vertices have heights that differ by . If it exists for a given coloring, it can be constructed easily by choosing the height of one vertex arbitrarily and then using the  requirement for adjacent heights to propagate this choice to neighbors in the graph until every vertex has a height. What can go wrong is that this propagation somehow leaves two adjacent vertices with heights that are too far apart. For instance, if the colors around a 6-cycle have the cyclic order 0–1–2–0–1–2 then you will come back to the start six units higher than you started.</p>

<p>Continuing to explain the terms in Cereceda’s equivalence, I think the 6-cycle pinchability condition is most easily explained in terms of <a href="https://en.wikipedia.org/wiki/Graph_homomorphism">graph homomorphisms</a>, maps from one graph to another that preserve adjacency. Consider a 6-cycle, 3-colored 0–1–2–0–1–2. It is also a bipartite graph, 2-colored black–white–black–white–black–white, with one vertex for each combination of colors in the 3-coloring and the 2-coloring. If you have any 3-coloring of a bipartite graph, you can map it onto the 6-cycle so that both the 3-coloring and the bipartition are preserved. If your 3-coloring does not have a height function (that is, there is a cycle that, when you propagate heights around it, comes back to its start at a different height) then the winding number of this cycle, as it maps around the 6-cycle, will tell you the difference in heights from start to end (divided by six). So a coloring without a height function gives you a homomorphism to the 6-cycle in which some cycle has nonzero winding number. On the other hand, if you have such a homomorphism, you can lift the colors from the 6-cycle back to the starting graph to give you a coloring without a height function. Cereceda’s “pinching” operations are a special type of homomorphism in which vertices at distance two from each other are repeatedly merged. Not every homomorphism comes from pinching in this way (with pinches you can only map a 12-cycle once around a 6-cycle, not twice around, for instance) so the proof that pinching homomorphisms exist for graphs without height functions is a little more complicated.</p>

<p>It’s possible to construct in polynomial time the shortest sequence of color changes to go from one 3-coloring to another, whenever the space of colorings is connected. Cereceda almost finds this algorithm but misses a small trick and ends up stating its existence only as a conjecture. As I explained in my previous post, if you choose the correct offset for the height functions of the two colorings, you can find this shortest sequence by greedily changing the color at a vertex of one color where the current height is farthest from the goal height. The trick that Cereceda misses is that if you don’t know the correct offset between the two height functions, you can just try them all (or more quickly use a median algorithm to find the optimal offset and the distance between colorings in linear time).</p>

<p>Unfortunately, as Cereceda proved, testing pinchability to a 6-cycle is -complete and therefore testing the connectivity of the space of 3-colorings (and the applicability of the height-based shortest reconfiguration algorithm) is -complete. For instance, I’m pretty sure the 10-vertex Möbius ladder shown below has height functions for all its 3-colorings, but I don’t know of an elegant way to prove this, and -completeness suggests that not all graphs have elegant proofs for this. This graph has lots of 6-cycles, for instance formed by any diagonal and the path around the outer cycle connecting its two endpoints. But trying to map the whole graph to a 6-cycle by folding it flat across a diagonal doesn’t work because it would map some edges to non-edges, and nothing else seems to work either.</p>

<p style="text-align: center;"><img alt="A 10-vertex M&#xF6;bius ladder" src="https://11011110.github.io/blog/assets/2019/M%C3%B6bius-ladder-10.svg"/></p>

<p>To save this post from being content-free, I want to describe a more easily recognized family of graphs that meets Cereceda’s criterion, and does have height functions for all its 3-colorings (so we can quickly find the shortest reconfiguration sequences in these graphs). It is the class of graphs in which the <a href="https://en.wikipedia.org/wiki/Cycle_space">cycle space</a> is generated by the 4-cycles, or in other words the graphs in which there exists a <a href="https://en.wikipedia.org/wiki/Cycle_basis">cycle basis</a> consisting only of 4-cycles. These graphs can be recognized simply by doing some mod-2 linear algebra to test whether the space generated by the 4-cycles has the same dimension as the cycle space. For instance, the Möbius ladder above is not in this class because the dimension of its cycle space (the number of edges beyond the ones in a spanning forest) is six but its number of 4-cycles (the cycles between two consecutive diagonals) is only five. Despite this example, the graphs generated by 4-cycles include a lot of natural classes of graphs that we might want to reconfigure 3-colorings of:</p>

<ul>
  <li>Trees</li>
  <li>Rectangular grid graphs and higher-dimensional hyperrectangular grid graphs</li>
  <li><a href="https://en.wikipedia.org/wiki/Squaregraph">Squaregraphs</a></li>
  <li>The dual graphs of simple line arrangements</li>
  <li>Complete bipartite graphs</li>
  <li><a href="https://en.wikipedia.org/wiki/Chordal_bipartite_graph">Chordal bipartite graphs</a></li>
  <li>The <a href="https://en.wikipedia.org/wiki/Cartesian_product_of_graphs">Cartesian products</a> of other graphs generated by 4-cycles</li>
</ul>

<p>To prove that Cartesian products preserve the property of being generated by 4-cycles, consider any cycle  in the product graph; we want to represent it as a mod-2 sum of 4-cycles. If two consecutive edges of  come from the two different factors, then the product of these edges is a 4-cycle, and adding this 4-cycle to  swaps the order of the two edges within . By repeated swaps we can segregate all the edges from the two factors from each other, changing  into two cycles, one from each factor, that meet at a common vertex. Then we can represent the two cycles separately within the two factors.</p>

<p>It’s straightforward to see that when 4-cycles generate the -homology of a graph, then height functions always exist, because the height difference around any cycle is the sum of the height differences of the 4-cycles generating it, which are all zero. But here by using the binary cycle space we’re looking at the -homology, which might be a different thing. There could be graphs whose -homology is generated by 4-cycles but whose -homology isn’t. For instance I think that adding one bipartite edge to the 10-vertex Möbius ladder produces an example of this phenomenon. So we need a proof that -homology is good enough. Or in simpler terms, when the cycle space is generated by 4-cycles, all 3-colorings have height functions.</p>

<p>We’ll prove this by contradiction, so let’s suppose that we have the smallest possible counterexample. That is, we have a graph , a 3-coloring of , and a cycle  in , such that the cycle space of  is generated by 4-cycles but going around  using the  rule to propagate heights produces a different height than you started with. By “smallest” I mean first, that  is as short as possible, second, that for that length of  the rest of  has as few vertices as possible, and third, that the number of 4-cycles in the representation of  is as small as possible.</p>

<p>Then  cannot have any chords, because if it did then a chord plus one of the two segments of  connecting the chord endpoints would form a shorter cycle with the same inconsistent heights. Because we are assuming that  is generated by 4-cycles, consider any set  of 4-cycles whose sum is . That is, each edge of  appears an odd number of times in cycles of , and each other edge of  appears an even number of times (possibly zero). Each 4-cycle in  must have a coloring of the form ––– or ––– for some colors , , and . If at least one of the two -colored vertices does not belong to , form a smaller graph  by merging these two -colored vertices. This merger does not change  or the coloring, so  stays a bad cycle. And it doesn’t change the property of  that it is generated by 4-cycles, because any cycle in the merged graph can be lifted to a cycle in the unmerged graph (possibly passing through –– in the merged 4-cycle and possibly not simple), represented by 4-cycles in  itself, and then merged back down to get a representation in the smaller graph. But because we’re assuming  was the smallest possible counterexample, this shrinkage can’t happen, so all of the 4-cycles in  have both -vertices in .</p>

<p>Now if we have a 4-cycle with two -vertices in , at least one of the other two vertices does not belong to , because  must be longer than four edges (else it would not have a bad coloring) and we’ve already ruled out the possibility that  has the chords that would be needed to make a 4-cycle using vertices only from . Let  be this vertex outside of , so we have a path –– connecting the two -vertices in . One of two things can happen: First, the two -vertices might only be two units apart in . But then, replacing the two-edge path between them by the path through  produces a new bad cycle of the same length, in the same graph , representable by a smaller set of 4-cycles. This contradicts our choice of  and  as being the smallest possible counterexample. Second, when the two -vertices are farther apart in , there are two cycles formed by path –– and by one of the two paths in  connecting the same two -vertices. Both of these cycles are shorter than , and at least one of them continues to have a bad coloring. So again we have found a smaller counterexample and a contradiction.</p>

<p>This case analysis leading in all cases to a contradiction shows that a smallest counterexample cannot exist, and therefore that all graphs generated by 4-cycles have height functions for all of their 3-colorings.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/103202898221719422">Discuss on Mastodon</a>; see also <a href="https://11011110.github.io/blog/2010/09/12/rapid-mixing-for.html">an earlier post on reconfiguring 3-colorings of cycles using stronger moves</a>; edited 2019-11-27 to correct rectraction vs pinchability in Cereceda’s characterization)</p></div>
    </content>
    <updated>2019-11-25T22:24:00Z</updated>
    <published>2019-11-25T22:24:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-11-28T00:29:07Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/11/25/postdoctoral-at-yale-university-apply-by-december-20-2019/</id>
    <link href="https://cstheory-jobs.org/2019/11/25/postdoctoral-at-yale-university-apply-by-december-20-2019/" rel="alternate" type="text/html"/>
    <title>POSTDOCTORAL at YALE UNIVERSITY (apply by December 20, 2019)</title>
    <summary>Applications are solicited for multiple postdoctoral positions at Yale in Algorithms, Optimization, Sampling, and Fairness. The positions are expected to start in Fall 2020 but can start earlier. Applicants should have their CV, research statement, and three letters emailed directly to nisheeth.vishnoi@gmail.com. Applications completed by December 20, 2019, will receive full consideration. Website: http://cs.yale.edu/homes/vishnoi/Positions.html Email: […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Applications are solicited for multiple postdoctoral positions at Yale in Algorithms, Optimization, Sampling, and Fairness. The positions are expected to start in Fall 2020 but can start earlier. Applicants should have their CV, research statement, and three letters emailed directly to nisheeth.vishnoi@gmail.com. Applications completed by December 20, 2019, will receive full consideration.</p>
<p>Website: <a href="http://cs.yale.edu/homes/vishnoi/Positions.html">http://cs.yale.edu/homes/vishnoi/Positions.html</a><br/>
Email: nisheeth.vishnoi@gmail.com</p></div>
    </content>
    <updated>2019-11-25T15:05:09Z</updated>
    <published>2019-11-25T15:05:09Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-11-29T16:20:45Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://theorydish.blog/?p=1539</id>
    <link href="https://theorydish.blog/2019/11/24/motwani-postdoctoral-fellowship-2/" rel="alternate" type="text/html"/>
    <title>Motwani Postdoctoral Fellowship</title>
    <summary>The theory group at Stanford invites applications for the Motwani postdoctoral fellowship in theoretical computer science. Information and application instructions below. Applications will be accepted until the positions are filled, but review of applicants will begin after Dec 15. Website: https://academicjobsonline.org/ajo/jobs/15578 Email: theory.stanford@gmail.com</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The theory group at Stanford invites applications for the Motwani postdoctoral fellowship in theoretical computer science. Information and application instructions below.</p>
<p>Applications will be accepted until the positions are filled, but review of applicants will begin after Dec 15.</p>
<p>Website: <a href="https://academicjobsonline.org/ajo/jobs/15578">https://academicjobsonline.org/ajo/jobs/15578</a><br/>
Email: theory.stanford@gmail.com</p></div>
    </content>
    <updated>2019-11-25T00:02:30Z</updated>
    <published>2019-11-25T00:02:30Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Omer Reingold</name>
    </author>
    <source>
      <id>https://theorydish.blog</id>
      <logo>https://theorydish.files.wordpress.com/2017/03/cropped-nightdish1.jpg?w=32</logo>
      <link href="https://theorydish.blog/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://theorydish.blog" rel="alternate" type="text/html"/>
      <link href="https://theorydish.blog/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://theorydish.blog/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Stanford's CS Theory Research Blog</subtitle>
      <title>Theory Dish</title>
      <updated>2019-11-29T16:21:28Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/11/25/postdoctoral-position-in-computational-social-choice-at-university-of-toronto-apply-by-december-15-2019/</id>
    <link href="https://cstheory-jobs.org/2019/11/25/postdoctoral-position-in-computational-social-choice-at-university-of-toronto-apply-by-december-15-2019/" rel="alternate" type="text/html"/>
    <title>Postdoctoral position in Computational Social Choice at University of Toronto (apply by December 15, 2019)</title>
    <summary>Postdoctoral position beginning in Fall 2020; fellow will work with Prof. Nisarg Shah on topics such as (but not limited to): computational social choice, fairness and incentives in machine learning, algorithmic game theory, and mechanism design. Applicants should have (prior to starting) a PhD in computer science, economics, operations research, or a related field. Website: […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Postdoctoral position beginning in Fall 2020; fellow will work with Prof. Nisarg Shah on topics such as (but not limited to): computational social choice, fairness and incentives in machine learning, algorithmic game theory, and mechanism design. Applicants should have (prior to starting) a PhD in computer science, economics, operations research, or a related field.</p>
<p>Website: <a href="https://www.cs.toronto.edu/theory/positions.html">https://www.cs.toronto.edu/theory/positions.html</a><br/>
Email: nisarg@cs.toronto.edu</p></div>
    </content>
    <updated>2019-11-25T00:01:22Z</updated>
    <published>2019-11-25T00:01:22Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-11-29T16:20:45Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/11/24/postdocs-at-university-of-toronto-apply-by-december-15-2019/</id>
    <link href="https://cstheory-jobs.org/2019/11/24/postdocs-at-university-of-toronto-apply-by-december-15-2019/" rel="alternate" type="text/html"/>
    <title>Postdocs at University of Toronto (apply by December 15, 2019)</title>
    <summary>The theory group at the University of Toronto anticipates up to three postdoctoral positions beginning September 2020. We seek candidates from all areas of theoretical computer science including algorithms, complexity theory, cryptography, differential privacy, distributed computing, graph theory, quantum computing, and theoretical aspects of machine learning. Website: https://www.cs.toronto.edu/theory/positions.html Email: hyuen@cs.toronto.edu</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The theory group at the University of Toronto anticipates up to three postdoctoral positions beginning September 2020. We seek candidates from all areas of theoretical computer science including algorithms, complexity theory, cryptography, differential privacy, distributed computing, graph theory, quantum computing, and theoretical aspects of machine learning.</p>
<p>Website: <a href="https://www.cs.toronto.edu/theory/positions.html">https://www.cs.toronto.edu/theory/positions.html</a><br/>
Email: hyuen@cs.toronto.edu</p></div>
    </content>
    <updated>2019-11-24T23:59:18Z</updated>
    <published>2019-11-24T23:59:18Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-11-29T16:20:45Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/11/24/motwani-postdoctoral-fellowship-at-stanford-computer-science-apply-by-december-15-2019/</id>
    <link href="https://cstheory-jobs.org/2019/11/24/motwani-postdoctoral-fellowship-at-stanford-computer-science-apply-by-december-15-2019/" rel="alternate" type="text/html"/>
    <title>Motwani Postdoctoral Fellowship at Stanford Computer Science (apply by December 15, 2019)</title>
    <summary>The theory group at Stanford invites applications for the Motwani postdoctoral fellowship in theoretical computer science. Information and application instructions below. Applications will be accepted until the positions are filled, but review of applicants will begin after Dec 15. Website: https://academicjobsonline.org/ajo/jobs/15578 Email: theory.stanford@gmail.com</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The theory group at Stanford invites applications for the Motwani postdoctoral fellowship in theoretical computer science. Information and application instructions below.</p>
<p>Applications will be accepted until the positions are filled, but review of applicants will begin after Dec 15.</p>
<p>Website: <a href="https://academicjobsonline.org/ajo/jobs/15578">https://academicjobsonline.org/ajo/jobs/15578</a><br/>
Email: theory.stanford@gmail.com</p></div>
    </content>
    <updated>2019-11-24T23:23:27Z</updated>
    <published>2019-11-24T23:23:27Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-11-29T16:20:45Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/169</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/169" rel="alternate" type="text/html"/>
    <title>TR19-169 |  On Exponential-Time Hypotheses, Derandomization, and Circuit Lower Bounds | 

	Roei Tell, 

	Lijie Chen, 

	Ron Rothblum, 

	Eylon Yogev</title>
    <summary>The Exponential-Time Hypothesis ($ETH$) is a strengthening of the $\mathcal{P} \neq \mathcal{NP}$ conjecture, stating that $3\text{-}SAT$ on $n$ variables cannot be solved in time $2^{\epsilon\cdot n}$, for some $\epsilon&gt;0$. In recent years, analogous hypotheses that are ``exponentially-strong'' forms of other classical complexity conjectures (such as $\mathcal{NP}\not\subseteq\mathcal{BPP}$ or $co\text{-}\mathcal{NP}\not\subseteq \mathcal{NP}$) have also been considered. These Exponential-Time Hypotheses have been widely influential across different areas of complexity theory. However, their connections to *derandomization and circuit lower bounds* have yet to be systematically studied. Such study is indeed the focus of the current work, and we prove a sequence of results demonstrating that *the connections between exponential-time hypotheses, derandomization, and circuit lower bounds are remarkably strong*.

First, we show that if $3\text{-}SAT$ (or even $TQBF$) cannot be solved by probabilistic algorithms that run in time $2^{n/\mathrm{polylog}(n)}$, then $\mathcal{BPP}$ can be deterministically simulated ``on average case'' in (nearly-)polynomial-time (i.e., in time $n^{\mathrm{polyloglog}(n)}$). This result addresses a long-standing lacuna in uniform ``hardness-to-randomness'' results, which did not previously extend to such parameter settings. Moreover, we extend this result to support an ``almost-always'' derandomization conclusion from an ``almost-always'' lower bound hypothesis.

Secondly, we show that *disproving* certain exponential-time hypotheses requires proving breakthrough circuit lower bounds. In particular, if $CircuitSAT$ for circuits over $n$ bits of size $\mathrm{poly}(n)$ can be solved by *probabilistic algorithms* in time $2^{n/\mathrm{polylog}(n)}$, then $\mathcal{BPE}$ does not have circuits of quasilinear size. The main novel feature of this result is that we only assume the existence of a *randomized* circuit-analysis algorithm, whereas previous similar results crucially relied on the hypothesis that the circuit-analysis algorithm does not use randomness.

Thirdly, we show that a very weak exponential-time hypothesis is closely-related to the classical question of whether derandomization and circuit lower bounds are *equivalent*. Specifically, we show two-way implications between the hypothesis that the foregoing equivalence holds and the hypothesis that $\mathcal{E}$ cannot be decided by ``small'' circuits that are *uniformly generated* by relatively-efficient non-deterministic machines. This highlights a sufficient-and-necessary path for progress towards proving that derandomization and circuit lower bounds are indeed equivalent.</summary>
    <updated>2019-11-24T11:50:42Z</updated>
    <published>2019-11-24T11:50:42Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-11-29T16:20:31Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/168</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/168" rel="alternate" type="text/html"/>
    <title>TR19-168 |  Beyond Natural Proofs: Hardness Magnification and Locality | 

	Ján Pich, 

	Lijie Chen, 

	Shuichi Hirahara, 

	Igor Carboni Oliveira, 

	Ninad Rajgopal, 

	Rahul Santhanam</title>
    <summary>Hardness magnification reduces major complexity separations (such as $EXP \not\subseteq NC^1$) to proving lower bounds for some natural problem $Q$ against weak circuit models. Several recent works [OS18, MMW19, CT19, OPS19, CMMW19, Oli19, CJW19a] have established results of this form. In the most intriguing cases, the required lower bound is known for problems that appear to be significantly easier than $Q$, while $Q$ itself is susceptible to lower bounds but these are not yet sufficient for magnification. 

In this work, we provide more examples of this phenomenon, and investigate the prospects of proving new lower bounds using this approach. In particular, we consider the following essential questions associated with the hardness magnification program:

– Does hardness magnification avoid the natural proofs barrier of Razborov and Rudich [RR97]? 
– Can we adapt known lower bound techniques to establish the desired lower bound for $Q$?

We establish that some instantiations of hardness magnification overcome the natural proofs barrier in the following sense: slightly superlinear-size circuit lower bounds for certain versions of the minimum circuit size problem MCSP imply the non-existence of natural proofs. As a corollary of our result, we show that certain magnification theorems not only imply strong worst-case circuit lower bounds but also rule out the existence of efficient learning algorithms. 

Hardness magnification might sidestep natural proofs, but we identify a source of difficulty when trying to adapt existing lower bound techniques to prove strong lower bounds via magnification. This is captured by a locality barrier: existing magnification theorems unconditionally show that the problems $Q$ considered above admit highly efficient circuits extended with small fan-in oracle gates, while lower bound techniques against weak circuit models quite often easily extend to circuits containing such oracles. This explains why direct adaptations of certain lower bounds are unlikely to yield strong complexity separations via hardness magnification.</summary>
    <updated>2019-11-24T05:59:30Z</updated>
    <published>2019-11-24T05:59:30Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-11-29T16:20:31Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=7582</id>
    <link href="https://windowsontheory.org/2019/11/23/harvard-opportunity-lecturing-advising-position/" rel="alternate" type="text/html"/>
    <title>Harvard opportunity: lecturing / advising position</title>
    <summary>Harvard Computer Science is seeking a Lecturer/Assistant Director of Undergraduate Studies. A great candidate would be someone passionate about teaching and mentoring and excited to build a diverse and inclusive Undergraduate Computer Science community at Harvard. The position requires a Ph.D and is open to all areas of computer science and related fields, but of course […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Harvard Computer Science is seeking a Lecturer/Assistant Director of Undergraduate Studies. A great candidate would be someone passionate about teaching and mentoring and excited to build a diverse and inclusive Undergraduate Computer Science community at Harvard. The position requires a Ph.D and is open to all areas of computer science and related fields, but of course personally I would love to have a theorist fill this role.</p>



<p>Key responsibilities are:</p>



<p>* Teach (or co-teach) one undergraduate Computer Science course per semester.</p>



<p>* Join and help lead the Computer Science Undergraduate Advising team (which includes mentoring and advising undergraduate students and developing materials, initiatives, and events to foster a welcoming and inclusive Harvard Computer Science community.)</p>



<p>The job posting with all details is at <a href="https://tiny.cc/harvardadus">https://tiny.cc/harvardadus</a> <br/></p>



<p>Any questions about this position, feel free to contact me or Steve Chong  (the co directors of undergraduate studies for CS at Harvard) at cs-dus at seas.harvard.edu <br/></p></div>
    </content>
    <updated>2019-11-23T17:56:24Z</updated>
    <published>2019-11-23T17:56:24Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2019-11-29T16:20:59Z</updated>
    </source>
  </entry>
</feed>
