<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2019-09-13T08:22:04Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.05828</id>
    <link href="http://arxiv.org/abs/1909.05828" rel="alternate" type="text/html"/>
    <title>Sublinear-Time Language Recognition and Decision by One-Dimensional Cellular Automata</title>
    <feedworld_mtime>1568332800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Modanese:Augusto.html">Augusto Modanese</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.05828">PDF</a><br/><b>Abstract: </b>After an apparent hiatus of roughly 30 years, we revisit a seemingly
neglected subject in the theory of (one-dimensional) cellular automata:
sublinear-time computation. The cellular automata model considered is that of
ACAs, which are language acceptors whose acceptance condition depends on the
states of all cells in the automaton. We prove a time hierarchy theorem for
sublinear-time ACA classes, analyze their intersection with the regular
languages, and, finally, establish strict inclusions respective to the parallel
computation classes SC and (uniform) AC. As an addendum, we introduce and
investigate the concept of a strong ACA (SACA) as the decider counterpart of a
(weak) ACA, show the class of languages decidable in constant time by SACAs
equals the locally testable languages, and determine $\Omega(\sqrt{n})$ as the
(tight) time complexity threshold for SACAs up to which no advantage respective
to constant time is possible.
</p></div>
    </summary>
    <updated>2019-09-13T01:20:26Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-09-13T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.05822</id>
    <link href="http://arxiv.org/abs/1909.05822" rel="alternate" type="text/html"/>
    <title>On the Hardness of Robust Classification</title>
    <feedworld_mtime>1568332800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gourdeau:Pascale.html">Pascale Gourdeau</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kanade:Varun.html">Varun Kanade</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kwiatkowska:Marta.html">Marta Kwiatkowska</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Worrell:James.html">James Worrell</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.05822">PDF</a><br/><b>Abstract: </b>It is becoming increasingly important to understand the vulnerability of
machine learning models to adversarial attacks. In this paper we study the
feasibility of robust learning from the perspective of computational learning
theory, considering both sample and computational complexity. In particular,
our definition of robust learnability requires polynomial sample complexity. We
start with two negative results. We show that no non-trivial concept class can
be robustly learned in the distribution-free setting against an adversary who
can perturb just a single input bit. We show moreover that the class of
monotone conjunctions cannot be robustly learned under the uniform distribution
against an adversary who can perturb $\omega(\log n)$ input bits. However if
the adversary is restricted to perturbing $O(\log n)$ bits, then the class of
monotone conjunctions can be robustly learned with respect to a general class
of distributions (that includes the uniform distribution). Finally, we provide
a simple proof of the computational hardness of robust learning on the boolean
hypercube. Unlike previous results of this nature, our result does not rely on
another computational model (e.g. the statistical query model) nor on any
hardness assumption other than the existence of a hard learning problem in the
PAC framework.
</p></div>
    </summary>
    <updated>2019-09-13T01:20:31Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-09-13T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.05711</id>
    <link href="http://arxiv.org/abs/1909.05711" rel="alternate" type="text/html"/>
    <title>Optimal Routing Schedules for Robots Operating in Aisle-Structures</title>
    <feedworld_mtime>1568332800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sorbelli:Francesco_Betti.html">Francesco Betti Sorbelli</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Carpin:Stefano.html">Stefano Carpin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cor=ograve=:Federico.html">Federico Corò</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Navarra:Alfredo.html">Alfredo Navarra</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pinotti:Cristina_M=.html">Cristina M. Pinotti</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.05711">PDF</a><br/><b>Abstract: </b>In this paper, we consider the Constant-cost Orienteering Problem (COP) where
a robot, constrained by a limited travel budget, aims at selecting a path with
the largest reward in an aisle-graph. The aisle-graph consists of a set of
loosely connected rows where the robot can change lane only at either end, but
not in the middle. Even when considering this special type of graphs, the
orienteering problem is known to be NP-hard. We optimally solve in polynomial
time two special cases, COP-FR where the robot can only traverse full rows, and
COP-SC where the robot can access the rows only from one side. To solve the
general COP, we then apply our special case algorithms as well as a new
heuristic that suitably combines them. Despite its light computational
complexity and being confined into a very limited class of paths, the optimal
solutions for COP-FR turn out to be competitive even for COP in both real and
synthetic scenarios. Furthermore, our new heuristic for the general case
outperforms state-of-art algorithms, especially for input with highly
unbalanced rewards.
</p></div>
    </summary>
    <updated>2019-09-13T01:24:05Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-13T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.05503</id>
    <link href="http://arxiv.org/abs/1909.05503" rel="alternate" type="text/html"/>
    <title>The Randomized Midpoint Method for Log-Concave Sampling</title>
    <feedworld_mtime>1568332800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Ruoqi Shen, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lee:Yin_Tat.html">Yin Tat Lee</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.05503">PDF</a><br/><b>Abstract: </b>Sampling from log-concave distributions is a well researched problem that has
many applications in statistics and machine learning. We study the
distributions of the form $p^{*}\propto\exp(-f(x))$, where
$f:\mathbb{R}^{d}\rightarrow\mathbb{R}$ has an $L$-Lipschitz gradient and is
$m$-strongly convex. In our paper, we propose a Markov chain Monte Carlo (MCMC)
algorithm based on the underdamped Langevin diffusion (ULD). It can achieve
$\epsilon\cdot D$ error (in 2-Wasserstein distance) in
$\tilde{O}\left(\kappa^{7/6}/\epsilon^{1/3}+\kappa/\epsilon^{2/3}\right)$
steps, where $D\overset{\mathrm{def}}{=}\sqrt{\frac{d}{m}}$ is the effective
diameter of the problem and $\kappa\overset{\mathrm{def}}{=}\frac{L}{m}$ is the
condition number. Our algorithm performs significantly faster than the
previously best known algorithm for solving this problem, which requires
$\tilde{O}\left(\kappa^{1.5}/\epsilon\right)$ steps. Moreover, our algorithm
can be easily parallelized to require only $O(\kappa\log\frac{1}{\epsilon})$
parallel steps.
</p>
<p>To solve the sampling problem, we propose a new framework to discretize
stochastic differential equations. We apply this framework to discretize and
simulate ULD, which converges to the target distribution $p^{*}$. The framework
can be used to solve not only the log-concave sampling problem, but any problem
that involves simulating (stochastic) differential equations.
</p></div>
    </summary>
    <updated>2019-09-13T01:23:45Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-13T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.05499</id>
    <link href="http://arxiv.org/abs/1909.05499" rel="alternate" type="text/html"/>
    <title>Online Linear Programming: Dual Convergence, New Algorithms, and Regret Bounds</title>
    <feedworld_mtime>1568332800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Xiaocheng.html">Xiaocheng Li</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Ye:Yinyu.html">Yinyu Ye</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.05499">PDF</a><br/><b>Abstract: </b>We study an online linear programming (OLP) problem under a random input
model in which the columns of the constraint matrix along with the
corresponding coefficients in the objective function are generated i.i.d. from
an unknown distribution and revealed sequentially over time. Virtually all
current online algorithms were based on learning the dual optimal
solutions/prices of the linear programs (LP), and their analyses were focused
on the aggregate objective value and solving the packing LP where all
coefficients in the constraint matrix and objective are nonnegative. However,
two major open questions are: (i) Does the set of LP optimal dual prices of OLP
converge to those of the "offline" LP, and (ii) Could the results be extended
to general LP problems where the coefficients can be either positive or
negative. We resolve these two questions by establishing convergence results
for the dual prices under moderate regularity conditions for general LP
problems. Then we propose a new type of OLP algorithm, Action-History-Dependent
Learning Algorithm, which improves the previous algorithm performances by
taking into account the past input data as well as and decisions/actions
already made. We derive an $O(\log n \log \log n)$ regret bound for the
proposed algorithm, against the $O(\sqrt{n})$ bound for typical dual-price
learning algorithms, and show that no dual-based thresholding algorithm
achieves a worst-case regret smaller than $O(\log n)$, where n is the number of
decision variables. Numerical experiments demonstrate the superior performance
of the proposed algorithms and the effectiveness of our
action-history-dependent design. Our results also indicate that, for solving
online optimization problems with constraints, it's better to utilize a
non-stationary policy rather than the stationary one.
</p></div>
    </summary>
    <updated>2019-09-13T01:25:56Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-13T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://emanueleviola.wordpress.com/?p=667</id>
    <link href="https://emanueleviola.wordpress.com/2019/09/12/those-who-sold-their-town-to-the-marijuana-industry-now-worry-about-vaping/" rel="alternate" type="text/html"/>
    <title>Those who sold their town to the marijuana industry now worry about vaping</title>
    <summary>Below is a statement from the same administration which rigged elections to sell their town to the marijuana industry.  The latter spent more than $300,000 to win the rigged election, see expense report, a figure that does not include money spent on attorneys to lobby the administration.  In less than a month Newton residents will […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div>Below is a statement from the same administration which <a href="https://emanueleviola.wordpress.com/tag/marijuana/">rigged elections to sell their town to the marijuana industry</a>.  The latter spent more than $300,000 to win the rigged election, see <a href="http://www.newtonma.gov/civicax/filebank/documents/95997">expense report</a>, a figure that does not include money spent on attorneys to lobby the administration.  In less than a month Newton residents will have their chance to hold the administration accountable.</div>
<div/>
<div>————————————</div>
<div/>
<div><strong>A multi-state outbreak of severe pulmonary disease associated with e-cigarette and marijuana vaping devices has struck.  […] Some contained nicotine and others contained marijuana or related substances.</strong></div>
<div/>
<div><strong>Newton Health and Human Services strongly urges residents to consider not using any e-cigarette or vaping products at this time.</strong></div></div>
    </content>
    <updated>2019-09-12T13:57:53Z</updated>
    <published>2019-09-12T13:57:53Z</published>
    <category term="Uncategorized"/>
    <category term="marijuana"/>
    <author>
      <name>Manu</name>
    </author>
    <source>
      <id>https://emanueleviola.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://emanueleviola.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://emanueleviola.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://emanueleviola.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://emanueleviola.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>by Manu</subtitle>
      <title>Thoughts</title>
      <updated>2019-09-13T08:21:09Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.05023</id>
    <link href="http://arxiv.org/abs/1909.05023" rel="alternate" type="text/html"/>
    <title>A Quantum Search Decoder for Natural Language Processing</title>
    <feedworld_mtime>1568246400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bausch:Johannes.html">Johannes Bausch</a>, Sathyawageeswar Subramanian, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Piddock:Stephen.html">Stephen Piddock</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.05023">PDF</a><br/><b>Abstract: </b>Probabilistic language models, e.g. those based on an LSTM, often face the
problem of finding a high probability prediction from a sequence of random
variables over a set of words. This is commonly addressed using a form of
greedy decoding such as beam search, where a limited number of
highest-likelihood paths (the beam width) of the decoder are kept, and at the
end the maximum-likelihood path is chosen. The resulting algorithm has linear
runtime in the beam width. However, the input is not necessarily distributed
such that a high-likelihood input symbol at any given time step also leads to
the global optimum. Limiting the beam width can thus result in a failure to
recognise long-range dependencies. In practice, only an exponentially large
beam width can guarantee that the global optimum is found: for an input of
length $n$ and average parser branching ratio $R$, the baseline classical
algorithm needs to query the input on average $R^n$ times. In this work, we
construct a quantum algorithm to find the globally optimal parse with high
constant success probability. Given the input to the decoder is distributed
like a power-law with exponent $k&gt;0$, our algorithm yields a runtime $R^{n
f(R,k)}$, where $f\le 1/2$, and $f\rightarrow 0$ exponentially quickly for
growing $k$. This implies that our algorithm always yields a super-Grover type
speedup, i.e. it is more than quadratically faster than its classical
counterpart. We further modify our procedure to recover a quantum beam search
variant, which enables an even stronger empirical speedup, while sacrificing
accuracy. Finally, we apply this quantum beam search decoder to Mozilla's
implementation of Baidu's DeepSpeech neural net, which we show to exhibit such
a power law word rank frequency, underpinning the applicability of our model.
</p></div>
    </summary>
    <updated>2019-09-12T23:21:29Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.05007</id>
    <link href="http://arxiv.org/abs/1909.05007" rel="alternate" type="text/html"/>
    <title>Optimality of the Subgradient Algorithm in the Stochastic Setting</title>
    <feedworld_mtime>1568246400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Daron Anderson, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Leith:Douglas.html">Douglas Leith</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.05007">PDF</a><br/><b>Abstract: </b>Recently Jaouad Mourtada and St\' ephane Ga\"iffas showed the anytime hedge
algorithm has pseudo-regret $O(\log (d) / \Delta)$ if the cost vectors are
generated by an i.i.d sequence in the cube $[0,1]^d$. Here $d$ is the dimension
and $\Delta$ the suboptimality gap. This is remarkable because the Hedge
algorithm was designed for the antagonistic setting. We prove a similar result
for the anytime subgradient algorithm on the simplex. Given i.i.d cost vectors
in the unit ball our pseudo-regret bound is $O(1/\Delta)$ and does not depend
on the dimension of the problem.
</p></div>
    </summary>
    <updated>2019-09-12T23:22:01Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.04910</id>
    <link href="http://arxiv.org/abs/1909.04910" rel="alternate" type="text/html"/>
    <title>An exact solution framework for the multiple gradual cover location problem</title>
    <feedworld_mtime>1568246400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Eduardo Álvarez-Miranda, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sinnl:Markus.html">Markus Sinnl</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.04910">PDF</a><br/><b>Abstract: </b>Facility and covering location models are key elements in many decision aid
tools in logistics, supply chain design, telecommunications, public
infrastructure planning, and many other industrial and public sectors. In many
applications, it is likely that customers are not dichotomously covered by
facilities, but gradually covered according to, e.g., the distance to the open
facilities. Moreover, customers are not served by a single facility, but by a
collection of them, which jointly serve them. In this paper we study the
recently introduced multiple gradual cover location problem (MGCLP). The MGCLP
addresses both of the issues described above.
</p>
<p>We provide four different mixed-integer programming formulations for the
MGCLP, all of them exploiting the submodularity of the objective function and
developed a branch-and-cut framework based one these formulations. The
framework is further enhanced by starting and primal heuristics and
initialization procedures.
</p>
<p>The computational results show that our approach allows to effectively
address different sets of instances. We provide optimal solution values for 13
instances from literature, where the optimal solution was not known, and
additionally provide improved solution values for seven instances. Many of
these instances can be solved within a minute. We also analyze the dependence
of the solution-structure on instance-characteristics.
</p></div>
    </summary>
    <updated>2019-09-12T23:22:08Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.04905</id>
    <link href="http://arxiv.org/abs/1909.04905" rel="alternate" type="text/html"/>
    <title>SwarmMesh: A Distributed Data Structure for Cooperative Multi-Robot Applications</title>
    <feedworld_mtime>1568246400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Majcherczyk:Nathalie.html">Nathalie Majcherczyk</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pinciroli:Carlo.html">Carlo Pinciroli</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.04905">PDF</a><br/><b>Abstract: </b>We present an approach to the distributed storage of data across a swarm of
mobile robots that forms a shared global memory. We assume that external
storage infrastructure is absent, and that each robot is capable of devoting a
quota of memory and bandwidth to distributed storage. Our approach is motivated
by the insight that in many applications data is collected at the periphery of
a swarm topology, but the periphery also happens to be the most dangerous
location for storing data, especially in exploration missions. Our approach is
designed to promote data storage in the locations in the swarm that best suit a
specific feature of interest in the data, while accounting for the constantly
changing topology due to individual motion. We analyze two possible features of
interest: the data type and the data item position in the environment. We
assess the performance of our approach in a large set of simulated experiments.
The evaluation shows that our approach is capable of storing quantities of data
that exceed the memory of individual robots, while maintaining near-perfect
data retention in high-load conditions.
</p></div>
    </summary>
    <updated>2019-09-12T23:22:17Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.04878</id>
    <link href="http://arxiv.org/abs/1909.04878" rel="alternate" type="text/html"/>
    <title>Promises Make Finite (Constraint Satisfaction) Problems Infinitary</title>
    <feedworld_mtime>1568246400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Barto:Libor.html">Libor Barto</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.04878">PDF</a><br/><b>Abstract: </b>The fixed template Promise Constraint Satisfaction Problem (PCSP) is a
recently proposed significant generalization of the fixed template CSP, which
includes approximation variants of satisfiability and graph coloring problems.
All the currently known tractable (i.e., solvable in polynomial time) PCSPs
over finite templates can be reduced, in a certain natural way, to tractable
CSPs. However, such CSPs are often over infinite domains. We show that the
infinity is in fact necessary by proving that a specific finite-domain PCSP,
namely (1-in-3-SAT, Not-All-Equal-3-SAT), cannot be naturally reduced to a
tractable finite-domain CSP, unless P=NP.
</p></div>
    </summary>
    <updated>2019-09-12T23:20:38Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-09-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.04871</id>
    <link href="http://arxiv.org/abs/1909.04871" rel="alternate" type="text/html"/>
    <title>Algebraic Theory of Promise Constraint Satisfaction Problems, First Steps</title>
    <feedworld_mtime>1568246400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Barto:Libor.html">Libor Barto</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.04871">PDF</a><br/><b>Abstract: </b>What makes a computational problem easy (e.g., in P, that is, solvable in
polynomial time) or hard (e.g., NP-hard)? This fundamental question now has a
satisfactory answer for a quite broad class of computational problems, so
called fixed-template constraint satisfaction problems (CSPs) -- it has turned
out that their complexity is captured by a certain specific form of symmetry.
This paper explains an extension of this theory to a much broader class of
computational problems, the promise CSPs, which includes relaxed versions of
CSPs such as the problem of finding a 137-coloring of a 3-colorable graph.
</p></div>
    </summary>
    <updated>2019-09-12T23:20:29Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-09-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.04785</id>
    <link href="http://arxiv.org/abs/1909.04785" rel="alternate" type="text/html"/>
    <title>Kronecker powers of tensors and Strassen's laser method</title>
    <feedworld_mtime>1568246400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Conner:Austin.html">Austin Conner</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gesmundo:Fulvio.html">Fulvio Gesmundo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Landsberg:Joseph_M=.html">Joseph M. Landsberg</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Ventura:Emanuele.html">Emanuele Ventura</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.04785">PDF</a><br/><b>Abstract: </b>We answer a question, posed implicitly by Coppersmith-Winogrand and
Buergisser et. al. and explicitly by Blaeser, showing the border rank of the
Kronecker square of the little Coppersmith-Winograd tensor is the square of the
border rank of the tensor for all q&gt;2, a negative result for complexity theory.
We further show that when q&gt;4, the analogous result holds for the Kronecker
cube. In the positive direction, we enlarge the list of explicit tensors
potentially useful for the laser method. We observe that a well-known tensor,
the 3x3 determinant polynomial regarded as a tensor, could potentially be used
in the laser method to prove the exponent of matrix multiplication is two.
Because of this, we prove new upper bounds on its Waring rank and rank (both
18), border rank and Waring border rank (both 17), which, in addition to being
promising for the laser method, are of interest in their own right. We discuss
"skew" cousins of the little Coppersmith-Winograd tensor and indicate whey they
may be useful for the laser method. We establish general results regarding
border ranks of Kronecker powers of tensors, and make a detailed study of
Kronecker squares of tensors of dimensions (3,3,3). In particular we show
numerically that for generic tensors in this space, the rank and border rank
are strictly sub-multiplicative.
</p></div>
    </summary>
    <updated>2019-09-12T23:20:44Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-09-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.04774</id>
    <link href="http://arxiv.org/abs/1909.04774" rel="alternate" type="text/html"/>
    <title>Coding for Sunflowers</title>
    <feedworld_mtime>1568246400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rao:Anup.html">Anup Rao</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.04774">PDF</a><br/><b>Abstract: </b>A sunflower is a family of sets that have the same pairwise intersections. We
simplify a recent result of Alweiss, Lovett, Wu and Zhang that gives an upper
bound on the size of every family of sets of size $k$ that does not contain a
sunflower. We show how to use the converse of Shannon's noiseless coding
theorem to give a cleaner proof of their result.
</p></div>
    </summary>
    <updated>2019-09-12T23:21:10Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-09-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.04759</id>
    <link href="http://arxiv.org/abs/1909.04759" rel="alternate" type="text/html"/>
    <title>Electrical Flows over Spanning Trees</title>
    <feedworld_mtime>1568246400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gupta:Swati.html">Swati Gupta</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Khodabakhsh:Ali.html">Ali Khodabakhsh</a>, Hassan Mortagy, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nikolova:Evdokia.html">Evdokia Nikolova</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.04759">PDF</a><br/><b>Abstract: </b>This is the first paper to give provable approximation guarantees for the
network reconfiguration problem from power systems. The problem seeks to find a
rooted tree such that the energy of the (unique) feasible electrical flow is
minimized. The tree requirement is motivated by operational constraints in
electricity distribution networks. The bulk of existing results on the
structure of electrical flows, Laplacian solvers, bicriteria tree
approximations, etc., do not easily give guarantees for this problem, while
many heuristic methods have been used in the power systems community as early
as 1989. Our main contribution is to advance the theory for network
reconfiguration by providing novel lower bounds and corresponding approximation
factors for various settings ranging from $O(n)$ for general graphs, to
$O(\sqrt{n})$ over grids with uniform resistances on edges, and $O(1)$ for
grids with uniform edge resistances and demands. We also provide a new method
for (approximate) graph sparsification that maintains the original resistances
of the edges.
</p></div>
    </summary>
    <updated>2019-09-12T23:21:40Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://tcsplus.wordpress.com/?p=363</id>
    <link href="https://tcsplus.wordpress.com/2019/09/11/the-fall-season-of-tcs-is-upon-us/" rel="alternate" type="text/html"/>
    <title>The Fall season of TCS+ is upon us!</title>
    <summary>With the summer winding down, the Fall ’19 season of TCS+ is coming fast! We’re excited to bring to you, over the next few months, great speakers and amazing results, right into the comfort of your home institution (or home home, for that matter). As a teaser, here are the first three talks of the […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>With the summer winding down, the Fall ’19 season of TCS+ is coming fast! We’re excited to bring to you, over the next few months, great speakers and amazing results, right into the comfort of your home institution (or home <em>home</em>, for that matter).</p>
<p>As a teaser, here are the first three talks of the season:</p>
<ul>
<li>
<ul>
<li><a href="http://web.stanford.edu/~msellke/main" rel="noopener" target="_blank">Mark Sellke</a> (Stanford) will tell us, on September 25th, about his recent work on <em>Chasing Convex Bodies.</em><em><br/>
</em></li>
<li><a href="https://cseweb.ucsd.edu/~slovett/" rel="noopener" target="_blank">Shachar Lovett</a> (UCSD) will on October 9th present his new results on the Sunflower Lemma.</li>
<li><a href="http://www.mathcs.emory.edu/~hhuan30/">Hao Huang</a> (Emory University) will talk on October 22nd <em>(note: a Tuesday)</em> about his recent proof of the Sensitivity Conjecture.</li>
</ul>
</li>
</ul>
<p>Stay tuned for those, and the following!</p></div>
    </content>
    <updated>2019-09-11T19:44:19Z</updated>
    <published>2019-09-11T19:44:19Z</published>
    <category term="Announcements"/>
    <author>
      <name>plustcs</name>
    </author>
    <source>
      <id>https://tcsplus.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://tcsplus.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://tcsplus.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://tcsplus.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://tcsplus.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A carbon-free dissemination of ideas across the globe.</subtitle>
      <title>TCS+</title>
      <updated>2019-09-13T08:21:21Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/117</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/117" rel="alternate" type="text/html"/>
    <title>TR19-117 |  Locally Testable Non-Malleable Codes | 

	Silas Richelson, 

	Sourya Roy</title>
    <summary>In this work we adapt the notion of non-malleability for codes or Dziembowski, Pietrzak and Wichs (ICS 2010) to locally testable codes. Roughly speaking, a locally testable code is non-malleable if any tampered codeword which passes the local test with good probability is close to a valid codeword which either encodes the original, or an unrelated message.
We instantiate our definition by proving that a Reed-Muller-type code is non-malleable in the following sense: any adversary who independently tampers the coordinates of the code so that the tampered code passes the test with good probability, is tampering the underlying polynomial according to an affine transformation.
To the best of our knowledge, prior to this work, polynomial codes were not known to possess any non-malleability guarantees. Our analysis builds on the sampler-based decoding techniques common to several recent works.</summary>
    <updated>2019-09-10T12:26:11Z</updated>
    <published>2019-09-10T12:26:11Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-09-13T08:20:33Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-25562705.post-4980143336209093039</id>
    <link href="http://aaronsadventures.blogspot.com/feeds/4980143336209093039/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=25562705&amp;postID=4980143336209093039" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/25562705/posts/default/4980143336209093039" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/25562705/posts/default/4980143336209093039" rel="self" type="application/atom+xml"/>
    <link href="http://aaronsadventures.blogspot.com/2019/09/a-new-analysis-of-adaptive-data-analysis.html" rel="alternate" type="text/html"/>
    <title>A New Analysis of "Adaptive Data Analysis"</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div style="text-align: center;"><i>This is a blog post about our new paper, which you can read here: </i><a href="https://arxiv.org/abs/1909.03577">https://arxiv.org/abs/1909.03577</a> </div><div style="text-align: center;"><br/></div>The most basic statistical estimation task is estimating the expected value of some predicate $q$ over a distribution $\mathcal{P}$: $\mathrm{E}_{x \sim \mathcal{P}}[q(x)]$, which I'll just write as $q(\mathcal{P})$. Think about estimating the mean of some feature in your data, or the error rate of a classifier that you have just trained.  There's a really obvious way to come up with a good estimate if you've got a dataset $S \sim \mathcal{P}^n$ of $n$ points that were sampled i.i.d. from the distribution: just use the empirical mean $a = \frac{1}{n}\sum_{i=1}^n q(S_i)$! In fact, this is a great way to estimate the values of a really large number of predicates, so long as they were chosen <i>non-adaptively</i>: that is, so long as you came up with all of the predicates you wanted to estimate before you estimated any of the answers. This phenomenon is, for example, what classical generalization theorems in machine learning rely on: the empirical error of a set of classifiers in some model class will be a good estimate of their actual, out-of-sample error, so long as your dataset is at least as large as the logarithm of your model class.<br/><div><br/></div><div>But this guarantee breaks down if the predicates that you want to estimate are chosen in sequence, adaptively. For example, suppose you are trying to fit a machine learning model to data. If you train your first model, estimate its error, and then as a result of the estimate tweak your model and estimate its error again, you are engaging in exactly this kind of adaptivity. If you repeat this many times (as you might when you are tuning hyper-parameters in your model) you could quickly get yourself into big trouble. Of course there is a simple way around this problem: just don't re-use your data. The most naive baseline that gives statistically valid answers is called "data splitting". If you want to test k models in sequence, just randomly partition your data into k equal sized parts, and test each model on a fresh part. The holdout method is just the special case of k = 2.  But this "naive" method doesn't make efficient use of data: its data requirements grow <i>linearly</i> with the number of models you want to estimate. </div><div><br/></div><div>It turns out its possible to do better by perturbing the empirical means with a little bit of noise before you use them: this is what we (Dwork, Feldman, Hardt, Pitassi, Reingold, and Roth --- DFHPRR) showed back in 2014 in <a href="https://arxiv.org/abs/1411.2664">this paper</a>, which helped kick off a small subfield known as "adaptive data analysis". In a nutshell, we proved a "transfer theorem" that says the following: if your statistical estimator is simultaneously <i>differentially private</i> and <i>sample accurate</i> --- meaning that with high probability it provides estimates that are close to the empirical means, then it will also be accurate out of sample. When paired with a simple differentially private mechanism for answering queries --- just perturbing their answers with Gaussian noise --- this gave a significant asymptotic improvement in data efficiency over the naive baseline! You can see how well it does in this figure (click to enlarge it): </div><div class="separator" style="clear: both; text-align: center;"><a href="https://1.bp.blogspot.com/-Eip3yKJl5mE/XXWfXoqt8KI/AAAAAAAATxY/FMSJHq4ClJgZXOhuACMC5ZMFFQ0W8cmOgCLcBGAs/s1600/DFHPRRonly.png" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="205" src="https://1.bp.blogspot.com/-Eip3yKJl5mE/XXWfXoqt8KI/AAAAAAAATxY/FMSJHq4ClJgZXOhuACMC5ZMFFQ0W8cmOgCLcBGAs/s320/DFHPRRonly.png" width="320"/></a></div><div style="text-align: left;">Well... Hmm. In this figure, we are plotting how many adaptively chosen queries can be answered accurately as a function of dataset size. By "accurately" we have arbitrarily chosen to mean: answers that have confidence intervals of width 0.1 and uniform coverage probability 95%. On the x axis, we've plotted the dataset size n, ranging from 100,000 to about 12 million. And we've plotted two methods: the "naive" sample splitting baseline, and using the sophisticated Gaussian perturbation technique, as analyzed by the bound we proved in the "DFHPRR" paper. (Actually --- a numerically optimized variant of that bound!) You can see the problem. Even with a dataset size in the tens of millions, the sophisticated method does substantially worse than the naive method! You can extrapolate from the curve that the DFHPRR bound will <i>eventually</i> beat the naive bound, but it would require a truly enormous dataset. When I try extending the plot out that far my optimizer runs into numeric instability issues. </div><div style="text-align: left;"><br/></div><div style="text-align: left;">There has been improvement since then. In particular, DFHPRR didn't even obtain the best bound asymptotically. It is folklore that differentially private estimates generalize in expectation: the trickier part is to show that they enjoy <i>high probability</i> generalization bounds. This is what we showed in a sub-optimal way in DFHPRR. In 2015, a <a href="https://arxiv.org/abs/1511.02513">beautiful paper</a> by Bassily, Nissim, Steinke, Smith, Stemmer, and Ullman (BNSSSU) introduced the amazing "monitor technique" to obtain the asymptotically optimal high probability bound. An upshot of the bound was that the Gaussian mechanism can be used to answer roughly $k = n^2$ queries --- a quadratic improvement over the naive sample splitting mechanism! You can read about this technique in the lecture notes of the <a href="https://adaptivedataanalysis.com/">adaptive data analysis class</a> Adam Smith and I taught a few years back.  Lets see how it does (click to enlarge):</div><div class="separator" style="clear: both; text-align: center;"><a href="https://1.bp.blogspot.com/-C83SCyN8uzc/XXWjUcHmTHI/AAAAAAAATxk/GbtveNxoh18E7xOA2HQf67OGj9ujeCAuwCLcBGAs/s1600/DFHPRRandBNSSSU.png" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="206" src="https://1.bp.blogspot.com/-C83SCyN8uzc/XXWjUcHmTHI/AAAAAAAATxk/GbtveNxoh18E7xOA2HQf67OGj9ujeCAuwCLcBGAs/s320/DFHPRRandBNSSSU.png" width="320"/></a></div><div style="text-align: left;">Substantially better! Now we're plotting n from 100,000 up to about only 1.7 million. At this scale, the DFHPRR bound appears to be constant (at essentially 0), whereas the BNSSSU bound clearly exhibits quadratic behavior. It even beats the baseline --- by a little bit, so long as your dataset has somewhat more than a million entries... I should add that what we're plotting here is again a numerically optimized variant of the BNSSSU bound, not the closed-form version from their paper. So maybe not yet a practical technique. The problem is that the monitor argument --- while brilliant --- seems unavoidably to lead to large constant overhead.  </div><div style="text-align: left;"><br/></div><div style="text-align: left;">Which brings us to our new work (this is joint work with Christopher Jung, Katrina Ligett, Seth Neel, Saeed Sharifi-Malvajerdi, and Moshe Shenfeld). We give a brand new proof of the transfer theorem. It is elementary, and in particular, obtains high probability generalization bounds directly from high probability sample-accuracy bounds, avoiding the need for the monitor argument. I think the proof is the most interesting part --- its simple and (I think) illuminating --- but an upshot is that we get <i>substantially</i> better bounds, even though the improvement is just in the constants (the existing BNSSSU bound is known to be asymptotically tight). Here's the plot with our bound included --- the x-axis is the same, but note the substantially scaled-up y axis (click to enlarge): </div><div style="text-align: left;"><br/></div><div class="separator" style="clear: both; text-align: center;"><a href="https://1.bp.blogspot.com/-oR4HDFR07bE/XXWlv1vVIDI/AAAAAAAATxw/Fqbm-weNbMoQ5WbOgeOY3f0p6N2QN9bMACLcBGAs/s1600/allthree.png" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="200" src="https://1.bp.blogspot.com/-oR4HDFR07bE/XXWlv1vVIDI/AAAAAAAATxw/Fqbm-weNbMoQ5WbOgeOY3f0p6N2QN9bMACLcBGAs/s320/allthree.png" width="320"/></a></div><div style="text-align: center;"><br/></div><div style="text-align: left;"><br/><b><u>Proof Sketch</u></b><br/>Ok: on to the proof. Here is the trick. In actuality, the dataset S is first sampled from $\mathcal{P}^n$, and then some data analyst interacts with a differentially private statistical estimator, resulting in some transcript $\pi$ of query answer pairs. But now imagine that <i>after the interaction is complete</i>, S is <i>resampled</i> from $Q_\pi = (\mathcal{P}^n)|\pi$, the posterior distribution on datasets conditioned on $\pi$. If you reflect on this for a moment, you'll notice that this resampling experiment doesn't change the joint distribution on dataset transcript pairs $(S,\pi)$ at all. So if the mechanism promised high probability sample accuracy bounds, it still promises them in this resampling experiment. But lets think about what that means: the mechanism can <i>first commit</i> to some set of answers $a_i$, and promise that with high probability, <i>after</i> S is resampled from $Q_\pi$, $|a_i - \frac{1}{n}\sum_{j=1}^n q_i(S_j)|$ is small. But under the resampling experiment, it is quite likely that the empirical value of the query $\frac{1}{n}\sum_{j=1}^n q_i(S_j)$ will end up being close to its expectation over the posterior: $q_i(Q_{\pi}) = \mathrm{E}_{S \sim Q_{\pi}}[\frac{1}{n}\sum_{j=1}^n q_i(S_j)]$. So the only way that a mechanism can promise high probability sample accuracy is if it actually promises high probability posterior accuracy: i.e. with high probability, for every query $q_i$ that was asked and answered, we must have that $|a_i - q_i(Q_\pi)|$ is small.<br/><br/>That part of the argument was generic --- it didn't use differential privacy at all! But it serves to focus attention on these posterior distributions $Q_\pi$ that our statistical estimator induces. And it turns out its not hard to see that the expected value of queries on posteriors induced by differentially private mechanisms have to be close to their true answers. For $(\epsilon,0)$-differential privacy, it follows almost immediately from the definition. Here is the derivation. Pick your favorite query $q$ and your favorite transcript $\pi$, and write $S_j \sim S$ to denote a uniformly randomly selected element of a dataset $S$:</div><div style="text-align: left;">$$q (Q_\pi) =  \sum_{x} q (x) \cdot \Pr_{S \sim \mathcal{P}^n, S_j \sim S} [S_j = x | \pi]= \sum_{x} q (x) \cdot \frac{\Pr [\pi | S_j = x ] \cdot \Pr_{S \sim \mathcal{P}^n, S_j \sim S} [S_j = x]}{\Pr[\pi]}$$<br/>$$\leq \sum_{x} q (x) \cdot \frac{e^\epsilon \Pr [\pi] \cdot \Pr_{S_j \sim \mathcal{P}} [S_j = x]}{\Pr[\pi]}<br/>= e^\epsilon \cdot q (\mathcal{P})$$<br/><br/>Here, the inequality follows from the definition of differential privacy, which controls the effect that fixing a single element of the dataset to any value $(S_j = x)$ can have on the probability of any transcript: it can increase it multiplicatively by a factor of at most $e^\epsilon$. </div><div style="text-align: left;"><br/>And thats it: So we must have that (with probability 1!), $|q(Q_\pi) - q(\mathcal{P})| \leq e^\epsilon-1 \approx \epsilon$. The transfer theorem then follows from the triangle inequality. We get a high probability bound for free, with no need for any heavy machinery.<br/><br/>The argument is just a little more delicate in the case of $(\epsilon,\delta)$-differential privacy, and can be extended beyond linear queries --- but I think this gives the basic idea. The details are in <a href="https://arxiv.org/abs/1909.03577">our new "JLNRSS" paper</a>. Incidentally, once nice thing about having many different proofs of the same theorem is that you can start to see some commonalities. One seems to be: it takes six authors to prove a transfer theorem!</div><div style="text-align: left;"><br/></div><div style="text-align: left;"><br/></div></div>
    </content>
    <updated>2019-09-10T10:40:00Z</updated>
    <published>2019-09-10T10:40:00Z</published>
    <author>
      <name>Aaron</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/09952936358739421126</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-25562705</id>
      <category term="game theory"/>
      <category term="news"/>
      <author>
        <name>Aaron</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/09952936358739421126</uri>
      </author>
      <link href="http://aaronsadventures.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/25562705/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://aaronsadventures.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/25562705/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <title>Adventures in Computation</title>
      <updated>2019-09-12T10:29:10Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4301</id>
    <link href="https://www.scottaaronson.com/blog/?p=4301" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4301#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4301" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Paul Bernays Lectures</title>
    <summary xml:lang="en-US">Last week, I had the honor of giving the annual Paul Bernays Lectures at ETH Zürich. My opening line: “as I look at the list of previous Bernays Lecturers—many of them Nobel physics laureates, Fields Medalists, etc.—I think to myself, how badly did you have to screw up this year in order to end up […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>Last week, I had the honor of giving the annual <a href="https://gess.ethz.ch/en/news-and-events/paul-bernays-lectures.html">Paul Bernays Lectures</a> at ETH Zürich.  My opening line: “as I look at the list of previous Bernays Lecturers—many of them Nobel physics laureates, Fields Medalists, etc.—I think to myself, how badly did you have to screw up this year in order to end up with me?”</p>



<p><a href="https://en.wikipedia.org/wiki/Paul_Bernays">Paul Bernays</a> was the primary assistant to David Hilbert, before Bernays (being Jewish by birth) was forced out of Göttingen by the Nazis in 1933.  He spent most of the rest of his career at ETH.  He’s perhaps best known for the <a href="https://en.wikipedia.org/wiki/Von_Neumann%E2%80%93Bernays%E2%80%93G%C3%B6del_set_theory">von Neumann-Bernays-Gödel set theory</a>, and for writing (in a volume by “Hilbert and Bernays,” but actually just Bernays) arguably the first full proof of Gödel’s <a href="https://en.wikipedia.org/wiki/G%C3%B6del%27s_incompleteness_theorems#Second_incompleteness_theorem">Second Incompleteness Theorem</a>.</p>



<p>Anyway, the idea of the Paul Bernays Lectures is to rotate between Bernays’s different interests in his long, distinguished career—interests that included math, philosophy, logic, and the foundations of physics.  I mentioned that, if there’s any benefit to carting me out to Switzerland for these lectures, it’s that quantum computing theory combines <em>all</em> of these interests.  And this happens to be the moment in history right before we start finding out, directly from experiments, whether quantum computers can indeed solve certain special problems much faster.</p>



<p>The general theme for my three lectures was “Quantum Computing and the Fundamental Limits of Computation.”  The attendance was a few hundred.  My idea was to take the audience from Church and Turing in the 1930s, all the way to the quantum computational supremacy experiments that Google and others are doing now—as part of a single narrative.</p>



<p>If you’re interested, streaming video of the lectures is available as of today (though I haven’t watched it—let me know if the quality is OK!), as well as of course my slides.  Here you go:</p>



<p><strong>Lecture 1: The Church-Turing Thesis and Physics (<a href="https://video.ethz.ch/speakers/bernays/2019/7b11b50e-f813-4d26-95e0-616cc350708c.html">watch streaming</a> / <a href="https://www.scottaaronson.com/talks/bernays1.ppt">PowerPoint slides</a>)</strong> <strong>(with an intro in German by Giovanni Sommaruga, who knew Bernays, and a second intro in English by Renato Renner, who appeared on this blog <a href="https://www.scottaaronson.com/blog/?p=3975">here</a>)</strong></p>



<blockquote class="wp-block-quote"><p><em>Abstract:</em> Is nature computable?  What should we even mean in formulating such a question?  For generations, the identification of “computable” with “computable by a Turing machine” has been seen as either an arbitrary mathematical definition, or a philosophical or psychological claim.  The rise of quantum computing and information, however, has brought a fruitful new way to look at the Church-Turing Thesis: namely, as a falsifiable empirical claim about the physical universe.  This talk seeks to examine the computability of the laws of physics from a modern standpoint—one that fully incorporates the insights of quantum mechanics, quantum field theory, quantum gravity, and cosmology.  We’ll critically assess ‘hypercomputing’ proposals involving (for example) relativistic time dilation, black holes, closed timelike curves, and exotic cosmologies, and will make a 21st-century case for the physical Church-Turing Thesis.</p></blockquote>



<p><strong>Lecture 2: The Limits of Efficient Computation (<a href="https://video.ethz.ch/speakers/bernays/2019/5564a353-d71b-46d4-bfc0-fa907de5de25.html">watch streaming</a> / <a href="https://www.scottaaronson.com/talks/bernays2.ppt">PowerPoint slides</a>)</strong></p>



<blockquote class="wp-block-quote"><p><em>Abstract:</em> Computer scientists care about what’s computable not only in principle, but within the resource constraints of the physical universe.  Closely related, which types of problems are solvable using a number of steps that scales reasonably (say, polynomially) with the problem size?  This lecture will examine whether the notorious NP-complete problems, like the Traveling Salesman Problem, are efficiently solvable using the resources of the physical world.  We’ll start with P=?NP problem of classical computer science—its meaning, history, and current status.  We’ll then discuss quantum computers: how they work, how they can sometimes yield exponential speedups over classical computers, and why many believe that not even they will do so for the NP-complete problems.  Finally, we’ll critically assess proposals that would use exotic physics to go even beyond quantum computers, in terms of what they would render computable in polynomial time. </p></blockquote>



<p><strong>Lecture 3: The Quest for Quantum Computational Supremacy (<a href="https://video.ethz.ch/speakers/bernays/2019/2a08c4a0-67e1-4e1f-8019-3e557fcb4cde.html">watch streaming</a> / <a href="https://www.scottaaronson.com/talks/bernays3.ppt">PowerPoint slides</a>)</strong></p>



<blockquote class="wp-block-quote"><p><em>Abstract:</em> Can useful quantum computers be built in our world?  This talk will discuss the current status of the large efforts currently underway at Google, IBM, and many other places to build noisy quantum devices, with 50-100 qubits, that can clearly outperform classical computers at least on some specialized tasks — a milestone that’s been given the unfortunate name of “quantum supremacy.”  We’ll survey recent theoretical work (on BosonSampling, random circuit sampling, and more) that aims to tell us: which problems should we give these devices, that we’re as confident as possible are hard for classical computers?  And how should we check whether the devices indeed solved them?  We’ll end by discussing a new protocol, for generating certified random bits, that can be implemented almost as soon as quantum supremacy itself is achieved, and which might therefore become the first application of quantum computing to be realized.</p></blockquote>



<p>Finally, thanks so much to Giovanni Sommaruga and everyone else at ETH for arranging a fantastic visit.</p></div>
    </content>
    <updated>2019-09-09T22:21:31Z</updated>
    <published>2019-09-09T22:21:31Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Announcements"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Complexity"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Quantum"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2019-09-10T22:56:44Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/116</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/116" rel="alternate" type="text/html"/>
    <title>TR19-116 |  $d$-to-$1$ Hardness of Coloring $4$-colorable Graphs with $O(1)$ colors | 

	Venkatesan Guruswami, 

	Sai Sandeep</title>
    <summary>The $d$-to-$1$ conjecture of Khot asserts that it is hard to satisfy an $\epsilon$ fraction of constraints of a satisfiable $d$-to-$1$ Label Cover instance, for arbitrarily small $\epsilon &gt; 0$. We prove that the $d$-to-$1$ conjecture for any fixed $d$ implies the hardness of coloring a $4$-colorable graph with $C$ colors for arbitrarily large integers $C$. Earlier, this implication was only known under the $2$-to-$1$ conjecture, which is the strongest in the family of $d$-to-$1$ conjectures.</summary>
    <updated>2019-09-09T20:29:16Z</updated>
    <published>2019-09-09T20:29:16Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-09-13T08:20:33Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/09/09/quics-hartree-postdoctoral-fellowship-at-university-of-maryland-apply-by-december-1-2019/</id>
    <link href="https://cstheory-jobs.org/2019/09/09/quics-hartree-postdoctoral-fellowship-at-university-of-maryland-apply-by-december-1-2019/" rel="alternate" type="text/html"/>
    <title>QuICS Hartree Postdoctoral Fellowship at University of Maryland (apply by December 1, 2019)</title>
    <summary>The Joint Center for Quantum Information and Computer Science seeks exceptional candidates for QuICS Hartree Postdoctoral Fellowships in Quantum Information and Computer Science. QuICS postdocs will interact with leading computer scientists and physicists at the University of Maryland and the National Institute of Standards and Technology. Website: https://academicjobsonline.org/ajo/jobs/14493 Email: quics-coordinator@umiacs.umd.edu</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Joint Center for Quantum Information and Computer Science seeks exceptional candidates for QuICS Hartree Postdoctoral Fellowships in Quantum Information and Computer Science. QuICS postdocs will interact with leading computer scientists and physicists at the University of Maryland and the National Institute of Standards and Technology.</p>
<p>Website: <a href="https://academicjobsonline.org/ajo/jobs/14493">https://academicjobsonline.org/ajo/jobs/14493</a><br/>
Email: quics-coordinator@umiacs.umd.edu</p></div>
    </content>
    <updated>2019-09-09T16:53:54Z</updated>
    <published>2019-09-09T16:53:54Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-09-13T08:20:46Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-5655789602676044507</id>
    <link href="https://blog.computationalcomplexity.org/feeds/5655789602676044507/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/09/are-there-any-natural-problems-complete.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/5655789602676044507" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/5655789602676044507" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/09/are-there-any-natural-problems-complete.html" rel="alternate" type="text/html"/>
    <title>Are there any natural problems complete for NP INTER TALLY? NP INTER SPARSE?</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><br/>
Recall:<br/>
<br/>
A is a <i>tally set</i> if A ⊆ 1<sup>*</sup>. <br/>
<br/>
<br/>
A is a <i>sparse set</i> if there is a polynomial p such that the number of strings of length n is ≤ p(n). <br/>
<br/>
<br/>
If there exists a sparse set A that is NP-hard under m-reductions (even btt-reductions) then P=NP. (See <a href="https://blog.computationalcomplexity.org/2006/04/favorite-theorems-small-sets.html">this post</a>.)<br/>
<br/>
If there exists a sparse set A that is NP-hard under T-reductions then PH collapses. (See <a href="https://blog.computationalcomplexity.org/2006/11/favorite-theorems-nonuniform.html">this post</a>.)<br/>
<br/>
Okay then!<br/>
<br/>
I have sometimes had a tally set or a sparse set that is in NP and I think that its not in P. I would like to prove, or at least conjecture, that it's NP-complete. But alas, I cannot since then P=NP. (Clarification: If my set is NP-complete then P=NP. I do not mean that the very act of conjecturing it would make P=NP. That would be an awesome superpower.)<br/>
<br/>
So what to do?  <br/>
<br/>
A is <i>NPSPARSE-complete </i> if A is in NP, A is sparse, and for all B that are in NP and sparse, B ≤<sub>m</sub> A.<br/>
<br/>
Similar for NPTALLY and one can also look at other types of reductions.<br/>
<br/>
So, can I show that my set is NPSPARSE-complete? Are there any NPSPARSE-complete sets? Are there NATURAL ones? (Natural is a slippery notion- see this <a href="https://blog.computationalcomplexity.org/2004/03/unnatural-post.html">post by Lance</a>.)<br/>
<br/>
Here is what I was able to find out (if more is known then please leave comments with pointers.)<br/>
<br/>
1) It was observed by <a href="https://lance.fortnow.com/papers/files/npsparse.pdf">Bhurman, Fenner, Fortnow, van Velkebeek</a> that the following set is NPTALLY-complete:<br/>
<br/>
Let M<sub>1</sub>, M<sub>2</sub>, ... be a standard list of NP-machines. Let<br/>
<br/>
A = { 1<sup>(i,n,t)</sup> : M<sub>i</sub>(1<sup>n</sup>) accepts on some path within t steps }'<br/>
<br/>
The set involves Turing Machines so its not quite what I want.<br/>
<br/>
<br/>
2) <a href="https://www.cs.umd.edu/users/gasarch/BLOGPAPERS/messnertoran.pdf">Messner and Toran</a> show that, under an unlikely assumption about proof systems there exists an NPSPARSE-complete set. The set involves Turing Machines. Plus it uses an unlikely assumption. Interesting, but not quite what I want.<br/>
<br/>
<br/>
3) Buhrman, Fenner, Fortnow, van Melkebeek also showed that there are relativized worlds where there are no NPSPARSE sets (this was their main result). Interesting but not quite what I want.  <br/>
<br/>
4) If A is NE-complete then the tally version: { 1<sup>x</sup> : x is in A } is likely NPTALLY-complete. This may help me get what I want.<br/>
<br/>
Okay then!<br/>
<br/>
Are there any other sets that are NPTALLY-complete. NPSPARSE-complete? The obnoxious answer is to take finite variants of A.  What I really want a set of such problems so that we can proof other problems NPTALLY-complete or NPSPARSE-complete with the ease we now prove problems NP-complete.<br/>
<br/>
<br/>
<br/></div>
    </content>
    <updated>2019-09-09T14:55:00Z</updated>
    <published>2019-09-09T14:55:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-09-11T09:48:34Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/09/09/multiple-postdoc-positions-at-irif-paris-france-apply-by-november-3-2019/</id>
    <link href="https://cstheory-jobs.org/2019/09/09/multiple-postdoc-positions-at-irif-paris-france-apply-by-november-3-2019/" rel="alternate" type="text/html"/>
    <title>Multiple Postdoc Positions at IRIF, Paris, France (apply by November 3, 2019)</title>
    <summary>IRIF is seeking excellent candidates for postdoctoral positions in all areas of the Foundations of Computer Science. Candidates must hold a Ph.D. degree in Computer Science or a related area before the starting date of the position. Knowledge of French is not required. For a list of specific openings as well as instructions how to […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>IRIF is seeking excellent candidates for postdoctoral positions in all areas of the Foundations of Computer Science.</p>
<p>Candidates must hold a Ph.D. degree in Computer Science or a related area before the starting date of the position. Knowledge of French is not required.</p>
<p>For a list of specific openings as well as instructions how to apply please visit the webpage mentioned below.</p>
<p>Website: <a href="https://www.irif.fr/postes/postdoc">https://www.irif.fr/postes/postdoc</a><br/>
Email: postdoc-advice@irif.fr</p></div>
    </content>
    <updated>2019-09-09T09:26:14Z</updated>
    <published>2019-09-09T09:26:14Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-09-13T08:20:46Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/115</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/115" rel="alternate" type="text/html"/>
    <title>TR19-115 |  Parameterized Intractability of Even Set and Shortest Vector Problem | 

	Arnab Bhattacharyya, 

	Édouard Bonnet, 

	László Egri, 

	Suprovat Ghoshal, 

	Karthik  C. S., 

	Bingkai Lin, 

	Pasin Manurangsi, 

	Dániel Marx</title>
    <summary>The k-Even Set problem is a parameterized variant of the Minimum Distance Problem of linear codes over $\mathbb{F}_2$, which can be stated as follows: given a generator matrix A and an integer k, determine whether the code generated by A has distance at most k, or in other words, whether there is a nonzero vector x such that Ax has at most k nonzero coordinates. The question of whether k-Even Set is fixed parameter tractable (FPT) parameterized by the distance k has been repeatedly raised in literature; in fact, it is one of the few remaining open questions from the seminal book of Downey and Fellows (1999). In this work, we show that k-Even Set is W[1]-hard under randomized reductions.

We also consider the parameterized k-Shortest Vector Problem (SVP), in which we are given a lattice whose basis vectors are integral and an integer k, and the goal is to determine whether the norm of the shortest vector (in the $\ell_p$ norm for some fixed p) is at most k. Similar to k-Even Set, understanding the complexity of this problem is also a long-standing open question in the field of Parameterized Complexity. We show that, for any p&gt;1, k-SVP is W[1]-hard to approximate (under randomized reductions) to some constant factor.</summary>
    <updated>2019-09-09T06:25:34Z</updated>
    <published>2019-09-09T06:25:34Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-09-13T08:20:33Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=17957</id>
    <link href="https://gilkalai.wordpress.com/2019/09/09/paul-balister-bela-bollobas-robert-morris-julian-sahasrabudhe-and-marius-tiba-flat-polynomials-exist/" rel="alternate" type="text/html"/>
    <title>Paul Balister, Béla Bollobás, Robert Morris, Julian Sahasrabudhe, and Marius Tiba: Flat polynomials exist!</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Béla Bollobás and Paul Erdős at the University of Cambridge in 1990. Credit George Csicsery (from the 1993 film “N is a Number”) (source) (I thank Gady Kozma for telling me about the result.) An old problem from analysis with a … <a href="https://gilkalai.wordpress.com/2019/09/09/paul-balister-bela-bollobas-robert-morris-julian-sahasrabudhe-and-marius-tiba-flat-polynomials-exist/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="https://gilkalai.files.wordpress.com/2019/09/bollobas-erdos-2.png"><img alt="" class="alignnone size-full wp-image-18015" src="https://gilkalai.files.wordpress.com/2019/09/bollobas-erdos-2.png?w=640"/></a></p>
<p><span class="caption-text" style="color: #ff0000;">Béla Bollobás and Paul Erdős at the University of Cambridge in 1990. </span><span class="credit"><span style="color: #ff0000;"><span class="visually-hidden">Credit</span> George Csicsery (from the 1993 film “N is a Number”)</span> <a href="https://wordplay.blogs.nytimes.com/2013/07/08/bollobas/">(source)</a></span></p>
<p>(I thank Gady Kozma for telling me about the result.)</p>
<p>An old problem from analysis with a rich history and close ties with combinatorics is now solved!</p>
<p>The paper is: Paul Balister, Béla Bollobás, Robert Morris, Julian Sahasrabudhe, and Marius Tiba,  <a href="https://arxiv.org/abs/1907.09464">Flat Littelwood Polynomials exist</a></p>
<p><strong>Abstract:</strong> We show that there exist absolute constants <span class="MathJax" id="MathJax-Element-1-Frame"><span class="math" id="MathJax-Span-1"><span class="mrow" id="MathJax-Span-2"><span class="mi" id="MathJax-Span-3">Δ </span><span class="mo" id="MathJax-Span-4">&gt; </span><span class="mi" id="MathJax-Span-5">δ </span><span class="mo" id="MathJax-Span-6">&gt; </span><span class="mn" id="MathJax-Span-7">0</span></span></span></span> such that, for all <em><span class="MathJax" id="MathJax-Element-2-Frame"><span class="math" id="MathJax-Span-8"><span class="mrow" id="MathJax-Span-9"><span class="mi" id="MathJax-Span-10">n</span><span class="mo" id="MathJax-Span-11">⩾</span><span class="mn" id="MathJax-Span-12">2</span></span></span></span></em>, there exists a polynomial <em><span class="MathJax" id="MathJax-Element-3-Frame"><span class="math" id="MathJax-Span-13"><span class="mrow" id="MathJax-Span-14"><span class="mi" id="MathJax-Span-15">P</span></span></span></span></em> of degree <em><span class="MathJax" id="MathJax-Element-4-Frame"><span class="math" id="MathJax-Span-16"><span class="mrow" id="MathJax-Span-17"><span class="mi" id="MathJax-Span-18">n</span></span></span></span></em>, with <span class="MathJax" id="MathJax-Element-5-Frame"><span class="math" id="MathJax-Span-19"><span class="mrow" id="MathJax-Span-20"><span class="mo" id="MathJax-Span-21">±</span><span class="mn" id="MathJax-Span-22">1</span></span></span></span> coefficients, such that</p>
<p style="text-align: center;"><img alt="\delta \sqrt n \le |P(z)| \le \Delta \sqrt n" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdelta+%5Csqrt+n+%5Cle+%7CP%28z%29%7C+%5Cle+%5CDelta+%5Csqrt+n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\delta \sqrt n \le |P(z)| \le \Delta \sqrt n"/></p>
<p>for all <em><span class="MathJax" id="MathJax-Element-7-Frame"><span class="math" id="MathJax-Span-45"><span class="mrow" id="MathJax-Span-46"><span class="mi" id="MathJax-Span-47">z </span><span class="mo" id="MathJax-Span-48">∈ </span><span class="texatom" id="MathJax-Span-49"><span class="mrow" id="MathJax-Span-50"><span class="mi" id="MathJax-Span-51">C</span></span></span></span></span></span></em> with <em><span class="MathJax" id="MathJax-Element-8-Frame"><span class="math" id="MathJax-Span-52"><span class="mrow" id="MathJax-Span-53"><span class="texatom" id="MathJax-Span-54"><span class="mrow" id="MathJax-Span-55"><span class="mo" id="MathJax-Span-56">|</span></span></span><span class="mi" id="MathJax-Span-57">z</span><span class="texatom" id="MathJax-Span-58"><span class="mrow" id="MathJax-Span-59"><span class="mo" id="MathJax-Span-60">|</span></span></span><span class="mo" id="MathJax-Span-61">=</span><span class="mn" id="MathJax-Span-62">1</span></span></span></span></em>. This confirms a conjecture of Littlewood from 1966.</p>
<h3><span style="color: #0000ff;">A little more about the result</span></h3>
<p>It is still a major open problem to replace <img alt="\delta" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdelta&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\delta"/> by <img alt="(1-o(1))" class="latex" src="https://s0.wp.com/latex.php?latex=%281-o%281%29%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(1-o(1))"/> and <img alt="\Delta" class="latex" src="https://s0.wp.com/latex.php?latex=%5CDelta&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Delta"/> by <img alt="1+o(1)" class="latex" src="https://s0.wp.com/latex.php?latex=1%2Bo%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1+o(1)"/> (ultra-flat polynomials).</p>
<p>The problem can be traced back to a 1916 paper by Hardy and Littlewood.</p>
<p>Shapiro (1959) and Rudin (1959) showed the existence of such polynomials when you only require <img alt="P(z) \le \Delta \sqrt n" class="latex" src="https://s0.wp.com/latex.php?latex=P%28z%29+%5Cle+%5CDelta+%5Csqrt+n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P(z) \le \Delta \sqrt n"/> for all <em><span class="MathJax" id="MathJax-Element-7-Frame"><span class="math" id="MathJax-Span-45"><span class="mrow" id="MathJax-Span-46"><span class="mi" id="MathJax-Span-47">z </span><span class="mo" id="MathJax-Span-48">∈ </span><span class="texatom" id="MathJax-Span-49"><span class="mrow" id="MathJax-Span-50"><span class="mi" id="MathJax-Span-51">C</span></span></span></span></span></span></em> with <em><span class="MathJax" id="MathJax-Element-8-Frame"><span class="math" id="MathJax-Span-52"><span class="mrow" id="MathJax-Span-53"><span class="texatom" id="MathJax-Span-54"><span class="mrow" id="MathJax-Span-55"><span class="mo" id="MathJax-Span-56">|</span></span></span><span class="mi" id="MathJax-Span-57">z</span><span class="texatom" id="MathJax-Span-58"><span class="mrow" id="MathJax-Span-59"><span class="mo" id="MathJax-Span-60">|</span></span></span><span class="mo" id="MathJax-Span-61">=</span><span class="mn" id="MathJax-Span-62">1</span></span></span></span></em>.</p>
<p>The new result confirms a conjecture of Littlewood from 1966 and answers a question by Erdős from 1957.</p>
<p>If one allows complex coefficients of absolute value one, ultra flat polynomials exist by a result of Kahane (1980). Bombieri and Bourgain (2009) gave an explicit construction with sharper bounds.</p>
<p>The proof relies strongly on Spencer’s famous result :”Six standard deviation suffices”.  (In fact, on a version of Spencer’s result by Lovett and Meka.)<span id="more-17957"/></p>
<h3><span style="color: #0000ff;">Six standard deviation suffices</span></h3>
<p>Here is a reminder of Spencer’s theorem. (See <a href="https://rjlipton.wordpress.com/2019/07/25/discrepancy-games-and-sensitivity/">this GLL post;</a> We talked about it before and also on related results in Discrepancy’s theory, see <a href="https://gilkalai.wordpress.com/2011/08/28/discrepancy-the-beck-fiala-theorem-and-the-answer-to-test-your-intuition-14/">this post</a> and <a href="https://gilkalai.wordpress.com/2013/08/08/poznan-random-structures-and-algorithms-2013/">this one</a> and also <a href="https://gowers.wordpress.com/2012/08/27/edp23-second-guest-post-by-gil-kalai/">this one</a> on Gowers’s blog.)</p>
<p>Spencer’s “Six standard deviation suffices” theorem:  If <img alt="L_i(x_1,\dots,x_n)=" class="latex" src="https://s0.wp.com/latex.php?latex=L_i%28x_1%2C%5Cdots%2Cx_n%29%3D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="L_i(x_1,\dots,x_n)="/> <img alt="= a_{i1} x_1 + \dots + a_{in} x_n," class="latex" src="https://s0.wp.com/latex.php?latex=%3D+a_%7Bi1%7D+x_1+%2B+%5Cdots+%2B+a_%7Bin%7D+x_n%2C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="= a_{i1} x_1 + \dots + a_{in} x_n,"/> <img alt="\quad 1 \leq i \leq n," class="latex" src="https://s0.wp.com/latex.php?latex=%5Cquad+1+%5Cleq+i+%5Cleq+n%2C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\quad 1 \leq i \leq n,"/> are <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> linear forms in <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> variables with all <img alt="|a_{ij}| \leq 1" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ca_%7Bij%7D%7C+%5Cleq+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|a_{ij}| \leq 1"/>, then there exist numbers <img alt="\varepsilon_1,\dots,\varepsilon_n \in \{-1,+1\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cvarepsilon_1%2C%5Cdots%2C%5Cvarepsilon_n+%5Cin+%5C%7B-1%2C%2B1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\varepsilon_1,\dots,\varepsilon_n \in \{-1,+1\}"/> such that <img alt="|L_i(\varepsilon_1,\dots,\varepsilon_n)| \leq K \sqrt{n}," class="latex" src="https://s0.wp.com/latex.php?latex=%7CL_i%28%5Cvarepsilon_1%2C%5Cdots%2C%5Cvarepsilon_n%29%7C+%5Cleq+K+%5Csqrt%7Bn%7D%2C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|L_i(\varepsilon_1,\dots,\varepsilon_n)| \leq K \sqrt{n},"/> for all <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/>.</p>
<h3><span style="color: #0000ff;">My favorite (rather) flat polynomial: the determinant</span></h3>
<p>The determinant thought of as a polynomial of <img alt="n^2" class="latex" src="https://s0.wp.com/latex.php?latex=n%5E2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n^2"/> variable is rather flat as far as upper bounds are concerned.  (Moreover, if you restrict yourself to matrices where the rows are orthonormal then the determinant is constant.) I will be happy to learn about  other rather-flat examples of explicit and algebraically significant polynomials. (Even on sub-varieties.)</p>
<p>Remark: Here is <a href="https://arxiv.org/abs/1904.04806">a paper by the same team</a> on Erdős’ covering systems.</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/09/bollobas-erdos-1.png"><img alt="" class="alignnone size-full wp-image-18016" src="https://gilkalai.files.wordpress.com/2019/09/bollobas-erdos-1.png?w=640"/></a></p></div>
    </content>
    <updated>2019-09-09T05:01:21Z</updated>
    <published>2019-09-09T05:01:21Z</published>
    <category term="Analysis"/>
    <category term="Combinatorics"/>
    <category term="B&#xE9;la Bollob&#xE1;s"/>
    <category term="Flat polynomials"/>
    <category term="Julian Sahasrabudhe"/>
    <category term="Marius Tiba"/>
    <category term="Paul Balister"/>
    <category term="Robert Morris"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-09-13T08:20:37Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16231</id>
    <link href="https://rjlipton.wordpress.com/2019/09/08/separating-words-by-automata/" rel="alternate" type="text/html"/>
    <title>Separating Words by Automata</title>
    <summary>Another exponential gap in complexity theory? [ From his home page ] Jeffrey Shallit is a famous researcher into many things, including number theory and being a skeptic. He has a colorful website with an extensive quotation page—one of my favorites by Howard Aiken is right at the top: Don’t worry about people stealing an […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Another exponential gap in complexity theory?</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2019/09/08/separating-words-by-automata/unknown-127/" rel="attachment wp-att-16234"><img alt="" class="alignright size-full wp-image-16234" src="https://rjlipton.files.wordpress.com/2019/09/unknown-1.jpeg?w=600"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">[ From his home page ]</font></td>
</tr>
</tbody>
</table>
<p>
Jeffrey Shallit is a famous researcher into many things, including number theory and being a skeptic. He has a colorful website with an extensive quotation <a href="https://cs.uwaterloo.ca/~shallit/quotes.html">page</a>—one of my favorites by Howard Aiken is right at the top:</p>
<blockquote><p><b> </b> <em> Don’t worry about people stealing an idea. If it’s original, you will have to ram it down their throats. </em>
</p></blockquote>
<p/><p>
Today I thought I would discuss a wonderful problem that Jeffrey has worked on.</p>
<p>
Jeffrey’s <a href="https://arxiv.org/abs/1103.4513">paper</a> is joint with Erik Demaine, Sarah Eisenstat, and David Wilson. See also his <a href="https://cs.uwaterloo.ca/~shallit/Talks/bc4.pdf">talk</a>. They say in their introduction:</p>
<blockquote><p><b> </b> <em> Imagine a computing device with very limited powers. What is the simplest computational problem you could ask it to solve? It is not the addition of two numbers, nor sorting, nor string matching—it is telling two inputs apart: distinguishing them in some way. </em>
</p></blockquote>
<p/><p>
More formally: </p>
<blockquote><p><b> </b> <em> Let <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{x}"/> and <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{y}"/> be two distinct <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n}"/> long strings over the usual binary alphabet. What is the size of the smallest deterministic automaton <img alt="{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{M}"/> that can accept one of the strings and reject the other? </em>
</p></blockquote>
<p/><p>
That is, how hard is it for a simple type of machine to tell <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> apart from <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y}"/>? There is no super cool name for the question—it is called the <i>Separating Words Problem</i> (<a href="https://en.wikipedia.org/wiki/Separating_words_problem">SWP</a>). </p>
<p>
</p><p/><h2> Some History </h2><p/>
<p/><p>
Pavel Goral&amp;ccaron;ik and Vaclav Koubek introduced the problem in 1986—see their paper <a href="https://link.springer.com/chapter/10.1007/3-540-16761-7_61">here</a>. Suppose that <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> and <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y}"/> are distinct binary words of length <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>. Define <img alt="{\bf{SEP}(x,y)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbf%7BSEP%7D%28x%2Cy%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bf{SEP}(x,y)}"/> to be the number of states of the smallest automaton that accepts <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> and rejects <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y}"/> or vice-versa. They proved the result that got people interested:</p>
<blockquote><p><b>Theorem 1</b> <em> For all distinct binary words <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{x}"/> and <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{y}"/> of length <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n}"/>, 	</em></p><em>
<p align="center"><img alt="\displaystyle  {\bf SEP}(x,y) =o(n). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7B%5Cbf+SEP%7D%28x%2Cy%29+%3Do%28n%29.+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="\displaystyle  {\bf SEP}(x,y) =o(n). "/></p>
</em><p><em/>
</p></blockquote>
<p>That is the size of the automaton is asymptotically sub-linear. Of course there is trivially a way to tell the words apart with order <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> states. The surprise is that one can do better, always.</p>
<p>
In 1989 John Robson obtained the best known result: </p>
<blockquote><p><b>Theorem 2</b> <em> For all distinct binary words <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{x}"/> and <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{y}"/> of length <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n}"/>, 	</em></p><em>
<p align="center"><img alt="\displaystyle  {\bf SEP}(x,y) = O(n^{2/5}(\log n)^{3/5}). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7B%5Cbf+SEP%7D%28x%2Cy%29+%3D+O%28n%5E%7B2%2F5%7D%28%5Clog+n%29%5E%7B3%2F5%7D%29.+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="\displaystyle  {\bf SEP}(x,y) = O(n^{2/5}(\log n)^{3/5}). "/></p>
</em><p><em/>
</p></blockquote>
<p/><p>
This bound is pretty strange. We rarely see bounds like it. This suggest to me that it is either special or it is not optimal. Not clear which is the case. By the way it is also known that there are <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> and <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y}"/> so that </p>
<p align="center"><img alt="\displaystyle  {\bf SEP}(x,y) = \Omega(\log n). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7B%5Cbf+SEP%7D%28x%2Cy%29+%3D+%5COmega%28%5Clog+n%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  {\bf SEP}(x,y) = \Omega(\log n). "/></p>
<p>Thus there is an exponential gap between the known lower and upper bounds. Welcome to complexity theory.</p>
<p>
What heightens interest in this gap is that whenever the words have different lengths, there is always a logarithmic-size automaton that separates them. The reason is our old friend, the Chinese Remainder Theorem. Simply, if <img alt="{m &lt; n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm+%3C+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m &lt; n}"/> there is always a short prime <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> that does not divide <img alt="{n - m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn+-+m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n - m}"/>, which means that the DFA that goes in a cycle of length <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> will end in a different state on any <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> of length <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m}"/> from the state on any <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y}"/> of length <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>. Moreover, the strings <img alt="{0^m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%5Em%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0^m}"/> and <img alt="{0^N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%5EN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0^N}"/> where <img alt="{N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N}"/> equals <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m}"/> plus the least common multiple of <img alt="{1,\dots,m+1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%2C%5Cdots%2Cm%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1,\dots,m+1}"/> require <img alt="{\Omega(\log N)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5COmega%28%5Clog+N%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Omega(\log N)}"/> states to separate. Padding these with <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>s gives equal-length pairs of all lengths <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> giving <b>SEP</b>(x,y)<img alt="{\sim \log n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csim+%5Clog+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\sim \log n}"/>.</p>
<p>
Some other facts about SWP can be found in the paper:</p>
<ul>
<li>
(a) It does not matter whether the alphabet is binary or larger. <p/>
</li><li>
(b) For random distinct <img alt="{x,y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%2Cy%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x,y}"/>, the expected number of states needed to separate them is at most <img alt="{4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{4}"/>. <p/>
</li><li>
(c) All length-<img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> pairs <img alt="{x,y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%2Cy%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x,y}"/> can be distinguished by deterministic pushdown automata (with two-way input tape) of size <img alt="{O(\log n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%28%5Clog+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{O(\log n)}"/>.
</li></ul>
<p>
Point (b) underscores why it has been hard to find “bad pairs” that defeat all small DFAs. All this promotes belief that logarithmic is the true upper bound as well. Jeffrey stopped short of calling this a conjecture in his talk, but he did offer a 100-pound prize (the talk was in Britain) for improving Robson’s bound. </p>
<p>
</p><p/><h2> Some Questions </h2><p/>
<p/><p>
There are many partial results in cases where <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> and <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y}"/> are restricted in some way. See the papers for details. I thought I would just repeat a couple of interesting open cases.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> How hard is it to tell words from their reversal? That is, if <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> is a word can we prove a better bound on 	</p>
<p align="center"><img alt="\displaystyle  {\bf SEP}(x,x^{R}). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7B%5Cbf+SEP%7D%28x%2Cx%5E%7BR%7D%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  {\bf SEP}(x,x^{R}). "/></p>
<p>Recall <img alt="{x^{R}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%5E%7BR%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x^{R}}"/> is the reversal of the word <img alt="{w}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{w}"/>. Of course we assume that <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> is not the same as its reversal—that is, we assume that <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> is not a palindrome.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> How hard is it to tell words apart from their cyclic shifts?</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> How hard is it to tell words from their <img alt="{\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\dots}"/> You get the idea: try other operations on words. </p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
The SWP is a neat question in my opinion. I wonder if there would be some interesting consequence if we could always tell two words apart with few states. The good measure of a conjecture is: how many consequences are there that follow from it? I wonder if there could be some interesting applications. What do you think?</p>
<p/></font></font></div>
    </content>
    <updated>2019-09-08T20:47:05Z</updated>
    <published>2019-09-08T20:47:05Z</published>
    <category term="History"/>
    <category term="Open Problems"/>
    <category term="People"/>
    <category term="Proofs"/>
    <category term="automata"/>
    <category term="exponential gap"/>
    <category term="open problem"/>
    <category term="seperate"/>
    <category term="words"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-09-13T08:20:43Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/114</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/114" rel="alternate" type="text/html"/>
    <title>TR19-114 |  Singular tuples of matrices is not a null cone (and, the symmetries of algebraic varieties) | 

	Visu Makam, 

	Avi Wigderson</title>
    <summary>The following multi-determinantal algebraic variety plays a central role in algebra, algebraic geometry and computational complexity theory: ${\rm SING}_{n,m}$, consisting of all $m$-tuples of $n\times n$ complex matrices which span only singular matrices. In particular, an efficient deterministic algorithm testing membership in ${\rm SING}_{n,m}$ will imply super-polynomial circuit lower bounds, a holy grail of the theory of computation.
  A sequence of recent works suggests such efficient algorithms for memberships in a general class of algebraic varieties, namely the null cones of linear group actions. Can this be used for the problem above? Our main result is negative: ${\rm SING}_{n,m}$ is not the null cone of any (reductive) group action! This stands in stark contrast to a non-commutative analog of this variety, and points to an inherent structural difficulty of ${\rm SING}_{n,m}$.
  To prove this result we identify precisely the group of symmetries of ${\rm SING}_{n,m}$. We find this characterization, and the tools we introduce to prove it, of independent interest. Our work significantly generalizes a result of Frobenius for the special case $m=1$, and suggests a general method for determining the symmetries of algebraic varieties.</summary>
    <updated>2019-09-08T06:43:31Z</updated>
    <published>2019-09-08T06:43:31Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-09-13T08:20:33Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-8890204.post-2445620530813705016</id>
    <link href="http://mybiasedcoin.blogspot.com/feeds/2445620530813705016/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=8890204&amp;postID=2445620530813705016" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/8890204/posts/default/2445620530813705016" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/8890204/posts/default/2445620530813705016" rel="self" type="application/atom+xml"/>
    <link href="http://mybiasedcoin.blogspot.com/2019/09/off-to-algoesa-2019.html" rel="alternate" type="text/html"/>
    <title>Off to ALGO/ESA 2019</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">I'm shortly hopping on a plane to head to ALGO/ESA.  I'll be giving a survey-ish talk on Learning Augmented Algorithms, covering my work so far in the area as well as some of the work by others.  I think it's a highly promising direction fitting in the framework of Beyond Worst Case Analysis, so I'm excited to give the talk, and hoping it's still a novel enough area to be new to most of the audience. <br/><br/>For those of you who are there, feel free to say hi -- I'm looking forward to talking to people. <br/><br/><br/></div>
    </content>
    <updated>2019-09-07T19:59:00Z</updated>
    <published>2019-09-07T19:59:00Z</published>
    <author>
      <name>Michael Mitzenmacher</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/02161161032642563814</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-8890204</id>
      <category term="conferences"/>
      <category term="research"/>
      <category term="society"/>
      <category term="algorithms"/>
      <category term="administration"/>
      <category term="teaching"/>
      <category term="Harvard"/>
      <category term="papers"/>
      <category term="graduate students"/>
      <category term="funding"/>
      <category term="talks"/>
      <category term="blogs"/>
      <category term="codes"/>
      <category term="jobs"/>
      <category term="reviews"/>
      <category term="personal"/>
      <category term="travel"/>
      <category term="undergraduate students"/>
      <category term="books"/>
      <category term="open problems"/>
      <category term="PCs"/>
      <category term="consulting"/>
      <category term="randomness"/>
      <category term="CCC"/>
      <category term="blog book project"/>
      <category term="research labs"/>
      <category term="ISIT"/>
      <category term="tenure"/>
      <category term="comments"/>
      <category term="recommendations"/>
      <category term="outreach"/>
      <category term="students"/>
      <author>
        <name>Michael Mitzenmacher</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06738274256402616703</uri>
      </author>
      <link href="http://mybiasedcoin.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/8890204/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://mybiasedcoin.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/8890204/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">My take on computer science -- <br/> 
algorithms, networking, information theory -- <br/> 
and related items.</div>
      </subtitle>
      <title>My Biased Coin</title>
      <updated>2019-09-09T05:02:53Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4297</id>
    <link href="https://www.scottaaronson.com/blog/?p=4297" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4297#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4297" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">A rare classified ad</title>
    <summary xml:lang="en-US">Dana and I are searching for a live-in nanny for our two kids, Lily (age 6) and Daniel (age 2). We can offer $750/week. We can also offer a private room with a full bathroom and a beautiful view in our home in central Austin, TX, as well as free food and other amenities. The […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>Dana and I are searching for a live-in nanny for our two kids, Lily (age 6) and Daniel (age 2).  We can offer $750/week.  We can also offer a private room with a full bathroom and a beautiful view in our home in central Austin, TX, as well as free food and other amenities.  The responsibilities include helping to take the kids to and from school and drive them to various activities, helping to get them ready for school/daycare in the morning and ready for sleep at night, cooking and other housework.  We’d ask for no more than 45 hours per week, and could give several days off at a time depending on scheduling constraints.</p>



<p>If interested, please shoot me an email, tell me all about yourself and provide references.</p>



<p>Obviously, feel free to let anyone else know who you think might be interested (but who might not read this blog).</p>



<p>I’m really sorry to be doing this here!  We tried on classified sites and didn’t find a good match.</p></div>
    </content>
    <updated>2019-09-07T15:35:07Z</updated>
    <published>2019-09-07T15:35:07Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="The Fate of Humanity"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2019-09-10T22:56:44Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-1092995341963635215</id>
    <link href="https://blog.computationalcomplexity.org/feeds/1092995341963635215/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/09/transitioning.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/1092995341963635215" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/1092995341963635215" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/09/transitioning.html" rel="alternate" type="text/html"/>
    <title>Transitioning</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">You may have noticed, or not, that I haven't posted or tweeted much in the last month. I've had a busy time moving back to Chicago and starting my new position as Dean of the College of Science at Illinois Tech.<br/>
<div>
<br/></div>
<div>
Part of that trip involved driving my electric Chevy Bolt from Atlanta to Chicago. You can do it, but it got a bit nerve wracking. There is only one high-speed charging station between Indianapolis and Chicago and you pray the charger outside the Lafayette Walmart actually works (it did). We passed many Tesla charging superstations, I will have to admit they have the better network. </div>
<div>
<br/></div>
<div>
Theoremwise, Ryan Alweiss, Shachar Lovett, Kewen Wu and Jiapeng Zhang had <a href="https://gilkalai.wordpress.com/2019/08/23/amazing-ryan-alweiss-shachar-lovett-kewen-wu-jiapeng-zhang-made-dramatic-progress-on-the-sunflower-conjecture/">significant improvements on the sunflower conjecture</a>. I posted on the sunflower theorem for Richard Rado's <a href="https://blog.computationalcomplexity.org/2006/04/richard-rado-1906-1989.html">centenary</a>. Nice to see there is still some give in it.</div>
<div>
<br/></div>
<div>
I probably will post less often in this new position. Bill asked me "Why is being a dean (or maybe its just the move) more time then being a chair? Were you this busy when you moved and first became chair?"<br/>
<br/>
When I moved to Atlanta, I moved a year ahead of the rest of the family and rented a condo. We had plenty of time to search for a house in Atlanta and plan the move. Here it all happened in a much more compressed time schedule and, since we've bought a condo, into a much more compressed space.</div>
<div>
<br/></div>
<div>
Being a chair certainly ate up plenty of time but it feels different as dean with a more external focus. I won't give up the blog but you'll probably hear a lot more from Bill than from me at least in the near future.</div></div>
    </content>
    <updated>2019-09-05T16:03:00Z</updated>
    <published>2019-09-05T16:03:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-09-11T09:48:34Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/113</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/113" rel="alternate" type="text/html"/>
    <title>TR19-113 |  Instance Complexity and Unlabeled Certificates in the Decision Tree Model | 

	Tomer Grossman, 

	Ilan Komargodski, 

	Moni Naor</title>
    <summary>Instance complexity is a measure of goodness of an algorithm in which the performance of one algorithm is compared to others per input. This is in sharp contrast to worst-case and average-case complexity measures, where the performance is compared either on the worst input or on an average one, respectively.

  We initiate the systematic study of instance complexity and optimality in the query model (a.k.a. the decision tree model). In this model, instance optimality of an algorithm for computing a function is the requirement that the complexity of an algorithm on any input is at most a constant factor larger than the complexity of the best correct algorithm. That is we compare the decision tree to one that receives a certificate and its complexity is measured only if the certificate is correct (but correctness should hold on any input).  We study both deterministic and randomized decision trees and provide various characterizations and barriers for more general results.

  We introduce a new measure of complexity called unlabeled-certificate complexity, appropriate for graph properties and other functions with symmetries, where information about the structure of the graph is given as a certificate, but not labels of individual vertices. More precisely, the certificate is some permutation of the input (rather than the input itself) and the correctness should be maintained even if the certificate is wrong. We study both worst case complexity and instance optimality with respect to this measure of complexity. In this setting an algorithm is said to be instance optimal if for every input it performs roughly as well as the best algorithm that is given an unlabeled certificate (but is correct on every input).  We show that instance optimality depends on the group of permutations in consideration. Our proofs rely on techniques from hypothesis testing and analysis of random graphs.</summary>
    <updated>2019-09-05T15:39:45Z</updated>
    <published>2019-09-05T15:39:45Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-09-13T08:20:33Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://emanueleviola.wordpress.com/?p=662</id>
    <link href="https://emanueleviola.wordpress.com/2019/09/05/e-ink-monitor-the-best-money-i-have-ever-spent-on-electronics/" rel="alternate" type="text/html"/>
    <title>E-ink monitor: the best money I have ever spent on electronics</title>
    <summary>We briefly interrupt the on-flight entertainment for an update on e-ink monitors (see previous posts here and here).  I am happy to report that during the summer my e-ink monitor worked extremely well.  Writing as I am doing now with the sun shining through my window is fantastic.  My entire summer production — including this […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p style="text-align: justify;">We briefly interrupt the <a href="https://emanueleviola.wordpress.com/2019/08/04/because-of-pollution-conferences-should-be-virtual/">on-flight entertainment</a> for an update on e-ink monitors (see previous posts <a href="https://emanueleviola.wordpress.com/2019/05/05/e-ink-on-the-move/">here</a> and <a href="https://emanueleviola.wordpress.com/2019/03/07/a-dream-come-true-sort-of-e-ink-monitors/">here</a>).  I am happy to report that during the summer my e-ink monitor worked extremely well.  Writing as I am doing now with the sun shining through my window is fantastic.  My entire summer production — including this <a href="https://emanueleviola.wordpress.com/2019/07/10/non-abelian-combinatorics-and-communication-complexity/">survey on non-abelian combinatorics</a> — was written exclusively on the e-ink monitor. I don’t think I ever felt so good about a piece of electronics since relentless market pressure forced me to abandon Amiga.</p></div>
    </content>
    <updated>2019-09-05T13:32:56Z</updated>
    <published>2019-09-05T13:32:56Z</published>
    <category term="Uncategorized"/>
    <category term="health"/>
    <category term="tech"/>
    <author>
      <name>Manu</name>
    </author>
    <source>
      <id>https://emanueleviola.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://emanueleviola.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://emanueleviola.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://emanueleviola.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://emanueleviola.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>by Manu</subtitle>
      <title>Thoughts</title>
      <updated>2019-09-13T08:21:12Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>http://ptreview.sublinear.info/?p=1178</id>
    <link href="https://ptreview.sublinear.info/?p=1178" rel="alternate" type="text/html"/>
    <title>News for August 2019</title>
    <summary>A comparatively slow month, as summer draws to a close: we found three papers online. Please let us know if we missed any! (Edit: And we added two papers missed from June.) Testing convexity of functions over finite domains, by Aleksandrs Belovs, Eric Blais, and Abhinav Bommireddi (arXiv). This paper studies the classic problem of […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>A comparatively slow month, as summer draws to a close: we found three papers online. Please let us know if we missed any! <em>(Edit: And we added two papers missed from June.) </em></p>



<p><strong>Testing convexity of functions over finite domains</strong>, by Aleksandrs Belovs, Eric Blais, and Abhinav Bommireddi (<a href="https://eccc.weizmann.ac.il/report/2019/092/">arXiv</a>). This paper studies the classic problem of convexity testing, and proves a number of interesting results on the adaptive and non-adaptive complexity of this problem in single- and multi-dimensional settings. In the single-dimensional setting on domain \([n]\), they show that adaptivity doesn’t help: the complexity will be \(O(\log n)\) in both cases. However, in the simplest two-dimensional setting, a domain of \([3] \times [n]\), they give a polylogarithmic upper bound in the adaptive setting, but a polynomial lower bound in the non-adaptive setting, showing a strong separation. Finally, they provide a lower bound for \([n]^d\) which scales exponentially in the dimension. This leaves open the tantalizing open question: is it possible to avoid the curse of dimensionality when testing convexity?</p>



<p><strong>Testing Isomorphism in the Bounded-Degree Graph Model</strong>, by Oded Goldreich (<a href="https://eccc.weizmann.ac.il/report/2019/102/">ECCC</a>). This work investigates the problem of testing isomorphism of graphs, focusing on the special case when the connected components are only polylogarithmically large (the general bounded-degree case is left open). One can consider when a graph is given as input, and we have to query a graph to test if they are isomorphic. This can be shown to be equivalent (up to polylogarithmic factors) to testing (from queries) whether a sequence is a permutation of a reference sequence. In turn, this can be shown to be equivalent to the classic distribution testing question of testing (from samples) whether a distribution is equal to some reference distribution. The same sequence of equivalences <em>almost</em> works for the case where there is no reference graph/sequence/distribution, but we only have query/query/sample access to the object. The one exception is that the reduction doesn’t work to reduce from testing distributions to testing whether a sequence is a permutation, due to challenges involving sampling with and without replacement. However, the author still shows the lower bound which would be implied by such a reduction by adapting Valiant’s proof for the distribution testing problem to this case.   </p>



<p><strong>Learning Very Large Graphs with Unknown Vertex Distributions</strong>, by Gábor Elek (<a href="https://arxiv.org/abs/1908.10170">arXiv</a>). In this note, the author studies a variant of distribution-free property testing on graphs, in which (roughly) neighboring vertices have probabilities of bounded ratio, and a query reveals this ratio. Applications to local graph algorithms and connections to dynamical systems are also discussed.</p>



<p>EDIT: We apparently missed two papers from June — the  first paper was accepted to NeurIPS 2019, the second to COLT 2019.<br/><strong>The Broad Optimality of Profile Maximum Likelihood</strong>, by Yi Hao and Alon Orlitsky (<a href="https://arxiv.org/abs/1908.10170">arXiv</a>). Recently, Acharya, Das, Orlitsky, and Suresh (ICML 2017) showed that the Profile Maximum Likelihood (PML) estimator enables a unified framework for estimating a number of distribution properties, including support size, support coverage, entropy, and distance to uniformity, obtaining estimates which are competitive with the best possible. The approach is rather clean: simply estimate the PML of the distribution (i.e., the maximum likelihood distribution of the data, if the the labels are discarded and only the multiplicities of elements are kept), and apply the plug-in estimator (i.e., if you want to estimate entropy, compute the entropy of the resulting PML distribution). The present work shows that PML is even more broadly applicable — such an approach applies to <em>any</em> property which is additive, symmetric, and appropriately Lipschitz. They also show specific results for many other properties which have been considered in the past, including Rényi entropy, distribution estimation, and identity testing.</p>



<p><strong>Sample-Optimal Low-Rank Approximation of Distance Matrices</strong> by Piotr Indyk, Ali Vakilian, Tal Wagner, David Woodruff (<a href="https://arxiv.org/abs/1906.00339">arXiv</a>). Getting a rank \(k\) approximation of an \(n \times m\) matrix \(M\) is about as classic a problem as it gets. Suppose we wanted a running time of \(O(n+m)\), which is sublinear in the matrix size. In general, this is not feasible, since there could be a single large entry that dominates the matrix norm. This paper studies the case where the matrix is itself a <em>distance matrix</em>. So there is an underlying point set in a metric space, and the \(i, j\)th entry of \(M\) is the distance between the $i$th and $j$th point. Previous work showed the existence of \(O((n+m)^{1+\gamma})\) time algorithms (for arbitrary small constant $\gamma &gt; 0$, with polynomial dependence on \(k\) and error parameters). This work gives an algorithm that runs in \(\widetilde{O}(n+m)\) time. The main idea is to sample the rows and columns according to row/column norms. </p></div>
    </content>
    <updated>2019-09-04T21:00:30Z</updated>
    <published>2019-09-04T21:00:30Z</published>
    <category term="Monthly digest"/>
    <author>
      <name>Gautam Kamath</name>
    </author>
    <source>
      <id>https://ptreview.sublinear.info</id>
      <link href="https://ptreview.sublinear.info/?feed=rss2" rel="self" type="application/atom+xml"/>
      <link href="https://ptreview.sublinear.info" rel="alternate" type="text/html"/>
      <subtitle>The latest in property testing and sublinear time algorithms</subtitle>
      <title>Property Testing Review</title>
      <updated>2019-09-12T23:24:38Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=17977</id>
    <link href="https://gilkalai.wordpress.com/2019/09/04/computer-science-and-its-impact-on-our-future/" rel="alternate" type="text/html"/>
    <title>Computer Science and its Impact on our Future</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">A couple weeks ago I told you about Avi Wigderson’s vision on the connections between the theory of computing and other areas of mathematics on the one hand and between computer science and other areas of science, technology and society … <a href="https://gilkalai.wordpress.com/2019/09/04/computer-science-and-its-impact-on-our-future/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>A couple weeks ago I told you about <a href="https://gilkalai.wordpress.com/2019/08/04/avi-wigdersons-integrating-computational-modeling-algorithms-and-complexity-into-theories-of-nature-marks-a-new-scientific-revolution-an-invitation-for-a-discussion/">Avi Wigderson’s vision</a> on the connections between the theory of computing and other areas of mathematics on the one hand and between computer science and other areas of science, technology and society on the other hand.  In this spirit I am happy to inform about the conference “<a href="https://academy.ac.il/Index/Entry.aspx?nodeId=741&amp;entryId=21026">Computer Science and its Impact on the Future</a>” to be held in Jerusalem, September 16-18, 2019.  This is a joint conference of the Israel Academy of Science and Humanities and the (US) National academy of Science.  Incidentally, September 17 2019 is the general elections day in Israel which will also have some impact on our future.</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/09/cs-academy.jpg"><img alt="" class="alignnone size-full wp-image-17978" height="1274" src="https://gilkalai.files.wordpress.com/2019/09/cs-academy.jpg?w=640&amp;h=1274" width="640"/></a></p>
<p>The program has sessions on quantum science and technology, computer science and society, computation and the life sciences, and AI and autonomous systems. The keynote speaker is Amnon Shashua who will speak on the promise of machime learning and AI in transforming industries. Other speakers are: Charles Bennett, Adi Stern, Dorit Aharonov, and Thomas Vidick (quantum); Noam Nisan, Omer Reingold, Shafi Goldwasser, and Moshe Vardi (society); Aviv Regev, Ron Shamir, Uri Alon and Leroy Hood (biology), Sarit Kraus, Eva Tardos, Naftali Tishby, and Gal Kaminka (AI), and David Harel (closing remarks).</p>
<p>As for startling connections between the theory of computation and other areas of mathematics let me refer to the <a href="https://gilkalai.wordpress.com/2019/08/23/amazing-ryan-alweiss-shachar-lovett-kewen-wu-jiapeng-zhang-made-dramatic-progress-on-the-sunflower-conjecture/">very recent post</a> with the big news on the sunflower conjecture.</p>
<p><span style="color: #000080;">In the spirit of the coming Israeli elections let me promise to report more on our recent great Oberwolfach conference, on my visit to CERN, and to tell more about the sunflower progress, and about various combinatorics (and more) news I heard about. </span></p>
<p><strong>Update: </strong>in partial fulfillment of my promises here are a couple of pictures from CERN and Oberwolfach.</p>
<p><span id="more-17977"/></p>
<p><a href="https://gilkalai.files.wordpress.com/2019/09/d7a2d79fd79ad7a7d7a8d7a9d79ed791d7a7d7a8d79e.jpg"><img alt="&#x5E2;&#x5DF;&#x5DA;&#x5E7;&#x5E8;&#x5E9;&#x5DE;&#x5D1;&#x5E7;&#x5E8;&#x5DE;" class="alignnone size-full wp-image-17986" src="https://gilkalai.files.wordpress.com/2019/09/d7a2d79fd79ad7a7d7a8d7a9d79ed791d7a7d7a8d79e.jpg?w=640"/></a><a href="https://gilkalai.files.wordpress.com/2019/09/atlas.jpg"><img alt="ATLAS" class="alignnone size-full wp-image-17987" src="https://gilkalai.files.wordpress.com/2019/09/atlas.jpg?w=640"/></a><a href="https://gilkalai.files.wordpress.com/2019/09/ow.jpg"><img alt="OW" class="alignnone size-full wp-image-17988" src="https://gilkalai.files.wordpress.com/2019/09/ow.jpg?w=640"/></a></p>
<p>ATLAS@CERN with my son in law Eran Shriker; The view at Oberwolfach.</p></div>
    </content>
    <updated>2019-09-04T18:52:03Z</updated>
    <published>2019-09-04T18:52:03Z</published>
    <category term="Academics"/>
    <category term="Computer Science and Optimization"/>
    <category term="Quantum"/>
    <category term="Updates"/>
    <category term="computer science"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-09-13T08:20:36Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=7547</id>
    <link href="https://windowsontheory.org/2019/09/04/make-equations-blue-in-powerpoint/" rel="alternate" type="text/html"/>
    <title>Make equations blue in powerpoint</title>
    <summary>Microsoft Powerpoint has a surprisingly powerful equation editor, which also allows to use latex macros such as \alpha to get . I’ve blogged about the equation editor before but one pet peeve of mine was that I like to have my math in a different color, but never found a way to do this automatically. […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Microsoft Powerpoint has a surprisingly powerful equation editor, which also allows to use latex macros such as <code>\alpha </code>to get <img alt="\alpha" class="latex" src="https://s0.wp.com/latex.php?latex=%5Calpha&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\alpha"/>. </p>



<p>I’ve blogged about the equation editor <a href="https://windowsontheory.org/2013/01/31/alt-equals/">before</a> but one pet peeve of mine was that I like to have my math in a different color, but never found a way to do this automatically. I finally decided to invest the time and find out how to do it. After a mere several years of investigation, I am happy to report that it is in fact possible to do so using Visual Basic for Applications (VBA). </p>



<p>You can view the developer tab by following <a href="https://support.office.com/en-us/article/show-the-developer-tab-e1192344-5e56-4d45-931b-e5fd9bea2d45">these instructions</a>, and then click on “macros”, type a name such as <code>All_eqs</code> and click on  “create” at which point you can add the following code:</p>


<pre class="brush: vb; gutter: false; title: ; notranslate">Sub All_eqs()

Dim oSld As Slide
Dim oShp As Shape
Dim oShapes As Shapes
 
For Each oSld In ActivePresentation.Slides
  Set oShapes = oSld.Shapes
  For Each oShp In oShapes
   If oShp.HasTextFrame Then
      If oShp.TextFrame.HasText Then
                With oShp.TextFrame.TextRange
                    For x = 1 To .Characters.Count
                        If .Characters(x).Font.Name = "Cambria Math" Then
                            .Characters(x).Font.Color.RGB = RGB(0, 112, 192)
                        End If
                    Next x
                End With

    End If
    End If
    Next oShp
 Next oSld
End Sub

</pre></div>
    </content>
    <updated>2019-09-04T15:44:27Z</updated>
    <published>2019-09-04T15:44:27Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2019-09-13T08:21:02Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16223</id>
    <link href="https://rjlipton.wordpress.com/2019/09/04/self-play-is-key/" rel="alternate" type="text/html"/>
    <title>Self-Play Is Key?</title>
    <summary>Self-play and Ramsey numbers [ Talking about worst case ] Avrim Blum is the CAO for TTIC. That is he is the Chief Academic Officer at the Toyota Technological Institute of Chicago. Avrim has and continues to make key contributions to many areas of theory—including machine learning, approximation algorithms, on-line algorithms, algorithmic game theory, the […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Self-play and Ramsey numbers</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2019/09/04/self-play-is-key/unknown-126/" rel="attachment wp-att-16226"><img alt="" class="alignright size-full wp-image-16226" src="https://rjlipton.files.wordpress.com/2019/09/unknown.jpeg?w=600"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">[ Talking about worst case ]</font></td>
</tr>
</tbody>
</table>
<p>
Avrim Blum is the CAO for TTIC. That is he is the Chief Academic Officer at the Toyota Technological Institute of Chicago. Avrim has and continues to make key contributions to many areas of theory—including machine learning, approximation algorithms, on-line algorithms, algorithmic game theory, the theory of database privacy, and non-worst-case analysis of algorithms. </p>
<p>
Today I want to discuss a suggestion of Avrim for research on self-play.<span id="more-16223"/></p>
<p>
Self-play is the key to many recent AI results on playing games. These results include essentially solving the games Chess, Go, Shogi, forms of poker, and many others. They were solved by algorithms that start with no knowledge of the game, save the rules. The algorithm then learn the secrets of playing the game by self-play: by playing games against itself. For example, the AI chess programs did not know that “a rook is worth more than a pawn.” But they discover that by playing the game over and over. Impressive. </p>
<p>
For example, David Sweet on his hacker <a href="https://hackernoon.com/self-play-1f69ceb06a4d">site</a> says referring to self-play: </p>
<blockquote><p><b> </b> <em> This is mysterious to me. If it only played against itself, where did new information come from? How did it know if it was doing well? If I play a game of chess against myself, should I say I did well if I beat myself? But when I beat myself, I also lose to myself. And how could I ever know if I’d do well against someone else? </em>
</p></blockquote>
<p>
</p><p/><h2> Planted Clique Problem </h2><p/>
<p/><p>
I was at TTIC last month and over lunch we discussed self-play possibilities for theory problems. I suggested that the planted clique <a href="https://en.wikipedia.org/wiki/Planted_clique">problem</a> might be a potential example. Recall the planted clique problem is the task of distinguishing two types of graphs:</p>
<ul>
<li>
Random graphs on <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> vertices generated with <img alt="{p=1/2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%3D1%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p=1/2}"/>, the probability that there is an edge between each pair of nodes; <p/>
</li><li>
Random graphs on <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> vertices generated with <img alt="{p=1/2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%3D1%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p=1/2}"/>, with a clique of size <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/> added, the planted clique.
</li></ul>
<p>
If <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/> is large, it is easy to tell these apart—just count the number of edges. If <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/> is small enough, it is open if one can tell them apart. The largest clique in a random graph typically has size near <img alt="{k=2\log_{2} n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%3D2%5Clog_%7B2%7D+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k=2\log_{2} n}"/>. This implies that there is a quasi-polynomial time average-case algorithm: just try all subsets of size around <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/>.</p>
<p>
My intuition was that a program might be able to exploit self-play to solve planted clique problems. The point is that it is easy, by definition, to generate “yes” and “no” examples for this problem. Note, this is not known for SAT problems—generating hard instances there is not clear. This was my point. Could the AI methods somehow divine the planted clique version of “a rook is worth more than a pawn”? Could they use self-play to solve planted clique problems?</p>
<p>
I wondered to the lunch group about all this. It left the group unexcited. </p>
<p>
</p><p/><h2> Ramsey Problem </h2><p/>
<p/><p>
Then Avrim asked a better question. He wondered if self-play methods could be used to solve a long standing problem concerning Ramsey numbers. Recall the Ramsey number <img alt="{R(s,s)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%28s%2Cs%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R(s,s)}"/> is defined as the smallest <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> such every red-green coloring of the edges of the complete graph <img alt="{K_{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BK_%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{K_{n}}"/> has either a red or a green subgraph of size at least <img alt="{s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s}"/>.</p>
<p>
The exact value of <img alt="{R(5, 5)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%285%2C+5%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R(5, 5)}"/> is unknown, although it is known to lie between <img alt="{43}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B43%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{43}"/> and <img alt="{48}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B48%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{48}"/>. See a <a href="https://gilkalai.wordpress.com/2017/03/29/r55">post</a> by Gil Kalai on his blog for some discussions. Joel Spencer quotes Paul Erdős: </p>
<blockquote><p><b> </b> <em> Erdős asks us to imagine an alien force, vastly more powerful than us, landing on Earth and demanding the value of <img alt="{R(5, 5)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%285%2C+5%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{R(5, 5)}"/> or they will destroy our planet. In that case, he claims, we should marshal all our computers and all our mathematicians and attempt to find the value. But suppose, instead, that they ask for <img alt="{R(6, 6)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%286%2C+6%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{R(6, 6)}"/>. In that case, he believes, we should attempt to destroy the aliens.	 </em>
</p></blockquote>
<p/><p>
Aliens are not attacking currently, but Avrim’s idea is that perhaps we could organize a self-play attack on the <img alt="{R(5,5)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%285%2C5%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R(5,5)}"/> problem. The idea would be to try to build a “game” version of this question. The algorithm would try to create a strategy that finds a red/green coloring for the complete graph so that no <img alt="{5}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B5%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{5}"/>-clique is all red or all green. </p>
<p>
We need to arrange the computation of the Ramsey number as the result of some type of game. The paradox to me is that the play of a game suggests <img alt="{\mathsf{PSPACE}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BPSPACE%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{PSPACE}}"/>, while the Ramsey calculation is clearly of complexity <img alt="{\mathsf{NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{NP}}"/>. So how do we make the Ramsey calculation into a game? Ken and I wonder if there is a natural game <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> so that playing the game well yields insight into the value of a Ramsey number.</p>
<blockquote><p><b> </b> <em> <i>Is there a game <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{G}"/> with simple rules so that playing it well yields bounds on general Ramsey numbers?</i> </em>
</p></blockquote>
<p>
</p><p/><h2> Attacks on Ramsey Numbers </h2><p/>
<p/><p>
There have been several attempts to use non-standard methods to compute Ramsey numbers. See the following: </p>
<ul>
<li>
In this <a href="https://link.springer.com/article/10.1007/s11128-013-0541-9">article</a>, quantum methods studied for the future, when hopefully quantum computers will be available. <p/>
</li><li>
In this <a href="https://themusegarden.wordpress.com/2013/05/11/a-genetic-algorithm-approach-to-ramsey-theory/">project</a> genetic methods are used on related Ramsey numbers. <p/>
</li><li>
In this <a href="https://arxiv.org/pdf/1512.01613.pdf">approach</a>, AI methods are used on related Ramsey numbers.
</li></ul>
<p>
See also this <a href="https://pdfs.semanticscholar.org/0662/893d7e04745a0709b3f1a092574f9dd3bf7b.pdf">survey</a> on computational methods in general.</p>
<p>
The asymmetry between the upper and lower bounds shapes approaches. The lower bound of 43 was proved by finding a two-coloring of the edges of <img alt="{K_{42}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BK_%7B42%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{K_{42}}"/> without a green or red <img alt="{5}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B5%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{5}"/>-clique. Once a single coloring is guessed its property is easy to prove. The <a href="https://arxiv.org/abs/1703.08768">improvement</a> of the upper bound from 49 to 48 two years ago <a href="https://gilkalai.wordpress.com/2017/03/29/r55">needed</a> checking two trillion cases in order to fence-away all possible colorings. This has led to a common belief that 43 is the answer—if it were higher then a coloring of <img alt="{K_{43}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BK_%7B43%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{K_{43}}"/> would have been found by now.</p>
<p>
Can we use self-play to turn this belief into something more concrete? The training would begin on running self-play on the known cases <img alt="{\dots 38,39,40,41,42}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots+38%2C39%2C40%2C41%2C42%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\dots 38,39,40,41,42}"/>. This should create a neural net that is highly skilled at finding colorings that are free of small monochrome cliques. The question is how to leverage its presumed failure once we hit size <img alt="{43}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B43%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{43}"/>.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Perhaps someone should take Avrim’s suggestion and try it out. A natural idea would be to see if this approach could compute the known smaller Ramsey numbers—getting their exact upper bounds. </p>
<p/></font></font></div>
    </content>
    <updated>2019-09-04T13:08:00Z</updated>
    <published>2019-09-04T13:08:00Z</published>
    <category term="Ideas"/>
    <category term="Open Problems"/>
    <category term="P=NP"/>
    <category term="People"/>
    <category term="games"/>
    <category term="planted"/>
    <category term="planted clique"/>
    <category term="PSPACE"/>
    <category term="sel-play"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-09-13T08:20:43Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-8890204.post-8050522808291360907</id>
    <link href="http://mybiasedcoin.blogspot.com/feeds/8050522808291360907/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=8890204&amp;postID=8050522808291360907" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/8890204/posts/default/8050522808291360907" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/8890204/posts/default/8050522808291360907" rel="self" type="application/atom+xml"/>
    <link href="http://mybiasedcoin.blogspot.com/2019/09/happy-new-academic-year-teaching.html" rel="alternate" type="text/html"/>
    <title>Happy New Academic Year:  Teaching Randomized Algorithms</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">It seems I haven't written on this blog for a while.<br/><br/>Today was the start of a new semester.  I'll be teaching Randomized Algorithms and Probabilistic Analysis, using the new edition of my book with Eli Upfal as a base, and throwing in other material.  (Everyone should buy the book!  <a href="https://www.amazon.com/gp/product/110715488X/ref=as_li_tl?ie=UTF8&amp;tag=michaelmitzen-20&amp;camp=1789&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=110715488X&amp;linkId=d598fb636637ebb656410099e7042a7c">Here's a link</a>.)  <br/><br/>It's a graduate level class, but generally designed for first year graduate students, and there were a lot of undergrads "shopping" it today.  (We don't do pre-registration at Harvard, and students get the first week to choose classes, known as shopping.)  So many that people were standing out the doors of the room.  But because we have a bit of a shortage of classes this semester, I'm guessing there's a good fraction of students just checking it out.  We'll see Thursday, but for now I'll predict we'll fit in the classroom, and wait to see if I'm wrong.  (If I'm wrong, that's wonderful too.)    <br/><br/>It's been four years since I last taught the course, so this time I'm trying something new.  When I've previously taught the course, I tried to make the class inviting and friendly by telling the class we'd begin without assuming the class knew probability, and so the first couple of weeks would be reviewing basics (like, say, linearity of expectations and union bounds), albeit in a CS algorithms context.  This time, I let the class know I'm assuming they know (or will pick up) basic probability, and so they should read chapters 1-4 on their own, and we'll start with Chapter 5, Balls and Bins models.  Over the last decade, I've seen a huge shift in probability knowledge -- Stat 110, Harvard's probability course, has become one of Harvard's biggest classes.  Many students have already taking AI or ML or even data science courses where they've done some (further) probability.  It feels appropriate (and safe) to assume people entering in the class know probability, or can review what they need on their own, and start the class further along.<br/><br/>Now finally, a request.  It's actually hard for me to teach when using this book, because I don't want to just read the book to the students.  That's boring.  On the other hand, if I thought something was important, I most likely already put it in the book.  We have to mix up the standard lecturing format a bit.  So two things we'll be doing are<br/><br/>1)  doing some "puzzle problems" at the beginning of most classes, so people can try to solve problems.  (Kind of a flipped classroom approach, but not a full commitment.)<br/>2)  reading papers, related to the class topics.<br/><br/>So if you have any good suggestions of probability puzzle problems, or readable papers (particularly application papers) that use relatively basic probabilistic analysis in neat ways, send them over.  I've got a semester to fill.<br/><br/>For curious people, here's one of today's starting problems, which I first learned about in graduate school.  (I'm pretty sure I owe thanks to Claire Kenyon for teaching it.  I'll link to the corresponding Wikipedia page on the problem maybe later.)<br/><br/>After lunch, Bob suggests the following game to see who pays.  Alice and Bob will each choose a different sequence of three flips.  (So they could choose "Heads-Tails-Heads'', or "Tails-Tails-Tails'' for example.)  After they choose, a fair coin will be tossed until one of their sequences appears as a consecutive subsequence of the coin tosses.  The player whose sequence appears first wins. (Note that if they choose the above sequences, and if the flips come up Heads-Tails-Tails-Tails, the player that chose Tails-Tails-Tails would win as soon as their subsequence appears;  it's not three flips, then start over again.)  Bob politely says that Alice can choose first, and after she chooses and tells him her sequence he'll choose a different sequence.  What should Alice choose?</div>
    </content>
    <updated>2019-09-04T04:13:00Z</updated>
    <published>2019-09-04T04:13:00Z</published>
    <author>
      <name>Michael Mitzenmacher</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/02161161032642563814</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-8890204</id>
      <category term="conferences"/>
      <category term="research"/>
      <category term="society"/>
      <category term="algorithms"/>
      <category term="administration"/>
      <category term="teaching"/>
      <category term="Harvard"/>
      <category term="papers"/>
      <category term="graduate students"/>
      <category term="funding"/>
      <category term="talks"/>
      <category term="blogs"/>
      <category term="codes"/>
      <category term="jobs"/>
      <category term="reviews"/>
      <category term="personal"/>
      <category term="travel"/>
      <category term="undergraduate students"/>
      <category term="books"/>
      <category term="open problems"/>
      <category term="PCs"/>
      <category term="consulting"/>
      <category term="randomness"/>
      <category term="CCC"/>
      <category term="blog book project"/>
      <category term="research labs"/>
      <category term="ISIT"/>
      <category term="tenure"/>
      <category term="comments"/>
      <category term="recommendations"/>
      <category term="outreach"/>
      <category term="students"/>
      <author>
        <name>Michael Mitzenmacher</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06738274256402616703</uri>
      </author>
      <link href="http://mybiasedcoin.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/8890204/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://mybiasedcoin.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/8890204/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">My take on computer science -- <br/> 
algorithms, networking, information theory -- <br/> 
and related items.</div>
      </subtitle>
      <title>My Biased Coin</title>
      <updated>2019-09-09T05:02:53Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://adamsheffer.wordpress.com/?p=5440</id>
    <link href="https://adamsheffer.wordpress.com/2019/09/03/were-hiring/" rel="alternate" type="text/html"/>
    <title>We’re Hiring!</title>
    <summary>Come join us! This year our math department has two types of positions available. We have a standard tenure track position, which would hopefully continue our awesome sequence of recent hires. But this post is not about the standard position. Instead, I’d like to talk a bit about our other type of position – a […]</summary>
    <updated>2019-09-03T15:31:52Z</updated>
    <published>2019-09-03T15:31:52Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Adam Sheffer</name>
    </author>
    <source>
      <id>https://adamsheffer.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://adamsheffer.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://adamsheffer.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://adamsheffer.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://adamsheffer.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Discrete geometry and other typos</subtitle>
      <title>Some Plane Truths</title>
      <updated>2019-09-13T08:21:18Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-1820902627345115895</id>
    <link href="https://blog.computationalcomplexity.org/feeds/1820902627345115895/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/09/can-mathematicians-fix-iphones-can.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/1820902627345115895" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/1820902627345115895" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/09/can-mathematicians-fix-iphones-can.html" rel="alternate" type="text/html"/>
    <title>Can Mathematicians Fix Iphones? Can anyone?</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><br/>
In my last post I noted that if I am asked (since I am a CS prof)<br/>
<br/>
<i>Can you fix my iphone</i><br/>
<br/>
is<br/>
<br/>
<i>No, I work on the math side of CS</i><br/>
<br/>
Some readers emailed me (I told them to comment instead but they were worried that other readers would argue with them) that NO, this is a tired and incorrect stereotype.  Here are some samples:<br/>
<br/>
1) People in Mathematics are no better or worse at fixing iphones, fixing cars, programming their VCR's, etc than the public.<br/>
<br/>
2) For that matter, people in academica, even in practical sounding fields like Systems, are no better.<br/>
<br/>
3) Is your nephew Jason who used to fix forklifts for a living  better at these things then the general public? I asked him. Answer: No, though he is better at fixing forklifts.<br/>
<br/>
I think something else is going on here. Lets look at fixing your own car. I think this is the sort of thing that some people used to be able to do but now very few can do it. Cars have gotten more complicated. <br/>
<br/>
Iphones are not quite there yet but its getting that way.  <br/>
<br/>
Of course somethings have gotten easier--- programming a DVR is much easier than programming a VCR.   And people can easily use WORD or write programs without having to know any hardware.<br/>
<br/>
OKAY, after all these random thoughts, here is the question: What do you think? <br/>
<br/>
Are people in CS or Math or CS theory better at X than the general public where X is NOT CS, Math or CS theory, but something like fixing their cars?<br/>
<br/>
And<br/>
<br/>
What has gotten harder? What has gotten easier?<br/>
<br/>
<br/>
<br/></div>
    </content>
    <updated>2019-09-03T14:56:00Z</updated>
    <published>2019-09-03T14:56:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-09-11T09:48:34Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://theorydish.blog/?p=1506</id>
    <link href="https://theorydish.blog/2019/09/02/itcs-deadline-one-week-to-go/" rel="alternate" type="text/html"/>
    <title>ITCS Deadline: one week to go!</title>
    <summary>An announcement from the ITCS PC. With roughly a week left, here is a reminder that the 11th Innovations in Theoretical Computer Science (ITCS) submission deadline is next Monday, September 9th, at 5:59pm PST. For more details on the scope and specifics, please consult the CFP here; it also contains the link to the submission server. We’re looking forward to reading your excellent and innovative submissions from across TCS!</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><em>An announcement from the ITCS PC.</em></p>
<p>With roughly a week left, here is a reminder that the <em>11<sup>th</sup> Innovations in Theoretical Computer Science</em> (ITCS) submission deadline is next <strong>Monday, September 9<sup>th</sup>, at 5:59pm PST.</strong></p>
<p>For more details on the scope and specifics, please <a href="http://itcs-conf.org/itcs20/itcs20-cfp.html">consult the CFP here</a>; it also contains the link to the <a href="https://easychair.org/my/conference?conf=itcs20">submission server</a>. We’re looking forward to reading your excellent and innovative submissions from across TCS!</p></div>
    </content>
    <updated>2019-09-02T22:22:26Z</updated>
    <published>2019-09-02T22:22:26Z</published>
    <category term="Uncategorized"/>
    <category term="conference"/>
    <author>
      <name>ccanonne</name>
    </author>
    <source>
      <id>https://theorydish.blog</id>
      <logo>https://theorydish.files.wordpress.com/2017/03/cropped-nightdish1.jpg?w=32</logo>
      <link href="https://theorydish.blog/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://theorydish.blog" rel="alternate" type="text/html"/>
      <link href="https://theorydish.blog/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://theorydish.blog/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Stanford's CS Theory Research Blog</subtitle>
      <title>Theory Dish</title>
      <updated>2019-09-13T08:21:34Z</updated>
    </source>
  </entry>
</feed>
