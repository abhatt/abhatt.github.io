<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2019-07-01T12:21:51Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-7054757178293557182</id>
    <link href="https://blog.computationalcomplexity.org/feeds/7054757178293557182/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/06/a-proof-that-227-pi-0-and-more.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7054757178293557182" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7054757178293557182" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/06/a-proof-that-227-pi-0-and-more.html" rel="alternate" type="text/html"/>
    <title>A proof that 22/7 - pi &gt; 0 and more</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><br/>
My father was a High School English teacher who did not know much math. As I was going off to college, intending to major in math, he gave me the following sage advice:<br/>
<br/>
1) <i>Take Physics as well as Math since Physics and Math go well together.</i> This was good advice. I took the first year of Physics for Physics Majors, and I later took a senior course in Mechanics since that was my favorite part of the first year course. Kudos to Dad!<br/>
<br/>
2) π <i>is exactly </i>22/7. I knew this was not true, but I also keow that I had no easy way to show him this. In fact, I wonder if I could have proven it myself back then.<br/>
<br/>
I had not thought about this in many years when I came across the following:<br/>
<br/>
Problem A-1 on the 1968 Putnam exam:<br/>
<br/>
Prove 22/7 - π = ∫<sub>0</sub><sup>1</sup> (x<sup>4</sup>(1-x)<sup>4</sup>)/(1+ x<sup>2</sup> )dx<br/>
<br/>
(I can easily do his by partial fractions and remembering that ∫ 1/(1+x^2) dx = tan<sup>-1</sup>x  which is tan inverse, not 1/tan. See <a href="https://www.cs.umd.edu/users/gasarch/BLOGPAPERS/pi.pdf">here</a>.)<br/>
<br/>
Since the integrand is positive on (0,1) and 0 on the endpoints, the integral is positive, hence  π &lt; 22/7.<br/>
<br/>
OKAY! I can show that to my Dad! Except that he would not understand the proof. This raises the question: what is the easiest proof that π ≠ 22/7?<br/>
<br/>
<br/>
Let n &amp;in N which we will choose later. By looking at the circle that is inscribed in a regular n-polygon (n even) one finds that <br/>
<br/>
<br/>
n tan(π/n) &gt;  π <br/>
<br/>
<br/>
So we seek an even  value of n such that<br/>
<br/>
<br/>
n tan(π/n) &lt; 22/7<br/>
<br/>
<br/>
Using Wolfram alpha the smallest such n is 92.<br/>
<br/>
Would that convince Dad? Would he understand it? Probably not. Oh well.<br/>
<br/>
Some misc points.<br/>
<br/>
<br/>
1)  While working on this post I originally wanted to find tan(π/2<sup>7</sup>) by using the half-angle formula many times, and get an exact answer in terms of radicals,  rather than using Wolfram Alpha. <br/>
<br/>
a) While I have lots of combinatorics books, theory of comp books, and more Ramsey Theory books than one person should own in my house, I didn't have a SINGLE book with any trig in it.<br/>
<br/>
b) I easily found it on the web: <br/>
<br/>
tan(x/2) = sqrt( (1-cos x)/(1+cos x) ) = sin x/(1+cos x) = (1-cos x)/(sin x).<br/>
<br/>
None of these seems like it would get me a nice expression for tan(π/2<sup>7</sup>). But I don't know. Is there a nice expression for tan(π/2<sup>k</sup>) ? If you know of one then leave a polite comment.<br/>
<br/>
2) I assumed that there was a more clever and faster way to do the integral. I could not find old Putnam exams and their solutions  the web (I'm sure they are there someplace! --- if you know then comment politely with a pointer). So I got a book out of the library <i>The William Lowell Putnam Mathematical Competition Problems and Solutions 1965--1984</i> by Alexanderson, Klosinski, and Larson. Here is the clever solution:<br/>
<br/>
<i>The standard approach from Elementary Calculus applies.<br/>
<br/>
</i><br/>
<br/>
Not as clever as I as hoping for.<br/>
<br/>
3) I also looked at the integral with 4 replaced by 1,2,3,4,...,16. The results are in the writeup I pointed to before. It looks like I can use this sequence to get  upper and lower bound on i, ln(2), pi+2ln(2), and pi-2ln(2). I have not proven any of this. But take a look!<br/>
<br/>
<br/>
4) When I looked up INSCRIBING a circle in a regular n-polygon, Google kept giving me CIRCUMSCRIBING. Why? I do not know but I can speculate. Archimedes had a very nice way of using circumscribed circles to approximate pi. Its on youtube <a href="https://www.youtube.com/watch?v=_rJdkhlWZVQ">here</a>.  Hence people are used to using circumscribed rather than inscribed circles.<br/>
<br/></div>
    </content>
    <updated>2019-07-01T02:34:00Z</updated>
    <published>2019-07-01T02:34:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-07-01T11:43:39Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1906.12334</id>
    <link href="http://arxiv.org/abs/1906.12334" rel="alternate" type="text/html"/>
    <title>K-Core Maximization through Edge Additions</title>
    <feedworld_mtime>1561939200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhou:Zhongxin.html">Zhongxin Zhou</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Fan.html">Fan Zhang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lin:Xuemin.html">Xuemin Lin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Wenjie.html">Wenjie Zhang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Chen.html">Chen Chen</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1906.12334">PDF</a><br/><b>Abstract: </b>A popular model to measure the stability of a network is k-core - the maximal
induced subgraph in which every vertex has at least k neighbors. Many studies
maximize the number of vertices in k-core to improve the stability of a
network. In this paper, we study the edge k-core problem: Given a graph G, an
integer k and a budget b, add b edges to non-adjacent vertex pairs in G such
that the k-core is maximized. We prove the problem is NP-hard and APX-hard. A
heuristic algorithm is proposed on general graphs with effective optimization
techniques. Comprehensive experiments on 9 real-life datasets demonstrate the
effectiveness and the efficiency of our proposed methods.
</p></div>
    </summary>
    <updated>2019-07-01T01:22:35Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1906.12298</id>
    <link href="http://arxiv.org/abs/1906.12298" rel="alternate" type="text/html"/>
    <title>Detecting Feedback Vertex Sets of Size $k$ in $O^\star(2.7^k)$ Time</title>
    <feedworld_mtime>1561939200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Jason.html">Jason Li</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nederlof:Jesper.html">Jesper Nederlof</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1906.12298">PDF</a><br/><b>Abstract: </b>In the Feedback Vertex Set problem, one is given an undirected graph $G$ and
an integer $k$, and one needs to determine whether there exists a set of $k$
vertices that intersects all cycles of $G$ (a so-called feedback vertex set).
Feedback Vertex Set is one of the most central problems in parameterized
complexity: It served as an excellent test bed for many important algorithmic
techniques in the field such as Iterative Compression~[Guo et al. (JCSS'06)],
Randomized Branching~[Becker et al. (J. Artif. Intell. Res'00)] and
Cut\&amp;Count~[Cygan et al. (FOCS'11)]. In particular, there has been a long race
for the smallest dependence $f(k)$ in run times of the type $O^\star(f(k))$,
where the $O^\star$ notation omits factors polynomial in $n$. This race seemed
to be run in 2011, when a randomized algorithm $O^\star(3^k)$ time algorithm
based on Cut\&amp;Count was introduced.
</p>
<p>In this work, we show the contrary and give a $O^\star(2.7^k)$ time
randomized algorithm. Our algorithm combines all mentioned techniques with
substantial new ideas: First, we show that, given a feedback vertex set of size
$k$ of bounded average degree, a tree decomposition of width $(1-\Omega(1))k$
can be found in polynomial time. Second, we give a randomized branching
strategy inspired by the one from~[Becker et al. (J. Artif. Intell. Res'00)] to
reduce to the aforementioned bounded average degree setting. Third, we obtain
significant run time improvements by employing fast matrix multiplication.
</p></div>
    </summary>
    <updated>2019-07-01T01:21:22Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1906.12297</id>
    <link href="http://arxiv.org/abs/1906.12297" rel="alternate" type="text/html"/>
    <title>Blocking dominating sets for $H$-free graphs via edge contractions</title>
    <feedworld_mtime>1561939200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Galby:Esther.html">Esther Galby</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lima:Paloma_T=.html">Paloma T. Lima</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Ries:Bernard.html">Bernard Ries</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1906.12297">PDF</a><br/><b>Abstract: </b>In this paper, we consider the following problem: given a connected graph
$G$, can we reduce the domination number of $G$ by one by using only one edge
contraction? We show that the problem is $\mathsf{coNP}$-hard when restricted
to subcubic claw-free graphs and $P_7$-free graphs.
</p></div>
    </summary>
    <updated>2019-07-01T01:20:50Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-07-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1906.12215</id>
    <link href="http://arxiv.org/abs/1906.12215" rel="alternate" type="text/html"/>
    <title>Improving and benchmarking of algorithms for decision making with lower previsions</title>
    <feedworld_mtime>1561939200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nakharutai:Nawapon.html">Nawapon Nakharutai</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Troffaes:Matthias_C=_M=.html">Matthias C. M. Troffaes</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Caiado:Camila_C=_S=.html">Camila C. S. Caiado</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1906.12215">PDF</a><br/><b>Abstract: </b>Maximality, interval dominance, and E-admissibility are three well-known
criteria for decision making under severe uncertainty using lower previsions.
We present a new fast algorithm for finding maximal gambles. We compare its
performance to existing algorithms, one proposed by Troffaes and Hable (2014),
and one by Jansen, Augustin, and Schollmeyer (2017). To do so, we develop a new
method for generating random decision problems with pre-specified ratios of
maximal and interval dominant gambles. Based on earlier work, we present
efficient ways to find common feasible starting points in these algorithms. We
then exploit these feasible starting points to develop early stopping criteria
for the primal-dual interior point method, further improving efficiency. We
find that the primal-dual interior point method works best. We also investigate
the use of interval dominance to eliminate non-maximal gambles. This can make
the problem smaller, and we observe that this benefits Jansen et al.'s
algorithm, but perhaps surprisingly, not the other two algorithms. We find that
our algorithm, without using interval dominance, outperforms all other
algorithms in all scenarios in our benchmarking.
</p></div>
    </summary>
    <updated>2019-07-01T01:44:54Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1906.12211</id>
    <link href="http://arxiv.org/abs/1906.12211" rel="alternate" type="text/html"/>
    <title>PUFFINN: Parameterless and Universally Fast FInding of Nearest Neighbors</title>
    <feedworld_mtime>1561939200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Aum=uuml=ller:Martin.html">Martin Aumüller</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Christiani:Tobias.html">Tobias Christiani</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pagh:Rasmus.html">Rasmus Pagh</a>, Michael Vesterli <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1906.12211">PDF</a><br/><b>Abstract: </b>We present PUFFINN, a parameterless LSH-based index for solving the
$k$-nearest neighbor problem with probabilistic guarantees. By parameterless we
mean that the user is only required to specify the amount of memory the index
is supposed to use and the result quality that should be achieved. The index
combines several heuristic ideas known in the literature. By small adaptions to
the query algorithm, we make heuristics rigorous. We perform experiments on
real-world and synthetic inputs to evaluate implementation choices and show
that the implementation satisfies the quality guarantees while being
competitive with other state-of-the-art approaches to nearest neighbor search.
</p>
<p>We describe a novel synthetic data set that is difficult to solve for almost
all existing nearest neighbor search approaches, and for which PUFFINN
significantly outperform previous methods.
</p></div>
    </summary>
    <updated>2019-07-01T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-07-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1906.12141</id>
    <link href="http://arxiv.org/abs/1906.12141" rel="alternate" type="text/html"/>
    <title>MGOS: A Library for Molecular Geometry and its Operating System</title>
    <feedworld_mtime>1561939200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Deok-Soo Kima, Joonghyun Ryua, Youngsong Choa, Mokwon Leeb, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cha:Jehyun.html">Jehyun Cha</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Song:Chanyoung.html">Chanyoung Song</a>, Sangwha Kim, Roman A Laskowskid, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sugihara:Kokichi.html">Kokichi Sugihara</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bhak:Jong.html">Jong Bhak</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Ryu:Seong_Eon.html">Seong Eon Ryu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1906.12141">PDF</a><br/><b>Abstract: </b>The geometry of atomic arrangement underpins the structural understanding of
molecules in many fields. However, no general framework of
mathematical/computational theory for the geometry of atomic arrangement
exists. Here we present "Molecular Geometry (MG)" as a theoretical framework
accompanied by "MG Operating System (MGOS)" which consists of callable
functions implementing the MG theory. MG allows researchers to model
complicated molecular structure problems in terms of elementary yet standard
notions of volume, area, etc. and MGOS frees them from the hard and tedious
task of developing/implementing geometric algorithms so that they can focus
more on their primary research issues. MG facilitates simpler modeling of
molecular structure problems; MGOS functions can be conveniently embedded in
application programs for the efficient and accurate solution of geometric
queries involving atomic arrangements. The use of MGOS in problems involving
spherical entities is akin to the use of math libraries in general purpose
programming languages in science and engineering.
</p></div>
    </summary>
    <updated>2019-07-01T01:45:10Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-07-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1906.12053</id>
    <link href="http://arxiv.org/abs/1906.12053" rel="alternate" type="text/html"/>
    <title>Generating Normal Networks via Leaf Insertion and Nearest Neighbor Interchange</title>
    <feedworld_mtime>1561939200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Louxin.html">Louxin Zhang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1906.12053">PDF</a><br/><b>Abstract: </b>Galled trees are studied as a recombination model in theoretic population
genetics. This class of phylogenetic networks has been generalized to
tree-child networks, normal networks and tree-based networks by relaxing a
structural condition. Although these networks are simple, their topological
structures have yet to be fully understood. It is well-known that all
phylogenetic trees on $n$ taxa can be generated by the insertion of the $n$-th
taxa to each edge of all the phylogenetic trees on $n-1$ taxa. We prove that
all tree-child networks with $k$ reticulate nodes on $n$ taxa can be uniquely
generated via three operations from all the tree-child networks with $k-1$ or
$k$ reticulate nodes on $n-1$ taxa . An application of this result is found in
counting tree-child networks and normal networks. In particular, a simple
formula is given for the number of rooted phylogenetic networks with one
reticulate node.
</p></div>
    </summary>
    <updated>2019-07-01T01:43:52Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1906.11999</id>
    <link href="http://arxiv.org/abs/1906.11999" rel="alternate" type="text/html"/>
    <title>Efficient Spatial Anti-Aliasing Rendering for Line Joins on Vector Maps</title>
    <feedworld_mtime>1561939200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/He:Chaoyang.html">Chaoyang He</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Ming.html">Ming Li</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1906.11999">PDF</a><br/><b>Abstract: </b>The spatial anti-aliasing technique for line joins (intersections of the road
segments) on vector maps is exclusively crucial to visual experience and system
performance. Due to limitations of OpenGL API, one common practice to achieve
the anti-aliased effect is splicing multiple triangles at varying scale levels
to approximate the fan-shaped line joins. However, this approximation
inevitably produces some unreality, and the system rendering performance is not
optimal. To circumvent these drawbacks, in this paper, we propose a simple but
efficient algorithm which uses only two triangles to substitute the multiple
triangles approximation and then renders a realistic fan-shaped curve with
alpha operation based on geometrical relation computing. Our experiment shows
it has advantages of a realistic anti-aliasing effect, less memory cost, higher
frame rate, and drawing line joins without overlapping rendering. Our proposed
spatial anti-aliasing technique has been widely used in Internet Maps such as
Tencent Mobile Maps and Tencent Automotive Maps.
</p></div>
    </summary>
    <updated>2019-07-01T01:47:11Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-07-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1906.11985</id>
    <link href="http://arxiv.org/abs/1906.11985" rel="alternate" type="text/html"/>
    <title>Near-Optimal Methods for Minimizing Star-Convex Functions and Beyond</title>
    <feedworld_mtime>1561939200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hinder:Oliver.html">Oliver Hinder</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sidford:Aaron.html">Aaron Sidford</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sohoni:Nimit_Sharad.html">Nimit Sharad Sohoni</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1906.11985">PDF</a><br/><b>Abstract: </b>In this paper, we provide near-optimal accelerated first-order methods for
minimizing a broad class of smooth nonconvex functions that are strictly
unimodal on all lines through a minimizer. This function class, which we call
the class of smooth quasar-convex functions, is parameterized by a constant
$\gamma \in (0,1]$, where $\gamma = 1$ encompasses the classes of smooth convex
and star-convex functions, and smaller values of $\gamma$ indicate that the
function can be "more nonconvex." We develop a variant of accelerated gradient
descent that computes an $\epsilon$-approximate minimizer of a smooth
$\gamma$-quasar-convex function with at most $O(\gamma^{-1} \epsilon^{-1/2}
\log(\gamma^{-1} \epsilon^{-1}))$ total function and gradient evaluations. We
also derive a lower bound of $\Omega(\gamma^{-1} \epsilon^{-1/2})$ on the
number of gradient evaluations required by any deterministic first-order method
in the worst case, showing that, up to a logarithmic factor, no deterministic
first-order algorithm can improve upon ours.
</p></div>
    </summary>
    <updated>2019-07-01T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1906.11948</id>
    <link href="http://arxiv.org/abs/1906.11948" rel="alternate" type="text/html"/>
    <title>Packing Boundary-Anchored Rectangles and Squares</title>
    <feedworld_mtime>1561939200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Therese Biedl, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Biniaz:Ahmad.html">Ahmad Biniaz</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Maheshwari:Anil.html">Anil Maheshwari</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mehrabi:Saeed.html">Saeed Mehrabi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1906.11948">PDF</a><br/><b>Abstract: </b>Consider a set $P$ of $n$ points on the boundary of an axis-aligned square
$Q$. We study the boundary-anchored packing problem on $P$ in which the goal is
to find a set of interior-disjoint axis-aligned rectangles in $Q$ such that
each rectangle is anchored (has a corner at some point in $P$), each point in
$P$ is used to anchor at most one rectangle, and the total area of the
rectangles is maximized. Here, a rectangle is anchored at a point $p$ in $P$ if
one of its corners coincides with $p$. In this paper, we show how to solve this
problem in time linear in $n$, provided that the points of $P$ are given in
sorted order along the boundary of $Q$. We also consider the problem for
anchoring squares and give an $O(n^4)$-time algorithm when the points in $P$
lie on two opposite sides of $Q$.
</p></div>
    </summary>
    <updated>2019-07-01T02:00:38Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-07-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1906.11710</id>
    <link href="http://arxiv.org/abs/1906.11710" rel="alternate" type="text/html"/>
    <title>The shocklet transform: A decomposition method for the identification of local, mechanism-driven dynamics in sociotechnical time series</title>
    <feedworld_mtime>1561939200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dewhurst:David_Rushing.html">David Rushing Dewhurst</a>, Thayer Alshaabi, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kiley:Dilan.html">Dilan Kiley</a>, Michael V. Arnold, Joshua R. Minot, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Danforth:Christopher_M=.html">Christopher M. Danforth</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dodds:Peter_Sheridan.html">Peter Sheridan Dodds</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1906.11710">PDF</a><br/><b>Abstract: </b>We introduce an unsupervised pattern recognition algorithm termed the
Discrete Shocklet Transform (DST) by which local dynamics of time series can be
extracted. Time series that are hypothesized to be generated by underlying
deterministic mechanisms have significantly different DSTs than do purely
random null models. We apply the DST to a sociotechnical data source, usage
frequencies for a subset of words on Twitter over a decade, and demonstrate the
ability of the DST to filter high-dimensional data and automate the extraction
of anomalous behavior.
</p></div>
    </summary>
    <updated>2019-07-01T01:44:18Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/06/30/linkage</id>
    <link href="https://11011110.github.io/blog/2019/06/30/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>Ok, some of these are not so much links as mini-reports from SPAA/STOC/FCRC. For an actual conference report, see Lance’s post.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Ok, some of these are not so much links as mini-reports from SPAA/STOC/FCRC. For an actual conference report, see <a href="https://blog.computationalcomplexity.org/2019/06/fcrc-2019.html">Lance’s post</a>.</p>

<ul>
  <li>
    <p><a href="https://uhills.org/the-university-hills-section-marker-a-history-of-maps-markers-and-monuments-that-eventually-created-university-hills/">Squaring the spherical earth</a> (<a href="https://mathstodon.xyz/@11011110/102285188426196734"/>). For surveying purposes, Orange County is divided into “sections”, typically one square mile (not axis-aligned!) with small brass markers at their corners. One corner lands in the UCI faculty housing development where I live, and the housing association took the opportunity to make a larger decorative marker for it.</p>
  </li>
  <li>
    <p><a href="https://gilkalai.wordpress.com/2019/03/22/danny-nguyen-and-igor-pak-presburger-arithmetic-problem-solved/">Integer linear programming, change-making, and Presburger arithmetic</a> (<a href="https://mathstodon.xyz/@11011110/102291138538406550"/>). Integer arithmetic problems with a constant number of variables and one level of quantifiers (example: given a constant number of coin types, find the largest amount of money for which you cannot make change) have long been known to be polynomially solvable, but <a href="http://www.math.ucla.edu/~pak/papers/hard_presburger3.pdf">in FOCS 2017 Nguyen and Pak proved that only two levels of quantifiers make the problem hard</a>.</p>
  </li>
  <li>
    <p><a href="https://tomas.rokicki.com/dottri.html">Dots and triangles</a> (<a href="https://mathstodon.xyz/@christianp/102297036146535876"/>). Online variant of dots and boxes by Tomas Rikicki.</p>
  </li>
  <li>
    <p><a href="https://cameroncounts.wordpress.com/2019/06/19/combinatorics-at-strathclyde/">University of Strathclyde proposes to axe combinatorics and their three strong combinatorics faculty members</a> (<a href="https://mathstodon.xyz/@11011110/102301038310925223"/>, <a href="https://gowers.wordpress.com/2019/06/19/the-fate-of-combinatorics-at-strathclyde/">via</a>). This comes despite the group being both strong in research and important in undergraduate education. The apparent cause is Strathclyde’s placement of combinatorics in computer science rather than in mathematics and in their use of standards aimed more at computer science than mathematics (like bringing in large grants). There’s an <a href="https://britishcombinatorial.wordpress.com/2019/06/20/combinatorics-at-strathclyde-2/">online petition against the cuts</a> closing very soon: 5pm British time, July 1.</p>
  </li>
  <li>
    <p>Catherine Greenhill is setting up a new network for women in combinatorics, meaning “anyone who identifies as a woman, is non-binary, two-spirit, or gender diverse” (<a href="https://mathstodon.xyz/@11011110/102311965002907932"/>). <a href="https://womenincombinatorics.com/">Their website</a> currently only has a sign-up form, but expect more to come.</p>
  </li>
  <li>
    <p>Slides from three of my recent conference talks (<a href="https://mathstodon.xyz/@11011110/102319479687501682"/>):
<a href="https://www.ics.uci.edu/~eppstein/pubs/Epp-SoCG-19-many-lines-slides.pdf">Cubic planar graphs that cannot be drawn on few lines</a>; <a href="https://www.ics.uci.edu/~eppstein/pubs/Epp-SoCG-19-counting-slides.pdf">Counting polygon triangulations is hard</a>; <a href="https://www.ics.uci.edu/~eppstein/pubs/Epp-SPAA-19-slides.pdf">NC algorithms for perfect matching and maximum flow in one-crossing-minor-free graphs</a>.</p>
  </li>
  <li>
    <p>Certain conference speakers need to be told that using sans-serif ∑ for one central notation and sans-serif bold ∑ for a different central notation is a bad idea. That decorating both of them by the same subscripts and the same hats doesn’t help. And that when someone asks for clarification of the notation, answering with “We should move on…this is a thing you can compute on your own” rather than actually explaining is rude (<a href="https://mathstodon.xyz/@11011110/102323855724493135"/>).</p>
  </li>
  <li>
    <p>The STOC Wikipedia edit-a-thon was called off because the convention center was locked up and participants couldn’t get into the room it was scheduled for (<a href="https://mathstodon.xyz/@11011110/102330434291269046"/>). But <a href="https://thmatters.wordpress.com/2019/06/26/edit-a-thon-update/">it was successfully rescheduled for the next day</a>, unfortunately too late in the conference for me to participate.</p>

    <p>In other news from STOC, spammy journal publishers have found a new way to spam us: fund student authors with travel awards (laudable and non-spammy!) but then require the student presenters to display a whole slide of advertising for the journal by way of acknowledgements (spammy!).</p>
  </li>
  <li>
    <p><a href="https://xkcd.com/2168/">xkcd on reading Wikipedia in the original Greek</a> (<a href="https://mathstodon.xyz/@11011110/102339055555301837"/>).</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1906.10668">Discrete logarithms in quasi-polynomial time in finite fields of fixed characteristic</a> (<a href="https://mathstodon.xyz/@erou/102337004608271854"/>). New preprint by Kleinjung and Weselowski.</p>
  </li>
  <li>
    <p><a href="https://www.youtube.com/watch?v=OerQAsqEOLc">Short video on interleaving multiple copies of the infinite Laves graph</a> (<a href="https://mathstodon.xyz/@11011110/102353592823020968"/>). Sound not necessary.</p>
  </li>
  <li>
    <p><a href="https://arstechnica.com/science/2019/06/two-new-papers-explore-the-complicated-physics-behind-bubbles-and-foams/">Two new papers explore the complicated physics behind bubbles and foams</a> (<a href="https://mathstodon.xyz/@11011110/102356874963380843"/>).
Juanes et al find <a href="http://dx.doi.org/10.1073/pnas.1819744116">universality in pinching off uniformly sized bubbles</a> from a tube much like drops from a dripping faucet. And Yanagisawa and Kurita discover <a href="http://dx.doi.org/10.1038/s41598-019-41486-6">two mechanisms for breaking bubbles to propagate through a foam</a>. As it contracts, the breaking bubble can hit other bubbles, and it can also scatter off droplets which hit other bubbles.</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1902.07622">Centrality analysis of Wikipedia links between mathematicians</a> (<a href="https://mathstodon.xyz/@11011110/102361585031049847"/>, <a href="https://en.wikipedia.org/wiki/Wikipedia:Wikipedia_Signpost/2019-06-30/Recent_research">via</a>). None of the names listed are surprising, but the ordering might be a little. Noether makes the top 10; Bourbaki, Grothendieck, and Turing are farther down. Martin Gardner makes the cut (barely), at #35.</p>
  </li>
</ul></div>
    </content>
    <updated>2019-06-30T16:16:00Z</updated>
    <published>2019-06-30T16:16:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-06-30T23:47:50Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1906.11811</id>
    <link href="http://arxiv.org/abs/1906.11811" rel="alternate" type="text/html"/>
    <title>Faster and Better Nested Dissection Orders for Customizable Contraction Hierarchies</title>
    <feedworld_mtime>1561852800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Lars Gottesbüren, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hamann:Michael.html">Michael Hamann</a>, Tim Niklas Uhl, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wagner:Dorothea.html">Dorothea Wagner</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1906.11811">PDF</a><br/><b>Abstract: </b>Graph partitioning has many applications. We consider the acceleration of
shortest path queries in road networks using Customizable Contraction
Hierarchies (CCH). It is based on computing a nested dissection order by
recursively dividing the road network into parts. Recently, with FlowCutter and
Inertial Flow, two flow-based graph bipartitioning algorithms have been
proposed for road networks. While FlowCutter achieves high-quality results and
thus fast query times, it is rather slow. Inertial Flow is particularly fast
due to the use of geographical information while still achieving acceptable
quality. We combine the techniques of both algorithms to achieve more than six
times faster preprocessing times than FlowCutter and even slightly better
quality. We show that using 16 cores of a shared-memory machine, this
preprocessing needs four minutes on the Europe road network.
</p></div>
    </summary>
    <updated>2019-06-30T23:26:46Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-06-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1906.11750</id>
    <link href="http://arxiv.org/abs/1906.11750" rel="alternate" type="text/html"/>
    <title>A Constant-Factor Approximation Algorithm for Online Coverage Path Planning with Energy Constraint</title>
    <feedworld_mtime>1561852800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dutta:Ayan.html">Ayan Dutta</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sharma:Gokarna.html">Gokarna Sharma</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1906.11750">PDF</a><br/><b>Abstract: </b>In this paper, we study the problem of coverage planning by a mobile robot
with a limited energy budget. The objective of the robot is to cover every
point in the environment while minimizing the traveled path length. The
environment is initially unknown to the robot. Therefore, it needs to avoid the
obstacles in the environment on-the-fly during the exploration. As the robot
has a specific energy budget, it might not be able to cover the complete
environment in one traversal. Instead, it will need to visit a static charging
station periodically in order to recharge its energy. To solve the stated
problem, we propose a budgeted depth-first search (DFS)-based exploration
strategy that helps the robot to cover any unknown planar environment while
bounding the maximum path length to a constant-factor of the shortest-possible
path length. Our $O(1)$-approximation guarantee advances the state-of-the-art
of log-approximation for this problem. Simulation results show that our
proposed algorithm outperforms the current state-of-the-art algorithm both in
terms of the traveled path length and run time in all the tested environments
with concave and convex obstacles.
</p></div>
    </summary>
    <updated>2019-06-30T23:22:07Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-06-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1906.11700</id>
    <link href="http://arxiv.org/abs/1906.11700" rel="alternate" type="text/html"/>
    <title>Efficient algorithms for modifying and sampling from a categorical distribution</title>
    <feedworld_mtime>1561852800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tang:Daniel.html">Daniel Tang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1906.11700">PDF</a><br/><b>Abstract: </b>Probabilistic programming languages and other machine learning applications
often require samples to be generated from a categorical distribution where the
probability of each one of $n$ categories is specified as a parameter. If the
parameters are hyper-parameters then they need to be modified, however, current
implementations of categorical distributions take $\mathcal{O}(n)$ time to
modify a parameter. If $n$ is large and the parameters are being frequently
modified, this can become prohibitive. Here we present the insight that a
Huffman tree is an efficient data structure for representing categorical
distributions and present algorithms to generate samples as well as add, delete
and modify categories in $\mathcal{O}(\log(n))$ time. We demonstrate that the
time to sample from the distribution remains, in practice, within a few percent
of the theoretical optimal value. The same algorithm may also be useful in the
context of adaptive Huffman coding where computational efficiency is important.
</p></div>
    </summary>
    <updated>2019-06-30T23:23:40Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-06-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1906.11524</id>
    <link href="http://arxiv.org/abs/1906.11524" rel="alternate" type="text/html"/>
    <title>Improved Distributed Approximation to Maximum Independent Set</title>
    <feedworld_mtime>1561852800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kawarabayashi:Ken=ichi.html">Ken-ichi Kawarabayashi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Khoury:Seri.html">Seri Khoury</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schild:Aaron.html">Aaron Schild</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schwartzman:Gregory.html">Gregory Schwartzman</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1906.11524">PDF</a><br/><b>Abstract: </b>We present improved results for approximating Maximum Independent Set
($\MaxIS$) in the standard LOCAL and CONGEST models of distributed computing.
Let $n$ and $\Delta$ be the number of nodes and maximum degree in the input
graph, respectively. Bar-Yehuda et al. [PODC 2017] showed that there is an
algorithm in the CONGEST model that finds a $\Delta$-approximation to $\MaxIS$
in $O(\MIS(n,\Delta)\log W)$ rounds, where $\MIS(n,\Delta)$ is the running time
for finding a \emph{maximal} independent set, and $W$ is the maximum weight of
a node in the network. Whether their algorithm is randomized or deterministic
depends on the $\MIS$ algorithm that they use as a black-box. Our results: (1)
A deterministic $O(\MIS(n,\Delta))$ rounds algorithm for
$O(\Delta)$-approximation to $\MaxIS$ in the CONGEST model. (2) A randomized
$2^{O(\sqrt{\log \log n})}$ rounds algorithm that finds, with high probability,
an $O(\Delta)$-approximation to $\MaxIS$ in the CONGEST model. (3) An
$\Omega(\log^*n)$ lower bound for any randomized algorithm that finds an
independent set of size $\Omega(n/\Delta)$ that succeeds with probability at
least $1-1/\log n$, even for the LOCAL model. This hardness result applies for
graphs of maximum degree $\Delta=O(n/\log^*n)$. One might wonder whether the
same hardness result applies for low degree graphs. We rule out this
possibility with our next result. (4) An $O(1)$ rounds algorithm that finds an
independent set of size $\Omega(n/\Delta)$ in graphs with maximum degree
$\Delta\leq n/\log n$, with high probability. Due to a lower bound of
$\Omega(\sqrt{\log n/\log \log n})$ that was given by Kuhn, Moscibroda and
Wattenhofer [JACM, 2016] on the number of rounds for finding a maximal
independent set ($\MIS$) in the LOCAL model, even for randomized algorithms,
our second result implies that finding an $O(\Delta)$-approximation to $\MaxIS$
is strictly easier than $\MIS$.
</p></div>
    </summary>
    <updated>2019-06-30T23:23:44Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-06-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1906.11447</id>
    <link href="http://arxiv.org/abs/1906.11447" rel="alternate" type="text/html"/>
    <title>Improved Upper Bounds on the Growth Constants of Polyominoes and Polycubes</title>
    <feedworld_mtime>1561852800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Barequet:Gill.html">Gill Barequet</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shalah:Mira.html">Mira Shalah</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1906.11447">PDF</a><br/><b>Abstract: </b>A $d$-dimensional polycube is a facet-connected set of cells (cubes) on the
$d$-dimensional cubical lattice~$\mathbb{Z}^d$. Let~$A_d(n)$ denote the number
of $d$-dimensional polycubes (distinct up to translations) with~$n$ cubes,
and~$\lambda_d$ denote the limit of the ratio~$A_d(n{+}1)/A_d(n)$ as~$n \to
\infty$. The exact value of~$\lambda_d$ is still unknown rigorously for any
dimension~$d \geq 2$; the asymptotics of~$\lambda_d$, as~$d \to \infty$, also
remained elusive as of today. In this paper, we revisit and extend the approach
presented by Klarner and Rivest in~1973 to bound $A_2(n)$ from above. Our
contributions are: Using available computing power, we prove that~$\lambda_2
\leq 4.5252$. This is the first improvement of the upper bound on~$\lambda_2$
in almost half a century; We prove that~$\lambda_d \leq (2d-2)e+o(1)$ for any
value of~$d \geq 2$, using a novel construction of a rational generating
function which dominates that of the sequence~$\left(A_d(n)\right)$; For $d=3$,
this provides a subtantial improvement of the upper bound on~$\lambda_3$
from~12.2071 to~9.8073;%~10.016; However, we implement an iterative process in
three dimensions, which improves further the upper bound
on~$\lambda_3$to~$9.3835$;
</p></div>
    </summary>
    <updated>2019-06-30T23:30:17Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-06-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1906.11423</id>
    <link href="http://arxiv.org/abs/1906.11423" rel="alternate" type="text/html"/>
    <title>Vector Programming Using Generative Recursion</title>
    <feedworld_mtime>1561852800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Moraz=aacute=n:Marco_T=.html">Marco T. Morazán</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1906.11423">PDF</a><br/><b>Abstract: </b>Vector programming is an important topic in many Introduction to Computer
Science courses. Despite the importance of vectors, learning vector programming
is a source of frustration for many students. Much of the frustration is rooted
in discovering the source of bugs that are manifested as out-of-bounds
indexing. The problem is that such bugs are, sometimes, rooted in incorrectly
computing an index. Other times, however, these errors are rooted in mistaken
reasoning about how to correctly process a vector. Unfortunately, either way,
all too often beginners are left adrift to resolve indexing errors on their
own. This article extends the work done on vector programming using vector
intervals and structural recursion to using generative recursion. As for
problems solved using structural recursion, vector intervals provide beginners
with a useful framework for designing code that properly indexes vectors. This
article presents the methodology and concrete examples that others may use to
build their own CS1 modules involving vector programming using any programming
language.
</p></div>
    </summary>
    <updated>2019-06-30T23:23:34Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-06-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1906.11385</id>
    <link href="http://arxiv.org/abs/1906.11385" rel="alternate" type="text/html"/>
    <title>A Tight Analysis of Greedy Yields Subexponential Time Approximation for Uniform Decision Tree</title>
    <feedworld_mtime>1561852800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Ray.html">Ray Li</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liang:Percy.html">Percy Liang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mussmann:Stephen.html">Stephen Mussmann</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1906.11385">PDF</a><br/><b>Abstract: </b>Decision Tree is a classic formulation of active learning: given $n$
hypotheses with nonnegative weights summing to 1 and a set of tests that each
partition the hypotheses, output a decision tree using the provided tests that
uniquely identifies each hypothesis and has minimum (weighted) average depth.
Previous works showed that the greedy algorithm achieves a $O(\log n)$
approximation ratio for this problem and it is NP-hard beat a $O(\log n)$
approximation, settling the complexity of the problem. However, for Uniform
Decision Tree, i.e. Decision Tree with uniform weights, the story is more
subtle. The greedy algorithm's $O(\log n)$ approximation ratio is the best
known, but the largest approximation ratio known to be NP-hard is
$4-\varepsilon$. We prove that the greedy algorithm gives a $O(\frac{\log
n}{\log C_{OPT}})$ approximation for Uniform Decision Tree, where $C_{OPT}$ is
the cost of the optimal tree and show this is best possible for the greedy
algorithm. As a corollary, this resolves a conjecture of Kosaraju, Przytycka,
and Borgstrom. Our results also hold for instances of Decision Tree whose
weights are not too far from uniform. Leveraging this result, we exhibit a
subexponential algorithm that yields an $O(1/\alpha)$ approximation to Uniform
Decision Tree in time $2^{O(n^\alpha)}$. As a corollary, achieving any
super-constant approximation ratio on Uniform Decision Tree is not NP-hard,
assuming the Exponential Time Hypothesis. This work therefore adds
approximating Uniform Decision Tree to a small list of natural problems that
have subexponential algorithms but no known polynomial time algorithms. Like
the greedy algorithm, our subexponential algorithm gives similar guarantees
even for slightly nonuniform weights.
</p></div>
    </summary>
    <updated>2019-06-30T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-06-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1906.11366</id>
    <link href="http://arxiv.org/abs/1906.11366" rel="alternate" type="text/html"/>
    <title>Quantum Entropy Scoring for Fast Robust Mean Estimation and Improved Outlier Detection</title>
    <feedworld_mtime>1561852800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dong:Yihe.html">Yihe Dong</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hopkins:Samuel_B=.html">Samuel B. Hopkins</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Jerry.html">Jerry Li</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1906.11366">PDF</a><br/><b>Abstract: </b>We study two problems in high-dimensional robust statistics: \emph{robust
mean estimation} and \emph{outlier detection}. In robust mean estimation the
goal is to estimate the mean $\mu$ of a distribution on $\mathbb{R}^d$ given
$n$ independent samples, an $\varepsilon$-fraction of which have been corrupted
by a malicious adversary. In outlier detection the goal is to assign an
\emph{outlier score} to each element of a data set such that elements more
likely to be outliers are assigned higher scores. Our algorithms for both
problems are based on a new outlier scoring method we call QUE-scoring based on
\emph{quantum entropy regularization}. For robust mean estimation, this yields
the first algorithm with optimal error rates and nearly-linear running time
$\widetilde{O}(nd)$ in all parameters, improving on the previous fastest
running time $\widetilde{O}(\min(nd/\varepsilon^6, nd^2))$. For outlier
detection, we evaluate the performance of QUE-scoring via extensive experiments
on synthetic and real data, and demonstrate that it often performs better than
previously proposed algorithms. Code for these experiments is available at
https://github.com/twistedcubic/que-outlier-detection .
</p></div>
    </summary>
    <updated>2019-06-30T23:21:48Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-06-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1906.11337</id>
    <link href="http://arxiv.org/abs/1906.11337" rel="alternate" type="text/html"/>
    <title>Voronoi Cells in Metric Algebraic Geometry of Plane Curves</title>
    <feedworld_mtime>1561852800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Madeline Brandt, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Weinstein:Madeleine.html">Madeleine Weinstein</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1906.11337">PDF</a><br/><b>Abstract: </b>Voronoi cells of varieties encode many features of their metric geometry. We
prove that each Voronoi or Delaunay cell of a plane curve appears as the limit
of a sequence of cells obtained from point samples of the curve. We then use
this result to study metric features of plane curves, including the medial
axis, curvature, evolute, bottlenecks, and reach. In each case, we provide
algebraic equations defining the object and, where possible, give formulas for
the degrees of these algebraic varieties. We then show how to identify the
desired metric feature from Voronoi or Delaunay cells, and therefore how to
approximate it by a finite point sample from the variety.
</p></div>
    </summary>
    <updated>2019-06-30T23:30:11Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-06-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1906.11327</id>
    <link href="http://arxiv.org/abs/1906.11327" rel="alternate" type="text/html"/>
    <title>The Adversarial Robustness of Sampling</title>
    <feedworld_mtime>1561852800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Ben=Eliezer:Omri.html">Omri Ben-Eliezer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yogev:Eylon.html">Eylon Yogev</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1906.11327">PDF</a><br/><b>Abstract: </b>Random sampling is a fundamental primitive in modern algorithms, statistics,
and machine learning, used as a generic method to obtain a small yet
"representative" subset of the data. In this work, we investigate the
robustness of sampling against adaptive adversarial attacks in a streaming
setting: An adversary sends a stream of elements from a universe $U$ to a
sampling algorithm (e.g., Bernoulli sampling or reservoir sampling), with the
goal of making the sample "very unrepresentative" of the underlying data
stream. The adversary is fully adaptive in the sense that it knows the exact
content of the sample at any given point along the stream, and can choose which
element to send next accordingly, in an online manner.
</p>
<p>Well-known results in the static setting indicate that if the full stream is
chosen in advance (non-adaptively), then a random sample of size $\Omega(d /
\varepsilon^2)$ is an $\varepsilon$-approximation of the full data with good
probability, where $d$ is the VC-dimension of the underlying set system
$(U,R)$. Does this sample size suffice for robustness against an adaptive
adversary? The simplistic answer is \emph{negative}: We demonstrate a set
system where a constant sample size (corresponding to VC-dimension $1$)
suffices in the static setting, yet an adaptive adversary can make the sample
very unrepresentative, as long as the sample size is (strongly) sublinear in
the stream length, using a simple and easy-to-implement attack.
</p>
<p>However, this attack is "theoretical only", requiring the set system size to
(essentially) be exponential in the stream length. This is not a coincidence:
We show that to make Bernoulli or reservoir sampling robust against adaptive
adversaries, the modification required is solely to replace the VC-dimension
term $d$ in the sample size with the cardinality term $\log |R|$. This nearly
matches the bound imposed by the attack.
</p></div>
    </summary>
    <updated>2019-06-30T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-06-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16046</id>
    <link href="https://rjlipton.wordpress.com/2019/06/29/a-prime-breakthrough/" rel="alternate" type="text/html"/>
    <title>A Prime Breakthrough</title>
    <summary>A breakthrough on the Riemann Hypothesis [ Composite of various sources ] Michael Griffin, Ken Ono, Larry Rolen, and Don Zagier (GORZ) have recently published a paper on an old approach to the famous Riemann Hypothesis (RH). Today we will discuss their work and its connection to P=NP. Their paper is titled, “Jensen polynomials for […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>A breakthrough on the Riemann Hypothesis</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2019/06/29/a-prime-breakthrough/gorz/" rel="attachment wp-att-16067"><img alt="" class="alignright size-medium wp-image-16067" height="300" src="https://rjlipton.files.wordpress.com/2019/06/gorz.png?w=261&amp;h=300" width="261"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">[ Composite of various sources ]</font></td>
</tr>
</tbody>
</table>
<p>
Michael Griffin, Ken Ono, Larry Rolen, and Don Zagier (GORZ) have recently published a paper on an old approach to the famous Riemann Hypothesis (RH).</p>
<p>
Today we will discuss their work and its connection to P=NP.</p>
<p>
Their <a href="https://arxiv.org/pdf/1902.07321.pdf">paper</a> is titled, “Jensen polynomials for the Riemann zeta function and other sequences.” The final <a href="https://doi.org/10.1073/pnas.1902572116">version</a> is in the Proceedings of the National Academy of Sciences (PNAS).</p>
<p>
The RH is still open. We are not aware of any update on the status of Michael Atiyah’s claim to have solved it since this <a href="https://blogs.ams.org/blogonmathblogs/2018/10/01/on-michael-atiyah-and-the-riemann-hypothesis/">note</a> on an AMS blog and our own <a href="https://rjlipton.wordpress.com/2018/09/26/reading-into-atiyahs-proof/">discussion</a> of his papers’ contents.</p>
<p>
Recall the RH is a central conjecture in number theory, and it has the following properties: </p>
<ul>
<li>
If true, it would greatly enhance our understanding of the structure of the primes: <img alt="{2,3,5,7,\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%2C3%2C5%2C7%2C%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2,3,5,7,\dots}"/> <p/>
</li><li>
It has resisted attacks for 160 years and counting. <p/>
</li><li>
There are an immense number of statements equivalent to the RH.
</li></ul>
<p>See, for example, the survey <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.66.3584&amp;rep=rep1&amp;type=pdf">paper</a>, “The Riemann Hypothesis,” by Brian Conrey. </p>
<p>
Complexity theory has the P=NP question; number theory has the RH. Both seem to be beyond reach, and both are fundamental questions. The recent work of GORZ has created buzz among number theorists—perhaps they are on the verge of a breakthrough? Is there hope that we might see progress on P=NP? Or must we wait 160 years? </p>
<p>
The buzz is reflected in a May 28 <a href="https://www.livescience.com/65577-riemann-hypothesis-big-step-math.html">story</a> in the online journal <i>LiveScience</i>. It quotes Enrico Bombieri, who wrote the official Clay Prize <a href="https://www.claymath.org/sites/default/files/official_problem_description.pdf">description</a> of RH, as saying:</p>
<blockquote><p><b> </b> <em> “Although this remains far away from proving the Riemann hypothesis, it is a big step forward. There is no doubt that this paper will inspire further fundamental work in other areas of number theory as well as in mathematical physics.” </em>
</p></blockquote>
<p/><p>
Bombieri wrote an accompanying <a href="https://www.pnas.org/content/early/2019/05/22/1906804116">paper</a> in PNAS, in which the above quoted sentences also appear. We will try to explain what the excitement is about.</p>
<p>
</p><p/><h2> The Approach and Results </h2><p/>
<p/><p>
RH is equivalent to the hyperbolicity of Jensen polynomials for the Riemann zeta function. Note: A real, polynomial <img alt="{p(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p(x)}"/> is <i>hyperbolic</i> if all its roots are real—a fancy name for a simple concept.</p>
<p>
There is an analytic function <img alt="{E(z)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BE%28z%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{E(z)}"/> so that 	</p>
<p align="center"><img alt="\displaystyle  RH \iff E(z) \text{ has all real roots}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++RH+%5Ciff+E%28z%29+%5Ctext%7B+has+all+real+roots%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  RH \iff E(z) \text{ has all real roots}. "/></p>
<p>Almost a hundred years ago, Johan Jensen and George Pólya created an approach to the RH based on <img alt="{E(z)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BE%28z%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{E(z)}"/>. Rather than prove <img alt="{E(z)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BE%28z%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{E(z)}"/> has only real roots, they showed it is enough to show that a family of polynomials <img alt="{J(n, d)(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BJ%28n%2C+d%29%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{J(n, d)(x)}"/> all are hyperbolic. The point is that polynomials are “simpler” than analytic functions—at least that is the hope.</p>
<p>
What GORZ prove is this: </p>
<blockquote><p><b>Theorem 1</b> <em> For each <img alt="{d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{d}"/> and almost all <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n}"/>, the polynomial <img alt="{J(n, d)(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BJ%28n%2C+d%29%28x%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{J(n, d)(x)}"/> is hyperbolic. </em>
</p></blockquote>
<p>Of course, “almost all” means that there at most a finite number of polynomials that are not hyperbolic. They also show that for degree <img alt="{d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d}"/> fixed, 	</p>
<p align="center"><img alt="\displaystyle  \lim_{n \rightarrow \infty} J(n, d)(x) = H_{d}(x). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clim_%7Bn+%5Crightarrow+%5Cinfty%7D+J%28n%2C+d%29%28x%29+%3D+H_%7Bd%7D%28x%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \lim_{n \rightarrow \infty} J(n, d)(x) = H_{d}(x). "/></p>
<p>Where the polynomials <img alt="{H_{d}(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BH_%7Bd%7D%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{H_{d}(x)}"/> have only real roots.</p>
<p>
This is explained further in a <a href="http://people.oregonstate.edu/~petschec/ONTD/Talk1.pdf">talk</a> by Ono, which has this table showing how the polynomials converge:</p>
<p><a href="https://rjlipton.wordpress.com/2019/06/29/a-prime-breakthrough/hyper/" rel="attachment wp-att-16049"><img alt="" class="aligncenter size-medium wp-image-16049" height="187" src="https://rjlipton.files.wordpress.com/2019/06/hyper.png?w=300&amp;h=187" width="300"/></a></p>
<p>Note: they use different notation for the polynomials.</p>
<p>
</p><p/><h2> The Approximation Property </h2><p/>
<p>There are many equivalent formulations of the RH.  While all are equivalent, some are more equivalent than others.  Some seem to be a more plausible path toward a resolution of the RH. Of course to date none have worked. </p>
<p>There is a way to distinguish equivalent formulations of the RH. Suppose that <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S"/> depends on some parameter <img alt="\beta" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbeta&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\beta"/>. Suppose that as <img alt="\beta" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbeta&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\beta"/> increases the statement <img alt="S(\beta)" class="latex" src="https://s0.wp.com/latex.php?latex=S%28%5Cbeta%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S(\beta)"/> becomes a weaker version of the RH.<br/>
Then let us informally say that the formulation <img alt="S(\beta)" class="latex" src="https://s0.wp.com/latex.php?latex=S%28%5Cbeta%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S(\beta)"/> has the “Approximation Property” (AP). The point is that progress in proving caes of <img alt="S(\beta)" class="latex" src="https://s0.wp.com/latex.php?latex=S%28%5Cbeta%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S(\beta)"/>—even as partial progress—is exciting. But if the equivalence only holds for <img alt="\beta=0" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbeta%3D0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\beta=0"/>, with no connections for higher <img alt="\beta" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbeta&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\beta"/>, then the partial progress could be seen as morally useful—but it is not really mathematically useful.</p>
<p>There are equivalences of the RH that have AP and some that seem not to have it. The approximation for the RH is natural. The RH states that there is no zero <img alt="\sigma + it" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csigma+%2B+it&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sigma + it"/> of the Riemann zeta function with <img alt="\sigma" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csigma&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sigma"/> above <img alt="1/2" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/2"/>. The weaker statement: If <img alt="\sigma + it" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csigma+%2B+it&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sigma + it"/> is a zero, then <img alt="\sigma &gt;  \alpha" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csigma+%3E++%5Calpha&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sigma &gt;  \alpha"/> is unknown for any <img alt="\alpha" class="latex" src="https://s0.wp.com/latex.php?latex=%5Calpha&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\alpha"/> in the open interval <img alt="(1/2,1)" class="latex" src="https://s0.wp.com/latex.php?latex=%281%2F2%2C1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(1/2,1)"/>. This can be used to get a property with the AP.</p>
<p>For example, this 2003 <a href="http://\href{https://arxiv.org/abs/math/0307215}">paper</a> by Luis Baez-Duarte, titled “A new necessary and sufficient condition for the Riemann hypothesis,” has the AP. He notes, in our terminology, that his property is an AP.</p>
<p/><h2> Open Problems </h2><p/>
<p/><p>
Does the approach of GORZ have the AP? The issue is that while we get a universal statement in terms of <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/>, the “all but finitely many” condition on <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> works against its being an approximation—what if the finite sets of exceptions grow in terms of <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/> in ways that offset the purpose behind the equivalence?</p>
<p/></font></font></div>
    </content>
    <updated>2019-06-29T14:50:42Z</updated>
    <published>2019-06-29T14:50:42Z</published>
    <category term="History"/>
    <category term="Open Problems"/>
    <category term="P=NP"/>
    <category term="Proofs"/>
    <category term="Results"/>
    <category term="hyperbolic"/>
    <category term="PNAS"/>
    <category term="polynomial"/>
    <category term="Proof"/>
    <category term="real roots"/>
    <category term="RH"/>
    <category term="Riemann Hypothesis"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-07-01T12:20:46Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=17489</id>
    <link href="https://gilkalai.wordpress.com/2019/06/28/another-sensation-annika-heckel-non-concentration-of-the-chromatic-number-of-a-random-graph/" rel="alternate" type="text/html"/>
    <title>Another sensation – Annika Heckel: Non-concentration of the chromatic number of a random graph</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Annika Heckel Sorry for the long period of non blogging. There are a lot of things to report and  various other plans for posts and I hope to come back to it soon. But it is nice to break the … <a href="https://gilkalai.wordpress.com/2019/06/28/another-sensation-annika-heckel-non-concentration-of-the-chromatic-number-of-a-random-graph/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="https://gilkalai.files.wordpress.com/2019/06/annika-1.png"><img alt="" class="alignnone size-full wp-image-17490" src="https://gilkalai.files.wordpress.com/2019/06/annika-1.png?w=640"/></a></p>
<p><span style="color: #ff0000;"><strong>Annika Heckel</strong></span></p>
<p>Sorry for the long period of non blogging. There are a lot of things to report and  various other plans for posts and I hope to come back to it soon. But it is nice to break the silence with another sensational result by Annika Heckel. I first heard about it some time ago and Noam Lifshitz just informed be that the<a href="https://arxiv.org/abs/1906.11808"> paper is on the arXive</a>!</p>
<h2><a href="https://arxiv.org/abs/1906.11808">Non-concentration of the chromatic number of a random graph</a></h2>
<p>And here is the <strong>abstract:</strong> We show that the chromatic number of $latex <span class="MathJax" id="MathJax-Element-1-Frame"><span class="math" id="MathJax-Span-1"><span class="mrow" id="MathJax-Span-2"><span class="msubsup" id="MathJax-Span-3"><span class="mi" id="MathJax-Span-4">G(</span><span class="texatom" id="MathJax-Span-5"><span class="mrow" id="MathJax-Span-6"><span class="mi" id="MathJax-Span-7">n</span><span class="mo" id="MathJax-Span-8">,</span><span class="mfrac" id="MathJax-Span-9"><span class="mn" id="MathJax-Span-10">1/</span><span class="mn" id="MathJax-Span-11">2)$</span></span></span></span></span></span></span></span> is not concentrated on fewer than <img alt="n^{1/4-\epsilon}" class="latex" src="https://s0.wp.com/latex.php?latex=n%5E%7B1%2F4-%5Cepsilon%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n^{1/4-\epsilon}"/>  consecutive values. This addresses a longstanding question raised by Erdős and several other authors.</p>
<p>The Introduction tells the history of the problem very nicely.</p></div>
    </content>
    <updated>2019-06-28T10:37:04Z</updated>
    <published>2019-06-28T10:37:04Z</published>
    <category term="Combinatorics"/>
    <category term="Annika Heckel"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-07-01T12:20:41Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-5703612485495687112</id>
    <link href="https://blog.computationalcomplexity.org/feeds/5703612485495687112/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/06/fcrc-2019.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/5703612485495687112" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/5703612485495687112" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/06/fcrc-2019.html" rel="alternate" type="text/html"/>
    <title>FCRC 2019</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody>
<tr><td style="text-align: center;"><a href="https://1.bp.blogspot.com/-1zksIfUU-7U/XRToEil7J7I/AAAAAAABpiI/nR4seqK1l08FfLoalQyM2OzdK3iZTwL2ACKgBGAs/s1600/MVIMG_20190626_112006_1.jpg" style="margin-left: auto; margin-right: auto;"><img border="0" height="240" src="https://1.bp.blogspot.com/-1zksIfUU-7U/XRToEil7J7I/AAAAAAABpiI/nR4seqK1l08FfLoalQyM2OzdK3iZTwL2ACKgBGAs/s320/MVIMG_20190626_112006_1.jpg" width="320"/></a></td></tr>
<tr><td class="tr-caption" style="text-align: center;">Georgia Tech FCRC Participants</td></tr>
</tbody></table>
I'm heading home from the <a href="https://fcrc.acm.org/">2019 ACM Federated Computing Research Conference</a> in Phoenix, a collection of computer science meetings including <a href="http://acm-stoc.org/stoc2019/">STOC</a>, <a href="http://learningtheory.org/colt2019/">COLT</a> and <a href="http://www.sigecom.org/ec19/">EC</a>.<br/>
<br/>
Geoff Hinton and Yann LeCun gave their Turing award lectures, their co-winner Yoshua Bengio not in attendance. Hinton talked about how machine learning triumphed over symbolic AI. LeCun argued that under uncertainty, one should learn the distribution instead of just the average. If you want more, just <a href="https://fcrc.acm.org/turing-lecture-at-fcrc-2019">watch it yourself</a>.<br/>
<div style="text-align: left;">
<br/></div>
<div style="text-align: left;">
To get to the STOC lectures you go up and down escalators and pass through ISCA (Computer Architecture) and PLDI (Programming Languages). It's like you are going up the computing stack until you reach algorithms and complexity. </div>
<div style="text-align: left;">
<br/>
The conference center was just two blocks from Chase Field so we could take in a Diamondbacks baseball game. They opened the roof because the temperature dropped into the double digits. Last night, Paul McCartney played at an arena just a block from the conference center, but instead I hung out at an Uber reception for the EC conference.<br/>
<br/></div>
<div style="text-align: left;">
Let me mention a best paper awardee, <a href="https://doi.org/10.1145/3313276.3316369">The Reachability Problem for Petri Nets is Not Elementary</a> by Wojciech Czerwinski, Slawomir Lasota, Ranko Lazic, Jerome Leroux and Filip Mazowiecki. In a Petri net you have a list of vectors of integers and an initial and final vector. You start with the initial vector and can add any of the other vectors nondeterministically as often as you like as long as no coordinate goes negative. Can you get to the final vector? This problem was known to be computable in "Ackermannian" time and EXPSPACE-hard. This paper shows the problem is not elementary, i.e. not solvable in running time a tower of 2's to the n. A <a href="https://arxiv.org/abs/1903.08575">recent result</a> shows Petri Nets reachability is primitive recursive for fixed dimensions.<br/>
<br/>
Avi Wigderson gave the Knuth Prize lecture exploring deep connections between mathematics and algorithms. Hopefully the video will be online soon.<br/>
<br/>
STOC next year in Chicago, EC as part of the Game Theory Congress in Budapest. </div></div>
    </content>
    <updated>2019-06-27T20:34:00Z</updated>
    <published>2019-06-27T20:34:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-07-01T11:43:39Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2019/06/27/student-combinatorics-day-at-bar-ilan-university-israel/</id>
    <link href="https://cstheory-events.org/2019/06/27/student-combinatorics-day-at-bar-ilan-university-israel/" rel="alternate" type="text/html"/>
    <title>Student Combinatorics Day at Bar Ilan University (Israel)</title>
    <summary>July 7, 2019 Bar Ilan University, Israel https://sites.google.com/a/math.biu.ac.il/student-combinatorics-day/ A one-day workshop in Combinatorics composed of a keynote talk of Noga Alon on list coloring and of 15 short talks by graduate students and postdocs.</summary>
    <updated>2019-06-27T16:35:25Z</updated>
    <published>2019-06-27T16:35:25Z</published>
    <category term="workshop"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2019-07-01T12:21:25Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/090</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/090" rel="alternate" type="text/html"/>
    <title>TR19-090 |  Quasilinear time list-decodable codes for space bounded channels | 

	Ronen Shaltiel, 

	Swastik Kopparty, 

	Jad Silbak</title>
    <summary>We consider codes for space bounded channels. This is a model for communication under noise that was studied by Guruswami and Smith (J. ACM 2016) and lies between the Shannon (random) and Hamming (adversarial) models. In this model, a channel is a space bounded procedure that reads the codeword in one pass, and modifies at most a $p$ fraction of the bits of the codeword.

Guruswami and Smith, and later work by Shaltiel and Silbak (RANDOM 2016), gave constructions of list-decodable codes with rate approaching $1-H(p)$ against channels with space $s=c \log n$, with encoding/decoding time $\poly(2^s)=\poly(n^c)$.

In this paper we show that for every constant $0 \le p 0$, there are codes with rate $R \ge 1-H(p)-\epsilon$, list size $\poly(1/\epsilon)$, and furthermore:
\begin{itemize}
\item Our codes can handle channels with space $s=n^{\Omega(1)}$, which is much larger than $O(\log n)$ achieved by previous work.
\item We give encoding and decoding algorithms that run in time $n \cdot \polylog(n)$. Previous work achieved large and unspecified $\poly(n)$ time (even for space $s=1 \cdot \log n$ channels).
\item We can handle space bounded channels that read the codeword in any order, whereas previous work considered channels that read the codeword in the standard order.
\end{itemize}
Our construction builds on the machinery of Guruswami and Smith (with some key modifications) replacing some nonconstructive codes and pseudorandom objects (that are found in exponential time by brute force) with efficient explicit constructions.
For this purpose we exploit recent results of Haramaty, Lee and Viola (SICOMP 2018) on pseudorandom properties of ``$t$-wise independence + low weight noise'' which we quantitatively improve using techniques by Forbes and Kelly (FOCS 2018).

To make use of such distributions, we give new explicit constructions of binary linear codes that have dual distance of $n^{\Omega(1)}$, and are also polynomial time list-decodable from relative distance $\half-\epsilon$, with list size $\poly(1/\epsilon)$. To the best of our knowledge, no such construction was previously known.

Somewhat surprisingly, we show that Reed-Solomon codes with dimension $k&lt;\sqrt{n}$, have this property if interpreted as binary codes (in some specific interpretation) which we term: ``Raw Reed-Solomon Codes''. A key idea is viewing Reed-Solomon codes as ``bundles'' of certain dual-BCH codewords.</summary>
    <updated>2019-06-27T11:33:00Z</updated>
    <published>2019-06-27T11:33:00Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-07-01T12:20:36Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://thmatters.wordpress.com/?p=1278</id>
    <link href="https://thmatters.wordpress.com/2019/06/26/edit-a-thon-update/" rel="alternate" type="text/html"/>
    <title>Edit-a-thon update</title>
    <summary>This event was a great success! Thank you to all of the participants for contributing your time. Please keep up the momentum and continue to edit the pages you made a start on. Please continue to record your progress on the list of topics. Special thanks to Aviad Rubinstein and Yuval Filmus for offering expert […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="https://thmatters.wordpress.com/2019/06/11/wikipedia-edit-a-thon-at-stoc19/">This event</a> was a great success! Thank you to all of the participants for contributing your time. Please keep up the momentum and continue to edit the pages you made a start on. Please continue to record your progress on the <a href="https://docs.google.com/spreadsheets/d/1zVUdxKk9nqR5Itwc37v26aRHMqgV9qI8XexssoFq_CE/edit?usp=sharing">list of topics</a>. Special thanks to Aviad Rubinstein and Yuval Filmus for offering expert advice at the event.</p>
<p>We plan to organize this event again at future STOCs, and hope many more people can participate. Even an hour of your time can have a huge impact on the community!</p>
<p><img alt="20190625_212644" class="  wp-image-1279 aligncenter" height="352" src="https://thmatters.files.wordpress.com/2019/06/20190625_212644.jpg?w=470&amp;h=352" width="470"/></p></div>
    </content>
    <updated>2019-06-26T15:54:42Z</updated>
    <published>2019-06-26T15:54:42Z</published>
    <category term="Uncategorized"/>
    <category term="workshops"/>
    <author>
      <name>shuchic</name>
    </author>
    <source>
      <id>https://thmatters.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://thmatters.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://thmatters.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://thmatters.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://thmatters.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theory Matters</title>
      <updated>2019-07-01T12:20:58Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://emanueleviola.wordpress.com/?p=645</id>
    <link href="https://emanueleviola.wordpress.com/2019/06/25/we-knew-the-best-threshold-circuit-lower-bounds-long-ago/" rel="alternate" type="text/html"/>
    <title>We knew the best threshold-circuit lower bounds long ago</title>
    <summary>For more than 20 years we’ve had lower bounds for threshold circuits of depth [IPS97], for a fixed . There have been several “explanations” for the lack of progress [AK10]. Recently Chen and Tell have given a better explanation showing that you can’t even improve the result to a better without proving “the whole thing.” […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>     <!--http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd-->                 <!-- html,xhtml,-css,NoFonts -->     </p>
<p style="text-align: justify;">For more than 20 years we’ve had <img alt="n^{1+c^{-d}}" class="latex" src="https://s0.wp.com/latex.php?latex=n%5E%7B1%2Bc%5E%7B-d%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n^{1+c^{-d}}"/> lower bounds for threshold circuits of depth <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/> <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XImpagliazzoPS97">IPS97</a>]</span>, for a fixed <img alt="c" class="latex" src="https://s0.wp.com/latex.php?latex=c&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c"/>. There have been several “explanations” for the lack of progress <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XAllenderK10">AK10</a>]</span>. Recently <a href="https://www.google.com/url%3Fsa%3Dt%26rct%3Dj%26q%3D%26esrc%3Ds%26source%3Dweb%26cd%3D1%26cad%3Drja%26uact%3D8%26ved%3D2ahUKEwiVrqqOgoXjAhWF1FkKHUgiBjcQFjAAegQIAhAC%26url%3Dhttps%3A%2F%2Feccc.weizmann.ac.il%2Freport%2F2018%2F199%2Fdownload%26usg%3DAOvVaw342o4eSvZMdt_vhMYa7kwk">Chen and Tell</a> have given a better explanation showing that you can’t even improve the result to a better <img alt="c" class="latex" src="https://s0.wp.com/latex.php?latex=c&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c"/> without proving “the whole thing.” </p>
<p style="text-align: justify;">   Say you have a finite group <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/> and you want to compute the <em>iterated product</em> of <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> elements. </p>
<p style="text-align: justify;">   <b>Warm-up <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XAllenderK10">AK10</a>]</span>.</b>. </p>
<p style="text-align: justify;">   Suppose you can compute this with circuits of size <img alt="s(n)=n^{10}" class="latex" src="https://s0.wp.com/latex.php?latex=s%28n%29%3Dn%5E%7B10%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s(n)=n^{10}"/> and depth <img alt="10" class="latex" src="https://s0.wp.com/latex.php?latex=10&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="10"/>. Now we show how you can trade size for depth. Put a complete tree with fan-in <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> on top of the group product, where each node computes the product of its children (this is correct by associativity, in general this works for a monoid). This tree needs depth <img alt="\log _{f}n" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clog+_%7Bf%7Dn&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\log _{f}n"/>. If you stick your circuit of size <img alt="s(n)" class="latex" src="https://s0.wp.com/latex.php?latex=s%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s(n)"/> and depth <img alt="O(1)" class="latex" src="https://s0.wp.com/latex.php?latex=O%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(1)"/> at each node, the depth of the overall circuit would be obviously <img alt="O(\log _{f}n)" class="latex" src="https://s0.wp.com/latex.php?latex=O%28%5Clog+_%7Bf%7Dn%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(\log _{f}n)"/> and the overall size would be dominated by the input layer which is <img alt="s(f)\cdot n/f&lt;s(f)\cdot n" class="latex" src="https://s0.wp.com/latex.php?latex=s%28f%29%5Ccdot+n%2Ff%3Cs%28f%29%5Ccdot+n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s(f)\cdot n/f&lt;s(f)\cdot n"/>. If you are aiming for overall depth <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/>, you need <img alt="f=n^{O(1/d)}" class="latex" src="https://s0.wp.com/latex.php?latex=f%3Dn%5E%7BO%281%2Fd%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f=n^{O(1/d)}"/>. This gives size <img alt="n^{1+O(1/d)}" class="latex" src="https://s0.wp.com/latex.php?latex=n%5E%7B1%2BO%281%2Fd%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n^{1+O(1/d)}"/>. </p>
<p style="text-align: justify;">   Hence we have shown that proving bounds <img alt="n^{1+\omega (1/d)}" class="latex" src="https://s0.wp.com/latex.php?latex=n%5E%7B1%2B%5Comega+%281%2Fd%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n^{1+\omega (1/d)}"/> for some depth <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/> suffices to prove <img alt="n^{10}" class="latex" src="https://s0.wp.com/latex.php?latex=n%5E%7B10%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n^{10}"/> lower bounds for depth <img alt="10" class="latex" src="https://s0.wp.com/latex.php?latex=10&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="10"/>. </p>
<p style="text-align: justify;">   <b>Chen and Tell.</b>. </p>
<p style="text-align: justify;">   The above is not the most efficient way to build a tree! I am writing this post following their paper to understand what they do. As they say, the idea is quite simple. While above the size will be dominated by the input layer, we want to balance things so that every layer has roughly the same contribution. </p>
<p style="text-align: justify;">   Let’s say we are aiming for size <img alt="n^{1+\epsilon }" class="latex" src="https://s0.wp.com/latex.php?latex=n%5E%7B1%2B%5Cepsilon+%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n^{1+\epsilon }"/> and let’s see what depth we can get. Let’s say now the size is <img alt="s(n)=n^{k}" class="latex" src="https://s0.wp.com/latex.php?latex=s%28n%29%3Dn%5E%7Bk%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s(n)=n^{k}"/>. Let us denote by <img alt="n_{i}" class="latex" src="https://s0.wp.com/latex.php?latex=n_%7Bi%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n_{i}"/> the number of nodes at level <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/> with <img alt="i=0" class="latex" src="https://s0.wp.com/latex.php?latex=i%3D0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i=0"/> being the root. The fan-in at level <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/> is <img alt="(n^{1+\epsilon }/n_{i})^{1/k}" class="latex" src="https://s0.wp.com/latex.php?latex=%28n%5E%7B1%2B%5Cepsilon+%7D%2Fn_%7Bi%7D%29%5E%7B1%2Fk%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(n^{1+\epsilon }/n_{i})^{1/k}"/> so that the cost is <img alt="n^{1+\epsilon }" class="latex" src="https://s0.wp.com/latex.php?latex=n%5E%7B1%2B%5Cepsilon+%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n^{1+\epsilon }"/> as desired. We have the recursion <img alt="n_{i+1}=n_{i}\cdot (n^{1+\epsilon }/n_{i})^{1/k}" class="latex" src="https://s0.wp.com/latex.php?latex=n_%7Bi%2B1%7D%3Dn_%7Bi%7D%5Ccdot+%28n%5E%7B1%2B%5Cepsilon+%7D%2Fn_%7Bi%7D%29%5E%7B1%2Fk%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n_{i+1}=n_{i}\cdot (n^{1+\epsilon }/n_{i})^{1/k}"/>. </p>
<p style="text-align: justify;">   The solution to this recursion is <img alt="n_{i}=n^{(1+\epsilon )(1-(1-1/k)^{i})}" class="latex" src="https://s0.wp.com/latex.php?latex=n_%7Bi%7D%3Dn%5E%7B%281%2B%5Cepsilon+%29%281-%281-1%2Fk%29%5E%7Bi%7D%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n_{i}=n^{(1+\epsilon )(1-(1-1/k)^{i})}"/>, see below. </p>
<p style="text-align: justify;">   So that’s it. We need to get to <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> nodes. So if you set <img alt="i=O(k\log (1/\epsilon ))" class="latex" src="https://s0.wp.com/latex.php?latex=i%3DO%28k%5Clog+%281%2F%5Cepsilon+%29%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i=O(k\log (1/\epsilon ))"/> you get say <img alt="n_{i}=n^{(1+\epsilon )(1-\epsilon ^{2})}&gt;n" class="latex" src="https://s0.wp.com/latex.php?latex=n_%7Bi%7D%3Dn%5E%7B%281%2B%5Cepsilon+%29%281-%5Cepsilon+%5E%7B2%7D%29%7D%3En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n_{i}=n^{(1+\epsilon )(1-\epsilon ^{2})}&gt;n"/>. Going back to <img alt="k=10" class="latex" src="https://s0.wp.com/latex.php?latex=k%3D10&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k=10"/>, we have exhibited circuits of size <img alt="n^{1+\epsilon }" class="latex" src="https://s0.wp.com/latex.php?latex=n%5E%7B1%2B%5Cepsilon+%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n^{1+\epsilon }"/> and depth just <img alt="O(\log 1/\epsilon )" class="latex" src="https://s0.wp.com/latex.php?latex=O%28%5Clog+1%2F%5Cepsilon+%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(\log 1/\epsilon )"/>. So proving stronger bounds than this would rule out circuits of size <img alt="n^{10}" class="latex" src="https://s0.wp.com/latex.php?latex=n%5E%7B10%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n^{10}"/> and depth <img alt="10" class="latex" src="https://s0.wp.com/latex.php?latex=10&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="10"/>. </p>
<p style="text-align: justify;">   <b>Added later: About the recurrence</b>. </p>
<p style="text-align: justify;">   Letting <img alt="a_{i}:=\log _{n}n_{i}" class="latex" src="https://s0.wp.com/latex.php?latex=a_%7Bi%7D%3A%3D%5Clog+_%7Bn%7Dn_%7Bi%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_{i}:=\log _{n}n_{i}"/> we have the following recurrence for the exponents of <img alt="n_{i}" class="latex" src="https://s0.wp.com/latex.php?latex=n_%7Bi%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n_{i}"/>. </p>
<p style="text-align: justify;">
</p><div style="text-align: center;"> <img alt="\begin{aligned} a_{0} &amp; =0\\ a_{i+1} &amp; =a_{i}(1-1/k)+(1+\epsilon )/k=:a_{i}b+c. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+a_%7B0%7D+%26+%3D0%5C%5C+a_%7Bi%2B1%7D+%26+%3Da_%7Bi%7D%281-1%2Fk%29%2B%281%2B%5Cepsilon+%29%2Fk%3D%3Aa_%7Bi%7Db%2Bc.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} a_{0} &amp; =0\\ a_{i+1} &amp; =a_{i}(1-1/k)+(1+\epsilon )/k=:a_{i}b+c. \end{aligned}"/> </div>
<p/>
<p style="text-align: justify;">   This gives </p>
<div style="text-align: center;"> <img alt="\begin{aligned} a_{i}=c\sum _{j\le i}b{}^{j}=c\frac {1-b^{i+1}}{1-b}=(1+\epsilon )(1-b^{i+1}). \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+a_%7Bi%7D%3Dc%5Csum+_%7Bj%5Cle+i%7Db%7B%7D%5E%7Bj%7D%3Dc%5Cfrac+%7B1-b%5E%7Bi%2B1%7D%7D%7B1-b%7D%3D%281%2B%5Cepsilon+%29%281-b%5E%7Bi%2B1%7D%29.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} a_{i}=c\sum _{j\le i}b{}^{j}=c\frac {1-b^{i+1}}{1-b}=(1+\epsilon )(1-b^{i+1}). \end{aligned}"/> </div>
<p/>
<p style="text-align: justify;">   If it was <img alt="a'_{i+1}=a'_{i}+(1+\epsilon )/k" class="latex" src="https://s0.wp.com/latex.php?latex=a%27_%7Bi%2B1%7D%3Da%27_%7Bi%7D%2B%281%2B%5Cepsilon+%29%2Fk&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a'_{i+1}=a'_{i}+(1+\epsilon )/k"/> obviously <img alt="a'_{k}" class="latex" src="https://s0.wp.com/latex.php?latex=a%27_%7Bk%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a'_{k}"/> would already be <img alt="1+\epsilon " class="latex" src="https://s0.wp.com/latex.php?latex=1%2B%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1+\epsilon "/>. Instead for <img alt="a_{i}" class="latex" src="https://s0.wp.com/latex.php?latex=a_%7Bi%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_{i}"/> we need to get to <img alt="k\log (1/\epsilon )" class="latex" src="https://s0.wp.com/latex.php?latex=k%5Clog+%281%2F%5Cepsilon+%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k\log (1/\epsilon )"/>. </p>
<p style="text-align: justify;">   <b>My two cents.</b>. </p>
<p style="text-align: justify;">   I am not sure I need more evidence that making progress on long-standing bounds in complexity theory is hard, but I do find it interesting to prove these links; we have quite a few by now! The fact that we have been stuck forever just short of proving “the whole thing” makes me think that these long-sought bounds may in fact be false. Would love to be proved wrong, but it’s 2019, this connection is proved by balancing a tree better, and you feel confident that P <img alt="\ne " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cne+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\ne "/> NP?    </p>
<h3 class="likesectionHead"><a id="x1-1000"/>References</h3>
<p style="text-align: justify;">
</p><div class="thebibliography">
<p class="bibitem"><span class="biblabel">  [AK10]<span class="bibsp">   </span></span><a id="XAllenderK10"/>Eric Allender and Michal Koucký.  Amplifying lower bounds by         means of self-reducibility. J. of the ACM, 57(3), 2010.         </p>
<p class="bibitem"><span class="biblabel">  [IPS97]<span class="bibsp">   </span></span><a id="XImpagliazzoPS97"/>Russell Impagliazzo, Ramamohan Paturi, and Michael E. Saks.         Size-depth  tradeoffs  for  threshold  circuits.    SIAM  J.  Comput.,         26(3):693–707, 1997. </p>
<p/></div></div>
    </content>
    <updated>2019-06-25T18:02:17Z</updated>
    <published>2019-06-25T18:02:17Z</published>
    <category term="Uncategorized"/>
    <category term="lower bounds"/>
    <category term="review"/>
    <author>
      <name>Emanuele</name>
    </author>
    <source>
      <id>https://emanueleviola.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://emanueleviola.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://emanueleviola.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://emanueleviola.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://emanueleviola.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>by Manu</subtitle>
      <title>Thoughts</title>
      <updated>2019-07-01T12:21:08Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://theorydish.blog/?p=1503</id>
    <link href="https://theorydish.blog/2019/06/24/on-the-importance-of-disciplinary-pride-for-multidisciplinary-collaboration/" rel="alternate" type="text/html"/>
    <title>On the Importance of Disciplinary Pride for Multidisciplinary Collaboration</title>
    <summary>    On the Importance of Disciplinary Pride for Multidisciplinary Collaboration I am a big fan of collaborations, even if they come with their own challenges. I always got further and enjoyed research much more because of my collaborators. I’m forever indebted to so many colleagues and dear, dear friends. Each and every one of them was better than me in some ways. To contribute, I had to remember my own strengths and bring them to the table. The premise of this post is that the same holds for collaboration between fields. It should be read as a call for theoreticians to bring the tools and the powerful way of thinking of TOC into collaborations. We shouldn’t be blind to the limitation of our field but obsessing on those limitations is misguided and would only limit our impact. Instead we should bring our best and trust on the other disciplines we collaborate with to do the same (allowing each to complement and compensate for the other). The context in which these thoughts came to my mind is Algorithmic Fairness. In this and other areas on the interface between society and computing, true collaboration is vital. Not surprisingly, attending multidisciplinary programs [...]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p> </p>
<p> </p>
<p>On the Importance of Disciplinary Pride for Multidisciplinary Collaboration</p>
<p>I am a big fan of collaborations, even if they <a href="https://windowsontheory.org/2014/07/01/collaboration-competition-and-competition-within-collaboration/">come with their own challenges</a>. I always got further and enjoyed research much more because of my collaborators. I’m forever indebted to so many colleagues and dear, dear friends. Each and every one of them was better than me in some ways. To contribute, I had to remember my own strengths and bring them to the table. The premise of this post is that the same holds for collaboration between fields. It should be read as a call for theoreticians to bring the tools and the powerful way of thinking of TOC into collaborations. We shouldn’t be blind to the limitation of our field but obsessing on those limitations is misguided and would only limit our impact. Instead we should bring our best and trust on the other disciplines we collaborate with to do the same (allowing each to complement and compensate for the other).</p>
<p>The context in which these thoughts came to my mind is Algorithmic Fairness. In this and other areas on the interface between society and computing, true <a href="https://theorydish.blog/2018/11/01/simons-cluster-on-algorithmic-fairness/">collaboration is vital</a>. Not surprisingly, attending multidisciplinary programs on Algorithm Fairness, is a major part of my professional activities these days. And I love it – I get to learn so much from people and disciplines that have been thinking about fairness for many decades and centuries. In addition, the Humanities are simply splendid. Multidisciplinary collaborations come with even more challenges than other collaborations: the language, tools and perspectives are different. But for exactly the same reasons they can be even more rewarding. Nevertheless, my fear and the reason for this post is that my less experienced TOC colleagues might come out from those interdisciplinary meetings frustrated and might lose confidence in what TOC can contribute. It feels to me that <a href="http://www.wisdom.weizmann.ac.il/~oded/PDF/toc-sp2.pdf">old lessons</a> about the value of TOC need to be learned again. There is a lot to be proud of, and holding to this pride would in fact make us better collaborators not worse.</p>
<p>In the context of Algorithmic Fairness, we should definitely acknowledge (as we often do) that science exists within political structures, that algorithms are not objective and that mathematical definitions cannot replace social norms as expressed by policy makers. But let’s not take these as excuses for inaction and let’s not withdraw to the role of spectators. In this era of algorithms, other disciplines need us just as much as we need them .</p>
<p> </p></div>
    </content>
    <updated>2019-06-24T16:43:23Z</updated>
    <published>2019-06-24T16:43:23Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Omer Reingold</name>
    </author>
    <source>
      <id>https://theorydish.blog</id>
      <logo>https://theorydish.files.wordpress.com/2017/03/cropped-nightdish1.jpg?w=32</logo>
      <link href="https://theorydish.blog/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://theorydish.blog" rel="alternate" type="text/html"/>
      <link href="https://theorydish.blog/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://theorydish.blog/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Stanford's CS Theory Research Blog</subtitle>
      <title>Theory Dish</title>
      <updated>2019-07-01T12:21:27Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-8803689043688761239</id>
    <link href="https://blog.computationalcomplexity.org/feeds/8803689043688761239/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/06/are-you-smarter-than-5th-grade-amoeba.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/8803689043688761239" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/8803689043688761239" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/06/are-you-smarter-than-5th-grade-amoeba.html" rel="alternate" type="text/html"/>
    <title>Are you smarter than a 5th grade amoeba?</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">(title of this blog is due to Henry Baker who posted an article about this elsewhere)<br/>
<br/>
Amoeba finds approx solution to TSP in linear time:<a href="https://phys.org/news/2018-12-amoeba-approximate-solutions-np-hard-problem.html">here</a>.<br/>
<br/>
Over the years we have seen models of computation that claim to solve NPC or other hard problems quickly. I ask non-rhetorically and with and open mind how they have panned out.<br/>
<br/>
In no particular order:<br/>
<br/>
1) Parallelism. For solving problems faster YES. For speeding up how to solve NPC problems I think YES. For making P=NP somehow NO.  Even so, parallel computers have been a definite practical success.<br/>
<br/>
2) Quantum Computing. Will they factor large numbers anytime soon? Ever? Should we view the effort to build them as an awesome and insightful Physics experiment? Are there any problems that they are NOW doing faster? Is Quantum Crypto (I know, not the same thing) actually used? Will other things of interest come out of the study of quantum computing? It already has, see <a href="https://theoryofcomputing.org/articles/gs002/gs002.pdf">here</a>.<br/>
<br/>
3) DNA computing. Did that lead to practical solutions to NPC problems? I do not think it did. Did that lead to interesting math? Interesting biology? Interesting science?  I do not know.<br/>
<br/>
4) Autistic  computing for finding primes: see <a href="https://blog.computationalcomplexity.org/2009/09/possibly-recruits-for-polymath-primes.html">here</a>. Oliver Sacks, the neurologist ,claimed that two autistic twin brothers could generate large primes quickly. This story was never put to a rigorous test and may not be quite right.<br/>
<br/>
5) Amoeba computing: Too early to tell. The article seems to say it succeeded on 8 cities<br/>
<br/>
The problem with all of these non-standard models of computing is SCALE.  And the more powerful classic computers get, the harder it is for these nonstandard models to compete.<br/>
<br/>
Are these models interesting even if they don't end up getting us fast algorithms? They can be:<br/>
<br/>
1) Do they lead to mathematics of interest? (Quantum- Yes, Parallelism- Yes)<br/>
<br/>
2) Did they inspire algorithms for classical computers? (Quantum- Yes)<br/>
<br/>
3) Do they give insight into other fields? (Quantum for Physics yes, DNA-computing for bio-??)<br/>
<br/>
4) Have they ACTUALLY sped up  up computations in meaningful ways for problems we care about (Parallelism  has)<br/>
<br/>
If  you know of any result which I missed<br/>
<br/>
 (e.g.,<br/>
<br/>
 Amoeba-computing giving insight into evolution,<br/>
<br/>
Autistic computing being used by the NSA to find primes,<br/>
<br/>
 DNA computing  leading to interesting mathematics)<br/>
<br/>
 then leave polite comments!<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/></div>
    </content>
    <updated>2019-06-24T05:03:00Z</updated>
    <published>2019-06-24T05:03:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-07-01T11:43:39Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16034</id>
    <link href="https://rjlipton.wordpress.com/2019/06/23/computer-science-gender-gap/" rel="alternate" type="text/html"/>
    <title>Computer Science Gender Gap</title>
    <summary>NY Times article on the paper LinkedIn source Lucy Lu Wang is the lead author of a paper released this Friday on gender parity in computer science. The paper is from the Allen Institute for Artificial Intelligence. The authors are Wang, Gabriel Stanovsky, Luca Weihs, and Oren Etzioni. We will call them WSWE for short. […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>NY Times article on the paper</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2019/06/23/computer-science-gender-gap/unknown-123/" rel="attachment wp-att-16036"><img alt="" class="alignright size-full wp-image-16036" src="https://rjlipton.files.wordpress.com/2019/06/unknown.jpeg?w=600"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">LinkedIn <a href="https://www.linkedin.com/in/lucylw/">source</a></font></td>
</tr>
</tbody>
</table>
<p>
Lucy Lu Wang is the lead author of a paper released this Friday on gender parity in computer science. The <a href="https://arxiv.org/pdf/1906.07883.pdf">paper</a> is from the Allen Institute for Artificial Intelligence. The authors are Wang, Gabriel Stanovsky, Luca Weihs, and Oren Etzioni.  We will call them WSWE for short. </p>
<p>
Today we will discuss some of the issues this study raises.</p>
<p>
The paper was highlighted by the New York Times in an <a href="https://www.nytimes.com/2019/06/21/technology/gender-gap-tech-computer-science.html">article</a> titled, “The Gender Gap in Computer Science Research Won’t Close for 100 Years.”  The news article begins with an equally sobering statement of this conclusion:</p>
<blockquote><p><b> </b> <em>Women will not reach parity with men in writing published computer science research in this century if current trends hold, according to a study released on Friday. </em>
</p></blockquote>
<p/><p>
We are for gender-neutral opportunities and have always promoted this—see our earlier discussions <a href="https://rjlipton.wordpress.com/2010/03/23/its-ada-lovelace-day/">here</a> and <a href="https://rjlipton.wordpress.com/2016/10/29/absolute-firsts/">here</a>. We are for doing a better job in supporting women in computer science. The study by WSWE is an important paper that helps frame the problem. Quoting them:</p>
<blockquote><p><b> </b> <em> The field has made more of an effort to reach a more balanced gender status. But the data seems to show that even with all the progress, we are still not making the change fast enough. </em>
</p></blockquote>
<p/><p>
I suggest that you might wish to read the paper. Unfortunately there are many papers with similar conclusions—see <a href="https://aclweb.org/anthology/D18-1301">this</a> by Natalie Schluter, for example. </p>
<p>
</p><p/><h2> Main Points </h2><p/>
<p/><p>
Here are some points of the paper by WSWE:</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <i>There is a measurable gap</i>. No one would, I believe, doubt this. But it is important to see that it is measurable. </p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <i>The gap is shrinking, but slowly</i>. Again this seems correct, but whether it is shrinking in all relevant measures of publication weight is still an issue.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <i>The predictions</i>. Perhaps it will not be closed for over a century. </p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <i>Modern technology allows such a study</i>. This is one aspect that we can all applaud. WSWE used automated tools that allowed this study to search millions of papers.</p>
<p>
</p><p/><h2> Issues </h2><p/>
<p>
WSWE filtered a corpus of <b>2.87 million</b> papers tagged as in computer science.  The volume constrained their approaches to handling several basic issues.</p>
<p/><p><br/>
<img alt="{\bullet}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet}"/> How to tell the gender of an author?  They use first names and try to detect gender from that alone. This is not easy.  Not only can differently-gendered names in different nations or language groups have the same Romanized form, many names apply to both genders within those groups.  The names Taylor and Kelley are perfect examples pf the latter. </p>
<p>
WSWE used a statistical weighing method. So “Taylor,” for example, would be weighted as 55 percent female, 45 percent male.  The weightings come from a large database called <i>Gender API</i> compiled from government and social agencies not directly related to computer science. </p>
<p/><p><br/>
<img alt="{\bullet}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet}"/> Another issue concerns the prediction part of their paper. They attempt to extrapolate and guess when there will be parity between female and male authorship. </p>
<p>
As all predictions this is not easy. It is my main complaint with this and other papers on the gender-gap issue. They predict that parity will not be reached until 2167, in 168 years. An earlier <a href="https://www.computerworld.com.au/article/640548/gender-parity-computer-science-could-take-280-years/">study</a> puts the parity point at 280 years away.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
I believe that a major issue is hiring by computer science departments and other institutions. A major CS department just hired <img alt="{N&gt;1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%3E1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N&gt;1}"/> assistant professors, of which <img alt="{N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N}"/> were male. This is a problem. </p>
<p>
Should studies on the gender gap count all papers? Perhaps they should weight the papers by some citation indices. Are women writing more impactful papers? What percent of papers by gender have citations rate above X?—you get the idea. </p>
<p>
Finally I wonder if parity is the right goal? <b>How about aiming for more women papers than men</b>? Why not?</p>
<p/><p><br/>
[various formatting and word edits]</p></font></font></div>
    </content>
    <updated>2019-06-23T22:33:38Z</updated>
    <published>2019-06-23T22:33:38Z</published>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="People"/>
    <category term="gender gap"/>
    <category term="gender parity"/>
    <category term="parity"/>
    <category term="study"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-07-01T12:20:46Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://minimizingregret.wordpress.com/?p=203</id>
    <link href="https://minimizingregret.wordpress.com/2019/06/23/lecture-notes-optimization-for-ml/" rel="alternate" type="text/html"/>
    <title>Lecture notes: optimization for ML</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Spring semester is over, yay! To celebrate summer, I’ve compiled lecture notes from the graduate course COS 598D, a.k.a. “optimization for machine learning“. The course is an aftermath of a few lectures and summer school tutorials given in various locations, in which  lectures goal of the course was to present the most useful methods and … <a class="more-link" href="https://minimizingregret.wordpress.com/2019/06/23/lecture-notes-optimization-for-ml/">Continue reading <span class="screen-reader-text">Lecture notes: optimization for ML</span> <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Spring semester is over, yay! To celebrate summer, I’ve compiled lecture notes from the graduate course COS 598D, a.k.a. “<a href="https://sites.google.com/view/optimization4machinelearning/home">optimization for machine learning</a>“.</p>
<p>The course is an aftermath of a few lectures and summer school tutorials given in various locations, in which  lectures goal of the course was to present the most useful methods and ideas in a rigorous-but-not-tedious way:</p>
<ul>
<li>Suitable for a mathematically-prepared undergraduate student, and/or researcher beginning their endeavor into machine learning.</li>
<li>Focus on the important: we start with stochastic gradient descent for training deep neural networks.</li>
<li>Bring out the main ideas: i.e. projection-free methods, second-order optimization, the three main acceleration techniques, qualitatively discuss the advantages and applicability of each.</li>
<li>*short* proofs, that everyone can follow and extend in their future research. I prefer being off by a constant/log factor from the best known bound with a more insightful proof.</li>
<li>Not loose track of the goal: generalization/regret, rather than final accuracy. This means we talked about online learning, generalization and precision issues in ML.</li>
</ul>
<p>The most recent version can be downloaded here:<br/>
<a href="https://drive.google.com/open?id=1GIDnw7T-NT4Do3eC0B5kYJlzwOs6nzIO" title="OPTtutorial">OPTtutorial</a></p>
<p>This is still work in progress, please feel free to send me typos/corrections, as well as other topics you’d like to see (on my todos already: lower bounds, quasi-convexity, and the homotopy method).</p>
<p>Note: zero-order/bandit optimization is an obvious topic that’s not address. The reason is purely subjective – it appears as a chapter in <a href="http://ocobook.cs.princeton.edu/">this textbook</a> (that also started as lecture notes!).</p>
<p> </p></div>
    </content>
    <updated>2019-06-23T21:49:40Z</updated>
    <published>2019-06-23T21:49:40Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Elad Hazan</name>
    </author>
    <source>
      <id>https://minimizingregret.wordpress.com</id>
      <logo>https://minimizingregret.files.wordpress.com/2017/08/cropped-pu1.png?w=32</logo>
      <link href="https://minimizingregret.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://minimizingregret.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://minimizingregret.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://minimizingregret.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Google Princeton AI and Hazan Lab @ Princeton University</subtitle>
      <title>Minimizing Regret</title>
      <updated>2019-07-01T12:21:34Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/06/23/postdoc-at-uc-san-diego-apply-by-august-1-2019/</id>
    <link href="https://cstheory-jobs.org/2019/06/23/postdoc-at-uc-san-diego-apply-by-august-1-2019/" rel="alternate" type="text/html"/>
    <title>postdoc at UC San Diego (apply by August 1, 2019)</title>
    <summary>We are looking for strong theory candidates working in the areas of machine learning, optimization, high dimensional statistics, privacy, fairness, and broadly interpreted data science. The postdoc is part of the Data Science fellows program at UCSD. Expected start date is October 1, 2019. As this is very late in the season, please apply online […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>We are looking for strong theory candidates working in the areas of machine learning, optimization, high dimensional statistics, privacy, fairness, and broadly interpreted data science. The postdoc is part of the Data Science fellows program at UCSD.</p>
<p>Expected start date is October 1, 2019. As this is very late in the season, please apply online in the website and ALSO email Shachar.</p>
<p>Website: <a href="http://dsfellows.ucsd.edu/">http://dsfellows.ucsd.edu/</a><br/>
Email: shachar.lovett@gmail.com</p></div>
    </content>
    <updated>2019-06-23T20:34:36Z</updated>
    <published>2019-06-23T20:34:36Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-07-01T12:20:49Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/06/23/phd-scholarship-in-computer-science-at-european-university-cyprus-apply-by-june-28-2019/</id>
    <link href="https://cstheory-jobs.org/2019/06/23/phd-scholarship-in-computer-science-at-european-university-cyprus-apply-by-june-28-2019/" rel="alternate" type="text/html"/>
    <title>PhD Scholarship in Computer Science at European University Cyprus (apply by June 28, 2019)</title>
    <summary>The Department of Computer Science and Eng. jointly with the Astrophysics and HPC Group of European University Cyprus announce one scholarship for the Ph.D. Program of Computing/Computer Science. The topics are: • Parallel Algorithms and HPC • Graph Theory and Applications • Big Data Applications on Astrophysics Opportunities for extra funding are also available. Website: […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Department of Computer Science and Eng. jointly with the Astrophysics and HPC Group of European University Cyprus announce one scholarship for the Ph.D. Program of Computing/Computer Science. The topics are: •	Parallel Algorithms and HPC<br/>
•	Graph Theory and Applications<br/>
•	Big Data Applications on Astrophysics<br/>
Opportunities for extra funding are also available.</p>
<p>Website: <a href="http://ahpc.euc.ac.cy/call-of-phd-positions-2/">http://ahpc.euc.ac.cy/call-of-phd-positions-2/</a><br/>
Email: A.Efstathiou@euc.ac.cy</p></div>
    </content>
    <updated>2019-06-23T20:34:36Z</updated>
    <published>2019-06-23T20:34:36Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-07-01T12:20:49Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/089</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/089" rel="alternate" type="text/html"/>
    <title>TR19-089 |  Exponential separation between shallow quantum circuits and unbounded fan-in shallow classical circuits | 

	Adam Bene Watts, 

	Robin Kothari, 

	Luke Schaeffer, 

	Avishay Tal</title>
    <summary>Recently, Bravyi, Gosset, and König (Science, 2018) exhibited a search problem called the 2D Hidden Linear Function (2D HLF) problem that can be solved exactly by a constant-depth quantum circuit using bounded fan-in gates (or QNC^0 circuits), but cannot be solved by any constant-depth classical circuit using bounded fan-in AND, OR, and NOT gates (or NC^0 circuits). In other words, they exhibited a search problem in QNC^0 that is not in NC^0.

We strengthen their result by proving that the 2D HLF problem is not contained in AC^0, the class of classical, polynomial-size, constant-depth circuits over the gate set of unbounded fan-in AND and OR gates, and NOT gates. We also supplement this worst-case lower bound with an average-case result: There exists a simple distribution under which any AC^0 circuit (even of nearly exponential size) has exponentially small correlation with the 2D HLF problem. Our results are shown by constructing a new problem in QNC^0, which we call the Relaxed Parity Halving Problem, which is easier to work with. We prove our AC^0 lower bounds for this problem, and then show that it reduces to the 2D HLF problem.

As a step towards even stronger lower bounds, we present a search problem that we call the Parity Bending Problem, which is in QNC^0/qpoly (QNC^0 circuits that are allowed to start with a quantum state of their choice that is independent of the input), but is not even in AC^0[2] (the class AC^0 with unbounded fan-in XOR gates).

All the quantum circuits in our paper are simple, and the main difficulty lies in proving the classical lower bounds. For this we employ a host of techniques, including a refinement of H{\aa}stad's switching lemmas for multi-output circuits that may be of independent interest, the Razborov-Smolensky AC^0[2] lower bound, Vazirani's XOR lemma, and lower bounds for non-local games.</summary>
    <updated>2019-06-23T04:09:25Z</updated>
    <published>2019-06-23T04:09:25Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-07-01T12:20:36Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://blog.ilyaraz.org/rss/11</id>
    <link href="https://blog.ilyaraz.org/?go=all/stoc-2019-workshop-data-science-through-a-geometric-lens/" rel="alternate" type="text/html"/>
    <title>STOC 2019 workshop “Data Science through a Geometric Lens”</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><i>Sign up for the new posts via the <a href="https://blog.ilyaraz.org/rss/">RSS feed</a></i>.</p>
<p>I would like to bring up a <a href="http://acm-stoc.org/stoc2019/">STOC 2019</a> workshop <a href="http://madscience.ucsd.edu/dsgl.html">Data Science through a Geometric Lens</a> (co-organized with <a href="https://cseweb.ucsd.edu/~dasgupta/">Sanjoy Dasgupta</a> and <a href="https://sites.google.com/site/cyrusrashtchian/">Cyrus Rashchtian</a>). It will happen on Sunday at 9am. We have a stellar line-up of speakers:</p>
<ul>
<li><a href="http://www.cs.cmu.edu/~dwoodruf/">David Woodruff</a></li>
<li><a href="http://sgunasekar.github.io/">Suriya Gunasekar</a></li>
<li><a href="https://voices.uchicago.edu/willett/">Rebecca Willett</a></li>
<li><a href="https://www.stat.washington.edu/person/hanyu-zhang">Hanyu Zhang</a></li>
<li><a href="http://www.columbia.edu/~skk2175/">Samory Kpotufe</a></li>
<li><a href="http://www.cs.cmu.edu/~ninamf/">Nina Balcan</a></li>
</ul>
<p>Some of the topics are a bit unusual for the STOC audience, and we hope you will be inspired by fresh ideas. Please do attend and bring your friends!</p></div>
    </summary>
    <updated>2019-06-23T03:12:56Z</updated>
    <published>2019-06-23T03:12:56Z</published>
    <source>
      <id>https://blog.ilyaraz.org/</id>
      <author>
        <name>Ilya Razenshteyn</name>
      </author>
      <link href="https://blog.ilyaraz.org/" rel="alternate" type="text/html"/>
      <link href="https://blog.ilyaraz.org/rss/" rel="self" type="application/rss+xml"/>
      <title>Lullaby of Cape Cod</title>
      <updated>2019-06-30T23:33:01Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/06/21/report-from-socg</id>
    <link href="https://11011110.github.io/blog/2019/06/21/report-from-socg.html" rel="alternate" type="text/html"/>
    <title>Report from SoCG</title>
    <summary>As I mentioned in my previous post, I just finished attending the Symposium on Computational Geometry in Portland. The conference proceedings are open access through LIPIcs.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>As I mentioned in <a href="https://11011110.github.io/blog/2019/06/20/portland-street-art.html">my previous post</a>, I just finished attending the Symposium on Computational Geometry in Portland. The <a href="http://drops.dagstuhl.de/opus/portals/lipics/index.php?semnr=16108">conference proceedings are open access through LIPIcs</a>.</p>

<p>The conference started on Tuesday (after some earlier social activities) with the best paper talk by Arnaud de Mesmay, “<a href="https://doi.org/10.4230/LIPIcs.SoCG.2019.27">Almost tight lower bounds for hard cutting problems in embedded graphs</a>” (with V. Cohen-Addad, É. Colin de Verdière, and D. Marx) proving that, to find the shortest set of cuts to slice a genus- surface into a disk, the exponent must depend linearly on  (assuming the exponential time hypothesis).</p>

<p>Several of the contributed talks from throughout the conference particularly caught my attention:</p>

<ul>
  <li>
    <p>Shay Moran’s paper with A. Yehudayoff, “<a href="https://doi.org/10.4230/LIPIcs.SoCG.2019.51">On weak -nets and the Radon number</a>” concerned abstract convexity spaces where the convex sets are any set family closed under intersection. A space has Radon number  if every  points can be partitioned into two subsets whose convex hulls (smallest containing convex sets) intersect, and a point in the intersection is called a Radon point. Having bounded Radon number turns out to be equivalent to having weak -nets, subsets of points that (for a given measure on the space) intersect every large convex set.</p>
  </li>
  <li>
    <p>Mitchell Jones’ “<a href="https://doi.org/10.4230/LIPIcs.SoCG.2019.41">Journey to the center of the point set</a>” (with Sariel Har-Peled) improved an old paper of mine on using Radon points to find points of high <a href="https://en.wikipedia.org/wiki/Centerpoint_(geometry)">Tukey depth</a> in high-dimensional point sets in time polynomial in the dimension, improving both the polynomial and the depth of the resulting points.</p>
  </li>
  <li>
    <p>Sariel Har-Peled spoke on his work with Timothy Chan, “<a href="https://doi.org/10.4230/LIPIcs.SoCG.2019.23">Smallest -enclosing rectangle revisited</a>”. As well as shaving logs from the time bounds for finding rectangles that enclose a given number of points and minimize their area or perimeter, they found a general reduction from problems on  points to  problems on  points, allowing one to turn factors of  in the time bounds into factors of . Previously such reductions were only known for -point subset problems where the optimal solution lies among the  nearest neighbors of some input point, true for rectangle perimeter but not rectangle area.</p>
  </li>
  <li>
    <p>Timothy Chan’s “<a href="https://doi.org/10.4230/LIPIcs.SoCG.2019.20">Computing Shapley values in the plane</a>” concerns an interesting combination of game theory and computational geometry. The <a href="https://en.wikipedia.org/wiki/Shapley_value">Shapley value</a> is a method for assigning credit when multiple people collaborate to produce some value (given as input a function from subsets of people to the value of a subset). It can be defined by adding contributors one-by-one in a random order and setting each contributor’s Shapley value to the expected increase in value when that contributor is added. It sums to the total value and is the unique function with this property that obeys several other natural and desirable axioms for credit assignment. For arbitrary functions from subsets of  contributors to subset values, it takes time  to compute, but Timothy described polynomial time algorithms for cases when the value function has some geometric meaning, such as when it measures the area of the convex hull of a subset of  points. There’s probably a lot more to be done in the same direction.</p>
  </li>
  <li>
    <p>Patrick Schnider’s “<a href="https://doi.org/10.4230/LIPIcs.SoCG.2019.56">Ham-Sandwich cuts and center transversals in subspaces</a>” has some partial results towards a conjectured generalization of the <a href="https://en.wikipedia.org/wiki/Ham_sandwich_theorem">ham sandwich theorem</a>: given  probability distributions in -dimensional Euclidean space, it should be possible to find  hyperplanes whose checkerboard partition of space simultaneously bisects all of the distributions.</p>
  </li>
  <li>
    <p>Jie Xue spoke on “<a href="https://doi.org/10.4230/LIPIcs.SoCG.2019.60">Near-optimal algorithms for shortest paths in weighted unit-disk graphs</a>” (with Haitao Wang). Here “weighted” means that overlapping unit disks are connected by an edge whose length is the Euclidean distance between their centers. Previous methods obtained near-linear algorithms by using bichromatic closest pair data structures to simulate Dijkstra’s algorithm. Instead, Wang and Xue use a related relaxation algorithm that partitions the plane into a grid and at each step relaxes all edges between certain pairs of grid squares, using data structures for additively weighted nearest neighbors. By avoiding the overhead of closest pairs they shave several logs from the runtime.</p>
  </li>
  <li>
    <p>Arnaud de Mesmay spoke again towards the end of the conference on “<a href="https://doi.org/10.4230/LIPIcs.SoCG.2019.49">The unbearable hardness of unknotting</a>”, with Yo’av Rieck, Eric Sedgwick, and Martin Tancer. They used a reduction from 3-satisfiability, with <a href="https://en.wikipedia.org/wiki/Hopf_link">Hopf links</a> for variables and <a href="https://en.wikipedia.org/wiki/Borromean_rings">Borromean links</a> for clauses (connected to each other by ribbons), to prove that it’s NP-complete to find an unlinked subset of a link with a maximum number of components. By a second level of replacement that doubles the strands of each link, they also showed that it’s NP-complete to find the minimum number of crossing changes or of Reidemeister moves to unlink a link or to unknot a knot.</p>
  </li>
</ul>

<p>On Tuesday afternoon I went to the workshop on open problems. After the obligatory open problem session, we debated whether we should collect problems on <a href="https://cs.smith.edu/~jorourke/TOPP/">The Open Problems Project</a>, <a href="http://www.openproblemgarden.org/">The Open Problem Garden</a>, or some new system that, since it doesn’t exist, can be more perfect than anything that does. Then I switched to the Young Researcher’s Forum (unfortunately missing the open problem implementation challenge); at the YRF, my student Daniel Frishberg spoke about <a href="https://arxiv.org/abs/1902.06875">our work on using nearest neighbor chains to speed up greedy algorithms</a>.</p>

<p>The invited talks on Wednesday and Friday were by Sanjoy Dasgupta and Bruce Donald, respectively. Dasgupta spoke on using concepts from geometric data structures to interpret the neural structure of the olfactory system in fruit flies (and hopefully, eventually, vice versa: to use our understanding of neural structures to develop new data structures). For instance, the first three layers of neurons in this system appear to implement an “expand-and-sparsify” data structure that represents low-dimensional normalized vectors by randomly mapping them to much higher dimensional vectors and then listing as a set a smaller number of high-value coordinates. This appears to be closely analogous to known methods for <a href="https://en.wikipedia.org/wiki/Locality-sensitive_hashing">locality-sensitive hashing</a>.  Donald spoke on using geometric methods to represent and infer the shapes of proteins, and to design proteins with desired shapes and functions.</p>

<p>Wednesday evening was the conference banquet, at the famed <a href="https://en.wikipedia.org/wiki/Crystal_Ballroom_(Portland,_Oregon)">Crystal Ballroom</a>, conveniently located near Powell’s Books. Matthew Dickerson showed up (after many years absence from SoCG) and brought some musical family members for a live concert.</p>

<p style="text-align: center;"><img alt="Marquee for Michael Dickerson and Shaky Situation" src="http://www.ics.uci.edu/~eppstein/pix/portland/ShakySituation-m.jpg" style="border-style: solid; border-color: black;"/></p>

<p>On Thursday afternoon I stopped by the workshop on algebraic methods where I had the pleasure of seing Josh Zahl give his talk on a whiteboard instead of using prepared slides. It was on methods for proving bounds on the number of incidences among geometric objects by combining naive bounds based on forbidden complete bipartite subgraphs of the incidence graphs, cuttings of space into smaller regions within which one applies these naive bounds, and cuttings of the objects into pieces in order to make the forbidden subgraphs smaller.</p>

<p>The conference business meeting was also Thursday, and ran very smoothly.
Next year SoCG will be in Zurich; the year after that, in Buffalo. We now have an officially incorporated society, <a href="http://www.computational-geometry.org/society/index.html">The Society for Computational Geometry</a>, so that we can maintain buffer funds for the conference from one year to the next; it will be supported by an increase of $30-$35 in non-student registration fees. And the attendees voted overwhelmingly in favor of both <a href="https://www.ics.uci.edu/~irani/safetoc.html">the SafeTOC anti-harassment guidelines</a> and ensuring and better advertising the availability of childcare at future conferences.</p>

<p>The conference was dedicated to the memory of <a href="https://en.wikipedia.org/wiki/Richard_M._Pollack">Ricky Pollack</a>, but it also included a celebration on Friday of a living computational geometer: <a href="https://en.wikipedia.org/wiki/John_Hershberger">John Hershberger</a>, who led the effort to bring SoCG to Oregon, and turned 60 just before the conference began. Happy birthday, John!</p>

<p>(<a href="https://mathstodon.xyz/@11011110/102313609521577006">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2019-06-21T22:09:00Z</updated>
    <published>2019-06-21T22:09:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-06-30T23:47:50Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://blogs.princeton.edu/imabandit/?p=1373</id>
    <link href="https://blogs.princeton.edu/imabandit/2019/06/20/optimal-bound-for-stochastic-bandits-with-corruption/" rel="alternate" type="text/html"/>
    <title>Optimal bound for stochastic bandits with corruption</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Guest post by Mark Sellke. In the comments of the previous blog post we asked if the new viewpoint on best of both worlds can be used to get clean “interpolation” results. The context is as follows: in a STOC … <a href="https://blogs.princeton.edu/imabandit/2019/06/20/optimal-bound-for-stochastic-bandits-with-corruption/">Continue reading <span class="meta-nav">→</span></a></p></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><em>Guest post by <a class="liexternal" href="http://web.stanford.edu/~msellke/main">Mark Sellke</a>.</em></p>
<p>In the <a class="liinternal" href="https://blogs.princeton.edu/imabandit/2019/06/10/amazing-progress-in-adversarially-robust-stochastic-multi-armed-bandits/#comments">comments</a> of the previous blog post we asked if the new viewpoint on best of both worlds can be used to get clean “interpolation” results. The context is as follows: in a <a class="liinternal" href="https://arxiv.org/abs/1803.09353">STOC 2018 paper</a> followed by a <a class="liinternal" href="https://arxiv.org/abs/1902.08647">COLT 2019 paper</a>, the following corruption model was discussed: stochastic bandits, except for <img alt="C" class="ql-img-inline-formula " height="12" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-eda88fce4ab12a676aa4baf036291115_l3.png?resize=14%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="14"/> rounds which are adversarial. The state of the art bounds were of the form: optimal (or almost optimal) stochastic term plus <img alt="K C" class="ql-img-inline-formula " height="12" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-189063850ed2dd251e3453bcdf72bb1f_l3.png?resize=30%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="30"/>, and it was mentioned as an open problem whether <img alt="KC" class="ql-img-inline-formula " height="12" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-a11b6676b92ebe2d33985ebf5d9107fe_l3.png?resize=30%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="30"/> could be improved to <img alt="C" class="ql-img-inline-formula " height="12" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-eda88fce4ab12a676aa4baf036291115_l3.png?resize=14%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="14"/> (there is a lower bound showing that <img alt="C" class="ql-img-inline-formula " height="12" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-eda88fce4ab12a676aa4baf036291115_l3.png?resize=14%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="14"/> is necessary — when <img alt="C = O(\sqrt{T})" class="ql-img-inline-formula " height="20" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-7a63a8eb07aa9c2f39df62272d6a867e_l3.png?resize=92%2C20&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="92"/>). As was discussed in the comment section, it seemed that indeed this clean best of both worlds approach should certainly shed light on the corruption model. It turns out that this is indeed the case, and a one-line calculation resolves positively the open problem from the COLT paper. The formal result is as follows (recall the notation/definitions from <a class="liinternal" href="https://blogs.princeton.edu/imabandit/2019/06/10/amazing-progress-in-adversarially-robust-stochastic-multi-armed-bandits/">the previous blog post</a>):</p>
<blockquote><p><strong>Lemma:</strong> Consider a strategy whose regret with respect to the optimal action <img alt="i^*" class="ql-img-inline-formula " height="13" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-9af0b76a90462b68c1d83fca9cc6604d_l3.png?resize=12%2C13&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="12"/> is upper bounded by</p>
<p class="ql-center-displayed-equation" style="line-height: 56px;"><span class="ql-right-eqno"> (1) </span><span class="ql-left-eqno">   </span><img alt="\begin{equation*} c \sum_{t=1}^T \sum_{i \neq i^*} \sqrt{\frac{x_{i,t}}{t}} \,. \end{equation*}" class="ql-img-displayed-equation " height="56" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-2ed2f41c6df060684cac5f6b54464432_l3.png?resize=122%2C56&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="122"/></p>
<p>Then in the <img alt="C" class="ql-img-inline-formula " height="12" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-eda88fce4ab12a676aa4baf036291115_l3.png?resize=14%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="14"/>-corruption stochastic bandit model one has that the regret is bounded by:</p>
<p class="ql-center-displayed-equation" style="line-height: 50px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\[ C + 2 c \sqrt{K C} + c^2 \sum_{i \neq i^*} \frac{\log(T)}{\Delta_i} \]" class="ql-img-displayed-equation " height="50" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c48324ec76e014154981894b80b05577_l3.png?resize=219%2C50&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="219"/></p>
<p> </p></blockquote>
<p>Note that by the previous blog post we know strategies that satisfy (1) with <img alt="c=10" class="ql-img-inline-formula " height="13" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-ac5b38b4377a6b37c2b5319ca167d4c1_l3.png?resize=49%2C13&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="49"/> (see Lemma 2 in the <a class="liinternal" href="https://blogs.princeton.edu/imabandit/2019/06/10/amazing-progress-in-adversarially-robust-stochastic-multi-armed-bandits/">previous post</a>).</p>
<p><em>Proof: In equation (1) let us apply Jensen over the corrupt rounds, this yields a term <img alt="c \sqrt{K C}" class="ql-img-inline-formula " height="18" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-aec148c42036e82bad7bbc28ce4df79f_l3.png?resize=53%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="53"/>. For the non-corrupt rounds, let us use that</em></p>
<p class="ql-center-displayed-equation" style="line-height: 45px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\[ c \sqrt{\frac{x_{i,t}}{t}} \leq \frac{1}{2} \left( \Delta_i x_{i,t} + \frac{c^2}{t \Delta_i} \right) \]" class="ql-img-displayed-equation " height="45" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-85bba8f5ccf6308ab72f723bb5aa19b6_l3.png?resize=213%2C45&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="213"/></p>
<p>The sum of the second term on the right hand side is upper bounded by <img alt="c^2 \sum_{i \neq i^*} \frac{\log(T)}{2 \Delta_i}" class="ql-img-inline-formula " height="28" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-b9e1680c083d81bc4a40e096a27bda7b_l3.png?resize=109%2C28&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="109"/>. On the other hand the sum (over non-corrupt rounds) of the first term is equal to <img alt="1/2" class="ql-img-inline-formula " height="18" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-1c652ece8cc629e4e659c41eeed4d410_l3.png?resize=25%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="25"/> of the regret over the non-corrupt rounds, which is certainly smaller than <img alt="1/2" class="ql-img-inline-formula " height="18" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-1c652ece8cc629e4e659c41eeed4d410_l3.png?resize=25%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="25"/> of the total regret plus <img alt="C" class="ql-img-inline-formula " height="12" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-eda88fce4ab12a676aa4baf036291115_l3.png?resize=14%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="14"/>. Thus we obtain (denoting <img alt="R" class="ql-img-inline-formula " height="12" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-dfd80738ac64385be5b381ea59d7fe55_l3.png?resize=14%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="14"/> for the total regret):</p>
<p class="ql-center-displayed-equation" style="line-height: 50px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\[ R \leq c \sqrt{K C} + c^2 \sum_{i \neq i^*} \frac{\log(T)}{2 \Delta_i} + \frac{C}{2} + \frac{R}{2} \]" class="ql-img-displayed-equation " height="50" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-936baa25f1189bd3993ce4dba58242c5_l3.png?resize=290%2C50&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="290"/></p>
<p>which concludes the proof.</p>
<p> </p></div>
    </content>
    <updated>2019-06-20T18:43:39Z</updated>
    <published>2019-06-20T18:43:39Z</published>
    <category term="Machine learning"/>
    <category term="Optimization"/>
    <category term="Theoretical Computer Science"/>
    <author>
      <name>Sebastien Bubeck</name>
    </author>
    <source>
      <id>https://blogs.princeton.edu/imabandit</id>
      <link href="https://blogs.princeton.edu/imabandit/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://blogs.princeton.edu/imabandit" rel="alternate" type="text/html"/>
      <subtitle>Random topics in optimization, probability, and statistics. By Sébastien Bubeck</subtitle>
      <title>I’m a bandit</title>
      <updated>2019-06-30T23:32:22Z</updated>
    </source>
  </entry>
</feed>
