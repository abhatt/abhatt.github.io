<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2020-08-26T22:24:39Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2020/08/24/ideal-special-quarter-theory-of-deep-learning/</id>
    <link href="https://cstheory-events.org/2020/08/24/ideal-special-quarter-theory-of-deep-learning/" rel="alternate" type="text/html"/>
    <title>IDEAL Special Quarter (Theory of Deep Learning)</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">September 21 – December 12, 2020 Online (https://www.ideal.northwestern.edu/special-quarters/fall-2020/) https://www.ideal.northwestern.edu/special-quarters/fall-2020/registration There will be a Special Quarter on Theory of Deep Learning this Fall as a part of IDEAL – The Institute for Data, Econometrics, Algorithms, and Learning, runs jointly with TTIC and the University of Chicago. The Special Quarter will be entirely online, and take place … <a class="more-link" href="https://cstheory-events.org/2020/08/24/ideal-special-quarter-theory-of-deep-learning/">Continue reading <span class="screen-reader-text">IDEAL Special Quarter (Theory of Deep Learning)</span></a></div>
    </summary>
    <updated>2020-08-24T16:02:27Z</updated>
    <published>2020-08-24T16:02:27Z</published>
    <category term="other"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2020-08-26T22:24:08Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://francisbach.com/?p=2561</id>
    <link href="https://francisbach.com/integration-by-parts-abel-transformation/" rel="alternate" type="text/html"/>
    <title>The many faces of integration by parts – I : Abel transformation</title>
    <summary>Integration by parts is a highlight of any calculus class. It leads to multiple classical applications for integration of logarithms, exponentials, etc., and it is the source of an infinite number of exercises and applications to special functions. In this post, I will look at a classical discrete extension that is useful in machine learning...</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p class="justify-text">Integration by parts is a highlight of any calculus class. It leads to multiple classical applications for integration of logarithms, exponentials, etc., and it is the source of an infinite number of exercises and applications to <a href="https://en.wikipedia.org/wiki/Special_functions">special functions</a>. In this post, I will look at a classical discrete extension that is useful in machine learning and optimization, namely <a href="https://en.wikipedia.org/wiki/Summation_by_parts">Abel transformation</a>, with applications to convergence proofs for the (stochastic) <a href="https://en.wikipedia.org/wiki/Subgradient_method">subgradient method</a>. Next month, extensions to higher dimensions will be considered, with applications to score functions [<a href="http://www.jmlr.org/papers/volume6/hyvarinen05a/hyvarinen05a.pdf">2</a>, <a href="https://www.jstor.org/stable/1914309">3</a>] and randomized smoothing [4, <a href="https://arxiv.org/pdf/2002.08676">5</a>].</p>



<h2>Abel transformation: from continuous to discrete</h2>



<p class="justify-text">The most classical version of integration by parts goes as follows. Given two continuously differentiable functions from \(\mathbb{R}\) to \(\mathbb{R}\), we have: $$ \int_a^b \!\!\!\!f(x)g'(x) dx = \Big[ f(x) g(x) \Big]_a^b \!-\! \int_a^b\!\!\! \!f'(x) g(x) dx =  f(b) g(b)\, – f(a)g(a)-\! \int_a^b\! \!\!\! f'(x) g(x) dx.$$ This is valid for less regular functions, but this is not the main concern here. The proof follows naturally from the derivative of a product, but there is a nice “proof without words” (see, e.g., [1, p. 42] or <a href="https://en.wikipedia.org/wiki/Integration_by_parts#Visualization">here</a>).</p>



<p class="justify-text">There is a discrete analogue referred to as <a href="https://en.wikipedia.org/wiki/Summation_by_parts">Abel transformation</a> or summation by parts, where derivatives are replaced by increments: given two real-valued sequences \((a_n)_{n \geq 0}\) and \((b_n)_{n \geq 0}\) (the second sequence could also be taken vector-valued), we can expand $$ \sum_{k=1}^n a_k ( b_k\, – b_{k-1}) =\sum_{k=1}^n a_k  b_k \ – \sum_{k=1}^n a_k  b_{k-1} = \sum_{k=1}^n a_k b_k \ – \sum_{k=0}^{n-1} a_{k+1} b_{k},$$ using a simple index increment in the second sum.  Rearranging terms, this leads to $$ \sum_{k=1}^n a_k ( b_k\, – b_{k-1}) = a_n b_n \ – a_0 b_0\  – \sum_{k=0}^{n-1} ( a_{k+1} – a_{k } ) b_k.$$ In other words, we can transfer the first-order difference from the sequence \((b_k)_{k \geq 0}\) to the sequence \((a_k)_{k \geq 0}\).  A few remarks:</p>



<ul class="justify-text"><li><strong>Warning</strong>! It is very easy/common to make mistakes with indices and signs.</li><li>I gave the direct proof but a proof through explicit integration by part is also possible, by introducing the piecewise-constant function \(f\) equal to \(a_k\) on \([k,k+1)\), and \(g\) continuous  piecewise affine equal to \(b_{k} + (t-k) ( b_{k+1}-b_{k})\) for \(t \in [k,k+1]\), and integrating between \(0+\) and \(n+\). </li></ul>



<p class="justify-text">There are classical applications for the convergence of series (see <a href="https://en.wikipedia.org/wiki/Summation_by_parts">here</a>), but in this post, I will show how it can lead to an elegant result for stochastic gradient descent for non-smooth functions and <em>decaying</em> step-sizes.</p>



<h2>Decaying step-sizes in stochastic gradient descent</h2>



<p class="justify-text">The Abel summation formula is quite useful when analyzing optimization algorithms, and we give a simple example below. We consider a sequence of random potentially <em>non-smooth</em> convex functions \((f_k)_{k \geq 0}\) which are independent and identically distributed functions from \(\mathbb{R}^d \) to \(\mathbb{R}\), with expectation \(F\). The goal is to find a minimizer \(x_\ast\) of \(F\) over a some convex bounded set \(\mathcal{C}\), only being given access to some stochastic gradients of \(f_k\) at well-chosen points. The most classical example is supervised machine learning, where \(f_k(\theta)\) is the loss of a random observation for the predictor parameterized by \(\theta\).  The difficulty here is the potential non-smoothness of the function \(f_k\) (e.g., for the <a href="https://en.wikipedia.org/wiki/Hinge_loss">hinge loss</a> and the <a href="https://en.wikipedia.org/wiki/Support_vector_machine">support vector machine</a>).</p>



<p class="justify-text">We consider the projected stochastic subgradient descent method. The deterministic version of this method dates back to Naum Shor [6] in 1962 (see nice history <a href="https://www.math.uni-bielefeld.de/documenta/vol-ismp/43_goffin-jean-louis.pdf">here</a>). The method goes as follows: starting from some \(\theta_0 \in \mathbb{R}^d\), we perform the iteration $$ \theta_{k} = \Pi_{ \mathcal{C} } \big( \theta_{k-1} – \gamma_k  \nabla f_k(\theta_{k-1}) \big),$$ where \(\Pi_{ \mathcal{C}}: \mathbb{R}^d \to \mathbb{R}^d\) is the orthogonal projection onto the set \(\mathcal{C}\), and \(\nabla f_k(\theta_{k-1})\) is any subgradient of \(f_k\) at \(\theta_{k-1}\). </p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-4324" height="211" src="https://francisbach.com/wp-content/uploads/2020/07/gradient_contours_projection-1024x410.png" width="528"/>One step of projected (sub)gradient descent: from a vector \(\theta\), we go down the direction of a negative subgradient \(\nabla f(\theta)\) of the function \(f\) (here typically a random function) and an orthogonal projection is performed to obtain the new vector \(\theta_+\).</figure></div>



<p class="justify-text">We make the following standard assumptions: (a) the set \(\mathcal{C}\) is convex and compact with diameter \(\Delta\) (with respect to the \(\ell_2\)-norm), (b) the functions \(f_k\) are almost surely convex and \(B\)-Lipschitz-continuous (or equivalently with gradients bounded in \(\ell_2\)-norm by \(B\)). We denote by \(\theta_\ast\) a minimizer of \(f\) on \(\mathcal{C}\) (there can be multiple ones). </p>



<p class="justify-text">For non-smooth problems, choosing a constant step-size does not lead to an algorithm converging to a global minimizer: decaying step-sizes are then needed.</p>



<h2>Convergence proof through Lyapunov functions</h2>



<p class="justify-text">Since the functions \(f_k\) are non-smooth, we cannot use Taylor expansions, and we rely on a now classical proof technique dating back from the 1960’s (see, e.g., a <a href="http://www.mathnet.ru/links/5d71a255cae8f1a313ac599b8f20a123/dan33049.pdf">paper</a> by Boris Polyak [7] in Russian), that has led to several extensions in particular for online learning [<a href="http://www.cs.cmu.edu/~maz/publications/techconvex.pdf">8</a>]. The proof relies on the concept of “<a href="https://en.wikipedia.org/wiki/Lyapunov_function">Lyapunov functions</a>“, often also referred to as “potential functions”. This is a non-negative function \(V(\theta_k)\) of the iterates \(\theta_k\), that is supposed to go down along iterations (at least in expectation). In optimization, standard Lyapunov functions are \(V(\theta)  = F(\theta)\, – F(\theta_\ast)\) or \(V(\theta) = \| \theta \ – \theta_\ast\|_2^2\). </p>



<p class="justify-text">For the subgradient method, we will not be able to show that the Lyapunov function is decreasing, but this will lead through a manipulation which is standard in linear dynamical system analysis to a convergence proof for the averaged iterate: that is, if \(V(\theta_k) \leqslant V(\theta_{k-1})\ – W(\theta_{k-1}) + \varepsilon_k\),  for a certain function \(W\) and extra positive terms \(\varepsilon_k\), then, using telescoping sums, $$ \frac{1}{n} \sum_{k=1}^n W(\theta_{k-1}) \leqslant \frac{1}{n} \big( V(\theta_0)\ – V(\theta_n) \big) + \frac{1}{n} \sum_{k=1}^n \varepsilon_k.$$ We can then either use <a href="https://en.wikipedia.org/wiki/Jensen%27s_inequality">Jensen’s inequality</a> to get a bound on \(W \big( \frac{1}{n} \sum_{k=1}^n \theta_{k-1} \big)\), or directly get a bound on \(\min_{k \in \{1,\dots,n\}} W(\theta_{k-1})\). The first solution gives a performance guarantee for a well-defined iterate, while the second solution only shows that among the first \(n-1\) iterates, one of them has a performance guarantee; in the stochastic set-up where latex \(W\) is an expectation, it is not easily possible to know which one, so we will consider only averaging below.</p>



<p class="justify-text"><strong>Standard inequality. </strong>We have, by contractivity of orthogonal projections: $$ \|\theta_k \ – \theta_\ast\|_2^2 =  \big\|  \Pi_{ \mathcal{C} } \big( \theta_{k-1} – \gamma_k   \nabla f_k(\theta_{k-1}) \big) – \Pi_{ \mathcal{C} } (\theta_\ast)  \big\|_2^2 \leqslant  \big\|   \theta_{k-1} – \gamma_k  \nabla f_k(\theta_{k-1}) -\   \theta_\ast  \big\|_2^2.$$ We can then expand the squared Euclidean norm to get: $$ \|\theta_k – \theta_\ast\|_2^2 \leqslant  \|\theta_{k-1} – \theta_\ast\|_2^2 \ – 2\gamma_k (\theta_{k-1} – \theta_\ast)^\top \nabla f_k (\theta_{k-1}) + \gamma_k^2 \|  \nabla f_k(\theta_{k-1})\|_2^2.$$ The last term is upper-bounded by \(\gamma_k^2 B^2\) because of the regularity assumption on \(f_k\). For the middle term, we use the convexity of \(f_k\), that is,  the function \(f_k\) is greater than its tangent at \(\theta_{k-1}\). See figure below.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-4331" height="220" src="https://francisbach.com/wp-content/uploads/2020/07/tangent_convex-1-1024x440.png" width="513"/>Convex function above its tangent at \(\theta_{k-1}\), leading to the desired inequality.</figure></div>



<p class="justify-text">We then obtain $$ f_k(\theta_\ast) \geqslant f_k(\theta_{k-1}) + \nabla f_k(\theta_{k-1})^\top ( \theta_{\ast} – \theta_{k-1}).$$</p>



<p class="justify-text">Putting everything together, this leads to $$ \|\theta_k \ – \theta_\ast\|_2^2 \leqslant  \|\theta_{k-1}\  – \theta_\ast\|_2^2 \ – 2\gamma_k  \big[ f_k(\theta_{k-1}) \ – f_k(\theta_\ast) \big] + \gamma_k^2 B^2.$$ At this point, except the last term, all terms are random. We can now take expectations, with a particular focus on the term \(\mathbb{E} \big[ f_k(\theta_{k-1}) \big]\), for which we can use the fact that the random function \(f_k\) is independent from the past, so that $$ \mathbb{E} \big[ f_k(\theta_{k-1}) \big] =  \mathbb{E} \Big[  \mathbb{E} \big[ f_k(\theta_{k-1}) \big| f_{1},\dots,f_{k-1}  \big] \Big] =\mathbb{E} \big[   F(\theta_{k-1})   \big] . $$ We thus get $$ \mathbb{E} \big[ \|\theta_k – \theta_\ast\|_2^2\big] \leqslant  \mathbb{E} \big[ \|\theta_{k-1} – \theta_\ast\|_2^2\big]  – 2\gamma_k \big( \mathbb{E} \big[ F(\theta_{k-1}) \big] – F(\theta_\ast) \big) + \gamma_k^2 B^2.$$ As above, we can now isolate the excess in function values as: $$ \mathbb{E} \big[ F(\theta_{k-1}) \big] – F(\theta_\ast)  \leqslant \frac{1}{2 \gamma_k} \Big( \mathbb{E} \big[ \|\theta_{k-1} – \theta_\ast\|_2^2\big] – \mathbb{E} \big[ \|\theta_{k} – \theta_\ast\|_2^2\big] \Big) + \frac{\gamma_k}{2} B^2.$$ At this point, the “optimization part” of the proof is done. Only algebraic manipulations are needed to obtain a convergence rate. This is where Abel transformation will come in.</p>



<h2>From fixed horizon to anytime algorithms</h2>



<p class="justify-text"><strong>The lazy way.</strong> At this point, many authors (including me sometimes) will take a constant step-size \(\gamma_k = \gamma\) so as to obtain a telescopic sum, leading to $$ \frac{1}{n} \sum_{k=1}^n \mathbb{E} \big[ F(\theta_{k-1}) \big] – F(\theta_\ast) \leqslant \frac{1}{2n\gamma}     \Big( \mathbb{E} \big[ \|\theta_{0} \ – \theta_\ast\|_2^2\big] – \mathbb{E} \big[ \|\theta_{n}\  – \theta_\ast\|_2^2\big] \Big) + \frac{\gamma}{2} B^2,$$ which is less than \(\displaystyle \frac{\Delta^2}{2n \gamma} + \frac{\gamma}{2} B^2\), and minimized for \(\displaystyle \gamma = \frac{ \Delta}{B \sqrt{n}}\), leading to a convergence rate less than \(\displaystyle \frac{ B \Delta}{\sqrt{n}}\). Using Jensen’s inequality, we then get for \(\bar{\theta}_n = \frac{1}{n} \sum_{k=1}^n \theta_{k-1}\): $$\mathbb{E} \big[ F(\bar{\theta}_{n}) \big] – F(\theta_\ast) \leqslant \frac{ B \Delta}{\sqrt{n}} .$$ This result leads to the desired rate but can be improved in at least one way: the step-size currently has to depend on the “horizon” \(n\) (which has to be known in advance), and the algorithm is not “anytime”, which is not desirable in practice (where one often launches an algorithm and stops it when it the performance gains have plateaued or when the user gets bored waiting).</p>



<p class="justify-text"><strong>Non-uniform averaging.</strong> Another way [<a href="https://www2.isye.gatech.edu/~nemirovs/SIOPT_RSA_2009.pdf">9</a>] is to consider the non-uniform average $$ \eta_{k} =   \frac{\sum_{k=1}^n \gamma_{k} \theta_{k-1}}{\sum_{k=1}^n \gamma_{k}}, $$ for which telescoping sums apply as before, to get $$ \mathbb{E} \big[ F(\eta_k) \big] – F(\theta_\ast) \leqslant \frac{1}{2} \frac{\Delta^2 + B^2 \sum_{k=1}^n \gamma_k^2}{\sum_{k=1}^n \gamma_{k}}.$$  Then, by selecting a decaying step-size \(\displaystyle \gamma_k = \frac{ \Delta}{B \sqrt{k}}\), that depends on the iteration number, we get a rate proportional to \(\displaystyle \frac{ B \Delta}{\sqrt{n}} ( 1 + \log n)\). We now have an anytime algorithm, but we have lost a logarithmic term, which is not the end of the world, but still disappointing. In [<a href="https://www2.isye.gatech.edu/~nemirovs/SIOPT_RSA_2009.pdf">9</a>], “tail-averaging” (only averaging iterates between a constant times \(n\) and \(n\)) is proposed, that removes the logarithmic term but requires to store iterates (moreover, the non-uniform averaging puts too much weight on the first iterates, slowing down convergence).</p>



<p class="justify-text"><strong>Using Abel transformation.</strong> If we start to sum inequalities from \(k=1\) to \(k=n\), we get, with \(\delta_k = \mathbb{E} \big[ \|\theta_{k} – \theta_\ast\|_2^2\big]\) (which is always between \(0\) and \(\Delta^2\)): $$ \frac{1}{n} \sum_{k=1}^n \mathbb{E} \big[ F(\theta_{k-1}) \big] – F(\theta_\ast)  \leqslant  \frac{1}{n} \sum_{k=1}^n \bigg( \frac{1}{2 \gamma_k} \Big( \delta_{k-1} –  \delta_k \Big)\bigg) +  \frac{1}{n} \sum_{k=1}^n \frac{\gamma_k}{2} B^2,$$ which can be transformed through Abel transformation into $$ \frac{1}{n} \sum_{k=1}^n \mathbb{E} \big[ F(\theta_{k-1}) \big] – F(\theta_\ast) \leqslant \frac{1}{n} \sum_{k=1}^{n-1}  {\delta_k} \bigg(\frac{1}{ 2 \gamma_{k+1}}- \frac{1}{ 2 \gamma_{k}} \bigg) + \frac{\delta_0}{2 n \gamma_1}- \frac{\delta_t}{2 n \gamma_t}+ \frac{1}{n} \sum_{k=1}^n \frac{\gamma_k}{2} B^2.$$ For decreasing step-size sequences, this leads to $$ \frac{1}{n} \sum_{k=1}^n \mathbb{E} \big[ F(\theta_{k-1}) \big] – F(\theta_\ast) \leqslant \frac{1}{n} \sum_{k=1}^{n-1} {\Delta^2} \bigg(\frac{1}{ 2\gamma_{k+1}}- \frac{1}{ 2\gamma_{k}} \bigg) + \frac{\Delta^2}{2n \gamma_1}+ \frac{1}{n} \sum_{k=1}^n \frac{\gamma_k}{2} B^2,$$ and thus $$ \frac{1}{n} \sum_{k=1}^n \mathbb{E} \big[ F(\theta_{k-1}) \big] – F(\theta_\ast) \leqslant \frac{\Delta^2 }{2 n \gamma_n} + \frac{1}{n} \sum_{k=1}^n \frac{\gamma_k}{2} B^2.$$ For \(\gamma_k = \frac{  \Delta}{B \sqrt{k}}\), this leads to an upper bound $$\frac{\Delta B }{2 \sqrt{n}} \big( 1+ \frac{1}{\sqrt{n}} \sum_{k=1}^n \frac{1}{\sqrt{k}}\big) \leqslant \frac{3 \Delta B }{2 \sqrt{n}},$$ which is up to a factor \(\frac{3}{2}\) exactly the same bound as with a constant step-size, but now with an anytime algorithm.</p>



<h2>Experiments</h2>



<p class="justify-text">To illustrate the behaviors above, let’s consider minimizing \(\mathbb{E}_x \| x – \theta \|_1\), with respect to \(\theta\), with \(f_k(\theta) = \| x_k- \theta\|_1\), where \(x_k\) is sampled independently from a given distribution (here independent log-normal distributions for each coordinate). The global optimum \(\theta_\ast\) is the per-coordinate median of the distribution of \(x\)’s.</p>



<p class="justify-text">When applying SGD, the chosen subgradient of \(f_k\) has components in \(\{-1,1\}\). Hence in the plots below in two dimensions, the iterates are always on a grid. With a constant step-size: if the \(\gamma\) is too large (right), there are large oscillations, while if \(\gamma\) is too small (left), optimization is too slow. Note that while the SGD iterate with a constant step-size is always oscillating, the averaged iterate converges to some point (which is not the global optimum, and is typically at distance \(O(\gamma)\) away from it [<a href="https://arxiv.org/pdf/1707.06386">11</a>]).</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-full is-resized"><img alt="" class="wp-image-4339" height="230" src="https://francisbach.com/wp-content/uploads/2020/07/sgd-1.gif" width="545"/>Stochastic gradient descent (averaged or not), with constant step-size. Left: small step-size. Right: large step-size (8 times larger).</figure></div>



<p class="justify-text">With a decaying step-size (figure below), the initial conditions are forgotten reasonably fast and the iterates converge to the global optimum (and of course, we get an anytime algorithm!).</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-full is-resized"><img alt="" class="wp-image-4340" height="295" src="https://francisbach.com/wp-content/uploads/2020/07/sgd_decaying.gif" width="310"/>Stochastic gradient descent (averaged or not), with decreasing step-size.</figure></div>



<p>We can now compare in terms of function values, showing that a constant step-size only works well for a specific range of iteration numbers.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-4335" height="276" src="https://francisbach.com/wp-content/uploads/2020/07/convergence_proofs.png" width="371"/>Comparison of expected performance for decaying and constant-step sizes. Several constant step-sizes are tested, with uniform spacings in log-scale (hence the the uniform spacings in performance for large \(n\)).</figure></div>



<h2>Conclusion</h2>



<p class="justify-text">Being able to deal with decaying step-sizes and anytime algorithms is arguably not a major improvement, but quite a satisfactory one, at least to me! Discrete integration by parts is the key enabler here.</p>



<p class="justify-text">There is another rewarding aspect which is totally unrelated to integration by parts: when applied to supervised machine learning, we just obtained from elementary principles (convexity) and few calculations a generalization bound <em>on unseen data</em>, which is as good as regular bounds from statistics [<a href="https://www.esaim-ps.org/articles/ps/pdf/2005/01/ps0420.pdf">10</a>] that use much more complex tools such as <a href="https://en.wikipedia.org/wiki/Rademacher_complexity">Rademacher complexities</a> (but typically no convexity assumptions): here, statistics considered independently from optimization is not only slower (considering the empirical risk and minimizing it using the plain non-stochastic subgradient method would lead to an \(n\) times slower algorithm) but also more difficult to analyze! </p>



<h2>References</h2>



<p class="justify-text">[1] Roger B. Nelsen, <em>Proofs without Words: Exercises in Visual Thinking</em>, Mathematical Association of America, 1997.<br/>[2] Aapo Hyvärinen, <a href="http://www.jmlr.org/papers/volume6/hyvarinen05a/hyvarinen05a.pdf">Estimation of non-normalized statistical models by score matching</a>. <em>Journal of Machine Learning Research</em>, <em>6</em>(Apr), 695-709, 2005.<br/>[3] Thomas M. Stoker, <a href="https://www.jstor.org/stable/1914309">Consistent estimation of scaled coefficients</a>.  <em>Econometrica: Journal of the Econometric Society</em>, 54(6):1461-1481, 1986.<br/>[4] Tamir Hazan, George Papandreou, and Daniel Tarlow. <a href="https://mitpress.mit.edu/books/perturbations-optimization-and-statistics">Perturbation, Optimization, and Statistics</a>. MIT Press, 2016.<br/>[5] Quentin Berthet, Matthieu Blondel, Olivier Teboul, Marco Cuturi, Jean-Philippe Vert, Francis Bach, <a href="https://arxiv.org/pdf/2002.08676">Learning with differentiable perturbed optimizers</a>. Technical report arXiv 2002.08676, 2020.<br/>[6] Naum Z. Shor. An application of the method of gradient descent to the solution of the network transportation problem. <em>Notes of Scientific Seminar on Theory and Applications of Cybernetics and Operations Research</em>, <em>Ukrainian Academy of Sciences</em>, Kiev, 9–17, 1962.<br/>[7] Boris T. Polyak, <a href="http://www.mathnet.ru/links/5d71a255cae8f1a313ac599b8f20a123/dan33049.pdf">A general method for solving extremal problems</a>. <em>Doklady Akademii Nauk SSSR</em>, 174(1):33–36, 1967.<br/>[8] Martin Zinkevich. <a href="http://www.cs.cmu.edu/~maz/publications/techconvex.pdf">Online convex programming and generalized infinitesimal gradient ascent</a>. <em>Proceedings of the international conference on machine learning )(ICML)</em>, 2003.<br/>[9] Arkadi Nemirovski, Anatoli Juditsky, Guanghui Lan, Alexander Shapiro<em>.</em> <a href="https://www2.isye.gatech.edu/~nemirovs/SIOPT_RSA_2009.pdf">Robust stochastic approximation approach to stochastic programming</a>. <em>SIAM Journal on optimization</em>, 19(4):1574-1609, 2009.<br/>[10] Stéphane Boucheron, Olivier Bousquet, Gabor Lugosi. <a href="https://www.esaim-ps.org/articles/ps/pdf/2005/01/ps0420.pdf">Theory of classification: A survey of some recent advances</a>. <em>ESAIM: probability and statistics</em>, <em>9</em>, 323-375, 2005.<br/>[11] Aymeric Dieuleveut, Alain Durmus, and Francis Bach. <a href="https://arxiv.org/pdf/1707.06386">Bridging the gap between constant step size stochastic gradient descent and Markov chains</a>. Annals of Statistics, 48(3):1348-1382, 2020.</p></div>
    </content>
    <updated>2020-08-04T15:55:26Z</updated>
    <published>2020-08-04T15:55:26Z</published>
    <category term="Tools"/>
    <author>
      <name>Francis Bach</name>
    </author>
    <source>
      <id>https://francisbach.com</id>
      <link href="https://francisbach.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://francisbach.com" rel="alternate" type="text/html"/>
      <subtitle>Francis Bach</subtitle>
      <title>Machine Learning Research Blog</title>
      <updated>2020-08-26T22:24:38Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://francisbach.com/?p=3843</id>
    <link href="https://francisbach.com/gradient-descent-for-wide-two-layer-neural-networks-implicit-bias/" rel="alternate" type="text/html"/>
    <title>Gradient descent for wide two-layer neural networks – II: Generalization and implicit bias</title>
    <summary>In this blog post, we continue our investigation of gradient flows for wide two-layer “relu” neural networks. In the previous post, Francis explained that under suitable assumptions these dynamics converge to global minimizers of the training objective. Today, we build on this to understand qualitative aspects of the predictor learnt by such neural networks. The...</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p class="justify-text">In this blog post, we continue our investigation of gradient flows for wide two-layer “relu” neural networks. In the <a href="https://francisbach.com/gradient-descent-neural-networks-global-convergence/">previous post</a>, Francis explained that under suitable assumptions these dynamics converge to global minimizers of the training objective. Today, we build on this to understand qualitative aspects of the predictor learnt by such neural networks. The content is mostly based on our recent joint work [<a href="https://arxiv.org/pdf/2002.04486.pdf">1</a>].</p>



<h2>1. Generalization with weight decay regularization</h2>



<p class="justify-text">Let us start our journey with the comfortable case where the training objective includes an explicit <em>weight decay</em> regularization (i.e. \(\ell_2\)-regularization on the parameters). Using the notations of the previous post, this consists in the following objective function on the space of probability measures on \(\mathbb{R}^{d+1}\):  $$ \underbrace{R\Big(\int_{\mathbb{R}^{d+1}} \Phi(w)d\mu(w)\Big)}_{\text{Data fitting term}} + \underbrace{\frac{\lambda}{2} \int_{\mathbb{R}^{d+1}} \Vert w \Vert^2_2d\mu(w)}_{\text{Regularization}} \tag{1}$$ where \(R\) is the loss and \(\lambda&gt;0\) is the regularization strength. Remember that a  neural network of finite width with \(m\) neurons is recovered with an empirical measure \(\mu = \frac1m \sum_{j=1}^m\delta_{w_j}\), in which case this regularization is proportional to the sum of the squares of all the parameters \(\frac{\lambda}{2m}\sum_{j=1}^m \Vert w_j\Vert^2_2\).</p>



<p class="justify-text"><strong>Variation norm.</strong> In the previous post, we have seen that the Wasserstein gradient flow of this objective function — an idealization of the gradient descent training dynamics in the large width limit — converges to a global minimizer \(\mu^*\) when initialized properly. An example of an admissible initialization is the hidden weights \(b_j\) distributed according to the uniform distribution \(\tau\) on the unit sphere \(\mathbb{S}^{d-1}\subset \mathbb{R}^d\) and the output weights \(a_j\) uniform in \(\{-1,1\}\). What does this minimizer look like in predictor space when the objective function is as in Eq. (1) ? </p>



<p class="justify-text">To answer this question, we define for a predictor \(h:\mathbb{R}^d\to \mathbb{R}\), the quantity $$ \Vert h \Vert_{\mathcal{F}_1} := \min_{\mu \in \mathcal{P}(\mathbb{R}^{d+1})} \frac{1}{2} \int_{\mathbb{R}^{d+1}} \Vert w\Vert^2_2 d\mu(w) \quad \text{s.t.}\quad h = \int_{\mathbb{R}^{d+1}} \Phi(w)d\mu(w).\tag{2} $$ As the notation suggests, \(\Vert \cdot \Vert_{\mathcal{F}_1}\) is a norm in the space of predictors. It is known as the <em>variation norm</em> [<a href="http://jmlr.org/papers/volume18/14-546/14-546.pdf">2</a>, <a href="https://www.cs.cas.cz/~vera/publications/journals/I3Edin.pdf">3</a>]. We call \(\mathcal{F}_1\) the space of functions with finite norm, which is a Banach space. By construction, the learnt predictor \(h^* = \int \Phi(w)d\mu^*(w)\) is a minimizer of the \(\mathcal{F}_1\)-regularized regression: $$ \min_{h:\mathbb{R}^d\to \mathbb{R}} R(h) + \lambda \Vert h \Vert_{\mathcal{F}_1} \tag{3}.$$ This \(\mathcal{F}_1\)-norm regularization shares similarity with \(\ell_1\) regularization [<a href="https://arxiv.org/pdf/1412.6614.pdf">4</a>]. To see this, observe that the “magnitude” \(\vert a\vert \Vert b\Vert_2\) of a relu function \(x\mapsto a(b^\top x)_+\) with parameter \(w=(a,b)\) equals \(\Vert w\Vert^2_2/2\) if \(\vert a\vert = \Vert b\Vert_2\) and is smaller otherwise. Thus parameterizing the relus by their direction \(\theta = b/\Vert b\Vert_2\) and optimizing over their signed magnitude \(r(\theta) = a\Vert b\Vert_2\)  we have $$ \Vert h \Vert_{\mathcal{F}_1} = \inf_{r:\mathbb{S}^{d-1}\to \mathbb{R}} \int_{\mathbb{S}^{d-1}} \vert r(\theta)\vert d\tau(\theta) \quad \text{s.t.}\quad h(x) = \int _{\mathbb{S}^{d-1}} r(\theta) (\theta^\top x)_+ d\tau(\theta).\tag{4}$$</p>



<p class="justify-text"><strong>Conjugate RKHS norm.</strong> The regression in the space \(\mathcal{F}_1\) is best understood when compared with the regression obtained by only training the output weights. We consider the same training dynamics with weight decay except that we fix the hidden weights to their initial value, where they are distributed according to the uniform distribution \(\tau\) on the sphere. In that case, the Wasserstein gradient flow also converges to the solution of a regularized regression as in Eq. (3) — this is in fact a convex problem —  but the regularizing norm is different and now defined as $$ \Vert h \Vert_{\mathcal{F}_2}^2 := \min_{r:\mathbb{S}^{d-1}\to \mathbb{R}} \int_{\mathbb{S}^{d-1}} \vert r(\theta)\vert^2 d\tau(\theta) \quad \text{s.t.}\quad h(x) = \int _{\mathbb{S}^{d-1}} r(\theta) (\theta^\top x)_+ d\tau(\theta).$$ We call \(\mathcal{F}_2\) the set of functions with finite norm. It can be shown to be a <a href="https://en.wikipedia.org/wiki/Reproducing_kernel_Hilbert_space">Reproducing Kernel Hilbert Space</a> (RKHS), with kernel  $$ K(x,x’) = \int_{\mathbb{S}^{d-1}} (\theta^\top x)_+ (\theta^\top x’)_+ d\tau(\theta),$$ which has a closed form expression [<a href="https://papers.nips.cc/paper/3628-kernel-methods-for-deep-learning.pdf">5</a>]. In this context, taking a finite width neural network corresponds to a random feature approximation of the kernel [<a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.446.9306&amp;rep=rep1&amp;type=pdf">6</a>, <a href="https://papers.nips.cc/paper/3182-random-features-for-large-scale-kernel-machines">7</a>].</p>



<p class="justify-text">Let us informally compare the properties of these spaces \(\mathcal{F}_1\) and \(\mathcal{F}_2\) (see [<a href="https://arxiv.org/abs/1412.8690">2</a>] for details):</p>



<ul class="justify-text"><li><strong>Approximation power.</strong> In high dimension, only very smooth functions have small \(\mathcal{F}_2\)-norm (in rough terms, the \(\lceil (d+3)/2\rceil\) first derivatives should be small). In contrast, there exists non-smooth functions with small \(\mathcal{F}_1\)-norm, an example being the relu function \(x\mapsto (\theta^\top x)_+\). Remarkably, if we define \(f(x)=g(Ux)\) where \(U\) is an orthogonal projection then \(\Vert f\Vert_{\mathcal{F}_1} \leq  \Vert g\Vert_{\mathcal{F}_2}\). This shows in particular that \(\mathcal{F}_1\) contains \(\mathcal{F}_2\) and that \(\mathcal{F}_1\) is <em>adaptive</em> to lower dimensional structures.</li><li><strong>Statistical complexity.</strong> It could be feared that the good approximation properties of \(\mathcal{F}_1\) come at the price of being “too large” as a hypothesis space, making it difficult to estimate a predictor in \(\mathcal{F}_1\) from few samples. But, as measured by their Rademacher complexities, the unit ball of \(\mathcal{F}_1\) is only \(O(\sqrt{d})\) larger than that of \(\mathcal{F}_2\). By going from \(\mathcal{F}_2\) to \(\mathcal{F}_1\), we thus add some nicely structured predictors to our hypothesis space, but not too much garbage that could fit unstructured noise.</li><li><strong>Generalization guarantees.</strong> By combining the two previous points, it is possible to prove that supervised learning in \(\mathcal{F}_1\) breaks the curse of dimensionality when the output depends on a lower dimensional projection of the input: the required number of training samples only depends mildly on the dimension \(d\).</li><li><strong>Optimization guarantees.</strong> However \(\mathcal{F}_1\) has a strong drawback : there is no known algorithm that solves the problem of Eq. (3) in polynomial time. On practical problems, gradient descent seems to behave well, but in general only qualitative results such as presented in the previous post are known. In contrast, various provably efficient algorithms can solve regression in \(\mathcal{F}_2\), which is a classical kernel ridge regression problem [Chap. 14.4.3, <a href="https://doc.lagout.org/science/Artificial%20Intelligence/Machine%20learning/Machine%20Learning_%20A%20Probabilistic%20Perspective%20%5BMurphy%202012-08-24%5D.pdf">8</a>].</li></ul>



<p class="justify-text">In the plot below, we compare the predictor learnt by gradient descent for a 2-D regression with the square loss and weight decay, after training (a) both layers — which is regression in \(\mathcal{F}_1\) — or (b) just the output layer — which is regression in \(\mathcal{F}_2\). This already illustrates some distinctive features of both spaces, although the differences become more stringent in higher dimensions. In particular, observe that in (a) the predictor is the combination of few relu functions, which illustrates  the sparsifying effect of the \(L^1\)-norm in Eq. (4). To simplify notations, we do not include a bias/intercept in the formulas but our numerical experiments include it, so in this plot the input is of the form \(x=(x_1,x_2,1)\) and \(d=3\).</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-4231" height="293" src="https://francisbach.com/wp-content/uploads/2020/07/regularized-2.png" width="564"/>Predictor learnt by the gradient flow on the square loss with weight decay, when training (a) both layers (b) only the output layer. The markers indicate the location of the training samples  \((x_i)_{i=1}^n\). <a href="https://github.com/lchizat/2020_implicitbias_blog/blob/master/exp_weightdecay.jl">[code]</a></figure></div>



<p class="justify-text">The qualitative picture is quite clear so far, but something is a bit unsettling: weight decay is often not needed to obtain a good performance in practice. Our line of reasoning however completely falls apart without such a regularization: if the objective function depends on the predictor only via its values on the training set, being a minimizer does not guarantee anything about generalization outside of the training set (remember that wide relu neural networks are <a href="https://en.wikipedia.org/wiki/Universal_approximation_theorem">universal approximators</a>). Why does it still work in the unregularized case? There must be something in the algorithm…</p>



<h2>2. Implicit bias: linear classification</h2>



<p class="justify-text">This something is called the <em>implicit bias</em> : when there are several minimizers, the optimization algorithm makes a specific choice. In the unregularized case, the “quality” of this choice is a crucial property of an algorithm; much more crucial than, say, its convergence speed on the training objective. To gradually build our intuition of the implicit bias of gradient flows, let us put neural networks aside for a moment and consider, following Soudry, Hoffer, Nacson, Gunasekar and Srebro [<a href="http://www.jmlr.org/papers/volume19/18-188/18-188.pdf">9</a>], a linear classification task.</p>



<p class="justify-text"><strong>Gradient flow of the smooth-margin.</strong> Let \((x_i,y_i)_{i=1}^n\) be a training set of \(n\) pairs of inputs \(x_i\in \mathbb{R}^d\) and outputs \(y_i\in \{-1,1\}\) and let us choose the exponential loss. The analysis that follows also apply to the logistic loss (which is the same as the cross-entropy loss after a sigmoid non-linearity) because only the “tail” of the loss matters, but it is more straightforward with the exponential loss. In order to give a natural “scale” to the problem, we  renormalize the empirical risk by taking minus its logarithm and consider the concave objective $$ F_\beta(a) = -\frac{1}{\beta}\log\Big( \frac1n \sum_{i=1}^n \exp(-\beta y_i \ x_i^\top a) \Big).\tag{5}$$ </p>



<p class="justify-text">Here \(\beta&gt;0\) is a parameter that will be useful in a moment. For now, we take \(\beta=1\) and we note \(F(a)=F_1(a)\).  In this context, the <em>margin</em> of a vector \(a\in \mathbb{R}^d\) is the quantity \(\min_{i} y_i\ x_i^\top a\) which quantifies how far this linear predictor is from making a wrong prediction on the training set.  </p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-4274" height="386" src="https://francisbach.com/wp-content/uploads/2020/07/max_margin-4.png" width="453"/>The margin of the linear predictor \(x \mapsto a^\top x\) with parameters \(a \in \mathbb{S}^{d-1}\) is the smallest distance of a training point to the decision boundary. We show here the max-margin predictor.</figure></div>



<p class="justify-text">Obtained via simple manipulations, the inequalities  $$ \min_i y_i\ x_i^\top a \leq F_\beta(a) \leq \min_i y_i\ x_i^\top a +\frac{\log(n)}{\beta}, \tag{6}$$ suggest to call \(F_\beta\) the <em>smooth-margin</em> because, well, it is smooth and converges to the margin \(F_\infty(a) := \min_i y_i x_i^\top a\) as \(\beta\to \infty\). Let us look at the gradient flow in the ascent direction that maximizes the smooth-margin: $$ a'(t) = \nabla F(a(t))$$ initialized with \(a(0)=0\) (here the initialization does not matter so much). The path followed by this gradient flow is exactly the same as the gradient flow on the empirical risk: taking the logarithm only changes the time parameterization or, in practice, the step-size.</p>



<p class="justify-text"><strong>Convergence to the max-margin.</strong> Assume that the data set is linearly separable, which means that the \(\ell_2\)-max-margin $$ \gamma := \max_{\Vert a\Vert_2 \leq 1} \min_i y_i x_i^\top a$$ is positive. In this case \(F\) is unbounded (indeed \(\lim_{\alpha \to \infty} F(\alpha a) =\infty\) whenever \(a\)  has a positive margin) and thus \(a(t)\) diverges. This is not an issue as such, since for classification, only the sign of the prediction matters.  This just means that the relevant question is not “where does \(a(t)\) converge?” but rather “towards which direction does it diverge?”. In other words, we are interested in the limit of \(\bar a(t):= a(t)/\Vert a(t)\Vert_2\) (in convex analysis, this is called the <em>cosmic limit</em> of \(a(t)\) [Chap. 3, <a href="https://www.springer.com/gp/book/9783540627722">10</a>], isn’t it beautiful ?).</p>



<p class="justify-text">The argument that follows is adapted from [<a href="https://arxiv.org/pdf/1802.08246.pdf">11</a>, <a href="https://arxiv.org/pdf/1803.07300.pdf">12</a>] and can be traced back to [<a href="http://proceedings.mlr.press/v28/telgarsky13-supp.pdf">13</a>] for coordinate ascent. It can be shown by looking at the structure of the gradient (see the end of the blog post) that \(\Vert \nabla F(a)\Vert_2\geq \gamma\) for all \(a\in \mathbb{R}^d\). By the inequality of Eq. (6) and the gradient flow property \(\frac{d}{dt}F(a(t))=\Vert \nabla F(a(t))\Vert_2^2\), it follows $$\begin{aligned}\min_i y_i x_i^\top a(t) \geq F(a(t)) \  – \log(n) \geq \gamma \int_0^t \Vert \nabla F(a(s))\Vert_2ds -\log (n).\end{aligned}$$  For \(t&gt; \log(n)/\gamma^2\), this lower bound is positive. We can then divide the left-hand side by \(\Vert a(t)\Vert_2\) and the right-hand side by the larger quantity \(\int_0^t \Vert\nabla F(a(s))\Vert_2ds\), and we get $$\min_i y_i x_i^\top \bar a(t) \geq \gamma -\frac{\log(n)}{\int_0^t \Vert\nabla F(a(s))\Vert_2ds} \geq \gamma -\frac{\log(n)}{\gamma t}.$$ This shows that the margin of \(\bar a(t) := a(t)/\Vert a(t)\Vert_2\) converges to the \(\ell_2\)-max-margin at a rate \(\log(n)/\gamma t\). That’s it, the implicit bias of this gradient flow is exposed!</p>



<p class="justify-text"><strong>Stability to step-size choice.</strong> To translate this argument to discrete time, we need decreasing step-sizes of order \(1/\sqrt{t}\) which deteriorates the convergence rate to \(\tilde O(1/\sqrt{t})\), see [<a href="https://arxiv.org/pdf/1802.08246.pdf">11</a>, <a href="https://arxiv.org/pdf/1803.07300.pdf">12</a>]. In [<a href="https://arxiv.org/pdf/2002.04486.pdf">1</a>], we proposed a different proof strategy (based on an online optimization interpretation of \(\bar a(t)\), as below) which recovers the same convergence rate \(O(1/\sqrt{t})\) with <em>exponentially larger</em> step-sizes. This suggests that these diverging trajectories are extremely robust to the choice of step-size.</p>



<p class="justify-text"><strong>Illustration. </strong>In the figure below, we plot on the left the evolution of the parameter \(a(t)\) and on the right the predictor \(x\mapsto (x,1)^\top a(t)\) with \(x\in \mathbb{R}^2\). In parameter space, we apply the hyperbolic tangent to the radial component which allows to easily visualize diverging trajectories. This way, the unit sphere represents the <em>horizon</em> of \(\mathbb{R}^d\), i.e., the set of directions at infinity [Chap. 3 in <a href="https://www.springer.com/gp/book/9783540627722">9</a>]. We will use the same convention in the other plots below.</p>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-4106" height="288" src="https://francisbach.com/wp-content/uploads/2020/07/linear.gif" width="586"/>Implicit bias of gradient descent for a linear classification task with the exponential loss: (left) parameter space, (right) predictor space.</figure></div>



<h2>3. Implicit bias:  training only the output layer</h2>



<p class="justify-text">Despite its apparently restrictive setting, the previous result already tells us something about wide neural networks. Consider the situation touched upon earlier where we only train the output weights \(a_j\) and the hidden weights \(b_j\) are picked uniformly at random on the sphere. This corresponds to learning a linear classifier on top of the random feature \([(b_j^\top x)_+]_{j=1}^m\). </p>



<p class="justify-text">As we have just shown, if the training set is separable, the normalized gradient flow of the unregularized exponential loss (or logistic loss) converges to a solution to  $$ \max_{\Vert a\Vert_2 \leq 1}\min_i y_i \sum_{j=1}^m  a_j (b_j^\top x_i)_+.$$ </p>



<p class="justify-text">This is a random feature approximation for the unregularized kernel support vector machine problem in the RKHS \(\mathcal{F}_2\), which is recovered in the large width limit \(m\to \infty\):  $$\max_{\Vert h\Vert_{\mathcal{F}_2}\leq 1} \min_i y_i h(x_i).$$ Notice that if \(m\) is large enough, the linear separability assumption is not even needed anymore, because any training set is separable in \(\mathcal{F}_2\) (at least if all \(x_i\)s are distinct and if we do not forget to include the bias/intercept).</p>



<p class="justify-text"><strong>Illustration.</strong> In the animation below, we plot on the left the evolution of the parameters and on the right the predictor for a 2-D classification task. In parameter space, each particle represents a neuron: their direction is fixed, their distance to \(0\) is their absolute weight and the color is red (+) or blue (-) depending on the sign of the weight. As above, the unit sphere is at infinity and the particles diverge. In predictor space, the markers represent the training samples of both classes, the color shows the predictor and the black line is the decision boundary. The fact that the predictor has a smooth decision boundary is in accordance with the properties of \(\mathcal{F}_2\) given above. </p>



<div class="wp-block-image"><figure class="aligncenter size-large"><img alt="" class="wp-image-4275" height="316" src="https://francisbach.com/wp-content/uploads/2020/07/film_output_comp-1.gif" width="640"/>Gradient descent on the output layer of a two-layer relu neural network with the exponential loss: (left) parameter space, (right) predictor space. <a href="https://github.com/lchizat/2020_implicitbias_blog/blob/master/exp_output.jl">[code]</a></figure></div>



<h2>4. Implicit bias: 2-homogeneous linear classifiers</h2>



<p class="justify-text">Although the analyses where neural networks behave like kernel methods are pleasant for us theoreticians because we are in conquered territory, they miss essential aspects of neural networks such as their adaptivity and their ability to learn a representation. Let us see if we can characterize the implicit bias of the gradient flow of the unregularized exponential loss when training <em>both</em> layers of the neural network.</p>



<p class="justify-text"><strong>A 2-homogeneous linear model.</strong> From an optimization point of view, an important property of two layer relu neural networks is that \(\Phi(\alpha w)= \alpha^2 \Phi(w)\) for all \(\alpha&gt;0\), i.e., they are positively 2-homogeneous in the training parameters. In contrast, a linear model is 1-homogeneous in the parameters. This seemingly little difference leads to drastic changes in the gradient flow dynamics. </p>



<p class="justify-text">Let us again build our intuition with a simplified model that captures key aspects of the dynamics, namely the linear classification setting of above. This time, we take any initialization \(r(0)\in \mathbb{R}^d\) with positive entries and the gradient flow in the ascent direction of the function \( F(r\odot r)\) where \(\odot\) is the elementwise product between two vectors and \(F\) is defined in Eq. (5). This is just a trick to obtain a 2-homogeneous parameterization of a linear model. This gradient flow satisfies $$ r'(t) = 2 r(t)\odot \nabla F(r(t)\odot r(t)).$$ </p>



<p class="justify-text"><strong>Normalized dynamics.</strong> Let us define \(\bar a(t):=(r(t)\odot r(t))/\Vert r(t)\Vert_2^2\) the normalized predictor associated to our dynamics which, by definition, belongs to the simplex \(\Delta_d\), i.e., the set of nonnegative vectors in \(\mathbb{R}^d\) that sum to one. Using the fact that \(\nabla F(\beta a) = \nabla F_\beta (a)\) for all \(\beta&gt;0\), we obtain $$\begin{aligned} \bar a'(t) &amp;= 2\frac{r(t)\odot r'(t)}{\Vert r(t)\Vert_2^2} -2 (r(t)^\top r'(t))\frac{r(t)\odot r(t)}{\Vert r(t)\Vert_2^4}\\ &amp;=4\bar a(t) \odot \nabla F_{\Vert r(t)\Vert_2^2}(\bar a(t))\ – \alpha(t) \bar a(t)\end{aligned}$$ where \(\alpha(t)\) is the scalar such that \(\sum_{i=1}^d a’_i(t) =0\). Online optimization experts might have recognized that this is (continuous time) <em>online mirror ascent in the simplex</em> for the sequence of smooth-margin functions \(F_{\Vert r(t)\Vert_2^2}\). Notice in particular the multiplicative updates: they correspond to the entropy mirror function, and they are particularly well suited for optimization in the high dimensional simplex [Chap.4, <a href="https://arxiv.org/pdf/1405.4980.pdf">14</a>].</p>



<p>What do we learn from this reformulation? </p>



<ul class="justify-text"><li>We can prove (by similar means) that if the data set is linearly separable then \(\Vert r(t)\Vert_2^2\) diverges. So the sequence of functions \(F_{\Vert r\Vert_2^2}\) converges to the margin \(F_\infty\) which means that \(\bar a(t)\) just ends up optimizing the function \(F_\infty\). As a consequence, we have $$\lim_{t\to \infty} y_i x_i^\top \bar a(t) = \max_{a\in \Delta_d} \min_{i} y_i x_i^\top a.$$ This exposes another implicit bias of gradient flow. Notice the key difference with the implicit bias obtained with a linear parameterization: we obtain here the \(\ell_1\)-max-margin (over classifiers with non-negative entries) instead of the \(\ell_2\)-max-margin.  </li><li>Beyond exposing the implicit bias, this reformulation shows that \(\bar a(t)\) implicitly optimizes a sequence of smooth objectives which converge to the margin \(F_\infty\). Unknowingly, we have recovered the well-principled optimization method that consists in approximating a non-smooth objective with smooth functions [<a href="https://www.math.ucdavis.edu/~sqma/MAT258A_Files/Nesterov-2005.pdf">15</a>].</li><li>While the conclusion above was only formal, this point of view leads to rigorous proofs of convergence and convergence rates in discrete time in \(\tilde O(1/\sqrt{t})\) with a step-size in \(O(1/\sqrt{t})\), by  exploiting tools from online optimization, see [<a href="https://arxiv.org/pdf/2002.04486.pdf">1</a>].</li></ul>



<h2>5. Implicit bias: fully trained 2-layer neural networks</h2>



<p class="justify-text">Once again this argument about linear predictors applies to neural networks: if we train both layers but only the magnitude of the hidden weights and not their direction, then this is equivalent to learning a 2-homogeneous linear model on top of the random feature \([  a_j(0) (x_i^\top b_j(0))_+]_{j=1}^m\). If each feature appears twice with opposite signs — which is essentially the case in the large width limit — then the simplex constraint can be equivalently replaced by an \(\ell_1\)-norm constraint on the weights. Recalling the definition of the \(\mathcal{F}_1\)-norm from Eq. (4), we thus obtain that, in the infinite-width limit, the normalized predictor converges to a solution to $$ \max_{\Vert h\Vert_{\mathcal{F}_1} \leq 1} \min_i y_i h(x_i).$$</p>



<p class="justify-text">This result is correct, but it is not relevant. In contrast to functions in \(\mathcal{F}_2\), functions in \(\mathcal{F}_1\) <em>can not</em> in general be approximated with few <em>random</em> features in high dimension. In fact, lower bounds that are exponential in the dimension exist in certain settings [Sec. X, <a href="http://www.stat.yale.edu/~arb4/publications_files/UniversalApproximationBoundsForSuperpositionsOfASigmoidalFunction.pdf">16</a>]. They can be approximated with a small number of features but those need to be data-dependent: in that sense, it is necessary to learn a representation – here,  a distribution over the hidden weights — in order to learn in \(\mathcal{F}_1\). </p>



<p class="justify-text">This raises the following question: do we obtain the same implicit bias when training both layers of the neural network, without fixing the direction of the input weights? In the following result, which is the main theorem of our paper [<a href="https://arxiv.org/abs/2002.04486">1</a>], we answer by the affirmative.</p>



<p class="justify-text"><strong>Theorem</strong> (C. and Bach [<a href="https://arxiv.org/abs/2002.04486">1</a>], informal). Assume that for some \(\sigma&gt;0\), the hidden weights \(b_j\) are initialized uniformly on the sphere of radius \(\sigma\) and the output weights \(a_j\) are uniform in \(\{-\sigma,\sigma\}\). Let \(\mu_t\) be the Wasserstein gradient flow for the unregularized exponential loss and \(h_t = \int \Phi(w)d\mu_t(w)\) be the corresponding dynamics in predictor space. Under some technical assumptions, the normalized predictor \(h_t/\Vert h_t\Vert_{\mathcal{F}_1}\) converges to a solution to the \(\mathcal{F}_1\)-max-margin problem: $$\max_{\Vert h\Vert_{\mathcal{F}_1} \leq 1} \min_i y_i h(x_i).$$</p>



<p class="justify-text">Giving an idea of proof would be a bit too technical for this blog post, but let us make some remarks:</p>



<ul class="justify-text"><li>The strength of this result is that although this dynamics could get trapped towards limit directions which are not optimal, this choice of initialization allows to avoid them all and to only converge to <em>global</em> minimizers of this max-margin problem. The principle behind this is similar to the global convergence result in the previous blog post. </li><li>The fact that optimizing on the direction of the hidden weights is compatible with the global optimality conditions of the \(\mathcal{F}_1\)-max-margin problem is very specific to the structure of positively 2-homogeneous problems, and should not be taken for granted for other architectures of neural networks.</li><li>Although at a formal level this result works for any initialization that is diverse enough (such as the standard Gaussian initialization), the initialization proposed here yields dynamics with a better behavior for relu networks: by initializing the hidden and output weights with equal norms – a property preserved by the dynamics – we avoid some instabilities in the gradient. Also notice that this result applies to any scale \(\sigma&gt;0\) of the initialization (we’ll see an intriguing consequence of this in the next section).</li></ul>



<p class="justify-text"><strong>Illustration.</strong> In the figure below, we plot the training dynamics when both layers are trained. In parameter space (left), each particle represents a neuron: its position is \(\vert a_j\vert b_j\) and its color depends on the sign of \(a_j\).  Here again the unit sphere is at infinity. The inactive neurons at the bottom correspond to those with a bias that is “too negative” at initialization. We observe that all the other neurons gather into few clusters: this is the sparsifying effect of the \(L^1\)-norm in Eq. (4). In predictor space, we obtain a polygonal classifier, as expected for a \(\mathcal{F}_1\)-max-margin classifier. See the paper [<a href="https://arxiv.org/pdf/2002.04486.pdf">1</a>] for experiments that illustrate the strengths of this classifier in terms of generalization.</p>



<div class="wp-block-image"><figure class="aligncenter size-large"><img alt="" class="wp-image-4194" height="316" src="https://francisbach.com/wp-content/uploads/2020/07/film_both_comp.gif" width="640"/>Training both layers of a wide relu neural network with the exponential loss: (left) space of parameters, (right) space of predictors. <a href="https://github.com/lchizat/2020_implicitbias_blog/blob/master/exp_bothlayers.jl">[code]</a></figure></div>



<h2>6. Lazy regime and the neural tangent kernel</h2>



<p class="justify-text">This blog post would not be complete without mentioning the <em>lazy regime</em>. This is yet another kind of implicit bias which, in our context, takes place when at initialization the weights have a large magnitude and the step-size is small. It was first exhibited in [<a href="https://papers.nips.cc/paper/8076-neural-tangent-kernel-convergence-and-generalization-in-neural-networks.pdf">17</a>] for deep neural networks (see also [<a href="https://arxiv.org/pdf/1810.02054.pdf">18</a>, <a href="https://arxiv.org/pdf/1811.03962.pdf">19</a>]). Hereafter, we follow the presentation of [<a href="https://arxiv.org/pdf/1812.07956.pdf">20</a>].</p>



<p class="justify-text"><strong>Lazy training via scaling.</strong> This phenomenon is in fact very general so let us present it with a generic parametric predictor \(h(W)\) with differential \(Dh(W)\). We introduce a scaling factor \(\alpha&gt;0\) and look at the gradient flow of \(F(W) := R(\alpha h(W))\) with a step-size \(1/\alpha^2\), that is $$ W'(t) = \ – \frac{1}{\alpha}Dh(W(t))^\top \nabla R(\alpha h(W(t))),$$ with initialization \(W(0)\). In terms of the predictor \(\alpha h(W)\), this yields the dynamics $$\frac{d}{dt} \alpha h(W(t)) = \ – Dh(W(t))Dh(W(t))^\top \nabla R(\alpha h(W(t)).$$ </p>



<p class="justify-text">Lazy training happens when we take \(\alpha\) large while making sure that \(\alpha h(W(0))\) stays bounded. In this case, we see that the parameters change at a rate \(O(1/\alpha)\), while the predictor changes at a rate independent of \(\alpha\). On any bounded time interval, in the limit of  a large \(\alpha\), the parameters only move infinitesimally, while the predictor still makes significant progress, hence the name <em>lazy training</em>.</p>



<p class="justify-text"><strong>Equivalent linear model.</strong> Since the parameters hardly move, if we assume that \(Dh(W(0))\neq 0\) then we can replace the map \(h\) by its linearization \(W \mapsto h(W(0))+Dh(W(0))(W-W(0))\). This means that the training dynamics essentially follows the gradient flow of the  objective $$ R\big ( \alpha h(W(0)) + \alpha Dh(W(0))(W-W(0)) \big)$$ which is a convex function of \(W\) as soon as \(R\) is convex.</p>



<p class="justify-text">If this objective admits a minimizer that is not too far away from \(W(0)\), then \(W(t)\) converges to this minimizer. If in contrast all  the minimizers are too far away (think of the exponential loss where they are at infinity), then the parameters will eventually move significantly and the lazy regime is just a transient regime in the early phase of training.  Of course, all these behaviors can be quantified and made more precise, because this phenomenon brings us back to the realm of linear models. </p>



<p class="justify-text">What all of this has to do with two-layer neural networks? As it happens, this scale factor appears implicit in various situations for these models; let us detail two of them. </p>



<p class="justify-text"><strong>Neural networks with \(1/\sqrt{m}\) scaling.</strong> For two-layer neural networks, lazy training occurs if we define \(h = \frac{1}{\sqrt{m}} \sum_{j=1}^m \Phi(w_j)\) instead of \(h=\frac{1}{m} \sum_{j=1}^m \Phi(w_j)\) before taking the infinite width limit. Indeed:</p>



<ul class="justify-text"><li>This induces a scaling factor \(\alpha = \sqrt{m} \to \infty\) compared to \(1/m\) which, as we have already seen, is the “correct” scaling that leads to a non-degenerate dynamics in parameter space as \(m\) increases. </li><li>Moreover, by the central limit theorem,  \(\frac{1}{\sqrt{m}} \sum_{j=1}^m \Phi(w_j(0)) = O(1)\) for typical random initializations of the parameters. So the initial predictor stays bounded.</li></ul>



<p class="justify-text">To take the Wasserstein gradient flow limit, the step-size has to be of order \(m\) (see previous blog post). So here we should take a step-size of order \(m/\alpha^2 = 1\). With such a step-size, all the conditions for lazy training are gathered when \(m\) is large. Intuitively, each neuron only moves infinitesimally, but they collectively produce a significant movement in predictor space.</p>



<p class="justify-text"><strong>Neural networks with large initialization.</strong> Coming back to our scaling in \(1/m\) and our Wasserstein gradient flow that is obtained in the large width limit, there is another way to enter the lazy regime: by increasing the variance of the initialization. </p>



<p class="justify-text">To see this, assume that \(h\) is a positively \(p\)-homogeneous parametric predictor, which means that \(h(\sigma W)=\sigma^p h(W)\) for all \(\sigma&gt;0\) and some \(p&gt;1\) (remember that this is true with \(p=2\) for our two-layer relu neural network). Take an initialization of the form \(W(0) = \sigma \bar W_0\) where \(\sigma&gt;0\) and \(h(\bar W_0)=0\) (which is also satisfied for our infinite width neural networks with the initialization considered previously). Consider the gradient flow of \(R(h(W))\) with step-size \(\sigma^{2-2p}\).   By defining \(\bar W(t) = W(t)/\sigma\) and using the fact that the differential of a p-homogeneous function <a href="https://en.wikipedia.org/wiki/Homogeneous_function#Positive_homogeneity">is (p-1)-homogeneous</a>, we have, on the one hand $$ \bar W'(t) = -\sigma^{-p} Dh(\bar W(t))^\top \nabla R(\sigma^p h(\bar W(t))), $$ and on the other hand $$\frac{d}{dt} \sigma^p h(\bar W(t)) =\  – Dh(\bar W(t))Dh(\bar W(t))^\top \nabla R(\sigma^p h(\bar W(t))).$$ So in terms of the dynamics \(\bar W(t)\), the situation is exactly equivalent to having a scaling factor \(\alpha=\sigma^p\). This implies that as the magnitude \(\sigma\) of the initialization increases, we enter the lazy regime, provided the step-size is of order \(\sigma^{2-2p}\).</p>



<p class="justify-text"><strong>Neural tangent kernel. </strong>What does the lazy regime tell us about the learnt predictor for two-layer neural networks? Assuming for simplicity that the predictor at initialization is \(0\), this regime amounts to learning a linear model on top of the feature \([(b_j^\top x)_+]_{j=1}^m\) — the derivative with respect to the output weights — concatenated with the feature \([x a_j 1_{b_j^\top x &gt; 0} ]_{j=1}^m\)  — the derivative with respect to the input weights. Compared to training only the output layer, this thus simply adds some features. </p>



<p class="justify-text">Assume for concreteness, that at initialization the hidden weights \(b_j\) are uniform on a sphere of large radius \(\sigma&gt;0\) and the output weights are uniform on \(\{-\kappa\sigma, \kappa\sigma\}\) where \(\kappa\geq 0\). For a large width and a large \(\sigma\), we enter the lazy regime which amounts to learning in a RKHS — let us call it \(\mathcal{F}_{2,\kappa}\) — that is slightly different from \(\mathcal{F}_2 = \mathcal{F}_{2,0}\), since its kernel \(K_\kappa\) contains another term: $$ K_\kappa(x,x’) = \int_{\mathbb{S}^{d-1}} (\theta^\top x)_+ (\theta^\top x’)_+d\tau(\theta) + \kappa^2 \int_{\mathbb{S}^{d-1}} (x^\top x’) 1_{\theta^\top x &gt; 0}1_{\theta^\top x’ &gt; 0}d\tau(\theta). $$</p>



<p class="justify-text">This kernel is called the Neural Tangent Kernel [<a href="https://papers.nips.cc/paper/8076-neural-tangent-kernel-convergence-and-generalization-in-neural-networks.pdf">17</a>] and the properties of the associated RKHS have been studied in [<a href="https://arxiv.org/pdf/1904.12191.pdf">21</a>, <a href="http://papers.nips.cc/paper/9449-on-the-inductive-bias-of-neural-tangent-kernels.pdf">22</a>], where it is shown to include functions that are slightly less smooth than those of \(\mathcal{F}_2\) when \(\kappa\) increases. This is illustrated in the plot below, obtained by training a wide neural network with \(\sigma\) large (to reach the lazy regime) on the square loss, and various values of \(\kappa\).</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-4213" height="287" src="https://francisbach.com/wp-content/uploads/2020/07/interp-4.png" width="574"/>1-D regression with a wide two-layer relu neural network (gradient descent on square loss, in the lazy regime) with 4 training samples (black dots). At initialization, output weights have \(\kappa\) times the (large) magnitude of the hidden weights. This implicitly solves kernel ridgeless regression for a kernel that depends on \(\kappa\). <a href="https://github.com/lchizat/2020_implicitbias_blog/blob/master/exp_NTK.jl">[code]</a></figure></div>



<p class="justify-text"><strong>Two implicit biases in one shot.</strong> The attentive reader might have noticed that for large initialization scale \(\sigma\gg 1\), when training both layers on the unregularized exponential loss, two of our analyses apply:  lazy training — that leads to a max-margin predictor in \(\mathcal{F}_{2,\kappa}\) — and the asymptotic implicit bias — that leads to a max-margin predictor in \(\mathcal{F}_{1}\).  So, where is the catch? </p>



<p class="justify-text">There is none! Since the minimizers of this loss are at infinity, the lazy regime is just a transient phase and we will observe both implicit biases along the training dynamics! Take a look at the video below: we observe that in early phases of training, the neurons do not move while learning a smooth classifier — this is the lazy regime and the classifier approaches the \(\mathcal{F}_{2,\kappa}\)-max-margin classifier. In later stages of training, the neurons start moving and the predictor converges to a \(\mathcal{F}_1\)-max-margin classifier as stated by the main theorem. The predictor jitters a little bit during training because I have chosen rather aggressive step-sizes. As shown in [<a href="https://arxiv.org/pdf/2007.06738.pdf">23</a>], the transition between these two implicit biases can be well understood in some simpler models.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large"><img alt="" class="wp-image-4219" height="316" src="https://francisbach.com/wp-content/uploads/2020/07/film_lazy2sparse_ns_comp-1.gif" width="640"/>Training both layers with gradient descent for the unregularized exponential loss. The only difference with the previous video is that at initialization the variance \(\sigma^2\) is larger and the step-size smaller \(\approx \sigma^{-2}\). First the network learns a classifier in the lazy regime (a kernel max-margin classifier) and eventually converges to the \(\mathcal{F}_1\)-max-margin classifier. [<a href="https://github.com/lchizat/2020_implicitbias_blog/blob/master/exp_lazy2adaptive.jl">code</a>]</figure></div>



<h2>Discussion</h2>



<p class="justify-text">In this blog post, I described how analyses of the training dynamics can help us understand the properties of the predictor learnt by neural networks even in the absence of an explicit regularization. Already for the simplest algorithm one can think of — gradient descent — we have found a variety of behaviors depending on the loss, the initialization or the step-size. </p>



<p class="justify-text">To achieve this description, the infinite width limit is of great help. It allows to obtain synthetic and precise characterizations of the learnt predictor, that can be used to derive generalization bounds. Yet, there are many interesting non-asymptotic effects caused by having a finite width.  In that sense, we were only concerned with the end of the curve of double descent [<a href="https://www.pnas.org/content/pnas/116/32/15849.full.pdf">24</a>].</p>



<h2>References</h2>



<p class="justify-text">[1] Lénaïc Chizat, Francis Bach. <a href="https://arxiv.org/pdf/2002.04486.pdf">Implicit Bias of Gradient Descent for Wide Two-layer Neural Networks Trained with the Logistic Loss.</a> <em>To appear in Conference On Learning Theory</em>, 2020.<br/>[2] Francis Bach. <a href="http://jmlr.org/papers/volume18/14-546/14-546.pdf">Breaking the curse of dimensionality with convex neural networks.</a> <em>The Journal of Machine Learning Research</em>, <em>18</em>(1), 629-681, 2017.<br/>[3]  Vera Kurková, Marcello Sanguineti. <a href="https://www.cs.cas.cz/~vera/publications/journals/I3Edin.pdf">Bounds on rates of variable-basis and neural-network approximation.</a> <em>IEEE Transactions on Information Theory</em>, 47(6):2659-2665, 2001.  <br/>[4] Behnam Neyshabur, Ryota Tomioka, Nathan Srebro. <a href="https://arxiv.org/pdf/1412.6614.pdf">In Search of the Real Inductive Bias: On the Role of Implicit Regularization in Deep Learning.</a> <em>ICLR (Workshop)</em>. 2015.<br/>[5] Youngmin Cho, Lawrence K. Saul.  <a href="https://papers.nips.cc/paper/3628-kernel-methods-for-deep-learning.pdf">Kernel methods for deep learning.</a> <em>Advances in neural information processing systems</em>. 342-350, 2009.<br/>[6] Radford M. Neal. <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.446.9306&amp;rep=rep1&amp;type=pdf"><em>Bayesian learning for neural networks</em>.</a> Springer Science &amp; Business Media, 2012.<br/>[7] Ali Rahimi, Benjamin Recht. <a href="https://papers.nips.cc/paper/3182-random-features-for-large-scale-kernel-machines.pdf">Random features for large-scale kernel machines.</a> <em>Advances in neural information processing systems</em>. 1177-1184, 2008.<br/>[8] Kevin P. Murphy. Machine Learning: A Probabilistic Perspective. <em>The MIT Press</em>, 2012<br/>[9] Daniel Soudry, Elad Hoffer, Mor Shpigel Nacson, Suriya Gunasekar, Nathan Srebro. <a href="http://www.jmlr.org/papers/volume19/18-188/18-188.pdf">The Implicit Bias of Gradient Descent on Separable Data.</a><em> The Journal of Machine Learning Research</em>, <em>19</em>(1), 2822-2878, 2018.<br/>[10] R. Tyrrell Rockafellar, Roger J-B. Wets. <a href="https://www.springer.com/gp/book/9783540627722"><em>Variational analysis</em>.</a> Springer Science &amp; Business Media, 2009.<br/>[11] Suriya Gunasekar,  Jason D. Lee, Daniel Soudry, Nathan Srebro.  <a href="https://par.nsf.gov/servlets/purl/10107856">Characterizing implicit bias in terms of optimization geometry.</a> <em>International Conference on Machine Learning</em>, 2018.<br/>[12] Ziwei Ji, Matus Telgarsky. <a href="https://arxiv.org/pdf/1803.07300.pdf">Risk and parameter convergence of logistic regression.</a> 2018.<br/>[13] Matus Telgarsky. <a href="https://arxiv.org/abs/1303.4172">Margins, Shrinkage, and Boosting.</a> <em>International Conference on Machine Learning</em>, 307-315, 2013.<br/>[14] Sébastien Bubeck. <a href="https://arxiv.org/pdf/1405.4980.pdf">Convex Optimization: Algorithms and Complexity.</a> Foundations and Trends in Machine Learning, 8(3-4):231-357, 2015.<br/>[15] Yuri Nesterov. <a href="https://www.math.ucdavis.edu/~sqma/MAT258A_Files/Nesterov-2005.pdf">Smooth minimization of non-smooth functions.</a> <em>Mathematical programming</em>, 103(1):127-152, 2005.<br/>[16] Anrew R. Barron. <a href="http://www.stat.yale.edu/~arb4/publications_files/UniversalApproximationBoundsForSuperpositionsOfASigmoidalFunction.pdf">Universal approximation bounds for superpositions of a sigmoidal function.</a> <em>IEEE Transactions on Information theory. </em>39(3), 930-945, 1993.<br/>[17] Arthur Jacot, Franck Gabriel, Clément Hongler. <a href="https://papers.nips.cc/paper/8076-neural-tangent-kernel-convergence-and-generalization-in-neural-networks.pdf">Neural tangent kernel: Convergence and generalization in neural networks.</a> <em>Advances in neural information processing systems.</em> 8571-8580, 2018.<br/>[18] Simon S Du, Xiyu Zhai, Barnabas Poczos, Aarti Singh. <a href="https://arxiv.org/pdf/1810.02054.pdf">Gradient descent provably optimizes over-parameterized neural networks.</a> <em>International Conference on Learning Representations.</em> 2019.<br/>[19] Zeyuan Allen-Zhu, Yuanzhi Li, Zhao Song. <a href="https://arxiv.org/pdf/1811.03962.pdf">A Convergence Theory for Deep Learning via Over-Parameterization.</a> <em> International Conference on Machine Learning</em>, PMLR 97:242-252, 2019.<br/>[20] Lénaïc Chizat, Édouard Oyallon, Francis Bach. <a href="https://papers.nips.cc/paper/8559-on-lazy-training-in-differentiable-programming.pdf">On lazy training in differentiable programming.</a> <em>Advances in Neural Information Processing Systems.</em> 2937-2947, 2019.<br/>[21] Behrooz Ghorbani, Song Mei, Theodor Misiakiewicz, Andrea Montanari. <a href="https://arxiv.org/pdf/1904.12191.pdf">Linearized two-layers neural networks in high dimension.</a> To appear in <em>Annals of Statistics</em>. 2019.<br/>[22] Alberto Bietti, Julien Mairal. <a href="http://papers.nips.cc/paper/9449-on-the-inductive-bias-of-neural-tangent-kernels">On the Inductive Bias of Neural Tangent Kernels</a>. <em>Advances in Neural Information Processing Systems.</em> p. 12893-12904, 2019.<br/>[23] Edward Moroshko, Suriya Gunasekar, Blake Woodworth, Jason D. Lee, Nathan Srebro, Daniel Soudry. <a href="https://arxiv.org/pdf/2007.06738.pdf">Implicit Bias in Deep Linear Classification: Initialization Scale vs Training Accuracy.</a> <em>Technical report arXiv:2007.06738</em>, 2020.<br/>[24] Mikhail Belkin, Daniel Hsu, Siyuan Ma, Soumik Mandal. <a href="https://www.pnas.org/content/pnas/116/32/15849.full.pdf">Reconciling modern machine-learning practice and the classical bias–variance trade-off.</a> <em>Proceedings of the National Academy of Sciences.</em> <em>116</em>(32), 15849-15854, 2019.</p>



<h3>Lower bound on the gradient norm for linear classification with the exponential loss</h3>



<p class="justify-text">In the context of Section 2, we want to prove that \(\Vert \nabla F(a)\Vert_2\geq \gamma\). For this, let \(Z\in \mathbb{R}^{n\times d}\) be the matrix with rows \(y_i x_i\) and let \(\Delta_n\) be the simplex in \(\mathbb{R}^n\). We have by duality $$ \gamma = \max_{\Vert a\Vert_2\leq 1}\min_{p\in \Delta_n} p^\top Z a =   \min_{p\in \Delta_n} \max_{\Vert a\Vert_2\leq 1} a^\top Z^\top p = \min_{p\in \Delta_n} \Vert Z^\top p\Vert_2 .$$  Also, notice that \(\nabla F(a) = Z^\top p\) with \(p_i = \frac{e^{-y_ix_i^\top a}}{\sum_{j=1}^n e^{-y_{j}x_{j}^\top a}}\). Since \(p \in \Delta_n\), we conclude that \(\Vert \nabla F(a)\Vert_2\geq \min_{p\in \Delta_n} \Vert Z^\top p\Vert_2 = \gamma\).</p></div>
    </content>
    <updated>2020-07-13T19:39:11Z</updated>
    <published>2020-07-13T19:39:11Z</published>
    <category term="Machine learning"/>
    <author>
      <name>Lénaïc Chizat</name>
    </author>
    <source>
      <id>https://francisbach.com</id>
      <link href="https://francisbach.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://francisbach.com" rel="alternate" type="text/html"/>
      <subtitle>Francis Bach</subtitle>
      <title>Machine Learning Research Blog</title>
      <updated>2020-08-26T22:24:39Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2020/07/11/2020-virtual-telluride-neuromorphic-cognition-engineering-workshop/</id>
    <link href="https://cstheory-events.org/2020/07/11/2020-virtual-telluride-neuromorphic-cognition-engineering-workshop/" rel="alternate" type="text/html"/>
    <title>2020 Virtual Telluride Neuromorphic Cognition Engineering Workshop</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">July 27-31, 2020 Telluride CO (virtual) https://sites.google.com/view/telluride2020/home We are happy to announce a Virtual Telluride Neuromorphic Cognition Engineering Workshop 2020 (https://tellurideneuromorphic.org/) this year in replacement of our usual Workshop in Telluride. The workshop will take place from July 27 to July 31 (8am to 10am PDT, or 17:00 to 19:00 CET). The format will be … <a class="more-link" href="https://cstheory-events.org/2020/07/11/2020-virtual-telluride-neuromorphic-cognition-engineering-workshop/">Continue reading <span class="screen-reader-text">2020 Virtual Telluride Neuromorphic Cognition Engineering Workshop</span></a></div>
    </summary>
    <updated>2020-07-11T05:05:01Z</updated>
    <published>2020-07-11T05:05:01Z</published>
    <category term="workshop"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2020-08-26T22:24:08Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2020/07/11/international-conference-on-neuromorphic-systems/</id>
    <link href="https://cstheory-events.org/2020/07/11/international-conference-on-neuromorphic-systems/" rel="alternate" type="text/html"/>
    <title>International Conference on Neuromorphic Systems</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">July 28-30, 2020 Oak Ridge National Laboratory (virtual) https://icons.ornl.gov ICONS 2020 will be held as a virtual conference. The goal of this conference is to bring together leading researchers in neuromorphic computing to present new research, develop new collaborations, and provide a forum to publish work in this area. Our focus will be on architectures, … <a class="more-link" href="https://cstheory-events.org/2020/07/11/international-conference-on-neuromorphic-systems/">Continue reading <span class="screen-reader-text">International Conference on Neuromorphic Systems</span></a></div>
    </summary>
    <updated>2020-07-11T05:04:39Z</updated>
    <published>2020-07-11T05:04:39Z</published>
    <category term="conference"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2020-08-26T22:24:08Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2020/07/11/neuromorphic-computing-opportunities-challenges-and-perspectives/</id>
    <link href="https://cstheory-events.org/2020/07/11/neuromorphic-computing-opportunities-challenges-and-perspectives/" rel="alternate" type="text/html"/>
    <title>Neuromorphic Computing: Opportunities, Challenges, and Perspectives</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">July 19, 2020 Virtual https://teuscher-lab.com/dac2020_neuromorphic_workshop/program/ The objective of this workshop is to bring together researchers from multiple disciplines, ranging from physical to biological sciences, to discuss the most promising approaches and overarching goals of neuromorphic computing technologies and paradigms that have the potential to drastically improve conventional approaches. The neuromorphic computing workshop aims to establish … <a class="more-link" href="https://cstheory-events.org/2020/07/11/neuromorphic-computing-opportunities-challenges-and-perspectives/">Continue reading <span class="screen-reader-text">Neuromorphic Computing: Opportunities, Challenges, and Perspectives</span></a></div>
    </summary>
    <updated>2020-07-11T05:04:18Z</updated>
    <published>2020-07-11T05:04:18Z</published>
    <category term="workshop"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2020-08-26T22:24:08Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://kamathematics.wordpress.com/?p=188</id>
    <link href="https://kamathematics.wordpress.com/2020/06/30/virtual-stoc-2020-behind-the-screens/" rel="alternate" type="text/html"/>
    <title>Virtual STOC 2020 – Behind the Screens</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">In order to assist organizers of other virtual conferences, the general chairs of STOC 2020 (myself, Konstantin Makarychev, Yury Makarychev and Madhur Tulsiani, with input from PC chair Julia Chuzhoy) wrote a detailed document describing the design and execution of the conference. I personally felt the conference went about as well as it could have … <a class="more-link" href="https://kamathematics.wordpress.com/2020/06/30/virtual-stoc-2020-behind-the-screens/">Continue reading<span class="screen-reader-text"> "Virtual STOC 2020 – Behind the Screens"</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>In order to assist organizers of other virtual conferences, the general chairs of STOC 2020 (myself, Konstantin Makarychev, Yury Makarychev and Madhur Tulsiani, with input from PC chair Julia Chuzhoy) wrote a detailed document describing the design and execution of the conference. I personally felt the conference went about as well as it could have gone, and despite many moving parts, there were minimal technical difficulties.</p>



<p>The guide is available here: <a href="https://docs.google.com/document/d/1nzyvfdsXLzqYXxxdjw1y_OHAYwGolHCZUkRVmlxG9BE/edit?ts=5efa758c" rel="noreferrer noopener" target="_blank">Virtual STOC 2020 – Behind the Screens</a>.</p>



<p>If you have any questions or comments, feel free to comment below, or join in the conversation on <a href="https://twitter.com/thegautamkamath/status/1277959908168695808">Twitter</a>.</p></div>
    </content>
    <updated>2020-06-30T13:13:16Z</updated>
    <published>2020-06-30T13:13:16Z</published>
    <category term="Events"/>
    <author>
      <name>Gautam</name>
    </author>
    <source>
      <id>https://kamathematics.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://kamathematics.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://kamathematics.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://kamathematics.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://kamathematics.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Kamathematics</title>
      <updated>2020-08-26T22:24:33Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2020/06/24/ideal-workshop-on-computational-vs-statistical-tradeoffs-in-network-inference/</id>
    <link href="https://cstheory-events.org/2020/06/24/ideal-workshop-on-computational-vs-statistical-tradeoffs-in-network-inference/" rel="alternate" type="text/html"/>
    <title>IDEAL Workshop on Computational vs Statistical Tradeoffs in Network Inference</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">June 29, 2020 Virtual https://www.ideal.northwestern.edu/events/workshop-computational-vs-statistical-tradeoffs-in-network-inference/ Network models have been used as a tool to understand the role of interconnections between entities in multiple research areas like sociology, biology, meteorology, economics, and computer science. Moreover emerging technological developments allow collecting data on increasingly larger networks. This leads to both computational and statistical challenges when inferring or … <a class="more-link" href="https://cstheory-events.org/2020/06/24/ideal-workshop-on-computational-vs-statistical-tradeoffs-in-network-inference/">Continue reading <span class="screen-reader-text">IDEAL Workshop on Computational vs Statistical Tradeoffs in Network Inference</span></a></div>
    </summary>
    <updated>2020-06-24T23:53:00Z</updated>
    <published>2020-06-24T23:53:00Z</published>
    <category term="workshop"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2020-08-26T22:24:06Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://theorydish.blog/?p=1791</id>
    <link href="https://theorydish.blog/2020/06/21/free-registeration-to-tcs-women-rising-star-talks/" rel="alternate" type="text/html"/>
    <title>(Free) Registeration to TCS Women Rising Star talks</title>
    <summary>TCS Women Rising Star talks are happening as part of TCS Women STOC Spotlight Workshop. Seven Rising Star speakers are lined up, all of whom are planning to be on the job market this year. In addition, Shafi Goldwasser will give a longer talk. Everybody is invited, but (free) registration is required. (Attendees don’t even have to pay the STOC registration fee.) More information is on the website:https://sigact.org/tcswomen/.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>TCS Women Rising Star talks are happening as part of TCS Women STOC Spotlight Workshop. Seven Rising Star speakers are lined up, all of whom are planning to be <em><strong>on the job market this year</strong></em>. In addition, Shafi Goldwasser will give a longer talk. Everybody is invited, but (free) registration is required. (Attendees don’t even have to pay the STOC registration fee.) More information is on the website:<br/><a href="https://sigact.org/tcswomen/" rel="noreferrer noopener" target="_blank">https://sigact.org/tcswomen/</a>. </p></div>
    </content>
    <updated>2020-06-22T04:16:26Z</updated>
    <published>2020-06-22T04:16:26Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Omer Reingold</name>
    </author>
    <source>
      <id>https://theorydish.blog</id>
      <logo>https://theorydish.files.wordpress.com/2017/03/cropped-nightdish1.jpg?w=32</logo>
      <link href="https://theorydish.blog/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://theorydish.blog" rel="alternate" type="text/html"/>
      <link href="https://theorydish.blog/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://theorydish.blog/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Stanford's CS Theory Research Blog</subtitle>
      <title>Theory Dish</title>
      <updated>2020-08-26T22:24:11Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://kamathematics.wordpress.com/?p=180</id>
    <link href="https://kamathematics.wordpress.com/2020/06/19/stoc-2020-goes-virtual/" rel="alternate" type="text/html"/>
    <title>STOC 2020 Goes Virtual!</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Starting on Monday, STOC is joining the trend of conferences going online, I believe the biggest theory conference to do so thus far. Given my experience with TCS+, I volunteered to lend a hand with the organization and logistics. It’s been a journey (with some unusual technical challenges), but I think we have something which … <a class="more-link" href="https://kamathematics.wordpress.com/2020/06/19/stoc-2020-goes-virtual/">Continue reading<span class="screen-reader-text"> "STOC 2020 Goes Virtual!"</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Starting on Monday, STOC is joining the trend of conferences going online, I believe the biggest theory conference to do so thus far. Given my experience with <a href="https://sites.google.com/site/plustcs/">TCS+</a>, I volunteered to lend a hand with the organization and logistics. It’s been a journey (with some <a href="https://twitter.com/thegautamkamath/status/1273055827092549634">unusual technical challenges</a>), but I think we have something which I hope will be engaging and generally a lot of fun. In addition to the typical academic component, we also have a social component planned as well. We learnt from the work of others, including the <a href="https://www.acm.org/virtual-conferences">ACM virtual conferences guide</a>, <a href="https://iclr.cc/Conferences/2020">ICLR 2020</a>, and <a href="https://www.daniellitt.com/blog/2020/4/20/wagon-lessons-learned">WAGON</a>. I may make some version of our logistics docs available to others after the conference, so others can learn from our experience as well. Anyway, read on for an announcement from me and the other General Chairs, Konstantin Makarychev, Yury Makarychev, and Madhur Tulsiani. See also the <a href="http://acm-stoc.org/stoc2020/">main STOC page</a> for a more complete list of credits.</p>



<hr class="wp-block-separator"/>



<p>Dear fellow theorists,</p>



<p>As you already know, STOC 2020 this year will be a virtual conference. If you are interested in attending the conference, but haven’t registered yet, <a href="http://www.cvent.com/events/52nd-annual-acm-symposium-on-theory-of-computing-stoc-2020-/event-summary-ea5fa7861d1a476d82bc10f667a1c0f4.aspx">please do so soon</a> (students: $25, regular: $50). This will help us ensure we have capacity for various online events. </p>



<p>Upon registration, you should receive a confirmation email from CVENT, also containing access information for various conference events. Also, if you are a student looking to register for STOC but the cost is a burden, please email us at <a href="mailto:stoc2020@ttic.edu">stoc2020@ttic.edu</a>.</p>



<p><strong>How will the conference work?</strong></p>



<ul><li><strong>Videos</strong>: The videos for all conference talks are now available on YouTube, and can be accessed through the links in the <a href="http://acm-stoc.org/stoc2020/STOCprogram.html">conference program</a>. Registration is <em>not required</em> to view the talks on Youtube.</li></ul>



<ul><li><strong>Slack</strong>: The conference has a Slack workspace, with one channel for every paper and workshop, and additional channels for information, announcements, social events, help, etc. The invitations for the Slack workspace will be sent to registered participants. Authors are also encouraged to monitor the channels for their papers. All access information for the conference will also be available here. The workspace is currently active, and will remain active for at least one week after the conference.</li></ul>



<ul><li><strong>Zoom sessions</strong>: The conference will feature Zoom sessions with short presentations by the speakers. The total time for each paper is 10 minutes. Given that participants have access to the full talks by the speakers on Youtube, these can be thought of as being analogues of poster sessions. The workshops will also be held as separate sessions. The links for the Zoom session via information in the confirmation email.</li></ul>



<ul><li><strong>Social events</strong>: The conference will include junior/senior “lunches”, breakout tables for impromptu and scheduled hangouts, and a group event using <a href="https://gather.town">gather.town</a>. The timings for the events can be found in the conference program. Sign-up links for various events will be sent to all registered participants – please do sign-up soon!</li></ul>



<p>See you all at (virtual) STOC 2020. Please do let us know if you have any questions or suggestions.</p></div>
    </content>
    <updated>2020-06-19T20:20:16Z</updated>
    <published>2020-06-19T20:20:16Z</published>
    <category term="Events"/>
    <author>
      <name>Gautam</name>
    </author>
    <source>
      <id>https://kamathematics.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://kamathematics.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://kamathematics.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://kamathematics.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://kamathematics.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Kamathematics</title>
      <updated>2020-08-26T22:24:34Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2020/06/12/logic-mentoring-workshop-2020/</id>
    <link href="https://cstheory-events.org/2020/06/12/logic-mentoring-workshop-2020/" rel="alternate" type="text/html"/>
    <title>Logic Mentoring Workshop 2020</title>
    <summary>July 6, 2020 Online http://lmw.mpi-sws.org/index.html The Logic Mentoring Workshop (LMW) will introduce young researchers to the technical and practical aspects of a career in logic research. It is targeted at students, from senior undergraduates to graduates, and will include talks and a panel session from leaders in the subject.</summary>
    <updated>2020-06-12T18:31:23Z</updated>
    <published>2020-06-12T18:31:23Z</published>
    <category term="workshop"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2020-08-26T22:24:08Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://tcsplus.wordpress.com/?p=441</id>
    <link href="https://tcsplus.wordpress.com/2020/06/06/tcs-talk-wednesday-june-10-cliff-stein-columbia-university/" rel="alternate" type="text/html"/>
    <title>TCS+ talk: Wednesday, June 10 — Cliff Stein, Columbia University</title>
    <summary>In solidarity with the current protests in the United States (https://www.shutdownstem.com/), our speaker asked that the talk this coming Wednesday be postponed. Cliff’s talk has been rescheduled to Thursday, June 18th; we will keep you updated in case of any further change. We would also take this opportunity to call the TCS community for feedback, […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>In solidarity with the current protests in the United States (<a href="https://www.shutdownstem.com/" rel="nofollow">https://www.shutdownstem.com/</a>), our speaker asked that the talk this coming Wednesday be postponed.</b></p>
<p><strong>Cliff’s talk has been rescheduled to <span style="color: #ff0000;">Thursday, June 18th</span>; we will keep you updated in case of any further change. We would also take this opportunity to <a href="https://sites.google.com/site/plustcs/suggest">call the TCS community for feedback, and for suggestions and comments</a>. As a small team organizing this virtual seminar, we are continuously trying to improve and welcome your input.</strong></p>
<p>The next TCS+ talk<em> (and the last of the season!)</em> will take place this coming Wednesday, June 10th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). <strong>Cliff Stein</strong> from Columbia University will speak about “<em>Parallel Approximate Undirected Shortest Paths Via Low Hop Emulators</em>” (abstract below).</p>
<p>You can reserve a spot as an individual or a group to join us live by signing up on <a href="https://sites.google.com/site/plustcs/livetalk/live-seat-reservation">the online form</a>. Due to security concerns, <em>registration is required</em> to attend the interactive talk. (The link to the YouTube livestream will also be posted <a href="https://sites.google.com/site/plustcs/livetalk">on our<br/>
website</a> on the day of the talk, so people who did not sign up will still be able to watch the talk live.) As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/site/plustcs/suggest">suggest</a> a possible topic or speaker, please see &gt;the website.</p>
<blockquote><p>Abstract: Although sequential algorithms with (nearly) optimal running time for finding shortest paths in undirected graphs with non-negative edge weights have been known for several decades, near-optimal parallel algorithms have turned out to be a much tougher challenge. In this talk, we present a <img alt="(1+\varepsilon)" class="latex" src="https://s0.wp.com/latex.php?latex=%281%2B%5Cvarepsilon%29&amp;bg=fff&amp;fg=444444&amp;s=0" title="(1+\varepsilon)"/>-approximate parallel algorithm for computing shortest paths in undirected graphs, achieving polylog depth and near-linear work. All prior <img alt="(1+\varepsilon)" class="latex" src="https://s0.wp.com/latex.php?latex=%281%2B%5Cvarepsilon%29&amp;bg=fff&amp;fg=444444&amp;s=0" title="(1+\varepsilon)"/>-algorithms with polylog depth perform at least superlinear work. Improving this long-standing upper bound obtained by Cohen (STOC’94) has been open for 25 years.</p>
<p>Our algorithm uses several new tools. Prior work uses hopsets to introduce shortcuts in the graph. We introduce a new notion that we call low hop emulators. We also introduce compressible preconditioners, which we use in conjunction with Serman’s framework (SODA ’17) for the uncapacitated minimum cost flow problem.</p>
<p>Joint work with Alex Andoni and Peilin Zhong.</p></blockquote></div>
    </content>
    <updated>2020-06-06T18:16:14Z</updated>
    <published>2020-06-06T18:16:14Z</published>
    <category term="Announcements"/>
    <author>
      <name>plustcs</name>
    </author>
    <source>
      <id>https://tcsplus.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://tcsplus.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://tcsplus.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://tcsplus.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://tcsplus.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A carbon-free dissemination of ideas across the globe.</subtitle>
      <title>TCS+</title>
      <updated>2020-08-26T22:24:02Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://francisbach.com/?p=2566</id>
    <link href="https://francisbach.com/gradient-descent-neural-networks-global-convergence/" rel="alternate" type="text/html"/>
    <link href="https://francisbach.com/wp-content/uploads/2020/05/ReLU_m100.mp4" length="434960" rel="enclosure" type="video/mp4"/>
    <title>Gradient descent for wide two-layer neural networks – I : Global convergence</title>
    <summary>Supervised learning methods come in a variety of flavors. While local averaging techniques such as nearest-neighbors or decision trees are often used with low-dimensional inputs where they can adapt to any potentially non-linear relationship between inputs and outputs, methods based on empirical risk minimization are the most commonly used in high-dimensional settings. Their principle is...</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p class="justify-text">Supervised learning methods come in a variety of flavors. While local averaging techniques such as <a href="https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm">nearest-neighbors</a> or <a href="https://en.wikipedia.org/wiki/Decision_tree_learning">decision trees</a> are often used with low-dimensional inputs where they can adapt to any potentially non-linear relationship between inputs and outputs, methods based on empirical risk minimization are the most commonly used in high-dimensional settings. Their principle is simple: optimize the (potentially regularized) risk on training data over prediction functions in a pre-defined set of functions.</p>



<p class="justify-text">When the set of a functions is a convex subset of a vector space with a finite-dimensional representation, with standard assumptions, the corresponding optimization problem is convex. This has the benefits of allowing a thorough theoretical understanding of the computational and statistical properties of learning methods, which often come with strong theoretical guarantees, in terms of running time [<a href="https://arxiv.org/pdf/1405.4980">1</a>, <a href="https://epubs.siam.org/doi/pdf/10.1137/16M1080173">2</a>, <a href="http://www.di.ens.fr/~fbach/bach_jenatton_mairal_obozinski_FOT.pdf">3</a>] or prediction performance on unseen data [<a href="https://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/understanding-machine-learning-theory-algorithms.pdf">4</a>, <a href="http://static.stevereads.com/papers_to_read/all_of_statistics.pdf">5</a>]. In particular, the linear parameterization can be done either explicitly by building a typically large finite set of features, or implicitly through the use of kernel methods and then a series of dedicated algorithms and theories can be leveraged for efficient non-linear predictions [6, <a href="http://papers.nips.cc/paper/3182-random-features-for-large-scale-kernel-machines.pdf">7</a>, <a href="http://papers.nips.cc/paper/6978-falkon-an-optimal-large-scale-kernel-method.pdf">8</a>].</p>



<p class="justify-text">However, linearly-parameterized sets of functions do not include neural networks, which lead to state-of-the-art performance in most learning tasks in computer vision, natural language processing, speech processing, in particular through the use of deep and convolutional neural networks [<a href="https://www.deeplearningbook.org/">9</a>].</p>



<h2>Two-layer neural networks with “relu” activations</h2>



<p class="justify-text">The goal of this blog post is to provide some understanding of why supervised machine learning work for the simplest form of such models: $$ h(x) = \frac{1}{m} \sum_{i=1}^m a_i ( b_i^\top x)_+ = \frac{1}{m} \sum_{i=1}^m a_i \max\{ b_i^\top x,0\},$$ where the input \(x\) is a vector in \(\mathbb{R}^d\), and \(m\) is the number of hidden neurons. The weights \(a_i \in \mathbb{R}\), \(i=1,\dots,n\), are the <em>output weights</em>, while the weights \(b_i \in \mathbb{R}^d\), \(i=1,\dots,n\), are the <em>input weights</em>. The rectified linear unit (“relu”) [<a href="http://www.jmlr.org/proceedings/papers/v15/glorot11a/glorot11a.pdf">10</a>] activation is used, and our results will depend heavily on its positive homogeneity (that is, for \(\lambda &gt; 0\), \((\lambda u)_+ = \lambda u_+\)).</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-3829" height="292" src="https://francisbach.com/wp-content/uploads/2020/05/nn_single_blog.png" width="407"/>Two-layer neural network in dimension \(d = 6\) with \(m=4\) hidden neurons, and a single output.</figure></div>



<p class="justify-text">Note that this is an idealized and much simplified set-up for deep learning, as there is a single hidden-layer, no convolutions, no pooling, etc. As I will show below, this simple set-up is already complex to understand, and I believe it captures some of the core difficulties associated with non-convexity.</p>



<p class="justify-text">The first question that one may come to after decades of research in learning theory is: <em>why is it so hard to analyze?</em>  </p>



<p class="justify-text">There are at least two major difficulties:</p>



<ul class="justify-text"><li><strong>Non-linearity</strong>: the dependence on the input weights \(b_i\)’s is non-linear because of the activation function, typically leading to non-convex optimization problems.</li><li><strong>Overparameterization</strong>: The number \(m\) of hidden neurons is very large (often so large that the number of parameters \(m(d+1)\) exceeds the number of observations), which is hard in terms of optimization and potentially generalization to unseen data. </li></ul>



<p class="justify-text">In this blog post, we will leverage the overparameterization and take \(m\) tending to infinity (without any dependence on the number of observations), which will allow us to derive theoretical results. We will leverage two key properties of the problem:</p>



<ul class="justify-text"><li><strong>Separability</strong> of the model in \(w_i = (a_i,b_i)\), that is, the prediction function \(h(x)\) is the sum of terms which are independently parameterized, as \(h = \frac{1}{m} \sum_{i=1}^m \Phi(w_i)\), where \(\Phi: \mathbb{R}^p \to \mathcal{F}\), with \(\mathcal{F}\) a space of functions. In our situation, \(p = d+1\) and: $$ \Phi(w)(x) = a (b^\top x)_+. $$ In other words,  there is no parameter sharing among hidden neurons. Unfortunately, this does not generalize to more than a single hidden layer.</li><li><strong>Homogeneity</strong>: the relu activation is positively homogeneous so that as as function of \(w = (a,b) \in \mathbb{R} \times \mathbb{R}^d\), \(\Phi(w)(x) = a (b^\top x)_+\) is positively 2-homogeneous, that is, \(\Phi(\lambda w) = \lambda^2 \Phi(w)\) for \(\lambda &gt; 0\).</li></ul>



<p class="justify-text">In this sequence of two blog posts, following a recent trend in optimization and machine learning theory [<a href="http://papers.nips.cc/paper/4900-non-strongly-convex-smooth-stochastic-approximation-with-convergence-rate-o1n.pdf">11</a>, <a href="https://www.pnas.org/content/pnas/116/32/15849.full.pdf">12</a>], optimization and statistics cannot be separated and need to be tackled together. I will focus on gradient flows on empirical or expected risks.</p>



<p class="justify-text">In this blog post, I will cover optimization and how over-parameterization leads to global convergence for 2-homogeneous models, a recent result obtained two years ago with <a href="https://lchizat.github.io/">Lénaïc Chizat</a> [<a href="http://papers.nips.cc/paper/7567-on-the-global-convergence-of-gradient-descent-for-over-parameterized-models-using-optimal-transport.pdf">13</a>]. This requires tools from optimal transport which I will briefly describe (for more details, see, e.g., [<a href="https://arxiv.org/abs/1803.00567">14</a>]).</p>



<p class="justify-text">Next month, I will focus on generalization capabilities and the several implicit biases associated with gradient descent in this context [<a href="https://papers.nips.cc/paper/8559-on-lazy-training-in-differentiable-programming.pdf">15</a>, <a href="https://arxiv.org/pdf/2002.04486">16</a>].</p>



<h2>Infinitely wide limit and probability measures</h2>



<p class="justify-text">Following the standard learning set-up, our goal will be to minimize with respect to the prediction function \(h\) the functional \(R\) defined as $$ R(h) = \mathbb{E}_{p(x,y)} \big[ \ell( y, h(x) ) \big],$$ where \(\ell(y,h(x))\) is the loss incurred by outputting \(h(x)\) when \(y\) is the true label. Even within deep learning, this loss is most often convex in its second argument, such as for least-squares or <a href="https://en.wikipedia.org/wiki/Loss_functions_for_classification">logistic</a> losses. Thus, I will assume that \(R\) is convex.</p>



<p>The expectation can be considered in two scenarios:</p>



<ul class="justify-text"><li><strong>Empirical risk</strong>: this corresponds to the situation where we have observations \((x_j,y_j)\), \(j=1,\dots,n\), coming from some joint distribution on \((x,y) \in \mathbb{R}^d \times \mathbb{R}\). Minimizing \(R\) then may not lead to any guarantee on unseen data unless some explicit or implicit regularization is used. In next blog post, I will consider the implicit regularization effect of gradient-based algorithms.</li><li><strong>Expected risk (or generalization performance)</strong>: The expectation is taken with respect to unseen data, and thus its value (or a gradient) cannot be computed. However, any training observation \((x_j,y_j)\) can lead to an unbiased estimate, and if single pass stochastic gradient is used, our guarantees will be on the expected risk.</li></ul>



<p class="justify-text">The main and very classical idea is to consider the minimization of $$ G(W) = G(w_1,\dots,w_m) = R \Big( \frac{1}{m} \sum_{i=1}^m \Phi(w_i) \Big),$$ and see it as the minimization of $$ F(\mu) = R \Big( \int_{\mathbb{R}^p} \Phi(w) d\mu(w) \Big),$$ with respect to a probability measure \(\mu\), with the equivalence for $$ \mu = \frac{1}{m} \sum_{i=1}^m \delta(w_i),$$ where \(\delta(w_i)\) is the Dirac measure at \(w_i\). See an illustration below.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-3852" height="93" src="https://francisbach.com/wp-content/uploads/2020/05/diracs_measures-1-1024x156.png" width="615"/>Left: discrete probability measure. Right: measure with density.</figure></div>



<p class="justify-text">When \(m\) is large, we can represent any measure in the <a href="https://en.wikipedia.org/wiki/Convergence_of_measures#Weak_convergence_of_measures">weak sense</a> (that is, expectations of any continuous and bounded functions can be approximated). The benefits of considering the space of all measures instead of discrete measures have been used already in variety of contexts in machine learning, statistics and signal processing [<a href="http://www.stat.yale.edu/~arb4/publications_files/UniversalApproximationBoundsForSuperpositionsOfASigmoidalFunction.pdf">17</a>, <a href="http://papers.nips.cc/paper/2800-convex-neural-networks.pdf">18</a>, <a href="http://jmlr.org/papers/volume18/14-546/14-546.pdf">19</a>]. In this blog post, the key benefit is that the set of measures in convex and \(h = \int_{\mathbb{R}^p} \Phi(w) d\mu(w) \) is linear in the measure \(\mu\), so that our optimization problem has become convex.</p>



<p class="justify-text">However, (1) It does not buy much in practice, as the set of probability measures is infinite-dimensional. <a href="https://en.wikipedia.org/wiki/Frank&#x2013;Wolfe_algorithm">Frank-Wolfe algorithms</a> can be used, but the choice of new neurons is a difficult optimization problem, NP-hard for the threshold activation function [<a href="https://epubs.siam.org/doi/pdf/10.1137/070685798">20</a>], with polynomial potentially high complexity for the relu activation [<a href="http://proceedings.mlr.press/v65/goel17a/goel17a.pdf">21</a>], and (2) this is not what is used in practice, which is (stochastic) gradient descent.</p>



<h2>Finite-dimensional gradient flow</h2>



<p class="justify-text">In this post, I will consider the gradient flow $$\dot{W} = \ – m \nabla G(W),$$ (where \(m\) is added as a normalization factor to allow a well-defined limit when \(m\) tends to infinity). This is still not exactly what is used in practice, but, as explained in <a href="https://francisbach.com/gradient-flows/">last month post</a>, this is a good approximation of gradient descent (if using the empirical risk, then leading to guarantees of global convergence on the empirical risk only), or stochastic gradient descent (if doing a single pass on the data, then leading to guarantees of global convergence on unseen data). This is a non-convex dynamics, with stationary points and local minima, even when \(m\) is large (see, e.g., [<a href="http://proceedings.mlr.press/v80/safran18a/safran18a.pdf">27</a>]).</p>



<p class="justify-text">Two main questions arise: (1) what does the gradient flow dynamics converge to when the number of neurons \(m\) tends to infinity, and (2) can we get any global convergence guarantees for the limiting dynamics?</p>



<h2>Mean-field limit and Wasserstein gradient flows</h2>



<p class="justify-text">When \(m\) tends to infinity, since we want to use the measure representation, we need to understand the effect of performing the gradient flow jointly on \(w_1,\dots,w_m\) on the measure $$ \mu = \frac{1}{m} \sum_{i=1}^m \delta(w_i),$$ and see if we can take a limit when \(m\) tends to infinity. This process of taking limits is common in physics and often referred to as the “mean-field” limit, and has been considered in a series of recent works [<a href="https://arxiv.org/pdf/1712.05438">22</a>, <a href="http://papers.nips.cc/paper/7567-on-the-global-convergence-of-gradient-descent-for-over-parameterized-models-using-optimal-transport.pdf">13</a>, <a href="https://www.pnas.org/content/pnas/115/33/E7665.full.pdf">23</a>, <a href="https://arxiv.org/pdf/1805.00915">24</a>]. To avoid too much technicality, I will assume that the map \(\Phi\) is sufficiently differentiable, which unfortunately exclude the relu activation; for dedicated results, see [<a href="http://papers.nips.cc/paper/7567-on-the-global-convergence-of-gradient-descent-for-over-parameterized-models-using-optimal-transport.pdf">13</a>].</p>



<p class="justify-text"><strong>Gradient flows on metric spaces.</strong> In order to understand the dynamics in the space of probability measures, we need to take a step backward and realize that gradient flows can be defined for many functions \(f\) on any metric space \(\mathcal{X}\). Indeed, it can be seen as the limit of taking infinitesimal steps of length \(\gamma\), where each new iterate \(x_{k+1}\) (corresponding to the value at time \(k\gamma\)) is defined recursively from \(x_k\) as $$x_{k+1} \in \arg\min_{x \in \mathcal{X}}\  f(x) + \frac{1}{2\gamma} d(x,x_k)^2.$$ As shown in [<a href="http://www2.stat.duke.edu/~sayan/ambrosio.pdf">25</a>, <a href="https://link.springer.com/content/pdf/10.1007/s13373-017-0101-1.pdf">26</a>], with some form of interpolation, this defines a curve with prescribed values \(x_k\) at each \(\gamma k\), and when the step-size \(\gamma\) goes to zero, this curves “converges” to the gradient flow.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-3960" height="212" src="https://francisbach.com/wp-content/uploads/2020/05/euler-1024x520.png" width="419"/>Gradient flow in bold black, with interpolating curve in red from 14 points \(x_0,\dots,x_{13}\).</figure></div>



<p class="justify-text">For the space \(\mathcal{X} = \mathbb{R}^d\) with the Euclidean distance and a continuously differentiable function \(f\), we obtain that $$x_{k+1} = x_k – \gamma f'(x_k) + o(\gamma),$$ and we get the usual gradient flow associated to \(f\), and the scheme above is nothing less than <a href="https://en.wikipedia.org/wiki/Euler_method">Euler discretization</a> that was described <a href="https://francisbach.com/gradient-flows/">last month</a>.</p>



<p class="justify-text"><strong>Vector space gradient flows on probability measures.</strong> Probability measures are a convex subset of measures with finite <a href="https://en.wikipedia.org/wiki/Total_variation#Total_variation_of_probability_measures">total variation</a>, which is equal to the \(\ell_1\)-norm between densities when the two probability measures have densities with respect to the same base measure. It is a normed vector space for which we could derive our first type of gradient flow, which can be seen as a continuous version of Frank-Wolfe algorithm, where atoms are added one by one, until convergence.  </p>



<p class="justify-text">As mentioned above, the fact that atoms are created sequentially seems attractive computationally. However, (1) deciding which one to add is a computationally hard problem, and (2) the flow on measures cannot be approximated by a finite evolving set of “particles” (here hidden neurons each defined by a vector \(w \in \mathbb{R}^{d+1}\)).</p>



<p class="justify-text"><strong>Wasserstein gradient flows on probability measures.</strong> There is another natural distance here, namely the <a href="https://en.wikipedia.org/wiki/Wasserstein_metric">Wasserstein distance</a> (sometimes called the Kantorovich–Rubinstein distance). In order to remain short, I will only define it between empirical measures $$\mu = \frac{1}{m} \sum_{i=1}^m \delta(w_i) \mbox{ and } \nu = \frac{1}{m} \sum_{i=1}^m \delta(v_i)$$ with the same number of points. The squared 2-Wasserstein distance is obtained by minimizing $$\frac{1}{m} \sum_{i=1}^m \| w_j – v_{\sigma(j)} \|_2^2$$ over all permutations \(\sigma: \{1,\dots,m\} \to \{1,\dots,m\}\). See illustration below.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-3886" height="171" src="https://francisbach.com/wp-content/uploads/2020/05/Wasserstein-2-1024x307.png" width="573"/>Wasserstein distance between two empirical measures: (left) original observations of two empirical measures with \(m = 11\) points, (right) assigning all black points to red points by minimizing the sum of squared distances between assigned points.</figure></div>



<p class="justify-text">This can be extended to any pair of probability measures, and used within gradient flows, it has a very natural decoupling property: if \(\mu\) is fixed, and \(\nu\) is within a small distance of \(\mu\) in Wasserstein distance, then the optimal permutation above will always be the same, that is, locally, the Wasserstein distance is a sum of squared Euclidean distances. Then, the Wasserstein gradient flow will lead to \(m\) independent local regular Euclidean gradient flows, which interact through the gradient term as: $$ \dot{w}_i = \ –  \nabla \Phi(w_i)  \nabla R\Big(\int_{\mathbb{R}^p} \Phi d\mu \Big),$$ where the Jacobian \(\nabla \Phi(w_i)\) is a linear operator from \(\mathcal{F}\) to \(\mathbb{R}^p\), and \( \nabla R: \mathbb{R}^p \to \mathcal{F}\) the gradient operator of \(R\). Since \(\mu = \frac{1}{m} \sum_{i=1}^m \delta(w_i)\), the dynamics of each particle interacts through the gradient of \(R\). </p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-3890" height="225" src="https://francisbach.com/wp-content/uploads/2020/05/Wasserstein_flows-1024x508.png" width="456"/>Gradient flow for \(m=7\) interacting particles.</figure></div>



<p class="justify-text">The intuitive reasoning above is behind the formal result for the function $$ F(\mu) = R \Big( \int_{\mathbb{R}^p} \Phi(w) d\mu(w) \Big),$$ that the limit of the Euclidean gradient flow on each particle when \(m\) tends to infinity, is exactly the Wasserstein gradient flow of \(F\). While I have proposed an intuitive explanation, this can be made more formal in particular through the use of partial differential equations on the density of the measure [<a href="http://papers.nips.cc/paper/7567-on-the-global-convergence-of-gradient-descent-for-over-parameterized-models-using-optimal-transport.pdf">13</a>] (see also nice <a href="http://web.math.ucsb.edu/~kcraig/math/curriculum_vitae_files/NIPS_120917.pdf">slides</a> from Katy Craig on Wasserstein gradient flows).</p>



<p class="justify-text"><strong>Stationary points.</strong> Since \(R\) is assumed convex over the convex set of probability measures, all local minima of \(R\) are global, and we should expect the gradient flow to converge to global optimum from any initial measure. This is true for the gradient flow associated with the total variation metric. However this is not true for the Wasserstein gradient flow, for which stationary points which are not global minimizers exist (given that for discrete measures this corresponds to classical backpropagation, this is well known to anybody who has ever trained a neural network). Note that there exists a notion of convexity for Wasserstein gradient flows, namely <a href="https://en.wikipedia.org/wiki/Geodesic_convexity">geodesic convexity</a>, but the function \(F\) is not geodesically convex in general.</p>



<h2>Global convergence</h2>



<p class="justify-text">We can now describe the main result from our recent work with Lénaïc [<a href="http://papers.nips.cc/paper/7567-on-the-global-convergence-of-gradient-descent-for-over-parameterized-models-using-optimal-transport.pdf">13</a>]: under assumptions described below, for the function \(F\) defined above, if the Wasserstein gradient flow converges to a measure, this measure has to be a global minimum of \(F\) (note that we cannot prove it is always convergent).</p>



<p class="justify-text">On top of technical regularity assumptions that I will not describe here, we need two crucial broad assumptions:</p>



<ul class="justify-text"><li><strong>Homogeneity</strong> of the function \(\Phi: \mathbb{R}^{d+1} \to \mathcal{F}\). We need a condition of this form, since if \(R\) is a linear function, then \(F(\mu)\) is of the form \(F(\mu) = \int_{\mathbb{R}^p} \psi(w)d\mu(w)\) with \(\psi(w) = R(\Phi(w))\), and the Wasserstein gradient flow will converge to a weighted some of Diracs at all local minimizers of \(\psi\), which is typically not a global minimizer.</li><li><strong>Initialization with positive mass in all directions</strong>. That is, \(w_i\)’s are uniformly distributed on the sphere or Gaussian, which is the de facto choice in practice. </li></ul>



<p class="justify-text"><strong>Illustration</strong>. We illustrate the result above by considering \(R\) as the square loss and \(y\) being generated from \(x\) through a neural network with \(m_0=5\) neurons. When running the gradient flow above, as soon as \(m \geqslant 5\), the model is sufficiently flexible to attain zero loss, which is thus the global optimum of the cost function. However, the gradient flow may not reach it, as it gets trapped in a local optimum. Our theoretical result suggests that when \(m\) is large, we should converge to the original neurons, which we see below. The surprising (and still unexplained) phenomenon is that \(m\) does not need to be much larger than \(m_0\) to see practical global convergence.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-3942" height="259" src="https://francisbach.com/wp-content/uploads/2020/05/ReLU_m5-1024x683.png" width="389"/>Position of \(m = 5\) neurons, plotted as \(|a_i| b_i \in \mathbb{R}^2\) for a two-dimensional problem. The five dotted lines are the directions of the generating neurons. Although \(m\) is large enough to lead to the global optimum, the flow gets stuck in a local optimum.</figure></div>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-3943" height="243" src="https://francisbach.com/wp-content/uploads/2020/05/ReLU_m10-1024x683.png" width="365"/>Position of \(m = 10\) neurons; same setting as above. The flow converges to the global optimum, although \(m\) is not large.</figure></div>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-3944" height="252" src="https://francisbach.com/wp-content/uploads/2020/05/ReLU_m100-1024x683.png" width="379"/>Position of \(m = 100\) neurons; same setting as above. The flow converges to the global optimum, with \(m\) large. See video below.</figure></div>



<figure class="wp-block-video aligncenter justify-text"><video src="https://francisbach.com/wp-content/uploads/2020/05/ReLU_m100.mp4"/>Position of \(m = 100\) neurons; exact same setting as above.</figure>



<h2>Discussion and open problems</h2>



<p class="justify-text">In this blog post, I described theoretical results showing the benefits of overparameterization: when the number of hidden neurons \(m\) tends to infinity, then the corresponding gradient flow converges to the global optimum of the cost function. The proof relies notably on homogeneity properties of the relu activation. </p>



<p class="justify-text">The main weakness of  this result is that is only <em>qualitative</em>: we cannot quantify how big \(m\) need to be to be close to the infinite width limit, or how fast the gradient flow converges to the global optimum. These are still open problems. Additional interesting areas of research are to extend these results to convolutional and/or deep networks.</p>



<p class="justify-text">Now that we know that we can obtain global convergence, I will describe next month the generalization properties when interpolating the training data with an overparameterized relu network [<a href="https://arxiv.org/pdf/2002.04486">16</a>].</p>



<p class="justify-text"><strong>Acknowledgements</strong>. I would like to thank Lénaïc Chizat for producing the nice figures and video of neural networks, proofreading this blog post, and making good clarifying suggestions.</p>



<h2>References</h2>



<p class="justify-text">[1] Sébastien Bubeck. <a href="https://arxiv.org/pdf/1405.4980">Convex Optimization: Algorithms and Complexity</a>. <em>Foundations and Trends in Machine Learning</em>, <em>8</em>(3-4), 231-357, 2015.<br/>[2] Léon Bottou, Frank E. Curtis, Jorge Nocedal. <a href="https://epubs.siam.org/doi/pdf/10.1137/16M1080173">Optimization methods for large-scale machine learning</a>. SIAM Review, 60(2):223-311, 2018.<br/>[3] Francis Bach, Rodolphe Jenatton, Julien Mairal, Guillaume Obozinski. <a href="http://www.di.ens.fr/~fbach/bach_jenatton_mairal_obozinski_FOT.pdf">Optimization with sparsity-inducing penalties</a>. <em>Foundations and Trends in Machine Learning, </em>4(1):1-106, 2012.<br/>[4] Shai Shalev-Shwartz, Shai Ben-David. <a href="https://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/understanding-machine-learning-theory-algorithms.pdf">Understanding machine learning: From theory to algorithms</a>. Cambridge University Press, 2014.<br/>[5] Larry Wasserman. <a href="http://static.stevereads.com/papers_to_read/all_of_statistics.pdf">All of statistics: a concise course in statistical inference</a>. Springer Science &amp; Business Media, 2013.<br/>[6] Bernhard Schölkopf, Alexander J. Smola. Learning with kernels: support vector machines, regularization, optimization, and beyond. MIT press, 2002.<br/>[7] Ali Rahimi and Benjamin Recht. <a href="http://papers.nips.cc/paper/3182-random-features-for-large-scale-kernel-machines.pdf">Random features for large-scale kernel machines</a>. <em>Advances in neural information processing systems</em>, 2008.<br/>[8] Alessandro Rudi, Luigi Carratino, Lorenzo Rosasco. <a href="http://papers.nips.cc/paper/6978-falkon-an-optimal-large-scale-kernel-method.pdf">Falkon: An optimal large scale kernel method</a>. <em>Advances in Neural Information Processing Systems</em>, 2017.<br/>[9] Ian Goodfellow, Yoshua Bengio, Aaron Courville. <a href="https://www.deeplearningbook.org/">Deep learning</a>. MIT Press, 2016.<br/>[10] Xavier Glorot, Antoine Bordes, and Yoshua Bengio. <a href="http://www.jmlr.org/proceedings/papers/v15/glorot11a/glorot11a.pdf">Deep sparse rectifier neural networks</a>. <em>International Conference on Artificial Intelligence and Statistics</em>, 2011.<br/>[11] Francis Bach and Eric Moulines. <a href="http://papers.nips.cc/paper/4900-non-strongly-convex-smooth-stochastic-approximation-with-convergence-rate-o1n.pdf">Non-strongly-convex smooth stochastic approximation with convergence rate O(1/n)</a>. <em>Advances in Neural Information Processing Systems</em>, 2013.<br/>[12] MIkhail Belkin, Daniel Hsu, Siyuan Ma, Soumik Mandal. <a href="https://www.pnas.org/content/pnas/116/32/15849.full.pdf">Reconciling modern machine-learning practice and the classical bias–variance trade-off</a>. <em>Proceedings of the National Academy of Sciences</em>, 116(32), 15849-15854, 2019.<br/>[13] Lénaïc Chizat, Francis Bach. <a href="http://papers.nips.cc/paper/7567-on-the-global-convergence-of-gradient-descent-for-over-parameterized-models-using-optimal-transport.pdf">On the Global Convergence of Gradient Descent for Over-parameterized Models using Optimal Transport</a>. <em>Advances in Neural Information Processing Systems</em>, 2018.<br/>[14] Gabriel Peyré, Marco Cututi. <em><a href="https://arxiv.org/abs/1803.00567">Computational Optimal Transport</a></em>. Foundations and Trends in Machine Learning, 51(1):1–44, 2019.<br/>[15] Lénaïc Chizat, Edouard Oyallon, Francis Bach. <a href="https://papers.nips.cc/paper/8559-on-lazy-training-in-differentiable-programming.pdf">On Lazy Training in Differentiable Programming</a>. <em>Advances in Neural Information Processing Systems</em>, 2019.<br/>[16] Lénaïc Chizat, Francis Bach. <a href="https://arxiv.org/pdf/2002.04486">Implicit Bias of Gradient Descent for Wide Two-layer Neural Networks Trained with the Logistic Loss</a>. Technical report, arXiv:2002.04486, 2020.<br/>[17] Andrew R. Barron. <a href="http://www.stat.yale.edu/~arb4/publications_files/UniversalApproximationBoundsForSuperpositionsOfASigmoidalFunction.pdf">Universal approximation bounds for superpositions of a sigmoidal function</a>. <em>IEEE Transactions on Information theory</em>, <em>39</em>(3), 930-945, 1993.<br/>[18] Yoshua Bengio, Nicolas Le Roux, Pascal Vincent, Olivier Delalleau, Patrice Marcotte. <a href="http://papers.nips.cc/paper/2800-convex-neural-networks.pdf">Convex neural networks</a>. <em>Advances in neural information processing systems</em>, 2006.<br/>[19] Francis Bach. <a href="http://jmlr.org/papers/volume18/14-546/14-546.pdf">Breaking the Curse of Dimensionality with Convex Neural Networks</a>.<strong> </strong><em>Journal of Machine Learning Research</em>, 18(19):1-53, 2017.<br/>[20] Venkatesan Guruswami, Prasad Raghavendra. <a href="https://epubs.siam.org/doi/pdf/10.1137/070685798">Hardness of learning halfspaces with noise</a>. <em>SIAM Journal on Computing</em>, 39(2):742-765, 2009.<br/>[21] Surbhi Goel, Varun Kanade, Adam Klivans, Justin Thaler. <a href="http://proceedings.mlr.press/v65/goel17a/goel17a.pdf">Reliably Learning the ReLU in Polynomial Time</a>. <em>Conference on Learning Theory</em>, 2017.<br/>[22] Atsushi Nitanda, Taiji Suzuki. <a href="https://arxiv.org/pdf/1712.05438">Stochastic particle gradient descent for infinite ensembles</a>. Technical report, arXiv:1712.05438, 2017.<br/>[23] Song Mei, Andrea Montanari, Phan-Minh Nguyen. <a href="https://www.pnas.org/content/pnas/115/33/E7665.full.pdf">A mean field view of the landscape of two-layer neural networks</a>. <em>Proceedings of the National Academy of Sciences</em> 115(33):E7665-E7671, 2018.<br/>[24] Grant M. Rotskoff, Eric Vanden-Eijnden. <a href="https://arxiv.org/pdf/1805.00915">Neural networks as interacting particle systems: Asymptotic convexity of the loss landscape and universal scaling of the approximation error</a>. Technical report, arXiv:1805.00915, 2018.<br/>[25] Luigi Ambrosio, Nicola Gigli, Giuseppe Savaré. <a href="http://www2.stat.duke.edu/~sayan/ambrosio.pdf">Gradient flows: in metric spaces and in the space of probability measures</a>. Springer Science &amp; Business Media, 2008<br/>[26] Filippo Santambrogio. <a href="https://link.springer.com/content/pdf/10.1007/s13373-017-0101-1.pdf">{Euclidean, metric, and Wasserstein} gradient flows: an overview</a>. <em>Bulletin of Mathematical Sciences</em>, <em>7</em>(1), 87-154, 2017.<br/>[27] Itay Safran, Ohad Shamir. <a href="http://proceedings.mlr.press/v80/safran18a/safran18a.pdf">Spurious Local Minima are Common in Two-Layer ReLU Neural Networks</a>. <em>International Conference on Machine Learning</em>, 2018.</p></div>
    </content>
    <updated>2020-06-01T07:32:48Z</updated>
    <published>2020-06-01T07:32:48Z</published>
    <category term="Machine learning"/>
    <author>
      <name>Francis Bach</name>
    </author>
    <source>
      <id>https://francisbach.com</id>
      <link href="https://francisbach.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://francisbach.com" rel="alternate" type="text/html"/>
      <subtitle>Francis Bach</subtitle>
      <title>Machine Learning Research Blog</title>
      <updated>2020-08-26T22:24:39Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://tcsplus.wordpress.com/?p=439</id>
    <link href="https://tcsplus.wordpress.com/2020/05/28/tcs-talk-wednesday-june-3-michael-p-kim-stanford-university/" rel="alternate" type="text/html"/>
    <title>TCS+ talk: Wednesday, June 3 — Michael P. Kim, Stanford University</title>
    <summary>The next TCS+ talk (and penultimate of the season!) will take place this coming Wednesday, June 3th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). Michael Kim from Stanford University will speak about “Learning from Outcomes:  Evidence-Based Rankings” (abstract below). You can reserve a spot as an individual […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The next TCS+ talk (and penultimate of the season!) will take place this coming Wednesday, June 3th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). <strong>Michael Kim</strong> from Stanford University will speak about “<em>Learning from Outcomes:  Evidence-Based Rankings</em>” (abstract below).</p>
<p>You can reserve a spot as an individual or a group to join us live by signing up on <a href="https://sites.google.com/site/plustcs/livetalk/live-seat-reservation">the online form</a>. Due to security concerns, <em>registration is required</em> to attend the interactive talk. (The link to the YouTube livestream will also be posted <a href="https://sites.google.com/site/plustcs/livetalk">on our<br/>
website</a> on the day of the talk, so people who did not sign up will still be able to watch the talk live.) As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/site/plustcs/suggest">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/site/plustcs/">the website</a>.</p>
<blockquote><p>Abstract: In this work, we address the task of ranking members of a population according to their qualifications based on a training set of binary outcome data. A natural approach for ranking is to reduce to prediction: first learn to predict individuals’ “probability” of success; then rank individuals in the order specified by the predictions. A concern with this approach is that such rankings may be vulnerable to manipulation. The rank of an individual depends not only on their own qualification but also on every other individuals’ qualifications, so small inaccuracies in prediction may result in a highly inaccurate and unfair induced ranking. We show how to obtain rankings that satisfy a number of desirable accuracy and fairness criteria, despite the coarseness of binary outcome data.<br/>
We develop two parallel definitions of evidence-based rankings. First, we study a semantic notion of <em>domination-compatibility</em>: if the training data suggest that members of a set <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=fff&amp;fg=444444&amp;s=0" title="S"/> are on-average more qualified than the members of <img alt="T" class="latex" src="https://s0.wp.com/latex.php?latex=T&amp;bg=fff&amp;fg=444444&amp;s=0" title="T"/>, then a ranking that favors <img alt="T" class="latex" src="https://s0.wp.com/latex.php?latex=T&amp;bg=fff&amp;fg=444444&amp;s=0" title="T"/> over <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=fff&amp;fg=444444&amp;s=0" title="S"/> (i.e., where <img alt="T" class="latex" src="https://s0.wp.com/latex.php?latex=T&amp;bg=fff&amp;fg=444444&amp;s=0" title="T"/> dominates <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=fff&amp;fg=444444&amp;s=0" title="S"/>) is blatantly inconsistent with the data, and likely to be discriminatory. Our definition asks for domination-compatibility, not just for a pair of sets (e.g., majority and minority populations), but rather for every pair of sets from a rich collection <img alt="\mathcal{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&amp;bg=fff&amp;fg=444444&amp;s=0" title="\mathcal{C}"/> of subpopulations. The second notion—evidence-consistency—aims at precluding even more general forms of discrimination: the ranking must be justified on the basis of consistency with the expectations for every set in the collection <img alt="\mathcal{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&amp;bg=fff&amp;fg=444444&amp;s=0" title="\mathcal{C}"/>. Somewhat surprisingly, while evidence-consistency is a strictly stronger notion than domination-compatibility when the collection <img alt="\mathcal{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&amp;bg=fff&amp;fg=444444&amp;s=0" title="\mathcal{C}"/> is predefined, the two notions are equivalent when the collection <img alt="\mathcal{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&amp;bg=fff&amp;fg=444444&amp;s=0" title="\mathcal{C}"/> may depend on the ranking itself. Finally, we show a tight connection between evidence-based rankings and multi-calibrated predictors [HKRR’18]. This connection establishes a way to reduce the task of ranking to prediction that ensures strong guarantees of fairness in the resulting ranking.<br/>
Joint work with Cynthia Dwork, Omer Reingold, Guy N. Rothblum, and Gal Yona. Appeared at FOCS 2019.</p></blockquote>
<p> </p></div>
    </content>
    <updated>2020-05-28T23:18:00Z</updated>
    <published>2020-05-28T23:18:00Z</published>
    <category term="Announcements"/>
    <author>
      <name>plustcs</name>
    </author>
    <source>
      <id>https://tcsplus.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://tcsplus.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://tcsplus.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://tcsplus.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://tcsplus.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A carbon-free dissemination of ideas across the globe.</subtitle>
      <title>TCS+</title>
      <updated>2020-08-26T22:24:02Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://theorydish.blog/?p=1701</id>
    <link href="https://theorydish.blog/2020/05/19/incentive-compatible-sensitive-surveys/" rel="alternate" type="text/html"/>
    <title>Incentive Compatible Sensitive Surveys</title>
    <summary>Crucial decisions are increasingly being made by automated machine learning algorithms. These algorithms rely on data, and without high quality data, the resulting decisions may be inaccurate and/or unfair. In some cases, data is readily available: for example, location data passively collected by smartphones. In other cases, data may be difficult to obtain by automated means, and it is necessary to directly survey the population. However, individuals are not always motivated to take surveys if they receive no benefit. Offering a monetary reward may incentivize some individuals to participate, but there is a problem with this approach: what if an individual’s data is correlated with their willingness to take the survey? For concreteness, imagine that you are a health administrator trying to estimate the average weight in a population. This is a sensitive attribute that individuals may be reluctant to disclose, especially if their weight is not considered healthy. A generic survey may yield disproportionately more respondents with “healthy” weights, and thus may result an an inaccurate estimate (see, e.g, Shields et al., 2011). In this post, we discuss three papers which propose solutions to this problem through the lens of mechanism design. The idea is to carefully design payments [...]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-1703" height="303" src="https://theorydish.files.wordpress.com/2020/05/survey.jpg?w=764" width="580"/></figure></div>

<p>Crucial decisions are increasingly being made by automated machine learning algorithms. These algorithms rely on data, and without high quality data, the resulting decisions may be inaccurate and/or unfair. In some cases, data is readily available: for example, location data passively collected by smartphones. In other cases, data may be difficult to obtain by automated means, and it is necessary to directly survey the population.</p>

<p>However, individuals are not always motivated to take surveys if they receive no benefit. Offering a monetary reward may incentivize some individuals to participate, but there is a problem with this approach: what if an individual’s data is correlated with their willingness to take the survey?</p>

<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-1708" height="184" src="https://theorydish.files.wordpress.com/2020/05/correlation.png?w=459" width="457"/></figure></div>

<p>For concreteness, imagine that you are a health administrator trying to estimate the average weight in a population. This is a sensitive attribute that individuals may be reluctant to disclose, especially if their weight is not considered healthy. A generic survey may yield disproportionately more respondents with “healthy” weights, and thus may result an an inaccurate estimate (see, e.g, Shields et al., 2011).</p>

<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-1707" height="234" src="https://theorydish.files.wordpress.com/2020/05/scale.jpeg?w=1024" width="408"/></figure></div>

<p>In this post, we discuss three papers which propose solutions to this problem through the lens of <em>mechanism design</em>. The idea is to carefully design payments so that we received an unbiased sample, leading to a hopefully accurate estimate.</p>

<h2><strong>Model</strong></h2>

<p>We use <img alt="z_i" class="latex" src="https://s0.wp.com/latex.php?latex=z_i&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="z_i"/> to denote agent <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="i"/>‘s data (e.g., her weight). We assume that each agent also has a personal cost <img alt="c_i" class="latex" src="https://s0.wp.com/latex.php?latex=c_i&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="c_i"/>, representing her level of reluctance to reveal her data. Agent <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="i"/> is willing to reveal <img alt="z_i" class="latex" src="https://s0.wp.com/latex.php?latex=z_i&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="z_i"/> if and only if she receives a payment of at least <img alt="c_i" class="latex" src="https://s0.wp.com/latex.php?latex=c_i&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="c_i"/>. Our goal is to allocate higher payments to agents with higher <img alt="c_i" class="latex" src="https://s0.wp.com/latex.php?latex=c_i&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="c_i"/>‘s, in order to get an unbiased sample. However, we also must obey an budget constraint: we cannot spend more than <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="B"/> total. The solution is to transact non-deterministically: with some probability, offer to purchase an agent’s data. Agents with higher costs will receive higher payments, but lower transaction probabilities.</p>

<p>We assume that agents are drawn at random independently from some distribution. Our crucial assumption is that we known the marginal distribution of agent costs, which we denote <img alt="\mathcal{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\mathcal{F}"/> (we will explore later what happens when this assumption is removed). However, we do not know the distribution of <img alt="z_i" class="latex" src="https://s0.wp.com/latex.php?latex=z_i&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="z_i"/>, and that distribution can be arbitrarily correlated with <img alt="\mathcal{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\mathcal{F}"/>. As mentioned above, one might expect agents with less “desirable” <img alt="z_i" class="latex" src="https://s0.wp.com/latex.php?latex=z_i&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="z_i"/>‘s may have higher costs, but one can imagine more complex correlations as well.</p>

<p>Our mechanisms consist of two parts: an <em>allocation rule</em> <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="A"/>, and a <em>payment rule</em> <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="P"/>. Given <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="A"/> and <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="P"/>, the mechanism works as follows:</p>

<ol><li>Ask each agent <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="i"/> to report <img alt="c_i" class="latex" src="https://s0.wp.com/latex.php?latex=c_i&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="c_i"/>. Let <img alt="c" class="latex" src="https://s0.wp.com/latex.php?latex=c&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="c"/> denote the actual reported cost.</li><li>With probability <img alt="A(c)" class="latex" src="https://s0.wp.com/latex.php?latex=A%28c%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="A(c)"/>, we purchase the agent’s data and pay her <img alt="P(c)" class="latex" src="https://s0.wp.com/latex.php?latex=P%28c%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="P(c)"/>. With probability <img alt="1 - A(c)" class="latex" src="https://s0.wp.com/latex.php?latex=1+-+A%28c%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="1 - A(c)"/>, we do not buy the data, and no payment is made.</li><li>At the end, use the data we learned to form an estimate of the population average of <img alt="z_i" class="latex" src="https://s0.wp.com/latex.php?latex=z_i&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="z_i"/>. Let <img alt="\bar{z}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbar%7Bz%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\bar{z}"/> denote our estimate.</li></ol>

<p>In this model, agent <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="i"/>‘s expected utility for reporting <img alt="c" class="latex" src="https://s0.wp.com/latex.php?latex=c&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="c"/> is <img alt="u_i(c) = A(c) (P(c) - c_i)" class="latex" src="https://s0.wp.com/latex.php?latex=u_i%28c%29+%3D+A%28c%29+%28P%28c%29+-+c_i%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="u_i(c) = A(c) (P(c) - c_i)"/>.</p>

<p>We have four main requirements:</p>

<ol><li><strong>Truthfulness. </strong>It should be in each agent’s best interest to truthfully report <img alt="c_i" class="latex" src="https://s0.wp.com/latex.php?latex=c_i&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="c_i"/>.</li><li><strong>Individual rationality. </strong>Agents should not receive negative utility if they are honest, i.e., we should have <img alt="P(c_i) \ge c_i" class="latex" src="https://s0.wp.com/latex.php?latex=P%28c_i%29+%5Cge+c_i&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="P(c_i) \ge c_i"/> for all <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="i"/>.</li><li><strong>Budget constrained. </strong>Our total expected payment should not exceed <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="B"/>, i.e., <img alt="\mathbb{E}[\sum_i A(c_i) P(c_i)] \le B" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BE%7D%5B%5Csum_i+A%28c_i%29+P%28c_i%29%5D+%5Cle+B&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\mathbb{E}[\sum_i A(c_i) P(c_i)] \le B"/>.</li><li><strong>Unbiased. </strong>Our estimate isn’t consistently too high or too low. Specifically, the expected value of our estimate should be equal to the true average, i.e., <img alt="\mathbb{E}[\bar{z}] = \mathbb{E}[z_i]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BE%7D%5B%5Cbar%7Bz%7D%5D+%3D+%5Cmathbb%7BE%7D%5Bz_i%5D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\mathbb{E}[\bar{z}] = \mathbb{E}[z_i]"/>.</li></ol>

<p>Lack of bias doesn’t mean that our estimate is accurate, however. To this end, our primary goal is to <strong>minimize the variance</strong>, subject to the mechanism obeying the four above criteria. We evaluate variance via a worst-case framework: given a mechanism, we wish minimize the variance with respect to the worst-case distribution of agents for that mechanism. The idea is that the distribution of <img alt="z_i" class="latex" src="https://s0.wp.com/latex.php?latex=z_i&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="z_i"/>‘s is not known to the mechanism, so we require it to perform well for all distributions.</p>

<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-1729" height="203" src="https://theorydish.files.wordpress.com/2020/05/goal.jpg?w=970" width="438"/>Goal.</figure></div>

<p>When we refer to the “optimal” mechanism, we mean minimum variance, subject to being truthful, individually rational, budget constrained, and unbiased (henceforth TIBU).</p>

<p><strong>The Horvitz Thomspon Estimator</strong></p>

<p>Once we have learned the <img alt="z_i" class="latex" src="https://s0.wp.com/latex.php?latex=z_i&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="z_i"/>‘s, how do we actual form an estimate of the mean? Luckily for us, this question has a simple answer. If we restrict ourselves to linear unbiased estimators, there is a unique way to do this, known as the <em>Horvitz-Thompson estimator</em>:</p>

<p><img alt="\bar{z} = \displaystyle\sum\limits_i \cfrac{z_i}{A(c_i)}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbar%7Bz%7D+%3D+%5Cdisplaystyle%5Csum%5Climits_i+%5Ccfrac%7Bz_i%7D%7BA%28c_i%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\bar{z} = \displaystyle\sum\limits_i \cfrac{z_i}{A(c_i)}"/></p>

<p>Thus our task is simply to choose <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="A"/> and <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="P"/>.</p>

<h2>Approach #1</h2>

<p>This model was first considered by Roth and Schoenebeck (2012). They are able to characterize a mechanism which is TIBU and has variance at most <img alt="1/n" class="latex" src="https://s0.wp.com/latex.php?latex=1%2Fn&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="1/n"/> more than the optimal variance, where <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="n"/> is the number of agents. However, they do make the strong assumption that <img alt="z_i" class="latex" src="https://s0.wp.com/latex.php?latex=z_i&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="z_i"/> is either 0 or 1.</p>

<p>Their approach relies on <em>Take-It-Or-Leave-It</em> mechanisms. Such a mechanism is defined by a distribution $G$ over the positive real numbers, and works as follows:</p>

<ol><li>Each agent <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="i"/> reports a cost <img alt="c" class="latex" src="https://s0.wp.com/latex.php?latex=c&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="c"/>.</li><li>Sample a payment <img alt="p" class="latex" src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="p"/> from <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="G"/>.</li><li>If <img alt="p \ge c" class="latex" src="https://s0.wp.com/latex.php?latex=p+%5Cge+c&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="p \ge c"/>, buy the agent’s data with payment <img alt="p" class="latex" src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="p"/>. If <img alt="p &lt; c" class="latex" src="https://s0.wp.com/latex.php?latex=p+%3C+c&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="p &lt; c"/>, do not buy the agent’s data.</li></ol>

<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img alt="" height="212" src="https://pbs.twimg.com/media/EDzLmHAWwAAEPkl.jpg" width="293"/></figure></div>

<p>This amounts to an allocation rule <img alt="A(c) = 1 - \text{Pr}[p\ge c]" class="latex" src="https://s0.wp.com/latex.php?latex=A%28c%29+%3D+1+-+%5Ctext%7BPr%7D%5Bp%5Cge+c%5D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="A(c) = 1 - \text{Pr}[p\ge c]"/>, and a payment rule <img alt="P(c)" class="latex" src="https://s0.wp.com/latex.php?latex=P%28c%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="P(c)"/> equal to the distribution <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="G"/> conditioned on being at least <img alt="c" class="latex" src="https://s0.wp.com/latex.php?latex=c&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="c"/>. The authors show that these mechanisms are fully general, i.e., any allocation and payment rule can be implemented by a Take-It-Or-Leave-It mechanism.</p>

<p>The proof of their main result is primarily based on using the calculus of variations to optimize over the space of distributions <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="G"/>. The paper contains some additional results, for example regarding an alternate model where we wish to minimize the budget, but that is outside the scope of this blog post.</p>

<h2>Approach #2</h2>

<p>Although the above result is a great step, it leaves room for improvement. First of all, the assumption that <img alt="z_i" class="latex" src="https://s0.wp.com/latex.php?latex=z_i&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="z_i"/> is binary is quite strong, and does not apply to our running example of body weight. Secondly, their mechanism does not quite achieve the optimal variance. Chen et al. (2018) remedy both of these concerns. That is, they allow <img alt="z_i" class="latex" src="https://s0.wp.com/latex.php?latex=z_i&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="z_i"/> to be any real number, and they characterize the TIBU mechanism with optimal variance. Their result also generalizes to more complex statistical estimates, not just the average <img alt="z_i" class="latex" src="https://s0.wp.com/latex.php?latex=z_i&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="z_i"/>, and it holds for both continuous and discrete agent distributions.</p>

<p>The approach of Chen et al. (2018) is based on two primary ideas. First, they show that any monotone allocation rule (i.e., we are always less likely to purchase data from an agent with higher cost) can be implemented in a TIBU fashion by a unique payment rule. Thus we only need to identify the optimal allocation rule. (This is similar to the standard result from auction theory about implementable monotone allocation rules (Myerson 1981).)</p>

<p>The second idea is to view the problem as a zero-sum game between ourselves (the mechanism designer) and an adversary who chooses the distribution of agents. Given a distribution, we choose an allocation rule to minimize the variance, and given an allocation rule, the adversary chooses a distribution to maximize the variance.</p>

<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img alt="" height="297" src="https://i2.wp.com/marketbusinessnews.com/wp-content/uploads/2016/08/Zero-Sum-Game.jpg?fit=511%2C521&amp;ssl=1&amp;resize=1200%2C1223.4833659491" width="292"/></figure></div>

<p>The authors are able to solve for the equilibrium of this game and thus identify the TIBU mechanism with minimum possible variance.</p>

<h2>Approach #3</h2>

<p>Approach #2 gave us our desired result: a minimum variance mechanism subject to our four desired properties (TIBU), for any distribution of <img alt="z_i" class="latex" src="https://s0.wp.com/latex.php?latex=z_i&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="z_i"/>‘s. But we are still making a very strong assumption: that we know the distribution of agent costs.</p>

<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-1766" height="230" src="https://theorydish.files.wordpress.com/2020/05/prior.png?w=500" width="427"/></figure></div>

<p>Chen and Zheng (2019) do away with this assumption in a follow-up paper. They consider a model where the mechanism has no prior information on the distribution of costs (or on the distribution of data), and $n$ agents arrive one-by-one in a uniformly random order. Each agent reports a cost, and we decide whether to buy her data, and what to pay her. In order to price well, we need to learn the cost distribution, but we must do this while simultaneously making irrevocable purchasing decisions. The main result is a TIBU mechanism with variance at most a constant factor worse than optimal.</p>

<p>The authors note that after each step <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="i"/>, the reported costs up to that point induce an empirical cost distribution <img alt="\mathcal{F}_i" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BF%7D_i&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\mathcal{F}_i"/>. Using the results of Chen et al. (2018), we can determine the optimal mechanism for <img alt="\mathcal{F}_i" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BF%7D_i&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\mathcal{F}_i"/>. The basic idea is to use that mechanism for the current step, learn a new agent cost <img alt="c_i" class="latex" src="https://s0.wp.com/latex.php?latex=c_i&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="c_i"/> (note that the agent reports <img alt="c_i" class="latex" src="https://s0.wp.com/latex.php?latex=c_i&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="c_i"/> regardless of whether we purchase her data) and then update our empirical distribution accordingly. (The authors actually end up using an approximately optimal allocation rule, but the idea is the same.) The mechanism also uses more budget in the earlier rounds, to make up for the pricing being less accurate.</p>

<h2>Discussion</h2>

<p>In this post, we considered the problem of surveying a sensitive attribute where an agent’s data may be correlated with their willingness to participate. We discussed three different approaches, all of which rely of giving higher payments to agents with higher costs, in order to incentivize them to participate and to obtain an unbiased estimate. The final approach was able to give a truthful, individually rational, budget feasible, and unbiased mechanism with approximately optimal variance, without making any prior assumptions on the distribution of agents.</p>

<p>However, all three of the approaches assume that agents cannot lie about the data. This is reasonable for some attributes, such as a body weight, where an agent can be asked to step onto a physical scale. However, requiring participants come in person to a particular location will certainly lead to less engagement. Furthermore, for other sensitive attributes, there may not be a verifiable way to obtain the data. Future work could investigate alternative models where this assumption is not necessary. For example, perhaps agents do not maliciously lie, but rather are simply inaccurate at reporting their own attributes. For example, research has demonstrated that people consistently over-report height and under-report weight (e.g., Gorber et al., 2007). Could a mechanism learn the pattern of inaccuracy and compensate for that to still obtain an unbiased estimate?</p>

<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-1775" height="243" src="https://theorydish.files.wordpress.com/2020/05/bias.png?w=1024" width="317"/></figure></div>

<h2><strong>References</strong></h2>

<ol><li>Yiling Chen, Nicole Immorlica, Brendan Lucier, Vasilis Syrgkanis, and Juba Ziani. “Optimal data acquisition for statistical estimation.” In <em>Proceedings of the 2018 ACM Conference on Economics and Computation</em>. 2018.</li><li>Yiling Chen and Shuran Zheng. “Prior-free data acquisition for accurate statistical estimation.” <em>Proceedings of the 2019 ACM Conference on Economics and Computation</em>. 2019.</li><li>Sarah Connor Gorber, Mark S. Tremplay, David Moher, and B. Gorber (2007). A comparison of direct vs. self‐report measures for assessing height, weight and body mass index: a systematic review. <em>Obesity reviews</em>, <em>8</em>(4), 307-326.</li><li>Roger Myerson. Optimal auction design. Mathematics of Operations Research, 6(1):58–73. 1981.</li><li>Aaron Roth and Grant Schoenebeck. “Conducting truthful surveys, cheaply.” <em>Proceedings of the 2012 ACM Conference on Electronic Commerce</em>. 2012.</li><li>Margot Shields, Sarah Connor Gorber, Ian Janssen, and Mark S. Tremblay. (2011). Bias in self-reported estimates of obesity in Canadian health surveys: an update on correction equations for adults. <em>Health Reports</em>, <em>22</em>(3), 35.</li></ol>

<p> </p></div>
    </content>
    <updated>2020-05-19T20:40:34Z</updated>
    <published>2020-05-19T20:40:34Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>bplaut</name>
    </author>
    <source>
      <id>https://theorydish.blog</id>
      <logo>https://theorydish.files.wordpress.com/2017/03/cropped-nightdish1.jpg?w=32</logo>
      <link href="https://theorydish.blog/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://theorydish.blog" rel="alternate" type="text/html"/>
      <link href="https://theorydish.blog/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://theorydish.blog/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Stanford's CS Theory Research Blog</subtitle>
      <title>Theory Dish</title>
      <updated>2020-08-26T22:24:12Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://theorydish.blog/?p=1781</id>
    <link href="https://theorydish.blog/2020/05/19/nominations-for-tcs-women-rising-star-talks-at-stoc/" rel="alternate" type="text/html"/>
    <title>Nominations for TCS Women Rising Star talks at STOC</title>
    <summary>Directly from the organizers: ———– Dear colleagues, We invite you to nominate speakers for TCS Women Rising Star talks at STOC 2019, which are planned as part of our virtual TCS Women Spotlight Workshop. To be eligible, your nominee has to be a female or a minority researcher working in theoretical computer science (all topics represented at STOC are welcome) and has to be a graduating PhD student or a postdoc. You can make your nomination by filling this form by May 28th: https://forms.gle/R9nmit62ESA6V9vv6 STOC 2020 workshops will happen between June 23 and 25, with exact day/time TBD. You can see the list of speakers from last year here: https://sigact.org/tcswomen/2nd-tcs-women-meeting/tcs-women-2019/ Looking forward to your nominations and to seeing you at the our TCS Women Spotlight Workshop, Barna Saha, Virginia Vassilevska Williams, and Sofya Raskhodnikova</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div>Directly from the organizers:</div>
<div/>
<div>———–</div>
<div/>
<div/>
<div>Dear colleagues,</div>
<div/>
<div>We invite you to nominate speakers for TCS Women Rising Star talks at STOC 2019, which are planned as part of our virtual TCS Women Spotlight Workshop. To be eligible, your nominee has to be a female or a minority researcher working in theoretical computer science (all topics represented at STOC are welcome) and has to be a graduating PhD student or a postdoc. You can make your nomination by filling this form by May 28th:</div>
<div/>
<div><a href="https://forms.gle/R9nmit62ESA6V9vv6" rel="noopener" target="_blank">https://forms.gle/R9nmit62ESA6V9vv6</a></div>
<div/>
<div>STOC 2020 workshops will happen between June 23 and 25, with exact day/time TBD.</div>
<div/>
<div>You can see the list of speakers from last year here:</div>
<div><a href="https://sigact.org/tcswomen/2nd-tcs-women-meeting/tcs-women-2019/" rel="noopener" target="_blank">https://sigact.org/tcswomen/2nd-tcs-women-meeting/tcs-women-2019/</a></div>
<div/>
<div>Looking forward to your nominations and to seeing you at the our TCS Women Spotlight Workshop,</div>
<div>Barna Saha, Virginia Vassilevska Williams, and Sofya Raskhodnikova</div></div>
    </content>
    <updated>2020-05-19T20:39:28Z</updated>
    <published>2020-05-19T20:39:28Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Omer Reingold</name>
    </author>
    <source>
      <id>https://theorydish.blog</id>
      <logo>https://theorydish.files.wordpress.com/2017/03/cropped-nightdish1.jpg?w=32</logo>
      <link href="https://theorydish.blog/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://theorydish.blog" rel="alternate" type="text/html"/>
      <link href="https://theorydish.blog/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://theorydish.blog/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Stanford's CS Theory Research Blog</subtitle>
      <title>Theory Dish</title>
      <updated>2020-08-26T22:24:12Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2020/05/18/siam-symposium-on-simplicity-in-algorithms/</id>
    <link href="https://cstheory-events.org/2020/05/18/siam-symposium-on-simplicity-in-algorithms/" rel="alternate" type="text/html"/>
    <title>SIAM Symposium on Simplicity in Algorithms</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">January 11-12, 2021 Westin Alexandria Old Town, Alexandria, Virginia, U.S. https://www.siam.org/conferences/cm/conference/sosa21 Submission deadline: August 12, 2020 Registration deadline: December 7, 2020 Symposium on Simplicity in Algorithms is a conference in theoretical computer science dedicated to advancing algorithms research by promoting simplicity and elegance in the design and analysis of algorithms. The benefits of simplicity are … <a class="more-link" href="https://cstheory-events.org/2020/05/18/siam-symposium-on-simplicity-in-algorithms/">Continue reading <span class="screen-reader-text">SIAM Symposium on Simplicity in Algorithms</span></a></div>
    </summary>
    <updated>2020-05-18T09:15:31Z</updated>
    <published>2020-05-18T09:15:31Z</published>
    <category term="other"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2020-08-26T22:24:08Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://tcsplus.wordpress.com/?p=435</id>
    <link href="https://tcsplus.wordpress.com/2020/05/14/tcs-talk-wednesday-may-20-mark-bun-boston-university/" rel="alternate" type="text/html"/>
    <title>TCS+ talk: Wednesday, May 20 — Mark Bun, Boston University</title>
    <summary>The next TCS+ talk will take place this coming Wednesday, May 20th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). Mark Bun from Boston University will speak about “An Equivalence between Private Classification and Online Predictability” (abstract below). You can reserve a spot as an individual or a […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The next TCS+ talk will take place this coming Wednesday, May 20th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). <strong>Mark Bun</strong> from Boston University will speak about “<em>An Equivalence between Private Classification and Online Predictability</em>” (abstract below).</p>
<p>You can reserve a spot as an individual or a group to join us live by signing up on <a href="https://sites.google.com/site/plustcs/livetalk/live-seat-reservation">the online form</a>. Due to security concerns, <em>registration is required</em> to attend the interactive talk. (The link to the YouTube livestream will also be posted <a href="https://sites.google.com/site/plustcs/livetalk">on our website</a> on the day of the talk, so people who did not sign up will still be able to watch the talk live.) As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/site/plustcs/suggest">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/site/plustcs/">the website</a>.</p>
<blockquote><p>Abstract: We prove that every concept class with finite Littlestone dimension can be learned by an (approximate) differentially-private algorithm. The converse direction was shown in recent work of Alon, Livni, Malliaris, and Moran, STOC ’19. Together these two results show that a class of functions is privately learnable if and only if it is learnable in the mistake-bound model of online learning. To establish our result, we introduce “global stability,” a new notion of algorithmic stability for learning algorithms that we show can always be satisfied when learning classes of finite Littlestone dimension.</p></blockquote>
<p> </p></div>
    </content>
    <updated>2020-05-14T18:04:41Z</updated>
    <published>2020-05-14T18:04:41Z</published>
    <category term="Announcements"/>
    <author>
      <name>plustcs</name>
    </author>
    <source>
      <id>https://tcsplus.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://tcsplus.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://tcsplus.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://tcsplus.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://tcsplus.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A carbon-free dissemination of ideas across the globe.</subtitle>
      <title>TCS+</title>
      <updated>2020-08-26T22:24:02Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://theorydish.blog/?p=1688</id>
    <link href="https://theorydish.blog/2020/05/14/pride-and-prejudice-from-research-to-practice/" rel="alternate" type="text/html"/>
    <title>Pride and Prejudice: From Research to Practice</title>
    <summary>Despite (or because of) being a devoted theoretician, I truly enjoy every occasion when theory influences practice. I therefore felt quite a bit of satisfaction when our rather recent work, in the context of algorithmic fairness (with Úrsula Hébert-Johnson, Michael P. Kim and Guy N. Rothblum), found an application for predicting COVID-19 complications. Researchers in Israel, in collaboration with Israel’s biggest health-care provider, adapted a refined model for predicting flu complications to a model for predicting COVID-19 complications.  At the time, only very limited data from China were available (marginal statistics).  This is where our work came in (following several past empiric studies of the method):  the team applied our algorithm to improve the accuracy of predictions across various subpopulations (as part of an immense research and engineering effort). Now that there is (unfortunately) more data, it seems that the predictor exhibited surprisingly good performance (surprising, due to the poor training data).  See a manuscript here, an interview here and a more technical talk here (starting at minute 36 roughly). The predictor was applied with the appropriate cautiousness to inform and advise patients. But this is also an example of the gravity of decisions by researchers and software developers. Taking [...]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Despite (or because of) being a devoted theoretician, I truly enjoy every occasion when theory influences practice. I therefore felt quite a bit of satisfaction when our <a href="https://arxiv.org/abs/1711.08513">rather recent work</a>, in the context of algorithmic fairness (with Úrsula Hébert-Johnson, Michael P. Kim and Guy N. Rothblum), found an application for predicting COVID-19 complications. Researchers in Israel, in collaboration with Israel’s biggest health-care provider, adapted a refined model for predicting flu complications to a model for predicting COVID-19 complications.  At the time, only very limited data from China were available (marginal statistics).  This is where our work came in (following several past empiric studies of the method):  the team applied our algorithm to improve the accuracy of predictions across various subpopulations (as part of an immense research and engineering effort). Now that there is (unfortunately) more data, it seems that the predictor exhibited surprisingly good performance (surprising, due to the poor training data).  See a <a href="https://www.medrxiv.org/content/10.1101/2020.04.23.20076976v1">manuscript</a> here, an interview <a href="https://www.youtube.com/watch?v=r_alyuZULYI">here</a> and a more technical talk <a href="https://www.youtube.com/watch?v=weaRmSVA3yM">here</a> (starting at minute 36 roughly). The predictor was applied with the appropriate cautiousness to inform and advise patients.</p>
<p>But this is also an example of the gravity of decisions by researchers and software developers. Taking it to extreme, imagine a predictor that is used to determine which patients are denied treatment in an overwhelmed hospital. The booming research area of algorithmic fairness sees a very short turnover from research ideas (in many areas) to deployment. In an ideal world, it would have been much better to first have a couple of decades to develop the computational foundations of algorithmic fairness, before the practical need arose. But in the real world, the huge scale of algorithmic decision making creates immense demand for solutions. Industry, as well as policy and law makers are unlikely to wait decades or even years, nor is it clear that they should. From my perspective, this reality underscores the urgency for <em>principled</em> and <em>deliberate</em> research – rather than <em>hasty</em> research – continuously developing the foundations of algorithmic fairness and offering answers to real-world challenges.</p></div>
    </content>
    <updated>2020-05-14T17:32:17Z</updated>
    <published>2020-05-14T17:32:17Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Omer Reingold</name>
    </author>
    <source>
      <id>https://theorydish.blog</id>
      <logo>https://theorydish.files.wordpress.com/2017/03/cropped-nightdish1.jpg?w=32</logo>
      <link href="https://theorydish.blog/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://theorydish.blog" rel="alternate" type="text/html"/>
      <link href="https://theorydish.blog/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://theorydish.blog/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Stanford's CS Theory Research Blog</subtitle>
      <title>Theory Dish</title>
      <updated>2020-08-26T22:24:11Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2020/05/12/ideal-workshop-on-estimation-of-network-processes-and-information-diffusion/</id>
    <link href="https://cstheory-events.org/2020/05/12/ideal-workshop-on-estimation-of-network-processes-and-information-diffusion/" rel="alternate" type="text/html"/>
    <title>IDEAL Workshop on Estimation of Network Processes and Information Diffusion</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">May 14, 2020 Virtual https://www.ideal.northwestern.edu/events/estimation-of-network-processes-and-information-diffusion/?fbclid=IwAR3HRiqCz8zTQfHt46hF-VF9PHE2F1v4uvQ6V_ggxmzKqFvromZXhVOOygY Many important dynamic processes are determined by an underlying network structure. Examples include the spread of epidemics, the dynamics of public opinions, the diffusion of information about social programs, and biological processes such as neural spike trains. Data about these processes is becoming increasingly available which has lead to a … <a class="more-link" href="https://cstheory-events.org/2020/05/12/ideal-workshop-on-estimation-of-network-processes-and-information-diffusion/">Continue reading <span class="screen-reader-text">IDEAL Workshop on Estimation of Network Processes and Information Diffusion</span></a></div>
    </summary>
    <updated>2020-05-12T03:47:26Z</updated>
    <published>2020-05-12T03:47:26Z</published>
    <category term="workshop"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2020-08-26T22:24:08Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://theorydish.blog/?p=1693</id>
    <link href="https://theorydish.blog/2020/05/10/weve-got-wit-and-they-got-talent/" rel="alternate" type="text/html"/>
    <title>We’ve got WIT and they got Talent</title>
    <summary>The wonderful Women in Theory is, like so many other events this year, virtual in 2020 (physical meeting postponed to 2021). And it is happening today! The virtual meeting lets our WIT show that their talents go beyond science. Highly recommended clip! I’ve been watching on loop 🙂</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The wonderful <a href="https://theorydish.blog/2020/01/09/women-in-theory-2018-call-for-application-2/">Women in Theory</a> is, like so many other events this year, virtual in 2020 (physical meeting <a href="https://womenintheory.wordpress.com/">postponed to 2021)</a>. And it is happening today! The virtual meeting lets our WIT show that their talents go beyond science. <a href="https://www.youtube.com/watch?v=4Wl-3kadvgw">Highly recommended clip</a>! I’ve been watching on loop <img alt="&#x1F642;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f642.png" style="height: 1em;"/></p></div>
    </content>
    <updated>2020-05-10T17:41:07Z</updated>
    <published>2020-05-10T17:41:07Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Omer Reingold</name>
    </author>
    <source>
      <id>https://theorydish.blog</id>
      <logo>https://theorydish.files.wordpress.com/2017/03/cropped-nightdish1.jpg?w=32</logo>
      <link href="https://theorydish.blog/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://theorydish.blog" rel="alternate" type="text/html"/>
      <link href="https://theorydish.blog/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://theorydish.blog/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Stanford's CS Theory Research Blog</subtitle>
      <title>Theory Dish</title>
      <updated>2020-08-26T22:24:11Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://tcsplus.wordpress.com/?p=430</id>
    <link href="https://tcsplus.wordpress.com/2020/05/08/430/" rel="alternate" type="text/html"/>
    <title>TCS+ talk: Wednesday, May 13 — Sahil Singla, Princeton University and IAS</title>
    <summary>The next TCS+ talk will take place this coming Wednesday, May 13th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). Sahil Singla from Princeton University and IAS will speak about “Online Vector Balancing and Geometric Discrepancy” (abstract below). You can reserve a spot as an individual or a […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The next TCS+ talk will take place this coming Wednesday, May 13th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). <strong>Sahil Singla</strong> from Princeton University and IAS will speak about “<em>Online Vector Balancing and Geometric Discrepancy</em>” (abstract below).</p>
<p>You can reserve a spot as an individual or a group to join us live by signing up on <a href="https://sites.google.com/site/plustcs/livetalk/live-seat-reservation">the online form</a>. Due to security concerns, <em>registration is required</em> to attend the interactive talk. (The link to the YouTube livestream will also be posted <a href="https://sites.google.com/site/plustcs/livetalk">on our website</a> on the day of the talk, so people who did not sign up will still be able to watch the talk live.) As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/site/plustcs/suggest">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/site/plustcs/">the website</a>.</p>
<blockquote><p>Abstract: We consider an online vector balancing question where <img alt="T" class="latex" src="https://s0.wp.com/latex.php?latex=T&amp;bg=fff&amp;fg=444444&amp;s=0" title="T"/> vectors, chosen from an arbitrary distribution over <img alt="[-1,1]^n" class="latex" src="https://s0.wp.com/latex.php?latex=%5B-1%2C1%5D%5En&amp;bg=fff&amp;fg=444444&amp;s=0" title="[-1,1]^n"/>, arrive one-by-one and must be immediately given a <img alt="\{+1,-1\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B%2B1%2C-1%5C%7D&amp;bg=fff&amp;fg=444444&amp;s=0" title="\{+1,-1\}"/> sign. The goal is to keep the discrepancy—the <img alt="\ell_{\infty}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell_%7B%5Cinfty%7D&amp;bg=fff&amp;fg=444444&amp;s=0" title="\ell_{\infty}"/>-norm of any signed prefix-sum—as small as possible. A concrete example of this question is the online interval discrepancy problem where <img alt="T" class="latex" src="https://s0.wp.com/latex.php?latex=T&amp;bg=fff&amp;fg=444444&amp;s=0" title="T"/> points are sampled one-by-one uniformly in the unit interval <img alt="[0,1]" class="latex" src="https://s0.wp.com/latex.php?latex=%5B0%2C1%5D&amp;bg=fff&amp;fg=444444&amp;s=0" title="[0,1]"/>, and the goal is to immediately color them <img alt="\{+1,-1\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B%2B1%2C-1%5C%7D&amp;bg=fff&amp;fg=444444&amp;s=0" title="\{+1,-1\}"/> such that every sub-interval remains always nearly balanced. As random coloring incurs <img alt="\Omega(T^{1/2})" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega%28T%5E%7B1%2F2%7D%29&amp;bg=fff&amp;fg=444444&amp;s=0" title="\Omega(T^{1/2})"/> discrepancy, while the worst-case offline bounds are <img alt="\Theta(\sqrt{n \log (T/n)})" class="latex" src="https://s0.wp.com/latex.php?latex=%5CTheta%28%5Csqrt%7Bn+%5Clog+%28T%2Fn%29%7D%29&amp;bg=fff&amp;fg=444444&amp;s=0" title="\Theta(\sqrt{n \log (T/n)})"/> for vector balancing and 1 for interval balancing, a natural question is whether one can (nearly) match the offline bounds in the online setting for these problems. One must utilize the stochasticity as in the worst-case scenario it is known that discrepancy is <img alt="\Omega(T^{1/2})" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega%28T%5E%7B1%2F2%7D%29&amp;bg=fff&amp;fg=444444&amp;s=0" title="\Omega(T^{1/2})"/> for any online algorithm.</p>
<p>In this work, we introduce a new framework that allows us to handle online vector balancing even when the input distribution has dependencies across coordinates. In particular, this lets us obtain a <img alt="\textrm{poly}(n, \log T)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctextrm%7Bpoly%7D%28n%2C+%5Clog+T%29&amp;bg=fff&amp;fg=444444&amp;s=0" title="\textrm{poly}(n, \log T)"/> bound for online vector balancing under arbitrary input distributions, and a <img alt="\textrm{poly}\log (T)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctextrm%7Bpoly%7D%5Clog+%28T%29&amp;bg=fff&amp;fg=444444&amp;s=0" title="\textrm{poly}\log (T)"/> bound for online interval discrepancy. Our framework is powerful enough to capture other well-studied geometric discrepancy problems; e.g., we obtain a <img alt="\textrm{poly}(\log^d (T))" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctextrm%7Bpoly%7D%28%5Clog%5Ed+%28T%29%29&amp;bg=fff&amp;fg=444444&amp;s=0" title="\textrm{poly}(\log^d (T))"/> bound for the online <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=fff&amp;fg=444444&amp;s=0" title="d"/>-dimensional Tusnády’s problem. All our bounds are tight up to polynomial factors.</p>
<p>A key new technical ingredient in our work is an anti-concentration inequality for sums of pairwise uncorrelated random variables, which might also be of independent interest.</p>
<p>Based on joint works with Nikhil Bansal, Haotian Jiang, Janardhan Kulkarni, and Makrand Sinha. Part of this work appears in STOC 2020 and is available at <a href="https://arxiv.org/abs/1912.03350" rel="nofollow">https://arxiv.org/abs/1912.03350</a></p></blockquote>
<p> </p></div>
    </content>
    <updated>2020-05-09T01:20:02Z</updated>
    <published>2020-05-09T01:20:02Z</published>
    <category term="Announcements"/>
    <author>
      <name>plustcs</name>
    </author>
    <source>
      <id>https://tcsplus.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://tcsplus.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://tcsplus.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://tcsplus.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://tcsplus.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A carbon-free dissemination of ideas across the globe.</subtitle>
      <title>TCS+</title>
      <updated>2020-08-26T22:24:02Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://dstheory.wordpress.com/?p=48</id>
    <link href="https://dstheory.wordpress.com/2020/05/05/friday-may-15-amin-karbasi-from-yale-university/" rel="alternate" type="text/html"/>
    <title>Friday, May 15 — Amin Karbasi from Yale University</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">The fourth Foundations of Data Science virtual talk will take place on Friday, May 15th at 11:00 AM Pacific Time (2:00 pm Eastern Time, 20:00 Central European Time, 19:00 UTC).  Amin Karbasi from Yale University will speak about “User-Friendly Submodular Maximization”. Abstract: Submodular functions model the intuitive notion of diminishing returns. Due to their far-reaching applications, they<a class="more-link" href="https://dstheory.wordpress.com/2020/05/05/friday-may-15-amin-karbasi-from-yale-university/">Continue reading <span class="screen-reader-text">"Friday, May 15 — Amin Karbasi from Yale University"</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The fourth Foundations of Data Science virtual talk will take place on Friday, May 15th at 11:00 AM Pacific Time (2:00 pm Eastern Time, 20:00 Central European Time, 19:00 UTC).  <strong>Amin Karbasi </strong>from Yale University will speak about “<em>User-Friendly Submodular Maximization</em>”.</p>



<p class="has-text-align-left"><strong>Abstract</strong>: Submodular functions model the intuitive notion of diminishing returns. Due to their far-reaching applications, they have been rediscovered in many fields such as information theory, operations research, statistical physics, economics, and machine learning. They also enjoy computational tractability as they can be minimized exactly or maximized approximately.</p>



<p>The goal of this talk is simple. We see how a little bit of randomness, a little bit of greediness, and the right combination can lead to pretty good methods for offline, streaming, and distributed solutions. I do not assume any background on submodularity and try to explain all the required details during the talk.</p>



<p><a href="https://sites.google.com/view/dstheory" rel="noreferrer noopener" target="_blank">Please register here to join the virtual talk.</a></p>



<p>The series is supported by the <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1934846&amp;HistoricalAwards=false">NSF HDR TRIPODS Grant 1934846</a>.</p></div>
    </content>
    <updated>2020-05-05T01:30:02Z</updated>
    <published>2020-05-05T01:30:02Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>dstheory</name>
    </author>
    <source>
      <id>https://dstheory.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://dstheory.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://dstheory.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://dstheory.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://dstheory.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Foundation of Data Science – Virtual Talk Series</title>
      <updated>2020-08-26T22:24:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://francisbach.com/?p=3460</id>
    <link href="https://francisbach.com/gradient-flows/" rel="alternate" type="text/html"/>
    <title>Effortless optimization through gradient flows</title>
    <summary>Optimization algorithms often rely on simple intuitive principles, but their analysis quickly leads to a lot of algebra, where the original idea is not transparent. In last month post, Adrien Taylor explained how convergence proofs could be automated. This month, I will show how proof sketches can be obtained easily for algorithms based on gradient...</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p class="justify-text">Optimization algorithms often rely on simple intuitive principles, but their analysis quickly leads to a lot of algebra, where the original idea is not transparent. In last month <a href="https://francisbach.com/computer-aided-analyses/">post</a>, <a href="https://www.di.ens.fr/~ataylor/">Adrien Taylor</a> explained how convergence proofs could be automated. This month, I will show how proof sketches can be obtained easily for algorithms based on gradient descent. This will be done using vanishing step-sizes that lead to <em>gradient flows</em>.</p>



<h2>Gradient as local information</h2>



<p class="justify-text">The intuitive principle behind gradient descent is the quest for <em>local</em> descent. We thus need to characterize the local behavior of the function we aim to optimize. This is what gradients are for.</p>



<p class="justify-text">In this blog post, I will consider minimizing a function \(f\) over \(\mathbb{R}^d\). Assuming \(f\) is differentiable, a first order Taylor expansion of \(f\) around a point \(x\) leads to $$f(x+\delta) = f(x) + \nabla f(x) ^\top \delta + o(\| \delta\|),$$ for any norm \(\| \cdot \|\) on \(\mathbb{R}^d\), where \(\nabla f(x) \in \mathbb{R}^d\) is  the gradient of \(f\) at \(x\), composed of partial derivatives of \(f\). Therefore, around \(x\), \(f\) is approximately affine.</p>



<p class="justify-text">Since we have a local affine approximation around \(x\), we can look for the direction of steepest descent, that is, the unit norm vector \(u \in \mathbb{R}^d\) such that \(f\) decays the most along \(u\), that is such that $$  u^\top \nabla f(x)$$ is minimized. This steepest descent direction depends on the choice of norm (assuming that the gradient is not zero at \(x\)).</p>



<p class="justify-text">For the \(\ell_2\)-norm, then minimizing \(u^\top \nabla f(x)\) such that \(\|u\|_2 = 1\), leads to $$ \displaystyle u = \ – \frac{\nabla f(x)}{ \| \nabla f(x) \|_2},$$ that is the steepest descent is along the negative gradient (see an illustration below). In this blog post I will only focus on this steepest descent direction. </p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-3542" height="149" src="https://francisbach.com/wp-content/uploads/2020/04/gradient_contours-1024x358.png" width="428"/>Function \(f\) represented through its contour lines for values 1, 2, 3, 4 and 5. Negative gradient \(– \nabla f(x)\) as the steepest descent direction at point \(x\), which is orthogonal to the contour lines.</figure></div>



<p class="justify-text">As as side note, for the \(\ell_1\)-norm, then minimizing \(u^\top \nabla f(x)\) such that \(\|u\|_1 = 1\), leads to $$u \in\  – \arg\max_{ v \in \{-e_1,\, e_1,\, -e_2,\, e_2,\dots,\, -e_d,\, e_d \}} v^\top \nabla f(x),$$ where \(e_i\) is the \(i\)-th canonical basis vector of \(\mathbb{R}^d\). Here the steepest descent is along a coordinate axis (along the positive or negative side), and this leads to various forms of <a href="https://en.wikipedia.org/wiki/Coordinate_descent">coordinate descent</a> (this will probably be a topic for another post). </p>



<p class="justify-text">Given that the negative gradient leads to the steepest descent direction (for the Euclidean norm), it is natural to use this as a direction for an iterative algorithm, an idea that dates back to <a href="https://en.wikipedia.org/wiki/Augustin-Louis_Cauchy">Cauchy</a> in 1847 [<a href="http://gallica.bnf.fr/ark:/12148/bpt6k90190w/f406">1</a>] (see the nice summary by Claude Le Maréchal [<a href="https://www.math.uni-bielefeld.de/documenta/vol-ismp/40_lemarechal-claude.pdf">2</a>]).</p>



<h2>From gradient descent to gradient flows</h2>



<p class="justify-text"><a href="https://en.wikipedia.org/wiki/Gradient_descent">Gradient descent</a> is the most classical iterative algorithm to minimize differentiable functions. It takes the form $$x_{n+1} = x_{n} \, – \gamma \nabla f(x_{n})$$ at iteration \(n\), where \(\gamma &gt; 0 \) is a step-size.  </p>



<p class="justify-text">Gradient descent comes in many flavors, steepest, stochastic, pre-conditioned, conjugate, proximal, projected, accelerated, etc. There are lots of papers and books [e.g., 3, 4, 5] analyzing it in various settings.</p>



<p class="justify-text">In this post, to simplify its analysis and setting the stage for later posts, I will present the gradient flow, which is essentially the limit of gradient descent when the step-size \(\gamma\) tends to zero.</p>



<p class="justify-text">More precisely, this is obtained by considering that our iterates \(x_n\) are sampled at each multiple of \(\gamma\), from a function \(X: \mathbb{R}_+ \to \mathbb{R}^d\), as $$x_n = X(n\gamma).$$ We can then use a piecewise affine interpolation to define a function defined on all points. We then have for \(t = n\gamma\), $$X(t + \gamma) = x_{n+1} =x_{n} \, – \gamma \nabla f(x_{n}) = X(t)\, – \gamma \nabla f(X(t)).$$ Dividing by \(\gamma\), we get $$ \frac{1}{\gamma} \big[ X(t + \gamma) \, – X(t) \big] = \, – \nabla f(X(t)).$$</p>



<p class="justify-text">When \(\gamma\) tends to zero (and with simple additional regularity assumptions), the left hand side tends to the derivative of \(X\) at \(t\), and thus the function \(X\) tends to the solution of the following <a href="https://en.wikipedia.org/wiki/Ordinary_differential_equation">ordinary differential equation</a> $$ \dot{X}(t) = \ – \nabla f (X(t)).$$ See an illustration below.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-full is-resized"><img alt="" class="wp-image-3479" height="271" src="https://francisbach.com/wp-content/uploads/2020/04/logistic_2d_flow.gif" width="348"/>Gradient descent (with piece-wise affine interpolation between iterates) vs. gradient flow on the same time scale for a logistic regression problem.</figure></div>



<p class="justify-text">Studying the gradient flow in lieu of the gradient descent recursions comes with pros and cons.</p>



<p class="justify-text"><strong>Simplified analyses</strong>. The gradient flow has no step-size, so all the traditional annoying issues regarding the choice of step-size, with line-search, constant, decreasing or with a weird schedule are unnecessary. Moreover, the use of differential calculus makes proving properties really simple (see examples below). We can thus focus on the essence of the algorithm rather than on technicalities.</p>



<p class="justify-text"><strong>From (continuous) flow to actual (discrete) algorithms</strong>. A flow cannot be run on a computer as it is a continuous-time object. The traditional discretization is the <a href="https://en.wikipedia.org/wiki/Euler_method">Euler method</a>, that exactly replaces the flow by a piecewise-affine interpolation of the gradient descent iterates, where as shown above, we see \(x_n\) as \(X(n\gamma)\), where \(\gamma\) is the time increment between two samples. Four interesting observations:</p>



<ul class="justify-text"><li><em>No direct proof transfer</em> : While Euler discretization always provides an algorithm, the generic convergence proofs do not allow to transfer immediately continuous-time proofs to convergence results for the discrete analysis. A key difficulty is to set-up the step-size \(\gamma\). However, the analysis can often be mimicked, i.e., similar <a href="https://en.wikipedia.org/wiki/Lyapunov_function">Lyapunov functions</a> can be used (see examples below).</li><li><em>Proximal algorithms</em> : Faced with non-continuous gradient functions, the <em>forward</em> version of Euler discretization \(x_{n+1} = x_{n} – \gamma \nabla f(x_{n})\) can be replaced by the <em>backward</em> version $$x_{n+1} = x_{n} \, –  \gamma \nabla f(x_{n+1}),$$ which is only implicit as it can be solved by minimizing $$ f(x) + \frac{1}{2\gamma}\|x-x_{n}\|_2^2,$$ thus leading to the <a href="https://fr.wikipedia.org/wiki/Algorithme_proximal_(optimisation)">proximal point algorithm</a>. Forward-backward schemes can also be recovered when \(f\) is the sum of a smooth and a non-smooth term.</li><li><em>Stochastic gradient descent</em> : There are two ways to deal with stochastic gradient descent, leading to two very different continuous limits. Adding independent and identically distributed (for simplicity) zero-mean noise \(\varepsilon_n\) to the gradient leads to the recursion $$x_{n+1} = x_{n} – \gamma \big[ \nabla f(x_{n}) + \varepsilon_n\big] = x_{n}\, – \gamma \nabla f(x_{n}) \,- \gamma \varepsilon_n,$$ where the noise is multiplied by the step-size \(\gamma\). Surprisingly, taking the limit when \(\gamma\) tends to zero leads to the deterministic gradient flow equation. A more detailed argument is presented at the end of post, but the main hand-waving reason is that the noise contribution vanishes because it is multiplied by the step-size. Note that this limiting behavior is consistent with a convergence to a minimizer of \(f\).</li><li><em>Convergence to a Langevin diffusion</em> : When instead the noise is added with magnitude proportional to the square root \(\sqrt{2 \gamma}\) of the step-size (which is asymptotically larger than \(\gamma\)), when \(\gamma\) tends to zero, and if the covariance of the noise is identity, we converge to a <a href="https://en.wikipedia.org/wiki/Diffusion_process">diffusion process</a> which is the solution of a <a href="https://en.wikipedia.org/wiki/Stochastic_differential_equation">stochastic differential equation</a>: $$ dX(t) = \ – \nabla f(X(t)) + \sqrt{2} dB(t),$$ where \(B\) is a standard <a href="https://en.wikipedia.org/wiki/Brownian_motion">Brownian motion</a>. Moreover, as \(t\) tends to infinity, \(X(t)\) happens to tend in distribution to a random variable with density proportional to \(\exp( – f(x) )\). See more details at the end of the post and in [6]. The difference in behavior is illustrated below.</li></ul>



<div class="wp-block-image justify-text"><figure class="aligncenter size-full is-resized"><img alt="" class="wp-image-3527" height="318" src="https://francisbach.com/wp-content/uploads/2020/04/logistic_2d_flow_SGD-3.gif" width="359"/> Comparison of flow and diffusion, for the same small \(\gamma\). The flow is deterministic and converges to a stationary point of \(f\) (here the global minimum), while the diffusion is stochastic and converges to a distribution (which is typically not a point mass)</figure></div>



<h2>Properties of gradient flows</h2>



<p class="justify-text">The gradient flow $$ \dot{X}(t) = \ – \nabla f (X(t)) $$ is well-defined for a wide variety of conditions on the function \(f\). The most classical ones are <a href="https://en.wikipedia.org/wiki/Picard%E2%80%93Lindel%C3%B6f_theorem">Lipschitz-continuity</a> of the gradient, or semi-convexity [<a href="https://link.springer.com/content/pdf/10.1007/s13373-017-0101-1.pdf">7</a>].</p>



<p class="justify-text">The most obvious property is that the function decreases along the flow; in other words, \(f(X(t))\) is decreasing, which is a simple consequence of $$ \frac{d}{dt} f(X(t)) =  \nabla f(X(t))^\top \frac{dX(t)}{dt} =\  – \| \nabla f (X(t) )\|_2^2 \leqslant 0.$$</p>



<p class="justify-text">If \(f\) is bounded from below, then \(f(X(t))\) will always converge (as a non-increasing function which is bounded from below, see <a href="https://en.wikipedia.org/wiki/Monotone_convergence_theorem">here</a>). However, in general, \(X(t)\) may not always converge without any further assumptions, e.g., it may oscillate forever. This is however rare and there are a variety of sufficient conditions for convergence of gradient flows, that date back to Lojasiewicz [8], and are based on “Lojasiewicz inequalities” that state that for \(y\) and \(x\) close enough, \(|f(x) – f(y)|^{1-\theta} \leqslant C \| \nabla f(x)\|\) for some \(C &gt; 0 \) and \(\theta \in (0,1)\). These are satisfied for “sub-analytical functions”, that include most functions one can imagine [<a href="https://www.sciencedirect.com/sdfe/reader/pii/S0022247X05006864/pdf">9</a>].</p>



<p class="justify-text">Once \(X(t)\) converges to some \(X(\infty) \in \mathbb{R}^d\), assuming \(\nabla f\) is continuous, we must have \(\nabla f(X(\infty))=0\), that is, \(X(\infty)\) is a stationary point of \(f\). Among all stationary points (that can be local minima, local maxima, or saddle-points), the one to which \(X(t)\) converges to depends on \(X(0)\).</p>



<p class="justify-text">Given any stationary point, one can look at the set of initializations that lead to it. Typically, only local minima are stable, that is, the attraction basins of other stationary points has typically zero Lebesgue measure (see, e.g., [<a href="http://www.jmlr.org/proceedings/papers/v49/lee16.pdf">10</a>]). See examples below. </p>



<p class="justify-text">We start with a simple function defined on the two-dimensional plane, with several local minima and saddle-points.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-3490" height="401" src="https://francisbach.com/wp-content/uploads/2020/04/plot_non_convex-1.png" width="511"/>Various gradient flows trajectories, starting from green points and ending in black points. Note the proximity of the three top starting points, all ending in different local minima. See the motion below.</figure></div>



<div class="wp-block-image justify-text"><figure class="aligncenter size-full is-resized"><img alt="" class="wp-image-3492" height="500" src="https://francisbach.com/wp-content/uploads/2020/04/logistic_2d_flow_noncvx-1.gif" width="519"/>Various gradient flows trajectories, in motion! All flows share the same time scale. Some seem “slower” than others (because the gradient norm is small).</figure></div>



<p class="justify-text">Before moving on, I cannot resist presenting a “real” two-dimensional example that probably all skiers, hikers, and cyclists with some form of mathematical abilities have thought of, the topographic map. Here is an example below:</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-3751" height="458" src="https://francisbach.com/wp-content/uploads/2020/04/glandon_croix_de_fer-1-1024x1024.jpg" width="458"/>Extract from <a href="https://www.geoportail.gouv.fr/">IGN</a> topographic map, around <a href="https://en.wikipedia.org/wiki/Col_du_Glandon">Col du Glandon</a> and <a href="https://en.wikipedia.org/wiki/Col_de_la_Croix_de_Fer">Col de la Croix de Fer</a> (French Alps).</figure></div>



<p class="justify-text">Given the topographic map, how would gradient descent or gradient flow perform? Clearly, this corresponds to a non convex function, but it is quite well-behaved, as following water flows will typically lead to sea level. I chose two starting points famous to cyclists, <a href="https://en.wikipedia.org/wiki/Col_du_Glandon">Col du Glandon</a> and <a href="https://en.wikipedia.org/wiki/Col_de_la_Croix_de_Fer">Col de la Croix de Fer</a>, and ran gradient descent with a small step-size (to approximate the gradient flow), without noise (left) and with noise (right), on the topographic map (thanks to <a href="http://recherche.ign.fr/labos/matis/cv.php?nom=Landrieu">Loïc Landrieu</a> for the data extraction).</p>



<figure class="wp-block-image size-large"><img alt="" class="wp-image-3753" height="394" src="https://francisbach.com/wp-content/uploads/2020/04/flows_final_square_small-1024x394.png" width="1024"/></figure>



<p class="justify-text">Without noise, the descent from la Croix de Fer ends up getting stuck quickly in a local minimum, while the one from Glandon goes down to the valley, but then is not able to follow the almost flat slope. When noise is added, the two flows go a bit lower, highlighting the benefits of noise to escape local minima.</p>



<h2>Gradient flows for optimization and machine learning</h2>



<p class="justify-text">There are (at least) two key questions in optimization and machine learning related to gradient flows: </p>



<ul class="justify-text"><li>When can we have global guarantees for convergence? That is, can we make sure that we choose an initialization point well enough to get the the global optimum <em>without knowing where the global optimum is</em>. A key difficulty is that the volume of the attraction basin of the global optimum can be made arbitrarily small, even for infinitely differentiable functions (imagine a function equal to zero everywhere except on a small ball where it is negative).</li><li>How fast can we get there? “there” can be a stationary point or a global optimum. This is an important question as mere convergence in the limit may be arbitrarily slow [<a href="https://papers.nips.cc/paper/6707-gradient-descent-can-take-exponential-time-to-escape-saddle-points.pdf">11</a>].</li></ul>



<p class="justify-text">An important class of function is <a href="https://en.wikipedia.org/wiki/Convex_function">convex functions</a>, where everything works out very well. We will study them below. Other functions will be studied in future posts.</p>



<h2>Convex functions</h2>



<p class="justify-text">We now assume that the function \(f\) is <a href="https://en.wikipedia.org/wiki/Convex_function">convex</a> and differentiable. Within machine learning, this corresponds to objective functions encountered for supervised learning which are based on empirical risk minimization with a prediction function which is linearly parameterized, such as <a href="https://en.wikipedia.org/wiki/Logistic_regression">logistic regression</a>.</p>



<p class="justify-text">There are various definitions of convexity, which are based on global properties (the function is always “below its chords”, or it is always “above its tangents”) or local properties (the Hessian is always positive semi-definite). The one which we need here is to be above its tangents, that is, for any \(x, y \in \mathbb{R}^d\), $$f(x) \geqslant f(y)  + \nabla f(y)^\top ( x \, – y).$$ Applying this to any stationary point \(y\) such that \(\nabla f(y)=0\) shows that for all \(x\), \(f(x) \geqslant f(y)\), that is, \(y\) is a global minimizer of \(f\). This is the classical benefit of convexity: no need to worry about local minima.</p>



<p class="justify-text">Another property we will need is the Lojasiewicz inequality, which is in particular satisfied when \(f\) is \(\mu\)-<a href="https://en.wikipedia.org/wiki/Convex_function#Strongly_convex_functions">strongly convex</a> (that is, \(f – \frac{\mu}{2} \| \cdot \|_2^2\) is convex): $$ f(x) \ – f(x_\ast) \leqslant \frac{1}{2 \mu} \| \nabla f (x)\|^2$$ for any minimizer \(x_\ast\) of \(f\) and any \(x\). This property allows to go from a bound on the gradient norm to a bound on function values.</p>



<p class="justify-text">We then obtain the convergence rate <em>in one line</em> as follows (see more details in [<a href="http://papers.nips.cc/paper/6711-integration-methods-and-optimization-algorithms.pdf">12</a>]): $$ \frac{d}{dt} \big[ f(X(t))\ – f(x_\ast) \big] =\  \nabla f(X(t))^\top \dot{X}(t) =  \ – \| \nabla f(X(t))\|_2^2 \leqslant \ – 2\mu  \big[ f(X(t)) \ – f(x_\ast) \big]$$ using the Lojasiewicz inequality above, leading to by simple integration of the derivative of \(\log \big[ f(X(t)) \ – f(x_\ast) \big]\): $$f(X(t)) \ – f(x_\ast) \leqslant \exp( – 2\mu t ) \big[ f(X(0))\  – f(x_\ast) \big], $$ that is, the convergence is exponential and the characteristic time is proportional to \(1/\mu\).</p>



<p class="justify-text">The gradient flow gives the main insight (exponential convergence); and applying the result above to \(t = \gamma n\), we seem to recover the traditional rate proportional to \(\exp( – \gamma \mu n)\); HOWEVER, this is only true asymptotically for \(\gamma\) tending to zero, and proving a result for gradient descent requires extra steps to deal with having a constant step-size. This requires typically \(\gamma \leqslant 1/L\), where \(L\) is the smoothness constant of \(f\), and the simplest proof happens to use the same structure (see [<a href="https://arxiv.org/pdf/1608.04636">13</a>] and references therein, as well as [<a href="http://www.mathnet.ru/php/getFT.phtml?jrnid=zvmmf&amp;paperid=7813&amp;what=fullt&amp;option_lang=eng">14</a>]).</p>



<p class="justify-text">Without strong convexity, we have, using the tangent property at \(X(t)\) and \(x_\ast\): $$ \frac{d}{dt}\big[   \| X(t)\ – x_\ast \|^2 \big] = \ –   2 ( X(t) \ – x_\ast )^\top \nabla f(X(t)) \leqslant \ – 2 \big[ f(X(t)) \ – f(x_\ast) \big],$$  leading to, by integrating from \(0\) to \(t\), and using the monotonicity of \(f(X(t))\): $$  f(X(t)) \ – f(x_\ast) \leqslant \frac{1}{t} \int_0^t \big[ f(X(u)) \ – f(x_\ast) \big] du \leqslant \frac{1}{2t} \| X(0) \ – x_\ast \|^2 \ – \frac{1}{2t} \| X(t) \ – x_\ast \|^2.$$ We recover the usual rates in \(O(1/n)\), with \(t = \gamma n\), with the same caveat as above (the step-size needs to be bounded).</p>



<h2>Conclusion</h2>



<p class="justify-text">In this blog post, I covered the basic aspects of gradient flows, in particular their relationships with various forms of gradient descent, and their use in obtaining simple convergence justifications. Next months, I will cover extensions of the analyses above, in particular in terms of (1) acceleration for convex functions, where several flows and discretizations are interesting beyond the gradient flow and Euler method [12, 15], and (2) another class of functions which includes non-convex functions as encountered when learning with neural networks [16].</p>



<h2>References</h2>



<p class="justify-text">[1] Augustin Louis Cauchy. <a href="http://gallica.bnf.fr/ark:/12148/bpt6k90190w/f406">Méthode générale pour la résolution des systèmes d’équations simultanées</a>. Compte Rendu à l’Académie des Sciences, 25:536–538, 1847.<br/>[2] Claude Lemaréchal. <a href="https://www.math.uni-bielefeld.de/documenta/vol-ismp/40_lemarechal-claude.pdf">Cauchy and the Gradient Method</a>. <em>Documenta Mathematica</em>, <a href="https://www.math.uni-bielefeld.de/documenta/vol-ismp/vol-ismp.html">Extra Volume: Optimization Stories</a>, 251–254, 2012.<br/>[3] Yurii Nesterov. <em>Introductory lectures on convex optimization: A basic course</em> (Vol. 87). Springer Science &amp; Business Media, 2013.<br/>[4] Dimitri P. Bertsekas, <em>Nonlinear programming</em>. Athena Scientific, 1999.<br/>[5] Jorge Nocedal and Stephen Wright. <em>Numerical optimization</em>. Springer Science &amp; Business Media, 2006.<br/>[6] Arnak S. Dalalyan. <a href="https://rss.onlinelibrary.wiley.com/doi/epdf/10.1111/rssb.12183">Theoretical guarantees for approximate sampling from smooth and log‐concave densities</a>. <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, 79(3), 651-676, 2017.<br/>[7] Filippo Santambrogio. <a href="https://link.springer.com/content/pdf/10.1007/s13373-017-0101-1.pdf">{Euclidean, metric, and Wasserstein} gradient flows: an overview</a>. <em>Bulletin of Mathematical Sciences</em>, <em>7</em>(1), 87-154, 2017.<br/>[8] Stanislaw Lojasiewicz. Sur les trajectoires du gradient d’une fonction analytique. <em>Seminari di Geometria</em>, 1983:115–117, 1982.<br/>[9] Jérôme Bolte, Aris Daniilidis, and Adrian Lewis. <a href="https://www.sciencedirect.com/sdfe/reader/pii/S0022247X05006864/pdf">A nonsmooth Morse–Sard theorem for subanalytic functions</a>. <em>Journal of Mathematical Analysis and Applications</em>, 321(2):729–740, 2006.<br/>[10] Jason D. Lee, Max Simchowitz, Michael I. Jordan, Benjamin Recht. <a href="http://www.jmlr.org/proceedings/papers/v49/lee16.pdf">Gradient descent only converges to minimizers</a>. <em>Conference on learning theory</em>, 1246-1257, 2016.<br/>[11] Simon S. Du, Chi Jin, Jason D. Lee, Michael I. Jordan, Barnabas Poczos, Aarti Singh. <a href="https://papers.nips.cc/paper/6707-gradient-descent-can-take-exponential-time-to-escape-saddle-points.pdf">Gradient descent can take exponential time to escape saddle points</a>. <em>Advances in neural information processing systems</em>, 1067-1077, 2017.<br/>[12] Damien Scieur, Vincent Roulet, Francis Bach, Alexandre d’Aspremont,. <a href="http://papers.nips.cc/paper/6711-integration-methods-and-optimization-algorithms.pdf">Integration methods and optimization algorithms</a>. <em>Advances in Neural Information Processing Systems</em>, 1109-1118, 2017.<br/>[13] Hamed Karimi, Julie Nutini, Mark Schmidt. <a href="https://arxiv.org/pdf/1608.04636">Linear convergence of gradient and proximal-gradient methods under the Polyak-Lojasiewicz condition</a>. <em>Joint European Conference on Machine Learning and Knowledge Discovery in Databases</em>, 795-811, 2016.<br/>[14] Boris T. Polyak. <a href="http://www.mathnet.ru/php/getFT.phtml?jrnid=zvmmf&amp;paperid=7813&amp;what=fullt&amp;option_lang=eng">Gradient methods for minimizing functionals</a>. <em>Zh. Vychisl. Mat. Mat. Fiz.</em>, 3(4):643–653, 1963. <br/>[15] Weijie Su, Stephen Boyd, Emmanuel J. Candès. <a href="http://www.jmlr.org/papers/volume17/15-084/15-084.pdf">A differential equation for modeling Nesterov’s accelerated gradient method: theory and insights</a>. <em>Journal of Machine Learning Research</em>, 17(1), 5312-5354, 2017.<br/>[16] Lénaïc Chizat, Francis Bach. <a href="http://papers.nips.cc/paper/7567-on-the-global-convergence-of-gradient-descent-for-over-parameterized-models-using-optimal-transport.pdf">On the global convergence of gradient descent for over-parameterized models using optimal transport</a>. <em>Advances in Neural Information Processing Systems</em>, 3036-3046, 2018.</p>



<h2>Limits of stochastic gradient descent for vanishing step-sizes</h2>



<p class="justify-text"><strong>Convergence to gradient flow. </strong>We consider fixed times \(t = n \gamma \) and \(s = m \gamma\), and we let \(\gamma\) tend to zero, with thus \(m\) and \(n\) tending to infinity. Starting from the recursion $$x_{n+1} = x_{n}\, – \gamma \nabla f(x_{n})\  – \gamma \varepsilon_n,$$ we get the following by applying it \(m\) times: $$X(t+s) \ – X(t) = x_{n+m}-x_n = \ – \gamma \sum_{k=0}^{m-1} \nabla f\Big(X\Big(t+\frac{sk}{m}\Big)\Big)\  – \gamma \sum_{k=0}^{m-1} \varepsilon_{k+n}.$$ The term \(\displaystyle \gamma \sum_{k=0}^{m-1} \nabla f\Big(X\Big(t+\frac{sk}{m}\Big)\Big)\) converges to \(\displaystyle \int_{t}^{t+s}\!\!\! \nabla f(X(u)) du\), while the term \(\gamma \sum_{k=0}^{m-1} \varepsilon_{k+n}\) has zero expectation and variance equal to \(\gamma^2 m = \gamma s \) times the variance of each \(\varepsilon_{k+n}\), and thus it tends to zero (since \(\gamma\) tends to zero). Thus, in the limit, $$X(t+s)\  – X(t) = \ – \int_{t}^{t+s} \!\!\! \nabla f(X(u)) du,$$ which is equivalent to the gradient flow equation.</p>



<p class="justify-text"><strong>Convergence to diffusion.</strong> We consider the recursion $$x_{n+1} = x_{n}\,  – \gamma \nabla f(x_{n}) + \sqrt{2\gamma} \varepsilon_n.$$ With the same argument as above, we now get $$X(t+s) \ – X(t) = x_{n+m}-x_n =\ – \gamma \sum_{k=0}^{m-1} \nabla f\Big(X\Big(t+\frac{sk}{m}\Big)\Big)\ – \sqrt{2\gamma} \sum_{k=0}^{m-1} \varepsilon_{k+n}.$$ Now the second term has zero mean but a variance proportional to \(2s\) (<em>which does not go to zero when \(\gamma\) goes to zero</em>). We can then use when \(m\) tends to infinity the <a href="https://en.wikipedia.org/wiki/Wiener_process#Wiener_process_as_a_limit_of_random_walk">limit of the sum of independent variables as a Wiener process</a>, to get $$X(t+s)\ – X(t) =\  – \int_{t}^{t+s} \!\!\! \nabla f(X(u)) du + \sqrt{2} \big[ B(t+s)-B(t) \big].$$ The <a href="https://en.wikipedia.org/wiki/It%C3%B4_diffusion#Invariant_measures">limiting distribution</a> of \(X(t)\) happens to be the so-called <a href="https://en.wikipedia.org/wiki/Gibbs_measure">Gibbs</a> distribution, with density \(\exp(-f(x))\) (the factor of \(\sqrt{2}\) was added to avoid an extra constant factor in the Gibbs distribution). More on this in a future post.</p></div>
    </content>
    <updated>2020-05-01T05:15:04Z</updated>
    <published>2020-05-01T05:15:04Z</published>
    <category term="Machine learning"/>
    <category term="Tools"/>
    <author>
      <name>Francis Bach</name>
    </author>
    <source>
      <id>https://francisbach.com</id>
      <link href="https://francisbach.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://francisbach.com" rel="alternate" type="text/html"/>
      <subtitle>Francis Bach</subtitle>
      <title>Machine Learning Research Blog</title>
      <updated>2020-08-26T22:24:38Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://tcsplus.wordpress.com/?p=428</id>
    <link href="https://tcsplus.wordpress.com/2020/04/30/tcs-talk-wednesday-may-6-nathan-klein-university-of-washington/" rel="alternate" type="text/html"/>
    <title>TCS+ talk: Wednesday, May 6 — Nathan Klein, University of Washington</title>
    <summary>The next TCS+ talk will take place this coming Wednesday, May 6th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). Nathan Klein from the University of Washington will speak about “An improved approximation algorithm for TSP in the half integral case” (abstract below). You can reserve a spot […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The next TCS+ talk will take place this coming Wednesday, May 6th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). <strong>Nathan Klein</strong> from the University of Washington will speak about “<em>An improved approximation algorithm for TSP in the half integral case” (abstract below).</em></p>
<p>You can reserve a spot as an individual or a group to join us live by signing up on <a href="https://sites.google.com/site/plustcs/livetalk/live-seat-reservation">the online form</a>. Due to security concerns, <em>registration is required</em> to attend the interactive talk. (The link to the YouTube livestream will also be posted <a href="https://sites.google.com/site/plustcs/livetalk">on our<br/>
website</a> on the day of the talk, so people who did not sign up will still be able to watch the talk live.) As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a>suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/site/plustcs/">the website</a>.</p>
<blockquote><p>Abstract: A classic result from Christofides in the 70s tells us that a fast algorithm for the traveling salesperson problem (TSP) exists which returns a solution at most 3/2 times worse than the optimal. Since then, however, no better approximation algorithm has been found. In this talk, I will give an overview of research towards the goal of beating 3/2 and will present the first sub-3/2 approximation algorithm for the special case of “half integral” TSP instances. These instances have received significant attention in part due to a conjecture from Schalekamp, Williamson and van Zuylen that they attain the integrality gap of the subtour polytope. If this conjecture is true, our work shows that the integrality gap of the polytope is bounded away from 3/2, giving hope for an improved approximation for the general case. This presentation is of joint work with Anna Karlin and Shayan Oveis Gharan.</p></blockquote></div>
    </content>
    <updated>2020-05-01T03:10:05Z</updated>
    <published>2020-05-01T03:10:05Z</published>
    <category term="Announcements"/>
    <author>
      <name>plustcs</name>
    </author>
    <source>
      <id>https://tcsplus.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://tcsplus.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://tcsplus.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://tcsplus.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://tcsplus.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A carbon-free dissemination of ideas across the globe.</subtitle>
      <title>TCS+</title>
      <updated>2020-08-26T22:24:02Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://theorydish.blog/?p=1676</id>
    <link href="https://theorydish.blog/2020/04/27/whats-your-story/" rel="alternate" type="text/html"/>
    <title>What’s Your Story?</title>
    <summary>Last quarter, I taught a course on research methods in TOC, which gave me an opportunity to think through many aspects of research. I was promoting a human-centric perspective on research: how to facilitate better research by addressing the conditions needed for an individual researcher and groups of researchers to succeed. As science is a communal effort, the communication of science is critical, and thus one of the topics we covered is oral presentations. There are plenty of resources about research talks, and mostly they emphasize form over matter. How many words in a slide? How many slides in a talk? how to and how not to use font colors? How to and how not to use animation? and so on. While all of these are important, I find that the failing of many research talks is on a much more basic level. Think back to a research talk you heard recently, or to one you heard a few months ago. You may remember how you felt and what you thought of the talk but what do you remember of this talk in terms of content? Most of us will find that we don’t remember much, I rarely do. Yet [...]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Last quarter, I taught <a href="https://omereingold.wordpress.com/cs-353-the-practice-of-theory-research/">a course on research methods</a> in TOC, which gave me an opportunity to think through many aspects of research. I was promoting a human-centric perspective on research: how to facilitate better research by addressing the conditions needed for an individual researcher and groups of researchers to succeed. As science is a communal effort, the communication of science is critical, and thus one of the topics we covered is oral presentations.</p>
<p>There are plenty of resources about research talks, and mostly they emphasize form over matter. How many words in a slide? How many slides in a talk? how to and how not to use font colors? How to and how not to use animation? and so on. While all of these are important, I find that the failing of many research talks is on a much more basic level.</p>
<p>Think back to a research talk you heard recently, or to one you heard a few months ago. You may remember how you felt and what you thought of the talk but what do you remember of this talk in terms of content? Most of us will find that we don’t remember much, I rarely do. Yet in our presentations, we often follow a research-paper-like mold and squeeze in many little details that are somehow important to us, forgetting that they will all vanish in our audience’s memory soon after (or completely missed in the first place). Giving a talk (writing a paper, writing a blog post etc.) is about communication: who is your audience? what are the limitation of the medium? what is the message you want to convey? Since so little stays with the audience long term, it makes sense to make sure that this little will be what seems most important for you to convey.</p>
<p>The idea I am promoting here is not new, and there are various techniques towards this goal. One (which I think Oded Goldreich shared with me), is to think of audience’s attention as a limited currency. Whenever you share a big idea you spend a big token and other ideas cost a smaller token. Imagine you have one or two big tokens and a few smaller tokens. <a href="https://www.youtube.com/watch?v=5OFAhBw0OXs">Another approach</a>, emphasizes the notion of <strong>a premise</strong>. The idea promoted here is that a talk needs a premise and this should be the title of the talk. Furthermore, every slide needs a premise and it should be the title of the slide. A premise is a main idea and is a complete sentence. It is not unusual to find a slide titled “Analysis” or “Efficiency” but neither of these is a premise. “Problem X has an efficient algorithm” could be. The talk’s premise could help you distill what you want the audience to take out of your talk. It also helps shape the talk, as everything that doesn’t serve the premise shouldn’t be there. Note that each paper can provoke many different premises and thus many different talks.</p>
<p>Here I want to play with a different idea, that I find intriguing, even if it may seem a bit extreme. It will not be controversial that a good talk (and paper) tells a story. After all, humans understand and remember narratives. But could we take inspiration from the form of storytelling in fiction writing? A vast literature, classifies different kinds of stories and explores their templates (see for example <a href="http://storybistro.com/7-story-frameworks/">this short discussion</a>).  Can we find analogues to these types in scientific research talks?</p>
<p>The type of story that is easiest to relate to is the <strong>Quest/Hero’s Journey</strong> (think Lord of the Rings). These have several distinct ingredients: a call to adventure, tests, allies, enemies, ordeal, reward, victorious return. Some research talks that follow this template do it well and preserve a sense of suspense and excitement, others seem like a long list of problems and the tricks that the work uses to handle them.</p>
<p>I believe that many other story templates can find analogues is research talks as well. Here are my initial attempts:</p>
<ul>
<li><strong>Coming of age</strong> stories – this area of research previously only had naive ideas but this works brings significant depth.</li>
<li><strong>The Under<span style="color: #000000;">dog</span></strong><span style="color: #000000;"> (think David and Goliath): a modest technique that concurred a great challenge.</span></li>
<li><strong>Rags to Riches</strong> (think the Ugly Duckling): an area or technique that were not successful prove powerful.
<ul>
<li>Similarly: <strong>Rebirth</strong> (reinvention, renewal).</li>
</ul>
</li>
<li><strong>Comedy</strong> (or the Clarity Tale) – conceptual works shedding a new perspective.</li>
<li><strong>Tragedy</strong> (or the Cautionary Tale) – Some impossibility results come to mind (couldn’t we view Arrow’s impossibility theorem as being tragic?)</li>
<li><strong>Redemption stories</strong>: the field so far has missed the point, was misleading or harmful, but this work makes amends.</li>
</ul>
<p>Can you suggest papers and a story type that could fit them?</p></div>
    </content>
    <updated>2020-04-27T16:26:33Z</updated>
    <published>2020-04-27T16:26:33Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Omer Reingold</name>
    </author>
    <source>
      <id>https://theorydish.blog</id>
      <logo>https://theorydish.files.wordpress.com/2017/03/cropped-nightdish1.jpg?w=32</logo>
      <link href="https://theorydish.blog/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://theorydish.blog" rel="alternate" type="text/html"/>
      <link href="https://theorydish.blog/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://theorydish.blog/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Stanford's CS Theory Research Blog</subtitle>
      <title>Theory Dish</title>
      <updated>2020-08-26T22:24:11Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://tcsplus.wordpress.com/?p=426</id>
    <link href="https://tcsplus.wordpress.com/2020/04/23/tcs-talk-wednesday-april-29-sepideh-mahabadi-ttic/" rel="alternate" type="text/html"/>
    <title>TCS+ talk: Wednesday, April 29 — Sepideh Mahabadi, TTIC</title>
    <summary>The next TCS+ talk will take place this coming Wednesday, April 29th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). Sepideh Mahabadi from TTIC will speak about “Non-Adaptive Adaptive Sampling in Turnstile Streams” (abstract below). You can reserve a spot as an individual or a group to join […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The next TCS+ talk will take place this coming Wednesday, April 29th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). <strong>Sepideh Mahabadi</strong> from TTIC will speak about “<em>Non-Adaptive Adaptive Sampling in Turnstile Streams</em>” (abstract below).</p>
<p>You can reserve a spot as an individual or a group to join us live by signing up on <a>the online form</a>. Due to security concerns, <em>registration is required</em> to attend the interactive talk. (The link to the YouTube livestream will also be posted <a>on our website</a> on the day of the talk, so people who did not sign up will still be able to watch the talk live.) As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a>suggest</a> a possible topic or speaker, please see <a>the website</a>.</p>
<blockquote><p>Abstract: Adaptive sampling is a useful algorithmic tool for data summarization problems in the classical centralized setting, where the entire dataset is available to the single processor performing the computation. Adaptive sampling repeatedly selects rows of an underlying <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=fff&amp;fg=444444&amp;s=0" title="n"/> by <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=fff&amp;fg=444444&amp;s=0" title="d"/> matrix <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=fff&amp;fg=444444&amp;s=0" title="A"/>, where <img alt="n \gg d" class="latex" src="https://s0.wp.com/latex.php?latex=n+%5Cgg+d&amp;bg=fff&amp;fg=444444&amp;s=0" title="n \gg d"/>, with probabilities proportional to their distances to the subspace of the previously selected rows. Intuitively, adaptive sampling seems to be limited to trivial multi-pass algorithms in the streaming model of computation due to its inherently sequential nature of assigning sampling probabilities to each row only after the previous iteration is completed. Surprisingly, we show this is not the case by giving the first one-pass algorithms for adaptive sampling on turnstile streams and using space <img alt="\text{poly}(d,k,\log n)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctext%7Bpoly%7D%28d%2Ck%2C%5Clog+n%29&amp;bg=fff&amp;fg=444444&amp;s=0" title="\text{poly}(d,k,\log n)"/>, where <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=fff&amp;fg=444444&amp;s=0" title="k"/> is the number of adaptive sampling rounds to be performed.</p>
<p>Our adaptive sampling procedure has a number of applications to various data summarization problems on turnstile streams that either improve state-of-the-art or have only been previously studied in the more relaxed row-arrival model. This includes column subset selection, subspace approximation, projective clustering, and volume maximization. We complement our volume maximization algorithmic results with lower bounds that are tight up to lower order terms, even for multi-pass algorithms. By a similar construction, we also obtain lower bounds for volume maximization in the row-arrival model, which we match with competitive upper bounds.</p>
<p>This is a joint work with Ilya Razenshteyn, David Woodruff, and Samson Zhou.</p></blockquote></div>
    </content>
    <updated>2020-04-23T16:59:09Z</updated>
    <published>2020-04-23T16:59:09Z</published>
    <category term="Announcements"/>
    <author>
      <name>plustcs</name>
    </author>
    <source>
      <id>https://tcsplus.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://tcsplus.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://tcsplus.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://tcsplus.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://tcsplus.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A carbon-free dissemination of ideas across the globe.</subtitle>
      <title>TCS+</title>
      <updated>2020-08-26T22:24:02Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://theorydish.blog/?p=1650</id>
    <link href="https://theorydish.blog/2020/04/22/private-libraries/" rel="alternate" type="text/html"/>
    <title>Reading in Private</title>
    <summary>(This blog post is based on joint work with Dima Kogan.) One of the great unsung perks of being a college student is having access to the university library. There is something thrilling about hunting down exactly the right reference deep in the stacks, or reading through the archived papers of a public figure from years back. The pandemic has closed all of our libraries for the time being. Even so, through the fruits of computer science—databases, the Internet, e-readers, and so on—we can get access to much of the same information even when we are cooped up at home. But for me, one of the true pleasures of using a library is the fact that I can browse through any book I want in complete privacy. If I want to go up to the stacks and read about tulip gardening, or road-bike maintenance, or strategies for managing anxiety, I can do that pretty much without anyone else knowing. In contrast, if I go online today and search for “tulip gardening,” Google will take careful note of my interest in tulips and I will be seeing ads about gardening tools for months. An ideal digital library would let us download [...]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><i>(This blog post is based on joint work with </i><a href="https://cs.stanford.edu/~dkogan/"><i>Dima Kogan</i></a><i>.)</i></p>
<p>One of the great unsung perks of being a college student is having access to the university library. There is something thrilling about hunting down exactly the right reference deep in the stacks, or reading through the archived papers of a public figure from years back.</p>
<p>The pandemic has closed all of our libraries for the time being. Even so, through the fruits of computer science—databases, the Internet, e-readers, and so on—we can get access to much of the same information even when we are cooped up at home.</p>
<p>But for me, one of the true pleasures of using a library is the fact that I can browse through any book I want in complete privacy. If I want to go up to the stacks and read about tulip gardening, or road-bike maintenance, or strategies for managing anxiety, I can do that pretty much without anyone else knowing.</p>
<p>In contrast, if I go online today and search for “tulip gardening,” Google will take careful note of my interest in tulips and I will be seeing ads about gardening tools for months.</p>
<p>An ideal digital library would let us download and read books without anyone—not even the library itself—learning which books we are reading. How could we build such a privacy-respecting digital library?</p>
<p>In this post, we will discuss the private-library problem and how <a href="https://eprint.iacr.org/2019/1075">our recent work on private information retrieval</a> might be able to help solve it.</p>
<h3><b>The Private-Library Problem</b></h3>
<p>Let us define the problem a little more precisely. We will imagine a protocol running between a library, which holds the books, and a student, who wants to download a particular book.</p>
<p>Say that the library has <img alt="N" class="latex" src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="N"/> books—let’s call the books <img alt="x=(x_1, \dots, x_N)" class="latex" src="https://s0.wp.com/latex.php?latex=x%3D%28x_1%2C+%5Cdots%2C+x_N%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="x=(x_1, \dots, x_N)"/>. To keep things simple, let’s pretend that each book consists of just a single bit of information, so <img alt="x_i \in \{0,1\}" class="latex" src="https://s0.wp.com/latex.php?latex=x_i+%5Cin+%5C%7B0%2C1%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="x_i \in \{0,1\}"/> for all <img alt="i \in \{1, \dots, N\}" class="latex" src="https://s0.wp.com/latex.php?latex=i+%5Cin+%5C%7B1%2C+%5Cdots%2C+N%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="i \in \{1, \dots, N\}"/>.</p>
<p>The student starts out holding the index <img alt="i \in \{1, \dots, N\}" class="latex" src="https://s0.wp.com/latex.php?latex=i+%5Cin+%5C%7B1%2C+%5Cdots%2C+N%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="i \in \{1, \dots, N\}"/> of her desired book. To fetch the digital book from the library, the student and library exchange some messages. At the end of the interaction, we want the following two properties to hold:</p>
<ul>
<li><b>Correctness.</b> The student should have her desired book (i.e., the bit <img alt="x_i" class="latex" src="https://s0.wp.com/latex.php?latex=x_i&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="x_i"/>).</li>
<li><b>Privacy. </b>The library should have not learned any information, in a cryptographic sense, about which book the student downloaded.</li>
</ul>
<p>Of course, we have grossly simplified the problem: a real book is more than a single bit in length, book titles are not consecutive integers, maybe the student would like to find a book using a keyword search, etc. But even this simplified private-information-retrieval problem, which <a href="http://www.tau.ac.il/~bchor/PIR.pdf">Chor, Goldreich, Kushilevitz, and Sudan introduced</a> in the 90s, is already interesting enough.</p>
<h3><b>A simple but inefficient solution</b></h3>
<p>There is a simple solution to this problem: the student can just ask the library to send her the contents of all <img alt="N" class="latex" src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="N"/> books. This solution achieves both correctness and privacy, so what’s the problem? Are we done?</p>
<p>Well, there are two problems:</p>
<ol>
<li>The amount of <b>communication</b> is large: Just to read a single book, the client must download the contents of the entire library! So this is terribly inefficient.</li>
<li>The amount of <b>computation</b> is large: Just to fetch a single book, the library must do work proportional to the size of the entire library. So “checking out” a book from this digital library will take a long time.</li>
</ol>
<p>Research on private information retrieval typically focuses on the first problem: how can we reduce the <i>communication</i> cost? Using a <a href="https://dl.acm.org/doi/abs/10.1145/2968443">variety</a> of <a href="https://ieeexplore.ieee.org/abstract/document/646125">clever</a> <a href="https://dl.acm.org/doi/abs/10.1145/2976749.2978429">techniques</a>, it is possible to drive down the communication cost to something very small—sub-polynomial or even logarithmic in the library size <img alt="N" class="latex" src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="N"/>.</p>
<p>But today we are interested in the <i>computational</i> burden on the library. Is there any way that the student can privately download a book from the library while requiring the library to do only <img alt="o(N)" class="latex" src="https://s0.wp.com/latex.php?latex=o%28N%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="o(N)"/> work in the process?</p>
<h3><b>Doing the hard work in advance</b></h3>
<p>To have both correctness and privacy, it seems that the library needs to touch each of the <img alt="N" class="latex" src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="N"/> books in the process of responding to each student’s request. And, in some sense, <a href="http://groups.csail.mit.edu/cis/pubs/malkin/BIM.ps">this is true</a>. So, to allow the library to run in time sublinear in <img alt="N" class="latex" src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="N"/>, we will have to tweak the problem slightly.</p>
<p>Our idea is to have the library do the <img alt="O(N)" class="latex" src="https://s0.wp.com/latex.php?latex=O%28N%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="O(N)"/>-time computation in an <b>offline phase</b>, which takes place <i>before</i> the student decides which book she wants to read. For example, this offline phase might happen overnight while the library’s servers would otherwise be idle.</p>
<p>Later on, once the student decides which book in the library she wants to read, the student and library can run a <img alt="o(N)" class="latex" src="https://s0.wp.com/latex.php?latex=o%28N%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="o(N)"/>-time <b>online phase</b> in which the student is able to retrieve her desired book. The total communication cost, in both offline and online phases, will be <img alt="o(N)" class="latex" src="https://s0.wp.com/latex.php?latex=o%28N%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="o(N)"/>.</p>
<p>So, by pushing the library’s expensive linear scan to an offline phase, the library can service the student’s request for a book in sublinear online time.</p>
<h3><b>Our offline/online private information retrieval scheme</b></h3>
<p>Let’s see how to construct such an offline/online scheme. To make things simple for the purposes of this post, let’s assume that the student has access to two non-colluding libraries that hold the same set of books. To be concrete, let’s call the two libraries “Stanford” and “Berkeley.”</p>
<p>The privacy property will hold as long as the librarians at Stanford and Berkeley don’t get together and share the information that they learned while running the protocol with the student. So Stanford and Berkeley here are “non-colluding.” (Equivalently, our scheme that protects privacy against an adversary that controls one of the two libraries—but not both.)</p>
<p/><div class="wp-caption aligncenter" id="attachment_1670" style="width: 571px;"><img alt="Offline-online PIR" class=" wp-image-1670" height="365" src="https://theorydish.files.wordpress.com/2020/04/offlineonline.png?w=300" width="561"/><p class="wp-caption-text" id="caption-attachment-1670">In the offline phase, which happens before the student knows which book she wants to read, the Stanford library does linear work. In the online phase, which runs once the student has the index of her desired book, the Berkeley library runs in sublinear time. (We are suppressing log factors here.)</p></div><p/>
<p>Now, let’s describe an offline/online protocol by which the student can privately fetch a book from the digital library:</p>
<p><b>Offline Phase.</b></p>
<ul>
<li>The student partitions the integers <img alt="\{1, .., N\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B1%2C+..%2C+N%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\{1, .., N\}"/> into <img alt="\sqrt{N}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csqrt%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\sqrt{N}"/> non-overlapping sets chosen at random, where each set has size <img alt="\sqrt{N}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csqrt%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\sqrt{N}"/>. Call these sets <img alt="S_1, \dots, S_{\sqrt{N}}" class="latex" src="https://s0.wp.com/latex.php?latex=S_1%2C+%5Cdots%2C+S_%7B%5Csqrt%7BN%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="S_1, \dots, S_{\sqrt{N}}"/>.</li>
<li>The student sends these sets <img alt="S_1, \dots, S_{\sqrt{N}}" class="latex" src="https://s0.wp.com/latex.php?latex=S_1%2C+%5Cdots%2C+S_%7B%5Csqrt%7BN%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="S_1, \dots, S_{\sqrt{N}}"/> to Stanford (the first library). To reduce the communication cost here, the student can compress these sets using pseudorandomness.</li>
<li>For each set <img alt="S_j" class="latex" src="https://s0.wp.com/latex.php?latex=S_j&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="S_j"/>, the Stanford library computes the <i>parity</i> of all of the books indexed by set <img alt="S_j" class="latex" src="https://s0.wp.com/latex.php?latex=S_j&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="S_j"/> and returns the parity bits <img alt="(b_1, \dots, b_{\sqrt{N}})" class="latex" src="https://s0.wp.com/latex.php?latex=%28b_1%2C+%5Cdots%2C+b_%7B%5Csqrt%7BN%7D%7D%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="(b_1, \dots, b_{\sqrt{N}})"/> to the student. In other words, if the books are <img alt="x=(x_1, \dots, x_N) \in \{0,1\}^n" class="latex" src="https://s0.wp.com/latex.php?latex=x%3D%28x_1%2C+%5Cdots%2C+x_N%29+%5Cin+%5C%7B0%2C1%5C%7D%5En&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="x=(x_1, \dots, x_N) \in \{0,1\}^n"/>, then <img alt="b_j = \sum_{k \in S_j} x_k \bmod 2" class="latex" src="https://s0.wp.com/latex.php?latex=b_j+%3D+%5Csum_%7Bk+%5Cin+S_j%7D+x_k+%5Cbmod+2&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="b_j = \sum_{k \in S_j} x_k \bmod 2"/>.</li>
</ul>
<p>The total communication in this phase is only <img alt="O(\sqrt{N})" class="latex" src="https://s0.wp.com/latex.php?latex=O%28%5Csqrt%7BN%7D%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="O(\sqrt{N})"/> bits and the student and the Stanford library can run this step <i>before</i> the student decides which book she wants to read.</p>
<p><b>Online Phase.</b> Once the student decides that she wants to read book <img alt="i \in \{1, \dots, N\}" class="latex" src="https://s0.wp.com/latex.php?latex=i+%5Cin+%5C%7B1%2C+%5Cdots%2C+N%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="i \in \{1, \dots, N\}"/>, the student and Berkeley (the second library) run the following steps:</p>
<ul>
<li>The student finds the set <img alt="S_j" class="latex" src="https://s0.wp.com/latex.php?latex=S_j&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="S_j"/> that contains the index <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="i"/> of her desired book.</li>
<li>The student flips a coin that is weighted to come up heads with some probability <img alt="p" class="latex" src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="p"/>, to be fixed later.</li>
<li>If the coin lands <span style="text-decoration: underline;">heads</span>:
<ul>
<li>The student sends <img alt="S \gets S_j \setminus \{i\}" class="latex" src="https://s0.wp.com/latex.php?latex=S+%5Cgets+S_j+%5Csetminus+%5C%7Bi%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="S \gets S_j \setminus \{i\}"/> to the Berkeley library.</li>
</ul>
</li>
<li>If the coin lands <span style="text-decoration: underline;">tails</span>:
<ul>
<li>The student samples <img alt="i' \gets_R S_j \setminus \{i\}" class="latex" src="https://s0.wp.com/latex.php?latex=i%27+%5Cgets_R+S_j+%5Csetminus+%5C%7Bi%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="i' \gets_R S_j \setminus \{i\}"/>.</li>
<li>The student sends <img alt="S \gets S_j \setminus \{i'\}" class="latex" src="https://s0.wp.com/latex.php?latex=S+%5Cgets+S_j+%5Csetminus+%5C%7Bi%27%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="S \gets S_j \setminus \{i'\}"/> to the Berkeley library.</li>
</ul>
</li>
<li>The Berkeley library receives the set <img alt="S \subseteq \{1, \dots, N\}" class="latex" src="https://s0.wp.com/latex.php?latex=S+%5Csubseteq+%5C%7B1%2C+%5Cdots%2C+N%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="S \subseteq \{1, \dots, N\}"/> from the student. The Berkeley library returns the contents of all books whose indices appear in set <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="S"/> to the student.</li>
<li>Now, the student can recover its desired book as follows:
<ul>
<li>If <span style="text-decoration: underline;">heads</span>: the student now has the parity of the books in <img alt="S_j" class="latex" src="https://s0.wp.com/latex.php?latex=S_j&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="S_j"/> (from the offline phase) and the value of all books in <img alt="S_j" class="latex" src="https://s0.wp.com/latex.php?latex=S_j&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="S_j"/> that are not book <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="i"/>. This is enough to recover the contents of book <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="i"/>.</li>
<li>If <span style="text-decoration: underline;">tails</span>: <img alt="i \in S" class="latex" src="https://s0.wp.com/latex.php?latex=i+%5Cin+S&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="i \in S"/>. In this case the Berkeley library has sent the contents of book <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="i"/> to the student in the online phase.</li>
</ul>
</li>
</ul>
<p>Even before we fix the weight <img alt="p" class="latex" src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="p"/> of the coin, we see that the protocol satisfies <b>correctness</b>, since no matter how the coin lands the client recovers its desired book. Also, the total communication cost is <img alt="O(\sqrt{N} \log N)" class="latex" src="https://s0.wp.com/latex.php?latex=O%28%5Csqrt%7BN%7D+%5Clog+N%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="O(\sqrt{N} \log N)"/> bits, which is sublinear as we had hoped. Finally, the <b>online computation cost</b> is also sublinear: the Berkeley library just needs to return <img alt="\sqrt{N}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csqrt%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\sqrt{N}"/> books to the client, which it can do in time roughly <img alt="O(\sqrt{N})" class="latex" src="https://s0.wp.com/latex.php?latex=O%28%5Csqrt%7BN%7D%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="O(\sqrt{N})"/>.</p>
<p>The last matter to address is <b>privacy</b>. Again, we are assuming that the adversary controls only one of the two libraries.</p>
<ul>
<li>In the offline phase, the student’s message to the Stanford library is independent of <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="i"/>, so the protocol is perfectly private with respect to Stanford.</li>
<li>In the online phase, we must be more careful. It turns out that if we choose the weight <img alt="p" class="latex" src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="p"/> of the coin as <img alt="p = 1 - (\sqrt{N} - 1)/N" class="latex" src="https://s0.wp.com/latex.php?latex=p+%3D+1+-+%28%5Csqrt%7BN%7D+-+1%29%2FN&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="p = 1 - (\sqrt{N} - 1)/N"/>, then the set <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="S"/> that the student sends to UC Berkeley in the online phase is just a uniformly random size-<img alt="(\sqrt{N}-1)" class="latex" src="https://s0.wp.com/latex.php?latex=%28%5Csqrt%7BN%7D-1%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="(\sqrt{N}-1)"/> subset of <img alt="\{1, \dots, N\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B1%2C+%5Cdots%2C+N%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\{1, \dots, N\}"/>.</li>
</ul>
<h3><b>Open problems</b></h3>
<p>So, the student can privately fetch a book from our digital libraries in sublinear online time. What else is left to do?</p>
<ul>
<li>Getting rid of the need for two non-colluding libraries is a clear next step. <a href="https://eprint.iacr.org/2019/1075">Our work</a> has some results along these lines, but they pay a price either in (a) asymptotic efficiency or in (b) the strength of the cryptographic assumptions required.</li>
<li>A beautiful paper of <a href="https://www.cs.bgu.ac.il/~beimel/Papers/BIM.pdf">Beimel, Ishai, and Malkin</a> shows that if the library can store its collection of books using a special type of error-correcting encoding, the <b>total</b> computational time at the libraries (not just the online time) can be sublinear in <img alt="N" class="latex" src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="N"/>. As far as we know, these schemes are not concretely efficient enough to use in practice. Could they be made so?</li>
<li>Privacy is just one of the many pleasures of using a physical library. During this period of confinement, I also miss the smell of the books, the beauty of light filtering through the stacks, and the peacefulness of thinking in a study carrel. Can a digital library ever give us these things too?</li>
</ul>
<p>If any of these questions catch your fancy, please check out <a href="https://eprint.iacr.org/2019/1075">our Eurocrypt paper</a> for more background, pointers, and results.</p>
<p>Don Knuth <a href="http://jmlr.csail.mit.edu/reviewing-papers/knuth_mathematical_writing.pdf">has reportedly said</a> “Using a great library to solve a specific problem… Now <i>that</i> […] is real living.” With better digital libraries, maybe we could all live a little bit more during these challenging days.</p></div>
    </content>
    <updated>2020-04-22T07:07:04Z</updated>
    <published>2020-04-22T07:07:04Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Henry Corrigan-Gibbs</name>
    </author>
    <source>
      <id>https://theorydish.blog</id>
      <logo>https://theorydish.files.wordpress.com/2017/03/cropped-nightdish1.jpg?w=32</logo>
      <link href="https://theorydish.blog/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://theorydish.blog" rel="alternate" type="text/html"/>
      <link href="https://theorydish.blog/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://theorydish.blog/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Stanford's CS Theory Research Blog</subtitle>
      <title>Theory Dish</title>
      <updated>2020-08-26T22:24:09Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://kamathematics.wordpress.com/?p=118</id>
    <link href="https://kamathematics.wordpress.com/2020/04/21/a-primer-on-private-statistics-part-ii/" rel="alternate" type="text/html"/>
    <title>A Primer on Private Statistics – Part II</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">By Gautam Kamath and Jonathan Ullman The second part of our brief survey of differentially private statistics. This time, we show how to privately estimate the CDF of a distribution (i.e., estimate the distribution in Kolmogorov distance), and conclude with pointers to some other work in the space. The first part of this series is here, and you … <a class="more-link" href="https://kamathematics.wordpress.com/2020/04/21/a-primer-on-private-statistics-part-ii/">Continue reading<span class="screen-reader-text"> "A Primer on Private Statistics – Part II"</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>By <a href="http://www.gautamkamath.com/">Gautam Kamath</a> and <a href="http://www.ccs.neu.edu/home/jullman/">Jonathan Ullman</a></p>
<p>The second part of our brief survey of differentially private statistics. This time, we show how to privately estimate the CDF of a distribution (i.e., estimate the distribution in Kolmogorov distance), and conclude with pointers to some other work in the space.</p>
<p>The first part of this series is <a href="https://kamathematics.wordpress.com/2020/04/14/a-primer-on-private-statistics-part-i/">here</a>, and you can download both parts in PDF form <a href="http://www.gautamkamath.com/writings/primer.pdf">here</a>.</p>
<p><b>1. CDF Estimation for Discrete, Univariate Distributions </b></p>
<p>Suppose we have a distribution <img alt="{P}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{P}"/> over the ordered, discrete domain <img alt="{\{1,\dots,D\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B1%2C%5Cdots%2CD%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{1,\dots,D\}}"/> and let <img alt="{\mathcal{P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{P}}"/> be the family of all such distributions. The CDF of the distribution is the function <img alt="{\Phi_{P} : \{1,\dots,D\} \rightarrow [0,1]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CPhi_%7BP%7D+%3A+%5C%7B1%2C%5Cdots%2CD%5C%7D+%5Crightarrow+%5B0%2C1%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Phi_{P} : \{1,\dots,D\} \rightarrow [0,1]}"/> given by</p>
<p align="center"><img alt="\displaystyle \Phi_{P}(j) = \mathop{\mathbb P}(P \leq j). \ \ \ \ \ (1)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5CPhi_%7BP%7D%28j%29+%3D+%5Cmathop%7B%5Cmathbb+P%7D%28P+%5Cleq+j%29.+%5C+%5C+%5C+%5C+%5C+%281%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \Phi_{P}(j) = \mathop{\mathbb P}(P \leq j). \ \ \ \ \ (1)"/></p>
<p>A natural measure of distance between CDFs is the <img alt="{\ell_\infty}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell_%5Cinfty%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\ell_\infty}"/> distance, as this is the sort of convergence guarantee that the empirical CDF satisfies. That is, in the non-private setting, the empirical CDF will achieve the minimax rate, which it known by [<a href="https://kamathematics.wordpress.com/feed/#DKW56">DKW56</a>, <a href="https://kamathematics.wordpress.com/feed/#Mas90">Mas90</a>] to be <a name="eqdkw"/></p>
<p><a name="eqdkw"/></p>
<p><a name="eqdkw"/></p>
<p align="center"><img alt="\displaystyle \max_{P \in \mathcal{P}} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| \Phi_{X} - \Phi_{P} \|_{\infty}) = O\left(\sqrt{\frac{1}{n}} \right). \ \ \ \ \ (2)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmax_%7BP+%5Cin+%5Cmathcal%7BP%7D%7D+%5Cmathop%7B%5Cmathbb+E%7D_%7BX_%7B1+%5Ccdots+n%7D+%5Csim+P%7D%28%5C%7C+%5CPhi_%7BX%7D+-+%5CPhi_%7BP%7D+%5C%7C_%7B%5Cinfty%7D%29+%3D+O%5Cleft%28%5Csqrt%7B%5Cfrac%7B1%7D%7Bn%7D%7D+%5Cright%29.+%5C+%5C+%5C+%5C+%5C+%282%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \max_{P \in \mathcal{P}} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| \Phi_{X} - \Phi_{P} \|_{\infty}) = O\left(\sqrt{\frac{1}{n}} \right). \ \ \ \ \ (2)"/></p>
<p><a name="eqdkw"/><a name="eqdkw"/><a name="eqdkw"/></p>
<p><b> 1.1. Private CDF Estimation </b></p>
<blockquote><p><b>Theorem 1</b> <em> <a name="thmcdf-ub"/> For every <img alt="{n \in {\mathbb N}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn+%5Cin+%7B%5Cmathbb+N%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n \in {\mathbb N}}"/> and every <img alt="{\epsilon,\delta &gt; 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%2C%5Cdelta+%3E+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\epsilon,\delta &gt; 0}"/>, there exists an <img alt="{(\epsilon,\delta)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28%5Cepsilon%2C%5Cdelta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(\epsilon,\delta)}"/>-differentially private mechanism <img alt="{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M}"/> such that </em></p>
<p align="center"><img alt="\displaystyle \max_{P \in \mathcal{P}} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| M(X_{1 \cdots n}) - \Phi_{P} \|_{\infty}) = O\left(\sqrt{\frac{1}{n}} + \frac{\log^{3/2}(D) \log^{1/2}(1/\delta)}{\epsilon n} \right). \ \ \ \ \ (3)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmax_%7BP+%5Cin+%5Cmathcal%7BP%7D%7D+%5Cmathop%7B%5Cmathbb+E%7D_%7BX_%7B1+%5Ccdots+n%7D+%5Csim+P%7D%28%5C%7C+M%28X_%7B1+%5Ccdots+n%7D%29+-+%5CPhi_%7BP%7D+%5C%7C_%7B%5Cinfty%7D%29+%3D+O%5Cleft%28%5Csqrt%7B%5Cfrac%7B1%7D%7Bn%7D%7D+%2B+%5Cfrac%7B%5Clog%5E%7B3%2F2%7D%28D%29+%5Clog%5E%7B1%2F2%7D%281%2F%5Cdelta%29%7D%7B%5Cepsilon+n%7D+%5Cright%29.+%5C+%5C+%5C+%5C+%5C+%283%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \max_{P \in \mathcal{P}} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| M(X_{1 \cdots n}) - \Phi_{P} \|_{\infty}) = O\left(\sqrt{\frac{1}{n}} + \frac{\log^{3/2}(D) \log^{1/2}(1/\delta)}{\epsilon n} \right). \ \ \ \ \ (3)"/></p>
</blockquote>
<p><em>Proof:</em> Assume without loss of generality that <img alt="{D = 2^{d}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD+%3D+2%5E%7Bd%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D = 2^{d}}"/> for an integer <img alt="{d \geq 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd+%5Cgeq+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d \geq 1}"/>. Let <img alt="{X_{1 \cdots n} \sim P}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_%7B1+%5Ccdots+n%7D+%5Csim+P%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X_{1 \cdots n} \sim P}"/> be a sample. By the triangle inequality, we have</p>
<p align="center"><img alt="\displaystyle \begin{array}{rll} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}{\| M(X_{1 \cdots n}) - \Phi_{P} \|_{\infty}} &amp;\leq{} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| \Phi_{X} - \Phi_{P} \|_{\infty} + \| M(X_{1 \cdots n}) - \Phi_{X} \|_{\infty}) \\ &amp;\leq{} O(\sqrt{1/n}) + \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| M(X_{1 \cdots n}) - \Phi_{X} \|_{\infty}), \end{array} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cbegin%7Barray%7D%7Brll%7D+%5Cmathop%7B%5Cmathbb+E%7D_%7BX_%7B1+%5Ccdots+n%7D+%5Csim+P%7D%7B%5C%7C+M%28X_%7B1+%5Ccdots+n%7D%29+-+%5CPhi_%7BP%7D+%5C%7C_%7B%5Cinfty%7D%7D+%26%5Cleq%7B%7D+%5Cmathop%7B%5Cmathbb+E%7D_%7BX_%7B1+%5Ccdots+n%7D+%5Csim+P%7D%28%5C%7C+%5CPhi_%7BX%7D+-+%5CPhi_%7BP%7D+%5C%7C_%7B%5Cinfty%7D+%2B+%5C%7C+M%28X_%7B1+%5Ccdots+n%7D%29+-+%5CPhi_%7BX%7D+%5C%7C_%7B%5Cinfty%7D%29+%5C%5C+%26%5Cleq%7B%7D+O%28%5Csqrt%7B1%2Fn%7D%29+%2B+%5Cmathop%7B%5Cmathbb+E%7D_%7BX_%7B1+%5Ccdots+n%7D+%5Csim+P%7D%28%5C%7C+M%28X_%7B1+%5Ccdots+n%7D%29+-+%5CPhi_%7BX%7D+%5C%7C_%7B%5Cinfty%7D%29%2C+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \begin{array}{rll} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}{\| M(X_{1 \cdots n}) - \Phi_{P} \|_{\infty}} &amp;\leq{} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| \Phi_{X} - \Phi_{P} \|_{\infty} + \| M(X_{1 \cdots n}) - \Phi_{X} \|_{\infty}) \\ &amp;\leq{} O(\sqrt{1/n}) + \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| M(X_{1 \cdots n}) - \Phi_{X} \|_{\infty}), \end{array} "/></p>
<p>so we will focus on constructing <img alt="{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M}"/> to approximate <img alt="{\Phi_{X}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CPhi_%7BX%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Phi_{X}}"/>.</p>
<p>For any <img alt="{\ell = 0,\dots,d-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell+%3D+0%2C%5Cdots%2Cd-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\ell = 0,\dots,d-1}"/> and <img alt="{j = 1,\dots,2^{d - \ell}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bj+%3D+1%2C%5Cdots%2C2%5E%7Bd+-+%5Cell%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{j = 1,\dots,2^{d - \ell}}"/>, consider the statistics</p>
<p align="center"><img alt="\displaystyle f_{\ell,j}(X_{1 \cdots n}) = \frac{1}{n} \sum_{i=1}^{n} {\bf 1}\{ (j-1)2^{\ell} + 1 \leq X_i \leq j 2^{\ell} \}. \ \ \ \ \ (4)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+f_%7B%5Cell%2Cj%7D%28X_%7B1+%5Ccdots+n%7D%29+%3D+%5Cfrac%7B1%7D%7Bn%7D+%5Csum_%7Bi%3D1%7D%5E%7Bn%7D+%7B%5Cbf+1%7D%5C%7B+%28j-1%292%5E%7B%5Cell%7D+%2B+1+%5Cleq+X_i+%5Cleq+j+2%5E%7B%5Cell%7D+%5C%7D.+%5C+%5C+%5C+%5C+%5C+%284%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle f_{\ell,j}(X_{1 \cdots n}) = \frac{1}{n} \sum_{i=1}^{n} {\bf 1}\{ (j-1)2^{\ell} + 1 \leq X_i \leq j 2^{\ell} \}. \ \ \ \ \ (4)"/></p>
<p>Let <img alt="{f : \{1,\dots,D\}^n \rightarrow [0,1]^{2D - 2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf+%3A+%5C%7B1%2C%5Cdots%2CD%5C%7D%5En+%5Crightarrow+%5B0%2C1%5D%5E%7B2D+-+2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f : \{1,\dots,D\}^n \rightarrow [0,1]^{2D - 2}}"/> be the function whose output consists of all <img alt="{2D-2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2D-2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2D-2}"/> such counts. To decipher this notation, for a given <img alt="{\ell}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\ell}"/>, the counts <img alt="{f_{\ell,\cdot}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_%7B%5Cell%2C%5Ccdot%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_{\ell,\cdot}}"/> form a histogram of <img alt="{X_{1 \cdots n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_%7B1+%5Ccdots+n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X_{1 \cdots n}}"/> using consecutive bins of width <img alt="{2^{\ell}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5E%7B%5Cell%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2^{\ell}}"/>, and we consider the <img alt="{\log(D)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog%28D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\log(D)}"/> histograms of geometrically increasing width <img alt="{1,2,4,\dots,D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%2C2%2C4%2C%5Cdots%2CD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1,2,4,\dots,D}"/>. First, we claim that the function <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/> has low sensitivity—for adjacent samples <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X}"/> and <img alt="{X'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X'}"/>,</p>
<p align="center"><img alt="\displaystyle \| f(X) - f(X') \|_2^2 \leq \frac{2 \log(D)}{n^2}. \ \ \ \ \ (5)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5C%7C+f%28X%29+-+f%28X%27%29+%5C%7C_2%5E2+%5Cleq+%5Cfrac%7B2+%5Clog%28D%29%7D%7Bn%5E2%7D.+%5C+%5C+%5C+%5C+%5C+%285%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \| f(X) - f(X') \|_2^2 \leq \frac{2 \log(D)}{n^2}. \ \ \ \ \ (5)"/></p>
<p>Thus, we can use the Gaussian mechanism:</p>
<p align="center"><img alt="\displaystyle M'(X_{1 \cdots n}) = f(X_{1 \cdots n}) + \mathcal{N}\left(0, \frac{2 \log(D) \log(1/\delta)}{\epsilon^2 n^2} \cdot \mathbb{I}_{2D \times 2D}\right). \ \ \ \ \ (6)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+M%27%28X_%7B1+%5Ccdots+n%7D%29+%3D+f%28X_%7B1+%5Ccdots+n%7D%29+%2B+%5Cmathcal%7BN%7D%5Cleft%280%2C+%5Cfrac%7B2+%5Clog%28D%29+%5Clog%281%2F%5Cdelta%29%7D%7B%5Cepsilon%5E2+n%5E2%7D+%5Ccdot+%5Cmathbb%7BI%7D_%7B2D+%5Ctimes+2D%7D%5Cright%29.+%5C+%5C+%5C+%5C+%5C+%286%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle M'(X_{1 \cdots n}) = f(X_{1 \cdots n}) + \mathcal{N}\left(0, \frac{2 \log(D) \log(1/\delta)}{\epsilon^2 n^2} \cdot \mathbb{I}_{2D \times 2D}\right). \ \ \ \ \ (6)"/></p>
<p>As we will argue, there exists a matrix <img alt="{A \in {\mathbb R}^{2D \times 2D}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA+%5Cin+%7B%5Cmathbb+R%7D%5E%7B2D+%5Ctimes+2D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A \in {\mathbb R}^{2D \times 2D}}"/> such that <img alt="{\Phi_{X} = A \cdot f(X_{1 \cdots n})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CPhi_%7BX%7D+%3D+A+%5Ccdot+f%28X_%7B1+%5Ccdots+n%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Phi_{X} = A \cdot f(X_{1 \cdots n})}"/>. We will let <img alt="{M(X_{1 \cdots n}) = A \cdot M'(X_{1 \cdots n})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%28X_%7B1+%5Ccdots+n%7D%29+%3D+A+%5Ccdot+M%27%28X_%7B1+%5Ccdots+n%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M(X_{1 \cdots n}) = A \cdot M'(X_{1 \cdots n})}"/>. Since differential privacy is closed under post-processing, <img alt="{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M}"/> inherits the privacy of <img alt="{M'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M'}"/>.</p>
<p>We will now show how to construct the matrix <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/> and analyze the error of <img alt="{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M}"/>. For any <img alt="{j = 1,\dots,D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bj+%3D+1%2C%5Cdots%2CD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{j = 1,\dots,D}"/>, we can form the interval <img alt="{\{1,\dots,j\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B1%2C%5Cdots%2Cj%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{1,\dots,j\}}"/> as the union of at most <img alt="{\log D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog+D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\log D}"/> disjoint intervals of the form we’ve computed, and therefore we can obtain <img alt="{\Phi_{X}(j)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CPhi_%7BX%7D%28j%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Phi_{X}(j)}"/> as the sum of at most <img alt="{\log D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog+D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\log D}"/> of the entries of <img alt="{f(X)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(X)}"/>. For example, if <img alt="{j = 5}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bj+%3D+5%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{j = 5}"/> then we can write</p>
<p align="center"><img alt="\displaystyle \{1,\dots,7\} = \{1,\dots,4\} \cup \{5,6\} \cup \{7\} \ \ \ \ \ (7)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5C%7B1%2C%5Cdots%2C7%5C%7D+%3D+%5C%7B1%2C%5Cdots%2C4%5C%7D+%5Ccup+%5C%7B5%2C6%5C%7D+%5Ccup+%5C%7B7%5C%7D+%5C+%5C+%5C+%5C+%5C+%287%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \{1,\dots,7\} = \{1,\dots,4\} \cup \{5,6\} \cup \{7\} \ \ \ \ \ (7)"/></p>
<p>and</p>
<p align="center"><img alt="\displaystyle \Phi_{X}(5) = f_{2,1} + f_{1,3} + f_{0,7}. \ \ \ \ \ (8)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5CPhi_%7BX%7D%285%29+%3D+f_%7B2%2C1%7D+%2B+f_%7B1%2C3%7D+%2B+f_%7B0%2C7%7D.+%5C+%5C+%5C+%5C+%5C+%288%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \Phi_{X}(5) = f_{2,1} + f_{1,3} + f_{0,7}. \ \ \ \ \ (8)"/></p>
<p>See the following diagram for a visual representation of the decomposition.</p>
<p><img alt="bin-tree-mech" class=" wp-image-142 aligncenter" height="300" src="https://kamathematics.files.wordpress.com/2020/04/bin-tree-mech.png" width="547"/></p>
<p>This shows hierarchical decomposition of the domain <img alt="{\{1,\dots,8\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B1%2C%5Cdots%2C8%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{1,\dots,8\}}"/> using 14 intervals. The highlighted squares represent the interval <img alt="{\{1,\dots,7\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B1%2C%5Cdots%2C7%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{1,\dots,7\}}"/> and the highlighted circles show the decomposition of this interval into a union of <img alt="{3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{3}"/> intervals in the tree.</p>
<p>Thus we can construct the matrix <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/> using this information. Note that each entry of <img alt="{A f(X)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA+f%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A f(X)}"/> is the sum of at most <img alt="{\log(D)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog%28D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\log(D)}"/> entries of <img alt="{f(X)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(X)}"/>. Thus, if we use the output of <img alt="{M'(X_{1 \cdots n})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%27%28X_%7B1+%5Ccdots+n%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M'(X_{1 \cdots n})}"/> in place of <img alt="{f(X_{1 \cdots n})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28X_%7B1+%5Ccdots+n%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(X_{1 \cdots n})}"/>, for every <img alt="{j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{j}"/> we obtain</p>
<p align="center"><img alt="\displaystyle \Phi_{X}(j) + \mathcal{N}(0, \sigma^2) \quad \textrm{for} \quad \sigma^2 = \frac{ 2 \log^2(D) \log(1/\delta)}{\epsilon^2 n^2}. \ \ \ \ \ (9)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5CPhi_%7BX%7D%28j%29+%2B+%5Cmathcal%7BN%7D%280%2C+%5Csigma%5E2%29+%5Cquad+%5Ctextrm%7Bfor%7D+%5Cquad+%5Csigma%5E2+%3D+%5Cfrac%7B+2+%5Clog%5E2%28D%29+%5Clog%281%2F%5Cdelta%29%7D%7B%5Cepsilon%5E2+n%5E2%7D.+%5C+%5C+%5C+%5C+%5C+%289%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \Phi_{X}(j) + \mathcal{N}(0, \sigma^2) \quad \textrm{for} \quad \sigma^2 = \frac{ 2 \log^2(D) \log(1/\delta)}{\epsilon^2 n^2}. \ \ \ \ \ (9)"/></p>
<p>Applying standard bounds on the expected supremum of a Gaussian process, we have</p>
<p align="center"><img alt="\displaystyle \mathop{\mathbb E}(\| M(X_{1 \cdots n}) - \Phi_{X} \|_{\infty}) = O( \sigma \sqrt{\log D}) = O\left(\frac{\log^{3/2}(D) \log^{1/2}(1/\delta)}{\epsilon n} \right). \ \ \ \ \ (10)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmathop%7B%5Cmathbb+E%7D%28%5C%7C+M%28X_%7B1+%5Ccdots+n%7D%29+-+%5CPhi_%7BX%7D+%5C%7C_%7B%5Cinfty%7D%29+%3D+O%28+%5Csigma+%5Csqrt%7B%5Clog+D%7D%29+%3D+O%5Cleft%28%5Cfrac%7B%5Clog%5E%7B3%2F2%7D%28D%29+%5Clog%5E%7B1%2F2%7D%281%2F%5Cdelta%29%7D%7B%5Cepsilon+n%7D+%5Cright%29.+%5C+%5C+%5C+%5C+%5C+%2810%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \mathop{\mathbb E}(\| M(X_{1 \cdots n}) - \Phi_{X} \|_{\infty}) = O( \sigma \sqrt{\log D}) = O\left(\frac{\log^{3/2}(D) \log^{1/2}(1/\delta)}{\epsilon n} \right). \ \ \ \ \ (10)"/></p>
<p><img alt="\Box" class="latex" src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Box"/></p>
<p><b> 1.2. Why Restrict the Domain? </b></p>
<p>A drawback of the estimator we constructed is that it only applies to distributions of finite support <img alt="{\{1,2,\dots,D\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B1%2C2%2C%5Cdots%2CD%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{1,2,\dots,D\}}"/>, albeit with a relatively mild dependence on the support size. If privacy isn’t a concern, then no such restriction is necessary, as the bound <a href="https://kamathematics.wordpress.com/feed/#eqdkw">(2)</a> applies equally well to any distribution over <img alt="{{\mathbb R}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb+R%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{\mathbb R}}"/>. Can we construct a differentially private estimator for distributions with infinite support?</p>
<p>Perhaps surprisingly, the answer to this question is no! Any differentially private estimator for the CDF of the distribution has to have a rate that depends on the support size, and cannot give non-trivial rates for distributions with infinite support.</p>
<blockquote><p><b>Theorem 2 ([<a href="https://kamathematics.wordpress.com/feed/#BNSV15">BNSV15</a>])</b> <em> <a name="thmcdf-lb"/> If <img alt="{\mathcal{P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{P}}"/> consists of all distributions on <img alt="{\{1,\dots,D\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B1%2C%5Cdots%2CD%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{1,\dots,D\}}"/>, then </em></p>
<p align="center"><img alt="\displaystyle \min_{M \in \mathcal{M}_{1, \frac{1}{n}}} \max_{P \in \mathcal{P}} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| M(X_{1 \cdots n}) - \Phi_{P} \|_{\infty}) = \Omega\left(\frac{\log^* D}{n} \right). \ \ \ \ \ (11)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmin_%7BM+%5Cin+%5Cmathcal%7BM%7D_%7B1%2C+%5Cfrac%7B1%7D%7Bn%7D%7D%7D+%5Cmax_%7BP+%5Cin+%5Cmathcal%7BP%7D%7D+%5Cmathop%7B%5Cmathbb+E%7D_%7BX_%7B1+%5Ccdots+n%7D+%5Csim+P%7D%28%5C%7C+M%28X_%7B1+%5Ccdots+n%7D%29+-+%5CPhi_%7BP%7D+%5C%7C_%7B%5Cinfty%7D%29+%3D+%5COmega%5Cleft%28%5Cfrac%7B%5Clog%5E%2A+D%7D%7Bn%7D+%5Cright%29.+%5C+%5C+%5C+%5C+%5C+%2811%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \min_{M \in \mathcal{M}_{1, \frac{1}{n}}} \max_{P \in \mathcal{P}} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| M(X_{1 \cdots n}) - \Phi_{P} \|_{\infty}) = \Omega\left(\frac{\log^* D}{n} \right). \ \ \ \ \ (11)"/></p>
</blockquote>
<p>The notation <img alt="{\log^* D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog%5E%2A+D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\log^* D}"/> refers to the <a href="https://en.wikipedia.org/wiki/Iterated_logarithm">iterated logarithm</a>.</p>
<p>We emphasize that this theorem shouldn’t meet with too much alarm, as <img alt="{\log^* D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog%5E%2A+D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\log^* D}"/> grows remarkably slowly with <img alt="{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D}"/>. There are differentially private CDF estimators that achieve very mild dependence on <img alt="{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D}"/> [<a href="https://kamathematics.wordpress.com/feed/#BNS13">BNS13</a>, <a href="https://kamathematics.wordpress.com/feed/#BNSV15">BNSV15</a>], including one nearly matching the lower bound in Theorem <a href="https://kamathematics.wordpress.com/feed/#thmcdf-lb">2</a>. Moreover, if we want to estimate a distribution over <img alt="{{\mathbb R}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb+R%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{\mathbb R}}"/>, and are willing to make some mild regularity conditions on the distribution, then we can approximate it by a distribution with finite support and only increase the rate slightly. However, what Theorem <a href="https://kamathematics.wordpress.com/feed/#thmcdf-lb">2</a> shows is that there is no “one-size-fits-all” solution to private CDF estimation that achieves similar guarantees to the empirical CDF. That is, the right algorithm has to be tailored somewhat to the application and the assumptions we can make about the distribution.</p>
<p><b>2. More Private Statistics </b></p>
<p>Of course, the story doesn’t end here! There’s a whole wide world of differentially private statistics beyond what we’ve mentioned already. We proceed to survey just a few other directions of study in private statistics.</p>
<p><b> 2.1. Parameter and Distribution Estimation </b></p>
<p>A number of the early works in differential privacy give methods for differentially private statistical estimation for i.i.d. data. The earliest works [<a href="https://kamathematics.wordpress.com/feed/#DN03">DN03</a>, <a href="https://kamathematics.wordpress.com/feed/#DN04">DN04</a>, <a href="https://kamathematics.wordpress.com/feed/#BDMN05">BDMN05</a>, <a href="https://kamathematics.wordpress.com/feed/#DMNS06">DMNS06</a>], which introduced the Gaussian mechanism, among other foundational results, can be thought of as methods for estimating the mean of a distribution over the hypercube <img alt="{\{0,1\}^d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B0%2C1%5C%7D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{0,1\}^d}"/> in the <img alt="{\ell_\infty}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell_%5Cinfty%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\ell_\infty}"/> norm. Tight lower bounds for this problem follow from the tracing attacks introduced in [<a href="https://kamathematics.wordpress.com/feed/#BUV14">BUV14</a>, <a href="https://kamathematics.wordpress.com/feed/#DSSUV15">DSSUV15</a>, <a href="https://kamathematics.wordpress.com/feed/#BSU17">BSU17</a>, <a href="https://kamathematics.wordpress.com/feed/#SU17a">SU17a</a>, <a href="https://kamathematics.wordpress.com/feed/#SU17b">SU17b</a>]. A very recent work of Acharya, Sun, and Zhang [<a href="https://kamathematics.wordpress.com/feed/#ASZ20">ASZ20</a>] adapts classical tools for proving estimation and testing lower bounds (lemmata of Assouad, Fano, and Le Cam) to the differentially private setting. Steinke and Ullman [<a href="https://kamathematics.wordpress.com/feed/#SU17b">SU17b</a>] give tight minimax lower bounds for the weaker guarantee of selecting the largest coordinates of the mean, which were refined by Cai, Wang, and Zhang [<a href="https://kamathematics.wordpress.com/feed/#CWZ19">CWZ19</a>] to give lower bounds for sparse mean-estimation problems.</p>
<p>Nissim, Raskhodnikova, and Smith introduced the highly general sample-and-aggregate paradigm, which they apply to several learning problems (e.g., learning mixtures of Gaussians) [<a href="https://kamathematics.wordpress.com/feed/#NRS07">NRS07</a>]. Later, Smith [<a href="https://kamathematics.wordpress.com/feed/#Smi11">Smi11</a>] showed that this paradigm can be used to transform any estimator for any asymptotically normal, univariate statistic over a bounded data domain into a differentially private one with the same asymptotic convergence rate.</p>
<p>Subsequent work has focused on both relaxing the assumptions in [<a href="https://kamathematics.wordpress.com/feed/#Smi11">Smi11</a>], particularly boundedness, and on giving finite-sample guarantees. Karwa and Vadhan investigated the problem of Gaussian mean estimation, proving the first near-optimal bounds for this setting [<a href="https://kamathematics.wordpress.com/feed/#KV18">KV18</a>]. In particular, exploiting concentration properties of Gaussian data allows us to achieve non-trivial results even with unbounded data, which is impossible in general. Following this, Kamath, Li, Singhal, and Ullman moved to the multivariate setting, investigating the estimation of Gaussians and binary product distributions in total variation distance [<a href="https://kamathematics.wordpress.com/feed/#KLSU19">KLSU19</a>]. In certain cases (i.e., Gaussians with identity covariance), this is equivalent to mean estimation in <img alt="{\ell_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\ell_2}"/>-distance, though not always. For example, for binary product distribution, one must estimate the mean in a type of <img alt="{\chi^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cchi%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\chi^2}"/>-distance instead. The perspective of distribution estimation rather than parameter estimation can be valuable. Bun, Kamath, Steinke, and Wu [<a href="https://kamathematics.wordpress.com/feed/#BKSW19">BKSW19</a>] develop a primitive for private hypothesis selection, which they apply to learn any coverable class of distributions under pure differential privacy. Through the lens of distribution estimation, their work implies an upper bound for mean estimation of binary product distributions that bypasses lower bounds for the same problem in the empirical setting. In addition to work on mean estimation in the sub-Gaussian setting, such as the results discussed earlier, mean estimation has also been studied under weaker moment conditions [<a href="https://kamathematics.wordpress.com/feed/#BS19">BS19</a>, <a href="https://kamathematics.wordpress.com/feed/#KSU20">KSU20</a>]. Beyond these settings, there has also been study of estimation of discrete multinomials, including estimation in Kolmogorov distance [<a href="https://kamathematics.wordpress.com/feed/#BNSV15">BNSV15</a>] and in total variation distance for structured distributions [<a href="https://kamathematics.wordpress.com/feed/#DHS15">DHS15</a>], and parameter estimation of Markov Random Fields [<a href="https://kamathematics.wordpress.com/feed/#ZKKW20">ZKKW20</a>].</p>
<p>A different approach to constructing differentially private estimators is based on robust statistics. This approah begins with the influential work of Dwork and Lei [<a href="https://kamathematics.wordpress.com/feed/#DL09">DL09</a>], which introduced the propose-test-release framework, and applied to estimating robust statistics such as the median and interquartile range. While the definitions in robust statistics and differential privacy are semantically similar, formal connections between the two remain relatively scant, which suggests a productive area for future study.</p>
<p><b> 2.2. Hypothesis Testing </b></p>
<p>An influential work of Homer et al. [<a href="https://kamathematics.wordpress.com/feed/#HSRDTMPSNC08">HSRDTMPSNC08</a>] demonstrated the vulnerability of classical statistics in a genomic setting, showing that certain <img alt="{\chi^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cchi%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\chi^2}"/>-statistics on many different variables could allow an attacker to determine the presence of an individual in a genome-wide association study (GWAS). Motivated by these concerns, an early line of work from the statistics community focused on addressing these issues [<a href="https://kamathematics.wordpress.com/feed/#VS09">VS09</a>, <a href="https://kamathematics.wordpress.com/feed/#USF13">USF13</a>, <a href="https://kamathematics.wordpress.com/feed/#YFSU14">YFSU14</a>].</p>
<p>More recently, work on private hypothesis testing can be divided roughly into two lines. The first focuses on the minimax sample complexity, in a line initiated by Cai, Daskalakis, and Kamath [<a href="https://kamathematics.wordpress.com/feed/#CDK17">CDK17</a>], who give an algorithm for privately testing goodness-of-fit (more precisely, a statistician might refer to this problem as one-sample testing of multinomial data). A number of subsequent works have essentially settled the complexity of this problem [<a href="https://kamathematics.wordpress.com/feed/#ASZ18">ASZ18</a>, <a href="https://kamathematics.wordpress.com/feed/#ADR18">ADR18</a>], giving tight upper and lower bounds. Other papers in this line study related problems, including the two-sample version of the problem, independence testing, and goodness-of-fit testing for multivariate product distributions [<a href="https://kamathematics.wordpress.com/feed/#ASZ18">ASZ18</a>, <a href="https://kamathematics.wordpress.com/feed/#ADR18">ADR18</a>, <a href="https://kamathematics.wordpress.com/feed/#ADKR19">ADKR19</a>, <a href="https://kamathematics.wordpress.com/feed/#CKMUZ19">CKMUZ19</a>]. A related paper studies the minimax sample complexity of property <em>estimation</em>, rather than testing of discrete distributions, including support size and entropy [<a href="https://kamathematics.wordpress.com/feed/#AKSZ18">AKSZ18</a>]. Other recent works in this vein focus on testing of simple hypotheses [<a href="https://kamathematics.wordpress.com/feed/#CKMTZ18">CKMTZ18</a>, <a href="https://kamathematics.wordpress.com/feed/#CKMSU19">CKMSU19</a>]. In particular [<a href="https://kamathematics.wordpress.com/feed/#CKMSU19">CKMSU19</a>] proves an analogue of the Neyman-Pearson Lemma for differentially private testing of simple hypotheses. A paper of Awan and Slavkovic [<a href="https://kamathematics.wordpress.com/feed/#AS18">AS18</a>] gives a universally optimal test when the domain size is two, however Brenner and Nissim [<a href="https://kamathematics.wordpress.com/feed/#BN14">BN14</a>] shows that such universally optimal tests cannot exist when the domain has more than two elements. A related problem in this space is private change-point detection [<a href="https://kamathematics.wordpress.com/feed/#CKMTZ18">CKMTZ18</a>, <a href="https://kamathematics.wordpress.com/feed/#CKMSU19">CKMSU19</a>, <a href="https://kamathematics.wordpress.com/feed/#CKLZ19">CKLZ19</a>] — in this setting, we are given a time series of datapoints which are sampled from a distribution, which at some point, changes to a different distribution. The goal is to (privately) determine when this point occurs.</p>
<p>Complementary to minimax hypothesis testing, a line of work [<a href="https://kamathematics.wordpress.com/feed/#WLK15">WLK15</a>, <a href="https://kamathematics.wordpress.com/feed/#GLRV16">GLRV16</a>, <a href="https://kamathematics.wordpress.com/feed/#KR17">KR17</a>, <a href="https://kamathematics.wordpress.com/feed/#KSF17">KSF17</a>, <a href="https://kamathematics.wordpress.com/feed/#CBRG18">CBRG18</a>, <a href="https://kamathematics.wordpress.com/feed/#SGGRGB19">SGGRGB19</a>, <a href="https://kamathematics.wordpress.com/feed/#CKSBG19">CKSBG19</a>] designs differentially private versions of popular test statistics for testing goodness-of-fit, closeness, and independence, as well as private ANOVA, focusing on the performance at small sample sizes. Work by Wang et al. [<a href="https://kamathematics.wordpress.com/feed/#WKLK18">WKLK18</a>] focuses on generating statistical approximating distributions for differentially private statistics, which they apply to hypothesis testing problems.</p>
<p><b> 2.3. Differential Privacy on Graphs </b></p>
<p>There is a significant amount of work on differentially private analysis of graphs. We remark that these algorithms can satisfy either edge or node differential privacy. The former (easier) guarantee defines a neighboring graph to be one obtained by adding or removing a single edge, while in the latter (harder) setting, a neighboring graph is one that can be obtained by modifying the set of edges connected to a single node. The main challenge in this area is that most graph statistics can have high sensitivity in the worst-case.</p>
<p>The initial works in this area focused on the empirical setting, and goals range from counting subgraphs [<a href="https://kamathematics.wordpress.com/feed/#KRSY11">KRSY11</a>, <a href="https://kamathematics.wordpress.com/feed/#BBDS13">BBDS13</a>, <a href="https://kamathematics.wordpress.com/feed/#KNRS13">KNRS13</a>, <a href="https://kamathematics.wordpress.com/feed/#CZ13">CZ13</a>, <a href="https://kamathematics.wordpress.com/feed/#RS16">RS16</a>] to outputting a privatized graph which approximates the original [<a href="https://kamathematics.wordpress.com/feed/#GRU12">GRU12</a>, <a href="https://kamathematics.wordpress.com/feed/#BBDS12">BBDS12</a>, <a href="https://kamathematics.wordpress.com/feed/#Upa13">Upa13</a>, <a href="https://kamathematics.wordpress.com/feed/#AU19">AU19</a>, <a href="https://kamathematics.wordpress.com/feed/#EKKL20">EKKL20</a>]. In contrast to the setting discussed in most of this series, it seems that there are larger qualitative differences between the study of empirical and population statistics due to the fact that many graph statistics have high worst-case sensitivity, but may have smaller sensitivity on typical graphs from many natural models.</p>
<p>In the population statistics setting, recent work has focused on parameter estimation of the underlying random graph model. So far this work has given estimators for the <img alt="{\beta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\beta}"/>-model [<a href="https://kamathematics.wordpress.com/feed/#KS16">KS16</a>] and graphons [<a href="https://kamathematics.wordpress.com/feed/#BCS15">BCS15</a>,<a href="https://kamathematics.wordpress.com/feed/#BCSZ18">BCSZ18</a>]. Graphons are a generalization of the stochastic block model, which is, in turn, a generalization of the Erdös-Rényi model. Interestingly, the methods of Lipschitz-extensions introduced in the empirical setting by [<a href="https://kamathematics.wordpress.com/feed/#BBDS13">BBDS13</a>, <a href="https://kamathematics.wordpress.com/feed/#KNRS13">KNRS13</a>] are the main tool used in the statistical setting as well. While the first works on private graphon estimation were not computationally efficient, a recent focus has been on obviating these issues for certain important cases, such as the Erdös-Rényi setting [<a href="https://kamathematics.wordpress.com/feed/#SU19">SU19</a>].</p>
<p><b>Bibliography</b></p>
<p><a name="ADKR19"/>[ADKR19] Maryam Aliakbarpour, Ilias Diakonikolas, Daniel M. Kane, and Ronitt Rubinfeld. Private testing of distributions via sample permutations. NeurIPS ’19.</p>
<p><a name="ADR18"/>[ADR18] Maryam Aliakbarpour, Ilias Diakonikolas, and Ronitt Rubinfeld. Differentially private identity and closeness testing of discrete distributions. ICML ’18.</p>
<p><a name="AKSZ18"/>[AKSZ18] Jayadev Acharya, Gautam Kamath, Ziteng Sun, and Huanyu Zhang. Inspectre: Privately estimating the unseen. ICML ’18.</p>
<p><a name="AS18"/>[AS18] Jordan Awan and Aleksandra Slavković. Differentially private uniformly most powerful tests for binomial data. NeurIPS ’18.</p>
<p><a name="ASZ18"/>[ASZ18] Jayadev Acharya, Ziteng Sun, and Huanyu Zhang. Differentially private testing of identity and closeness of discrete distributions. NeurIPS ’18.</p>
<p><a name="ASZ20"/>[ASZ20] Jayadev Acharya, Ziteng Sun, and Huanyu Zhang. Differentially private Assouad, Fano, and Le Cam. arXiv, 2004.06830, 2020.</p>
<p><a name="AU19"/>[AU19] Raman Arora and Jalaj Upadhyay. On differentially private graph sparsification and applications. NeurIPS ’19.</p>
<p><a name="BBDS12"/>[BBDS12] Jeremiah Blocki, Avrim Blum, Anupam Datta, and Or Sheffet. The Johnson-Lindenstrauss transform itself preserves differential privacy. FOCS ’12.</p>
<p><a name="BBDS13"/>[BBDS13] Jeremiah Blocki, Avrim Blum, Anupam Datta, and Or Sheffet. Differentially private data analysis of social networks via restricted sensitivity. ITCS ’13.</p>
<p><a name="BCS15"/>[BCS15] Christian Borgs, Jennifer Chayes, and Adam Smith. Private graphon estimation for sparse graphs. NIPS ’15.</p>
<p><a name="BCSZ18"/>[BCSZ18] Christian Borgs, Jennifer Chayes, Adam Smith, and Ilias Zadik. Revealing network structure, confidentially: Improved rates for node-private graphon estimation. FOCS ’18.</p>
<p><a name="BDMN05"/>[BDMN05] Avrim Blum, Cynthia Dwork, Frank McSherry, and Kobbi Nissim. Practical privacy: The SuLQ framework. PODS ’05.</p>
<p><a name="BKSW19"/>[BKSW19] Mark Bun, Gautam Kamath, Thomas Steinke, and Zhiwei Steven Wu. Private hypothesis selection. NeurIPS ’19.</p>
<p><a name="BN14"/>[BN14] Hai Brenner and Kobbi Nissim. Impossibility of differentially private universally optimal mechanisms. SIAM Journal on Computing, 43(5), 2014.</p>
<p><a name="BNS13"/>[BNS13] Amos Beimel, Kobbi Nissim, and Uri Stemmer. Private learning and sanitization: Pure vs. approximate differential privacy. APPROX-RANDOM ’13.</p>
<p><a name="BNSV15"/>[BNSV15] Mark Bun, Kobbi Nissim, Uri Stemmer, and Salil Vadhan. Differentially private release and learning of threshold functions. FOCS ’15.</p>
<p><a name="BS19"/>[BS19] Mark Bun and Thomas Steinke. Average-case averages: Private algorithms for smooth sensitivity and mean estimation. NeurIPS ’19.</p>
<p><a name="BSU17"/>[BSU17] Mark Bun, Thomas Steinke, and Jonathan Ullman. Make up your mind: The price of online queries in differential privacy. SODA ’17.</p>
<p><a name="BUV14"/>[BUV14] Mark Bun, Jonathan Ullman, and Salil Vadhan. Fingerprinting codes and the price of approximate differential privacy. STOC ’14.</p>
<p><a name="CBRG18"/>[CBRG18] Zachary Campbell, Andrew Bray, Anna Ritz, and Adam Groce. Differentially private ANOVA testing. ICDIS ’18.</p>
<p><a name="CDK17"/>[CDK17] Bryan Cai, Constantinos Daskalakis, and Gautam Kamath. Priv’it: Private and sample efficient identity testing. ICML ’17.</p>
<p><a name="CKLZ19"/>[CKLZ19] Rachel Cummings, Sara Krehbiel, Yuliia Lut, and Wanrong Zhang. Privately detecting changes in unknown distributions. arXiv, 1910.01327, 2019.</p>
<p><a name="CKMSU19"/>[CKMSU19] Clément L. Canonne, Gautam Kamath, Audra McMillan, Adam Smith, and Jonathan Ullman. The structure of optimal private tests for simple hypotheses. STOC ’19.</p>
<p><a name="CKMTZ18"/>[CKMTZ18] Rachel Cummings, Sara Krehbiel, Yajun Mei, Rui Tuo, and Wanrong Zhang. Differentially private change-point detection. NeurIPS ’18.</p>
<p><a name="CKMUZ19"/>[CKMUZ19] Clément L. Canonne, Gautam Kamath, Audra McMillan, Jonathan Ullman, and Lydia Zakynthinou. Private identity testing for high-dimensional distributions. arXiv, 1905.11947, 2019.</p>
<p><a name="CKSBG19"/>[CKSBG19] Simon Couch, Zeki Kazan, Kaiyan Shi, Andrew Bray, and Adam Groce. Differentially private nonparametric hypothesis testing. CCS ’19.</p>
<p><a name="CWZ19"/>[CWZ19] T. Tony Cai, Yichen Wang, and Linjun Zhang. The cost of privacy: Optimal rates of convergence for parameter estimation with differential privacy. arXiv, 1902.04495, 2019.</p>
<p><a name="CZ13"/>[CZ13] Shixi Chen and Shuigeng Zhou. Recursive mechanism: Towards node differential privacy and unrestricted joins. SIGMOD ’13.</p>
<p><a name="DHS15"/>[DHS15] Ilias Diakonikolas, Moritz Hardt, and Ludwig Schmidt. Differentially private learning of structured discrete distributions. NIPS ’15.</p>
<p><a name="DKW56"/>[DKW56] Aryeh Dvoretzky, Jack Kiefer, and Jacob Wolfowitz. Asymptotic minimax character of the sample distribution function and of the classical multinomial estimator. The Annals of Mathematical Statistics, 27(3), 1956.</p>
<p><a name="DL09"/>[DL09] Cynthia Dwork and Jing Lei. Differential privacy and robust statistics. STOC ’09.</p>
<p><a name="DMNS06"/>[DMNS06] Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith. Calibrating noise to sensitivity in private data analysis. TCC ’06.</p>
<p><a name="DN03"/>[DN03] Irit Dinur and Kobbi Nissim. Revealing information while preserving privacy. PODS ’03.</p>
<p><a name="DN04"/>[DN04] Cynthia Dwork and Kobbi Nissim. Privacy-preserving datamining on vertically partitioned databases. CRYPTO ’04.</p>
<p><a name="DSSUV15"/>[DSSUV15] Cynthia Dwork, Adam Smith, Thomas Steinke, Jonathan Ullman, and Salil Vadhan. Robust traceability from trace amounts. FOCS ’15.</p>
<p><a name="EKKL20"/>[EKKL20] Marek Eliáš, Michael Kapralov, Janardhan Kulkarni, and Yin Tat Lee. Differentially private release of synthetic graphs. SODA ’20.</p>
<p><a name="GLRV16"/>[GLRV16] Marco Gaboardi, Hyun-Woo Lim, Ryan M. Rogers, and Salil P. Vadhan. Differentially private chi-squared hypothesis testing: Goodness of fit and independence testing. ICML ’16.</p>
<p><a name="GRU12"/>[GRU12] Anupam Gupta, Aaron Roth, and Jonathan Ullman. Iterative constructions and private data release. TCC ’12.</p>
<p><a name="HSRDTMPSNC08"/>[HSRDTMPSNC08] Nils Homer, Szabolcs Szelinger, Margot Redman, David Duggan, Waibhav Tembe, Jill Muehling, John V. Pearson, Dietrich A. Stephan, Stanley F. Nelson, and David W. Craig. PLoS Genetics, 4(8), 2008.</p>
<p><a name="KLSU19"/>[KLSU19] Gautam Kamath, Jerry Li, Vikrant Singhal, and Jonathan Ullman. Privately learning high-dimensional distributions. COLT ’19.</p>
<p><a name="KNRS13"/>[KNRS13] Shiva Prasad Kasiviswanathan, Kobbi Nissim, Sofya Raskhodnikova, and Adam Smith. Analyzing graphs with node differential privacy. TCC ’13.</p>
<p><a name="KR17"/>[KR17] Daniel Kifer and Ryan M. Rogers. A new class of private chi-square tests. AISTATS ’17.</p>
<p><a name="KRSY11"/>[KRSY11] Vishesh Karwa, Sofya Raskhodnikova, Adam Smith, and Grigory Yaroslavtsev. Private analysis of graph structure. VLDB ’11.</p>
<p><a name="KS16"/>[KS16] Vishesh Karwa and Aleksandra Slavković. Inference using noisy degrees: Differentially private β-model and synthetic graphs. The Annals of Statistics, 44(1), 2016.</p>
<p><a name="KSF17"/>[KSF17] Kazuya Kakizaki, Jun Sakuma, and Kazuto Fukuchi. Differentially private chi-squared test by unit circle mechanism. ICML ’17.</p>
<p><a name="KSU20"/>[KSU20] Gautam Kamath, Vikrant Singhal, and Jonathan Ullman. Private mean estimation of heavy-tailed distributions. arXiv, 2002.09464, 2020.</p>
<p><a name="KV18"/>[KV18] Vishesh Karwa and Salil Vadhan. Finite sample differentially private confidence intervals. ITCS ’18.</p>
<p><a name="Mas90"/>[Mas90] Pascal Massart. The tight constant in the Dvoretzky-Kiefer-Wolfowitz inequality. The Annals of Probability, 18(3), 1990.</p>
<p><a name="NRS07"/>[NRS07] Kobbi Nissim, Sofya Raskhodnikova, and Adam Smith. Smooth sensitivity and sampling in private data analysis. STOC ’07.</p>
<p><a name="RS16"/>[RS16] Sofya Raskhodnikova and Adam D. Smith. Lipschitz extensions for node-private graph statistics and the generalized exponential mechanism. FOCS ’16.</p>
<p><a name="Smi11"/>[Smi11] Adam Smith. Privacy-preserving statistical estimation with optimal convergence rates. STOC ’11.</p>
<p><a name="SGGRGB19"/>[SGGRGB19] Marika Swanberg, Ira Globus-Harris, Iris Griffith, Anna Ritz, Adam Groce, and Andrew Bray. Improved differentially private analysis of variance. PETS ’19.</p>
<p><a name="SU17a"/>[SU17a] Thomas Steinke and Jonathan Ullman. Between pure and approximate differential privacy. Journal of Privacy and Confidentiality, 7(2), 2017.</p>
<p><a name="SU17b"/>[SU17b] Thomas Steinke and Jonathan Ullman. Tight lower bounds for differentially private selection. FOCS ’17.</p>
<p><a name="SU19"/>[SU19] Adam Sealfon and Jonathan Ullman. Efficiently estimating Erdos-Renyi graphs with node differential privacy. NeurIPS ’19.</p>
<p><a name="Upa13"/>[Upa13] Jalaj Upadhyay. Random projections, graph sparsification, and differential privacy. ASIACRYPT ’13.</p>
<p><a name="USF13"/>[USF13] Caroline Uhler, Aleksandra Slavković, and Stephen E. Fienberg. Privacy-preserving data sharing for genome-wide association studies. The Journal of Privacy and Confidentiality, 5(1), 2013.</p>
<p><a name="VS09"/>[VS09] Duy Vu and Aleksandra Slavković. Differential privacy for clinical trial data: Preliminary evaluations. ICDMW ’09.</p>
<p><a name="WKLK18"/>[WKLK18] Yue Wang, Daniel Kifer, Jaewoo Lee, and Vishesh Karwa. Statistical approximating distributions under differential privacy. The Journal of Privacy and Confidentiality, 8(1), 2018.</p>
<p><a name="WLK15"/>[WLK15] Yue Wang, Jaewoo Lee, and Daniel Kifer. Revisiting differentially private hypothesis tests for categorical data. arXiv, 1511.03376, 2015.</p>
<p><a name="YFSU14"/>[YFSU14] Fei Yu, Stephen E. Fienberg, Aleksandra B. Slavković, and Caroline Uhler. Scalable privacy-preserving data sharing methodology for genome-wide association studies. Journal of Biomedical Informatics, 50, 2014.</p>
<p><a name="ZKKW20"/>[ZKKW20] Huanyu Zhang, Gautam Kamath, Janardhan Kulkarni, and Zhiwei Steven Wu. Privately learning Markov random fields. arXiv, 2002.09463, 2020.</p></div>
    </content>
    <updated>2020-04-21T13:36:53Z</updated>
    <published>2020-04-21T13:36:53Z</published>
    <category term="Technical"/>
    <author>
      <name>Gautam</name>
    </author>
    <source>
      <id>https://kamathematics.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://kamathematics.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://kamathematics.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://kamathematics.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://kamathematics.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Kamathematics</title>
      <updated>2020-08-26T22:24:34Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2020/04/20/workshop-on-local-algorithms/</id>
    <link href="https://cstheory-events.org/2020/04/20/workshop-on-local-algorithms/" rel="alternate" type="text/html"/>
    <title>Workshop on Local Algorithms</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">July 20-21, 2020 Virtual (8am — 12pm Pacific Time) https://www.mit.edu/~mahabadi/workshops/WOLA-2020.html Submission deadline: May 15, 2020 Registration deadline: June 30, 2020 Due to the current situation with COVID-19, we have decided to hold a virtual and shorter version of WOLA this year. WOLA 2020 will run for two days between 8am – 12pm PT to maximize … <a class="more-link" href="https://cstheory-events.org/2020/04/20/workshop-on-local-algorithms/">Continue reading <span class="screen-reader-text">Workshop on Local Algorithms</span></a></div>
    </summary>
    <updated>2020-04-20T20:26:48Z</updated>
    <published>2020-04-20T20:26:48Z</published>
    <category term="workshop"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2020-08-26T22:24:08Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://tcsplus.wordpress.com/?p=415</id>
    <link href="https://tcsplus.wordpress.com/2020/04/19/tcs-talk-wednesday-april-22-huacheng-yu-princeton/" rel="alternate" type="text/html"/>
    <title>TCS+ talk: Wednesday, April 22 — Huacheng Yu, Princeton</title>
    <summary>The next TCS+ talk will take place this coming Wednesday, April 22nd at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). Huacheng Yu from Princeton will speak about a “Nearly Optimal Static Las Vegas Succinct Dictionary” (abstract below). You can reserve a spot as an individual or a group […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The next TCS+ talk will take place this coming Wednesday, April 22nd at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). <strong>Huacheng Yu</strong> from Princeton will speak about a “<em>Nearly Optimal Static Las Vegas Succinct Dictionary</em>” (abstract below).</p>
<p>You can reserve a spot as an individual or a group to join us live by signing up on <a href="https://sites.google.com/site/plustcs/livetalk">the online form</a>. Due to security concerns, <strong>registration is required</strong> to attend the interactive talk. (The link to the YouTube livestream will also be posted <a>on our website</a> on the day of the talk, so people who did not sign up will still be able to watch the talk live.) As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/site/plustcs/suggest">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/site/plustcs/">the website</a>.</p>
<blockquote><p>Abstract: Given a set <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=fff&amp;fg=444444&amp;s=0" title="S"/> of <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=fff&amp;fg=444444&amp;s=0" title="n"/> (distinct) keys from key space <img alt="[U]" class="latex" src="https://s0.wp.com/latex.php?latex=%5BU%5D&amp;bg=fff&amp;fg=444444&amp;s=0" title="[U]"/>, each associated with a value from <img alt="\Sigma" class="latex" src="https://s0.wp.com/latex.php?latex=%5CSigma&amp;bg=fff&amp;fg=444444&amp;s=0" title="\Sigma"/>, the <em>static dictionary problem</em> asks to preprocess these (key, value) pairs into a data structure, supporting value-retrieval queries: for any given <img alt="x \in [U]" class="latex" src="https://s0.wp.com/latex.php?latex=x+%5Cin+%5BU%5D&amp;bg=fff&amp;fg=444444&amp;s=0" title="x \in [U]"/>, valRet<img alt="(x)" class="latex" src="https://s0.wp.com/latex.php?latex=%28x%29&amp;bg=fff&amp;fg=444444&amp;s=0" title="(x)"/> must return the value associated with <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=fff&amp;fg=444444&amp;s=0" title="x"/> if <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=fff&amp;fg=444444&amp;s=0" title="x"/> is in <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=fff&amp;fg=444444&amp;s=0" title="S"/>, or return “N/A” if <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=fff&amp;fg=444444&amp;s=0" title="x"/> is not in <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=fff&amp;fg=444444&amp;s=0" title="S"/>. The special case where <img alt="|\Sigma|=1" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5CSigma%7C%3D1&amp;bg=fff&amp;fg=444444&amp;s=0" title="|\Sigma|=1"/> is called the membership problem. The “textbook” solution is to use a hash table, which occupies linear space and answers each query in constant time. On the other hand, the minimum possible space to encode all (key, value) pairs is only <img alt="\textrm{OPT} := \lg \binom{U}{n} + n \lg |\Sigma|" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctextrm%7BOPT%7D+%3A%3D+%5Clg+%5Cbinom%7BU%7D%7Bn%7D+%2B+n+%5Clg+%7C%5CSigma%7C&amp;bg=fff&amp;fg=444444&amp;s=0" title="\textrm{OPT} := \lg \binom{U}{n} + n \lg |\Sigma|"/> bits, which could be much less.</p>
<p>In this talk, we will talk about a randomized dictionary data structure using <img alt="\textrm{OPT}+\textrm{poly}\lg n+O(\lg\lg\cdots\lg U)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctextrm%7BOPT%7D%2B%5Ctextrm%7Bpoly%7D%5Clg+n%2BO%28%5Clg%5Clg%5Ccdots%5Clg+U%29&amp;bg=fff&amp;fg=444444&amp;s=0" title="\textrm{OPT}+\textrm{poly}\lg n+O(\lg\lg\cdots\lg U)"/> bits of space and expected constant query time, assuming the query algorithm have access to an external data-independent lookup table of size <img alt="n^{0.001}" class="latex" src="https://s0.wp.com/latex.php?latex=n%5E%7B0.001%7D&amp;bg=fff&amp;fg=444444&amp;s=0" title="n^{0.001}"/>. Previously, even for membership queries and when <img alt="U\leq n^{O(1)}" class="latex" src="https://s0.wp.com/latex.php?latex=U%5Cleq+n%5E%7BO%281%29%7D&amp;bg=fff&amp;fg=444444&amp;s=0" title="U\leq n^{O(1)}"/>, the best known data structure with constant query time requires <img alt="\textrm{OPT}+n/\textrm{poly} \lg n" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctextrm%7BOPT%7D%2Bn%2F%5Ctextrm%7Bpoly%7D+%5Clg+n&amp;bg=fff&amp;fg=444444&amp;s=0" title="\textrm{OPT}+n/\textrm{poly} \lg n"/> bits of space (due to Pagh [Pagh’01] and Pătraşcu [Pat’08]). It has <img alt="O(\lg n)" class="latex" src="https://s0.wp.com/latex.php?latex=O%28%5Clg+n%29&amp;bg=fff&amp;fg=444444&amp;s=0" title="O(\lg n)"/> query time when the space is at most <img alt="\textrm{OPT}+n^{0.999}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctextrm%7BOPT%7D%2Bn%5E%7B0.999%7D&amp;bg=fff&amp;fg=444444&amp;s=0" title="\textrm{OPT}+n^{0.999}"/>.</p></blockquote></div>
    </content>
    <updated>2020-04-19T18:01:40Z</updated>
    <published>2020-04-19T18:01:40Z</published>
    <category term="Announcements"/>
    <author>
      <name>plustcs</name>
    </author>
    <source>
      <id>https://tcsplus.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://tcsplus.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://tcsplus.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://tcsplus.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://tcsplus.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A carbon-free dissemination of ideas across the globe.</subtitle>
      <title>TCS+</title>
      <updated>2020-08-26T22:24:02Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://kamathematics.wordpress.com/?p=49</id>
    <link href="https://kamathematics.wordpress.com/2020/04/14/a-primer-on-private-statistics-part-i/" rel="alternate" type="text/html"/>
    <title>A Primer on Private Statistics – Part I</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">By Gautam Kamath and Jonathan Ullman Differentially private statistics is a very lively research area, and has seen a lot of activity in the last couple years. While the phrasing is a slight departure from previous work which focused on estimation with worst-case datasets, it turns out that the differences are often superficial. In a … <a class="more-link" href="https://kamathematics.wordpress.com/2020/04/14/a-primer-on-private-statistics-part-i/">Continue reading<span class="screen-reader-text"> "A Primer on Private Statistics – Part I"</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>By <a href="http://www.gautamkamath.com/">Gautam Kamath</a> and <a href="http://www.ccs.neu.edu/home/jullman/">Jonathan Ullman</a></p>
<p>Differentially private statistics is a very lively research area, and has seen a lot of activity in the last couple years. While the phrasing is a slight departure from previous work which focused on estimation with worst-case datasets, it turns out that the differences are often superficial. In a short series of blog posts, we hope to educate readers on some of the recent advancements in this area, as well as shed light on some of the connections between the old and the new. We’ll describe the settings, cover a couple of technical examples, and give pointers to some other directions in the area. Thanks to <a href="https://cs-people.bu.edu/ads22/">Adam Smith</a> for helping kick off this project, <a href="http://www.cs.columbia.edu/~ccanonne/">Clément Canonne</a>, <a href="https://www.cis.upenn.edu/~aaroth/">Aaron Roth</a>, and <a href="http://www.thomas-steinke.net/">Thomas Steinke</a> for helpful comments, and <a href="https://lucatrevisan.github.io/">Luca Trevisan</a> for his <a href="https://lucatrevisan.wordpress.com/latex-to-wordpress/">LaTeX2WP script</a>.</p>
<p><b>1. Introduction </b></p>
<p>Statistics and machine learning are now ubiquitous in data analysis. Given a dataset, one immediately wonders what it allows us to infer about the underlying population. However, modern datasets don’t exist in a vacuum: they often contain sensitive information about the individuals they represent. Without proper care, statistical procedures will result in gross violations of privacy. Motivated by the shortcomings of ad hoc methods for data anonymization, Dwork, McSherry, Nissim, and Smith introduced the celebrated notion of differential privacy [<a href="https://kamathematics.wordpress.com/feed/#DMNS06">DMNS06</a>].</p>
<p>From its inception, some of the driving motivations for differential privacy were applications in statistics and the social sciences, notably disclosure limitation for the US Census. And yet, the lion’s share of differential privacy research has taken place within the computer science community. As a result, the specific applications being studied are often not formulated using statistical terminology, or even as statistical problems. Perhaps most significantly, much of the early work in computer science (though definitely not all) focus on estimating some property <em>of a dataset</em> rather than estimating some property <em>of an underlying population</em>.</p>
<p>Although the earliest works exploring the interaction between differential privacy and classical statistics go back to at least 2009 [<a href="https://kamathematics.wordpress.com/feed/#VS09">VS09</a>,<a href="https://kamathematics.wordpress.com/feed/#FRY10">FRY10</a>], the emphasis on differentially private statistical inference in the computer science literature is somewhat more recent. However, while earlier results on differential privacy did not always formulate problems in a statistical language, statistical inference was a key motivation for most of this work. As a result many of the techniques that were developed have direct applications in statistics, for example establishing minimax rates for estimation problems.</p>
<p>The purpose of this series of blog posts is to highlight some of those results in the computer science literature, and present them in a more statistical language. Specifically, we will discuss:</p>
<ul>
<li>Tight minimax lower bounds for privately estimating the mean of a multivariate distribution over <img alt="{{\mathbb R}^d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb+R%7D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{\mathbb R}^d}"/>, using the technique of <em>tracing attacks</em> developed in [<a href="https://kamathematics.wordpress.com/feed/#BUV14">BUV14</a>,<a href="https://kamathematics.wordpress.com/feed/#DSSUV15">DSSUV15</a>, <a href="https://kamathematics.wordpress.com/feed/#BSU17">BSU17</a>, <a href="https://kamathematics.wordpress.com/feed/#SU17a">SU17a</a>, <a href="https://kamathematics.wordpress.com/feed/#SU17b">SU17b</a>, <a href="https://kamathematics.wordpress.com/feed/#KLSU19">KLSU19</a>].
<p> </p>
</li>
<li>Upper bounds for estimating a distribution in Kolmogorov distance, using the ubiquitous <em>binary-tree mechanism</em> introduced in [<a href="https://kamathematics.wordpress.com/feed/#DNPR10">DNPR10</a>,<a href="https://kamathematics.wordpress.com/feed/#CSS11">CSS11</a>].</li>
</ul>
<p>In particular, we hope to encourage computer scientists working on differential privacy to pay more attention to the applications of their methods in statistics, and share with statisticians many of the powerful techniques that have been developed in the computer science literature.</p>
<p> </p>
<p><b> 1.1. Formulating Private Statistical Inference </b></p>
<p>Essentially every differentially private statistical estimation task can be phrased using the following setup. We are given a dataset <img alt="{X = (X_1, \dots, X_n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX+%3D+%28X_1%2C+%5Cdots%2C+X_n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X = (X_1, \dots, X_n)}"/> of size <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>, and we wish to design an algorithm <img alt="{M \in \mathcal{M}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM+%5Cin+%5Cmathcal%7BM%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M \in \mathcal{M}}"/> where <img alt="{\mathcal{M}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BM%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{M}}"/> is the class of mechanisms that are both:</p>
<ol>
<li>differentially private, and</li>
<li>accurate, either in expectation or with high probability, according to some task-specific measure.</li>
</ol>
<p>A few comments about this framework are in order. First, although the accuracy requirement is stochastic in nature (i.e., an algorithm might not be accurate depending on the randomness of the algorithm and the data generation process), the privacy requirement is worst-case in nature. That is, the algorithm must protect privacy for every dataset <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X}"/>, even those we believe are very unlikely.</p>
<p>Second, the accuracy requirement is stated rather vaguely. This is because the notion of accuracy of an algorithm is slightly more nuanced, depending on whether we are concerned with <em>empirical</em> or <em>population</em> statistics. A particular emphasis of these blog posts is to explore the difference (or, as we will see, the lack of a difference) between these two notions of accuracy. The former estimates a quantity of the observed dataset, while the latter estimates a quantity of an unobserved distribution which is assumed to have generated the dataset.</p>
<p>More precisely, the former can be phrased in terms of empirical loss, of the form:</p>
<p align="center"><img alt="\displaystyle \min_{M \in \mathcal{M}}~\max_{X \in \mathcal{X}}~\mathop{\mathbb E}_M(\ell(M(X), f(X))), " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmin_%7BM+%5Cin+%5Cmathcal%7BM%7D%7D%7E%5Cmax_%7BX+%5Cin+%5Cmathcal%7BX%7D%7D%7E%5Cmathop%7B%5Cmathbb+E%7D_M%28%5Cell%28M%28X%29%2C+f%28X%29%29%29%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \min_{M \in \mathcal{M}}~\max_{X \in \mathcal{X}}~\mathop{\mathbb E}_M(\ell(M(X), f(X))), "/></p>
<p>where <img alt="{\mathcal{M}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BM%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{M}}"/> is some class of <em>randomized estimators</em> (e.g., differentially private estimators), <img alt="{\mathcal{X}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BX%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{X}}"/> is some class of <em>datasets</em>, <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/> is some quantity of interest, and <img alt="{\ell}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\ell}"/> is some <em>loss function</em>. That is, we’re looking to find an estimator that has small expected loss on <em>any dataset</em> in some class.</p>
<p>In contrast, statistical minimax theory looks at statements about population loss, of the form:</p>
<p align="center"><img alt="\displaystyle \min_{M \in \mathcal{M}}~\max_{P \in \mathcal{P}}~\mathop{\mathbb E}_{X \sim P, M}(\ell(M(X),f(P))), " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmin_%7BM+%5Cin+%5Cmathcal%7BM%7D%7D%7E%5Cmax_%7BP+%5Cin+%5Cmathcal%7BP%7D%7D%7E%5Cmathop%7B%5Cmathbb+E%7D_%7BX+%5Csim+P%2C+M%7D%28%5Cell%28M%28X%29%2Cf%28P%29%29%29%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \min_{M \in \mathcal{M}}~\max_{P \in \mathcal{P}}~\mathop{\mathbb E}_{X \sim P, M}(\ell(M(X),f(P))), "/></p>
<p>where <img alt="{\mathcal{P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{P}}"/> is some family of <em>distributions</em> over datasets (typically consisting of i.i.d. samples). That is, we’re looking to find an estimator that has small expected loss on random data from <em>any distribution</em> in some class. In particular, note that the randomness in this objective additionally includes the data generating procedure <img alt="{X \sim P}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX+%5Csim+P%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X \sim P}"/>.</p>
<p>These two formulations are formally very different in several ways. First, the empirical formulation requires an estimator to have small loss on <em>worst-case</em> datasets, whereas the statistical formulation only requires the estimator to have small loss <em>on average</em> over datasets drawn from certain distributions. Second, the statistical formulation requires that we estimate the unknown quantity <img alt="{f(P)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28P%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(P)}"/>, and thus necessitates a solution to the non-private estimation problem. On the other hand, the empirical formulation only asks us to estimate the known quantity <img alt="{f(X)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(X)}"/>, and thus if there were no privacy constraint it would always be possible to compute <img alt="{f(X)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(X)}"/> exactly. Third, typically in the statistical formulation, we require that the dataset is drawn i.i.d., which means that we are more constrained when proving lower bounds for estimation than we are in the empirical problem.</p>
<p>However, in practice (more precisely, in the practice of doing theoretical research), these two formulations are more alike than they are different, and results about one formulation often imply results about the other formulation. On the algorithmic side, classical statistical results will often tell us that <img alt="{\ell(f(X),f(P))}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell%28f%28X%29%2Cf%28P%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\ell(f(X),f(P))}"/> is small, in which case algorithms that guarantee <img alt="{\ell(M(X),f(X))}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell%28M%28X%29%2Cf%28X%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\ell(M(X),f(X))}"/> is small also guarantee <img alt="{\ell(M(X),f(P))}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell%28M%28X%29%2Cf%28P%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\ell(M(X),f(P))}"/> is small.</p>
<p>Moreover, typical lower bound arguments for empirical quantities are often statistical in nature. These typically involving constructing some simple “hard distribution” over datasets such that no private algorithm can estimate well on average for this distribution, and thus these lower bound arguments also apply to estimating population statistics for some simple family of distributions. We will proceed to give some examples of estimation problems that were originally studied by computer scientists with the empirical formulation in mind. These results either implicitly or explicitly provide solutions to the corresponding population versions of the same problems—our goal is to spell out and illustrate these connections.</p>
<p><b>2. DP Background </b></p>
<p>Let <img alt="{X = (X_1,X_2,\dots,X_n) \in \mathcal{X}^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX+%3D+%28X_1%2CX_2%2C%5Cdots%2CX_n%29+%5Cin+%5Cmathcal%7BX%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X = (X_1,X_2,\dots,X_n) \in \mathcal{X}^n}"/> be a collection of <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> samples where each individual sample comes from the domain <img alt="{\mathcal{X}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BX%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{X}}"/>. We say that two samples <img alt="{X,X' \in \mathcal{X}^*}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%2CX%27+%5Cin+%5Cmathcal%7BX%7D%5E%2A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X,X' \in \mathcal{X}^*}"/> are <em>adjacent</em>, denoted <img alt="{X \sim X'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX+%5Csim+X%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X \sim X'}"/>, if they differ on at most one individual sample. Intuitively, a randomized algorithm <img alt="{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M}"/>, which is often called a <em>mechanism</em> for historical reasons, is <em>differentially private</em> if the distribution of <img alt="{M(X)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M(X)}"/> and <img alt="{M(X')}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%28X%27%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M(X')}"/> are similar for every pair of adjacent samples <img alt="{X,X'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%2CX%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X,X'}"/>.</p>
<blockquote>
<p><b>Definition 1 ([<a href="https://kamathematics.wordpress.com/feed/#DMNS06">DMNS06</a>])</b><em> A mechanism <img alt="{M \colon \mathcal{X}^n \rightarrow \mathcal{R}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM+%5Ccolon+%5Cmathcal%7BX%7D%5En+%5Crightarrow+%5Cmathcal%7BR%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M \colon \mathcal{X}^n \rightarrow \mathcal{R}}"/> is <em><img alt="{(\epsilon,\delta)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28%5Cepsilon%2C%5Cdelta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(\epsilon,\delta)}"/>-differentially private</em> if for every pair of adjacent datasets <img alt="{X \sim X'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX+%5Csim+X%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X \sim X'}"/>, and every (measurable) <img alt="{R \subseteq R}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR+%5Csubseteq+R%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R \subseteq R}"/> </em></p>
<p align="center"><img alt="\displaystyle \mathop{\mathbb P}(M(X) \in R) \leq e^{\epsilon} \cdot \mathop{\mathbb P}(M(X') \in R) + \delta. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmathop%7B%5Cmathbb+P%7D%28M%28X%29+%5Cin+R%29+%5Cleq+e%5E%7B%5Cepsilon%7D+%5Ccdot+%5Cmathop%7B%5Cmathbb+P%7D%28M%28X%27%29+%5Cin+R%29+%2B+%5Cdelta.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \mathop{\mathbb P}(M(X) \in R) \leq e^{\epsilon} \cdot \mathop{\mathbb P}(M(X') \in R) + \delta. "/></p>
<p> </p>
</blockquote>
<p>We let <img alt="{\mathcal{M}_{\epsilon,\delta}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BM%7D_%7B%5Cepsilon%2C%5Cdelta%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{M}_{\epsilon,\delta}}"/> denote the set of mechanisms that satisfy <img alt="{(\epsilon,\delta)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28%5Cepsilon%2C%5Cdelta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(\epsilon,\delta)}"/>-differential privacy.</p>
<blockquote>
<p><b>Remark 1</b> <em> To simplify notation, and to maintain consistency with the literature, we adopt the convention of defining the mechanism only for a fixed sample size <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>. What this means in practice is that the mechanisms we describe treat the sample size <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> is <em>public information</em> that need not be kept private. While one could define a more general model where <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> is not fixed, it wouldn’t add anything to this discussion other than additional complexity. </em></p>
</blockquote>
<blockquote>
<p><b>Remark 2</b> <em> In these blog posts, we stick to the most general formulation of differential privacy, so-called <em>approximate differential privacy</em>, i.e. <img alt="{(\epsilon,\delta)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28%5Cepsilon%2C%5Cdelta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(\epsilon,\delta)}"/>-differential privacy for <img alt="{\delta &gt; 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+%3E+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\delta &gt; 0}"/> essentially because this is the notion that captures the widest variety of private mechanisms. Almost all of what follows would apply equally well, with minor technical modifications, to slightly stricter notions of <em>concentrated differential privacy [</em><a href="https://kamathematics.wordpress.com/feed/#DR16">DR16</a>, <a href="https://kamathematics.wordpress.com/feed/#BS16">BS16</a>, <a href="https://kamathematics.wordpress.com/feed/#BDRS18">BDRS18</a>], Rényi differential privacy [<a href="https://kamathematics.wordpress.com/feed/#Mir17">Mir17</a>], or <em>Gaussian differential privacy [<a href="https://kamathematics.wordpress.com/feed/#DRS19">DRS19</a>]</em>. While so-called <em>pure differential privacy</em>, i.e. <img alt="{(\epsilon,0)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28%5Cepsilon%2C0%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(\epsilon,0)}"/>-differential privacy has also been studied extensively, this notion is artificially restrictive and excludes many differentially private mechanisms. </em></p>
</blockquote>
<p>A key property of differential privacy that helps when desinging efficient estimators is <em>closure under postprocessing</em>:</p>
<blockquote>
<p><b>Lemma 2 (Post-Processing [<a href="https://kamathematics.wordpress.com/feed/#DMNS06">DMNS06</a>])</b><em> <a name="lempost-processing"/> If <img alt="{M \colon \mathcal{X}^n \rightarrow \mathcal{R}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM+%5Ccolon+%5Cmathcal%7BX%7D%5En+%5Crightarrow+%5Cmathcal%7BR%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M \colon \mathcal{X}^n \rightarrow \mathcal{R}}"/> is <img alt="{(\epsilon,\delta)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28%5Cepsilon%2C%5Cdelta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(\epsilon,\delta)}"/>-differentially private and <img alt="{M' \colon \mathcal{R} \rightarrow \mathcal{R}'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%27+%5Ccolon+%5Cmathcal%7BR%7D+%5Crightarrow+%5Cmathcal%7BR%7D%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M' \colon \mathcal{R} \rightarrow \mathcal{R}'}"/> is any randomized algorithm, then <img alt="{M' \circ M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%27+%5Ccirc+M%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M' \circ M}"/> is <img alt="{(\epsilon,\delta)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28%5Cepsilon%2C%5Cdelta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(\epsilon,\delta)}"/>-differentially private. </em></p>
</blockquote>
<p>The estimators we present in this work will use only one tool for achieving differential privacy, the <em>Gaussian Mechanism</em>.</p>
<blockquote>
<p><b>Lemma 3 (Gaussian Mechanism)</b> <em> <a name="lemgauss-mech"/> Let <img alt="{f \colon \mathcal{X}^n \rightarrow {\mathbb R}^d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf+%5Ccolon+%5Cmathcal%7BX%7D%5En+%5Crightarrow+%7B%5Cmathbb+R%7D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f \colon \mathcal{X}^n \rightarrow {\mathbb R}^d}"/> be a function and let </em></p>
<p align="center"><img alt="\displaystyle \Delta_{f} = \sup_{X\sim X'} \| f(X) - f(X') \|_2 " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5CDelta_%7Bf%7D+%3D+%5Csup_%7BX%5Csim+X%27%7D+%5C%7C+f%28X%29+-+f%28X%27%29+%5C%7C_2+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \Delta_{f} = \sup_{X\sim X'} \| f(X) - f(X') \|_2 "/></p>
<p>denote its <em><img alt="{\ell_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\ell_2}"/>-sensitivity</em>. The <em>Gaussian mechanism</em></p>
<p align="center"><img alt="\displaystyle M(X) = f(X) + \mathcal{N}\left(0 , \frac{2 \log(2/\delta)}{\epsilon^2} \cdot \Delta_{f}^2 \cdot {\mathbb I}_{d \times d} \right) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+M%28X%29+%3D+f%28X%29+%2B+%5Cmathcal%7BN%7D%5Cleft%280+%2C+%5Cfrac%7B2+%5Clog%282%2F%5Cdelta%29%7D%7B%5Cepsilon%5E2%7D+%5Ccdot+%5CDelta_%7Bf%7D%5E2+%5Ccdot+%7B%5Cmathbb+I%7D_%7Bd+%5Ctimes+d%7D+%5Cright%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle M(X) = f(X) + \mathcal{N}\left(0 , \frac{2 \log(2/\delta)}{\epsilon^2} \cdot \Delta_{f}^2 \cdot {\mathbb I}_{d \times d} \right) "/></p>
<p><em> satisfies <img alt="{(\epsilon,\delta)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28%5Cepsilon%2C%5Cdelta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(\epsilon,\delta)}"/>-differential privacy. </em></p>
</blockquote>
<p><b>3. Mean Estimation in <img alt="{{\mathbb R}^d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb+R%7D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{\mathbb R}^d}"/> </b></p>
<p>Let’s take a dive into the problem of <em>private mean estimation</em> for some family <img alt="{\mathcal{P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{P}}"/> of multivariate distributions over <img alt="{{\mathbb R}^d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb+R%7D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{\mathbb R}^d}"/>. This problem has been studied for various families <img alt="{\mathcal{P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{P}}"/> and various choices of loss function. Here we focus on perhaps the simplest variant of the problem, in which <img alt="{\mathcal{P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{P}}"/> contains distributions of bounded support <img alt="{[\pm 1]^d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5B%5Cpm+1%5D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{[\pm 1]^d}"/> and the loss is the <img alt="{\ell_2^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell_2%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\ell_2^2}"/> error. We emphasize, however, that the methods we discuss here are quite versatile and can be used to derive minimax bounds for other variants of the mean-estimation problem.</p>
<p>Note that, by a simple argument, the non-private minimax rate for this class is achieved by the empirical mean, and is</p>
<p align="center"><img alt="\displaystyle \max_{P \in \mathcal{P}} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| \overline{X} - \mu\|_2^2) = \frac{d}{n}. \ \ \ \ \ (1)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmax_%7BP+%5Cin+%5Cmathcal%7BP%7D%7D+%5Cmathop%7B%5Cmathbb+E%7D_%7BX_%7B1+%5Ccdots+n%7D+%5Csim+P%7D%28%5C%7C+%5Coverline%7BX%7D+-+%5Cmu%5C%7C_2%5E2%29+%3D+%5Cfrac%7Bd%7D%7Bn%7D.+%5C+%5C+%5C+%5C+%5C+%281%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \max_{P \in \mathcal{P}} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| \overline{X} - \mu\|_2^2) = \frac{d}{n}. \ \ \ \ \ (1)"/></p>
<p>The main goal of this section is to derive the minimax bound <a name="eqRd-minimax"/></p>
<p align="center"><img alt="\displaystyle \min_{M \in \mathcal{M}_{\epsilon,\frac{1}{n}}} \max_{P \in \mathcal{P}} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| M(X_{1 \cdots n}) - \mu \|_2^2) = \frac{d}{n} + \tilde\Theta\left(\frac{d^2}{\epsilon^2 n^2}\right). \ \ \ \ \ (2)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmin_%7BM+%5Cin+%5Cmathcal%7BM%7D_%7B%5Cepsilon%2C%5Cfrac%7B1%7D%7Bn%7D%7D%7D+%5Cmax_%7BP+%5Cin+%5Cmathcal%7BP%7D%7D+%5Cmathop%7B%5Cmathbb+E%7D_%7BX_%7B1+%5Ccdots+n%7D+%5Csim+P%7D%28%5C%7C+M%28X_%7B1+%5Ccdots+n%7D%29+-+%5Cmu+%5C%7C_2%5E2%29+%3D+%5Cfrac%7Bd%7D%7Bn%7D+%2B+%5Ctilde%5CTheta%5Cleft%28%5Cfrac%7Bd%5E2%7D%7B%5Cepsilon%5E2+n%5E2%7D%5Cright%29.+%5C+%5C+%5C+%5C+%5C+%282%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \min_{M \in \mathcal{M}_{\epsilon,\frac{1}{n}}} \max_{P \in \mathcal{P}} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| M(X_{1 \cdots n}) - \mu \|_2^2) = \frac{d}{n} + \tilde\Theta\left(\frac{d^2}{\epsilon^2 n^2}\right). \ \ \ \ \ (2)"/></p>
<p><a name="eqRd-minimax"/> Recall that <img alt="{\tilde \Theta(f(n))}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctilde+%5CTheta%28f%28n%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\tilde \Theta(f(n))}"/> refers to a function which is both <img alt="{O(f(n) \log^{c_1} f(n))}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%28f%28n%29+%5Clog%5E%7Bc_1%7D+f%28n%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{O(f(n) \log^{c_1} f(n))}"/> and <img alt="{\Omega(f(n) \log^{c_2} f(n))}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5COmega%28f%28n%29+%5Clog%5E%7Bc_2%7D+f%28n%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Omega(f(n) \log^{c_2} f(n))}"/> for some constants <img alt="{c_1, c_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc_1%2C+c_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c_1, c_2}"/>. The proof of this lower bound is based on <em>robust tracing attacks</em>, also called <em>membership inference attacks</em>, which were developed in a chain of papers [<a href="https://kamathematics.wordpress.com/feed/#BUV14">BUV14</a>, <a href="https://kamathematics.wordpress.com/feed/#DSSUV15">DSSUV15</a>, <a href="https://kamathematics.wordpress.com/feed/#BSU17">BSU17</a>, <a href="https://kamathematics.wordpress.com/feed/#SU17a">SU17a</a>, <a href="https://kamathematics.wordpress.com/feed/#SU17b">SU17b</a>, <a href="https://kamathematics.wordpress.com/feed/#KLSU19">KLSU19</a>]. We remark that this lower bound is almost identical to the minimax bound for mean estimation proven in the much more recent work of Cai, Wang, and Zhang [<a href="https://kamathematics.wordpress.com/feed/#CWZ19">CWZ19</a>], but it lacks tight dependence on the parameter <img alt="{\delta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\delta}"/>, which we discuss in the following remark.</p>
<blockquote>
<p><b>Remark 3</b> <em> The choice of <img alt="{\delta = 1/n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+%3D+1%2Fn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\delta = 1/n}"/> in <a href="https://kamathematics.wordpress.com/feed/#eqRd-minimax">(2)</a> may look strange at first. For the upper bound this choice is arbitrary—as we will see, we can upper bound the rate for any <img alt="{\delta &gt; 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+%3E+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\delta &gt; 0}"/> at a cost of a factor of <img alt="{O(\log(1/\delta))}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%28%5Clog%281%2F%5Cdelta%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{O(\log(1/\delta))}"/>. The lower bound applies only when <img alt="{\delta \leq 1/n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+%5Cleq+1%2Fn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\delta \leq 1/n}"/>. Note that the rate is qualitatively different when <img alt="{\delta \gg 1/n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+%5Cgg+1%2Fn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\delta \gg 1/n}"/>. However, we emphasize that <img alt="{(\epsilon,\delta)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28%5Cepsilon%2C%5Cdelta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(\epsilon,\delta)}"/>-differential privacy is not a meaningful privacy notion unless <img alt="{\delta \ll 1/n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+%5Cll+1%2Fn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\delta \ll 1/n}"/>. In particular, the mechanism that randomly outputs <img alt="{\delta n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\delta n}"/> elements of the sample satisfies <img alt="{(0,\delta)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%280%2C%5Cdelta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(0,\delta)}"/>-differential privacy. However, when <img alt="{\delta \gg 1/n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+%5Cgg+1%2Fn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\delta \gg 1/n}"/>, this mechanism completely violates the privacy of <img alt="{\gg 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cgg+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\gg 1}"/> person in the dataset. Moreover, taking the empirical mean of these <img alt="{\delta n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\delta n}"/> samples gives rate <img alt="{d/\delta n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%2F%5Cdelta+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d/\delta n}"/>, which would violate our lower bound when <img alt="{\delta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\delta}"/> is large enough. On the other hand, we would expect the minimax rate to become slower when <img alt="{\delta \ll 1/n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+%5Cll+1%2Fn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\delta \ll 1/n}"/>. This expectation is, in fact, correct, however the proof we present does not give the tight dependence on the parameter <img alt="{\delta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\delta}"/>. See [<a href="https://kamathematics.wordpress.com/feed/#SU17a">SU17a</a>] for a refinement that can obtain the right dependence on <img alt="{\delta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\delta}"/>, and [<a href="https://kamathematics.wordpress.com/feed/#CWZ19">CWZ19</a>] for the details of how to apply this refinement in the i.i.d. setting. </em></p>
</blockquote>
<p><b> 3.1. A Simple Upper Bound </b></p>
<blockquote>
<p><b>Theorem 4</b> <em> For every <img alt="{n \in {\mathbb N}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn+%5Cin+%7B%5Cmathbb+N%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n \in {\mathbb N}}"/>, and every <img alt="{\epsilon,\delta &gt; 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%2C%5Cdelta+%3E+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\epsilon,\delta &gt; 0}"/>, there exists an <img alt="{(\epsilon,\delta)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28%5Cepsilon%2C%5Cdelta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(\epsilon,\delta)}"/>-differentially private private mechanism <img alt="{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M}"/> such that <a name="eqmean-est-ub"/></em></p>
<p><em><em><a name="eqmean-est-ub"/></em></em></p>
<p align="center"><img alt="\displaystyle \max_{P \in \mathcal{P}} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| M(X_{1 \cdots n}) - \mu \|_2^2) \leq \frac{d}{n} + \frac{2 d^2 \log(2/\delta)}{\epsilon^2 n^2}. \ \ \ \ \ (3)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmax_%7BP+%5Cin+%5Cmathcal%7BP%7D%7D+%5Cmathop%7B%5Cmathbb+E%7D_%7BX_%7B1+%5Ccdots+n%7D+%5Csim+P%7D%28%5C%7C+M%28X_%7B1+%5Ccdots+n%7D%29+-+%5Cmu+%5C%7C_2%5E2%29+%5Cleq+%5Cfrac%7Bd%7D%7Bn%7D+%2B+%5Cfrac%7B2+d%5E2+%5Clog%282%2F%5Cdelta%29%7D%7B%5Cepsilon%5E2+n%5E2%7D.+%5C+%5C+%5C+%5C+%5C+%283%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \max_{P \in \mathcal{P}} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| M(X_{1 \cdots n}) - \mu \|_2^2) \leq \frac{d}{n} + \frac{2 d^2 \log(2/\delta)}{\epsilon^2 n^2}. \ \ \ \ \ (3)"/></p>
<p><em><a name="eqmean-est-ub"/></em></p>
<p><em><a name="eqmean-est-ub"/> </em></p>
</blockquote>
<p><em>Proof:</em> Define the mechanism</p>
<p align="center"><img alt="\displaystyle M(X_{1 \cdots n}) = \overline{X} + \mathcal{N}\left(0, \frac{2 d \log(2/\delta)}{\varepsilon^2 n^2} \cdot \mathbb{I}_{d \times d} \right). \ \ \ \ \ (4)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+M%28X_%7B1+%5Ccdots+n%7D%29+%3D+%5Coverline%7BX%7D+%2B+%5Cmathcal%7BN%7D%5Cleft%280%2C+%5Cfrac%7B2+d+%5Clog%282%2F%5Cdelta%29%7D%7B%5Cvarepsilon%5E2+n%5E2%7D+%5Ccdot+%5Cmathbb%7BI%7D_%7Bd+%5Ctimes+d%7D+%5Cright%29.+%5C+%5C+%5C+%5C+%5C+%284%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle M(X_{1 \cdots n}) = \overline{X} + \mathcal{N}\left(0, \frac{2 d \log(2/\delta)}{\varepsilon^2 n^2} \cdot \mathbb{I}_{d \times d} \right). \ \ \ \ \ (4)"/></p>
<p>This mechanism satisfies <img alt="{(\epsilon,\delta)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28%5Cepsilon%2C%5Cdelta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(\epsilon,\delta)}"/>-differential privacy by Lemma <a href="https://kamathematics.wordpress.com/feed/#lemgauss-mech">3</a>, noting that for any pair of adjacent samples <img alt="{X_{1 \cdots n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_%7B1+%5Ccdots+n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X_{1 \cdots n}}"/> and <img alt="{X'_{1 \cdots n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%27_%7B1+%5Ccdots+n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X'_{1 \cdots n}}"/>, <img alt="{\| \overline{X} - \overline{X}'\|_2^2 \leq \frac{d}{n^2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7C+%5Coverline%7BX%7D+-+%5Coverline%7BX%7D%27%5C%7C_2%5E2+%5Cleq+%5Cfrac%7Bd%7D%7Bn%5E2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\| \overline{X} - \overline{X}'\|_2^2 \leq \frac{d}{n^2}}"/>.</p>
<p>Let <img alt="{\sigma^2 = \frac{2 d \log(2/\delta)}{\varepsilon^2 n^2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csigma%5E2+%3D+%5Cfrac%7B2+d+%5Clog%282%2F%5Cdelta%29%7D%7B%5Cvarepsilon%5E2+n%5E2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\sigma^2 = \frac{2 d \log(2/\delta)}{\varepsilon^2 n^2}}"/>. Note that since the Gaussian noise has mean <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/> and is independent of <img alt="{\overline{X} - \mu}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Coverline%7BX%7D+-+%5Cmu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\overline{X} - \mu}"/>, we have</p>
<p align="center"><img alt="\displaystyle \begin{array}{rll} \mathop{\mathbb E}(\| M(X_{1 \cdots n}) - \mu \|_2^2) ={} &amp;\mathop{\mathbb E}(\| \overline{X} - \mu \|_2^2) + \mathop{\mathbb E}(\| M(X_{1 \cdots n}) - \overline{X} \|_2^2 ) \\ \leq{} &amp;\frac{d}{n} + \mathop{\mathbb E}(\| M(X_{1 \cdots n}) - \overline{X} \|_2^2 ) \\ ={} &amp;\frac{d}{n} + \mathop{\mathbb E}(\| \mathcal{N}(0, \sigma^2 \mathbb{I}_{d \times d}) \|_2^2 ) \\ ={} &amp;\frac{d}{n} + \sigma^2 d \\ ={} &amp;\frac{d}{n} + \frac{2 d^2 \log(2/\delta)}{\epsilon^2 n^2}. \end{array} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cbegin%7Barray%7D%7Brll%7D+%5Cmathop%7B%5Cmathbb+E%7D%28%5C%7C+M%28X_%7B1+%5Ccdots+n%7D%29+-+%5Cmu+%5C%7C_2%5E2%29+%3D%7B%7D+%26%5Cmathop%7B%5Cmathbb+E%7D%28%5C%7C+%5Coverline%7BX%7D+-+%5Cmu+%5C%7C_2%5E2%29+%2B+%5Cmathop%7B%5Cmathbb+E%7D%28%5C%7C+M%28X_%7B1+%5Ccdots+n%7D%29+-+%5Coverline%7BX%7D+%5C%7C_2%5E2+%29+%5C%5C+%5Cleq%7B%7D+%26%5Cfrac%7Bd%7D%7Bn%7D+%2B+%5Cmathop%7B%5Cmathbb+E%7D%28%5C%7C+M%28X_%7B1+%5Ccdots+n%7D%29+-+%5Coverline%7BX%7D+%5C%7C_2%5E2+%29+%5C%5C+%3D%7B%7D+%26%5Cfrac%7Bd%7D%7Bn%7D+%2B+%5Cmathop%7B%5Cmathbb+E%7D%28%5C%7C+%5Cmathcal%7BN%7D%280%2C+%5Csigma%5E2+%5Cmathbb%7BI%7D_%7Bd+%5Ctimes+d%7D%29+%5C%7C_2%5E2+%29+%5C%5C+%3D%7B%7D+%26%5Cfrac%7Bd%7D%7Bn%7D+%2B+%5Csigma%5E2+d+%5C%5C+%3D%7B%7D+%26%5Cfrac%7Bd%7D%7Bn%7D+%2B+%5Cfrac%7B2+d%5E2+%5Clog%282%2F%5Cdelta%29%7D%7B%5Cepsilon%5E2+n%5E2%7D.+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \begin{array}{rll} \mathop{\mathbb E}(\| M(X_{1 \cdots n}) - \mu \|_2^2) ={} &amp;\mathop{\mathbb E}(\| \overline{X} - \mu \|_2^2) + \mathop{\mathbb E}(\| M(X_{1 \cdots n}) - \overline{X} \|_2^2 ) \\ \leq{} &amp;\frac{d}{n} + \mathop{\mathbb E}(\| M(X_{1 \cdots n}) - \overline{X} \|_2^2 ) \\ ={} &amp;\frac{d}{n} + \mathop{\mathbb E}(\| \mathcal{N}(0, \sigma^2 \mathbb{I}_{d \times d}) \|_2^2 ) \\ ={} &amp;\frac{d}{n} + \sigma^2 d \\ ={} &amp;\frac{d}{n} + \frac{2 d^2 \log(2/\delta)}{\epsilon^2 n^2}. \end{array} "/></p>
<p><img alt="\Box" class="latex" src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Box"/></p>
<p> </p>
<p><b> 3.2. Minimax Lower Bounds via Tracing </b></p>
<blockquote>
<p><b>Theorem 5</b> <em> <a name="thmmean-lb"/> For every <img alt="{n, d \in {\mathbb N}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%2C+d+%5Cin+%7B%5Cmathbb+N%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n, d \in {\mathbb N}}"/>, <img alt="{\epsilon &gt; 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon+%3E+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\epsilon &gt; 0}"/>, and <img alt="{\delta &lt; 1/96n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+%3C+1%2F96n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\delta &lt; 1/96n}"/>, if <img alt="{\mathcal{P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{P}}"/> is the class of all product distributions on <img alt="{\{\pm 1\}^{d}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B%5Cpm+1%5C%7D%5E%7Bd%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{\pm 1\}^{d}}"/>, then for some constant <img alt="{C &gt; 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC+%3E+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C &gt; 0}"/>, </em></p>
<p align="center"><img alt="\displaystyle \min_{M \in \mathcal{M}_{\epsilon,\delta}} \max_{P \in \mathcal{P}} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P,M}(\| M(X_{1 \cdots n}) - \mu \|_2^2) = \Omega\left(\min \left\{ \frac{d^2}{ \epsilon^2 n^2}, d \right\}\right). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmin_%7BM+%5Cin+%5Cmathcal%7BM%7D_%7B%5Cepsilon%2C%5Cdelta%7D%7D+%5Cmax_%7BP+%5Cin+%5Cmathcal%7BP%7D%7D+%5Cmathop%7B%5Cmathbb+E%7D_%7BX_%7B1+%5Ccdots+n%7D+%5Csim+P%2CM%7D%28%5C%7C+M%28X_%7B1+%5Ccdots+n%7D%29+-+%5Cmu+%5C%7C_2%5E2%29+%3D+%5COmega%5Cleft%28%5Cmin+%5Cleft%5C%7B+%5Cfrac%7Bd%5E2%7D%7B+%5Cepsilon%5E2+n%5E2%7D%2C+d+%5Cright%5C%7D%5Cright%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \min_{M \in \mathcal{M}_{\epsilon,\delta}} \max_{P \in \mathcal{P}} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P,M}(\| M(X_{1 \cdots n}) - \mu \|_2^2) = \Omega\left(\min \left\{ \frac{d^2}{ \epsilon^2 n^2}, d \right\}\right). "/></p>
<p> </p>
</blockquote>
<p>Note that it is trivial to achieve error <img alt="{d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d}"/> for any distribution using the mechanism <img alt="{M(X_{1 \cdots n}) \equiv 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%28X_%7B1+%5Ccdots+n%7D%29+%5Cequiv+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M(X_{1 \cdots n}) \equiv 0}"/>, so the result says that the error must be <img alt="{\Omega(d^2/\epsilon^2 n^2)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5COmega%28d%5E2%2F%5Cepsilon%5E2+n%5E2%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Omega(d^2/\epsilon^2 n^2)}"/> whenever this error is significantly smaller than the trivial error of <img alt="{d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d}"/>.</p>
<p><b>Tracing Attacks.</b></p>
<p>Before giving the formal proof, we will try to give some intuition for the high-level proof strategy. The proof can be viewed as constructing a <em>tracing attack </em>[<a href="https://kamathematics.wordpress.com/feed/#DSSU17">DSSU17</a>] (sometimes called a <em>membership inference attack</em>) of the following form. There is an attacker who has the data of some individual <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y}"/> chosen in one of the two ways: either <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y}"/> is a random element of the sample <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X}"/>, or <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y}"/> is an independent random sample from the population <img alt="{P}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{P}"/>. The attacker is given access to the true distribution <img alt="{P}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{P}"/> and the outcome of the mechanism <img alt="{M(X)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M(X)}"/>, and wants to determine which of the two is the case. If the attacker can succeed, then <img alt="{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M}"/> cannot be differentially private. To understand why this is the case, if <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y}"/> is a member of the dataset, then the attacker should say <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y}"/> is in the dataset, but if we consider the adjacent dataset <img alt="{X'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X'}"/> where we replace <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y}"/> with some independent sample from <img alt="{P}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{P}"/>, then the attacker will now say <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y}"/> is independent of the dataset. Thus, <img alt="{M(X)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M(X)}"/> and <img alt="{M(X')}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%28X%27%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M(X')}"/> cannot be close in the sense required by differential privacy.</p>
<p>Thus, the proof works by constructing a test statistic <img alt="{Z = Z(M(X),Y,P),}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BZ+%3D+Z%28M%28X%29%2CY%2CP%29%2C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Z = Z(M(X),Y,P),}"/> that the attacker can use to distinguish the two possibilities for <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y}"/>. In particular, we show that there is a distribution over populations <img alt="{P}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{P}"/> such that <img alt="{\mathop{\mathbb E}(Z)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathop%7B%5Cmathbb+E%7D%28Z%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathop{\mathbb E}(Z)}"/> is small when <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y}"/> is independent of <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X}"/>, but for <em>every</em> sufficiently accurate mechanism <img alt="{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M}"/>, <img alt="{\mathop{\mathbb E}(Z)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathop%7B%5Cmathbb+E%7D%28Z%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathop{\mathbb E}(Z)}"/> is large when <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y}"/> is a random element of <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X}"/>.</p>
<p><b>Proof of Theorem <a href="https://kamathematics.wordpress.com/feed/#thmmean-lb">5</a>.</b></p>
<p>The proof that we present closely follows the one that appears in Thomas Steinke’s Ph.D. thesis [<a href="https://kamathematics.wordpress.com/feed/#Ste16">Ste16</a>].</p>
<p>We start by constructing a “hard distribution” over the family of product distributions <img alt="{\mathcal{P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{P}}"/>. Let <img alt="{\mu = (\mu^1,\dots,\mu^d) \in [-1,1]^d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmu+%3D+%28%5Cmu%5E1%2C%5Cdots%2C%5Cmu%5Ed%29+%5Cin+%5B-1%2C1%5D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mu = (\mu^1,\dots,\mu^d) \in [-1,1]^d}"/> consist of <img alt="{d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d}"/> independent draws from the uniform distribution on <img alt="{[-1,1]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5B-1%2C1%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{[-1,1]}"/> and let <img alt="{P_{\mu}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP_%7B%5Cmu%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{P_{\mu}}"/> be the product distribution over <img alt="{\{\pm 1\}^{d}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B%5Cpm+1%5C%7D%5E%7Bd%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{\pm 1\}^{d}}"/> with mean <img alt="{\mu}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mu}"/>. Let <img alt="{X_1,\dots,X_n \sim P_{\mu}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_1%2C%5Cdots%2CX_n+%5Csim+P_%7B%5Cmu%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X_1,\dots,X_n \sim P_{\mu}}"/> and <img alt="{X = (X_1,\dots,X_n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX+%3D+%28X_1%2C%5Cdots%2CX_n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X = (X_1,\dots,X_n)}"/>.</p>
<p>Let <img alt="{M \colon \{\pm 1\}^{n \times d} \rightarrow [\pm 1]^d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM+%5Ccolon+%5C%7B%5Cpm+1%5C%7D%5E%7Bn+%5Ctimes+d%7D+%5Crightarrow+%5B%5Cpm+1%5D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M \colon \{\pm 1\}^{n \times d} \rightarrow [\pm 1]^d}"/> be any <img alt="{(\epsilon,\delta)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28%5Cepsilon%2C%5Cdelta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(\epsilon,\delta)}"/>-differentially private mechanism and let</p>
<p align="center"><img alt="\displaystyle \alpha^2 = \mathop{\mathbb E}_{\mu,X,M}(\| M(X) - \mu\|_2^2 ) \ \ \ \ \ (5)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Calpha%5E2+%3D+%5Cmathop%7B%5Cmathbb+E%7D_%7B%5Cmu%2CX%2CM%7D%28%5C%7C+M%28X%29+-+%5Cmu%5C%7C_2%5E2+%29+%5C+%5C+%5C+%5C+%5C+%285%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \alpha^2 = \mathop{\mathbb E}_{\mu,X,M}(\| M(X) - \mu\|_2^2 ) \ \ \ \ \ (5)"/></p>
<p>be its expected loss. We will prove the desired lower bound on <img alt="{\alpha^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha^2}"/>.</p>
<p>For every element <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/>, we define the random variables</p>
<p align="center"><img alt="\displaystyle Z_i = Z_i(M(X),X_i,\mu) = \left\langle M(X) - \mu, X_i - \mu \right\rangle \\ Z'_{i} = Z'_i(M(X_{\sim i}), X_i, \mu) = \left\langle M(X_{\sim i}) - \mu, X_i - \mu \right\rangle, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+Z_i+%3D+Z_i%28M%28X%29%2CX_i%2C%5Cmu%29+%3D+%5Cleft%5Clangle+M%28X%29+-+%5Cmu%2C+X_i+-+%5Cmu+%5Cright%5Crangle+%5C%5C+Z%27_%7Bi%7D+%3D+Z%27_i%28M%28X_%7B%5Csim+i%7D%29%2C+X_i%2C+%5Cmu%29+%3D+%5Cleft%5Clangle+M%28X_%7B%5Csim+i%7D%29+-+%5Cmu%2C+X_i+-+%5Cmu+%5Cright%5Crangle%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle Z_i = Z_i(M(X),X_i,\mu) = \left\langle M(X) - \mu, X_i - \mu \right\rangle \\ Z'_{i} = Z'_i(M(X_{\sim i}), X_i, \mu) = \left\langle M(X_{\sim i}) - \mu, X_i - \mu \right\rangle, "/></p>
<p>where <img alt="{X_{\sim i}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_%7B%5Csim+i%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X_{\sim i}}"/> denotes <img alt="{(X_1,\dots,X'_i,\dots,X_n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28X_1%2C%5Cdots%2CX%27_i%2C%5Cdots%2CX_n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(X_1,\dots,X'_i,\dots,X_n)}"/> where <img alt="{X'_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%27_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X'_i}"/> is an independent sample from <img alt="{P_\mu}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP_%5Cmu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{P_\mu}"/>. Our goal will be to show that, privacy and accuracy imply both upper and lower bounds on <img alt="{\mathop{\mathbb E}(\sum_i Z_i)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathop%7B%5Cmathbb+E%7D%28%5Csum_i+Z_i%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathop{\mathbb E}(\sum_i Z_i)}"/> that depend on <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/>, and thereby obtain a bound on <img alt="{\alpha^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha^2}"/>.</p>
<p>The first claim says that, when <img alt="{X_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X_i}"/> is <em>not</em> in the sample, then the likelihood random variable has mean <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/> and variance controlled by the expected <img alt="{\ell_2^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell_2%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\ell_2^2}"/> error of the mechanism.</p>
<blockquote>
<p><b>Claim 1</b> <em> <a name="clmmean-lb-1"/> For every <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/>, <img alt="{\mathop{\mathbb E}(Z'_i) = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathop%7B%5Cmathbb+E%7D%28Z%27_i%29+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathop{\mathbb E}(Z'_i) = 0}"/>, <img alt="{\mathrm{Var}(Z'_i) \leq 4\alpha^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathrm%7BVar%7D%28Z%27_i%29+%5Cleq+4%5Calpha%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathrm{Var}(Z'_i) \leq 4\alpha^2}"/>, and <img alt="{\|Z'_i\|_\infty \leq 4d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7CZ%27_i%5C%7C_%5Cinfty+%5Cleq+4d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\|Z'_i\|_\infty \leq 4d}"/>. </em></p>
</blockquote>
<p><em>Proof:</em> Conditioned on any value of <img alt="{\mu}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mu}"/>, <img alt="{M(X_{\sim i})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%28X_%7B%5Csim+i%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M(X_{\sim i})}"/> is independent from <img alt="{X_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X_i}"/>. Moreover, <img alt="{\mathop{\mathbb E}(X_i - \mu) = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathop%7B%5Cmathbb+E%7D%28X_i+-+%5Cmu%29+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathop{\mathbb E}(X_i - \mu) = 0}"/>, so we have</p>
<p align="center"><img alt="\displaystyle \begin{array}{rll} &amp;\mathop{\mathbb E}_{\mu,X,M}(\langle M(X_{\sim i}) - \mu, X_i - \mu \rangle) \\ = &amp;\mathop{\mathbb E}_{\mu}(\mathop{\mathbb E}_{X,M}(\langle M(X_{\sim i}) - \mu, X_i - \mu \rangle)) \\ = &amp;\mathop{\mathbb E}_{\mu}(\left\langle \mathop{\mathbb E}_{X,M}(M(X_{\sim i}) - \mu), \mathop{\mathbb E}_{X,M}(X_i - \mu) \right \rangle ) \\ = &amp;\mathop{\mathbb E}_{\mu}(\left\langle \mathop{\mathbb E}_{X,M}(M(X_{\sim i}) - \mu), 0 \right \rangle ) \\ = &amp;0. \end{array} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cbegin%7Barray%7D%7Brll%7D+%26%5Cmathop%7B%5Cmathbb+E%7D_%7B%5Cmu%2CX%2CM%7D%28%5Clangle+M%28X_%7B%5Csim+i%7D%29+-+%5Cmu%2C+X_i+-+%5Cmu+%5Crangle%29+%5C%5C+%3D+%26%5Cmathop%7B%5Cmathbb+E%7D_%7B%5Cmu%7D%28%5Cmathop%7B%5Cmathbb+E%7D_%7BX%2CM%7D%28%5Clangle+M%28X_%7B%5Csim+i%7D%29+-+%5Cmu%2C+X_i+-+%5Cmu+%5Crangle%29%29+%5C%5C+%3D+%26%5Cmathop%7B%5Cmathbb+E%7D_%7B%5Cmu%7D%28%5Cleft%5Clangle+%5Cmathop%7B%5Cmathbb+E%7D_%7BX%2CM%7D%28M%28X_%7B%5Csim+i%7D%29+-+%5Cmu%29%2C+%5Cmathop%7B%5Cmathbb+E%7D_%7BX%2CM%7D%28X_i+-+%5Cmu%29+%5Cright+%5Crangle+%29+%5C%5C+%3D+%26%5Cmathop%7B%5Cmathbb+E%7D_%7B%5Cmu%7D%28%5Cleft%5Clangle+%5Cmathop%7B%5Cmathbb+E%7D_%7BX%2CM%7D%28M%28X_%7B%5Csim+i%7D%29+-+%5Cmu%29%2C+0+%5Cright+%5Crangle+%29+%5C%5C+%3D+%260.+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \begin{array}{rll} &amp;\mathop{\mathbb E}_{\mu,X,M}(\langle M(X_{\sim i}) - \mu, X_i - \mu \rangle) \\ = &amp;\mathop{\mathbb E}_{\mu}(\mathop{\mathbb E}_{X,M}(\langle M(X_{\sim i}) - \mu, X_i - \mu \rangle)) \\ = &amp;\mathop{\mathbb E}_{\mu}(\left\langle \mathop{\mathbb E}_{X,M}(M(X_{\sim i}) - \mu), \mathop{\mathbb E}_{X,M}(X_i - \mu) \right \rangle ) \\ = &amp;\mathop{\mathbb E}_{\mu}(\left\langle \mathop{\mathbb E}_{X,M}(M(X_{\sim i}) - \mu), 0 \right \rangle ) \\ = &amp;0. \end{array} "/></p>
<p>For the second part of the claim, since <img alt="{(X_i - \mu)^2 \leq 4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28X_i+-+%5Cmu%29%5E2+%5Cleq+4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(X_i - \mu)^2 \leq 4}"/>, we have <img alt="{\mathrm{Var}(Z'_i) \leq 4 \cdot \mathop{\mathbb E}(\| M(X) - \mu \|_2^2) = 4\alpha^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathrm%7BVar%7D%28Z%27_i%29+%5Cleq+4+%5Ccdot+%5Cmathop%7B%5Cmathbb+E%7D%28%5C%7C+M%28X%29+-+%5Cmu+%5C%7C_2%5E2%29+%3D+4%5Calpha%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathrm{Var}(Z'_i) \leq 4 \cdot \mathop{\mathbb E}(\| M(X) - \mu \|_2^2) = 4\alpha^2}"/>. The final part of the claim follows from the fact that every entry of <img alt="{M(X_{\sim i}) - \mu}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%28X_%7B%5Csim+i%7D%29+-+%5Cmu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M(X_{\sim i}) - \mu}"/> and <img alt="{X_i - \mu}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_i+-+%5Cmu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X_i - \mu}"/> is bounded by <img alt="{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2}"/> in absolute value, and <img alt="{Z'_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BZ%27_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Z'_i}"/> is a sum of <img alt="{d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d}"/> such entries, so its absolute value is always at most <img alt="{4d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B4d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{4d}"/>. <img alt="\Box" class="latex" src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Box"/></p>
<p>The next claim says that, because <img alt="{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M}"/> is differentially private, <img alt="{Z_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BZ_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Z_i}"/> has similar expectation to <img alt="{Z'_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BZ%27_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Z'_i}"/>, and thus its expectation is also small.</p>
<blockquote>
<p><b>Claim 2</b> <em><a name="clmmean-lb-2"/> <img alt="{\mathop{\mathbb E}(\sum_{i=1}^{n} Z_i) \leq 4n\alpha \epsilon + 8n \delta d.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathop%7B%5Cmathbb+E%7D%28%5Csum_%7Bi%3D1%7D%5E%7Bn%7D+Z_i%29+%5Cleq+4n%5Calpha+%5Cepsilon+%2B+8n+%5Cdelta+d.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathop{\mathbb E}(\sum_{i=1}^{n} Z_i) \leq 4n\alpha \epsilon + 8n \delta d.}"/> </em></p>
</blockquote>
<p><em>Proof:</em> The proof is a direct calculation using the following inequality, whose proof is relatively simple using the definition of differential privacy:</p>
<p align="center"><img alt="\displaystyle \mathop{\mathbb E}(Z_i) \leq \mathop{\mathbb E}(Z'_i) + 2\epsilon \sqrt{\mathrm{Var}(Z'_i)} + 2\delta \| Z'_i \|_\infty. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmathop%7B%5Cmathbb+E%7D%28Z_i%29+%5Cleq+%5Cmathop%7B%5Cmathbb+E%7D%28Z%27_i%29+%2B+2%5Cepsilon+%5Csqrt%7B%5Cmathrm%7BVar%7D%28Z%27_i%29%7D+%2B+2%5Cdelta+%5C%7C+Z%27_i+%5C%7C_%5Cinfty.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \mathop{\mathbb E}(Z_i) \leq \mathop{\mathbb E}(Z'_i) + 2\epsilon \sqrt{\mathrm{Var}(Z'_i)} + 2\delta \| Z'_i \|_\infty. "/></p>
<p>Given the inequality and Claim <a href="https://kamathematics.wordpress.com/feed/#clmmean-lb-1">1</a>, we have</p>
<p align="center"><img alt="\displaystyle \mathop{\mathbb E}(Z_i) \leq 0 + (2\epsilon)(2\alpha) + (2\delta)(2d) = 4\epsilon \alpha + 8 \delta d . " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmathop%7B%5Cmathbb+E%7D%28Z_i%29+%5Cleq+0+%2B+%282%5Cepsilon%29%282%5Calpha%29+%2B+%282%5Cdelta%29%282d%29+%3D+4%5Cepsilon+%5Calpha+%2B+8+%5Cdelta+d+.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \mathop{\mathbb E}(Z_i) \leq 0 + (2\epsilon)(2\alpha) + (2\delta)(2d) = 4\epsilon \alpha + 8 \delta d . "/></p>
<p>The claim now follows by summing over all <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/>. <img alt="\Box" class="latex" src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Box"/></p>
<p>The final claim says that, because <img alt="{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M}"/> is accurate, the expected sum of the random variables <img alt="{Z_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BZ_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Z_i}"/> is large.</p>
<blockquote>
<p><b>Claim 3</b> <em> <a name="clmmean-lb-3"/> <img alt="{\mathop{\mathbb E}(\sum_{i=1}^{n} Z_i) \geq \frac{d}{3} - \alpha^2.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathop%7B%5Cmathbb+E%7D%28%5Csum_%7Bi%3D1%7D%5E%7Bn%7D+Z_i%29+%5Cgeq+%5Cfrac%7Bd%7D%7B3%7D+-+%5Calpha%5E2.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathop{\mathbb E}(\sum_{i=1}^{n} Z_i) \geq \frac{d}{3} - \alpha^2.}"/> </em></p>
</blockquote>
<p>The proof relies on the following key lemma, whose proof we omit.</p>
<blockquote>
<p><b>Lemma 6 (Fingerprinting Lemma [<a href="https://kamathematics.wordpress.com/feed/#BSU17">BSU17</a>])</b><em> <a name="lemfp"/> If <img alt="{\mu \in [\pm 1]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmu+%5Cin+%5B%5Cpm+1%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mu \in [\pm 1]}"/> is sampled uniformly, <img alt="{X_1,\dots,X_n \in \{\pm 1\}^{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_1%2C%5Cdots%2CX_n+%5Cin+%5C%7B%5Cpm+1%5C%7D%5E%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X_1,\dots,X_n \in \{\pm 1\}^{n}}"/> are sampled independently with mean <img alt="{\mu}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mu}"/>, and <img alt="{f \colon \{\pm 1\}^n \rightarrow [\pm 1]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf+%5Ccolon+%5C%7B%5Cpm+1%5C%7D%5En+%5Crightarrow+%5B%5Cpm+1%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f \colon \{\pm 1\}^n \rightarrow [\pm 1]}"/> is any function, then </em></p>
<p align="center"><img alt="\displaystyle \mathop{\mathbb E}_{\mu,X}((f(X) - \mu) \cdot \sum_{i=1}^{n} (X_i - \mu)) \geq \frac{1}{3} - \mathop{\mathbb E}_{\mu,X}((f(X) - \mu)^2). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmathop%7B%5Cmathbb+E%7D_%7B%5Cmu%2CX%7D%28%28f%28X%29+-+%5Cmu%29+%5Ccdot+%5Csum_%7Bi%3D1%7D%5E%7Bn%7D+%28X_i+-+%5Cmu%29%29+%5Cgeq+%5Cfrac%7B1%7D%7B3%7D+-+%5Cmathop%7B%5Cmathbb+E%7D_%7B%5Cmu%2CX%7D%28%28f%28X%29+-+%5Cmu%29%5E2%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \mathop{\mathbb E}_{\mu,X}((f(X) - \mu) \cdot \sum_{i=1}^{n} (X_i - \mu)) \geq \frac{1}{3} - \mathop{\mathbb E}_{\mu,X}((f(X) - \mu)^2). "/></p>
<p> </p>
</blockquote>
<p>The lemma is somewhat technical, but for intuition, consider the case where <img alt="{f(X) = \frac{1}{n}\sum_{i} X_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28X%29+%3D+%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bi%7D+X_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(X) = \frac{1}{n}\sum_{i} X_i}"/> is the empirical mean. In this case we have</p>
<p align="center"><img alt="\displaystyle \begin{array}{rcl} \mathop{\mathbb E}_{\mu,X}((f(X) - \mu) \cdot \sum_{i=1}^n (X_i - \mu)) ={} \mathop{\mathbb E}_{\mu}(\frac{1}{n} \sum_i \mathop{\mathbb E}_{X}( (X_i - \mu)^2) ) ={} \mathop{\mathbb E}_{\mu}(\mathrm{Var}(X_i)) = \frac{1}{3}. \end{array} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cbegin%7Barray%7D%7Brcl%7D+%5Cmathop%7B%5Cmathbb+E%7D_%7B%5Cmu%2CX%7D%28%28f%28X%29+-+%5Cmu%29+%5Ccdot+%5Csum_%7Bi%3D1%7D%5En+%28X_i+-+%5Cmu%29%29+%3D%7B%7D+%5Cmathop%7B%5Cmathbb+E%7D_%7B%5Cmu%7D%28%5Cfrac%7B1%7D%7Bn%7D+%5Csum_i+%5Cmathop%7B%5Cmathbb+E%7D_%7BX%7D%28+%28X_i+-+%5Cmu%29%5E2%29+%29+%3D%7B%7D+%5Cmathop%7B%5Cmathbb+E%7D_%7B%5Cmu%7D%28%5Cmathrm%7BVar%7D%28X_i%29%29+%3D+%5Cfrac%7B1%7D%7B3%7D.+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \begin{array}{rcl} \mathop{\mathbb E}_{\mu,X}((f(X) - \mu) \cdot \sum_{i=1}^n (X_i - \mu)) ={} \mathop{\mathbb E}_{\mu}(\frac{1}{n} \sum_i \mathop{\mathbb E}_{X}( (X_i - \mu)^2) ) ={} \mathop{\mathbb E}_{\mu}(\mathrm{Var}(X_i)) = \frac{1}{3}. \end{array} "/></p>
<p>The lemma says that, when <img alt="{\mu}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mu}"/> is sampled this way, then any modification of <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/> that reduces the correlation between <img alt="{f(X)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(X)}"/> and <img alt="{\sum_i X_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csum_i+X_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\sum_i X_i}"/> will increase the mean-squared-error of <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/> proportionally.</p>
<p>We now prove Claim <a href="https://kamathematics.wordpress.com/feed/#clmmean-lb-3">3</a>.</p>
<p><em>Proof:</em> We can apply the lemma to each coordinate of the estimate <img alt="{M(X)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M(X)}"/>.</p>
<p align="center"><img alt="\displaystyle \begin{array}{rll} \mathop{\mathbb E}(\sum_{i=1}^{n} Z_i) ={} &amp;\mathop{\mathbb E}(\sum_{i=1}^{n} \left\langle M(X) - \mu, X_i - \mu \right\rangle) \\ ={} &amp;\sum_{j=1}^{d} \mathop{\mathbb E}((M^j(X) - \mu^j)\cdot \sum_{i=1}^{n} (X_i^j - \mu^j)) \\ \geq{} &amp;\sum_{j=1}^{d} \left( \frac{1}{3} - \mathop{\mathbb E}((M^j(X) - \mu^j)^2) \right) \\ ={} &amp;\frac{d}{3} - \mathop{\mathbb E}(\| M(X) - \mu \|_2^2) ={} \frac{d}{3} - \alpha^2. \end{array} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cbegin%7Barray%7D%7Brll%7D+%5Cmathop%7B%5Cmathbb+E%7D%28%5Csum_%7Bi%3D1%7D%5E%7Bn%7D+Z_i%29+%3D%7B%7D+%26%5Cmathop%7B%5Cmathbb+E%7D%28%5Csum_%7Bi%3D1%7D%5E%7Bn%7D+%5Cleft%5Clangle+M%28X%29+-+%5Cmu%2C+X_i+-+%5Cmu+%5Cright%5Crangle%29+%5C%5C+%3D%7B%7D+%26%5Csum_%7Bj%3D1%7D%5E%7Bd%7D+%5Cmathop%7B%5Cmathbb+E%7D%28%28M%5Ej%28X%29+-+%5Cmu%5Ej%29%5Ccdot+%5Csum_%7Bi%3D1%7D%5E%7Bn%7D+%28X_i%5Ej+-+%5Cmu%5Ej%29%29+%5C%5C+%5Cgeq%7B%7D+%26%5Csum_%7Bj%3D1%7D%5E%7Bd%7D+%5Cleft%28+%5Cfrac%7B1%7D%7B3%7D+-+%5Cmathop%7B%5Cmathbb+E%7D%28%28M%5Ej%28X%29+-+%5Cmu%5Ej%29%5E2%29+%5Cright%29+%5C%5C+%3D%7B%7D+%26%5Cfrac%7Bd%7D%7B3%7D+-+%5Cmathop%7B%5Cmathbb+E%7D%28%5C%7C+M%28X%29+-+%5Cmu+%5C%7C_2%5E2%29+%3D%7B%7D+%5Cfrac%7Bd%7D%7B3%7D+-+%5Calpha%5E2.+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \begin{array}{rll} \mathop{\mathbb E}(\sum_{i=1}^{n} Z_i) ={} &amp;\mathop{\mathbb E}(\sum_{i=1}^{n} \left\langle M(X) - \mu, X_i - \mu \right\rangle) \\ ={} &amp;\sum_{j=1}^{d} \mathop{\mathbb E}((M^j(X) - \mu^j)\cdot \sum_{i=1}^{n} (X_i^j - \mu^j)) \\ \geq{} &amp;\sum_{j=1}^{d} \left( \frac{1}{3} - \mathop{\mathbb E}((M^j(X) - \mu^j)^2) \right) \\ ={} &amp;\frac{d}{3} - \mathop{\mathbb E}(\| M(X) - \mu \|_2^2) ={} \frac{d}{3} - \alpha^2. \end{array} "/></p>
<p>The inequality is Lemma <a href="https://kamathematics.wordpress.com/feed/#lemfp">6</a>. <img alt="\Box" class="latex" src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Box"/></p>
<p>Combining Claims <a href="https://kamathematics.wordpress.com/feed/#clmmean-lb-2">2</a> and <a href="https://kamathematics.wordpress.com/feed/#clmmean-lb-3">3</a> gives</p>
<p align="center"><img alt="\displaystyle \frac{d}{3} - \alpha^2 \leq 4n\alpha \epsilon + 8n \delta d. \ \ \ \ \ (6)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cfrac%7Bd%7D%7B3%7D+-+%5Calpha%5E2+%5Cleq+4n%5Calpha+%5Cepsilon+%2B+8n+%5Cdelta+d.+%5C+%5C+%5C+%5C+%5C+%286%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \frac{d}{3} - \alpha^2 \leq 4n\alpha \epsilon + 8n \delta d. \ \ \ \ \ (6)"/></p>
<p>Now, if <img alt="{\alpha^2 \geq \frac{d}{6}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%5E2+%5Cgeq+%5Cfrac%7Bd%7D%7B6%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha^2 \geq \frac{d}{6}}"/> then we’re done, so we’ll assume that <img alt="{\alpha^2 \leq \frac{d}{6}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%5E2+%5Cleq+%5Cfrac%7Bd%7D%7B6%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha^2 \leq \frac{d}{6}}"/>. Further, by our assumption on the value of <img alt="{\delta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\delta}"/>, <img alt="{8n \delta d \leq \frac{d}{12}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B8n+%5Cdelta+d+%5Cleq+%5Cfrac%7Bd%7D%7B12%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{8n \delta d \leq \frac{d}{12}}"/>. In this case we can rearrange terms and square both sides to obtain</p>
<p align="center"><img alt="\displaystyle \alpha^2 \geq{} \frac{1}{16 \epsilon^2 n^2} \left(\frac{d}{3} - \alpha^2 - 8 n\delta d\right)^2 \geq \frac{1}{16 \epsilon^2 n^2} \left(\frac{d}{12}\right)^2 = \frac{d^2}{2304 \epsilon^2 n^2}. \ \ \ \ \ (7)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Calpha%5E2+%5Cgeq%7B%7D+%5Cfrac%7B1%7D%7B16+%5Cepsilon%5E2+n%5E2%7D+%5Cleft%28%5Cfrac%7Bd%7D%7B3%7D+-+%5Calpha%5E2+-+8+n%5Cdelta+d%5Cright%29%5E2+%5Cgeq+%5Cfrac%7B1%7D%7B16+%5Cepsilon%5E2+n%5E2%7D+%5Cleft%28%5Cfrac%7Bd%7D%7B12%7D%5Cright%29%5E2+%3D+%5Cfrac%7Bd%5E2%7D%7B2304+%5Cepsilon%5E2+n%5E2%7D.+%5C+%5C+%5C+%5C+%5C+%287%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \alpha^2 \geq{} \frac{1}{16 \epsilon^2 n^2} \left(\frac{d}{3} - \alpha^2 - 8 n\delta d\right)^2 \geq \frac{1}{16 \epsilon^2 n^2} \left(\frac{d}{12}\right)^2 = \frac{d^2}{2304 \epsilon^2 n^2}. \ \ \ \ \ (7)"/></p>
<p>Combining the two cases for <img alt="{\alpha^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha^2}"/> gives <img alt="{\alpha^2 \geq \min\{ \frac{d}{6}, \frac{d^2}{2304 \epsilon^2 n^2} \}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%5E2+%5Cgeq+%5Cmin%5C%7B+%5Cfrac%7Bd%7D%7B6%7D%2C+%5Cfrac%7Bd%5E2%7D%7B2304+%5Cepsilon%5E2+n%5E2%7D+%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha^2 \geq \min\{ \frac{d}{6}, \frac{d^2}{2304 \epsilon^2 n^2} \}}"/>, as desired.</p>
<p><b>Bibliography</b></p>
<p>[BDRS18]<a name="BDRS18"/> Mark Bun, Cynthia Dwork, Guy N. Rothblum, and Thomas Steinke. Composable and versatile privacy via truncated CDP. STOC ’18.</p>
<p>[BS16]<a name="BS16"/> Mark Bun and Thomas Steinke. Concentrated differential privacy: Simplifications, extensions, and lower bounds. TCC ’16-B.</p>
<p>[BSU17]<a name="BSU17"/> Mark Bun, Thomas Steinke, and Jonathan Ullman. Make up your mind: The price of online queries in differential privacy. SODA ’17.</p>
<p>[BUV14]<a name="BUV14"/> Mark Bun, Jonathan Ullman, and Salil Vadhan. Fingerprinting codes and the price of approximate differential privacy. STOC ’14.</p>
<p>[CSS11]<a name="CSS11"/> T-H Hubert Chan, Elaine Shi, and Dawn Song. Private and continual release of statistics. ACM Transactions on Information and System Security, 14(3):26, 2011.</p>
<p>[CWZ19]<a name="CWZ19"/> T. Tony Cai, Yichen Wang, and Linjun Zhang. The cost of privacy: Optimal rates of convergence for parameter estimation with differential privacy. arXiv, 1902.04495, 2019.</p>
<p>[DMNS06]<a name="DMNS06"/> Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith. Calibrating noise to sensitivity in private data analysis. TCC ’06.</p>
<p>[DNPR10]<a name="DNPR10"/> Cynthia Dwork, Moni Naor, Toniann Pitassi, and Guy N. Rothblum. Differential privacy under continual observation. STOC ’10.</p>
<p>[DR16]<a name="DR16"/> Cynthia Dwork and Guy N. Rothblum. Concentrated differential privacy. arXiv, 1603.01887, 2016.</p>
<p>[DRS19]<a name="DRS19"/> Jinshuo Dong, Aaron Roth, and Weijie J. Su. Gaussian differential privacy. arXiv, 1905.02383, 2019.</p>
<p>[DSSU17]<a name="DSSU17"/> Cynthia Dwork, Adam Smith, Thomas Steinke, Jonathan Ullman, and Salil Vadhan. Robust traceability from trace amounts. FOCS ’15.</p>
<p>[DSSUV15]<a name="DSSUV15"/> Cynthia Dwork, Adam Smith, Thomas Steinke, and Jonathan Ullman. Exposed! a survey of attacks on private data. Annual Review of Statistics and Its Application, 4:61–84, 2017.</p>
<p>[FRY10]<a name="FRY10"/> Stephen E. Fienberg, Alessandro Rinaldo, and Xiaolin Yang. Differential privacy and the risk-utility tradeoff for multi-dimensional contingency tables. PSD ’10.</p>
<p>[KLSU19]<a name="KLSU19"/> Gautam Kamath, Jerry Li, Vikrant Singhal, and Jonathan Ullman. Privately learning high-dimensional distributions. COLT ’19.</p>
<p>[Mir17]<a name="Mir17"/> Ilya Mironov. Rényi differential privacy. CSF ’17.</p>
<p>[Ste16]<a name="Ste16"/> Thomas Alexander Steinke. Upper and Lower Bounds for Privacy and Adaptivity in Algorithmic Data Analysis. PhD thesis, 2016.</p>
<p>[SU17a]<a name="SU17a"/> Thomas Steinke and Jonathan Ullman. Between pure and approximate differential privacy. Journal of Privacy and Confidentiality, 7(2), 2017.</p>
<p>[SU17b]<a name="SU17b"/> Thomas Steinke and Jonathan Ullman. Tight lower bounds for differentially private selection. FOCS ’17.</p>
<p>[VS09]<a name="VS09"/> Duy Vu and Aleksandra Slavković. Differential privacy for clinical trial data: Preliminary evaluations. ICDMW ’09.</p>


<p/></div>
    </content>
    <updated>2020-04-14T14:23:37Z</updated>
    <published>2020-04-14T14:23:37Z</published>
    <category term="Technical"/>
    <author>
      <name>Gautam</name>
    </author>
    <source>
      <id>https://kamathematics.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://kamathematics.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://kamathematics.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://kamathematics.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://kamathematics.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Kamathematics</title>
      <updated>2020-08-26T22:24:34Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://dstheory.wordpress.com/?p=43</id>
    <link href="https://dstheory.wordpress.com/2020/04/11/friday-april-17-shachar-lovett-from-uc-san-diego/" rel="alternate" type="text/html"/>
    <title>Friday, April 17 — Shachar Lovett from UC San Diego</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">The third Foundations of Data Science virtual talk will take place next Friday, April 17th at 11:00 AM Pacific Time (2:00 pm Eastern Time, 20:00 Central European Time, 19:00 UTC).  Shachar Lovett from UC San Diego will speak about “The power of asking more informative questions about the data”. Abstract: Many supervised learning algorithms (such as<a class="more-link" href="https://dstheory.wordpress.com/2020/04/11/friday-april-17-shachar-lovett-from-uc-san-diego/">Continue reading <span class="screen-reader-text">"Friday, April 17 — Shachar Lovett from UC San Diego"</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The third Foundations of Data Science virtual talk will take place next Friday, April 17th at 11:00 AM Pacific Time (2:00 pm Eastern Time, 20:00 Central European Time, 19:00 UTC).  <strong>Shachar Lovett</strong> from UC San Diego will speak about “<em>The power of asking more informative questions about the data</em>”.</p>



<p><strong>Abstract</strong>: Many supervised learning algorithms (such as deep learning) need a large collection of labelled data points in order to perform well. However, what is easy to get are large amounts of unlabelled data. Labeling data is an expensive procedure, as it usually needs to be done manually, often by a domain expert. Active learning provides a mechanism to bridge this gap. Active learning algorithms are given a large collection of unlabelled data points. They need to smartly choose a few data points to query their label. The goal is then to automatically infer the labels of many other data points.</p>



<p>In this talk, we will explore the option of giving active learning algorithms additional power, by allowing them to have richer interaction with the data. We will see how allowing for even simple types of queries, such as comparing two data points, can exponentially improve the number of queries needed in various settings. Along the way, we will see interesting connections to both geometry and combinatorics, and a surprising application to fine grained complexity.</p>



<p>Based on joint works with Daniel Kane, Shay Moran and Jiapeng Zhang.</p>



<p><a href="https://sites.google.com/view/dstheory">Link to join the virtual talk.</a></p>



<p>The series is supported by the <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1934846&amp;HistoricalAwards=false">NSF HDR TRIPODS Grant 1934846</a>. </p></div>
    </content>
    <updated>2020-04-11T20:52:09Z</updated>
    <published>2020-04-11T20:52:09Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>dstheory</name>
    </author>
    <source>
      <id>https://dstheory.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://dstheory.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://dstheory.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://dstheory.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://dstheory.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Foundation of Data Science – Virtual Talk Series</title>
      <updated>2020-08-26T22:24:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://tcsplus.wordpress.com/?p=413</id>
    <link href="https://tcsplus.wordpress.com/2020/04/04/tcs-talk-wednesday-april-8-ramon-van-handel-princeton/" rel="alternate" type="text/html"/>
    <title>TCS+ talk: Wednesday, April 8 — Ramon van Handel, Princeton</title>
    <summary>The next TCS+ talk will take place this coming Wednesday, April 8th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). Ramon van Handel from Princeton will speak about how “Rademacher type and Enflo type coincide” (abstract below). You can reserve a spot as an individual or a group […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The next TCS+ talk will take place this coming Wednesday, April 8th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). <strong>Ramon van Handel</strong> from Princeton will speak about how “<em>Rademacher type and Enflo type coincide</em>” (abstract below).</p>
<p>You can reserve a spot as an individual or a group to join us live by signing up on <a href="https://sites.google.com/site/plustcs/livetalk/live-seat-reservation">the online form</a>. (The link will also be posted <a href="https://sites.google.com/site/plustcs/livetalk">on our website</a> on the day of the talk, so people who did not sign up will still be able to join, until the maximum capacity of 300 seats is reached.) As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/site/plustcs/suggest">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/site/plustcs/">the website</a>.</p>
<blockquote><p>Abstract: In Banach space theory, Rademacher type is an important invariant that controls many geometric and probabilistic properties of normed spaces. It is of considerable interest in various settings to understand to what extent such powerful tools extend to general metric spaces. A natural metric analogue of Rademacher type was proposed by Enflo in the 1960s-70s, and has found a number of interesting applications. Despite much work in the intervening years, however, the relationship between Rademacher type and Enflo type has remained unclear. This basic question is settled in joint work with Paata Ivanisvili and Sasha Volberg: in the setting of Banach spaces, Rademacher type and Enflo type coincide. The proof is based on a very simple but apparently novel insight on how to prove dimension-free inequalities on the Boolean cube. I will not assume any prior background in Banach space theory in the talk.</p></blockquote></div>
    </content>
    <updated>2020-04-04T22:46:48Z</updated>
    <published>2020-04-04T22:46:48Z</published>
    <category term="Announcements"/>
    <author>
      <name>plustcs</name>
    </author>
    <source>
      <id>https://tcsplus.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://tcsplus.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://tcsplus.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://tcsplus.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://tcsplus.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A carbon-free dissemination of ideas across the globe.</subtitle>
      <title>TCS+</title>
      <updated>2020-08-26T22:24:02Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://francisbach.com/?p=2445</id>
    <link href="https://francisbach.com/computer-aided-analyses/" rel="alternate" type="text/html"/>
    <title>Computer-aided analyses in optimization</title>
    <summary>In this blog post, I want to illustrate how computers can be great allies in designing (and verifying) convergence proofs for first-order optimization methods. This task can be daunting, and highly non-trivial, but nevertheless usually unavoidable when performing complexity analyses. A notable example is probably the convergence analysis of the stochastic average gradient (SAG) [1],...</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p class="justify-text">In this blog post, I want to illustrate how computers can be great allies in designing (and verifying) convergence proofs for first-order optimization methods. This task can be daunting, and highly non-trivial, but nevertheless usually unavoidable when performing complexity analyses. A notable example is probably the convergence analysis of the stochastic average gradient (SAG) [<a href="https://arxiv.org/pdf/1309.2388.pdf">1</a>], whose original proof was computer assisted.</p>



<p class="justify-text">To this end, we will mostly spend time on what is referred to as <em>performance estimation problems</em> (PEPs), introduced by Yoel Drori and Marc Teboulle [<a href="https://link.springer.com/article/10.1007/s10107-013-0653-0">2</a>]. Performance estimation is also closely related to the topic of <em>integral quadratic constraints</em> (IQCs), introduced in the context of optimization by Laurent Lessard, Benjamin Recht and Andrew Packard [<a href="https://epubs.siam.org/doi/abs/10.1137/15M1009597">3</a>]. In terms of presentations, IQCs  leverages control theory, whereas PEPs might seem more natural in the optimization community. This blog post essentially presents PEPs from the point of view of [<a href="https://link.springer.com/article/10.1007/s10107-016-1009-3">4</a>], instantiated on a running example.</p>



<h2>Overview, motivations</h2>



<p class="justify-text">First-order methods for continuous optimization belong to the large panel of algorithms that are usually approached via worst-case analyses. In this context, analyses rely on combining inequalities (that are due to assumptions on the problem classes), in potentially long, non-intuitive, and technical, proofs. For the insiders, those proofs all look very similar. For the outsiders, those proofs all look rather repelling, technical (long pages of chained inequalities), probably not interesting, and like computer codes: usually intuitive mostly for their authors.</p>



<p class="justify-text">In what follows, I want to show how (and why) those proofs are indeed all very similar. On the way, I want to emphasize how those combinations of inequalities are related to the “true essence” of worst-case analyses (which rely on computing worst-case scenarios), and to provide examples on how to constructively obtain them.</p>



<p class="justify-text">We take the stand of illustrating the PEP approach on a single iteration of gradient descent, as it essentially contains all necessary ingredients to understand the methodology in other contexts as well. Certain details of the following text are (probably unavoidably) a bit technical. However, going through the detailed computations is not essential, and the text should contain the necessary ingredients for understanding the essence of the methodology.</p>



<h2>Running example: gradient descent</h2>



<p class="justify-text">Let us consider a naive, but standard, example: unconstrained convex minimization $$x_\star= \underset{x\in\mathbb{R}^d}{\mathrm{arg min}} f(x)$$with gradient descent: \(x_{k+1}=x_k-\gamma \nabla f(x_k)\). Let us assume \(f(\cdot)\) to be continuously differentiable, to have a \(L\)-Lipschitz gradient (a.k.a., \(L\)-smoothness), and to be \(\mu\)-strongly convex. Those functions satisfy, for all \(x,y\in\mathbb{R}^d\):<br/>– strong convexity, see e.g., [<a href="https://link.springer.com/book/10.1007/978-1-4419-8853-9">5</a>, Definition 2.1.2]: $$\tag{1}f(x) \geqslant      f(y)+\langle{\nabla f(y)}; {x-y}\rangle+\tfrac{\mu}{2} \lVert x-y\rVert^2,$$- smoothness, see e.g., [<a href="https://link.springer.com/book/10.1007/978-1-4419-8853-9">5</a>, Theorem 2.1.5]: $$\tag{2} f(x) \leqslant      f(y)+\langle{\nabla f(y)}; {x-y}\rangle+\tfrac{L}{2}\lVert x-y\rVert^2.$$Let us recall that in the case of twice continuously differentiable functions, smoothness and strong convexity amount to requiring  that $$\mu I \preccurlyeq \nabla^2 f(x) \preccurlyeq L I,$$ for some \(0&lt; \mu&lt;L&lt; \infty\) and for all \(x\in\mathbb{R}^d\) (in other words, all eigenvalues of \(\nabla^2 f(x)\) are between \(\mu\) and \(L\)). In what follows, we denote by \(\mathcal{F}_{\mu,L}\) the class of \(L\)-smooth \(\mu\)-strongly convex functions (irrespective of the dimension \(d\)).</p>



<div class="wp-block-group"><div class="wp-block-group__inner-container">
<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img alt="" height="204" src="https://www.di.ens.fr/~ataylor/BlogPost/SmoothStronglyConvex.png" width="473"/>Figure 1: the blue function is \(L\)-smooth and \(\mu\)-strongly convex (it is possible to create respectively global upper and lower quadratic bounds from every \(x\in\mathbb{R}^d\) with respectively curvatures \(L\) and \(\mu\)).</figure></div>
</div></div>



<p class="justify-text">In this context, convergence of gradient descent can be studied in many ways. Here, for the sake of the example, we will do it in terms of two base quantities: distance to optimality \(\lVert x_k-x_\star\rVert\), and function value accuracy \(f(x_k)-f(x_\star)\). There are, of course, infinitely many other possibilities, such as gradient norm \(\rVert \nabla f(x_k)\lVert\), Bregman divergence \(f(x_\star)-f(x_k)-\langle{\nabla f(x_k)};{x_\star-x_k}\rangle\), or even best function value observed throughout the iterations \(\min_{0\leq i\leq k} \{f(x_i)-f(x_\star)\}\): the reader can adapt the lines below for his/her favorite criterion. </p>



<p class="justify-text">For later reference, let us provide another inequality that is known to  hold for all \(x,y\in\mathbb{R}^d\) for any \(L\)-smooth \( \mu\)-strongly convex function: <br/>– bound on inner product, see, e.g., [<a href="https://link.springer.com/book/10.1007/978-1-4419-8853-9">5</a>,  Theorem 2.1.11]: $$\langle{\nabla f(x)-\nabla f(y)};{x-y}\rangle  \geqslant        \tfrac{1}{L+\mu} \lVert{\nabla f(x)-\nabla f(y)}\rVert^2+\tfrac{\mu  L}{L+\mu}\lVert{x-y}\rVert^2.\tag{3}$$ In the case \(\mu=0\) this inequality is known as “cocoercivity”. This (perhaps mysterious) inequality happens to play an important role in convergence proofs.</p>



<h3>A standard convergence result</h3>



<p class="justify-text">Let us start by stating two known results along with their simple proofs (see, e.g.,  [<a href="https://link.springer.com/book/10.1007/978-1-4419-8853-9">5</a>, Theorem 2.1.14] or [6, Section 1.4.2, Theorems 2 &amp; 3]):<br/>– convergence in distance:  $$\begin{array}{rl}    \rVert{x_{k+1}-x_\star}\lVert^2&amp;= \lVert{x_k-x_\star}\rVert^2+\gamma^2\lVert{\nabla f(x_k)}\rVert^2-2\gamma\langle{\nabla f(x_k)};{x_k-x_\star}\rangle \\ \     &amp; \leqslant      \left(1-\tfrac{2\gamma L \mu}{L+\mu}\right)\lVert{x_k-x_\star}\rVert^2+\gamma\left(\gamma-\tfrac2{L+\mu}\right)\lVert{\nabla f(x_k)}\rVert^2, \end{array} $$ where the second line follows from smoothness and strong convexity of \(f\) via the bound (3) on the inner product (with \(x=x_k\) and \(y=x_\star\)). For the particular choice \(\gamma=\tfrac2{L+\mu}\), the second term on the right hand side disappears, and we end up with<br/>     $$\lVert{x_{k+1}-x_\star}\rVert^2 \leqslant      \left(\tfrac{L-\mu}{L+\mu}\right)^2\lVert{x_k-x_\star}\rVert^2,$$ which, following from \(0&lt;\mu&lt;L&lt;\infty\), satisfies \(0&lt; \tfrac{L-\mu}{L+\mu}&lt;1\), hence proving linear convergence of gradient descent in this setup, by recursively applying the previous inequality: $$ \lVert{x_{k}-x_\star}\rVert^2 \leqslant      \left(\tfrac{L-\mu}{L+\mu}\right)^{2k}\lVert{x_0-x_\star}\rVert^2.$$ – Convergence in function values: one can simply use the result in distance along with the previous basic inequalities (1) and (2) characterizing smoothness and strong convexity (both with \(y=x_\star\)):<br/>     $$f(x_k)-f(x_\star) \leqslant \hspace{-.15cm}\tfrac{L}{2}\hspace{-.1cm}\rVert{x_k-x_\star}\lVert^2  \leqslant  \hspace{-.15cm}    \tfrac{L}{2}\hspace{-.1cm}\left(\tfrac{L-\mu}{L+\mu}\right)^{\hspace{-.1cm}2k} \rVert{x_0-x_\star}\lVert^2 \leqslant  \hspace{-.15cm}     \tfrac{L}{\mu}\hspace{-.1cm} \left(\tfrac{L-\mu}{L+\mu}\right)^{\hspace{-.1cm}2k}(f(x_0)-f(x_\star)).$$  It is also possible to directly look for convergence in terms of function values, but it is then usually unclear in the literature what inequalities to use, and I am not aware of any such proof leading to the same rate without the leading \(\tfrac{L}{\mu}\) (except the proof presented below).</p>



<p class="justify-text">At this point, even in this toy example, a few very legitimate questions can be raised:<br/>– can we improve anything? Can gradient descent really behaves like that on this class of functions?<br/>– How could we have guessed the inequality to use, and the shape of the corresponding proof? Obviously, the obscure fact is to arrive to inequality (1).  Therefore, is there a principled way for choosing the right inequalities to use, for example for studying convergence in terms of other quantities, such as  function values?<br/>– Is this the unique way to arrive to the desired result? If yes, how likely are we to find such proofs for more complicated cases (algorithms and/or function class)?</p>



<p class="justify-text">For the specific step size choice \(\gamma=\tfrac2{L+\mu}\), a partial answer to the first question is obtained by the observation that the rate is actually achieved on the quadratic function<br/> $$f(x)=\tfrac12 \, x^\top \begin{bmatrix}<br/> L &amp; 0\\ 0 &amp; \mu<br/> \end{bmatrix}x.$$ The following lines precisely target the missing answers.</p>



<h2>Worst-case analysis through worst-case scenarios</h2>



<p class="justify-text">Let us start by rephrasing our goal, and restrict ourselves to the study of a single iteration. We fix our target to finding the smallest possible value of \(\rho\) such that the inequality<br/> $$ \lVert{x_{k+1}-x_\star}\rVert^2  \leqslant       \rho^2 \lVert{x_k-x_\star}\rVert^2 $$ is valid for all \(x_k\) and \(x_{k+1}=x_k-\gamma \nabla f(x_k)\) (hence \(\rho\) is a function of \(\gamma\)). In other words, our goal is to solve<br/>$$ \rho^2(\gamma):= \sup \left\{ \frac{\lVert{x_{k+1}-x_\star}\rVert^2}{\lVert{x_k-x_\star}\rVert^2}\, \big|\, f\in\mathcal{F}_{\mu,L},\, x_{k+1}=x_k-\gamma \nabla f(x_k),\, \nabla f(x_\star)=0\right\}.$$<br/>Alternatively, we could be interested in studying convergence in other forms: for function values, we could target to solve the slightly modified problem:<br/> $$ \sup  \left\{ \frac{f(x_{k+1})-f(x_\star)}{f(x_{k})-f(x_\star)}\, \big|\, f\in\mathcal{F}_{\mu,L},\, x_{k+1}=x_k-\gamma \nabla f(x_k),\, \nabla f(x_\star)=0 \right\}.$$ It turns out that in both cases, the problem can be solved both numerically to high precision, and analytically, and that the answer is \(\rho^2(\gamma)=\max\{(1-\mu\gamma)^2,(1-L\gamma)^2\}\).</p>



<p class="justify-text">The only thing we did, so far, was to explicitly reformulate the problem of finding the best (smallest) convergence rate as the problem of finding the worst-case scenario, nothing more. In what follows, some parts might become slightly technical, but the overall idea is only to reformulate this problem of finding the worst-case scenarios, for solving it.</p>



<h3>Dealing with an infinite-dimensional variable: the function \(f\)</h3>



<p class="justify-text">The first observation is that the problem of computing \(\rho\) is stated as an infinite-dimensional optimization problem: we are looking for the worst possible problem instance (a function \(f\) and an initial point \(x_k\)) within a predefined class of problems. The first step we take to work around this is to reformulate it in the following equivalent  form (note that we maximize also over the dimension \(d\)—we discuss later how to remove it):<br/>$$\begin{array}{rl} \rho^2:= \underset{f,\, x_k,\,x_\star,\, g_k,\,d}{\sup} &amp;\displaystyle \frac{\lVert{x_{k}-\gamma g_k-x_\star}\rVert^2}{\lVert{x_k-x_\star}\rVert^2}\\<br/> \text{s.t. }    &amp; \exists f\in\mathcal{F}_{\mu,L}:\, g_k= \nabla f(x_k),\, 0=\nabla f(x_\star).<br/>\end{array}$$<br/>This problem intrinsically does not look better (it contains an  existence constraint), but it allows using mathematical tools which are referred to as  <em>interpolation,</em> or <em>extension</em>, theorems [<a href="https://link.springer.com/article/10.1007/s10107-016-1009-3">4</a>, <a href="https://arxiv.org/pdf/1603.00241.pdf">7</a>, <a href="https://hal.archives-ouvertes.fr/hal-01530908/file/DHLL_appendix.pdf">8</a>]. The problem is depicted on Figure 2:</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img alt="" height="209" src="https://www.di.ens.fr/~ataylor/BlogPost/Interpolation.png" width="490"/>Figure 2: discrete interpolation (or extension) problem: given a set of triplets \(\{(\text{coordinate}, \text{gradient}, \text{function value})\}\) can we recover a function within a determined class that explains those triplets?</figure></div>



<p class="justify-text">It turns out that convex interpolation (that is, neglecting smoothness and strong convexity) is actually rather simple:</p>



<ul class="justify-text"><li>given a convex function and an index set \(I\), any set of samples \(\{(x_i,g_i,f_i)\}_{i\in I}\) of the form \(\{(\text{coordinate}, \text{(sub)gradient}, \text{function value})\}\)) satisfies, for all \(i,j\in I\): $$f_i \geqslant      f_j+\langle g_j; x_i-x_j\rangle,$$ by definition of subgradient, as illustrated on Figure 3.</li></ul>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img alt="" height="205" src="https://www.di.ens.fr/~ataylor/BlogPost/SamplingCvx.png" width="485"/>Figure 3: sampling from a convex function.</figure></div>



<ul class="justify-text"><li>In the other direction, given a set of triplets \(\{(x_i,g_i,f_i)\}_{i\in I}\) satisfying the previous inequality for all pairs \(i,j\in I\), one can simply recover a  convex function by the following construction: $$f(x)=\underset{i\in I}{\max}\{ f_i+\langle g_i;x-x_i\rangle\},$$ which is depicted on Figure 4.</li></ul>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img alt="" height="207" src="https://www.di.ens.fr/~ataylor/BlogPost/InterpolateCvx.png" width="487"/>Figure 4: some set \(\{(x_i,g_i,f_i)\}_{i\in I}\) and its piecewise affine interpolant \(f(x)=\underset{i\in I}{\max}\{ f_i+\langle g_i;x-x_i\rangle\}\).</figure></div>



<ul class="justify-text"><li>Formally, the reasoning allows arriving to the following “convex interpolation” (or “convex extension”) result, where we denote the set of (closed, proper) convex functions by \(\mathcal{F}_{0,\infty}\) (to be understood as \(L\)-smooth \(\mu\)-strongly convex functions with \(\mu=0\) and \(L=\infty\)): $$\begin{array}{c}\exists f\in\mathcal{F}_{0,\infty}: \,  g_k\in\partial f(x_k) \text{ and } f_k=f(x_k) \ \ \forall k\in  I\\ \Leftrightarrow\\ f_i \geqslant       f_j+\langle{g_j};{x_i-x_j}\rangle\quad \forall i,j\in I,\end{array}$$ where \(\partial f(x)\) denotes the subdifferential of \(f\) at \(x\).</li></ul>



<p class="justify-text">In the next section, we use a similar interpolation result for taking smoothness and strong convexity into account. The result is a bit more technical, but follows from similar constructions as those for convex interpolation—the main difference being that the interpolation is done on the Fenchel conjugate instead, in order to incorporate smoothness, see [<a href="https://link.springer.com/article/10.1007/s10107-016-1009-3">4</a>, Section 2].</p>



<h3>Reformulation through convex interpolation</h3>



<p class="justify-text">Back to the problem of computing worst-case scenarios, we can now reformulate the existence constraint <em>exactly</em> using the following result (see [<a href="https://link.springer.com/article/10.1007/s10107-016-1009-3">4</a>,  Theorem 4]): let \(I\) be a finite index set and let \( S=\{(x_i,g_i,f_i)\}_{i\in I}\) be a set of triplets, then<br/>  $$\begin{array}{c}\exists f\in\mathcal{F}_{\mu,L}: \,  g_i=\nabla f(x_i) \text{ and } f_i=f(x_i) \text{ for all } i\in  I\\ \Leftrightarrow\\  f_i \geqslant      f_j+\langle{g_j};{x_i-x_j}\rangle+\frac{1}{2L}\lVert{g_i-g_j}\rVert^2+\frac{\mu}{2(1-\mu/L)}\lVert{x_i-x_j-\frac{{1}}{L}(g_i-g_j)}\rVert^2  \,\,\, \forall i,j\in I.\end{array}$$ Therefore, the previous problem can be reformulated as (recalling that \(g_\star=0\))<br/>$$  \begin{array}{rl} \underset{{f_k,\,f_\star,\, x_k,\,x_\star,\, g_k,\,d}} {\sup}&amp;\displaystyle\frac{\rVert{x_{k}-\gamma  g_k-x_\star}\lVert^2}{\rVert{x_k-x_\star}\lVert^2}\\<br/>      \text{s.t. }    &amp; f_\star \geqslant      f_k+\langle{g_k};{x_\star-x_k}\rangle+\frac{1}{2L}\lVert{g_k}\rVert^2+\frac{\mu}{2(1-\mu/L)}\lVert{x_k-x_\star-\frac{{1}}{L}g_k}\rVert^2\\<br/>      &amp; f_k \geqslant      f_\star+\frac{1}{2L}\lVert{g_k}\rVert^2+\frac{\mu}{2(1-\mu/L)}\lVert{x_k-x_\star-\frac{{1}}{L}g_k}\rVert^2.<br/>\end{array}$$ </p>



<h3>Quadratic reformulation</h3>



<p class="justify-text">The next step is to remove the ratio appearing in the objective function, which we do via an homogeneity argument, as follows.</p>



<p class="justify-text">Starting from a feasible point, scale \(x_k,\,x_\star,g_k\) by some \(\alpha&gt;0\) and \(f_k,\,f_\star\) by \(\alpha^2\) and observe it does not change the value of the objective, while still being a feasible point. Therefore, the problem can be reformulated as a nonconvex QCQP (quadratically constrained quadratic program): $$  \begin{array}{rl} \underset{{f_k,\,f_\star,\, x_k,\,x_\star,\, g_k,\,d}} {\sup}&amp;\displaystyle{\rVert{x_{k}-\gamma  g_k-x_\star}\lVert^2}\\<br/>       \text{s.t. }    &amp; f_\star \geqslant      f_k+\langle{g_k};{x_\star-x_k}\rangle+\frac{1}{2L}\lVert{g_k}\rVert^2+\frac{\mu}{2(1-\mu/L)}\lVert{x_k-x_\star-\frac{{1}}{L}g_k}\rVert^2\\<br/>       &amp; f_k \geqslant      f_\star+\frac{1}{2L}\lVert{g_k}\rVert^2+\frac{\mu}{2(1-\mu/L)}\lVert{x_k-x_\star-\frac{{1}}{L}g_k}\rVert^2\\ &amp;{\rVert{x_k-x_\star}\lVert^2} \leqslant      1,<br/> \end{array}$$  which is quadratic in \(x_k\), \(x_\star\) and  \(g_k\), and linear in \(f_\star\) and \(f_k\). Actually, in the current form, nonconvexity comes from the term “\(\langle{g_k};{x_\star-x_k}\rangle\)” in the second constraint (and from the objective, due to maximization). It turns out that this problem can be reformulated <em>losslessly</em> using semidefinite programming (this is due to the maximization over \(d\), as commented at the end of the next section). </p>



<h3>Semidefinite reformulation</h3>



<p class="justify-text">At the end of this section, we will be able to compute, numerically, the values of the rate \(\rho^2(\gamma)\) for given values of the parameters \(\mu,\,L\), and \(\gamma\).</p>



<p class="justify-text">The last step in the reformulation goes as follows: the previous problem can be reformulated as a semidefinite program, as it is linear in terms of the entries of the following Gram matrix<br/>$$G = \begin{pmatrix}<br/>     \lVert{x_k-x_\star}\rVert^2 &amp; \langle{g_k};{x_k-x_\star}\rangle \\ \langle{g_k};{x_k-x_\star}\rangle &amp; \lVert{g_k}\rVert^2<br/>     \end{pmatrix}\succcurlyeq 0,$$ and in terms of the function values \(f_k\) and \(f_\star\). From those variables, one reformulate the previous problem as $$\begin{array}{rl} \underset{f_k,\,f_\star,\, G\succeq 0}{\sup} \, &amp;{\mathrm{Tr} (A_\text{num} G)}\\<br/>      \text{s.t. }    &amp; f_k-f_\star+\mathrm{Tr} (A_1 G)\leqslant 0\\<br/>      &amp;  f_\star-f_k+\mathrm{Tr} (A_2 G)\leqslant 0 \\<br/>      &amp;\mathrm{Tr} (A_\text{denom} G) \leqslant      1,\end{array}$$ which is a gentle semidefinite program where we picked matrices \(A_{\text{num}}\), \(A_{\text{denom}}\), \(A_1\) and \(A_2\) for encoding the previous terms. That is, we choose those matrices such that<br/> $$\begin{array}{rl}<br/>\mathrm{Tr}(A_{\text{denom}} G)&amp;=\lVert{x_k-x_\star}\rVert^2,\\  \mathrm{Tr}(A_{\text{num}} G)&amp;=\lVert{x_k-\gamma g_k-x_\star}\rVert^2,\\ \mathrm{Tr}(A_1G)&amp;=\langle{g_k};{x_\star-x_k}\rangle+\frac{1}{2L}\lVert{g_k}\rVert^2+\frac{\mu}{2(1-\mu/L)}\lVert{x_k-x_\star-\frac{{1}}{L}g_k}\rVert^2,\\ \mathrm{Tr}(A_2G)&amp;=\tfrac{1}{2L}\lVert g_k\rVert^2+\tfrac{\mu}{2(1-\mu/L)}\lVert x_k-x_\star-\tfrac1L g_k\rVert^2.\end{array}$$ One possibility is to choose \(A_{\text{num}}\), \(A_{\text{denom}}\), \(A_1\) and \(A_2\) as symmetric matrices, as follows: $$\begin{array}{cc}<br/> A_{\text{denom}}=\begin{pmatrix}     1 &amp; 0\\ 0 &amp; 0     \end{pmatrix}, &amp; A_{\text{num}}=\begin{pmatrix}     1 &amp; -\gamma\\ -\gamma &amp; \gamma^2     \end{pmatrix}, \\ A_1=\begin{pmatrix}\tfrac{\mu}{2(1-\mu/L)} &amp; -\tfrac12-\tfrac{\mu}{2(L-\mu)} \\ -\tfrac12-\tfrac{\mu}{2(L-\mu)} &amp; \tfrac{1}{2L}+\tfrac{\mu}{2L(L-\mu)}\end{pmatrix}, &amp;  A_2=\begin{pmatrix}\tfrac{\mu}{2(1-\mu/L)} &amp; -\tfrac{\mu}{2(L-\mu)} \\ -\tfrac{\mu}{2(L-\mu)} &amp; \tfrac{1}{2L}+\tfrac{\mu}{2L(L-\mu)} \end{pmatrix}.\end{array}$$</p>



<p class="justify-text">All those steps can be carried out in the exact same way for the problem of computing the convergence rate for function values, reaching a similar problem with \(6\) inequality constraints instead—because interpolation conditions have to be imposed on all pairs of points in a set of \(3\) points: \(x_k\), \(x_{k+1}\) and \(x_\star\), instead of only \(2\) for the distance problem. The objective function is then \(f_{k+1}-f_\star\), the de-homogenization constraint (arising from the denominator of the objective function) is \(f_{k}-f_\star \leqslant     1\), and the Gram matrix is \(3\times 3\):<br/>$$G=\begin{pmatrix}<br/>     \lVert{x_k-x_\star}\rVert^2 &amp; \langle{g_k};{x_k-x_\star}\rangle&amp; \langle{g_{k+1}};{x_k-x_\star}\rangle\\ \langle{g_k};{x_k-x_\star}\rangle &amp; \lVert{g_k}\rVert^2 &amp; \langle{g_k};{g_{k+1}}\rangle \\<br/>     \langle{g_{k+1}};{x_k-x_\star}\rangle &amp; \langle{g_{k+1}};{g_k}\rangle &amp; \lVert{g_{k+1}}\rVert^2<br/>     \end{pmatrix}\succcurlyeq 0, $$ and the function values variables are \(f_k\), \(f_{k+1}\) and \(f_\star\).</p>



<p class="justify-text">We provide the numerical optimal values of those semidefinite programs on Figure 5 for both convergence in distances and in function values. </p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img alt="" height="324" src="https://www.di.ens.fr/~ataylor/BlogPost/ObjectiveValues.png" width="534"/>Figure 5: worst-cases of the ratio \(\frac{\lVert{x_{k+1}-x_\star}\rVert^2}{\lVert{x_k-x_\star}\rVert^2}\) (red) and \(\frac{f(x_{k+1})-f_\star}{f(x_k)-f_\star}\) (dashed blue) as functions of the step size \(\gamma\), for the case where \(f\) is \(1\)-smooth and \(0.1\)-strongly convex. The results match exactly the expected \(\max\{(1-\gamma L)^2,(1-\gamma\mu)^2\}\) in both cases. Note that the corresponding SDPs can be solved both for “good and bad” choices of step sizes: if the step size is chosen wisely then \(\rho(\gamma)&lt;1\), and otherwise \(\rho(\gamma)\geqslant 1\). The SDP confirms the common knowledge that \(\gamma\in (0,2/L)\Rightarrow \rho(\gamma)&lt; 1\). Numerical values obtained through YALMIP [<a href="https://yalmip.github.io/">9</a>] and Mosek [<a href="https://www.mosek.com/">10</a>].</figure></div>



<p class="justify-text">As a conclusion for this section, let us note that we showed how to compute the “best” rates that are dimension independent. In general, requiring the iterates and gradient (e.g., \(x_k\) and \(g_k\) for the problem in terms of distance, and \(x_k\), \(g_k\) and \(g_{k+1}\) for function values, and potentially more vectors when dealing with more complex settings) to lie in \(\mathbb{R}^d\) is equivalent to adding a rank constraint in the SDP. </p>



<h2>Duality between worst-case scenarios and combinations of inequalities</h2>



<p class="justify-text">Any feasible point to the previous SDP corresponds to a <em>lower bound</em>: a sampled version of a potentially difficult function for gradient descent. If we want to find <em>upper bounds</em> on the rate, a natural way to proceed is to go to the dual side of the previous SDPs, where any feasible point will naturally correspond to an upper bound on the convergence rate (by <em>weak duality</em>). As the primal problems were SDPs, their Lagrangian duals are SDPs as well. Let us associate one multiplier per constraint: $$ \begin{array}{rl}<br/>f_k-f_\star+\mathrm{Tr} (A_1 G)\leqslant 0&amp;:\lambda_1\\<br/>f_\star-f_k+\mathrm{Tr} (A_2 G)\leqslant 0&amp;:\lambda_2\\<br/>\mathrm{Tr}(A_\text{denom} G) \leqslant 1&amp;: \tau.<br/>\end{array}$$The dual is then<br/>$$\begin{array}{rl}<br/> \underset{\tau,\,\lambda_1,\,\lambda_2}{\min} &amp; \, \tau \\<br/> \text{s.t. } &amp; \lambda_1=\lambda_2,\\<br/> &amp; S:=A_\text{num}-\tau A_\text{denom}-\lambda_1A_1-\lambda_2A_2 \preccurlyeq 0,\\<br/> &amp;\tau,\lambda_1,\lambda_2 \geqslant  0.<br/> \end{array}$$ Hence, by weak duality, any feasible point to this last SDP corresponds to an upper bound on the rate: \(\tau \geqslant \rho^2\). A mere rephrasing of weak duality can be obtained through the following reasoning: assume we received some feasible \(\tau,\lambda_1,\lambda_2\) (and hence \(\lambda_1=\lambda_2\) and a corresponding \(S\preccurlyeq 0\)), we then get, for any primal feasible \(G\succcurlyeq0\):<br/>$$\begin{array}{rl}\mathrm{Tr}(SG)&amp;=\mathrm{Tr}(A_{\text{num}}G)-\tau\mathrm{Tr}(A_{\text{denom}}G)-\lambda_1\mathrm{Tr}(A_1G)-\lambda_2\mathrm{Tr}(A_2G)\\&amp;=\lVert x_{k+1}-x_\star\rVert^2-\tau\lVert x_{k}-x_\star\rVert^2\\ \,&amp;\,\,\,-\lambda_1[     f_k-f_\star+\langle{g_k};{x_\star-x_k}\rangle+\frac{1}{2L}\lVert{g_k}\rVert^2+\frac{\mu}{2(1-\mu/L)}\lVert{x_k-x_\star-\frac{{1}}{L}g_k}\rVert^2]\\ &amp;\,\,\,-\lambda_2 [f_\star-f_k+\frac{1}{2L}\lVert{g_k}\rVert^2+\frac{\mu}{2(1-\mu/L)}\lVert{x_k-x_\star-\frac{{1}}{L}g_k}\rVert^2]\\ &amp;\geqslant \lVert x_{k+1}-x_\star\rVert^2-\tau\lVert x_{k}-x_\star\rVert^2, \end{array}$$ where the first equality follows from the definition of \(S\), the second equality corresponds to the definitions of \(A_{\text{num}}\), \(A_{\text{denom}}\), \(A_1\) and \(A_2\), and the last inequality follows from the sign of the interpolation inequalities (constraints in the primal) for any primal feasible point. Hence, we indeed have that any feasible \(\tau\) corresponds to a valid upper bound on the convergence rate, as $$S\preccurlyeq 0 \,\,\Rightarrow \,\, \mathrm{Tr}(SG)\leqslant 0\,\,\Rightarrow  \lVert x_{k+1}-x_\star\rVert^2-\tau\lVert x_{k}-x_\star\rVert^2\leqslant 0.$$ In order to obtain analytical proofs, we therefore need to find analytical dual feasible points, and numerics can of course help in this process! Let’s look at what the optimal dual solutions look like for our two running examples.</p>



<ul class="justify-text"><li> in Figure 6, we provide the numerical values for \(\lambda_1\) and \(\lambda_2\) for the distance problem.</li></ul>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img alt="" height="316" src="https://www.di.ens.fr/~ataylor/BlogPost/Multipliers_distance.png" width="467"/>Figure 6: numerical values of optimal dual variables: \(\lambda_1\) (red) and \(\lambda_2\) (dashed blue) as functions of the step size \(\gamma\), for the case where \(f\) is \(1\)-smooth and \(0.1\)-strongly convex. The results match \(\lambda_1=\lambda_2=2\gamma \rho(\gamma)\) with \(\rho(\gamma)=\max\{|1-\gamma L|,|1-\gamma\mu|\}\). Numerical values obtained with YALMIP [<a href="https://yalmip.github.io/">9</a>] and Mosek [<a href="https://www.mosek.com/">10</a>].</figure></div>



<ul class="justify-text"><li>For function values, the SDP is slightly more complicated, as more inequalities are involved (6 interpolation inequalities). We provide raw numerical values for the six multipliers in Figure 7.</li></ul>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img alt="" height="348" src="https://www.di.ens.fr/~ataylor/BlogPost/Multipliers_function.png" width="463"/>Figure 7: numerical values of optimal dual variables (for the rate in function values): \(\lambda_1,\lambda_2, …,\lambda_6\) as functions of the step size \(\gamma\), for the case where \(f\) is \(1\)-smooth and \(0.1\)-strongly convex. Numerical values obtained with YALMIP [<a href="https://yalmip.github.io/">9</a>] and Mosek [<a href="https://www.mosek.com/">10</a>].</figure></div>



<p>For those who want a bit more details, here are a few additional pointers:</p>



<ul class="justify-text"><li>Strong duality holds—a way to prove it is to show that there exists a Slater point in the primal, see e.g., [<a href="https://link.springer.com/article/10.1007/s10107-016-1009-3">4</a>, Theorem 6]—, and hence primal and dual optimal values match.</li><li>There might be different ways to optimaly combine the interpolation inequalities for proving the desired results. In other words: dual optimal solutions are often not unique—which is, in fact, quite a good news: I am sure nobody want to find the analytical version of the multipliers provided in Figure 7.</li><li>It is often possible to simplify the proofs by using fewer, or weaker, inequalities. This might lead to ”cleaner” results, typically (but not always) at the cost of ”weaker” rates. This was done for designing the proof for function values, later in this text.</li></ul>



<h2>Combinations of inequalities: same proofs without SDPs</h2>



<p class="justify-text">So far, we showed that computing convergence rates can be done in a very principled way. To this end, one can solve semidefinite programs—which may have arbitrarily complicated analytical solutions. Here, I want to emphasize that the process of <em>verifying</em> a solution can be quite different to that of<em> finding</em> a solution. Put in other words, although the dual certificates (a.k.a., the proofs) might have been found by solving SDPs, they can be formulated in ways that do not require the reader to know anything about the PEP methodology, nor on any SDP material, for verifying them. This fact might actually not be very surprising to the reader, as many proofs arising in the first-order optimization literature actually “only consists” in linear combinations of (quadratic) inequalities. On the one hand, those proofs can be seen as feasible points to “dual SDPs”, although generally not explicitely proved as such. On the other hand, proofs arising from the SDPs might therefore be expected to be writable without any explicit reference to semidefinite programing and performance estimation problems.<br/></p>



<p class="justify-text">In what follows, we provide the proofs for gradient descent, using the previous numerical inspiration, but without explicitly relying on any semidefinite program. The reader is not expected to verify any of those computations, as our goal is rather to emphasize that the principles underlying both proofs are exactly the same: reformulating linear combinations of inequalities.</p>



<p class="justify-text">For both proofs below, we limit ourselves to the step size regime \(0\leq   \gamma \leq \tfrac{2}{L+\mu}\), and we prove  that, in  this regime, \(\rho(\gamma)=(1-\gamma\mu)\)—actually we only proof the upper bounds, but one can easily verify that they are <em>tight</em> on simple quadratic functions.  The complete proofs (for the proximal gradient method),  can be found in [<a href="https://arxiv.org/pdf/1705.04398.pdf">11</a>]. </p>



<h3>Example 1: distance to optimality</h3>



<p class="justify-text">Recall the notations: \(g_k:=\nabla f(x_k)\), \(f_k:= f(x_k)\), \(g_\star:=\nabla f(x_\star)\), and \(f_\star:= f(x_\star)\).</p>



<p class="justify-text">For distance to optimality, sum the following inequalities with their corresponding weights: $$\begin{array}{r}     f_\star \geqslant      f_k+\langle{g_k};{x_\star-x_k}\rangle+\frac{1}{2L}\lVert{g_k-g_\star}\rVert^2+\frac{\mu}{2(1-\mu/L)}\lVert{x_k-x_\star-\frac{{1}}{L}(g_k-g_\star)}\rVert^2  :\lambda_1,  \\     f_k \geqslant      f_\star+\langle{g_\star};{x_k-x_\star}\rangle+\frac{1}{2L}\lVert{g_k-g_\star}\rVert^2+\frac{\mu}{2(1-\mu/L)}\lVert{x_k-x_\star-\frac{{1}}{L}(g_k-g_\star)}\rVert^2:\lambda_2.     \end{array}$$ We use the following values for the multipliers: \(\lambda_1=\lambda_2=2\gamma\rho(\gamma) \geqslant      0\) (see Figure 6). </p>



<p class="justify-text">After appropriate substitutions of \(g_\star\), \(x_{k+1}\), and \(\rho(\gamma)\), using respectively \(g_\star=0\), \(x_{k+1}=x_k-\gamma g_k\) and \(\rho(\gamma)=(1-\gamma\mu)\), and with little effort, one can check that the previous weighted sum of inequalities can be written in the form: $$ \begin{array}{rl}    \lVert{x_{k+1}-x_\star}\rVert^2  \leqslant      &amp; \left(1-\gamma \mu \right)^2\lVert{x_{k}-x_\star}\rVert^2 -\frac{\gamma(2-\gamma (L+\mu))}{L-\mu} \lVert{\mu {(x_k  -x_\star)} – g_k}\rVert^2. \end{array}$$ This statement can be checked simply by expanding both expressions (i.e., the weighted sum and its reformulation) and verifying that all terms indeed match.</p>



<p class="justify-text">Finally, using $$\gamma(2-\gamma (L+\mu)) \geqslant      0,  \text{ and } L-\mu \geqslant      0,$$ which are nonnegative by assumptions on the values of \(L\in(0,\infty)\), \(\mu\in (0,L)\) and \(\gamma\in(0,2/(L+\mu))\), we arrive to the desired $$ \lVert{x_{k+1}-x_\star}\rVert^2 \leqslant      \left(1-\gamma \mu \right)^2\lVert{x_{k}-x_\star}\rVert^2.$$</p>



<p class="justify-text">Note that, by using \(\lambda_1=\lambda_2\), the weighted sum exactly corresponds to the (scaled by a positive constant) inequality introduced in the early stage of this note for studying distance to optimality. However, the resulting expression is tight for all values of the step size here, whereas it was only tight for \(\gamma=2/(L+\mu)\) earlier, due to a different choice of weights! </p>



<p class="justify-text">The curious reader might wonder how to find such a reformulation. Actually, back in terms of SDPs, and using the expressions for the multipliers, it simply corresponds to $$\mathrm{Tr}(SG)=-\frac{\gamma(2-\gamma (L+\mu))}{L-\mu} \lVert{\mu {(x_k  -x_\star)} – g_k}\rVert^2.$$ In the example below, the reformulation is a bit more tricky—as \(\mathrm{Tr}(SG)\)  has two nonnegative terms, which were simply obtained by doing an analytical Cholesky factorization of the term \(\mathrm{Tr}(SG)\)—, but the idea is exactly the same.</p>



<h3>Example 2: function values</h3>



<p class="justify-text">For function values, we combine the following inequalities after multiplication with their respective coefficients:    </p>



<p class="justify-text">$$\scriptsize \begin{array}{lr}     f_k \geqslant      f_{k+1}+\langle{g_{k+1}};{x_k-x_{k+1}}\rangle+\frac{1}{2L}\lVert{g_k-g_{k+1}}\rVert^2+\frac{\mu}{2(1-\mu/L)}\lVert{x_k-x_{k+1}-\frac{1}{L}(g_k-g_{k+1})}\rVert^2    &amp;:\lambda_1,\\<br/>f_\star \geqslant      f_k+\langle{g_k};{x_\star-x_k}\rangle+\frac{1}{2L}\lVert{g_k-g_\star}\rVert^2+\frac{\mu}{2(1-\mu/L)}\lVert{x_k-x_\star-\frac{1}{L}(g_k-g_\star)}\rVert^2  &amp;:\lambda_2, \\<br/>f_\star \geqslant      f_{k+1}+\langle{g_{k+1}};{x_\star-x_{k+1}}\rangle+\frac{1}{2L}\lVert{g_\star-g_{k+1}}\rVert^2+\frac{\mu}{2(1-\mu/L)}\lVert{x_\star-x_{k+1}-\frac{1}{L}(g_\star-g_{k+1})}\rVert^2  &amp;:\lambda_3.     \end{array}$$ We use the following multipliers \(\lambda_1=\rho(\gamma)\), \(\lambda_2=(1-\rho(\gamma))\rho(\gamma)\), and  \(\lambda_3=1-\rho(\gamma)\) (obtained by greedily trying to set different combinations of multipliers to \(0\) in the SDP—see Figure 7 for the values without such simplifications).</p>



<p class="justify-text">Again, after appropriate substitutions of \(g_\star\), \(x_{k+1}\), and \(\rho(\gamma)\), using respectively \(g_\star=0\), \(x_{k+1}=x_k-\gamma g_k\) and \(\rho(\gamma)=(1-\gamma\mu)\), we obtain that the weighted sum of inequalities can be reformulated exactly as $$  \begin{array}{rl}          f(x_{k+1})-f_\star \leqslant      &amp;\left(1-\gamma \mu\right)^2 \left(f(x_k)-f_\star\right)\\&amp;-\frac{1}{2 (L-\mu)}\lVert \nabla f(x_{k+1})-(1-\gamma  (L+\mu))\nabla f(x_k) +\gamma  \mu  L (x_\star-x_k)\rVert^2\\<br/>&amp;-\frac{\gamma  L(2- \gamma  (L+\mu))}{2 (L-\mu )}\lVert \nabla f(x_k)+\mu  (x_\star-x_k)\rVert^2.\end{array}$$ Again, this statement can be checked simply by expanding both expressions (i.e., the weighted sum and its reformulation), and verifying that all terms match. The desired conclusion $$ f(x_{k+1})-f_\star \leqslant \left(1-\gamma \mu\right)^2 \left(f(x_k)-f_\star\right), $$ follows from the signs of the leading coefficients: \(\gamma(2-\gamma (L+\mu)) \geqslant      0\), and \(L-\mu \geqslant      0\).</p>



<h3>To go further</h3>



<p class="justify-text">Before finishing, let us mention that we only dealt with linear convergence through a single iteration of gradient descent.</p>



<p class="justify-text">There are quite a few ways to handle both more iterations and sublinear convergence rates. Using SDPs, probably the most natural approach is to directly incorporate several iterations in the problem by  studying, for example, ratios of the form  $$\sup_{f\in\mathcal{F}_{\mu,L},\, x_0}  \frac{f(x_{N})-f_\star}{\lVert x_0-x_\star\rVert^2}. $$ This type of approach was used in the work of Drori and Teboulle [<a href="https://arxiv.org/pdf/1206.3209.pdf">2</a>] and in most consecutive PEP-related works: it has the advantage of providing  comfortable “non-improvable results” [<a href="https://link.springer.com/article/10.1007/s10107-016-1009-3">4</a>, <a href="https://arxiv.org/pdf/1512.07516.pdf">12</a>]   (by providing matching lower bounds) for any given \(N\), but requires solving larger and larger SDPs. Alternatively, simpler proofs can often be obtained through the use of  Lyapunov (or potential) functions—i.e., study a single iteration to produce recursable inequalities; a nice introduction is provided in [<a href="http://www.theoryofcomputing.org/articles/v015a004/v015a004.pdf">13</a>]. This idea can be exploited in PEPs [<a href="https://arxiv.org/pdf/1902.00947.pdf">14</a>] by enforcing the proofs to have a certain structure. Those principles are also at the heart of the related approach using integral quadratic constraints [<a href="https://epubs.siam.org/doi/abs/10.1137/15M1009597">3</a>, <a href="http://proceedings.mlr.press/v70/hu17a/hu17a.pdf">15</a>]. </p>



<h2>Take-home message and conclusions</h2>



<p class="justify-text">The overall message of this note is that first-order methods can often be studied directly using the definition of their “worst-cases” (i.e., by trying to find worst-case scenarios), along with their dual counterparts (linear combinations of inequalities), by translating them into semidefinite programs.</p>



<p class="justify-text">What we saw might look like an overkill for studying gradient descent. However, as long as we deal with Euclidean spaces, the same approach actually works beyond this simple case. In particular, the same technique applies to first-order methods performing explicit, projected, proximal, conditional, and inexact (sub)gradient steps [<a href="https://arxiv.org/pdf/1512.07516.pdf">12</a>].</p>



<p class="justify-text">Finally, let us mention a few previous works illustrating that the use of such computer-assisted proofs allowed obtaining results that are apparently too complicated for us to find bare-handed—even in apparently simple contexts.  Reasonable examples include the direct proof for convergence rates in  function values [<a href="https://arxiv.org/pdf/1705.04398.pdf">11</a>] presented above, but also proofs arising in the context of optimized numerical schemes [<a href="https://arxiv.org/pdf/1206.3209.pdf">2</a>, <a href="https://arxiv.org/abs/1409.2636">16</a>, <a href="https://arxiv.org/pdf/1406.5468.pdf">17</a>, <a href="https://arxiv.org/pdf/1803.06600.pdf">18</a>]—in particular [<a href="https://arxiv.org/pdf/1803.06600.pdf">18</a>] presents a method for minimizing the gradient norm at the last iterate, in smooth convex minimization—,  in the context of monotone inclusions [<a href="https://arxiv.org/pdf/1812.00146.pdf">19</a>],  and even for more general fixed-point problems (e.g., for Halpern iterations [<a href="http://www.optimization-online.org/DB_FILE/2017/11/6336.pdf">20</a>]).</p>



<h3>Toolbox</h3>



<p class="justify-text">The PErformance EStimation TOolbox (PESTO) [<a href="https://perso.uclouvain.be/julien.hendrickx/availablepublications/PESTO_CDC_2017.pdf">21</a>, see <a href="https://github.com/AdrienTaylor/Performance-Estimation-Toolbox/graphs/traffic">Github</a>] allows a quick access to the methodology without worrying about details of semidefinite reformulations. The toolbox contains many  examples (about 50) in different settings, and include progresses on the approach, and results, by other groups (which are much more thoroughly referenced in the <a href="https://github.com/AdrienTaylor/Performance-Estimation-Toolbox/blob/master/UserGuide.pdf">user guide</a>). In particular, we included standard classes of functions and operators, along with examples for analyzing recent optimized methods.</p>



<h2>References</h2>



<p class="justify-text">[1] Mark Schmidt, Nicolas Le Roux, Francis Bach. <a href="https://arxiv.org/pdf/1309.2388.pdf">Minimizing finite sums with the stochastic average gradient</a>. <em>Mathematical Programming</em>, <em>162</em>(1-2), 83-112, 2017.<br/>[2] Yoel Drori, Marc Teboulle. <a href="https://arxiv.org/pdf/1206.3209.pdf">Performance of first-order methods for smooth convex minimization: a novel approach</a>. <em>Mathematical Programming</em>, 145(1-2), 451-482, 2014.<br/>[3] Laurent Lessard, Benjamin Recht, Andrew Packard. <a href="https://epubs.siam.org/doi/abs/10.1137/15M1009597">Analysis and design of  optimization algorithms via integral quadratic constraints</a>. <em>SIAM Journal on Optimization</em>, 26(1), 57-95, 2016.<br/>[4] Adrien Taylor,  Julien Hendrickx, François Glineur. <a href="https://link.springer.com/article/10.1007/s10107-016-1009-3">Smooth strongly convex interpolation and exact worst-case performance of first-order methods</a>. <em>Mathematical Programming</em>, 161(1-2), 307-345, 2017.<br/>[5] Yurii Nesterov. <a href="https://link.springer.com/book/10.1007/978-1-4419-8853-9">Introductory Lectures on Convex Optimization : a Basic Course</a>. <em>Applied optimization</em>. Kluwer Academic Publishing, 2004.<br/>[6]  Boris Polyak. Introduction to Optimization. Optimization Software New York, 1987.<br/>[7] Daniel Azagra, Carlos Mudarra. <a href="https://arxiv.org/pdf/1603.00241.pdf">An extension theorem for convex functions of class \(C^{1,1}\) on Hilbert spaces</a>. <em>Journal of Mathematical Analysis and Applications</em>, 446(2):1167–1182, 2017.<br/>[8] Aris Daniilidis, Mounir Haddou, Erwan Le Gruyer, Olivier Ley. <a href="https://hal.archives-ouvertes.fr/hal-01530908/file/DHLL_appendix.pdf">Explicit formulas for \(C^{1,1}\) Glaeser-Whitney extensions of 1-Taylor fields in Hilbert spaces</a>. <em>Proceedings of the American Mathematical Society</em>, 146(10):4487–4495, 2018.<br/>[9] Johan Löfberg. <a href="https://yalmip.github.io/">YALMIP : A toolbox for modeling and optimization in MATLAB</a>. <em>Proceedings of the CACSD Conference</em>, 2004.<br/>[10] APS Mosek. <a href="https://www.mosek.com/">The MOSEK optimization software</a>. Online at http://www.mosek.com, 54, 2010.<br/>[11] Adrien Taylor, Julien Hendrickx, François Glineur. <a href="https://arxiv.org/pdf/1705.04398.pdf">Exact worst-case convergence rates of the proximal gradient method for  composite convex minimization</a>. <em>Journal of Optimization Theory and Applications</em>, vol. 178, no 2, p. 455-476, 2018.<br/>[12] Adrien Taylor, Julien Hendrickx, François Glineur. <a href="https://arxiv.org/pdf/1512.07516.pdf">Exact worst-case performance of first-order methods for composite convex optimization</a>. <em>SIAM Journal on Optimization</em>, vol. 27, no 3, p. 1283-1313, 2017.<br/>[13] Nikhil Bansal, Anupam Gupta. <a href="http://www.theoryofcomputing.org/articles/v015a004/v015a004.pdf">Potential-Function Proofs for Gradient Methods. <em>Theory of Computing</em></a>, <em>15</em>(1), 1-32, 2019.<br/>[14] Adrien Taylor, Francis Bach. <a href="https://arxiv.org/pdf/1902.00947.pdf">Stochastic first-order methods: non-asymptotic and computer-aided analyses via potential functions</a>, <em>Proceedings of the 32nd Conference on Learning Theory (COLT)</em>, 99:2934-2992, 2019.  <br/>[15] Bin Hu, Laurent Lessard. <a href="http://proceedings.mlr.press/v70/hu17a/hu17a.pdf">Dissipativity theory for Nesterov’s accelerated method</a>, <em>Proceedings of the 34th International Conference on Machine Learning</em>, 70:1549-1557, 2017. <br/>[16] Yoel Drori, Marc Teboulle. <a href="https://arxiv.org/abs/1409.2636">An optimal variant of Kelley’s cutting-plane method</a>. <em>Mathematical Programming</em> 160.1-2: 321-351, 2016.<br/>[17] Donghwan<strong> </strong>Kim, Jeffrey Fessler. <a href="https://arxiv.org/pdf/1406.5468.pdf">Optimized first-order methods for smooth convex minimization</a>, <em>Mathematical programming</em>, <em>159</em>(1-2), 81-107, 2016.<br/>[18] Donghwan Kim, Jeffrey Fessler. <a href="https://arxiv.org/pdf/1803.06600.pdf">Optimizing the efficiency of first-order methods for decreasing the gradient of smooth convex functions</a>, <em>preprint arXiv:1803.06600</em>, 2018. <br/>[19] Ernest Ryu, Adrien Taylor, Carolina Bergeling, Pontus Giselsson. <a href="https://arxiv.org/pdf/1812.00146.pdf">Operator splitting performance estimation: Tight contraction factors and optimal parameter selection</a>, <em><em>SIAM Journal on Optimization</em> (to appear), 2020.</em><br/>[20] Felix Lieder. <a href="http://www.optimization-online.org/DB_FILE/2017/11/6336.pdf">On the convergence rate of the Halpern-iteration</a>. Technical Report, 2019.<br/>[21] Adrien Taylor, Julien Hendrickx, François Glineur.  <a href="https://perso.uclouvain.be/julien.hendrickx/availablepublications/PESTO_CDC_2017.pdf">Performance estimation toolbox (PESTO): automated worst-case analysis of  first-order optimization methods</a>,<em> Proceedings of the 56th Annual Conference on Decision and Control (CDC)</em>, pp. 1278-1283, 2017.</p></div>
    </content>
    <updated>2020-04-03T11:37:27Z</updated>
    <published>2020-04-03T11:37:27Z</published>
    <category term="Machine learning"/>
    <category term="Tools"/>
    <author>
      <name>Adrien Taylor</name>
    </author>
    <source>
      <id>https://francisbach.com</id>
      <link href="https://francisbach.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://francisbach.com" rel="alternate" type="text/html"/>
      <subtitle>Francis Bach</subtitle>
      <title>Machine Learning Research Blog</title>
      <updated>2020-08-26T22:24:38Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://theorydish.blog/?p=1644</id>
    <link href="https://theorydish.blog/2020/04/01/approx-random-2020-is-virtual-from-the-get-go/" rel="alternate" type="text/html"/>
    <title>APPROX/RANDOM 2020 is Virtual From the Get Go</title>
    <summary>While APPROX/RANDOM 2020 was scheduled for September, we decided to reduce uncertainty in these stormy days and declare it to be virtual already in the CFP. We hope to have APPROX/RANDOM 2021 hosted in Seattle by UW, instead of this year,  So if you never sent papers to APPROX/RANDOM because you hate travel, this is your year to start!</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>While <a href="https://randomconference.com/random-2020-home/">APPROX/RANDOM 2020</a> was scheduled for September, we decided to reduce uncertainty in these stormy days and declare it to be virtual already in the <a href="https://randomconference.files.wordpress.com/2020/04/randomapprox2020cfp-3.pdf">CFP</a>. We hope to have APPROX/RANDOM 2021 hosted in Seattle by UW, instead of this year,  So if you never sent papers to APPROX/RANDOM because you hate travel, this is your year to start!</p></div>
    </content>
    <updated>2020-04-01T22:37:07Z</updated>
    <published>2020-04-01T22:37:07Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Omer Reingold</name>
    </author>
    <source>
      <id>https://theorydish.blog</id>
      <logo>https://theorydish.files.wordpress.com/2017/03/cropped-nightdish1.jpg?w=32</logo>
      <link href="https://theorydish.blog/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://theorydish.blog" rel="alternate" type="text/html"/>
      <link href="https://theorydish.blog/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://theorydish.blog/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Stanford's CS Theory Research Blog</subtitle>
      <title>Theory Dish</title>
      <updated>2020-08-26T22:24:10Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://theorydish.blog/?p=1640</id>
    <link href="https://theorydish.blog/2020/03/30/forc-2020-going-strong-going-virtual/" rel="alternate" type="text/html"/>
    <title>FORC 2020: Going Strong, Going Virtual</title>
    <summary>FORC 2020 accepted papers are out. Despite the last minute announcement and minimal advertising of this new conference, we have an exciting and strong program. This confirms our conviction that the new conference fills an important need for a home to the TOC sub-community that works on the societal aspects of computation. Unfortunately, but non-surprisingly, the conference will be virtual this year. But I’m sure that, thanks to Aaron Roth and to the inaugural PC, we will make the best what’s possible and have a great event.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>FORC 2020 <a href="https://responsiblecomputing.org/accepted-papers/?fbclid=IwAR0NTKaoKheiOmzYYyBqbDVtnkrPL8ooELD2RvfRFe7BHMF5tbgFg_bV840">accepted papers are out</a>. Despite the <a href="https://theorydish.blog/2019/10/30/toc-for-society/">last minute announcement</a> and minimal advertising of this new conference, we have an exciting and strong program. This confirms our conviction that the new conference fills an important need for a home to the TOC sub-community that works on the societal aspects of computation.</p>
<p>Unfortunately, but non-surprisingly, the conference will be virtual this year. But I’m sure that, thanks to <a href="https://www.cis.upenn.edu/~aaroth/">Aaron Roth</a> and to the inaugural PC, we will make the best what’s possible and have a great event.</p></div>
    </content>
    <updated>2020-03-30T20:35:21Z</updated>
    <published>2020-03-30T20:35:21Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Omer Reingold</name>
    </author>
    <source>
      <id>https://theorydish.blog</id>
      <logo>https://theorydish.files.wordpress.com/2017/03/cropped-nightdish1.jpg?w=32</logo>
      <link href="https://theorydish.blog/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://theorydish.blog" rel="alternate" type="text/html"/>
      <link href="https://theorydish.blog/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://theorydish.blog/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Stanford's CS Theory Research Blog</subtitle>
      <title>Theory Dish</title>
      <updated>2020-08-26T22:24:09Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://tcsplus.wordpress.com/?p=410</id>
    <link href="https://tcsplus.wordpress.com/2020/03/28/tcs-talk-wednesday-april-1-venkat-guruswami-cmu/" rel="alternate" type="text/html"/>
    <title>TCS+ talk: Wednesday, April 1 — Venkat Guruswami, CMU</title>
    <summary>The next TCS+ talk will take place this coming Wednesday, April 1th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). Venkat Guruswami from CMU will speak about “Arıkan meets Shannon: Polar codes with near-optimal convergence to channel capacity” (abstract below). You can reserve a spot as an individual […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The next TCS+ talk will take place this coming Wednesday, April 1th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). <strong>Venkat Guruswami</strong> from CMU will speak about “<em>Arıkan meets Shannon: Polar codes with near-optimal convergence to channel capacity</em>” (abstract below).</p>
<p>You can reserve a spot as an individual or a group to join us live by signing up on <a href="https://sites.google.com/site/plustcs/livetalk/live-seat-reservation">the online form</a>. (The link will also be posted <a href="https://sites.google.com/site/plustcs/livetalk">on our website</a> on the day of the talk, so people who did not sign up will still be able to join, until the maximum capacity of 300 seats is reached.) As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/site/plustcs/suggest">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/site/plustcs/">the website</a>.</p>
<blockquote><p>Abstract: We establish a constructive version of Shannon’s noisy coding theorem for binary codes, with information rate converging near-optimally fast to channel capacity as a function of code length. Specifically, let <img alt="W" class="latex" src="https://s0.wp.com/latex.php?latex=W&amp;bg=fff&amp;fg=444444&amp;s=0" title="W"/> be an arbitrary binary-input memoryless symmetric channel with Shannon capacity <img alt="I(W)" class="latex" src="https://s0.wp.com/latex.php?latex=I%28W%29&amp;bg=fff&amp;fg=444444&amp;s=0" title="I(W)"/>, and fix any <img alt="\delta &gt;0" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdelta+%3E0&amp;bg=fff&amp;fg=444444&amp;s=0" title="\delta &gt;0"/>. We construct, for any sufficiently small <img alt="\varepsilon &gt;0" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cvarepsilon+%3E0&amp;bg=fff&amp;fg=444444&amp;s=0" title="\varepsilon &gt;0"/>, binary linear codes of block length <img alt="O(1/\varepsilon^{2+\delta})" class="latex" src="https://s0.wp.com/latex.php?latex=O%281%2F%5Cvarepsilon%5E%7B2%2B%5Cdelta%7D%29&amp;bg=fff&amp;fg=444444&amp;s=0" title="O(1/\varepsilon^{2+\delta})"/> and rate <img alt="I(W)-\varepsilon" class="latex" src="https://s0.wp.com/latex.php?latex=I%28W%29-%5Cvarepsilon&amp;bg=fff&amp;fg=444444&amp;s=0" title="I(W)-\varepsilon"/> that enable reliable communication on <img alt="W" class="latex" src="https://s0.wp.com/latex.php?latex=W&amp;bg=fff&amp;fg=444444&amp;s=0" title="W"/> with quasi-linear time encoding and decoding. Shannon’s theorem implies the existence of such codes (without efficient constructions or decoding) with block length <img alt="O(1/\varepsilon^2)" class="latex" src="https://s0.wp.com/latex.php?latex=O%281%2F%5Cvarepsilon%5E2%29&amp;bg=fff&amp;fg=444444&amp;s=0" title="O(1/\varepsilon^2)"/>. This quadratic dependence on the gap epsilon to capacity is known to be best possible. Previously such a construction was only known for the case of the erasure channel.</p>
<p>Our codes are a variant of Arıkan’s polar codes based on multiple carefully constructed local kernels, one for each intermediate channel that arises in the decoding. A key technical ingredient in the analysis is a strong converse to the noisy coding theorem that shows extreme unpredictability of even a single message bit when communicating via random linear codes at rates slightly above capacity.</p>
<p>Joint work with Andrii Riazanov and Min Ye.</p></blockquote>
<p> </p></div>
    </content>
    <updated>2020-03-28T16:46:12Z</updated>
    <published>2020-03-28T16:46:12Z</published>
    <category term="Announcements"/>
    <author>
      <name>plustcs</name>
    </author>
    <source>
      <id>https://tcsplus.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://tcsplus.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://tcsplus.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://tcsplus.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://tcsplus.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A carbon-free dissemination of ideas across the globe.</subtitle>
      <title>TCS+</title>
      <updated>2020-08-26T22:24:02Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://dstheory.wordpress.com/?p=39</id>
    <link href="https://dstheory.wordpress.com/2020/03/19/friday-march-27-sujay-sanghavi-from-ut-austin/" rel="alternate" type="text/html"/>
    <title>Friday, March 27 — Sujay Sanghavi from UT Austin</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">The second Foundations of Data Science virtual talk will take place next Friday, March 27th at 11:00 AM Pacific Time (2:00 pm Eastern Time, 20:00 Central European Time, 19:00 UTC).  Sujay Sanghavi from University of Texas at Austin will speak about “Towards Model Agnostic Robustness”. Abstract: It is now common practice to try and solve machine<a class="more-link" href="https://dstheory.wordpress.com/2020/03/19/friday-march-27-sujay-sanghavi-from-ut-austin/">Continue reading <span class="screen-reader-text">"Friday, March 27 — Sujay Sanghavi from UT Austin"</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The second Foundations of Data Science virtual talk will take place next Friday, March 27th at 11:00 AM Pacific Time (2:00 pm Eastern Time, 20:00 Central European Time, 19:00 UTC).  <strong>Sujay Sanghavi</strong> from University of Texas at Austin will speak about “<em>Towards Model Agnostic Robustness</em>”.</p>



<p><strong>Abstract</strong>: It is now common practice to try and solve machine learning problems by starting with a complex existing model or architecture, and fine-tuning/adapting it to the task at hand. However, outliers, errors or even just sloppiness in training data often lead to drastic drops in performance. </p>



<p>We investigate a simple generic approach to correct for this, motivated by a classic statistical idea: trimmed loss. This advocates jointly (a) selecting which training samples to ignore, and (b) fitting a model on the remaining samples. As such this is computationally infeasible even for linear regression. We propose and study the natural iterative variant that alternates between these two steps (a) and (b) – each of which individually can be easily accomplished in pretty much any statistical setting. We also study the batch-SGD variant of this idea. We demonstrate both theoretically (for generalized linear models) and empirically (for vision and NLP neural network models) that this effectively recovers accuracy in the presence of bad training data.</p>



<p>This work is joint with Yanyao Shen and Vatsal Shah and appears in NeurIPS 2019, ICML 2019 and AISTATS 2020.</p>



<p><a href="https://sites.google.com/view/dstheory">Link to join the virtual talk.</a></p>



<p>The series is supported by the <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1934846&amp;HistoricalAwards=false">NSF HDR TRIPODS Grant 1934846</a>. </p></div>
    </content>
    <updated>2020-03-19T02:29:19Z</updated>
    <published>2020-03-19T02:29:19Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>dstheory</name>
    </author>
    <source>
      <id>https://dstheory.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://dstheory.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://dstheory.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://dstheory.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://dstheory.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Foundation of Data Science – Virtual Talk Series</title>
      <updated>2020-08-26T22:24:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://theorydish.blog/?p=1570</id>
    <link href="https://theorydish.blog/2020/03/18/private-and-secure-distributed-matrix-multiplication/" rel="alternate" type="text/html"/>
    <title>Private and Secure Distributed Matrix Multiplication</title>
    <summary>Machine learning on big data sets takes a significant amount of computational power, so it is often necessary to offload some of the work to external distributed systems, such as an Amazon EC2 cluster. It is useful to be able to utilize external resources for computation tasks while keeping the actual data private and secure. In particular, matrix multiplication is an essential step in many machine learning processes, but the owner of the matrices may have reasons to keep the actual values protected. In this post, we’ll discuss four works about secure distributed computation. First, we’ll talk about a method of using MDS (maximum distance separable) error correcting codes to add security and privacy to general data storage (“Cross Subspace Alignment and the Asymptotic Capacity of X-Secure T-Private Information Retrieval” by Jia, Sun, Jafar). Then we’ll discuss method of adapting a coding strategy for straggler mitigation (“Polynomial codes: an optimal design for high-dimensional coded matrix multiplication” by Yu, Qian, Maddah-Ali, Avestimehr) in matrix multiplication to instead add security or privacy (“On the capacity of secure distributed matrix multiplication” by Chang, Tandon and “Private Coded Matrix Multiplication” by Kim, Yang, Lee) Throughout this post we will use variations on the following communication model: The [...]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Machine learning on big data sets takes a significant amount of computational power, so it  is often necessary to offload some of the work to external distributed systems, such as an Amazon EC2 cluster. It is useful to be able to utilize external resources for computation tasks while keeping the actual data <em>private</em> and<em> secure</em>. In particular, matrix multiplication is an essential step in many machine learning processes, but the owner of the matrices may have reasons to keep the actual values protected.</p>



<p>In this post, we’ll discuss four works about secure distributed computation. First, we’ll talk about a method of using MDS (maximum distance separable) error correcting codes to add security and privacy to general data storage (“<a href="https://arxiv.org/pdf/1808.07457.pdf">Cross Subspace Alignment and the Asymptotic Capacity of X-Secure T-Private Information Retrieval”</a> by Jia, Sun, Jafar). </p>



<p>Then we’ll discuss method of adapting a coding strategy for straggler mitigation (<a href="http://papers.nips.cc/paper/7027-polynomial-codes-an-optimal-design-for-high-dimensional-coded-matrix-multiplication.pdf">“Polynomial codes: an optimal design for high-dimensional coded matrix multiplication”</a> by Yu, Qian, Maddah-Ali, Avestimehr) in matrix multiplication to instead add security or privacy (<a href="https://uweb.engr.arizona.edu/~wchang/Globecom-SecureMM-2018.pdf">“On the capacity of secure distributed matrix multiplication”</a> by Chang, Tandon and <a href="https://ieeexplore-ieee-org.stanford.idm.oclc.org/abstract/document/8832193">“Private Coded Matrix Multiplication”</a> by Kim, Yang, Lee)</p>



<p>Throughout this post we will use variations on the following communication model:</p>



<figure class="wp-block-image size-large is-resized"><img alt="" class="wp-image-1572" height="192" src="https://theorydish.files.wordpress.com/2020/03/blog_fig1.png?w=1024" width="404"/></figure>



<p>The data in the grey box is only given to the master, so workers only have access to what they receive (via green arrows). Later on we will also suppose the workers have a shared library not available to the master. The workers do not communicate with each other as part of the computation, but we want to prevent them from figuring out anything about the data if they do talk to each other.</p>



<p> This model is related to <em>private computation</em> but not exactly the same. We assume the servers are “honest but curious”, meaning they won’t introduce malicious computations. We also only require the master to receive the final result, and don’t need to protect any data from the master. This is close to the BGW scheme ([Ben-Or, Goldwasser, Wigderson ’88]), but we do not allow workers to communicate with each other as part of the computation of the result.</p>



<p> We consider <em>unconditional</em> or <em>information-theoretic</em> security, meaning the data is protected even if the workers have unbounded computational power. Furthermore, we will consider having <em>perfect  secrecy</em>, in which the mutual information between the information revealed to the workers and the actual messages is zero.</p>



<h2>X-Secure T-Private Information Retrieval</h2>



<p> Before we get into matrix-matrix multiplication, consider the problem of storing information on the workers to be retrieved by the master, such that it is “protected.” What do we mean by that? [Jia, Sun, and Jafar ’19] define X-secure T-private information retrieval as follows: </p>



<blockquote class="wp-block-quote"><p>Let <img alt="W_1,...,W_{K}" class="latex" src="https://s0.wp.com/latex.php?latex=W_1%2C...%2CW_%7BK%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="W_1,...,W_{K}"/> be a data set of messages, such that each <img alt="W_i" class="latex" src="https://s0.wp.com/latex.php?latex=W_i&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="W_i"/> consists of <img alt="L" class="latex" src="https://s0.wp.com/latex.php?latex=L&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="L"/> random bits. A storage scheme of <img alt="W_{1},...,W_{K}" class="latex" src="https://s0.wp.com/latex.php?latex=W_%7B1%7D%2C...%2CW_%7BK%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="W_{1},...,W_{K}"/> on <img alt="N" class="latex" src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="N"/> nodes is </p><p>1. <em>X-secure</em> if any set of up to <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="X"/> servers cannot determine anything about any <img alt="W_i" class="latex" src="https://s0.wp.com/latex.php?latex=W_i&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="W_i"/> and</p><p>2. <em>T-private </em> if given a query from the user to retrieve some data element <img alt="W_{\theta}" class="latex" src="https://s0.wp.com/latex.php?latex=W_%7B%5Ctheta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="W_{\theta}"/>, any set of up to <img alt="T" class="latex" src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="T"/> users cannot determine the value of <img alt="\theta" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctheta&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\theta"/>.</p><cite>[Jia, Sun, and Jafar ’19]</cite></blockquote>



<p>Letting <img alt="Q_{1}^{[\theta]},...,Q_{N}^{[\theta]}" class="latex" src="https://s0.wp.com/latex.php?latex=Q_%7B1%7D%5E%7B%5B%5Ctheta%5D%7D%2C...%2CQ_%7BN%7D%5E%7B%5B%5Ctheta%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="Q_{1}^{[\theta]},...,Q_{N}^{[\theta]}"/> be the set of queries sent to each node and <img alt="S_1,...,S_N" class="latex" src="https://s0.wp.com/latex.php?latex=S_1%2C...%2CS_N&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="S_1,...,S_N"/> be the information stored on each node  (all vectors of length L), we depict this as:</p>



<figure class="wp-block-image size-large is-resized"><img alt="" class="wp-image-1581" height="223" src="https://theorydish.files.wordpress.com/2020/03/blog_fig2.png?w=1024" width="452"/></figure>



<p>The information theoretic requirements of this system to be correct can be summarized as follows (using notation <img alt="S_{[1:N]}" class="latex" src="https://s0.wp.com/latex.php?latex=S_%7B%5B1%3AN%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="S_{[1:N]}"/> for set <img alt="S_1,...,S_N" class="latex" src="https://s0.wp.com/latex.php?latex=S_1%2C...%2CS_N&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="S_1,...,S_N"/>):</p>



<figure class="wp-block-table"><table><tbody><tr><td><strong>Property</strong></td><td><strong>Information Theoretic Requirement</strong></td></tr><tr><td>Data messages are size <img alt="L" class="latex" src="https://s0.wp.com/latex.php?latex=L&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="L"/> bits</td><td><img alt="H(W_1)=H(W_2)=....=H(W_K) = L" class="latex" src="https://s0.wp.com/latex.php?latex=H%28W_1%29%3DH%28W_2%29%3D....%3DH%28W_K%29+%3D+L&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="H(W_1)=H(W_2)=....=H(W_K) = L"/></td></tr><tr><td>Data messages are independent</td><td><img alt="H(W_1,...,W_K) = KL" class="latex" src="https://s0.wp.com/latex.php?latex=H%28W_1%2C...%2CW_K%29+%3D+KL&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="H(W_1,...,W_K) = KL"/></td></tr><tr><td>Data can be determined from the stored information</td><td><img alt="H(W_1,....,W_K)|S_{[1:N]}) = 0" class="latex" src="https://s0.wp.com/latex.php?latex=H%28W_1%2C....%2CW_K%29%7CS_%7B%5B1%3AN%5D%7D%29+%3D+0&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="H(W_1,....,W_K)|S_{[1:N]}) = 0"/></td></tr><tr><td>User has no prior knowledge of server data</td><td><img alt="I(S_{[1:N]};Q^{[\theta]}_{[1:N]},\theta) = 0" class="latex" src="https://s0.wp.com/latex.php?latex=I%28S_%7B%5B1%3AN%5D%7D%3BQ%5E%7B%5B%5Ctheta%5D%7D_%7B%5B1%3AN%5D%7D%2C%5Ctheta%29+%3D+0&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="I(S_{[1:N]};Q^{[\theta]}_{[1:N]},\theta) = 0"/></td></tr><tr><td>X-Security</td><td><img alt="I(S_{\mathcal{X}};W_1,...,W_K) = 0" class="latex" src="https://s0.wp.com/latex.php?latex=I%28S_%7B%5Cmathcal%7BX%7D%7D%3BW_1%2C...%2CW_K%29+%3D+0&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="I(S_{\mathcal{X}};W_1,...,W_K) = 0"/>, <img alt="\forall \mathcal{X}\subset [1:N],|\mathcal{X}|=X" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cforall+%5Cmathcal%7BX%7D%5Csubset+%5B1%3AN%5D%2C%7C%5Cmathcal%7BX%7D%7C%3DX&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\forall \mathcal{X}\subset [1:N],|\mathcal{X}|=X"/></td></tr><tr><td> T-Privacy</td><td><img alt="I(Q_{\mathcal{T}}^{[\theta]},S_{\mathcal{T}}; \theta) = 0," class="latex" src="https://s0.wp.com/latex.php?latex=I%28Q_%7B%5Cmathcal%7BT%7D%7D%5E%7B%5B%5Ctheta%5D%7D%2CS_%7B%5Cmathcal%7BT%7D%7D%3B+%5Ctheta%29+%3D+0%2C&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="I(Q_{\mathcal{T}}^{[\theta]},S_{\mathcal{T}}; \theta) = 0,"/>  <img alt="\forall \mathcal{T} \subset [1:N], |\mathcal{T}|=T" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cforall+%5Cmathcal%7BT%7D+%5Csubset+%5B1%3AN%5D%2C+%7C%5Cmathcal%7BT%7D%7C%3DT&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\forall \mathcal{T} \subset [1:N], |\mathcal{T}|=T"/></td></tr><tr><td>Nodes answer only based on their data and received query </td><td><img alt="H(A_n^{[\theta]}| Q_n^{[\theta]},S_n) =0" class="latex" src="https://s0.wp.com/latex.php?latex=H%28A_n%5E%7B%5B%5Ctheta%5D%7D%7C+Q_n%5E%7B%5B%5Ctheta%5D%7D%2CS_n%29+%3D0&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="H(A_n^{[\theta]}| Q_n^{[\theta]},S_n) =0"/></td></tr><tr><td>User can decode desired message from answers</td><td><img alt="H(W_{\theta} | A_{[1:N]}^{[\theta]},Q_{[1:N]}^{[\theta]} ,\theta) = 0" class="latex" src="https://s0.wp.com/latex.php?latex=H%28W_%7B%5Ctheta%7D+%7C+A_%7B%5B1%3AN%5D%7D%5E%7B%5B%5Ctheta%5D%7D%2CQ_%7B%5B1%3AN%5D%7D%5E%7B%5B%5Ctheta%5D%7D+%2C%5Ctheta%29+%3D+0&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="H(W_{\theta} | A_{[1:N]}^{[\theta]},Q_{[1:N]}^{[\theta]} ,\theta) = 0"/></td></tr></tbody></table></figure>



<p>Given these constraints, Jia et al. give bounds on the capacity of the system. Capacity is the maximum rate achievable, where rate is defined as bits requested by the worker (<img alt="L" class="latex" src="https://s0.wp.com/latex.php?latex=L&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="L"/>, the length of a single message) divided by the number of bits downloaded by the worker. The bounds are in terms of the capacity of T-Private Information Retrieval, (which is the same as the above definition, with only requirement 2).</p>



<blockquote class="wp-block-quote"><p>If <img alt="N \leq X+T" class="latex" src="https://s0.wp.com/latex.php?latex=N+%5Cleq+X%2BT&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="N \leq X+T"/> then for arbitrary <img alt="K" class="latex" src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="K"/>, <img alt="C_{XSTPIR}(N,K,X,T) = \frac{N-X}{N}C_{TPIR}(N-X,K,T) = \frac{N-X}{NK}" class="latex" src="https://s0.wp.com/latex.php?latex=C_%7BXSTPIR%7D%28N%2CK%2CX%2CT%29+%3D+%5Cfrac%7BN-X%7D%7BN%7DC_%7BTPIR%7D%28N-X%2CK%2CT%29+%3D+%5Cfrac%7BN-X%7D%7BNK%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="C_{XSTPIR}(N,K,X,T) = \frac{N-X}{N}C_{TPIR}(N-X,K,T) = \frac{N-X}{NK}"/>.</p><p><img alt="\displaystyle C_{XSTPIR}(N,K,X,T) \leq \left(\frac{N-X}{N}\right) C_{TPIR}(N-X,K,T)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+C_%7BXSTPIR%7D%28N%2CK%2CX%2CT%29+%5Cleq+%5Cleft%28%5Cfrac%7BN-X%7D%7BN%7D%5Cright%29+C_%7BTPIR%7D%28N-X%2CK%2CT%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle C_{XSTPIR}(N,K,X,T) \leq \left(\frac{N-X}{N}\right) C_{TPIR}(N-X,K,T)"/></p><p> When <img alt="N\leq X+T" class="latex" src="https://s0.wp.com/latex.php?latex=N%5Cleq+X%2BT&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="N\leq X+T"/>: <img alt="\displaystyle C_{XSTPIR}(N,K,X,T) = \left(\frac{N-X}{N}\right) C_{TPIR}(N-X,K,T) = \frac{N-X}{NK}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+C_%7BXSTPIR%7D%28N%2CK%2CX%2CT%29+%3D+%5Cleft%28%5Cfrac%7BN-X%7D%7BN%7D%5Cright%29+C_%7BTPIR%7D%28N-X%2CK%2CT%29+%3D+%5Cfrac%7BN-X%7D%7BNK%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle C_{XSTPIR}(N,K,X,T) = \left(\frac{N-X}{N}\right) C_{TPIR}(N-X,K,T) = \frac{N-X}{NK}"/> </p><p> <img alt="\displaystyle\lim_{K\to \infty} C_{XSTPIR}(N,K,X,T) = \lim_{K\to \infty} \left(\frac{N-K}{N}\right) C_{TPIR}(N-X,K,T) =\begin{cases}&#xA0; &#xA0;1-(\frac{X+T}{N}) &amp; N&gt;X+T  \\&#xA0;  0 &amp; N\leq X+T \end{cases}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%5Clim_%7BK%5Cto+%5Cinfty%7D+C_%7BXSTPIR%7D%28N%2CK%2CX%2CT%29+%3D+%5Clim_%7BK%5Cto+%5Cinfty%7D+%5Cleft%28%5Cfrac%7BN-K%7D%7BN%7D%5Cright%29+C_%7BTPIR%7D%28N-X%2CK%2CT%29+%3D%5Cbegin%7Bcases%7D%C2%A0+%C2%A01-%28%5Cfrac%7BX%2BT%7D%7BN%7D%29+%26+N%3EX%2BT++%5C%5C%C2%A0++0+%26+N%5Cleq+X%2BT+%5Cend%7Bcases%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle\lim_{K\to \infty} C_{XSTPIR}(N,K,X,T) = \lim_{K\to \infty} \left(\frac{N-K}{N}\right) C_{TPIR}(N-X,K,T) =\begin{cases}&#xA0; &#xA0;1-(\frac{X+T}{N}) &amp; N&gt;X+T  \\&#xA0;  0 &amp; N\leq X+T \end{cases}"/></p><cite>[Jia, Sun, and Jafar ’19]</cite></blockquote>



<p>Jia et al. give schemes that achieve these bounds while preserving the privacy and security constraints by introducing random noise vectors into how data is stored and queries are constructed. The general scheme for <img alt="N&gt;X+T" class="latex" src="https://s0.wp.com/latex.php?latex=N%3EX%2BT&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="N&gt;X+T"/> uses <em>cross subspace alignment</em>, which essentially chooses how to construct the stored information and the queries such that the added noise mostly “cancels out” when the master combines all the response from the servers. The scheme for <img alt="N\leq X+T" class="latex" src="https://s0.wp.com/latex.php?latex=N%5Cleq+X%2BT&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="N\leq X+T"/> is straightforward to explain, and demonstrates the idea of using error correcting codes that treat the random values as the message and the actual data as the “noise.”</p>



<p>For this scheme, the message length <img alt="L" class="latex" src="https://s0.wp.com/latex.php?latex=L&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="L"/> is set to <img alt="N-X" class="latex" src="https://s0.wp.com/latex.php?latex=N-X&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="N-X"/> (the number of nodes <img alt="N" class="latex" src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="N"/>, minus the maximum number of colluding servers <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="X"/>). First, we generate <img alt="K" class="latex" src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="K"/> random bit vectors of length <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="X"/>:</p>



<figure class="wp-block-image size-large is-resized"><img alt="" class="wp-image-1590" height="157" src="https://theorydish.files.wordpress.com/2020/03/blog_fig3.png?w=856" width="370"/></figure>



<p>Next, apply an <img alt="(N,X)" class="latex" src="https://s0.wp.com/latex.php?latex=%28N%2CX%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="(N,X)"/> MDS code to <img alt="Z_1,...,Z_K" class="latex" src="https://s0.wp.com/latex.php?latex=Z_1%2C...%2CZ_K&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="Z_1,...,Z_K"/> to get <img alt="\bar{Z}_1,..,\bar{Z}_K" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbar%7BZ%7D_1%2C..%2C%5Cbar%7BZ%7D_K&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\bar{Z}_1,..,\bar{Z}_K"/>, which are <img alt="K" class="latex" src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="K"/> encoded vectors of length <img alt="N" class="latex" src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="N"/>:</p>



<figure class="wp-block-image size-large"><img alt="" class="wp-image-1591" src="https://theorydish.files.wordpress.com/2020/03/blog_fig4.png?w=1024"/></figure>



<p>For our data <img alt="W_1,...,W_K" class="latex" src="https://s0.wp.com/latex.php?latex=W_1%2C...%2CW_K&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="W_1,...,W_K"/>, we pad each vector with zeros to get <img alt="\bar{W}_1,..,\bar{W}_K" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbar%7BW%7D_1%2C..%2C%5Cbar%7BW%7D_K&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\bar{W}_1,..,\bar{W}_K"/> of length <img alt="N" class="latex" src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="N"/>:</p>



<figure class="wp-block-image size-large"><img alt="" class="wp-image-1592" src="https://theorydish.files.wordpress.com/2020/03/blog_fig5.png?w=1024"/></figure>



<p>Now that the dimensions line up, we can add the two together and store each column <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="n"/> at the <img alt="n^{th}" class="latex" src="https://s0.wp.com/latex.php?latex=n%5E%7Bth%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="n^{th}"/> node:</p>



<figure class="wp-block-image size-large"><img alt="" class="wp-image-1593" src="https://theorydish.files.wordpress.com/2020/03/blog_fig6.png?w=1024"/></figure>



<p>To access the data, the user downloads all <img alt="NK" class="latex" src="https://s0.wp.com/latex.php?latex=NK&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="NK"/> bits. The length <img alt="N" class="latex" src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="N"/> string downloaded from  row <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="i"/> can be used to decode <img alt="\bar{Z}_i" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbar%7BZ%7D_i&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\bar{Z}_i"/>: <img alt="\bar{W}_{L+1},\bar{W}_{L+2},...,\bar{W}_{N}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbar%7BW%7D_%7BL%2B1%7D%2C%5Cbar%7BW%7D_%7BL%2B2%7D%2C...%2C%5Cbar%7BW%7D_%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\bar{W}_{L+1},\bar{W}_{L+2},...,\bar{W}_{N}"/> are all zero, so columns <img alt="L+1 = N-X+1" class="latex" src="https://s0.wp.com/latex.php?latex=L%2B1+%3D+N-X%2B1&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="L+1 = N-X+1"/> through <img alt="N" class="latex" src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="N"/> have the values of <img alt="\bar{Z}_{i,N-X+1},...,\bar{Z}_{i,N}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbar%7BZ%7D_%7Bi%2CN-X%2B1%7D%2C...%2C%5Cbar%7BZ%7D_%7Bi%2CN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\bar{Z}_{i,N-X+1},...,\bar{Z}_{i,N}"/>. This gives the user <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="X"/> values from the MDS code used on each row, so they can decode and get <img alt="Z_1,...,Z_K" class="latex" src="https://s0.wp.com/latex.php?latex=Z_1%2C...%2CZ_K&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="Z_1,...,Z_K"/> and <img alt="\bar{Z}_{1},...,\bar{Z}_K" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbar%7BZ%7D_%7B1%7D%2C...%2C%5Cbar%7BZ%7D_K&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\bar{Z}_{1},...,\bar{Z}_K"/>. Then a subtraction from the downloaded data gives <img alt="W_1,...,W_{K}" class="latex" src="https://s0.wp.com/latex.php?latex=W_1%2C...%2CW_%7BK%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="W_1,...,W_{K}"/>. Because of the MDS property of the code used to get <img alt="\bar{Z}_1,...,\bar{Z}_K" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbar%7BZ%7D_1%2C...%2C%5Cbar%7BZ%7D_K&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\bar{Z}_1,...,\bar{Z}_K"/>, this scheme is X-secure and because the user downloads all bits, it is T-private.</p>



<h2>Matrix Multiplication with Polynomial Codes</h2>



<p>We now move on to the task of matrix-matrix multiplication. The methods for secure and private distributed matrix multiplication we will discuss shortly are based on <em>polynomial codes</em>, used by [Yu, Maddah-Ali, Avestimehr ’17] for doing distributed matrix multiplications robust to stragglers. Suppose the master has matrices <img alt="{\bf{A}} \in \mathbb{F}_q^{m\times n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbf%7BA%7D%7D+%5Cin+%5Cmathbb%7BF%7D_q%5E%7Bm%5Ctimes+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bf{A}} \in \mathbb{F}_q^{m\times n}"/> and <img alt="{\bf{B}} \in \mathbb{F}_q^{n \times p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbf%7BB%7D%7D+%5Cin+%5Cmathbb%7BF%7D_q%5E%7Bn+%5Ctimes+p%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bf{B}} \in \mathbb{F}_q^{n \times p}"/> for some finite field <img alt="\mathbb{F}_q" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BF%7D_q&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\mathbb{F}_q"/>, and <img alt="m,n,p \in \mathbb{Z}^+" class="latex" src="https://s0.wp.com/latex.php?latex=m%2Cn%2Cp+%5Cin+%5Cmathbb%7BZ%7D%5E%2B&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="m,n,p \in \mathbb{Z}^+"/>. Assume <img alt="m" class="latex" src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="m"/> and <img alt="p" class="latex" src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="p"/> are divisible by <img alt="N" class="latex" src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="N"/>, so we can represent the matrices divided into <img alt="N" class="latex" src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="N"/> submatrices: </p>



<p class="has-text-align-center"><img alt="{\bf{A}}= \begin{bmatrix}A_1\\ A_2 \\ \vdots \\ A_m\end{bmatrix}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbf%7BA%7D%7D%3D+%5Cbegin%7Bbmatrix%7DA_1%5C%5C+A_2+%5C%5C+%5Cvdots+%5C%5C+A_m%5Cend%7Bbmatrix%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bf{A}}= \begin{bmatrix}A_1\\ A_2 \\ \vdots \\ A_m\end{bmatrix}"/>               and        <img alt="{\bf{B}}= \begin{bmatrix}B_1&amp; B_2 &amp; \dots &amp;B_n\end{bmatrix}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbf%7BB%7D%7D%3D+%5Cbegin%7Bbmatrix%7DB_1%26+B_2+%26+%5Cdots+%26B_n%5Cend%7Bbmatrix%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bf{B}}= \begin{bmatrix}B_1&amp; B_2 &amp; \dots &amp;B_n\end{bmatrix}"/> </p>



<p>So to recover <img alt="\bf{AB}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbf%7BAB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\bf{AB}"/>, the master needs each entry of: </p>



<p><img alt="{\bf{AB}} = \begin{bmatrix}A_1B_1 &amp; A_1B_2 &amp; \dots &amp; A_1B_n\\A_2B_1 &amp; A_2B_2 &amp; \dots &amp; A_2 B_n\\\vdots &amp; \vdots &amp;\vdots &amp;\vdots\\A_mB_1 &amp;A_mB_2 &amp; \dots&#xA0; &amp; A_mB_n \end{bmatrix}." class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbf%7BAB%7D%7D+%3D+%5Cbegin%7Bbmatrix%7DA_1B_1+%26+A_1B_2+%26+%5Cdots+%26+A_1B_n%5C%5CA_2B_1+%26+A_2B_2+%26+%5Cdots+%26+A_2+B_n%5C%5C%5Cvdots+%26+%5Cvdots+%26%5Cvdots+%26%5Cvdots%5C%5CA_mB_1+%26A_mB_2+%26+%5Cdots%C2%A0+%26+A_mB_n+%5Cend%7Bbmatrix%7D.&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bf{AB}} = \begin{bmatrix}A_1B_1 &amp; A_1B_2 &amp; \dots &amp; A_1B_n\\A_2B_1 &amp; A_2B_2 &amp; \dots &amp; A_2 B_n\\\vdots &amp; \vdots &amp;\vdots &amp;\vdots\\A_mB_1 &amp;A_mB_2 &amp; \dots&#xA0; &amp; A_mB_n \end{bmatrix}."/></p>



<p>The key idea of polynomial codes is to encode <img alt="A_1,...,A_m" class="latex" src="https://s0.wp.com/latex.php?latex=A_1%2C...%2CA_m&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="A_1,...,A_m"/> and <img alt="B_1,...,B_n" class="latex" src="https://s0.wp.com/latex.php?latex=B_1%2C...%2CB_n&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="B_1,...,B_n"/> in polynomials <img alt="\tilde{A}_i" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctilde%7BA%7D_i&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\tilde{A}_i"/> and <img alt="\tilde{B}_i" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctilde%7BB%7D_i&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\tilde{B}_i"/> to be sent to the <img alt="i^{th}" class="latex" src="https://s0.wp.com/latex.php?latex=i%5E%7Bth%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="i^{th}"/> worker,  where they are multiplied and the result is returned. The goal of Yu et al. was to create robustness to stragglers, and so they add redundancy in this process so that not all workers need to return a result for the master to be able to determine <img alt="\bf{AB}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbf%7BAB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\bf{AB}"/>. In particular, only <img alt="mn" class="latex" src="https://s0.wp.com/latex.php?latex=mn&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="mn"/> returned values are needed, so <img alt="N-mn" class="latex" src="https://s0.wp.com/latex.php?latex=N-mn&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="N-mn"/> servers can be slow or fail completely without hurting the computation. This method can be thought of as setting up the encodings of <img alt="\bf{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbf%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\bf{A}"/> and <img alt="\bf{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbf%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\bf{B}"/> so that the resulting multiplications <img alt="\tilde{C}_1=\tilde{A}_1\tilde{B}_1,...,\tilde{C}_N=\tilde{A}_N\tilde{B}_N" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctilde%7BC%7D_1%3D%5Ctilde%7BA%7D_1%5Ctilde%7BB%7D_1%2C...%2C%5Ctilde%7BC%7D_N%3D%5Ctilde%7BA%7D_N%5Ctilde%7BB%7D_N&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\tilde{C}_1=\tilde{A}_1\tilde{B}_1,...,\tilde{C}_N=\tilde{A}_N\tilde{B}_N"/> are evaluations of a polynomial with coefficients  <img alt="A_1B_1,A_1B_2,...,A_2B_1....,A_mB_n" class="latex" src="https://s0.wp.com/latex.php?latex=A_1B_1%2CA_1B_2%2C...%2CA_2B_1....%2CA_mB_n&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="A_1B_1,A_1B_2,...,A_2B_1....,A_mB_n"/> at <img alt="N" class="latex" src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="N"/> different points — equivalent to a Reed-Solomon code. </p>



<figure class="wp-block-image size-large"><img alt="" class="wp-image-1603" src="https://theorydish.files.wordpress.com/2020/03/blog_fig7.png?w=1024"/></figure>



<p>This idea is adapted by [Chang, Tandon ’18] to protect the data from colluding servers: noise is incorporated into the encodings such that the number of encoded matrices required to determine anything about the data is greater than the security threshold <img alt="X &lt; N" class="latex" src="https://s0.wp.com/latex.php?latex=X+%3C+N&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="X &lt; N"/>. Since the master receives all <img alt="N" class="latex" src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="N"/> responses it is able to decode the result of <img alt="\textbf{AB}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctextbf%7BAB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\textbf{AB}"/>, but no set of <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="X"/> nodes can decode <img alt="\textbf{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctextbf%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\textbf{A}"/>, <img alt="\textbf{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctextbf%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\textbf{B}"/>, or <img alt="\textbf{AB}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctextbf%7BAB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\textbf{AB}"/>. Similarly, [Kim, Yang, Li ’19] adapts this idea to impose privacy on a matrix-matrix multiplication: workers are assumed to have a shared library <img alt="\{{\textbf{B}}_i\}_{i=1}^M" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B%7B%5Ctextbf%7BB%7D%7D_i%5C%7D_%7Bi%3D1%7D%5EM&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\{{\textbf{B}}_i\}_{i=1}^M"/>, and the user would like to multiply <img alt="{\textbf{A}}{\textbf{B}}_{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctextbf%7BA%7D%7D%7B%5Ctextbf%7BB%7D%7D_%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\textbf{A}}{\textbf{B}}_{D}"/> for some <img alt="D \in[1:M]" class="latex" src="https://s0.wp.com/latex.php?latex=D+%5Cin%5B1%3AM%5D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="D \in[1:M]"/> without revealing the value of <img alt="D" class="latex" src="https://s0.wp.com/latex.php?latex=D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="D"/> to the workers. The workers encode the entire library such that when the  encoding is multiplied by an encoded input <img alt="\tilde{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctilde%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\tilde{A}"/> from the master, the result is useful to the master in decoding <img alt="{\textbf{A}}{\textbf{B}}_D" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctextbf%7BA%7D%7D%7B%5Ctextbf%7BB%7D%7D_D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\textbf{A}}{\textbf{B}}_D"/>.</p>



<p>Chang and Tandon consider the following two privacy models, where up to <img alt="\ell" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\ell"/> servers may collude. The master also has <img alt="K^{(A)}" class="latex" src="https://s0.wp.com/latex.php?latex=K%5E%7B%28A%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="K^{(A)}"/> (and in the second model, <img alt="K^{(B)}" class="latex" src="https://s0.wp.com/latex.php?latex=K%5E%7B%28B%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="K^{(B)}"/>), which are matrices of random values with the same dimensions as <img alt="\textbf{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctextbf%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\textbf{A}"/> (and <img alt="\textbf{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctextbf%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\textbf{B}"/>). These are used in creating the encodings <img alt="\tilde{A}_i" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctilde%7BA%7D_i&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\tilde{A}_i"/> (and <img alt="\tilde{B}_i" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctilde%7BB%7D_i&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\tilde{B}_i"/>).</p>



<p> <img alt="\textbf{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctextbf%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\textbf{B}"/> is public, <img alt="\textbf{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctextbf%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\textbf{A}"/> is private:</p>



<figure class="wp-block-image size-large"><img alt="" class="wp-image-1604" src="https://theorydish.files.wordpress.com/2020/03/blog_fig8.png?w=1024"/></figure>



<p>Both private:</p>



<figure class="wp-block-image size-large"><img alt="" class="wp-image-1605" src="https://theorydish.files.wordpress.com/2020/03/blog_fig9.png?w=1024"/></figure>



<p>Kim, Yang, and Lee take a similar approach of applying the method of polynomial code to <em>private</em> matrix multiplication. As before, there are <img alt="N" class="latex" src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="N"/> workers, but now the master wants to multiply <img alt="\textbf{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctextbf%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\textbf{A}"/> with some <img alt="{\textbf{B}}_D" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctextbf%7BB%7D%7D_D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\textbf{B}}_D"/> in shared library <img alt="\{{\textbf{B}}_i\}_{i=1}^M" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B%7B%5Ctextbf%7BB%7D%7D_i%5C%7D_%7Bi%3D1%7D%5EM&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\{{\textbf{B}}_i\}_{i=1}^M"/> (all the workers have the shared library). </p>



<p>Since the master isn’t itself encoding <img alt="\{{\textbf{B}}\}_{i=1}^M" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B%7B%5Ctextbf%7BB%7D%7D%5C%7D_%7Bi%3D1%7D%5EM&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\{{\textbf{B}}\}_{i=1}^M"/> it has to tell the workers how to encode the library so that it can reconstruct the desired product. This is done by having the master tell the workers what values of <img alt="\vec{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cvec%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\vec{y}"/> they should use to evaluate the polynomial that corresponds to encoding each library matrix. We denote the encoding of the library done by each worker <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="i"/> as the multivariate polynomial <img alt="h" class="latex" src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="h"/> which is evaluated at <img alt="\{{\textbf{B}}\}_{i=1}^M" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B%7B%5Ctextbf%7BB%7D%7D%5C%7D_%7Bi%3D1%7D%5EM&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\{{\textbf{B}}\}_{i=1}^M"/> and the node-specific vector <img alt="y^{(i)}_{[1:M]}" class="latex" src="https://s0.wp.com/latex.php?latex=y%5E%7B%28i%29%7D_%7B%5B1%3AM%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="y^{(i)}_{[1:M]}"/> to get the node’s encoding, <img alt="\tilde{B}_i" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctilde%7BB%7D_i&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\tilde{B}_i"/>. The worker multiplies this with the encoding of <img alt="\textbf{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctextbf%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\textbf{A}"/> it receives, <img alt="\tilde{A}_i" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctilde%7BA%7D_i&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\tilde{A}_i"/> and returns the resulting value <img alt="Z_i" class="latex" src="https://s0.wp.com/latex.php?latex=Z_i&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="Z_i"/>. All together, we get the following communication model: </p>



<figure class="wp-block-image size-large"><img alt="" class="wp-image-1611" src="https://theorydish.files.wordpress.com/2020/03/blog_fig10.png?w=1024"/></figure>



<h2>Conclusion</h2>



<p>As we’ve seen, coding techniques originally designed to add redundancy and protect against data loss can also be used to intentionally incorporate noise for data protection. In particular, this can be done when out-sourcing matrix multiplications, making it a useful technique in many data processing and machine learning applications.</p>



<p>References:</p>



<ul><li><a href="https://arxiv.org/pdf/1808.07457.pdf">Jia, Zhuqing, Hua Sun, and Syed Ali Jafar. “Cross Subspace Alignment and the Asymptotic Capacity of  X-Secure T-Private Information Retrieval.” <em>IEEE Transactions on Information Theory</em> 65.9 (2019): 5783-5798.</a></li><li><a href="http://papers.nips.cc/paper/7027-polynomial-codes-an-optimal-design-for-high-dimensional-coded-matrix-multiplication.pdf">Yu, Qian, Mohammad Maddah-Ali, and Salman Avestimehr. “Polynomial codes: an optimal design for high-dimensional coded matrix multiplication.” <em>Advances in Neural Information Processing Systems</em>. 2017.</a></li><li><a href="https://uweb.engr.arizona.edu/~wchang/Globecom-SecureMM-2018.pdf">Chang, Wei-Ting, and Ravi Tandon. “On the capacity of secure distributed matrix multiplication.” <em>2018 IEEE Global Communications Conference (GLOBECOM)</em>. IEEE, 2018.</a></li><li><a href="https://ieeexplore-ieee-org.stanford.idm.oclc.org/abstract/document/8832193">Kim, Minchul, Heecheol Yang, and Jungwoo Lee. “Private Coded Matrix Multiplication.” <em>IEEE Transactions on Information Forensics and Security</em> (2019).</a></li></ul>



<p/></div>
    </content>
    <updated>2020-03-18T23:14:58Z</updated>
    <published>2020-03-18T23:14:58Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Alex Porter</name>
    </author>
    <source>
      <id>https://theorydish.blog</id>
      <logo>https://theorydish.files.wordpress.com/2017/03/cropped-nightdish1.jpg?w=32</logo>
      <link href="https://theorydish.blog/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://theorydish.blog" rel="alternate" type="text/html"/>
      <link href="https://theorydish.blog/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://theorydish.blog/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Stanford's CS Theory Research Blog</subtitle>
      <title>Theory Dish</title>
      <updated>2020-08-26T22:24:12Z</updated>
    </source>
  </entry>
</feed>
