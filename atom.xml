<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2021-01-15T18:39:08Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry>
    <id>tag:blogger.com,1999:blog-25562705.post-8763851996229403535</id>
    <link href="http://aaronsadventures.blogspot.com/feeds/8763851996229403535/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=25562705&amp;postID=8763851996229403535" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/25562705/posts/default/8763851996229403535" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/25562705/posts/default/8763851996229403535" rel="self" type="application/atom+xml"/>
    <link href="http://aaronsadventures.blogspot.com/2021/01/how-to-estimate-uncertainty-of.html" rel="alternate" type="text/html"/>
    <title>How to Estimate the Uncertainty of Predictions</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><!--wp:paragraph {"align":"center"}--><p class="has-text-align-center" style="text-align: center;"><i>This is a post about a new paper <a href="https://arxiv.org/abs/2101.01739">Online Multivalid Learning: Means, Moments, and Prediction Intervals</a>, that is joint work with Varun Gupta, Christopher Jung, Georgy Noarov, and Mallesh Pai. It is <a href="https://toc4fairness.org/how-to-estimate-the-uncertainty-of-predictions">cross-posted to the new TOC4Fairness blog</a>. </i></p><!--/wp:paragraph--> <!--wp:paragraph--><p>Suppose you go and train the latest, greatest machine learning architecture to predict something important. Say (to pick an example entirely out of thin air) you are in the midst of a pandemic, and want to predict the severity of patients' symptoms in 2 days time, so as to triage scarce medical resources. Since you will be using these predictions to make decisions, you would like them to be accurate in various ways: for example, at the very least, you will want your predictions to be calibrated, and you may also want to be able to accurately quantify the uncertainty of your predictions (say with 95% prediction intervals). It is a fast moving situation, and data is coming in dynamically --- and you need to make decisions as you go. What can you do? </p><!--/wp:paragraph--> <!--wp:paragraph--><p>The first thing you might do is <a href="https://twitter.com/Aaroth/status/1272545845603434497">ask on twitter</a>! What you will find is that the standard tool for quantifying uncertainty in settings like this is <a href="https://jmlr.csail.mit.edu/papers/volume9/shafer08a/shafer08a.pdf">conformal prediction</a>. The conformal prediction literature has a number of elegant techniques for endowing arbitrary point prediction methods with <em>marginal prediction intervals</em>: i.e intervals $(\ell(x), u(x))$ such that over the randomness of some data distribution over labelled examples $(x,y)$: $\Pr_{(x,y)}\left[y \in [\ell(x), u(x)]\right] \approx 0.95$ These would be 95% marginal prediction intervals --- but in general you could pick your favorite coverage probability $1-\delta$.  </p><!--/wp:paragraph--> <!--wp:paragraph--><p>Conformal prediction has a lot going for it --- its tools are very general and flexible, and lead to practical algorithms. But it also has two well known shortcomings:</p><!--/wp:paragraph--> <!--wp:list {"ordered":true}--><ol><li><strong>Strong Assumptions</strong>. Like many tools from statistics and machine learning, conformal prediction methods require that the future look like the past. In particular, they require that the data be drawn i.i.d. from some distribution --- or at least be <em>exchangable</em> (i.e. their distribution should be invariant to permutation). This is sometimes the case --- but it often is not. In our pandemic scenario, the distribution on patient features might quickly change in unexpected ways as the disease moves between different populations, as might the relationship between features and outcomes, as treatments advance. In other settings in which consequential decisions are being made about people --- like lending and hiring decisions --- people might intentionally manipulate their features in response to the predictive algorithms you deploy, in an attempt to get the outcome they want. Or you might be trying to predict outcomes in time series data, in which there are explicit dependencies across time. In all of these scenarios, exchangeability is violated.</li><li><strong>Weak Guarantees</strong>. Marginal coverage guarantees are <em>averages over people</em>. 95% marginal coverage means that the true label falls within the predicted interval for 95% of people. It need not mean anything for <em>people like you</em>. For example, if you are part of a demographic group that makes up less than 5% of the population, it is entirely consistent with the guarantees of a 95% marginal prediction interval that labels for people from your demographic group fall outside of their intervals 100% of the time. This can be both an accuracy and a <strong><em>fairness</em> </strong>concern --- marginal prediction works well for "typical" members of a population, but not necessarily for everyone else. </li></ol><!--/wp:list--> <!--wp:paragraph--><p>What kinds of improvements might we hope for? Lets start with how to strengthen the guarantee:</p><!--/wp:paragraph--> <!--wp:paragraph--><p><strong>Multivalidity</strong> Ideally, we would want <em>conditional</em> guarantees --- i.e. the promise that for every $x$, that we would have $\Pr_{y}\left[y \in [\ell(x), u(x)] | x \right] \approx 0.95$. In other words, that somehow for each individual, the prediction interval was valid for them specifically, over the "unrealized" (or unmeasured) randomness of the world. Of course this is too much to hope for. In a rich feature space, we have likely never seen anyone exactly like you before (i.e. with your feature vector $x$). So strictly speaking, we have no information at all about your conditional label distribution. We still have to average over people. But we don't have to average over everybody. An important idea that has been investigated in <a href="https://arxiv.org/abs/1711.08513">several </a><a href="https://arxiv.org/abs/1711.05144">different </a><a href="https://arxiv.org/abs/1805.12317">contexts </a>in recent years in the theory literature on fairness is that we might articulate a very rich collection of (generally intersecting) demographic groups $G$ corresponding to relevant subsets of the data domain, and ask for things that we care about to hold true as averaged over any group $S \in G$ in the collection. In the case of prediction intervals, this would correspond to asking for something like that simultaneously for every demographic group $S \in G$, $\Pr_{(x,y)}\left[y \in [\ell(x), u(x)] | x \in S \right] \approx 0.95$. Note here that an individual might be a member of many different demographic groups, and can interpret the guarantees of their prediction interval as averages over any of those demographic groups, at their option. This is what we can achieve --- at least for any such group that isn't too small.  </p><!--/wp:paragraph--> <!--wp:paragraph--><p>And what kinds of assumptions do we need?</p><!--/wp:paragraph--> <!--wp:paragraph--><p><strong>Adversarial Data </strong>Actually, its not clear that we need any! Many learning problems which initially appear to require distributional assumptions turn out to be solvable even in the worst case over data sequences --- i.e. even if a clever adversary, with full knowledge of your algorithm, and with the intent only to sabotage your learning guarantees, is allowed to adaptively choose data to present to your algorithm. This is the case for <a href="https://academic.oup.com/biomet/article-abstract/85/2/379/298827">calibrated weather prediction</a>, as well as <a href="http://proceedings.mlr.press/v48/syrgkanis16.pdf">general contextual prediction</a>. It turns out to be the case for us as well. Instead of promising coverage probabilities of $1-\delta + O(1/T)$ after $T$ rounds <em>on the underlying distribution</em>, as<a href="https://www.stat.cmu.edu/~ryantibs/papers/conformal.pdf"> conformal prediction is able to</a>, (for us there is no underlying distribution) we offer <em>empirical</em> coverage rates of $1-\delta \pm O(1/\sqrt{T})$. This kind of guarantee is quite similar to what<a href="https://www.stat.cmu.edu/~ryantibs/papers/conformal.pdf"> conformal prediction guarantees about empirical coverage</a>. </p><!--/wp:paragraph--> <!--wp:paragraph--><p><strong>More Generally </strong>Our techniques are not specific to prediction intervals. We can do the same thing for predicting label means, and predicting variances of the residuals of arbitrary prediction methods. For mean prediction, this corresponds to an algorithm for providing <a href="https://arxiv.org/abs/1711.08513">multi-calibrated predictions in the sense of Hebert-Johnson et al</a>, in an online adversarial environment. For variances and other higher moments, it corresponds to an online algorithm for making <a href="https://arxiv.org/abs/2008.08037">mean-conditioned moment multicalibrated predictions in the sense of Jung et al</a>.</p><!--/wp:paragraph--> <!--wp:paragraph--><p><strong>Techniques</strong> At the risk of boring my one stubbornly remaining reader, let me say a few words about how we do it. We generalize an idea that dates back to an argument that<a href="https://dash.harvard.edu/bitstream/handle/1/3203773/fudenberg_calibrate.pdf"> Fudenberg and Levine first made in 1995</a> --- and is closely related to <a href="http://www.ma.huji.ac.il/hart/papers/calib-minmax.pdf">an earlier, beautiful argument by Sergiu Hart</a> --- but that I just learned about this summer, and thought was just amazing. It applies broadly to solving any prediction task that would be easy, if only you were facing a known data distribution. This is the case for us. If, for each arriving patient at our hospital, a wizard <em>told us</em> their "true" distribution over outcome severity, we could easily make calibrated predictions by always predicting the mean of this distribution --- and we could similarly read off correct 95% coverage intervals from the CDF of the distribution. So what? That's not the situation we are in, of course. Absent a wizard, we first need to commit to some learning algorithm, and only then will the adversary decide what data to show us. </p><!--/wp:paragraph--> <!--wp:paragraph--><p>But lets put our game theory hats on. Suppose we've been making predictions for awhile. We can write down some measure of our error so far --- say the maximum, over all demographic groups in $G$, of the deviation of our empirical coverage so far from our 95% coverage target.  For the next round, define a zero sum game, in which we (the learner) want to minimize the <em>increase</em> in this measure of error, and the adversary wants to maximize it. The defining feature of zero-sum games is that how well you can do in them is independent of which player has to announce their distribution on play first --- this is the celebrated <a href="https://en.wikipedia.org/wiki/Minimax_theorem">Minimax Theorem</a>. So to evaluate how well the learner could do in this game, we can think about the situation involving a Wizard above, in which for each arriving person, before we have to make a prediction for them, we get to observe their true label distribution. Of course in this scenario we can do well, because for all of our goals, our measure of success is based on how well our predictions match observed properties of these distributions. The Minimax theorem tells us that (at least in principle --- it doesn't give us the algorithm), there must therefore also be a learning algorithm that can do just as well, but against an adversary. </p><!--/wp:paragraph--> <!--wp:paragraph--><p>The minimax argument is slick, but non-constructive. To actually pin down a concrete algorithm, we need to solve for the equilibrium in the corresponding game. That's what we spend much of the paper doing, for each of the prediction tasks that we study. For multicalibration, we get a simple, elementary algorithm --- but for the prediction interval problem, although we get a polynomial time algorithm, it involves solving a linear program with a separation oracle at each round. Finding more efficient and practical ways to do this strikes me as an important problem. </p><!--/wp:paragraph--> <!--wp:paragraph--><p>Finally, I had more fun writing this paper --- learning about old techniques from the game theoretic calibration literature --- than I've had in awhile. I hope a few people enjoy reading it!</p><!--/wp:paragraph--><p> </p></div>
    </content>
    <updated>2021-01-15T14:01:00Z</updated>
    <published>2021-01-15T14:01:00Z</published>
    <author>
      <name>Aaron</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/09952936358739421126</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-25562705</id>
      <category term="game theory"/>
      <category term="news"/>
      <author>
        <name>Aaron</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/09952936358739421126</uri>
      </author>
      <link href="http://aaronsadventures.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/25562705/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://aaronsadventures.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/25562705/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <title>Adventures in Computation</title>
      <updated>2021-01-15T14:01:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://toc4fairness.org/?p=1242</id>
    <link href="https://toc4fairness.org/how-to-estimate-the-uncertainty-of-predictions/" rel="alternate" type="text/html"/>
    <title>How to Estimate the Uncertainty of Predictions</title>
    <summary>This is a post about a new paper Online Multivalid Learning: Means, Moments, and Prediction Intervals, that is joint work with Varun Gupta, Christopher Jung, Georgy Noarov, and Mallesh Pai. ...</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p class="has-text-align-center">This is a post about a new paper <em><a href="https://arxiv.org/abs/2101.01739">Online Multivalid Learning: Means, Moments, and Prediction Intervals</a></em>, that is joint work with Varun Gupta, Christopher Jung, Georgy Noarov, and Mallesh Pai.  </p>



<p>Suppose you go and train the latest, greatest machine learning architecture to predict something important. Say (to pick an example entirely out of thin air) you are in the midst of a pandemic, and want to predict the severity of patients’ symptoms in 2 days time, so as to triage scarce medical resources. Since you will be using these predictions to make decisions, you would like them to be accurate in various ways: for example, at the very least, you will want your predictions to be calibrated, and you may also want to be able to accurately quantify the uncertainty of your predictions (say with 95% prediction intervals). It is a fast moving situation, and data is coming in dynamically — and you need to make decisions as you go. What can you do? </p>



<p>The first thing you might do is <a href="https://twitter.com/Aaroth/status/1272545845603434497">ask on twitter</a>! What you will find is that the standard tool for quantifying uncertainty in settings like this is <a href="https://jmlr.csail.mit.edu/papers/volume9/shafer08a/shafer08a.pdf">conformal prediction</a>. The conformal prediction literature has a number of elegant techniques for endowing arbitrary point prediction methods with <em>marginal prediction intervals</em>: i.e intervals <img alt="(\ell(x), u(x))" class="latex" src="https://s0.wp.com/latex.php?latex=%28%5Cell%28x%29%2C+u%28x%29%29&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002" title="(\ell(x), u(x))"/> such that over the randomness of some data distribution over labelled examples <img alt="(x,y)" class="latex" src="https://s0.wp.com/latex.php?latex=%28x%2Cy%29&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002" title="(x,y)"/>: <img alt="\Pr_{(x,y)}\left[y \in [\ell(x), u(x)]\right] \approx 0.95" class="latex" src="https://s0.wp.com/latex.php?latex=%5CPr_%7B%28x%2Cy%29%7D%5Cleft%5By+%5Cin+%5B%5Cell%28x%29%2C+u%28x%29%5D%5Cright%5D+%5Capprox+0.95&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002" title="\Pr_{(x,y)}\left[y \in [\ell(x), u(x)]\right] \approx 0.95"/> These would be 95% marginal prediction intervals — but in general you could pick your favorite coverage probability <img alt="1-\delta" class="latex" src="https://s0.wp.com/latex.php?latex=1-%5Cdelta&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002" title="1-\delta"/>.  </p>



<p>Conformal prediction has a lot going for it — its tools are very general and flexible, and lead to practical algorithms. But it also has two well known shortcomings:</p>



<ol><li><strong>Strong Assumptions</strong>. Like many tools from statistics and machine learning, conformal prediction methods require that the future look like the past. In particular, they require that the data be drawn i.i.d. from some distribution — or at least be <em>exchangable</em> (i.e. their distribution should be invariant to permutation). This is sometimes the case — but it often is not. In our pandemic scenario, the distribution on patient features might quickly change in unexpected ways as the disease moves between different populations, as might the relationship between features and outcomes, as treatments advance. In other settings in which consequential decisions are being made about people — like lending and hiring decisions — people might intentionally manipulate their features in response to the predictive algorithms you deploy, in an attempt to get the outcome they want. Or you might be trying to predict outcomes in time series data, in which there are explicit dependencies across time. In all of these scenarios, exchangeability is violated.</li><li><strong>Weak Guarantees</strong>. Marginal coverage guarantees are <em>averages over people</em>. 95% marginal coverage means that the true label falls within the predicted interval for 95% of people. It need not mean anything for <em>people like you</em>. For example, if you are part of a demographic group that makes up less than 5% of the population, it is entirely consistent with the guarantees of a 95% marginal prediction interval that labels for people from your demographic group fall outside of their intervals 100% of the time. This can be both an accuracy and a <strong><em>fairness</em> </strong>concern — marginal prediction works well for “typical” members of a population, but not necessarily for everyone else. </li></ol>



<p>What kinds of improvements might we hope for? Lets start with how to strengthen the guarantee:</p>



<p><strong>Multivalidity</strong> Ideally, we would want <em>conditional</em> guarantees — i.e. the promise that for every <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002" title="x"/>, that we would have <img alt="\Pr_{y}\left[y \in [\ell(x), u(x)] | x \right] \approx 0.95" class="latex" src="https://s0.wp.com/latex.php?latex=%5CPr_%7By%7D%5Cleft%5By+%5Cin+%5B%5Cell%28x%29%2C+u%28x%29%5D+%7C+x+%5Cright%5D+%5Capprox+0.95&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002" title="\Pr_{y}\left[y \in [\ell(x), u(x)] | x \right] \approx 0.95"/>. In other words, that somehow for each individual, the prediction interval was valid for them specifically, over the “unrealized” (or unmeasured) randomness of the world. Of course this is too much to hope for. In a rich feature space, we have likely never seen anyone exactly like you before (i.e. with your feature vector <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002" title="x"/>). So strictly speaking, we have no information at all about your conditional label distribution. We still have to average over people. But we don’t have to average over everybody. An important idea that has been investigated in <a href="https://arxiv.org/abs/1711.08513">several </a><a href="https://arxiv.org/abs/1711.05144">different </a><a href="https://arxiv.org/abs/1805.12317">contexts </a>in recent years in the theory literature on fairness is that we might articulate a very rich collection of (generally intersecting) demographic groups <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002" title="G"/> corresponding to relevant subsets of the data domain, and ask for things that we care about to hold true as averaged over any group <img alt="S \in G" class="latex" src="https://s0.wp.com/latex.php?latex=S+%5Cin+G&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002" title="S \in G"/> in the collection. In the case of prediction intervals, this would correspond to asking for something like that simultaneously for every demographic group <img alt="S \in G" class="latex" src="https://s0.wp.com/latex.php?latex=S+%5Cin+G&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002" title="S \in G"/>, <img alt="\Pr_{(x,y)}\left[y \in [\ell(x), u(x)] | x \in S \right] \approx 0.95" class="latex" src="https://s0.wp.com/latex.php?latex=%5CPr_%7B%28x%2Cy%29%7D%5Cleft%5By+%5Cin+%5B%5Cell%28x%29%2C+u%28x%29%5D+%7C+x+%5Cin+S+%5Cright%5D+%5Capprox+0.95&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002" title="\Pr_{(x,y)}\left[y \in [\ell(x), u(x)] | x \in S \right] \approx 0.95"/>. Note here that an individual might be a member of many different demographic groups, and can interpret the guarantees of their prediction interval as averages over any of those demographic groups, at their option. This is what we can achieve — at least for any such group that isn’t too small. </p>



<p>And what kinds of assumptions do we need?</p>



<p><strong>Adversarial Data </strong>Actually, its not clear that we need any! Many learning problems which initially appear to require distributional assumptions turn out to be solvable even in the worst case over data sequences — i.e. even if a clever adversary, with full knowledge of your algorithm, and with the intent only to sabotage your learning guarantees, is allowed to adaptively choose data to present to your algorithm. This is the case for <a href="https://academic.oup.com/biomet/article-abstract/85/2/379/298827">calibrated weather prediction</a>, as well as <a href="http://proceedings.mlr.press/v48/syrgkanis16.pdf">general contextual prediction</a>. It turns out to be the case for us as well. Instead of promising coverage probabilities of <img alt="1-\delta + O(1/T)" class="latex" src="https://s0.wp.com/latex.php?latex=1-%5Cdelta+%2B+O%281%2FT%29&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002" title="1-\delta + O(1/T)"/> after <img alt="T" class="latex" src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002" title="T"/> rounds <em>on the underlying distribution</em>, as<a href="https://www.stat.cmu.edu/~ryantibs/papers/conformal.pdf"> conformal prediction is able to</a>, we offer <em>empirical</em> coverage rates of <img alt="1-\delta \pm O(1/\sqrt{T})" class="latex" src="https://s0.wp.com/latex.php?latex=1-%5Cdelta+%5Cpm+O%281%2F%5Csqrt%7BT%7D%29&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002" title="1-\delta \pm O(1/\sqrt{T})"/> (since for us there is no underlying distribution). This kind of guarantee is quite similar to what<a href="https://www.stat.cmu.edu/~ryantibs/papers/conformal.pdf"> conformal prediction guarantees about empirical coverage</a>. </p>



<p><strong>More Generally </strong>Our techniques are not specific to prediction intervals. We can do the same thing for many other distributional quantities. We work this out in the case of predicting label means, and predicting variances of the residuals of arbitrary prediction methods. For mean prediction, this corresponds to an algorithm for providing <a href="https://arxiv.org/abs/1711.08513">multi-calibrated predictions in the sense of Hebert-Johnson et al</a>, in an online adversarial environment. For variances and other higher moments, it corresponds to an online algorithm for making <a href="https://arxiv.org/abs/2008.08037">mean-conditioned moment multicalibrated predictions in the sense of Jung et al</a>.</p>



<p><strong>Techniques</strong> At the risk of boring my one stubbornly remaining reader, let me say a few words about how we do it. We generalize an idea that dates back to an argument that<a href="https://dash.harvard.edu/bitstream/handle/1/3203773/fudenberg_calibrate.pdf"> Fudenberg and Levine first made in 1995</a> — and is closely related to <a href="http://www.ma.huji.ac.il/hart/papers/calib-minmax.pdf">an earlier, beautiful argument by Sergiu Hart</a> — but that I just learned about this summer, and thought was just amazing. It applies broadly to solving any prediction task that would be easy, if only you were facing a known data distribution. This is the case for us. If, for each arriving patient at our hospital, a wizard <em>told us</em> their “true” distribution over outcome severity, we could easily make calibrated predictions by always predicting the mean of this distribution — and we could similarly read off correct 95% coverage intervals from the CDF of the distribution. So what? That’s not the situation we are in, of course. Absent a wizard, we first need to commit to some learning algorithm, and only then will the adversary decide what data to show us. </p>



<p>But lets put our game theory hats on. Suppose we’ve been making predictions for awhile. We can write down some measure of our error so far — say the maximum, over all demographic groups in <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002" title="G"/>, of the deviation of our empirical coverage so far from our 95% coverage target.  For the next round, define a zero sum game, in which we (the learner) want to minimize the <em>increase</em> in this measure of error, and the adversary wants to maximize it. The defining feature of zero-sum games is that how well you can do in them is independent of which player has to announce their distribution on play first — this is the celebrated <a href="https://en.wikipedia.org/wiki/Minimax_theorem">Minimax Theorem</a>. So to evaluate how well the learner could do in this game, we can think about the situation involving a Wizard above, in which for each arriving person, before we have to make a prediction for them, we get to observe their true label distribution. Of course in this scenario we can do well, because for all of our goals, our measure of success is based on how well our predictions match observed properties of these distributions. The Minimax theorem tells us that (at least in principle — it doesn’t give us the algorithm), there must therefore also be a learning algorithm that can do just as well, but against an adversary. </p>



<p>The minimax argument is slick, but non-constructive. To actually pin down a concrete algorithm, we need to solve for the equilibrium in the corresponding game. That’s what we spend much of the paper doing, for each of the prediction tasks that we study. For multicalibration, we get a simple, elementary algorithm — but for the prediction interval problem, although we get a polynomial time algorithm, it involves solving a linear program with a separation oracle at each round. Finding more efficient and practical ways to do this strikes me as an important problem. </p>



<p>Finally, I had more fun writing this paper — learning about old techniques from the game theoretic calibration literature — than I’ve had in awhile. I hope a few people enjoy reading it!</p>



<p/>



<p/></div>
    </content>
    <updated>2021-01-15T14:00:00Z</updated>
    <published>2021-01-15T14:00:00Z</published>
    <category term="Blog"/>
    <category term="multicalibration"/>
    <category term="papers"/>
    <category term="subgroup fairness"/>
    <category term="uncertainty"/>
    <author>
      <name>Aaron Roth</name>
    </author>
    <source>
      <id>https://toc4fairness.org</id>
      <logo>https://i1.wp.com/toc4fairness.org/wp-content/uploads/2020/10/cropped-favicon.png?fit=32%2C32&amp;ssl=1</logo>
      <link href="https://toc4fairness.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://toc4fairness.org" rel="alternate" type="text/html"/>
      <subtitle>a simons collaboration project</subtitle>
      <title>TOC for Fairness</title>
      <updated>2021-01-15T18:39:08Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/01/14/assistant-professor-at-university-of-toronto-toronto-canada-apply-by-january-28-2021/</id>
    <link href="https://cstheory-jobs.org/2021/01/14/assistant-professor-at-university-of-toronto-toronto-canada-apply-by-january-28-2021/" rel="alternate" type="text/html"/>
    <title>Assistant Professor at University of Toronto, Toronto, Canada (apply by January 28, 2021)</title>
    <summary>The Department of Computer Science at the University of Toronto invites applications for up to two full-time tenure stream positions in the areas of Security and Cryptography. The appointments will be at the rank of Assistant Professor and will commence on July 1, 2021, or shortly thereafter. Website: https://jobs.utoronto.ca/job/Toronto-Assistant-Professor-Security-and-Cryptography-ON/543569117/ Email: recruit@cs.toronto.edu</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Department of Computer Science at the University of Toronto invites applications for up to two full-time tenure stream positions in the areas of Security and Cryptography. The appointments will be at the rank of Assistant Professor and will commence on July 1, 2021, or shortly thereafter.</p>
<p>Website: <a href="https://jobs.utoronto.ca/job/Toronto-Assistant-Professor-Security-and-Cryptography-ON/543569117/">https://jobs.utoronto.ca/job/Toronto-Assistant-Professor-Security-and-Cryptography-ON/543569117/</a><br/>
Email: recruit@cs.toronto.edu</p></div>
    </content>
    <updated>2021-01-14T22:40:03Z</updated>
    <published>2021-01-14T22:40:03Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-01-15T18:37:48Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/01/14/faculty-position-in-algorithms-and-complexity-at-university-of-edinburgh-apply-by-february-21-2021/</id>
    <link href="https://cstheory-jobs.org/2021/01/14/faculty-position-in-algorithms-and-complexity-at-university-of-edinburgh-apply-by-february-21-2021/" rel="alternate" type="text/html"/>
    <title>Faculty position in Algorithms and Complexity at University of Edinburgh (apply by February 21, 2021)</title>
    <summary>The School of Informatics at the University of Edinburgh invites applicants for Lecturer (“Assistant Professor”), and Reader (“Associate Professor”) in Algorithms and Complexity. For a full advert for the post, and how to apply, please see the link below. Website: https://elxw.fa.em3.oraclecloud.com/hcmUI/CandidateExperience/en/sites/CX_1001/job/295 Email: kousha@inf.ed.ac.uk</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The School of Informatics at the University of Edinburgh invites applicants for Lecturer (“Assistant Professor”), and Reader (“Associate Professor”) in Algorithms and Complexity.</p>
<p>For a full advert for the post, and how to apply, please see the link below.</p>
<p>Website: <a href="https://elxw.fa.em3.oraclecloud.com/hcmUI/CandidateExperience/en/sites/CX_1001/job/295">https://elxw.fa.em3.oraclecloud.com/hcmUI/CandidateExperience/en/sites/CX_1001/job/295</a><br/>
Email: kousha@inf.ed.ac.uk</p></div>
    </content>
    <updated>2021-01-14T18:21:26Z</updated>
    <published>2021-01-14T18:21:26Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-01-15T18:37:48Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=17987</id>
    <link href="https://rjlipton.wordpress.com/2021/01/14/priming-random-restrictions/" rel="alternate" type="text/html"/>
    <title>Priming Random Restrictions</title>
    <summary>Can we expand the base of their use? Technion commemoration src Bella Subbotovskaya was doing Boolean complexity lower bounds in 1961. She originated the method of restrictions of Boolean functions and proved that the formula size of the parity function of variables is at least . The parity bound was improved to quadratic in 1971 […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Can we expand the base of their use?</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2021/01/bella.png"><img alt="" class="alignright wp-image-17989" height="231" src="https://rjlipton.files.wordpress.com/2021/01/bella.png?w=135&amp;h=231" width="135"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Technion commemoration <a href="https://history.math.technion.ac.il/sites/CMS/archive/year_2006-2007/different-approaches/">src</a></font></td>
</tr>
</tbody>
</table>
<p>
Bella Subbotovskaya was doing Boolean complexity lower bounds in 1961. She <a href="https://en.wikipedia.org/wiki/Bella_Subbotovskaya">originated</a> the method of <em>restrictions</em> of Boolean functions and proved that the formula size of the parity function of <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{n}"/> variables is at least <img alt="{n^{3/2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%5E%7B3%2F2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{n^{3/2}}"/>. The parity bound was improved to quadratic in 1971 by Valeriy Khrapchenko, who passed away only last year and was the only child of the Soviet literature and arts leader Mikhail Khrapchenko. Then Johan Håstad <a href="https://www.csc.kth.se/~johanh/shrinkgeneral.pdf">strengthened</a> the whole method to quadratic.</p>
<p>
Today we discuss not possible further sharpenings but rather how to extend the ways of applying it.</p>
<p>
Subbotovskaya was most unfortunately killed in a mysterious manner in 1982. George Szpiro in 2007 wrote an <a href="http://www.ams.org/notices/200710/tx071001326p.pdf">article</a> reviewing the circumstances amid her questioning by the KGB for co-founding and hosting the “Jewish People’s University” amid rampant anti-Semitism in Soviet academies. She was also a talented violist and vocalist and investigated computer-assisted musical composition and analysis. See also her MacTutor <a href="https://mathshistory.st-andrews.ac.uk/Biographies/Subbotovskaya/">biography</a>.</p>
<p>
As presented by Stasys Jukna in his 2012 <a href="http://www.thi.cs.uni-frankfurt.de/~jukna/boolean/BFC-draft.pdf">book</a> <em>Boolean Function Complexity</em>, Subbotovskaya gave an algorithm for optimizing the trimming of a formula over the <img alt="{\wedge,\vee,\neg}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cwedge%2C%5Cvee%2C%5Cneg%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\wedge,\vee,\neg}"/> basis at its leaves by substituting for <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{m}"/> of the <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{n}"/> variables, one at a time. She used an averaging argument that readily extends to give the same-order bounds on random restrictions. Random restrictions have other advantages that have led to wonderful work besides those above, including the recent <a href="https://eccc.weizmann.ac.il/report/2018/107/">oracle separation</a> of <img alt="{\mathsf{BQP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BBQP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\mathsf{BQP}}"/> from the polynomial hierarchy. We want to discuss targeting the restrictions toward possible particular sensitivities of the Boolean functions computed by the formulas.</p>
<p>
</p><p/><h2> The Method </h2><p/>
<p/><p>
Subbotovskaya’s argument considers every <img alt="{\wedge}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cwedge%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\wedge}"/> or <img alt="{\vee}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cvee%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\vee}"/> gate <img alt="{g}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{g}"/>, in a minimal formula <img alt="{\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\phi}"/> computing the function <img alt="{f(x_1,\dots,x_n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28x_1%2C%5Cdots%2Cx_n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{f(x_1,\dots,x_n)}"/>, that has <img alt="{x_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{x_i}"/> or <img alt="{\bar{x}_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbar%7Bx%7D_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\bar{x}_i}"/> as an input, for some <img alt="{i = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{i = 1}"/> to <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{n}"/>. Note that because <img alt="{\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\phi}"/> is a formula, one of the two possible assignments <img alt="{a_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{a_i}"/> to <img alt="{x_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{x_i}"/> renders the other input <img alt="{T_{g,i}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_%7Bg%2Ci%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{T_{g,i}}"/> to <img alt="{g}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{g}"/> immaterial. If <img alt="{\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\phi}"/> has <img alt="{s_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{s_n}"/> leaves, then we can not only choose <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{i}"/> so that <img alt="{x_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{x_i}"/> or <img alt="{\bar{x}_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbar%7Bx%7D_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\bar{x}_i}"/> occurs at least <img alt="{\frac{s_n}{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7Bs_n%7D%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\frac{s_n}{n}}"/> times, we can set it to wipe out at least half of the subtrees <img alt="{T_{g,i}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_%7Bg%2Ci%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{T_{g,i}}"/>. </p>
<p>
The final note is that doing so does not double-cancel any variable: if <img alt="{T_{g_i}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_%7Bg_i%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{T_{g_i}}"/> contains <img alt="{x_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{x_i}"/> or <img alt="{\bar{x}_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbar%7Bx%7D_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\bar{x}_i}"/>, then assigning <img alt="{1 - a_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1+-+a_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{1 - a_i}"/> to that occurrence leaves the function computed by <img alt="{g}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{g}"/> unchanged—but that contradicts the minimality of <img alt="{\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\phi}"/>. Hence no subformula <img alt="{T_{g,i}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_%7Bg%2Ci%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{T_{g,i}}"/> contains <img alt="{x_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{x_i}"/> or <img alt="{\bar{x}_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbar%7Bx%7D_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\bar{x}_i}"/>. The upshot is that we can set <img alt="{x_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{x_i}"/> so that the resulting formula <img alt="{\phi'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\phi'}"/> in <img alt="{n-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{n-1}"/> variables has <img alt="{s_{n-1} \leq s_n - \frac{3s_n}{2n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs_%7Bn-1%7D+%5Cleq+s_n+-+%5Cfrac%7B3s_n%7D%7B2n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{s_{n-1} \leq s_n - \frac{3s_n}{2n}}"/> leaves. It is convenient to weaken this inequality by </p>
<p align="center"><img alt="\displaystyle  s_{n-1} \leq s_n\left(1 - \frac{3}{2}\frac{1}{n}\right) \leq s_n\left(1 - \frac{1}{n}\right)^{3/2}, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++s_%7Bn-1%7D+%5Cleq+s_n%5Cleft%281+-+%5Cfrac%7B3%7D%7B2%7D%5Cfrac%7B1%7D%7Bn%7D%5Cright%29+%5Cleq+s_n%5Cleft%281+-+%5Cfrac%7B1%7D%7Bn%7D%5Cright%29%5E%7B3%2F2%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="\displaystyle  s_{n-1} \leq s_n\left(1 - \frac{3}{2}\frac{1}{n}\right) \leq s_n\left(1 - \frac{1}{n}\right)^{3/2}, "/></p>
<p>so that by iterating we can exploit the identity that for any <img alt="{k \leq n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk+%5Cleq+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{k \leq n}"/>, </p>
<p align="center"><img alt="\displaystyle  \left(1 - \frac{1}{n}\right)\left(1 - \frac{1}{n-1}\right)\cdots\left(1 - \frac{1}{k+1}\right) = \frac{k}{n}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cleft%281+-+%5Cfrac%7B1%7D%7Bn%7D%5Cright%29%5Cleft%281+-+%5Cfrac%7B1%7D%7Bn-1%7D%5Cright%29%5Ccdots%5Cleft%281+-+%5Cfrac%7B1%7D%7Bk%2B1%7D%5Cright%29+%3D+%5Cfrac%7Bk%7D%7Bn%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="\displaystyle  \left(1 - \frac{1}{n}\right)\left(1 - \frac{1}{n-1}\right)\cdots\left(1 - \frac{1}{k+1}\right) = \frac{k}{n}. "/></p>
<p>The upshot is that for any <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{m}"/>, we can set <img alt="{n-m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn-m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{n-m}"/> variables so that the size <img alt="{s_{m}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs_%7Bm%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{s_{m}}"/> of the resulting formula in <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{m}"/> variables obeys the bound </p>
<p align="center"><img alt="\displaystyle  s_{m} \leq s_n\left(\frac{m}{n}\right)^{3/2},\qquad\text{so}\qquad s_n \geq s_{m}\left(\frac{n}{m}\right)^{3/2}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++s_%7Bm%7D+%5Cleq+s_n%5Cleft%28%5Cfrac%7Bm%7D%7Bn%7D%5Cright%29%5E%7B3%2F2%7D%2C%5Cqquad%5Ctext%7Bso%7D%5Cqquad+s_n+%5Cgeq+s_%7Bm%7D%5Cleft%28%5Cfrac%7Bn%7D%7Bm%7D%5Cright%29%5E%7B3%2F2%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="\displaystyle  s_{m} \leq s_n\left(\frac{m}{n}\right)^{3/2},\qquad\text{so}\qquad s_n \geq s_{m}\left(\frac{n}{m}\right)^{3/2}. "/></p>
<p>Because the parity function is such that any way of setting <img alt="{n-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{n-1}"/> variables leaves the formula needing (at least) one read of the remaining variable, we can carry this all the way down to <img alt="{m=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{m=1}"/> to deduce <img alt="{s_n \geq n^{3/2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs_n+%5Cgeq+n%5E%7B3%2F2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{s_n \geq n^{3/2}}"/>. Note: this is concrete, not asymptotic. </p>
<p>
Via induction on gates <img alt="{g}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{g}"/> deeper than those at the leaves, and techniques that adapt to how closely the two subtrees of <img alt="{g}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{g}"/> are balanced, Håstad increased the exponent from <img alt="{3/2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{3/2}"/> to <img alt="{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{2}"/> in all cases, on pain of carrying some lower-order terms that make the bounds asymptotic. His lemmas rely more on the restrictions being random, including one that estimates the probability that the restriction already leaves a formula dependent on only one variable. </p>
<p>
</p><p/><h2> An Intuitive Framing </h2><p/>
<p/><p>
For sake of exposition we wave away the lower-order terms and write <img alt="{\gtrdot}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cgtrdot%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\gtrdot}"/> for the numerical inequalities. We frame the restrictions with notation that can help us target subsets <img alt="{I}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BI%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{I}"/> of variables to restrict, outside of which <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{f}"/> remains sensitive.</p>
<blockquote><p><b>Definition 1</b> <em> Let <img alt="{f : \{0,1\}^n \rightarrow \{0,1\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf+%3A+%5C%7B0%2C1%5C%7D%5En+%5Crightarrow+%5C%7B0%2C1%5C%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" title="{f : \{0,1\}^n \rightarrow \{0,1\}}"/> be a Boolean function. We say that 	</em></p><em>
<p align="center"><img alt="\displaystyle  \textsf{free}(f,I,\alpha) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Ctextsf%7Bfree%7D%28f%2CI%2C%5Calpha%29+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" title="\displaystyle  \textsf{free}(f,I,\alpha) "/></p>
<p>holds provided <img alt="{I \subset [n]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BI+%5Csubset+%5Bn%5D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" title="{I \subset [n]}"/> and <img alt="{\alpha: I \rightarrow \{0,1\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%3A+I+%5Crightarrow+%5C%7B0%2C1%5C%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\alpha: I \rightarrow \{0,1\}}"/> and for some <img alt="{x \neq y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx+%5Cneq+y%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" title="{x \neq y}"/> in <img alt="{\{0,1\}^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B0%2C1%5C%7D%5En%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\{0,1\}^n}"/> the following hold: </p>
<ol>
<li>
The inequality <img alt="{f(x) \neq f(y)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29+%5Cneq+f%28y%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" title="{f(x) \neq f(y)}"/> holds. <p/>
</li><li>
For all <img alt="{k \in I}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk+%5Cin+I%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" title="{k \in I}"/>, 	<p/>
<p align="center"><img alt="\displaystyle  x_k = y_k = \alpha(k). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++x_k+%3D+y_k+%3D+%5Calpha%28k%29.+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" title="\displaystyle  x_k = y_k = \alpha(k). "/></p>
</li></ol>
</em><p><em/>
</p></blockquote>
<p/><p>
Thus <img alt="{\textsf{free}(f,I,\alpha)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctextsf%7Bfree%7D%28f%2CI%2C%5Calpha%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\textsf{free}(f,I,\alpha)}"/> holds provided the value <img alt="{f(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{f(x)}"/> is not determined by just knowing <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{x}"/> on the set of positions in <img alt="{I}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BI%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{I}"/>. The remaining <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{m}"/> positions are needed.</p>
<blockquote><p><b>Theorem 2 (Main Theorem of Random Restriction Theory)</b> <em> Let <img alt="{f : \{0,1\}^n \rightarrow \{0,1\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf+%3A+%5C%7B0%2C1%5C%7D%5En+%5Crightarrow+%5C%7B0%2C1%5C%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" title="{f : \{0,1\}^n \rightarrow \{0,1\}}"/> be a Boolean function. Suppose that for a constant positive fraction of <img alt="{I,\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BI%2C%5Calpha%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" title="{I,\alpha}"/> with <img alt="{I}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BI%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" title="{I}"/> of size <img alt="{n-m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn-m%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" title="{n-m}"/>, 	</em></p><em>
<p align="center"><img alt="\displaystyle  \textsf{free}(f,I,\alpha) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Ctextsf%7Bfree%7D%28f%2CI%2C%5Calpha%29+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" title="\displaystyle  \textsf{free}(f,I,\alpha) "/></p>
<p>holds. Then 	 	</p>
<p align="center"><img alt="\displaystyle  L(f) \gtrdot \frac{n^2}{m^2}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++L%28f%29+%5Cgtrdot+%5Cfrac%7Bn%5E2%7D%7Bm%5E2%7D.+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" title="\displaystyle  L(f) \gtrdot \frac{n^2}{m^2}. "/></p>
</em><p><em/>
</p></blockquote>
<p>
</p><p/><h2> An Example and Nonexample </h2><p/>
<p/><p>
To see how this scheme applies in the case of the parity function, we can set <img alt="{m=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{m=1}"/>. No matter which inputs are selected, the value of the function stays undetermined after <img alt="{n-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{n-1}"/> inputs are set. That is, the following is always true: 	</p>
<p align="center"><img alt="\displaystyle  \textsf{free}(\textit{parity},I,\alpha), " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Ctextsf%7Bfree%7D%28%5Ctextit%7Bparity%7D%2CI%2C%5Calpha%29%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="\displaystyle  \textsf{free}(\textit{parity},I,\alpha), "/></p>
<p>for all <img alt="{I}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BI%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{I}"/> of size at most <img alt="{n-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{n-1}"/> and all <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\alpha}"/>. Thus the main theorem says that the formula lower bound for the parity function is order <img alt="{n^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{n^2}"/>. </p>
<p>
Note that the only property of the parity function <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{f}"/> being used is the global way it satisfies <img alt="{\textsf{free}(f,I,\alpha)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctextsf%7Bfree%7D%28f%2CI%2C%5Calpha%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\textsf{free}(f,I,\alpha)}"/>. We want to look for other patterns that can yield good bounds. Of course, patterns of sensitivity of Boolean functions have been looked at in many ways. We want to try to build a bridge from them to number theory.</p>
<p>
For a <em>non-</em>example, consider the set <img alt="{E}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BE%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{E}"/> of even numbers. Let us number the variables so that <img alt="{x_1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{x_1}"/> stands for the ones place in binary notation, <img alt="{x_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{x_2}"/> for the twos place, and so on. Then <img alt="{E}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BE%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{E}"/> depends only on <img alt="{x_1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{x_1}"/>. Whether <img alt="{\textsf{free}(f,I,\alpha)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctextsf%7Bfree%7D%28f%2CI%2C%5Calpha%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\textsf{free}(f,I,\alpha)}"/> holds depends entirely on <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{1}"/> not belonging to <img alt="{I}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BI%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{I}"/>. If <img alt="{m = n/c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm+%3D+n%2Fc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{m = n/c}"/> for some <img alt="{c &gt; 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc+%3E+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{c &gt; 1}"/> then it holds with constant probability, and the framework gives </p>
<p align="center"><img alt="\displaystyle  L(E) \gtrdot c^2. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++L%28E%29+%5Cgtrdot+c%5E2.+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="\displaystyle  L(E) \gtrdot c^2. "/></p>
<p>Well, OK, we really know <img alt="{L(E) = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL%28E%29+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{L(E) = 1}"/> so this is where the overhead hidden by <img alt="{\gtrdot}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cgtrdot%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\gtrdot}"/> can’t be ignored. But at least this illustrates how the framework doesn’t get too excited about a frequently alternating numerical function. Similar remarks apply when the function is multiples of <img alt="{2^k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5Ek%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{2^k}"/> where <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{k}"/> is small. </p>
<p>
</p><p/><h2> A Prime Objective </h2><p/>
<p/><p>
We would like to apply the random restrictions method to the Boolean function <img alt="{\pi(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\pi(x)}"/> that identifies whether the <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{n}"/>-bit binary string <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{x}"/> denotes a prime number. It has been known for decades that the Boolean circuit complexity of <img alt="{\pi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\pi}"/> is polynomial. This follows from the existence of a polynomial random algorithm for <img alt="{\pi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\pi}"/> due to <a href="https://en.wikipedia.org/wiki/Solovay-Strassen_primality_test">Solvay-Strassen</a> or the later <a href="https://en.wikipedia.org/wiki/Miller-Rabin_primality_test">Miller-Rabin</a> algorithm and Adleman’s <a href="https://ieeexplore.ieee.org/abstract/document/4567965">connection</a> between such algorithms and Boolean circuit complexity.</p>
<p>
There are <a href="https://www.sciencedirect.com/science/article/pii/S0022000000917252">strong</a> lower <a href="https://www.sciencedirect.com/science/article/pii/S0304397504001884">bounds</a> on special circuit models, but nothing so general as formulas, let alone unrestricted circuits. Certainly <img alt="{\pi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\pi}"/> is a harder function that parity, but we don’t know of a quadratic formula lower bound for it. Can we prove one in the framework?</p>
<p/><p>
Our intuition comes from considering various ways in which the primes are dense and uniformly—but not too regularly—distributed. Two simple ways are:</p>
<ol>
<li>
The average size gap between prime numbers is <img alt="{O(\log n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%28%5Clog+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{O(\log n)}"/>. <p/>
</li><li>
The maximum size gap between prime numbers is <img alt="{O(\log^{2} n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%28%5Clog%5E%7B2%7D+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{O(\log^{2} n)}"/>.
</li></ol>
<p>
The first is of course a consequence of the prime number theorem. The second follows from the widely believed Cramér <a href="https://en.wikipedia.org/wiki/Cramer%27s_conjecture">conjecture</a>. </p>
<p>
We will not really need this conjecture—we will not need it to hold everywhere. Our basic framework will only need it to hold for a positive fraction of small intervals of numbers that we sample. What we need instead is for a positive-fraction version to hold under a more liberal notion of “gap.” </p>
<p>
Here is an outline to try to prove a formula size lower bound of <img alt="{n^{2-\epsilon}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%5E%7B2-%5Cepsilon%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{n^{2-\epsilon}}"/> on <img alt="{\pi(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\pi(x)}"/>, for some <img alt="{\epsilon &gt; 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon+%3E+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\epsilon &gt; 0}"/>. Let 	</p>
<p align="center"><img alt="\displaystyle  t = n^{1-\epsilon}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++t+%3D+n%5E%7B1-%5Cepsilon%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="\displaystyle  t = n^{1-\epsilon}. "/></p>
<p>We will use the random restriction method for <img alt="{p = 1/t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp+%3D+1%2Ft%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{p = 1/t}"/>. Apply the method. The issue is now if we leave only <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{m}"/> input bits unset, then what is the probability that 	</p>
<p align="center"><img alt="\displaystyle  \textsf{free}(\pi,I,\alpha)? " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Ctextsf%7Bfree%7D%28%5Cpi%2CI%2C%5Calpha%29%3F+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="\displaystyle  \textsf{free}(\pi,I,\alpha)? "/></p>
<p>Certainly we cannot always leave <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{1}"/> bit unset like with the XOR function. Look at this: 	</p>
<p align="center"><img alt="\displaystyle  11*111. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++11%2A111.+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="\displaystyle  11*111. "/></p>
<p>The input is either 	</p>
<p align="center"><img alt="\displaystyle  111111 = 63 \text{ or } 110111 = 55 . " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++111111+%3D+63+%5Ctext%7B+or+%7D+110111+%3D+55+.+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="\displaystyle  111111 = 63 \text{ or } 110111 = 55 . "/></p>
<p>And both are not a prime. In general, our finger has come to rest on the question of what is known or can be shown about the behavior of the set of primes on “hypercubic” sets—that is, sets that add or subtract all sums from a selected subset of the powers of <img alt="{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{2}"/>.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
There must be other lower bounds on the primes. We cannot seem to find them. Any help?</p>
<p/></font></font></div>
    </content>
    <updated>2021-01-14T16:51:43Z</updated>
    <published>2021-01-14T16:51:43Z</published>
    <category term="All Posts"/>
    <category term="History"/>
    <category term="Ideas"/>
    <category term="Oldies"/>
    <category term="People"/>
    <category term="primes"/>
    <category term="Proofs"/>
    <category term="Results"/>
    <category term="Bella Subbotovskaya"/>
    <category term="circuit complexity"/>
    <category term="formula complexity"/>
    <category term="Johan Hastad"/>
    <category term="lower bounds"/>
    <category term="random restrictions"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2021-01-15T18:37:42Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=20949</id>
    <link href="https://gilkalai.wordpress.com/2021/01/14/to-cheer-you-up-in-difficult-times-17-amazing-the-erdos-faber-lovasz-conjecture-for-large-n-was-proved-by-dong-yeap-kang-tom-kelly-daniela-kuhn-abhishek-methuku-and-deryk-osthus/" rel="alternate" type="text/html"/>
    <title>To cheer you up in difficult times 17: Amazing! The Erdős-Faber-Lovász conjecture (for large n) was proved by Dong Yeap Kang, Tom Kelly, Daniela Kühn, Abhishek Methuku, and Deryk Osthus!</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Dong Yeap Kang, Tom Kelly, Daniela Kühn, Abhishek Methuku, and Deryk Osthus have just uploaded a paper to the arXive, A proof of the Erdős-Faber-Lovász conjecture. (I am thankful to Nati Linial and Ryan Alweiss for telling me about it.) … <a href="https://gilkalai.wordpress.com/2021/01/14/to-cheer-you-up-in-difficult-times-17-amazing-the-erdos-faber-lovasz-conjecture-for-large-n-was-proved-by-dong-yeap-kang-tom-kelly-daniela-kuhn-abhishek-methuku-and-deryk-osthus/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Dong Yeap Kang, Tom Kelly, Daniela Kühn, Abhishek Methuku, and Deryk Osthus have just uploaded a paper to the arXive, <a href="https://arxiv.org/abs/2101.04698">A proof of the Erdős-Faber-Lovász conjecture</a>. (I am thankful to Nati Linial and Ryan <span class="qu"><span class="gD">Alweiss for telling me about it.)</span></span></p>
<p>Here is one formulation of the conjecture:</p>
<p><strong>Erdős-Faber-Lovász Conjecture:</strong> Let <img alt="F" class="latex" src="https://s0.wp.com/latex.php?latex=F&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="F"/> be a family of <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="k"/>-subsets of <img alt="\{1,2,\dots,n\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B1%2C2%2C%5Cdots%2Cn%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="\{1,2,\dots,n\}"/>. Suppose that every two sets in <img alt="F" class="latex" src="https://s0.wp.com/latex.php?latex=F&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="F"/> have at most one element in common, then <img alt="F" class="latex" src="https://s0.wp.com/latex.php?latex=F&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="F"/> can be divided into at most <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="n"/> families so that every two sets in each of these families are disjoint.</p>
<p>Using some standard hypergraph jargon the conjecture can be stated as follows:</p>
<p><strong>Erdős-Faber-Lovász Conjecture: </strong>The chromatic index of any linear hypergraph on <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="n"/> vertices is at most <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="n"/>.</p>
<p>Here a linear hypergraph is a hypergraph where every two edges share at most one vertex. The chromatic index of a hypergraph is the number of colors needed to color the edges so that  every two intersecting edges have distinct colors.</p>
<p>The new result asserts</p>
<p><strong>Theorem</strong>  (Kang, Kelly, Kühn, Methuku, and Osthus): For every sufficiently large <em>n</em>, every linear hypergraph <em>H</em> on <em>n</em> vertices has chromatic index at most <em>n</em>.</p>
<p>A stability versions of this result, which confirm a prediction of Jeff Kahn, is also provided. Of course, it will be interesting to settle the conjecture for all values of n.</p>
<p>This is an amazing breakthrough! Congratulations!</p>
<p><a href="https://gilkalai.files.wordpress.com/2021/01/efl3.png"><img alt="" class="alignnone size-full wp-image-20963" src="https://gilkalai.files.wordpress.com/2021/01/efl3.png?w=640"/></a></p>
<p>(from Wikipedea)</p>
<p> </p>
<p><a href="https://gilkalai.files.wordpress.com/2021/01/efl.png"><img alt="" class="alignnone size-full wp-image-20959" height="194" src="https://gilkalai.files.wordpress.com/2021/01/efl.png?w=640&amp;h=194" width="640"/></a></p>
<p><span style="color: #800000;"><strong>Daniella Kühn, Deryk Osthus, Tom Kelly, and Abhishek Methuku</strong>  (I will add a picture of <strong>Dong Yeap Kang</strong> when I will find Update: found! see below.)</span></p>
<p><a href="https://gilkalai.files.wordpress.com/2021/01/kang.jpg"><img alt="" class="alignnone size-thumbnail wp-image-20969" height="150" src="https://gilkalai.files.wordpress.com/2021/01/kang.jpg?w=150&amp;h=150" width="150"/></a></p>
<h2>A little more</h2>
<p>Background and links: Here is the <a href="https://en.wikipedia.org/wiki/Erd%C5%91s%E2%80%93Faber%E2%80%93Lov%C3%A1sz_conjecture">Wikipedea</a> article. We mentioned the conjecture in <a href="https://gilkalai.wordpress.com/2011/06/30/around-borsuks-conjecture-1-some-problems/">this post</a> and <a href="https://gilkalai.wordpress.com/2013/09/04/around-borsuks-conjecture-3-how-to-save-borsuks-conjecture/">this one</a>.</p>
<p><strong>Matching and Fractional version</strong>. In 1982 Paul Seymour proved that any linear hypergraph <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="H"/> has a matching of size <img alt="e(H)/n" class="latex" src="https://s0.wp.com/latex.php?latex=e%28H%29%2Fn&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="e(H)/n"/>. In 1992 Jeff Kahn and Paul Seymour proved that the fractional chromatic index of any linear hypergraph on <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="n"/> vertices is at most <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="n"/>.</p>
<p><strong>Approximate version via the semi random method.</strong> In 1992 Jeff Kahn proved that chromatic index of any linear hypergraph on <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="n"/> vertices is at most <img alt="n(1+o(1))" class="latex" src="https://s0.wp.com/latex.php?latex=n%281%2Bo%281%29%29&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="n(1+o(1))"/>. Kahn used the Rödl nibble (aka semi-random) method. Kahn extended the result to list-coloring.</p>
<h3 style="text-align: center;"><a href="https://gilkalai.files.wordpress.com/2021/01/jeffk.png"><img alt="" class="alignnone size-full wp-image-20960" src="https://gilkalai.files.wordpress.com/2021/01/jeffk.png?w=640"/></a></h3>
<h3>Open problems</h3>
<p>There are many related open questions and some are mentioned in the paper. It will be interesting to prove EFL conjecture for all values of <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="n"/>. EFL-conjecture extends to  beautiful generalization of Vizing’s theorem which is still open. Also the EFL-conjecture for <em>list coloring </em>is still open<em>. </em>See also this 1994 article by Jeff Kahn on <a href="http://www.mathunion.org/ICM/ICM1994.2/Main/icm1994.2.1353.1362.ocr.pdf">Hypergraphs matching, covering and coloring problems</a>.</p>
<p>Another interesting problem is:</p>
<p><strong>The restricted Larman’s conjecture:</strong> Let <img alt="F" class="latex" src="https://s0.wp.com/latex.php?latex=F&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="F"/> be an intersecting family of <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="k"/>-subsets of <img alt="\{1,2,\dots,n\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B1%2C2%2C%5Cdots%2Cn%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="\{1,2,\dots,n\}"/>.  Then <img alt="F" class="latex" src="https://s0.wp.com/latex.php?latex=F&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="F"/> can be divided into at most <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="n"/> 2-intersecting families, namely so that every two sets in each of these families have at least <img alt="2" class="latex" src="https://s0.wp.com/latex.php?latex=2&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="2"/> elements in common.</p>
<p><strong>Little Update:</strong> A few more details on the last problem. As far as I know for the restricted Larman conjecture it is not even known that <img alt="F" class="latex" src="https://s0.wp.com/latex.php?latex=F&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="F"/> can always be divided into <img alt="(1+o(1))" class="latex" src="https://s0.wp.com/latex.php?latex=%281%2Bo%281%29%29&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="(1+o(1))"/> 2-intersecting families.</p>
<p>Now, call G strongly 2-intersecting if the intersection of all sets in <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="G"/> has at least two elements.  Furedi and Seymour proved that F can be <em>fractionally covered</em> by <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="n"/> strongly 2-intersecting subfamilies. They conjectured that F can always be covered by <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="n"/> strongly 2-intersecting families, however Jeff Kahn and I disproved this conjecture.</p></div>
    </content>
    <updated>2021-01-14T13:51:35Z</updated>
    <published>2021-01-14T13:51:35Z</published>
    <category term="Combinatorics"/>
    <category term="Updates"/>
    <category term="Abhishek Methuku"/>
    <category term="Daniela K&#xFC;hn"/>
    <category term="Deryk Osthus"/>
    <category term="Dong Yeap Kang"/>
    <category term="Erdos-Faber-Lovasz conjecture"/>
    <category term="Tom Kelly"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2021-01-15T18:37:37Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/01/14/postdoc-at-hse-university-apply-by-february-14-2021/</id>
    <link href="https://cstheory-jobs.org/2021/01/14/postdoc-at-hse-university-apply-by-february-14-2021/" rel="alternate" type="text/html"/>
    <title>Postdoc at HSE University (apply by February 14, 2021)</title>
    <summary>HSE University’s Faculty of Computer Science now receives applications for the postdoctoral positions in several laboratories. At present, there are ten open postdoctoral positions in ten out of twelve Faculty’s laboratories. Research areas range from algebraic topology and bioinformatics to data analysis, neural networks and process mining. Website: https://cs.hse.ru/en/news/433773574.html Email: abasov@hse.ru</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>HSE University’s Faculty of Computer Science now receives applications for the postdoctoral positions in several laboratories.<br/>
At present, there are ten open postdoctoral positions in ten out of twelve Faculty’s laboratories. Research areas range from algebraic topology and bioinformatics to data analysis, neural networks and process mining.</p>
<p>Website: <a href="https://cs.hse.ru/en/news/433773574.html">https://cs.hse.ru/en/news/433773574.html</a><br/>
Email: abasov@hse.ru</p></div>
    </content>
    <updated>2021-01-14T12:42:07Z</updated>
    <published>2021-01-14T12:42:07Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-01-15T18:37:48Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2101.05235</id>
    <link href="http://arxiv.org/abs/2101.05235" rel="alternate" type="text/html"/>
    <title>Space-Efficient Algorithms for Reachability in Geometric Graphs</title>
    <feedworld_mtime>1610582400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bhore:Sujoy.html">Sujoy Bhore</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jain:Rahul.html">Rahul Jain</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2101.05235">PDF</a><br/><b>Abstract: </b>The problem of graph Reachability is to decide whether there is a path from
one vertex to another in a given graph. In this paper, we study the
Reachability problem on three distinct graph families -- intersection graphs of
Jordan regions, unit contact disk graphs (penny graphs), and chordal graphs.
For each of these graph families, we present space-efficient algorithms for the
Reachability problem. In order to obtain these results, we use the vertex
separator of these graphs effectively, and design space-efficient algorithms to
find such separators. The constructions of the separators presented here can be
of independent interest.
</p></div>
    </summary>
    <updated>2021-01-14T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2021-01-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2101.05223</id>
    <link href="http://arxiv.org/abs/2101.05223" rel="alternate" type="text/html"/>
    <title>Distributed storage algorithms with optimal tradeoffs</title>
    <feedworld_mtime>1610582400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Luby:Michael.html">Michael Luby</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Richardson:Thomas.html">Thomas Richardson</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2101.05223">PDF</a><br/><b>Abstract: </b>One of the primary objectives of a distributed storage system is to reliably
store large amounts of source data for long durations using a large number $N$
of unreliable storage nodes, each with $c$ bits of storage capacity. Storage
nodes fail randomly over time and are replaced with nodes of equal capacity
initialized to zeroes, and thus bits are erased at some rate $e$. To maintain
recoverability of the source data, a repairer continually reads data over a
network from nodes at an average rate $r$, and generates and writes data to
nodes based on the read data.
</p>
<p>The distributed storage source capacity is the maximum amount of source that
can be reliably stored for long periods of time. Previous research shows that
asymptotically the distributed storage source capacity is at most
$\left(1-\frac{e}{2 \cdot r}\right) \cdot N \cdot c$ as $N$ and $r$ grow.
</p>
<p>In this work we introduce and analyze algorithms such that asymptotically the
distributed storage source data capacity is at least the above equation. Thus,
the above equation expresses a fundamental trade-off between network traffic
and storage overhead to reliably store source data.
</p></div>
    </summary>
    <updated>2021-01-14T22:45:17Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-01-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2101.05142</id>
    <link href="http://arxiv.org/abs/2101.05142" rel="alternate" type="text/html"/>
    <title>Resolution with Symmetry Rule applied to Linear Equations</title>
    <feedworld_mtime>1610582400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schweitzer:Pascal.html">Pascal Schweitzer</a>, Constantin Seebach <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2101.05142">PDF</a><br/><b>Abstract: </b>This paper considers the length of resolution proofs when using
Krishnamurthy's classic symmetry rules. We show that inconsistent linear
equation systems of bounded width over a fixed finite field $\mathbb{F}_p$ with
$p$ a prime have, in their standard encoding as CNFs, polynomial length
resolutions when using the local symmetry rule (SRC-II).
</p>
<p>As a consequence it follows that the multipede instances for the graph
isomorphism problem encoded as CNF formula have polynomial length resolution
proofs. This contrasts exponential lower bounds for
individualization-refinement algorithms on these graphs.
</p>
<p>For the Cai-F\"urer-Immerman graphs, for which Tor\'an showed exponential
lower bounds for resolution proofs (SAT 2013), we also show that already the
global symmetry rule (SRC-I) suffices to allow for polynomial length proofs.
</p></div>
    </summary>
    <updated>2021-01-14T22:38:30Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2021-01-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2101.05033</id>
    <link href="http://arxiv.org/abs/2101.05033" rel="alternate" type="text/html"/>
    <title>Practical Fully Dynamic Minimum Cut Algorithms</title>
    <feedworld_mtime>1610582400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Henzinger:Monika.html">Monika Henzinger</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Noe:Alexander.html">Alexander Noe</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schulz:Christian.html">Christian Schulz</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2101.05033">PDF</a><br/><b>Abstract: </b>We present a practically efficient algorithm for maintaining a global minimum
cut in large dynamic graphs under both edge insertions and deletions. While
there has been theoretical work on this problem, our algorithm is the first
implementation of a fully-dynamic algorithm. The algorithm uses the theoretical
foundation and combines it with efficient and finely-tuned implementations to
give an algorithm that can maintain the global minimum cut of a graph with
rapid update times. We show that our algorithm gives up to multiple orders of
magnitude speedup compared to static approaches both on edge insertions and
deletions.
</p></div>
    </summary>
    <updated>2021-01-14T22:38:56Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-01-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2101.05032</id>
    <link href="http://arxiv.org/abs/2101.05032" rel="alternate" type="text/html"/>
    <title>Round-Competitive Algorithms for Uncertainty Problems with Parallel Queries</title>
    <feedworld_mtime>1610582400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Erlebach:Thomas.html">Thomas Erlebach</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hoffmann:Michael.html">Michael Hoffmann</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lima:Murilo_S=_de.html">Murilo S. de Lima</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2101.05032">PDF</a><br/><b>Abstract: </b>The area of computing with uncertainty considers problems where some
information about the input elements is uncertain, but can be obtained using
queries. For example, instead of the weight of an element, we may be given an
interval that is guaranteed to contain the weight, and a query can be performed
to reveal the weight. While previous work has considered models where queries
are asked either sequentially (adaptive model) or all at once (non-adaptive
model), and the goal is to minimize the number of queries that are needed to
solve the given problem, we propose and study a new model where $k$ queries can
be made in parallel in each round, and the goal is to minimize the number of
query rounds. We use competitive analysis and present upper and lower bounds on
the number of query rounds required by any algorithm in comparison with the
optimal number of query rounds. Given a set of uncertain elements and a family
of $m$ subsets of that set, we present an algorithm for determining the value
of the minimum of each of the subsets that requires at most $(2+\varepsilon)
\cdot \mathrm{opt}_k+\mathrm{O}\left(\frac{1}{\varepsilon} \cdot \lg m\right)$
rounds for every $0&lt;\varepsilon&lt;1$, where $\mathrm{opt}_k$ is the optimal
number of rounds, as well as nearly matching lower bounds. For the problem of
determining the $i$-th smallest value and identifying all elements with that
value in a set of uncertain elements, we give a $2$-round-competitive
algorithm. We also show that the problem of sorting a family of sets of
uncertain elements admits a $2$-round-competitive algorithm and this is the
best possible.
</p></div>
    </summary>
    <updated>2021-01-14T22:42:03Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-01-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2101.05031</id>
    <link href="http://arxiv.org/abs/2101.05031" rel="alternate" type="text/html"/>
    <title>Memory-Efficient Modeling and Slicing of Large-Scale Adaptive Lattice Structures</title>
    <feedworld_mtime>1610582400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liu:Shengjun.html">Shengjun Liu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liu:Tao.html">Tao Liu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zou:Qiang.html">Qiang Zou</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Weiming.html">Weiming Wang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Doubrovski:Eugeni_L=.html">Eugeni L. Doubrovski</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Charlie_C=_L=.html">Charlie C. L. Wang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2101.05031">PDF</a><br/><b>Abstract: </b>Lattice structures have been widely used in various applications of additive
manufacturing due to its superior physical properties. If modeled by triangular
meshes, a lattice structure with huge number of struts would consume massive
memory. This hinders the use of lattice structures in large-scale applications
(e.g., to design the interior structure of a solid with spatially graded
material properties). To solve this issue, we propose a memory-efficient method
for the modeling and slicing of adaptive lattice structures. A lattice
structure is represented by a weighted graph where the edge weights store the
struts' radii. When slicing the structure, its solid model is locally evaluated
through convolution surfaces and in a streaming manner. As such, only limited
memory is needed to generate the toolpaths of fabrication. Also, the use of
convolution surfaces leads to natural blending at intersections of struts,
which can avoid the stress concentration at these regions. We also present a
computational framework for optimizing supporting structures and adapting
lattice structures with prescribed density distributions. The presented methods
have been validated by a series of case studies with large number (up to 100M)
of struts to demonstrate its applicability to large-scale lattice structures.
</p></div>
    </summary>
    <updated>2021-01-14T22:50:40Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2021-01-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2101.04914</id>
    <link href="http://arxiv.org/abs/2101.04914" rel="alternate" type="text/html"/>
    <title>A Tail Estimate with Exponential Decay for the Randomized Incremental Construction of Search Structures</title>
    <feedworld_mtime>1610582400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gudmundsson:Joachim.html">Joachim Gudmundsson</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Seybold:Martin_P=.html">Martin P. Seybold</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2101.04914">PDF</a><br/><b>Abstract: </b>We revisit the randomized incremental construction of the Trapezoidal Search
DAG (TSD) for a set of $n$ non-crossing segments, e.g. edges from planar
subdivisions. It is well known that this point location structure has ${\cal
O}(n)$ expected size and ${\cal O}(n \ln n)$ expected construction time.
</p>
<p>Our main result is an improved tail bound, with exponential decay, for the
size of the TSD: There is a constant such that the probability for a TSD to
exceed its expected size by more than this factor is at most $1/e^n$. This
yields improved bounds on the TSD construction and their maintenance. I.e. TSD
construction takes with high probability ${\cal O}(n \ln n)$ time and TSD size
can be made worst case ${\cal O}(n)$ with an expected rebuild cost of ${\cal
O}(1)$.
</p>
<p>The proposed analysis technique also shows that the expected depth is ${\cal
O}(\ln n)$, which partially solves a recent conjecture by Hemmer et al. that is
used in the CGAL implementation of the TSD.
</p></div>
    </summary>
    <updated>2021-01-14T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2021-01-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2101.04818</id>
    <link href="http://arxiv.org/abs/2101.04818" rel="alternate" type="text/html"/>
    <title>Improved Hierarchical Clustering on Massive Datasets with Broad Guarantees</title>
    <feedworld_mtime>1610582400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hajiaghayi:MohammadTaghi.html">MohammadTaghi Hajiaghayi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Knittel:Marina.html">Marina Knittel</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2101.04818">PDF</a><br/><b>Abstract: </b>Hierarchical clustering is a stronger extension of one of today's most
influential unsupervised learning methods: clustering. The goal of this method
is to create a hierarchy of clusters, thus constructing cluster evolutionary
history and simultaneously finding clusterings at all resolutions. We propose
four traits of interest for hierarchical clustering algorithms: (1) empirical
performance, (2) theoretical guarantees, (3) cluster balance, and (4)
scalability. While a number of algorithms are designed to achieve one to two of
these traits at a time, there exist none that achieve all four.
</p>
<p>Inspired by Bateni et al.'s scalable and empirically successful Affinity
Clustering [NeurIPs 2017], we introduce Affinity Clustering's successor,
Matching Affinity Clustering. Like its predecessor, Matching Affinity
Clustering maintains strong empirical performance and uses Massively Parallel
Communication as its distributed model. Designed to maintain provably balanced
clusters, we show that our algorithm achieves good, constant factor
approximations for Moseley and Wang's revenue and Cohen-Addad et al.'s value.
We show Affinity Clustering cannot approximate either function. Along the way,
we also introduce an efficient $k$-sized maximum matching algorithm in the MPC
model.
</p></div>
    </summary>
    <updated>2021-01-14T22:46:08Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-01-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://toc4fairness.org/?p=1276</id>
    <link href="https://toc4fairness.org/launching-toc4fairness/" rel="alternate" type="text/html"/>
    <title>Launching TOC4Fairness</title>
    <summary>I am excited to launch the Simons Foundation’s Collaboration on the Theory of Algorithmic Fairness, funded by the Simons Foundation. This is a large-scale multi-institutional effort to accelerate the (already ...</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I am excited to launch the <a href="https://toc4fairness.org/">Simons Foundation’s Collaboration on the Theory of Algorithmic Fairness</a>, funded by<a href="https://www.simonsfoundation.org/"> the Simons Foundation</a>. This is a large-scale multi-institutional effort to accelerate the (already powerful) impact of TOC on the emerging area of algorithmic fairness. Beyond the ambitious research goals of this project (which we will discuss in future posts), we hope it will play an important role in community building and bridge building to other fields of research. In addition to launching <a href="https://toc4fairness.org/category/blog/">this blog</a> and <a href="https://toc4fairness.org/">our site</a>, we are also launching a <a href="https://toc4fairness.org/category/events/">research seminar</a> that will feature a diverse set of talks. We are very exited to have  <a href="https://toc4fairness.org/inaugural-meeting-toc4fairness-seminar-annette-zimmermann/">Annette Zimmermann</a> as our inaugural speaker (a week from today). </p>



<p>If you want to join our seminar, please email toc4fairness-director@cs.stanford.edu and we will add you to our email list (which we will be careful not to overuse).</p></div>
    </content>
    <updated>2021-01-13T15:45:36Z</updated>
    <published>2021-01-13T15:45:36Z</published>
    <category term="Blog"/>
    <author>
      <name>Omer Reingold</name>
    </author>
    <source>
      <id>https://toc4fairness.org</id>
      <logo>https://i1.wp.com/toc4fairness.org/wp-content/uploads/2020/10/cropped-favicon.png?fit=32%2C32&amp;ssl=1</logo>
      <link href="https://toc4fairness.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://toc4fairness.org" rel="alternate" type="text/html"/>
      <subtitle>a simons collaboration project</subtitle>
      <title>TOC for Fairness</title>
      <updated>2021-01-15T18:39:08Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/005</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/005" rel="alternate" type="text/html"/>
    <title>TR21-005 |  Robust testing of low-dimensional functions | 

	Anindya De, 

	Elchanan Mossel, 

	Joe Neeman</title>
    <summary>A natural problem in high-dimensional inference is to decide if a classifier $f:\mathbb{R}^n \rightarrow \{-1,1\}$ depends on a small number of linear directions of its input data. Call a function $g: \mathbb{R}^n \rightarrow \{-1,1\}$, a linear $k$-junta if it is completely determined by some $k$-dimensional subspace of the input space. A recent work of the authors showed that linear $k$-juntas are testable. Thus there exists an algorithm to distinguish between: 
1. $f: \mathbb{R}^n \rightarrow \{-1,1\}$ which is a linear $k$-junta with surface area $s$, 
2. $f$ is $\epsilon$-far from any linear $k$-junta with surface area $(1+\epsilon)s$, where the query complexity of the algorithm is independent of the ambient dimension $n$.
  Following the surge of interest in noise-tolerant property testing, in this paper we prove a noise-tolerant (or robust) version of this result. Namely, we give an algorithm which given any $c&gt;0$, $\epsilon&gt;0$, distinguishes between 
1. $f: \mathbb{R}^n \rightarrow \{-1,1\}$ has correlation at least $c$ with some linear $k$-junta with surface area $s$. 
2. $f$ has correlation at most $c-\epsilon$ with any linear $k$-junta with surface area at most $s$. The query complexity of our tester is $k^{\mathrm{poly}(s/\epsilon)}$.

  Using our techniques, we also obtain a fully noise tolerant tester with the same query complexity for any class $\mathcal{C}$ of linear $k$-juntas with surface area bounded by $s$. As a consequence, we obtain a fully noise tolerant tester with query complexity $k^{O(\mathrm{poly}(\log k/\epsilon))}$ for the class of intersection of $k$-halfspaces (for constant $k$) over the Gaussian space. Our query complexity is independent of the ambient dimension $n$. Previously, no non-trivial noise tolerant testers were known even for a single halfspace.</summary>
    <updated>2021-01-12T23:28:41Z</updated>
    <published>2021-01-12T23:28:41Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-01-15T18:37:33Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>http://sarielhp.org/blog/?p=9406</id>
    <link href="https://sarielhp.org/blog/?p=9406" rel="alternate" type="text/html"/>
    <title>How to have irritating files in subdirectory…</title>
    <summary>If you are formatting a paper for lipics, but don’t want all their files in the paper directory, add the following to the top of the main latex file: This is under the assumption that lipics/ subdirectory contains the .cls file.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>If you are formatting a paper for lipics, but don’t want all their files in the paper directory, add the following to the top of the main latex file: </p>



<pre class="wp-block-code"><code>\makeatletter
\def\input@path{{lipics/}{../lipics/}} 
\makeatother
\documentclass[a4paper,USenglish,cleveref,autoref,thm-restate]%
{socg-lipics-v2019}</code></pre>



<p>This is under the assumption that lipics/ subdirectory contains the .cls file.</p></div>
    </content>
    <updated>2021-01-12T15:53:53Z</updated>
    <published>2021-01-12T15:53:53Z</published>
    <category term="Tweet"/>
    <category term="latex"/>
    <category term="Research"/>
    <author>
      <name>Sariel</name>
    </author>
    <source>
      <id>https://sarielhp.org/blog</id>
      <link href="https://sarielhp.org/blog/?feed=rss2" rel="self" type="application/atom+xml"/>
      <link href="https://sarielhp.org/blog" rel="alternate" type="text/html"/>
      <subtitle>Sariel's blog</subtitle>
      <title>Vanity of Vanities, all is Vanity</title>
      <updated>2021-01-15T18:37:27Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://agtb.wordpress.com/?p=3510</id>
    <link href="https://agtb.wordpress.com/2021/01/11/call-for-proposals-ec-2021-workshops-and-tutorials/" rel="alternate" type="text/html"/>
    <title>CALL FOR PROPOSALS: EC 2021 WORKSHOPS AND TUTORIALS</title>
    <summary>The EC 2021 conference invites proposals for tutorials and workshops to be held in conjunction with the ACM Conference on Economics and Computation (ACM EC). EC’21 will be held either virtually or in a hybrid format. In the latter case, tutorial/workshop organizers will have the opportunity to decide whether to hold their event in person […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="http://ec21.sigecom.org/">The EC 2021 conference</a> invites proposals for tutorials and workshops to be held in conjunction with the ACM Conference on Economics and Computation (ACM EC). EC’21 will be held either virtually or in a hybrid format. In the latter case, tutorial/workshop organizers will have the opportunity to decide whether to hold their event in person or remotely.</p>



<h3>Tutorials</h3>



<p>Tutorials provide an opportunity to educate the community about emerging topics of interest, or about topics from related fields that merit additional attention from the EC community.  A tutorial is an opportunity to invite colleagues and young researchers to get excited about a well-defined topic, to prepare them to dive into the literature and to guide them to the most exciting developments and open problems. Typically, tutorials run for half a day (3-3.5 hours) and consist of a series of presentations by experts in the field.</p>



<p>Tutorial proposals should contain:</p>



<ul><li>the title of the tutorial</li><li>the names, contact information, and short biographies of the organizers</li><li>a description of the tutorial theme</li><li>the organization/format of the tutorial</li><li>any related tutorials that have been run</li><li>required facilities for the tutorial</li></ul>



<p>Tutorial proposals should be emailed to <a href="mailto:ec21-tutorial-chairs@acm.org" rel="noreferrer noopener" target="_blank">ec21-tutorial-chairs@acm.org</a>.</p>



<h3>Workshops</h3>



<p>Workshops provide an opportunity to bring together researchers to discuss emerging areas of research in an informal forum. Workshop schedules should be designed to promote discussion and debate. A workshop may include invited talks, contributed talks, panel discussions, poster sessions, open problem sessions, presentations of work in progress, or any other activities that stimulate new ideas for research. It is up to the workshop organizers to determine the format and technical content of each workshop and to solicit contributions, but we encourage workshops that devote some time to contributed content.</p>



<p>Workshop proposals should contain:</p>



<ul><li>the title of the workshop</li><li>the names, contact information, and short biographies of the organizers</li><li>the names of confirmed or candidate participants</li><li>a description of the workshop theme</li><li>the reviewing process for participants</li><li>the organization/format of the workshop</li><li>any previous versions of the workshop</li><li>required facilities for the workshop</li><li>the desired workshop length (half-day, full day, etc.)</li></ul>



<p>For accepted workshops, the desired length will be honored as closely as possible.</p>



<p>We especially encourage proposals that bring together participants with diverse backgrounds and experience.</p>



<p>Workshop proposals should be emailed to <a href="mailto:ec21-workshop-chairs@acm.org" rel="noreferrer noopener" target="_blank">ec21-workshop-chairs@acm.org</a>.</p>



<h3>Key dates:</h3>



<p>March 1, 2021: Due date for submitting workshop or tutorial proposal</p>



<p>March 22, 2021: Tutorial &amp; workshop proposal accept/reject notifications</p>



<p>July 19, 2021: Conference Tutorials</p>



<p>July 20-22, 2021: Conference technical program</p>



<p>July 23, 2021: Conference Workshops</p>



<h3>Tutorial co-chairs</h3>



<p>Shengwu Li, Harvard University</p>



<p>Sigal Oren, Ben-Gurion University</p>



<h3>Workshop co-chairs</h3>



<p>Hu Fu, University of British Columbia</p>



<p>Annie Liang, Northwestern University</p>



<p/></div>
    </content>
    <updated>2021-01-11T08:41:27Z</updated>
    <published>2021-01-11T08:41:27Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Noam Nisan</name>
    </author>
    <source>
      <id>https://agtb.wordpress.com</id>
      <logo>https://secure.gravatar.com/blavatar/52ef314e11e379febf97d1a97547f4cd?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fbuttonw-com.png</logo>
      <link href="https://agtb.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://agtb.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://agtb.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://agtb.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Computation, Economics, and Game Theory</subtitle>
      <title>Turing's Invisible Hand</title>
      <updated>2021-01-15T18:37:39Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-6412374969669821012</id>
    <link href="https://blog.computationalcomplexity.org/feeds/6412374969669821012/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2021/01/the-acm-history-committee-call-for.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/6412374969669821012" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/6412374969669821012" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2021/01/the-acm-history-committee-call-for.html" rel="alternate" type="text/html"/>
    <title>The ACM History Committee call for proposals looks wrong</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p> In November I (and prob everyone in the ACM) got an email that was a call for proposal from the ACM History committee. <a href="https://history.acm.org/wp-content/uploads/2020/11/ACM-fellowship_CFP_2021-final-1.pdf">Here</a> is a pointer to it. </p><p>One of the passages in it just seems wrong to me:</p><p><i>This fellowship program is designed to support research and/or curatorial projects related to ACM's professional and educational activities and/or to ACM's rich institutional history including its organization, SIG activities, and conferences. </i></p><p>I will give  examples of history projects that are interesting but do not fit the description. I challenge you to give me a history project that is interesting that does fit the bill. </p><p>1) Compare and contrast how NP-completeness developed in America and in the USSR. For the USSR side it would be an expansion of  Trakhtenbrot's article <a href="https://drdoane.com/wp-content/uploads/2020/08/survey_of_russian_approaches_to_perebor.pdf">here</a>. OH, no good, Leonid Levin was not a member of the ACM.</p><p>2) Measure how various CS fields have changed by looking at the topics on the CALL FOR PAPERS for a conference. This would be a MASSIVE expansion of my blog post on how CCC call for papers, changed , see <a href="https://blog.computationalcomplexity.org/2011/05/how-has-structures-oh-i-mean-ccc.html">here</a>. OH, I could only do ACM conferences. STOC but not FOCS. Okay, it makes perfect sense to study only ACM conference. Oh wait. IT MAKES NO SENSE WHATSOEVER.</p><p>3) When did mathematicians begin looking at P vs NP seriously? (e.g.,  In  The Handbook of Mathematical Logic from 1977 only one article mentions P vs NP: Michael Rabin's article on Decidable theories mentioned that even decidable theories may take a long time to decide and noted the importance of the P vs NP problem). How did MATH and CS  interact early on and now? This would need  one to look at math journals. How many of those are ACM? I would guess very few. </p><p>4) When did engineers begin looking at P vs NP seriously, or even notice it? Same issue as the last item. </p><p>5) Looking at how Programming lang design has changed one would have to only look at conference and journals that were ACM. And for those that were ACM but then dropped ACM you might only be able to use them up to the cutoff year. </p><p>6) Which academic studies eventually lead to practical products people can use? This is a really broad topic so one could narrow it down to just academic studies that appeared in ACM journals or conferences. Is that a good way to narrow the focus? Spoiler alert: NO.</p><p>7) I recently filled out a survey about the future of theory and if it is insular (the topic of another post surely). Most of the questions were about ``STOC-FOCS'' The people who did the survey clearly do not care that one is ACM and one is IEEE. Does anyone? I ask non-rhetorically. </p><p>Despite the capitol letters, I am not so much mad as puzzled. So I ask non-rhetorically: </p><p>Q1) Did the ACM really mean for people to do history in a way where you can only use ACM materials? </p><p>Q2) If no then please rewrite the Call for Proposals. </p><p>Q3) If yes then give examples of studies that would be interesting. </p><p>I am not asking to be snarky, I really want to know. And I note that <i>interesting</i> is subjective. </p><p>(ADDED LATER- two historians who have worked with this kind of history left comments that indicate the grant is FINE with non-ACM stuff, so Q1 above seems to have the answer NO. Given that they should rewrite the call for proposal next time they do this. ALSO- the historians left pointers to VERY INTERESTING papers they wrote.) </p><p><i><br/></i></p><p><br/></p></div>
    </content>
    <updated>2021-01-11T04:39:00Z</updated>
    <published>2021-01-11T04:39:00Z</published>
    <author>
      <name>gasarch</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03004932739846901628</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2021-01-14T10:17:09Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/004</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/004" rel="alternate" type="text/html"/>
    <title>TR21-004 |  Junta Distance Approximation with Sub-Exponential Queries | 

	Vishnu Iyer, 

	Avishay Tal, 

	Michael Whitmeyer</title>
    <summary>Leveraging tools of De, Mossel, and Neeman [FOCS, 2019], we show two different results pertaining to the tolerant testing of juntas. Given black-box access to a Boolean function $f:\{\pm1\}^{n} \to \{\pm1\}$ we give a poly$(k, \frac{1}{\varepsilon})$ query algorithm that distinguishes between functions that are $\gamma$-close to $k$-juntas and $(\gamma+\varepsilon)$-far from $k'$-juntas, where $k' = O(\frac{k}{\varepsilon^2})$. In the non-relaxed setting, we extend our ideas to give a  $2^{\tilde{O}(\sqrt{k}/\varepsilon)}$ (adaptive) query algorithm that distinguishes between functions that are $\gamma$-close to $k$-juntas and $(\gamma+\varepsilon)$-far from $k$-juntas. To the best of our knowledge, this is the first subexponential-in-$k$ query algorithm for approximating the distance of $f$ to being a $k$-junta (previous results of Blais, Canonne, Eden,  Levi,  and  Ron [SODA, 2018] and De, Mossel, and Neeman [FOCS, 2019] required exponentially many queries in $k$). Our techniques are Fourier analytical and introduce the new notion of "normalized influences'' that might be of independent interest.</summary>
    <updated>2021-01-10T16:21:56Z</updated>
    <published>2021-01-10T16:21:56Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-01-15T18:37:33Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=20474</id>
    <link href="https://gilkalai.wordpress.com/2021/01/10/open-problem-session-of-huji-combsem-problem-5-gil-kalai-the-3%e1%b5%88-problem/" rel="alternate" type="text/html"/>
    <title>Open problem session of HUJI-COMBSEM: Problem #5, Gil Kalai – the 3ᵈ problem</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">This post continues to describe problems presented at our open problems session back in November 2020. Here is the first post in the series.  Today’s problem was presented by me, and it was an old 1989 conjecture of mine. A … <a href="https://gilkalai.wordpress.com/2021/01/10/open-problem-session-of-huji-combsem-problem-5-gil-kalai-the-3%e1%b5%88-problem/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>This post continues to describe problems presented at our open problems session back in November 2020. Here is the <a href="https://gilkalai.wordpress.com/2020/11/25/open-problem-session-of-huji-combsem-problem-1-nati-linial-turan-type-theorems-for-simplicial-complexes/">first post</a> in the series.  Today’s problem was presented by me, and it was <a href="https://idp.springer.com/authorize/casa?redirect_uri=https://link.springer.com/content/pdf/10.1007/BF01788696.pdf&amp;casa_token=tLZCajryjNcAAAAA:ij5u7eLRf5IBH0sym5BHY8q5l_H3H175bvo-ydaVfwU5nWzmOTSD0_4yQDAYwk9H-R_rxT5n1fHsxxmo-A">an old 1989 conjecture of mine</a>.</p>
<p>A convex set K is centrally symmetric if <img alt="x \in K" class="latex" src="https://s0.wp.com/latex.php?latex=x+%5Cin+K&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="x \in K"/> implies that <img alt="-x \in K" class="latex" src="https://s0.wp.com/latex.php?latex=-x+%5Cin+K&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="-x \in K"/>.</p>
<h3><strong>Conjecture:</strong> Let P be a centrally symmetric d-polytope. Then P has at least 3ᵈ non-empty faces.</h3>
<p>Here we count P itself as a face.</p>
<p><span style="color: #008000;"><strong>Before we continue</strong> let me mention</span> <a href="https://www.him.uni-bonn.de/programs/current-trimester-program/interplay-high-dimensional-geometry-probability/interplay-high-dimensional-geometry-probability-winterschool/">a winter school on “The Interplay between High-Dimensional Geometry and Probability”,</a> <span style="color: #008000;">January 11-15. Among other exciting lectures Bo’az Klartag will give 3 lectures on Yuansi Chen’s work on the KLS conjecture, that we discussed in <a href="https://gilkalai.wordpress.com/2020/12/21/to-cheer-you-up-in-difficult-times-15-yuansi-chen-achieved-a-major-breakthrough-on-bourgains-slicing-problem-and-the-kannan-lovasz-and-simonovits-conjecture/">this post</a>.</span></p>
<p><strong>Now back to the 3ᵈ conjecture. </strong>A case of equality is the <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="d"/>-dimensional cube <img alt="C_d" class="latex" src="https://s0.wp.com/latex.php?latex=C_d&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="C_d"/>. The faces of <img alt="C_d" class="latex" src="https://s0.wp.com/latex.php?latex=C_d&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="C_d"/> corresponds to (-1,1,*)-vectors of length <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="d"/>. Given such a vector it corresponds to a face of the cube whose vertices are obtained by replacing the *’s with ±1 in all possible ways.  Of course the dual of <img alt="C_d" class="latex" src="https://s0.wp.com/latex.php?latex=C_d&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="C_d"/> also has <img alt="3^d" class="latex" src="https://s0.wp.com/latex.php?latex=3%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="3^d"/> non-empty faces.</p>
<p><a href="https://gilkalai.files.wordpress.com/2021/01/octahedral_prism.png"><img alt="" class="alignnone size-medium wp-image-20912" height="300" src="https://gilkalai.files.wordpress.com/2021/01/octahedral_prism.png?w=300&amp;h=300" width="300"/></a></p>
<p> </p>
<p><a href="https://en.wikipedia.org/wiki/Schlegel_diagram" title="Schlegel diagram"><span style="color: #ff0000;">Schlegel diagram</span></a><span style="color: #ff0000;"> of the <a href="https://en.wikipedia.org/wiki/Octahedral_prism" style="color: #ff0000;" title="Octahedral prism">octahedral prism</a>, a 4-dimensional Hanner polytope.  (attribution: </span><span class="mw-mmv-source-author"><span class="mw-mmv-author mw-mmv-source"><span style="color: #ff0000;">Robert Webb’s <a class="extiw" href="https://en.wikipedia.org/wiki/Stella_(software)" style="color: #ff0000;" title="en:Stella (software)">Stella software</a> as the creator of this image along with a link to the website: <a class="external free" href="http://www.software3d.com/Stella.php" rel="nofollow" style="color: #ff0000;">http://www.software3d.com/Stella.php</a>. via Wikipedea.)</span> </span></span></p>
<h3>Some comments</h3>
<p>Here are some points raised in the discussion and further comments.</p>
<ol>
<li>There are many cases of equality – all <a href="https://en.wikipedia.org/wiki/Hanner_polytope"><em>Hanner polytopes</em></a>. Those are obtained from intervals by taking the two operations, a) Cartesian product, b) moving from a polytope P to its polar-dual P*, and apply them in all possible ways.</li>
<li><span style="color: #0000ff;">Nati asked if a <img alt="(2+\epsilon)^d" class="latex" src="https://s0.wp.com/latex.php?latex=%282%2B%5Cepsilon%29%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="(2+\epsilon)^d"/> lower bound is known. To the best of my knowledge even this is not known.</span></li>
<li>Gideon asked about the connections with <a href="https://en.wikipedia.org/wiki/Mahler_volume">Mahler’s conjecture</a> that for every d-dimentional centrally symmetric body K, <img alt="vol(K)vol(K*) \ge 4^n/n!" class="latex" src="https://s0.wp.com/latex.php?latex=vol%28K%29vol%28K%2A%29+%5Cge+4%5En%2Fn%21&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="vol(K)vol(K*) \ge 4^n/n!"/>  . Indeed the cases of equality are conjectured to be the same – the class of Hanner polytopes. (Mahler’s conjecture and its relations to combinatorics would deserve a separate post.) The recent paper <a href="https://www.sciencedirect.com/science/article/pii/S0001870818303372?casa_token=YEJdSwTFFaIAAAAA:k-e1q7dtnSZslAg5ZZYtJJQrgLiCbDE7_uNBITsrrUxOkCc5A8ThPF5CPTIcD4HUhTcVlUqeaAM" id="1oYidvdGYaQJ"><span dir="ltr">Flag numbers and floating bodies</span>‏</a> by <span dir="ltr"><a href="https://scholar.google.com/citations?user=MqLwWBgAAAAJ&amp;hl=iw&amp;oi=sra">F Besau</a>, C Schütt, EM Werner looks very relevant.</span></li>
<li>For simplicial polytopes the conjecture follows from results of Stanley (1986) and is related t0 a result by Barany and Lovasz (1982).</li>
<li>The conjecture is related to a 1979 theorem of Figiel, Lindenstrauss, and Milman that asserts that for every centrally symmetric <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="d"/> polytope <img alt="\log f_0(P) \log f_{d-1}(P) \ge \gamma d" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clog+f_0%28P%29+%5Clog+f_%7Bd-1%7D%28P%29+%5Cge+%5Cgamma+d&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="\log f_0(P) \log f_{d-1}(P) \ge \gamma d"/>, for some universal constant <img alt="\gamma" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cgamma&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="\gamma"/>.</li>
<li>A somewhat more general conjecture would be that the number of <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="k"/>-faces of the barycentric subdivision of <img alt="K" class="latex" src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="K"/> is always as large as the number of <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="k"/>-faces of the barycentric subdivision of <img alt="C_d" class="latex" src="https://s0.wp.com/latex.php?latex=C_d&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="C_d"/>. The case <img alt="k=0" class="latex" src="https://s0.wp.com/latex.php?latex=k%3D0&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="k=0"/> is the original conjecture and I regard the case <img alt="k=d-1" class="latex" src="https://s0.wp.com/latex.php?latex=k%3Dd-1&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="k=d-1"/> (sometimes referred to as the “flag-number conjecture”) as even closer to Mahler’s conjecture. See the paper by Schmidt and Ziegler, <a href="https://www.mi.fu-berlin.de/math/groups/discgeom/ziegler/Preprintfiles/127PREPRINT.pdf">Ten Problems in Geometry.</a></li>
<li>In <a href="https://arxiv.org/abs/0708.3661">this paper</a> by Raman Sanyal, Axel Werner, and Günter M. Ziegler, the conjecture is proved for <img alt="d \le 4" class="latex" src="https://s0.wp.com/latex.php?latex=d+%5Cle+4&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="d \le 4"/>. The proof is rather involved and rely on an extension of the lower bound theorem. (It does not extend to polyhedral spheres.)  The paper also gives counterexamples for two much stronger conjectures that I made in my 1989 paper.</li>
</ol>
<h3>Some further comments</h3>
<p><span id="more-20474"/></p>
<ol>
<li>Hanner polytopes form an exciting family of polytopes. They have the maximum Banach-Mazur distance from the Euclidean ball, and it is conjectured that only these polytopes attain this maximum. They also have the 2-3 Helly-property (namely every three pairwise intersecting translates have a point in common. It was proved by Lima and Jensen that this property holds only by Hanner polytopes!</li>
<li>The proof for the conjecture for d=4 involves the “extended lower bound inequality”.</li>
<li><span style="color: #0000ff;">Another conjecture of mine of a similar spirit is: a polyhedral d-manifold (more generally, a regular CW manifold) in dimension <em>d</em> which is not a sphere has at least <img alt="2^{(3d+4)/2}" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7B%283d%2B4%29%2F2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="2^{(3d+4)/2}"/> faces. (Including the empty face.)</span></li>
<li>Flag <img alt="(d-1)" class="latex" src="https://s0.wp.com/latex.php?latex=%28d-1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="(d-1)"/>-dimensional spheres also have at least <img alt="3^d" class="latex" src="https://s0.wp.com/latex.php?latex=3%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="3^d"/> faces. This follows from a theorem by Roy Meshulam.</li>
<li>Completely balanced <img alt="(d-1)" class="latex" src="https://s0.wp.com/latex.php?latex=%28d-1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="(d-1)"/>-dimensional spheres also have at least <img alt="3^d" class="latex" src="https://s0.wp.com/latex.php?latex=3%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="3^d"/> faces. (I think.) (What about zonotopes, you may ask.)</li>
<li>The class of spheres in items 4 and 5 are simplicial. So an extensions of these classes to classes of polyhedral spheres (and regular CW spheres) would be interesting.</li>
<li>d-Polytopes with no triangular 2-faces also have at least <img alt="3^d" class="latex" src="https://s0.wp.com/latex.php?latex=3%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="3^d"/> non-empty faces this follows from a theorem of Blind and Blind.</li>
<li>Looking around in papers that referred to my old paper I discovered the following appealing class of polytopes and interesting conjecture about them. A polytope P is 2-level if for every facet F of P there is a hyperplane parallel to the hyperplane through F that contains all vertices not in F. The conjecture is that for such a d-polytope P, <img alt="f_0(P)f_{d-1}(P)\le d2^{d+1}" class="latex" src="https://s0.wp.com/latex.php?latex=f_0%28P%29f_%7Bd-1%7D%28P%29%5Cle+d2%5E%7Bd%2B1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="f_0(P)f_{d-1}(P)\le d2^{d+1}"/>. This conjecture was made in the paper <a href="https://arxiv.org/abs/1703.01943">Enumeration of 2-level polytopes by</a>  Bohn,  Faenza,  Fiorini,  Fisikopoulos, Macchia, and Pashkovich. (<strong>Update:</strong> Giulia commented that the conjecture on 2-level polytopes by Bohn et al. was recently solved by Andrey Kupavskii and Stefan Weltge: <a href="https://arxiv.org/abs/2008.07153" rel="nofollow ugc">https://arxiv.org/abs/2008.07153</a>.)</li>
<li>Interesting classes of polytopes arising from graphs that are very near the conjecture can be found in the paper <a href="https://arxiv.org/abs/1201.5790" id="KdEkliExsEIJ"><span dir="ltr">Face numbers of centrally symmetric polytopes from split graphs</span>‏</a> by <span dir="ltr">Freij, Henze, Schmitt, and Ziegler. See also Independence complexes of perfect graphs by Freij and Henze in <a href="https://gilkalai.files.wordpress.com/2021/01/documents05_vol3.pdf">this report</a>.</span></li>
</ol>
<p><strong>Update (Jan 12,2021):</strong> Looking at old correspondence with Ragnar Freij, Matthias Henze, and Günter Ziegler, I came across the following conjecture that related the flag number conjecture and Mahler’s conjecture. Let P be a centrally symmetric d-polytope. Let <img alt="1+m(P)=vol(K)/vol(K*)/ (4^d/d!)" class="latex" src="https://s0.wp.com/latex.php?latex=1%2Bm%28P%29%3Dvol%28K%29%2Fvol%28K%2A%29%2F+%284%5Ed%2Fd%21%29&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="1+m(P)=vol(K)/vol(K*)/ (4^d/d!)"/>, and let <img alt="1+fn(P)=mf(P)/(2^dd!)." class="latex" src="https://s0.wp.com/latex.php?latex=1%2Bfn%28P%29%3Dmf%28P%29%2F%282%5Edd%21%29.&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="1+fn(P)=mf(P)/(2^dd!)."/> For a centrally symmetric $d$-polytope <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="P"/>, Mahler’s conjecture asserts that <img alt="m(P) \ge 0" class="latex" src="https://s0.wp.com/latex.php?latex=m%28P%29+%5Cge+0&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="m(P) \ge 0"/> and the flag number conjecture asserts that <img alt="fn(P) \ge 0" class="latex" src="https://s0.wp.com/latex.php?latex=fn%28P%29+%5Cge+0&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="fn(P) \ge 0"/>.</p>
<h3 style="text-align: center;"><strong>Conjecture:</strong>  fn(<em>P</em>) ≥ 4 m(<em>P</em>)</h3>
<p>It is also conjectured that equality holds for Jensen’s polytopes of perfect graphs.</p>
<p> </p>
<p> </p>
<p> </p></div>
    </content>
    <updated>2021-01-10T15:23:15Z</updated>
    <published>2021-01-10T15:23:15Z</published>
    <category term="Combinatorics"/>
    <category term="Computer Science and Optimization"/>
    <category term="Geometry"/>
    <category term="Open problems"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2021-01-15T18:37:37Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/003</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/003" rel="alternate" type="text/html"/>
    <title>TR21-003 |  Inverse-Exponential Correlation Bounds and Extremely Rigid Matrices from a New Derandomized XOR Lemma | 

	Lijie Chen, 

	Xin Lyu</title>
    <summary>In this work we prove that there is a function $f \in \textrm{E}^\textrm{NP}$ such that, for every sufficiently large $n$ and $d = \sqrt{n}/\log n$, $f_n$ ($f$ restricted to $n$-bit inputs) cannot be $(1/2 + 2^{-d})$-approximated by $\textrm{F}_2$-polynomials of degree $d$. We also observe that a minor improvement (e.g., improving $d$ to $n^{1/2+\varepsilon}$ for any $\varepsilon &gt; 0$) over our result will imply $\textrm{E}^\textrm{NP}$ cannot be computed by depth-$3$ $\textrm{AC}^0$-circuits of $2^{n^{1/2 + \varepsilon}}$ size, which is a notoriously hard open question in complexity theory. 
	
	Using the same proof techniques, we are also able to construct extremely rigid matrices over $\textrm{F}_2$ in $\textrm{P}^\textrm{NP}$. More specifically, we show that for every constant $\varepsilon \in (0,1)$, there is a $\textrm{P}^\textrm{NP}$ algorithm which on input $1^n$ outputs an $n\times n$ $\textrm{F}_2$-matrix $H_n$ satisfying $\mathcal{R}_{H_n}(2^{\log^{1 - \varepsilon} n}) \ge (1/2 - \exp(-\log^{2/3 \cdot \varepsilon} n) ) \cdot n^2$, for every sufficiently large $n$. This improves the recent $\textrm{P}^\textrm{NP}$ constructions of rigid matrices in [Alman and Chen, FOCS 2019] and [Bhangale et al., FOCS 2020], which only gives  $\Omega(n^2)$ rigidity.
	
	The key ingredient in the proof of our new results is a new derandomized XOR lemma based on approximate linear sums, which roughly says that given an $n$-input function $f$ which cannot be $0.99$-approximated by certain linear sum of $s$ many functions in $\mathcal{F}$ within $\ell_1$-distance, one can construct a new function $\textrm{Amp}^f$ with $\widetilde{O}(n)$ input bits, which cannot be $(1/2+s^{\Omega(1)})$-approximated by $\mathcal{F}$-functions. Taking $\mathcal{F}$ to be a function collection containing low-degree $\textrm{F}_2$-polynomials or low-rank $\textrm{F}_2$-matrices, our results are then obtained by first using the algorithmic method to construct a function which is weakly hard against linear sums of $\mathcal{F}$ in the above sense, and then apply the derandomized XOR lemma to $f$.
	
	We obtain our new derandomized XOR lemma by giving a generalization of the famous hardcore lemma by Impagliazzo. Our generalization in some sense constructs a non-Boolean hardcore of a weakly hard function $f$ with respect to $\mathcal{F}$-functions, from the weak inapproximability of $f$ by any linear sum of $\mathcal{F}$ with bounded $\ell_p$-norm. This generalization recovers the original hardcore lemma by considering the $\ell_{\infty}$-norm. Surprisingly, when we switch to the $\ell_1$-norm, we immediately rediscover Levin's proof of Yao's XOR Lemma. That is, these first two proofs of Yao's XOR Lemma can be unified with our new perspective. For proving the correlation bounds, our new derandomized XOR lemma indeed works with the $\ell_{4/3}$-norm.</summary>
    <updated>2021-01-08T21:03:46Z</updated>
    <published>2021-01-08T21:03:46Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-01-15T18:37:33Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/002</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/002" rel="alternate" type="text/html"/>
    <title>TR21-002 |  Fooling Constant-Depth Threshold Circuits | 

	Pooya Hatami, 

	William Hoza, 

	Avishay Tal, 

	Roei Tell</title>
    <summary>We present new constructions of pseudorandom generators (PRGs) for two of the most widely-studied non-uniform circuit classes in complexity theory. Our main result is a construction of the first non-trivial PRG for linear threshold (LTF) circuits of arbitrary constant depth and super-linear size. This PRG fools circuits with depth $d\in\mathbb{N}$ and $n^{1+\delta}$ wires, where $\delta = 2^{-O(d)}$, using seed length $O(n^{1-\delta})$ and with error $2^{-n^{\delta}}$. This tightly matches the best known lower bounds for this circuit class. As a consequence of our result, all the known hardness for LTF circuits has now effectively been translated into pseudorandomness. This brings the extensive effort in the last decade to construct PRGs and deterministic circuit-analysis algorithms for this class to the point where any subsequent improvement would yield breakthrough lower bounds.
    
Our second contribution is a PRG for De Morgan formulas of size $s$ whose seed length is $s^{1/3+o(1)} \cdot \mathrm{polylog}(1/\epsilon)$ for error $\epsilon$. In particular, our PRG can fool formulas of sub-cubic size $s=n^{3-\Omega(1)}$ with an exponentially small error $\epsilon=\exp({-n^{\Omega(1)}})$. This significantly improves the inverse-polynomial error of the previous state-of-the-art for such formulas by Impagliazzo, Meka, and Zuckerman (FOCS 2012), and again tightly matches the best currently-known lower bounds for this class.
    
In both settings, a key ingredient in our constructions is a pseudorandom restriction procedure that has tiny failure probability, but simplifies the function to a non-natural "hybrid computational model" that combines several computational models. As part of our proofs we also construct "extremely low-error" PRGs for related circuit classes; for example, we construct a PRG for the class of functions computable by an arbitrary function of $s$ linear threshold functions that can handle even the extreme setting of parameters $s=n/\mathrm{polylog}(n)$ and $\epsilon=2^{-n/\mathrm{polylog}(n)}$.</summary>
    <updated>2021-01-08T21:01:25Z</updated>
    <published>2021-01-08T21:01:25Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-01-15T18:37:33Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/01/08/samuel-eilenberg-assistant-professor-at-university-of-warsaw-apply-by-february-12-2020/</id>
    <link href="https://cstheory-jobs.org/2021/01/08/samuel-eilenberg-assistant-professor-at-university-of-warsaw-apply-by-february-12-2020/" rel="alternate" type="text/html"/>
    <title>Samuel Eilenberg Assistant Professor at University of Warsaw (apply by February 12, 2020)</title>
    <summary>The Faculty of Mathematics, Informatics and Mechanics at University of Warsaw (MIM UW) invites applications for positions of an assistant professor (“adiunkt” in Polish) in Computer Science, starting on 1st October 2021 (or 1st Feb 2022). Note: compared to a standard assistant professor position, Samuel Eilenberg Assistant Professor comes with reduced teaching load and increased […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Faculty of Mathematics, Informatics and Mechanics at University of Warsaw (MIM UW) invites applications for positions of an assistant professor (“adiunkt” in Polish) in Computer Science, starting on 1st October 2021 (or 1st Feb 2022).</p>
<p>Note: compared to a standard assistant professor position, Samuel Eilenberg Assistant Professor comes with reduced teaching load and increased salary.</p>
<p>Website: <a href="https://www.mimuw.edu.pl/sites/default/files/konkursy/wmim_1210_ek_01_2021_en.pdf">https://www.mimuw.edu.pl/sites/default/files/konkursy/wmim_1210_ek_01_2021_en.pdf</a><br/>
Email: kowalik@mimuw.edu.pl</p></div>
    </content>
    <updated>2021-01-08T17:14:00Z</updated>
    <published>2021-01-08T17:14:00Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-01-15T18:37:48Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/01/08/assistant-professor-at-university-of-warsaw-apply-by-february-12-2021/</id>
    <link href="https://cstheory-jobs.org/2021/01/08/assistant-professor-at-university-of-warsaw-apply-by-february-12-2021/" rel="alternate" type="text/html"/>
    <title>Assistant professor at University of Warsaw (apply by February 12, 2021)</title>
    <summary>The Faculty of Mathematics, Informatics and Mechanics at University of Warsaw (MIM UW) invites applications for positions of an assistant professor (“adiunkt” in Polish) in Computer Science, starting on 1st October 2021 (or 1st Feb 2022). Website: https://www.mimuw.edu.pl/sites/default/files/konkursy/wmim_1210_ek_03_2021_en.pdf Email: kowalik@mimuw.edu.pl</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Faculty of Mathematics, Informatics and Mechanics at University of Warsaw (MIM UW) invites applications for positions of an assistant professor (“adiunkt” in Polish) in Computer Science, starting on 1st October 2021 (or 1st Feb 2022).</p>
<p>Website: <a href="https://www.mimuw.edu.pl/sites/default/files/konkursy/wmim_1210_ek_03_2021_en.pdf">https://www.mimuw.edu.pl/sites/default/files/konkursy/wmim_1210_ek_03_2021_en.pdf</a><br/>
Email: kowalik@mimuw.edu.pl</p></div>
    </content>
    <updated>2021-01-08T17:11:22Z</updated>
    <published>2021-01-08T17:11:22Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-01-15T18:37:48Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=5247</id>
    <link href="https://www.scottaaronson.com/blog/?p=5247" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=5247#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=5247" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">To all Trumpists who comment on this blog</title>
    <summary xml:lang="en-US">The violent insurrection now unfolding in Washington DC is precisely the thing you called me nuts, accused me of “Trump Derangement Syndrome,” for warning about since 2016. Crazy me, huh, always seeing brownshirts around the corner? And you called the other side violent anarchists? This is all your doing. So own it. Wallow in it. […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>The violent insurrection now unfolding in Washington DC is precisely the thing you called me nuts, accused me of “Trump Derangement Syndrome,” for warning about since 2016.  Crazy me, huh, always seeing brownshirts around the corner?  And you called the <em>other</em> side violent anarchists?  This is all your doing.  So own it.  Wallow in it.  May you live the rest of your lives in shame.</p>



<p><strong><span class="has-inline-color has-vivid-red-color">Update (Jan. 7):</span></strong> As someone who hasn’t always agreed with BLM’s slogans and tactics, I viewed the stunning passivity of the police yesterday against white insurrectionists in the Capitol as one of the strongest arguments imaginable for BLM’s main contentions.</p></div>
    </content>
    <updated>2021-01-06T21:01:45Z</updated>
    <published>2021-01-06T21:01:45Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="The Fate of Humanity"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2021-01-14T21:04:20Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-44450853695391906</id>
    <link href="https://blog.computationalcomplexity.org/feeds/44450853695391906/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2021/01/my-survey-on-hilberts-10th-for.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/44450853695391906" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/44450853695391906" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2021/01/my-survey-on-hilberts-10th-for.html" rel="alternate" type="text/html"/>
    <title>My Survey on Hilbert's 10th for particular (d,n) is  ready for you to help me on!</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p> Hilbert's 10th problem is  (in modern terminology) to find an algorithm that will, given a poly </p><p>p(x1,...,xn) in Z[x1,...,xn], determine if it has a solution in the integers. </p><p>This was shown undecidable by the combined efforts of Davis-Putnam-Robinson and Matiyasevich. </p><p>I posted <a href="https://blog.computationalcomplexity.org/2020/05/why-is-there-no-dn-grid-for-hilberts.html">here</a> about the question of: For which (d,n) is H10 undecidable when restricted to degree d and number of vars n?</p><p>I was  invited to make an article out of the blog post and what I learned from the comments  for  the Algorithms column of BEATCS. That first draft is</p><p><a href="https://www.cs.umd.edu/users/gasarch/BLOGPAPERS/h10_final.pdf">here</a><br/></p><p><br/></p><p>Did I miss an important reference? (Note- I had meant to get out Matiyasevich's book on H10 but have been unable to because of the Pandemic, so if you have it my have stuff I need to know.) </p><p>Did I misspell Matiyasevich? </p><p>Did I say something stupid?</p><p>Please leave comments or email me directly if you have suggestions. </p><p>Incidentally I am usually the one who is asking someone else to do an open problems column, a book review, a guest blog. Nice to be the askee instead of the asker for a change of pace. </p><p><br/></p></div>
    </content>
    <updated>2021-01-06T01:13:00Z</updated>
    <published>2021-01-06T01:13:00Z</published>
    <author>
      <name>gasarch</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03004932739846901628</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2021-01-14T10:17:09Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=17976</id>
    <link href="https://rjlipton.wordpress.com/2021/01/05/predictions-for-2021/" rel="alternate" type="text/html"/>
    <title>Predictions For 2021</title>
    <summary>This year is a Blum integer, 43*47 2017 article, not via Zoom Allan Lichtman correctly predicted the 2020 presidential election, based on a 7-6 edge in “keys” to Joe Biden. His model, which he developed in 1981 with the late Vladimir Keilis-Borok, simply says that the incumbent party will lose the presidential election if 6 […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>This year is a Blum integer, 43*47</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2021/01/lichtman2017.png"><img alt="" class="alignright wp-image-17978" height="120" src="https://rjlipton.files.wordpress.com/2021/01/lichtman2017.png?w=180&amp;h=120" width="180"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">2017 <a href="https://bethesdamagazine.com/bethesda-magazine/march-april-2017/how-bethesdas-allan-lichtman-predicted-the-election-for-trump/">article</a>, not via Zoom</font></td>
</tr>
</tbody>
</table>
<p>
Allan Lichtman correctly predicted the 2020 presidential election, based on a 7-6 edge in “<a href="https://en.wikipedia.org/wiki/The_Keys_to_the_White_House">keys</a>” to Joe Biden. His model, which he <a href="https://www.pnas.org/content/78/11/7230">developed</a> in 1981 with the late Vladimir Keilis-Borok, simply says that the incumbent party will lose the presidential election if 6 or more keys go against them. It has been right in every election since 1984.</p>
<p>
Today we make some predictions for the new year, 2021.<br/>
<span id="more-17976"/></p>
<p>
Lichtman has not ventured a prediction for today’s Senate runoff elections in Georgia. Last November 19, he penned an <a href="https://thehill.com/opinion/campaign/526780-time-to-jettison-horse-race-polls">article</a> eviscerating the performance of poll aggregation in the November 3 election. We have considered writing a post about that and about statistical predictions during the pandemic, in the direction of taking more moderate assessments of how various polls, predictions, and policies have fared.</p>
<p>
Polls of today’s races currently show a 1–2 percentage point edge for the Democratic candidates, but there are multiple caveats: The difference is just about one standard deviation, well within the margin of error even after aggregation. The polls have gyrated with multiple lead flips this past month; two polls from the past few days collected <a href="https://projects.fivethirtyeight.com/georgia-senate-polls/?cid=rrpromo">here</a> show both Republican candidates tied or ahead. Many pollsters have <a href="https://fivethirtyeight.com/videos/why-many-pollsters-are-sitting-out-the-georgia-runoffs/">avoided</a> these races, and the five most recent polls all have sample sizes well under 1,000. The count beginning tonight may show a zigzag blue-to-red-to-“blur” shift for reasons of which votes are tallied when that we discussed generally <a href="https://rjlipton.wordpress.com/2020/11/03/the-election-night-time-warp/">here</a>.</p>
<p>
With that said, let us address non-election predictions.</p>
<p>
</p><p/><h2> Previous Predictions </h2><p/>
<p/><p>
Back in <a href="https://rjlipton.wordpress.com/2019/01/06/predictions-for-2019/">2019</a> we made some predictions that were easy:</p>
<ul>
<li>
<em>No circuit lower bound <img alt="{1000n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1000n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{1000n}"/> or better will be proved for SAT.</em> Well that’s a freebie. <p/>
</li><li>
<em>A computer scientist will win a Nobel Prize.</em> No—indeed, less close than other years. <p/>
</li><li>
<em>At least five claims that <img alt="{{\mathsf{P}=\mathsf{NP}}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathsf%7BP%7D%3D%5Cmathsf%7BNP%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{{\mathsf{P}=\mathsf{NP}}}"/> and five that <img alt="{{\mathsf{P} \neq \mathsf{NP}}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathsf%7BP%7D+%5Cneq+%5Cmathsf%7BNP%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{{\mathsf{P} \neq \mathsf{NP}}}"/> will be made.</em> Gerhard Woeginger’s claims <a href="https://www.win.tue.nl/~gwoegi/P-versus-NP.htm">page</a> is still paused at 2016, so we can only judge from our own window of communications made to us or commented in the blog. All we can say is that the number in each case is “order-of” <img alt="{5}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B5%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{5}"/>. <p/>
</li><li>
<em>A “provably” secure crypto-system will be broken.</em> For this one we don’t have to check any claims. We just pocket the “yes” answer.
</li></ul>
<p>
We skipped 2020—maybe that was smart of us? Our point about predictions in 2019 was the importance of “<em>when</em>” as opposed to “<em>what</em>.” With regard to some predictions, we can take the pandemic is as a global postponement of “when.”</p>
<p>
We claim complete and ongoing timeliness with another 2019 prediction, however. In full, we wrote:</p>
<ul>
<li>
<em>Quantum supremacy will be proved—finally.</em> But be careful: there is a problem with this whole direction. See the next section.
</li></ul>
<p>
The section two years ago talked about the difficulties of proving such a claim. A claim was duly made in October 2019, which we evaluated <a href="https://rjlipton.wordpress.com/2019/10/27/quantum-supremacy-at-last/">here</a>, but arguments over “proof” have not abated. They have just recently been summarized by Gil Kalai <a href="https://gilkalai.wordpress.com/2020/12/29/the-argument-against-quantum-computers-a-very-short-introduction/">here</a>, and also <a href="https://www.scottaaronson.com/blog/?p=5159">here</a> by Scott Aaronson in regard to an independent <a href="https://science.sciencemag.org/content/370/6523/1460">claim</a> by researchers from USTC in China.</p>
<p>
</p><p/><h2> Predictions for 2021 </h2><p/>
<p/><p>
Here are some new predictions for 2021. We will try and skip easy ones like the above. We will try to make some that are surprising. We’ve made predictions about evidence for life on exoplanets before; we do something different there too. We do not venture any about the course of the pandemic.</p>
<ol>
<li>
<em>Quantum algorithms: <img alt="{\mathsf{BQP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BBQP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\mathsf{BQP}}"/> will be proved to be in sub-exponential time.</em> <p/>
</li><li>
<em>Further work with <a href="https://en.wikipedia.org/wiki/AlphaFold">AlphaFold</a> will lead to a proof of a sub-exponential time algorithm for protein folding.</em> <p/>
</li><li>
<em>In consequence or independently, a SAT algorithm will be discovered that runs in sub-exponential time, thereby refuting various forms of the Exponential Time Hypothesis.</em> What do we mean by “sub-exponential” time here? Dick says the time for the SAT algorithm will be <img alt="{2^{\sqrt{n}\log n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5E%7B%5Csqrt%7Bn%7D%5Clog+n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{2^{\sqrt{n}\log n}}"/>. Ken more modestly says time <img alt="{2^{O(n/\log n)}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5E%7BO%28n%2F%5Clog+n%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{2^{O(n/\log n)}}"/>. <p/>
</li><li>
<em>Another Clay prize problem (besides <img alt="{\mathsf{P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\mathsf{P}}"/> versus <img alt="{\mathsf{NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\mathsf{NP}}"/>) will be claimed as solved, and then retracted.</em> <p/>
</li><li>
<em>A new kind of sorting network of size <img alt="{O(n \log n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%28n+%5Clog+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{O(n \log n)}"/> will be discovered, inspired by a connection to <img alt="{O(n\log n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%28n%5Clog+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{O(n\log n)}"/> integer <a href="https://rjlipton.wordpress.com/2019/03/29/integer-multiplication-in-nlogn-time/">multiplication</a><a>.</a></em><a> <p/>
</a></li><li><a>
<em>A new factoring algorithm will be discovered that beats the number field sieve.</em> <p/>
</a></li><li><a>
<em>A lower bound argument will show that clique requires formula size <img alt="{n^{10}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%5E%7B10%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{n^{10}}"/> over the <img alt="{\vee,\wedge,\neg}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cvee%2C%5Cwedge%2C%5Cneg%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\vee,\wedge,\neg}"/> basis.</em> <p/>
</a></li><li><a>
<em>Significant chemical evidence will be observed for the existence of life on a</em> </a><a href="https://www.nytimes.com/2020/09/14/science/venus-life-clouds.html">non</a>–<a href="https://en.wikipedia.org/wiki/Perseverance_(rover)">exoplanet</a>. <p/>
</li><li>
<em>Dogs will reach 25% of the proficiency of cats at <a href="https://www.boredpanda.com/cat-and-dog-challenge/?utm_source=google&amp;utm_medium=organic&amp;utm_campaign=organic">navigating</a> home obstacle courses, but not before the third quarter of 2021.</em> <p/>
</li><li>
<em>Privacy-preserving apps for doodling during Zoom meetings will become hot sellers by midyear.</em>
</li></ol>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
What are your predictions for 2021? </p>
<p/></font></font></div>
    </content>
    <updated>2021-01-05T20:25:13Z</updated>
    <published>2021-01-05T20:25:13Z</published>
    <category term="All Posts"/>
    <category term="History"/>
    <category term="News"/>
    <category term="People"/>
    <category term="Allen Lichtman"/>
    <category term="elections"/>
    <category term="exponential-time hypothesis"/>
    <category term="polls"/>
    <category term="predictions"/>
    <category term="quantum advantage"/>
    <category term="quantum supremacy"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2021-01-15T18:37:42Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://kamathematics.wordpress.com/?p=205</id>
    <link href="https://kamathematics.wordpress.com/2021/01/05/soda-2021-funds-for-student-registration-fees/" rel="alternate" type="text/html"/>
    <title>SODA 2021: Funds for Student Registration Fees</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">UPDATE: An update from Shang-Hua Teng: Dear TCS Students: SIAM has today reopened the application portal for SODA21 Student Registration Waiver. The new deadline will be this Friday, January 8 at 11:59pm EST. SODA21 will be held virtually on Jan. 10 – Jan. 13, 2021. Please note that having paper(s) in SODA and its associated … <a class="more-link" href="https://kamathematics.wordpress.com/2021/01/05/soda-2021-funds-for-student-registration-fees/">Continue reading<span class="screen-reader-text"> "SODA 2021: Funds for Student Registration Fees"</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>UPDATE: An update from Shang-Hua Teng:</p>



<p>Dear TCS Students:</p>



<p>SIAM has today reopened the application portal for SODA21 Student Registration Waiver. The new deadline will be this Friday, January 8 at 11:59pm EST.</p>



<p>SODA21 will be held virtually on Jan. 10 – Jan. 13, 2021.</p>



<p>Please note that having paper(s) in SODA and its associated Symposiums is not a requirement. For this year’s application, the letter of recommendation from advisors is not required as well. The goal of the support from Google, Microsoft, and ACM is to increase opportunity for students to attend this premier TCS conference.</p>



<p>Looking forward to seeing you in SODA’21.</p>



<hr class="wp-block-separator"/>



<p>ORIGINAL MESSAGE: Please see below for a message from Shang-Hua Teng, regarding the possibility of waivers for SODA 2021 registration for students.</p>



<hr class="wp-block-separator"/>



<p>Dear TCS students:<br/><br/>By now, it is hard to overestimate the impact of the COVID19 pandemic to society. However, like every challenge, it has created some opportunities. For example, essentially all major conferences in TCS this year have been transformed into virtual ones, making them more accessible to scholars/students across the world (of course at the expense of traditional interactions). <br/><br/>ACM-SIAM Symposium on Discrete Algorithms (SODA21) will be held virtually this year, on Jan. 10 – 13, 2021. As you may know, this is the premier conference on algorithms .<br/><br/>See <a href="https://www.siam.org/conferences/cm/conference/soda21" rel="noreferrer noopener" target="_blank">https://www.siam.org/conferences/cm/conference/soda21</a><br/><br/>Thanks to our industry partners and ACM SIGACT group, SODA has some funds for covering student registrations. I am writing to informing you this opportunity and encourage you to apply:<br/> See: <br/>1. <a href="https://awards.siam.org/" rel="noreferrer noopener" target="_blank">https://awards.siam.org/</a> <br/>2. <a href="https://www.siam.org/conferences/cm/lodging-and-support/travel-support/soda21-travel-support" rel="noreferrer noopener" target="_blank">https://www.siam.org/conferences/cm/lodging-and-support/travel-support/soda21-travel-support</a><br/>That deadline is Dec. 27, 2020. Like before, having papers in SODA is not prerequisite.<br/><br/>Shang-Hua Teng<br/>On Behalf of SODA Steering Committee<br/></p></div>
    </content>
    <updated>2021-01-05T19:25:00Z</updated>
    <published>2021-01-05T19:25:00Z</published>
    <category term="Events"/>
    <author>
      <name>Gautam</name>
    </author>
    <source>
      <id>https://kamathematics.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://kamathematics.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://kamathematics.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://kamathematics.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://kamathematics.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Kamathematics</title>
      <updated>2021-01-15T18:39:01Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://francisbach.com/?p=5325</id>
    <link href="https://francisbach.com/finding-global-minima-with-kernel-approximations/" rel="alternate" type="text/html"/>
    <title>Finding global minima with kernel approximations</title>
    <summary>Last month, I showed how global optimization based only on accessing function values can be hard with no convexity assumption. In a nutshell, with limited smoothness, the number of function evaluations has to grow exponentially fast in dimension, which is a rather negative statement. On the positive side, this number does not grow as fast...</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p class="justify-text"><a href="https://francisbach.com/optimization-is-as-hard-as-approximation/">Last month</a>, I showed how global optimization based only on accessing function values can be hard with no convexity assumption. In a nutshell, with limited smoothness, the number of function evaluations has to grow exponentially fast in dimension, which is a rather negative statement. On the positive side, this number does not grow as fast for highly smooth functions. However, optimal algorithms end up approximating the whole function to minimize, and <em>then</em> minimizing the approximation, which takes exponential time in general. In this post, I will describe very recent work with Alessandro Rudi and Ulysse Marteau-Ferey [<a href="https://www.di.ens.fr/~fbach/gloptikernel.pdf">1</a>] that essentially <em>jointly</em> approximates the function and minimizes the approximation.</p>



<p class="justify-text">Our task for this post will be to minimize a function \(f: \mathbb{R}^d \to \mathbb{R}\), for which we know the global minimizer is already located in a certain bounded set \(\Omega\) (typically a large ball). We can query values of \(f\) at any point in \(\Omega\).</p>



<p class="justify-text">It turns out it can be formulated as a convex optimization problem (there has to be a catch in this statement, stay tuned).</p>



<h2>All optimization problems are convex!</h2>



<p class="justify-text">We consider the following minimization problem: $$\tag{1} \sup_{c \in \mathbb{R}} \ c \ \ \mbox{ such that } \ \ \forall x \in \Omega, \ f(x) \geqslant c.$$ As illustrated below, this corresponds to finding the largest lower bound \(c\) on the function.</p>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-5352" height="203" src="https://francisbach.com/wp-content/uploads/2020/12/f_above_c-1-1024x670.png" width="310"/></figure></div>



<p class="justify-text">Assuming \(f\) attains its global minimizer \(f_\ast\) in \(\Omega\), then the optimal value of the problem above is attained and is clearly \(f_\ast\), that is, the problem in Eq. (1) leads to the minimal value of \(f\). </p>



<p class="justify-text">Moreover, each constraint in Eq. (1) is a linear constraint in \(c\), and the objective is linear. Hence we obtain a linear programming problem which is a particularly simple instance of a convex optimization problem. Thus, all optimization problems are convex!</p>



<p class="justify-text">The catch here is that the set of inequalities is dense, that is, in general, \(\Omega\) contains infinitely many elements, and thus the number of constraints is infinite.</p>



<p class="justify-text"><strong>Duality.</strong> It is worth deriving the convex optimization dual (being loose here in terms of regularity and integrability conditions). We add a Lagrange multiplier \(\mu(x) \geqslant 0\) for each of the constraints \(f(x) \, – c \geqslant 0\), and consider the Lagrangian<br/>$$ \mathcal{L}(c,\mu) = c + \int_{\Omega} \! \mu(x) \big( f(x) \, – c\big) dx.$$ Maximizing it with respect to \(c\) leads to the constraint \(\int_\Omega \mu(x) dx = 1\), that is, \(\mu\) represents a probability distribution, and the dual problem is $$ \inf_{\mu \in \mathbb{R}^\Omega} \int_{\Omega} \! \mu(x) f(x) dx \ \ \mbox{ such that } \int_\Omega\! \mu(x) dx = 1 \mbox{ and } \forall x \in \Omega, \ \mu(x) \geqslant 0.$$ In words, we minimize the expectation of \(f\) with respect to all probability distributions on \(\Omega\) with densities. Here, the infimum is obtained from any probability measure that puts mass only on the minimizer of \(f\) on \(\Omega\). This measure is typically not absolutely continuous, and thus the infimum is not attained (no big deal).</p>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-5350" height="202" src="https://francisbach.com/wp-content/uploads/2020/12/f_and_mu-1024x699.png" width="295"/></figure></div>



<p class="justify-text">This is also a convex optimization problem, with a linear objective function on the infinite-dimensional set of probability measures.</p>



<p class="justify-text">Overall, we get convex but (apparently) useless problems. We will first need an efficient way to represent non-negativity of functions (this will be applied to \(f(x) \, – c\)).</p>



<h2>Positivity with “sums of squares”</h2>



<p class="justify-text">We now start to make some assumptions on the function \(f\) to be minimized. We will assume that it can be written as $$\forall x \in \Omega, \ f(x) = \langle \phi(x), F \phi(x) \rangle,$$ for some feature vector \(\phi(x)\) in some Hilbert space \(\mathcal{H}\), and \(F\) a symmetric linear operator on \(\mathcal{H}\). </p>



<p class="justify-text">We will need infinite dimensions later, but you can safely assume that \(\mathcal{H}\) is a classical Euclidean space (e.g., \(\mathbb{R}^{{\rm dim}(\mathcal{H})}\)), and that we have $$\forall x \in \Omega, \ f(x) = \phi(x)^\top F \phi(x) = \sum_{i,j=1}^{{\rm dim}(\mathcal{H})} F_{ij} \phi(x)_i \phi(x)_j.$$</p>



<p class="justify-text">We will also assume that the constant function on \(\Omega\) can be represented as well, that is, there exists \(u \in \mathcal{H}\) such that \(\forall x \in \Omega, \ \langle u, \phi(x) \rangle = 1.\) This is to ensure that we can represent within the optimization problem above the function \(f(x) \, – c = \langle \phi(x), (F – c \, u \otimes u) \phi(x) \rangle\).</p>



<p class="justify-text">The most classical example is the set of polynomials of degree \(2r\) for which we can choose \(\phi(x)\) to be of dimension \(d+r \choose r\) and contain all monomials are degree less than \(r\). We will go infinite-dimensional and link this to kernels later in this post.</p>



<p class="justify-text">You may wonder why we are not simply modeling the function \(f\) with a classical formulation \(f(x) = \langle w, \phi(x) \rangle\). This is precisely to be able to enforce positivity.</p>



<p class="justify-text"><strong>Positivity through “sum-of-squares”.</strong> We can assume that the operator \(F\) is positive-semidefinite (which we will denote \(F \succcurlyeq 0\)), that is, all of its eigenvalues are non-negative, or, for all \(h \in \mathcal{H}\), \(\langle h, F h \rangle \geqslant 0\). Then this implies that the function \(f\) is pointwise positive. Thus:  $$ \tag{2} F \succcurlyeq 0 \ \ \Rightarrow \ \ \forall x \in \Omega, \ f(x)  = \langle \phi(x), F \phi(x) \rangle \geqslant 0. $$</p>



<p class="justify-text">We refer to such functions as “sum-of-squares”. Indeed, given the spectral decomposition of \(F\) as $$ F = \sum_{i \in I} \lambda_i h_i \otimes h_i, $$ with \(I\) a countable set, and \((h_i)_{i \in I}\) an orthonormal family in \(\mathcal{H}\), we have \(\lambda_i \geqslant 0\) for all \(i \in I\), and thus we can write $$ f(x) = \langle \phi(x), F \phi(x) \rangle = \sum_{i \in I} \lambda_i \langle \phi(x) , (h_i \otimes h_i) \phi(x) \rangle = \sum_{i=1}^n \big( \sqrt{\lambda_i} \langle h_i , \phi(x) \rangle \big)^2.$$ That is, the function \(f\) is a sum of squares of functions.</p>



<p class="justify-text">A key question is whether the implication in Eq. \((2)\) can be reversed. In other words, <em>can we write all non-negative functions as sum-of-squares?</em> The answer will depend on the chosen feature map \(\phi: \Omega \to \mathcal{H}\).</p>



<p class="justify-text"><strong>Polynomials.</strong> For polynomials, the answer is known to be positive in dimension 1, but negative in higher dimensions (see the nice review in [<a href="https://www.jstor.org/stable/2695736">2</a>]): that is, unless \(d=1\), or \(d=2\) and \(r=2\), there are polynomials of degree \(2r\) in dimension \(d\) that are non-negative but are not the sum of squares of polynomials. </p>



<p class="justify-text">Keeping in mind the difference being non-negative and being a sum of squares, let’s look how this can be used for global optimization of polynomials.</p>



<h2>Polynomial optimization with sums-of-squares</h2>



<p class="justify-text">We now consider that \(f\) is a polynomial of degree \(2r\), and that \(\phi(x)\) is of dimension \(d+r \choose r\) and contain all monomials of degree less than \(r\). We consider representing the constraint \(f(x)\geqslant c\) in Eq. (1), as \(f(x) = c + \langle \phi(x), A \phi(x) \rangle\) for some positive-definite operator (here a matrix) \(A\). With the notations above, this is equivalent to \(F = c u \otimes u + A\) and \(A \succcurlyeq 0\). This leads to the following optimization problem (no localization set \(\Omega\) is used): $$ \tag{3} \max_{c \in \mathbb{R}, A \succcurlyeq 0} c \ \mbox{ such that } \ \forall x \in \mathbb{R}^d, \ f(x) = c + \langle \phi(x), A \phi(x) \rangle .$$ This in now a problem in finite dimension, which is a <a href="https://en.wikipedia.org/wiki/Semidefinite_programming">semidefinite programming</a> problem, and can thus a priori be solved in polynomial time in \(d+r \choose r\). See [<a href="https://epubs.siam.org/doi/abs/10.1137/S1052623400366802">3</a>, 4] for more details.</p>



<p class="justify-text">At this point, beyond the potentially large dimension of the convex problem when \(r\) and \(d\) grow, there is a major concern: is the problem in Eq. (3) equivalent to the one in Eq. (1)? This is true if and only if the polynomial \(f(x) \, – f_\ast\) is a a sum-of-squares, which given the discussion above may not happen as soon as \(d \geqslant 2\). </p>



<p class="justify-text">In order to apply to all polynomials, the problem has to be changed. A simple reformulation is possible [<a href="https://epubs.siam.org/doi/abs/10.1137/S1052623400366802">3</a>] by assuming that the global minimum of \(f\) is attained within the set \(\Omega = \{ x \in \mathbb{R}^d, \ x^\top x \leqslant R^2\}\) for some \(R &gt; 0\). It turns out (and this is a highly non-trivial fact) that all polynomials \(f(x) \) which are positive on \(\Omega\) can be written as \(f(x) = q(x) + ( R^2 – x^\top x ) p(x)\), where \(q(x)\) and \(p(x) \) are sum-of-squares polynomials. The only issue is that the degrees of \(p\) and \(q\) are not known in advance so a sequence (a so-called “hierarchy”) of problems have to be solved with increasing degrees, each providing a lower bound on \(f_\ast\). </p>



<p class="justify-text">When the degree is large enough so that the sum-of-squares representation exists for \(f – f_\ast\), then the following problem  $$ \max_{c \in \mathbb{R}, A, B \succcurlyeq 0} c \mbox{ such that } \forall x \in \mathbb{R}^d, \ f(x) = c + \langle \phi(x), A \phi(x) \rangle + ( R^2 – x^\top x ) \langle \phi(x), B \phi(x) \rangle$$ is a semi-definite program, whose solution leads to \(c = f_\ast\).</p>



<p class="justify-text">This remains a large semi-definite program whose order is not known in advance and for which complicated solvers are needed. I will now present our recent work where we go infinite-dimensional, and some of these issues are alleviated (but some others are created).</p>



<h2>Going infinite-dimensional</h2>



<p class="justify-text">We now consider \(\phi(x)\) to be infinite-dimensional. In order to allow finite-dimensional manipulations of various objects, we consider feature maps which are obtained from <a href="https://en.wikipedia.org/wiki/Positive-definite_kernel">positive-definite kernels</a>. More precisely, we consider the so-called <a href="https://en.wikipedia.org/wiki/Sobolev_space">Sobolev space</a> \(\mathcal{H}\) of functions on \(\Omega\) with all partial derivatives up to order \(s\) which are square-integrable. When \(s &gt; d/2\), then this is a reproducing kernel Hilbert space, that is, there exists a positive-definite kernel \(k: \Omega \times \Omega \to \mathbb{R}\) such that the feature map \(\phi(x) = k(\cdot,x)\) allows to access function values as \(h(x) = \langle h, \phi(x) \rangle\) for all \(h \in \mathcal{H}\). For the algorithm, we will only need access to the kernel; for example, for \(s = d/2+1/2\), we can choose the usual exponential \(k(x,y) = \exp( – \alpha \| x – y \|_2)\).</p>



<p class="justify-text">We now consider the same problem as for polynomials, but with this new feature map: $$\tag{4} \max_{c \in \mathbb{R}, A \succcurlyeq 0} c \ \mbox{ such that } \ \forall x \in \Omega, \ f(x) = c + \langle \phi(x), A \phi(x) \rangle .$$ In order to have an exact reformulation, we need that there exists some \(A_\ast\) such that \(\forall x \in \Omega, \ f(x)  \, – f_\ast = \langle \phi(x), A_\ast \phi(x) \rangle\). It turns out to be true [<a href="https://www.di.ens.fr/~fbach/gloptikernel.pdf">1</a>] with appropriate geometric conditions on \(x\) (such as isolated second-order strict global minimizers within \(\Omega\)) and regularity (at least \(s+3\) derivatives); see [<a href="https://www.di.ens.fr/~fbach/gloptikernel.pdf">1</a>] for details.</p>



<p class="justify-text">This is all very nice, but the problem in Eq. (4) is still an infinite-dimensional problem (note that we have gone from a continuum of inequalities to elements of a Hilbert space, but that’s not much of a gain). </p>



<h2>Controlled approximation through sampling</h2>



<p class="justify-text">We can now leverage classical and more recent techniques from kernel methods. The main idea is to subsample the set of equalities in Eq. (4), that is consider \(n\) points \(x_1,\dots,x_n \in \Omega\), and solve instead the regularized sampled problem $$\tag{5} \max_{c \in \mathbb{R}, A \succcurlyeq 0} c \ – \, \lambda \, {\rm tr}(A) \ \mbox{ such that }\  \forall i \in \{1,\dots,n\}, \ f(x_i) = c + \langle \phi(x_i), A \phi(x_i) \rangle , $$ where \(\lambda &gt; 0\) is a regularization parameter.</p>



<p class="justify-text"><strong>Approximation guarantees.</strong> Beyond computational considerations, how big does \(n\) need to be to obtain a value of \(c\) which is at most \(\varepsilon\) away from \(f_\ast\)? From <a href="https://francisbach.com/optimization-is-as-hard-as-approximation/">last post</a>, if \(f\) is \(m\)-times differentiable, we cannot have \(n\) smaller than \(\varepsilon^{-d/m}\). As shown in [<a href="https://www.di.ens.fr/~fbach/gloptikernel.pdf">1</a>], for points \(x_1,\dots,x_n \in \Omega\) selected uniformly at random, then \(n\) can be taken to of the order \(\varepsilon^{-d/(m – d/2 – 3)}\) for a well-chosen Sobolev space \(s\) and regularization parameter \(\lambda\). This is not the optimal rate \(\varepsilon^{-d/(m – d/2)}\) , but close when \(m\) and \(d\) are large.</p>



<p class="justify-text"><strong>Finite-dimensional algorithm.</strong> The problem in Eq. (5) is still infinite-dimensional. We can leverage a recent work, again with Ulysse Marteau-Ferey and Alessandro Rudi [<a href="http://arxiv.org/pdf/2007.03926(opens in a new tab)">5</a>], that shows that a <a href="https://en.wikipedia.org/wiki/Representer_theorem">representer theorem</a> exists for this type of problems: the optimization for the operator \(A\) may be restricted to \(A\) of the form $$A = \sum_{i,j} C_{ij} \phi(x_i) \otimes \phi(x_j)$$ for a positive definite <em>matrix</em> \(C \in \mathbb{R}^{n \times n}\). This leads to a semi-definite programming problem of size \(n\), whose running-time complexity is polynomial in \(n\) (e.g, \(O(n^{3.5})\)), with standard general-purpose toolboxes (such as <a href="http://cvxr.com/cvx/">CVX</a>).</p>



<p class="justify-text">In order to tackle large values \(n\) which are larger than \(1000\), simple iterative algorithms can be designed (see [<a href="https://www.di.ens.fr/~fbach/gloptikernel.pdf">1</a>] for a damped Newton algorithm which does not require any singular value decompositions, with complexity \(O(n^3)\) per iteration). Classical tools for efficient kernel methods, such as column sampling / Nyström method (see [<a href="http://proceedings.mlr.press/v30/Bach13.pdf">6</a>, <a href="http://papers.neurips.cc/paper/5936-less-is-more-nystrom-computational-regularization.pdf">7</a>] and references therein) or random features (see [<a href="http://papers.neurips.cc/paper/6914-generalization-properties-of-learning-with-random-features.pdf">8</a>, <a href="https://jmlr.org/papers/volume18/15-178/15-178.pdf">9</a>] and references therein), could also be used to avoid a cubic or quadratic complexity in \(n\).</p>



<p class="justify-text"><strong>Comparison with random search.</strong> Instead of solving the problem in Eq. (5), we could output the minimal value of \(f(x_i)\) for \(i \in \{1,\dots,n\}\), which is exactly random search if the points \(x_i\) are random (this also happens to correspond to using \(\lambda=0\) in Eq. (5)). This can only achieve an error \(\varepsilon\) for \(n\) of order \(\varepsilon^{-d}\); in other words, it cannot leverage smoothness, while our algorithm can. The main technical reason is that subsampling inequalities provide weaker guarantees than subsampling equalities, and thus representing the non-negativity of a function through an equality (which our method essentially does) provides significant benefits.</p>



<h2>Duality</h2>



<p class="justify-text">As always in convex optimization, it is beneficial to look at dual problems. It turns out that iterative algorithms are easier to build for the finite-dimensional dual problem to Eq. (5). We rather look now at the dual of Eq. (4) and make the parallel with the primal original problem in Eq. (1) and its dual.</p>



<p class="justify-text">Introducing a Lagrange multiplier \(\mu(x)\) for the constraint \(f(x) = c + \langle \phi(x), A \phi(x) \rangle\) (this time not constrained to be non-negative because we have an equality constraint), we can form the Lagrangian $$\mathcal{L}(c,A,\mu) = c + \int_{\Omega} \! \mu(x) \big( f(x) \, – c \, – \langle \phi(x), A \phi(x) \rangle \big) dx.$$ Maximizing with respect to \(c\) again leads to the constraint \(\int_\Omega \mu(x) dx = 1\), while minimizing with respect to \(A \succcurlyeq 0\) leads to the constraint \(\int_\Omega \mu(x) \phi(x) \otimes \phi(x) dx \succcurlyeq 0 .\) The dual problem thus becomes $$ \inf_{\mu \in \mathbb{R}^\Omega} \int_{\Omega} \! \mu(x) f(x) dx \ \ \mbox{ such that } \int_\Omega\! \mu(x) dx = 1 \mbox{ and } \ \int_\Omega \mu(x) \phi(x) \otimes \phi(x)dx \succcurlyeq 0.$$ The impact of the representation of non-negative functions by quadratic forms in \(\phi(x)\) is to replace the non-negativity contraint on all \(\mu(x)\) by the positivity of the matrix \(\int_\Omega \mu(x) \phi(x) \otimes \phi(x)dx\), which is weaker in general, but equivalent if \(\phi(x)\) is “large” enough.</p>



<p class="justify-text">Note that the dual problem through a signed measure that should concentrate around the minimizers of \(f\) leads to a natural candidate \(\int_\Omega x \mu(x) dx\) for the optimizer (see more details in [<a href="https://www.di.ens.fr/~fbach/gloptikernel.pdf">1</a>], and a similar dual formulation for polynomials in [<a href="https://arxiv.org/pdf/2011.08566.pdf">10</a>]).</p>



<h2>Simulations</h2>



<p class="justify-text">In order to highlight how the optimization method works, I will first present how it minimizes the multi-modal function in dimension \(d=2\) pictured below on \([-1,1]^2\).</p>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-5384" height="367" src="https://francisbach.com/wp-content/uploads/2021/01/f3d_blog-1024x768.png" width="500"/></figure></div>



<p class="justify-text">We consider sampling a sequence of points \(x_1, x_2,\dots \in \mathbb{R}^2\) from a <a href="https://en.wikipedia.org/wiki/Low-discrepancy_sequence">quasi-random sequence </a>(so that it fills the space more evenly that purely random). The random points are displayed in purple while the solution of our algorithm is displayed in red, with increasing numbers \(n\) of sampled points. On the right plot, the model \(c + \langle \phi(x), A \phi(x) \rangle\) is displayed, showing that the model becomes more accurate as \(n\) grows.</p>



<div class="wp-block-image"><figure class="aligncenter size-full"><img alt="" class="wp-image-5385" height="434" src="https://francisbach.com/wp-content/uploads/2021/01/gloptikernel_blog.gif" width="1196"/></figure></div>



<p class="justify-text">We also consider a problem in dimension \(d=8\), where we compare random sampling and our algorithm (“gloptikernel”), as \(n\) grows (see [<a href="https://arxiv.org/pdf/2012.11978">1</a>] for the experimental set-up).</p>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-5383" height="302" src="https://francisbach.com/wp-content/uploads/2021/01/plot_blog_perf.png" width="362"/></figure></div>



<p class="justify-text">Clearly, the chosen baseline (random sampling) is rudimentary, though optimal up to logarithmic terms for non-smooth problems where only Lipschitz-continuity is assumed. We can also compare to gradient descent with random restarts (“random+GD” below, with the same overall number of function evaluations). As shown below, when the gradient information is robust, this baseline performs similarly (left plot), while when a high frequency component is added to the function (which makes the gradient information non reliable, right plot), the local descent algorithm needs more function evaluations.</p>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-5410" height="262" src="https://francisbach.com/wp-content/uploads/2021/01/randomGD-1-1024x442.png" width="607"/></figure></div>



<p class="justify-text">It would be interesting to compare this new algorithms to other global optimization algorithms based on function evaluations, such as <a href="https://en.wikipedia.org/wiki/CMA-ES">CMA-ES</a> or <a href="https://en.wikipedia.org/wiki/Bayesian_optimization">Bayesian optimization</a>.</p>



<h2>Conclusion</h2>



<p class="justify-text">In this post, I presented an algorithm for global optimization that can provably leverage smoothness with an algorithm which has a running time which is polynomial in the dimension and the number of function evaluations. For large smoothness factors, the number of such evaluations has a dependence on the precision \(\varepsilon\) which has no exponential dependence in dimension in the exponent (but still in the constants: we cannot optimize multivariate polynomials in polynomial time…).</p>



<p class="justify-text">These ideas can be extended in a number of ways.</p>



<p class="justify-text"><strong>General relaxation tool for dense inequalities. </strong>We can generalize the previous developments to all problems with a continuum of constraints on a variable \(\theta\), such as, $$ \forall x \in \Omega, \ H(\theta,x) \geqslant 0.$$ The corresponding Lagrange multipliers also satisfy $$ \forall x \in \Omega, \ \mu(x) \geqslant 0$$ (there may be other ones like in the problem above). Now the question is: should we use the non-negative modelisation with quadratic forms in the primal or in the dual? Or equivalently, replace the non-negativity constraint by the positivity of the integral of \(\phi(x) \otimes \phi(x)\) in the dual or in the primal?</p>



<p class="justify-text">The answer depends on the expected smoothness of the function which is non-negative. In the optimization problem, we expect \(f(x) \, – c\) to be smooth at the optimum, while \(\mu(x)\) which is approximating a Dirac clearly isn’t; therefore, the choice is clear (at least in retrospect since we originally tried to model \(\mu(x)\) as a quadratic form…).</p>



<p class="justify-text"><strong>Constrained optimization.</strong> Following [<a href="https://epubs.siam.org/doi/abs/10.1137/S1052623400366802">3</a>], we can apply the same algorithmic technique to constrained optimization, by formulating the problem of minimizing \(f(x)\) such that \(g(x) &gt; 0\) as maximizing \(c\) such that \(f(x) = c + p(x) + g(x)q(x)\), and \(p, q\) non-negative functions. We can (at least in principle) then replace the non-negative constraints by \(p(x) = \langle \phi(x),A\phi(x)\rangle\) and \(q(x) =\langle \phi(x),B\phi(x)\rangle\) for positive operators \(A\) and \(B\). All this remains to be explored in more details.</p>



<p class="justify-text"><strong>Acknowledgements</strong>. I would like to thank Alessandro Rudi and Ulysse Marteau-Ferey for proofreading this blog post and making good clarifying suggestions.</p>



<h2>References</h2>



<p class="justify-text">[1] Alessandro Rudi, Ulysse Marteau-Ferey, Francis Bach. <a href="https://www.di.ens.fr/~fbach/gloptikernel.pdf">Finding Global Minima via Kernel </a><a href="https://arxiv.org/pdf/2012.11978">Approximations</a>. Technical report arXiv:2012.11978, 2020.<br/>[2] Walter Rudin. <a href="https://www.jstor.org/stable/2695736">Sums of squares of polynomials</a>. <em>The American Mathematical Monthly</em>, <em>107</em>(9), 813-821, 2000.<br/>[3] Jean-Bernard Lasserre. <a href="https://epubs.siam.org/doi/abs/10.1137/S1052623400366802">Global optimization with polynomials and the problem of moments</a>. <em>SIAM Journal on Optimization</em>, 11(3):796–817, 2001.<br/>[4] Jean-Bernard Lasserre. Moments, Positive Polynomials and their Applications, volume 1. World Scientific, 2010.<br/>[5] Ulysse Marteau-Ferey, Francis Bach, and Alessandro Rudi. <a href="https://arxiv.org/pdf/2007.03926">Non-parametric models for non-negative functions</a>. Advances in Neural Information Processing Systems, 33, 2020.<br/>[6] Francis Bach. <a href="http://proceedings.mlr.press/v30/Bach13.pdf">Sharp analysis of low-rank kernel matrix approximations</a>. Conference on Learning Theory, pages 185–209, 2013.<br/>[7] Alessandro Rudi, Raffaello Camoriano, and Lorenzo Rosasco. <a href="http://papers.neurips.cc/paper/5936-less-is-more-nystrom-computational-regularization.pdf">Less is more: Nyström computational regularization</a>. Advances in Neural Information Processing Systems,  2015.<br/>[8] Alessandro Rudi and Lorenzo Rosasco. <a href="http://papers.neurips.cc/paper/6914-generalization-properties-of-learning-with-random-features.pdf">Generalization properties of learning with random features</a>. Advances in Neural Information Processing Systems, 30, 2017.<br/>[9] Francis Bach. <a href="https://jmlr.org/papers/volume18/15-178/15-178.pdf">On the equivalence between kernel quadrature rules and random feature expansions</a>. Journal of Machine Learning Research, 18(1):714–751, 2017.<br/>[10] Jean-Bernard Lasserre. <a href="https://arxiv.org/pdf/2011.08566.pdf">The moment-SOS hierarchy and the Christoffel-Darboux kernel.</a> Technical Report arXiv:2011.08566, 2020.</p></div>
    </content>
    <updated>2021-01-05T12:32:00Z</updated>
    <published>2021-01-05T12:32:00Z</published>
    <category term="Machine learning"/>
    <author>
      <name>admin</name>
    </author>
    <source>
      <id>https://francisbach.com</id>
      <link href="https://francisbach.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://francisbach.com" rel="alternate" type="text/html"/>
      <subtitle>Francis Bach</subtitle>
      <title>Machine Learning Research Blog</title>
      <updated>2021-01-15T18:39:05Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://ptreview.sublinear.info/?p=1458</id>
    <link href="https://ptreview.sublinear.info/?p=1458" rel="alternate" type="text/html"/>
    <title>News for December 2020</title>
    <summary>Happy 2021! We now cover the last papers of 2020: a (smaller) spread with graph property testing, distribution property testing, and circuit complexity. Almost Optimal Bounds for Sublinear-Time Sampling of k-Cliques: Sampling Cliques is Harder Than Counting by Talya Eden, Dana Ron, and Will Rosenbaum (arXiv). In many settings, sampling and counting are tightly coupled; the classic […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Happy 2021! We now cover the last papers of 2020: a (smaller) spread with graph property testing, distribution property testing, and circuit complexity.</p>



<p><strong>Almost Optimal Bounds for Sublinear-Time Sampling of k-Cliques: Sampling Cliques is Harder Than Counting</strong> by Talya Eden, Dana Ron, and Will Rosenbaum (<a href="https://arxiv.org/abs/2012.04090">arXiv</a>). In many settings, sampling and counting are tightly coupled; the classic example being permanent estimation and sampling random bipartite matchings.This paper investigates the problem of sampling uniform random cliques, and unearths an interesting separation of approximately uniform sampling from approximate counting. Let’s consider the fundamental problem of edge and triangle counting, in graphs of constant arboricity. This class, which contains all minor-closed families, has deep connections to clique counting; clique counting can be done in linear time for bounded arboricity graphs.) The input connected graph \(G\) has \(n\) vertices, \(m\) edges, and \(t\) triangles. We assume the standard query model, with uniform random vertices, neighbor, and degree queries. Our aim is to get \((1+\varepsilon)\)-approximations for \(m\) and \(t\) (in general, any \(k\)-clique count). It is known from previous work that edge estimation can be done in \(O(1)\) time and triangle estimation can be done in \(O(n/t)\) time (ignoring log and \(\varepsilon\) dependencies). Moreover, these bounds is optimal. Can one get similar bounds for approximately sampling a uniform random edge/triangle? Previous work of <a href="https://drops.dagstuhl.de/opus/volltexte/2018/8300/">Eden-Rosenbaum</a> achieve such a bound for sampling edges. Surprisingly, this paper shows that triangle sampling is fundamentally harder, and requires \(\Omega(n^{3/4}/\sqrt{t})\) queries. The main result gives a precise and optimal bound for uniform sampling \(k\)-cliques in graphs of arboricity \(\alpha\).  </p>



<p><strong>Testing and reconstruction via decision trees </strong>by Guy Blanc, Jane Lange, and Li-Yang Tan (<a href="https://arxiv.org/abs/2012.08735">arXiv</a>). A property tester is an (sublinear) algorithm that distinguishes an object with a property from those that are far. Reconstruction is a much stronger sublinear algorithm, which actually provides query access to the closest object. Suppose we have query access to an \(n\)-variate Boolean function \(f\), and the property \(\mathcal{P}\) of interest is size-\(s\) decision trees. A reconstructor would give query access to a function \(g \in \mathcal{P}\), such that \(dist(f,g) = O(OPT_f)\), where \(OPT_f\) is the distance of \(f\) to \(\mathcal{P}\). Observe that a reconstructor automatically gives a distance estimator (just estimate \(dist(f,g)\) by random sampling). One of the main results of this paper is a (weaker, bicriteria) reconstructor, where \(g\) is guaranteed to have decision-tree complexity \(s^{O(\log^2s)}\). Each query to \(g\) is computed in \(poly(\log s, 1/\varepsilon)\cdot n\) time. This reconstructor leads to a number of testing results, and reconstructors for other properties like low Fourier degree. Another interesting result proven: if there exists an efficient reconstructor that gets \(g\) of size \(s\), then there exists an efficient proper learner for decision trees (a big open problem).</p>



<p><strong>Testing Product Distributions: A Closer Look </strong>by Arnab Bhattacharyya, Sutanu Gayen, Saravanan Kandasamy, and N. V. Vinodchandran (<a href="https://arxiv.org/abs/2012.14632">arXiv</a>). This paper is on distribution testing, where all distributions involved are promised to be <em>product distributions</em>. Let \(P, Q\) be distributions over \(\Sigma^n\), where \(Sigma\) is some (small) finite set. The problems studied are identity testing (\(Q\) is known/fixed, and one gets samples from unknown \(P\)) and closeness testing (both unknown). It is known from previous work that these problems can basically be solved with \(O(n|\Sigma|\varepsilon^{-2})\) samples. Note that the domain size is exponential in \(n\); thus, these bounds give an exponential improvement over identity/closeness testing in the vanilla (non-product) setting. Tolerant testing is of special significance here. Because the domain is so large, it makes sense to allow for some distance even in the “yes” case. The main result of this paper is to completely map out the complexities for identity/closeness testing where we wish to distinguish \(d_1(P,Q) &lt; \varepsilon_1\) from \(d_2(P,Q) &gt; \varepsilon_2\), where \(d_1, d_2\) are potentially different distance measures. For example, the paper considers total variation (TV), KL, Hellinger, and \(\chi^2\) distances. An important improvement achieved is for identity testing where \(d_1\) is Hellinger and \(d_2\) is TV distance: for certain values of \(\varepsilon_1, \varepsilon_2\), one can get a tester of optimal sample complexity \(O(\sqrt{n|\Sigma|})\). Previous bounds only gave a \(O(n|\Sigma|)\) sample complexity. There are a number of new lower bounds for different combinations of \(d_1, d_2\) distance pairs.</p></div>
    </content>
    <updated>2021-01-05T05:26:33Z</updated>
    <published>2021-01-05T05:26:33Z</published>
    <category term="Monthly digest"/>
    <author>
      <name>Seshadhri</name>
    </author>
    <source>
      <id>https://ptreview.sublinear.info</id>
      <link href="https://ptreview.sublinear.info/?feed=rss2" rel="self" type="application/atom+xml"/>
      <link href="https://ptreview.sublinear.info" rel="alternate" type="text/html"/>
      <subtitle>The latest in property testing and sublinear time algorithms</subtitle>
      <title>Property Testing Review</title>
      <updated>2021-01-14T23:02:27Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/01/04/postdoctoral-fellow-at-the-university-of-texas-at-austin-apply-by-january-25-2021/</id>
    <link href="https://cstheory-jobs.org/2021/01/04/postdoctoral-fellow-at-the-university-of-texas-at-austin-apply-by-january-25-2021/" rel="alternate" type="text/html"/>
    <title>Postdoctoral Fellow at The University of Texas at Austin (apply by January 25, 2021)</title>
    <summary>The Computer Science Dept. at UT Austin invites applications for a Postdoctoral Fellow in theoretical computer science for the 21-22 academic year to work with David Zuckerman. Research interests should overlap with his: pseudorandomness, computational complexity, coding theory, and more. Review of applicants will begin on Jan. 25, but applications will be accepted until the […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Computer Science Dept. at UT Austin invites applications for a Postdoctoral Fellow in theoretical computer science for the 21-22 academic year to work with David Zuckerman. Research interests should overlap with his: pseudorandomness, computational complexity, coding theory, and more. Review of applicants will begin on Jan. 25, but applications will be accepted until the position is filled.</p>
<p>Website: <a href="https://utaustin.wd1.myworkdayjobs.com/UTstaff/job/UT-MAIN-CAMPUS/Postdoctoral-Fellow_R_00011430-1">https://utaustin.wd1.myworkdayjobs.com/UTstaff/job/UT-MAIN-CAMPUS/Postdoctoral-Fellow_R_00011430-1</a><br/>
Email: maguilar@cs.utexas.edu</p></div>
    </content>
    <updated>2021-01-04T20:52:10Z</updated>
    <published>2021-01-04T20:52:10Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-01-15T18:37:48Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/01/04/tenure-track-assistant-professor-at-bocconi-university-apply-by-january-8-2021/</id>
    <link href="https://cstheory-jobs.org/2021/01/04/tenure-track-assistant-professor-at-bocconi-university-apply-by-january-8-2021/" rel="alternate" type="text/html"/>
    <title>Tenure -track Assistant Professor at Bocconi University (apply by January 8, 2021)</title>
    <summary>Bocconi University, based in Milan, is Italy’s premiere private university. We invite applications for two tenure-track assistant professor positions in Computer Science. Compensation, which is negotiated on a case-by-case basis, will be highly competitive. The language of instruction is English. Website: https://lucatrevisan.wordpress.com/2020/12/11/bocconi-is-looking-for-assistant-professors-in-computer-science/ Email: l.trevisan@unibocconi.it</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Bocconi University, based in Milan, is Italy’s premiere private university. We invite applications for two tenure-track assistant professor positions in Computer Science. Compensation, which is negotiated on a case-by-case basis, will be highly competitive. The language of instruction is English.</p>
<p>Website: <a href="https://lucatrevisan.wordpress.com/2020/12/11/bocconi-is-looking-for-assistant-professors-in-computer-science/">https://lucatrevisan.wordpress.com/2020/12/11/bocconi-is-looking-for-assistant-professors-in-computer-science/</a><br/>
Email: l.trevisan@unibocconi.it</p></div>
    </content>
    <updated>2021-01-04T17:32:11Z</updated>
    <published>2021-01-04T17:32:11Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-01-15T18:37:48Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://lucatrevisan.wordpress.com/?p=4490</id>
    <link href="https://lucatrevisan.wordpress.com/2021/01/04/application-deadline-for-assistant-professor-positions-at-bocconi/" rel="alternate" type="text/html"/>
    <title>Application Deadline for Assistant Professor Positions at Bocconi</title>
    <summary>[application page] [call for applications] Bocconi University is looking for two Tenure-Track Assistant Professors in Computer Science, for positions starting in Fall 2021: the application deadline is this Friday, January 8, 2021. More information in an earlier post.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="https://jobmarket.unibocconi.eu/application.php?f=YjA2NGMyYjczODcyYTkxMWMxNzE5MDVjZWM5NGFkNTJeNjI=">[application page]</a> <a href="https://jobmarket.unibocconi.eu/include/dwload.php?a=Mjg2XmVhOWY0MWYzNzJlMTJmYjI2NDhiZmU0MDI2ODZjMjQyXi9kMC9qb2JtYXJrZXQudW5pYm9jY29uaS5ldS91cGxvYWQvREVDL3Nlc3Npb25fNjItMjAyMDExMTNeam1rX3Nlc3Npb25eam1zX15qbXNfZmlsZV9kZXRhaWxzX2VuXjYy">[call for applications]</a></p>



<p>Bocconi University is looking for two Tenure-Track Assistant Professors in Computer Science, for positions starting in Fall 2021: the application deadline is this Friday, January 8, 2021. </p>



<p>More information in an <a href="https://lucatrevisan.wordpress.com/2020/12/11/bocconi-is-looking-for-assistant-professors-in-computer-science/">earlier post</a>.</p></div>
    </content>
    <updated>2021-01-04T16:58:22Z</updated>
    <published>2021-01-04T16:58:22Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>luca</name>
    </author>
    <source>
      <id>https://lucatrevisan.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://lucatrevisan.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://lucatrevisan.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://lucatrevisan.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://lucatrevisan.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>"Marge, I agree with you - in theory. In theory, communism works. In theory." -- Homer Simpson</subtitle>
      <title>in   theory</title>
      <updated>2021-01-15T18:37:11Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/01/04/assistant-professor-in-computer-science-with-possiblity-of-tenure-track-at-department-of-computer-science-technical-faculty-of-it-aalborg-university-apply-by-february-10-2021/</id>
    <link href="https://cstheory-jobs.org/2021/01/04/assistant-professor-in-computer-science-with-possiblity-of-tenure-track-at-department-of-computer-science-technical-faculty-of-it-aalborg-university-apply-by-february-10-2021/" rel="alternate" type="text/html"/>
    <title>Assistant Professor in Computer Science (with possiblity of Tenure Track) at Department of Computer Science, Technical Faculty of IT, Aalborg University (apply by February 10, 2021)</title>
    <summary>Department of Computer Science at Aalborg University’s Technical Faculty of IT is looking to appoint a number of Assistant Professors (with possibility of tenure-track) for our Aalborg and Copenhagen Campus, starting June 1, 2021 or soon after this. Website: https://www.stillinger.aau.dk/vis-stilling/?vacancy=1136722 Email: jesper@cs.aau.dk</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Department of Computer Science at Aalborg University’s Technical Faculty of IT is looking to appoint a number of Assistant Professors (with possibility of tenure-track) for our Aalborg and Copenhagen Campus, starting June 1, 2021 or soon after this.</p>
<p>Website: <a href="https://www.stillinger.aau.dk/vis-stilling/?vacancy=1136722">https://www.stillinger.aau.dk/vis-stilling/?vacancy=1136722</a><br/>
Email: jesper@cs.aau.dk</p></div>
    </content>
    <updated>2021-01-04T10:12:53Z</updated>
    <published>2021-01-04T10:12:53Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-01-15T18:37:48Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/01/04/associate-professor-in-computer-science-at-department-of-computer-science-technical-faculty-of-it-aalborg-university-apply-by-february-10-2021/</id>
    <link href="https://cstheory-jobs.org/2021/01/04/associate-professor-in-computer-science-at-department-of-computer-science-technical-faculty-of-it-aalborg-university-apply-by-february-10-2021/" rel="alternate" type="text/html"/>
    <title>Associate Professor in Computer Science at Department of Computer Science, Technical Faculty of IT, Aalborg University (apply by February 10, 2021)</title>
    <summary>Department of Computer Science at Aalborg University’s Technical Faculty of IT is looking to appoint a number of Associate Professors for our Aalborg and Copenhagen Campus, starting June 1, 2021 or soon after this. Website: https://www.stillinger.aau.dk/vis-stilling/?vacancy=1136728 Email: jesper@cs.aau.dk</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Department of Computer Science at Aalborg University’s Technical Faculty of IT is looking to appoint a number of Associate Professors for our Aalborg and Copenhagen Campus, starting June 1, 2021 or soon after this.</p>
<p>Website: <a href="https://www.stillinger.aau.dk/vis-stilling/?vacancy=1136728">https://www.stillinger.aau.dk/vis-stilling/?vacancy=1136728</a><br/>
Email: jesper@cs.aau.dk</p></div>
    </content>
    <updated>2021-01-04T10:08:37Z</updated>
    <published>2021-01-04T10:08:37Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-01-15T18:37:48Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/001</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/001" rel="alternate" type="text/html"/>
    <title>TR21-001 |  Computation Over the Noisy Broadcast Channel with Malicious Parties | 

	Raghuvansh Saxena, 

	Gillat Kol, 

	Klim Efremenko, 

	Dmitry Paramonov</title>
    <summary>We study the $n$-party noisy broadcast channel with a constant fraction of malicious parties. Specifically, we assume that each non-malicious party holds an input bit, and communicates with the others in order to learn the input bits of all non-malicious parties. In each communication round, one of the parties broadcasts a bit to all other parties, and the bit received by each party is flipped with a fixed constant probability (independently for each recipient). How many rounds are needed?

Assuming there are no malicious parties, Gallager gave an $\mathcal{O}(n \log \log n)$-round protocol for the above problem, which was later shown to be optimal. This protocol, however, inherently breaks down in the presence of malicious parties.

We present a novel $n \cdot \tilde{\mathcal{O}}\left(\sqrt{\log n}\right)$-round protocol, that solves this problem even when almost half of the parties are malicious. Our protocol uses a new type of error correcting code, which we call a locality sensitive code and which may be of independent interest. Roughly speaking, these codes map "close" messages to "close" codewords, while messages that are not close are mapped to codewords that are very far apart.

We view our result as a first step towards a theory of property preserving interactive coding, i.e., interactive codes that preserve useful properties of the protocol being encoded. In our case, the naive protocol  over the noiseless broadcast channel, where all the parties broadcast their input bit and output all the bits received, works even in the presence of malicious parties. Our simulation of this protocol, unlike Gallager's, preserves this property of the original protocol.</summary>
    <updated>2021-01-03T21:04:23Z</updated>
    <published>2021-01-03T21:04:23Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-01-15T18:37:33Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/01/03/postdoc-in-parallel-and-distributed-algorithms-at-university-of-warwick-apply-by-january-13-2021/</id>
    <link href="https://cstheory-jobs.org/2021/01/03/postdoc-in-parallel-and-distributed-algorithms-at-university-of-warwick-apply-by-january-13-2021/" rel="alternate" type="text/html"/>
    <title>Postdoc in Parallel and Distributed Algorithms at University of Warwick (apply by January 13, 2021)</title>
    <summary>In connection with a research grant of Professor Artur Czumaj, we are looking for excellent candidates for a postdoc position in the area of the design and analysis of parallel and distributed algorithms, focusing on fundamental research in this area. Website: https://warwick.ac.uk/fac/sci/dcs/people/artur_czumaj/postdoc-advert-jan-2021 Email: aczumaj@acm.org</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>In connection with a research grant of Professor Artur Czumaj, we are looking for excellent candidates for a postdoc position in the area of the design and analysis of parallel and distributed algorithms, focusing on fundamental research in this area.</p>
<p>Website: <a href="https://warwick.ac.uk/fac/sci/dcs/people/artur_czumaj/postdoc-advert-jan-2021">https://warwick.ac.uk/fac/sci/dcs/people/artur_czumaj/postdoc-advert-jan-2021</a><br/>
Email: aczumaj@acm.org</p></div>
    </content>
    <updated>2021-01-03T16:25:31Z</updated>
    <published>2021-01-03T16:25:31Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-01-15T18:37:48Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=5240</id>
    <link href="https://www.scottaaronson.com/blog/?p=5240" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=5240#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=5240" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Distribute the vaccines NOW!</title>
    <summary xml:lang="en-US">My last post about covid vaccines felt like shouting uselessly into the void … at least until Patrick Collison, the cofounder of Stripe and a wonderful friend, massively signal-boosted the post by tweeting it. This business is of such life-and-death urgency right now, and a shift in attitude or a hardening of resolve by just […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>My <a href="https://www.scottaaronson.com/blog/?p=5224">last post</a> about covid vaccines felt like shouting uselessly into the void … at least until <a href="https://en.wikipedia.org/wiki/Patrick_Collison">Patrick Collison</a>, the cofounder of Stripe and a wonderful friend, massively signal-boosted the post by <a href="https://mobile.twitter.com/patrickc/status/1345139269904474113">tweeting</a> it.  This business is of such life-and-death urgency right now, and a <em>shift in attitude</em> or a <em>hardening of resolve</em> by just a few people reading could have such an outsized effect, that with apologies to anyone wanting me to return to my math/CS/physics lane, I feel like a second post on the same topic is called for.</p>



<p>Here’s my main point for today (as you might have noticed, I’ve changed the tagline of this entire blog accordingly):</p>



<p><strong>Reasonable people can disagree about whether vaccination could have, or should have, started much earlier.  But now that we in the US <em>have</em> painstakingly approved two vaccines, we should all agree about the <span class="has-inline-color has-vivid-red-color">urgent need to get millions of doses into people’s arms before they spoil!</span>  Sure, better the elderly than the young, better essential than inessential workers—but much more importantly, better today than tomorrow, and better anyone than no one!</strong></p>



<p>Israel, which <em>didn’t</em> do especially well in earlier stages of the pandemic, is now putting the rest of the planet to shame with vaccinations.  What Dana and I hear from our friends and relatives there confirms what you can read <a href="https://www.theguardian.com/world/2020/dec/30/how-has-israel-launched-the-worlds-fastest-covid-vaccination-drive">here</a>, <a href="https://l.facebook.com/l.php?u=https%3A%2F%2Fwww.nytimes.com%2F2021%2F01%2F01%2Fworld%2Fmiddleeast%2Fisrael-coronavirus-vaccines.html%3Ffbclid%3DIwAR1mmRY74TuILhmj08gqlTM3bUlHjIgcl4bYpl788Z8Y8gPnVV9O3c9NdX8&amp;h=AT3_NCHDgesUdnhZASL2Q4v840iZjNdwl9PF_by1ekphfj74Aj558AJRN4jE_vLygxmdETWAzHpJjBv_WaTYvfOtdjuloJsQwU6HpitdfO4Mng8og-m9Y7PyXsvb2rWs3Q&amp;__tn__=%2CmH-R&amp;c[0]=AT2H2XioKIFzYeGiu0qeLpT21jx4aDKGvcu4ymay0B8b1AVIW0fPfMQW-jBEjojJvf8Q0p_387lyA7EGqh29PllsKvZUKAbVuBXyxet7VrpMc4bMIzHkSm2B35yFxWJ1zsyxtQesY6-dcQmt6s2PvpWSMIo">here</a>, and elsewhere.  Rabin Square in Tel Aviv is now a huge <a href="https://static01.nyt.com/images/2021/01/01/world/01virus-israel-vaccine02/merlin_181829658_7892b3dd-561f-4678-8a02-29b507628ab6-jumbo.jpg?quality=90&amp;auto=webp">vaccination field site</a>.  Vaccinations are now proceeding 24/7, even on Shabbat—something the ultra-Orthodox rabbis are <a href="https://www.israelnationalnews.com/News/News.aspx/293713">grudgingly tolerating</a> under the doctrine of <a href="https://en.wikipedia.org/wiki/Pikuach_nefesh#:~:text=Pikuach%20nefesh%20is%20the%20principle,of%20the%20Torah%20becomes%20inapplicable.">“pikuach nefesh”</a> (i.e., saving a life overrides almost every other religious obligation).  Israelis are receiving texts at all hours telling them when it’s their turn and where to go.  Apparently, after the nurses are finished with everyone who had appointments, rather than waste whatever already-thawed supply is left, they simply go into the street and <a href="https://twitter.com/erlichya/status/1344735831655936001">offer the extra doses</a> to anyone passing by.</p>



<p>Contrast that with the <a href="https://www.nytimes.com/2020/12/31/opinion/coronavirus-vaccines-expiring.html">historic fiasco</a>—yes, <em>another</em> historic fiasco—<a href="https://nymag.com/intelligencer/article/americas-vaccine-rollout-disaster.html">now unfolding in the US</a>.  The Trump administration had pledged to administer 20 million vaccines (well, Trump originally said <em>100</em> million) by the end of 2020.  Instead, fewer than three million were administered, with the already-glacial pace slowing even further over the holidays.  Unbelievably, <em>millions of doses are on track to spoil this month, before they can be administered</em>.  The bottleneck is now not manufacturing, it’s not supply, it’s just pure bureaucratic dysfunction and chaos, lack of funding and staff, and a stone-faced unwillingness by governors to deviate from harebrained “plans” and “guidelines” even with their populations’ survival at stake.</p>



<p>Famously, the CDC urged that essential workers get vaccinated before the elderly, since even though their own modeling predicted that many more people from all ethnic groups would die that way, at least the deaths would be more equitably distributed.  While there <em>are</em> some good arguments to prioritize essential workers, an outcry then led to the CDC partially backtracking, and to many states just making up their own guidelines.  But we’re now, for real, headed for a scenario where none of these moral-philosophy debates turn out to matter, since the vaccines will simply spoil in freezers (!!!) while the medical system struggles to comply with the Byzantine rules about who gets them first.</p>



<p>While I’d <em>obviously</em> never advocate such a thing, one wonders whether there’s an idealistic medical worker, somewhere in the US, who’s willing to risk jail for vaccinating people without approval, using supply that would otherwise be wasted.  If <em>anything</em> could galvanize this sad and declining nation to move faster, maybe it’s that.</p>



<p/><hr/><p/>



<p>In my <a href="https://www.scottaaronson.com/blog/?p=5224">last post</a>, I invited people to explain to me where I went wrong in my naïve, simplistic, doofus belief that, were our civilization still capable of “WWII” levels of competence, flexibility, and calculated risk-tolerance, most of the world could have already been vaccinated by now.  In the rest of this post, I’d like to list the eight most important counterarguments to that position that commenters offered (at least, those that I hadn’t already anticipated in the post itself), together with my brief responses to them.</p>



<ol><li><strong>Faster approval wouldn’t have helped, since the limiting factor was just the time needed to ramp up the supply.</strong>  As the first part of this post discussed, ironically supply is <em>not</em> now the limiting factor, and approval even a month or two earlier could’ve provided precious time to iron out the massive problems in distribution.  More broadly, though, what’s becoming obvious is that we needed faster <em>everything</em>: testing, approval, manufacturing, and distribution.</li><li><strong>The real risk, with vaccines, is long-term side effects, ones that might manifest only after years.</strong>  What I don’t get is, if people genuinely believe this, then why are they OK with having approved the vaccines <em>last month</em>?  Why shouldn’t we have waited until 2024, or maybe 2040?  By that point, those of us who were still alive could take the covid vaccine with <em>real</em> confidence, at least that the dreaded side effects would be unlikely to manifest before 2060.</li><li><strong>Much like with <a href="https://en.wikipedia.org/wiki/Amdahl%27s_law">Amdahl’s Law</a>, there are limits to how much more money could’ve sped up vaccine manufacturing.</strong>   My problem is that, while this is undoubtedly true, I see no indication that we were anywhere close to those limits—or indeed, that the paltry ~$9 billion the US spent on covid vaccines was the output of <em>any</em> rational cost/benefit calculation.  It’s like: suppose an enemy army had invaded the US mainland, slaughtered 330,000 people, and shut down much of the economy.  Can you imagine Congress responding by giving the Pentagon a <em>1.3%</em> budget increase to fight back, reasoning that any more would run up against Amdahl’s Law?  That’s how much $9 billion is.</li><li><strong>The old, inactivated-virus vaccines often took years to develop, so spending years to test them as well made a lot more sense.</strong>  This is undoubtedly true, but is not a counterargument.  It’s time to rethink the whole vaccine approval process for the era of programmable mRNA, which is <em>also</em> the era of pandemics that can spread around the world in months.</li><li><strong>Human challenge trials wouldn’t have provided much information, because you can’t do challenge trials with old or sick people, and because covid spread so widely that normal Phase III trials were perfectly informative.</strong>  Actually, <a href="https://www.1daysooner.org/">1DaySooner</a> had plenty of elderly volunteers and volunteers with preexisting conditions.  It bothers me how the impossibility of using those volunteers is treated like a law of physics, rather than what it is: another non-obvious moral tradeoff.  Also, compared to Phase III trials, it looks like challenge trials would’ve bought us at least a couple months and maybe a half-million lives.</li><li><strong>Doctors can’t think like utilitarians—e.g., risking hundreds of lives in challenge trials in order to save millions of lives with a vaccine—because it’s a slippery slope from there to cutting up one person in order to save ten with their organs.</strong>  Well, I think the <em>informed consent</em> of the challenge trial participants is a pretty important factor here!  As is their &gt;99% chance of survival.  Look, <em>anyone</em> who works in public health makes utilitarian tradeoffs; the question is whether they’re good or bad ones.  As someone who lost most of his extended family in the Holocaust, my rule of thumb is that, if you’re worrying every second about whether you might become Dr. Mengele, that’s a pretty good sign that you <em>won’t</em> become Dr. Mengele.</li><li><strong>If a hastily-approved vaccine turned out to be ineffective or dangerous, it could diminish the public’s trust in all future vaccines.</strong>  Yes, of course there’s such a tradeoff, but I want you to notice the immense irony: this argument effectively says we can condemn millions to die right now, out of concern for hypothetical <em>other</em> millions in the future.  And yet some of the people making this argument will then turn around and call <em>me</em> a callous utilitarian!</li><li><strong>I’m suffering from hindsight bias: it might be clear <em>now</em> that vaccine approval and distribution should’ve happened a lot faster, but experts had no way of knowing that in the spring.</strong>  <a href="https://www.scottaaronson.com/blog/?p=4780">Here’s</a> my post from May 1, entitled “Vaccine challenge trials NOW!”  I was encouraged by the many others who said similar things still earlier.  Was it just a lucky gamble?  Had we been allowed to get vaccinated then, at least we could’ve put our bloodstreams where our mouths were, and profited from the gamble!  More seriously, I sympathize with the decision-makers who’d be on the hook had an early vaccine rollout proved disastrous.  But if we don’t learn a lesson from this, and ready ourselves for the <em>next</em> pandemic with an mRNA platform that can be customized, tested, and injected into people’s arms within at most 2-3 months, we’ll <em>really</em> have no excuse.</li></ol>



<p/></div>
    </content>
    <updated>2021-01-02T09:36:18Z</updated>
    <published>2021-01-02T09:36:18Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="The Fate of Humanity"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2021-01-14T21:04:20Z</updated>
    </source>
  </entry>
</feed>
