<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2019-05-29T22:24:01Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-1040381893569171546</id>
    <link href="https://blog.computationalcomplexity.org/feeds/1040381893569171546/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/05/nsf-panels.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/1040381893569171546" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/1040381893569171546" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/05/nsf-panels.html" rel="alternate" type="text/html"/>
    <title>NSF Panels</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">The government shut down in January led to delays at the National Science Foundation and only recently announcing decisions on grants submitted last fall. For those who successfully received awards, congratulations! For those who didn't, don't take it personally, buckle up and try again.<br/>
<br/>
For those who don't know how the process works, for each grant program, the program directors organize one or more panels which typically meets in person at NSF headquarters in Alexandria, Virginia. A typical panel has about a dozen panelists and twenty or so proposals. Before the panels, each proposal gets at least three reviews by the panelists. Discussions ensue over a day or two, proposals get sorted into categories: Highly Competitive, Competitive, Low Competitive and Not Competitive and then ranked ordered in the top categories.<br/>
<br/>
There are tight rules for Conflict-of-Interest and those who are conflicted have to leave the room during the discussions on those papers.<br/>
<br/>
If you do get asked to serve on a panel, you should definitely do so. You get to see how the process works and help influence funding and research directions in your field. You can't reveal when you serve on a particular panel but you can say "Served on NSF Panels" on your CV.<br/>
<br/>
Panels tend to take proposals that will likely make progress and not take ones less risky. Funding risky proposals is specifically mentioned to the panel but when push comes to shove and there is less funding than worthy proposals, panelists gravitate towards proposals that don't take chances.<br/>
<br/>
Panels are not unlike conference program committees. It didn't always work this way, it used to be more like journal publications. I remember when the program director would send out proposals for outside reviews and then make funding decisions. That gave the program director more discretion to fund a wider variety of proposals.<br/>
<br/>
The NSF budget for computing goes up slowly while the number of academic computer scientists grows at a much larger clip. Until this changes, we'll have more and more worthy proposals unfunded, particularly proposals of bold risky projects. That's the saddest part of all.</div>
    </content>
    <updated>2019-05-29T20:09:00Z</updated>
    <published>2019-05-29T20:09:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-05-29T20:09:33Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1905.11968</id>
    <link href="http://arxiv.org/abs/1905.11968" rel="alternate" type="text/html"/>
    <title>Chasing Convex Bodies Optimally</title>
    <feedworld_mtime>1559088000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sellke:Mark.html">Mark Sellke</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1905.11968">PDF</a><br/><b>Abstract: </b>In the chasing convex bodies problem, an online player receives a request
sequence of $N$ convex sets $K_1,\dots, K_N$ contained in a normed space
$\mathbb R^d$. The player starts at $x_0\in \mathbb R^d$, and after observing
each $K_n$ picks a new point $x_n\in K_n$. At each step the player pays a
movement cost of $||x_n-x_{n-1}||$. The player aims to maintain a constant
competitive ratio against the minimum cost possible in hindsight, i.e. knowing
all requests in advance. The existence of a finite competitive ratio for convex
body chasing was first conjectured in 1991 by Friedman and Linial. This
conjecture was recently resolved with an exponential $2^{O(d)}$ upper bound on
the competitive ratio.
</p>
<p>In this paper, we drastically improve the exponential upper bound. We give an
algorithm achieving competitive ratio $d$ for arbitrary normed spaces, which is
exactly tight for $\ell^{\infty}$. In Euclidean space, our algorithm achieves
nearly optimal competitive ratio $O(\sqrt{d\log N})$, compared to a lower bound
of $\sqrt{d}$. Our approach extends another recent work which chases nested
convex bodies using the classical Steiner point of a convex body. We define the
functional Steiner point of a convex function and apply it to the work function
to obtain our algorithm.
</p></div>
    </summary>
    <updated>2019-05-29T01:29:06Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-05-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1905.11947</id>
    <link href="http://arxiv.org/abs/1905.11947" rel="alternate" type="text/html"/>
    <title>Private Identity Testing for High-Dimensional Distributions</title>
    <feedworld_mtime>1559088000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Canonne:Cl=eacute=ment_L=.html">Cl√©ment L. Canonne</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kamath:Gautam.html">Gautam Kamath</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/McMillan:Audra.html">Audra McMillan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/u/Ullman:Jonathan.html">Jonathan Ullman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zakynthinou:Lydia.html">Lydia Zakynthinou</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1905.11947">PDF</a><br/><b>Abstract: </b>In this work we present novel differentially private identity
(goodness-of-fit) testers for natural and widely studied classes of
multivariate product distributions: Gaussians in $\mathbb{R}^d$ with known
covariance and product distributions over $\{\pm 1\}^{d}$. Our testers have
improved sample complexity compared to those derived from previous techniques,
and are the first testers whose sample complexity matches the order-optimal
minimax sample complexity of $O(d^{1/2}/\alpha^2)$ in many parameter regimes.
We construct two types of testers, exhibiting tradeoffs between sample
complexity and computational complexity. Finally, we provide a two-way
reduction between testing a subclass of multivariate product distributions and
testing univariate distributions, and thereby obtain upper and lower bounds for
testing this subclass of product distributions.
</p></div>
    </summary>
    <updated>2019-05-29T01:26:11Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-05-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1905.11924</id>
    <link href="http://arxiv.org/abs/1905.11924" rel="alternate" type="text/html"/>
    <title>Paper Matching with Local Fairness Constraints</title>
    <feedworld_mtime>1559088000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kobren:Ari.html">Ari Kobren</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Saha:Barna.html">Barna Saha</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/McCallum:Andrew.html">Andrew McCallum</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1905.11924">PDF</a><br/><b>Abstract: </b>Automatically matching reviewers to papers is a crucial step of the peer
review process for venues receiving thousands of submissions. Unfortunately,
common paper matching algorithms often construct matchings suffering from two
critical problems: (1) the group of reviewers assigned to a paper do not
collectively possess sufficient expertise, and (2) reviewer workloads are
highly skewed. In this paper, we propose a novel local fairness formulation of
paper matching that directly addresses both of these issues. Since optimizing
our formulation is not always tractable, we introduce two new algorithms,
FairIR and FairFlow, for computing fair matchings that approximately optimize
the new formulation. FairIR solves a relaxation of the local fairness
formulation and then employs a rounding technique to construct a valid matching
that provably maximizes the objective and only compromises on fairness with
respect to reviewer loads and papers by a small constant. In contrast, FairFlow
is not provably guaranteed to produce fair matchings, however it can be 2x as
efficient as FairIR and an order of magnitude faster than matching algorithms
that directly optimize for fairness. Empirically, we demonstrate that both
FairIR and FairFlow improve fairness over standard matching algorithms on real
conference data. Moreover, in comparison to state-of-the-art matching
algorithms that optimize for fairness only, FairIR achieves higher objective
scores, FairFlow achieves competitive fairness, and both are capable of more
evenly allocating reviewers.
</p></div>
    </summary>
    <updated>2019-05-29T01:31:17Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-05-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1905.11888</id>
    <link href="http://arxiv.org/abs/1905.11888" rel="alternate" type="text/html"/>
    <title>Communication Complexity in Locally Private Distribution Estimation and Heavy Hitters</title>
    <feedworld_mtime>1559088000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Acharya:Jayadev.html">Jayadev Acharya</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sun:Ziteng.html">Ziteng Sun</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1905.11888">PDF</a><br/><b>Abstract: </b>We consider the problems of distribution estimation and heavy hitter
(frequency) estimation under privacy and communication constraints. While these
constraints have been studied separately, optimal schemes for one are
sub-optimal for the other. We propose a sample-optimal $\varepsilon$-locally
differentially private (LDP) scheme for distribution estimation, where each
user communicates only one bit, and requires no public randomness. We show that
Hadamard Response, a recently proposed scheme for $\varepsilon$-LDP
distribution estimation is also utility-optimal for heavy hitter estimation.
Finally, we show that unlike distribution estimation, without public randomness
where only one bit suffices, any heavy hitter estimation algorithm that
communicates $o(\min \{\log n, \log k\})$ bits from each user cannot be
optimal.
</p></div>
    </summary>
    <updated>2019-05-29T01:29:11Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-05-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1905.11877</id>
    <link href="http://arxiv.org/abs/1905.11877" rel="alternate" type="text/html"/>
    <title>Chasing Convex Bodies with Linear Competitive Ratio</title>
    <feedworld_mtime>1559088000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Argue:C=_J=.html">C. J. Argue</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gupta:Anupam.html">Anupam Gupta</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Guruganesh:Guru.html">Guru Guruganesh</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tang:Ziye.html">Ziye Tang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1905.11877">PDF</a><br/><b>Abstract: </b>We study the problem of chasing convex bodies online: given a sequence of
convex bodies $K_t\subseteq \mathbb{R}^d$ the algorithm must respond with
points $x_t\in K_t$ in an online fashion (i.e., $x_t$ is chosen before
$K_{t+1}$ is revealed). The objective is to minimize the total distance between
successive points in this sequence. Recently, Bubeck et al. (STOC 2019) gave a
$2^{O(d)}$-competitive algorithm for this problem. We give an algorithm that is
$O(\min(d, \sqrt{d \log T}))$-competitive for any sequence of length $T$.
</p></div>
    </summary>
    <updated>2019-05-29T01:26:58Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-05-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1905.11838</id>
    <link href="http://arxiv.org/abs/1905.11838" rel="alternate" type="text/html"/>
    <title>A Parameterized Perspective on Protecting Elections</title>
    <feedworld_mtime>1559088000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dey:Palash.html">Palash Dey</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Misra:Neeldhara.html">Neeldhara Misra</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nath:Swaprava.html">Swaprava Nath</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shakya:Garima.html">Garima Shakya</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1905.11838">PDF</a><br/><b>Abstract: </b>We study the parameterized complexity of the optimal defense and optimal
attack problems in voting. In both the problems, the input is a set of voter
groups (every voter group is a set of votes) and two integers $k_a$ and $k_d$
corresponding to respectively the number of voter groups the attacker can
attack and the number of voter groups the defender can defend. A voter group
gets removed from the election if it is attacked but not defended. In the
optimal defense problem, we want to know if it is possible for the defender to
commit to a strategy of defending at most $k_d$ voter groups such that, no
matter which $k_a$ voter groups the attacker attacks, the outcome of the
election does not change. In the optimal attack problem, we want to know if it
is possible for the attacker to commit to a strategy of attacking $k_a$ voter
groups such that, no matter which $k_d$ voter groups the defender defends, the
outcome of the election is always different from the original (without any
attack) one.
</p></div>
    </summary>
    <updated>2019-05-29T01:38:08Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-05-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1905.11822</id>
    <link href="http://arxiv.org/abs/1905.11822" rel="alternate" type="text/html"/>
    <title>Robotic bees: Algorithms for collision detection and prevention</title>
    <feedworld_mtime>1559088000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Vincent Arcila, Isabel Piedrahita <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1905.11822">PDF</a><br/><b>Abstract: </b>In the following paper we will discuss data structures suited for distance
threshold queries keeping in mind real life application such as collision
detection on robotic bees. We will focus on spatial hashes designed to store 3D
points and capable of fastly determining which of them surpass a specific
threshold from any other. In this paper we will discuss related literature,
explain in depth the data structure chosen with its design criteria, operations
and speed and memory efficiency analysis.
</p></div>
    </summary>
    <updated>2019-05-29T01:33:35Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-05-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1905.11743</id>
    <link href="http://arxiv.org/abs/1905.11743" rel="alternate" type="text/html"/>
    <title>Certified lattice reduction</title>
    <feedworld_mtime>1559088000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Espitau:Thomas.html">Thomas Espitau</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Joux:Antoine.html">Antoine Joux</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1905.11743">PDF</a><br/><b>Abstract: </b>Quadratic form reduction and lattice reduction are fundamental tools in
computational number theory and in computer science, especially in
cryptography. The celebrated Lenstra-Lenstra-Lov\'asz reduction algorithm
(so-called LLL) has been improved in many ways through the past decades and
remains one of the central methods used for reducing integral lattice basis. In
particular, its floating-point variants-where the rational arithmetic required
by Gram-Schmidt orthogonalization is replaced by floating-point arithmetic-are
now the fastest known. However, the systematic study of the reduction theory of
real quadratic forms or, more generally, of real lattices is not widely
represented in the literature. When the problem arises, the lattice is usually
replaced by an integral approximation of (a multiple of) the original lattice,
which is then reduced. While practically useful and proven in some special
cases, this method doesn't offer any guarantee of success in general. In this
work, we present an adaptive-precision version of a generalized LLL algorithm
that covers this case in all generality. In particular, we replace
floating-point arithmetic by Interval Arithmetic to certify the behavior of the
algorithm. We conclude by giving a typical application of the result in
algebraic number theory for the reduction of ideal lattices in number fields.
</p></div>
    </summary>
    <updated>2019-05-29T01:37:29Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-05-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1905.11635</id>
    <link href="http://arxiv.org/abs/1905.11635" rel="alternate" type="text/html"/>
    <title>Complexity lower bounds for computing the approximately-commuting operator value of non-local games to high precision</title>
    <feedworld_mtime>1559088000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Coudron:Matthew.html">Matthew Coudron</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Slofstra:William.html">William Slofstra</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1905.11635">PDF</a><br/><b>Abstract: </b>We study the problem of approximating the commuting-operator value of a
two-player non-local game. It is well-known that it is $\mathrm{NP}$-complete
to decide whether the classical value of a non-local game is 1 or $1-
\epsilon$. Furthermore, as long as $\epsilon$ is small enough, this result does
not depend on the gap $\epsilon$. In contrast, a recent result of Fitzsimons,
Ji, Vidick, and Yuen shows that the complexity of computing the quantum value
grows without bound as the gap $\epsilon$ decreases. In this paper, we show
that this also holds for the commuting-operator value of a game. Specifically,
in the language of multi-prover interactive proofs, we show that the power of
$\mathrm{MIP}^{co}(2,1,1,s)$ (proofs with two provers, one round, completeness
probability $1$, soundness probability $s$, and commuting-operator strategies)
can increase without bound as the gap $1-s$ gets arbitrarily small.
</p>
<p>Our results also extend naturally in two ways, to perfect zero-knowledge
protocols, and to lower bounds on the complexity of computing the
approximately-commuting value of a game. Thus we get lower bounds on the
complexity class $\mathrm{PZK}$-$\mathrm{MIP}^{co}_{\delta}(2,1,1,s)$ of
perfect zero-knowledge multi-prover proofs with approximately-commuting
operator strategies, as the gap $1-s$ gets arbitrarily small. While we do not
know any computable time upper bound on the class $\mathrm{MIP}^{co}$, a result
of the first author and Vidick shows that for $s = 1-1/\text{poly}(f(n))$ and
$\delta = 1/\text{poly}(f(n))$, the class $\mathrm{MIP}^{co}_\delta(2,1,1,s)$,
with constant communication from the provers, is contained in
$\mathrm{TIME}(\exp(\text{poly}(f(n))))$. We give a lower bound of
$\mathrm{coNTIME}(f(n))$ (ignoring constants inside the function) for this
class, which is tight up to polynomial factors assuming the exponential time
hypothesis.
</p></div>
    </summary>
    <updated>2019-05-29T01:20:55Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-05-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1905.11612</id>
    <link href="http://arxiv.org/abs/1905.11612" rel="alternate" type="text/html"/>
    <title>Average Bias and Polynomial Sources</title>
    <feedworld_mtime>1559088000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bhattacharyya:Arnab.html">Arnab Bhattacharyya</a>, Philips George John, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Ghoshal:Suprovat.html">Suprovat Ghoshal</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Meka:Raghu.html">Raghu Meka</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1905.11612">PDF</a><br/><b>Abstract: </b>We identify a new notion of pseudorandomness for randomness sources, which we
call the average bias. Given a distribution $Z$ over $\{0,1\}^n$, its average
bias is: $b_{\text{av}}(Z) =2^{-n} \sum_{c \in \{0,1\}^n} |\mathbb{E}_{z \sim
Z}(-1)^{\langle c, z\rangle}|$. A source with average bias at most $2^{-k}$ has
min-entropy at least $k$, and so low average bias is a stronger condition than
high min-entropy. We observe that the inner product function is an extractor
for any source with average bias less than $2^{-n/2}$.
</p>
<p>The notion of average bias especially makes sense for polynomial sources,
i.e., distributions sampled by low-degree $n$-variate polynomials over
$\mathbb{F}_2$. For the well-studied case of affine sources, it is easy to see
that min-entropy $k$ is exactly equivalent to average bias of $2^{-k}$. We show
that for quadratic sources, min-entropy $k$ implies that the average bias is at
most $2^{-\Omega(\sqrt{k})}$. We use this relation to design dispersers for
separable quadratic sources with a min-entropy guarantee.
</p></div>
    </summary>
    <updated>2019-05-29T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-05-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1905.11580</id>
    <link href="http://arxiv.org/abs/1905.11580" rel="alternate" type="text/html"/>
    <title>A near-optimal algorithm for approximating the John Ellipsoid</title>
    <feedworld_mtime>1559088000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cohen:Michael_B=.html">Michael B. Cohen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cousins:Ben.html">Ben Cousins</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lee:Yin_Tat.html">Yin Tat Lee</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yang:Xin.html">Xin Yang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1905.11580">PDF</a><br/><b>Abstract: </b>We develop a simple and efficient algorithm for approximating the John
Ellipsoid of a symmetric polytope. Our algorithm is near optimal in the sense
that our time complexity matches the current best verification algorithm. We
also provide the MATLAB code for further research.
</p></div>
    </summary>
    <updated>2019-05-29T01:29:30Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-05-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1905.11573</id>
    <link href="http://arxiv.org/abs/1905.11573" rel="alternate" type="text/html"/>
    <title>On the Complexity of Distributed Splitting Problems</title>
    <feedworld_mtime>1559088000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bamberger:Philipp.html">Philipp Bamberger</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Ghaffari:Mohsen.html">Mohsen Ghaffari</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kuhn:Fabian.html">Fabian Kuhn</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Maus:Yannic.html">Yannic Maus</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/u/Uitto:Jara.html">Jara Uitto</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1905.11573">PDF</a><br/><b>Abstract: </b>One of the fundamental open problems in the area of distributed graph
algorithms is the question of whether randomization is needed for efficient
symmetry breaking. While there are fast, $\text{poly}\log n$-time randomized
distributed algorithms for all of the classic symmetry breaking problems, for
many of them, the best deterministic algorithms are almost exponentially
slower. The following basic local splitting problem, which is known as the
\emph{weak splitting} problem takes a central role in this context: Each node
of a graph $G=(V,E)$ has to be colored red or blue such that each node of
sufficiently large degree has at least one node of each color among its
neighbors. Ghaffari, Kuhn, and Maus [STOC '17] showed that this seemingly
simple problem is complete w.r.t. the above fundamental open question in the
following sense: If there is an efficient $\text{poly}\log n$-time determinstic
distributed algorithm for weak splitting, then there is such an algorithm for
all locally checkable graph problems for which an efficient randomized
algorithm exists. In this paper, we investigate the distributed complexity of
weak splitting and some closely related problems. E.g., we obtain efficient
algorithms for special cases of weak splitting, where the graph is nearly
regular. In particular, we show that if $\delta$ and $\Delta$ are the minimum
and maximum degrees of $G$ and if $\delta=\Omega(\log n)$, weak splitting can
be solved deterministically in time
$O\big(\frac{\Delta}{\delta}\cdot\text{poly}(\log n)\big)$. Further, if $\delta
= \Omega(\log\log n)$ and $\Delta\leq 2^{\varepsilon\delta}$, there is a
randomized algorithm with time complexity
$O\big(\frac{\Delta}{\delta}\cdot\text{poly}(\log\log n)\big)$.
</p></div>
    </summary>
    <updated>2019-05-29T01:35:51Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-05-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1905.11566</id>
    <link href="http://arxiv.org/abs/1905.11566" rel="alternate" type="text/html"/>
    <title>Adaptive Reduced Rank Regression</title>
    <feedworld_mtime>1559088000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wu:Qiong.html">Qiong Wu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wong:Felix_Ming_Fai.html">Felix Ming Fai Wong</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liu:Zhenming.html">Zhenming Liu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Yanhua.html">Yanhua Li</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kanade:Varun.html">Varun Kanade</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1905.11566">PDF</a><br/><b>Abstract: </b>Low rank regression has proven to be useful in a wide range of forecasting
problems. However, in settings with a low signal-to-noise ratio, it is known to
suffer from severe overfitting. This paper studies the reduced rank regression
problem and presents algorithms with provable generalization guarantees. We use
adaptive hard rank-thresholding in two different parts of the data analysis
pipeline. First, we consider a low rank projection of the data to eliminate the
components that are most likely to be noisy. Second, we perform a standard
multivariate linear regression estimator on the data obtained in the first
step, and subsequently consider a low-rank projection of the obtained
regression matrix. Both thresholding is performed in a data-driven manner and
is required to prevent severe overfitting as our lower bounds show.
Experimental results show that our approach either outperforms or is
competitive with existing baselines.
</p></div>
    </summary>
    <updated>2019-05-29T01:24:46Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-05-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1905.11564</id>
    <link href="http://arxiv.org/abs/1905.11564" rel="alternate" type="text/html"/>
    <title>Adversarially Robust Learning Could Leverage Computational Hardness</title>
    <feedworld_mtime>1559088000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Garg:Sanjam.html">Sanjam Garg</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jha:Somesh.html">Somesh Jha</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mahloujifar:Saeed.html">Saeed Mahloujifar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mahmoody:Mohammad.html">Mohammad Mahmoody</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1905.11564">PDF</a><br/><b>Abstract: </b>Over recent years, devising classification algorithms that are robust to
adversarial perturbations has emerged as a challenging problem. In particular,
deep neural nets (DNNs) seem to be susceptible to small imperceptible changes
over test instances. In this work, we study whether there is any learning task
for which it is possible to design classifiers that are only robust against
polynomial-time adversaries. Indeed, numerous cryptographic tasks (e.g.
encryption of long messages) are only be secure against computationally bounded
adversaries, and are indeed mpossible for computationally unbounded attackers.
Thus, it is natural to ask if the same strategy could help robust learning.
</p>
<p>We show that computational limitation of attackers can indeed be useful in
robust learning by demonstrating a classifier for a learning task in which
computational and information theoretic adversaries of bounded perturbations
have very different power. Namely, while computationally unbounded adversaries
can attack successfully and find adversarial examples with small perturbation,
polynomial time adversaries are unable to do so unless they can break standard
cryptographic hardness assumptions. Our results, therefore, indicate that
perhaps a similar approach to cryptography (relying on computational hardness)
holds promise for achieving computationally robust machine learning. We also
show that the existence of such learning task in which computational robustness
beats information theoretic robustness implies (average case) hard problems in
$\mathbf{NP}$.
</p></div>
    </summary>
    <updated>2019-05-29T01:21:19Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-05-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1905.11512</id>
    <link href="http://arxiv.org/abs/1905.11512" rel="alternate" type="text/html"/>
    <title>A New Algorithm for Decremental Single-Source Shortest Paths with Applications to Vertex-Capacitated Flow and Cut Problems</title>
    <feedworld_mtime>1559088000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chuzhoy:Julia.html">Julia Chuzhoy</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Khanna:Sanjeev.html">Sanjeev Khanna</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1905.11512">PDF</a><br/><b>Abstract: </b>We study the vertex-decremental Single-Source Shortest Paths (SSSP) problem:
given an undirected graph $G=(V,E)$ with lengths $\ell(e)\geq 1$ on its edges
and a source vertex $s$, we need to support (approximate) shortest-path queries
in $G$, as $G$ undergoes vertex deletions. In a shortest-path query, given a
vertex $v$, we need to return a path connecting $s$ to $v$, whose length is at
most $(1+\epsilon)$ times the length of the shortest such path, where
$\epsilon$ is a given accuracy parameter. The problem has many applications,
for example to flow and cut problems in vertex-capacitated graphs.
</p>
<p>Our main result is a randomized algorithm for vertex-decremental SSSP with
total expected update time $O(n^{2+o(1)}\log L)$, that responds to each
shortest-path query in $O(n\log L)$ time in expectation, returning a
$(1+\epsilon)$-approximate shortest path. The algorithm works against an
adaptive adversary. The main technical ingredient of our algorithm is an
$\tilde O(|E(G)|+ n^{1+o(1)})$-time algorithm to compute a \emph{core
decomposition} of a given dense graph $G$, which allows us to compute short
paths between pairs of query vertices in $G$ efficiently. We believe that this
core decomposition algorithm may be of independent interest. We use our result
for vertex-decremental SSSP to obtain $(1+\epsilon)$-approximation algorithms
for maximum $s$-$t$ flow and minimum $s$-$t$ cut in vertex-capacitated graphs,
in expected time $n^{2+o(1)}$, and an $O(\log^4n)$-approximation algorithm for
the vertex version of the sparsest cut problem with expected running time
$n^{2+o(1)}$. These results improve upon the previous best known results for
these problems in the regime where $m= \omega(n^{1.5 + o(1)})$.
</p></div>
    </summary>
    <updated>2019-05-29T01:33:41Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-05-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1905.11458</id>
    <link href="http://arxiv.org/abs/1905.11458" rel="alternate" type="text/html"/>
    <title>Noise sensitivity of Boson Sampling and density of bosons</title>
    <feedworld_mtime>1559088000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Valery Shchesnovich <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1905.11458">PDF</a><br/><b>Abstract: </b>Inevitable experimental noise lies on the way to demonstrate the
computational advantage of quantum devices over digital computers in some
specific tasks. One of the proposals is Boson Sampling of Aaronson &amp; Arkhipov,
where the specific classically hard task is sampling from the many-body quantum
interference of $N$ indistinguishable single bosons on a $M$-dimensional
unitary network. Can a noisy realisation of Boson Sampling be efficiently and
faithfully simulated classically? We consider how the output distribution of
noisy Boson Sampling can be distinguished from that of classical simulation
accounting for the many-body interference only up to a fixed order. It is shown
that one can distinguish the output distribution of noisy Boson Sampling from
that of classical simulation with a number of samples that depends solely on
the highest order of quantum interference accounted for by the classical
simulation, noise amplitude, and density of bosons $\rho = N/M$. The results
indicate that noisy Boson Sampling in a regime of finite density of bosons,
$\rho= \Theta(1)$, i.e., on a small network $M = N/\rho$, retains quantum
advantage over digital computers if the amplitude of noise remains bounded as
$N$ scales up.
</p></div>
    </summary>
    <updated>2019-05-29T01:21:16Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-05-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-25562705.post-831739446833439686</id>
    <link href="http://aaronsadventures.blogspot.com/feeds/831739446833439686/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=25562705&amp;postID=831739446833439686" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/25562705/posts/default/831739446833439686" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/25562705/posts/default/831739446833439686" rel="self" type="application/atom+xml"/>
    <link href="http://aaronsadventures.blogspot.com/2019/05/individual-notions-of-fairness-you-can.html" rel="alternate" type="text/html"/>
    <title>Individual Notions of Fairness You Can Use</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div style="text-align: center;"><span style="font-size: x-large;"><u>Individual Notions of Fairness You Can Use</u></span></div><br/>Our group at Penn has been thinking about when <i>individual </i>notions of fairness might be practically achievable for awhile, and we have <a href="https://arxiv.org/abs/1905.10660">two</a>¬†<a href="https://arxiv.org/abs/1905.10607">new</a>¬†approaches.<br/><br/><span style="font-size: large;"><u>Background</u>:</span><br/><u>Statistical Fairness</u><br/>I've written about this before, <a href="http://aaronsadventures.blogspot.com/2017/11/between-statistical-and-individual.html">here</a>. But briefly: there are two families of definitions in the fairness in machine learning literature. The first group of definitions, which I call <i>statistical</i>¬†fairness notions, is far and away the most popular. If you want to come up with your own statistical fairness notion, you can follow this recipe:<br/><ol><li>Partition the world into a small number of "protected sub-groups". You will probably be thinking along the lines of race or gender or something similar when you do this.</li><li>Pick your favorite error/accuracy metric for a classifier. This might literally be classification error, or false positive or false negative rate, or positive predictive value, or something else. Lots of options here.¬†</li><li>Ask that this metric be approximately equalized across your protected groups.</li><li>Finally, enjoy your new statistical fairness measure! Congratulations!</li></ol><div>These definitions are far and away the most popular in this literature, in large part (I think) because they are so immediately actionable. Because they are defined as conditions on a small number of expectations, you can easily check whether your classifier is "fair" according to these metrics, and (although there are some interesting computational challenges) go and try and learn classifiers subject to these constraints.¬†</div><div><br/></div><div>Their major problem is related to the reason for their success: they are defined as conditions on a small number of expectations or <i>averages</i>¬†over people, and so they don't promise much to particular individuals. I'll borrow an example from our <a href="https://arxiv.org/abs/1711.05144">fairness gerrymandering</a> paper from a few years ago to put this in sharp relief. Imagine that we are building a system to decide who to incarcerate, and we want to be "fair" with respect to both gender (men and women) and race (green and blue people). We decide that in our scenario, it is the false positives who are harmed (innocent people sent to jail), and so to be fair, we decide should equalize the false positive rate: across men and women, and across greens and blues. But one way to do this is to jail all green men and blue women. This does indeed equalize the false positive rate (at 50%) across all four of the groups we specified, but is cold comfort if you happen to be a green man --- since then you will be jailed with certainty. The problem was our fairness constraint was never a promise to an individual to begin with, just a promise about the average behavior of our classifier over a large group. And although this is a toy example constructed to make a point, things like this happen in real data too.¬†</div><br/><u>Individual Fairness</u><br/>Individual notions of fairness, on the other hand, really do correspond to promises made to individuals. There are at least two kinds of individual fairness definitions that have been proposed: <a href="https://dl.acm.org/citation.cfm?id=2090255">metric fairness</a>, and <a href="http://papers.nips.cc/paper/6355-fairness-in-learning-classic-and-contextual-bandits">weakly meritocratic fairness</a>. Metric fairness proposes that the learner will be handed a <i>task specific similarity metric</i>, and requires that individuals who are close together in the metric should have a similar probability of being classified as positive. Weakly meritocratic fairness, on the other hand, takes the (unknown) labels of an individual as a measure of merit, and requires that individuals who have a higher probability of really having a positive label should have only a higher probability of being classified as positive. This in particular implies that false positive and false negative rates should be equalized <i>across individuals</i>, where now the word <i>rate</i>¬†is averaging over only the randomness of the classifier, not over people. What makes both of these <i>individual</i>¬†notions of fairness is that they impose constraints that bind on all pairs of individuals and not just over averages of people.<br/><br/>Definitions like this have the advantage of strong individual-level semantics, which the statistical definitions don't have. But they also have big problems: for metric fairness, the obvious question is: <i>where does the metric come from</i>? Even granting that fairness should be some Lipschitz condition on a metric, it seems hard to pin down what the metric is, and different people will disagree: coming up with the metric seems to encapsulate a large part of the original problem of defining fairness. For weakly meritocratic fairness, the obvious problem is that we don't know what the labels are. Its possible to do non-trivial things if you make assumptions about the label generating process, but its not at all clear you can do any non-trivial learning subject to this constraint if you don't make strong assumptions.<br/><br/><span style="font-size: large;"><u>Two New Approaches:</u></span><br/>We have two new approaches, building off of metric fairness and weakly meritocratic fairness respectively. Both have the advantages of statistical notions of fairness in that they can be put into practice without making unrealistic assumptions about the data, and without needing to wait on someone to hand us a metric. But they continue to make meaningful promises to individuals.<br/><br/><u>Subjective Individual Fairness</u><br/>Lets start with our variant of metric fairness, which we call subjective individual fairness. (This is joint work with Michael Kearns, our PhD students Chris Jung and Seth Neel, our former PhD student Steven Wu, and Steven's student (our grand student!) Logan Stapleton). The paper is here:¬†<a href="https://arxiv.org/abs/1905.10660">https://arxiv.org/abs/1905.10660</a>. We stick with the premise that "similar people should be treated similarly", and that whether or not it is correct/just/etc., it is at least fair to treat two people the same way, in the sense that we classify them as positive with the same probability. But we don't want to assume anything else.<br/><br/>Suppose I were to create a machine learning fairness panel: I could recruit "AI Ethics" experts, moral philosophers, hyped up consultants, people off the street, toddlers, etc. I would expect that there would be as many different conceptions of fairness as there were people on the panel, and that none of them could precisely quantify what they meant by fairness --- certainly not in the form of a "fairness metric". But I could still ask these people, in particular cases, if they thought it was fair that two particular individuals be treated differently or not.<br/><br/>Of course, I would have no reason to expect that the responses that I got from the different panelists would be consistent with one another --- or possibly even internally consistent (we won't assume, e.g. that the responses satisfy any kind of triangle inequality). Nevertheless, once we fix a data distribution and a group of people who have opinions about fairness, we have a well defined tradeoff we can hope to manage: any classifier we could choose will have both:<br/><ol><li>Some error rate, and</li><li>Some frequency with which it makes a pair of decisions that someone in the group finds unfair.¬†</li></ol><div>We can hope to find classifiers that optimally trade off 1 and 2: note this is a coherent tradeoff even though we haven't forced the people to try and express their conceptions of fairness into some consistent metric. What we show is that you can do this.¬†</div><div><br/></div><div>Specifically, given a set of pairs that we have determined should be treated similarly, there is an <i>oracle efficient </i>algorithm that can find the optimal classifier subject to the constraint that no pair of individuals that has been specified as a constraint should have a substantially different probability of positive classification. Oracle efficiency means that what we can do is reduce the "fair learning" problem to a regular old learning problem, without fairness constraints. If we can solve the regular learning problem, we can also solve the fair learning problem. This kind of fairness constraint also generalizes in the standard way: if you ask your fairness panel about a reasonably small number of pairs, and then solve the in-sample problem subject to these constraints, the classifier you learn will also satisfy the fairness constraints out of sample. And it works: we implement the algorithm and try it out on the COMPAS data set, with fairness constraints that we elicited from 43 human (undergrad) subjects. The interesting thing is that once you have an algorithm like this, it isn't only a tool to create "fair" machine learning models: its also a new instrument to investigate human conceptions of fairness. We already see quite a bit of variation among our 43 subjects in our preliminary experiments. We plan to pursue this direction more going forward.</div><div><br/></div><div><u>Average Individual Fairness</u></div><div>Next, our variant of weakly meritocratic fairness. This is joint work with Michael Kearns and our student Saeed Sharifi. The paper is here:¬†<a href="https://arxiv.org/abs/1905.10607">https://arxiv.org/abs/1905.10607</a>.¬†In certain scenarios, it really does seem tempting to think about fairness in terms of false positive rates. Criminal justice is a great example, in the sense that it is clear that everyone agrees on which outcome they <i>want</i>¬†(they would like to be released from jail), and so the people we are being unfair to really do seem to be the false positives: the people who should have been released from jail, but who were mistakenly incarcerated for longer. So in our "fairness gerrymandering" example above, maybe the problem with thinking about false positive rates wasn't a problem with <i>false positives</i>, but with <i>rates</i>: i.e. the problem was that the word rate averaged over many people, and so it didn't promise <i>you</i>¬†anything. Our idea is to redefine the word rate.¬†</div><div><br/></div><div>In some (but certainly not all) settings, people are subject to not just one, but many classification tasks. For example, consider online advertising: you might be shown thousands of targeted ads each month. Or applying for schools (a process that is centralized in cities like New York): you apply not just to one school, but to many. In situations like this, we can model the fact that we have not just a distribution over people, but also a distribution over (or collection of) problems.¬†</div><div><br/></div><div>Once we have a distribution over problems, we can define the error rate, or false positive rate, or any other rate you like <i>for individuals. </i>It is now sensible to talk about Alice's false positive rate, or Bob's error rate, because rate has been redefined as an average over problems, for a particular individual. So we can now ask for individual fairness notions in the spirit of the statistical notions of fairness we discussed above! We no longer need to define protected groups: we can now ask that the false positive rates, or error rates, be equalized across all pairs of people.¬†</div><div><br/></div><div>It turns out that given a reasonably sized sample of people, and a reasonably sized sample of problems, it is tractable to find the optimal classifier subject to constraints like this in sample, and that these guarantees generalize out of sample. The in-sample algorithm is again an oracle-efficient algorithm, or in other words, a reduction to standard, unconstrained learning. The generalization guarantee here is a little interesting, because now we are talking about simultaneous generalization in two different directions: to people we haven't seen before, and also to problems we haven't seen before. This requires thinking a little bit about what kind of object we are even trying to output: a mapping from new problems to classifiers. The details are in the paper (spoiler --- the mapping is defined by the optimal dual variables for the empirical risk minimization problem): here, I'll just point out that again, the algorithm is practical to implement, and we perform some simple experiments with it.¬†</div><div><br/></div><div><br/></div><br/><br/><br/></div>
    </content>
    <updated>2019-05-28T10:47:00Z</updated>
    <published>2019-05-28T10:47:00Z</published>
    <author>
      <name>Aaron</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/09952936358739421126</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-25562705</id>
      <category term="game theory"/>
      <category term="news"/>
      <author>
        <name>Aaron</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/09952936358739421126</uri>
      </author>
      <link href="http://aaronsadventures.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/25562705/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://aaronsadventures.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/25562705/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <title>Adventures in Computation</title>
      <updated>2019-05-29T14:44:55Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1905.11166</id>
    <link href="http://arxiv.org/abs/1905.11166" rel="alternate" type="text/html"/>
    <title>Hierarchy of Transportation Network Parameters and Hardness Results</title>
    <feedworld_mtime>1559001600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Blum:Johannes.html">Johannes Blum</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1905.11166">PDF</a><br/><b>Abstract: </b>The graph parameters highway dimension and skeleton dimension were introduced
to capture the properties of transportation networks. As many important
optimization problems like Travelling Salesperson, Steiner Tree or $k$-Center
arise in such networks, it is worthwhile to study them on graphs of bounded
highway or skeleton dimension.
</p>
<p>We investigate the relationships between mentioned parameters and how they
are related to other important graph parameters that have been applied
successfully to various optimization problems. We show that the skeleton
dimension is incomparable to any of the parameters distance to linear forest,
bandwidth, treewidth and highway dimension and hence, it is worthwhile to study
mentioned problems also on graphs of bounded skeleton dimension. Moreover, we
prove that the skeleton dimension is upper bounded by the max leaf number and
that for any graph on at least three vertices there are edge weights such that
both parameters are equal.
</p>
<p>Then we show that computing the highway dimension according to most recent
definition is NP-hard, which answers an open question stated by Feldmann et al.
Finally we prove that on graphs $G=(V,E)$ of skeleton dimension
$\mathcal{O}(\log^2 \vert V \vert)$ it is NP-hard to approximate the $k$-Center
problem within a factor less than $2$.
</p></div>
    </summary>
    <updated>2019-05-28T23:22:01Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-05-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1905.11092</id>
    <link href="http://arxiv.org/abs/1905.11092" rel="alternate" type="text/html"/>
    <title>A Rate-Distortion Framework for Explaining Neural Network Decisions</title>
    <feedworld_mtime>1559001600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Jan Macdonald, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/W=auml=ldchen:Stephan.html">Stephan W√§ldchen</a>, Sascha Hauch, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kutyniok:Gitta.html">Gitta Kutyniok</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1905.11092">PDF</a><br/><b>Abstract: </b>We formalise the widespread idea of interpreting neural network decisions as
an explicit optimisation problem in a rate-distortion framework. A set of input
features is deemed relevant for a classification decision if the expected
classifier score remains nearly constant when randomising the remaining
features. We discuss the computational complexity of finding small sets of
relevant features and show that the problem is complete for
$\mathsf{NP}^\mathsf{PP}$, an important class of computational problems
frequently arising in AI tasks. Furthermore, we show that it even remains
$\mathsf{NP}$-hard to only approximate the optimal solution to within any
non-trivial approximation factor. Finally, we consider a continuous problem
relaxation and develop a heuristic solution strategy based on assumed density
filtering for deep ReLU neural networks. We present numerical experiments for
two image classification data sets where we outperform established methods in
particular for sparse explanations of neural network decisions.
</p></div>
    </summary>
    <updated>2019-05-28T23:21:26Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-05-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1905.10902</id>
    <link href="http://arxiv.org/abs/1905.10902" rel="alternate" type="text/html"/>
    <title>Engineering Kernelization for Maximum Cut</title>
    <feedworld_mtime>1559001600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Damir Ferizovic, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hespe:Demian.html">Demian Hespe</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lamm:Sebastian.html">Sebastian Lamm</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mnich:Matthias.html">Matthias Mnich</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schulz:Christian.html">Christian Schulz</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Strash:Darren.html">Darren Strash</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1905.10902">PDF</a><br/><b>Abstract: </b>Kernelization is a general theoretical framework for preprocessing instances
of NP-hard problems into (generally smaller) instances with bounded size, via
the repeated application of data reduction rules. For the fundamental Max Cut
problem, kernelization algorithms are theoretically highly efficient for
various parameterizations. However, the efficacy of these reduction rules in
practice---to aid solving highly challenging benchmark instances to
optimality---remains entirely unexplored.
</p>
<p>We engineer a new suite of efficient data reduction rules that subsume most
of the previously published rules, and demonstrate their significant impact on
benchmark data sets, including synthetic instances, and data sets from the VLSI
and image segmentation application domains. Our experiments reveal that current
state-of-the-art solvers can be sped up by up to multiple orders of magnitude
when combined with our data reduction rules. On social and biological networks
in particular, kernelization enables us to solve four instances that were
previously unsolved in a ten-hour time limit with state-of-the-art solvers;
three of these instances are now solved in less than two seconds.
</p></div>
    </summary>
    <updated>2019-05-28T23:23:16Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-05-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1905.10867</id>
    <link href="http://arxiv.org/abs/1905.10867" rel="alternate" type="text/html"/>
    <title>Regular resolution for CNF of bounded incidence treewidth with few long clauses</title>
    <feedworld_mtime>1559001600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Andrea Cali, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Razgon:Igor.html">Igor Razgon</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1905.10867">PDF</a><br/><b>Abstract: </b>We demonstrate that Regular Resolution is FPT for two restricted families of
CNFs of bounded incidence treewidth. The first includes CNFs having at most $p$
clauses whose removal results in a CNF of primal treewidth at most $k$. The
parameters we use in this case are $p$ and $k$. The second class includes CNFs
of bounded one-sided (incidence) treewdth, a new parameter generalizing both
primal treewidth and incidence pathwidth. The parameter we use in this case is
the one-sided treewidth.
</p></div>
    </summary>
    <updated>2019-05-28T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-05-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1905.10833</id>
    <link href="http://arxiv.org/abs/1905.10833" rel="alternate" type="text/html"/>
    <title>Improved Distributed Approximations for Minimum-Weight Two-Edge-Connected Spanning Subgraph</title>
    <feedworld_mtime>1559001600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dory:Michal.html">Michal Dory</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Ghaffari:Mohsen.html">Mohsen Ghaffari</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1905.10833">PDF</a><br/><b>Abstract: </b>The minimum-weight $2$-edge-connected spanning subgraph (2-ECSS) problem is a
natural generalization of the well-studied minimum-weight spanning tree (MST)
problem, and it has received considerable attention in the area of network
design. The latter problem asks for a minimum-weight subgraph with an edge
connectivity of $1$ between each pair of vertices while the former strengthens
this edge-connectivity requirement to $2$. Despite this resemblance, the 2-ECSS
problem is considerably more complex than MST. While MST admits a linear-time
centralized exact algorithm, 2-ECSS is NP-hard and the best known centralized
approximation algorithm for it (that runs in polynomial time) gives a
$2$-approximation.
</p>
<p>In this paper, we give a deterministic distributed algorithm with round
complexity of $\widetilde{O}(D+\sqrt{n})$ that computes a
$(5+\epsilon)$-approximation of 2-ECSS, for any constant $\epsilon&gt;0$. Up to
logarithmic factors, this complexity matches the
$\widetilde{\Omega}(D+\sqrt{n})$ lower bound that can be derived from Das Sarma
et al. [STOC'11], as shown by Censor-Hillel and Dory [OPODIS'17]. Our result is
the first distributed constant approximation for 2-ECSS in the nearly optimal
time and it improves on a recent randomized algorithm of Dory [PODC'18], which
achieved an $O(\log n)$-approximation in $\widetilde{O}(D+\sqrt{n})$ rounds.
</p>
<p>We also present an alternative algorithm for $O(\log n)$-approximation, whose
round complexity is linear in the low-congestion shortcut parameter of the
network, following a framework introduced by Ghaffari and Haeupler [SODA'16].
This algorithm has round complexity $\widetilde{O}(D+\sqrt{n})$ in worst-case
networks but it provably runs much faster in many well-behaved graph families
of interest. For instance, it runs in $\widetilde{O}(D)$ time in planar
networks and those with bounded genus, bounded path-width or bounded
tree-width.
</p></div>
    </summary>
    <updated>2019-05-28T23:31:17Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-05-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1905.10825</id>
    <link href="http://arxiv.org/abs/1905.10825" rel="alternate" type="text/html"/>
    <title>Phase Transitions and Cyclic Phenomena in Bandits with Switching Constraints</title>
    <feedworld_mtime>1559001600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Simchi=Levi:David.html">David Simchi-Levi</a>, Yunzong Xu <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1905.10825">PDF</a><br/><b>Abstract: </b>We consider the classical stochastic multi-armed bandit problem with a
constraint on the total cost incurred by switching between actions. We prove
matching upper and lower bounds on regret and provide near-optimal algorithms
for this problem. Surprisingly, we discover phase transitions and cyclic
phenomena of the optimal regret. That is, we show that associated with the
multi-armed bandit problem, there are phases defined by the number of arms and
switching costs, where the regret upper and lower bounds in each phase remain
the same and drop significantly between phases. The results enable us to fully
characterize the trade-off between regret and incurred switching cost in the
stochastic multi-armed bandit problem, contributing new insights to this
fundamental problem. Under the general switching cost structure, the results
reveal a deep connection between bandit problems and graph traversal problems,
such as the shortest Hamiltonian path problem.
</p></div>
    </summary>
    <updated>2019-05-28T23:29:51Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-05-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1905.10820</id>
    <link href="http://arxiv.org/abs/1905.10820" rel="alternate" type="text/html"/>
    <title>Geodesics in persistence diagram space</title>
    <feedworld_mtime>1559001600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chowdhury:Samir.html">Samir Chowdhury</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1905.10820">PDF</a><br/><b>Abstract: </b>It is known that for a variety of choices of metrics, including the standard
bottleneck distance, the space of persistence diagrams admits geodesics.
Typically these existence results produce geodesics that have the form of a
convex combination. More specifically, given two persistence diagrams and a
choice of metric, one obtains a bijection realizing the distance between the
diagrams, and uses this bijection to linearly interpolate from one diagram to
another. We prove that for several families of metrics, every geodesic in
persistence diagram space arises as such a convex combination. For certain
other choices of metrics, we explicitly construct infinite families of
geodesics that cannot have this form.
</p></div>
    </summary>
    <updated>2019-05-28T23:31:51Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-05-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1905.10809</id>
    <link href="http://arxiv.org/abs/1905.10809" rel="alternate" type="text/html"/>
    <title>Minimum Age TDMA Scheduling</title>
    <feedworld_mtime>1559001600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kuo:Tung=Wei.html">Tung-Wei Kuo</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1905.10809">PDF</a><br/><b>Abstract: </b>We consider a transmission scheduling problem in which multiple systems
receive update information through a shared Time Division Multiple Access
(TDMA) channel. To provide timely delivery of update information, the problem
asks for a schedule that minimizes the overall age of information. We call this
problem the Min-Age problem. This problem is first studied by He \textit{et
al.} [IEEE Trans. Inform. Theory, 2018], who identified several special cases
where the problem can be solved optimally in polynomial time. Our contribution
is threefold. First, we introduce a new job scheduling problem called the
Min-WCS problem, and we prove that, for any constant $r \geq 1$, every
$r$-approximation algorithm for the Min-WCS problem can be transformed into an
$r$-approximation algorithm for the Min-Age problem. Second, we give a
randomized 2.733-approximation algorithm and a dynamic-programming-based exact
algorithm for the Min-WCS problem. Finally, we prove that the Min-Age problem
is NP-hard.
</p></div>
    </summary>
    <updated>2019-05-28T23:24:28Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-05-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1905.10775</id>
    <link href="http://arxiv.org/abs/1905.10775" rel="alternate" type="text/html"/>
    <title>Deterministic Distributed Dominating Set Approximation in the CONGEST Model</title>
    <feedworld_mtime>1559001600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Janosch Deurer, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kuhn:Fabian.html">Fabian Kuhn</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Maus:Yannic.html">Yannic Maus</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1905.10775">PDF</a><br/><b>Abstract: </b>We develop deterministic approximation algorithms for the minimum dominating
set problem in the CONGEST model with an almost optimal approximation
guarantee. For $\epsilon&gt;1/{\text{{poly}}}\log \Delta$ we obtain two algorithms
with approximation factor $(1+\epsilon)(1+\ln (\Delta+1))$ and with runtimes
$2^{O(\sqrt{\log n \log\log n})}$ and $O(\Delta\cdot\text{poly}\log \Delta
+\text{poly}\log \Delta \log^{*} n)$, respectively. Further we show how
dominating set approximations can be deterministically transformed into a
connected dominating set in the \CONGEST model while only increasing the
approximation guarantee by a constant factor. This results in a deterministic
$O(\log \Delta)$-approximation algorithm for the minimum connected dominating
set with time complexity
</p>
<p>$2^{O(\sqrt{\log n \log\log n})}$.
</p></div>
    </summary>
    <updated>2019-05-28T23:30:19Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-05-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1905.10747</id>
    <link href="http://arxiv.org/abs/1905.10747" rel="alternate" type="text/html"/>
    <title>On the monotone complexity of the shift operator</title>
    <feedworld_mtime>1559001600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sergeev:Igor_S=.html">Igor S. Sergeev</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1905.10747">PDF</a><br/><b>Abstract: </b>We show that the complexity of minimal monotone circuits implementing a
monotone version of the shift operator on $n$ boolean inputs is $\Theta(n\log
n)$.
</p></div>
    </summary>
    <updated>2019-05-28T23:22:21Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-05-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1905.10716</id>
    <link href="http://arxiv.org/abs/1905.10716" rel="alternate" type="text/html"/>
    <title>Algorithmic and geometric aspects of data depth with focus on $\beta$-skeleton depth</title>
    <feedworld_mtime>1559001600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shahsavarifar:Rasoul.html">Rasoul Shahsavarifar</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1905.10716">PDF</a><br/><b>Abstract: </b>The statistical rank tests play important roles in univariate non-parametric
data analysis. If one attempts to generalize the rank tests to a multivariate
case, the problem of defining a multivariate order will occur. It is not clear
how to define a multivariate order or statistical rank in a meaningful way. One
approach to overcome this problem is to use the notion of data depth which
measures the centrality of a point with respect to a given data set. In other
words, a data depth can be applied to indicate how deep a point is located with
respect to a given data set. Using data depth, a multivariate order can be
defined by ordering the data points according to their depth values. Various
notions of data depth have been introduced over the last decades. In this
thesis, we discuss three depth functions: two well-known depth functions
halfspace depth and simplicial depth, and one recently defined depth function
named as $\beta$-skeleton depth, $\beta\geq 1$. The $\beta$-skeleton depth is
equivalent to the previously defined spherical depth and lens depth when
$\beta=1$ and $\beta=2$, respectively. Our main focus in this thesis is to
explore the geometric and algorithmic aspects of $\beta$-skeleton depth.
</p></div>
    </summary>
    <updated>2019-05-28T23:32:08Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-05-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1905.10682</id>
    <link href="http://arxiv.org/abs/1905.10682" rel="alternate" type="text/html"/>
    <title>Counting Homomorphisms Modulo a Prime Number</title>
    <feedworld_mtime>1559001600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Amirhossein Kazeminia, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bulatov:Andrei_A=.html">Andrei A. Bulatov</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1905.10682">PDF</a><br/><b>Abstract: </b>Counting problems in general and counting graph homomorphisms in particular
have numerous applications in combinatorics, computer science, statistical
physics, and elsewhere. One of the most well studied problems in this area is
#GraphHom(H) --- the problem of finding the number of homomorphisms from a
given graph G to the graph H. Not only the complexity of this basic problem is
known, but also of its many variants for digraphs, more general relational
structures, graphs with weights, and others.
</p>
<p>In this paper we consider a modification of #GraphHom(H), the #_p GraphHom(H)
problem, p a prime number: Given a graph G, find the number of homomorphisms
from G to H modulo p. In a series of papers Faben and Jerrum, and Goebel et al.
determined the complexity of #_2 GraphHom(H) in the case H (or, in fact, a
certain graph derived from H) is square-free, that is, does not contain a
4-cycle. Also, Goebel et al. found the complexity of #_p GraphHom(H) for an
arbitrary prime p when H is a tree. Here we extend the above result to show
that the #_p GraphHom(H) problem is #_p P-hard whenever the derived graph
associated with H is square-free and is not a star, which completely classifies
the complexity of #_p GraphHom(H) for square-free graphs H.
</p></div>
    </summary>
    <updated>2019-05-28T23:22:29Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-05-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1905.10670</id>
    <link href="http://arxiv.org/abs/1905.10670" rel="alternate" type="text/html"/>
    <title>Subgraph Isomorphism on Graph Classes that Exclude a Substructure</title>
    <feedworld_mtime>1559001600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bodlaender:Hans_L=.html">Hans L. Bodlaender</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hanaka:Tesshu.html">Tesshu Hanaka</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kobayashi:Yasuaki.html">Yasuaki Kobayashi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kobayashi:Yusuke.html">Yusuke Kobayashi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Okamoto:Yoshio.html">Yoshio Okamoto</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Otachi:Yota.html">Yota Otachi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zanden:Tom_C=_van_der.html">Tom C. van der Zanden</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1905.10670">PDF</a><br/><b>Abstract: </b>We study Subgraph Isomorphism on graph classes defined by a fixed forbidden
graph. Although there are several ways for forbidding a graph, we observe that
it is reasonable to focus on the minor relation since other well-known
relations lead to either trivial or equivalent problems. When the forbidden
minor is connected, we present a near dichotomy of the complexity of Subgraph
Isomorphism with respect to the forbidden minor, where the only unsettled case
is $P_{5}$, the path of five vertices. We then also consider the general case
of possibly disconnected forbidden minors. We show fixed-parameter tractable
cases and randomized XP-time solvable cases parameterized by the size of the
forbidden minor $H$. We also show that by slightly generalizing the tractable
cases, the problem becomes NP-complete. All unsettle cases are equivalent to
$P_{5}$ or the disjoint union of two $P_{5}$'s. As a byproduct, we show that
Subgraph Isomorphism is fixed-parameter tractable parameterized by vertex
integrity. Using similar techniques, we also observe that Subgraph Isomorphism
is fixed-parameter tractable parameterized by neighborhood diversity.
</p></div>
    </summary>
    <updated>2019-05-28T23:24:34Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-05-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1905.10592</id>
    <link href="http://arxiv.org/abs/1905.10592" rel="alternate" type="text/html"/>
    <title>Evacuating Two Robots from a Disk: A Second Cut</title>
    <feedworld_mtime>1559001600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Disser:Yann.html">Yann Disser</a>, S√∂ren Schmitt <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1905.10592">PDF</a><br/><b>Abstract: </b>We present an improved algorithm for the problem of evacuating two robots
from the unit disk via an unknown exit on the boundary. Robots start at the
center of the disk, move at unit speed, and can only communicate locally. Our
algorithm improves previous results by Brandt et al. [CIAC'17] by introducing a
second detour through the interior of the disk. This allows for an improved
evacuation time of $5.6234$. The best known lower bound of $5.255$ was shown by
Czyzowicz et al. [CIAC'15].
</p></div>
    </summary>
    <updated>2019-05-28T23:29:17Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-05-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1905.10510</id>
    <link href="http://arxiv.org/abs/1905.10510" rel="alternate" type="text/html"/>
    <title>Resisting Adversarial Attacks by $k$-Winners-Take-All</title>
    <feedworld_mtime>1559001600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/x/Xiao:Chang.html">Chang Xiao</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhong:Peilin.html">Peilin Zhong</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zheng:Changxi.html">Changxi Zheng</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1905.10510">PDF</a><br/><b>Abstract: </b>We propose a simple change to the current neural network structure for
defending against gradient-based adversarial attacks. Instead of using popular
activation functions (such as ReLU), we advocate the use of
$k$-Winners-Take-All ($k$-WTA) activation, a $C^0$ discontinuous function that
purposely invalidates the neural network model's gradient at densely
distributed input data points. Our proposal is theoretically rationalized. We
show why the discontinuities in $k$-WTA networks can largely prevent
gradient-based search of adversarial examples and why they at the same time
remain innocuous to the network training. This understanding is also
empirically backed. Even without notoriously expensive adversarial training,
the robustness performance of our networks is comparable to conventional ReLU
networks optimized by adversarial training. Furthermore, after also optimized
through adversarial training, our networks outperform the state-of-the-art
methods under white-box attacks on various datasets that we experimented with.
</p></div>
    </summary>
    <updated>2019-05-28T23:24:04Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-05-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-27705661.post-955320605612447790</id>
    <link href="http://processalgebra.blogspot.com/feeds/955320605612447790/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=27705661&amp;postID=955320605612447790" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/955320605612447790" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/955320605612447790" rel="self" type="application/atom+xml"/>
    <link href="http://processalgebra.blogspot.com/2019/05/an-interview-with-jamie-gabbay-and.html" rel="alternate" type="text/html"/>
    <title>An interview with Jamie Gabbay and Andrew Pitts, 2019 Alonzo Church Award recipients</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">The 2019 Alonzo Church Award committee consisting of Thomas Eiter, Javier Esparza, Radha Jagadeesan, Catuscia Palamidessi, and Natarajan Shankar, have selected <a href="http://www.gabbay.org.uk/">Murdoch J. Gabbay </a>and <a href="https://www.cl.cam.ac.uk/~amp12/">Andrew M. Pitts </a>for the <a href="http://eatcs.org/index.php/component/content/article/1-news/2812-the-2019-alonzo-church-award">2019 Alonzo Church Award</a>, for introducing the theory of nominal representations, a powerful and elegant mathematical model for computing with data involving atomic names. In particular, the nomination for the Alonzo Church Award singled out the following two papers:<br/><ul><li>‚Äú<a href="https://www.cl.cam.ac.uk/~amp12/papers/newaas/newaas-jv.pdf">A new approach to abstract syntax with variable binding</a>‚Äù by Murdoch J. Gabbay and Andrew M. Pitts, Formal Aspects of Computing 13(3):341‚Äì 363, 2002; and</li><li>‚Äú<a href="https://www.cl.cam.ac.uk/~amp12/papers/nomlfo/nomlfo-draft.pdf">Nominal logic, a first order theory of names and binding</a>‚Äù by Andrew M. Pitts, Information and Computation 186(2):165‚Äì193, 2003.</li></ul>For the conference version of the first article, Andy and Jamie will also be receiving the Test-of-Time Award from LICS 1999.<br/><br/>The award recipients kindly agreed to answer some questions of mine via email. You can find the transcript of the interview below. My questions are labelled with <b>LA</b>, Andy's answers with <b>AP</b> and Jamie's with <b>JG</b>. I hope that you'll enjoy reading their insights and the story of their award-receiving work as much as I did myself. <br/><br/><div dir="ltr"><b>LA: </b>You are receiving the 2019 Alonzo Church Award  for  Outstanding Contributions to Logic and Computation as well as the  Test-of-Time Award from LICS 1999 for your invention of nominal  techniques to provide a semantic understanding of abstract syntax with  binding.¬†¬† Could you briefly describe the history of the ideas that led  you to use the <a href="https://en.wikipedia.org/wiki/Permutation_model">permutation model of set theory with atoms</a> due to  Fraenkel and Mostowski to represent name abstraction and fresh name  generation? What were the  main inspirations and motivations for your work? In your opinion, how  did nominal techniques advance the state of the art at that time?</div><div dir="ltr"/><br/><div dir="ltr"><b>AP: </b>I have had a long-standing interest in the mathematical semantics of programming language features that restrict resources to a specific scope, or hide information from a program's environment; think local mutable state in languages like <a href="http://ocaml.org/">OCaml</a>, or channel-name restriction in the <a href="https://en.wikipedia.org/wiki/%CE%A0-calculus">pi-calculus</a>. When <a href="http://homepages.inf.ed.ac.uk/stark/">Ian Stark</a> was doing his PhD with me in the 90s we tried to understand a simple instance: the observable properties of higher-order functions combined with dynamically generated atomic names that can be tested for equality, but don't have any other attribute -- we called this the "nu-calculus". Ian gave a denotational semantics for the nu-calculus using Moggi's monad for modelling dynamic allocation. That monad is defined on the category of pullback-preserving functors from the category of injective functions between finite ordinals to the category of sets. This functor category was well-known to me from topos theory, where it is called <a href="https://ncatlab.org/nlab/show/Schanuel+topos">Schanuel's topos </a>and hosts the generic model of a geometric theory of an infinite decidable set.  A few years later, when Jamie joined me as a PhD student in 1998, I suggested we look at the Schanuel topos as a setting for initial algebra semantics of syntax involving binding operations, modulo alpha-equivalence. I think Jamie prefers set theory over category theory, so he pushed us to use another known equivalent presentation of the Schanuel topos, in terms of continuous actions of the group of permutations of the set N of natural numbers (topologized as a subspace of the product of countably many copies of N). In this form there is an obvious connection with the cumulative hierarchy of sets (with atoms) that are hereditarily finitely supported with respect to the action of permuting atoms. This universe of sets was devised by Fraenkel and Mostowski in the first part of the twentieth century to model ZFA set theory without axioms of choice.  Whether one emphasises set theory or category theory, the move to making permutations of names, rather than injections between sets of names, the primary concept was very fruitful. For example, it certainly makes higher-order constructions (functions and powersets) in the topos/set-theory easier to describe and use. We ended up with a generic construction for name-abstraction modulo <a href="https://en.wikipedia.org/wiki/Lambda_calculus#Alpha_equivalence">alpha-equivalence</a> compatible with classical higher-order logic or set theory, so long as one abstains from unrestricted use of choice. </div><div dir="ltr"/><div dir="ltr"><br/><b>JG:</b> At the time it wasn't an idea to consider names as elements of a distinctive datatype of names, with properties just like other datatypes such as the natural numbers Nat. If we want to add 1 to 1, we take 1:Nat and invoke the "plus" function, which is a specific thing associated to Nat; so why not abstract a in x by assuming a:Atm (where Atm is a distinct thing in our mathematical universe) and x:X and invoking a function "abstract", which is a thing associated to Atm?  We unfolded the implications of this idea in set theory and rediscovered FM sets.  I was inspired by the way I saw mathematics built up in ZF set theory as an undergraduate, starting from a simple basis and building up the cumulative hierarchy.  When I saw the chance to do this for a universe with names, I jumped at the chance.  It turns out FM sets are not required.  Nominal techniques can be built in ZFA set theory, which contains more functions and permits unrestricted choice. </div><div dir="ltr"><br/><b>LA: </b>Over  the last fifteen years, nominal techniques have become a fundamental  tool for modelling locality in computation, underlying research  presented in over a hundred papers, new programming languages and models  of computation. They have applications to the syntax and semantics of  programming languages, to logics for machine-assisted reasoning about  programming-language semantics and to the automatic verification of  specifications in process calculi. Variations on nominal sets are used  in automata theory over infinite alphabets, with applications to  querying XML and databases, and also feature in work on models of  Homotopy Type Theory. When did it dawn on you that you had succeeded in  finding a very good model for name abstraction and fresh name  generation, and one that would have a  lot of impact? Did you imagine that your model would generate such a  large amount of follow-up work, leading to a whole body of work on  nominal computation theory? <br/><br/><b>AP: </b>No, to begin with I was very focussed on getting better techniques for computing and reasoning about syntax with bound names. But that only represents a part of the current broad landscape of nominal techniques, the part that mainly depends on the mathematical notion of "finite support" (a way of expressing, via name-permutation, that an object only involves finitely many names). Independently of us, some people realised that a related notion of finiteness, "orbit-finiteness" (which expresses that an object is finite modulo symmetries) is crucial for many applications of nominal techniques. I am referring to the work of Montanari and Pistore on pi-calculus and <a href="https://core.ac.uk/download/pdf/82414059.pdf">HD automata </a>using named sets (yet another equivalent of the Schanuel topos) and the work on automata theory over infinite alphabets (and much else besides) using "sets with atoms" by the Warsaw group (Bojanczyk, Klin, Lasota, Torunczyk,...). The latter is particularly significant because it considers groups of symmetry for atoms other than the full permutation group (in which the only property of an atom preserved under symmetry is its identity). <br/><br/><b>JG:</b> Yes, I did.  Nobody could anticipate the specific applications but I knew we were on to something, which is why I stayed on to build the field after the PhD.  The amount of structure was just too striking.  This showed early: e.g. in the equivariance properties, and the commutation of nominal atoms-abstraction with function-spaces.  When I sent the proof of this property to Andrew, at first he didn't believe it!  I had a sense that there was something deep going on and I still do. <br/><br/><b>LA: </b>What is the result of  yours on nominal techniques you are most proud of? And what are your  favourite results amongst those achieved by others on nominal computation?<b/><br/><b><br/></b><b>AP:</b> Not so much a specific result, but rather a logical concept, the freshness quantifier (which we wrote using an upside down "N" -- N stands for "New"). In informal practice when reasoning about syntax involving binders, one often chooses <i>some</i> fresh name for the bound variable, but then has to revise that choice in view of later ones; but fortunately <i>any </i>fresh name does as well as some particular one. This distinctive "some/any" property occurs all over the place when computing and reasoning about languages with binders and the freshness quantifier formalises it, in terms of the freshness ("not in the support of") relation and conventional quantifiers.  For the second part of your question I would choose two things. One is the work by Jamie with Fernandez and Mackie on <a href="https://www.sciencedirect.com/science/article/pii/S0890540106001635">nominalrewriting systems</a>, which won the PPDP Most Influential Paper 10-year Award in 2014. The second is the characterisation of orbit-finite sets with atoms in terms of "set-builder expressions"---see Klin et al, "<a href="https://www.mimuw.edu.pl/~szymtor/papers/locfin.pdf">Locally Finite Constraint Satisfaction Problems</a>", Proc. LICS 2015); it's a nice application of the classical model theory of homogeneous structures with interesting applications for languages that compute with finite structures. <br/><br/><b>JG:</b> Thanks for asking.  Aside from the initial papers, my work on nominal rewriting with Fernandez has probably had most impact.  However, I am rather fond of the thread of research going from Nominal Algebra, through the axiomatisation of substitution and first-order logic and the characterisation of quantification as a limit in nominal sets, and on to Stone duality.  It's a mathematical foundation built from a nominal perspective of naming and quantification and I hope that as the state of the art in nominal techniques advances and broadens, it might prove useful.  Andrew's book has been helpful in marking out nominal techniques as a field.  I also agree with Andrew that orbit-finiteness and the applications of this idea to transition systems and automata, is important.  I like the automata work for another concrete reason: nominal techniques were discovered in the context of names and binding in syntax, which has bequeathed a misconception that nominal techniques are <i>only</i> about this.  The Warsaw school of nominal techniques gives an independent illustration of the other applications of these ideas. <br/><b><br/></b><b><b>LA: </b></b>Twenty years have passed since your LICS 1999 paper and the  literature on variations on nominal techniques now contains over a hundred papers. Do you expect any further  development related to the theory and application of nominal techniques in the  coming years? What advice would you give to a PhD student who is  interested in working on topics related to nominal computation today?</div><div dir="ltr"><br/><b>AP: </b> For the purpose of answering your question, let's agree to divide LICS topics into Programming Languages and Semantics (PLS) versus Logic and Algorithms (LAS). (So long as we don't think of it as a dichotomy!) Then it seems to me that applications of nominal techniques to LAS are currently in the ascendant and show no sign of slowing down. My own interests are with PLS and there is still work to be done there. In particular, I would like better support for using nominal techniques within the mainstream interactive theorem proving systems: we have the Nominal Package of Urban and Berghofer for classical higher-order logic within Isabelle (which lead to Urban and Tasson winning the CADE Skolem Award in 2015), but nothing analogous for systems based on dependent type theory, such as Agda, Coq and Lean. Recent work of Swan (arXiv:1702.01556) gives us a better understanding of how to develop nominal sets within constructive logic; but I have yet to see a dependent type theory that both corresponds to some form of constructive nominal logic under Curry-Howard and is sufficiently simple that it appeals to users of systems lke Coq who want to mechanise programming language meta-theory in a nameful style. Really, I would like the utility of the FreshML programming language that Jamie, Mark Shinwell and I proposed in 2003 (and which Mark implemented as a patch of OCaml) restricted to total functional programming in the style of Agda; but I don't quite know how to achieve that. <br/><br/><b>JG:</b> Yes.  We are far from understanding nominal techniques and the field has a lot of life and will continue to surprise.  I've always believed that.  A key sticking-point right now is implementations.  I wrote a paper about this recently, on equivariance and the foundations of nominal techniques.  One point in the paper is a sketch for a next-generation nominal theorem-prover (based on ZFA + equivariance).  I'd like to see this carried out, so if anybody reading this is interested then please be in touch.  I'd also like to see nominal techniques implemented as a package in a language like Haskell, ML, or even Python!  If we can get this stuff into the working programmer's toolbox, in a way that just works and does not require special configuration, then that would be helpful.  I suspect that nominal techniques as currently presented in the maths papers, might not fit into a programming language at the moment.  The theory is too strong and may need weakened first.  We need a subset of nominal techniques weak enough to squeeze into an existing language, yet expressive enough for interesting applications.  Some general advice, specifically for the PhD student.  If you have an idea which most people around you don't understand, consider this may be a gap in the collective imagination.  There can be peer pressure when faced by incomprehension to blame yourself, back down, and think about something else.  By all means do this, but only if you yourself judge it right to do so. <br/><br/></div><b>LA: </b>Is there any general research-related lesson you have learnt in the process of working on nominal techniques?<br/><br/><b>AP: </b>On the one hand, don't lose sight of what application your theory is supposed to be good for; but on the other hand, let beauty and simplicity be your guide.<br/><br/><b>JG:</b> Yes:<br/><ul><li>Proving stuff is 30% of the work; convincing people is 70%.¬†</li><li>It's the basic ideas that are hard, not the complicated theorems.</li><li>Competence and imagination are orthogonal.¬†</li><li>It's doesn't have to be complex to be clever.¬†</li><li>Elegant + applicable is a potent combination.¬†</li><li>Seek out good listeners.  Give up quickly on bad ones.  Try to be a good listener.¬†</li><li>Other people have a lot to teach you, but it might not be the things you expected.¬†</li><li>Writing papers is fun. ¬† </li></ul><b>LA: </b>Thanks to both of you for your willingness to answer my questions and congratulations for the awards you will be receiving this summer!</div>
    </content>
    <updated>2019-05-26T22:52:00Z</updated>
    <published>2019-05-26T22:52:00Z</published>
    <author>
      <name>Luca Aceto</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/01092671728833265127</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-27705661</id>
      <author>
        <name>Luca Aceto</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/01092671728833265127</uri>
      </author>
      <link href="http://processalgebra.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://processalgebra.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Papers I find interesting---mostly, but not solely, in Process Algebra---, and some fun stuff in Mathematics and Computer Science at large and on general issues related to research, teaching and academic life.</subtitle>
      <title>Process Algebra Diary</title>
      <updated>2019-05-29T07:54:42Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-27705661.post-7244168862511547770</id>
    <link href="http://processalgebra.blogspot.com/feeds/7244168862511547770/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=27705661&amp;postID=7244168862511547770" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/7244168862511547770" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/7244168862511547770" rel="self" type="application/atom+xml"/>
    <link href="http://processalgebra.blogspot.com/2019/05/ice-tcs-theory-day-2019.html" rel="alternate" type="text/html"/>
    <title>ICE-TCS Theory Day 2019</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><i>This post also appears on the <a href="https://ice-tcs.blogspot.com/2019/05/ice-tcs-theory-day-2019.html">ICE-TCS blog</a>. </i><br/><br/>On Friday, 3 May, ICE-TCS hosted its <a href="http://icetcs.ru.is/theory-day2019.html">15th annual Theory Day</a>. The event consisted of two 45-minute presentations by <a href="https://dblp.uni-trier.de/pers/hd/b/Boppana:Ravi_B=">Ravi  Boppana</a> (Department of Mathematics, MIT) and <a href="https://dcc.fceia.unr.edu.ar/~erivas/">Exequiel Rivas</a>(Inria Paris - Rocquencourt, France),  and three ten-minute presentations by ICE-TCS researchers highlighting some of the recent research directions pursued by members of the centre.<br/><br/><a href="https://dblp.uni-trier.de/pers/hd/b/Boppana:Ravi_B=">Ravi  Boppana</a> kicked off the Theory Day with a wonderfully paced talk on his <a href="https://www.combinatorics.org/ojs/index.php/eljc/article/view/v24i3p40">work</a> with <a href="https://holzman.technion.ac.il/">Ron Holzman</a> on Tomaszewski‚Äôs problem on randomly signed sums. The problem is as follows. Let <span class="mjx-chtml MathJax_CHTML" id="MathJax-Element-1-Frame" style="font-size: 129%;" tabindex="0"><span class="mjx-math" id="MJXc-Node-1"><span class="mjx-mrow" id="MJXc-Node-2"><span class="mjx-msubsup" id="MJXc-Node-3"><span class="mjx-base"><span class="mjx-mi" id="MJXc-Node-4"><span class="mjx-char MJXc-TeX-math-I" style="padding-bottom: 0.28em;">v</span></span></span><span class="mjx-sub"><span class="mjx-mn" id="MJXc-Node-5"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.39em;">1</span></span></span></span></span></span></span>, <span class="mjx-chtml MathJax_CHTML" id="MathJax-Element-2-Frame" style="font-size: 129%;" tabindex="0"><span class="mjx-math" id="MJXc-Node-6"><span class="mjx-mrow" id="MJXc-Node-7"><span class="mjx-msubsup" id="MJXc-Node-8"><span class="mjx-base"><span class="mjx-mi" id="MJXc-Node-9"><span class="mjx-char MJXc-TeX-math-I" style="padding-bottom: 0.28em;">v</span></span></span><span class="mjx-sub"><span class="mjx-mn" id="MJXc-Node-10"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.39em;">2</span></span></span></span></span></span></span>, ..., <span class="mjx-chtml MathJax_CHTML" id="MathJax-Element-3-Frame" style="font-size: 129%;" tabindex="0"><span class="mjx-math" id="MJXc-Node-11"><span class="mjx-mrow" id="MJXc-Node-12"><span class="mjx-msubsup" id="MJXc-Node-13"><span class="mjx-base"><span class="mjx-mi" id="MJXc-Node-14"><span class="mjx-char MJXc-TeX-math-I" style="padding-bottom: 0.28em;">v</span></span></span><span class="mjx-sub"><span class="mjx-mi" id="MJXc-Node-15"><span class="mjx-char MJXc-TeX-math-I" style="padding-bottom: 0.28em;">n</span></span></span></span></span></span></span> be real numbers whose squares add up to 1.¬† Consider the <span class="mjx-chtml MathJax_CHTML" id="MathJax-Element-4-Frame" style="font-size: 129%;" tabindex="0"><span class="mjx-math" id="MJXc-Node-16"><span class="mjx-mrow" id="MJXc-Node-17"><span class="mjx-msubsup" id="MJXc-Node-18"><span class="mjx-base"><span class="mjx-mn" id="MJXc-Node-19"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.39em;">2</span></span></span><span class="mjx-sup" style="font-size: 70.7%; padding-left: 0px; vertical-align: 0.591em;"><span class="mjx-mi" id="MJXc-Node-20"><span class="mjx-char MJXc-TeX-math-I" style="padding-bottom: 0.28em;">n</span></span></span></span></span></span></span> signed sums of the form <span class="mjx-chtml MathJax_CHTML" id="MathJax-Element-5-Frame" style="font-size: 129%;" tabindex="0"><span class="mjx-math" id="MJXc-Node-21"><span class="mjx-mrow" id="MJXc-Node-22"><span class="mjx-mi" id="MJXc-Node-23"><span class="mjx-char MJXc-TeX-math-I" style="padding-bottom: 0.28em;">S</span></span><span class="mjx-mo MJXc-space3" id="MJXc-Node-24"><span class="mjx-char MJXc-TeX-main-R">=</span></span><span class="mjx-mo MJXc-space3" id="MJXc-Node-25"><span class="mjx-char MJXc-TeX-size1-R">‚àë</span></span><span class="mjx-mo MJXc-space1" id="MJXc-Node-26"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.39em;">¬±</span></span><span class="mjx-msubsup" id="MJXc-Node-27"><span class="mjx-base"><span class="mjx-mi" id="MJXc-Node-28"><span class="mjx-char MJXc-TeX-math-I" style="padding-bottom: 0.28em;">v</span></span></span><span class="mjx-sub"><span class="mjx-mi" id="MJXc-Node-29"><span class="mjx-char MJXc-TeX-math-I" style="padding-bottom: 0.28em;">i</span></span></span></span></span></span></span>.¬† Can there be more signed sums whose value is greater than 1 then those whose value¬† is at most 1? <a href="https://holzman.technion.ac.il/files/2012/09/combsigns.pdf">Holzman and Kleitman (1992) </a>proved that at least 3/8 of these sums satisfy <span class="mjx-chtml MathJax_CHTML" id="MathJax-Element-6-Frame" style="font-size: 129%;" tabindex="0"><span class="mjx-math" id="MJXc-Node-30"><span class="mjx-mrow" id="MJXc-Node-31"><span class="mjx-texatom" id="MJXc-Node-32"><span class="mjx-mrow" id="MJXc-Node-33"><span class="mjx-mo" id="MJXc-Node-34"><span class="mjx-char MJXc-TeX-main-R">|</span></span></span></span><span class="mjx-mi" id="MJXc-Node-35"><span class="mjx-char MJXc-TeX-math-I" style="padding-bottom: 0.28em;">S</span></span><span class="mjx-texatom" id="MJXc-Node-36"><span class="mjx-mrow" id="MJXc-Node-37"><span class="mjx-mo" id="MJXc-Node-38"><span class="mjx-char MJXc-TeX-main-R">|</span></span></span></span><span class="mjx-mo MJXc-space3" id="MJXc-Node-39"><span class="mjx-char MJXc-TeX-main-R">‚â§</span></span><span class="mjx-mn MJXc-space3" id="MJXc-Node-40"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.39em;">1</span></span></span></span></span>.¬† In his talk, Ravi showed us the main ideas Holzman and he used to improve the bound to  13/32.<br/><br/>Computational effects model the interaction of computer programs with their environment. In his talk, <a href="https://dcc.fceia.unr.edu.ar/~erivas/"> Exequiel Rivas</a>taught us how <a href="https://en.wikipedia.org/wiki/Monad_(category_theory)">monads</a>can be used to capture computational effects (a research programme that started with <a href="https://core.ac.uk/download/pdf/21173011.pdf">Moggi's award-winning work</a>), and then, discussed some attempts to incorporate merging operations in the monadic picture.<br/><br/>Two of the short talks were given by Henning A. √ölfarsson and Elli  Anastasiadi. Henning described the work of his group on¬† a tool, called  the CombSpecSearcher, that automates the methods used by  combinatorialists to prove some of their theorems, The tool is able to  prove results featured in dozens of research papers. Watch this space for updates on its  development and for its successes!<br/><br/>Elli Anastasiadi, a PhD student who is already playing an important role  for the centre, gave a clear seven-minute introduction to <a href="https://people.csail.mit.edu/virgi/ipec-survey.pdf">fine-grained complexity</a> and to the notion of <a href="https://en.wikipedia.org/wiki/Fine-grained_reduction">fine-grained reduction</a>.<br/><br/>The 2019 Theory Day was well attended, at least by the standards of a  TCS event in Iceland. If all goes well, we'll be back next year.</div>
    </content>
    <updated>2019-05-12T22:37:00Z</updated>
    <published>2019-05-12T22:37:00Z</published>
    <author>
      <name>Luca Aceto</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/01092671728833265127</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-27705661</id>
      <author>
        <name>Luca Aceto</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/01092671728833265127</uri>
      </author>
      <link href="http://processalgebra.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://processalgebra.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Papers I find interesting---mostly, but not solely, in Process Algebra---, and some fun stuff in Mathematics and Computer Science at large and on general issues related to research, teaching and academic life.</subtitle>
      <title>Process Algebra Diary</title>
      <updated>2019-05-29T07:54:42Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-27705661.post-4286404438772500234</id>
    <link href="http://processalgebra.blogspot.com/feeds/4286404438772500234/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=27705661&amp;postID=4286404438772500234" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/4286404438772500234" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/4286404438772500234" rel="self" type="application/atom+xml"/>
    <link href="http://processalgebra.blogspot.com/2019/04/the-complexity-of-identifying.html" rel="alternate" type="text/html"/>
    <title>The Complexity of Identifying Characteristic Formulae</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">One of the classic results in concurrency theory is the Hennessy-Milner Theorem. This result states that<br/><ol><li>two bisimilar states in a labelled transition system satisfy exactly the same formulae in a multi-modal logic now called Hennessy-Milner logic, and¬†</li><li>two states in a labelled transition system that satisfy a mild finiteness constraint (called image finiteness)¬† and enjoy the same properties expressible in Hennessy-Milner logic are bisimilar.</li></ol>See, for instance, Section 1.2 in <a href="http://homepages.inf.ed.ac.uk/cps/chapbisim.pdf">these notes by Colin Stirling</a> for an exposition of that result. A consequence of the Hennessy-Milner Theorem is that whenever two states <i>p </i>and <i>q </i>in a labelled transition system are <i>not</i> bisimilar, one can come up with a formula in Hennessy-Milner logic that <i>p </i>satisfies, but<i> q </i>does not<i>. </i>Moreover, for each state <i>p </i>in a finite, loop-free labelled transition systems, it is possible to construct a formula <i>F(p) </i>in Hennessy-Milner logic that completely characterizes <i>p</i> up to bisimilarity. This means that, for each state <i>q</i>, <i>p</i> is bisimilar to <i>q</i> if, and only if, <i>q</i> satisfies <i>F(p)</i>. The formula<i> F(p) </i>is called a characteristic formula for<i> p </i>up to bisimilarity.<i> </i>One can obtain a similar result for states in finite labelled transition systems by extending Hennessy-Milner logic with greatest fixed points. <i><br/></i><br/><br/>Characteristic formulae have a long history in concurrency theory. However, to be best of my knowledge, the complexity of determining whether a formula is characteristic had not been studied before <a href="https://sites.google.com/view/antonisachilleos">Antonis Achilleos</a> first addressed the problem in <a href="https://arxiv.org/abs/1605.01004">this conference paper</a>. In that paper, Antonis focused on the complexity of the problem of determining whether a formula <i>F</i> is complete, in the sense that, for each formula <i>G</i>, it can derive either <i>G</i> or its negation.<br/><br/>Our recent preprint¬†   <a href="http://icetcs.ru.is/theofomon/CharFormComplexity.pdf"><i>The   Complexity of Identifying Characteristic Formulae</i></a> extends the results originally obtained by Antonis to a variety of modal logics, possibly including least and greatest fixed-point operators. In the paper, we show that completeness, characterization, and validity have the same complexity ‚Äî with some exceptions for which there are, in general, no complete formulae. So, for most modal logics of interest, the problem is coNP-complete or PSPACE-complete, and becomes EXPTIME-complete for modal logics with fixed points. To prove our upper bounds, we present a nondeterministic procedure with an oracle for validity that combines tableaux and a test for bisimilarity, and determines whether a formula is complete.<br/><br/>I think that there is still a lot of work that can be done in studying this problem, with respect to a variety of other notions of equivalence considered in concurrency theory, so stay tuned for further updates.¬†</div>
    </content>
    <updated>2019-04-18T17:19:00Z</updated>
    <published>2019-04-18T17:19:00Z</published>
    <author>
      <name>Luca Aceto</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/01092671728833265127</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-27705661</id>
      <author>
        <name>Luca Aceto</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/01092671728833265127</uri>
      </author>
      <link href="http://processalgebra.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://processalgebra.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Papers I find interesting---mostly, but not solely, in Process Algebra---, and some fun stuff in Mathematics and Computer Science at large and on general issues related to research, teaching and academic life.</subtitle>
      <title>Process Algebra Diary</title>
      <updated>2019-05-29T07:54:42Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-27705661.post-5728082181118033622</id>
    <link href="http://processalgebra.blogspot.com/feeds/5728082181118033622/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=27705661&amp;postID=5728082181118033622" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/5728082181118033622" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/5728082181118033622" rel="self" type="application/atom+xml"/>
    <link href="http://processalgebra.blogspot.com/2019/04/the-ice-tcs-blog.html" rel="alternate" type="text/html"/>
    <title>The ICE-TCS blog</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">After about 14 years, <a href="http://icetcs.ru.is/">ICE-TCS</a> has finally decided to have <a href="https://ice-tcs.blogspot.com/">its own blog</a>. In the past, I have covered ICE-TCS related news here and I will continue to do so. Those posts will also appear in the centre's blog.<br/><br/>Have a look at the <a href="https://ice-tcs.blogspot.com/">new blog</a> if you are interested in the work we do and in the events at our little centre in Reykjavik, Iceland.</div>
    </content>
    <updated>2019-04-13T12:14:00Z</updated>
    <published>2019-04-13T12:14:00Z</published>
    <author>
      <name>Luca Aceto</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/01092671728833265127</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-27705661</id>
      <author>
        <name>Luca Aceto</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/01092671728833265127</uri>
      </author>
      <link href="http://processalgebra.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://processalgebra.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Papers I find interesting---mostly, but not solely, in Process Algebra---, and some fun stuff in Mathematics and Computer Science at large and on general issues related to research, teaching and academic life.</subtitle>
      <title>Process Algebra Diary</title>
      <updated>2019-05-29T07:54:42Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-27705661.post-5618334143658813829</id>
    <link href="http://processalgebra.blogspot.com/feeds/5618334143658813829/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=27705661&amp;postID=5618334143658813829" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/5618334143658813829" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/5618334143658813829" rel="self" type="application/atom+xml"/>
    <link href="http://processalgebra.blogspot.com/2019/04/icse-2019-acm-sigsoft-distinguished.html" rel="alternate" type="text/html"/>
    <title>ICSE 2019 ACM SIGSOFT Distinguished Paper Award to GSSI students</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div>I am very pleased to inform you that Emilio Cruciani and Roberto Verdecchia, two third-year PhD students in CS at the GSSI,¬† and their coauthors Breno Miranda and Antonia Bertolino (member of the Scientific Committee of the PhD programme in CS at the GSSI) will receive¬†an ICSE 2019 ACM SIGSOFT Distinguished Paper Award for their paper "<a href="https://robertoverdecchia.github.io/papers/ICSE_2019.pdf">Scalable Approaches for Test Suite Reduction</a>".¬†</div><div>¬†</div><div>Distinguished Papers represent the very best contributions to the ICSE Technical Track, and are awarded to up to 10% of the papers. (ICSE is the premiere annual conference in the field of software engineering and is very competitive.) This is a remarkable achievement that reflects well on the authors, on CS@GSSI and on the institute as a whole.¬†</div><div><br/></div><div>Congratulations to Antonella, Breno, Emilio and Roberto, not to mention the GSSI as a whole!</div></div>
    </content>
    <updated>2019-04-13T09:13:00Z</updated>
    <published>2019-04-13T09:13:00Z</published>
    <author>
      <name>Luca Aceto</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/01092671728833265127</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-27705661</id>
      <author>
        <name>Luca Aceto</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/01092671728833265127</uri>
      </author>
      <link href="http://processalgebra.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://processalgebra.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Papers I find interesting---mostly, but not solely, in Process Algebra---, and some fun stuff in Mathematics and Computer Science at large and on general issues related to research, teaching and academic life.</subtitle>
      <title>Process Algebra Diary</title>
      <updated>2019-05-29T07:54:42Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-27705661.post-1713001394320488394</id>
    <link href="http://processalgebra.blogspot.com/feeds/1713001394320488394/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=27705661&amp;postID=1713001394320488394" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/1713001394320488394" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/1713001394320488394" rel="self" type="application/atom+xml"/>
    <link href="http://processalgebra.blogspot.com/2019/04/eatcs-award-2019-to-thomas-henzinger.html" rel="alternate" type="text/html"/>
    <title>EATCS Award 2019 to Thomas Henzinger</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">The EATCS has just announced that <a href="https://pub.ist.ac.at/~tah/">Thomas Henzinger</a> is the <a href="http://eatcs.org/index.php/component/content/article/1-news/2811-the-eatcs-award-2019-laudatio-for-thomas-henzinger">EATCS Award 2019 recipient</a> for "fundamental contributions to the theory and practice of formal verification and synthesis of reactive, real-time, and hybrid computer systems, and to the application of formal methods to biological systems." Congratulations to¬† the award committee---consisting of Artur Czumaj, Marta Kwiatkowska and Christos Papadimitriou (chair)---for their great choice, to Tom for a very well deserved award and to the TCS community at large.<br/><br/>Of course, Tom Henzinger needs no introduction. However, let me use this post to provide a bird's eye view of his career and of some of his many contributions to TCS, which would be enough for a good number of very successful research careers. The text below is largely due to <a href="http://di.ulb.ac.be/verif/jfr/">Jean-Francois Raskin</a>. <br/><br/><br/><b>Biographical sketch</b> Thomas A. Henzinger is the President of <a href="http://www.ist.ac.at/">IST Austria</a> (Institute of Science and Technology Austria), which, under his leadership, has quickly become one of the most impactful research institutes in the world. Before joining IST as its first president, Tom was Assistant Professor of Computer Science at Cornell University (1992-95), Assistant Professor (1996-97), Associate Professor (1997-98) and Professor (1998-2004) of Electrical Engineering and Computer Sciences at the University of California, Berkeley. He was also the Director of the Max-Planck Institute for Computer Science in Saarbruecken, Germany (1999) and Professor of Computer and Communication Sciences at EPFL in Lausanne, Switzerland (2004-09).<br/><br/>Tom is an ISI highly cited researcher and his h-index is 103, according to <a href="https://scholar.google.com/citations?user=jpgplxUAAAAJ&amp;hl=en">Google Scholar</a>. He is a member of Academia Europaea, a member of the German Academy of Sciences (Leopoldina), a member of the Austrian Academy of Sciences, a Fellow of the AAAS, a Fellow of the EATCS, a Fellow of the ACM, and a Fellow of the IEEE. He was the recipient of the Milner Award of the Royal Society in 2015, of the Wittgenstein Award of the Austrian Science Fund and was granted an ERC Advanced Investigator Grant in 2010. He received the SIGPLAN POPL Most Influential Paper Award (2014), Logic in Computer Science Test-of-Time Award (2012), ACM SIGSOFT Impact Paper Award (2011), and Best Paper awards at SIGSOFT FSE and CONCUR.<br/><br/><b>Main scientific achievements</b> Tom's research focuses on modern systems theory, especially models, algorithms, and tools for the design and verification of reliable software, hardware and embedded systems. His <a href="https://pub.ist.ac.at/~tah/Publications/bytopic.html#hytech">HyTech tool </a>was the first model checker for mixed discrete-continuous systems.<br/><br/>Tom has made a large number of fundamental contributions to theoretical computer science. Here I will limit myself to mentioning a small number of research areas where he has been particularly prolific and influential.<br/><ul><li><i><a href="https://pub.ist.ac.at/~tah/Publications/bytopic.html#real-time">The theory of timed and hybrid systems</a>.</i> Tom has defined and studied the expressiveness and the algorithmic complexity of several real-time extensions of temporal logics. He is one of the most important contributors to the <a href="https://pub.ist.ac.at/~tah/Publications/bytopic.html#hytech">theory of hybrid automata and to algorithms for the analysis of suchmodels</a>. His papers on the subject are among the most cited ones in the field of computer-aided verification. As an example, his paper ‚ÄúSymbolic model checking for real-time systems‚Äù received a LICS Test-of-Time Award in 2012. He has also studied the gap that exists between mathematical models of systems (e.g. hybrid automata) and their implementation on physical hardware. To bridge this gap, he developed models of physical platforms such as <a href="https://pub.ist.ac.at/~tah/Publications/bytopic.html#giotto">Giotto</a> and E-machines, and he devised ways to relate their semantics with the one of the abstract mathematical models.</li><li><i><a href="https://pub.ist.ac.at/~tah/Publications/bytopic.html#games">Games for verification and control</a>.</i> Tom has introduced the logic ATL*, which extends LTL and CTL* with the ability to reason about strategies that can be played by coalitions of agents/components in models of multi-agent/component systems. He has contributed to the understanding of the potential of adopting concepts from game theory for modeling and reasoning about open systems. He has contributed to a large number of algorithmic advances for solving game-graph problems and to better understand their computational complexity.</li><li><i>From Boolean models to quantitative models for verification and synthesis.</i> Tom has recently investigated how to shift from Boolean models to quantitative models. This research proposes quantitative generalizations of the paradigms that had success in reactive modeling, such as compositionality, property-preserving abstraction, model checking and synthesis. With those models, we can specify and reason about quantitative aspects, such as resource consumption, or compare the performance of different design solutions in embedded systems. He has obtained a substantial funding from the European Research Council to proceed along this promising line of research.</li><li><a href="https://pub.ist.ac.at/~tah/Publications/bytopic.html#blast"><i>Foundations of software model checking.</i></a> Tom has contributed substantially to the algorithms underlying the analysis of software systems by introducing the concept of lazy abstraction. Those ideas have been implemented in the highly influential tool Blast. This line of work was honoured with the Most Influential 2004 POPL Paper Award which he received in 2014.</li><li><a href="https://pub.ist.ac.at/~tah/Publications/bytopic.html#bio"><i>Computational modelling of biological systems.</i></a> Tom and his coworkers have shown that computational models are well suited to model the dynamics of biological systems. This is part of a broader research program that has the objective to show that concepts introduced to formalize reactive systems are helpful to model and reason about biological systems.</li></ul>Those important theoretical contributions have always been developed with relevant practical applications in mind. Consequently, Thomas Henzinger has not only worked on the foundations of our subject, but he also transferred his theoretical ideas into practice by developing tools and by suggesting methodologies that could be used in applying his theoretical results.<br/><br/>Tom is a research leader who has had a profound influence on his PhD students and post-docs. To wit, several of his former students are now well-recognized researchers that enrich the life of our research community and now lead successful research groups.<br/><br/><b>Addendum 12 April 2019:</b> In case you are interested, you can find a short interview I had with Tom Henzinger a while back <a href="http://processalgebra.blogspot.com/2017/02/an-interview-with-thomas-henzinger.html">here</a>. <br/><br/></div>
    </content>
    <updated>2019-04-11T18:33:00Z</updated>
    <published>2019-04-11T18:33:00Z</published>
    <author>
      <name>Luca Aceto</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/01092671728833265127</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-27705661</id>
      <author>
        <name>Luca Aceto</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/01092671728833265127</uri>
      </author>
      <link href="http://processalgebra.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://processalgebra.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Papers I find interesting---mostly, but not solely, in Process Algebra---, and some fun stuff in Mathematics and Computer Science at large and on general issues related to research, teaching and academic life.</subtitle>
      <title>Process Algebra Diary</title>
      <updated>2019-05-29T07:54:42Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-27705661.post-1237807013127291431</id>
    <link href="http://processalgebra.blogspot.com/feeds/1237807013127291431/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=27705661&amp;postID=1237807013127291431" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/1237807013127291431" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/1237807013127291431" rel="self" type="application/atom+xml"/>
    <link href="http://processalgebra.blogspot.com/2019/04/guarded-recursion-and-unique-fixed.html" rel="alternate" type="text/html"/>
    <title>Guarded recursion and unique fixed points: A pill of wisdom from a recent ICE-TCS seminar</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Last Tuesday, <a href="https://www8.cs.fau.de/sergey">Sergey Goncharov</a> (FAU Erlangen-N√ºrnberg, Germany) delivered an <a href="http://www.icetcs.ru.is/" target="_blank">ICE-TCS</a> seminar entitled <i>Guarded traced categories for recursion and iteration</i>. In his talk, Sergey presented recent results, based on¬† joint work (in progress) with <a href="http://www8.informatik.uni-erlangen.de/schroeder/" target="_blank">Lutz Schr√∂der </a>and <a href="https://www.cs.bham.ac.uk/~pbl/" target="_blank">Paul Blain Levy</a>, on axiomatizing the theory of guarded  fixed points with applications to process algebra in monad-based form, where  the notion of guardedness originated.¬† <br/><br/>In the classic theory of process calculi without internal actions, an equation<br/><br/><div style="text-align: center;"><i>X = P(X)¬†</i></div><br/>is <i>guarded</i> if each occurrence of the variable <i>X </i>in the expression <i>P(X) </i>occurs within the scope of some prefixing operator. A classic result in the theory of, for instance, Milner's <a href="https://en.wikipedia.org/wiki/Calculus_of_communicating_systems" target="_blank">Calculus of Communicating Systems</a> is that guarded equations have unique solutions modulo <a href="https://en.wikipedia.org/wiki/Bisimilarity">bisimilarity.</a> For instance, the equation<br/><br/><div style="text-align: center;"><i>X = a.X¬†</i></div><br/>denotes the process <i>rec X. a.X</i> that executes action <i>a</i> indefinitely. If one interprets the above equation over the complete lattice of all languages of finite words over some alphabet, then its only solution is the empty language.<br/><br/>I freely admit that I was under the impression that guarded equations always had unique solutions, but I was wrong. There was a point in the talk at which Sergey showed that the above equation has more than one solution over other domains. Consider, for instance, the set of languages of infinite words over the singleton alphabet <i>{a}</i>. There are only two such languages, namely the empty language and <i>{a<sup>œâ</sup>}</i>, and both are solutions to the above equation. (This is not surprising, since a-prefixing is just the identity function over this family of languages.) The same holds true when we interpret that equation over the set of all languages of finite and infinite words over some alphabet.<br/><br/>This is probably not news to many, but I have learnt a lesson from attending the talk myself: Guardedness does <i>not </i>imply uniqueness of solutions. <br/><br/>To the young researchers of all ages out there: Go to talks and keep an open mind. You will learn a few bits of information that you might need in your future research projects or you might clarify some misconceptions you might have had, like I did last Tuesday.</div>
    </content>
    <updated>2019-04-04T12:40:00Z</updated>
    <published>2019-04-04T12:40:00Z</published>
    <author>
      <name>Luca Aceto</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/01092671728833265127</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-27705661</id>
      <author>
        <name>Luca Aceto</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/01092671728833265127</uri>
      </author>
      <link href="http://processalgebra.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://processalgebra.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Papers I find interesting---mostly, but not solely, in Process Algebra---, and some fun stuff in Mathematics and Computer Science at large and on general issues related to research, teaching and academic life.</subtitle>
      <title>Process Algebra Diary</title>
      <updated>2019-05-29T07:54:42Z</updated>
    </source>
  </entry>
</feed>
