<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2019-02-11T18:21:29Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2019/02/11/parameterized-approximation-algorithms-workshop-paaw-2019/</id>
    <link href="https://cstheory-events.org/2019/02/11/parameterized-approximation-algorithms-workshop-paaw-2019/" rel="alternate" type="text/html"/>
    <title>Parameterized Approximation Algorithms Workshop (PAAW) 2019</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">July 8, 2019 Patras, Greece https://sites.google.com/site/aefeldmann/parameterized-approximation-algorithms-workshop-paaw-2019 Submission deadline: April 26, 2019 Registration deadline: April 30, 2019 The 2019 edition of the Parameterized Approximation Algorithms Workshop (PAAW) will take place as a satellite workshop of ICALP 2019 in Patras, Greece, on Monday July 8th 2019. — Topics of interest — – Parameterized approximation algorithms – Lossy … <a class="more-link" href="https://cstheory-events.org/2019/02/11/parameterized-approximation-algorithms-workshop-paaw-2019/">Continue reading <span class="screen-reader-text">Parameterized Approximation Algorithms Workshop (PAAW) 2019</span></a></div>
    </summary>
    <updated>2019-02-11T15:31:13Z</updated>
    <published>2019-02-11T15:31:13Z</published>
    <category term="workshop"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2019-02-11T18:21:16Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.03164</id>
    <link href="http://arxiv.org/abs/1902.03164" rel="alternate" type="text/html"/>
    <title>Detecting mixed-unitary quantum channels is NP-hard</title>
    <feedworld_mtime>1549843200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Colin Do-Yan Lee, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Watrous:John.html">John Watrous</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.03164">PDF</a><br/><b>Abstract: </b>A quantum channel is said to be a mixed-unitary channel if it can be
expressed as a convex combination of unitary channels. We prove that, given the
Choi representation of a quantum channel, it is NP-hard with respect to
polynomial-time Turing reductions to determine whether or not that channel is a
mixed-unitary channel. This hardness result holds even under the assumption
that the channel is not within an inverse-polynomial distance (in the dimension
of the space upon which it acts) of the boundary of the mixed-unitary channels.
</p></div>
    </summary>
    <updated>2019-02-11T02:20:51Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-02-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.03102</id>
    <link href="http://arxiv.org/abs/1902.03102" rel="alternate" type="text/html"/>
    <title>Using Background Knowledge to Rank Itemsets</title>
    <feedworld_mtime>1549843200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tatti:Nikolaj.html">Nikolaj Tatti</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mampaey:Michael.html">Michael Mampaey</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.03102">PDF</a><br/><b>Abstract: </b>Assessing the quality of discovered results is an important open problem in
data mining. Such assessment is particularly vital when mining itemsets, since
commonly many of the discovered patterns can be easily explained by background
knowledge. The simplest approach to screen uninteresting patterns is to compare
the observed frequency against the independence model. Since the parameters for
the independence model are the column margins, we can view such screening as a
way of using the column margins as background knowledge.
</p>
<p>In this paper we study techniques for more flexible approaches for infusing
background knowledge. Namely, we show that we can efficiently use additional
knowledge such as row margins, lazarus counts, and bounds of ones. We
demonstrate that these statistics describe forms of data that occur in practice
and have been studied in data mining.
</p>
<p>To infuse the information efficiently we use a maximum entropy approach. In
its general setting, solving a maximum entropy model is infeasible, but we
demonstrate that for our setting it can be solved in polynomial time.
Experiments show that more sophisticated models fit the data better and that
using more information improves the frequency prediction of itemsets.
</p></div>
    </summary>
    <updated>2019-02-11T02:23:18Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.02967</id>
    <link href="http://arxiv.org/abs/1902.02967" rel="alternate" type="text/html"/>
    <title>Generic reductions for in-place polynomial multiplication</title>
    <feedworld_mtime>1549843200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Giorgi:Pascal.html">Pascal Giorgi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Grenet:Bruno.html">Bruno Grenet</a>, Daniel Roche <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.02967">PDF</a><br/><b>Abstract: </b>The polynomial multiplication problem has attracted considerable attention
since the early days of computer algebra, and several algorithms have been
designed to achieve the best possible time complexity. More recently, efforts
have been made to improve the space complexity, developing modified versions of
a few specific algorithms to use no extra space while keeping the same
asymptotic running time. In this work, we broaden the scope in two regards.
First, we ask whether an arbitrary multiplication algorithm can be performed
in-place generically. Second, we consider two important variants which produce
only part of the result (and hence have less space to work with), the so-called
middle and short products, and ask whether these operations can also be
performed in-place. To answer both questions in (mostly) the affirmative, we
provide a series of reductions starting with any linear-space multiplication
algorithm. For full and short product algorithms these reductions yield
in-place versions with the same asymptotic time complexity as the out-of-place
version. For the middle product, the reduction incurs an extra logarithmic
factor in the time complexity only when the algorithm is quasi-linear.
</p></div>
    </summary>
    <updated>2019-02-11T02:20:36Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-02-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.02921</id>
    <link href="http://arxiv.org/abs/1902.02921" rel="alternate" type="text/html"/>
    <title>Are your Items in Order?</title>
    <feedworld_mtime>1549843200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tatti:Nikolaj.html">Nikolaj Tatti</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.02921">PDF</a><br/><b>Abstract: </b>Items in many datasets can be arranged to a natural order. Such orders are
useful since they can provide new knowledge about the data and may ease further
data exploration and visualization. Our goal in this paper is to define a
statistically well-founded and an objective score measuring the quality of an
order. Such a measure can be used for determining whether the current order has
any valuable information or can it be discarded.
</p>
<p>Intuitively, we say that the order is good if dependent attributes are close
to each other. To define the order score we fit an order-sensitive model to the
dataset. Our model resembles a Markov chain model, that is, the attributes
depend only on the immediate neighbors. The score of the order is the BIC score
of the best model. For computing the measure we introduce a fast dynamic
program. The score is then compared against random orders: if it is better than
the scores of the random orders, we say that the order is good. We also show
the asymptotic connection between the score function and the number of free
parameters of the model. In addition, we introduce a simple greedy approach for
finding an order with a good score. We evaluate the score for synthetic and
real datasets using different spectral orders and the orders obtained with the
greedy method.
</p></div>
    </summary>
    <updated>2019-02-11T02:23:03Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.02889</id>
    <link href="http://arxiv.org/abs/1902.02889" rel="alternate" type="text/html"/>
    <title>Space-efficient merging of succinct de Bruijn graphs</title>
    <feedworld_mtime>1549843200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Egidi:Lavinia.html">Lavinia Egidi</a>, Felipe A. Louza, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Manzini:Giovanni.html">Giovanni Manzini</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.02889">PDF</a><br/><b>Abstract: </b>We propose a new algorithm for merging succinct representations of de Bruijn
graphs introduced in [Bowe et al. WABI 2012]. Our algorithm is inspired by the
approach introduced by Holt and McMillan [Bionformatics 2014, ACM-BCB 2014] for
merging Burrow-Wheeler transforms. In addition to its input, our algorithm uses
only four bitvectors of working space and all data is accessed sequentially
making the algorithm suitable for external memory execution. Our algorithm can
also merge Colored succinct de Bruijn graphs, and can compute the Variable
Order succinct representation from the plain representation of the input
graphs.
</p>
<p>Combining our merging algorithm with recent results on de Bruijn graph
construction, we provide a space efficient procedure for building succinct
representations of de Bruijn graphs for very large collections.
</p></div>
    </summary>
    <updated>2019-02-11T02:21:50Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.02861</id>
    <link href="http://arxiv.org/abs/1902.02861" rel="alternate" type="text/html"/>
    <title>Discovering Descriptive Tile Trees by Mining Optimal Geometric Subtiles</title>
    <feedworld_mtime>1549843200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tatti:Nikolaj.html">Nikolaj Tatti</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vreeken:Jilles.html">Jilles Vreeken</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.02861">PDF</a><br/><b>Abstract: </b>When analysing binary data, the ease at which one can interpret results is
very important. Many existing methods, however, discover either models that are
difficult to read, or return so many results interpretation becomes impossible.
Here, we study a fully automated approach for mining easily interpretable
models for binary data. We model data hierarchically with noisy
tiles-rectangles with significantly different density than their parent tile.
To identify good trees, we employ the Minimum Description Length principle.
</p>
<p>We propose STIJL, a greedy any-time algorithm for mining good tile trees from
binary data. Iteratively, it finds the locally optimal addition to the current
tree, allowing overlap with tiles of the same parent. A major result of this
paper is that we find the optimal tile in only $\Theta(NM\min(N, M))$ time.
STIJL can either be employed as a top-$k$ miner, or by MDL we can identify the
tree that describes the data best.
</p>
<p>Experiments show we find succinct models that accurately summarise the data,
and, by their hierarchical property are easily interpretable.
</p></div>
    </summary>
    <updated>2019-02-11T02:22:22Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.02834</id>
    <link href="http://arxiv.org/abs/1902.02834" rel="alternate" type="text/html"/>
    <title>The Long and the Short of It: Summarising Event Sequences with Serial Episodes</title>
    <feedworld_mtime>1549843200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tatti:Nikolaj.html">Nikolaj Tatti</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vreeken:Jilles.html">Jilles Vreeken</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.02834">PDF</a><br/><b>Abstract: </b>An ideal outcome of pattern mining is a small set of informative patterns,
containing no redundancy or noise, that identifies the key structure of the
data at hand. Standard frequent pattern miners do not achieve this goal, as due
to the pattern explosion typically very large numbers of highly redundant
patterns are returned.
</p>
<p>We pursue the ideal for sequential data, by employing a pattern set mining
approach-an approach where, instead of ranking patterns individually, we
consider results as a whole. Pattern set mining has been successfully applied
to transactional data, but has been surprisingly under studied for sequential
data.
</p>
<p>In this paper, we employ the MDL principle to identify the set of sequential
patterns that summarises the data best. In particular, we formalise how to
encode sequential data using sets of serial episodes, and use the encoded
length as a quality score. As search strategy, we propose two approaches: the
first algorithm selects a good pattern set from a large candidate set, while
the second is a parameter-free any-time algorithm that mines pattern sets
directly from the data. Experimentation on synthetic and real data demonstrates
we efficiently discover small sets of informative patterns.
</p></div>
    </summary>
    <updated>2019-02-11T02:21:08Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>http://bit-player.org/?p=2137</id>
    <link href="http://bit-player.org/2019/divisive-factorials" rel="alternate" type="text/html"/>
    <link href="http://bit-player.org/2019/divisive-factorials#comments" rel="replies" type="text/html"/>
    <link href="http://bit-player.org/2019/divisive-factorials/feed/atom" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Divisive factorials!</title>
    <summary type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml">The other day I was derailed by this tweet from Fermat’s Library: The moment I saw it, I had to stop in my tracks, grab a scratch pad, and check out the formula. The result made sense in a rough-and-ready … <a href="http://bit-player.org/2019/divisive-factorials">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>The other day I was derailed by this tweet from Fermat’s Library:</p>
<p><img alt="Inverse factorial tweet" border="0" class="aligncenter" height="385" src="http://bit-player.org/wp-content/uploads/2019/02/inverse-factorial-tweet.png" width="592"/></p>
<p class="undent">The moment I saw it, I had to stop in my tracks, grab a scratch pad, and check out the formula. The result made sense in a rough-and-ready sort of way. Since the multiplicative version of \(n!\) goes to infinity as \(n\) increases, the “divisive” version should go to zero. And \(\frac{n^2}{n!}\) does exactly that; the polynomial function \(n^2\) grows slower than the exponential function \(n!\) for large enough \(n\):</p>
<p>\[\frac{1}{1}, \frac{4}{2}, \frac{9}{6}, \frac{16}{24}, \frac{25}{120}, \frac{36}{720}, \frac{49}{5040}, \frac{64}{40320}, \frac{81}{362880}, \frac{100}{3628800}.\]</p>
<p class="undent">But why does the quotient take the particular form \(\frac{n^2}{n!}\)? Where does the \(n^2\) come from?</p>
<p>To answer that question, I had to revisit the long-ago trauma of learning to divide fractions, but I pushed through the pain. Proceeding from left to right through the formula in the tweet, we first get \(\frac{n}{n-1}\). Then, dividing that quantity by \(n-2\) yields</p>
<p>\[\cfrac{\frac{n}{n-1}}{n-2} = \frac{n}{(n-1)(n-2)}.\]</p>
<p class="undent">Continuing in the same way, we ultimately arrive at:</p>
<p>\[n \mathbin{/} (n-1) \mathbin{/} (n-2) \mathbin{/} (n-3) \mathbin{/} \cdots \mathbin{/} 1 = \frac{n}{(n-1) (n-2) (n-3) \cdots 1} = \frac{n}{(n-1)!}\]</p>
<p class="undent">To recover the tweet’s stated result of \(\frac{n^2}{n!}\), just multiply numerator and denominator by \(n\). (To my taste, however, \(\frac{n}{(n-1)!}\) is the more perspicuous expression.)</p>
<hr/>
<p>I am a card-carrying factorial fanboy. You can keep your fancy Fibonaccis; <em>this</em> is my favorite function. Every time I try out a new programming language, my first exercise is to write a few routines for calculating factorials. Over the years I have pondered several variations on the theme, such as replacing \(\times\) with \(+\) in the definition (which produces triangular numbers). But I don’t think I’ve ever before considered substituting \(\mathbin{/}\) for \(\times\). It’s messy. Because multiplication is commutative and associative, you can define \(n!\) simply as the product of all the integers from \(1\) through \(n\), without worrying about the order of the operations. With division, order can’t be ignored. In general, \(x \mathbin{/} y \ne y \mathbin{/}x\), and \((x \mathbin{/} y) \mathbin{/} z \ne x \mathbin{/} (y \mathbin{/} z)\).</p>
<p>The Fermat’s Library tweet puts the factors in descending order: \(n, n-1, n-2, \ldots, 1\). The most obvious alternative is the ascending sequence \(1, 2, 3, \ldots, n\). What happens if we define the divisive factorial as \(1 \mathbin{/} 2 \mathbin{/}  3 \mathbin{/} \cdots \mathbin{/} n\)? Another visit to the schoolroom algorithm for dividing fractions yields this simple answer:</p>
<p>\[1 \mathbin{/} 2 \mathbin{/}  3 \mathbin{/} \cdots \mathbin{/} n = \frac{1}{2 \times 3 \times 4 \times \cdots \times n} = \frac{1}{n!}.\]</p>
<p class="undent">In other words, when we repeatedly divide while counting up from \(1\) to \(n\), the final quotient is the reciprocal of \(n!\).  (I wish I could put an exclamation point at the end of that sentence!) If you’re looking for a canonical answer to the question, “What do you get if you divide instead of multiplying in \(n!\)?” I would argue that \(\frac{1}{n!}\) is a better candidate than \(\frac{n}{(n - 1)!}\). Why not embrace the symmetry between \(n!\) and its inverse?</p>
<p>Of course there are many other ways to arrange the <em>n</em> integers in the set \(\{1 \ldots n\}\). How many ways? As it happens, \(n!\) of them! Thus it would seem there are \(n!\) distinct ways to define the divisive \(n!\) function. However, looking at the answers for the two permutations discussed above suggests there’s a simpler pattern at work. Whatever element of the sequence happens to come first winds up in the numerator of a big fraction, and the denominator is the product of all the other elements. As a result, there are really only \(n\) different outcomes—assuming we stick to performing the division operations from left to right. For any integer \(k\) between \(1\) and \(n\), putting \(k\) at the head of the queue creates a divisive \(n!\) equal to \(k\) divided by all the other factors. We can write this out as:</p>
<p>\[\cfrac{k}{\frac{n!}{k}}, \text{ which can be rearranged as } \frac{k^2}{n!}.\]</p>
<p class="undent">And thus we also solve the minor mystery of how \(\frac{n}{(n-1)!}\) became \(\frac{n^2}{n!}\) in the tweet.</p>
<p>It’s worth noting that all of these functions converge to zero as \(n\) goes to infinity. Asymptotically speaking, \(\frac{1^2}{n!}, \frac{2^2}{n!}, \ldots, \frac{n^2}{n!}\) are all alike.</p>
<hr/>
<p>Ta dah! Mission accomplished. Problem solved. Done and dusted. Now we know everything there is to know about divisive factorials, right?</p>
<p>Well, maybe there’s one more question. What does the computer say? If you take your favorite factorial algorithm, and do as the tweet suggests, replacing any appearance of the \(\times\) (or <code>*</code>) operator with <code>/</code>, what happens? Which of the \(n\) variants of divisive \(n!\) does the program produce?</p>
<p>Here’s <em>my</em> favorite algorithm for computing factorials, in the form of a <a href="https://julialang.org/">Julia</a> program:</p>
<pre class="language-julia"><code>function mul!(n)
    if n == 1
        return 1
    else
        return n * mul!(n - 1)
    end
end
</code></pre>
<p>This is the algorithm that has introduced generations of nerds to the concept of recursion. In narrative form it says: If \(n\) is \(1\), then \(mul!(n)\) is \(1\). Otherwise, evaluate the function \(mul!(n-1)\), then multiply the result by \(n\). You might ask what happens if \(n\) is zero or negative. You might ask, but please don’t. For present purposes, \(n \in \mathbb{N}\).Starting with any positive \(n\), the sequence of recursive calls must eventually bottom out with \(n = 1\).</p>
<p>The function can be written more tersely using Julia’s one-liner style of definition:.</p>
<pre class="language-julia"><code>mul!(n)  =  n == 1 ? 1 : n * mul!(n - 1)</code></pre>
<p>The right side of the assignment statement is a conditional expression, or ternary operator, which has the form <code>a ? b : c</code>. Here <code>a</code> is a boolean test clause, which must return a value of either <code>true</code> or <code>false</code>. If <code>a</code> is <code>true</code>, clause <code>b</code> is evaluated, and the result becomes the value of the entire expression. Otherwise clause <code>c</code> is evaluated.</p>
<p>Just to be sure I’ve got this right, here are the first 10 factorials, as calculated by this program:</p>
<pre class="language-julia"><code>[mul!(n) for n in 1:10]
10-element Array{Int64,1}:
       1
       2
       6
      24
     120
     720
    5040
   40320
  362880
 3628800</code></pre>
<p class="indent">Now let’s edit that definition and convert the single occurence of <code>*</code> to a <code>/</code>, leaving everything else (except the name of the function) unchanged.</p>
<pre class="language-julia"><code>div!(n)  =  n == 1 ? 1 : n / div!(n - 1)</code></pre>
<p>And here’s what comes back when we run the program for values of \(n\) from \(1\) through \(20\):</p>
<pre class="language-julia"><code>[div!(n) for n in 1:20]
20-element Array{Real,1}:
 1                 
 2.0               
 1.5               
 2.6666666666666665
 1.875             
 3.2               
 2.1875            
 3.657142857142857 
 2.4609375         
 4.063492063492063 
 2.70703125        
 4.432900432900433 
 2.9326171875      
 4.773892773892774 
 3.14208984375     
 5.092152292152292 
 3.338470458984375 
 5.391690662278897 
 3.523941040039063 
 5.675463855030418 </code></pre>
<p>Huh? That sure doesn’t look like it’s converging to zero—not as \(\frac{1}{n!}\) or as \(\frac{n}{n - 1}\). As a matter of fact, it doesn’t look like it’s going to converge at all. The graph below suggests the sequence is made up of two alternating components, both of which appear to be slowly growing toward infinity as well as diverging from one another.</p>
<p><img alt="Div" border="0" class="aligncenter" height="" src="http://bit-player.org/wp-content/uploads/2019/02/div.svg" width=""/></p>
<p class="indent">In trying to make sense of what we’re seeing here, it helps to change the output type of the <code>div!</code> function. Instead of applying the division operator <code>/</code>, which returns the quotient as a floating-point number, we can substitute the  <code>//</code> operator, which returns an exact rational quotient, reduced to lowest terms.</p>
<pre class="language-julia"><code>div!(n)  =  n == 1 ? 1 : n // div!(n - 1)</code></pre>
<p class="undent">Here’s the sequence of values for <code>n in 1:20</code>:</p>
<pre class="language-julia"><code>20-element Array{Real,1}:
       1      
      2//1    
      3//2    
      8//3    
     15//8    
     16//5    
     35//16   
    128//35   
    315//128  
    256//63   
    693//256  
   1024//231  
   3003//1024 
   2048//429  
   6435//2048 
  32768//6435 
 109395//32768
  65536//12155
 230945//65536
 262144//46189 </code></pre>
<p>The list is full of curious patterns. It’s a double helix, with even numbers and odd numbers zigzagging in complementary strands. The even numbers are not just even; they are all powers of \(2\). Also, they appear in pairs—first in the numerator, then in the denominator—and their sequence is nondecreasing. But there are gaps; not all powers of \(2\) are present. The odd strand looks even more complicated, with various small prime factors flitting in and out of the numbers. (The primes <em>have</em> to be small—smaller than \(n\), anyway.)</p>
<p>This outcome took me by surprise. I had really expected to see a much tamer sequence, like those I worked out with pencil and paper. All those jagged, jitterbuggy ups and downs made no sense. Nor did the overall trend of unbounded growth in the ratio. How could you keep dividing and dividing, and wind up with bigger and bigger numbers?</p>
<p>At this point you may want to pause before reading on, and try to work out your own theory of where these zigzag numbers are coming from. If you need a hint, you can get a strong one—almost a spoiler—by looking up the sequence of numerators or the sequence of denominators in the <a href="http://oeis.org">Online Encyclopedia of Integer Sequences</a>.</p>
<hr/>
<p>Here’s another hint. A small edit to the <code>div!</code> program completely transforms the output. Just flip the final clause, changing <code>n // div!(n - 1)</code> into <code>div!(n - 1) // n</code>. </p>
<pre class="language-julia"><code>div!(n)  =  n == 1 ? 1 : div!(n - 1) // n</code></pre>
<p class="undent">Now the results look like this:</p>
<pre class="language-julia"><code>10-element Array{Real,1}:
  1                    
 1//2                  
 1//6                  
 1//24                 
 1//120                
 1//720                
 1//5040               
 1//40320              
 1//362880             
 1//3628800</code></pre>
<p>This is the inverse factorial function we’ve already seen, the series of quotients generated when you march left to right through an ascending sequence of divisors \(1 \mathbin{/} 2 \mathbin{/}  3 \mathbin{/} \cdots \mathbin{/} n\). </p>
<p>It’s no surprise that flipping the final clause in the procedure alters the outcome. After all, we know that division is not commutative or associative. What’s not so easy to see is why the sequence of quotients generated by the original program takes that weird zigzag form. What mechanism is giving rise to those paired powers of 2 and the alternation of odd and even?</p>
<p>I have found that it’s easier to explain what’s going on in the zigzag sequence when I describe an iterative version of the procedure, rather than the recursive one. (This is an embarrassing admission for someone who has argued that recursive definitions are easier to reason about, but there you have it.) Here’s the program:</p>
<pre class="language-julia"><code>function div!_iter(n)
    q = 1
    for i in 1:n
        q = i // q
    end
    return q
end</code></pre>
<p>I submit that this looping procedure is operationally identical to the recursive function, in the sense that if <code>div!(n)</code> and <code>div!_iter(n)</code> both return a result for some positive integer <code>n</code>, it will always be the same result. Here’s my evidence: </p>
<pre class="language-julia"><code>[div!(n) for n in 1:20]    [div!_iter(n) for n in 1:20]
            1                         1//1    
           2//1                       2//1    
           3//2                       3//2    
           8//3                       8//3    
          15//8                      15//8    
          16//5                      16//5    
          35//16                     35//16   
         128//35                    128//35   
         315//128                   315//128  
         256//63                    256//63   
         693//256                   693//256  
        1024//231                  1024//231  
        3003//1024                 3003//1024 
        2048//429                  2048//429  
        6435//2048                 6435//2048 
       32768//6435                32768//6435 
      109395//32768              109395//32768
       65536//12155               65536//12155
      230945//65536              230945//65536
      262144//46189              262144//46189</code></pre>
<p>To understand the process that gives rise to these numbers, consider the successive values of the variables \(i\) and \(q\) each time the loop is executed. Initially, \(i\) and \(q\) are both set to \(1\); hence, after the first passage through the loop, the statement <code>q = i // q</code> gives \(q\) the value \(\frac{1}{1}\). Next time around, \(i = 2\) and \(q = \frac{1}{1}\), so \(q\)’s new value is \(\frac{2}{1}\). On the third iteration, \(i = 3\) and \(q = \frac{2}{1}\), yielding \(\frac{i}{q} \rightarrow \frac{3}{2}\). If this is still confusing, try thinking of \(\frac{i}{q}\) as \(i \times \frac{1}{q}\). The crucial observation is that on every passage through the loop, \(q\) is inverted, becoming \(\frac{1}{q}\).</p>
<p>If you unwind these operations, and look at the multiplications and divisions that go into each element of the series, a pattern emerges:</p>
<p>\[\frac{1}{1}, \quad \frac{2}{1}, \quad \frac{1 \cdot 3}{2}, \quad \frac{2 \cdot 4}{1 \cdot 3}, \quad \frac{1 \cdot 3 \cdot 5}{2 \cdot 4} \quad \frac{2 \cdot 4 \cdot 6}{1 \cdot 3 \cdot 5}\]</p>
<p class="undent">The general form is:</p>
<p>\[\frac{1 \cdot 3 \cdot 5 \cdot \cdots \cdot n}{2 \cdot 4 \cdot \cdots \cdot (n-1)} \quad (\text{odd } n) \qquad  \frac{2 \cdot 4 \cdot 6 \cdot \cdots \cdot n}{1 \cdot 3 \cdot 5 \cdot \cdots \cdot (n-1)} \quad (\text{even } n).<br/>
\]</p>
<hr/>
<p>The functions \(1 \cdot 3 \cdot 5 \cdot \cdots \cdot n\) for odd \(n\) and \(2 \cdot 4 \cdot 6 \cdot \cdots \cdot n\) for even \(n\) have a name! They are known as double factorials, with the notation \(n!!\). Terrible terminology, no? Better to have named them “semi-factorials.” And if I didn’t know better, I would read \(n!!\) as “the factorial of the factorial.” The double factorial of <em>n</em> is defined as the product of <em>n</em> and all smaller positive integers of the same parity. Thus our peculiar sequence of zigzag quotients is simply \(\frac{n!!}{(n-1)!!}\).</p>
<p>A <a href="https://www.tandfonline.com/doi/abs/10.4169/math.mag.85.3.177">2012 article</a> by Henry W. Gould and Jocelyn Quaintance (behind a paywall, regrettably) surveys the applications of double factorials. They turn up more often than you might guess. In the middle of the 17th century John Wallis came up with this identity:</p>
<p>\[\frac{\pi}{2} = \frac{2 \cdot 2 \cdot 4 \cdot 4 \cdot 6 \cdot 6 \cdots}{1 \cdot 3 \cdot 3 \cdot 5 \cdot 5 \cdot 7 \cdots} = \lim_{n \rightarrow \infty} \frac{((2n)!!)^2}{(2n + 1)!!(2n - 1)!!}\]</p>
<p class="undent">An even weirder series, involving the cube of a quotient of double factorials, sums to \(\frac{2}{\pi}\). That one was discovered by (who else?) Srinivasa Ramanujan.</p>
<p>Gould and Quaintance also discuss the double factorial counterpart of binomial coefficients. The standard binomial coefficient is defined as:</p>
<p>\[\binom{n}{k} = \frac{n!}{k! (n-k)!}.\]</p>
<p class="undent">The double version is:</p>
<p>\[\left(\!\binom{n}{k}\!\right) = \frac{n!!}{k!! (n-k)!!}.\]</p>
<p class="undent">Note that our zigzag numbers fit this description and therefore qualify as double factorial binomial coefficients. Specifically, they are the numbers:</p>
<p>\[\left(\!\binom{n}{1}\!\right) = \left(\!\binom{n}{n - 1}\!\right) = \frac{n!!}{1!! (n-1)!!}.\]</p>
<p class="undent">The regular binomial \(\binom{n}{1}\) is not very interesting; it is simply equal to \(n\). But the doubled version \(\left(\!\binom{n}{1}\!\right)\), as we’ve seen, dances a livelier jig. And, unlike the single binomial, it is not always an integer. (The only integer values are \(1\) and \(2\).)</p>
<p>Seeing the zigzag numbers as ratios of double factorials explains quite a few of their properties, starting with the alternation of evens and odds. We can also see why all the even numbers in the sequence are powers of 2. Consider the case of \(n = 6\). The numerator of this fraction is \(2 \cdot 4 \cdot 6 = 48\), which acquires a factor of \(3\) from the \(6\). But the denominator is \(1 \cdot 3 \cdot 5 = 15\). The \(3\)s above and below cancel, leaving \(\frac{16}{5}\). Such cancelations will happen in every case. Whenever an odd factor \(m\) enters the even sequence, it must do so in the form \(2 \cdot m\), but at that point \(m\) itself must already be present in the odd sequence.</p>
<hr/>
<p>Is the sequence of zigzag numbers a reasonable answer to the question, “What happens when you divide instead of multiply in \(n!\)?” Or is the computer program that generates them just a buggy algorithm? My personal judgment is that \(\frac{1}{n!}\) is a more intuitive answer, but \(\frac{n!!}{(n - 1)!!}\) is more interesting.</p>
<p>Furthermore, the mere existence of the zigzag sequence broadens our horizons. As noted above, if you insist that the division algorithm must always chug along the list of \(n\) factors in order, at each stop dividing the number on the left by the number on the right, then there are only \(n\) possible outcomes, and they all look much alike. But the zigzag solution suggests wilder possibilities. We can formulate the task as follows. Take the set of factors \(\{1 \dots n\}\), select a subset, and invert all the elements of that subset; now multiply all the factors, both the inverted and the upright ones. If the inverted subset is empty, the result is the ordinary factorial \(n!\). If <em>all</em> of the factors are inverted, we get the inverse \(\frac{1}{n!}\). And if every second factor is inverted, starting with \(n - 1\), the result is an element of the zigzag sequence.</p>
<p>These are only a few among the many possible choices; in total there are \(2^n\) subsets of \(n\) items. For example, you might invert every number that is prime or a power of a prime \((2, 3, 4, 5, 7, 8, 9, 11, \dots)\). For small \(n\), the result jumps around but remains consistently less than \(1\):</p>
<p><img alt="Prime powers" border="0" class="centered" height="" src="http://bit-player.org/wp-content/uploads/2019/02/prime-powers.svg" width=""/></p>
<p class="undent">If I were to continue this plot to larger \(n\), however, it would take off for the stratosphere. Prime powers get sparse farther out on the number line.</p>
<hr/>
<p>Here’s a question. We’ve seen factorial variants that go to zero as \(n\) goes to infinity, such as \(1/n!\). We’ve seen other variants grow without bound as \(n\) increases, including \(n!\) itself, and the zigzag numbers. Are there any versions of the factorial process that converge to a finite bound other than zero?</p>
<p>My first thought was this algorithm:</p>
<pre class="language-julia"><code>function greedy_balance(n)
    q = 1
    while n &gt; 0
        q = q &gt; 1 ? q /= n : q *= n
        n -= 1
    end
    return q
end</code></pre>
<p class="undent">We loop through the integers from \(n\) down to \(1\), calculating the running product/quotient \(q\) as we go. At each step, if the current value of \(q\) is greater than \(1\), we divide by the next factor; otherwise, we multiply. This scheme implements a kind of feedback control or target-seeking behavior. If \(q\) gets too large, we reduce it; too small and we increase it. I conjectured that as \(n\) goes to infinity, \(q\) would settle into an ever-narrower range of values near \(1\).</p>
<p>Running the experiment gave me another surprise:</p>
<p><img alt="Greedy balance linear" border="0" class="centered" height="" src="http://bit-player.org/wp-content/uploads/2019/02/greedy_balance_linear.svg" width=""/></p>
<p class="undent">That sawtooth wave is not quite what I expected. One minor peculiarity is that the curve is not symmetric around \(1\); the excursions above have higher amplitude than those below. But this distortion is more visual than mathematical. Because \(q\) is a ratio, the distance from \(1\) to \(10\) is the same as the distance from \(1\) to \(\frac{1}{10}\), but it doesn’t look that way on a linear scale. The remedy is to plot the log of the ratio:</p>
<p><img alt="Greedy balance" border="0" class="centered" height="" src="http://bit-player.org/wp-content/uploads/2019/02/greedy_balance.svg" width=""/></p>
<p>Now the graph is symmetric, or at least approximately so, centered on \(0\), which is the logarithm of \(1\). But a larger mystery remains. The sawtooth waveform is very regular, with a period of \(4\), and it shows no obvious signs of shrinking toward the expected limiting value of \(\log q = 0\). Numerical evidence suggests that as \(n\) goes to infinity the peaks of this curve converge on a value just above \(q = \frac{5}{3}\), and the troughs approach a value just below \(q = \frac{3}{5}\). (The corresponding base-\(10\) logarithms are roughly \(\pm0.222\). I have not worked out why this should be so. Perhaps someone will explain it to me.</p>
<p>The failure of this greedy algorithm doesn’t mean we can’t find a divisive factorial that converges to \(q = 1\). If we work with the logarithms of the factors, this procedure becomes an instance of a well-known compu­tational problem called the number partitioning problem. You are given a set of real numbers and asked to divide it into two sets whose sums are equal, or as close to equal as possible. It’s a certifiably hard problem, but it has also been called (<a href="http://bit-player.org/bph-publications/AmSci-2002-03-Hayes-NPP.pdf">PDF</a>) “the easiest hard problem.”For any given \(n\), we might find that inverting some other subset of the factors gives a better approximation to \(n! = 1\). For small \(n\), we can solve the problem by brute force: Just look at all \(2^n\) subsets and pick the best one.</p>
<p>I have computed the optimal partitionings up to \(n = 30\), where there are a billion possibilities to choose from.</p>
<p><img alt="Optimum balance graph" border="0" class="centered" height="" src="http://bit-player.org/wp-content/uploads/2019/02/optimum_balance_graph.svg" width=""/></p>
<p class="undent">The graph is clearly flatlining. You could use the same method to force convergence to any other value between \(0\) and \(n!\).</p>
<p>And thus we have yet another answer to the question in the tweet that launched this adventure. What happens when you divide instead of multiply in n!? Anything you want.</p></div>
    </content>
    <updated>2019-02-10T08:48:33Z</updated>
    <published>2019-02-10T08:48:33Z</published>
    <category scheme="http://bit-player.org" term="computing"/>
    <category scheme="http://bit-player.org" term="mathematics"/>
    <author>
      <name>Brian Hayes</name>
      <uri>http://bit-player.org</uri>
    </author>
    <source>
      <id>http://bit-player.org/feed/atom</id>
      <link href="http://bit-player.org" rel="alternate" type="text/html"/>
      <link href="http://bit-player.org/feed/atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">An amateur's outlook on computation and mathematics</subtitle>
      <title xml:lang="en-US">bit-player</title>
      <updated>2019-02-10T20:48:43Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.02755</id>
    <link href="http://arxiv.org/abs/1902.02755" rel="alternate" type="text/html"/>
    <title>Significance of Episodes Based on Minimal Windows</title>
    <feedworld_mtime>1549756800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tatti:Nikolaj.html">Nikolaj Tatti</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.02755">PDF</a><br/><b>Abstract: </b>Discovering episodes, frequent sets of events from a sequence has been an
active field in pattern mining. Traditionally, a level-wise approach is used to
discover all frequent episodes. While this technique is computationally
feasible it may result in a vast number of patterns, especially when low
thresholds are used.
</p>
<p>In this paper we propose a new quality measure for episodes. We say that an
episode is significant if the average length of its minimal windows deviates
greatly when compared to the expected length according to the independence
model. We can apply this measure as a post-pruning step to test whether the
discovered frequent episodes are truly interesting and consequently to reduce
the number of output.
</p>
<p>As a main contribution we introduce a technique that allows us to compute the
distribution of lengths of minimal windows using the independence model. Such a
computation task is surpisingly complex and in order to solve it we compute the
distribution iteratively starting from simple episodes and progressively moving
towards the more complex ones. In our experiments we discover candidate
episodes that have a sufficient amount of minimal windows and test each
candidate for significance. The experimental results demonstrate that our
approach finds significant episodes while ignoring uninteresting ones.
</p></div>
    </summary>
    <updated>2019-02-10T23:22:02Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-08T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.02526</id>
    <link href="http://arxiv.org/abs/1902.02526" rel="alternate" type="text/html"/>
    <title>Going Far From Degeneracy</title>
    <feedworld_mtime>1549756800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fomin:Fedor_V=.html">Fedor V. Fomin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Golovach:Petr_A=.html">Petr A. Golovach</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lokshtanov:Daniel.html">Daniel Lokshtanov</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Panolan:Fahad.html">Fahad Panolan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Saurabh:Saket.html">Saket Saurabh</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zehavi:Meirav.html">Meirav Zehavi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.02526">PDF</a><br/><b>Abstract: </b>An undirected graph G is d-degenerate if every subgraph of G has a vertex of
degree at most d. By the classical theorem of Erd\H{o}s and Gallai from 1959,
every graph of degeneracy d&gt;1 contains a cycle of length at least d+1. The
proof of Erd\H{o}s and Gallai is constructive and can be turned into a
polynomial time algorithm constructing a cycle of length at least d+1. But can
we decide in polynomial time whether a graph contains a cycle of length at
least d+2? An easy reduction from Hamiltonian Cycle provides a negative answer
to this question: deciding whether a graph has a cycle of length at least d+2
is NP-complete. Surprisingly, the complexity of the problem changes drastically
when the input graph is 2-connected. In this case we prove that deciding
whether G contains a cycle of length at least d+k can be done in time
2^{O(k)}|V(G)|^{O(1)}. In other words, deciding whether a 2-connected n-vertex
G contains a cycle of length at least d+log n can be done in polynomial time.
</p>
<p>Similar algorithmic results hold for long paths in graphs. We observe that
deciding whether a graph has a path of length at least d+1 is NP-complete.
However, we prove that if graph G is connected, then deciding whether G
contains a path of length at least d+k can be done in time 2^{O(k)}n^{O(1)}. We
complement these results by showing that the choice of degeneracy as the `above
guarantee parameterization' is optimal in the following sense: For any
\epsilon&gt;0 it is NP-complete to decide whether a connected (2-connected) graph
of degeneracy d has a path (cycle) of length at least (1+\epsilon)d.
</p></div>
    </summary>
    <updated>2019-02-10T23:22:42Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-08T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.02499</id>
    <link href="http://arxiv.org/abs/1902.02499" rel="alternate" type="text/html"/>
    <title>A fast algorithm for constructing balanced binary search trees</title>
    <feedworld_mtime>1549756800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Ruzankin:Pavel_S=.html">Pavel S. Ruzankin</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.02499">PDF</a><br/><b>Abstract: </b>We suggest a new non-recursive algorithm for constructing a binary search
tree given an array of numbers. The algorithm has $O(N)$ time and $O(1)$ memory
complexities if the given array of $N$ numbers is sorted. The resulting tree is
of minimal height and can be transformed to a complete binary search tree
(retaining minimal height) with $O(\log N)$ time and $O(1)$ memory.
</p></div>
    </summary>
    <updated>2019-02-10T23:22:17Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-08T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.02459</id>
    <link href="http://arxiv.org/abs/1902.02459" rel="alternate" type="text/html"/>
    <title>On Mean Estimation for General Norms with Statistical Queries</title>
    <feedworld_mtime>1549756800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Jerry.html">Jerry Li</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nikolov:Aleksandar.html">Aleksandar Nikolov</a>, Ilya Razenshteyn, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Waingarten:Erik.html">Erik Waingarten</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.02459">PDF</a><br/><b>Abstract: </b>We study the problem of mean estimation for high-dimensional distributions,
assuming access to a statistical query oracle for the distribution. For a
normed space $X = (\mathbb{R}^d, \|\cdot\|_X)$ and a distribution supported on
vectors $x \in \mathbb{R}^d$ with $\|x\|_{X} \leq 1$, the task is to output an
estimate $\hat{\mu} \in \mathbb{R}^d$ which is $\epsilon$-close in the distance
induced by $\|\cdot\|_X$ to the true mean of the distribution. We obtain sharp
upper and lower bounds for the statistical query complexity of this problem
when the the underlying norm is symmetric as well as for Schatten-$p$ norms,
answering two questions raised by Feldman, Guzm\'{a}n, and Vempala (SODA 2017).
</p></div>
    </summary>
    <updated>2019-02-10T23:22:21Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-08T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.02428</id>
    <link href="http://arxiv.org/abs/1902.02428" rel="alternate" type="text/html"/>
    <title>Fourier bounds and pseudorandom generators for product tests</title>
    <feedworld_mtime>1549756800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lee:Chin_Ho.html">Chin Ho Lee</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.02428">PDF</a><br/><b>Abstract: </b>We study the Fourier spectrum of functions $f\colon \{0,1\}^{mk} \to
\{-1,0,1\}$ which can be written as a product of $k$ Boolean functions $f_i$ on
disjoint $m$-bit inputs. We prove that for every positive integer $d$, \[
</p>
<p>\sum_{S \subseteq [mk]: |S|=d} |\hat{f_S}| = O(m)^d . \] Our upper bound is
tight up to a constant factor in the $O(\cdot)$. Our proof builds on a new
`level-$d$ inequality' that bounds above $\sum_{|S|=d} \hat{f_S}^2$ for any
$[0,1]$-valued function $f$ in terms of its expectation, which may be of
independent interest.
</p>
<p>As a result, we construct pseudorandom generators for such functions with
seed length $\tilde O(m + \log(k/\varepsilon))$, which is optimal up to
polynomial factors in $\log m$, $\log\log k$ and $\log\log(1/\varepsilon)$. Our
generator in particular works for the well-studied class of combinatorial
rectangles, where in addition we allow the bits to be read in any order. Even
for this special case, previous generators have an extra $\tilde
O(\log(1/\varepsilon))$ factor in their seed lengths.
</p>
<p>Using Schur-convexity, we also extend our results to functions $f_i$ whose
range is $[-1,1]$.
</p></div>
    </summary>
    <updated>2019-02-10T23:20:49Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-02-08T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.02398</id>
    <link href="http://arxiv.org/abs/1902.02398" rel="alternate" type="text/html"/>
    <title>$\mathsf{QMA}$ Lower Bounds for Approximate Counting</title>
    <feedworld_mtime>1549756800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kretschmer:William.html">William Kretschmer</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.02398">PDF</a><br/><b>Abstract: </b>We prove a query complexity lower bound for $\mathsf{QMA}$ protocols that
solve approximate counting: estimating the size of a set given a membership
oracle. This gives rise to an oracle $A$ such that $\mathsf{SBP}^A \not\subset
\mathsf{QMA}^A$, resolving an open problem of Aaronson [2]. Our proof uses the
polynomial method to derive a lower bound for the $\mathsf{SBQP}$ query
complexity of the $\mathsf{AND}$ of two approximate counting instances. We use
Laurent polynomials as a tool in our proof, showing that the "Laurent
polynomial method" can be useful even for problems involving ordinary
polynomials.
</p></div>
    </summary>
    <updated>2019-02-10T23:21:15Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-02-08T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.02392</id>
    <link href="http://arxiv.org/abs/1902.02392" rel="alternate" type="text/html"/>
    <title>Finding Good Itemsets by Packing Data</title>
    <feedworld_mtime>1549756800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tatti:Nikolaj.html">Nikolaj Tatti</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vreeken:Jilles.html">Jilles Vreeken</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.02392">PDF</a><br/><b>Abstract: </b>The problem of selecting small groups of itemsets that represent the data
well has recently gained a lot of attention. We approach the problem by
searching for the itemsets that compress the data efficiently. As a compression
technique we use decision trees combined with a refined version of MDL. More
formally, assuming that the items are ordered, we create a decision tree for
each item that may only depend on the previous items. Our approach allows us to
find complex interactions between the attributes, not just co-occurrences of
1s. Further, we present a link between the itemsets and the decision trees and
use this link to export the itemsets from the decision trees. In this paper we
present two algorithms. The first one is a simple greedy approach that builds a
family of itemsets directly from data. The second one, given a collection of
candidate itemsets, selects a small subset of these itemsets. Our experiments
show that these approaches result in compact and high quality descriptions of
the data.
</p></div>
    </summary>
    <updated>2019-02-10T23:21:21Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-08T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.02371</id>
    <link href="http://arxiv.org/abs/1902.02371" rel="alternate" type="text/html"/>
    <title>Diffeomorphic Medial Modeling</title>
    <feedworld_mtime>1549756800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yushkevich:Paul_A=.html">Paul A. Yushkevich</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Aly:Ahmed.html">Ahmed Aly</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Jiancong.html">Jiancong Wang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/x/Xie:Long.html">Long Xie</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gorman:Robert_C=.html">Robert C. Gorman</a>, Alison Pouch, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Younes:Laurent.html">Laurent Younes</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.02371">PDF</a><br/><b>Abstract: </b>Deformable shape modeling approaches that describe objects in terms of their
medial axis geometry (e.g., m-reps [Pizer et al., 2003]) yield rich geometrical
features that can be useful for analyzing the shape of sheet-like biological
structures, such as the myocardium. We present a novel shape analysis approach
that combines the benefits of medial shape modeling and diffeomorphometry. Our
algorithm is formulated as a problem of matching shapes using diffeomorphic
flows under constraints that approximately preserve medial axis geometry during
deformation. As the result, correspondence between the medial axes of similar
shapes is maintained. The approach is evaluated in the context of modeling the
shape of the left ventricular wall from 3D echocardiography images.
</p></div>
    </summary>
    <updated>2019-02-10T23:33:11Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-02-08T01:30:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra</id>
    <link href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html" rel="alternate" type="text/html"/>
    <title>Big convex polyhedra in grids</title>
    <summary>I recently wrote here about big convex polygons in grids, a problem for which we know very precise answers. This naturally raises the question: what about higher dimensions? How many vertices can be part of a convex polyhedron in an grid, or more generally a convex polytope in a -dimensional grid of side length ? Here we do still know some pretty good answers, at least up to constant factors in spaces of constant dimension.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I recently wrote here about <a href="https://11011110.github.io/blog/2018/09/05/big-convex-polygons.html">big convex polygons in grids</a>, a problem for which we know very precise answers. This naturally raises the question: what about higher dimensions? How many vertices can be part of a convex polyhedron in an  grid, or more generally a convex polytope in a -dimensional grid of side length ? Here we do still know some pretty good answers, at least up to constant factors in spaces of constant dimension.</p>

<p>The problem is included in a 2008 survey by Imre Bárány,<sup id="fnref:bar"><a class="footnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fn:bar">1</a></sup> according to whom the maximum number of vertices is</p>



<p>For instance, in three dimensional  grids the maximum number of vertices is .</p>

<p>One way to find polyhedra with this many vertices is to take the convex hull of the points in a ball,<sup id="fnref:bl"><a class="footnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fn:bl">2</a></sup> <sup id="fnref:bd"><a class="footnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fn:bd">3</a></sup> or in scaled copies of any fixed smooth convex body. Another way, which should generate polyhedra with a somewhat less irregular appearance and (up to constant factors) the same number of vertices, is to take the <a href="https://en.wikipedia.org/wiki/Minkowski_addition">Minkowski sum</a> of all line segments (up to scaling and translation) that will fit into a smaller grid, of side length . For instance, the <a href="https://en.wikipedia.org/wiki/Truncated_rhombicuboctahedron">truncated rhombicuboctahedron</a> below<sup id="fnref:ruen"><a class="footnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fn:ruen">4</a></sup> is the Minkowski sum of all the line segments that fit into a unit cube. Its 96 vertices lie in a  grid. In general, this method produces a <a href="https://en.wikipedia.org/wiki/Zonohedron">zonohedron</a> whose complexity can be analyzed in terms of a -dimensional arrangement of  hyperplanes. As long as this arrangement is not too degenerate (which it appears not to be, but I haven’t worked out the details carefully) this should give
a number of vertices within a constant factor of the number coming from the convex hull construction.</p>

<p style="text-align: center;"><img alt="Truncated rhombicuboctahedron" src="https://11011110.github.io/blog/assets/2019/truncated-rhombicuboctahedron2.png"/></p>

<p>A matching upper bound comes from a 1963 paper by G. K. Andrews,<sup id="fnref:and"><a class="footnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fn:and">5</a></sup> and Bárány writes that although several more proofs have been published none of them is easy. I’m not sure whether the difficulty is in getting the exact bound or in the fact that Andrews and the later proofs allow more general shapes with volume  that don’t fit into a grid, but it’s not hard to get close to the right bound simply by counting the number of possible facets of a given volume . By using <a href="https://en.wikipedia.org/wiki/Lenstra%E2%80%93Lenstra%E2%80%93Lov%C3%A1sz_lattice_basis_reduction_algorithm">lattice basis reduction</a> the integer vectors in the hyperplane through any facet have a nearly-orthogonal basis whose product of lengths is proportional to . By considering how this product of lengths can be broken down into factors of different scales, and counting how many integer vectors of those lengths exist, it follows that the number of possible facets of volume  is . Combining this with the  surface area of a grid polytope gives the correct upper bound on the number of vertices up to a polylog factor.</p>

<p>What about when the dimension is not constant? The best general construction I know for high dimensions is to take all points with a fixed distance  from the grid center. There are  possible values for the distance, so this construction produces a convex polytope with  vertices. It comes from a 1946 paper by Behrend, who uses this idea to find <a href="https://en.wikipedia.org/wiki/Salem%E2%80%93Spencer_set">dense sets of integers with no arithmetic progressions</a>.<sup id="fnref:beh"><a class="footnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fn:beh">6</a></sup> It is never worse to use the convex hull of the ball than the points on a sphere,
and it is tempting to guess that (at least when  is singly exponential in  so that  becomes constant) the convex hull technique will produce slightly more vertices, , but I don’t know whether this is true or if so how to prove it. A celebrated paper by Elkin from 2011 produces exactly this factor of  improvement in Behrend’s progression-free sets,<sup id="fnref:elk"><a class="footnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fn:elk">7</a></sup> but appears to be doing it some other way than by finding larger convex polytopes.</p>

<div class="footnotes">
  <ol>
    <li id="fn:bar">
      <p>Bárány, Imre (2008), “Extremal problems for convex lattice polytopes: a survey”, <em>Surveys on Discrete and Computational Geometry</em>, Contemporary Mathematics 453, Amer. Math. Soc., pp. 87–103, <a href="https://doi.org/10.1090/conm/453/08796">doi:10.1090/conm/453/08796</a>, <a href="https://mathscinet.ams.org/mathscinet-getitem?mr=2405678">MR2405678</a>. <a class="reversefootnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fnref:bar">↩</a></p>
    </li>
    <li id="fn:bl">
      <p>Bárány, Imre and Larman, David (1998), “The convex hull of the integer points in a large ball”, <em>Math. Ann.</em> 312 (1), pp. 167–181, <a href="https://doi.org/10.1007/s002080050217">doi:10.1007/s002080050217</a>, <a href="https://mathscinet.ams.org/mathscinet-getitem?mr=1645957">MR1645957</a>. <a class="reversefootnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fnref:bl">↩</a></p>
    </li>
    <li id="fn:bd">
      <p>Balog, Antal and Deshouillers, Jean-Marc (1999), “On some convex lattice polytopes”. <em>Number Theory in Progress</em>, Vol. 2 (Zakopane-Kościelisko, 1997), de Gruyter, pp. 591–606, <a href="https://mathscinet.ams.org/mathscinet-getitem?mr=1689533">MR1689533</a>. <a class="reversefootnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fnref:bd">↩</a></p>
    </li>
    <li id="fn:ruen">
      <p>Ruen, Tom (2014), “Truncated rhombicuboctahedron”, CC-BY-SA 4.0, <a href="https://commons.wikimedia.org/wiki/File:Truncated_rhombicuboctahedron2.png">File:Truncated rhombicuboctahedron2.png</a> on Wikimedia commons. <a class="reversefootnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fnref:ruen">↩</a></p>
    </li>
    <li id="fn:and">
      <p>Andrews, George E. (1963), “A lower bound for the volume of strictly convex bodies with many boundary lattice points”, <em>Trans. Amer. Math. Soc.</em> 106, pp. 270–279, <a href="https://doi.org/10.2307/1993769">doi:10.2307/1993769</a>, <a href="https://mathscinet.ams.org/mathscinet-getitem?mr=0143105">MR0143105</a>. <a class="reversefootnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fnref:and">↩</a></p>
    </li>
    <li id="fn:beh">
      <p>Behrend, F. A. (1946), “On sets of integers which contain no three terms in arithmetical progression”, <em>Proc. Nat. Acad. Sci.</em> 32 (12), pp. 331–332, <a href="https://doi.org/10.1073/pnas.32.12.331">doi:10.1073/pnas.32.12.331</a>, <a href="https://mathscinet.ams.org/mathscinet-getitem?mr=0018694">MR0018694</a>. <a class="reversefootnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fnref:beh">↩</a></p>
    </li>
    <li id="fn:elk">
      <p>Elkin, Michael (2011), “An improved construction of progression-free sets”, <em>Israel J. Math.</em> 184, pp. 93–128, <a href="https://arxiv.org/abs/0801.4310">arXiv:0801.4310</a>, <a href="https://doi.org/10.1007%2Fs11856-011-0061-1">doi:10.1007/s11856-011-0061-1</a>, <a href="https://www.ams.org/mathscinet-getitem?mr=2823971">MR2823971</a>. <a class="reversefootnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fnref:elk">↩</a></p>
    </li>
  </ol>
</div>

<p>(<a href="https://mathstodon.xyz/@11011110/101564963348879092">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2019-02-09T15:07:00Z</updated>
    <published>2019-02-09T15:07:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-02-10T07:57:17Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>http://ptreview.sublinear.info/?p=1087</id>
    <link href="https://ptreview.sublinear.info/?p=1087" rel="alternate" type="text/html"/>
    <title>News for January 2019</title>
    <summary>Minimax Testing of Identity to a Reference Ergodic Markov Chain, by Geoffrey Wolfer and Aryeh Kontorovich (arXiv). This work studies distributional identity testing on Markov chains from a single trajectory, as recently introduced by Daskalakis, Dikkala, and Gravin: we wish to test whether a Markov chain is equal to some reference chain, or far from […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><strong>Minimax Testing of Identity to a Reference Ergodic Markov Chain</strong>, by Geoffrey Wolfer and Aryeh Kontorovich (<a href="https://arxiv.org/abs/1902.00080">arXiv</a>). This work studies distributional identity testing on Markov chains from a single trajectory, as recently introduced by <a href="https://arxiv.org/abs/1704.06850">Daskalakis, Dikkala, and Gravin</a>: we wish to test whether a Markov chain is equal to some reference chain, or far from it. This improves on previous work by considering a stronger distance measure than before, and showing that the sample complexity only depends on properties of the reference chain (which we are trying to test identity to). It additionally proves instance-by-instance bounds (where the sample complexity depends on properties of the specific chain we wish to test identity to).</p>



<p><strong>Almost Optimal Distribution-free Junta Testing</strong>, by Nader H. Bshouty (<a href="https://arxiv.org/abs/1901.00717">arXiv</a>). This paper provides a \(\tilde O(k/\varepsilon)\)-query algorithm with two-sided error for testing if a Boolean function is a \(k\)-junta (that is, its value depends only on \(k\) of its variables) in the distribution-free model (where distance is measured with respect to an unknown distribution from which we can sample). This complexity is a quadratic improvement over the \(\tilde O(k^2)/\varepsilon\)-query algorithm of <a href="https://arxiv.org/abs/1802.04859">Chen, Liu, Servedio, Sheng, and Xie</a>. This complexity is also near-optimal, as shown in a lower bound by Saglam (which we covered back in <a href="https://ptreview.sublinear.info/?p=1030">August</a>).</p>



<p><strong>Exponentially Faster Massively Parallel Maximal Matching</strong>, by Soheil Behnezhad, MohammadTaghi Hajiaghayi, and David G. Harris (<a href="https://arxiv.org/abs/1901.03744">arXiv</a>). The authors consider maximal matching in the Massively Parallel Computation (MPC) model. They show that one can compute a maximal matching in \(O(\log \log \Delta)\)-rounds, with \(O(n)\) space per machine. This is an exponential improvement over the previous works, which required either \(\Omega(\log n)\) rounds or \(n^{1 + \Omega(1)}\) space per machine. Corollaries of their result include approximation algorithms for vertex cover, maximum matching, and weighted maximum matching. </p></div>
    </content>
    <updated>2019-02-08T18:30:54Z</updated>
    <published>2019-02-08T18:30:54Z</published>
    <category term="Monthly digest"/>
    <author>
      <name>Gautam Kamath</name>
    </author>
    <source>
      <id>https://ptreview.sublinear.info</id>
      <link href="https://ptreview.sublinear.info/?feed=rss2" rel="self" type="application/atom+xml"/>
      <link href="https://ptreview.sublinear.info" rel="alternate" type="text/html"/>
      <subtitle>The latest in property testing and sublinear time algorithms</subtitle>
      <title>Property Testing Review</title>
      <updated>2019-02-10T23:36:30Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://agtb.wordpress.com/?p=3379</id>
    <link href="https://agtb.wordpress.com/2019/02/08/acm-sigecom-elections/" rel="alternate" type="text/html"/>
    <title>ACM SIGecom Elections</title>
    <summary>The following message just went out to ACM SIGecom members: ———- Forwarded message ——— From: Monique Chang &lt;chang@hq.acm.org&gt; Date: Mon, Feb 4, 2019 at 2:20 PM Subject: 2019 ACM SIGecom Election: Candidate Slate Announcement To: &lt;SIG-ELECTION-ANNOUNCEMENT@listserv.acm.org&gt; Dear ACM SIGecom Member, The ACM SIGecom Nominating Committee has proposed the following candidates for the 2019 ACM SIGecom election. Chair […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><span style="font-weight: 400;">The following message just went out to ACM SIGecom members:</span></p>
<blockquote><p>———- Forwarded message ———<br/>
From: <strong>Monique Chang</strong> &lt;<a href="mailto:chang@hq.acm.org">chang@hq.acm.org</a>&gt;<br/>
Date: Mon, Feb 4, 2019 at 2:20 PM<br/>
Subject: 2019 ACM SIGecom Election: Candidate Slate Announcement<br/>
To: &lt;<a href="mailto:SIG-ELECTION-ANNOUNCEMENT@listserv.acm.org">SIG-ELECTION-ANNOUNCEMENT@listserv.acm.org</a>&gt;</p>
<p>Dear ACM SIGecom Member,</p>
<p>The ACM SIGecom Nominating Committee has proposed the following candidates for the 2019 ACM SIGecom election.</p>
<p><strong><u>Chair</u></strong><br/>
(Running Unopposed)</p>
<p>Nicole Immorlica</p>
<p><strong><u>Vice-Chair</u></strong></p>
<p>Scott Kominers</p>
<p>Ariel Procaccia</p>
<p><strong><u>Secretary-Treasurer</u></strong></p>
<p>Hu Fu</p>
<p>Katrina Ligett</p>
<p>In accordance with the ACM SIG Bylaws, additional candidates may be placed on the ballot by petition. All candidates must be ACM Professional Members, as well as members of the SIG. Anyone interested in petitioning must inform ACM Headquarters, Pat Ryan (<a href="mailto:ryanp@hq.acm.org">ryanp@hq.acm.org</a>), and SIGecom’s Secretary-Treasurer, Jenn Wortman Vaughan (<a href="mailto:jenn@microsoft.com">jenn@microsoft.com</a>), of their intent to petition by <strong>15 March 2019</strong>. Petitions must be submitted to ACM Headquarters for verification by <strong>2 April 2019</strong>.</p>
<p>Monique Chang</p>
<p>ACM SIG Elections Coordinator</p>
<p>Office of Policy and Administration</p></blockquote>
<p><span style="font-weight: 400;">Three things for members of our community to note:</span></p>
<ol>
<li style="font-weight: 400;">It’s important vote (once the link goes out; note that the current email is just an announcement and an invitation for additional candidates to petition to be included on the ballot). The SIG leadership is very important for the ongoing direction of our organization. Your vote makes a difference, because our elections are often decided by small margins.</li>
</ol>
<ol start="2">
<li style="font-weight: 400;">If you didn’t get this email, you’re likely not registered as a member of our SIG. Membership costs only $5 for students and $10 for others; AFAIK, you don’t have to be an ACM member to be a SIG member. Our number of members is an important signal to the ACM about the strength of our community (which is why we have set our fees so low). Votes like this one are also restricted to members! If your membership has lapsed, or if you’ve never taken the plunge, this might be a good occasion to do so, by clicking on the link below:</li>
</ol>
<p style="font-weight: 400;"><a href="https://www.acm.org/special-interest-groups/sigs/sigecom">https://www.acm.org/special-interest-groups/sigs/sigecom</a></p>
<ol start="3">
<li style="font-weight: 400;">Thanks to our nominations chair, David Parkes, who put together the slate of candidates just listed, and also to all of the candidates who agreed to serve. Our community is really lucky to have such a strong and deep pool of volunteers, and this is one more example. Indeed, in advance, I’d particularly like to thank those candidates who *don’t* win, whoever they turn out to be: it’s thankless to stick one’s neck out for an election only to see someone else get chosen (often by a small margin; see #1), but your willingness to serve is much appreciated.</li>
</ol></div>
    </content>
    <updated>2019-02-08T02:44:19Z</updated>
    <published>2019-02-08T02:44:19Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Kevin Leyton-Brown</name>
    </author>
    <source>
      <id>https://agtb.wordpress.com</id>
      <logo>https://secure.gravatar.com/blavatar/52ef314e11e379febf97d1a97547f4cd?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fbuttonw-com.png</logo>
      <link href="https://agtb.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://agtb.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://agtb.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://agtb.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Computation, Economics, and Game Theory</subtitle>
      <title>Turing's Invisible Hand</title>
      <updated>2019-02-11T18:20:37Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/017</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/017" rel="alternate" type="text/html"/>
    <title>TR19-017 |  Fourier bounds and pseudorandom generators for product tests | 

	Chin Ho Lee</title>
    <summary>We study the Fourier spectrum of functions $f\colon \{0,1\}^{mk} \to \{-1,0,1\}$ which can be written as a product of $k$ Boolean functions $f_i$ on disjoint $m$-bit inputs.  We prove that for every positive integer $d$,
\[
  \sum_{S \subseteq [mk]: |S|=d} |\hat{f_S}| = O(m)^d .
\]
Our upper bound is tight up to a constant factor in the $O(\cdot)$.  Our proof builds on a new "level-$d$ inequality" that bounds above $\sum_{|S|=d} \hat{f_S}^2$ for any $[0,1]$-valued function $f$ in terms of its expectation, which may be of independent interest.

As a result, we construct pseudorandom generators for such functions with seed length $\tilde O(m + \log(k/\varepsilon))$, which is optimal up to polynomial factors in $\log m$, $\log\log k$ and $\log\log(1/\varepsilon)$.  Our generator in particular works for the well-studied class of combinatorial rectangles, where in addition we allow the bits to be read in any order.  Even for this special case, previous generators have an extra $\tilde O(\log(1/\varepsilon))$ factor in their seed lengths. 

Using Schur-convexity, we also extend our results to functions $f_i$ whose range is $[-1,1]$.</summary>
    <updated>2019-02-07T14:59:22Z</updated>
    <published>2019-02-07T14:59:22Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-02-11T18:20:33Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/016</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/016" rel="alternate" type="text/html"/>
    <title>TR19-016 |  The hardest halfspace | 

	Alexander A. Sherstov</title>
    <summary>We study the approximation of halfspaces $h:\{0,1\}^n\to\{0,1\}$ in the infinity norm by polynomials and rational functions of any given degree.  Our main result is an explicit construction of the "hardest" halfspace, for which we prove polynomial and rational approximation lower bounds that match the trivial upper bounds achievable for all halfspaces.  This completes a lengthy line of work started by Myhill and Kautz (1961).

As an application, we construct a communication problem with essentially the largest possible gap, of $n$ versus $2^{-\Omega(n)},$ between the sign-rank and discrepancy. Equivalently, our problem exhibits a gap of $\log n$ versus $\Omega(n)$ between the communication complexity with unbounded versus weakly unbounded error, improving quadratically on previous constructions and completing a line of work started by Babai, Frankl, and Simon (FOCS 1986). Our results further generalize to the $k$-party number-on-the-forehead model, where we obtain an explicit separation of $\log n$ versus $\Omega(n/4^{n})$ for communication with unbounded versus weakly unbounded error. This gap is a quadratic improvement on previous work and matches the state of the art for number-on-the-forehead lower bounds.</summary>
    <updated>2019-02-07T14:57:13Z</updated>
    <published>2019-02-07T14:57:13Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-02-11T18:20:33Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-971154734717743655</id>
    <link href="https://blog.computationalcomplexity.org/feeds/971154734717743655/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/02/an-immerman-szelepcsenyi-story.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/971154734717743655" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/971154734717743655" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/02/an-immerman-szelepcsenyi-story.html" rel="alternate" type="text/html"/>
    <title>An Immerman-Szelepcsényi Story</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">As a grad student in the late 80's I had the opportunity to witness many great and often surprising theorems in computational complexity. Let me tell you about one of them, the Immerman-Szelepcsényi result that <a href="https://blog.computationalcomplexity.org/2003/06/foundations-of-complexity-lesson-19.html">nondeterministic space is closed under complement</a>. I wish I had the original emails for this story but instead I'm working from memory and apologies if I get some of the details wrong. I'm expanding from a <a href="https://blog.computationalcomplexity.org/2002/08/last-spring-i-saw-copenhagen-great.html">short version</a> from the early days of this blog.<br/>
<br/>
I started my graduate work at UC Berkeley in 1985 and then moved to MIT in the summer of '86, following my advisor Michael Sipser. In the summer of 1987, Neil Immerman, then at Yale, proved his famous result building on his work in <a href="https://en.wikipedia.org/wiki/Descriptive_complexity_theory">descriptive complexity</a> In those days you didn't email papers, he made copies and sent them by US postal mail to several major researchers in complexity including Sipser. But Sipser was away for the summer, I believe in Russia, and the paper sat in his office.<br/>
<br/>
Immerman also sent the paper to a Berkeley professor, probably Manuel Blum, who gave it to one of his students who decided to speak about the result in a student-led seminar. I forgot who was the student, maybe Moni Naor. I was still on the Berkeley email list so I got the talk announcement and went into complexity ecstasy over the news. I asked Moni (or whomever was giving the talk) if he could tell me details and he sent me a nice write-up of the proof. Given the importance of the result, I sent the proof write-up out to the MIT theory email list.<br/>
<br/>
Guess who was on the MIT theory list? Neil Immerman. Neil wrote back with his own explanation of the proof. Neil explained how it came out of descriptive complexity but as a pure write-up of a proof of the theorem, Moni did an excellent job.<br/>
<br/>
We found out about Robert Szelepcsényi when his paper showed up a few months later in the Bulletin of the European Association for Theoretical Computer Science. Szelepcsényi came to the problem from formal languages, whether context-sensitive languages (nondeterministic linear space) was closed under complement. Szelepcsényi, an undergrad in Slovakia at the time, heard about the problem in a class he took. Szelepcsényi's proof was very similar to Immerman. Szelepcsényi's paper took longer to get to US researchers but likely was proven and written about the same time as Immerman.<br/>
<br/>
Even though both papers were <a href="https://doi.org/10.1137/0217058">published</a> <a href="https://doi.org/10.1007/BF00299636">separately</a> we refer to the result as Immerman-Szelepcsényi and is now just some old important theorem you see in introductory theory classes.</div>
    </content>
    <updated>2019-02-07T12:47:00Z</updated>
    <published>2019-02-07T12:47:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>https://plus.google.com/101693130490639305932</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>https://plus.google.com/101693130490639305932</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-02-11T10:40:07Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/015</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/015" rel="alternate" type="text/html"/>
    <title>TR19-015 |  QMA Lower Bounds for Approximate Counting | 

	William Kretschmer</title>
    <summary>We prove a query complexity lower bound for $QMA$ protocols that solve approximate counting: estimating the size of a set given a membership oracle. This gives rise to an oracle $A$ such that $SBP^A \not\subset QMA^A$, resolving an open problem of Aaronson [2]. Our proof uses the polynomial method to derive a lower bound for the $SBQP$ query complexity of the $AND$ of two approximate counting instances. We use Laurent polynomials as a tool in our proof, showing that the "Laurent polynomial method" can be useful even for problems involving ordinary polynomials.</summary>
    <updated>2019-02-07T08:16:08Z</updated>
    <published>2019-02-07T08:16:08Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-02-11T18:20:33Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=15634</id>
    <link href="https://rjlipton.wordpress.com/2019/02/06/an-old-but-cool-result/" rel="alternate" type="text/html"/>
    <title>An Old But Cool Result</title>
    <summary>Solving a type of Fermat Equation Leo Moser was a mathematician who worked on a very varied set of problems. He for example raised a question about “worms,” and invented a notation for huge numbers. Today I want to talk about one of his results with a very short proof. No, it is not about […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p/><p>
<font color="#0044cc"><br/>
<em>Solving a type of Fermat Equation</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2019/02/06/an-old-but-cool-result/unknown-117/" rel="attachment wp-att-15639"><img alt="" class="alignright size-full wp-image-15639" src="https://rjlipton.files.wordpress.com/2019/02/unknown.jpeg?w=600"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2"/></td>
</tr>
</tbody>
</table>
<p>
Leo Moser was a <a href="https://en.wikipedia.org/wiki/Leo_Moser">mathematician</a> who worked on a very varied set of problems. He for example raised a question about “worms,” and invented a notation for huge <a href="https://en.wikipedia.org/wiki/Steinhaus-Moser_notation">numbers</a>.</p>
<p>
Today I want to talk about one of his results with a very short proof.</p>
<p>
No, it is not about worms. That is a <a href="https://en.wikipedia.org/wiki/Moser%27s_worm_problem">question</a> in discrete geometry that is still open I believe: “What is the region of smallest area which can accommodate every planar arc of length one?” The region must be able to hold the arc inside but the curve can be moved and rotated to allow it to fit. A disk of diameter <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/> works and has area about <img alt="{ 0.78}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+0.78%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ 0.78}"/>. It is possible to do much better and get around <img alt="{ 0.27}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+0.27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ 0.27}"/>. </p>
<p><a href="https://rjlipton.wordpress.com/2019/02/06/an-old-but-cool-result/worm3/" rel="attachment wp-att-15636"><img alt="" class="aligncenter size-medium wp-image-15636" height="143" src="https://rjlipton.files.wordpress.com/2019/02/worm3.png?w=300&amp;h=143" width="300"/></a></p>
<p>See this <a href="https://www.nada.kth.se/~johanh/snakes.pdf">paper</a> for some additional details.</p>
<p>
No, it is not about a conjecture of Paul Erdős See <a href="https://arxiv.org/pdf/1011.2956.pdf">this</a> for a great paper on this result: </p>
<blockquote><p><b>Theorem 1</b> <em> Suppose that 	</em></p><em>
<p align="center"><img alt="\displaystyle  1^{k} + 2^{k} + \cdots + (m-1)^{k} = m^{k}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++1%5E%7Bk%7D+%2B+2%5E%7Bk%7D+%2B+%5Ccdots+%2B+%28m-1%29%5E%7Bk%7D+%3D+m%5E%7Bk%7D.+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="\displaystyle  1^{k} + 2^{k} + \cdots + (m-1)^{k} = m^{k}. "/></p>
<p>Then any <img alt="{(m,k)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28m%2Ck%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{(m,k)}"/> solution in integers with <img alt="{k \ge 2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk+%5Cge+2%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{k \ge 2}"/> must have 	</p>
<p align="center"><img alt="\displaystyle  m &gt; 10^{10^{6}}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++m+%3E+10%5E%7B10%5E%7B6%7D%7D.+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="\displaystyle  m &gt; 10^{10^{6}}. "/></p>
</em><p><em/>
</p></blockquote>
<p>Erdős conjectured there are no solutions at all. It is easy to check that for <img alt="{k=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k=1}"/> the unique solution is a bit smaller: 	</p>
<p align="center"><img alt="\displaystyle  1 + 2 = 3." class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++1+%2B+2+%3D+3.&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  1 + 2 = 3."/></p>
<p>
</p><p/><h2> The Result </h2><p/>
<p/><p>
Yes, it is about the solution to a natural family of Diophantine equations. This result of Moser comes from an old paper of his. The result can be found on the wonderful blog called <a href="https://www.cut-the-knot.org/arithmetic/algebra/TwoParameterFermat.shtml">cut-the-knot</a> written by Alexander Bogomolny.</p>
<p>
The question considered by Moser is simple to state: </p>
<blockquote><p><b> </b> <em> Consider the equation over the integers <img alt="{x^{a} + y^{b} = z^{c}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%5E%7Ba%7D+%2B+y%5E%7Bb%7D+%3D+z%5E%7Bc%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{x^{a} + y^{b} = z^{c}}"/> where <img alt="{a, b, c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%2C+b%2C+c%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{a, b, c}"/> are fixed values that are relatively prime. Show that there are infinitely many integer solutions. </em>
</p></blockquote>
<p/><p>
The surprise, to me, is that this equation always has integer solutions. I thought about it for a bit and had no idea how to even start.</p>
<p>
The solution is as follows. The initial insight is that the restriction on the exponents implies that there are integers <img alt="{m, n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%2C+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m, n}"/> so that <img alt="{abm + 1 = cn}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Babm+%2B+1+%3D+cn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{abm + 1 = cn}"/>. </p>
<p>
Wait a minute. We must be careful by what we mean by “the values of <img alt="{a,b,c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%2Cb%2Cc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a,b,c}"/> are relatively prime.” We need more than the greatest common divisor (GCD) of <img alt="{a,b,c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%2Cb%2Cc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a,b,c}"/> is <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>. We need that <img alt="{ab}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bab%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ab}"/> and <img alt="{c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c}"/> are relatively prime. Note that <img alt="{6,10,15}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B6%2C10%2C15%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{6,10,15}"/> have GCD equal to <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/> but no matter which of the triple is “<img alt="{c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c}"/>” we cannot find the needed <img alt="{m,n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%2Cn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m,n}"/>: 	</p>
<p align="center"><img alt="\displaystyle  (6\cdot 10,15) &gt; 1, (10\cdot 15, 6)&gt;1, (15,6 \cdot 10) &gt; 1. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%286%5Ccdot+10%2C15%29+%3E+1%2C+%2810%5Ccdot+15%2C+6%29%3E1%2C+%2815%2C6+%5Ccdot+10%29+%3E+1.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  (6\cdot 10,15) &gt; 1, (10\cdot 15, 6)&gt;1, (15,6 \cdot 10) &gt; 1. "/></p>
<p>I thank Subrahmanyam Kalyanasundaram for catching this.</p>
<p>
The next idea is not to look for a single set of solutions but rather to find a parametrized solution. That is try to find expressions for <img alt="{x,y,z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%2Cy%2Cz%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x,y,z}"/> that depend on some variables <img alt="{u,v}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu%2Cv%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u,v}"/> so that for all <img alt="{u,v}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu%2Cv%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u,v}"/> the equation is satisfied. </p>
<p>
Then set 	</p>
<p align="center"><img alt="\displaystyle  x = u^{bm}(u^{abm} + v^{abm})^{bm}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++x+%3D+u%5E%7Bbm%7D%28u%5E%7Babm%7D+%2B+v%5E%7Babm%7D%29%5E%7Bbm%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  x = u^{bm}(u^{abm} + v^{abm})^{bm}. "/></p>
<p align="center"><img alt="\displaystyle  y = v^{am}(u^{abm} + v^{abm})^{am}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++y+%3D+v%5E%7Bam%7D%28u%5E%7Babm%7D+%2B+v%5E%7Babm%7D%29%5E%7Bam%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  y = v^{am}(u^{abm} + v^{abm})^{am}. "/></p>
<p>Note as <img alt="{u,v}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu%2Cv%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u,v}"/> vary over integers the values of <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> and <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y}"/> vary over integers too. The claim is that this is a parameterization of the equation. Let’s see why. We need to figure out what <img alt="{x^{a} + y^{b}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%5E%7Ba%7D+%2B+y%5E%7Bb%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x^{a} + y^{b}}"/> is equal to. It looks a bit nasty but it is not. Let <img alt="{W = u^{abm} + v^{abm}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BW+%3D+u%5E%7Babm%7D+%2B+v%5E%7Babm%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{W = u^{abm} + v^{abm}}"/>. Then 	</p>
<p align="center"><img alt="\displaystyle  x = u^{bm}W^{bm}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++x+%3D+u%5E%7Bbm%7DW%5E%7Bbm%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  x = u^{bm}W^{bm}. "/></p>
<p align="center"><img alt="\displaystyle  y = v^{am}W^{am}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++y+%3D+v%5E%7Bam%7DW%5E%7Bam%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  y = v^{am}W^{am}. "/></p>
<p>So <img alt="{x^{a} + y^{b} }" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%5E%7Ba%7D+%2B+y%5E%7Bb%7D+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x^{a} + y^{b} }"/> is 	</p>
<p align="center"><img alt="\displaystyle  u^{abm} W^{abm} + v^{abm}W^{abm}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++u%5E%7Babm%7D+W%5E%7Babm%7D+%2B+v%5E%7Babm%7DW%5E%7Babm%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  u^{abm} W^{abm} + v^{abm}W^{abm}. "/></p>
<p>Which magically is 	</p>
<p align="center"><img alt="\displaystyle  W^{abm}(u^{abm} + v^{abm}) = W^{abm+1}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++W%5E%7Babm%7D%28u%5E%7Babm%7D+%2B+v%5E%7Babm%7D%29+%3D+W%5E%7Babm%2B1%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  W^{abm}(u^{abm} + v^{abm}) = W^{abm+1}. "/></p>
<p>Thus setting 	</p>
<p align="center"><img alt="\displaystyle  z = W^{n} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++z+%3D+W%5E%7Bn%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  z = W^{n} "/></p>
<p>implies that 	</p>
<p align="center"><img alt="\displaystyle  x^{a} + y^{b} = W^{abm+1} = W^{cn} = (W^{n})^{c} = z^{c}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++x%5E%7Ba%7D+%2B+y%5E%7Bb%7D+%3D+W%5E%7Babm%2B1%7D+%3D+W%5E%7Bcn%7D+%3D+%28W%5E%7Bn%7D%29%5E%7Bc%7D+%3D+z%5E%7Bc%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  x^{a} + y^{b} = W^{abm+1} = W^{cn} = (W^{n})^{c} = z^{c}. "/></p>
<p>Very neat. By the way we do need to note that as <img alt="{u}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u}"/> and <img alt="{v}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bv%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{v}"/> run through integers the values of <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> and <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y}"/> and <img alt="{z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bz%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{z}"/> vary enough to get an infinite number of solutions. A simple growth argument shows that this is true.</p>
<p>
The key trick was to <b>not</b> use a standard idea and apply the binomial theorem and expand 	</p>
<p align="center"><img alt="\displaystyle  (u^{abm} + v^{abm})^{bm}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%28u%5E%7Babm%7D+%2B+v%5E%7Babm%7D%29%5E%7Bbm%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  (u^{abm} + v^{abm})^{bm}. "/></p>
<p>My algebra DNA suggests that expanding such an expression is often a good idea. Here it would lead to a mess. This is a case where using the binomial expansion does not work.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
I really like Moser’s clever solution to the diophantine equation 	</p>
<p align="center"><img alt="\displaystyle  x^{a} + y^{b} = z^{c}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++x%5E%7Ba%7D+%2B+y%5E%7Bb%7D+%3D+z%5E%7Bc%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  x^{a} + y^{b} = z^{c}. "/></p>
<p>Note that it must fail when <img alt="{a=b=c=p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%3Db%3Dc%3Dp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a=b=c=p}"/> for <img alt="{p&gt;2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%3E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p&gt;2}"/> by the famous solution to the original Fermat equation. </p></font></font></div>
    </content>
    <updated>2019-02-06T12:57:11Z</updated>
    <published>2019-02-06T12:57:11Z</published>
    <category term="Oldies"/>
    <category term="Open Problems"/>
    <category term="People"/>
    <category term="Proofs"/>
    <category term="Diophantine"/>
    <category term="Fermat"/>
    <category term="worm problem"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-02-11T18:20:40Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>http://corner.mimuw.edu.pl/?p=1062</id>
    <link href="http://corner.mimuw.edu.pl/?p=1062" rel="alternate" type="text/html"/>
    <title>HALG 2019 - Call For Submissions of Short Contributed Presentations</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">The HALG 2019 conference seeks submissions for contributed presentations. Each presentation is expected to consist of a poster and a short talk (an invitation to the poster). There will be no conference proceedings, hence presenting work already published at a … <a href="http://corner.mimuw.edu.pl/?p=1062">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The HALG 2019 conference seeks submissions for contributed presentations. Each presentation is expected to consist of a poster and a short talk (an invitation to the poster). There will be no conference proceedings, hence presenting work already published at a different venue or journal (or to be submitted there) is welcome.</p>
<p>If you would like to present your results at HALG 2019, please submit their details the abstract of the talk or the contribution of the poster via EasyChair: <a href="https://easychair.org/conferences/?conf=halg2019" rel="noopener noreferrer" target="_blank">https://easychair.org/conferences/?conf=halg2019</a></p>
<p>The abstract should include (when relevant) information where the results have been published/accepted (e.g., conference), and where they are publicly available (e.g., arXiv). All submissions will be reviewed by the program committee, giving priority to new work not formally published yet, and to papers published in 2018 or later.</p>
<p>Submissions deadline: March 15th, 2019.<br/>
Late submissions will be accepted subject to space constraints.</p></div>
    </content>
    <updated>2019-02-06T11:41:10Z</updated>
    <published>2019-02-06T11:41:10Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>sank</name>
    </author>
    <source>
      <id>http://corner.mimuw.edu.pl</id>
      <link href="http://corner.mimuw.edu.pl/?feed=rss2" rel="self" type="application/atom+xml"/>
      <link href="http://corner.mimuw.edu.pl" rel="alternate" type="text/html"/>
      <subtitle>University of Warsaw</subtitle>
      <title>Banach's Algorithmic Corner</title>
      <updated>2019-02-10T23:35:34Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=92</id>
    <link href="https://gilkalai.wordpress.com/2019/02/05/extremal-combinatorics-v-posets/" rel="alternate" type="text/html"/>
    <title>Extremal Combinatorics V: POSETS</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">This is the remaining post V on partially ordered sets of my series on extremal combinatorics (I,II,III,IV,VI).  We will talk here about POSETS – partially ordered sets. The study of order is very important in many areas of mathematics starting … <a href="https://gilkalai.wordpress.com/2019/02/05/extremal-combinatorics-v-posets/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><em>This is the remaining post V on partially ordered sets of my series on extremal combinatorics (<a href="https://gilkalai.wordpress.com/2008/05/01/extremal-combinatorics-i/">I</a>,<a href="https://gilkalai.wordpress.com/2008/07/17/extermal-combinatorics-ii-some-geometry-and-number-theory/">II</a>,<a href="https://gilkalai.wordpress.com/2008/09/28/extremal-combinatorics-iii-some-basic-theorems/">III</a>,<a href="https://gilkalai.wordpress.com/2008/10/06/extremal-combinatorics-iv-shifting/">IV</a>,<a href="https://gilkalai.wordpress.com/2009/05/21/extremal-combinatorics-vi-the-frankl-wilson-theorem/">VI</a>). </em></p>
<p>We will talk here about POSETS – partially ordered sets. The study of order is very important in many areas of mathematics starting with the order relation on the integers and reals in algebra and in Euclidean geometry. The set of all subsets of a set can be partially ordered by inclusion and this is a very basic example of posets. While the study of order and posets is a separate area on its own, parts of it are very important in extremal combinatorics and we will give a little taste here.</p>
<p style="text-align: center;"><span style="color: #0000ff;"><strong>Dear readers, please contribute your favorite result or problem on partially ordered sets (or Sorting) in the comment session.</strong></span></p>
<p>A chain <img alt="C \subset P" class="latex" src="https://s0.wp.com/latex.php?latex=C+%5Csubset+P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C \subset P"/> in a POSET is a set of elements so that every two of them are comparable. An antichain $A \subset P$ is a set of elements so that every two distinct elemenאs in <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> are incomparable.  (Antichains are also called independent sets.) An immediate but important Lemma is:</p>
<p><strong>The immediate lemma:</strong> The intersection of a chain <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> and an antichain <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/> contains at most one element. <strong><span style="color: #993366;">Walla!</span></strong></p>
<h3>Dilworth’s theorem</h3>
<p>Dilworth’s theorem (DT): Every finite partially ordered <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> set can be covered by <img alt="a(P)" class="latex" src="https://s0.wp.com/latex.php?latex=a%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a(P)"/> chains.</p>
<p>(By the immediate lemma, at least <img alt="a(P)" class="latex" src="https://s0.wp.com/latex.php?latex=a%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a(P)"/> chains are needed.)</p>
<p>Dual Dilworth theorem: Every partially ordered sets can be covered by <img alt="c(P)" class="latex" src="https://s0.wp.com/latex.php?latex=c%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c(P)"/> antichains.</p>
<p>(By the immediate lemma, at least <img alt="c(P)" class="latex" src="https://s0.wp.com/latex.php?latex=c%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c(P)"/> antichains are needed.)</p>
<p>The proof of the dual Dilworth theorem is easy. Note that the set <img alt="A_1=MIN(P)" class="latex" src="https://s0.wp.com/latex.php?latex=A_1%3DMIN%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_1=MIN(P)"/> of minimal elements of <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> is an antichain. Let <img alt="A_k = MIN (P\backslash (A_1 \cup A_2 \cup \dots A_{k-1}))" class="latex" src="https://s0.wp.com/latex.php?latex=A_k+%3D+MIN+%28P%5Cbackslash+%28A_1+%5Ccup+A_2+%5Ccup+%5Cdots+A_%7Bk-1%7D%29%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_k = MIN (P\backslash (A_1 \cup A_2 \cup \dots A_{k-1}))"/>. We need two easy observations. First, <img alt="A_k is an antichain" class="latex" src="https://s0.wp.com/latex.php?latex=A_k+is+an+antichain&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_k is an antichain"/> and second: If <img alt="A_k \ne \emptyset" class="latex" src="https://s0.wp.com/latex.php?latex=A_k+%5Cne+%5Cemptyset&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_k \ne \emptyset"/> then there is a chain with one element from <img alt="A_i: 1 \le i\le k" class="latex" src="https://s0.wp.com/latex.php?latex=A_i%3A+1+%5Cle+i%5Cle+k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_i: 1 \le i\le k"/>. <strong><span style="color: #0000ff;">Walla!</span></strong></p>
<p>The proof of Dilworth’s theorem is by induction on $|P|$. For the induction step you first consider the case where every antichain of maximal size is either <img alt="MAX(P)" class="latex" src="https://s0.wp.com/latex.php?latex=MAX%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="MAX(P)"/> or <img alt="MIN (P)" class="latex" src="https://s0.wp.com/latex.php?latex=MIN+%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="MIN (P)"/>. In this case you consider a chain with one element in <img alt="MAX(P)" class="latex" src="https://s0.wp.com/latex.php?latex=MAX%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="MAX(P)"/> and one element in <img alt="MIN (P)" class="latex" src="https://s0.wp.com/latex.php?latex=MIN+%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="MIN (P)"/> and delete these elements from <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/>. For the resulting post <img alt="Q" class="latex" src="https://s0.wp.com/latex.php?latex=Q&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Q"/>, <img alt="a(Q)=a(P)-1" class="latex" src="https://s0.wp.com/latex.php?latex=a%28Q%29%3Da%28P%29-1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a(Q)=a(P)-1"/> and we can use the induction hypothesis.</p>
<p>Otherwise there is an antichain <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> of maximum size <img alt="t=a(P)" class="latex" src="https://s0.wp.com/latex.php?latex=t%3Da%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t=a(P)"/> which is not <em>MAX(P)</em> or <em>MIN(P)</em>.  Put <img alt="A=\{a_1,a_2,\dots,a_t\}" class="latex" src="https://s0.wp.com/latex.php?latex=A%3D%5C%7Ba_1%2Ca_2%2C%5Cdots%2Ca_t%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A=\{a_1,a_2,\dots,a_t\}"/>. Let <img alt="P^+" class="latex" src="https://s0.wp.com/latex.php?latex=P%5E%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P^+"/> be the set of elements in <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> which are larger or equal some element in <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/>, and let <img alt="P^-" class="latex" src="https://s0.wp.com/latex.php?latex=P%5E-&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P^-"/> be the set of elements in <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> which are smaller or equal some element in <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/>.</p>
<p>Now,</p>
<ol>
<li><img alt="P^+ \cup P^-=P" class="latex" src="https://s0.wp.com/latex.php?latex=P%5E%2B+%5Ccup+P%5E-%3DP&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P^+ \cup P^-=P"/>. Otherwise we could add an element to <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> to form a larger antichain.</li>
<li><img alt="P^+ \cap P^- = A" class="latex" src="https://s0.wp.com/latex.php?latex=P%5E%2B+%5Ccap+P%5E-+%3D+A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P^+ \cap P^- = A"/>. Otherwise, there will be two elements of <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> which are comparable.</li>
</ol>
<p>So by the induction hypothesis <img alt="P^+" class="latex" src="https://s0.wp.com/latex.php?latex=P%5E%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P^+"/> can be covered by <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t"/> chains <img alt="C_1^+, C_2^+, \dots, C_t^+" class="latex" src="https://s0.wp.com/latex.php?latex=C_1%5E%2B%2C+C_2%5E%2B%2C+%5Cdots%2C+C_t%5E%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_1^+, C_2^+, \dots, C_t^+"/> and <img alt="P^-" class="latex" src="https://s0.wp.com/latex.php?latex=P%5E-&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P^-"/> can be covered by <img alt="a(P" class="latex" src="https://s0.wp.com/latex.php?latex=a%28P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a(P"/>$ chains <img alt="C_1^-, C_2^-, \dots, C_t^-" class="latex" src="https://s0.wp.com/latex.php?latex=C_1%5E-%2C+C_2%5E-%2C+%5Cdots%2C+C_t%5E-&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_1^-, C_2^-, \dots, C_t^-"/>. Bu re-indexing we can assume that both <img alt="C_i^+" class="latex" src="https://s0.wp.com/latex.php?latex=C_i%5E%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_i^+"/> and <img alt="C_i^-" class="latex" src="https://s0.wp.com/latex.php?latex=C_i%5E-&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_i^-"/> contains <img alt="a_i" class="latex" src="https://s0.wp.com/latex.php?latex=a_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_i"/>. It follows that <img alt="a_i" class="latex" src="https://s0.wp.com/latex.php?latex=a_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_i"/> is the minimal element in $C_i^+$ and the maximal element in $C_i^-$ and hence <img alt="C_i=:C_i^+ \cup C_i^-" class="latex" src="https://s0.wp.com/latex.php?latex=C_i%3D%3AC_i%5E%2B+%5Ccup+C_i%5E-&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_i=:C_i^+ \cup C_i^-"/> is a chain. The <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t"/> chains <img alt="C_1, C_2, \dots, C_t" class="latex" src="https://s0.wp.com/latex.php?latex=C_1%2C+C_2%2C+%5Cdots%2C+C_t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_1, C_2, \dots, C_t"/> cover <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/>. <span style="color: #993366;"><strong>Sababa!</strong></span></p>
<p>An <strong>important Corollary</strong> both from Dilworth’s theorem and its dual is that</p>
<p style="text-align: center;"><img alt="a(P) c(P) \ge |P|." class="latex" src="https://s0.wp.com/latex.php?latex=a%28P%29+c%28P%29+%5Cge+%7CP%7C.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a(P) c(P) \ge |P|."/></p>
<h3>Erdos-Szekeres theorem</h3>
<p>The fundamental Erdos Szekeres theorem asserts that if <img alt="n=ab+1" class="latex" src="https://s0.wp.com/latex.php?latex=n%3Dab%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n=ab+1"/> then every sequence <img alt="a_1,a_2,\dots ,a_n" class="latex" src="https://s0.wp.com/latex.php?latex=a_1%2Ca_2%2C%5Cdots+%2Ca_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_1,a_2,\dots ,a_n"/> of different real numbers contains a monotone increasing sequence of length <img alt="a+1" class="latex" src="https://s0.wp.com/latex.php?latex=a%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a+1"/> or a monotone decreasing sequence of length <img alt="b+1" class="latex" src="https://s0.wp.com/latex.php?latex=b%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="b+1"/>.</p>
<p>There are simple proofs. For example, associate to every <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/> a pair <img alt="(I_k,D_k)" class="latex" src="https://s0.wp.com/latex.php?latex=%28I_k%2CD_k%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(I_k,D_k)"/> of integers where  <img alt="I_k" class="latex" src="https://s0.wp.com/latex.php?latex=I_k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="I_k"/> is the maximum length of the increasing subsequence starting with <img alt="a_k" class="latex" src="https://s0.wp.com/latex.php?latex=a_k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_k"/> and <img alt="D_k" class="latex" src="https://s0.wp.com/latex.php?latex=D_k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D_k"/> is the maximum length of the deccreasing subsequence starting with <img alt="a_k" class="latex" src="https://s0.wp.com/latex.php?latex=a_k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_k"/>. The result follows from the easy observation that all these pairs are different.</p>
<p>Both Dilworth’ theorem and its easy dual imply easily (in fact we need only the important corollary) the Erdos Szekeres theorem when we define the following partial order: <img alt="i &lt; k" class="latex" src="https://s0.wp.com/latex.php?latex=i+%3C+k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i &lt; k"/> if both <img alt="i&lt;k" class="latex" src="https://s0.wp.com/latex.php?latex=i%3Ck&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i&lt;k"/> and <img alt="a_i &lt; a_k" class="latex" src="https://s0.wp.com/latex.php?latex=a_i+%3C+a_k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_i &lt; a_k"/>.</p>
<h3>Looking at Sperner’s theorem again</h3>
<p>Sperner’s theorem asserts that the maximal size of an antichain of subsets of an <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> elements set is <img alt="{{n} \choose {[n/2]}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7Bn%7D+%5Cchoose+%7B%5Bn%2F2%5D%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{{n} \choose {[n/2]}}"/>. By Dilworth’s theorem it follows that we can cover all sets by <img alt="{{n} \choose {[n/2]}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7Bn%7D+%5Cchoose+%7B%5Bn%2F2%5D%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{{n} \choose {[n/2]}}"/> chains (and, of course when we exhibit such a covering it reproves Sperner’s theorem). A symmetric saturated chain decomposition is a partition of <img alt="P(n)" class="latex" src="https://s0.wp.com/latex.php?latex=P%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P(n)"/> (=all subsets of <img alt="[n]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Bn%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="[n]"/>) to saturated chains where each chain has, for some <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>, sets of sizes $k,k+1,\dots,d-k$. You can build such a decomposition inductively.</p>
<p>Start with a decomposition for <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> for each chain <img alt="C_i" class="latex" src="https://s0.wp.com/latex.php?latex=C_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_i"/> create a new chain <img alt="C'_i" class="latex" src="https://s0.wp.com/latex.php?latex=C%27_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C'_i"/> by adding the element <img alt="n+1" class="latex" src="https://s0.wp.com/latex.php?latex=n%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n+1"/> to every set. And then move the top set in <img alt="C'_i" class="latex" src="https://s0.wp.com/latex.php?latex=C%27_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C'_i"/> to <img alt="C_i" class="latex" src="https://s0.wp.com/latex.php?latex=C_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_i"/>.  <strong>Walla!</strong></p>
<p>This is the beginning of a very beautiful story related also to the Dedekind Problem about  number of antichains in <img alt="P(n)" class="latex" src="https://s0.wp.com/latex.php?latex=P%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P(n)"/>.</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/02/untitledgreene-kleitman2.png"><img alt="" class="alignnone size-full wp-image-16834" height="489" src="https://gilkalai.files.wordpress.com/2019/02/untitledgreene-kleitman2.png?w=640&amp;h=489" width="640"/></a></p>
<p><strong><span style="color: #ff0000;">Curtis Greene and Danny Kleitman</span></strong></p>
<h3>The Greene-Kleitman theorem</h3>
<p>Let <img alt="a_k(P)" class="latex" src="https://s0.wp.com/latex.php?latex=a_k%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_k(P)"/> be the maximum size of the union <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X"/> of <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/> antichains in a poset <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/>. For every chain For every chain <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/> we have <img alt="|C \cap X| \le \min\{|C|,k\}" class="latex" src="https://s0.wp.com/latex.php?latex=%7CC+%5Ccap+X%7C+%5Cle+%5Cmin%5C%7B%7CC%7C%2Ck%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|C \cap X| \le \min\{|C|,k\}"/>. Therefore for a partition of <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> to chains <img alt="C_1,C_2,\dots,C_t" class="latex" src="https://s0.wp.com/latex.php?latex=C_1%2CC_2%2C%5Cdots%2CC_t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_1,C_2,\dots,C_t"/> we   have <img alt="\sum\min\{|C_i|,k\ge |X|" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csum%5Cmin%5C%7B%7CC_i%7C%2Ck%5Cge+%7CX%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sum\min\{|C_i|,k\ge |X|"/>. The <a href="https://www.encyclopediaofmath.org/index.php/Greene-Kleitman_theorem">Greene-Kleitman theorem</a> asserts that there is always  a decomposition into chains with <img alt="\sum\min\{|C_i|,k\}=a_k(P)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csum%5Cmin%5C%7B%7CC_i%7C%2Ck%5C%7D%3Da_k%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sum\min\{|C_i|,k\}=a_k(P)"/>.</p>
<h3>The perfect graph theorem.</h3>
<p>What is the relation between the very easy dual Dilworth theorem and the harder Dilworth theorem? As it turns out there is a very general theorem, Lovasz’ perfect graph theorem, that shows that these two theorems are equivalent.</p>
<p>A graph G is perfect if for every induced subgraph H, the chromatic number equals the clique number. Lovasz’ theorem  (conjectured by Claude Berge) asserts that complements of perfect graphs are perfect. The perfectness of the comparability graph of a poset amounts to the dual Dilworth theorem, and for its complement it is the Dilworth theorem. Lovasz in fact proved that perfectness is equivalent to the relation $\latex \omega(H)\cdot \alpha (H) \ge |H|$ for every induced subgraph H. (For posets this is our important corollary above.)</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/02/kahn-linial-saks.png"><img alt="" class="alignnone size-full wp-image-16832" height="239" src="https://gilkalai.files.wordpress.com/2019/02/kahn-linial-saks.png?w=640&amp;h=239" width="640"/></a></p>
<p><strong><span style="color: #ff0000;">Jeff Kahn and Jake Baron </span></strong><span style="color: #ff0000;">(</span><span style="color: #ff0000;"><a href="http://archive.dimacs.rutgers.edu/DIMACS_highlights/tuza/tuza.html">see here on their 2016 asymptotic solution to Tusza’s conjecture</a></span><span style="color: #ff0000;">),</span><strong><span style="color: #ff0000;"> Mike Saks, and Nati Linial</span></strong></p>
<h3>Startling theorems on POSETS: Kahn-Saks,  Linial-Saks, Linial-Kahn, and Kahn-Saks</h3>
<p>Here  are some beautiful and important theorems on posets. An order ideas <img alt="I" class="latex" src="https://s0.wp.com/latex.php?latex=I&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="I"/> of a post is a set of elements so that if <img alt="x in I" class="latex" src="https://s0.wp.com/latex.php?latex=x+in+I&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x in I"/> and <img alt="y &lt; x" class="latex" src="https://s0.wp.com/latex.php?latex=y+%3C+x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y &lt; x"/> then <img alt="y \in I" class="latex" src="https://s0.wp.com/latex.php?latex=y+%5Cin+I&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y \in I"/>.</p>
<p><strong>Theorem (Linial-Saks, 1985):</strong> In every poset <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> there is an element which is contained in more than δ and less than 1-δ order ideas of <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/>.  (<a href="http://www.cs.huji.ac.il/~nati/PAPERS/central_element.pdf">Paper</a>)</p>
<p><strong>Theorem (Kahn-Saks, 1984):</strong> For every Poset <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> which is not a chain there are two incomparable elements <img alt="x,y" class="latex" src="https://s0.wp.com/latex.php?latex=x%2Cy&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x,y"/> such that the number of linear extensions of <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> for which <img alt="x&lt;y" class="latex" src="https://s0.wp.com/latex.php?latex=x%3Cy&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x&lt;y"/> is between 3/11 and 8/11. (<a href="https://link.springer.com/article/10.1007/BF00565647">Paper</a>)</p>
<p>A <a href="http://www.cs.huji.ac.il/~nati/PAPERS/brunn_minkowski.pdf">simpler proof</a> was found in the late 80s by Kahn and Linial and by Karzanov and Khachiyan. It  is  based on the Brunn Minkowski theorem and gives a weaker constant <img alt="1/2e" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F2e&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/2e"/> .</p>
<p><strong>Theorem (Kahn-Saks, 1987)</strong>: For every finite distributive lattice <img alt="L" class="latex" src="https://s0.wp.com/latex.php?latex=L&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="L"/> the maximum antichain is of size <img alt="o(|L|)" class="latex" src="https://s0.wp.com/latex.php?latex=o%28%7CL%7C%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="o(|L|)"/>. (<a href="https://core.ac.uk/download/pdf/82629369.pdf">Paper</a>)</p>
<p>Lattices are special types of posets with the property that for every set of elements (pairs <img alt="\{x,y\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7Bx%2Cy%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{x,y\}"/> suffice in the finite case), there is a unique minimal elements above them all (denoted for pairs by <i>x</i> ∧ <i>y</i>) and a unique maximal element (denoted for pairs by <i>x</i> ∨ <i>y</i>) below them all.</p>
<p>A <a href="https://en.wikipedia.org/wiki/Distributive_lattice">distributive lattice</a> is a lattice that satisfies for every <em>x, y</em> and <em>z</em>, the relation</p>
<p style="text-align: center;"><i>x</i> ∧ (<i>y</i> ∨ <i>z</i>) = (<i>x</i> ∧ <i>y</i>) ∨ (<i>x</i> ∧ <i>z</i>)</p>
<p>Birkhoff’s representation theorem asserts that finite distributive lattices can be represented as order ideals of posets (ordered by inclusion).</p>
<p> </p>
<p> </p></div>
    </content>
    <updated>2019-02-05T11:18:54Z</updated>
    <published>2019-02-05T11:18:54Z</published>
    <category term="Combinatorics"/>
    <category term="Claude Berge"/>
    <category term="Curtis Greene"/>
    <category term="Daniel Kleitman"/>
    <category term="Dilworth's theorem"/>
    <category term="Extremal combinatorics"/>
    <category term="Jeff Kahn"/>
    <category term="Laci Lovasz"/>
    <category term="Mike Saks"/>
    <category term="Nati Linial"/>
    <category term="Posets"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-02-11T18:20:36Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-27705661.post-8542550481798271953</id>
    <link href="http://processalgebra.blogspot.com/feeds/8542550481798271953/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=27705661&amp;postID=8542550481798271953" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/8542550481798271953" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/8542550481798271953" rel="self" type="application/atom+xml"/>
    <link href="http://processalgebra.blogspot.com/2019/02/two-awards-at-hicss19-for-csgssi.html" rel="alternate" type="text/html"/>
    <title>Two awards at HICSS’19 for CS@GSSI student Roberto Verdecchia</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div><div><a href="https://robertoverdecchia.github.io/" target="_blank">Roberto Verdecchia</a>, a third-year Ph.D. student of the Gran Sasso Science Institute (GSSI) and the Vrije Universiteit Amsterdam (VU) has received two distinct prizes at the 52nd Hawaii International Conference on System Sciences (HICSS’19;<span> </span><a href="http://hicss.hawaii.edu/" style="color: #1155cc;" target="_blank">http://hicss.hawaii.edu/</a>) for his research paper “<a href="https://robertoverdecchia.github.io/papers/HICSS_2019.pdf" style="color: #1155cc;" target="_blank">DecidArch: Playing Cards as Software Architects</a>”, which is <span style="font-family: Helvetica; font-size: 12px;">co-authored with</span><i style="font-family: Helvetica; font-size: 12px;"> </i>Patricia Lago, Jia F. Cai (both at VU Amsterdam), Remco C. de Boer (ArchiXL) and Philippe Kruchten (University of British Columbia). Out of over 780 papers presented at HICCS within 11 different research tracks, the study was presented with the “Best Paper award” of the Software Education and Training track. Additionally, the article was also selected as one of the five “ISSIP-IBM-CBA Student Paper Award for Best Industry Studies Paper” of HICCS’19.</div><div><br/>The study presents a novel educational game conceived to train students and practitioners in concepts related to software architecture and decision making. The game is currently used as an interactive session of the course “Software Architecture”, taught at the Vrije Universiteit Amsterdam.<br/><br/>The two prizes were adjudicated independently by two distinct committees.</div><div> </div><div>Congratulations to Roberto!</div><div><br/></div><div>Let me close by adding that I expect that Roberto will deliver his PhD thesis in the autumn 2019 and will soon be on the job market. If you have a postdoc or tenure-track  position in SE, keep him mind. </div></div></div>
    </content>
    <updated>2019-02-05T08:58:00Z</updated>
    <published>2019-02-05T08:58:00Z</published>
    <author>
      <name>Luca Aceto</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/01092671728833265127</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-27705661</id>
      <author>
        <name>Luca Aceto</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/01092671728833265127</uri>
      </author>
      <link href="http://processalgebra.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://processalgebra.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Papers I find interesting---mostly, but not solely, in Process Algebra---, and some fun stuff in Mathematics and Computer Science at large and on general issues related to research, teaching and academic life.</subtitle>
      <title>Process Algebra Diary</title>
      <updated>2019-02-05T08:58:47Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://lucatrevisan.wordpress.com/?p=4206</id>
    <link href="https://lucatrevisan.wordpress.com/2019/02/04/%e6%81%ad%e5%96%9c%e5%8f%91%e8%b4%a2-11/" rel="alternate" type="text/html"/>
    <title>恭喜发财!</title>
    <summary>新年快乐！ Advertisements</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><img alt="8cxnLMGdi" class="alignnone size-full wp-image-4207" src="https://lucatrevisan.files.wordpress.com/2019/02/8cxnlmgdi.png?w=584"/></p>
<p>新年快乐！</p></div>
    </content>
    <updated>2019-02-05T06:45:35Z</updated>
    <published>2019-02-05T06:45:35Z</published>
    <category term="&#x65B0;&#x5E74;"/>
    <author>
      <name>luca</name>
    </author>
    <source>
      <id>https://lucatrevisan.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://lucatrevisan.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://lucatrevisan.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://lucatrevisan.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://lucatrevisan.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>"Marge, I agree with you - in theory. In theory, communism works. In theory." -- Homer Simpson</subtitle>
      <title>in   theory</title>
      <updated>2019-02-11T18:20:09Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4122</id>
    <link href="https://www.scottaaronson.com/blog/?p=4122" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4122#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4122" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Sabineblogging</title>
    <summary xml:lang="en-US">I’ve of course been following the recent public debate about whether to build a circular collider to succeed the LHC—notably including Sabine Hossenfelder’s New York Times column arguing that we shouldn’t.  (See also the responses by Jeremy Bernstein and Lisa Randall, and the discussion on Peter Woit’s blog, and Daniel Harlow’s Facebook thread, and this Vox […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>I’ve of course been following the recent public debate about whether to build a circular collider to succeed the LHC—notably including <a href="https://www.nytimes.com/2019/01/23/opinion/particle-physics-large-hadron-collider.html">Sabine Hossenfelder’s <em>New York Times</em> column</a> arguing that we shouldn’t.  (See also the <a href="https://www.nytimes.com/2019/02/01/opinion/letters/physics-research-collider-cern.html">responses</a> by Jeremy Bernstein and Lisa Randall, and the <a href="http://www.math.columbia.edu/~woit/wordpress/?p=10768">discussion on Peter Woit’s blog</a>, and <a href="https://www.facebook.com/daniel.harlow.31/posts/10104284984149212">Daniel Harlow’s Facebook thread</a>, and <a href="https://www.vox.com/future-perfect/2019/1/22/18192281/cern-large-hadron-collider-future-circular-collider-physics">this <em>Vox</em> piece</a> by Kelsey Piper.)  Let me blog about this as a way of cracking my knuckles or tuning my violin, just getting back into blog-shape after a long hiatus for travel and family and the beginning of the semester.</p>
<p>Regardless of whether this opinion is widely shared among my colleagues, I like Sabine.  I’ve often found her <a href="http://backreaction.blogspot.com/">blogging</a> funny and insightful, and I wish more non-Lubos physicists would articulate their thoughts for the public the way she does, rather than just standing on the sidelines and criticizing the ones who do. I find it unfortunate that some of the replies to Sabine’s arguments dwelled on her competence and “standing” in physics (even if we set aside—as we should—Lubos’s misogynistic rants, whose predictability could be used to calibrate atomic clocks). It’s like this: if high-energy physics <em>had</em> reached a pathological state of building bigger and bigger colliders for no good reason, then we’d <em>expect</em> that it would take a semi-outsider to say so in public, so then it wouldn’t be a further surprise to find precisely such a person doing it.</p>
<p>Not for the first time, though, I find myself coming down on the opposite side as Sabine. Basically, <em>if</em> civilization could get its act together and find the money, I think it would be pretty awesome to build a new collider to push forward the energy frontier in our understanding of the universe.<br/><!--StartFragment--></p>


<p>Note that I’m not making the much stronger claim that this is the <em>best possible</em> use of $20 billion for science.  Plausibly a thousand $20-million projects could be found that would advance our understanding of reality by more than a new collider would.  But it’s also important to realize that that’s not the question at stake here.  When, for example, the US Congress cancelled the <a href="https://en.wikipedia.org/wiki/Superconducting_Super_Collider">Superconducting Supercollider</a> midway through construction—partly, it’s believed, on the basis of opposition from eminent physicists in other subfields, who argued that they could do equally important science for much cheaper—none of the SSC budget, as in 0% of it, ever <em>did</em> end up redirected to those other subfields.  In practice, then, the question of “whether a new collider is worth it” is probably best considered in absolute terms, rather than relative to other science projects.</p>



<p>What I found most puzzling, in Sabine’s writings on this subject, was the leap in logic from</p>



<ol><li>many theorists expected that superpartners, or other new particles besides the Higgs boson, had a good chance of being discovered at the LHC, based on statistical arguments about “natural” parameter values, and</li><li>the basic soundness of naturalness arguments was always open to doubt, and indeed the LHC results to date offer zero support for them, and</li><li>many of the same theorists now want an even bigger collider, and continue to expect new particles to be found, and haven’t sufficiently reckoned with their previous failed predictions, to …</li><li><strong>therefore</strong> we shouldn’t build the bigger collider.</li></ol>



<p>How do we get from 1-3 to 4: is the idea that we should <em>punish</em> the errant theorists, by withholding an experiment that they want, in order to deter future wrong predictions?  After step 3, it seems to me that Sabine could equally well have gone to: and therefore it’s all the more important that we <em>do</em> build a new collider, in order to establish all the more conclusively that there’s just an energy desert up there—and that I, Sabine, was right to emphasize that possibility, and those other theorists were wrong to downplay it!</p>



<p>Like, I gather that there are independently motivated scenarios where there <em>would</em> be only the Higgs at the LHC scale, and then new stuff at the next energy scale beyond it.  And as an unqualified outsider who enjoys talking to friends in particle physics and binge-reading about it, I’d find it hard to assign the totality of those scenarios less than ~20% credence or more than ~80%—certainly if the actual experts don’t either.</p>



<p>And crucially, it’s not as if <em>raising the collision energy</em> is just one arbitrary direction in which to look for new fundamental physics, among a hundred a-priori equally promising directions.  Basically, there’s raising the collision energy and then there’s everything else.  By raising the energy, you’re not testing one specific idea for physics beyond Standard Model, but a hundred or a thousand ideas in one swoop.</p>



<p>The situation reminds me a little of the quantum computing skeptics who say: scalable QC can never work, in practice and probably even in principle; the mainstream physics community only <em>thinks</em> it can work because of groupthink and hype; therefore, we shouldn’t waste more funds trying to make it work.  With the sole, very interesting exception of Gil Kalai, none of the skeptics ever seem to draw what strikes me as an equally logical conclusion: whoa, let’s go <em>full speed ahead</em> with trying to build a scalable QC, because there’s an epochal revolution in physics to be had here—once the experimenters finally see that I was right and the mainstream was wrong, and they start to unravel the reasons why!</p>



<p>Of course, $20 billion is a significant chunk of change, by the standards of science even if not by the standards of random government wastages (like our recent $11 billion shutdown).  And ultimately, decisions do need to be made about which experiments are most interesting to pursue with limited resources.  And if a future circular collider <em>were</em> built, and if it indeed just found a desert, I think the balance would tilt pretty strongly toward Sabine’s position—that is, toward declining to build an even bigger and more expensive collider after that.  If the Patriots drearily won every Superbowl 13-3, year after year after year, eventually no one would watch anymore and the Superbowl would get cancelled (well, maybe that will happen for other reasons…).</p>



<p>But it’s worth remembering that—correct me if I’m wrong—so far there have been <em>no</em> cases in the history of particle physics of massively expanding the energy frontier and finding absolutely nothing new there (i.e., nothing that at least conveyed multiple bits of information, as the Higgs mass did).  And while my opinion should count for less than a neutrino mass, just thinking it over a-priori, I keep coming back to the question: before we close the energy frontier for good, shouldn’t there have been at least <em>one</em> unmitigated null result, rather than zero?</p></div>
    </content>
    <updated>2019-02-04T12:30:47Z</updated>
    <published>2019-02-04T12:30:47Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Procrastination"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2019-02-04T15:45:24Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-9219479121065296157</id>
    <link href="https://blog.computationalcomplexity.org/feeds/9219479121065296157/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/02/dont-know-football-but-still-want-bet.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/9219479121065296157" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/9219479121065296157" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/02/dont-know-football-but-still-want-bet.html" rel="alternate" type="text/html"/>
    <title>Don't know Football but still want bet on the Superb Owl?</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div>
(Superb Owl is not a typo. I've heard (and it could be wrong) that the  NFL guards their copyright so you can't even say `Buy Beer here for the YOU KNOW WHATl' but instead `Buy Beer here for the big game''. Stephen Colbert a long time ago go around this by calling the game Superb Owl.)</div>
<div>
<br/></div>
<div>
<br/></div>
<div>
If I knew more about football  I might place a bet related to the Superb Owl. What kind of bets can I place?</div>
<div>
<br/></div>
<div>
1) Bet the point spread: Last time I looked the Patriots were a 2.5 point favorite. So either bet that Patriots will win by more than  2.5 or the Rams will lose by less than 2.5 or just win.</div>
<div>
<br/></div>
<div>
2) Over-Under: bet that either the total score will be over 56.5 or under it.</div>
<div>
<br/></div>
<div>
 There are prop-bets-- bets that are ABOUT the game but not related to the final score.</div>
<div>
<br/></div>
<div>
I've seen the following</div>
<div>
<br/></div>
<div>
1) Tom Brady will retire after the game. I wonder if Tom Brady (or a friend of his) could bet on this one knowing some inside information. Not i any state in America, but off-shore...</div>
<div>
<br/></div>
<div>
2) Jamie White will score the first touchdown.</div>
<div>
<br/></div>
<div>
3) Will Gladys Knight's   National Anthem go longer than 1 minute, 50 seconds (it was 1:47 seconds a few days ago but it shifted to 1:50).</div>
<div>
<br/></div>
<div>
Amazingly, this last one is what Josh Hermsmeyer (on Nate Silver's Webpage)  chose to focus on: <a href="https://fivethirtyeight.com/features/the-super-bowls-best-matchup-is-gladys-knight-vs-the-clock/">here</a>. Note that:</div>
<div>
<br/></div>
<div>
1) The people who picked 1 minute 50 seconds as the over-under probably didn't do much research. They might have set it to get the same number of people on both sides, which may explain the shift; however, I can't imagine this bet got that much action. Then again, I'm not that imaginative.</div>
<div>
<br/></div>
<div>
2) Josh DID. He did an  analysis of what is likely (he thinks it will go longer)</div>
<div>
<br/></div>
<div>
3) So- can Josh bet on this an clean up? Can you bet on this and clean up?</div>
<div>
<br/></div>
<div>
4) There is an issue: Some kinds of bets are legal in some places (betting who will WIN or beat a point-spread is legal in Las Vegas-- the Supreme court struck down a federal anti-betting rule). Some prop bets are legal. The Gladys Knight one is not.  Why not? Someone could have inside information! Gladys Knight would!</div>
<div>
<br/></div>
<div>
So you CAN bet  Rams+2.5 beats the Patriots LEGALLY</div>
<div>
<br/></div>
<div>
but to bet Gladys Knight's National Anthem will take more than 1 minute 50 seconds you might need to use  BITCOIN, and go to some offshore account. Too much sugar for a <a href="https://en.bitcoin.it/wiki/Satoshi_(unit)">satoshi</a>.</div>
<div>
<br/></div>
<div>
5) There is another issue- there is no such thing as a sure thing (I blogged on that <a href="https://blog.computationalcomplexity.org/2008/02/there-is-no-such-thing-as-sure-thing.html">here</a>). People who bet on sports for a living (I know one such person and will blog about that later) play THE LONG GAME. So to say</div>
<div>
<br/></div>
<div>
          <i> I will withdraw X dollars (for large X)  from my investments and bet it on </i></div>
<div>
<i>          Gladys Knight's</i><i>  Star Spangled Banner to go more than 1 minute 50 seconds</i></div>
<div>
<i>          because its a sure thing</i></div>
<div>
<br/></div>
<div>
Would be... a very bad idea.<br/>
<br/>
The above was all written the day before Superb Owl. Now its the next day and Gladys Knight has sung the National Anthem. So who won the Gladys Knight Bowl? The answer is not as straightforward as it could be, see <a href="https://www.usatoday.com/story/sports/nfl/super-bowl/2019/02/03/super-bowl-2019-gladys-knight-causes-prop-bet-controversy-anthem/2764778002/">here</a>.</div>
<div>
<br/></div></div>
    </content>
    <updated>2019-02-04T02:36:00Z</updated>
    <published>2019-02-04T02:36:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>https://plus.google.com/101693130490639305932</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-02-11T10:40:07Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/014</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/014" rel="alternate" type="text/html"/>
    <title>TR19-014 |  A New Proof of Nonsignalling Multiprover Parallel Repetition Theorem | 

	Himanshu Tyagi, 

	Shun Watanabe</title>
    <summary>We present an information theoretic proof of the nonsignalling multiprover parallel repetition theorem, a recent extension of its two-prover variant that underlies many hardness of approximation results. The original proofs used de Finetti type decomposition for strategies. We present a new proof that is based on a technique we introduced recently for proving strong converse results in multiuser information theory and entails a change of measure after replacing hard information constraints with soft ones.</summary>
    <updated>2019-02-03T12:39:00Z</updated>
    <published>2019-02-03T12:39:00Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-02-11T18:20:33Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=15616</id>
    <link href="https://rjlipton.wordpress.com/2019/02/03/a-strange-horizon/" rel="alternate" type="text/html"/>
    <title>A Strange Horizon</title>
    <summary>Data science of many things including citations Amazon India source Paul Allison is an emeritus professor of sociology at the University of Pennsylvania and the founder and president of the company Statistical Horizons. They provides short courses and seminars for statistical training. Today we have a short seminar on statistics and horizons of effectiveness. Our […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><font color="#0044cc"><br/>
<em>Data science of many things including citations</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2019/02/03/a-strange-horizon/allisonamazon/" rel="attachment wp-att-15619"><img alt="" class="alignright wp-image-15619" height="200" src="https://rjlipton.files.wordpress.com/2019/02/allisonamazon.jpg?w=133&amp;h=200" width="133"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Amazon India <a href="https://www.amazon.in/l/B001H6KWN6">source</a></font></td>
</tr>
</tbody>
</table>
<p>
Paul Allison is an emeritus professor of sociology at the University of Pennsylvania and the founder and president of the company <a href="https://statisticalhorizons.com/">Statistical Horizons</a>. They provides short courses and seminars for statistical training. </p>
<p>
Today we have a short seminar on statistics and horizons of effectiveness. <span id="more-15616"/></p>
<p>
Our first topic is about citations. Did we say citations? What are we in research more interested in than citations? Allison co-wrote a paper on a <a href="https://en.wikipedia.org/wiki/Lotka's_law">“law”</a> claimed by Alfred Lotka about how the number of citations behaves. Full details in a moment, but two upshots are: </p>
<ul>
<li>
Over half of the papers are contributed by a few highly prolific authors. <p/>
</li><li>
One-shot authors are roughly <img alt="{61\%}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B61%5C%25%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{61\%}"/> of the population but account for only a tiny proportion of the literature.
</li></ul>
<p>
</p><p/><h2> Allison’s Paper </h2><p/>
<p>Allison co-wrote his <a href="https://statisticalhorizons.com/wp-content/uploads/AllisonEtAl.SSS76.pdf">paper</a>, “Lotka’s Law: A Problem in Its Interpretation and Application,” with Derek de Solla Price, Belver Griffith, Michael Moravcsik, and John Stewart in 1976. Lotka’s law, which is related to George Zipf’s famous <a href="https://en.wikipedia.org/wiki/Zipf's_law">law</a>, alleges that over any time period in any scientific or literary field, the number <img alt="{a(n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a(n)}"/> of authors with <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> contributions obeys </p>
<p align="center"><img alt="\displaystyle  a(n) = \frac{C}{n^2}, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++a%28n%29+%3D+%5Cfrac%7BC%7D%7Bn%5E2%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  a(n) = \frac{C}{n^2}, "/></p>
<p>where <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> is independent of <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>. This suggests a maximum of <img alt="{n_{max} = \sqrt{C}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn_%7Bmax%7D+%3D+%5Csqrt%7BC%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n_{max} = \sqrt{C}}"/> on the range of <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>, since higher <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> give <img alt="{a(n) &lt; 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%28n%29+%3C+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a(n) &lt; 1}"/>, but there is also a probabilistic interpretation: The law says that the total number of papers at <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> is <img alt="{C/n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%2Fn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C/n}"/>, and that gives a positive constant expectation even when <img alt="{n_{max}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn_%7Bmax%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n_{max}}"/> varies as <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/>. Both cases yield that out of the total number <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> of papers, which has <img alt="{T = \Theta(C\log(C))}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT+%3D+%5CTheta%28C%5Clog%28C%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T = \Theta(C\log(C))}"/>, over half of them are contributed by a vanishing percentage of highly prolific authors. Meanwhile, one-shot authors are roughly <img alt="{6/\pi^2 \approx 61\%}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B6%2F%5Cpi%5E2+%5Capprox+61%5C%25%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{6/\pi^2 \approx 61\%}"/> of the population but account for only a <img alt="{1/\log(T)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%2F%5Clog%28T%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1/\log(T)}"/> proportion of the literature.</p>
<p>
However, the paper also remarks on a third case, namely making <img alt="{n_{max}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn_%7Bmax%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n_{max}}"/> a fixed constant—since human time is finite in any field. This puts a sharper <em>horizon</em> on Lotka’s Law and changes the inferences made as the horizon is approached. The paper shows how the <img alt="{n_{max}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn_%7Bmax%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n_{max}}"/> factor intrudes on other inferences they would like to draw, even between the former two cases. And never mind <a href="http://www.revistadestatistica.ro/index.php/the-power-of-lotkas-law-through-the-eyes-of-r/">more</a>–<a href="https://rjlipton.wordpress.com/feed/www.fosareh.net/fa/files/pdf/Osareh-mostafavi-collnet[1].doc">recent</a> <a href="http://www.collnet.de/Berlin-2008/LarsenWIS2008llc.pdf">evidence</a> of <a href="http://www.librarywaves.com/index.php/lw/article/download/51/45/">breakdowns</a> in Lotka’s law. </p>
<p>
</p><p/><h2> Horizons </h2><p/>
<p/><p>
We have mentioned de Solla Price <a href="https://rjlipton.wordpress.com/2012/09/29/why-we-lose-sleep-some-nights/">before</a> in regard to his founding <a href="https://en.wikipedia.org/wiki/Scientometrics">scientometrics</a>. In practice this is mainly concerned with citation analysis and other productivity metrics, but its widely-quoted definition, “the science of measuring and analyzing science,” strikes us as broader. We feel there should be a component for measuring limitations of the effectiveness of the science one is practicing.</p>
<p>
Now of course in statistics there are longstanding measures of statistical <a href="https://en.wikipedia.org/wiki/Power_(statistics)">power</a> and experiment acuity and of <em>noise</em> in general. Nevertheless, the cascading “(non-)reproducibility crisis” argues that more needs to be addressed. The development of software tools to counter “<a href="https://en.wikipedia.org/wiki/Data_dredging">p-hacking</a>” exemplifies a new layer of scientific modeling to do so—which could be called introspective modeling. </p>
<p>
I will exemplify with two “horizons” that are apparent in my own statistical chess research. One involves estimating the Elo rating of “perfect play.” The other involves the level of skill at which my data may cease to be effective. The former has captured popular imagination—it was among the first questions posed to me by Judit Polgar in a broadcast during the 2016 world championship match—but the latter is my concern in practice. We will see that these may be the same horizon, approached either by looking down from the stars or up from the road. </p>
<p>
I am not the first to do this kind of work or face the issue of its resolving power. Matej Guid, Artiz Perez, and Ivan Bratko made it the sole topic of a 2008 followup <a href="https://pdfs.semanticscholar.org/fcdc/9fb1e88c40de12ad9481f0d580f803bc1582.pdf">paper</a> to their 2006 <a href="https://en.chessbase.com/news/2006/world_champions2006.pdf">study</a> of all games in world championship matches. But their indicators strike me as weak. Most simply, they do not try to estimate where their horizon <em>is</em>, just argue that their results are not wholly beyond it. We will try to do more—but speculatively. The first step is rock-solid—it is a big surprise I found last month.</p>
<p>
</p><p/><h2> More Data, More Resolution </h2><p/>
<p/><p>
I use strong chess programs to take two main kinds of data. My full model uses programs in an analysis mode that evaluates all available moves to the same degree of thoroughness and takes roughly 4–6 hours per game. My quicker “screening” tests use programs in their normal playing mode, which gives full shrift only to what’s considered the best move, but shaves the time down to 10–15 minutes. For my AAAI 2011 <a href="https://cse.buffalo.edu/~regan/papers/pdf/ReHa11c.pdf">paper</a> with Guy Haworth, I used over 400,000 positions from 5,700 games at rating levels from Elo 1600 to 2700 only, all run on my office and home PCs. Below Elo 2000 the available data was so scant that noise is evident in the paper’s table.</p>
<p>
Since then, many more games by lower-rated players are being archived—much thanks to the greater availability of chessboards that automatically record moves in the standard <a href="https://en.wikipedia.org/wiki/Portable_Game_Notation">PGN</a> format, and to an upswell in tournaments, for youth in particular. Last year, thanks to the great free bandwidth granted by my university’s Center for Computational Research (<a href="http://www.buffalo.edu/ccr.html">CCR</a>), I took data in the quicker mode from over 10,600,000 moves from just over 400,000 game-sides (counting White and Black separately) in every tournament compiled by <a href="https://en.chessbase.com/">ChessBase</a> as well as some posted only by The Week in Chess (<a href="http://theweekinchess.com/">TWIC</a>) or provided directly by the World Chess Federation (FIDE). My two main test quantities are:</p>
<ul>
<li>
The percentage of the computer’s best move being the one the player chose (“MM%”). <p/>
</li><li>
The average error judged by the computer per move, scaling down large differences (“ASD”).
</li></ul>
<p>
My 2011 paper found strong linear relations of these quantities to the players’ rating, and great ASD fits on a 3-million-move data set are shown graphically in this <a href="https://rjlipton.wordpress.com/2016/11/30/when-data-serves-turkey/">post</a>. With MM% and my new 2018 data, here is what I see when I limit to the 1600–2700 range, grouping in “buckets” of 25 Elo points. All screenshots are taken with Andrew Que’s Polynomial Regression <a href="http://polynomialregression.drque.net/online.php">applet</a>. They all show data taken with Stockfish 9 run to search depth at least 20 and breadth at least 200 million nodes; the similar data for the chess program Komodo 11.3 gives similar results.</p>
<p><a href="https://rjlipton.wordpress.com/2019/02/03/a-strange-horizon/linearmmpfitpart/" rel="attachment wp-att-15620"><img alt="" class="aligncenter wp-image-15620" height="285" src="https://rjlipton.files.wordpress.com/2019/02/linearmmpfitpart.png?w=450&amp;h=285" width="450"/></a></p>
<p>
Even with vastly more data, there still does not appear any reason to reject the simple hypothesis that the relation to rating is linear. Not only is <img alt="{R^2 &gt; 0.99}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%5E2+%3E+0.99%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R^2 &gt; 0.99}"/>, the quality of fit is terrific. The noise under Elo 2000 is minimal.</p>
<p>
But now I have over 14,000 moves in individual buckets clear down to the FIDE minimum 1000 rating; only the 2750 bucket with 11,923 moves and the 2800-level bucket with 6,340 (from just a handful of the world’s elite players) lag behind. When those buckets are added, here is what we see:</p>
<p><a href="https://rjlipton.wordpress.com/2019/02/03/a-strange-horizon/linearmmpfita/" rel="attachment wp-att-15622"><img alt="" class="aligncenter wp-image-15622" height="285" src="https://rjlipton.files.wordpress.com/2019/02/linearmmpfita.png?w=450&amp;h=285" width="450"/></a></p>
<p>
The linear hypothesis is notably less tenable. Instead, a quadratic polynomial fits supremely well:</p>
<p>
<a href="https://rjlipton.wordpress.com/2019/02/03/a-strange-horizon/quadraticmmpfita/" rel="attachment wp-att-15623"><img alt="" class="aligncenter wp-image-15623" height="285" src="https://rjlipton.files.wordpress.com/2019/02/quadraticmmpfita.png?w=450&amp;h=285" width="450"/></a></p>
<p>
Thus it seems I must admit a <em>nonlinearity</em> into my chess model. This may not be just about slightly improving my model’s application to players at the ends of the rating spectrum. Philosophically, nonlinearity can be a game-changer: the way Newtonian physics is fine for flying jets all around the globe but finding your neighbor’s house via <a href="http://physicscentral.com/explore/writers/will.cfm">GPS</a> absolutely requires Einstein. </p>
<p>
</p><p/><h2> The Horizon Issue </h2><p/>
<p/><p>
Let us flip the axes so that <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X}"/> is MM% and <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y}"/> is rating. Then the intercept of <img alt="{X = 100\%}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX+%3D+100%5C%25%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X = 100\%}"/> would give the rating of perfect agreement with the computer. Well, here is what we see:</p>
<p>
<a href="https://rjlipton.wordpress.com/2019/02/03/a-strange-horizon/quadraticmmpfitflipext/" rel="attachment wp-att-15624"><img alt="" class="aligncenter wp-image-15624" height="285" src="https://rjlipton.files.wordpress.com/2019/02/quadraticmmpfitflipext.png?w=450&amp;h=285" width="450"/></a></p>
<p>
Having the rating of perfect agreement be about 1950—which is a amateur A-level in the US—is ludicrous. The greater import is how the increase stops at Elo 3000 with matching just under 75%. The serious implication I draw is that this helps locate the horizon of effectiveness of the data and my methods based on it. Meanwhile, I’ve had the sense from applications that my full model based on smaller higher-quality data is coherent up to about 3100 but cannot tell differences above that. </p>
<p>
Indeed, there is a corroborating indicator of this horizon: The top chess programs, or even different (major) versions of the same program, don’t even match <em>each other</em> over 75% with regularity. Moreover, the <em>same program</em> will fairly often change to a different move when left running for more time or to a greater search depth. If it didn’t change, it wouldn’t improve. Thus my tests, which have no foreknowledge of how long a program used to cheat was running and on how powerful hardware, cannot expect to register positives at a higher rate. The natural agreement rates for human players range from about 35% for novices to upwards of 60% for world champions. </p>
<p>
</p><p/><h2> The Average-Error Case </h2><p/>
<p/><p>
The fit to average scaled error-per-move (ASD) shows the other side of the horizon issue. The ASD measure is more tightly correlated to rating—as the graphs in the above-mentioned <a href="https://rjlipton.wordpress.com/2016/11/30/when-data-serves-turkey/">post</a> suffice to indicate. Here is the corresponding graph on the new data, again with flipped axes:</p>
<p>
<a href="https://rjlipton.wordpress.com/2019/02/03/a-strange-horizon/linearasdfit/" rel="attachment wp-att-15625"><img alt="" class="aligncenter wp-image-15625" height="285" src="https://rjlipton.files.wordpress.com/2019/02/linearasdfit.png?w=450&amp;h=285" width="450"/></a></p>
<p>
Only under 1250 Elo does perfect linearity seem to be countermanded. The issue, however, is at the other end. Committing asymptotically zero error seems to be a more acute indicator of perfection than 100% agreement with a strong program. However, the <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y}"/>-intercept there is given as a rating under 3300, whereas computer programs have been reliably <a href="http://www.computerchess.org.uk/ccrl/404/">rated</a> above 3400, and very recently over 3500. Thus we’d appear to have computers rated higher than perfection.</p>
<p>
One can move from the above indication of my setup losing mojo before 3000 to allege that it is insufficient for fair judgment of human players above 2500, say, so that the intercept is not valid. My counter-argument is that the same intercept is also a robust extrapolation from the range 1500 to 2500 where the linear fit is nearly perfect and the computer’s sufficiency for authoritative judgment of the players is beyond doubt. </p>
<p>
Nevertheless, the above “game-changer” for the move-matching percentage suggests the same for ASD. A quadratic fit to ASD produces the following results:</p>
<p>
<a href="https://rjlipton.wordpress.com/2019/02/03/a-strange-horizon/quadraticasdfitnw/" rel="attachment wp-att-15626"><img alt="" class="aligncenter wp-image-15626" height="285" src="https://rjlipton.files.wordpress.com/2019/02/quadraticasdfitnw.png?w=450&amp;h=285" width="450"/></a></p>
<p>
Now the <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y}"/>-intercept at <img alt="{X = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X = 0}"/> is within error bars of 3500, in agreement with the 3475 figure currently used in my full model and less starkly under the measured ratings.</p>
<p>
</p><p/><h2> One More Riff </h2><p/>
<p/><p>
Let us think of move-matching for a given rating <img alt="{R}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R}"/> as a flip of a biased coin with heads probability <img alt="{p = p_R}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp+%3D+p_R%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p = p_R}"/>. If we plot <img alt="{R}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R}"/> not against <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> but against <img alt="{p\cdot p(1-p)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%5Ccdot+p%281-p%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p\cdot p(1-p)}"/>, we recover a nearly perfect linear fit (the plot shows <img alt="{4p^2 (1-p)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B4p%5E2+%281-p%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{4p^2 (1-p)}"/>):</p>
<p>
<a href="https://rjlipton.wordpress.com/2019/02/03/a-strange-horizon/ppqfit/" rel="attachment wp-att-15627"><img alt="" class="aligncenter wp-image-15627" height="285" src="https://rjlipton.files.wordpress.com/2019/02/ppqfit.png?w=450&amp;h=285" width="450"/></a></p>
<p>
Well, <img alt="{p(1-p)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%281-p%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p(1-p)}"/> is the variance of one coin flip. Why should multiplying <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> by this variance recover a linear fit in the <em>mean</em>? Only multiplying <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> by the square root of <img alt="{p(1-p)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%281-p%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p(1-p)}"/> still leaves a significantly non-linear plot. </p>
<p>
Recovering <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> from <img alt="{p^2(1-p)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%5E2%281-p%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p^2(1-p)}"/> needs solving a cubic equation. The maximum value is at <img alt="{p = \frac{2}{3}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp+%3D+%5Cfrac%7B2%7D%7B3%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p = \frac{2}{3}}"/> and is <img alt="{\frac{4}{27}.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B4%7D%7B27%7D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\frac{4}{27}.}"/> Multiplying by <img alt="{4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{4}"/> as in the plot makes <img alt="{\frac{16}{27} \approx 0.592593}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B16%7D%7B27%7D+%5Capprox+0.592593%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\frac{16}{27} \approx 0.592593}"/> the maximum solvable value. This regression line associates this to a rating of only 2860. This suggests a tangibly lower horizon. It also seems contradicted by the fact of Magnus Carlsen maintaining a rating over 2860 from January 2013 through June 2015, yet his engine agreement did not approach 66.7%.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
We’ve connected the horizon of perfect play to whether the fundamental relationship of rating to agreement with strong computer programs is linear, quadratic, or indirectly cubic. Which relationship is true? What further tests may best ascertain the range of effectiveness of inferences from these data?</p>
<p/></font></font></div>
    </content>
    <updated>2019-02-03T06:37:57Z</updated>
    <published>2019-02-03T06:37:57Z</published>
    <category term="All Posts"/>
    <category term="chess"/>
    <category term="detection"/>
    <category term="Ideas"/>
    <category term="Teaching"/>
    <category term="Alfred Lotka"/>
    <category term="Derek de Solla Price"/>
    <category term="horizons"/>
    <category term="linear regression"/>
    <category term="nonlinearity"/>
    <category term="Paul Allison"/>
    <category term="statistics"/>
    <author>
      <name>KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-02-11T18:20:41Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://theorydish.blog/?p=1490</id>
    <link href="https://theorydish.blog/2019/02/02/stoca-workshop/" rel="alternate" type="text/html"/>
    <title>STOCA workshop</title>
    <summary>For the past few months, we, the STOC 2019 PC, have enjoyed the privilege of reading and discussing a lot of exciting submissions. On Sunday and Monday we will reject most of them. After that, on Tuesday February 5th, we will celebrate with a 1-day workshop hosted at Google. Here is the official website for registration (free!) and other useful infromation: https://sites.google.com/view/stoca19/home</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>For the past few months, we, the STOC 2019 PC, have enjoyed the privilege of reading and discussing a lot of exciting submissions. On Sunday and Monday we will reject most of them. After that, on <strong>Tuesday February 5th</strong>, we will celebrate with a 1-day workshop hosted at Google.</p>
<p>Here is the official website for registration (free!) and other useful infromation:<br/>
<a href="https://sites.google.com/view/stoca19/home">https://sites.google.com/view/stoca19/home</a></p></div>
    </content>
    <updated>2019-02-03T05:31:05Z</updated>
    <published>2019-02-03T05:31:05Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>aviad.rubinstein</name>
    </author>
    <source>
      <id>https://theorydish.blog</id>
      <logo>https://theorydish.files.wordpress.com/2017/03/cropped-nightdish1.jpg?w=32</logo>
      <link href="https://theorydish.blog/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://theorydish.blog" rel="alternate" type="text/html"/>
      <link href="https://theorydish.blog/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://theorydish.blog/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Stanford's CS Theory Research Blog</subtitle>
      <title>Theory Dish</title>
      <updated>2019-02-11T18:21:18Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=16779</id>
    <link href="https://gilkalai.wordpress.com/2019/02/02/konstantin-tikhomrov-the-probability-that-a-bernoulli-matrix-is-singular/" rel="alternate" type="text/html"/>
    <title>Konstantin Tikhomirov: The Probability that a Bernoulli Matrix is Singular</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Konstantin Tikhomirov An old problem in combinatorial random matrix theory is cracked! Singularity of random Bernoulli matrices by Konstantin Tikhomirov Abstract: For each , let be an n×n random matrix with independent ±1 entries. We show that P( is singular}=, … <a href="https://gilkalai.wordpress.com/2019/02/02/konstantin-tikhomrov-the-probability-that-a-bernoulli-matrix-is-singular/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="https://gilkalai.files.wordpress.com/2019/02/tikhomirov.jpg"><img alt="" class="alignnone size-full wp-image-16826" src="https://gilkalai.files.wordpress.com/2019/02/tikhomirov.jpg?w=640"/></a></p>
<p><span style="color: #ff0000;"><strong>Konstantin Tikhomirov</strong></span></p>
<p>An old problem in combinatorial random matrix theory is cracked!</p>
<p><a href="https://arxiv.org/abs/1812.09016"><strong>Singularity of random Bernoulli matrices</strong></a> by <strong>Konstantin Tikhomirov</strong></p>
<p><strong>Abstract</strong>: For each <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>, let <img alt="M_n" class="latex" src="https://s0.wp.com/latex.php?latex=M_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="M_n"/> be an <em>n</em>×<em>n</em> random matrix with independent ±1 entries. We show that</p>
<p style="text-align: center;">P(<img alt="M_n" class="latex" src="https://s0.wp.com/latex.php?latex=M_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="M_n"/> is singular}=<img alt="(1/2+o_n(1))^n" class="latex" src="https://s0.wp.com/latex.php?latex=%281%2F2%2Bo_n%281%29%29%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(1/2+o_n(1))^n"/>,</p>
<p>which settles an old problem. Some generalizations are considered.</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/02/komlos.jpg"><img alt="" class="alignnone size-full wp-image-16821" src="https://gilkalai.files.wordpress.com/2019/02/komlos.jpg?w=640"/></a></p>
<p><span style="color: #ff0000;"><b>János Komlós</b></span></p>
<h3>Background and discussion</h3>
<p>What is the probability <img alt="s(n)" class="latex" src="https://s0.wp.com/latex.php?latex=s%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s(n)"/> that a random n by n matrix with <img alt="\pm 1" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpm+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\pm 1"/> entries is singular? Well, it can be singular if either two rows are identical, or if two columns are identical. This happens with probability</p>
<p style="text-align: center;"><img alt="n(n-1)(1+0(1)) \cdot 2^{-n}" class="latex" src="https://s0.wp.com/latex.php?latex=n%28n-1%29%281%2B0%281%29%29+%5Ccdot+2%5E%7B-n%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n(n-1)(1+0(1)) \cdot 2^{-n}"/>.</p>
<p>Are there other more dominant reasons for singularity? Are most <img alt="\pm 1" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpm+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\pm 1"/> matrices nonsingular as <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> tends to infinity? The first results in this direction are by Janos Komlos who first proved in 1968 that <img alt="s(n)=o(1)" class="latex" src="https://s0.wp.com/latex.php?latex=s%28n%29%3Do%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s(n)=o(1)"/> and later that <img alt="s(n)=O(1/\sqrt n)" class="latex" src="https://s0.wp.com/latex.php?latex=s%28n%29%3DO%281%2F%5Csqrt+n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s(n)=O(1/\sqrt n)"/>. A major breakthrough came in 1995 when  <a href="http://www.ams.org/journals/jams/1995-08-01/S0894-0347-1995-1260107-2/home.html">Kahn , Komlos, and Szemeredi proved</a> that <img alt="s(n) \le 0.999^n" class="latex" src="https://s0.wp.com/latex.php?latex=s%28n%29+%5Cle+0.999%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s(n) \le 0.999^n"/>. Terry Tao and Van Vu improved in 2006 the constant to 0.939 and then to (3/4+o(1)) and the, now broken, world record from 2010 was <img alt="(1/\sqrt 2)+o(1))^n" class="latex" src="https://s0.wp.com/latex.php?latex=%281%2F%5Csqrt+2%29%2Bo%281%29%29%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(1/\sqrt 2)+o(1))^n"/>  by Jean Bourgain, Van Vu and Philip Wood. Congratulations Konstantin!</p>
<p>If you want to tease the Gods of Mathematics you can try to prove that <img alt="s(n) =n(n-1)(1+o(1)) \cdot 2^{-n}" class="latex" src="https://s0.wp.com/latex.php?latex=s%28n%29+%3Dn%28n-1%29%281%2Bo%281%29%29+%5Ccdot+2%5E%7B-n%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s(n) =n(n-1)(1+o(1)) \cdot 2^{-n}"/>? and, as suggested in the Kahn-Komlós-Szemerédi paper,  even prove an expansion  <img alt="s(n) = 2{{n} \choose {2}}(\frac{1}{2})^{n}+2{{n}\choose {4}} (\frac{3}{8})^n\cdots" class="latex" src="https://s0.wp.com/latex.php?latex=s%28n%29+%3D+2%7B%7Bn%7D+%5Cchoose+%7B2%7D%7D%28%5Cfrac%7B1%7D%7B2%7D%29%5E%7Bn%7D%2B2%7B%7Bn%7D%5Cchoose+%7B4%7D%7D+%28%5Cfrac%7B3%7D%7B8%7D%29%5En%5Ccdots&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s(n) = 2{{n} \choose {2}}(\frac{1}{2})^{n}+2{{n}\choose {4}} (\frac{3}{8})^n\cdots"/> based on dependencies between <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-tuples of rows and columns.</p>
<p>Let me mention that  <a href="https://arxiv.org/abs/math/0505156">Kevin Costello, Tao, and Vu, proved in 2005</a> that  random symmetric matrices are almost surely non-singular.  This is related to beautiful mathematics. <a href="https://arxiv.org/abs/0804.2362"> Tao and Vu also proved</a> that the probability for vanishing of the permanent of a Bernoulli matrix is <img alt="o(1)" class="latex" src="https://s0.wp.com/latex.php?latex=o%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="o(1)"/>. I am not sure what is the proven behavior for permanents and one may expect that vanishing of the permanent occurs in probability which is super exponentially small. (Perhaps <img alt="C/\sqrt {n!}" class="latex" src="https://s0.wp.com/latex.php?latex=C%2F%5Csqrt+%7Bn%21%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C/\sqrt {n!}"/>.)</p>
<p>Here are related posts on Tao’s blog What’s New. <a href="https://terrytao.wordpress.com/2007/12/05/milliman-lecture-ii-additive-combinatorics-and-random-matrices/">A post on Tao’s Milliman’s lecture on the additive combinatorics and random matrices</a>; <a href="https://terrytao.wordpress.com/2008/04/16/on-the-permanent-of-a-random-bernoulli-matrix/">On the permamnent of random Bernoulli matrix</a>;</p>
<h3>Determinants and the guaranteed cancellation phenomenon</h3>
<p>The value of the determinant of a Bernoulli matrix is the sum of <em>n!</em> ±1 terms. So we can guess that the expected value will be around <img alt="\sqrt {n!}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csqrt+%7Bn%21%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sqrt {n!}"/>, and with high probability it is near the expected value. There is something special about the determinant which we can call the <strong>Guaranteed Cancellation Phenomenon (GCP)</strong>. The value of the determinant of a Bernoulli  matrix is at most <img alt="n^{n/2}" class="latex" src="https://s0.wp.com/latex.php?latex=n%5E%7Bn%2F2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n^{n/2}"/> which is not that much larger than <img alt="\sqrt {n!}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csqrt+%7Bn%21%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sqrt {n!}"/>. (GCP applies to matrices with real or complex variables with rows with prescribed  <img alt="\ell_2" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\ell_2"/> norms.)  Guaranteed cancellation is a very interesting mathematical phenomenon in various contexts. (For example, the prime number theorem and the Riemann hypothesis are about guaranteed cancellation.) The determinant itself is a polynomial of degree <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> with <img alt="n^2" class="latex" src="https://s0.wp.com/latex.php?latex=n%5E2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n^2"/> variables , and GCP for determinants was one of the starting points in a paper that I wrote with Leonard Schulman on <a href="https://arxiv.org/abs/1804.04828">quasi-random multilinear polynomials</a>. (For other examples of GCP see also this <a href="https://mathoverflow.net/questions/59530/horst-kn%C3%B6rrers-permutation-cancellation-problem">MO question</a> and various posts  on Mobius randomness.) Maybe it is time to ask on MathOverflow for a list of places were GCP  is expected or proven.)</p>
<p>Sperner, the Littlewood-Offord problem, and additive combinatorics</p>
<p>The determinant of a <img alt="\pm 1" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpm+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\pm 1"/> matrix is the signed sum of <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> minors. It follows from Sperner’s theorem that if <img alt="m" class="latex" src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m"/> of these minors are non-zero then the probability that the sum vanishes is <img alt="O(1/\sqrt m)" class="latex" src="https://s0.wp.com/latex.php?latex=O%281%2F%5Csqrt+m%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(1/\sqrt m)"/>. This is the idea behind Komlos’ second proof. The relevant general question (backward <a href="https://en.wikipedia.org/wiki/Littlewood%E2%80%93Offord_problem">Littlewood Offord</a>  problem) which is of much independent interest is “Under which conditions on a sequence <img alt="a_1,a_2, \dots, a_n" class="latex" src="https://s0.wp.com/latex.php?latex=a_1%2Ca_2%2C+%5Cdots%2C+a_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_1,a_2, \dots, a_n"/> we can guarantee that the probability that a signed sum of the sequence vanished (or has a small absolute value) is small.” The famous Erdos-Moser conjecture (solved on the nose by Stanley using the Hard Lefschetz theorem, sharpening a result by Sárközy and Szemerédi) asserts that if the elements of the sequence are distinct then the larger vanishing probability is attained by the sequence of integers between <em>-[n/2]</em> and +<em>[n/2]</em>. In this case (like for any arithmetic progression) the vanishing probability is <img alt="n^{-3/2}" class="latex" src="https://s0.wp.com/latex.php?latex=n%5E%7B-3%2F2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n^{-3/2}"/>.  Kahn, Komlos and Szemeredi relied on (and extended)  a theory by  Gábor Halász for guaranteeing that the vanishing probability is small (exponentially small) and, of course, much work is needed to prove that Halász-type conditions are satisfied.</p>
<p>I was excited by the 2005 solution for symmetric matrices also because it involved a quadratic version of Littlewood-Offord type results which are of much independent interest. I think that there are many interesting remaining open problems.</p>
<p> </p></div>
    </content>
    <updated>2019-02-02T18:37:12Z</updated>
    <published>2019-02-02T18:37:12Z</published>
    <category term="Combinatorics"/>
    <category term="Probability"/>
    <category term="Konstantin Tikhomirov"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-02-11T18:20:36Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-6555947.post-2316741109895040253</id>
    <link href="http://blog.geomblog.org/feeds/2316741109895040253/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://blog.geomblog.org/2019/02/more-fat-blogging.html#comment-form" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/6555947/posts/default/2316741109895040253" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/6555947/posts/default/2316741109895040253" rel="self" type="application/atom+xml"/>
    <link href="http://feedproxy.google.com/~r/TheGeomblog/~3/SO5XVo9kvXw/more-fat-blogging.html" rel="alternate" type="text/html"/>
    <title>More FAT* blogging</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Session 3: <a href="https://algorithmicfairness.wordpress.com/2019/01/30/fat-papers-profiling-and-representation/">Representation and Profiling</a><br/><br/>Session 4: <a href="https://algorithmicfairness.wordpress.com/2019/02/01/fat-papers-fairness-methods/">Fairness methods. </a><img alt="" height="1" src="http://feeds.feedburner.com/~r/TheGeomblog/~4/SO5XVo9kvXw" width="1"/></div>
    </content>
    <updated>2019-02-02T07:46:00Z</updated>
    <published>2019-02-02T07:46:00Z</published>
    <category scheme="http://www.blogger.com/atom/ns#" term="conf-blogs"/>
    <category scheme="http://www.blogger.com/atom/ns#" term="fat*"/><feedburner:origlink xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0">http://blog.geomblog.org/2019/02/more-fat-blogging.html</feedburner:origlink>
    <author>
      <name>Suresh Venkatasubramanian</name>
      <email>noreply@blogger.com</email>
      <uri>https://plus.google.com/112165457714968997350</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-6555947</id>
      <category term="research"/>
      <category term="community"/>
      <category term="miscellaneous"/>
      <category term="soda"/>
      <category term="conferences"/>
      <category term="data-mining"/>
      <category term="socg"/>
      <category term="blogosphere"/>
      <category term="publishing"/>
      <category term="clustering"/>
      <category term="teaching"/>
      <category term="jobs"/>
      <category term="funding"/>
      <category term="humor"/>
      <category term="awards"/>
      <category term="outreach"/>
      <category term="stoc"/>
      <category term="cs.CG"/>
      <category term="focs"/>
      <category term="nsf"/>
      <category term="reviewing"/>
      <category term="socg-2010"/>
      <category term="fairness"/>
      <category term="academy"/>
      <category term="latex"/>
      <category term="stoc2017"/>
      <category term="theoryfest"/>
      <category term="workshops"/>
      <category term="acm"/>
      <category term="conf-blogs"/>
      <category term="writing"/>
      <category term="cs.DS"/>
      <category term="cs.LG"/>
      <category term="geometry"/>
      <category term="p-vs-nc"/>
      <category term="advising"/>
      <category term="sabbatical"/>
      <category term="simons foundation"/>
      <category term="announcement"/>
      <category term="big-data"/>
      <category term="deadline"/>
      <category term="jeff phillips"/>
      <category term="streaming"/>
      <category term="books"/>
      <category term="large-data"/>
      <category term="p-vs-np"/>
      <category term="cra"/>
      <category term="cstheory"/>
      <category term="focs2010"/>
      <category term="icdm"/>
      <category term="math.PR"/>
      <category term="memorial"/>
      <category term="personal"/>
      <category term="posters"/>
      <category term="potd"/>
      <category term="rajeev motwani"/>
      <category term="shonan"/>
      <category term="socg2012"/>
      <category term="software"/>
      <category term="stoc2012"/>
      <category term="GIA"/>
      <category term="SDM"/>
      <category term="alenex"/>
      <category term="alenex2011"/>
      <category term="arxiv"/>
      <category term="career"/>
      <category term="complexity"/>
      <category term="cs.CC"/>
      <category term="deolalikar"/>
      <category term="distributions"/>
      <category term="madalgo"/>
      <category term="nips"/>
      <category term="sdm2011"/>
      <category term="shape"/>
      <category term="talks"/>
      <category term="technology"/>
      <category term="theory.SE"/>
      <category term="travel"/>
      <category term="video"/>
      <category term="8f-cg"/>
      <category term="DBR"/>
      <category term="ICS"/>
      <category term="LISPI"/>
      <category term="acceptances"/>
      <category term="bibtex"/>
      <category term="bregman"/>
      <category term="cfp"/>
      <category term="clustering-book"/>
      <category term="column"/>
      <category term="combinatorial geometry"/>
      <category term="current-distance"/>
      <category term="ecml-pkdd"/>
      <category term="empirical"/>
      <category term="esa"/>
      <category term="fat*"/>
      <category term="focs2012"/>
      <category term="focs2014"/>
      <category term="fwcg"/>
      <category term="game theory"/>
      <category term="godel"/>
      <category term="graphs"/>
      <category term="implementation"/>
      <category term="journals"/>
      <category term="kernels"/>
      <category term="misc"/>
      <category term="models"/>
      <category term="obituary"/>
      <category term="productivity"/>
      <category term="programming"/>
      <category term="society"/>
      <category term="soda2011"/>
      <category term="topology"/>
      <category term="turing"/>
      <category term="tv"/>
      <category term="women-in-theory"/>
      <category term=".02"/>
      <category term="IMA"/>
      <category term="MOOC"/>
      <category term="PPAD"/>
      <category term="accountability"/>
      <category term="active-learning"/>
      <category term="aggregator"/>
      <category term="algorithms"/>
      <category term="ams"/>
      <category term="analco"/>
      <category term="barriers"/>
      <category term="beamer"/>
      <category term="blogging"/>
      <category term="candes"/>
      <category term="civil rights"/>
      <category term="classification"/>
      <category term="coding-theory"/>
      <category term="coffee"/>
      <category term="conjecture"/>
      <category term="cosmos"/>
      <category term="counting"/>
      <category term="cricket"/>
      <category term="cs.DC"/>
      <category term="dagstuhl"/>
      <category term="databuse"/>
      <category term="dimacs"/>
      <category term="dimensionality-reduction"/>
      <category term="distributed-learning"/>
      <category term="double-blind review"/>
      <category term="duality"/>
      <category term="eda"/>
      <category term="embarrassing"/>
      <category term="expanders"/>
      <category term="experiments"/>
      <category term="fake-news"/>
      <category term="fatml"/>
      <category term="fellowships"/>
      <category term="focs2013"/>
      <category term="fonts"/>
      <category term="gct"/>
      <category term="ggplot"/>
      <category term="gpu"/>
      <category term="graph minors"/>
      <category term="gt.game-theory"/>
      <category term="guest-post"/>
      <category term="guitar"/>
      <category term="hangouts"/>
      <category term="hirsch"/>
      <category term="history"/>
      <category term="ipe"/>
      <category term="ita"/>
      <category term="jmm"/>
      <category term="k-12"/>
      <category term="knuth"/>
      <category term="machine-learning"/>
      <category term="massive"/>
      <category term="math.ST"/>
      <category term="media"/>
      <category term="memes"/>
      <category term="metoo"/>
      <category term="metrics"/>
      <category term="morris"/>
      <category term="movies"/>
      <category term="multicore"/>
      <category term="music"/>
      <category term="narrative"/>
      <category term="networks"/>
      <category term="nih"/>
      <category term="parallelism"/>
      <category term="partha niyogi"/>
      <category term="polymath"/>
      <category term="polymath research"/>
      <category term="polytopes"/>
      <category term="postdocs"/>
      <category term="privacy"/>
      <category term="quant-ph"/>
      <category term="quantum"/>
      <category term="randomness"/>
      <category term="review"/>
      <category term="sampling"/>
      <category term="seminars"/>
      <category term="social-networking"/>
      <category term="soda2014"/>
      <category term="students"/>
      <category term="sublinear"/>
      <category term="submissions"/>
      <category term="summer-school"/>
      <category term="superbowl"/>
      <category term="surveys"/>
      <category term="svn"/>
      <category term="television"/>
      <category term="traffic"/>
      <category term="twitter"/>
      <category term="utah"/>
      <category term="wads"/>
      <category term="white elephant"/>
      <category term="xkcd"/>
      <author>
        <name>Suresh Venkatasubramanian</name>
        <email>noreply@blogger.com</email>
      </author>
      <link href="http://blog.geomblog.org/" rel="alternate" type="text/html"/>
      <link href="http://www.blogger.com/feeds/6555947/posts/default?alt=atom&amp;start-index=26&amp;max-results=25&amp;redirect=false" rel="next" type="application/atom+xml"/>
      <link href="http://feeds.feedburner.com/TheGeomblog" rel="self" type="application/atom+xml"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <subtitle>Ruminations on computational geometry, algorithms, theoretical computer science and life</subtitle>
      <title>The Geomblog</title>
      <updated>2019-02-02T07:46:06Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=7467</id>
    <link href="https://windowsontheory.org/2019/02/01/black-holes-a-complexity-theory-perspective/" rel="alternate" type="text/html"/>
    <title>Black Holes, a Complexity Theory perspective</title>
    <summary>Guest post by Chi-Ning Chou and Parth Mehta from the physics and computation seminar. Abstract The firewall paradox (introduced here) is a bewitching thought experiment that mandates a deeper understanding of our reality. As luck would have it, QFT predictions seem sound, GR calculations appear valid, and semi-classical approximations look reasonable: no one is willing […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Guest post by Chi-Ning Chou and Parth Mehta from <a href="https://www.boazbarak.org/fall18seminar/">the physics and computation seminar</a>.</p>
<h3>Abstract</h3>
<p>The firewall paradox (introduced <em>here</em>) is a bewitching thought experiment that mandates a deeper understanding of our reality. As luck would have it, QFT predictions seem sound, GR calculations appear valid, and semi-classical approximations look reasonable: no one is willing to budge! To save Alice from burning in the miserable firewall, therefore, we must come up with a radically new proposal. This blog post aims to map what seems to be a hard, physics dilemma into a Computer Science problem that we can, using the grace of a lazy programmer, show to be hard to solve. In particular, we present an overview of the Harlow-Hayden decoding task and show how it maps the Firewall Paradox to a hard computation on a quantum computer. We end by rigorously defining quantum circuit complexity, Aaronson’s improved proof, AdS/CFT correspondence, and some fascinating homework (open) problems.</p>
<h2>Why all the fuss?</h2>
<p>Have you ever confessed to yourself that you don’t quite understand Black Hole complementarity well? In the past decade or so, physicists realized they did not grasp the concept thoroughly either. The firewall paradox is a natural result of bewildered physicists trying to make sense of reality. Thus far, no satisfying physical explanation reaches people’s consensus. Nevertheless, Daniel Harlow and Patrick Hayden [HH13] proposed a tempting solution to the firewall paradox using Computational Complexity (CC). Concretely, they showed the following.</p>
<p style="text-align: center;"><img alt="\text{A conjecture in CC is true}\Rightarrow\text{Firewalls do not exist}." class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctext%7BA+conjecture+in+CC+is+true%7D%5CRightarrow%5Ctext%7BFirewalls+do+not+exist%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\text{A conjecture in CC is true}\Rightarrow\text{Firewalls do not exist}."/></p>
<p>We elaborate on this deep connection throughout this post.</p>
<h3>Problem Solving: Physics v.s. Computer Science</h3>
<p>The notion of a `conjecture’ has different implications for either field. In Physics, a wrong conjecture often delights physicists since there is more work left to do and better theory required to explain the physical phenomenon under study. For complexity theorists, however, if, say, the famous <img alt="\mathbf{P}\neq\mathbf{NP}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BP%7D%5Cneq%5Cmathbf%7BNP%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{P}\neq\mathbf{NP}"/> is proved to be false, a few consequences follow. First, the authors of the proof win a million dollars (See the <a href="http://www.claymath.org/millennium-problems/p-vs-np-problem" rel="noopener" target="_blank">Millennium problems</a>.). Second, such a result would break almost all the foundations of computational complexity and cryptography. That is, refuting an (important) conjecture in computational complexity is tantamount to resulting in real-world catastrophes! Below in Table 1 is a short summary.</p>
<table style="border: 1px solid black; border-collapse: collapse;">
<tbody>
<tr style="border: 1px solid black;">
<td style="border: 1px solid black;"/>
<td style="border: 1px solid black;">Theoretical Physics</td>
<td style="border: 1px solid black;">Theoretical Computer Science</td>
</tr>
<tr style="border: 1px solid black;">
<td style="border: 1px solid black;">Object</td>
<td style="border: 1px solid black;">Are the mathematical models for our physical world correct?</td>
<td style="border: 1px solid black;">Is our intuition about the mathematical models we defined correct?</td>
</tr>
<tr style="border: 1px solid black;">
<td style="border: 1px solid black;">Consequences of disproving</td>
<td style="border: 1px solid black;">After few days/months/years, physicists will come up with a new model and try to falsify it.</td>
<td style="border: 1px solid black;">The belief system of complexity theorists collapses. Some super algorithms might show up and shake the world.</td>
</tr>
<tr style="border: 1px solid black;">
<td style="border: 1px solid black;">How to prove/disprove</td>
<td style="border: 1px solid black;">Checking mathematical consistency, doing both thought and empirical experiments.</td>
<td style="border: 1px solid black;">Using fancy mathematics or designing super algorithms.</td>
</tr>
</tbody>
</table>
<p style="text-align: center;">Table 1: “Conjecture”, as used in Physics and Computer Science.</p>
<p>We labour above to convince the reader about these differences because the Harlow-Hayden decoding task has vital implications for both, Physics and Computer Science. The connections between Black Holes and Computational Complexity can be thought of as a new <em>testbench</em> for physical models.</p>
<h2>Reckless review: Quantum Information</h2>
<h3>Gates</h3>
<p>In Quantum Computation, gates are unitary operators. Some common gates used in the Quantum Information literature are as follows:</p>
<ul>
<li>
<div>Single-qubit: Pauli matrices (<em>i.e.,</em> <img alt="X,Y,Z" class="latex" src="https://s0.wp.com/latex.php?latex=X%2CY%2CZ&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X,Y,Z"/>), phase operator <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/>, Hadamard matrix <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/>.</div>
</li>
<li>
<div>Two-qubit: CNOT, Toffoli, CZ.</div>
</li>
</ul>
<p>For more details, please refer to [NC02]. Interestingly enough, singe-qubit and two-qubit gates are sufficient to construct any <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>-qubit gates! Such a set of operators is said to be <em>universal</em>. For example, <img alt="\{\text{Toffoli},H,P\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B%5Ctext%7BToffoli%7D%2CH%2CP%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{\text{Toffoli},H,P\}"/> and <img alt="\{\text{CNOT},G\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B%5Ctext%7BCNOT%7D%2CG%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{\text{CNOT},G\}"/> are universal for almost every single-qubit operator. Furthermore, Kitaev and Solovay gave a <em>qualitative</em> version of the universality theorem by showing that getting an <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon"/> approximation to an <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>-qubit operator in trace norm, only <img alt="O(\log^21/\epsilon)" class="latex" src="https://s0.wp.com/latex.php?latex=O%28%5Clog%5E21%2F%5Cepsilon%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(\log^21/\epsilon)"/> gates are needed. A final remark on unitary operators: an <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>-qubit operator is actually a matrix of size <img alt="2^n" class="latex" src="https://s0.wp.com/latex.php?latex=2%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^n"/> by <img alt="2^n" class="latex" src="https://s0.wp.com/latex.php?latex=2%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^n"/>. Namely, it requires <img alt="2^{2n}-2^n" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7B2n%7D-2%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{2n}-2^n"/> complex numbers to describe an <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>-qubit operator. (Note the difference between <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> and <img alt="2^n" class="latex" src="https://s0.wp.com/latex.php?latex=2%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^n"/>.)</p>
<h3>Quantum circuits</h3>
<p>A quantum circuit <img alt="\mathcal{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{C}"/> has inputs consisting of <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>-qubits, potentially with <img alt="m" class="latex" src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m"/> <em><a href="https://en.wikipedia.org/wiki/Ancilla_bit" rel="noopener" target="_blank">ancilla bits</a></em>. The computation is done by interior gates from some universal gate set, <em>e.g., </em><img alt="\{\text{Toffoli},H,P\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B%5Ctext%7BToffoli%7D%2CH%2CP%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{\text{Toffoli},H,P\}"/>. The outputs are <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> qubits with potentially <img alt="m" class="latex" src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m"/> bits of garbage. See the following example of quantum circuit for the <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>-qubit Hadamard operator <img alt="H_n| x\rangle=\sum_{y\in\{0,1\}^n}(-1)^{\langle x,y\rangle}|y\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=H_n%7C+x%5Crangle%3D%5Csum_%7By%5Cin%5C%7B0%2C1%5C%7D%5En%7D%28-1%29%5E%7B%5Clangle+x%2Cy%5Crangle%7D%7Cy%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H_n| x\rangle=\sum_{y\in\{0,1\}^n}(-1)^{\langle x,y\rangle}|y\rangle"/> in Figure 1.</p>
<div class="wp-caption aligncenter" id="attachment_7472" style="width: 413px;"><img alt="hadamard" class="alignnone  wp-image-7472" height="266" src="https://windowsontheory.files.wordpress.com/2019/02/hadamard-e1549002349573.png?w=403&amp;h=266" width="403"/><p class="wp-caption-text">Figure 1: A quantum circuit for the n-qubit Hadamard operator.</p></div>
<p>Similarly, the size of a quantum circuit is defined as the number of interior gates. In Figure 1 for example, the size of the circuit is <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>.</p>
<h3>Quantum circuit complexity: <strong>BQP/poly</strong></h3>
<p>Let <img alt="f:\{0,1\}^n\rightarrow\{0,1\}" class="latex" src="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D%5En%5Crightarrow%5C%7B0%2C1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f:\{0,1\}^n\rightarrow\{0,1\}"/> be a boolean function. Define its quantum circuit complexity as the size of the smallest quantum circuit <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/> such that for any <img alt="x\in\{0,1\}^n" class="latex" src="https://s0.wp.com/latex.php?latex=x%5Cin%5C%7B0%2C1%5C%7D%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x\in\{0,1\}^n"/></p>
<p style="text-align: center;"><img alt="\Pr\left[\mathcal{M}_1(C|x\rangle)=f(x)\right]\geq\frac{2}{3}." class="latex" src="https://s0.wp.com/latex.php?latex=%5CPr%5Cleft%5B%5Cmathcal%7BM%7D_1%28C%7Cx%5Crangle%29%3Df%28x%29%5Cright%5D%5Cgeq%5Cfrac%7B2%7D%7B3%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Pr\left[\mathcal{M}_1(C|x\rangle)=f(x)\right]\geq\frac{2}{3}."/></p>
<p>Let <img alt="\mathbf{BQSIZE}[s(n)]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BBQSIZE%7D%5Bs%28n%29%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{BQSIZE}[s(n)]"/> denote the class of boolean functions of quantum circuit complexity at most <img alt="s(n)" class="latex" src="https://s0.wp.com/latex.php?latex=s%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s(n)"/>. The complexity class <img alt="\mathbf{BQP/poly}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BBQP%2Fpoly%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{BQP/poly}"/> is defined as <img alt="\cup_{c\in\mathbb{N}}\mathbf{BQSIZE}[n^c]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ccup_%7Bc%5Cin%5Cmathbb%7BN%7D%7D%5Cmathbf%7BBQSIZE%7D%5Bn%5Ec%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\cup_{c\in\mathbb{N}}\mathbf{BQSIZE}[n^c]"/>. It immediately follows from definition that <img alt="\mathbf{P/poly}\subseteq\mathbf{BQP/poly}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BP%2Fpoly%7D%5Csubseteq%5Cmathbf%7BBQP%2Fpoly%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{P/poly}\subseteq\mathbf{BQP/poly}"/>. As proving lower bound for <img alt="\mathbf{P/poly}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BP%2Fpoly%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{P/poly}"/> (<em>i.e.,</em> finding a problem that is not in <img alt="\mathbf{P/poly}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BP%2Fpoly%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{P/poly}"/>) is a long-standing extremely difficult problem, it is believed to be hard to prove lower bound against <img alt="\mathbf{BQP/poly}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BBQP%2Fpoly%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{BQP/poly}"/>.</p>
<h3>Uniform quantum circuit complexity: BQP</h3>
<p>As <img alt="\mathbf{BQP/poly}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BBQP%2Fpoly%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{BQP/poly}"/> is too powerful to work with, one might want to define a weaker version of the quantum complexity measure. A natural choice is considering a <em>uniform</em> computational model.</p>
<p>In the classical setting, a uniform computational model is defined using a Turing machine. However, it is not clear how to define the corresponding version, a quantum Turing machine. One way to do so is via <em>uniform circuits</em>, defined as follows. We say a circuit family <img alt="\mathcal{C}=\{C_n\}_{n\in\mathbb{N}}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D%3D%5C%7BC_n%5C%7D_%7Bn%5Cin%5Cmathbb%7BN%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{C}=\{C_n\}_{n\in\mathbb{N}}"/> is <img alt="\mathbf{P}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BP%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{P}"/>-uniform if there exists a polynomial time Turing machine such that on input <img alt="1^n" class="latex" src="https://s0.wp.com/latex.php?latex=1%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1^n"/>, it outputs <img alt="C_n" class="latex" src="https://s0.wp.com/latex.php?latex=C_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_n"/>.</p>
<p>Let <img alt="f:\{0,1\}^n\rightarrow\{0,1\}" class="latex" src="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D%5En%5Crightarrow%5C%7B0%2C1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f:\{0,1\}^n\rightarrow\{0,1\}"/> be a boolean function. Define its uniform quantum circuit complexity as the size of the smallest <strong>uniform</strong> quantum circuit <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/> such that for any <img alt="x\in\{0,1\}^n" class="latex" src="https://s0.wp.com/latex.php?latex=x%5Cin%5C%7B0%2C1%5C%7D%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x\in\{0,1\}^n"/></p>
<p style="text-align: center;"><img alt="\Pr\left[\mathcal{M}_1(C|x\rangle)=f(x)\right]\geq\frac{2}{3}." class="latex" src="https://s0.wp.com/latex.php?latex=%5CPr%5Cleft%5B%5Cmathcal%7BM%7D_1%28C%7Cx%5Crangle%29%3Df%28x%29%5Cright%5D%5Cgeq%5Cfrac%7B2%7D%7B3%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Pr\left[\mathcal{M}_1(C|x\rangle)=f(x)\right]\geq\frac{2}{3}."/></p>
<p>Let <img alt="\mathbf{BQTIME}[s(n)]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BBQTIME%7D%5Bs%28n%29%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{BQTIME}[s(n)]"/> denote the class of boolean functions of quantum circuit complexity at most <img alt="s(n)" class="latex" src="https://s0.wp.com/latex.php?latex=s%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s(n)"/>. The complexity class <img alt="\mathbf{BQP}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BBQP%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{BQP}"/> is defined as <img alt="\cup_{c\in\mathbb{N}}\mathbf{BQTIME}[n^c]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ccup_%7Bc%5Cin%5Cmathbb%7BN%7D%7D%5Cmathbf%7BBQTIME%7D%5Bn%5Ec%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\cup_{c\in\mathbb{N}}\mathbf{BQTIME}[n^c]"/>. It immediately follows from definition that <img alt="\mathbf{P}\subseteq\mathbf{BPP}\subseteq\mathbf{BQP}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BP%7D%5Csubseteq%5Cmathbf%7BBPP%7D%5Csubseteq%5Cmathbf%7BBQP%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{P}\subseteq\mathbf{BPP}\subseteq\mathbf{BQP}"/>.</p>
<h3>Unitary complexity: C(U)</h3>
<p>Let <img alt="U\in\mathbb{C}^{2^n\times2^n}" class="latex" src="https://s0.wp.com/latex.php?latex=U%5Cin%5Cmathbb%7BC%7D%5E%7B2%5En%5Ctimes2%5En%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U\in\mathbb{C}^{2^n\times2^n}"/> be an unitary matrix. Define <img alt="C(U)" class="latex" src="https://s0.wp.com/latex.php?latex=C%28U%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C(U)"/> be the smallest quantum circuit <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/> such that</p>
<p style="text-align: center;"><img alt="\|C-U\|_{\infty}\leq\frac{1}{3}." class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7CC-U%5C%7C_%7B%5Cinfty%7D%5Cleq%5Cfrac%7B1%7D%7B3%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\|C-U\|_{\infty}\leq\frac{1}{3}."/></p>
<p>This unitary complexity can be thought of as a relaxation of the quantum circuit complexity. The reason is that here a unitary matrix <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/> might not compute a boolean function. Thus, proving a lower bound for <img alt="\mathbf{BQSIZE}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BBQSIZE%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{BQSIZE}"/> implies a lower bound for unitary complexity while the converse is not clear. Namely, proving a super-polynomial lower bound for the unitary complexity might be an easier task.</p>
<p>However, no non-trivial<sup>1</sup> lower bound for the unitary complexity is known and there is, unfortunately, no formal <em>barrier result</em> explaining why this is difficult to prove.</p>
<h3>Warm-up: Gottesman-Knill</h3>
<p>We defined quantum circuits above, and we hope you find them exotic – at least start-up investors do. But given how fundamental quantum circuits are to the Harlow-Hayden decoding task, we ask: is it possible to efficiently (classically) simulate a quantum circuit made up of a restricted but non-trivial set of quantum gates? We show below a restricted variant of the popular Gottesman-Knill Theorem:</p>
<blockquote><p><strong>Theorem (Gottesman-Knill).<br/>
</strong><span style="color: #4b4f53; background-color: #ffffff;">1. Given: Clifford circuit <img alt="\mathcal{C}: |\alpha_1\rangle\otimes \cdots \otimes |\alpha_n\rangle \rightarrow \{|0\rangle,|1\rangle\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D%3A+%7C%5Calpha_1%5Crangle%5Cotimes+%5Ccdots+%5Cotimes+%7C%5Calpha_n%5Crangle+%5Crightarrow+%5C%7B%7C0%5Crangle%2C%7C1%5Crangle%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{C}: |\alpha_1\rangle\otimes \cdots \otimes |\alpha_n\rangle \rightarrow \{|0\rangle,|1\rangle\}"/> made up of gates <img alt="\{CNOT, P, H\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7BCNOT%2C+P%2C+H%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{CNOT, P, H\}"/>, where <img alt="\mathcal{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{C}"/> is measured on its first output line.<br/>
</span><span style="color: #4b4f53; background-color: #ffffff;">2.Task: Show that it is possible to (classically) efficiently sample the output distribution of <img alt="\mathcal{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{C}"/>.</span></p></blockquote>
<p><em>Proof:</em></p>
<p><img alt="\Pr(0) = \langle{\psi_0|\mathcal{C}^{\dag}(|0\rangle}\langle0|)\mathcal{C}|\psi_0\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%5CPr%280%29+%3D+%5Clangle%7B%5Cpsi_0%7C%5Cmathcal%7BC%7D%5E%7B%5Cdag%7D%28%7C0%5Crangle%7D%5Clangle0%7C%29%5Cmathcal%7BC%7D%7C%5Cpsi_0%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Pr(0) = \langle{\psi_0|\mathcal{C}^{\dag}(|0\rangle}\langle0|)\mathcal{C}|\psi_0\rangle"/> where <img alt="|\psi_0\rangle = |\alpha_1\rangle\otimes \cdots \otimes |\alpha_n\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi_0%5Crangle+%3D+%7C%5Calpha_1%5Crangle%5Cotimes+%5Ccdots+%5Cotimes+%7C%5Calpha_n%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi_0\rangle = |\alpha_1\rangle\otimes \cdots \otimes |\alpha_n\rangle"/>. Since the projector can be written as <img alt="|0\rangle\langle0|= \frac{I + Z}{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7C0%5Crangle%5Clangle0%7C%3D+%5Cfrac%7BI+%2B+Z%7D%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|0\rangle\langle0|= \frac{I + Z}{2}"/>, we get</p>
<p style="text-align: center;"><img alt="\Pr(0) = \langle\psi_0|\mathcal{C}^{\dag}(\frac{I + Z}{2})\mathcal{C}|\psi_0\rangle =\frac{1}{2}[1 + \langle\psi_0|\mathcal{C}^{\dag}Z_1\mathcal{C}|\psi_0\rangle]" class="latex" src="https://s0.wp.com/latex.php?latex=%5CPr%280%29+%3D+%5Clangle%5Cpsi_0%7C%5Cmathcal%7BC%7D%5E%7B%5Cdag%7D%28%5Cfrac%7BI+%2B+Z%7D%7B2%7D%29%5Cmathcal%7BC%7D%7C%5Cpsi_0%5Crangle+%3D%5Cfrac%7B1%7D%7B2%7D%5B1+%2B+%5Clangle%5Cpsi_0%7C%5Cmathcal%7BC%7D%5E%7B%5Cdag%7DZ_1%5Cmathcal%7BC%7D%7C%5Cpsi_0%5Crangle%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Pr(0) = \langle\psi_0|\mathcal{C}^{\dag}(\frac{I + Z}{2})\mathcal{C}|\psi_0\rangle =\frac{1}{2}[1 + \langle\psi_0|\mathcal{C}^{\dag}Z_1\mathcal{C}|\psi_0\rangle]"/></p>
<p>where <img alt="Z_1 = Z \otimes I\cdots \otimes I" class="latex" src="https://s0.wp.com/latex.php?latex=Z_1+%3D+Z+%5Cotimes+I%5Ccdots+%5Cotimes+I&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Z_1 = Z \otimes I\cdots \otimes I"/> since we only measure the first output line of <img alt="\mathcal{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{C}"/>. At first glance, <img alt="\langle\psi_0|\mathcal{C}^{\dag}Z_1\mathcal{C}|\psi_0\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clangle%5Cpsi_0%7C%5Cmathcal%7BC%7D%5E%7B%5Cdag%7DZ_1%5Cmathcal%7BC%7D%7C%5Cpsi_0%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\langle\psi_0|\mathcal{C}^{\dag}Z_1\mathcal{C}|\psi_0\rangle"/> might look like a monstrous computation to perform since, in general, the operator in the middle is a <img alt="2^n\times 2^n" class="latex" src="https://s0.wp.com/latex.php?latex=2%5En%5Ctimes+2%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^n\times 2^n"/> matrix, so the calculating the inner product would require exponential time classically. However, recognizing that Clifford gates are normalizers of the Pauli Group on <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> qubits, note that <img alt="\mathcal{C}^{\dag}Z_1\mathcal{C} = P_1 \otimes \cdots \otimes P_n" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D%5E%7B%5Cdag%7DZ_1%5Cmathcal%7BC%7D+%3D+P_1+%5Cotimes+%5Ccdots+%5Cotimes+P_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{C}^{\dag}Z_1\mathcal{C} = P_1 \otimes \cdots \otimes P_n"/> where <img alt="P_i" class="latex" src="https://s0.wp.com/latex.php?latex=P_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P_i"/> is some Pauli matrix. It is straightforward to show that these update rules can be computed efficiently. We thus have</p>
<p><img alt="\langle\psi_0|\mathcal{C}^{\dag}Z_1\mathcal{C}|\psi_0\rangle = \langle\psi_0|P_1 \otimes \cdots \otimes P_n|\psi_0\rangle = \prod_{i = 1}^{n} \langle\alpha_i|P_i|\alpha_i\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clangle%5Cpsi_0%7C%5Cmathcal%7BC%7D%5E%7B%5Cdag%7DZ_1%5Cmathcal%7BC%7D%7C%5Cpsi_0%5Crangle+%3D+%5Clangle%5Cpsi_0%7CP_1+%5Cotimes+%5Ccdots+%5Cotimes+P_n%7C%5Cpsi_0%5Crangle+%3D+%5Cprod_%7Bi+%3D+1%7D%5E%7Bn%7D+%5Clangle%5Calpha_i%7CP_i%7C%5Calpha_i%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\langle\psi_0|\mathcal{C}^{\dag}Z_1\mathcal{C}|\psi_0\rangle = \langle\psi_0|P_1 \otimes \cdots \otimes P_n|\psi_0\rangle = \prod_{i = 1}^{n} \langle\alpha_i|P_i|\alpha_i\rangle"/></p>
<p>which is a product of <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> terms. We have thus reduced the (exponentially large) burden of computing a giant <img alt="2^n\times 2^n" class="latex" src="https://s0.wp.com/latex.php?latex=2%5En%5Ctimes+2%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^n\times 2^n"/> matrix<br/>
to computing <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> matrices size <img alt="2\times 2" class="latex" src="https://s0.wp.com/latex.php?latex=2%5Ctimes+2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2\times 2"/>, so we can sample the output distribution efficiently.</p>
<h2>The Firewall paradox and the Harlow-Hayden decoding task</h2>
<h3>Physics to CS</h3>
<div class="wp-caption aligncenter" id="attachment_7468" style="width: 411px;"><img alt="bh" class="alignnone  wp-image-7468" height="417" src="https://windowsontheory.files.wordpress.com/2019/02/bh.png?w=401&amp;h=417" width="401"/><p class="wp-caption-text">Figure 2: A cartoon representing drama (no pun intended) near the Black Hole.</p></div>
<p>All of the black hole physics covered in the previous blog post leads to the moment (we hope) you have been waiting for: a charming resolution of the firewall paradox. Consider the interior of an old, rusty black hole <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> that has radiated away more than half of its matter. Let <img alt="R" class="latex" src="https://s0.wp.com/latex.php?latex=R&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R"/> be the old Hawking radiation, and let <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> represent the fresh Hawking radiation coming right out of the boundary of the Black Hole. Alice is our canonical Ph.D. student who is brave enough to risk her life for physics. Since <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> is a giant information scrambler, we expect to find entanglement between <img alt="R" class="latex" src="https://s0.wp.com/latex.php?latex=R&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R"/> and <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> with overwhelming probability. We know from QFT that there are bell pairs straddling the event horizon of the black hole, so <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> and <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> should be maximally entangled. But this is a problem because <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> cannot be entangled with both <img alt="R" class="latex" src="https://s0.wp.com/latex.php?latex=R&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R"/> and <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/>! The AMPS argument shows that if Alice is able to distill a bell pair between <img alt="R" class="latex" src="https://s0.wp.com/latex.php?latex=R&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R"/> and <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/>, then we should see a firewall of photons at the event horizon, thus violating the no-drama postulate. See Figure 2 for more intuition about the set up. (Note that the <img alt="\cup" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ccup&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\cup"/>‘s represent Bell Pairs, as consistent with the 3D-Quon Language) If we take Black Hole complimentary seriously, then we have an answer! If Alice does not distill a Bell pair between <img alt="R" class="latex" src="https://s0.wp.com/latex.php?latex=R&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R"/> and <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/>, then nothing really happens. However, if Alice does manage to distill the entanglement between <img alt="R" class="latex" src="https://s0.wp.com/latex.php?latex=R&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R"/> and <img alt="B " class="latex" src="https://s0.wp.com/latex.php?latex=B+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B "/>, then we witness a firewall. Is not this answer so very unsatisfactory? Why should the existence of a firewall depend on Alice’s ability to distill entanglement? What is so special about this decoding task?<br/>
The H-H decoding task answers precisely this question. Intuitively, it says that if Alice manages to distill a Bell pair between <img alt="R" class="latex" src="https://s0.wp.com/latex.php?latex=R&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R"/> and <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/>, she could also invert a one-way function, a task we believe is very hard to perform! We conjecture that Alice would take exponential time to decode the entanglement, so the Black Hole would disappear long before Alice even makes a dent in the problem! Before we provide an in depth resolution of the paradox through the H-H decoding, let us (as good philosophers do) briefly review assumptions:</p>
<ol>
<li>The Black Hole <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> can be modelled by a finite collection of qubits, say <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> qubits.</li>
<li>Alice is told that the initial state of <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> is the product basis <img alt="|0\rangle^{\otimes n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7C0%5Crangle%5E%7B%5Cotimes+n%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|0\rangle^{\otimes n}"/>.</li>
<li>Black Hole dynamics are assumed to be unitary, so Alice need not worry about some spooky M-theory that may claim to evolve <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> in a non-unitary fashion.</li>
<li><img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> is a giant information scrambler, represented by some random circuit <img alt="\mathcal{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{C}"/>.</li>
<li>Fresh radiation <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> is a single qubit, w.l.o.g., since any additional qubits could be made a part of <img alt="R" class="latex" src="https://s0.wp.com/latex.php?latex=R&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R"/>.</li>
<li><img alt="|\psi\rangle_{RBH}" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle_%7BRBH%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi\rangle_{RBH}"/> is not Haar-Random. Mini-exercise: prove that if <img alt="|\psi\rangle_{RBH}" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle_%7BRBH%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi\rangle_{RBH}"/> is Haar-Random, our job becomes easy because the circuit complexity of the H-H decoding task grows exponentially with <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>, the size of <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/>.</li>
<li>Alice has access only to circuit <img alt="\mathcal{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{C}"/> and <img alt="R, B" class="latex" src="https://s0.wp.com/latex.php?latex=R%2C+B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R, B"/> but not <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/>. Trivial Mini-exercise: prove that if Alice has access to <img alt="R,B,H, \mathcal{C}" class="latex" src="https://s0.wp.com/latex.php?latex=R%2CB%2CH%2C+%5Cmathcal%7BC%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R,B,H, \mathcal{C}"/>, then it is easy to distill the entanglement between <img alt="R" class="latex" src="https://s0.wp.com/latex.php?latex=R&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R"/> and <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/>.</li>
<li>Alice may be an intellectual Goddess who just knows which unitary to apply, or, more realistically, someone who has exponential time to prepare before the Black Hole forms. Of crucial importance therefore is the circuit complexity of the unitary Alice applies to distill the Bell pair, not so much the process of finding the unitary.</li>
</ol>
<h3>Distilling the B-R Bell pair</h3>
<p>Let us jump into the definition of the <em>Harlow-Hayden decoding task</em>.</p>
<p><strong>Definition (Harlow-Hayden decoding task).</strong><br/>
Given a (polynomial-size) quantum circuit <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/> as input such that <img alt="|\psi\rangle_{RBH}=C|0^n\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle_%7BRBH%7D%3DC%7C0%5En%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi\rangle_{RBH}=C|0^n\rangle"/> where <img alt="R,B,H" class="latex" src="https://s0.wp.com/latex.php?latex=R%2CB%2CH&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R,B,H"/> are three disjoint part of the <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> qubits. Furthermore, it is guaranteed that there exists a unitary operator <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/> acting only on the qubits in <img alt="R" class="latex" src="https://s0.wp.com/latex.php?latex=R&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R"/> such that after applying <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/>, the rightmost bit of <img alt="R" class="latex" src="https://s0.wp.com/latex.php?latex=R&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R"/> and the leftmost bit of <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> forms a bell pair <img alt="\frac{|00\rangle+|11\rangle}{\sqrt{2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B%7C00%5Crangle%2B%7C11%5Crangle%7D%7B%5Csqrt%7B2%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\frac{|00\rangle+|11\rangle}{\sqrt{2}}"/>. The goal of the Harlow-Hayden decoding task is then to find a quantum circuit for such U on the qubits in <img alt="R" class="latex" src="https://s0.wp.com/latex.php?latex=R&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R"/>. See Figure 3.</p>
<div class="wp-caption aligncenter" id="attachment_7474" style="width: 410px;"><img alt="hhd" class="alignnone  wp-image-7474" height="238" src="https://windowsontheory.files.wordpress.com/2019/02/hhd.png?w=400&amp;h=238" width="400"/><p class="wp-caption-text">Figure 3: The Harlow-Hayden decoding task.</p></div>
<p>A necessary condition for the firewall paradox to make sense is that the Harlow-Hayden decoding task should be <em>easy</em>. If Alice cannot distill the entanglement efficiently, the black hole will evaporate before Alice is ready to witness the firewall!</p>
<p>To refute the firewall paradox, Harlow and Hayden proved the following theorem.</p>
<blockquote><p><strong>Theorem 1.<br/>
</strong>If the Harlow-Hayden decoding task can be done in <img alt="\mathbf{BQP/poly}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BBQP%2Fpoly%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{BQP/poly}"/>, then <img alt="\mathbf{SZK}\subseteq\mathbf{BQP/poly}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BSZK%7D%5Csubseteq%5Cmathbf%7BBQP%2Fpoly%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{SZK}\subseteq\mathbf{BQP/poly}"/>.<strong><br/>
</strong></p></blockquote>
<p>We won’t formally define the complexity class <img alt="\mathbf{SZK}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BSZK%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{SZK}"/>. However, it is important to know that the foundation of the lattice-based cryptography, a promising <em>quantum-secure</em> crypto framework, is based on the hardness of some problem in <img alt="\mathbf{SZK}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BSZK%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{SZK}"/>. If <img alt="\mathbf{SZK}\subseteq\mathbf{BQP/poly}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BSZK%7D%5Csubseteq%5Cmathbf%7BBQP%2Fpoly%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{SZK}\subseteq\mathbf{BQP/poly}"/>, then all lattice-based cryptosystems can be broken by polynomial time quantum algorithm!</p>
<p>Instead of a proof for Theorem 1, which is more involved, we give a proof for an improvement of the Harlow-Hayden theorem due to Scott Aaronson. (Aaronson also showed that there might not even exist quantum-secure cryptography if the Harlow-Hayden decoding task can be efficiently solved!)</p>
<h2>Aaronson’s improvement</h2>
<p>In Aaronson’s lecture notes [Aar16], he showed the following improvement on Theorem 1.</p>
<blockquote><p><strong>Theorem 2.</strong><br/>
If the Harlow-Hayden decoding task can be done in <img alt="\mathbf{BQP/poly}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BBQP%2Fpoly%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{BQP/poly}"/>, then quantum-secure injective one-way function does not exist.</p></blockquote>
<p>Before formally defining a one way function, it is paramount to understand its impact: modern cryptosystems are built from some variant of a one-way function. Intuitively, primitives that have the one-way property are (i) easy to implement (<em>e.g.,</em> encrypt) but (ii) hard to invert (<em>e.g.,</em> be attacked). As a result, if there is no quantum-secure injective one-way function, then that is strong evidence that quantum-secure cryptography might not exist.</p>
<p>Now, let us formally define what quantum-secure injective one-way function is and give a formal proof for Theorem 2.</p>
<blockquote><p><strong>Definition 1 (Quantum-secure injective one-way function).<br/>
</strong>A boolean function <img alt="f:\{0,1\}^n\rightarrow\{0,1\}^m" class="latex" src="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D%5En%5Crightarrow%5C%7B0%2C1%5C%7D%5Em&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f:\{0,1\}^n\rightarrow\{0,1\}^m"/> is a quantum-secure injective one-way function if</p>
<ul>
<li><img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> is injective,</li>
<li><img alt="f\in\mathbf{BQP/poly}" class="latex" src="https://s0.wp.com/latex.php?latex=f%5Cin%5Cmathbf%7BBQP%2Fpoly%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f\in\mathbf{BQP/poly}"/>, and</li>
<li>for any polynomial time quantum algorithm <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/></li>
</ul>
<div style="text-align: center;"><img alt="\Pr_{x\in\{0,1\}^n}[f(x)=f(A(f(x)))]\leq\frac{1}{\text{poly}(n)}." class="latex" src="https://s0.wp.com/latex.php?latex=%5CPr_%7Bx%5Cin%5C%7B0%2C1%5C%7D%5En%7D%5Bf%28x%29%3Df%28A%28f%28x%29%29%29%5D%5Cleq%5Cfrac%7B1%7D%7B%5Ctext%7Bpoly%7D%28n%29%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Pr_{x\in\{0,1\}^n}[f(x)=f(A(f(x)))]\leq\frac{1}{\text{poly}(n)}."/></div>
</blockquote>
<p>Note that since <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> is injective, the last condition can actually be phrased as <img alt="x=A(f(x))" class="latex" src="https://s0.wp.com/latex.php?latex=x%3DA%28f%28x%29%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x=A(f(x))"/>. Also, the condition should be read as “on input <img alt="f(x)" class="latex" src="https://s0.wp.com/latex.php?latex=f%28x%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f(x)"/>, the quantum algorithm <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> outputs <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/>”, namely, <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> inverts <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/>.</p>
<div><em>Proof:</em></div>
<div/>
<p>Suppose the Harlow-Hayden decoding task is in <img alt="\mathbf{BQP/poly}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BBQP%2Fpoly%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{BQP/poly}"/>, we are going to show that for any injective <img alt="f:\{0,1\}^n\rightarrow\{0,1\}^m" class="latex" src="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D%5En%5Crightarrow%5C%7B0%2C1%5C%7D%5Em&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f:\{0,1\}^n\rightarrow\{0,1\}^m"/> computable by some polynomial size quantum circuit, there is a polynomial time quantum algorithm that inverts <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/>. Namely, <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> is not a quantum-secure injective one-way function.To get an efficient inverting algorithm for <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/>, let us first prepare a special circuit <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/> from <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> and treat it as an input to the Harlow-Hayden decoding task. The circuit <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/> will simply map the <img alt="|0^{m+2+n}\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7C0%5E%7Bm%2B2%2Bn%7D%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|0^{m+2+n}\rangle"/> to the following state</p>
<p style="text-align: center;"><img alt="\frac{1}{\sqrt{2^{m+2+n}}}\sum_{x\in\{0,1\}^n}\left(|x,0^{m-n},0\rangle_R|0\rangle_B+|f(x),1\rangle_R|1\rangle_B\right)|x\rangle_H." class="latex" src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B%5Csqrt%7B2%5E%7Bm%2B2%2Bn%7D%7D%7D%5Csum_%7Bx%5Cin%5C%7B0%2C1%5C%7D%5En%7D%5Cleft%28%7Cx%2C0%5E%7Bm-n%7D%2C0%5Crangle_R%7C0%5Crangle_B%2B%7Cf%28x%29%2C1%5Crangle_R%7C1%5Crangle_B%5Cright%29%7Cx%5Crangle_H.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\frac{1}{\sqrt{2^{m+2+n}}}\sum_{x\in\{0,1\}^n}\left(|x,0^{m-n},0\rangle_R|0\rangle_B+|f(x),1\rangle_R|1\rangle_B\right)|x\rangle_H."/></p>
<p>Note that as <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> has a polynomial size quantum circuit, the circuit <img alt="\mathcal{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{C}"/> can also be implemented in polynomial size.Next, the easiness of the Harlow-Hayden decoding task guarantees us the existence of a unitary operation <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/> on the qubits in <img alt="R" class="latex" src="https://s0.wp.com/latex.php?latex=R&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R"/> such that for any <img alt="x\in\{0,1\}^n" class="latex" src="https://s0.wp.com/latex.php?latex=x%5Cin%5C%7B0%2C1%5C%7D%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x\in\{0,1\}^n"/></p>
<p style="text-align: center;"><img alt="U\left(\frac{|x,0^{m-n},0\rangle_R+|f(x),1\rangle_R}{\sqrt{2}}\right) = |\phi_x\rangle_R\left(\frac{|0\rangle+|1\rangle}{\sqrt{2}}\right)" class="latex" src="https://s0.wp.com/latex.php?latex=U%5Cleft%28%5Cfrac%7B%7Cx%2C0%5E%7Bm-n%7D%2C0%5Crangle_R%2B%7Cf%28x%29%2C1%5Crangle_R%7D%7B%5Csqrt%7B2%7D%7D%5Cright%29+%3D+%7C%5Cphi_x%5Crangle_R%5Cleft%28%5Cfrac%7B%7C0%5Crangle%2B%7C1%5Crangle%7D%7B%5Csqrt%7B2%7D%7D%5Cright%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U\left(\frac{|x,0^{m-n},0\rangle_R+|f(x),1\rangle_R}{\sqrt{2}}\right) = |\phi_x\rangle_R\left(\frac{|0\rangle+|1\rangle}{\sqrt{2}}\right)"/></p>
<p>for some state <img alt="|\phi_x\rangle_R" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cphi_x%5Crangle_R&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\phi_x\rangle_R"/>. By restricting <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/> on the first <img alt="m" class="latex" src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m"/> qubits, one can get unitary operators <img alt="V" class="latex" src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="V"/> and <img alt="W" class="latex" src="https://s0.wp.com/latex.php?latex=W&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="W"/> such that for all <img alt="x\in\{0,1\}^n" class="latex" src="https://s0.wp.com/latex.php?latex=x%5Cin%5C%7B0%2C1%5C%7D%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x\in\{0,1\}^n"/>,</p>
<p style="text-align: center;"><img alt="V|x,0^{m-n}\rangle=|\phi_x\rangle\text{ and }W|f(x)\rangle=|\phi_x\rangle." class="latex" src="https://s0.wp.com/latex.php?latex=V%7Cx%2C0%5E%7Bm-n%7D%5Crangle%3D%7C%5Cphi_x%5Crangle%5Ctext%7B+and+%7DW%7Cf%28x%29%5Crangle%3D%7C%5Cphi_x%5Crangle.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="V|x,0^{m-n}\rangle=|\phi_x\rangle\text{ and }W|f(x)\rangle=|\phi_x\rangle."/></p>
<p>Thus, <img alt="V^\dagger W" class="latex" src="https://s0.wp.com/latex.php?latex=V%5E%5Cdagger+W&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="V^\dagger W"/> inverts <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> because for any <img alt="x\in\{0,1\}^n" class="latex" src="https://s0.wp.com/latex.php?latex=x%5Cin%5C%7B0%2C1%5C%7D%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x\in\{0,1\}^n"/>,</p>
<p style="text-align: center;"><img alt="V^\dagger W|f(x)\rangle=|x,0^{m-n}\rangle." class="latex" src="https://s0.wp.com/latex.php?latex=V%5E%5Cdagger+W%7Cf%28x%29%5Crangle%3D%7Cx%2C0%5E%7Bm-n%7D%5Crangle.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="V^\dagger W|f(x)\rangle=|x,0^{m-n}\rangle."/></p>
<p>Furthermore, as we are guaranteed that the Harlow-Hayden decoding task is in <img alt="\mathbf{BQP/poly}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BBQP%2Fpoly%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{BQP/poly}"/>, <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/> as well as <img alt="V" class="latex" src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="V"/> and <img alt="W" class="latex" src="https://s0.wp.com/latex.php?latex=W&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="W"/> all have polynomial size quantum circuits! Namely, <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> can be efficiently inverted by a quantum algorithm and thus <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> is not a quantum-secure injective one-way function.</p>
<h2>What’s next?</h2>
<p>The Harlow-Hayden decoding task as well as the Aaronson’s improvement can be interpreted as (strong) evidence that distilling the B-R Bell pair is hard (in the worst-case<sup>2</sup>). One might hope for an <em>average-case</em> hardness for the Harlow-Hayden decoding task and thus infer that <em>most</em> black holes are difficult to distill. However, even if such average-case hardness results existed, physicists would still remain dissatisfied! The foremost grievance a physicist may have is the lack of a coherent causal framework to model reality. That is, what happens if, in the<br/>
very small but non-zero chance, a black hole is easy to distill? Does that mean that a firewall exists in such black hole? How can a unifying theory explain such situation coherently? An ideal theory for theoretical physicists should work for <em>every</em> black hole instead of for <em>most</em> black holes! Second, physicists seem to dislike the abstract, process-theoretic approach undertaken by computer scientists. Here, we have completely ignored talking about the internal dynamics of a black hole or even a full description of its evolving Hilbert space. They would, for instance, like to see a <em>differential equation</em> that captures the difficulty of distilling a black hole throughout its evolution. Resolutions to the firewall paradox or effort towards building a theory of quantum gravity should be somewhat <em>explicit</em> in the sense that one can really instantiate some (toy) examples from the theory and see how the system evolves and examine whether this fits the real experience from the world. In other words, a theory with a black box (<em>i.e.,</em> a complexity conjecture) might not be regarded as a resolution.</p>
<h3>Homework</h3>
<ol>
<li>What powers would Alice need to ensure that she can efficiently distill the B-R bell pair. What if we assume <img alt="\mathbf{P = PSPACE}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BP+%3D+PSPACE%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{P = PSPACE}"/>?</li>
<li>Can we show that the decoding is hard on average, rather than for the worst case?</li>
<li>What are some similar deep connections between black holes and complexity theory?</li>
<li>For people interested in the quantum complexity theory, there are many open problems regarding the quantum circuit complexity: consider the <em>unitary synthesis problem</em><sup>3</sup> proposed by Scott Aaronson [Aar16].</li>
<li>Another interesting problem is connecting the difficulty of proving quantum circuit lower bounds to other complexity problem such as classical circuit lower bounds or cryptographic assumptions.</li>
</ol>
<h2>Footnotes</h2>
<p><sup>1</sup>Non-trivial here means the unitary matrix <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/> is explicit in the sense that given <img alt="i,j\in[2^n]]" class="latex" src="https://s0.wp.com/latex.php?latex=i%2Cj%5Cin%5B2%5En%5D%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i,j\in[2^n]]"/>, one can efficiently compute <img alt="U_{ij}" class="latex" src="https://s0.wp.com/latex.php?latex=U_%7Bij%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U_{ij}"/>.<br/>
<sup>2</sup>Hard in worst-case means that there does not exist efficient algorithm that works on <em>every</em> input. Another hardness notion is hard on <em>average</em>, by which we mean there does not exist efficient algorithm the works for <em>most</em> of the input. Showing average-case hardness is in general a more difficult task than proving worst-case hardness.<br/>
<sup>3</sup>Does the following hold: for any unitary matrix <img alt="U\in\mathbb{C}^{2^n\times2^n}" class="latex" src="https://s0.wp.com/latex.php?latex=U%5Cin%5Cmathbb%7BC%7D%5E%7B2%5En%5Ctimes2%5En%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U\in\mathbb{C}^{2^n\times2^n}"/>, there exists a classical oracle <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> such that <img alt="C^A(U)=n^{O(1)}" class="latex" src="https://s0.wp.com/latex.php?latex=C%5EA%28U%29%3Dn%5E%7BO%281%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C^A(U)=n^{O(1)}"/> where <img alt="C^A(U)" class="latex" src="https://s0.wp.com/latex.php?latex=C%5EA%28U%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C^A(U)"/> is the minimum size of quantum circuit that approximates <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/> with oracle access to <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/>.</p>
<h2>References</h2>
<div>[Aar16] Scott Aaronson. The complexity of quantum states and transformations: from quantum money to black holes. <em>arXiv preprint arXiv:1607.05256</em>, 2016.</div>
<div/>
<div>[HH13] Daniel Harlow and Patrick Hayden. Quantum computation vs. firewalls.</div>
<div><em>Journal of High Energy Physics</em>, 2013(6):85, 2013.</div>
<div/>
<div>[NC02] Michael A Nielsen and Isaac Chuang. Quantum computation and quantum information, 2002.</div></div>
    </content>
    <updated>2019-02-01T05:44:24Z</updated>
    <published>2019-02-01T05:44:24Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Chi-Ning Chou</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2019-02-11T18:20:57Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/01/31/linkage</id>
    <link href="https://11011110.github.io/blog/2019/01/31/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>As usual, follow me on Mathstodon to see these as I post them rather than two weeks later.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>As usual, follow <a href="https://mathstodon.xyz/@11011110">me</a> on <a href="https://mathstodon.xyz">Mathstodon</a> to see these as I post them rather than two weeks later.</p>

<ul>
  <li>
    <p><a href="https://montrealgazette.com/news/organizers-fear-visa-issues-may-push-ai-conferences-to-avoid-canada">Half of the 200 people who needed visas to attend one of the satellite workshops of NeurIPS 2018 in Montreal were unable to get them in time</a> (<a href="https://mathstodon.xyz/@11011110/101429260698057077"/>, <a href="https://www.wired.com/story/canada-welcome">see also</a>), making it more likely that future conferences depending on international attendance will avoid Canada.</p>
  </li>
  <li>
    <p>This is not a cinnamon bun (<a href="https://mathstodon.xyz/@11011110/101438594980314031"/>). It’s actually a 160 million year old fossil snail shell from Madagascar, roughly the size of a large fist (or cinnamon bun). I don’t think it’s particularly rare or valuable; I picked it up because I liked its shape.</p>

    <p style="text-align: center;"><img alt="Fossil gastropod" src="https://www.ics.uci.edu/~eppstein/pix/gastropod/gastropod-m.jpg" style="border-style: solid; border-color: black;"/></p>
  </li>
  <li>
    <p><a href="https://www.ics.uci.edu/~nmamano/knightstour.html">Web site for generating knight’s tours of oversized chessboards with approximately-minimum numbers of bends and crossings</a> (<a href="https://mathstodon.xyz/@11011110/101445919833908876"/>). For background on how it works, see the short paper by Besa, Johnson, Mamano, and Osegueda (all UCI students) in <a href="https://doi.org/10.1007/978-3-030-04414-5"><em>Graph Drawing 2018</em></a> pp. 661–663 – unfortunately I don’t know of a non-paywalled link.</p>
  </li>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/Besse_Day">Besse Beulah Day</a> (<a href="https://mathstodon.xyz/@11011110/101451632049375948"/>), in the 1940s, was one of the first to apply the design of experiments to engineering, after previously having learned to use the technique in forestry. Jacqueline Telford wrote about her briefly in <a href="https://www.jhuapl.edu/techdigest/TD/td2703/telford.pdf">a 2007 survey</a>. Searching for the phrase “Besse Day, working at” finds that Telford’s account of Day’s work has been plagiarized by at least six other works. It’s a form of fame, I guess, to be copied so much.</p>
  </li>
  <li>
    <p><a href="https://theconversation.com/how-one-german-city-developed-and-then-lost-generations-of-math-geniuses-106750">The slow rise and rapid fall of Göttingen as the world capital of mathematics</a> (<a href="https://mathstodon.xyz/@11011110/101457036274744941"/>).</p>
  </li>
  <li>
    <p><a href="https://www.quantamagazine.org/carolina-araujo-is-building-a-network-of-women-in-mathematics-20190122/">An interview with Brazilian mathematician Carolina Araujo</a> (<a href="https://mathstodon.xyz/@11011110/101464602401203371"/>) on the gender gap in mathematics and what still needs to be done to close it.</p>
  </li>
  <li>
    <p><a href="https://doi.org/10.1038/s42256-018-0002-3">If you sample enough times from an unknown distribution over an unknown finite subset of , can you (with high probability) produce a finite set of measure at least ?</a> (<a href="https://mathstodon.xyz/@11011110/101470101768702252"/>, <a href="https://twitter.com/johncarlosbaez/status/1083055024119308288">via</a>, <a href="https://www.metafilter.com/178941/Learnability-can-be-undecidable">via2</a>). Your set does not need to consist only of the points you’ve sampled! You can do it if   for finite  but not otherwise.</p>
  </li>
  <li>
    <p><a href="https://agtb.wordpress.com/2019/01/22/guest-post-like-a-swarm-of-locusts-vijay-vazirani/">Vijay Vazirani on the flocking behavior of theoretical computer scientists</a> (<a href="https://mathstodon.xyz/@11011110/101472666044751626"/>). Vijay’s post also includes an announcement for a semester-long <a href="https://simons.berkeley.edu/programs/market2019">program on online and matching-based market design</a> at the Simons Institute in Berkeley.</p>
  </li>
  <li>
    <p>The view from my desk (<a href="https://mathstodon.xyz/@11011110/101478744747251421"/>). Actually my office has lots of windows with a nice view of a well-used plaza, outdoor coffee shop, trees, and distant mountains. But to see that, I have to get up and go over to one of the windows. If I stay at my desk and look up at the window, I see this interesting geometric pattern instead.</p>

    <p style="text-align: center;"><img alt="UC Irvine's CalIT2 building from Donald Bren Hall, room 4082" src="https://www.ics.uci.edu/~eppstein/pix/deskview/deskview-m.jpg" style="border-style: solid; border-color: black;"/></p>
  </li>
  <li>
    <p><a href="https://scholar.social/@GerardWestendorp/101478161346333486">Gerard Westendorp made a snowdecahedron</a> but <a href="https://scholar.social/@GerardWestendorp/101483814063002454">global warming melted it</a>.</p>
  </li>
  <li>
    <p><a href="http://homepages.gac.edu/~jsiehler/games/blocks-start.html">Online sliding block puzzles</a> (<a href="https://mathstodon.xyz/@jsiehler/101472426764291238"/>) by
Jacob Siehler. The goal is to swap the positions of two colored blocks. Even the easy ones are non-obvious.</p>
  </li>
  <li>
    <p>Cute proof of <a href="https://en.wikipedia.org/wiki/Sperner%27s_theorem">Sperner’s theorem</a> (<a href="https://mathstodon.xyz/@11011110/101495343260074941"/>) from a talk by R. P. Stanley: represent subsets of  by strings of<br/>
 parentheses, “)” in position  if  is in the set, “(” otherwise. In each string, flip the first unmatched “(”, grouping the subsets into chains like (()(( – )()(( – )())( – )())). Each chain touches the middle level once, and any other antichain at most once, so the middle level is the biggest antichain.</p>
  </li>
  <li>
    <p>Two triangles in a convex point set can cross or overlap in eight configurations, colorfully named the taco, mariposa, bat, nested, crossing, ears, swords, and david by “<a href="https://www.combinatorics.org/ojs/index.php/eljc/article/view/v26i1p8">More Turán-Type Theorems for Triangles in Convex Point Sets</a>”, a new paper in <em>Elect. J. Comb.</em> by Aronov, Dujmović, Morin, Ooms, and Schultz (<a href="https://mathstodon.xyz/@11011110/101507914773539844"/>). For 246 of the 256 subsets of configurations, they find near-max families of triangles avoiding the subset. The remaining 8 subsets are equivalent to “tripod packing”, which is less well-understood but the subject of another newly published paper, “<a href="https://doi.org/10.1007/s00454-018-0012-2">New Results on Tripod Packings</a>” (<em>Discrete Comput. Geom.</em>, by Östergård and Pöllänen). The tripod problem has a complicated history of independent rediscovery, not all of which was known to Östergård and Pöllänen, so see the <em>EJC</em> paper for a more thorough survey.</p>
  </li>
  <li>
    <p><a href="https://mathvis.academic.wlu.edu/2017/07/13/creating-a-3d-printable-lorenz-attractor/">Creating a 3D-printable Lorenz attractor</a> (<a href="https://mathstodon.xyz/@11011110/101514403573957983"/>). From Elizabeth Denne’s <a href="https://mathvis.academic.wlu.edu">“Visions in Math” blog</a> which, sadly, seems to have gone on hiatus after publishing this in 2017.</p>
  </li>
</ul></div>
    </content>
    <updated>2019-01-31T21:27:00Z</updated>
    <published>2019-01-31T21:27:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-02-10T07:57:17Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-5538403199779655367</id>
    <link href="https://blog.computationalcomplexity.org/feeds/5538403199779655367/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/01/phish-before-turkey.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/5538403199779655367" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/5538403199779655367" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/01/phish-before-turkey.html" rel="alternate" type="text/html"/>
    <title>Phish Before Turkey</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">The Chronicle of Higher Education recently published a story <a href="https://www.chronicle.com/article/Phishing-Scheme-Targets/245535">Phishing Scheme Targets Professors’ Desire to Please Their Deans — All for $500 in Gift Cards</a>. The same thing happened to me last fall.<br/>
<br/>
Twas the day before Thanksgiving and an email went out to most of the faculty in my department.<br/>
<blockquote class="tr_bq">
<b>From: </b>Lance Fortnow &lt;lancefortnow@yahoo.com&gt;<br/>
<b>Sent: </b>Wednesday, November 21, 2018 1:45 PM<br/>
<b>To: </b>[name deleted]<br/>
<b>Subject:</b> </blockquote>
<blockquote class="tr_bq">
Hello,are you available?</blockquote>
At the time I was in New Jersey visiting family. lancefortnow@yahoo.com is not my email. I do own fortnow@yahoo.com but don't email there, I rarely check it.<br/>
<br/>
Some faculty checked with me to see if this is real. One faculty called me to see what I wanted. Once I found out what was happening I sent a message to my entire faculty to ignore those emails.<br/>
<br/>
Some faculty did reply to see what I want. The response:<br/>
<blockquote class="tr_bq">
i need you to help me get an Amazon gifts card from the store,i will reimburse you back when i get to the office.</blockquote>
One of our security faculty decided to follow up and replied "Sure! Let me get them for you. Could you provide more more information? e.g., amount and #cards. I can bring them on Monday." The reply:<br/>
<blockquote class="tr_bq">
The amount i want is $100 each in two (2) piece so that will make it a total of $200 l'll be reimbursing back to you.i need physical cards which you are going to get from the store. When you get them,just scratch it and take a picture of them and attach it to the email then send it to me here ok</blockquote>
<div>
He went a few more rounds before the phisher just stopped responding.</div>
<div>
<br/></div>
<div>
A week later, a different faculty member came to my office and said I wanted to see him but he's been out of town. I said it was nice to see him but I didn't ask to talk to him and we figured out the confusion was the phishing email.</div>
<div>
<br/></div>
<div>
Someone went through the trouble of creating a fake email address in my name, looking up the email addresses of the faculty in the department and individually emailing each of them, without realizing computer science professors won't fall for a gift card phishing attack. Or at least none of them admitted falling for it.</div></div>
    </content>
    <updated>2019-01-31T16:46:00Z</updated>
    <published>2019-01-31T16:46:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>https://plus.google.com/101693130490639305932</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>https://plus.google.com/101693130490639305932</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-02-11T10:40:07Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/013</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/013" rel="alternate" type="text/html"/>
    <title>TR19-013 |  CSPs with Global Modular Constraints: Algorithms and Hardness via Polynomial Representations | 

	Joshua Brakensiek, 

	Sivakanth Gopi, 

	Venkatesan Guruswami</title>
    <summary>We study the complexity of Boolean constraint satisfaction problems (CSPs) when the assignment must have Hamming weight in some congruence class modulo $M$, for various choices of the modulus $M$. Due to the known classification of tractable Boolean CSPs, this mainly reduces to the study of three cases: 2SAT, HornSAT, and LIN-MOD2 (linear equations mod $2$). We classify the moduli $M$ for which these respective problems are polynomial time solvable, and when they are not (assuming the ETH). Our study reveals that this modular constraint lends a surprising richness to these classic, well-studied problems, with interesting broader connections to complexity theory and coding theory. The HornSAT case is connected to the covering complexity of polynomials representing the NAND function mod $M$. The LIN-MOD2 case is tied to the sparsity of polynomials representing the OR function mod $M$, which in turn has connections to modular weight distribution properties of linear codes and locally decodable codes. In both cases, the analysis of our algorithm as well as the hardness reduction rely on these polynomial representations, highlighting an interesting algebraic common ground between hard cases for our algorithms and the gadgets which show hardness. These new complexity measures of polynomial representations merit further study.

The inspiration for our study comes from a recent work by Nägele, Sudakov, and Zenklusen on submodular minimization with a global congruence constraint. Our algorithm for HornSAT has strong similarities to their algorithm, and in particular identical kind of set systems arise in both cases. Our connection to polynomial representations leads to a simpler analysis of such set systems, and also sheds light on (but does not resolve) the complexity of submodular minimization with a congruency requirement modulo a composite $M$.</summary>
    <updated>2019-01-31T15:15:39Z</updated>
    <published>2019-01-31T15:15:39Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-02-11T18:20:33Z</updated>
    </source>
  </entry>
</feed>
