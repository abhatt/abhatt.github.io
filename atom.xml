<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2020-07-02T23:31:08Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=7759</id>
    <link href="https://windowsontheory.org/2020/07/02/crowdsourcing-masters-program/" rel="alternate" type="text/html"/>
    <title>Crowdsourcing Masters program</title>
    <summary>Going directly from undergraduate to Ph.D can be a good idea for many students interested in research, but it’s not the only route or the best choice for everyone. As I wrote before, for students that discovered their interest in theoretical CS late in their undergrad, or perhaps after they graduated, a research Masters, can […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Going directly from undergraduate to Ph.D can be a good idea for many students interested in research, but it’s not the only route or the best choice for everyone.</p>



<p>As <a href="https://windowsontheory.org/2018/02/20/research-masters/">I wrote before</a>, for students that discovered their interest in theoretical CS late in their undergrad, or perhaps after they graduated, a research Masters, can be a great option. This is particularly the case if the program is funded (i.e., students get a stipend and don’t need to pay tuition). Such programs are not common in the U.S., but there are some excellent choices around the world.</p>



<p>Since (as far as I know) there is no single source listing such programs, I thought a crowdsourced Google spreadsheet might be useful and so created one here: <a href="http://tiny.cc/tcsmasters" rel="nofollow">http://tiny.cc/tcsmasters</a></p>



<p>If you know of more places, please fill out this form: <a href="https://forms.gle/qfnbEZYYYDtFCDpx9" rel="nofollow">https://forms.gle/qfnbEZYYYDtFCDpx9</a> </p></div>
    </content>
    <updated>2020-07-02T19:26:22Z</updated>
    <published>2020-07-02T19:26:22Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2020-07-02T23:29:54Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.00533</id>
    <link href="http://arxiv.org/abs/2007.00533" rel="alternate" type="text/html"/>
    <title>Partial Recovery in the Graph Alignment Problem</title>
    <feedworld_mtime>1593648000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hall:Georgina.html">Georgina Hall</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Massouli=eacute=:Laurent.html">Laurent Massoulié</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.00533">PDF</a><br/><b>Abstract: </b>In this paper, we consider the graph alignment problem, which is the problem
of recovering, given two graphs, a one-to-one mapping between nodes that
maximizes edge overlap. This problem can be viewed as a noisy version of the
well-known graph isomorphism problem and appears in many applications,
including social network deanonymization and cellular biology. Our focus here
is on partial recovery, i.e., we look for a one-to-one mapping which is correct
on a fraction of the nodes of the graph rather than on all of them, and we
assume that the two input graphs to the problem are correlated Erd\"os-R\'enyi
graphs of parameters $(n,q,s)$. Our main contribution is then to give necessary
and sufficient conditions on $(n,q,s)$ under which partial recovery is possible
with high probability as the number of nodes $n$ goes to infinity. These
conditions are compact, easily interpretable, and cover a vast majority of the
parameter space.
</p></div>
    </summary>
    <updated>2020-07-02T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-07-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.00512</id>
    <link href="http://arxiv.org/abs/2007.00512" rel="alternate" type="text/html"/>
    <title>Factoring Polynomials over Finite Fields with Linear Galois Groups: An Additive Combinatorics Approach</title>
    <feedworld_mtime>1593648000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Guo:Zeyu.html">Zeyu Guo</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.00512">PDF</a><br/><b>Abstract: </b>Let $\tilde{f}(X)\in\mathbb{Z}[X]$ be a degree-$n$ polynomial such that
$f(X):=\tilde{f}(X)\bmod p$ factorizes into $n$ distinct linear factors over
$\mathbb{F}_p$. We study the problem of deterministically factoring $f(X)$ over
$\mathbb{F}_p$ given $\tilde{f}(X)$. Under the generalized Riemann hypothesis
(GRH), we give an improved deterministic algorithm that computes the complete
factorization of $f(X)$ in the case that the Galois group of $\tilde{f}(X)$ is
(permutation isomorphic to) a linear group $G\leq \mathrm{GL}(V)$ on the set
$S$ of roots of $\tilde{f}(X)$, where $V$ is a finite-dimensional vector space
over a finite field $\mathbb{F}$ and $S$ is identified with a subset of $V$. In
particular, when $|S|=|V|^{\Omega(1)}$, the algorithm runs in time polynomial
in $n^{\log n/(\log\log\log\log n)^{1/3}}$ and the size of the input, improving
Evdokimov's algorithm. Our result also applies to a general Galois group $G$
when combined with a recent algorithm of the author.
</p>
<p>To prove our main result, we introduce a family of objects called linear
$m$-schemes and reduce the problem of factoring $f(X)$ to a combinatorial
problem about these objects. We then apply techniques from additive
combinatorics to obtain an improved bound. Our techniques may be of independent
interest.
</p></div>
    </summary>
    <updated>2020-07-02T23:20:30Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-07-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.00445</id>
    <link href="http://arxiv.org/abs/2007.00445" rel="alternate" type="text/html"/>
    <title>Error Correcting Codes, finding polynomials of bounded degree agreeing on a dense fraction of a set of points</title>
    <feedworld_mtime>1593648000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Priyank Deshpande <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.00445">PDF</a><br/><b>Abstract: </b>Here we present some revised arguments to a randomized algorithm proposed by
Sudan to find the polynomials of bounded degree agreeing on a dense fraction of
a set of points in $\mathbb{F}^{2}$ for some field $\mathbb{F}$.
</p></div>
    </summary>
    <updated>2020-07-02T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-07-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.00413</id>
    <link href="http://arxiv.org/abs/2007.00413" rel="alternate" type="text/html"/>
    <title>Multi-Axis Support-Free Printing of Freeform Parts with Lattice Infill Structures</title>
    <feedworld_mtime>1593648000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Yamin.html">Yamin Li</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tang:Kai.html">Kai Tang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/He:Dong.html">Dong He</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Xiangyu.html">Xiangyu Wang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.00413">PDF</a><br/><b>Abstract: </b>In additive manufacturing, infill structures are commonly used to reduce the
weight and cost of a solid part. Currently, most infill structure generation
methods are based on the conventional 2.5-axis printing configuration, which,
although able to satisfy the self-supporting condition on the infills, suffer
from the well-known stair-case effect on the finished surface and the need of
extensive support for overhang features. In this paper, based on the emerging
continuous multi-axis printing configuration, we present a new lattice infill
structure generation algorithm, which is able to achieve both the
self-supporting condition for the infills and the support-free requirement at
the boundary surface of the part. The algorithm critically relies on the use of
three mutually orthogonal geodesic distance fields that are embedded in the
tetrahedral mesh of the solid model. The intersection between the iso-geodesic
distance surfaces of these three geodesic distance fields naturally forms the
desired lattice of infill structure, while the density of the infills can be
conveniently controlled by adjusting the iso-values. The lattice infill pattern
in each curved slicing layer is trimmed to conform to an Eulerian graph so to
generate a continuous printing path, which can effectively reduce the nozzle
retractions during the printing process. In addition, to cater to the
collision-free requirement and to improve the printing efficiency, we also
propose a printing sequence optimization algorithm for determining a
collision-free order of printing of the connected lattice infills, which seeks
to reduce the air-move length of the nozzle. Ample experiments in both computer
simulation and physical printing are performed, and the results give a
preliminary confirmation of the advantages of our methodology.
</p></div>
    </summary>
    <updated>2020-07-02T23:21:21Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-07-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.00373</id>
    <link href="http://arxiv.org/abs/2007.00373" rel="alternate" type="text/html"/>
    <title>Can Global Optimization Strategy Outperform Myopic Strategy for Bayesian Parameter Estimation?</title>
    <feedworld_mtime>1593648000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhu:Juanping.html">Juanping Zhu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gu:Hairong.html">Hairong Gu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.00373">PDF</a><br/><b>Abstract: </b>Bayesian adaptive inference is widely used in psychophysics to estimate
psychometric parameters. Most applications used myopic one-step ahead strategy
which only optimizes the immediate utility. The widely held expectation is that
global optimization strategies that explicitly optimize over some horizon can
largely improve the performance of the myopic strategy. With limited studies
that compared myopic and global strategies, the expectation was not challenged
and researchers are still investing heavily to achieve global optimization. Is
that really worthwhile? This paper provides a discouraging answer based on
experimental simulations comparing the performance improvement and computation
burden between global and myopic strategies in parameter estimation of multiple
models. The finding is that the added horizon in global strategies has
negligible contributions to the improvement of optimal global utility other
than the most immediate next steps (of myopic strategy). Mathematical recursion
is derived to prove that the contribution of utility improvement of each added
horizon step diminishes fast as that step moves further into the future.
</p></div>
    </summary>
    <updated>2020-07-02T23:20:37Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-07-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.00323</id>
    <link href="http://arxiv.org/abs/2007.00323" rel="alternate" type="text/html"/>
    <title>Future Urban Scenes Generation Through Vehicles Synthesis</title>
    <feedworld_mtime>1593648000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Simoni:Alessandro.html">Alessandro Simoni</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bergamini:Luca.html">Luca Bergamini</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Palazzi:Andrea.html">Andrea Palazzi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Calderara:Simone.html">Simone Calderara</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cucchiara:Rita.html">Rita Cucchiara</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.00323">PDF</a><br/><b>Abstract: </b>In this work we propose a deep learning pipeline to predict the visual future
appearance of an urban scene. Despite recent advances, generating the entire
scene in an end-to-end fashion is still far from being achieved. Instead, here
we follow a two stages approach, where interpretable information is included in
the loop and each actor is modelled independently. We leverage a per-object
novel view synthesis paradigm; i.e. generating a synthetic representation of an
object undergoing a geometrical roto-translation in the 3D space. Our model can
be easily conditioned with constraints (e.g. input trajectories) provided by
state-of-the-art tracking methods or by the user itself. This allows us to
generate a set of diverse realistic futures starting from the same input in a
multi-modal fashion. We visually and quantitatively show the superiority of
this approach over traditional end-to-end scene-generation methods on CityFlow,
a challenging real world dataset.
</p></div>
    </summary>
    <updated>2020-07-02T23:23:33Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-07-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.00204</id>
    <link href="http://arxiv.org/abs/2007.00204" rel="alternate" type="text/html"/>
    <title>Learning an arbitrary mixture of two multinomial logits</title>
    <feedworld_mtime>1593648000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tang:Wenpin.html">Wenpin Tang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.00204">PDF</a><br/><b>Abstract: </b>In this paper, we consider mixtures of multinomial logistic models (MNL),
which are known to $\epsilon$-approximate any random utility model. Despite its
long history and broad use, rigorous results are only available for learning a
uniform mixture of two MNLs. Continuing this line of research, we study the
problem of learning an arbitrary mixture of two MNLs. We show that the
identifiability of the mixture models may only fail on an algebraic variety of
Lebesgue measure $0$, implying that all existing algorithms apply in the almost
sure sense. This is done by reducing the problem of learning a mixture of two
MNLs to the problem of solving a system of univariate quartic equations. As a
byproduct, we derive an algorithm to learn any mixture of two MNLs in linear
time provided that a mixture of two MNLs over some finite universe is
identifiable. Several numerical experiments and conjectures are also presented.
</p></div>
    </summary>
    <updated>2020-07-02T23:20:48Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-07-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.00062</id>
    <link href="http://arxiv.org/abs/2007.00062" rel="alternate" type="text/html"/>
    <title>Deep Feature Space: A Geometrical Perspective</title>
    <feedworld_mtime>1593648000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kansizoglou:Ioannis.html">Ioannis Kansizoglou</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bampis:Loukas.html">Loukas Bampis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gasteratos:Antonios.html">Antonios Gasteratos</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.00062">PDF</a><br/><b>Abstract: </b>One of the most prominent attributes of Neural Networks (NNs) constitutes
their capability of learning to extract robust and descriptive features from
high dimensional data, like images. Hence, such an ability renders their
exploitation as feature extractors particularly frequent in an abundant of
modern reasoning systems. Their application scope mainly includes complex
cascade tasks, like multi-modal recognition and deep Reinforcement Learning
(RL). However, NNs induce implicit biases that are difficult to avoid or to
deal with and are not met in traditional image descriptors. Moreover, the lack
of knowledge for describing the intra-layer properties -- and thus their
general behavior -- restricts the further applicability of the extracted
features. With the paper at hand, a novel way of visualizing and understanding
the vector space before the NNs' output layer is presented, aiming to enlighten
the deep feature vectors' properties under classification tasks. Main attention
is paid to the nature of overfitting in the feature space and its adverse
effect on further exploitation. We present the findings that can be derived
from our model's formulation, and we evaluate them on realistic recognition
scenarios, proving its prominence by improving the obtained results.
</p></div>
    </summary>
    <updated>2020-07-02T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-07-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/06/30/postdoc-at-university-of-oxford-apply-by-september-11-2020/</id>
    <link href="https://cstheory-jobs.org/2020/06/30/postdoc-at-university-of-oxford-apply-by-september-11-2020/" rel="alternate" type="text/html"/>
    <title>postdoc at University of Oxford (apply by September 11, 2020)</title>
    <summary>All Souls College Oxford are advertising a 5 year postdoctoral research fellowship in theoretical computer science, with a tentative start date 1 Oct 2021. This is an exceptional opportunity for a first-rate early career researcher in theoretical computer science. Website: https://www.asc.ox.ac.uk/post-doctoral-research-fellowships-2020-further-particulars Email: pdrf.admin@all-souls.ox.ac.uk</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>All Souls College Oxford are advertising a 5 year postdoctoral research fellowship in theoretical computer science, with a tentative start date 1 Oct 2021. This is an exceptional opportunity for a first-rate early career researcher in theoretical computer science.</p>
<p>Website: <a href="https://www.asc.ox.ac.uk/post-doctoral-research-fellowships-2020-further-particulars">https://www.asc.ox.ac.uk/post-doctoral-research-fellowships-2020-further-particulars</a><br/>
Email: pdrf.admin@all-souls.ox.ac.uk</p></div>
    </content>
    <updated>2020-06-30T16:27:02Z</updated>
    <published>2020-06-30T16:27:02Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-07-02T23:29:39Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2020/06/30/linkage</id>
    <link href="https://11011110.github.io/blog/2020/06/30/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>The five bridges puzzle (). Sort of like the bridges of Königsberg, but stochastic. A cute puzzle with a connection to percolation theory and connection games.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><ul>
  <li>
    <p><a href="https://scilogs.spektrum.de/hlf/the-five-bridges-puzzle/">The five bridges puzzle</a> (<a href="https://mathstodon.xyz/@11011110/104357604444143899"/>). Sort of like the bridges of Königsberg, but stochastic. A cute puzzle with a connection to percolation theory and connection games.</p>
  </li>
  <li>
    <p>Dubious journal publisher MDPI provides special-issue editors with some number of no-publication-charge slots, but requires that priority for these slots be given to first-world scholars, because they are the ones with “more abundant scientific research resources” (read: funds to pay publication charges). This didn’t sit well with three environmental health failure researchers, who <a href="https://retractionwatch.com/2020/06/16/failure-fails-as-publisher-privileges-the-privileged/">resigned their guest editorship over it</a> (<a href="https://mathstodon.xyz/@11011110/104363585936972806"/>, <a href="https://wash.leeds.ac.uk/what-the-f-how-we-failed-to-publish-a-journal-special-issue-on-failures/">see also</a>).</p>
  </li>
  <li>
    <p>On today’s edition of <a href="https://11011110.github.io/blog/2018/06/24/la-maddalena-non-reuleaux.html">not the Reuleaux triangle</a>, we have <a href="https://twitter.com/Nukaq/status/1273803547574972416">the logo of Whale Cove, Nunavut</a> (<a href="https://mathstodon.xyz/@11011110/104368587916436396"/>, <a href="https://www.metafilter.com/187552/Nunavut-Aesthetics">via</a>).  The sides of the triangle are straighter than a Reuleaux triangle would be, and its corners are slightly narrower than equilateral. Cool logo, though.</p>

    <p style="text-align: center;"><img alt="Logo of Whale Cove, Nunavut" src="https://11011110.github.io/blog/assets/2020/beluga-reuleaux.png"/></p>
  </li>
  <li>
    <p><a href="https://computerhistory.org/blog/discovering-dennis-ritchies-lost-dissertation/">Discovering Dennis Ritchie’s lost dissertation</a> (<a href="https://mathstodon.xyz/@11011110/104375200069651123"/>, <a href="https://news.ycombinator.com/item?id=23582070">via</a>). Ritchie’s doctoral committee signed off in 1968, but the Harvard Library wanted a bound copy and he was unwilling to pay the binding costs so he never officially received his Ph.D. According to the post, the thesis defines a simple model of computation characterizing primitive recursion, within which one can prove that the complexity and growth rates of primitive recursive functions are equal.</p>
  </li>
  <li>
    <p><a href="https://mathstodon.xyz/@tpfto/104376254903441351">J.M. redraws the xkcd golden spiral in Mathematica</a>. The thing that annoys me about it is the non-monotonic curvature, but that appears to be unavoidable.</p>
  </li>
  <li>
    <p><a href="https://www.youtube.com/playlist?list=PLn0nrSd4xjjadfcMd5xvmJ_GNSLDi1ATn">Playlist of talk videos from this year’s Symposium on Theory of Computing</a> (<a href="https://mathstodon.xyz/@11011110/104389387469883738"/>).</p>
  </li>
  <li>
    <p><a href="https://www.youtube.com/watch?v=wujEE3PRVUo">Video on the projective geometry of sidewalk trompe-l’oeil chalk art</a> (<a href="https://mathstodon.xyz/@11011110/104397742913356589"/>), and <a href="https://www.youtube.com/watch?v=L95cNBEfi5I">another one with less mathematics, more flying pigs and cute space aliens</a>.</p>
  </li>
  <li>
    <p><a href="https://www.makeuseof.com/tag/reduce-video-file-size-without-sacrificing-quality/">Some advice I needed on how to reduce video file size</a> (<a href="https://mathstodon.xyz/@11011110/104402114011362297"/>). Their suggestion of Handbrake worked well on its default settings and easily reached the file size I needed to reach, without sacrificing quality. (This was for a video of voice over still slides, so it should have been easy to compress, but iMovie couldn’t do it.)</p>
  </li>
  <li>
    <p><a href="https://blogs.ams.org/beyondreviews/2020/06/29/the-mathematics-genealogy-project-moves-to-the-cloud/">The Mathematics Genealogy Project rises into the clouds</a> (<a href="https://mathstodon.xyz/@11011110/104407629370705734"/>) like a phoenix from the flames of its dead former server. Or maybe not quite as poetically as that, but I use this resource daily in Wikipedia biography editing, so it’s a relief to learn that it’s back after its recent outage.</p>
  </li>
  <li>
    <p><a href="https://dl.acm.org/doi/10.1145/3357713.3384232">QCSP monsters and the demise of the Chen conjecture</a> (<a href="https://mathstodon.xyz/@11011110/104414859746330563"/>, <a href="https://www.youtube.com/watch?v=c2HjFlcTjQ0">talk video</a>). In STOC’20, Zhuk and Martin show that <a href="https://en.wikipedia.org/wiki/Schaefer%27s_dichotomy_theorem">dichotomy for constraint satisfaction</a> gets messier for quantified CSP. Chen conjectured that QCSP problems are either in NP or PSPACE-complete, but this new paper shows that coNP-completeness can happen for 3 elements and more elements lead to even more classes. Relatedly, <a href="http://eatcs.org/index.php/component/content/article/1-news/2849-the-eatcs-bestows-the-presburger-award-2020">Zhuk just won the Presburger Award</a>.</p>
  </li>
  <li>
    <p>I learned while writing <a href="https://en.wikipedia.org/wiki/Doyle_spiral">a Wikipedia article on Doyle spirals</a> (<a href="https://mathstodon.xyz/@11011110/104418935123493700"/>) that although the pure-mathematics work in this area dates to Coxeter in 1968 and the work of Thurston and his followers in the 1980s and 1990s, the use of spiral patterns of tangent circles to model plant growth can be traced back much earlier, to Gerrit van Iterson in 1907. The image below, which I used as the lead for the article, is an illustration of phylogeny from <a href="https://archive.org/details/popularsciencemo79newy/page/450/mode/2up">a 1911 <em>Popular Science</em> story about mathematical patterns in nature</a>.</p>

    <p style="text-align: center;"><img alt="Doyle spiral from _Popular Science_, 1911" src="https://11011110.github.io/blog/assets/2020/Doyle.png"/></p>
  </li>
  <li>
    <p><a href="https://www.lms.ac.uk/news-entry/26062020-1657/lms-prize-winners-2020">This year’s London Math Soc. prizewinners</a> (<a href="https://mathstodon.xyz/@11011110/104431647996227722"/>, <a href="https://twitter.com/hollykrieger/status/1276590144628416512">via</a>). For some reason they keep the <a href="https://www.lms.ac.uk/prizes/louisbachelierprize">Louis Bachelier Prize in a separate listing</a>. These results have already led me to add to Wikipedia brief articles on <a href="https://en.wikipedia.org/wiki/Maria_Bruna">Maria Bruna</a> (a Whitehead Prize winner) and <a href="https://en.wikipedia.org/wiki/Pauline_Barrieu">Pauline Barrieu</a> (Bachelier 2018).</p>
  </li>
  <li>
    <p><a href="https://www.chronicle.com/article/georgia-s-top-down/249095">A power struggle between the Georgia state university system and state government blocks Georgia Tech and other campuses from enacting any coronavirus safety rules</a> (<a href="https://mathstodon.xyz/@11011110/104435200227063842"/>).</p>
  </li>
</ul></div>
    </content>
    <updated>2020-06-30T16:06:00Z</updated>
    <published>2020-06-30T16:06:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2020-06-30T23:34:57Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/097</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/097" rel="alternate" type="text/html"/>
    <title>TR20-097 |  6-Uniform Maker-Breaker Game Is PSPACE-Complete | 

	Md Lutfar Rahman, 

	Thomas Watson</title>
    <summary>In a STOC 1976 paper, Schaefer proved that it is PSPACE-complete to determine the winner of the so-called Maker-Breaker game on a given set system, even when every set has size at most 11. Since then, there has been no improvement on this result. We prove that the game remains PSPACE-complete even when every set has size 6.</summary>
    <updated>2020-06-30T15:23:11Z</updated>
    <published>2020-06-30T15:23:11Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-07-02T23:29:15Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://kamathematics.wordpress.com/?p=188</id>
    <link href="https://kamathematics.wordpress.com/2020/06/30/virtual-stoc-2020-behind-the-screens/" rel="alternate" type="text/html"/>
    <title>Virtual STOC 2020 – Behind the Screens</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">In order to assist organizers of other virtual conferences, the general chairs of STOC 2020 (myself, Konstantin Makarychev, Yury Makarychev and Madhur Tulsiani, with input from PC chair Julia Chuzhoy) wrote a detailed document describing the design and execution of the conference. I personally felt the conference went about as well as it could have … <a class="more-link" href="https://kamathematics.wordpress.com/2020/06/30/virtual-stoc-2020-behind-the-screens/">Continue reading<span class="screen-reader-text"> "Virtual STOC 2020 – Behind the Screens"</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>In order to assist organizers of other virtual conferences, the general chairs of STOC 2020 (myself, Konstantin Makarychev, Yury Makarychev and Madhur Tulsiani, with input from PC chair Julia Chuzhoy) wrote a detailed document describing the design and execution of the conference. I personally felt the conference went about as well as it could have gone, and despite many moving parts, there were minimal technical difficulties.</p>



<p>The guide is available here: <a href="https://docs.google.com/document/d/1nzyvfdsXLzqYXxxdjw1y_OHAYwGolHCZUkRVmlxG9BE/edit?ts=5efa758c" rel="noreferrer noopener" target="_blank">Virtual STOC 2020 – Behind the Screens</a>.</p>



<p>If you have any questions or comments, feel free to comment below, or join in the conversation on <a href="https://twitter.com/thegautamkamath/status/1277959908168695808">Twitter</a>.</p></div>
    </content>
    <updated>2020-06-30T13:13:16Z</updated>
    <published>2020-06-30T13:13:16Z</published>
    <category term="Events"/>
    <author>
      <name>Gautam</name>
    </author>
    <source>
      <id>https://kamathematics.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://kamathematics.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://kamathematics.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://kamathematics.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://kamathematics.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Kamathematics</title>
      <updated>2020-07-02T23:31:03Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4886</id>
    <link href="https://www.scottaaronson.com/blog/?p=4886" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4886#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4886" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">David Poulin</title>
    <summary xml:lang="en-US">2020 sucks. Yesterday I learned that David Poulin, a creative and widely-beloved quantum computing and information theorist, has died at age 43, of an aggressive brain cancer. After studying under many of the field’s legends—Gilles Brassard, Wojciech Zurek, Ray Laflamme, Gerard Milburn, John Preskill—David became a professor at the University of Sherbrooke in Quebec. There […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><div class="wp-block-image"><figure class="aligncenter"><img alt="100+ &quot;Dave Poulin&quot; profiles | LinkedIn" src="https://media-exp1.licdn.com/dms/image/C4E03AQG9DmvmxhU3RA/profile-displayphoto-shrink_200_200/0?e=1597276800&amp;v=beta&amp;t=wav_nmh_CgU1IgzEbc89IQlfL5fNg0k6lcxs9_F_6qk"/></figure></div>



<p>2020 sucks.</p>



<p>Yesterday I learned that <a href="https://www.cifar.ca/cifarnews/2020/06/18/a-quantum-festschrift-for-david-poulin">David Poulin</a>, a creative and widely-beloved quantum computing and information theorist, has died at age 43, of an aggressive brain cancer.  After studying under many of the field’s legends—Gilles Brassard, Wojciech Zurek, Ray Laflamme, Gerard Milburn, John Preskill—David became a professor at the University of Sherbrooke in Quebec.  There he played a leading role in CIFAR (the Canadian Institute For Advanced Research), eventually co-directing its quantum information science program with Aephraim Steinberg.  Just this fall (!), David moved to Microsoft Research to start a new phase of his career.  He’s survived by a large family.</p>



<p>While I can’t claim any deep knowledge of David’s work—he and I pursued very different problems—it seems appropriate to mention some of his best-known contributions.  With David Kribs, Ray Laflamme, and Maia Lesosky, he <a href="https://arxiv.org/abs/quant-ph/0504189">introduced</a> the formalism of operator quantum error correction, and made many other contributions to the theory of quantum error-correction and fault-tolerance (including the estimation of thresholds).  He and coauthors <a href="https://www.nature.com/articles/ncomms1147">showed</a> in a <em>Nature</em> paper how to do quantum state tomography on 1D matrix product states efficiently.  With Pavithran Iyer, he <a href="https://arxiv.org/abs/1310.3235">proved</a> that optimal decoding of stabilizer codes is #P-hard.</p>



<p>And if none of that makes a sufficient impression on <em>Shtetl-Optimized</em> readers: well, back in 2013, when D-Wave was claiming to have achieved huge quantum speedups, David Poulin was one of the few experts willing to take a clear skeptical stance in public (including right in my comment section—see <a href="https://www.scottaaronson.com/blog/?p=1400#comment-79596">here</a> for example).</p>



<p>I vividly remember being officemates with David back in 2003, at the Perimeter Institute in Waterloo—before Perimeter had its sleek black building, when it still operated out of a converted tavern.  (My and David’s office was in the basement, reached via a narrow staircase.)  David liked to tease me: for example, if I found him in conversation with someone else and asked what it was about, he’d say, “oh, nothing to do with computational efficiency, no reason for you to care.”  (And yet, much of David’s work ultimately <em>would</em> have to do with computational efficiency.)</p>



<p>David was taken way too soon and will be missed by everyone who knew him.  Feel free to share David stories in the comments.</p></div>
    </content>
    <updated>2020-06-30T04:47:23Z</updated>
    <published>2020-06-30T04:47:23Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Announcements"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Quantum"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2020-06-30T04:47:23Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=17244</id>
    <link href="https://rjlipton.wordpress.com/2020/06/29/taking-a-problem-down-a-peg/" rel="alternate" type="text/html"/>
    <title>Taking a Problem Down a Peg</title>
    <summary>By blowing up its objects Composite crop of src1, src2 Joshua Greene and Andrew Lobb proved last month that every smooth Jordan curve in the plane and real , there are four points on the curve that form a rectangle with sides of ratio . Today we explain how this result relates to Otto Toeplitz’s […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>By blowing up its objects</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2020/06/29/taking-a-problem-down-a-peg/greenelobb/" rel="attachment wp-att-17246"><img alt="" class="alignright wp-image-17246" height="120" src="https://rjlipton.files.wordpress.com/2020/06/greenelobb.png?w=183&amp;h=120" width="183"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Composite crop of <a href="https://math.berkeley.edu/people/faculty/joshua-evan-greene">src1</a>, <a href="https://groups.oist.jp/mathprog/andrew-lobb">src2</a></font></td>
</tr>
</tbody>
</table>
<p>
Joshua Greene and Andrew Lobb <a href="https://arxiv.org/pdf/2005.09193.pdf">proved</a> last month that every <em>smooth</em> Jordan curve in the plane and real <img alt="{r \leq 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br+%5Cleq+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r \leq 1}"/>, there are four points on the curve that form a rectangle with sides of ratio <img alt="{r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r}"/>.</p>
<p>
Today we explain how this result relates to Otto Toeplitz’s famous “square peg conjecture,” which is the case <img alt="{r = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r = 1}"/> when the curve need not be smooth.</p>
<p>
We noticed this via an <a href="https://www.quantamagazine.org/new-geometric-perspective-cracks-old-problem-about-rectangles-20200625/">article</a> last Thursday by Kevin Hartnett for <em>Quanta</em>. Hartnett describes this research advance as a product of the pandemic inducing them to take time for deeper reflection on fundamental problems. We wonder how much is bubbling on hard problems in our own field—this is one reason for our last post’s <a href="https://rjlipton.wordpress.com/2020/06/21/some-real-and-some-virtual-news">interest</a> in (good kinds of) “gossip.”  He also gives great diagrams for the geometrical intuition.</p>
<p>
We will portray this advance instead along lines of things we’ve said recently about how to attack hard problems by seeking and solving simpler ones or special cases as stepping stones. Dick wrote a <a href="https://rjlipton.wordpress.com/2018/10/21/the-inscribed-square-problem/">post</a> two years ago on the original Toeplitz problem, which this work still leaves open. That post focused on ways general Jordan curves can be nasty. This one needs an extra niceness condition but proves a stronger result for all <img alt="{r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r}"/>. How much can progress on “nice” inform problems with “nasty”? That kind of question comes up in complexity theory all the time.</p>
<p>
</p><p/><h2> Pegging Rectangles </h2><p/>
<p/><p>
A <em>Jordan curve</em> is the image of a continuous 1-1 map <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/> from the circle to the plane. The condition of being 1-1 prevents the image from intersecting itself, so it is a single closed loop. By the Jordan curve <a href="https://en.wikipedia.org/wiki/Jordan_curve_theorem">theorem</a>, the loop always partitions the rest of the plane into two connected regions, exactly one of which is bounded. Amazingly, a Jordan curve <a href="https://en.wikipedia.org/wiki/Osgood_curve">can</a> have positive Lebesgue measure, yet cannot fill all of <img alt="{\mathbb{R}^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BR%7D%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathbb{R}^2}"/>. Such curves can, however, approach the kind of space-filling curves defined by Giuseppe Peano, and thus have any Lebesgue density less than <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>, as was noted also by William Osgood in his 1903 <a href="https://www.jstor.org/stable/pdf/1986455.pdf">paper</a>.</p>
<p>
The Toeplitz conjecture is that every Jordan curve has four points that form a square. As noted in Dick’s post, the positive-area case is actually an easy yes-case. Nasty cases are where the curve is nowhere-differentiable with zero area. Thus far, the problem has been answered <em>yes</em> only in the presence of some uniformity condition that limits the local nastiness of the curve. The simplest one is for the curve to be <em>smooth</em> in that <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/> has a continuous first derivative. Here is a smooth curve that is not convex, so that the square need not be “inside” the curve:</p>
<p/><p/>
<p><a href="https://rjlipton.wordpress.com/2020/06/29/taking-a-problem-down-a-peg/matschkefig2/" rel="attachment wp-att-17247"><img alt="" class="aligncenter size-full wp-image-17247" src="https://rjlipton.files.wordpress.com/2020/06/matschkefig2.jpg?w=600"/></a></p>
<p>
This diagram is from Benjamin Matchske’s wonderful recent <a href="https://www.ams.org/notices/201404/rnoti-p346.pdf">survey</a> of the peg problem in the <em>AMS Notices</em>. Four months ago we’d have said it looks like a thin heart or fat boomerang. <i>Now</i> it looks to us like a face mask.</p>
<p>
As the survey notes, it is easy to show that every Jordan curve has <em>some</em> rectangle. The rectangle problem is to show that rectangles of <i>every</i> aspect ratio <img alt="{r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r}"/> can be pegged to the curve. There are two main reasons the square and rectangle problems are hard and harder:</p>
<ol>
<li>
Although any Jordan curve can be written as a limit of nice ones, the squares in the nice ones can degenerate to a single point in the limit. <p/>
</li><li>
Even for nice curves, a parity property that holds for squares can fail for rectangles.
</li></ol>
<p>
The property in the second point enables arguments of the kind: <em>for generic curves the number of squares is odd, therefore it is nonzero</em>. This then carries over to sufficiently nice curves in the generic closure. The failure of this property for rectangles is a main reason the results by Greene and Lobb are new.</p>
<p>
</p><p/><h2> The Paper </h2><p/>
<p/><p>
The new paper is written tersely at a high level, and we must confess not being able to catch all details in compressed time. But we can highlight some aspects of the argument. First, as we have said, it exemplifies:</p>
<ul>
<li>
<em>Solve a Simpler Problem</em>.
</li></ul>
<p>
This is however coupled with a second aspect:</p>
<ul>
<li>
<em>Bring Up the Reserves</em>.
</li></ul>
<p>
It may be that the rectangle conjecture is not only true but “equally true” in the sense that the fundamental reason applies equally well to the case of rectangles. The parity argument that works for cases involving squares may be a crutch that misses the deepest explanations. Promoting arguments that avoid this crutch may marshal resources needed to make a breakthrough on the main problem for completely general Jordan curves.</p>
<p>
This runs somewhat counter to what we have said about <img alt="{\mathsf{NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{NP}}"/> versus <img alt="{\mathsf{P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{P}}"/> proof attempts recently. The reason for <img alt="{\mathsf{P &lt; NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%3C+NP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{P &lt; NP}}"/> believed by most is that problems like SAT require <em>exponential</em> time, not just super-polynomial time. Yet no one knows even a <em>super-linear</em> lower bound, apart from barely-superlinear bounds that exploit grainy aspects of the multitape Turing machine model and apply only to it. Nor is any super-linear lower bound known on Boolean circuit size. Maybe it is a viable strategy also to “bring up reserves” by finding restricted cases where (conditional) exponential lower bounds can be proven, as well as to explore contingencies like <a href="https://en.wikipedia.org/wiki/Exponential_time_hypothesis">SETH</a>, as we covered <a href="https://rjlipton.wordpress.com/2015/06/01/puzzling-evidence/">here</a>. But both of use have always felt that the super-linear frontier holds the buried keys to further progress.</p>
<p>
The Greene-Lobb proof has two aspects that may also resonate in complexity:</p>
<ul>
<li>
<em>Blow Up the Objects</em>.
</li></ul>
<p>
The <a href="https://www.quantamagazine.org/new-geometric-perspective-cracks-old-problem-about-rectangles-20200625/">article</a> in <em>Quanta</em> has great diagrams illustrating how the set of pairs of points on the curve corresponds to a Möbius strip in a related space. Cole Hugelmeyer, a graduate student at Princeton, <a href="https://arxiv.org/pdf/1911.07336.pdf">proved</a> last year how to get rectangles covering at least one-third of possible values <img alt="{r \in (0,1]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br+%5Cin+%280%2C1%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r \in (0,1]}"/> by embedding the Möbius strips in a four-dimensional space. Intersections between a strip and a rotated copy yield rectangles on the original Jordan curve. </p>
<p>
That led Greene and Lobb to consider larger objects with properties like pairs of Möbius strips in the larger space. The Klein bottle is the natural next thing to consider and led to a feature of their proof that made the desired conclusion pop out:</p>
<ul>
<li>
<em>Identify and Rule Out Obstructions</em>.
</li></ul>
<p>
The clever point pivots on the fact that a Klein bottle cannot be smoothly embedded into the complex plane <img alt="{\mathbb{C}^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BC%7D%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathbb{C}^2}"/> as a Lagrangian submanifold. The proof shows that for any prescribed aspect ratio <img alt="{r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r}"/> one can construct a mapping that almost succeeds in embedding such a Klein bottle. The fact that it must fail means that the image must yield a point of intersection witnessing the failure. The presence of this point then yields the construction of four other points on the Jordan curve that form the vertices of the needed rectangle.</p>
<p>
We have briefly <a href="https://rjlipton.wordpress.com/2018/06/06/princeton-is-invariant/">mentioned</a> how the concept of <em>obstructions</em> is integral to the <a href="https://en.wikipedia.org/wiki/Geometric_complexity_theory">Geometric</a> <a href="https://dl.acm.org/doi/10.1145/1944345.1944346">Complexity</a> <a href="http://gct.cs.uchicago.edu/">Theory</a> attack on <img alt="{\mathsf{P &lt; NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%3C+NP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{P &lt; NP}}"/>. Closer to home, however, is how László Babai's graph isomorphism algorithm and proof works by identifying a subclass of graphs called Johnson graphs as obstructions to a simpler algorithm, as we highlighted <a href="https://rjlipton.wordpress.com/2017/01/06/snow-and-theory/">here</a>.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Can you find more lessons from the new advance on the Toeplitz problem?  Dick and I have considered ideas of blowing up from languages to pairs of languages (and making <i>reductions</i> between problems the fundamental units of analysis) but this has not gone beyond dreamwork.</p>
<p/></font></font></div>
    </content>
    <updated>2020-06-29T21:20:08Z</updated>
    <published>2020-06-29T21:20:08Z</published>
    <category term="All Posts"/>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="Proofs"/>
    <category term="Results"/>
    <category term="Andrew Lobb"/>
    <category term="Cole Hugelmeyer"/>
    <category term="computational geometry"/>
    <category term="conjecture"/>
    <category term="geometry"/>
    <category term="Joshua Greene"/>
    <category term="Toeplitz"/>
    <author>
      <name>KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2020-07-02T23:29:34Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-7761235140481153504</id>
    <link href="https://blog.computationalcomplexity.org/feeds/7761235140481153504/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/06/can-you-name-famous-living-chemist-can.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7761235140481153504" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7761235140481153504" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/06/can-you-name-famous-living-chemist-can.html" rel="alternate" type="text/html"/>
    <title>Can you name a famous living Chemist? Can anyone?</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><br/>
I was re-watching the  Greatest-of-all-time Jeopardy championship and the following happen (I paraphrase)<br/>
<br/>
----------------------<br/>
Alex Trebek: The category is Chemistry and we have a special guest reading the clues.<br/>
<br/>
Darling: I wonder who that will be.<br/>
<br/>
Bill: Hmm. I assume some famous chemist.<br/>
------------------------<br/>
<br/>
So who was it? Bryan Cranston, the actor who PLAYED chemist Walter White on <i>Breaking Bad.</i><br/>
<br/>
Why couldn't they get a famous living chemist to read the clues?<br/>
<br/>
My guess: there are no famous living chemists.<br/>
<br/>
The number of famous living scientists is fairly short and they are often known for things that are not quite their science. Some are famous because the popularize science (deGrasse Tyson, Dawkins) or because of something unusual about their life (Hawkings when he was alive) or for something else entirely that they did (Ted Kaczynski).  Are any famous for the actual work that they do in the science?<br/>
<br/>
Andrew Wiles was famous for a brief time, and even made People Magazine's <i>25 most intriguing people of the year</i> list in the early 1990's (after he solved Fermat's Last Theorem). So he was famous but it was short lived.<br/>
<br/>
Terry Tao was on the Colbert Report (see <a href="http://www.cc.com/video-clips/6wtwlg/the-colbert-report-terence-tao">here</a>) after he won the Fields Medal, the MacAuthor Genius award, and the Breakthrough prize. And even that fame was short lived.<br/>
<br/>
I looked at the web page of Nobel Prize winners, <a href="https://www.nobelprize.org/prizes/lists/all-nobel-prizes">here</a>.<br/>
<br/>
The only Chemistry Nobel's I recognized were Marie Curie,  Irene Joilet-Curie (Marie's Daughter), and Erst Rutherford.<br/>
<br/>
The only Physics Nobel's I recognized were<br/>
<br/>
Richard Feynman,<br/>
<br/>
 Eugene Wigner (for writing about <a href="https://www.dartmouth.edu/~matc/MathDrama/reading/Wigner.html">The unreasonable effectiveness of mathematics in the natural sciences</a>),<br/>
<br/>
Richard Hofstadter (since he was the father of Douglas H and an uncle of Leonard H)<br/>
<br/>
 Andrew Geim (since he won  both an Ig-Noble prize and a Nobel prize, see  <a href="https://blog.computationalcomplexity.org/2010/10/noble-and-ig-noble-prizes.html">here</a>)<br/>
<br/>
Wolfgang Pauli (I've heard the term `Pauli Principle" though I did not know what it was until I looked it up while preparing this blog. I prob still don't really know what it means.)<br/>
<br/>
Enrico Fermi<br/>
<br/>
Erwin Schrodinger<br/>
<br/>
Paul Dirac<br/>
<br/>
Robert Millikan<br/>
<br/>
Albert Einstein<br/>
<br/>
Max Karl Ernest Ludwig Planck (I thought his last name was `Institute')<br/>
<br/>
Johannes Diderik van der Waals<br/>
<br/>
Pierre Curie<br/>
<br/>
Marie Curie<br/>
<br/>
<br/>
So, some questions:<br/>
<br/>
a) Am I wrong? Are there famous living chemists I never heard of? Are there any famous living scientists who are famous for their work in science?<br/>
<br/>
b) If I am right then was there ever a time when there were famous scientists?<br/>
<br/>
c) If there was such a time, what changed?<br/>
<br/>
(I ask all of this non-rhetorically and with no agenda to push.)<br/>
<br/>
<br/>
<br/>
<br/>
<br/></div>
    </content>
    <updated>2020-06-29T20:36:00Z</updated>
    <published>2020-06-29T20:36:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2020-07-02T13:25:12Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/06/29/postdocs-phd-students-in-the-theory-of-distributed-parallel-computing-at-aalto-university-apply-by-august-31-2020/</id>
    <link href="https://cstheory-jobs.org/2020/06/29/postdocs-phd-students-in-the-theory-of-distributed-parallel-computing-at-aalto-university-apply-by-august-31-2020/" rel="alternate" type="text/html"/>
    <title>Postdocs &amp; PhD students in the theory of distributed &amp; parallel computing at Aalto University (apply by August 31, 2020)</title>
    <summary>The research groups of Jukka Suomela and Jara Uitto at Aalto University (Helsinki, Finland) are looking for several postdoctoral researchers and/or doctoral students to work on the foundations of distributed and parallel computing. Website: https://research.cs.aalto.fi/da/jobs/ Email: jukka.suomela@aalto.fi and jara.uitto@aalto.fi</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The research groups of Jukka Suomela and Jara Uitto at Aalto University (Helsinki, Finland) are looking for several postdoctoral researchers and/or doctoral students to work on the foundations of distributed and parallel computing.</p>
<p>Website: <a href="https://research.cs.aalto.fi/da/jobs/">https://research.cs.aalto.fi/da/jobs/</a><br/>
Email: jukka.suomela@aalto.fi and jara.uitto@aalto.fi</p></div>
    </content>
    <updated>2020-06-29T16:00:22Z</updated>
    <published>2020-06-29T16:00:22Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-07-02T23:29:39Z</updated>
    </source>
  </entry>

  <entry>
    <id>http://benjamin-recht.github.io/2020/06/29/tour-revisited/</id>
    <link href="http://benjamin-recht.github.io/2020/06/29/tour-revisited/" rel="alternate" type="text/html"/>
    <title>What We've Learned to Control</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I’m giving a keynote address at the <a href="https://www.ifac2020.org/">virtual IFAC congress this July</a>, and I submitted an abstract that forces me to reflect on the current state of research at the intersection of machine learning and control. 2020 is particularly appropriate for reflection: For personal reasons, I’ve been working in this space for about half a decade now and <a href="https://www.argmin.net/2018/06/25/outsider-rl/">wrote a blog series on the topic two years ago</a> and it seemed like ideal timing. For the broader community, 2020 happens to be the year we were promised fleets of self-driving cars. Of course, for a myriad of reasons, we’re nowhere close to achieving this goal. Full self-driving has been a key motivator of work in learning-enabled autonomous systems, and it’s important to note this example as a marker of how difficult problems this space really are.</p>

<p>The research community has come to terms with this difficulty, and has committed itself to address the many pressing challenges. Over the last year I attended several great meetings on this topic, including an <a href="https://ajwagen.github.io/adsi_learning_and_control/">NSF funded workshop at UW</a>, a plenary session at <a href="https://ita.ucsd.edu/ws/">ITA</a>, a workshop on intersections of <a href="https://www.ipam.ucla.edu/programs/workshops/intersections-between-control-learning-and-optimization/?tab=overview">learning, control, and optimization at IPAM</a>, and the <a href="https://sites.google.com/berkeley.edu/l4dc/home">second annual conference on Learning for Dynamics and Control</a>. There is clearly a ton of enthusiasm from researchers in a many different disciplines, and we’re seeing fascinating results mixing techniques from machine learning, computer science, and control. Obviously, I’m going to be leaving out many incredible papers, but, focusing on the theoretical end of the spectrum, perhaps I could highlight <a href="https://arxiv.org/abs/1912.11899">new work on policy optimization</a> that demonstrates how simple optimization techniques can efficiently solve classic, nonconvex control-design problems or <a href="https://arxiv.org/abs/1902.08721">work connecting regret minimization and adaptive control</a> that provides nonasymptotic bounds.</p>

<p>This work has been very useful for establishing language to bridge communication between the diverse research camps interested in the space of learning, dynamics and automation. But, as I’ll discuss shortly, I’d argue that it hasn’t provided many promising approaches to improving large-scale autonomy. That’s ok! These problems are incredibly difficult and aren’t going to be solved by wishing for them to be solved. But I also think it might be worth taking a moment to reflect on which problems we are working on. It’s always a bit too easy for theorists to focus  on improving technical results and lose sight of why someone proved those results in the first place.</p>

<p>As an illustrative example, my research group spent a lot of time studying the <a href="http://www.argmin.net/2018/02/08/lqr/">Linear Quadratic Regulator</a> (LQR). The point of this work was initially to establish baselines: LQR has a closed form solution when the model is known, so we wanted to understand how different algorithms might perform when the underlying model was unknown. It turns out that if you are willing to collect enough data, the best thing you can do for LQR is <a href="https://arxiv.org/abs/1902.07826">estimate the dynamical model, and then exploit this model as if it were true</a>. This so-called “certainty equivalent control” is what practitioners have been doing since the mid-60s to fly satellites and solve other optimal control problems. Proving this result required a bunch of new mathematical insights that established connections between high dimensional statistics and automatic control theory. But it did not bring us closer to solving new challenges in robotics or autonomous systems. Our work here merely showed that what the controls community had been doing for 50 years was already about as well as we could do for this important baseline problem.</p>

<p>So what are the ways forward? Are there things that theory-minded folks can work on short term that might help us understand paths towards improving learning systems in complex feedback loops? Let me suggest a few challenges that I see as both very pressing, but also ones where we might be able to make near-term progress.</p>

<h2 id="machine-learning-is-still-not-reliable-technology">Machine Learning is still not reliable technology</h2>

<p>At the aforementioned <a href="https://www.ipam.ucla.edu/programs/workshops/intersections-between-control-learning-and-optimization/?tab=overview">IPAM meeting</a>, Richard Murray gave a <a href="https://www.youtube.com/watch?v=Wi8Y---ce28">fantastic survey of the sorts of standards of reliability imposed in aerospace engineering</a>. Go watch it! I don’t want to spoil it for you, but his discussion of Ram Air Turbines is gripping. Richard covers what is needed to get to the sorts of reliability we’d like in autonomous systems. Unfortunately, having <a href="https://arxiv.org/abs/2003.08237">88.5% Top-1 accuracy on ImageNet</a>—while a stunning achievement—doesn’t tell us how to get to systems with failure rates on the order of 1 in a billion. As Boeing has tragically shown, cutting corners on autonomous system safety standards has horrible, tragic consequences.</p>

<p>How can we make machine learning more robust? How can we approach the failure rates needed for safe, reliable autonomy? And how can we establish testing protocols to assure we have such low failure rates?</p>

<h2 id="prediction-systems-in-feedback-loops">Prediction systems in feedback loops</h2>

<p>One particular aspect that I think is worth considering is how supervised learning systems can function as “sensors” in feedback loops. Even if you know everything about a dynamical system, when you observe the state via an estimator generated by a learned component, it’s not clear how to best take action on this observation. Most classic control and planning assumes that your errors in state-estimation are Gaussian or nicely uniformly bounded. Of course, the errors from machine learning systems are neither of these (I recommend checking out the <a href="https://youtu.be/A0cb7wZVFf4">crazy videos</a> of the <a href="https://twitter.com/greentheonly/status/1130956365063761920">confusion</a> that comes out of Tesla Autopilot’s vision systems). How to properly characterize the errors of machine learning systems for control applications seems like a useful, understudied problem. Using off-the-shelf machine learing analysis, it’s unavoidable to have to densely sample all of the possible scenarios in advance in order to guarantee the sort of uniform error bounds desired by control algorithms. This isn’t practical, and, indeed, it’s clear that this sort of sensor characterization is not needed to make reasonable demos work. Though it’s a bit mundane, I think a huge contribution lies in understanding how much data we need to quantify the uncertainty in learned perception components. It’s still not clear to me if this is a machine learning question or a closed-loop design question, and I suspect both views of the problem will be needed to make progress.</p>

<h2 id="why-are-we-all-sleeping-on-model-predictive-control">Why are we all sleeping on model predictive control?</h2>

<p>I still remain baffled by how <a href="http://www.argmin.net/2018/05/02/adp/">model predictive control</a> (MPC) is consistently under appreciated. We’ll commonly see the same tasks in the same meeting, one task done on a robot using some sort of deep reinforcement learning and the other done using model predictive control, and the disparity in performance is stark. It’s like the difference between watching an Olympic level sprinter and me jogging in my neighborhood with a set of orthotics.</p>

<p>Here’s an example from the IPAM workshop. Martin Riedmiller presented work at DeepMind to catch a ball in a cup:</p>



<p>This system uses two cameras, has a rather large “cup,” (it’s a wastepaper basket) and yet still takes 3 days to train on the robot. Francesco Borrelli presented a different approach. Using only a single camera and basic, simple Newtonian physics, and MPC they were able to achieve this performance on the standard-sized “ball-in-a-cup” toy:</p>



<p>If you only saw these two videos, I can’t fathom why would you invest all of your assets into deep RL. I understand there are still a lot of diehards out there, and I know this will offend them. But I want to make a constructive point: so many theorists are spending a lot of time studying RL algorithms, but few in the ML community are analyzing MPC and why it’s so successful. We should rebalance our allocation of mental resources!</p>

<p>Now, while the basic idea of MPC is very simple, the theory gets very hairy very quickly. It definitely takes some time and effort to learn about how to prove convergence of MPC protocols. I’d urge the MPC crowd to connect more with the learning theory crowd to see if a common ground can be found to better understand how MPC works and how we might push its performance even farther.</p>

<h2 id="perhaps-we-should-stop-taking-cues-from-alphago">Perhaps we should stop taking cues from AlphaGo?</h2>

<p>One of the grand goals in RL is to use function approximation algorithms to estimate value functions. The conventional wisdom asserts that the world is a giant Markov Decision Process and once you have its value function, you can just greedily maximize it and you’ll win at life. Now, this sort of approach clearly doesn’t work for robots, and I’m perplexed by why people still think it will work at all. Part of the motivation is that this approach was used to solve Go. But at some point I think we all have to come to terms with the fact that games are not the real world.</p>

<p>Now, I’d actually argue that RL <em>does</em> work in the real world, but it’s in systems that most people don’t actively think of as RL systems. Greedy value function estimation and exploitation is <em>literally</em> how all internet revenue is made. Systems simply use past data to estimate value functions and then choose the action that maximizes the value at the next step. Though seldom described as such, these are instances of the “greedy contextual bandit” algorithm, and this algorithm makes tech companies tons of money. But many researchers have also pointed out that this algorithm leads to misinformation, polarization, and radicalization.</p>

<p>Everyone tries to motivate RL by the success of AlphaGo, but they should be using the success of Facebook and Google instead. And if they did this, I think it would be a lot more clear why RL is terrifying and dangerous, and one whose limitations we desperately need to understand so that we can build safer tools.</p>

<h2 id="lessons-from-the-70s-about-optimal-control">Lessons from the 70s about optimal control</h2>

<p>I have one set of ideas along these lines that, while I think is important, I still am having a hard time articulating. Indeed, I might just take a few blog posts to work through my thoughts on this, but let me close this blog with a teaser of discussions to come. As I mentioned above, optimal control was a guiding paradigm for a variety of control applications in the 60s and 70s. During this time, it seemed like there might even be hidden benefits to a full-on optimization paradigm: though you’d optimize a single, simple objective, you would often get additional robustness guarantees for free. However, it turned out that this was very misleading and that <a href="https://ieeexplore.ieee.org/document/1101812">there were no guarantees of robustness even for simple optimal control problems</a>. This shouldn’t be too surprising, as if you devote a lot of resources towards one objective, you are likely neglecting some other objective. But showing how and why these fragilities arise is quite delicate. It’s not always obvious how you <em>should</em> be devoting your resources.</p>

<p>Trying to determine how to allocate engineering resources to balance safety and performance is the heart of “robust control.” One thing I’m fascinated by moving forward is if any of the early developments in robust control might transfer over for a new kind of “robust ML.” Unfortunately for all of us, robust control is a rather encrypted literature. There is a lot of mathematics, but often not clear statements about <em>why</em> we study particular problems or what are the fundamental limits of feedback. While diligent young learning theorists have been scouring classic control theory text books for insights, these books don’t always articulate what we can and cannot do and what are the problems that control theory might help solve. We still have a lot of work to do in communicating what we know and what problems remain challenging. I think it would be useful for control theorists to think of how to best communicate the fundamental concepts of robust control. I hope to take up this challenge in the next few months on this blog.</p>

<p><em>I’d like to thank Sarah Dean, Horia Mania, Nik Matni, and Ludwig Schmidt for their helpful feedback on this post. I’d also like to thank John Doyle for several inspiring conversations about robustness in optimal control and on the encrypted state of the control theory literature.</em></p></div>
    </summary>
    <updated>2020-06-29T00:00:00Z</updated>
    <published>2020-06-29T00:00:00Z</published>
    <source>
      <id>http://benjamin-recht.github.io/</id>
      <author>
        <name>Ben Recht</name>
      </author>
      <link href="http://benjamin-recht.github.io/" rel="alternate" type="text/html"/>
      <link href="http://benjamin-recht.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Musings on systems, information, learning, and optimization.</subtitle>
      <title>arg min blog</title>
      <updated>2020-07-02T23:30:37Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2020/06/28/sorting-integer-offsets</id>
    <link href="https://11011110.github.io/blog/2020/06/28/sorting-integer-offsets.html" rel="alternate" type="text/html"/>
    <title>Sorting with integer offsets</title>
    <summary>Here’s a cute exercise for the next time you’re teaching radix sorting in an algorithms class:</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Here’s a cute exercise for the next time you’re teaching radix sorting in an algorithms class:</p>

<p>Suppose you’re given as input a set of real numbers , and an integer parameter . Describe an algorithm for sorting the  numbers  in time . You can assume that standard arithmetic operations on real numbers (including comparisons and rounding down to an integer) take constant time per operation.</p>

<p>Models of computation that mix constant-time real arithmetic and rounding operations can be problematic, as by building up and then rounding numbers with unlimited precision you can access a level of computational power beyond what actual computers can do, but I don’t think that’s a concern here. If someone wants to use bit-packing tricks to implement a crazy but fast sorting algorithm in this model, they’re beyond the level of this exercise.</p>

<p>The same method (which I’m not going to describe, to preserve its value as an exercise) more generally allows you to take as input pairs  and sort the numbers  in time  where . But it relies heavily on the fact that you’re adding integers to the ’s. For a problem that can’t be handled in this way, consider instead sorting the numbers  where we multiply instead of adding. Or, if you prefer to view this as a type of <a href="https://en.wikipedia.org/wiki/X_%2B_Y_sorting"> sorting</a> problem, take logs in your favorite base and sort the numbers . It’s not at all obvious to me whether this can be done in the same  time bound.</p>

<p>The motivation for looking at all this is <a href="https://cstheory.stackexchange.com/q/47120/95">a question about how to implement the greedy set cover quickly</a>. You can find the unweighted <a href="https://en.wikipedia.org/wiki/Set_cover_problem#Greedy_algorithm">greedy set cover</a> in linear time (linear in the sum of the sizes of the input sets; this is an exercise in CLRS), and you can approximate the weighted greedy set cover very accurately in linear time using similar ideas. If you could sort  quickly you could use the sorted order to compute the weighted greedy set cover exactly in the same time as the sorting algorithm. Which is totally useless because the greedy cover is already an approximation, so a fast and accurate approximation to the greedy cover is good enough. But I think the question of sorting  is interesting despite its uselessness in this application.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/104424777130789257">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2020-06-28T17:54:00Z</updated>
    <published>2020-06-28T17:54:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2020-06-30T23:34:57Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-8890204.post-2151790274753933095</id>
    <link href="http://mybiasedcoin.blogspot.com/feeds/2151790274753933095/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=8890204&amp;postID=2151790274753933095" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/8890204/posts/default/2151790274753933095" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/8890204/posts/default/2151790274753933095" rel="self" type="application/atom+xml"/>
    <link href="http://mybiasedcoin.blogspot.com/2020/06/stoc-workshop-on-algorithms-with.html" rel="alternate" type="text/html"/>
    <title>STOC Workshop on "Algorithms with Predictions"</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">The STOC workshop on Algorithms with Predictions was on Friday, and I thought it went really well!  I can't speak for my talk, but the other 3 talks (Tim Roughgarden, Edith Cohen, Ravi Kumar) were fantastic and inspiring, and I really recommend them for anyone with an interest in "Beyond Worst-Case Analysis".   <br/><br/>The talks are <a href="https://www.youtube.com/watch?v=byKYJwN6XKw&amp;feature=youtu.be">all on Youtube</a>.  And the <a href="https://www.mit.edu/~vakilian/stoc-workshop.html">workshop page</a> is full of useful links and information. </div>
    </content>
    <updated>2020-06-27T18:06:00Z</updated>
    <published>2020-06-27T18:06:00Z</published>
    <author>
      <name>Michael Mitzenmacher</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/02161161032642563814</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-8890204</id>
      <category term="conferences"/>
      <category term="research"/>
      <category term="society"/>
      <category term="algorithms"/>
      <category term="administration"/>
      <category term="teaching"/>
      <category term="Harvard"/>
      <category term="papers"/>
      <category term="graduate students"/>
      <category term="funding"/>
      <category term="talks"/>
      <category term="blogs"/>
      <category term="codes"/>
      <category term="jobs"/>
      <category term="reviews"/>
      <category term="personal"/>
      <category term="travel"/>
      <category term="undergraduate students"/>
      <category term="books"/>
      <category term="open problems"/>
      <category term="PCs"/>
      <category term="consulting"/>
      <category term="randomness"/>
      <category term="CCC"/>
      <category term="blog book project"/>
      <category term="research labs"/>
      <category term="ISIT"/>
      <category term="tenure"/>
      <category term="comments"/>
      <category term="recommendations"/>
      <category term="outreach"/>
      <category term="students"/>
      <author>
        <name>Michael Mitzenmacher</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06738274256402616703</uri>
      </author>
      <link href="http://mybiasedcoin.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/8890204/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://mybiasedcoin.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/8890204/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">My take on computer science -- <br/> 
algorithms, networking, information theory -- <br/> 
and related items.</div>
      </subtitle>
      <title>My Biased Coin</title>
      <updated>2020-06-27T18:06:03Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=7756</id>
    <link href="https://windowsontheory.org/2020/06/26/stoc-2020-slack-channel-open-from-madhur-tulsiani/" rel="alternate" type="text/html"/>
    <title>STOC 2020 slack channel open (from Madhur Tulsiani)</title>
    <summary>Madhur writes: Thanks to all who participated in STOC 2020! Since the discussions on some of the topics from the business meeting, on SafeToC, and  on the papers/workshops are still ongoing, we will keep the Slack workspace open till July 31st (instead of just one week after the conference, as announced earlier). Also, if any […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Madhur writes:</p>



<p>Thanks to all who participated in STOC 2020! Since the discussions on some of the topics from the business meeting, on SafeToC, and  on the papers/workshops are still ongoing, we will keep the Slack workspace open till <strong>July 31st</strong> (instead of just one week after the conference, as announced earlier). Also, if any members of the community are interested in joining the discussions, they are welcome to email us (<a>stoc2020@ttic.edu</a>) and we can send them an invitation to join the workspace.</p>



<p>Of course the organizers may not always be able to quickly respond to help messages during the next month. However, all members are welcome to participate in discussions, create new topics or channels as needed, and use the workspace as they prefer.</p>



<p>TheoryFest organization team (<a href="mailto:stoc2020@ttic.edu" rel="noreferrer noopener" target="_blank">stoc2020@ttic.edu</a>)</p></div>
    </content>
    <updated>2020-06-27T01:37:25Z</updated>
    <published>2020-06-27T01:37:25Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2020-07-02T23:29:53Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=19925</id>
    <link href="https://gilkalai.wordpress.com/2020/06/26/to-cheer-you-up-in-difficult-times-6-play-rani-sharims-two-player-games-of-life-read-maya-bar-hillel-presentation-on-catching-lies-with-statistics-and-more/" rel="alternate" type="text/html"/>
    <title>To cheer you up in difficult times 6:  Play Rani Sharim’s two-player games of life,  read Maya Bar-Hillel presentation on catching lies with statistics, and more.</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Sorry for the long blog silence. In this post I wish to give a few links each of which probably deserves a full post. I will start with Rani Sharim’s two-player variants of John Conway’s game-of-life Here is a web-page … <a href="https://gilkalai.wordpress.com/2020/06/26/to-cheer-you-up-in-difficult-times-6-play-rani-sharims-two-player-games-of-life-read-maya-bar-hillel-presentation-on-catching-lies-with-statistics-and-more/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Sorry for the long blog silence. In this post I wish to give a few links each of which probably deserves a full post. I will start with</p>
<h2>Rani Sharim’s two-player variants of John Conway’s game-of-life</h2>
<p><a href="https://ranisharim.github.io/game_of_life_2_players/">Here is a web-page</a> by a student in my “Game Theory” course where you can play several two-players variants of John Conway’s game-of-life.  (A couple of variants were considered before. See, e.g. <a href="https://arxiv.org/abs/cond-mat/0207679">this  paper</a>.)</p>
<p>I really enjoyed playing Rani’s games and it can certainly cheer you up in difficult times. Questions about the game, remarks, and suggestions for improvements and for new features, are most welcome.</p>
<h2>How to catch lies with statistics, a 2006  presentation by Maya Bar-Hillel</h2>
<p><a href="https://gilkalai.files.wordpress.com/2020/06/mayesther.png"><img alt="" class="alignnone size-full wp-image-19929" src="https://gilkalai.files.wordpress.com/2020/06/mayesther.png?w=640"/></a></p>
<p>Maya Bar-Hillel (left) and Ester Samuel-Cahn</p>
<p>Here is an interesting 2006 <a href="https://gilkalai.files.wordpress.com/2020/06/ester.ppt">power point presentation entitled <strong><em>How to detect lies with statistics</em></strong> by Maya Bar-Hillel.</a>  This was a talk given by Maya at the <a href="http://www.esterconference.huji.ac.il/">conference</a> honoring Prof. Ester Samuel- Cahn , Jerusalem, December 18-20, 2006, and it described a planned research project of Maya Bar-Hillel with Yossi Rinott, David Budescu and myself. At the end we did not pursue it, mainly because each of us was involved in various other projects (but also because we were skeptical about some aspects of it.)  Ester Samuel-Cahn (1933-2015) was a famous Israeli statistician. (Here is a <a href="http://www.sci-princess.info/archives/291">post by Yosi Levy in Hebrew</a> about the conference and about Ester.)</p>
<p>The lecture starts with “Last year, <em>Statistical Science</em> celebrated 50 years for `How to Lie with Statistics’ the book [by Durell Huff] whose title inspired this talk.”</p>
<p>And here are a few other quotes from Maya’s presentation</p>
<p>“We are not sure a general toolkit for detecting lies with statistics can be developed. Perhaps that explains why none yet exists.  We have shown just a collection of anecdotes. But they can be classified and categorized. Some do seem generalizeable, at least to some extent.”</p>
<p>and the conclusion</p>
<blockquote><p>A famous quip by Fred Mosteller: “It is easy to lie with statistics, but easier to lie without them.”</p>
<p>Likewise, we should say:  “It is possible to detect (some) lies with statistics, but easier to detect them with other means”.</p></blockquote>
<h2>New bounds for Ryser’s conjecture and related problems</h2>
<p>Peter Keevash, Alexey Pokrovskiy, Benny Sudakov, and Liana Yepremyan’s paper  <a href="https://arxiv.org/abs/2005.00526">New bounds for Ryser’s conjecture and related problems,</a> describes remarkable progress very old questions regarding transversals in Latin square.</p>
<h2>Topological Tverberg news</h2>
<p>I came across a very interesting paper <a href="https://arxiv.org/abs/2005.05251">The topological Tverberg problem beyond <span class="search-hit mathjax">prime</span> powers</a> by Florian Frick and Pablo Soberón with new bounds and a new method for topological Tverberg theorem in the non prime-power case.</p>
<h2>Jeager’s conjecture refuted</h2>
<p>A year ago I came across <a href="https://www.facebook.com/photo.php?fbid=2114324995342352&amp;set=a.507523926022475&amp;type=3&amp;theater">this cool facebook post</a> by Rupei Xu</p>
<blockquote><p>OMG! Just learned that Jaeger’s conjecture is false for every t&gt;=3. An interesting consequence of it is that a specific version of Goddyn’s conjecture on thin spanning trees is false, which shows some negative evidence that the thin spanning tree approaches may fail to lead to a constant factor approximation algorithm for ATSP!</p></blockquote>
<h2>A cool rainbow post <a href="http://matroidunion.org/?p=2541">Short rainbow cycles in graphs and matroids</a> by Tony Huynh</h2>
<h2>More on the game of life</h2>
<p>Let me mention two problems I posted 6-7 years ago about Conway’s game of life. <a class="question-hyperlink" href="https://mathoverflow.net/questions/132402/conways-game-of-life-for-random-initial-position">Conway’s game of life for random initial position</a> and <a class="question-hyperlink" href="https://cstheory.stackexchange.com/questions/17914/does-a-noisy-version-of-conways-game-of-life-support-universal-computation">Does a noisy version of Conway’s game of life support universal computation?</a></p>
<div class="left-sidebar js-pinned-left-sidebar ps-relative" id="left-sidebar">
<div class="left-sidebar--sticky-container js-sticky-leftnav"/>
</div>
<p> </p>
<p> </p></div>
    </content>
    <updated>2020-06-25T21:21:45Z</updated>
    <published>2020-06-25T21:21:45Z</published>
    <category term="Combinatorics"/>
    <category term="Games"/>
    <category term="Rationality"/>
    <category term="Maya Bar Hillel"/>
    <category term="Rani Sharim"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2020-07-02T23:29:28Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-8890204.post-5732832478359389342</id>
    <link href="http://mybiasedcoin.blogspot.com/feeds/5732832478359389342/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=8890204&amp;postID=5732832478359389342" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/8890204/posts/default/5732832478359389342" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/8890204/posts/default/5732832478359389342" rel="self" type="application/atom+xml"/>
    <link href="http://mybiasedcoin.blogspot.com/2020/06/writing-code-for-paper-note-to-students.html" rel="alternate" type="text/html"/>
    <title>Writing Code for a Paper :  A Note to Students</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">This post both relates to some of the stuff I'll be presenting at Friday's STOC workshop on Algorithms with Predictions, but is also for future students in my classes, who sometimes wonder why I have them write code on theory material.  (Somehow this might be a theme for a lecture in my grad class next semester, so maybe these are a first attempt at notes for the lecture.  Comments  and  suggestions welcome.)<br/><br/>Some of the work I'm doing is looking at how queueing systems perform with various sorts of predictions on the times the jobs take.  This particular work I'm doing on my own.  (While most of my research has been and is with collaborators, and it's one of the things I enjoy about computer science -- we're a very collaborative field!, which seems to surprise many people -- I still sometimes like to do research projects on my own.  I've looked at queueing systems since my PhD thesis, and it's a bit outside the research interest of most of my collaborator pool, and it's "fun" sometimes to do my own thing.  The reason why "fun" is in quotes is described below.)  <br/><br/>Often in my work in queueing I'm looking at mean-field limits (meant to model infinite systems of queues, which provides a good approximation for large finite systems under reasonable assumptions), where I can derive families of differential equations describing the system behavior.  I can also simulate the large finite system directly, and make sure the results match.  I generally do this for all of these types of papers.<br/><br/>Now the numbers I get from simulating the system directly and from simulating the differential equations should match (say within 1% or so).  If they don't, something is wrong.  In an effort to avoid wrongness, I won't consider the paper ready for outside consumption until I get a match.  Unfortunately, there are three ways things can go wrong.<br/><br/>1.  My simulation code for the queueing system might have bugs.<br/>2.  My code to evaluate the differential equations might have bugs.<br/>3.  My equations themselves might have bugs.<br/><br/>And I find there are two main categories of bugs.  Sometimes the bugs are simple/standard coding mistakes -- I'm off by 1 on an index, or I cut and paste and forget to change an i++ to a j++ in one my double loops, or I type x instead of a y.  Usually it's pretty easy to find these things, although I've had times where a hidden typo took hours to find.  But sometimes the bug is a thinking mistake -- I've forgotten a subcase and so my equations aren't complete (and so my code evaluating the equations won't give the right answer), or I've not handled a subcase correctly in my simulation.  That type usually takes longer. <br/><br/>Usually, the first time through, most all of these types of bugs happen -- my math is off, I've typed some stuff wrong, it can all happen.  And then, like coders everywhere, I go through and fix it.  And it's painful.  Sometimes everything goes right, a quick check or two and everything works.  For more complicated stuff, it's more time figuring out what went wrong than setting up the code to begin with.  And being the personality type to not let things sit, that can mean late nights figuring out what went wrong.<br/><br/>For my talk this week, there was one last problem I wanted to include, which meant finally taking the model and writing the equations and code.  I didn't even need it for the talk, but it's also the last bit before I put a paper draft on arxiv, so taking advantage of a deadline, I figured now was the time.  Which means the last 2 days, I've spent many hours (and a late night) trying to remove the disagreements.<br/><br/>On the plus side, when everything finally works, it's a wonderful feeling.  And it always makes me feel better when I have worked to verify my math this way;  this time, what kept me up well past midnight and took several hours to track down was actually a boundary case I had left out of the equations.  (I had looked at the equations over and over again without noticing I had left out the subcase;  I had to step through numbers from the differential equations one time step at a time to track down what was missing, and then the numbers told me what I had done wrong.)<br/><br/>On the down side, it's work, and debugging is never particularly fun.<br/><br/>For students out there, maybe I'm just explaining that I understand the pain that I am putting you through.  You may wonder why I have you do simulations that take a few hours if you do them well, but days if you don't think through the best approach.  But using programming and theory together can be powerful;  it's helped me countless times in my research.<br/><br/>(Related: on theory and experiments that <a href="https://cacm.acm.org/magazines/2015/9/191184-theory-without-experiments/fulltext">I've written on before</a>, along with <a href="https://cacm.acm.org/magazines/2015/9/191183-experiments-as-research-validation/fulltext">a viewpoint by Jeffrey Ullman</a>.)<br/><br/><br/></div>
    </content>
    <updated>2020-06-25T17:35:00Z</updated>
    <published>2020-06-25T17:35:00Z</published>
    <author>
      <name>Michael Mitzenmacher</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/02161161032642563814</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-8890204</id>
      <category term="conferences"/>
      <category term="research"/>
      <category term="society"/>
      <category term="algorithms"/>
      <category term="administration"/>
      <category term="teaching"/>
      <category term="Harvard"/>
      <category term="papers"/>
      <category term="graduate students"/>
      <category term="funding"/>
      <category term="talks"/>
      <category term="blogs"/>
      <category term="codes"/>
      <category term="jobs"/>
      <category term="reviews"/>
      <category term="personal"/>
      <category term="travel"/>
      <category term="undergraduate students"/>
      <category term="books"/>
      <category term="open problems"/>
      <category term="PCs"/>
      <category term="consulting"/>
      <category term="randomness"/>
      <category term="CCC"/>
      <category term="blog book project"/>
      <category term="research labs"/>
      <category term="ISIT"/>
      <category term="tenure"/>
      <category term="comments"/>
      <category term="recommendations"/>
      <category term="outreach"/>
      <category term="students"/>
      <author>
        <name>Michael Mitzenmacher</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06738274256402616703</uri>
      </author>
      <link href="http://mybiasedcoin.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/8890204/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://mybiasedcoin.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/8890204/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">My take on computer science -- <br/> 
algorithms, networking, information theory -- <br/> 
and related items.</div>
      </subtitle>
      <title>My Biased Coin</title>
      <updated>2020-06-27T18:06:03Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://emanueleviola.wordpress.com/?p=775</id>
    <link href="https://emanueleviola.wordpress.com/2020/06/25/we-dont-need-no-education/" rel="alternate" type="text/html"/>
    <title>We don’t need no education</title>
    <summary>Around us, educational systems whose primary emphasis is on social rather than intellectual skills are simply disintegrating. Unequipped for content delivery, teachers spray parents with a mixture of links and credentials whose collection is a complete waste of everybody’s time. Suggestion: What about assigning homework and let teachers provide feedback? To all the school-age kids […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Around us, educational systems whose primary emphasis is on social rather than intellectual skills are simply disintegrating.  Unequipped for content delivery, teachers spray parents with a mixture of links and credentials whose collection is a complete waste of everybody’s time.  Suggestion: What about assigning <em>homework </em>and let teachers provide <em>feedback</em>?</p>



<p>To all the school-age kids stuck at home doing some fun coding, <a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=&amp;cad=rja&amp;uact=8&amp;ved=2ahUKEwio8MDa4JvqAhWfVhUIHSAIABgQyCkwAHoECBUQBw&amp;url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DYR5ApYxkU-U&amp;usg=AOvVaw0s6Ai-o5-CNtyqFC7uHT_4">this immortal song is for you</a>.</p></div>
    </content>
    <updated>2020-06-25T10:29:13Z</updated>
    <published>2020-06-25T10:29:13Z</published>
    <category term="Uncategorized"/>
    <category term="Utopia"/>
    <author>
      <name>Manu</name>
    </author>
    <source>
      <id>https://emanueleviola.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://emanueleviola.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://emanueleviola.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://emanueleviola.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://emanueleviola.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>by Manu</subtitle>
      <title>Thoughts</title>
      <updated>2020-07-02T23:30:01Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/06/25/postdoc-in-experimental-algorithms-at-national-university-of-singapore-apply-by-august-15-2020/</id>
    <link href="https://cstheory-jobs.org/2020/06/25/postdoc-in-experimental-algorithms-at-national-university-of-singapore-apply-by-august-15-2020/" rel="alternate" type="text/html"/>
    <title>Postdoc in Experimental Algorithms at National University of Singapore (apply by August 15, 2020)</title>
    <summary>A one-year postdoc position (with a possibility of extension for another year) in experimental (/practical) algorithms is available at NUS. The position will be jointly hosted by Diptarka Chakraborty and Kuldeep S. Meel. Applications are invited from candidates who have solid background in algorithm design/formal methods, mathematics. A prior experience in programming would be a […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>A one-year postdoc position (with a possibility of extension for another year) in experimental (/practical) algorithms is available at NUS. The position will be jointly hosted by Diptarka Chakraborty and Kuldeep S. Meel. Applications are invited from candidates who have solid background in algorithm design/formal methods, mathematics. A prior experience in programming would be a plus.</p>
<p>Website: <a href="https://sites.google.com/view/diptarka/postdoc-advertisement">https://sites.google.com/view/diptarka/postdoc-advertisement</a><br/>
Email: diptarka@comp.nus.edu.sg</p></div>
    </content>
    <updated>2020-06-25T06:10:01Z</updated>
    <published>2020-06-25T06:10:01Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-07-02T23:29:39Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/06/25/postdoc-in-tcs-at-national-university-of-singapore-apply-by-august-15-2020-2/</id>
    <link href="https://cstheory-jobs.org/2020/06/25/postdoc-in-tcs-at-national-university-of-singapore-apply-by-august-15-2020-2/" rel="alternate" type="text/html"/>
    <title>Postdoc in TCS at National University of Singapore (apply by August 15, 2020)</title>
    <summary>A one-year postdoc position (with a possibility of extension for another year, subject to availability of fund) in theoretical computer science is available in the research group of Diptarka Chakraborty at NUS. Applications are invited from candidates who have solid background in algorithm design, computational complexity and mathematics. Website: https://sites.google.com/view/diptarka/postdoc-advertisement Email: diptarka@comp.nus.edu.sg</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>A one-year postdoc position (with a possibility of extension for another year, subject to availability of fund) in theoretical computer science is available in the research group of Diptarka Chakraborty at NUS. Applications are invited from candidates who have solid background in algorithm design, computational complexity and mathematics.</p>
<p>Website: <a href="https://sites.google.com/view/diptarka/postdoc-advertisement">https://sites.google.com/view/diptarka/postdoc-advertisement</a><br/>
Email: diptarka@comp.nus.edu.sg</p></div>
    </content>
    <updated>2020-06-25T06:05:34Z</updated>
    <published>2020-06-25T06:05:34Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-07-02T23:29:39Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/06/25/postdoc-in-tcs-at-national-university-of-singapore-apply-by-august-15-2020/</id>
    <link href="https://cstheory-jobs.org/2020/06/25/postdoc-in-tcs-at-national-university-of-singapore-apply-by-august-15-2020/" rel="alternate" type="text/html"/>
    <title>Postdoc in TCS at National University of Singapore (apply by August 15, 2020)</title>
    <summary>A one-year postdoc position (with a possibility of extension for another year, subject to availability of fund) in theoretical computer science is available in the research group of Diptarka Chakraborty at NUS. Applications are invited from candidates who have solid background in algorithm design, computational complexity and mathematics. Website: https://sites.google.com/view/diptarka/postdoc-advertisement Email: diptarka@comp.nus.edu.sg</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>A one-year postdoc position (with a possibility of extension for another year, subject to availability of fund) in theoretical computer science is available in the research group of Diptarka Chakraborty at NUS. Applications are invited from candidates who have solid background in algorithm design, computational complexity and mathematics.</p>
<p>Website: <a href="https://sites.google.com/view/diptarka/postdoc-advertisement">https://sites.google.com/view/diptarka/postdoc-advertisement</a><br/>
Email: diptarka@comp.nus.edu.sg</p></div>
    </content>
    <updated>2020-06-25T06:05:03Z</updated>
    <published>2020-06-25T06:05:03Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-07-02T23:29:39Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2020/06/24/ideal-workshop-on-computational-vs-statistical-tradeoffs-in-network-inference/</id>
    <link href="https://cstheory-events.org/2020/06/24/ideal-workshop-on-computational-vs-statistical-tradeoffs-in-network-inference/" rel="alternate" type="text/html"/>
    <title>IDEAL Workshop on Computational vs Statistical Tradeoffs in Network Inference</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">June 29, 2020 Virtual https://www.ideal.northwestern.edu/events/workshop-computational-vs-statistical-tradeoffs-in-network-inference/ Network models have been used as a tool to understand the role of interconnections between entities in multiple research areas like sociology, biology, meteorology, economics, and computer science. Moreover emerging technological developments allow collecting data on increasingly larger networks. This leads to both computational and statistical challenges when inferring or … <a class="more-link" href="https://cstheory-events.org/2020/06/24/ideal-workshop-on-computational-vs-statistical-tradeoffs-in-network-inference/">Continue reading <span class="screen-reader-text">IDEAL Workshop on Computational vs Statistical Tradeoffs in Network Inference</span></a></div>
    </summary>
    <updated>2020-06-24T23:53:00Z</updated>
    <published>2020-06-24T23:53:00Z</published>
    <category term="workshop"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2020-07-02T23:30:30Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/096</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/096" rel="alternate" type="text/html"/>
    <title>TR20-096 |  On the asymptotic complexity of sorting | 

	Igor Sergeev</title>
    <summary>We investigate the number of pairwise comparisons sufficient to sort $n$ elements chosen from a linearly ordered set. This number is shown to be $\log_2(n!) + o(n)$ thus improving over the previously known upper bounds of the form $\log_2(n!) + \Theta(n)$. The new bound is achieved by the proposed group insertion sorting algorithm.</summary>
    <updated>2020-06-24T17:41:11Z</updated>
    <published>2020-06-24T17:41:11Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-07-02T23:29:15Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/095</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/095" rel="alternate" type="text/html"/>
    <title>TR20-095 |  On Basing Auxiliary-Input Cryptography on NP-hardness via Nonadaptive Black-Box Reductions | 

	Mikito Nanashima</title>
    <summary>A black-box (BB) reduction is a central proof technique in theoretical computer science. However, the limitations on BB reductions have been revealed for several decades, and the series of previous work gives strong evidence that we should avoid a nonadaptive BB reduction to base cryptography on NP-hardness (e.g., Akavia et al., 2006). Then should we also give up such a familiar proof technique even for an intermediate step towards cryptography?

In this paper, we continue to explore the capability of nonadaptive BB reductions and extend our knowledge on such a central technique out of the current (worst-to-average) framework. In particular, we investigate the attempt to base weaker cryptographic notions allowed to take auxiliary-input via nonadaptive BB reductions. As a result, we prove the following theorems: (1) if we base an auxiliary-input pseudorandom generator (AIPRG) on NP-hardness via a nonadaptive BB reduction, then the polynomial hierarchy collapses; (2) if we base an auxiliary-input one-way function (AIOWF) or auxiliary-input hitting set generator (AIHSG) on NP-hardness via a nonadaptive BB reduction, then an (i.o.-)one-way function also exists based on NP-hardness (via an adaptive BB reduction).

The first result gives new evidence that nonadaptive BB reductions are insufficient to base AIPRG. The second result also yields a weaker but still surprising consequence of nonadaptive BB reductions, that is, a one-way function based on NP-hardness. In fact, the second result is interpreted as the following two opposite ways. Pessimistically, it shows that basing AIOWF or AIHSG via nonadaptive BB reductions is harder than constructing a one-way function based on NP-hardness, which can be regarded as a negative result. Note that AIHSG is a weak primitive implied even by the hardness of learning; thus, this pessimistic view gives conceptually stronger limitations than the currently known limitations on nonadaptive BB reductions. Optimistically, our result gives a new hope: a breakthrough construction of auxiliary-input primitives might also be useful to construct standard cryptographic primitives. This optimistic view enhances the significance of further investigation on constructing auxiliary-input or other intermediate cryptographic primitives instead of standard cryptographic primitives.</summary>
    <updated>2020-06-24T16:44:42Z</updated>
    <published>2020-06-24T16:44:42Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-07-02T23:29:15Z</updated>
    </source>
  </entry>

  <entry>
    <id>http://offconvex.github.io/2020/06/24/equilibrium-min-max/</id>
    <link href="http://offconvex.github.io/2020/06/24/equilibrium-min-max/" rel="alternate" type="text/html"/>
    <title>An equilibrium in nonconvex-nonconcave min-max optimization</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>While there has been incredible progress in convex and nonconvex minimization, a multitude of problems in ML today are in need of efficient algorithms to solve min-max optimization problems. 
 Unlike minimization, where algorithms can always be shown to converge to some local minimum, there is no notion of a local equilibrium in min-max optimization that exists for general nonconvex-nonconcave functions.
    In two recent papers, we give  two notions of local equilibria that are guaranteed to exist and efficient algorithms to compute them.
In this post we present the key ideas behind a second-order notion of local min-max equilibrium from <a href="https://arxiv.org/abs/2006.12363">this paper</a> and in the next we will talk about a different notion along with the algorithm and show its implications to GANs from <a href="https://arxiv.org/abs/2006.12376">this paper</a>.</p>

<h2 id="min-max-optimization">Min-max optimization</h2>

<p>Min-max optimization of an objective function $f:\mathbb{R}^d \times \mathbb{R}^d \rightarrow \mathbb{R}$</p>



<p>is a powerful framework in optimization, economics, and ML as it allows one to model learning in the presence of multiple agents with competing objectives.
In ML applications, such as <a href="https://arxiv.org/abs/1406.2661">GANs</a> and <a href="https://adversarial-ml-tutorial.org">adversarial robustness</a>, the min-max objective function may be nonconvex-nonconcave.
We know that min-max optimization is at least as hard as minimization, hence, we cannot hope to find a globally optimal solution to min-max problems for general functions.</p>

<h2 id="approximate-local-minima-for-minimization">Approximate local minima for minimization</h2>

<p>Let us first revisit the special case of minimization, where there is a natural notion of an approximate second-order local minimum.</p>

<blockquote>
  <p>$x$ is a second-order $\varepsilon$-local minimum of $\mathcal{L}:\mathbb{R}^d\rightarrow \mathbb{R}$ if
</p>
</blockquote>

<p>Now suppose we just wanted to minimize a function $\mathcal{L}$, and we start from any point which is <em>not</em> at an $\varepsilon$-local minimum of $\mathcal{L}$.
Then we can always find a direction to travel in along which either $\mathcal{L}$ decreases rapidly, or the second derivative of $\mathcal{L}$ is large.
 By searching in such a direction we can easily find a new point which has a smaller value of $\mathcal{L}$ using only local information about the gradient and Hessian of $\mathcal{L}$.
 This means that we can keep decreasing $\mathcal{L}$ until we reach an $\varepsilon$-local minimum (see <a href="https://www.researchgate.net/profile/Boris_Polyak2/publication/220589612_Cubic_regularization_of_Newton_method_and_its_global_performance/links/09e4150dd2f0320879000000/Cubic-regularization-of-Newton-method-and-its-global-performance.pdf">Nesterov and Polyak</a>,  <a href="https://dl.acm.org/doi/10.1145/3055399.3055464">here</a>,  <a href="http://proceedings.mlr.press/v40/Ge15.pdf">here</a>,  and also an earlier <a href="https://www.offconvex.org/2016/03/22/saddlepoints">blog post</a> for how to do this with only access to gradients of $\mathcal{L}$).
 If $\mathcal{L}$ is Lipschitz smooth and bounded, we will reach an $\varepsilon$-local minimum in polynomial time from any starting point.</p>

<blockquote>
  <p>Is there an analogous definition with similar properties for min-max optimization?</p>
</blockquote>

<h2 id="problems-with-current-local-optimality-notions">Problems with current local optimality notions</h2>
<p>There has been much recent work on extending theoretical results in nonconvex minimization to min-max optimization (see <a href="https://arxiv.org/abs/1906.00331">here</a>, <a href="https://papers.nips.cc/paper/9430-efficient-algorithms-for-smooth-minimax-optimization">here</a>, <a href="https://arxiv.org/pdf/1807.02629.pdf">here</a>,  <a href="https://papers.nips.cc/paper/9631-solving-a-class-of-non-convex-min-max-games-using-iterative-first-order-methods.pdf">here</a>, <a href="https://arxiv.org/abs/1910.07512">here</a>.
One way to extend the notion of local minimum to the min-max setting is to seek a solution point called a “local saddle”–a point $(x,y)$ where 1) $y$ is a local maximum for $f(x, \cdot)$ and 2) $x$ is a local minimum for $f(\cdot, y).$</p>

<p>For instance,
 this is used  <a href="https://arxiv.org/abs/1706.08500">here</a>, <a href="https://arxiv.org/pdf/1901.00838.pdf">here</a>, <a href="https://arxiv.org/pdf/1705.10461.pdf">here</a>, and <a href="http://proceedings.mlr.press/v89/adolphs19a.html">here</a>.
But, there are very simple examples of two-dimensional bounded functions where a local saddle does not exist.</p>

<blockquote>
  <p>For instance, consider $f(x,y) = sin(x+y)$ from <a href="https://arxiv.org/abs/1902.00618">here</a>. Check that none of the points on this function are simultaneously a local minimum for $x$ and local maximum for $y$.</p>
</blockquote>

<p>The fact that no local saddle exists may be surprising, since an $\varepsilon$-global solution to a min-max optimization problem <em>is</em> guaranteed to exist as long as the objective function is uniformly bounded.
Roughly, this is because, in a global min-max setting, the max-player is empowered to globally maximize the function $f(x,\cdot)$, and the min-player is empowered to minimize the “global max” function $\max_y(f(x, \cdot))$.</p>

<p>The ability to compute the global max  allows the min-player to  predict the max-player’s response.
If $x$ is a global minimum of $\max_y(f(x, \cdot))$, the min-player is aware of this fact and will have no incentive to update $x$.
On the other hand, if the min-player can only simulate the max-player’s updates locally (as in local saddle),
then the min-player may try to update her strategy even when it leads to a net increase in $f$.
This can happen because the min-player is not powerful enough to accurately simulate the max-player’s response. (See  a  <a href="https://arxiv.org/abs/1902.00618">related notion</a> of local optimality with similar issues due to vanishingly small updates.)</p>

<p>The fact that players who can only make local predictions are
unable to predict their opponents’ responses can lead to convergence problems in many popular algorithms such as<br/>
gradient descent ascent (GDA). This non-convergence behavior can occur if the function has no local saddle point (e.g. the function $sin(x+y)$  mentioned above), and can even happen on some functions, like $f(x,y) = xy$ which do have a local saddle point.</p>

<div style="text-align: center;">
<img alt="" src="http://www.offconvex.org/assets/GDA_spiral_fast.gif"/>
<br/>
<b>Figure 1.</b> GDA spirals off to infinity from almost every starting point on the objective function $f(x,y) = xy$. 
</div>
<p><br/></p>

<h2 id="greedy-max-a-computationally-tractable-alternative-to-global-max">Greedy max: a computationally tractable alternative to global max</h2>

<p>To allow for a more stable min-player, and a more stable notion of local optimality, we would like to empower the min-player to more effectively simulate the max-player’s response. 
While the notion of global min-max does exactly this by having the min-player compute the global max function $\max_y(f(\cdot,y))$, computing the global maximum may be intractable.</p>

<p>Instead, we replace the global max function $\max_y (f(\cdot ,y))$ with a computationally tractable alternative. 
Towards this end, we restrict the max-player’s response, and the min-player’s simulation of this response, to updates which can be computed using any algorithm from a class of second-order optimization algorithms.
More specifically, we restrict the max-player to updating $y$ by traveling along continuous paths which start at the current value of $y$ and along which either $f$ is increasing or the second derivative of $f$ is positive.  We refer to such paths as greedy paths since they model a class of second-order “greedy” optimization algorithms.</p>

<blockquote>
  <p><strong>Greedy path:</strong> A unit-speed path $\varphi:[0,\tau] \rightarrow \mathbb{R}^d$ is greedy if $f$ is non-decreasing over this path, and for every $t\in[0,\tau]$
</p>
</blockquote>

<p>Roughly speaking, when restricted to updates obtained from greedy paths, the max-player will always be able to reach a point which is an approximate local maximum for $f(x,\cdot)$, although there may not be a greedy path which leads the max-player to a global maximum.</p>

<div style="text-align: center;">
<img alt="" src="http://www.offconvex.org/assets/greedy_region_omega_t.png" style="width: 400px;"/> <img alt="" src="http://www.offconvex.org/assets/global_max_path_no_axes_t.png" style="width: 400px;"/> 
<br/>
 <b>Figure 2.</b> <i>Left:</i> The light-colored region $\Omega$ is reachable from the initial point $A$ by a greedy path; the dark region is not reachable. <i>Right:</i> There is always a greedy path from any point $A$ to a local maximum ($B$), but a global maximum ($C$) may not be reachable by any greedy path.
</div>
<p><br/></p>

<p>To define an alternative to $\max_y(f(\cdot,y))$, we consider the local maximum point with the largest value of $f(x,\cdot)$ attainable from a given starting point $y$ by any greedy path.
We refer to the value of $f$ at this point as the <em>greedy max function</em>, and denote this value by $g(x,y)$.</p>

<blockquote>
  <p><strong>Greedy max function:</strong> 
    $g(x,y) = \max_{z \in \Omega} f(x,z),$
where $\Omega$ is points reachable from $y$ by greedy path.</p>
</blockquote>

<h2 id="our-greedy-min-max-equilibrium">Our greedy min-max equilibrium</h2>
<p>We use the greedy max function to define a new second-order notion of local optimality for min-max optimization, which we refer to as a greedy min-max equilibrium.
Roughly speaking, we say that $(x,y)$ is a greedy min-max equilibrium if 
1) $y$ is a local maximum for $f(x,\cdot)$ (and hence the endpoint of a greedy path), and 
2) if $x$ is a local minimum of the greedy max function $g(\cdot,y)$.</p>

<p>In other words, $x$ is a local minimum of $\max_y f(\cdot, y)$ under the constraint that the maximum is computed only over the set of greedy paths starting at $y$.
Unfortunately, even if $f$ is smooth, the greedy max function may not be differentiable with respect to $x$ and may even be discontinuous.</p>

<div style="text-align: center;">
<img alt="" src="http://www.offconvex.org/assets/discontinuity2_grid_t.png" width="400"/> <img alt="" src="http://www.offconvex.org/assets/discontinuity2g_grid_t.png" width="400"/> 
<br/>
 <b>Figure 3.</b> <i>Left:</i> If we change $x$ from one value $x$ to a very close value $\hat{x}$, the largest value of $f$ reachable by greedy path undergoes a discontinuous change.  <i>Right:</i>  This means the greedy max function $g(x,y)$ is discontinuous in $x$.</div>
<p><br/></p>

<p>This creates a problem, since the definition of $\varepsilon$-local minimum only applies to smooth functions.</p>

<p>To solve this problem we would ideally like to smooth $g$ by convolution with a Gaussian.
Unfortunately, convolution can cause the local minima of a function to “shift”– a point which is a local minimum for $g$ may no longer be a local minimum for the convolved version of $g$ (to see why, try convolving the function $f(x) = x - 3x I(x\leq 0) + I(x \leq 0)$ with a Gaussian $N(0,\sigma^2)$ for any $\sigma&gt;0$).
To avoid this, we instead consider a “truncated” version of $g$, and then convolve this function in the $x$ variable with a Gaussian to obtain our smoothed version of $g$.</p>

<p>This allows us to define a notion of greedy min-max equilibrium.  We say that a point $(x^\star, y^\star)$ is a greedy min-max equilibrium if $y^\star$ is an approximate local maximum of $f(x^\star, \cdot)$, and $x^\star$ is an $\varepsilon$-local minimum of this smoothed version of $g(\cdot, y^\star)$.</p>

<blockquote>
  <p><b>Greedy min-max equilibrium:</b>
$(x^{\star}, y^{\star})$ is a greedy min-max equilibrium if

 
where $S(x,y):= \mathrm{smooth}_x(\mathrm{truncate}(g(x, y))$.</p>
</blockquote>

<p>Any point which is a local saddle point (talked about earlier) also satisifeis our equilibrium conditions. The converse, however, cannot be true as a local saddle point may not always exist. Further, for compactly supported convex-concave functions a point is a greedy min-max equilibrium (in an appropriate sense) if and only if it is a global min-max point. (See Section 7 and Appendix A respectively in <a href="https://arxiv.org/abs/2006.12363">our paper</a>.)</p>

<h2 id="greedy-min-max-equilibria-always-exist-and-can-be-found-efficiently">Greedy min-max equilibria always exist! (And can be found efficiently)</h2>
<p>In <a href="https://arxiv.org/abs/2006.12363">this paper</a> we show: A greedy min-max equilibrium is always guaranteed to exist provided that $f$ is uniformly bounded with Lipschitz Hessian. We do so by providing an algorithm which converges to a greedy min-max equilibrium, and, moreover, we show that it is able to do this in polynomial time from any initial point:</p>

<blockquote>
  <p><b>Main theorem:</b> Suppose that we are given access to a smooth function $f:\mathbb{R}^d \times \mathbb{R}^d \rightarrow \mathbb{R}$ and to its gradient and Hessian.  And suppose that $f$ is unformly bounded by $b&gt;0$ and has $L$-Lipschitz Hessian.
Then given any initial point, our algorithm returns an $\varepsilon$-greedy min-max equilibrium $(x^\star,y^\star)$ of $f$ in $\mathrm{poly}(b, L, d, \frac{1}{\varepsilon})$ time.</p>
</blockquote>

<p>There are a number of difficulties that our algorithm and proof must overcome:
One difficulty in designing an algorithm is that the greedy max function may be discontinuous. 
To find an approximate local minimum of a discontinuous function, our algorithm combines a Monte-Carlo hill climbing algorithm with a <a href="https://arxiv.org/abs/cs/0408007">zeroth-order optimization version</a> of stochastic gradient descent.
Another difficulty is that, while one can easily compute a greedy path from any starting point, there may be many different greedy paths which end up at different local maxima.
Searching for the greedy path which leads to the local maximum point with the largest value of $f$ may be infeasible.
In other words the greedy max function $g$ may be intractable to compute.</p>

<div style="text-align: center;">
<img alt="" src="http://www.offconvex.org/assets/greedy_paths_no_axes_t.png" width="400"/> 
<br/>
 <b>Figure 4.</b>There are many different greedy paths that start at the same point $A$.  They can end up at different local maxima ($B$, $D$), with different values of $f$.  In many cases it may be intractable to search over all these paths to compute the greedy max function.
 </div>
<p><br/></p>

<p>To get around this problem, rather than computing the exact value of $g(x,y)$, we instead compute a lower bound $h(x,y)$ for the greedy max function. Since we are able to obtain this lower bound by computing only a <em>single</em> greedy path, it is much easier to compute than greedy max function.</p>

<p>In our paper, we prove that if 1) $x^\star$ is an approximate local minimum for the this lower bound $h(\cdot, y^\star)$, and  2) $y^\star$ is a an approximate local maximum for $f(x^\star, \cdot)$, then $x^\star$ is also an approximate local minimum for the greedy max $g(\cdot, y^\star)$.
This allows us to design an algorithm which obtains a greedy min-max point by minimizing the computationally tractable lower bound $h$, instead of the greedy max function which may be intractable to compute.</p>

<h2 id="to-conclude">To conclude</h2>

<p>In this post we have shown how to extend a notion of second-order equilibrium for minimization to min-max optimization which is guaranteed to exist for any function which is bounded and Lipschitz, with Lipschitz gradient and Hessian.
We have also shown that our algorithm is able to find this equilibrium in  polynomial time from any initial point.</p>

<blockquote>
  <p>Our results do not require any additional assumptions such as convexity, monotonicity, or sufficient bilinearity.</p>
</blockquote>

<p>In an upcoming blog post we will show how one can use some of the ideas from here to obtain a new min-max optimization algorithm with applications to stably training GANs.</p></div>
    </summary>
    <updated>2020-06-24T10:00:00Z</updated>
    <published>2020-06-24T10:00:00Z</published>
    <source>
      <id>http://offconvex.github.io/</id>
      <author>
        <name>Off the Convex Path</name>
      </author>
      <link href="http://offconvex.github.io/" rel="alternate" type="text/html"/>
      <link href="http://offconvex.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Algorithms off the convex path.</subtitle>
      <title>Off the convex path</title>
      <updated>2020-07-02T23:30:28Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/094</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/094" rel="alternate" type="text/html"/>
    <title>TR20-094 |  Is it possible to improve Yao’s XOR lemma using reductions that exploit the efficiency of their oracle? | 

	Ronen Shaltiel</title>
    <summary>Yao's XOR lemma states that for every function $f:\set{0,1}^k \ar \set{0,1}$, if $f$ has hardness $2/3$ for $P/poly$ (meaning that for every circuit $C$ in $P/poly$, $\Pr[C(X)=f(X)] \le 2/3$ on a uniform input $X$), then the task of computing $f(X_1) \oplus \ldots \oplus f(X_t)$ for sufficiently large $t$ has hardness $\half +\epsilon$ for $P/poly$.

Known proofs of this lemma cannot achieve $\epsilon=\frac{1}{k^{\omega(1)}}$, and even for $\epsilon=\frac{1}{k}$, we do not know how to replace
$P/poly$ by AC$^0[\textsc{parity}]$ (the class of constant depth circuits with the gates $\set{\textsc{and,or,not,parity}}$ of unbounded fan-in).

Recently, Grinberg, Shaltiel and Viola (FOCS 2018) (building on a sequence of earlier works) showed that these limitations cannot be circumvented by \emph{black-box reductions}. Namely, by reductions $\Red^{(\cdot)}$ that given oracle access to a function $D$ that violates the conclusion of Yao's XOR lemma, implement a circuit that violates the assumption of Yao's XOR lemma.

There are a few known reductions in the related literature on worst-case to average case reductions that are \emph{non-black box}. Specifically, the reductions of Gutfreund, Shaltiel and Ta Shma (Computational Complexity 2007) and  Hirahara (FOCS 2018)) are ``class reductions'' that are only guaranteed to succeed when given oracle access to an oracle $D$ from some efficient class of algorithms. These works seem to circumvent some black-box impossibility results.

In this paper we extend the previous limitations of Grinberg, Shaltiel and Viola to class reductions, giving evidence that class reductions cannot yield the desired improvements in Yao's XOR lemma.  To the best of our knowledge, this is the first limitation on reductions for hardness amplification that applies to class reductions.

Our technique imitates the previous lower bounds for black-box reductions, replacing the inefficient oracle used in that proof, with an efficient one that is based on limited independence, and developing tools to deal with the technical difficulties that arise following this replacement.</summary>
    <updated>2020-06-24T05:25:21Z</updated>
    <published>2020-06-24T05:25:21Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-07-02T23:29:15Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4870</id>
    <link href="https://www.scottaaronson.com/blog/?p=4870" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4870#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4870" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Pseudonymity as a trivial concession to genius</title>
    <summary xml:lang="en-US">Update (6/24): For further thoughts and context about this unfolding saga, see this excellent piece by Tom Chivers (author of The AI Does Not Hate You, so far the only book about the rationalist community, one that I reviewed here). This morning, like many others, I woke up to the terrible news that Scott Alexander—the […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p><strong><span class="has-inline-color has-vivid-red-color">Update (6/24):</span></strong> For further thoughts and context about this unfolding saga, see <a href="https://unherd.com/2020/06/slate-star-codex-must-remain-anonymous/">this excellent piece by Tom Chivers</a> (author of <em>The AI Does Not Hate You</em>, so far the only book about the rationalist community, one that I <a href="https://www.scottaaronson.com/blog/?p=4361">reviewed here</a>).</p>



<p/><hr/><p/>



<p>This morning, like many others, I woke up to the terrible news that Scott Alexander—the man I call “the greatest Scott A. of the Internet”—has <a href="https://slatestarcodex.com/">deleted SlateStarCodex in its entirety</a>.  The reason, Scott explains, is that the <em>New York Times</em> was planning to run an article about SSC.  Even though the article was going to be <em>positive</em>, NYT decided that by policy, it would need to include Scott’s real surname (Alexander is his middle name).  Scott felt that revealing his name to the world would endanger himself and his psychiatry patients.  Taking down his entire blog was the only recourse that he saw.</p>



<p>The NYT writer, Cade Metz, was someone who I’d previously known and trusted from his reporting on Google’s quantum supremacy experiment.  So in recent weeks, I’d spent a couple hours on the phone with Cade, answering his questions about the rationality community, the history of my interactions with it, and why I thought SlateStarCodex spoke to so many readers.  Alas, when word got around the rationality community that Cade was writing a story, a huge panic arose that he was planning on some sort of <em>Gawker</em>-style hit piece or takedown.  Trying to tamp down the fire, I told Scott Alexander and others that I knew Cade, his intentions were good, he was only trying to understand the community, and everyone should help him by talking to him openly.</p>



<p>In a year of historic ironies, here’s another one: that it was the decent, reasonable, and well-meaning Cade Metz, rather than any of the SneerClubbers or Twitter-gangsters who despised Scott Alexander for sharing his honest thoughts on hot-button issues, who finally achieved the latter’s dark dream of exiling Scott from the public sphere.</p>



<p>The recent news had already been bad enough: Trump’s “temporary suspension” of J1 and H1B visas (which will deal a body blow to American universities this year, and to all the foreign scientists who planned to work at them), on top of the civil unrest, on top of the economic collapse, on top of the now-resurgent coronavirus.  But with no more SlateStarCodex, now I <em>really</em> feel like my world is coming to an end.</p>



<p>I’ve considered SSC to be the best blog on the Internet since not long after discovering it five years ago.  Of course my judgment is colored by one of the most notorious posts in SSC’s history (“Untitled”) being a ferocious defense of me, when thousands were attacking me and it felt like my life was finished.  But that’s merely what brought me there in the first place.  I stayed because of Scott’s insights about everything else, and because of the humor and humanity and craftsmanship of his prose.  Since then I had the privilege to become friends with Scott, not only virtually but in real life, and to meet dozens of others in the SSC community, in its Bay Area epicenter and elsewhere.</p>



<p>In my view, for SSC to be <em>permanently</em> deleted would be an intellectual loss on the scale of, let’s say, John Stuart Mill or Mark Twain burning their collected works.  That might sound like hyperbole, but not (I don’t think) to the tens of thousands who read Scott’s essays and fiction, particularly during their 2013-2016 heyday, and who went from casual enjoyment to growing admiration to the gradual recognition that they were experiencing, “live,” the works that future generations of teachers will assign their students when they cover the early twenty-first century.  The one thing that mitigates this tragedy is the hope that it will yet be reversed (and, of course, the fact that backups still exist in the bowels of the Internet).</p>



<p>When I discovered Scott Alexander in early 2015, the one issue that gave me pause was his strange insistence on maintaining pseudonymity, even as he was already then becoming more and more of a public figure.  In effect, Scott was trying to erect a firewall between his Internet persona and his personal and professional identities, and was <em>relying on the entire world’s goodwill</em> not to breach that firewall.  I thought to myself, “this can’t <em>possibly</em> last!  Scott simply writes too well to evade mainstream notice forever—and once he’s on the world’s radar, he’ll need to make a choice, about who he is and whether he’s ready to own his gifts to posterity under his real name.”  In retrospect, what astonishes me is that Scott has been able to maintain the “double life” for as long as he has!</p>



<p>In his takedown notice, Scott writes that it’s considered vitally important in psychiatry for patients to know almost nothing about their doctors, beyond their names and their areas of expertise.  That caused me to wonder: OK, but doesn’t the world already have enough psychiatrists who are ciphers to their patients?  Would it be so terrible to have one psychiatrist with a clear public persona—possibly even one who patients sought out <em>because</em> of his public persona, because his writings gave evidence that he’d have sympathy or insight about their conditions?  To become a psychiatrist, does one really need to take a lifelong vow of boringness—a vow never to do or say anything notable enough that one would be “outed” to one’s patients?  What would Freud, or Jung, or any of the other famous therapist-intellectuals of times past have thought about such a vow?</p>



<p>Scott also mentions that he’s gotten death threats, and harassing calls to his workplace, from people who hate him because of his blog (and who found his real name by sleuthing).  I wish I knew a solution to that.  For what it’s worth, my blogging has <em>also</em> earned me a death threat, and threats to sue me, and accusatory letters to the president of my university—although in my case, the worst threats came neither from Jew-hating neo-Nazis nor from nerd-bashing SJWs, but from crackpots enraged that I wouldn’t use my blog to credit their proof of P≠NP or their refutation of quantum mechanics.</p>



<p>When I started <em>Shtetl-Optimized</em> back in 2005, I remember thinking: this is it.  From now on, the only secrets I’ll have in life will be ephemeral and inconsequential ones.  From this day on, every student in my class, every prospective employer, every woman who I ask on a date (I wasn’t married yet), can know whatever they want to know about my political sympathies, my deepest fears and insecurities, any of it, with a five-second Google search.  Am I ready for that?  I decided that I was—partly just because I‘ve never had the mental space to maintain multiple partitioned identities <em>anyway</em>, to remember what each one is or isn’t allowed to know and say!  I won’t pretend that this is the right decision for everyone, but it was my decision, and I stuck with it, and it wasn’t always easy but I’m still here and so evidently are you.</p>



<p>I’d be <em>overjoyed</em> if Scott Alexander were someday to reach a place in his life where he felt comfortable deciding similarly.  That way, not only could he enjoy the full acclaim that he’s earned for what he’s given to the world, but (much more importantly) his tens of thousands of fans would be able to continue benefitting from his insights.</p>



<p>For now, though, the brute fact is that Scott is obviously <em>not</em> comfortable making that choice.  That being so, it seems to me that, if the NYT was able to respect the pseudonymity of Banksy and many others who it’s reported on in the past, when revealing their real names would serve no public interest, then it should also be able to respect Scott Alexander’s pseudonymity.  Especially now that Scott has sent the most credible signal imaginable of how much he values that pseudonymity, a signal that astonished even me.  The world does not exist only to serve its rare geniuses, but surely it can make such trivial concessions to them.</p></div>
    </content>
    <updated>2020-06-23T17:41:53Z</updated>
    <published>2020-06-23T17:41:53Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Nerd Interest"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2020-06-30T04:47:23Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/093</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/093" rel="alternate" type="text/html"/>
    <title>TR20-093 |  Reduction From Non-Unique Games To Boolean Unique Games | 

	Dana Moshkovitz, 

	Ronen Eldan</title>
    <summary>We reduce the problem of proving a "Boolean Unique Games Conjecture" (with gap $1-\delta$ vs. $1-C\delta$, for any $C&gt; 1$, and sufficiently small $\delta&gt;0$) to the problem of proving a PCP Theorem for a certain non-unique game.
In a previous work, Khot and Moshkovitz suggested an inefficient candidate reduction (i.e., without a proof of soundness). 
The current work is the first to provide an efficient reduction along with a proof of soundness. 
The non-unique game we reduce from is similar to non-unique games for which PCP theorems are known.
Our proof relies on a new concentration theorem for functions in Gaussian space that are restricted to a random hyperplane. We bound the typical Euclidean distance between the low degree part of the restriction of the function to the hyperplane and the restriction to the hyperplane of the low degree part of the function.</summary>
    <updated>2020-06-23T14:41:45Z</updated>
    <published>2020-06-23T14:41:45Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-07-02T23:29:15Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/06/22/postdoc-at-technion-israel-institute-of-technology-apply-by-august-1-2020/</id>
    <link href="https://cstheory-jobs.org/2020/06/22/postdoc-at-technion-israel-institute-of-technology-apply-by-august-1-2020/" rel="alternate" type="text/html"/>
    <title>Postdoc at Technion Israel Institute of Technology (apply by August 1, 2020)</title>
    <summary>Looking for excellent CS theory graduates for a postdoctoral position at the Computer Science Faculty of Technion Israel Institute of Technology, in Prof. Nir Ailon’s group. Research topics include theory of learning, optimization, information theory and their intersection. Website: https://nailon.net.technion.ac.il/ Email: mayasidis@cs.technion.ac.il</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Looking for excellent CS theory graduates for a postdoctoral position at the Computer Science Faculty of Technion Israel Institute of Technology, in Prof. Nir Ailon’s group. Research topics include theory of learning, optimization, information theory and their intersection.</p>
<p>Website: <a href="https://nailon.net.technion.ac.il/">https://nailon.net.technion.ac.il/</a><br/>
Email: mayasidis@cs.technion.ac.il</p></div>
    </content>
    <updated>2020-06-22T08:35:15Z</updated>
    <published>2020-06-22T08:35:15Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-07-02T23:29:39Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-5075242632528707140</id>
    <link href="https://blog.computationalcomplexity.org/feeds/5075242632528707140/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/06/winner-of-ramsey-meme-contest.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/5075242632528707140" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/5075242632528707140" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/06/winner-of-ramsey-meme-contest.html" rel="alternate" type="text/html"/>
    <title>Winner of Ramsey Meme Contest</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">My REU program had a Ramsey Meme Contest.<br/>
<br/>
The winner was Saadiq Shaik with this entry:<br/>
<br/>
<a href="https://www.cs.umd.edu/users/gasarch/BLOGPAPERS/idont.jpg">I Don't Always...</a><br/>
<br/>
I challenge my readers to come up with other Ramsey Memes! or Complexity Memes! or point me to some that are already out there.<br/>
<br/>
<br/>
<br/>
<br/></div>
    </content>
    <updated>2020-06-22T05:15:00Z</updated>
    <published>2020-06-22T05:15:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2020-07-02T13:25:12Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://theorydish.blog/?p=1791</id>
    <link href="https://theorydish.blog/2020/06/21/free-registeration-to-tcs-women-rising-star-talks/" rel="alternate" type="text/html"/>
    <title>(Free) Registeration to TCS Women Rising Star talks</title>
    <summary>TCS Women Rising Star talks are happening as part of TCS Women STOC Spotlight Workshop. Seven Rising Star speakers are lined up, all of whom are planning to be on the job market this year. In addition, Shafi Goldwasser will give a longer talk. Everybody is invited, but (free) registration is required. (Attendees don’t even have to pay the STOC registration fee.) More information is on the website:https://sigact.org/tcswomen/.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>TCS Women Rising Star talks are happening as part of TCS Women STOC Spotlight Workshop. Seven Rising Star speakers are lined up, all of whom are planning to be <em><strong>on the job market this year</strong></em>. In addition, Shafi Goldwasser will give a longer talk. Everybody is invited, but (free) registration is required. (Attendees don’t even have to pay the STOC registration fee.) More information is on the website:<br/><a href="https://sigact.org/tcswomen/" rel="noreferrer noopener" target="_blank">https://sigact.org/tcswomen/</a>. </p></div>
    </content>
    <updated>2020-06-22T04:16:26Z</updated>
    <published>2020-06-22T04:16:26Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Omer Reingold</name>
    </author>
    <source>
      <id>https://theorydish.blog</id>
      <logo>https://theorydish.files.wordpress.com/2017/03/cropped-nightdish1.jpg?w=32</logo>
      <link href="https://theorydish.blog/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://theorydish.blog" rel="alternate" type="text/html"/>
      <link href="https://theorydish.blog/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://theorydish.blog/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Stanford's CS Theory Research Blog</subtitle>
      <title>Theory Dish</title>
      <updated>2020-07-02T23:30:32Z</updated>
    </source>
  </entry>

  <entry>
    <id>http://benjamin-recht.github.io/2020/06/22/virtual-conferences/</id>
    <link href="http://benjamin-recht.github.io/2020/06/22/virtual-conferences/" rel="alternate" type="text/html"/>
    <title>The Uncanny Valley of Virtual Conferences</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>We wrapped up two amazing days of <a href="http://www.l4dc.org/">L4DC 2020</a> last Friday. It’s pretty wild to watch this community grow so quickly: starting as a <a href="https://kgatsis.github.io/learning_for_control_workshop_CDC2018/">workshop</a> at <a href="https://kgatsis.github.io/learning_for_control_workshop_CDC2018/">CDC 2018</a>, the conference organizers put together an <a href="https://l4dc.mit.edu/">inaugural event at MIT</a> in only a few months and were overwhelmed by nearly 400 attendees. Based on a groundswell of support from the participants, we decided to add contributed talks and papers this year. We had passionate volunteers for our <a href="https://sites.google.com/berkeley.edu/l4dc/organizers-pc">70-person program committee</a>, and they did heroic work of reviewing 135 submissions for this year’s program.</p>

<p>Then, of course, the pandemic hit forcing us to cancel our in-person event. As most conferences in a similar situation as ours, we decided to move to a virtual setting. I think that had we not had contributed papers, we would have simply canceled this year (I’ll return to this later). But to respect the passion and hard-work of our contributors, we tried to come up with a reasonable plan for running this conference virtually.</p>

<p>When we started planning to go virtual, there were too many options to sort through: Zoom webinars and breakout rooms? Sli.do Q&amp;As? Google Hangouts? Slack channels? We had so many tools for virtual community building, each with their own pluses and minuses. Our main constraints were that we wanted to highlight the best contributed papers as talks in some way, to give visibility to the wonderful set of accepted papers without burdening the authors with more work, to be inclusive to the broader community of folks interested in learning and automation, and, importantly, to not charge registration fees.</p>

<p>We eventually settled on the following scheme:</p>
<ol>
  <li>We had a Zoom room for invited and contributed speakers and moderators.</li>
  <li>This Zoom was <a href="https://www.youtube.com/watch?v=b_sJb1k9dVY">live streamed to Youtube</a>.</li>
  <li>Questions were gathered by grad student moderators who scanned the YouTube live chat and then relayed inquiries back to the speakers.</li>
  <li>We tried to keep the live part under four hours per day and to provide ample breaks. We recognize how hard it is to sit in front of a live stream for much more than that.</li>
  <li>Further discussion was then done on <a href="https://openreview.net/group?id=L4DC.org/2020/Conference">OpenReview</a>, where we hosted all accepted papers of the conference.</li>
  <li>The proceedings of the conference were subsequently archived by <a href="http://proceedings.mlr.press/">Proceedings of Machine Learning Research</a>.</li>
</ol>

<p>Though it took a lot of work to tie all these pieces together, everything went super smoothly in the end. I was basically able to run the entire AV setup from my garage.</p>

<p class="center"><img alt="where the magic happens" src="http://www.argmin.net/assets/command_station.jpg" width="250px"/></p>

<p>The only thing that cost money here was the Zoom account (20 dollars/month, though subsidized by Berkeley) and my home internet connection. I know that Zoom and YouTube have well documented issues, and I think it’s imperative that they continue to strive to fix these problems, but I also think it’s easy to forget how empowering this technology is. This format opens up conferences to those who can’t travel for financial or logistical reasons, and lowers the energy to engage with cutting edge research. Being able to sit in my garage and run a virtual conference with speakers spanning 10 time zones and nearly 2000 viewers is a wonder of modern times.</p>

<h2 id="second-life-still-has-a-long-way-to-go">Second Life still has a long way to go.</h2>

<p>There are still many parts of the online conference that felt cheated and incomplete. I still don’t know how to run a virtual poster session effectively. Most of our papers have not yet received any comments on <a href="https://openreview.net/group?id=L4DC.org/2020/Conference">OpenReview</a>, though comments are still open and I’d encourage you to drop by and ask questions! Partially, I think this lack of engagement stems from the considerable amount of effort required to participate, especially when it is compared to somewhat aimlessly ambling through a poster session.</p>

<p>Indeed, many aspects of live conferences are simply not replicable with our current tools, whether they be chance encounters or meetings with friends from far away. On the other hand, maybe we shouldn’t try to replicate this experience! Maybe we need to think harder about what opportunities our technology has for building communities and how we can better support these facets of academic interaction. When I think back on the decades of conferences I’ve attended, I can think of only a few posters that really got me interested in reading a paper, and <a href="https://papers.nips.cc/paper/3323-the-tradeoffs-of-large-scale-learning.pdf">one later won a test of time award at NeurIPS</a>. Poster sessions always felt like an anachronistic means to justify a work travel expense rather than an effective means of academic knowledge dissemination. Is there a better way forward that uses our current technological constraints to amplify the voices of young scholars with cutting edge ideas? I don’t have great ideas for how to do this yet, but new interaction structures may emerge as we deal with at least one more year without meetings with hundreds of people.</p>

<h2 id="how-much-should-conferences-cost">How much should conferences cost?</h2>

<p>We were able to do L4DC, with the proceedings and all, for free. Obviously, the program committee put in tons of work in reviewing and organizing the logistics. But reviewing labor isn’t compensated by any conference. All peer reviewed conferences rely on the volunteer service labor of a dedicated program committee. The main line items we expected for L4DC were for renting physical space, paying an AV crew, and food. But in the virtual world, these expenses drop to near zero.</p>

<p>I’m supposed to give a plenary talk at the <a href="https://www.ifac2020.org/">Virtual IFAC Congress</a> in July. I have to say, I am troubled: IFAC is charging <a href="https://www.ifac2020.org/registration/">380 euros per person</a> for registration. [<strong>UPDATE (06/28/20):</strong> <em>IFAC has reduced their registration fee to 80 euros for those who wish to watch videos but not upload a paper. 40 euros for students. Kudos to them for reducing the fees.</em>]
What does one get for this sum? Access to video streams and the ability to publish papers. This seems exorbitantly expensive. Why would anyone watch a talk I give at IFAC when I promise to just release it on YouTube at the same time? What value is IFAC providing back to the academic community?</p>

<h2 id="decoupling-papers-from-talks">Decoupling papers from talks</h2>

<p>One of the main things the registration fee at many conferences provides is a stamp of academic approval. It is a de facto publication fee. Led by computer science, conferences in engineering are replacing journals as the archives where CV-building work is cataloged. Though this wasn’t the initial purpose of conferences in computer science, conferences do have many attractive features over journals for rapidly evolving fields: Conferences have speedy turn-around times and clearly delineated submission and decision dates. This archival aspect of conferences, however, has nothing to do with community building or scholarly dissemination. Why do we need to couple a talk to a publication? Can’t we separate these two as is done in every other academic field?</p>

<p>Our collective pandemic moment gives us an opportunity not only to rethink community-building but also our publication model. With 10000-person mega-conferences like <a href="http://icml.cc">AI Summer</a> and <a href="http://neurips.cc">AI Winter</a>, why can’t we keep all of the deadlines the same but remove all of the talks? We’d still have the same reviewing architecture, which has been wholly virtual for over a decade. And we could still publish all of the proceedings online for free, which has been done for multiple decades.</p>

<p>The decoupling proposal here would have effectively zero overhead on our communities: the deadlines, CMTs, program committees, and proceedings could all function exactly the same way (though, to be fair, these systems all have warts worth improving upon). New archival, fast-turnaround journals could easily start using the same tools. Indeed, I’ve always been enamored with the idea of an arxiv-overlay journal that simply is a table of contents that points towards particular versions of arxiv papers as “accepted.” And a really radical idea would be to solicit <em>talks</em>—not papers—for virtual conferences where potential speakers would submit slides or videos to demonstrate proficiency in the medium in which they’d present.</p>

<p>I tend to dismiss most of the bloviation about how coronavirus permanently changes everything about how we live our lives. But it does provide us an opportunity to pause and assess whether current systems are functioning well. I’d argue that the current conference system hasn’t been functioning well for a while, but this simple decoupling of papers and talks might clear up a lot of the issues currently facing the hard-charging computing world.</p>

<p><em>Many thanks to my dedicated, passionate L4DC Co-organizers: Alex Bayen, Ali Jadbababie, George Pappas, Pablo Parrilo, Claire Tomlin, and Melanie Zeilinger. I’d also like to thank Rediet Abebe, Jordan Ellenberg, Eric Jonas, Angjoo Kanazawa, Adam Klivans, Nik Matni, Chris Re, and Tom Ristenpart for their helpful feedback on this post.</em></p></div>
    </summary>
    <updated>2020-06-22T00:00:00Z</updated>
    <published>2020-06-22T00:00:00Z</published>
    <source>
      <id>http://benjamin-recht.github.io/</id>
      <author>
        <name>Ben Recht</name>
      </author>
      <link href="http://benjamin-recht.github.io/" rel="alternate" type="text/html"/>
      <link href="http://benjamin-recht.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Musings on systems, information, learning, and optimization.</subtitle>
      <title>arg min blog</title>
      <updated>2020-07-02T23:30:37Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2020/06/21/subpract</id>
    <link href="https://11011110.github.io/blog/2020/06/21/subpract.html" rel="alternate" type="text/html"/>
    <title>Subpract</title>
    <summary>I’ve written here before about subtraction games, two-player games in which the players remove tokens from a pile of tokens, the number of removed tokens is required to belong to a designated subtraction set, and the goal is to make the last move. For instance, subtract a square, a game I studied at FUN 2018, is of this type, with the subtraction set being the square numbers.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I’ve <a href="https://11011110.github.io/blog/2018/04/18/subtraction-games.html">written here before</a> about <a href="https://en.wikipedia.org/wiki/Subtraction_game">subtraction games</a>, two-player games in which the players remove tokens from a pile of tokens, the number of removed tokens is required to belong to a designated <em>subtraction set</em>, and the goal is to make the last move. For instance, <a href="https://en.wikipedia.org/wiki/Subtract_a_square">subtract a square</a>, a game <a href="https://doi.org/10.4230/LIPIcs.FUN.2018.20">I studied at FUN 2018</a>, is of this type, with the subtraction set being the square numbers.</p>

<p>At some point in studying these games I also briefly looked at the subtraction game whose subtraction set is the set of <a href="https://en.wikipedia.org/wiki/Practical_number">practical numbers</a>, the numbers whose sums of divisors include all values up to the given numbers. The sequence of these numbers begins</p>



<p>and it turns out to be important here that, after the first one, they’re all even. Let’s call the subtraction game with this subtraction set <em>subpract</em>.</p>

<p>For a subtraction game, or more generally any <a href="https://en.wikipedia.org/wiki/Impartial_game">impartial game</a>, the game states can be partitioned into -positions (where the player who played previously is winning with optimal play) and -positions (where the next player to move can force a win); the -positions tend to be rarer than the -positions, and it’s important to know where they are because the optimal strategy in the game is to move to a -position whenever possible.</p>

<p><a href="http://oeis.org/A275432">OEIS A275432</a> lists the -positions for subpract. They are:</p>



<p>For instance, it’s a winning move in subpract to move to a pile of ten tokens (if you can), because  whatever move your opponent makes from there lets you win. If your opponent takes an even number of tokens, you will be able to take all the remaining tokens and win immediately. And if your opponent takes one token, leaving a pile of nine tokens, you can win by taking six more and leaving a pile of three tokens. Then, regardless of how your opponent responds, you will be able to take all the tokens on your next move.</p>

<p>An obvious pattern jumps out from this list of -positions: they come in pairs, spaced three apart. More precisely, an even number  is a -position if and only if the odd number  is a -position. It’s not just a coincidence, true at the start of the sequence and then false later on: it carries on throughout the entire sequence of -positions. More strongly, this same three-apart pairing of  -positions holds for any subtraction game whose subtraction set contains <span style="white-space: nowrap;">, , and ,</span> and does not contain any other odd numbers.</p>

<h1 id="proof-of-the-pairing-property">Proof of the pairing property</h1>

<p>To prove this, I need to show that  is a -position if and only if  is a winning position. We can prove this by induction, where we assume that all the -positions below  and  are paired up in the same way, and use it to prove that the same pairing holds for  and . The basic idea of the proof is to assume that one of the two players has a winning strategy for the <span style="white-space: nowrap;">position ,</span> and to copy that strategy for , most of the time playing the same moves and responses that you would play for the smaller position. Whenever a sequence of moves is applicable to both  and  and preserves the parity of the starting position, the induction hypothesis shows that it has the same outcome for both starting positions. However, there are a few cases where you may be forced to deviate from this strategy:</p>

<ul>
  <li>
    <p>If  is an -position, but its winning move is to subtract one token leading to an odd -position , then copying that move from the starting position  would lead to the position  which may not be a -position. Instead you should subtract four tokens to get to the position  directly.</p>
  </li>
  <li>
    <p>If  is a -position, and you’re trying to copy its winning strategy in the position , your opponent may be able to subtract , a move that is not possible in , so you have no response to copy. But in this case the result is a pile of just one token, from which you can immediately win.</p>
  </li>
  <li>
    <p>Again, if you’re trying to copy the winning strategy for -position  in the position , your opponent may subtract only one token. In this case, the winning response when starting from  might be to subtract an even number, leading to an odd -position . If you copy this response, you will end up at  which may not be a -position. But instead of copying the -strategy, you can simply subtract two tokens, leading to the position  itself.</p>
  </li>
  <li>
    <p>Similarly, it may be the case that the winning response to an opponent’s even move from  is to take a single token, leading to odd -position . Copying this strategy from the starting position  would again lead to . But in this case you can subtract four tokens leading to  again.</p>
  </li>
</ul>

<p>It’s tempting to guess that, more strongly than pairing -positions and -positions in this way, subpract and similar subtraction games have a pairing of their <a href="https://en.wikipedia.org/wiki/Sprague%E2%80%93Grundy_theorem">nim-values</a>, where the nim-value of an odd position always equals the nim-value of the even position three units smaller. But it’s not true. For instance, in subpract, a pile of four tokens has nim-value 1 while a pile of seven tokens has nim-value 4.</p>

<h1 id="other-subtraction-sets">Other subtraction sets</h1>

<p>Probably the most obvious choice of another subtraction set that begins  and has no larger odd numbers would be the powers of two, but they don’t give rise to an interesting subtraction game: the -positions are just the multiples of three. The same thing happens whenever there are no multiples of three in the subtraction set, as happens for instance with the <a href="https://11011110.github.io/blog/2020/06/21/Telephone number (mathematics)">telephone numbers</a> and <a href="http://oeis.org/A003422">left factorials</a>.</p>

<p>Another natural subtraction set to which this theory applies is the sequence of <a href="http://oeis.org/A025487">Hardy–Ramanujan integers (A025487)</a>, the numbers whose prime factorization  has a non-increasing sequence of exponents . They are:</p>



<p>These are a subset of the practical numbers so one would expect their subtraction game to have more-dense -positions. My implementation found that these -positions are:</p>



<p>again obeying the offset-by-three pairing as it should, and otherwise having somewhat irregular intervals between its -positions.</p>

<p>The <a href="http://oeis.org/A000084">enumeration function of the series-parallel graphs and the cographs</a> is even after its first term because of series-parallel duality; it begins</p>



<p>These are not all practical; for instance, 10, 1532, and 43930 are not practical. The sequence of -positions for their subtraction game begins</p>



<p>mostly differing by three between consecutive values but with occasional glitches where the larger multiple-of-three subtraction set values kick in.</p>

<p>And finally, if we subtract numbers that are one less than a prime, we get the subtraction set</p>



<p>and the sequence of -positions</p>



<p>Its small values have many five-unit gaps but that pattern appears to die out after the quadruple of -positions .</p>

<p>(<a href="https://mathstodon.xyz/@11011110/104384624632242432">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2020-06-21T16:29:00Z</updated>
    <published>2020-06-21T16:29:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2020-06-30T23:34:57Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=17214</id>
    <link href="https://rjlipton.wordpress.com/2020/06/21/some-real-and-some-virtual-news/" rel="alternate" type="text/html"/>
    <title>Some Real and Some Virtual News</title>
    <summary>Gossip and more. Composite of , src1, src3 Jessica Deters, Izabel Aguiar, and Jacqueline Feuerborn are the authors of the paper, “The Mathematics of Gossip.” They use infection models—specifically the Susceptible-Infected-Recovered (SIR) model—to discuss gossip. Their work was done before the present pandemic, in 2017–2019. It is also described in a nice profile of Aguiar. […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Gossip and more.</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2020/06/detersaguiarfeuerborn-1.png"><img alt="" class="alignright size-full wp-image-17221" src="https://rjlipton.files.wordpress.com/2020/06/detersaguiarfeuerborn-1.png?w=600"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Composite of <a href="https://jessicadeters.wordpress.com/">, </a><a href="https://izabelpaguiar.com/about/">src1</a>, <a href="https://www.linkedin.com/in/jacqueline-feuerborn-87b7b3106/">src3</a></font></td>
</tr>
</tbody>
</table>
<p>
Jessica Deters, Izabel Aguiar, and Jacqueline Feuerborn are the authors of the <a href="https://scholarship.claremont.edu/cgi/viewcontent.cgi?article=1036&amp;context=codee">paper</a>, “The Mathematics of Gossip.” They use infection models—specifically the Susceptible-Infected-Recovered (<a href="https://en.wikipedia.org/wiki/Compartmental_models_in_epidemiology#The_SIR_model">SIR</a>) model—to discuss gossip. Their work was done <em>before</em> the present pandemic, in 2017–2019.  It is also described in a nice <a href="https://sciencebuffs.org/2018/05/14/to-gossip-is-human-to-math-divine/">profile</a> of Aguiar. Their analogy is expressed by a drawing in their paper: </p>
<p><a href="https://rjlipton.files.wordpress.com/2020/06/gossipcough.jpg"><img alt="" class="aligncenter wp-image-17218" height="125" src="https://rjlipton.files.wordpress.com/2020/06/gossipcough.jpg?w=400&amp;h=125" width="400"/></a></p>
<p/><p><br/>
Not just for today, but for the summer at least, Ken and I want to share some gossip, share some problems, and ask our readers a question.</p>
<p><span id="more-17214"/></p>
<p>
The question first. Ken and I wonder if GLL should start a virtual theory “lunch” meeting, that would meet periodically via Zoom. It would be like meeting for a theory lunch in the old days—just not all in the same room. Some topic might be agreed on, perhaps a short presentation, and always a chance to swap some gossip. Plus maybe ask the group for advice on a problem.</p>
<p>
I do miss the old meetings: </p>
<p/><p/>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2020/06/meet.png"><img alt="" class="aligncenter size-medium wp-image-17219" height="224" src="https://rjlipton.files.wordpress.com/2020/06/meet.png?w=300&amp;h=224" width="300"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">AcademicKeys #78 <a href="https://www.academickeys.com/all/cartoon.php?dothis=display&amp;cartoon[IDX]=78">source</a></font>
</td>
</tr>
</tbody></table>
<p>
What do you think? Should we have such meetings?</p>
<p>
</p><p/><h2> Some Gossip </h2><p/>
<p/><p>
The study of gossip feeds into other issues of the spread of information and misinformation during an election year. Ken’s Buffalo colleague Kenny Joseph has <a href="https://kennyjoseph.github.io/">research</a> on the spread of fake news and Twitter sentiment using mathematical tools adjacent to those of the trio above. Ken and I still intend to say more about epidemiology models ourselves when we get time. But no, here by “gossip” we just mean actual pieces of gossip—just as at a conference or other kind of in-person meeting.</p>
<p>
Here are two examples of the kind of gossip we might exchange. </p>
<p>
Anna Gilbert is moving from Michigan math to Yale math and statistics. She will be the John C. Malone Professor of Mathematics, Professor of Statistics &amp; Data Science. Pretty impressive. She was at Michigan math for <img alt="{2^{4}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5E%7B4%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2^{4}}"/> years. She told me that she could not wait for the next power of <img alt="{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2}"/>, and thus had to try a new place, with new challenges. </p>
<p>
<a href="https://rjlipton.files.wordpress.com/2020/06/gilbert-1.png"><img alt="" class="aligncenter wp-image-17233" height="163" src="https://rjlipton.files.wordpress.com/2020/06/gilbert-1.png?w=127&amp;h=163" width="127"/></a></p>
<p>
Rich DeMillo is a long time friend who is at Georgia Institute of Technology and is not moving. He continues working on making voting fair, secure, and efficient. He is referenced in a recent article on voting issues in Georgia. See <a href="https://www.voanews.com/usa/us-politics/activists-cite-tabulation-flaw-georgia-mail-ballots">here</a> for details. </p>
<p>
<a href="https://rjlipton.files.wordpress.com/2020/06/demillo-1.jpg"><img alt="" class="aligncenter wp-image-17234" height="138" src="https://rjlipton.files.wordpress.com/2020/06/demillo-1.jpg?w=149&amp;h=138" width="149"/></a></p>
<p>
Note: we have in mind pleasant and factual gossip. The most useful kind is about probable directions and emphases to make projects attractive to pursue. This leads into our other component.</p>
<p>
</p><p/><h2> Possible Problems To Present </h2><p/>
<p/><p>
Here are a problem from each of us as examples of what could be discussed in these meetings and why that might give advantage over just hunting the literature. Both are about factoring—always factoring…</p>
<p>
</p><p/><h3> Factoring: Ken </h3><p/>
<p/><p>
I, Ken, would like to know about field tests of approximative methods in quantum computing, specifically of shortcuts to Shor’s Algorithm. The approximations I have in mind are rougher than those I find in the literature and need not be physically natural.</p>
<p>
To explain, the way Shor’s algorithm is proven correct in Shor’s paper and all textbooks we know—including ours—uses an exact analysis involving the quantum Fourier transform, in which exponentially fine phase angles appear in terms. Approximation can be argued in several ways. Circuits of Hadamard, CNOT, and <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/>-gates, in which no phase angle finer than <img alt="{\pi/4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%2F4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\pi/4}"/> appears, can approximate arbitrary quantum circuits to exponential precision with polynomial overhead. With just Hadamard and Toffoli gates, hence <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/> and <img alt="{\pi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\pi}"/> as the only phases, one can approximate the data returned by measurements in the algorithm, though without approximating the algorithm’s result vectors in complex Hilbert space. There are other ways to approximate those vectors while eliding the finer phase components. We would like to see more attention to the concrete overheads of all these methods.</p>
<p>
What I would really like to discuss, however, is efforts toward more-brusque approximations that could yield new classical attempts on factoring. For a broad example, note that not only does <img alt="{\mathsf{BQP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BBQP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{BQP}}"/> reduce to <img alt="{\mathsf{\#P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7B%5C%23P%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{\#P}}"/> but also individual steps in Shor’s algorithm can be broken down as reductions to counting. Now suppose we apply approximate counting heuristics to those steps. The stock answer for why this doesn’t work to approximate quantum measurement properties <em>globally</em> is that those probabilities have the form </p>
<p align="center"><img alt="\displaystyle  p = \frac{f_1(x) - f_2(x)}{D} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++p+%3D+%5Cfrac%7Bf_1%28x%29+-+f_2%28x%29%7D%7BD%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  p = \frac{f_1(x) - f_2(x)}{D} "/></p>
<p>where <img alt="{f_1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_1}"/> and <img alt="{f_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_2}"/> are <img alt="{\mathsf{\#P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7B%5C%23P%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{\#P}}"/> functions and <img alt="{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D}"/> is something like <img alt="{2^{n/2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5E%7Bn%2F2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2^{n/2}}"/>. Note the knowledge beforehand that <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> is between <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/> and <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>. The point is that <img alt="{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D}"/> is exponential yet smaller than the additive approximations possible in polynomial time for <img alt="{f_1(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_1%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_1(x)}"/> and <img alt="{f_2(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_2%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_2(x)}"/> individually, so the approximation gives no help to the difference. </p>
<p>
However, this does not prevent using approximations of magnitudes that are not differences at intermediate steps. For a vein of more particular examples, I raise the translation from quantum gates to Boolean formulas in my 2018 <a href="https://link.springer.com/chapter/10.1007/978-3-662-56499-8_4">paper</a> with Amlan Chakrabarti and my recent PhD graduate Chaowen Guan. This translation can encode the state <img alt="{\Phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CPhi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Phi}"/> at any intermediate stage of an execution of Shor’s algorithm by a Boolean formula <img alt="{\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\phi}"/>. The size of <img alt="{\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\phi}"/> stays linear in the size of the quantum circuit being simulated—the exponential explosion happens only when we try to count solutions to <img alt="{\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\phi}"/>. The formula <img alt="{\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\phi}"/> encodes all the information in <img alt="{\Phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CPhi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Phi}"/>, including the implicit presence of fine phase angles. Now suppose we alter <img alt="{\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\phi}"/> to a <img alt="{\phi'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\phi'}"/> whose corresponding <img alt="{\Phi'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CPhi%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Phi'}"/> is a simplified approximation of <img alt="{\Phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CPhi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Phi}"/>. The kicker is that <img alt="{\Phi'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CPhi%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Phi'}"/> might not need to be a legal quantum state. The transformations in our paper for later stages of the circuit will still apply building on <img alt="{\phi'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\phi'}"/>. </p>
<p>
Is there any chance of this working? Heuristic approaches applying SAT to factoring have been tried and found to be <a href="https://toughsat.appspot.com/">tough</a>. The nice site <a href="http://beyondnp.org/">BeyondNP</a> includes <a href="http://beyondnp.org/pages/solvers/model-counters-exact/">links</a> to #SAT counters such as <a href="https://sites.google.com/site/marcthurley/sharpsat">sharpSAT</a> and <a href="https://www.cs.rochester.edu/u/kautz/Cachet/index.htm">Cachet</a>. Thus we are not asking anything outlandish. Leveraging Shor’s algorithm might be a new approach. Has anyone tried it? That’s the kind of question I would visit a conference to ask, where wider arity might work better than asking people individually. Thus also for raising it in a meeting.</p>
<p>
</p><p/><h3> Factoring: Dick </h3><p/>
<p/><p>
I have recently been thinking about the power of weak sub-theories of Peano Arithmetic. There are many proofs known that there are an infinite number of prime numbers. The usual proofs use this:</p>
<blockquote><p><b> </b> <em> For all <img alt="{x&gt;1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%3E1%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{x&gt;1}"/> there is some prime <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{p}"/> that divides <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{x}"/>. </em>
</p></blockquote>
<p>Given this it is not hard to prove, in many ways, that there are an infinite number of primes. Euclid’s original proof uses it in the step: Let <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> divide <img alt="{p_{1}\cdots p_{n} + 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_%7B1%7D%5Ccdots+p_%7Bn%7D+%2B+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p_{1}\cdots p_{n} + 1}"/>. The idea is suppose some weak theory can prove the above. This means that it can prove: 	</p>
<p align="center"><img alt="\displaystyle  \forall x&gt;1 \ \exists y \ y|x \text{ and } \mathsf{prime}(y). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cforall+x%3E1+%5C+%5Cexists+y+%5C+y%7Cx+%5Ctext%7B+and+%7D+%5Cmathsf%7Bprime%7D%28y%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \forall x&gt;1 \ \exists y \ y|x \text{ and } \mathsf{prime}(y). "/></p>
<p>	 I believe that this shows that if the theory is weak enough that this implies that factoring is in polynomial time. Is this known? Is it true? </p>
<p>
Once again, we can hunt for literature on this. We can ask individual people, such as Avi Wigderson and various co-authors of his. But our hunch is that this topic was explored in the 1990s without a definitive resolution. It could be more effective to get up to speed on it and share ideas in a meeting.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Should we start a virtual theory lunch? Would you attend?</p>
<p>
<b>Added 6/21:</b> Getting back to gossip, we wonder if the all-to-all nature of a Zoom meeting, versus few-to-few in a conference hallway, would filter out the badder kinds of gossip.</p></font></font></div>
    </content>
    <updated>2020-06-21T15:17:56Z</updated>
    <published>2020-06-21T15:17:56Z</published>
    <category term="All Posts"/>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="People"/>
    <category term="Factoring"/>
    <category term="Gossip"/>
    <category term="infection models"/>
    <category term="Izabel Aguiar"/>
    <category term="Jacqueline Feuerborn"/>
    <category term="Jessica Deters"/>
    <category term="Logic"/>
    <category term="meetings"/>
    <category term="quantum"/>
    <category term="Shor's algorithm"/>
    <category term="videoconferencing"/>
    <category term="witness functions"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2020-07-02T23:29:34Z</updated>
    </source>
  </entry>
</feed>
