<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2020-12-07T07:39:01Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=5151</id>
    <link href="https://www.scottaaronson.com/blog/?p=5151" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=5151#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=5151" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Shor’s algorithm in higher dimensions: Guest post by Greg Kuperberg</title>
    <summary xml:lang="en-US">Upbeat advertisement: If research in QC theory or CS theory otherwise is your thing, then wouldn’t you like to live in peaceful, quiet, bicycle-based Davis, California, and be a faculty member at the large, prestigious, friendly university known as UC Davis? In the QCQI sphere, you’d have Marina Radulaski, Bruno Nachtergaele, Martin Fraas, Mukund Rangamani, Veronika Hubeny, and Nick Curro as faculty colleagues, among others; […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p><strong>Upbeat advertisement:</strong> If research in QC theory or CS theory otherwise is your thing, then wouldn’t you like to live in peaceful, quiet, <a href="https://vimeo.com/75059452" rel="noreferrer noopener" target="_blank">bicycle-based</a><a href="https://en.wikipedia.org/wiki/Davis,_California" rel="noreferrer noopener" target="_blank"> Davis, California</a>, and be a faculty member at the large, prestigious, friendly university known as <a href="https://www.ucdavis.edu/" rel="noreferrer noopener" target="_blank">UC Davis</a>? In the QCQI sphere, you’d have <a href="https://sites.google.com/site/marinaradulaski/" rel="noreferrer noopener" target="_blank">Marina Radulaski</a>, <a href="https://www.math.ucdavis.edu/~bxn/" rel="noreferrer noopener" target="_blank">Bruno Nachtergaele</a>, <a href="https://www.math.ucdavis.edu/~fraas/" rel="noreferrer noopener" target="_blank">Martin Fraas</a>, <a href="https://mukund.physics.ucdavis.edu/" rel="noreferrer noopener" target="_blank">Mukund Rangamani</a>, <a href="https://hubeny.physics.ucdavis.edu/" rel="noreferrer noopener" target="_blank">Veronika Hubeny</a>, and <a href="https://curro.ucdavis.edu/">Nick Curro</a> as faculty colleagues, among others; and <a href="https://www.math.ucdavis.edu/~greg/" rel="noreferrer noopener" target="_blank">yours truly</a>, and hopefully more people in the future. This year the UC Davis <a href="https://cs.ucdavis.edu/" rel="noreferrer noopener" target="_blank">CS department</a> has a <a href="https://recruit.ucdavis.edu/JPF03853" rel="noreferrer noopener" target="_blank">faculty opening in quantum computing</a>, and another <a href="https://recruit.ucdavis.edu/JPF03838" rel="noreferrer noopener" target="_blank">faculty opening in CS theory</a> including quantum computing. If you are interested, then time is of the essence, since the full-consideration deadline is December 15.</p>



<hr class="wp-block-separator"/>



<p>In this guest post, I will toot my own horn about a paper in progress (hopefully nearly finished) that goes back to the revolutionary early days of quantum computing, namely Shor’s algorithm. <strong>The takeway: I think that the strongest multidimensional generalization of Shor’s algorithm has been missed for decades. It appears to be a new algorithm that does more than the standard generalization described by Kitaev.</strong> (Scott wanted me to channel Captain Kirk and boldly go with a takeaway, so I did.)</p>



<p>Unlike Shor’s algorithm proper, I don’t know of any dramatic applications of this new algorithm. However, more than one quantum algorithm was discovered just because it looked interesting, and then found applications later. The input to Shor’s algorithm is a function \(f:\mathbb{Z} \to S\), in other words a symbol-valued function \(f\) on the integers, which is periodic with an unknown period \(p\) and otherwise injective. In equations, \(f(x) = f(y)\) if only if \(p\) divides \(x-y\). In saying that the input is a function \(f\), I mean that Shor’s algorithm is provided with an algorithm to compute \(f\) efficiently. Shor’s algorithm itself can then find the period \(p\) in (quantum) polynomial time in the number of digits of \(p\). (Not polynomial time in \(p\), polynomial time in its logarithm.) If you’ve heard that Shor’s algorithm can factor integers, that is just one special case where \(f(x) = a^x\) mod \(N\), the integer to factor. In its generalized form, Shor’s algorithm is miraculous. In particular, if \(f\) is a black-box function, then it is routine to prove that any classical algorithm to do the same thing needs exponentially many values of \(f\), or values \(f(x)\) where \(x\) has exponentially many digits.</p>



<p>Shor’s algorithm begat the Shor-Kitaev algorithm, which does the same thing for a higher dimensional periodic function \(f:\mathbb{Z}^d \to S\), where \(f\) is now periodic with respect to a lattice \(L\). The Shor-Kitaev algorithm in turn begat the hidden subgroup problem (called HSP among friends), where \(\mathbb{Z}\) or \(\mathbb{Z}^d\) is replaced by a group \(G\), and now \(f\) is \(L\)-periodic for some subgroup \(L\). HSP varies substantially in both its computationally difficulty and its complexity status, depending on the structure of \(G\) as well as optional restrictions on \(L\).</p>



<p>A funny thing happened <s>on the way to the forum</s> in later work on HSP. Most of the later work has been in the special case that the ambient group \(G\) is finite, even though \(G\) is infinite in the famous case of Shor’s algorithm. My paper-to-be explores the hidden subgroup problem in various cases when \(G\) is infinite. In particular, I noticed that even the case \(G = \mathbb{Z}^d\) isn’t fully solved, because the Shor-Kitaev algorithm makes the extra assumption that \(L\) is a maximum-rank lattice, or equivalently that \(L\) a finite-index subgroup of \(\mathbb{Z}^d\). As far as I know, the more general case where \(L\) might have lower rank wasn’t treated previously. I found an extension of Shor-Kitaev to handle this case, which is I will sketch after discussing some points about HSP in general.</p>



<h2>Quantum algorithms for HSP</h2>



<p>Every known quantum algorithm for HSP has the same two opening steps. First prepare an equal superposition \(|\psi_G\rangle\) of “all” elements of the ambient group \(G\), then apply a unitary form of the hiding function \(f\) to get the following: \[ U_f|\psi_G\rangle \propto \sum_{x \in G} |x,f(x)\rangle. \] Actually, you can only do exactly this when \(G\) is a finite group. You cannot make an equal quantum superposition on an infinite set, for the same reason that you cannot choose an integer uniformly at random from among all of the integers: It would defy the laws of probability. Since computers are finite, a realistic quantum algorithm cannot make an unequal quantum superposition on an infinite set either. However, if \(G\) is a well-behaved infinite group, then you can approximate the same idea by making an equal superposition on a large but finite box \(B \subseteq G\) instead: \[ U_f|\psi_G\rangle \propto \sum_{x \in B \subseteq G} |x,f(x)\rangle. \] Quantum algorithms for HSP now follow a third counterintuitive “step”, namely, that you should discard the output qubits that contain the value \(f(x)\). You should take the values of \(f\) to be incomprehensible data, encrypted for all you know. A good quantum algorithm evaluates \(f\) too few times to interpret its output, so you might as well let it go. (By contrast, a classical algorithm is forced to dig for the only meaningful information that the output of \(f\) to have. Namely, it has to keep searching until it finds equal values.) What remains, want what turns out to be highly valuable, is the input state in a partially measured form. I remember joking with <a href="http://tuvalu.santafe.edu/~moore/" rel="noreferrer noopener" target="_blank">Cris Moore</a> about the different ways of looking at this step:</p>



<ol><li>You can measure the output qubits.</li><li>The janitor can fish the output qubits out of the trash and measure them for you.</li><li>You can secretly not measure the output qubits and say you did.</li><li>You can keep the output qubits and say you threw them away.</li></ol>



<p>Measuring the output qubits wins you the purely mathematical convenience that the posterior state on the input qubits is pure (a vector state) rather than mixed (a density matrix). However, since no use is made of the measured value, it truly makes no difference for the algorithm.</p>



<p>The final universal step for all HSP quantum algorithms is to apply a quantum Fourier transform (or QFT) to the input register and measure the resulting Fourier mode. This might seem like a creative step that may or may not be a good idea. However, if you have an efficient algorithm for the QFT for your particular group \(G\), then you might as well do this, because (taking the interpretation that you threw away the output register) the environment already knows the Fourier mode. You can assume that this Fourier mode has been published in the New York Times, and you won’t lose anything by reading the papers.</p>



<h2>Fourier modes and Fourier stripes</h2>



<p>I’ll now let \(G = \mathbb{Z}^d\) and make things more explicit, for starters by putting arrows on elements \(\vec{x} \in \mathbb{Z}^d\) to indicate that they are lattice vectors. The standard begining produces a superposition \(|\psi_{L+\vec{v}}\rangle\) on a translate \(L+\vec{v}\) of the hidden lattice \(L\). (Again, \(L\) is the periodicity of \(f\).) If this state could be an equal superposition on the infinite set \(L+\vec{v}\), and if you could do a perfect QFT on the infinite group \(\mathbb{Z}^d\), then the resulting Fourier mode would be a randomly chosen element of a certain dual group \(L^\# \subseteq (\mathbb{R}/\mathbb{Z})^d\) inside the torus of Fourier modes of \(\mathbb{Z}^d\). Namely, \(L^\#\) consists of those vectors \(\vec{y} \in (\mathbb{R}/\mathbb{Z})^d\) whose such that the dot product \(\vec{x} \cdot \vec{y}\) is an integer for every \(\vec{x} \in L\). (If you expected the Fourier dual of the integers \(\mathbb{Z}\) to be a circle \(\mathbb{R}/2\pi\mathbb{Z}\) of length \(2\pi\), I found it convenient here to rescale it to a circle \(\mathbb{R}/\mathbb{Z}\) of length 1. This is often considered gauche these days, like using \(h\) instead of \(\hbar\) in quantum mechanics, but in context it’s okay.) In principle, you can learn \(L^\#\) from sampling it, and then learn \(L\) from \(L^\#\). Happily, the unknown and irrelevant translation vector \(\vec{v}\) is erased in this method.</p>



<p>In practice, it’s not so simple. As before, you cannot actually make an equal superposition on all of \(L+\vec{v}\), but only trimmed to a box \(B \subseteq \mathbb{Z}^d\). If you have \(q\) qubits available for each coordinate of \(\mathbb{Z}^d\), then \(B\) might be a \(d\)-dimensional cube with \(Q = 2^q\) lattice points in each direction. Following Peter Shor’s famous paper, the standard thing to do here is to identify \(B\) with the finite group \((\mathbb{Z}/Q)^d\) and do the QFT there instead. This is gauche as pure mathematics, but it’s reasonable as computer science. In any case, it works, but it comes at a price. You should rescale the resulting Fourier mode \(\vec{y} \in (\mathbb{Z}/Q)^d\) as \(\vec{y}_1 = \vec{y}/Q\) to match it to the torus \((\mathbb{R}/\mathbb{Z})^d\). Even if you do that, \(\vec{y}_1\) is not actually a uniformly random element of \(L^\#\), but rather a noisy, discretized approximation of one.</p>



<p>In Shor’s algorithm, the remaining work is often interpreted as the post-climax. In this case \(L = p\mathbb{Z}\), where \(p\) is the hidden period of \(f\), and \(L^\#\) consists of the multiples of \(1/p\) in \(\mathbb{R}/\mathbb{Z}\). The Fourier mode \(y_1\) (skipping the arrow since we are in one dimension) is an approximation to some fraction \(r/p\) with roughly \(q\) binary digits of precision. (\(y_1\) is often but not always the very best binary approximation to \(r/p\) with the available precision.) If you have enough precision, you can learn a fraction from its digits, either in base 2 or in any base. For instance, if I’m thinking of a fraction that is approximately 0.2857, then 2/7 is much closer than any other fraction with a one-digit denominator. As many people know, and as Shor explained in his paper, continued fractions are an efficient and optimal algorithm for this in larger cases.</p>



<p>The Shor-Kitaev algorithm works the same way. You can denoise each coordinate of each Fourier example \(\vec{y}_1\) with the continued fraction algorithm to obtain an exact element \(\vec{y}_0 \in L^\#\). You can learn \(L^\#\) with a polynomial number of samples, and then learn \(L\) from that with integer linear algebra. However, this approach can only work if \(L^\#\) is a finite group, or equivalently when \(L\) has maximum rank \(d\). This condition is explicitly stated in Kitaev’s paper, and in most but not all of the papers and books that cite this algorithm. if \(L\) has maximum rank, then the picture in Fourier space looks like this: </p>



<figure class="wp-block-image"><a href="https://www.scottaaronson.com/f1-torus.png"><img alt="" src="https://www.scottaaronson.com/f1-torus.png"/></a></figure>



<p>However, if \(L\) has rank \(\ell &lt; d\), then \(L^\#\) is a pattern of \((k-\ell)\)-dimensional stripes, like this instead: </p>



<figure class="wp-block-image"><a href="https://www.scottaaronson.com/f2-torus.png"><img alt="" src="https://www.scottaaronson.com/f2-torus.png"/></a></figure>



<p>In this case, as the picture indicates, each coordinate of \(\vec{y}_1\) is flat random and individually irreparable. If you knew the direction of the stripes, then you use could define a slanted coordinate system where some of the coordinates of \(\vec{y}_1\) could be repaired. But the tangent directions of \(L^\#\) essentially beg the question. They are the orthogonal space of \(L_\mathbb{R}\), the vector space subtended by the hidden subgroup \(L\). If you know \(L_\mathbb{R}\), then you can find \(L\) by running Shor-Kitaev in the lattice \(L_\mathbb{R} \cap \mathbb{Z}^d\).</p>



<p>My solution to this conundrum is to observe that the multiples of a randomly chosen point \(\vec{y}_0\) in \(L^\#\) have a good chance of filling out \(L^\#\) adequately well, in particular to land near \(\vec{0}\) often enough to reveal the tangent directions of \(L^\#\). You have to make do with a noisy sample \(\vec{y}_1\) instead, but by making the QFT radix \(Q\) large enough, you can reduce the noise well enough for this to work. Still, even if you know that these small, high-quality multiples of \(\vec{y}_1\) exist, they are needles in an exponential haystack of bad multiples, so how do you find them? It turns out that the versatile LLL algorithm, which finds a basis of short vectors in a lattice, can be used here. The multiples of \(\vec{y}_0\) (say, for simplicity) aren’t a lattice, they are a dense orbit in \(L^\#\) or part of it. However, they are a shadow of a lattice one dimension higher, that you can supply to the LLL algorithm. This step produces lets you compute the linear span \(L_\mathbb{R}\) of \(L\) from its perpendicular space, and then as mentioned you can use Shor-Kitaev to learn the exact geometry of \(L\).</p></div>
    </content>
    <updated>2020-12-07T06:14:50Z</updated>
    <published>2020-12-07T06:14:50Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Complexity"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Quantum"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2020-12-07T06:55:57Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-3063488709598214165</id>
    <link href="https://blog.computationalcomplexity.org/feeds/3063488709598214165/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/12/in-1974-planarity-was-ov-time-and-could.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/3063488709598214165" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/3063488709598214165" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/12/in-1974-planarity-was-ov-time-and-could.html" rel="alternate" type="text/html"/>
    <title>In 1974 Planarity was O(V) time and could do 900 node graphs in 12 seconds! Fast then...</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>In 1974  Hopcroft and Tarjan showed that Planarity is in polynomial time. That is an understatement- they actually have an O(V) algorithm which one can actually code up. See their paper <a href="https://dl.acm.org/doi/pdf/10.1145/321850.321852">here</a>.</p><p>It has the curious line:</p><p><br/></p><p><i>An Algol implementation of the algorithm successfully tested graphs with as many as 900 vertices in less than 12 seconds.</i></p><p>900 nodes in 12 second was fast then but it slow now. </p><p>1) How would their algorithm do on todays machines? How does that compare to what Moore's law (for time) would have predicted? Can this help us determine an x such that Moore's law stopped working at year x. I've  heard various candidates for x including the notion that the death of Moore's law has been greatly exaggerated. Moore himself is still alive, at the age of 91. </p><p>2) Are there better algorithms now? Nothing can beat O(V); however, is there an algorithm  with a better constant? </p><p>3) Is there a modern implementation of it (or perhaps even an old implementation run on a modern machine)? If so, how fast does it run on 900 nodes? 9000 nodes? 90,000 nodes? 900,000 nodes? Not sure where to stop.</p><p>4) The people in the real world who really need to solve this problem fast: (a) do they exist, and (b) if they do exist then what do they use? </p><p><br/></p><p><br/></p><p><br/></p></div>
    </content>
    <updated>2020-12-07T02:53:00Z</updated>
    <published>2020-12-07T02:53:00Z</published>
    <author>
      <name>gasarch</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03004932739846901628</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2020-12-07T06:26:42Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2020/12/06/long-countours-chessboard</id>
    <link href="https://11011110.github.io/blog/2020/12/06/long-countours-chessboard.html" rel="alternate" type="text/html"/>
    <title>Long contours and chessboard coloring</title>
    <summary>The image below is a topographic map of some parkland a couple miles from my house, clipped from opentopomap.org.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The image below is a topographic map of some parkland a couple miles from my house, clipped from <a href="https://opentopomap.org/#map=15/33.61985/-117.77702">opentopomap.org</a>.</p>

<p style="text-align: center;"><img alt="Topographic map of Bommer Canyon, Irvine, from opentopomap.org" src="https://11011110.github.io/blog/assets/2020/BommerCanyon.jpg"/></p>

<p>Here’s another picture of the same place that I took <a href="http://www.ics.uci.edu/~eppstein/pix/vvbc/">a few years ago</a>.</p>

<p style="text-align: center;"><img alt="Bommer Canyon, Irvine" src="https://www.ics.uci.edu/~eppstein/pix/vvbc/MustardMeadow-m.jpg"/></p>

<p>It’s pretty hilly there, as you can tell from the brown <a href="https://11011110.github.io/blog/2020/12/06/Contour line">contour lines</a> on the map, sets of points that are all at the same height as each other. Some contours are short closed curves. Typically these surround hilltops, although they could also mark basins in the landscape; it’s dry enough here that a basin wouldn’t necessarily stay filled with rainwater. Others wiggle around for quite a long distance before escaping the map and connecting to its surrounding regions. Some of them (including the darker brown curve surrounding a pair of hilltops in the upper left of the map) look like they cross or touch themselves at a saddle point of the landscape. This kind of point, where four or more branches of a contour meet, can indeed happen for a contour at the exact height of a saddle point, but a closeup inspection of the upper left one reveals that it has slightly lower height and is actually a single simple closed curve around both hills. It is also possible for contours to reach a dead end (for instance when they follow the top of a level ridgeline) or for an odd number of branches to meet at a junction.</p>

<p>It turns out that every possible landscape has a contour that stretches from one edge of the map to the opposite edge. To state this more precisely and avoid fractal difficulties, let’s model the landscape as a <a href="https://en.wikipedia.org/wiki/Polyhedral_terrain">polyhedral terrain</a> or <a href="https://en.wikipedia.org/wiki/Triangulated_irregular_network">triangulated irregular network</a>, the graph of a piecewise-linear continuous function from a planar polygon \(p\) to the height at each point. Its <a href="https://en.wikipedia.org/wiki/Level_set">level sets</a> are inverse images of heights, and its contours are connected components of level sets. They might not actually be curves or lines; for instance a level plain in the landscape would belong to a single contour. Every contour touches the boundary of \(P\) in a (possibly empty) set of points, dividing the boundary into arcs. Then the existence of a long contour can be stated more explicitly: there is a contour such that all of these arcs have length at most half the perimeter of \(P\). If \(P\) is a rectangle or square, this long contour touches two opposite sides, possibly at their endpoints, because avoiding both a horizontal side and a vertical side would cause the arc containing those sides to be too long.</p>

<p>The proof sketch is not particularly difficult but I’ve indented it below so you can skip over it anyway:</p>

<p style="padding-left: 40px;">Start with the contour containing an arbitrary boundary point, and suppose that it doesn’t immediately solve the problem. This means that there is an arc (and there can be only one) between two of its boundary points (say clockwise from \(x\) to \(y\)) that covers more than half of the perimeter of \(P\). Now consider what happens if you move clockwise continuously from \(x\) to some point \(x'\), and then walk along a contour from \(x'\) (staying to the left whenever you have a choice) to reach another boundary point \(y'\). Then \(y'\), wherever it is, must be within the arc from \(x\) to \(y\), because the two contours cannot cross, so the arc from \(x'\) to \(y'\) is shorter than the arc from \(x\) to \(y\). As we move \(x'\) continuously away from \(x\), the position of \(y'\) moves continuously in the other direction away from \(y\), except at points when the contour passes through a vertex of the landscape; at those points the contour can change its shape discontinuously and \(y'\) can jump discontinuously. But regardless of whether \(y'\) changes continuously or jumps, the length of the arc from \(x'\) to \(y'\) decreases as \(x'\) and \(y'\) move towards each other until eventually they cross.</p>

<p style="padding-left: 40px;">At some point before they do cross, one of two other things must happen. Either the length of arc \(x'y'\) decreases continuously through half the perimeter, or it jumps from being larger than half the perimeter to being smaller than half the perimeter. If it decreases continuously through half the perimeter, the contour containing the points \(x'\) and \(y'\) at the time that it reaches exactly half the perimeter has the desired property. If it jumps, consider the contour \(C\) exactly at the point when it jumps. If \(C\) has the desired property, we are done. Alternatively, there might still be a long boundary arc \(uv\) for \(C\), nested within the pre-jump arc \(x'y'\), and we can continue the same process from there until eventually terminating in one of the other cases.</p>

<p style="padding-left: 40px;">(Exercise: Use this method to find a long contour in the topographic map.)</p>

<p>That was all very continuous and topological but I actually came to this problem from something much more discrete: If you color the squares of a chessboard with three colors, must there be some two of the three colors whose squares stretch all the way across the board, touching edge to edge? In contrast, with four colors you can make colorings where all two-color regions are small:</p>

<p style="text-align: center;"><img alt="4-coloring of grid squares so that 2-colored regions are all small" src="https://11011110.github.io/blog/assets/2020/plaid.svg"/></p>

<p>The four-coloring above is <em>proper</em> (no two adjacent squares have the same color) and I can use contours prove that every proper three-coloring has a two-colored region that stretches across the board.</p>

<p>The idea is, first, to turn any three-coloring of the chessboard squares into a discrete height function, one that takes integer values on each square and where these values differ by \(\pm 1\) on adjacent squares, so that the coloring can be recovered by taking the heights modulo three. I discussed this briefly in an <a href="https://11011110.github.io/blog/2019/10/16/from-one-fold.html">earlier post about reconfiguring Miura-folded origami</a>, with the following example:</p>

<p style="text-align: center;"><img alt="Height function of a proper 3-coloring of a square grid" src="https://11011110.github.io/blog/assets/2019/heightfn.svg"/></p>

<p>It doesn’t look very continuous, but we can make it continuous by using these height values only for the middle points of the squares. At each corner point where two or four squares come together, set the height value to be the average of the heights of the squares that meet there. Divide each square into four isosceles right triangles, meeting at the center of the square, and interpolate these height values linearly within each triangle. Then, find a long contour for the resulting polyhedral terrain. If the long contour is at an integer height, it can be turned into an edge-to-edge sequence of squares using that height and either one of the two neighboring integer heights. If the long contour is at a non-integer height, it can be turned into an edge-to-edge sequence of squares using the integer heights closest to it above and below that height. The image below shows the integer and half-integer contours of the same grid 3-coloring, with the long contour through the large red-yellow region shown in bold. The crosshatched regions are level shelves in the surface, and the black dots are peaks and basins.</p>

<p style="text-align: center;"><img alt="Topographic map of height function derived from proper 3-coloring of a square grid" src="https://11011110.github.io/blog/assets/2020/checkerboard-topo.svg"/></p>

<p>Sadly, the same argument doesn’t work for improper three-colorings, because they don’t usually have height functions. More strongly, the property that we want to prove, the existence of large two-colored regions, is just not true of improper colorings. The improper coloring below can be extended to arbitrarily large chessboards, with all two-colored regions having at most 13 squares:</p>

<p style="text-align: center;"><img alt="Improper 3-coloring of grid squares so that 2-colored regions are all small" src="https://11011110.github.io/blog/assets/2020/plaid2.svg"/></p>

<p>(<a href="https://mathstodon.xyz/@11011110/105335210914176059">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2020-12-06T12:29:00Z</updated>
    <published>2020-12-06T12:29:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2020-12-06T22:52:09Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/183</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/183" rel="alternate" type="text/html"/>
    <title>TR20-183 |  Constant Depth Formula and Partial Function Versions of MCSP are Hard | 

	Rahul Ilango</title>
    <summary>Attempts to prove the intractability of the Minimum Circuit Size Problem (MCSP) date as far back as the 1950s and are well-motivated by connections to cryptography, learning theory, and average-case complexity. In this work, we make progress, on two fronts, towards showing MCSP is intractable under worst-case assumptions. 


While Masek showed in the late 1970s that the version of MCSP for DNF formulas is NP-hard, extending this result to the case of depth-$3$ AND/OR formulas was open.  We show that determining the minimum size of a depth-$d$ formula computing a given Boolean function is NP-hard under quasipolynomial-time randomized reductions for all constant $d \geq 2$. Our approach is based on a method to "lift" depth-$d$ formula lower bounds to depth-$(d+1)$. This method also implies the existence of a function with a $2^{\Omega_d(n)}$ additive gap between its depth-$d$ and depth-$(d+1)$ formula complexity.


We also make progress in the case of general, unrestricted circuits. We show that the version of MCSP where the input is a partial function (represented by a string in $\{0,1,\star\}^*$) is not in P under the Exponential Time Hypothesis (ETH).


Intriguingly, we formulate a notion of lower bound statements being $(P/poly)$-recognizable that is closely related to Razborov and Rudich's definition of being $(P/poly)$-constructive. We show that unless there are subexponential-sized circuits computing SAT, the collection of lower bound statements used to prove the correctness of our reductions cannot be $(P/poly)$-recognizable.</summary>
    <updated>2020-12-06T02:49:15Z</updated>
    <published>2020-12-06T02:49:15Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-12-07T07:37:38Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2012.02119</id>
    <link href="http://arxiv.org/abs/2012.02119" rel="alternate" type="text/html"/>
    <title>Robustly Learning Mixtures of $k$ Arbitrary Gaussians</title>
    <feedworld_mtime>1607212800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bakshi:Ainesh.html">Ainesh Bakshi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Diakonikolas:Ilias.html">Ilias Diakonikolas</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jia:He.html">He Jia</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kane:Daniel_M=.html">Daniel M. Kane</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kothari:Pravesh_K=.html">Pravesh K. Kothari</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vempala:Santosh_S=.html">Santosh S. Vempala</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2012.02119">PDF</a><br/><b>Abstract: </b>We give a polynomial-time algorithm for the problem of robustly estimating a
mixture of $k$ arbitrary Gaussians in $\mathbb{R}^d$, for any fixed $k$, in the
presence of a constant fraction of arbitrary corruptions. This resolves the
main open problem in several previous works on algorithmic robust statistics,
which addressed the special cases of robustly estimating (a) a single Gaussian,
(b) a mixture of TV-distance separated Gaussians, and (c) a uniform mixture of
two Gaussians. Our main tools are an efficient \emph{partial clustering}
algorithm that relies on the sum-of-squares method, and a novel tensor
decomposition algorithm that allows errors in both Frobenius norm and low-rank
terms.
</p></div>
    </summary>
    <updated>2020-12-06T22:43:24Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-12-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2012.01967</id>
    <link href="http://arxiv.org/abs/2012.01967" rel="alternate" type="text/html"/>
    <title>Sketching Persistence Diagrams</title>
    <feedworld_mtime>1607212800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sheehy:Donald_R=.html">Donald R. Sheehy</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sheth:Siddharth.html">Siddharth Sheth</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2012.01967">PDF</a><br/><b>Abstract: </b>Given a persistence diagram with $n$ points, we give an algorithm that
produces a sequence of $n$ persistence diagrams converging in bottleneck
distance to the input diagram, the $i$th of which has $i$ distinct (weighted)
points and is a $2$-approximation to the closest persistence diagram with that
many distinct points. For each approximation, we precompute the optimal
matching between the $i$th and the $(i+1)$st. Perhaps surprisingly, the entire
sequence of diagrams as well as the sequence of matchings can be represented in
$O(n)$ space. The main approach is to use a variation of the greedy permutation
of the persistence diagram to give good Hausdorff approximations and assign
weights to these subsets. We give a new algorithm to efficiently compute this
permutation, despite the high implicit dimension of points in a persistence
diagram due to the effect of the diagonal. The sketches are also structured to
permit fast (linear time) approximations to the Hausdorff distance between
diagrams -- a lower bound on the bottleneck distance. For approximating the
bottleneck distance, sketches can also be used to compute a linear-size
neighborhood graph directly, obviating the need for geometric data structures
used in state-of-the-art methods for bottleneck computation.
</p></div>
    </summary>
    <updated>2020-12-06T22:51:02Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-12-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2012.01947</id>
    <link href="http://arxiv.org/abs/2012.01947" rel="alternate" type="text/html"/>
    <title>A Sparse Delaunay Filtration</title>
    <feedworld_mtime>1607212800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sheehy:Donald_R=.html">Donald R. Sheehy</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2012.01947">PDF</a><br/><b>Abstract: </b>We show how a filtration of Delaunay complexes can be used to approximate the
persistence diagram of the distance to a point set in $R^d$. Whereas the full
Delaunay complex can be used to compute this persistence diagram exactly, it
may have size $O(n^{\lceil d/2 \rceil})$. In contrast, our construction uses
only $O(n)$ simplices. The central idea is to connect Delaunay complexes on
progressively denser subsamples by considering the flips in an incremental
construction as simplices in $d+1$ dimensions. This approach leads to a very
simple and straightforward proof of correctness in geometric terms, because the
final filtration is dual to a $(d+1)$-dimensional Voronoi construction similar
to the standard Delaunay filtration complex. We also, show how this complex can
be efficiently constructed.
</p></div>
    </summary>
    <updated>2020-12-06T22:50:51Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-12-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2012.01920</id>
    <link href="http://arxiv.org/abs/2012.01920" rel="alternate" type="text/html"/>
    <title>Quantum learning algorithms imply circuit lower bounds</title>
    <feedworld_mtime>1607212800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Arunachalam:Srinivasan.html">Srinivasan Arunachalam</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Grilo:Alex_B=.html">Alex B. Grilo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gur:Tom.html">Tom Gur</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Oliveira:Igor_C=.html">Igor C. Oliveira</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sundaram:Aarthi.html">Aarthi Sundaram</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2012.01920">PDF</a><br/><b>Abstract: </b>We establish the first general connection between the design of quantum
algorithms and circuit lower bounds. Specifically, let $\mathfrak{C}$ be a
class of polynomial-size concepts, and suppose that $\mathfrak{C}$ can be
PAC-learned with membership queries under the uniform distribution with error
$1/2 - \gamma$ by a time $T$ quantum algorithm. We prove that if $\gamma^2
\cdot T \ll 2^n/n$, then $\mathsf{BQE} \nsubseteq \mathfrak{C}$, where
$\mathsf{BQE} = \mathsf{BQTIME}[2^{O(n)}]$ is an exponential-time analogue of
$\mathsf{BQP}$. This result is optimal in both $\gamma$ and $T$, since it is
not hard to learn any class $\mathfrak{C}$ of functions in (classical) time $T
= 2^n$ (with no error), or in quantum time $T = \mathsf{poly}(n)$ with error at
most $1/2 - \Omega(2^{-n/2})$ via Fourier sampling. In other words, even a
marginal improvement on these generic learning algorithms would lead to major
consequences in complexity theory.
</p>
<p>Our proof builds on several works in learning theory, pseudorandomness, and
computational complexity, and crucially, on a connection between non-trivial
classical learning algorithms and circuit lower bounds established by Oliveira
and Santhanam (CCC 2017). Extending their approach to quantum learning
algorithms turns out to create significant challenges. To achieve that, we show
among other results how pseudorandom generators imply learning-to-lower-bound
connections in a generic fashion, construct the first conditional pseudorandom
generator secure against uniform quantum computations, and extend the local
list-decoding algorithm of Impagliazzo, Jaiswal, Kabanets and Wigderson (SICOMP
2010) to quantum circuits via a delicate analysis. We believe that these
contributions are of independent interest and might find other applications.
</p></div>
    </summary>
    <updated>2020-12-06T22:37:39Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-12-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2012.01883</id>
    <link href="http://arxiv.org/abs/2012.01883" rel="alternate" type="text/html"/>
    <title>Competition analysis on the over-the-counter credit default swap market</title>
    <feedworld_mtime>1607212800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Abraham:Louis.html">Louis Abraham</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2012.01883">PDF</a><br/><b>Abstract: </b>We study two questions related to competition on the OTC CDS market using
data collected as part of the EMIR regulation.
</p>
<p>First, we study the competition between central counterparties through
collateral requirements. We present models that successfully estimate the
initial margin requirements. However, our estimations are not precise enough to
use them as input to a predictive model for CCP choice by counterparties in the
OTC market.
</p>
<p>Second, we model counterpart choice on the interdealer market using a novel
semi-supervised predictive task. We present our methodology as part of the
literature on model interpretability before arguing for the use of conditional
entropy as the metric of interest to derive knowledge from data through a
model-agnostic approach. In particular, we justify the use of deep neural
networks to measure conditional entropy on real-world datasets. We create the
$\textit{Razor entropy}$ using the framework of algorithmic information theory
and derive an explicit formula that is identical to our semi-supervised
training objective. Finally, we borrow concepts from game theory to define
$\textit{top-k Shapley values}$. This novel method of payoff distribution
satisfies most of the properties of Shapley values, and is of particular
interest when the value function is monotone submodular. Unlike classical
Shapley values, top-k Shapley values can be computed in quadratic time of the
number of features instead of exponential. We implement our methodology and
report the results on our particular task of counterpart choice.
</p>
<p>Finally, we present an improvement to the $\textit{node2vec}$ algorithm that
could for example be used to further study intermediation. We show that the
neighbor sampling used in the generation of biased walks can be performed in
logarithmic time with a quasilinear time pre-computation, unlike the current
implementations that do not scale well.
</p></div>
    </summary>
    <updated>2020-12-06T22:49:12Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-12-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2012.01880</id>
    <link href="http://arxiv.org/abs/2012.01880" rel="alternate" type="text/html"/>
    <title>On Parameterized Complexity of Binary Networked Public Goods Game</title>
    <feedworld_mtime>1607212800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dey:Palash.html">Palash Dey</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Maiti:Arnab.html">Arnab Maiti</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2012.01880">PDF</a><br/><b>Abstract: </b>In the Binary Networked Public Goods game, every player needs to decide if
she participates in a public project whose utility is shared equally by the
community. We study the problem of computing if there exists a pure strategy
Nash equilibrium (PSNE) in such games. The problem is already known to be
NP-complete. We provide fine-grained analysis of this problem under the lens of
parameterized complexity theory. We consider various natural graph parameters
and show either W[1]-hardness or exhibit an FPT algorithm. We finally exhibit
some special graph classes, for example path, cycle, bi-clique, complete graph,
etc., which always have a PSNE if the utility function of the players are fully
homogeneous.
</p></div>
    </summary>
    <updated>2020-12-06T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-12-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2012.01845</id>
    <link href="http://arxiv.org/abs/2012.01845" rel="alternate" type="text/html"/>
    <title>Computing Crisp Simulations and Crisp Directed Simulations for Fuzzy Graph-Based Structures</title>
    <feedworld_mtime>1607212800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nguyen:Linh_Anh.html">Linh Anh Nguyen</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2012.01845">PDF</a><br/><b>Abstract: </b>Like bisimulations, simulations and directed simulations are used for
analyzing graph-based structures such as automata, labeled transition systems,
linked data networks, Kripke models and interpretations in description logic.
Simulations characterize the class of existential modal formulas, whereas
directed simulations characterize the class of positive modal formulas. These
notions are worth studying. For example, one may be interested in checking
whether a given finite automaton simulates another or whether an object in a
linked data network has all positive properties that another object has. To
deal with vagueness and uncertainty, fuzzy graph-based structures are used
instead of crisp ones. In this article, we design efficient algorithms with the
complexity $O((m+n)n)$ for computing the largest crisp simulation and the
largest crisp directed simulation between two finite fuzzy labeled graphs,
where $n$ is the number of vertices and $m$ is the number of nonzero edges of
the input fuzzy graphs. We also adapt them to computing the largest crisp
simulation and the largest crisp directed simulation between two finite fuzzy
automata.
</p></div>
    </summary>
    <updated>2020-12-06T22:50:03Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-12-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2012.01764</id>
    <link href="http://arxiv.org/abs/2012.01764" rel="alternate" type="text/html"/>
    <title>Optimal labelling schemes for adjacency, comparability and reachability</title>
    <feedworld_mtime>1607212800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bonamy:Marthe.html">Marthe Bonamy</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Esperet:Louis.html">Louis Esperet</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Groenland:Carla.html">Carla Groenland</a>, Alex Scott <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2012.01764">PDF</a><br/><b>Abstract: </b>We construct asymptotically optimal adjacency labelling schemes for every
hereditary class containing $2^{\Omega(n^2)}$ $n$-vertex graphs as $n\to
\infty$. This regime contains many classes of interest, for instance perfect
graphs or comparability graphs, for which we obtain an efficient adjacency
labelling scheme with labels of $n/4+o(n)$ bits per vertex. This implies the
existence of a reachability labelling scheme for digraphs with labels of
$n/4+o(n)$ bits per vertex. We also use this result to construct a poset on
$2^{n/4+o(n)}$ elements, that contains all $n$-element posets. All these
results are best possible, up to the lower order term, and solve several open
problems in the area.
</p></div>
    </summary>
    <updated>2020-12-06T22:48:19Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-12-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2012.01752</id>
    <link href="http://arxiv.org/abs/2012.01752" rel="alternate" type="text/html"/>
    <title>Distributed algorithms for fractional coloring</title>
    <feedworld_mtime>1607212800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bousquet:Nicolas.html">Nicolas Bousquet</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Esperet:Louis.html">Louis Esperet</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pirot:Fran=ccedil=ois.html">François Pirot</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2012.01752">PDF</a><br/><b>Abstract: </b>In this paper we study fractional coloring from the angle of distributed
computing. Fractional coloring is the linear relaxation of the classical notion
of coloring, and has many applications, in particular in scheduling. It is
known that for every real $\alpha&gt;1$ and integer $\Delta$, a fractional
coloring of total weight at most $\alpha(\Delta+1)$ can be obtained
deterministically in a single round in graphs of maximum degree $\Delta$, in
the LOCAL model of computation. However, a major issue of this result is that
the output of each vertex has unbounded size. Here we prove that even if we
impose the more realistic assumption that the output of each vertex has
constant size, we can find fractional colourings with a weight arbitrarily
close to known tight bounds for the fractional chromatic number in several
cases of interest. Moreover, we improve on classical bounds on the chromatic
number by considering the fractional chromatic number instead, without
significantly increasing the output size and the round complexity of the
existing algorithms.
</p></div>
    </summary>
    <updated>2020-12-06T22:49:18Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-12-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2012.01530</id>
    <link href="http://arxiv.org/abs/2012.01530" rel="alternate" type="text/html"/>
    <title>Decoding Multivariate Multiplicity Codes on Product Sets</title>
    <feedworld_mtime>1607212800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bhandari:Siddharth.html">Siddharth Bhandari</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Harsha:Prahladh.html">Prahladh Harsha</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kumar:Mrinal.html">Mrinal Kumar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sudan:Madhu.html">Madhu Sudan</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2012.01530">PDF</a><br/><b>Abstract: </b>The multiplicity Schwartz-Zippel lemma bounds the total multiplicity of
zeroes of a multivariate polynomial on a product set. This lemma motivates the
multiplicity codes of Kopparty, Saraf and Yekhanin [J. ACM, 2014], who showed
how to use this lemma to construct high-rate locally-decodable codes. However,
the algorithmic results about these codes crucially rely on the fact that the
polynomials are evaluated on a vector space and not an arbitrary product set.
</p>
<p>In this work, we show how to decode multivariate multiplicity codes of large
multiplicities in polynomial time over finite product sets (over fields of
large characteristic and zero characteristic). Previously such decoding
algorithms were not known even for a positive fraction of errors. In contrast,
our work goes all the way to the distance of the code and in particular exceeds
both the unique decoding bound and the Johnson bound. For errors exceeding the
Johnson bound, even combinatorial list-decodablity of these codes was not
known.
</p>
<p>Our algorithm is an application of the classical polynomial method directly
to the multivariate setting. In particular, we do not rely on a reduction from
the multivariate to the univariate case as is typical of many of the existing
results on decoding codes based on multivariate polynomials. However, a vanilla
application of the polynomial method in the multivariate setting does not yield
a polynomial upper bound on the list size. We obtain a polynomial bound on the
list size by taking an alternative view of multivariate multiplicity codes. In
this view, we glue all the partial derivatives of the same order together using
a fresh set $z$ of variables. We then apply the polynomial method by viewing
this as a problem over the field $\mathbb{F}(z)$ of rational functions in $z$.
</p></div>
    </summary>
    <updated>2020-12-06T22:38:47Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-12-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2012.01499</id>
    <link href="http://arxiv.org/abs/2012.01499" rel="alternate" type="text/html"/>
    <title>Instance-Sensitive Algorithms for Pure Exploration in Multinomial Logit Bandit</title>
    <feedworld_mtime>1607212800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Karpov:Nikolai.html">Nikolai Karpov</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Qin.html">Qin Zhang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2012.01499">PDF</a><br/><b>Abstract: </b>Motivated by real-world applications such as fast fashion retailing and
online advertising, the Multinomial Logit Bandit (MNL-bandit) is a popular
model in online learning and operations research, and has attracted much
attention in the past decade. However, it is a bit surprising that pure
exploration, a basic problem in bandit theory, has not been well studied in
MNL-bandit so far. In this paper we give efficient algorithms for pure
exploration in MNL-bandit. Our algorithms achieve instance-sensitive pull
complexities. We also complement the upper bounds by an almost matching lower
bound.
</p></div>
    </summary>
    <updated>2020-12-06T22:42:22Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-12-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2012.01420</id>
    <link href="http://arxiv.org/abs/2012.01420" rel="alternate" type="text/html"/>
    <title>Constructing Segmented Differentiable Quadratics to Determine Algorithmic Run Times and Model Non-Polynomial Functions</title>
    <feedworld_mtime>1607212800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Goyal:Ananth.html">Ananth Goyal</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2012.01420">PDF</a><br/><b>Abstract: </b>We propose an approach to determine the continual progression of algorithmic
efficiency, as an alternative to standard calculations of time complexity,
likely, but not exclusively, when dealing with data structures with unknown
maximum indexes and with algorithms that are dependent on multiple variables
apart from just input size. The proposed method can effectively determine the
run time behavior $F$ at any given index $x$ , as well as $\frac{\partial
F}{\partial x}$, as a function of only one or multiple arguments, by combining
$\frac{n}{2}$ quadratic segments, based upon the principles of Lagrangian
Polynomials and their respective secant lines. Although the approach used is
designed for analyzing the efficacy of computational algorithms, the proposed
method can be used within the pure mathematical field as a novel way to
construct non-polynomial functions, such as $\log_2{n}$ or $\frac{n+1}{n-2}$,
as a series of segmented differentiable quadratics to model functional behavior
and reoccurring natural patterns. After testing, our method had an average
accuracy of above of 99\% with regard to functional resemblance.
</p></div>
    </summary>
    <updated>2020-12-06T22:38:36Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-12-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=20557</id>
    <link href="https://gilkalai.wordpress.com/2020/12/06/photonic-huge-quantum-advantage/" rel="alternate" type="text/html"/>
    <title>Photonic Huge Quantum Advantage ???</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">This is a quick and preliminary post about a very recent announcement in a Science Magazine paper: Quantum computational advantage using photons by a group of researchers leaded by Jianwei Pan and Chao-Yang Lu. (Most of the researchers are from … <a href="https://gilkalai.wordpress.com/2020/12/06/photonic-huge-quantum-advantage/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>This is a quick and preliminary post about a very recent announcement in a Science Magazine paper: <a href="https://science.sciencemag.org/content/early/2020/12/02/science.abe8770">Quantum computational advantage using photons</a> by a group of researchers leaded by <a href="https://en.wikipedia.org/wiki/Pan_Jianwei">Jianwei Pan</a> and <a href="https://twitter.com/chaoyanglu?ref_src=twsrc%5Egoogle%7Ctwcamp%5Eserp%7Ctwgr%5Eauthor">Chao-Yang Lu.</a> (Most of the researchers are from USTC in Hefei, China.)</p>
<p>The paper announces achieving  quantum advantage (aka “quantum supremacy”) using photonic implementation of BosonSampling.  (I heard about it from a <a href="https://www.scottaaronson.com/blog/?p=5122">SO post</a> that contains further links.) The claimed advantage is huge and clearly I will have to look carefully at the results, the data, and the interpretation. The idea that this could be done was raised ten years ago by Aaronson and Arkhipov and we discussed it in <a href="https://gilkalai.wordpress.com/2010/11/17/aaronson-and-arkhipovs-result-on-hierarchy-collapse/">here</a> and in several other posts along with the idea that it<em> cannot</em> be done.</p>
<p>Boson Sampling was studied in a 2014 paper by Guy Kindler and me <a href="https://arxiv.org/abs/1409.3093" rel="nofollow ugc">Gaussian Noise Sensitivity and BosonSampling</a>. Our paper and the connection with noise sensitivity and the Fourier description is the basis for <a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=&amp;cad=rja&amp;uact=8&amp;ved=2ahUKEwii7ure67ftAhVDhqQKHRMsCyoQFjACegQIAhAC&amp;url=https%3A%2F%2Fwww.ams.org%2Fnotices%2F201605%2Frnoti-p508.pdf&amp;usg=AOvVaw3S3tSldRaLR6RwskAYwLUo">my argument</a> against quantum computers.  Of course, a demonstration of a huge quantum advantage, as claimed in the new paper, if valid, would refute my theory.</p>
<p>The crux of the matter is if the statistical performance of the photonic samples produced in the experiment could be achieved by classical sampling. (This is referred to as “spoofing.”) My paper with Guy proposes a very simple way to try to do it based  on the low degree Hermite-Fourier truncation of the Boson Sampling distribution.</p>
<p>The easiest way to implement it is as follows: Given an n by m matrix you draw (with the appropriate weights based on repeated columns) at random n by n minor M (with repeated columns), then compute the degree k approximation X to the |permanent(M)|^2, (based on formula (8) from our paper) and then take the sample with probability according to the value of X and toss it away otherwise. This may work even for degree-2 truncation. (Rather than the straight truncation we can also try the “Beckner-noise” version but I don’t think this will make much difference.)</p>
<p>Since my paper with Guy Kindler offers “off the shelf” classic algorithm that may “spoof” the claims I propose to test it. (And I am a little surprised that this was not tried already.)</p>
<p><a href="https://gilkalai.files.wordpress.com/2020/12/bosonsampling.png"><img alt="" class="alignnone size-full wp-image-20563" height="384" src="https://gilkalai.files.wordpress.com/2020/12/bosonsampling.png?w=640&amp;h=384" width="640"/></a></p>
<p> </p></div>
    </content>
    <updated>2020-12-05T22:08:44Z</updated>
    <published>2020-12-05T22:08:44Z</published>
    <category term="Combinatorics"/>
    <category term="Physics"/>
    <category term="Probability"/>
    <category term="Quantum"/>
    <category term="BosonSampling"/>
    <category term="quantum supremacy"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2020-12-07T07:37:42Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/182</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/182" rel="alternate" type="text/html"/>
    <title>TR20-182 |  An Improved Derandomization of the Switching Lemma | 

	Zander Kelley</title>
    <summary>We prove a new derandomization of Håstad's switching lemma, showing how to efficiently generate restrictions satisfying the switching lemma for DNF or CNF formulas of size $m$ using only $\widetilde{O}(\log m)$ random bits. Derandomizations of the switching lemma have been useful in many works as a key building-block for constructing objects which are in some way provably-pseudorandom with respect to AC$^0$-circuits.

Here, we use our new derandomization to give an improved analysis of the pseudorandom generator of Trevisan and Xue for AC$^0$-circuits (CCC'13): we show that  the generator $\varepsilon$-fools size-$m$, depth-$D$ circuits with $n$-bit inputs using only $\widetilde{O}(\log(m/\varepsilon)^{D} \cdot \log n)$ random bits. In particular, we obtain (modulo the $\log \log$-factors hidden in the $\widetilde{O}$-notation) a dependence on $m/\varepsilon$ which is best-possible with respect to currently-known AC$^0$-circuit lower bounds.</summary>
    <updated>2020-12-04T20:39:05Z</updated>
    <published>2020-12-04T20:39:05Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-12-07T07:37:38Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/181</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/181" rel="alternate" type="text/html"/>
    <title>TR20-181 |  Monotone Circuit Lower Bounds from Robust Sunflowers | 

	Bruno Pasqualotto Cavalar, 

	Mrinal Kumar, 

	Benjamin Rossman</title>
    <summary>Robust sunflowers are a generalization of combinatorial sunflowers that have applications in monotone circuit complexity, DNF sparsification, randomness extractors, and recent advances on the Erd\H{o}s-Rado sunflower conjecture.  The recent breakthrough of Alweiss, Lovett, Wu and Zhang gives an improved bound on the maximum size of a $w$-set system that excludes a robust sunflower.  In this paper, we use this result to obtain an $\exp(n^{1/2-o(1)})$ lower bound on the monotone circuit size of an explicit $n$-variate monotone function, improving the previous best known $\exp(n^{1/3-o(1)})$ due to Andreev and Harnik and Raz. We also show an $\exp(\Omega(n))$ lower bound on the monotone arithmetic circuit size of a related polynomial.  Finally, we introduce a notion of robust clique-sunflowers and use this to prove an $n^{\Omega(k)}$ lower bound on the monotone circuit size of the CLIQUE function for all $k \le n^{1/3-o(1)}$, strengthening the bound of Alon and Boppana.</summary>
    <updated>2020-12-04T19:54:54Z</updated>
    <published>2020-12-04T19:54:54Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-12-07T07:37:38Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/12/04/harvard-quantum-initiative-postdocoral-fellowship-at-harvard-apply-by-december-4-2020/</id>
    <link href="https://cstheory-jobs.org/2020/12/04/harvard-quantum-initiative-postdocoral-fellowship-at-harvard-apply-by-december-4-2020/" rel="alternate" type="text/html"/>
    <title>Harvard Quantum Initiative postdocoral fellowship at Harvard (apply by December 4, 2020)</title>
    <summary>(Soft deadline but please apply as soon as you can) 2 year fellowship with possiblity of 3rd year extention. Applications focused on collaborative and cross-disciplinary research are especially encouraged. Competitive annual salary, discretionary funds to support their research, and access to opportunities such as lunches with visiting speakers and access to research seed funding. Website: […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>(Soft deadline but please apply as soon as you can)</p>
<p>2 year fellowship with possiblity of 3rd year extention.</p>
<p>Applications focused on collaborative and cross-disciplinary research are especially encouraged.</p>
<p>Competitive annual salary, discretionary funds to support their research, and access to opportunities such as lunches with visiting speakers and access to research seed funding.</p>
<p>Website: <a href="https://academicjobsonline.org/ajo/fellowship/17462">https://academicjobsonline.org/ajo/fellowship/17462</a><br/>
Email: ann_quaicoe@fas.harvard.edu</p></div>
    </content>
    <updated>2020-12-04T19:12:06Z</updated>
    <published>2020-12-04T19:12:06Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-12-07T07:37:51Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://lucatrevisan.wordpress.com/?p=4430</id>
    <link href="https://lucatrevisan.wordpress.com/2020/12/04/keith-ball-on-bourgains-legacy-in-geometric-functional-analysis/" rel="alternate" type="text/html"/>
    <title>Keith Ball on Bourgain’s Legacy in Geometric Functional Analysis</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">The Bulletin of the AMS has just posted an article by Keith Ball on the legacy of Bourgain’s work on geometric functional analysis. This beautifully written article talks about results and conjectures that are probably familiar to readers of in … <a href="https://lucatrevisan.wordpress.com/2020/12/04/keith-ball-on-bourgains-legacy-in-geometric-functional-analysis/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Bulletin of the AMS has just posted an <a href="https://www.ams.org/journals/bull/0000-000-00/S0273-0979-2020-01719-2/S0273-0979-2020-01719-2.pdf">article by Keith Ball</a> on the legacy of Bourgain’s work on geometric functional analysis. </p>

<p/>

<p>
This beautifully written article talks about results and conjectures that are probably familiar to readers of <i>in theory</i>, but from the perspective of their mathematical motivations and of the bigger picture in which they fit.</p>



<p/></div>
    </content>
    <updated>2020-12-04T13:52:28Z</updated>
    <published>2020-12-04T13:52:28Z</published>
    <category term="math"/>
    <category term="theory"/>
    <category term="Geometric Functional Analysis"/>
    <category term="Jean Bourgain"/>
    <category term="Keith Ball"/>
    <author>
      <name>luca</name>
    </author>
    <source>
      <id>https://lucatrevisan.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://lucatrevisan.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://lucatrevisan.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://lucatrevisan.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://lucatrevisan.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>"Marge, I agree with you - in theory. In theory, communism works. In theory." -- Homer Simpson</subtitle>
      <title>in   theory</title>
      <updated>2020-12-07T07:37:11Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/12/04/phd-positions-at-international-max-planck-research-school-on-trustworthy-computing-apply-by-december-31-2020/</id>
    <link href="https://cstheory-jobs.org/2020/12/04/phd-positions-at-international-max-planck-research-school-on-trustworthy-computing-apply-by-december-31-2020/" rel="alternate" type="text/html"/>
    <title>PhD positions  at International Max Planck Research School on Trustworthy Computing (apply by December 31, 2020)</title>
    <summary>The International Max Planck Research School on Trustworthy Computing is a graduate program jointly run by the Max Planck Institutes for Informatics and Software Systems, Saarland University, and TU Kaiserslautern. It offers a fully funded PhD program that leads to a doctoral degree from one of the participating universities and is open to students with […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The International Max Planck Research School on Trustworthy Computing is a graduate program jointly run by the Max Planck Institutes for Informatics and Software Systems, Saarland University, and TU Kaiserslautern. It offers a fully funded PhD program that leads to a doctoral degree from one of the participating universities and is open to students with a degree in computer science or equivalent.</p>
<p>Website: <a href="https://www.imprs-trust.mpg.de/">https://www.imprs-trust.mpg.de/</a><br/>
Email: imprs@mpi-klsb.mpg.de</p></div>
    </content>
    <updated>2020-12-04T12:53:37Z</updated>
    <published>2020-12-04T12:53:37Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-12-07T07:37:51Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=7948</id>
    <link href="https://windowsontheory.org/2020/12/03/obfuscation-the-season-4-finale/" rel="alternate" type="text/html"/>
    <title>Obfuscation: The season 4 Finale</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">For many of the famous open problems of theoretical computer science, most researchers agree on what the answer is, but the challenge is to prove it. Most complexity theorists (with few notable exceptions) believe that P≠NP, but we don’t know how to prove it. Similarly, most people working on matrix multiplication believe that there is … <a class="more-link" href="https://windowsontheory.org/2020/12/03/obfuscation-the-season-4-finale/">Continue reading <span class="screen-reader-text">Obfuscation: The season 4 Finale</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p/>



<p>For many of the famous open problems of theoretical computer science, most researchers agree on what the answer is, but the challenge is to <em>prove </em>it. Most complexity theorists (with few notable exceptions) believe that P≠NP, but we don’t know how to prove it. Similarly, most people working on matrix multiplication believe that there is an Õ(n²) algorithm for this problem, but we’re still stuck at <a href="https://arxiv.org/abs/2010.05846">2.3728596</a>.   We believed that primality checking has a deterministic polynomial-time algorithm long before it was <a href="https://en.wikipedia.org/wiki/AKS_primality_test">proven </a>and we still believe the same holds for polynomial identity testing.</p>



<p>The story of <em>cryptographic obfuscation</em> is different. This story deserves a full length blog post (though see my now outdated <a href="https://cacm.acm.org/magazines/2016/3/198855-hopes-fears-and-software-obfuscation/fulltext">survey</a>), but the short version is as follows. In 2001 we (in a <a href="http://www.wisdom.weizmann.ac.il/~oded/p_obfuscate.html">paper </a>with Goldreich, Impagliazzo, Rudich, Sahai, Vadhan, and Yang) showed that what is arguably the most natural definition of obfuscation is impossible to achieve. That paper explored a number of obfuscation-related questions, and in particular left as an open question the existence of so-called <em>indistinguishable obfuscators</em> or <em>IO</em>. Since then there were arguably more negative than positive results in obfuscation research until in 2012, extending some of the ideas behind fully-homomorphic encryption, <a href="https://eprint.iacr.org/2012/610">Garg Gentry and Halevi</a> gave a heuristic construction of multilinear map, which one can think of as “Diffie Hellman on steroids” (or maybe LSD..). Then in 2013 <a href="https://eprint.iacr.org/2013/451">Garg, Gentry, Halevi., Raykova, Sahai and Waters (GGHRSW)</a> built on top of these maps to give a heuristic construction of IO. </p>



<p>The GGHRSW paper opened the floodgates to many papers using IO to achieve many longstanding cryptographic goals as well as show that IO provides a unified approach to solve many classic cryptographic problems. The fact that so many goals were achieved through heuristic constructions was not very comforting to cryptographers. Even less comforting was the fact that several cryptographic attacks were discovered on these heuristic constructions. The years that followed saw a sequence of constructions and breaks,  giving cryptographers an “emotional whiplash”.  Everyone agreed that IO would be amazing if it exists, but whether or not it actually exists depended on who you asked, and what paper in the eprint archive they read that morning…</p>



<p>The “holy grail” in this line of work is to base obfuscation on a standard assumption, and ideally Regev’s <a href="https://en.wikipedia.org/wiki/Learning_with_errors">Learning With Errors (LWE)</a> assumption. Of course, we don’t know that LWE is true (in particular LWE implies P≠NP) but if it’s false it would bring down so much of the field that cryptographers might as well pack their bags and do machine learning (or try to sabotage progress in quantum computing, since the only other standard <a href="https://eprint.iacr.org/2017/365">assumptions for public-key crypto</a> are broken by fully scalable quantum computing).</p>



<p>We have not yet achieved this holy grail (this is only the 4th season) but as described in <a href="https://www.quantamagazine.org/computer-scientists-achieve-crown-jewel-of-cryptography-20201110/">this quanta article</a>, there has been a remarkable progress in the last few months. In particular, <a href="https://eprint.iacr.org/2020/1003">Jain, Lin and Sahai (JLS)</a>  (building on a long sequence of works by  many people including Ananth, Matt, Tessaro and Vaikuntanathan) obtained IO based on LWE and several standard assumptions in cryptography. This is arguably the first “heuristic free” construction, and is a fantastic breakthrough. However, there is still work to do – the JLS construction uses not just LWE but also a variant of it that is not as well studied. It is also based on pairing-based cryptography. This is an area that has thousands of papers, but for which known instantiations can be broken by quantum computers.  However, there is yet more hope – in another  sequence of works by <a href="https://eprint.iacr.org/2018/633">Agrawal</a>, <a href="https://eprint.iacr.org/2020/1024">Brakerski, Döttling, Garg, and Malavolta</a>, <a href="https://eprint.iacr.org/2020/1042">Wee and Wichs</a>, <a href="https://eprint.iacr.org/2020/1010">Gay and Pass</a> a construction of IO was achieved that is “almost” heuristic free. It still uses one heuristic assumption (circular security) but has the advantage that apart from this assumption it only relies on LWE. </p>



<p>One can hope that in the next season, these two lines of work will converge to give a construction of IO based on LWE, achieving a “meta theorem” deriving from LWE a huge array of cryptographic primitives.</p>



<p>Want to learn more about these amazing advances? Want to know what’s next in store for IO? <br/><br/>Fortunately there is a virtual <a href="https://simons.berkeley.edu/workshops/obfuscation-symposium">Simons symposium on indistinguishability obfuscation</a> <strong>coming to your computer screen on December 10-11</strong>. Authors of all the papers mentioned will join together in coordinated presentations to give a unified view of the field and the challenges ahead. We will also have a historical opening talk by Yael Kalai, as well as a talk by Benny Applebaum on the computational assumptions used, followed by a panel discussion with Yael, Benny and Chris Peikert. Finally, like every proper crypto event, there will be a rump session, though you will have to supply your own beer.</p>



<p>See the <a href="https://simons.berkeley.edu/workshops/obfuscation-symposium">schedule of the workshop</a> and you can register on <a href="https://simons.berkeley.edu/workshops/obfuscation-symposium">this page</a>.</p>



<p>Hope you to see you there! Bring your favorite programs to obfuscate with you*<br/><br/>*<sub>Disclaimer/fine print: Due to large constants and exponents, we do not recommend the compiler be used on programs that are more than one nanobit long.</sub></p>



<p>Image credit: <a href="https://news.mit.edu/2015/secure-foundation-any-cryptographic-system-1028">MIT</a></p></div>
    </content>
    <updated>2020-12-04T00:30:44Z</updated>
    <published>2020-12-04T00:30:44Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2020-12-07T07:38:08Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=5122</id>
    <link href="https://www.scottaaronson.com/blog/?p=5122" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=5122#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=5122" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Quantum supremacy, now with BosonSampling</title>
    <summary xml:lang="en-US">Update (12/5): The Google team, along with Gil Kalai, have raised questions about whether the results of the new BosonSampling experiment might be easier to spoof classically than the USTC team thought they were, because of a crucial difference between BosonSampling and qubit-based random circuit sampling. Namely, with random circuit sampling, the marginal distribution over […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p><strong><span class="has-inline-color has-vivid-red-color">Update (12/5):</span></strong> The Google team, along with Gil Kalai, have raised questions about whether the results of the new BosonSampling experiment might be easier to spoof classically than the USTC team thought they were, because of a crucial difference between BosonSampling and qubit-based random circuit sampling.  Namely, with random circuit sampling, the marginal distribution over any k output qubits (for small k) is exponentially close to the uniform distribution.  With BosonSampling, by contrast, the marginal distribution over k output modes is <em>distinguishable</em> from uniform, as Arkhipov and I noted in a <a href="https://arxiv.org/abs/1309.7460">2013 followup paper</a>.  On the one hand, these easily-detected nonuniformities provide a quick, useful sanity check for whether BosonSampling is being done correctly.  On the other hand, they <em>might</em> also give classical spoofing algorithms more of a toehold.  The question is whether, by spoofing the k-mode marginals, a classical algorithm could also achieve scores on the relevant “HOG” (Heavy Output Generation) benchmark that are comparable to what the USTC team reported.</p>



<p>One way or the other, this question should be resolvable by looking at the data that’s already been collected, and we’re trying now to get to the bottom of it.  And having failed to flag this potential issue when I reviewed the paper, I felt a moral obligation at least to let my readers know about it as soon as I did.  If nothing else, this is an answer to those who claim this stuff is all obvious.  Please pardon the science underway!</p>



<p/><hr/><p/>



<p>A group led by <a href="https://en.wikipedia.org/wiki/Pan_Jianwei">Jianwei Pan</a> and <a href="https://twitter.com/chaoyanglu?ref_src=twsrc%5Egoogle%7Ctwcamp%5Eserp%7Ctwgr%5Eauthor">Chao-Yang Lu</a>, based mainly at USTC in Hefei, China, announced today that it <a href="https://science.sciencemag.org/lookup/doi/10.1126/science.abe8770">achieved BosonSampling with 40-70 detected photons</a>—up to and beyond the limit where a classical supercomputer could feasibly verify the results.  (Technically, they achieved a variant called <a href="https://arxiv.org/abs/1612.01199">Gaussian BosonSampling</a>: a generalization of what I called <a href="https://www.scottaaronson.com/blog/?p=1579">Scattershot BosonSampling</a> in a 2013 post on this blog.)</p>



<p>For more, see also <a href="https://www.sciencenews.org/article/new-light-based-quantum-computer-jiuzhang-supremacy">Emily Conover’s piece in <em>Science News</em></a>, or <a href="https://www.scientificamerican.com/article/light-based-quantum-computer-exceeds-fastest-classical-supercomputers/">Daniel Garisto’s in <em>Scientific American</em></a>, both of which I consulted on.  (Full disclosure: I was one of the reviewers for the Pan group’s <em>Science</em> paper, and will be writing the Perspective article to accompany it.)</p>



<p>The new result follows the <a href="https://arxiv.org/abs/1910.09930">announcement</a> of 14-photon BosonSampling by the same group a year ago.  It represents the second time quantum supremacy has been reported, following Google’s celebrated <a href="https://www.scottaaronson.com/blog/?p=4317">announcement</a> from last year, and the first time it’s been done using photonics rather than superconducting qubits.</p>



<p>As the co-inventor of <a href="https://www.scottaaronson.com/papers/optics.pdf">BosonSampling</a> (with Alex Arkhipov), obviously I’m gratified about this.</p>



<p>For anyone who regards it as boring or obvious, <a href="https://www.scottaaronson.com/blog/?p=2435#comment-798278">here</a> and <a href="https://www.scottaaronson.com/blog/?p=1579#comment-92034">here</a> is Gil Kalai<a href="http://gilkalai.wordpress.com/">,</a> on this blog, telling me why BosonSampling would never scale beyond 8-10 photons.  (He wrote that, if aliens forced us to try, then much like with the <a href="https://en.wikipedia.org/wiki/Ramsey%27s_theorem">Ramsey number</a> R(6,6), our only hope would be to attack the aliens.)  <a href="https://www.youtube.com/watch?v=oR-ufBz13Eg">Here’s </a>Kalai making a similar prediction, on the impossibility of quantum supremacy by BosonSampling or any other means, in his plenary address to the International Congress of Mathematicians two years ago.</p>



<p>Even if we set aside the quantum computing skeptics, many colleagues told me they thought experimental BosonSampling was a dead end, because of photon losses and the staggering difficulty of synchronizing 50-100 single-photon sources.  They said that a convincing demonstration of quantum supremacy would have to await the arrival of <a href="https://en.wikipedia.org/wiki/Quantum_threshold_theorem">quantum fault-tolerance</a>—or at any rate, some hardware platform more robust than photonics.  I always agreed that they might be right.  Furthermore, even if 50-photon BosonSampling <em>was</em> possible, after Google reached the supremacy milestone first with superconducting qubits, it wasn’t clear if anyone would still bother.  Even when I learned a year ago about the USTC group’s intention to go for it, I was skeptical, figuring I’d believe it when I saw it.</p>



<p>Obviously the new result isn’t dispositive.  Nevertheless, as someone whose intellectual origins are close to pure math, it’s strange and exciting to find myself in a field where, once in a while, the world itself gets to weigh in on a theoretical disagreement.</p>



<p>Since excitement is best when paired with accurate understanding, please help yourself to the following FAQ, which I might add more to over the next couple days.</p>



<p><strong>What is BosonSampling?</strong>  You must be new here!  Briefly, it’s a proposal for achieving quantum supremacy by simply passing identical, non-interacting photons through an array of beamsplitters, and then measuring where they end up.  For more: in increasing order of difficulty, <a href="https://news.mit.edu/2011/quantum-experiment-0302">here’s</a> an <em>MIT News</em> article from back in 2011, <a href="https://en.wikipedia.org/wiki/Boson_sampling">here’s</a> the Wikipedia page, <a href="http://www.scottaaronson.com/talks/bbn.ppt">here</a> are my PowerPoint slides, <a href="https://www.scottaaronson.com/blog/?p=1631">here</a> are my lecture notes from Rio de Janeiro, and <a href="https://www.scottaaronson.com/papers/optics.pdf">here’s</a> my original paper with Arkhipov.</p>



<p><strong>What is quantum supremacy?</strong>  Roughly, the use of a programmable or configurable quantum computer to solve <em>some</em> well-defined computational problem much faster than we know how to solve it with any existing classical computer.  “Quantum supremacy,” a term <a href="https://arxiv.org/abs/1203.5813">coined</a> by John Preskill in 2012, does <em>not</em> mean useful QC, or scalable QC, or fault-tolerant QC, all of which remain outstanding challenges.  For more, see my <a href="https://www.scottaaronson.com/blog/?p=4317">Supreme Quantum Supremacy FAQ</a>, or (e.g.) my recent <a href="https://www.youtube.com/watch?v=ZLhyTFk-WGs">Lytle Lecture</a> for the University of Washington.</p>



<p><strong>If Google already announced quantum supremacy a year ago, what’s the point of this new experiment?</strong>  To me, at least, quantum supremacy seems important enough to do at least twice!  Also, as I said, this represents the first demonstration that quantum supremacy is possible <em>via photonics</em>.  Finally, as the authors point out, the new experiment has one big technical advantage compared to Google’s: namely, many more possible output states (~10<sup>30</sup> of them, rather than a mere ~9 quadrillion).  This makes it infeasible to calculate the whole probability distribution over outputs and store it on a gigantic hard disk (after which one could easily generate as many samples as one wanted), which is what IBM proposed doing in its <a href="https://arxiv.org/abs/1910.09534">response</a> to Google’s announcement.</p>



<p><strong>Is BosonSampling a form of universal quantum computing?</strong>  No, we don’t even think it can simulate universal <em>classical</em> computing!  It’s designed for exactly one task: namely, demonstrating quantum supremacy and refuting Gil Kalai.  It <em>might</em> have some other applications besides that, but if so, they’ll be icing on the cake.  This is in contrast to Google’s Sycamore processor, which in principle <em>is</em> a universal quantum computer, just with a severe limit on the number of qubits (53) and how many layers of gates one can apply to them (about 20).</p>



<p><strong>Is BosonSampling at least a <em>step</em> toward universal quantum computing?</strong>  I think so!  In 2000, Knill, Laflamme, and Milburn (KLM) <a href="https://en.wikipedia.org/wiki/KLM_protocol">famously showed</a> that pure, non-interacting photons, passing through a network of beamsplitters, are capable of universal QC, provided we assume one extra thing: namely, the ability to measure the photons at intermediate times, and change which beamsplitters to apply to the remaining photons depending on the outcome.  In other words, “BosonSampling plus adaptive measurements equals universality.”  Basically, KLM is the holy grail that experimental optics groups around the world have been working toward for 20 years, with BosonSampling just a more achievable pit stop along the way.</p>



<p><strong>Are there any applications of BosonSampling?</strong>  We don’t know yet.  There are proposals in the literature to apply BosonSampling to vibronic spectra in quantum chemistry, finding dense subgraphs, and other problems, but I’m not yet sure whether these proposals will yield real speedups over the best we can do with classical computers, for a task of practical interest that involves estimating specific numbers (as opposed to sampling tasks, where BosonSampling almost certainly <em>does</em> yield exponential speedups, but which are rarely the thing practitioners directly care about).  [See <a href="https://www.scottaaronson.com/blog/?p=5122#comment-1867226">this comment</a> for further discussion of the issues regarding dense subgraphs.]  In a completely different direction, one could try to use BosonSampling to generate cryptographically certified random bits, along the lines of my proposal from 2018, much like one could with qubit-based quantum circuits.</p>



<p><strong>How hard is it to simulate BosonSampling on a classical computer?</strong>  As far as we know today, the difficulty of simulating a “generic” BosonSampling experiment increases roughly like 2<sup>n</sup>, where n is the number of detected photons.  It <em>might</em> be easier than that, particularly when noise and imperfections are taken into account; and at any rate it might be easier to spoof the statistical tests that one applies to verify the outputs.  I and others managed to give some theoretical evidence against those possibilities, but just like with Google’s experiment, it’s conceivable that some future breakthrough will change the outlook and remove the case for quantum supremacy.</p>



<p><strong>Do you have any amusing stories?</strong>  When I refereed the <em>Science</em> paper, I asked why the authors directly verified the results of their experiment only for up to 26-30 photons, relying on plausible extrapolations beyond that.  While directly verifying the results of n-photon BosonSampling takes ~2<sup>n</sup> time for any known classical algorithm, I said, surely it should be possible with existing computers to go up to n=40 or n=50?  A couple weeks later, the authors responded, saying that they’d now verified their results up to n=40, but it burned $400,000 worth of supercomputer time so they decided to stop there.  This was by far the most expensive referee report I ever wrote!</p>



<p>Also: when Covid first started, and facemasks were plentiful in China but almost impossible to get in the US, Chao-Yang Lu, one of the leaders of the new work and my sometime correspondent on the theory of BosonSampling, decided to mail me a box of 200 masks (I didn’t ask for it).  I don’t think that influenced my later review, but it was appreciated nonetheless.</p>



<p>Huge congratulations to the whole team for their accomplishment!</p></div>
    </content>
    <updated>2020-12-03T22:19:03Z</updated>
    <published>2020-12-03T22:19:03Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Announcements"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Complexity"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Quantum"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2020-12-07T06:55:57Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/12/03/postdoc-at-tel-aviv-university-at-tel-aviv-university-apply-by-december-31-2020/</id>
    <link href="https://cstheory-jobs.org/2020/12/03/postdoc-at-tel-aviv-university-at-tel-aviv-university-apply-by-december-31-2020/" rel="alternate" type="text/html"/>
    <title>Postdoc at Tel Aviv University at Tel Aviv University (apply by December 31, 2020)</title>
    <summary>I (Gil Cohen) invite applications for a postdoctoral position to start in September 2021 (the exact start date will be flexible). The position will have an initial appointment of one year, but will be extendible to two years. My main research interests right now include randomness extractors, derandomization of space bounded computation, tree codes, coding […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I (Gil Cohen) invite applications for a postdoctoral position to start in September 2021 (the exact start date will be flexible). The position will have an initial appointment of one year, but will be extendible to two years. My main research interests right now include randomness extractors, derandomization of space bounded computation, tree codes, coding theory, and spectral graph theory.</p>
<p>Website: <a href="https://www.gilcohen.org/postdoc2021">https://www.gilcohen.org/postdoc2021</a><br/>
Email: gil@tauex.tau.ac.il</p></div>
    </content>
    <updated>2020-12-03T18:04:18Z</updated>
    <published>2020-12-03T18:04:18Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-12-07T07:37:51Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/12/03/postdoctoral-associate-at-dimacs-at-rutgers-university-apply-by-january-15-2021/</id>
    <link href="https://cstheory-jobs.org/2020/12/03/postdoctoral-associate-at-dimacs-at-rutgers-university-apply-by-january-15-2021/" rel="alternate" type="text/html"/>
    <title>Postdoctoral Associate at DIMACS at Rutgers University (apply by January 15, 2021)</title>
    <summary>DIMACS, the Center for Discrete Mathematics and Theoretical Computer Science, invites applications for postdoctoral associate positions for 2021-2023. Applicants should be recent PhDs with interest in DIMACS areas, including theoretical computer science, discrete mathematics, statistics, operations research, data science, AI, machine learning, and their applications. Website: https://jobs.rutgers.edu/postings/122935 Email: postdoc@dimacs.rutgers.edu</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>DIMACS, the Center for Discrete Mathematics and Theoretical Computer Science, invites applications for postdoctoral associate positions for 2021-2023. Applicants should be recent PhDs with interest in DIMACS areas, including theoretical computer science, discrete mathematics, statistics, operations research, data science, AI, machine learning, and their applications.</p>
<p>Website: <a href="https://jobs.rutgers.edu/postings/122935">https://jobs.rutgers.edu/postings/122935</a><br/>
Email: postdoc@dimacs.rutgers.edu</p></div>
    </content>
    <updated>2020-12-03T18:02:31Z</updated>
    <published>2020-12-03T18:02:31Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-12-07T07:37:51Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-3699673705974309715</id>
    <link href="https://blog.computationalcomplexity.org/feeds/3699673705974309715/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/12/chess-is-back.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/3699673705974309715" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/3699673705974309715" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/12/chess-is-back.html" rel="alternate" type="text/html"/>
    <title>Chess is Back</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Back in 2005, I wrote a post titled <a href="https://blog.computationalcomplexity.org/2005/11/chess-and-poker.html">Chess and Poker</a>. Not really comparing the two but noting that Chess had lost its mojo while poker had high-stakes prime time tournaments. The inspiration was an <a href="https://www.nytimes.com/2005/11/27/opinion/all-the-right-moves.html">NYT Op-Ed</a> that started "CHESS in America is having a crisis". I suggested that computers getting better than humans may have reduced interest in the game. </p><p>Now chess is <a href="https://www.nytimes.com/2020/11/23/arts/television/chess-set-board-sales.html">booming again</a>, due to all of us being stuck at home and the Netflix limited series <a href="https://www.imdb.com/title/tt10048342/">The Queen's Gambit</a> (highly recommended). </p><p>The fictional show takes place in the 1960's when interest in chess in the US started to pick up due to <a href="https://blog.computationalcomplexity.org/2008/01/bobby-fischer-guest-post-by-ken-regan.html">Bobby Fischer's exploits</a> and well before computers played a decent game. Fischer isn't mentioned in the Netflix series, the main character Beth Harmon sort of plays his role. The games themselves, created by Gary Kasparov and others, are even a joy to watch. Check out <a href="https://www.youtube.com/watch?v=oIMaTKOZG-8">this analysis</a> of the final game (spoiler warning). </p><p>The New York Times <a href="https://www.nytimes.com/2012/04/22/crosswords/chess/chess-50-years-of-new-york-times-columns.html">started a chess column</a> in 1962 and ran its <a href="https://www.nytimes.com/2014/10/12/crosswords/chess/after-rocky-start-grand-prix-finds-a-favorite-in-the-lead.html">last column</a> in 2014, though that might be saying more about the state of newspapers than the state of chess.</p><p>What about the computers? They have just gotten so good and with <a href="https://blog.computationalcomplexity.org/2017/12/our-ai-future-good-and-ugly.html">AlphaZero</a> mastering the game with just machine learning on top of the rules of chess, it's not even fun to watch computer versus computer anymore. Now we're back to watching humans and getting back into the games ourselves.</p><p>Computers have opened the door to cheating. Complexity theorist Ken Regan has a <a href="http://www.buffalo.edu/news/experts/ken-regan-faculty-expert-chess.html">side gig</a> reviewing games to determine if a player punching above their weight secretly used a computer algorithm. </p><p>Microsoft just <a href="https://www.microsoft.com/en-us/research/blog/the-human-side-of-ai-for-chess/">announced</a> chess programs that play as a human at various levels of strength. I suppose someone could use a program like this to cheat in a way that even Ken couldn't detect. But mostly it would be like Googling in pub trivia--just takes the fun out of the game.</p></div>
    </content>
    <updated>2020-12-03T14:48:00Z</updated>
    <published>2020-12-03T14:48:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2020-12-07T06:26:42Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/180</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/180" rel="alternate" type="text/html"/>
    <title>TR20-180 |  Shrinkage under Random Projections, and Cubic Formula Lower Bounds for $\mathbf{AC}^0$ | 

	Yuval Filmus, 

	Or Meir, 

	Avishay Tal</title>
    <summary>Håstad showed that any De Morgan formula (composed of AND, OR and NOT gates) shrinks by a factor of $O(p^{2})$ under a random restriction that leaves each variable alive independently with probability $p$ [SICOMP, 1998]. Using this result, he gave an $\widetilde{\Omega}(n^{3})$ formula size lower bound for the Andreev function, which, up to lower order improvements, remains the state-of-the-art lower bound for any explicit function.

  In this work, we extend the shrinkage result of Håstad to hold under a far wider family of random restrictions and their generalization — random projections. Based on our shrinkage results, we obtain an $\widetilde{\Omega}(n^{3})$ formula size lower bound for an explicit function computed in $\mathbf{AC}^0$. This improves upon the best known formula size lower bounds for $\mathbf{AC}^0$, that were only quadratic prior to our work. In addition, we prove that the KRW conjecture [Karchmer et al., Computational Complexity 5(3/4), 1995] holds for inner functions for which the unweighted quantum adversary bound is tight. In particular, this holds for inner functions with a tight Khrapchenko bound.

  Our random projections are tailor-made to the function's structure so that the function maintains structure even under projection --- using such projections is necessary, as standard random restrictions simplify $\mathbf{AC}^0$ circuits. In contrast, we show that any De Morgan formula shrinks by a quadratic factor under our random projections, allowing us to prove the cubic lower bound.

  Our proof techniques build on the proof of Håstad for the simpler case of balanced formulas. This allows for a significantly simpler proof at the cost of slightly worse parameters. As such, when specialized to the case of $p$-random restrictions, our proof can be used as an exposition of Håstad's result.</summary>
    <updated>2020-12-03T02:53:05Z</updated>
    <published>2020-12-03T02:53:05Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-12-07T07:37:38Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=17821</id>
    <link href="https://rjlipton.wordpress.com/2020/12/02/too-long-didnt-read/" rel="alternate" type="text/html"/>
    <title>Too Long, Didn’t Read</title>
    <summary>How to summarize papers Top row: Cohan, Weld. Bottom: Cachola, Lo. Isabel Cachola, Kyle Lo, Arman Cohan, Daniel Weld are the authors of a recent paper on summarizing papers. They are all connected in various way to the Allen Institute for Artificial Intelligence. Today we take a moment to try out the webtool that comes […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>How to summarize papers</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2020/12/02/too-long-didnt-read/all-8/" rel="attachment wp-att-17825"><img alt="" class="alignright wp-image-17825" height="134" src="https://rjlipton.files.wordpress.com/2020/12/all.png?w=200&amp;h=134" width="200"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Top row: Cohan, Weld. Bottom: Cachola, Lo.</font></td>
</tr>
</tbody>
</table>
<p>
Isabel Cachola, Kyle Lo, Arman Cohan, Daniel Weld are the authors of a recent <a href="https://arxiv.org/abs/2004.15011">paper</a> on summarizing papers. They are all connected in various way to the <a href="https://allenai.org/papers">Allen Institute</a> for Artificial Intelligence. </p>
<p>
Today we take a moment to try out the <a href="https://scitldr.apps.allenai.org/">webtool</a> that comes with their paper.  It is noted also in a <a href="https://www.nature.com/articles/d41586-020-03277-2">news item</a> last week in <i>Nature</i>.</p>
<p>
They have created a program that reads a science article and outputs a single sentence that summarizes its content. Their goal is to help researchers search through the huge number of published papers faster than looking at abstracts. The software utilizes neural networks trained on many examples. </p>
<p>
For example: Their own <a href="https://arxiv.org/abs/2004.15011">paper</a> has for its abstract:</p>
<blockquote><p><b> </b> <em> We introduce TLDR generation, a new form of extreme summarization, for scientific papers. TLDR generation involves high source compression and requires expert background knowledge and understanding of complex domain-specific language. To facilitate study on this task, we introduce SCITLDR, a new multi-target dataset of 5.4K TLDRs over 3.2K papers. SCITLDR contains both author-written and expert-derived TLDRs, where the latter are collected using a novel annotation protocol that produces high-quality summaries while minimizing annotation burden. We propose CATTS, a simple yet effective learning strategy for generating TLDRs that exploits titles as an auxiliary training signal. CATTS improves upon strong baselines under both automated metrics and human evaluations. </em>
</p></blockquote>
<p/><p>
And this becomes:</p>
<blockquote><p><b> </b> <em> “We introduce SCITLDR, a new multi-target dataset of 5.4K TLDRs over 3.2K papers.” </em>
</p></blockquote>
<p/><p>
Not so impressive, but more on their program shortly.</p>
<p>
</p><p/><h2> Another Tryout </h2><p/>
<p/><p>
Perhaps the big news this week is an advance on protein folding by Google DeepMind, the same team whose work on <a href="https://rjlipton.wordpress.com/2016/03/11/stonefight-at-the-goke-corral/">AlphaGo</a> and <a href="https://rjlipton.wordpress.com/2017/12/17/truth-from-zero/">AlphaZero</a> we have covered. Sure enough, their new system is called <a href="https://en.wikipedia.org/wiki/AlphaFold">AlphaFold</a>—actually, AlphaFold2. See <a href="https://en.wikipedia.org/wiki/Protein_folding">here</a> for basic information: </p>
<p/><p><br/>
<a href="https://rjlipton.wordpress.com/2020/12/02/too-long-didnt-read/fold-2/" rel="attachment wp-att-17826"><img alt="" class="aligncenter wp-image-17826" height="222" src="https://rjlipton.files.wordpress.com/2020/12/fold.png?w=500&amp;h=222" width="500"/></a></p>
<p/><p><br/>
The detailed <a href="https://deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology">announcement</a> on the DeepMind <a href="https://deepmind.com/blog">blog</a> says:</p>
<blockquote><p><b> </b> <em> Until we’ve published a paper on this work, please cite: “High Accuracy Protein Structure Prediction Using Deep Learning,” John Jumper [et al.]. In Fourteenth Critical Assessment of Techniques for Protein Structure Prediction (Abstract Book), 30 November – 4 December 2020. Retrieved from <a href="https://predictioncenter.org/casp14/doc/CASP14_Abstracts.pdf">here</a></em>.
</p></blockquote>
<p>The link under “<a href="https://predictioncenter.org/casp14/doc/CASP14_Abstracts.pdf">here</a>” goes to a long book of abstracts. Among them, there is a <a href="https://www.nature.com/articles/s41586-019-1923-7">paper</a> last January in <em>Nature</em> with many of the same authors, though Jumper not as first author. Using its abstract, we got:</p>
<blockquote><p><b> </b> <em> “We train a neural network to make accurate predictions of the distances between pairs of residues, which convey more information about the structure than contact predictions.” </em>
</p></blockquote>
<p/><p>
The abstracts book has the abstract for the current paper:</p>
<blockquote><p><b> </b> <em> In the CASP14 experiment, we deployed AlphaFold 2. This new system uses a different deep learning method than CASP13 AlphaFold, and it produces much more accurate protein structures and estimates of model accuracy. The training data for the system is publicly available and similar to that used for CASP13 AlphaFold. </em>
</p></blockquote>
<p/><p>
This is already short, but with SCITLDR it becomes:</p>
<blockquote><p><b> </b> <em> “In the CASP14 experiment, we deployed AlphaFold 2.0, a new deep learning system that produces much more accurate protein structures and” </em>
</p></blockquote>
<p/><p>
The dangling “and” is a little mystifying. SCITLDR has optional fields for <i>Introduction</i> and <i>Conclusions</i>. The entry in the abstracts book has a body titled “Methods,” whose last subsection “T1064” reads like a conclusion, so we added them as such. We cleaned up the paste from PDF to have normal line breaks. After a few seconds, we obtained:</p>
<blockquote><p><b> </b> <em> “In the CASP14 experiment, we deployed AlphaFold 2.0, a novel attention-based deep learning architecture that produces accurate protein structures” </em>
</p></blockquote>
<p/><p>
The DeepMind announcement poses a further challenge: how to glean an important paper that for now exists only as a blog post. The first paragraph of their <a href="https://deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology">post</a> is boldfaced and reads like an abstract:</p>
<blockquote><p><b> </b> <em> Proteins are essential to life, supporting practically all its functions. They are large complex molecules, made up of chains of amino acids, and what a protein does largely depends on its unique 3D structure. Figuring out what shapes proteins fold into is known as the “protein folding problem,” and has stood as a grand challenge in biology for the past 50 years. In a major scientific advance, the latest version of our AI system AlphaFold has been recognised as a solution to this grand challenge by the organisers of the biennial Critical Assessment of protein Structure Prediction (CASP). This breakthrough demonstrates the impact AI can have on scientific discovery and its potential to dramatically accelerate progress in some of the most fundamental fields that explain and shape our world. </em>
</p></blockquote>
<p/><p>
It becomes: </p>
<blockquote><p><b> </b> <em> “AlphaFold has been recognized as a solution to this grand challenge by the organizers of the Critical Assessment of protein Structure Prediction (CASP)” </em>
</p></blockquote>
<p/><p>
Pretty good—do you agree?</p>
<p>
</p><p/><h2> Even Faster </h2><p/>
<p/><p>
Both Ken and I are fans of the <a href="https://en.wikipedia.org/wiki/The_Mathematical_Experience">book</a> <em>The Mathematical Experience</em> by Philip Davis and Reuben Hersch. The following passage, from the chapter “The Ideal Mathematician,” describes how one writes a paper, but Ken has always taken it to describe the swiftness needed to read a paper:</p>
<blockquote><p><b> </b> <em> The intended readers (all twelve of them) can decode the formal presentation, detect the new idea hidden in lemma 4, ignore the routine and uninteresting calculations of lemmas 1, 2, 3, 5, 6, 7, and see what the author is doing and why he does it. </em>
</p></blockquote>
<p/><p>
Nowadays we pore through papers as they appear on arXiv. For most, we just scan the titles. For others, we go to the main page with the abstract. For some, we click on the PDF to read the paper. This may be the greatest exercise in freedom of intellect we have our professional lives, but it is also an exercise in speed. We who do research in time complexity need to minimize our own time. </p>
<p>
</p><p/><h2> Some CS Examples </h2><p/>
<p/><p>
Another way to say this: we all need to read through the literature faster and more precisely. Here are a few examples of their one sentence abstracts for theory papers from the SCITLDR program. Rate them by seeing if you can match the summarizes with the papers.</p>
<p/><p><br/>
Here are the one sentence summaries: </p>
<ol>
<li>
“Finite automata are considered in this paper as instruments for classifying finite tapes.” <p/>
</li><li>
“The number of steps required to compute a function depends, in general, on the type of computer that is used, on the choice of computer program” <p/>
</li><li>
“In this paper, it is proven that when both randomization and interaction are allowed, the proofs that can be verified in polynomial time are” <p/>
</li><li>
“In this paper a computational complexity theory of the “knowledge” contained in a proof is developed.” <p/>
</li><li>
“It is shown that any recognition problem solved by a polynomial time-bounded nondeterministic Turing machine can be “reduced” <p/>
</li><li>
“We prove that there are arbitrarily long arithmetic progressions of primes.” <p/>
</li><li>
“Nonuniform Upper Bounds: The Converse Direction of the Nonuniform Complexity Bounds .”
</li></ol>
<p/><p><br/>
Match them to the paper titles: </p>
<ol>
<li>
The complexity of theorem-proving procedures <p/>
</li><li>
Some connections between nonuniform and uniform complexity classes <p/>
</li><li>
Finite Automata and Their Decision Problem <p/>
</li><li>
A Machine-Independent theory of the Complexity of Recursive Functions <p/>
</li><li>
Some connections between nonuniform and uniform complexity classes <p/>
</li><li>
The Knowledge Complexity Of Interactive Proof Systems <p/>
</li><li>
The primes contain arbitrarily long arithmetic progressions
</li></ol>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p>The papers:</p>
<ol>
<li>
“Finite automata are considered in this paper as instruments for classifying finite tapes.” <a href="http://www.cse.chalmers.se/~coquand/AUTOMATA/rs.pdf">1</a><p/>
<p/></li><li>
“The number of steps required to compute a function depends, in general, on the type of computer that is used, on the choice of computer program” <a href="http://port70.net/~nsz/articles/classic/blum_complexity_1976.pdf">2</a><p/>
<p/></li><li>
“In this paper, it is proven that when both randomization and interaction are allowed, the proofs that can be verified in polynomial time are” <a href="https://dl.acm.org/doi/10.1145/146585.146609">3</a><p/>
<p/></li><li>
“In this paper a computational complexity theory of the “knowledge” contained in a proof is developed.” <a href="http://crypto.cs.mcgill.ca/~crepeau/COMP647/2007/TOPIC02/GMR89.pdf">4</a><p/>
<p/></li><li>
“It is shown that any recognition problem solved by a polynomial time-bounded nondeterministic Turing machine can be “reduced” <a href="https://dl.acm.org/doi/10.1145/800157.805047">5</a><p/>
<p/></li><li>
“We prove that there are arbitrarily long arithmetic progressions of primes.” <a href="https://arxiv.org/abs/math/0404188">6</a><p/>
<p/></li><li>
“Nonuniform Upper Bounds: The Converse Direction of the Nonuniform Complexity Bounds .” <a href="https://dl.acm.org/doi/10.1145/800141.804678">7</a>
</li></ol>
<p>
The answers in brief: <b>a-5, b-7,c-1,d-2,e-3,f-4,g-6</b>.</p>
<p/><p><br/>
[fixed blog formatting issues, fixed paper ascription in the intro]</p></font></font></div>
    </content>
    <updated>2020-12-02T22:17:28Z</updated>
    <published>2020-12-02T22:17:28Z</published>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="Results"/>
    <category term="literature"/>
    <category term="papers"/>
    <category term="protein folding"/>
    <category term="search"/>
    <category term="summary"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2020-12-07T07:37:47Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/179</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/179" rel="alternate" type="text/html"/>
    <title>TR20-179 |  Decoding Multivariate Multiplicity Codes on Product Sets | 

	Mrinal Kumar, 

	Siddharth Bhandari, 

	Prahladh Harsha, 

	Madhu Sudan</title>
    <summary>The multiplicity Schwartz-Zippel lemma bounds the total multiplicity of zeroes of a multivariate polynomial on a product set. This lemma motivates the multiplicity codes of Kopparty, Saraf and Yekhanin [J. ACM, 2014], who showed how to use this lemma to construct high-rate locally-decodable codes. However, the algorithmic results about these codes crucially rely on the fact that the polynomials are evaluated on a vector space and not an arbitrary product set. 

In this work, we show how to decode multivariate multiplicity codes of large multiplicities in polynomial time over finite product sets (over fields of large characteristic and zero characteristic).  Previously such decoding algorithms were not known even for a positive fraction of errors. In contrast, our work goes all the way to the distance of the code and in particular exceeds both the unique decoding bound and the Johnson bound. For errors exceeding the Johnson bound, even combinatorial list-decodablity of these codes was not known.

Our algorithm is an application of the classical polynomial method directly to the multivariate setting. In particular, we do not rely on a reduction from the multivariate to the univariate case as is typical of many of the existing results on decoding codes based on multivariate polynomials.  However, a vanilla application of the polynomial method in the multivariate setting does not yield a polynomial upper bound on the list size. We obtain a polynomial bound on the list size by taking an alternative view of multivariate multiplicity codes. In this view,  we glue all the partial derivatives of the same order  together  using a fresh set $\mathbf{z}$ of variables.  We then apply the polynomial method by viewing this as a problem over the field $\mathbb{F}(\mathbf{z})$ of rational functions in $\mathbf{z}$.</summary>
    <updated>2020-12-02T15:26:31Z</updated>
    <published>2020-12-02T15:26:31Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-12-07T07:37:38Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/12/02/tenure-track-assistant-professors-at-rochester-institute-of-technology-apply-by-january-2-2021/</id>
    <link href="https://cstheory-jobs.org/2020/12/02/tenure-track-assistant-professors-at-rochester-institute-of-technology-apply-by-january-2-2021/" rel="alternate" type="text/html"/>
    <title>Tenure-track assistant professors at Rochester Institute of Technology (apply by January 2, 2021)</title>
    <summary>The Department of Computer Science at the Rochester Institute of Technology invites applications for full-time tenure-track assistant professor positions starting in Fall 2021. We are looking to hire in all areas of computer science that strengthen our department. Website: https://sjobs.brassring.com/TGnewUI/Search/Home/Home?partnerid=25483&amp;siteid=5291#jobDetails=1534060_5291 Email: csfacsearch@cs.rit.edu</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Department of Computer Science at the Rochester Institute of Technology invites applications for full-time tenure-track assistant professor positions starting in Fall 2021. We are looking to hire in all areas of computer science that strengthen our department.</p>
<p>Website: <a href="https://sjobs.brassring.com/TGnewUI/Search/Home/Home?partnerid=25483&amp;siteid=5291#jobDetails=1534060_5291">https://sjobs.brassring.com/TGnewUI/Search/Home/Home?partnerid=25483&amp;siteid=5291#jobDetails=1534060_5291</a><br/>
Email: csfacsearch@cs.rit.edu</p></div>
    </content>
    <updated>2020-12-02T01:44:24Z</updated>
    <published>2020-12-02T01:44:24Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-12-07T07:37:51Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://theorydish.blog/?p=1814</id>
    <link href="https://theorydish.blog/2020/12/01/motwani-postdoc-announced/" rel="alternate" type="text/html"/>
    <title>Motwani Postdoc Announced</title>
    <summary>After discussing postdoc opportunities with me and the opportunities as part of the Simons Collaboration on the Theory of Algorithmic Fairness, let me conclude with postdoc opportunities with Stanford theory group: The theory group at Stanford invites applications for the Motwani postdoctoral fellowship in theoretical computer science. Information and application instructions below. Applications will be accepted until the positions are filled, but review of applicants will begin after Dec 15. Website: https://academicjobsonline.org/ajo/jobs/17685Email: theory.stanford@gmail.com</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>After discussing <a href="https://theorydish.blog/2020/11/16/hiring-postdocs/">postdoc opportunities with me</a> and the <a href="https://toc4fairnesses.org/postdoc-opportunities/">opportunities as part of the Simons Collaboration on the Theory of Algorithmic Fairness</a>, let me conclude with postdoc opportunities with Stanford theory group:</p>



<p>The theory group at Stanford invites applications for the Motwani postdoctoral fellowship in theoretical computer science. Information and application instructions below. Applications will be accepted until the positions are filled, but review of applicants will begin after Dec 15.</p>



<p>Website: <a href="https://academicjobsonline.org/ajo/jobs/17685">https://academicjobsonline.org/ajo/jobs/17685</a><br/>Email: theory.stanford@gmail.com</p></div>
    </content>
    <updated>2020-12-01T18:59:01Z</updated>
    <published>2020-12-01T18:59:01Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Omer Reingold</name>
    </author>
    <source>
      <id>https://theorydish.blog</id>
      <logo>https://theorydish.files.wordpress.com/2017/03/cropped-nightdish1.jpg?w=32</logo>
      <link href="https://theorydish.blog/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://theorydish.blog" rel="alternate" type="text/html"/>
      <link href="https://theorydish.blog/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://theorydish.blog/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Stanford's CS Theory Research Blog</subtitle>
      <title>Theory Dish</title>
      <updated>2020-12-07T07:38:26Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/12/01/motwani-postdoctoral-fellowship-at-stanford-computer-science-apply-by-december-15-2020/</id>
    <link href="https://cstheory-jobs.org/2020/12/01/motwani-postdoctoral-fellowship-at-stanford-computer-science-apply-by-december-15-2020/" rel="alternate" type="text/html"/>
    <title>Motwani Postdoctoral Fellowship at Stanford Computer Science (apply by December 15, 2020)</title>
    <summary>The theory group at Stanford invites applications for the Motwani postdoctoral fellowship in theoretical computer science. Information and application instructions below. Applications will be accepted until the positions are filled, but review of applicants will begin after Dec 15. Website: https://academicjobsonline.org/ajo/jobs/17685 Email: theory.stanford@gmail.com</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The theory group at Stanford invites applications for the Motwani postdoctoral fellowship in theoretical computer science. Information and application instructions below. Applications will be accepted until the positions are filled, but review of applicants will begin after Dec 15.</p>
<p>Website: <a href="https://academicjobsonline.org/ajo/jobs/17685">https://academicjobsonline.org/ajo/jobs/17685</a><br/>
Email: theory.stanford@gmail.com</p></div>
    </content>
    <updated>2020-12-01T00:48:59Z</updated>
    <published>2020-12-01T00:48:59Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-12-07T07:37:51Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://theorydish.blog/?p=1809</id>
    <link href="https://theorydish.blog/2020/11/30/postdoc-opportunities-in-algorithmic-fairness/" rel="alternate" type="text/html"/>
    <title>Postdoc Opportunities in Algorithmic Fairness</title>
    <summary>As promised, more postdoctoral positions now available for 2021 The Simons Collaboration on the Theory of Algorithmic Fairness seek highly qualified candidates (within five years of the award of their PhD) for a postdoctoral research position. Appointments will begin Summer or Fall 2021. This multi-year program will host several postdoctoral researchers working on modeling and theoretical work understanding (a) the sources of discriminatory behavior of algorithms, and (b) how best to mitigate such impacts. Descriptions of the scientific agendas of this research collaboration can be found at https://toc4fairnesses.org/. Fellows will be able to collaborate broadly, including with researchers at partner institutions: Stanford University, Toyota Institute of Technology at Chicago, Massachusetts Institute of Technology, Harvard University, UC Berkeley, Cornell University,  Hebrew University of Jerusalem, Weizmann Institute of Science, University of Toronto,  University of Washington, and University of Pennsylvania.  The anticipated term for a fellowship is one or two years – to be decided at the time of appointment, with the possibility of extension based on mutual agreement. In addition to competitive salary and benefits, the fellowship also includes funding for independent travel to workshops, conferences and other universities and research labs. In order to apply, please email a CV, research statement, and have two [...]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="https://theorydish.blog/2020/11/16/hiring-postdocs/">As promised</a>, more postdoctoral positions now available for 2021</p>



<p>The <a href="https://www.simonsfoundation.org/2020/06/18/foundation-announces-simons-collaboration-on-the-theory-of-algorithmic-fairness/">Simons Collaboration on the Theory of Algorithmic Fairness</a> seek highly qualified candidates (within five years of the award of their PhD) for a postdoctoral research position. Appointments will begin Summer or Fall 2021.</p>



<p>This multi-year program will host several postdoctoral researchers working on modeling and theoretical work understanding (a) the sources of discriminatory behavior of algorithms, and (b) how best to mitigate such impacts.</p>



<p>Descriptions of the scientific agendas of this research collaboration can be found at <a href="https://toc4fairnesses.org/" rel="noreferrer noopener" target="_blank">https://toc4fairnesses.org/</a>.</p>



<p>Fellows will be able to collaborate broadly, including with researchers at partner institutions: Stanford University, Toyota Institute of Technology at Chicago, Massachusetts Institute of Technology, Harvard University, UC Berkeley, Cornell University,  Hebrew University of Jerusalem, Weizmann Institute of Science, University of Toronto,  University of Washington, and University of Pennsylvania.</p>



<p> The anticipated term for a fellowship is one or two years – to be decided at the time of appointment, with the possibility of extension based on mutual agreement. In addition to competitive salary and benefits, the fellowship also includes funding for independent travel to workshops, conferences and other universities and research labs.</p>



<p>In order to apply, please email a CV, research statement, and have two reference letters sent to <a href="mailto:jamiemmt@cs.washington.edu" rel="noreferrer noopener" target="_blank">jamiemmt@cs.washington.edu</a>. Applications and reference letters are due Dec. 31, 2020, though we will consider applications which arrive after that date. Decisions will be made in February.</p>



<p>Jamie Morgenstern, chair of the postdoctoral search committee<br/>Simons Collaboration on the Foundations of Fairness in Machine Learning</p></div>
    </content>
    <updated>2020-11-30T21:38:08Z</updated>
    <published>2020-11-30T21:38:08Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Omer Reingold</name>
    </author>
    <source>
      <id>https://theorydish.blog</id>
      <logo>https://theorydish.files.wordpress.com/2017/03/cropped-nightdish1.jpg?w=32</logo>
      <link href="https://theorydish.blog/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://theorydish.blog" rel="alternate" type="text/html"/>
      <link href="https://theorydish.blog/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://theorydish.blog/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Stanford's CS Theory Research Blog</subtitle>
      <title>Theory Dish</title>
      <updated>2020-12-07T07:38:26Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/11/30/faculty-at-university-of-california-santa-cruz-apply-by-january-12-2021/</id>
    <link href="https://cstheory-jobs.org/2020/11/30/faculty-at-university-of-california-santa-cruz-apply-by-january-12-2021/" rel="alternate" type="text/html"/>
    <title>Faculty at University of California, Santa Cruz (apply by January 12, 2021)</title>
    <summary>The Computer Science &amp; Engineering department at UC Santa Cruz is recruiting for six junior faculty positions, two in theoretical computer science, two in applied machine learning, and two in experimental systems. (The TCS position URL is given below. For the others, look at the open recruitments in Computer Science and Engineering.) Website: https://recruit.ucsc.edu/JPF00962 Email: […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Computer Science &amp; Engineering department at UC Santa Cruz is recruiting for six junior faculty positions, two in theoretical computer science, two in applied machine learning, and two in experimental systems.<br/>
(The TCS position URL is given below. For the others, look at the open recruitments in Computer Science and Engineering.)</p>
<p>Website: <a href="https://recruit.ucsc.edu/JPF00962">https://recruit.ucsc.edu/JPF00962</a><br/>
Email: C. Seshadhri</p></div>
    </content>
    <updated>2020-11-30T21:15:21Z</updated>
    <published>2020-11-30T21:15:21Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-12-07T07:37:51Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2020/11/30/linkage</id>
    <link href="https://11011110.github.io/blog/2020/11/30/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>An amusing if minor repeated typo in the literature: “appiled superconductivity (\(\mathbb{M}\)). I think its 177 Google Scholar hits are the fault of IEEE, which spells Trans. on Applied Superconductivity correctly on its site but misspells it repeatedly in the doi database. So if you get your citations from doi metadata, you will get this error. You can see the metadata for an example by curl -LH "Accept: application/x-bibtex" https://doi.org/10.1109/TASC.2005.849553.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><ul>
  <li>
    <p><a href="https://scholar.google.com/scholar?q=%22Appiled+Superconductivity%22">An amusing if minor repeated typo in the literature: “appiled superconductivity</a> (<a href="https://mathstodon.xyz/@11011110/105224219465552642">\(\mathbb{M}\)</a>). I think its 177 Google Scholar hits are the fault of IEEE, which spells <em>Trans. on Applied Superconductivity</em> correctly on its site but misspells it repeatedly in the doi database. So if you get your citations from doi metadata, you will get this error. You can see the metadata for an example by <code class="language-plaintext highlighter-rouge">curl -LH "Accept: application/x-bibtex" https://doi.org/10.1109/TASC.2005.849553</code>.</p>
  </li>
  <li>
    <p><a href="https://post.lurk.org/@crickxson/105199692913412250">A map of the percentages of female researchers in Europe</a>. The numbers are highest in the Baltics and Balkans; the discussion thread suggests that there’s a negative correlation with pay.</p>
  </li>
  <li>
    <p><a href="https://news.ycombinator.com/item?id=25149206">YouTube no longer an acceptable platform for course lecture or academic talk content</a> (<a href="https://mathstodon.xyz/@11011110/105238898515120908">\(\mathbb{M}\)</a>). Unless, of course, you and your university are comfortable with your students or other audience members being subject to advertisements that interrupt the lectures and are beyond your control both in their placement and content.</p>
  </li>
  <li>
    <p><a href="https://www.quantamagazine.org/geometry-reveals-how-the-world-is-assembled-from-cubes-20201119/">Scientists uncover the universal geometry of geology</a> (<a href="https://mathstodon.xyz/@11011110/105241748181882434">\(\mathbb{M}\)</a>). This is all a bit mystic and breathless and woo, but what <em>Quanta</em> really seems to mean to is that if you subdivide space by randomly recursively splitting by planes (sort of like a 3d <a href="https://en.wikipedia.org/wiki/Gilbert_tessellation">Gilbert tessellation</a>) then the average number of sides per bottom-level polyhedron is six.</p>
  </li>
  <li>
    <p><a href="https://cameroncounts.wordpress.com/2020/11/19/a-paradox-and-where-it-led/">A paradox, and where it led</a> (<a href="https://mathstodon.xyz/@11011110/105249285864846993">\(\mathbb{M}\)</a>). Peter Cameron looks at the inclusion graphs of countable models of not-well-founded set theories. The well-founded ones are all the Rado graph, but without foundation the results are more varied.</p>
  </li>
  <li>
    <p><a href="https://theconversation.com/curved-origami-offers-a-creative-route-to-making-robots-and-other-mechanical-devices-150253">Curved origami robot grippers with tunable stiffness</a> (<a href="https://mathstodon.xyz/@11011110/105260956314627650">\(\mathbb{M}\)</a>).</p>
  </li>
  <li>
    <p><a href="https://blog.archive.org/2020/11/23/foss-wins-again-free-and-open-source-communities-comes-through-on-19th-century-newspapers-and-books-and-periodicals/">Archive.org improves accuracy of OCR and compression of PDF on its huge collection of old scanned printed documents by switching to open-source software</a> (<a href="https://mathstodon.xyz/@11011110/105264347147907544">\(\mathbb{M}\)</a>).</p>
  </li>
  <li>
    <p><a href="https://hackers.town/@_cr0_tab/105165210380388504">Four common mathematical means of two quantities in a single compass-and-straightedge construction</a>.</p>
  </li>
  <li>
    <p><a href="http://cstaecker.fairfield.edu/~cstaecker/machines/graphsheets.html">More different kinds of graph paper than you might have even thought possible</a> (<a href="https://mathstodon.xyz/@11011110/105275252021160077">\(\mathbb{M}\)</a>).</p>
  </li>
  <li>
    <p><a href="https://renato.athaydes.com/posts/comparing-jvm-alternatives-to-js.html">Comparison of six ways to get your old Java applets running again on the modern web</a> (<a href="https://mathstodon.xyz/@11011110/105284817164400009">\(\mathbb{M}\)</a>, <a href="https://news.ycombinator.com/item?id=19714924">via</a>). I have a couple of old defunct ones that I’m tempted to try this on…</p>
  </li>
  <li>
    <p><a href="https://mathstodon.xyz/@jsiehler/105288859971030412">New names for special types of hexagon: “squashogon”, “boltogon”, “extremely irregular hexagon”, and “treeah star”</a>. Boltogons are the zigzag 180-degree symmetric ones.</p>
  </li>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/Wikipedia:Wikipedia_Signpost/2020-11-29/Essay">Some tips for avoiding sexist language when writing about women</a> (<a href="https://mathstodon.xyz/@11011110/105298265490259050">\(\mathbb{M}\)</a>). This is from 2015, when singular “they” was more controversial, and mostly aimed at Wikipedia editing, but it was recently reprinted in the Wikipedia <em>Signpost</em>, and I think it is still topical more generally.)</p>
  </li>
  <li>
    <p><a href="https://www.ams.org/journals/notices/202011/rnoti-p1780.pdf">The place of blogs in the modern math world, Katherine Thompson, <em>Notices of the AMS</em></a> (<a href="https://mathstodon.xyz/@11011110/105301116392488191">\(\mathbb{M}\)</a>). “Clearly, mathematicians are using blogs. … And yet despite all of the work that goes into blogs, the mathematical community has no idea what to make of them—even at the most basic level like citation.”</p>
  </li>
</ul></div>
    </content>
    <updated>2020-11-30T18:15:00Z</updated>
    <published>2020-11-30T18:15:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2020-12-06T22:52:09Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/178</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/178" rel="alternate" type="text/html"/>
    <title>TR20-178 |  Reciprocal Inputs in Arithmetic and Tropical Circuits | 

	Stasys Jukna, 

	Hannes Seiwert, 

	Igor Sergeev</title>
    <summary>It is known that the size of monotone arithmetic $(+,\ast)$ circuits can be  exponentially decreased by allowing just one division  "at the very end," at the output gate. A natural question is: can the size of $(+,\ast)$ circuits be substantially  reduced if we allow divisions "at the very beginning," that is, if besides  nonnegative real constants and variables $x_1,\ldots,x_n$, the circuits can also use their reciprocals $1/x_1,\ldots,1/x_n$ as inputs. We answer this question in the negative: the gain in circuit size is  then always at most quadratic.


Over tropical $(\min,+)$ and $(\max,+)$ semirings, division turns into subtraction; so, reciprocal inputs are then $-x_1,\ldots,-x_n$.  We give the same negative answer also for tropical circuits. The question of whether reciprocal inputs can substantially speed up tropical $(\min,+,\max)$ circuits, using both $\min$ and $\max$ gates, remains open.</summary>
    <updated>2020-11-30T17:48:06Z</updated>
    <published>2020-11-30T17:48:06Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-12-07T07:37:38Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/11/30/tenure-track-assistant-professors-at-aalto-university-apply-by-january-10-2021/</id>
    <link href="https://cstheory-jobs.org/2020/11/30/tenure-track-assistant-professors-at-aalto-university-apply-by-january-10-2021/" rel="alternate" type="text/html"/>
    <title>Tenure Track Assistant Professors at Aalto University (apply by January 10, 2021)</title>
    <summary>The Department of Computer Science at Aalto University invites applications for tenure-track positions at the Assistant Professor level. We are a diverse community welcoming applications in ALL AREAS of Computer Science. Our CS Theory group (https://research.cs.aalto.fi/theory/) has e.g. received the best paper awards in FOCS 2019 and ICALP 2017, as well as ERC starting grants […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Department of Computer Science at Aalto University invites applications for tenure-track positions at the Assistant Professor level. We are a diverse community welcoming applications in ALL AREAS of Computer Science.</p>
<p>Our CS Theory group (<a href="https://research.cs.aalto.fi/theory/">https://research.cs.aalto.fi/theory/</a>) has e.g. received the best paper awards in FOCS 2019 and ICALP 2017, as well as ERC starting grants in 2014 and 2017.</p>
<p>Website: <a href="https://www.aalto.fi/en/open-positions/tenure-track-assistant-professors-in-computer-science">https://www.aalto.fi/en/open-positions/tenure-track-assistant-professors-in-computer-science</a><br/>
Email: laura.kuusisto-noponen@aalto.fi</p></div>
    </content>
    <updated>2020-11-30T15:42:33Z</updated>
    <published>2020-11-30T15:42:33Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-12-07T07:37:51Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://decentralizedthoughts.github.io/2020-11-30-the-lock-commit-paradigm-multi-shot-and-mixed-faults/</id>
    <link href="https://decentralizedthoughts.github.io/2020-11-30-the-lock-commit-paradigm-multi-shot-and-mixed-faults/" rel="alternate" type="text/html"/>
    <title>The Lock-Commit Paradigm: Multi-shot and Mixed Faults</title>
    <summary>In this follow up post, we show a multi-shot synchronous protocol for uniform consensus that can tolerate $f$ omission failures, given 2f &lt; n. We then extend it to one that tolerates both $f$ omission failures and $k$ crash failures given k+2f &lt; n. Multi-shot Lock-Commit Instead of solving consensus...</summary>
    <updated>2020-11-30T14:01:00Z</updated>
    <published>2020-11-30T14:01:00Z</published>
    <source>
      <id>https://decentralizedthoughts.github.io</id>
      <author>
        <name>Decentralized Thoughts</name>
      </author>
      <link href="https://decentralizedthoughts.github.io" rel="alternate" type="text/html"/>
      <link href="https://decentralizedthoughts.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Decentralized thoughts about decentralization</subtitle>
      <title>Decentralized Thoughts</title>
      <updated>2020-12-07T01:21:31Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/11/30/research-associate-postdoc-at-university-of-edinburgh-apply-by-january-6-2021/</id>
    <link href="https://cstheory-jobs.org/2020/11/30/research-associate-postdoc-at-university-of-edinburgh-apply-by-january-6-2021/" rel="alternate" type="text/html"/>
    <title>Research Associate (Postdoc) at University of Edinburgh (apply by January 6, 2021)</title>
    <summary>Applications are invited for research associate positions in Algorithms and Complexity, funded by the European Research Council (ERC) starting grant “New Approaches to Counting and Sampling” (NACS), led by Dr. Heng Guo in the School of Informatics, University of Edinburgh. Website: https://elxw.fa.em3.oraclecloud.com/hcmUI/CandidateExperience/en/sites/CX_1001/job/123/ Email: hguo@inf.ed.ac.uk</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Applications are invited for research associate positions in Algorithms and Complexity, funded by the European Research Council (ERC) starting grant “New Approaches to Counting and Sampling” (NACS), led by Dr. Heng Guo in the School of Informatics, University of Edinburgh.</p>
<p>Website: <a href="https://elxw.fa.em3.oraclecloud.com/hcmUI/CandidateExperience/en/sites/CX_1001/job/123/">https://elxw.fa.em3.oraclecloud.com/hcmUI/CandidateExperience/en/sites/CX_1001/job/123/</a><br/>
Email: hguo@inf.ed.ac.uk</p></div>
    </content>
    <updated>2020-11-30T10:30:00Z</updated>
    <published>2020-11-30T10:30:00Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-12-07T07:37:51Z</updated>
    </source>
  </entry>
</feed>
