<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2022-02-11T14:39:43Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en">
    <id>http://nisheethvishnoi.wordpress.com/?p=147</id>
    <link href="https://nisheethvishnoi.wordpress.com/2022/02/11/focs-2021-talk-videos/" rel="alternate" type="text/html"/>
    <title>FOCS 2021 Talk Videos</title>
    <summary>After more than a year of planning, FOCS 2021 concluded yesterday. In case you missed all or part of the event, the talks for all of 117 papers and for the three workshops are now available on this youtube channel. The full versions of all papers (and videos) are also freely available here. Many thanks […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>After more than a year of planning, FOCS 2021 concluded yesterday. </p>



<p>In case you missed all or part of the event, the talks for all of 117 papers and for the three workshops are now available on <a href="https://www.youtube.com/channel/UClrteoQ-ULzlZZaWi6c6iKw/playlists">this youtube</a> channel.</p>



<p>The full versions of all papers (and videos) are also freely available <a href="https://focs2021.cs.colorado.edu/program/">here</a>.</p>



<p>Many thanks to more than 1000 people, including authors, program committee members, external reviewers, organizers, TCMF members, volunteers, and attendees for making this happen! </p>



<figure class="wp-block-video"/></div>
    </content>
    <updated>2022-02-11T14:30:16Z</updated>
    <published>2022-02-11T14:30:16Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>nisheethvishnoi</name>
    </author>
    <source>
      <id>https://nisheethvishnoi.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://nisheethvishnoi.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://nisheethvishnoi.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://nisheethvishnoi.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://nisheethvishnoi.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Algorithms, Nature, and Society</title>
      <updated>2022-02-11T14:39:16Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://rjlipton.wpcomstaging.com/?p=19636</id>
    <link href="https://rjlipton.wpcomstaging.com/2022/02/10/national-academy-of-engineering-elects/" rel="alternate" type="text/html"/>
    <title>National Academy of Engineering Elects</title>
    <summary>The problem in this business isn’t to keep people from stealing your ideas; it’s making them steal your ideas!—Howard Aiken Composite crop of homepage photos Taher Elgamal and Anna Karlin are among 111 new US members of the National Academy of Engineering (NAE). That’s one-hundred-and-eleven, not seven in binary. Today we congratulate them and all […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>The problem in this business isn’t to keep people from stealing your ideas; it’s making them steal your ideas!—Howard Aiken</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2022/02/10/national-academy-of-engineering-elects/egak/" rel="attachment wp-att-19638"><img alt="" class="alignright size-full wp-image-19638" height="115" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/02/EGAK.png?resize=155%2C115&amp;ssl=1" width="155"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Composite crop of homepage photos</font></td>
</tr>
</tbody>
</table>
<p>
Taher Elgamal and Anna Karlin are among 111 <a href="https://www.nae.edu/270224/National-Academy-of-Engineering-Elects-111-Members-and-22-International-Members">new US members</a> of the National Academy of Engineering (NAE). That’s one-hundred-and-eleven, not seven in binary.</p>
<p>
Today we congratulate them and all the new members.</p>
<p>
Elgamal and Karlin are the two closest to theory, by my reckoning. Elgamal developed the <a href="https://en.wikipedia.org/wiki/ElGamal_encryption">ElGamal</a> encryption scheme. Elgamal spelled his name with a capital G at the time of his famous 1985 <a href="https://caislab.kaist.ac.kr/lecture/2010/spring/cs548/basic/B02.pdf">paper</a> but it is lowercased on his own LinkedIn <a href="https://www.linkedin.com/in/taherelgamal/">page</a>, on Wikipedia, on his RSA conference <a href="https://www.rsaconference.com/experts/dr-taherelgamal">page</a>, and by the NAE. Wikipedia explains that he spells it more simply so that “it is less likely to be mangled in English.” Yet his invention keeps the capital G. Ken and I think a good reason for this is that it uses a large cyclic group <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. The citation also hails his work on <a href="https://en.wikipedia.org/wiki/Transport_Layer_Security#SSL_1.0,_2.0,_and_3.0">SSL</a> and other internet protocols.</p>
<p>
We featured Karlin’s nifty joint paper on the metric TSP problem recently <a href="https://rjlipton.wpcomstaging.com/2020/10/26/a-vast-and-tiny-breakthrough/">here</a>. She is also on the editorial board of the new TheoretiCS <a href="https://rjlipton.wpcomstaging.com/2021/12/01/the-new-journal/">journal</a>. I was glad to serve with her on an NSF committee to promote <a href="https://rjlipton.wpcomstaging.com/2011/07/12/time-chunks-and-theory-nuggets/">nuggets</a> of theory. She holds the Bill and Melinda Gates Chair at the Paul Allen School of Computer Science and Engineering at the University of Washington.</p>
<p>
The new members bring the total US membership in the NAE to 2,388. Joining them are 22 new international members. They include Natarajan Chandrasekaran of Tata Sons for advancing the Indian software industry and Hongjiang Zhang of The Carlyle Group in Beijing for multimedia computing. </p>
<p><a href="https://rjlipton.wpcomstaging.com/2022/02/10/national-academy-of-engineering-elects/nae/" rel="attachment wp-att-19639"><img alt="" class="aligncenter wp-image-19639" height="120" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/02/nae.png?resize=120%2C120&amp;ssl=1" width="120"/></a></p>
<p>
</p><p/><h2> New Members in Computing </h2><p/>
<p/><p>
There are many other new members in areas of computing besides theory. Here are some of the new members that work in computer science—including the citations for Elgamal and Karlin. </p>
<ul>
<p/><li>
Bergeron, Kathleen, vice president, Hardware Engineering, Apple Inc., Los Gatos, Calif. <i>For contributions to and leadership in the invention and engineering product realization of innovative designs.</i><p/>
<p/></li><li>
Bovik, Alan C., Cockrell Family Regents Endowed Chair in Engineering and professor, Electrical and Computer Engineering, University of Texas, Austin. <i>For contributions to the development of tools for image and video quality assessment.</i><p/>
<p/></li><li>
Cohn, John Maxwell, IBM Fellow, MIT-IBM Watson AI Lab, Cambridge, Mass. <i>For improving design productivity of high-performance analog and mixed-signal circuits and for evangelizing STEM education.</i><p/>
<p/></li><li>
Croak, Marian R., vice president, Engineering, Google LLC, Fair Haven, N.J. <i>For technical and managerial leadership in the implementation of packet voice networking and for promotion of minority inclusion in engineering.</i><p/>
<p/></li><li>
Czerwinski, Mary, partner researcher and research manager, Microsoft Research, Redmond, Wash. <i>For the application of psychological principles to the design and understanding of human computer interaction.</i><p/>
<p/></li><li>
Elgamal, Taher, chief technology officer, Security, Salesforce, San Francisco. <i>For contributions to cryptography, e-commerce, and protocols for secure internet transactions.</i><p/>
<p/></li><li>
Fields, Craig I., chairman, Defense Science Board, U.S. Department of Defense, Washington, D.C. <i>For contributions to the development of systems and technology for national security and their transfer to commercial applications.</i><p/>
<p/></li><li>
Hammack, William S., William H. and Janet G. Lycan Professor, Chemical and Biomolecular Engineering, University of Illinois, Urbana-Champaign. <i>For innovations in multidisciplinary engineering education, outreach, and service to the profession through development and communication of internet-delivered content.</i><p/>
<p/></li><li>
Karlin, Anna, Bill and Melinda Gates Chair, Allen School of Computer Science &amp; Engineering, University of Washington, Seattle. <i>For contributions to the design and analysis of randomized algorithms and their impact on computer systems and the internet.</i><p/>
<p/></li><li>
Karniadakis, George Em, Charles Pitts Robinson and John Palmer Barstow Professor, Division of Applied Mathematics and School of Engineering, Brown University, Providence, R.I. <i>For computational tools, from high-accuracy algorithms to machine learning, and applications to complex flows, stochastic processes, and microfluidics.</i><p/>
<p/></li><li>
Levoy, Marc, Vmware Founders Professor (emeritus), Computer Science, Stanford University, Stanford, Calif. <i>For contributions to computer graphics and digital photography.</i><p/>
<p/></li><li>
Mauro, John C., professor, Department of Materials Science and Engineering, Pennsylvania State University, University Park. <i>For developing and applying data-driven models and machine learning that enable high-strength, damage-resistant glasses.</i><p/>
<p/></li><li>
Nadella, Satya, chairman and chief executive officer, Microsoft Corp., Redmond, Wash. <i>For advancing corporate computing infrastructure as a cloud service, and for international leadership on sociotechnical systems and practice.</i> <p/>
<p/></li><li>
Nahrstedt, Klara, Grainger Distinguished Chair, Grainger College of Engineering, University of Illinois, Urbana-Champaign. <i>For contributions to managing quality of service in distributed multimedia systems and networks.</i><p/>
<p/></li><li>
Reiman, Martin I., professor, Department of Industrial Engineering and Operations Research, Columbia University, Murray Hill, N.J. <i>For contributions to network theory and applications in large-scale stochastic systems.</i><p/>
<p/></li><li>
Sahinidis, Nikolaos V., Gary C. Butler Family Chair and Professor, H. Milton Stewart School of Industrial and Systems Engineering, Georgia Institute of Technology, Atlanta. <i>For contributions to global optimization and the development of widely used software for optimization and machine learning.</i><p/>
<p/></li><li>
Sapiro, Guillermo, James B. Duke Distinguished Professor, Electrical and Computer Engineering, Duke University, Durham, N.C. <i>For contributions to the theory and practice of imaging.</i><p/>
<p/></li><li>
Veloso, Manuela M., head, Artificial Intelligence Research, JPMorgan Chase &amp; Co., New York City. <i>For contributions to machine learning and its applications in robotics and the financial services industry.</i><p/>
<p/></li><li>
Whitney, Telle, CEO, Telle Whitney Consulting LLC, Scotts Valley, Calif. <i>For contributions to structured silicon design and for increasing the participation of women in computing careers.</i><p/>
<p/></li><li>
Willcox, Karen E., director, Oden Institute for Computational Engineering and Sciences, University of Texas, Austin. <i>For contributions to computational engineering methods for the design and optimal control of high-dimensional systems with uncertainties.</i><p/>
</li></ul>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
We count 8 women of the 20 above: Bergeron, Croak, Czerwinski, Karlin, Nahrstedt, Veloso, Whitney, and Willcox. That’s quite a lot better than other rations we’ve observed. How can awareness of this success be filtered through? We also note Anna’s <a href="https://medium.com/@karlin_41004/why-women-and-everyone-else-should-code-18e4a0a46a47">essay</a>, “Why Women (and Everyone Else) Should Code.”</p>
<p/></font></font></div>
    </content>
    <updated>2022-02-11T01:40:02Z</updated>
    <published>2022-02-11T01:40:02Z</published>
    <category term="All Posts"/>
    <category term="News"/>
    <category term="People"/>
    <category term="Anna Karlin"/>
    <category term="National Academy of Engineering"/>
    <category term="new members"/>
    <category term="Taher Elgamal"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wpcomstaging.com</id>
      <logo>https://s0.wp.com/i/webclip.png</logo>
      <link href="https://rjlipton.wpcomstaging.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wpcomstaging.com" rel="alternate" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel's Lost Letter and P=NP</title>
      <updated>2022-02-11T14:37:57Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2022/02/10/hereditary-first-order</id>
    <link href="https://11011110.github.io/blog/2022/02/10/hereditary-first-order.html" rel="alternate" type="text/html"/>
    <title>Hereditary first order graph properties can be hard</title>
    <summary>Many natural classes of undirected graphs are hereditary, meaning that if you delete vertices from any graph in the class, the induced subgraph that you get always remains in this class. Every hereditary class of graphs can be defined by its forbidden induced subgraphs, the minimal graphs that do not belong to the class. When there are only finitely many of these forbidden subgraphs, it is possible to define the class by a formula in the first-order logic of graphs describing the graphs that do not have these subgraphs, and to test membership in the class in polynomial time by searching for a forbidden subgraph. Examples include:</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Many natural classes of undirected graphs are <a href="https://en.wikipedia.org/wiki/Hereditary_property">hereditary</a>, meaning that if you delete vertices from any graph in the class, the induced subgraph that you get always remains in this class. Every hereditary class of graphs can be defined by its <a href="https://en.wikipedia.org/wiki/Forbidden_graph_characterization">forbidden induced subgraphs</a>, the minimal graphs that do not belong to the class. When there are only finitely many of these forbidden subgraphs, it is possible to define the class by a formula in the first-order <a href="https://en.wikipedia.org/wiki/Logic_of_graphs">logic of graphs</a> describing the graphs that do not have these subgraphs, and to test membership in the class in polynomial time by searching for a forbidden subgraph. Examples include:</p>

<ul>
  <li>
    <p>The <a href="https://en.wikipedia.org/wiki/Threshold_graph">threshold graphs</a>, whose forbidden subgraphs are a four-vertex path, four-vertex cycle, or four-vertex perfect matching.</p>
  </li>
  <li>
    <p>The <a href="https://en.wikipedia.org/wiki/Cograph">cographs</a>, whose single forbidden subgraph is a four-vertex path.</p>
  </li>
  <li>
    <p>The <a href="https://en.wikipedia.org/wiki/Triangle-free_graph">triangle-free graphs</a>, whose single forbidden subgraph is a <span style="white-space: nowrap;">triangle \(K_3\).</span></p>
  </li>
  <li>
    <p>The <a href="https://en.wikipedia.org/wiki/Claw-free_graph">claw-free graphs</a>, whose single forbidden subgraph is the four-vertex <span style="white-space: nowrap;">tree \(K_{1,3}\).</span></p>
  </li>
  <li>
    <p>The <a href="https://en.wikipedia.org/wiki/Line_graph">line graphs</a>, which have a forbidden subgraph characterization with nine forbidden subgraphs:</p>
  </li>
</ul>

<p style="text-align: center;"><img alt="The nine forbidden induced subgraphs of line graphs" src="https://11011110.github.io/blog/assets/2022/nonline.svg"/></p>

<p>However, there might be infinitely many forbidden subgraphs. In many such cases, it is still possible to recognize these graphs in polynomial time, often by a greedy algorithm that removes vertices one at a time based on some local structure. Additionally, in these cases, it is often possible to describe the property of being one of the forbidden subgraphs by a first-order formula, so that the graph class is the class of graphs none of whose subgraphs model that formula. For instance:</p>

<ul>
  <li>
    <p>The <a href="https://en.wikipedia.org/wiki/Degeneracy_(graph_theory)"><span style="white-space: nowrap;">\(d\)-degenerate</span> graphs</a> are graphs in which no non-empty induced subgraph has all vertices of degree greater <span style="white-space: nowrap;">than \(d\).</span> They can be recognized in polynomial time as the graphs reducible to empty by repeatedly removing low-degree vertices.</p>
  </li>
  <li>
    <p>The <a href="https://en.wikipedia.org/wiki/Distance-hereditary_graph">distance-hereditary graphs</a> are graphs in which every induced subgraph with two or more vertices has a degree-one vertex, or twins, two vertices with equal closed or open neighborhoods. They can be recognized in polynomial time by repeatedly removing degree-one vertices or merging twins.</p>
  </li>
  <li>
    <p>The <a href="https://en.wikipedia.org/wiki/Chordal_graph">chordal graphs</a> are graphs with no induced cycle of more than three vertices, or the graphs in which every non-empty induced subgraph has a simplicial vertex, a vertex whose neighbors are all adjacent. They can be recognized in polynomial time by repeatedly removing simplicial vertices.</p>
  </li>
  <li>
    <p>The <a href="https://en.wikipedia.org/wiki/Perfect_graph">perfect graphs</a> are graphs with no odd induced cycle of more than three vertices, or its complement. They can be recognized in polynomial time but the algorithm is complicated.</p>
  </li>
</ul>

<p>Obviously, not all hereditary classes are like that; one could, for instance, forbid induced cycles whose lengths belong to an undecidable set of integers, and get a hereditary class of graphs whose recognition problem is again undecidable. But this led me to wonder: is there a connection between the first-order recognizability of the forbidden subgraphs and the polynomial recognizability of the graph class itself? Could it be that every hereditary class defined by a first-order set of forbidden subgraphs is polynomially recognizable?</p>

<p>No!</p>

<p>The counterexample I found is the family of graphs whose forbidden subgraphs are the non-empty <a href="https://en.wikipedia.org/wiki/Perfect_graph">cubic (3-regular) graphs</a>. Let’s call these the cubic-free graphs. Being cubic is easily expressed in first-order logic, so the forbidden subgraphs for the cubic-free graphs are first-order recognizable. However, under standard assumptions, the cubic-free graphs themselves are not polynomially recognizable: their recognition problem is <span style="white-space: nowrap;">\(\mathsf{coNP}\)-complete.</span> Put another way, the problem <small>CUBIC INDUCED SUBGRAPH</small> asking whether a given graph has a non-empty cubic induced subgraph is <span style="white-space: nowrap;">\(\mathsf{NP}\)-complete.</span></p>

<p>I found lots of references in the literature to problems of finding non-empty cubic subgraphs (not required to be induced subgraphs; see Garey &amp; Johnson GT32), or to finding cubic induced subgraphs with some constraint on their size, but not to the <small>CUBIC INDUCED SUBGRAPH</small> problem itself. So instead, I found an <span style="white-space: nowrap;">\(\mathsf{NP}\)-completeness</span> reduction myself, from <a href="https://en.wikipedia.org/wiki/3-dimensional_matching"><small>3-DIMENSIONAL MATCHING</small></a>, in which the input is a 3-uniform hypergraph (meaning that each hyperedge touches three hypervertices) and one must find a subset of the hyperedges that touches every hypervertex exactly once. An example of my reduction is shown below, from which I think the general case should be more clear.</p>

<p style="text-align: center;"><img alt="NP-completeness reduction from 3-dimensional matching to cubic induced subgraph" src="https://11011110.github.io/blog/assets/2022/3dm23is.svg"/></p>

<p>The input hypergraph is shown with its hypervertices as large blue disks and its hyperedges as medium-sized yellow disks. Inside each of these disks is shown part of a graph, a gadget into which that piece of the hypergraph is translated to form a piece of a <small>CUBIC INDUCED SUBGRAPH</small> instance. The example hypergraph used in the image is 4-regular (every hypervertex touches four hyperedges) but that’s not essential. Once you start making choices of which vertices to include or exclude in an induced subgraph, you can make a chain of inferences from that choice:</p>
<ul>
  <li>If you have included a vertex that has only three non-excluded neighbors, you must include all three of them.</li>
  <li>If you have included a vertex that has three included neighbors, you must exclude all its other neighbors.</li>
  <li>If some vertex has fewer than three neighbors that are not excluded, you must exclude it.</li>
</ul>

<p>It follows from this sort of reasoning that the only non-empty cubic induced subgraphs are like the ones shown by the dark red vertices in these gadgets: a vertex for each of the the hyperedges in a matching (such as the matching of dark-yellow hyperedges), and a corresponding subset of the vertices in every hypervertex gadget. Because finding a cubic induced subgraph is <span style="white-space: nowrap;">\(\mathsf{NP}\)-complete,</span> its complementary problem, testing whether a graph is cubic-free, is <span style="white-space: nowrap;">\(\mathsf{coNP}\)-complete.</span></p>

<p>(<a href="https://mathstodon.xyz/@11011110/107776994325248199">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2022-02-10T17:40:00Z</updated>
    <published>2022-02-10T17:40:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2022-02-11T02:28:19Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2022/02/10/postdoc-in-computational-complexity-at-imperial-college-london-apply-by-april-15-2022/</id>
    <link href="https://cstheory-jobs.org/2022/02/10/postdoc-in-computational-complexity-at-imperial-college-london-apply-by-april-15-2022/" rel="alternate" type="text/html"/>
    <title>Postdoc in computational complexity at Imperial College London (apply by April 15, 2022)</title>
    <summary>Applications are invited for a postdoctoral position at the Complexity Group, Imperial College London, led by prof. Iddo Tzameret and funded by the ERC. The position is for one year with up to two-year extension. The start date is flexible, and the salary is generous. This position is based at the South Kensington campus in […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Applications are invited for a postdoctoral position at the Complexity Group, Imperial College London, led by prof. Iddo Tzameret and funded by the ERC. The position is for one year with up to two-year extension. The start date is flexible, and the salary is generous. This position is based at the South Kensington campus in the heart of London. Applications will be accepted until position filled.</p>
<p>Website: <a href="https://www.doc.ic.ac.uk/~itzamere/PhD_Postdoc_Post.html">https://www.doc.ic.ac.uk/~itzamere/PhD_Postdoc_Post.html</a><br/>
Email: iddo.tzameret@gmail.com</p></div>
    </content>
    <updated>2022-02-10T17:39:08Z</updated>
    <published>2022-02-10T17:39:08Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2022-02-11T14:38:01Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2022/02/10/tenure-track-assistant-professor-at-university-of-vienna-apply-by-march-15-2022/</id>
    <link href="https://cstheory-jobs.org/2022/02/10/tenure-track-assistant-professor-at-university-of-vienna-apply-by-march-15-2022/" rel="alternate" type="text/html"/>
    <title>Tenure-track assistant professor at University of Vienna (apply by March 15, 2022)</title>
    <summary>The faculty of Computer Science is looking for outstanding internationally recognized early career scientists with a research focus on scalable algorithmic approaches for AI. This competence is documented by publications in top venues in relevant areas, including, but not limited to, – machine learning, – AI, – algorithms, or – high performance computing research. Website: […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The faculty of Computer Science is looking for outstanding internationally recognized early career scientists with a research focus on scalable algorithmic approaches for AI.<br/>
This competence is documented by publications in top venues in relevant areas, including, but not limited to, – machine learning,<br/>
– AI,<br/>
– algorithms, or<br/>
– high performance computing research.</p>
<p>Website: <a href="https://univis.univie.ac.at/ausschreibungstellensuche/flow/bew_ausschreibung-flow?_flowExecutionKey=_c11E8D826-8A93-525D-7F25-64B17F6D4117_k70C7134F-AA27-C4B1-26FA-8A869B87BA6B&amp;tid=89875.28">https://univis.univie.ac.at/ausschreibungstellensuche/flow/bew_ausschreibung-flow?_flowExecutionKey=_c11E8D826-8A93-525D-7F25-64B17F6D4117_k70C7134F-AA27-C4B1-26FA-8A869B87BA6B&amp;tid=89875.28</a><br/>
Email: monika.henzinger@univie.ac.at</p></div>
    </content>
    <updated>2022-02-10T14:34:39Z</updated>
    <published>2022-02-10T14:34:39Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2022-02-11T14:38:01Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=22399</id>
    <link href="https://gilkalai.wordpress.com/2022/02/10/is-hqca-possible-a-conversation-with-michael-brooks/" rel="alternate" type="text/html"/>
    <title>Is HQCA Possible? A conversation with Michael Brooks</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Here is a short email interview from April 2021 with Michael Brooks from “New Scientist”. Dear Professor Kalai, I’m writing a short feature for New Scientist magazine on the theme “Will we ever have a useful quantum computer?”. I’m aware … <a href="https://gilkalai.wordpress.com/2022/02/10/is-hqca-possible-a-conversation-with-michael-brooks/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Here is a short email interview from April 2021 with Michael Brooks from “New Scientist”.</p>
<p><span class="im"><strong>Dear Professor Kalai,</strong> <b>I’m writing a short feature for New Scientist magazine on the theme “Will we ever have a useful quantum computer?”. I’m aware of your work on the problems with noise, and your position that error correction won’t be possible.</b></span></p>
<p>This is correct. My analysis asserts that quality error correction won’t be possible and that even the easier target of <span class="il">HQCA</span> (huge quantum computational advantage) won’t be possible. Here is a <a href="https://arxiv.org/abs/2008.05188">link</a> to my new paper that you may find useful. It refers to recent developments: the Google Sycamore experiment and <span class="il">HQCA</span> claims are discussed in Sections 6 and 7, and there is a new Section 9 regarding the very recent developments.</p>
<p><b>I was wondering whether anything you’ve seen – demonstrations or arguments – in the last few months have done anything to change your mind, or whether you are now more convinced than ever that we won’t ever see truly useful (beyond doing science) quantum computing?  </b></p>
<p>Well, I think that my theory is rather strong but not ironclad. As for the level of my conviction, it does not change often, but roughly speaking there were three stages to my research (and level of conviction):</p>
<p>1) 2005-2013.   What I did was (in hindsight) exploring consequences of the failure of quantum fault tolerance and, on the way, some mistakes in the logic of firmly believing that quantum computers could be built. But, as I often said at that time, I did not think my work then gave a reason for people to change their a priori beliefs.</p>
<p>2) 2013-2019.  Following my work with Guy Kindler I saw a clear scientific argument for why quantum computers will fail. (We first considered the special case of boson sampling and later I extended it in  greater generality.) Since that time, I regard my argument to be strong enough to change people a priori beliefs, and my level of conviction went up as well. But, as I said, it is not an ironclad argument.</p>
<p>3) 2019 – onward.  The experimental claims by Google and later by a group from Hefei, China would, if correct, refute my argument. So, naturally, this casts some doubts also in my mind. However, there are good technical reasons to doubt the fantastic claims by the Hefei group, and on that matter actually my 2014 paper with Kindler comes to play. The situation with the Google experiment is more delicate, but there are reasons to doubt their experimental claims as well.</p>
<p>As for a priori beliefs: In my view the situation is that it is hard to believe that quantum computers are not possible, but it is even harder to believe that quantum computers are possible <img alt="&#x1F642;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f642.png" style="height: 1em;"/> . So much experimental and theoretical research is needed before humankind will crack this puzzle.</p>
<p><span class="im"><b>Also, I was wondering if the retraction of the main paper about creating Majorana fermions (<a href="https://www.nature.com/articles/d41586-021-00612-z" rel="noopener" target="_blank">https://www.nature.com/articles/d41586-021-00612-z</a>) kills topological computing’s hopes of getting us there?</b></span></p>
<p>No, the retraction of a single paper does not kill at all topological computing’s hopes. In fact, the researchers who found the mistake are hopeful that a successful experiment of that kind is possible and are also hopeful regarding further experimental steps towards topological quantum computing.</p>
<p>My general argument does extend to topological quantum computing and asserts that stable topological qubits are not possible.</p>
<p>Thanks for your interest and best wishes,  Gil Kalai</p>
<p><strong>Additional comments:</strong> The (very nice) <a href="https://www.scientiststudy.com/2021/09/why-it-might-be-impossible-to-build.html">article appeared in August 2021</a> and (accurately) refers to my position: “Gil Kalai, a mathematician at the Hebrew University of Jerusalem in Israel, argued that the basic noise level in a quantum computer will always be too high, no matter how many qubits are available. ‘My analysis says that correcting quality errors will not be possible.’ ” The article quotes also <a href="https://researchportal.helsinki.fi/en/persons/sabrina-maniscalco/publications/">Sabrina Maniscalco</a> from the University of Helsinki in Finland who said: “Finding a cure for the effect of environmental noise is not only, in my opinion, a technological problem, but more conceptual and fundamental. I would say that I am optimistic, rather than confident”.</p>
<p>My debate with Aram Harrow over GLL <a href="https://rjlipton.wpcomstaging.com/2012/01/30/perpetual-motion-of-the-21st-century/">started ten years ago</a>. A lot has happened in these ten years! (Here is a <a href="https://rjlipton.wpcomstaging.com/2012/01/30/perpetual-motion-of-the-21st-century/#comment-18029">comment</a> from the debate on my assessment of the situation at that time.)</p>
<p>The researchers who took on themselves the thankless task of putting the Microsoft Majorana claims under scrutiny and found the mistakes are <a href="https://www.physicsandastronomy.pitt.edu/people/sergey-frolov" rel="noopener" target="_blank">Sergey Frolov</a> and <a href="https://www.fqt.unsw.edu.au/staff/vincent-mourik-0" rel="noopener" target="_blank">Vincent Mourik</a>. (See also <a href="https://www.nature.com/articles/d41586-021-00954-8">Frolov’s commentary</a> in “Nature” and <a href="https://www.quantamagazine.org/major-quantum-computing-strategy-suffers-serious-setbacks-20210929/">this article</a> in “Quanta Magazine”.) They drew important conclusions for the need of sharing raw data and other experimental details for such experiments.</p>
<p>For more details:  on my view regarding quantum computers see <a href="https://gilkalai.wordpress.com/2020/12/29/the-argument-against-quantum-computers-a-very-short-introduction/" rel="bookmark">The Argument Against Quantum Computers – A Very Short Introduction</a> (December 2020); and on Google’s supremacy experiment see <a href="https://gilkalai.wordpress.com/2019/11/13/gils-collegial-quantum-supremacy-skepticism-faq/" rel="bookmark">Gil’s Collegial Quantum Supremacy Skepticism FAQ</a> (November 2019).</p></div>
    </content>
    <updated>2022-02-10T09:57:23Z</updated>
    <published>2022-02-10T09:57:23Z</published>
    <category term="Computer Science and Optimization"/>
    <category term="Quantum"/>
    <category term="Aram Harrow"/>
    <category term="Michael Brooks"/>
    <category term="Quantum computers"/>
    <category term="Sabrina Maniscalco"/>
    <category term="Sergey Frolov"/>
    <category term="Vincent Mourik"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2022-02-11T14:37:46Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2022/02/10/postdoc-positions-in-algorithms-complexity-at-university-of-california-san-diego-apply-by-march-31-2022/</id>
    <link href="https://cstheory-jobs.org/2022/02/10/postdoc-positions-in-algorithms-complexity-at-university-of-california-san-diego-apply-by-march-31-2022/" rel="alternate" type="text/html"/>
    <title>Postdoc Positions in Algorithms &amp; Complexity at University of California San Diego (apply by March 31, 2022)</title>
    <summary>Multiple postdoc positions available at UCSD Theory group to work on graph algorithms, randomized and approximation algorithms, fine-grained complexity, and additive combinatorics. Apply directly to barnas@ucsd.edu. Must include your resume, and contact information of three reference writers. Website: https://cstheory.ucsd.edu/home.html Email: barnas@ucsd.edu</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Multiple postdoc positions available at UCSD Theory group to work on graph algorithms, randomized and approximation algorithms, fine-grained complexity, and additive combinatorics. Apply directly to barnas@ucsd.edu. Must include your resume, and contact information of three reference writers.</p>
<p>Website: <a href="https://cstheory.ucsd.edu/home.html">https://cstheory.ucsd.edu/home.html</a><br/>
Email: barnas@ucsd.edu</p></div>
    </content>
    <updated>2022-02-10T08:02:51Z</updated>
    <published>2022-02-10T08:02:51Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2022-02-11T14:38:01Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://tcsplus.wordpress.com/?p=595</id>
    <link href="https://tcsplus.wordpress.com/2022/02/09/tcs-talk-wednesday-february-23-merav-parter-weizmann-institute-of-science/" rel="alternate" type="text/html"/>
    <title>TCS+ talk: Wednesday, February 23 — Merav Parter, Weizmann Institute of Science</title>
    <summary>The first TCS+ talk of 2022 will take place on Wednesday, February 23rd at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 18:00 UTC). Merav Parter from Weizmann Institute of Science will speak about “New Diameter Reducing Shortcuts: Breaking the Barrier” (abstract below). You can reserve a spot as an individual […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The first TCS+ talk of 2022 will take place on Wednesday, February 23rd at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 18:00 UTC). <a href="https://www.weizmann.ac.il/math/parter/home"><strong>Merav Parter</strong></a> from Weizmann Institute of Science will speak about “<em>New Diameter Reducing Shortcuts: Breaking the <img alt="O(\sqrt{n})" class="latex" src="https://s0.wp.com/latex.php?latex=O%28%5Csqrt%7Bn%7D%29&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/> Barrier</em>” (abstract below).</p>
<p>You can reserve a spot as an individual or a group to join us live by signing up on <a href="https://sites.google.com/view/tcsplus/welcome/next-tcs-talk">the online form</a>. Registration is <em>not</em> required to attend the interactive talk, and the link will be posted on the website the day prior to the talk; however, by registering in the form, you will receive a reminder, along with the link. (The recorded talk will also be posted <a href="https://sites.google.com/view/tcsplus/welcome/past-talks">on our website</a> afterwards) As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/view/tcsplus/welcome/suggest-a-talk">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/view/tcsplus/">the website</a>.</p>
<blockquote class="wp-block-quote"><p>Abstract: For an <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/>-vertex digraph <img alt="G=(V,E)" class="latex" src="https://s0.wp.com/latex.php?latex=G%3D%28V%2CE%29&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/>, a <em>shortcut set</em> is a (small) subset of edges <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/> taken from the transitive closure of <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/> that, when added to <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/> guarantees that the diameter of <img alt="G \cup H" class="latex" src="https://s0.wp.com/latex.php?latex=G+%5Ccup+H&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/> is small. Shortcut sets, introduced by Thorup in 1993, have a wide range of applications in algorithm design, especially in the context of parallel, distributed and dynamic computation on directed graphs. A folklore result in this context shows that every <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/>-vertex digraph admits a shortcut set of linear size (i.e., of <img alt="O(n)" class="latex" src="https://s0.wp.com/latex.php?latex=O%28n%29&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/> edges) that reduces the diameter to <img alt="\widetilde{O}(\sqrt{n})" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cwidetilde%7BO%7D%28%5Csqrt%7Bn%7D%29&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/>. Despite extensive research over the years, the question of whether one can reduce the diameter to <img alt="o(\sqrt{n})" class="latex" src="https://s0.wp.com/latex.php?latex=o%28%5Csqrt%7Bn%7D%29&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/> with <img alt="\widetilde{O}(n)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cwidetilde%7BO%7D%28n%29&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/> shortcut edges has been left open.</p>
<p>In this talk, I will present the first improved diameter-sparsity tradeoff for this problem, breaking the <img alt="\sqrt{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csqrt%7Bn%7D&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/> diameter barrier. Specifically, we show an <img alt="O(n^{\omega})" class="latex" src="https://s0.wp.com/latex.php?latex=O%28n%5E%7B%5Comega%7D%29&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/>-time randomized algorithm for computing a linear shortcut set that reduces the diameter of the digraph to <img alt="\widetilde{O}(n^{1/3})" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cwidetilde%7BO%7D%28n%5E%7B1%2F3%7D%29&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/>. We also extend our algorithms to provide improved <img alt="(\beta,\epsilon)" class="latex" src="https://s0.wp.com/latex.php?latex=%28%5Cbeta%2C%5Cepsilon%29&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/> hopsets for <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/>-vertex weighted directed graphs.</p>
<p>Joint work with Shimon Kogan.</p></blockquote></div>
    </content>
    <updated>2022-02-10T04:08:49Z</updated>
    <published>2022-02-10T04:08:49Z</published>
    <category term="Announcements"/>
    <author>
      <name>plustcs</name>
    </author>
    <source>
      <id>https://tcsplus.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://tcsplus.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://tcsplus.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://tcsplus.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://tcsplus.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A carbon-free dissemination of ideas across the globe.</subtitle>
      <title>TCS+</title>
      <updated>2022-02-11T14:38:47Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.04640</id>
    <link href="http://arxiv.org/abs/2202.04640" rel="alternate" type="text/html"/>
    <title>Sharper Rates for Separable Minimax and Finite Sum Optimization via Primal-Dual Extragradient Methods</title>
    <feedworld_mtime>1644451200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jin:Yujia.html">Yujia Jin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sidford:Aaron.html">Aaron Sidford</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tian:Kevin.html">Kevin Tian</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.04640">PDF</a><br/><b>Abstract: </b>We design accelerated algorithms with improved rates for several fundamental
classes of optimization problems. Our algorithms all build upon techniques
related to the analysis of primal-dual extragradient methods via relative
Lipschitzness proposed recently by [CST21].
</p>
<p>(1) Separable minimax optimization. We study separable minimax optimization
problems $\min_x \max_y f(x) - g(y) + h(x, y)$, where $f$ and $g$ have
smoothness and strong convexity parameters $(L^x, \mu^x)$, $(L^y, \mu^y)$, and
$h$ is convex-concave with a $(\Lambda^{xx}, \Lambda^{xy},
\Lambda^{yy})$-blockwise operator norm bounded Hessian. We provide an algorithm
with gradient query complexity $\tilde{O}\left(\sqrt{\frac{L^{x}}{\mu^{x}}} +
\sqrt{\frac{L^{y}}{\mu^{y}}} + \frac{\Lambda^{xx}}{\mu^{x}} +
\frac{\Lambda^{xy}}{\sqrt{\mu^{x}\mu^{y}}} +
\frac{\Lambda^{yy}}{\mu^{y}}\right)$. Notably, for convex-concave minimax
problems with bilinear coupling (e.g.\ quadratics), where $\Lambda^{xx} =
\Lambda^{yy} = 0$, our rate matches a lower bound of [ZHZ19].
</p>
<p>(2) Finite sum optimization. We study finite sum optimization problems
$\min_x \frac{1}{n}\sum_{i\in[n]} f_i(x)$, where each $f_i$ is $L_i$-smooth and
the overall problem is $\mu$-strongly convex. We provide an algorithm with
gradient query complexity $\tilde{O}\left(n + \sum_{i\in[n]}
\sqrt{\frac{L_i}{n\mu}} \right)$. Notably, when the smoothness bounds
$\{L_i\}_{i\in[n]}$ are non-uniform, our rate improves upon accelerated SVRG
[LMH15, FGKS15] and Katyusha [All17] by up to a $\sqrt{n}$ factor.
</p>
<p>(3) Minimax finite sums. We generalize our algorithms for minimax and finite
sum optimization to solve a natural family of minimax finite sum optimization
problems at an accelerated rate, encapsulating both above results up to a
logarithmic factor.
</p></div>
    </summary>
    <updated>2022-02-10T22:48:59Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-02-10T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.04627</id>
    <link href="http://arxiv.org/abs/2202.04627" rel="alternate" type="text/html"/>
    <title>Automated Discovery of Geometrical Theorems in GeoGebra</title>
    <feedworld_mtime>1644451200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kov=aacute=cs:Zolt=aacute=n.html">Zoltán Kovács</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yu:Jonathan_H=.html">Jonathan H. Yu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.04627">PDF</a><br/><b>Abstract: </b>We describe a prototype of a new experimental GeoGebra command and tool,
Discover, that analyzes geometric figures for salient patterns, properties, and
theorems. This tool is a basic implementation of automated discovery in
elementary planar geometry. The paper focuses on the mathematical background of
the implementation, as well as methods to avoid combinatorial explosion when
storing the interesting properties of a geometric figure.
</p></div>
    </summary>
    <updated>2022-02-10T22:50:07Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2022-02-10T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.04626</id>
    <link href="http://arxiv.org/abs/2202.04626" rel="alternate" type="text/html"/>
    <title>Symbolic Comparison of Geometric Quantities in GeoGebra</title>
    <feedworld_mtime>1644451200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kov=aacute=cs:Zolt=aacute=n.html">Zoltán Kovács</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vajda:R=oacute=bert.html">Róbert Vajda</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.04626">PDF</a><br/><b>Abstract: </b>Comparison of geometric quantities usually means obtaining generally true
equalities of different algebraic expressions of a given geometric figure.
Today's technical possibilities already support symbolic proofs of a
conjectured theorem, by exploiting computer algebra capabilities of some
dynamic geometry systems as well. We introduce GeoGebra's new feature, the
Compare command, that helps the users in experiments in planar geometry. We
focus on automatically obtaining conjectures and their proofs at the same time,
including not just equalities but inequalities too. Our contribution can
already be successfully used to support teaching geometry classes at secondary
level, by getting several well-known and some previously unpublished result
within seconds on a modern personal computer.
</p></div>
    </summary>
    <updated>2022-02-10T22:50:27Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2022-02-10T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.04551</id>
    <link href="http://arxiv.org/abs/2202.04551" rel="alternate" type="text/html"/>
    <title>Shortest Paths without a Map, but with an Entropic Regularizer</title>
    <feedworld_mtime>1644451200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bubeck:S=eacute=bastien.html">Sébastien Bubeck</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Coester:Christian.html">Christian Coester</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rabani:Yuval.html">Yuval Rabani</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.04551">PDF</a><br/><b>Abstract: </b>In a 1989 paper titled "shortest paths without a map", Papadimitriou and
Yannakakis introduced an online model of searching in a weighted layered graph
for a target node, while attempting to minimize the total length of the path
traversed by the searcher. This problem, later called layered graph traversal,
is parametrized by the maximum cardinality $k$ of a layer of the input graph.
It is an online setting for dynamic programming, and it is known to be a rather
general and fundamental model of online computing, which includes as special
cases other acclaimed models. The deterministic competitive ratio for this
problem was soon discovered to be exponential in $k$, and it is now nearly
resolved: it lies between $\Omega(2^k)$ and $O(k2^k)$. Regarding the randomized
competitive ratio, in 1993 Ramesh proved, surprisingly, that this ratio has to
be at least $\Omega(k^2 / \log^{1+\epsilon} k)$ (for any constant $\epsilon &gt;
0$). In the same paper, Ramesh also gave an $O(k^{13})$-competitive randomized
online algorithm. Since 1993, no progress has been reported on the randomized
competitive ratio of layered graph traversal. In this work we show how to apply
the mirror descent framework on a carefully selected evolving metric space, and
obtain an $O(k^2)$-competitive randomized online algorithm, nearly matching the
known lower bound on the randomized competitive ratio.
</p></div>
    </summary>
    <updated>2022-02-10T22:38:59Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-02-10T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.04515</id>
    <link href="http://arxiv.org/abs/2202.04515" rel="alternate" type="text/html"/>
    <title>Leverage Score Sampling for Tensor Product Matrices in Input Sparsity Time</title>
    <feedworld_mtime>1644451200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Woodruff:David_P=.html">David P. Woodruff</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zandieh:Amir.html">Amir Zandieh</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.04515">PDF</a><br/><b>Abstract: </b>We give an input sparsity time sampling algorithm for spectrally
approximating the Gram matrix corresponding to the $q$-fold column-wise tensor
product of $q$ matrices using a nearly optimal number of samples, improving
upon all previously known methods by poly$(q)$ factors. Furthermore, for the
important special care of the $q$-fold self-tensoring of a dataset, which is
the feature matrix of the degree-$q$ polynomial kernel, the leading term of our
method's runtime is proportional to the size of the dataset and has no
dependence on $q$. Previous techniques either incur a poly$(q)$ factor slowdown
in their runtime or remove the dependence on $q$ at the expense of having
sub-optimal target dimension, and depend quadratically on the number of
data-points in their runtime. Our sampling technique relies on a collection of
$q$ partially correlated random projections which can be simultaneously applied
to a dataset $X$ in total time that only depends on the size of $X$, and at the
same time their $q$-fold Kronecker product acts as a near-isometry for any
fixed vector in the column span of $X^{\otimes q}$. We show that our sampling
methods generalize to other classes of kernels beyond polynomial, such as
Gaussian and Neural Tangent kernels.
</p></div>
    </summary>
    <updated>2022-02-10T22:44:34Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-02-10T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.04377</id>
    <link href="http://arxiv.org/abs/2202.04377" rel="alternate" type="text/html"/>
    <title>Constant Approximating Parameterized $k$-SetCover is W[2]-hard</title>
    <feedworld_mtime>1644451200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lin:Bingkai.html">Bingkai Lin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Ren:Xuandi.html">Xuandi Ren</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sun:Yican.html">Yican Sun</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Xiuhan.html">Xiuhan Wang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.04377">PDF</a><br/><b>Abstract: </b>In this paper, we prove that it is W[2]-hard to approximate $k$-SetCover
within any constant ratio. Our proof is built upon the recently developed
threshold graph composition technique. We propose a strong notion of threshold
graph and use a new composition method to prove this result. Our technique
could also be applied to rule out polynomial time $o\left(\frac{\log n}{\log
\log n}\right)$ ratio approximation algorithms for the non-parameterized
$k$-SetCover problem, assuming W[1]$\ne$FPT.
</p>
<p>We highlight that our proof does not depend on the well-known PCP theorem,
and only involves simple combinatorial objects. Furthermore, our reduction
results in a $k$-SetCover instance with $k$ as small as $O\left(\log^2 n\cdot
\log \log n\right)$.
</p></div>
    </summary>
    <updated>2022-02-10T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-02-10T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.04349</id>
    <link href="http://arxiv.org/abs/2202.04349" rel="alternate" type="text/html"/>
    <title>Cartesian Tree Subsequence Matching</title>
    <feedworld_mtime>1644451200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Tsubasa Oizumi, Takeshi Kai, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mieno:Takuya.html">Takuya Mieno</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Inenaga:Shunsuke.html">Shunsuke Inenaga</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Arimura:Hiroki.html">Hiroki Arimura</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.04349">PDF</a><br/><b>Abstract: </b>Park et al. [TCS 2020] observed that the similarity between two (numerical)
strings can be captured by the Cartesian trees: The Cartesian tree of a string
is a binary tree recursively constructed by picking up the smallest value of
the string as the root of the tree. Two strings of equal length are said to
Cartesian-tree match if their Cartesian trees are isomorphic. Park et al. [TCS
2020] introduced the following Cartesian tree substring matching (CTMStr)
problem: Given a text string $T$ of length $n$ and a pattern string of length
$m$, find every consecutive substring $S = T[i..j]$ of a text string $T$ such
that $S$ and $P$ Cartesian-tree match. They showed how to solve this problem in
$\tilde{O}(n+m)$ time. In this paper, we introduce the Cartesian tree
subsequence matching (CTMSeq) problem, that asks to find every minimal
substring $S = T[i..j]$ of $T$ such that $S$ contains a subsequence $S'$ which
Cartesian-tree matches $P$. We prove that the CTMSeq problem can be solved
efficiently, in $O(m n p(n))$ time, where $p(n)$ denotes the update/query time
for dynamic predecessor queries. By using a suitable dynamic predecessor data
structure, we obtain $O(mn \log \log n)$-time $O(n \log m)$-space solution for
CTMSeq. This contrasts CTMSeq with closely related order-preserving subsequence
matching (OPMSeq) which was shown to be NP-hard by Bose et al. [IPL 1998].
</p></div>
    </summary>
    <updated>2022-02-10T22:41:09Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-02-10T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.04262</id>
    <link href="http://arxiv.org/abs/2202.04262" rel="alternate" type="text/html"/>
    <title>Parsimonious Learning-Augmented Caching</title>
    <feedworld_mtime>1644451200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Im:Sungjin.html">Sungjin Im</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kumar:Ravi.html">Ravi Kumar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Petety:Aditya.html">Aditya Petety</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Purohit:Manish.html">Manish Purohit</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.04262">PDF</a><br/><b>Abstract: </b>Learning-augmented algorithms -- in which, traditional algorithms are
augmented with machine-learned predictions -- have emerged as a framework to go
beyond worst-case analysis. The overarching goal is to design algorithms that
perform near-optimally when the predictions are accurate yet retain certain
worst-case guarantees irrespective of the accuracy of the predictions. This
framework has been successfully applied to online problems such as caching
where the predictions can be used to alleviate uncertainties.
</p>
<p>In this paper we introduce and study the setting in which the
learning-augmented algorithm can utilize the predictions parsimoniously. We
consider the caching problem -- which has been extensively studied in the
learning-augmented setting -- and show that one can achieve quantitatively
similar results but only using a sublinear number of predictions.
</p></div>
    </summary>
    <updated>2022-02-10T22:40:20Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-02-10T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.04246</id>
    <link href="http://arxiv.org/abs/2202.04246" rel="alternate" type="text/html"/>
    <title>The decision problem for perfect matchings in dense hypergraphs</title>
    <feedworld_mtime>1644451200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Luyining Gan, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Han:Jie.html">Jie Han</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.04246">PDF</a><br/><b>Abstract: </b>Given $1\le \ell &lt;k$ and $\delta&gt;0$, let $\textbf{PM}(k,\ell,\delta)$ be the
decision problem for the existence of perfect matchings in $n$-vertex
$k$-uniform hypergraphs with minimum $\ell$-degree at least
$\delta\binom{n-\ell}{k-\ell}$. For $k\ge 3$, the decision problem in general
$k$-uniform hypergraphs, equivalently $\textbf{PM}(k,\ell,0)$, is one of Karp's
21 NP-complete problems. Moreover, a reduction of Szyma\'{n}ska showed that
$PM(k, \ell, \delta)$ is NP-complete for $\delta &lt; 1-(1-1/k)^{k-\ell}$. A
breakthrough by Keevash, Knox and Mycroft [STOC '13] resolved this problem for
$\ell=k-1$ by showing that $PM(k, k-1, \delta)$ is in P for $\delta &gt; 1/k$.
Based on their result for $\ell=k-1$, Keevash, Knox and Mycroft conjectured
that $PM(k, \ell, \delta)$ is in P for every $\delta &gt; 1-(1-1/k)^{k-\ell}$.
</p>
<p>In this paper it is shown that this decision problem for perfect matchings
can be reduced to the study of the minimum $\ell$-degree condition forcing the
existence of fractional perfect matchings. That is, we hopefully solve the
"computational complexity" aspect of the problem by reducing it to a well-known
extremal problem in hypergraph theory. In particular, together with existing
results on fractional perfect matchings, this solves the conjecture of Keevash,
Knox and Mycroft for $\ell\ge 0.4k$.
</p></div>
    </summary>
    <updated>2022-02-10T22:38:06Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2022-02-10T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.04185</id>
    <link href="http://arxiv.org/abs/2202.04185" rel="alternate" type="text/html"/>
    <title>OSM-tree: A Sortedness-Aware Index</title>
    <feedworld_mtime>1644451200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Raman:Aneesh.html">Aneesh Raman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sarkar:Subhadeep.html">Subhadeep Sarkar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Olma:Matthaios.html">Matthaios Olma</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Athanassoulis:Manos.html">Manos Athanassoulis</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.04185">PDF</a><br/><b>Abstract: </b>Indexes facilitate efficient querying when the selection predicate is on an
indexed key. As a result, when loading data, if we anticipate future selective
(point or range) queries, we typically maintain an index that is gradually
populated as new data is ingested. In that respect, indexing can be perceived
as the process of adding structure to an incoming, otherwise unsorted, data
collection. The process of adding structure comes at a cost, as instead of
simply appending incoming data, every new entry is inserted into the index. If
the data ingestion order matches the indexed attribute order, the ingestion
cost is entirely redundant and can be avoided (e.g., via bulk loading in a
B+-tree). However, state-of-the-art index designs do not benefit when data is
ingested in an order that is close to being sorted but not fully sorted. In
this paper, we study how indexes can benefit from partial data sortedness or
near-sortedness, and we propose an ensemble of techniques that combine bulk
loading, index appends, variable node fill/split factor, and buffering, to
optimize the ingestion cost of a tree index in presence of partial data
sortedness. We further augment the proposed design with necessary metadata
structures to ensure competitive read performance. We apply the proposed design
paradigm on a state-of-the-art B+-tree, and we propose the Ordered Sort-Merge
tree (OSM-tree). OSM-tree outperforms the state of the art by up to 8.8x in
ingestion performance in the presence of sortedness, while falling back to a
B+-tree's ingestion performance when data is scrambled. OSM-tree offers
competitive query performance, leading to performance benefits between 28% and
5x for mixed read/write workloads.
</p></div>
    </summary>
    <updated>2022-02-10T22:38:24Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-02-10T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://ptreview.sublinear.info/?p=1622</id>
    <link href="https://ptreview.sublinear.info/2022/02/news-for-january-2021-2/" rel="alternate" type="text/html"/>
    <title>News for January 2022</title>
    <summary>A slow month to start 2022, as far as property testing (and myself) are concerned — “only” 3 papers, and a delay of several days in posting this. Let’s jump in with quantum testing! Testing matrix product states, by Mehdi Soleimanifar and John Wright (arXiv). Suppose you are given a state \(|\psi\rangle\) of \(n\) qubits, […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>A slow month to start 2022, as far as property testing (and myself) are concerned — “only” 3 papers, and a delay of several days in posting this. Let’s jump in with quantum testing!</p>



<p><strong>Testing matrix product states</strong>, by Mehdi Soleimanifar and John Wright (<a href="https://arxiv.org/abs/2201.01824">arXiv</a>). Suppose you are given a state \(|\psi\rangle\) of \(n\) qubits, and want to know “how entangled” this whole thing is: for instance, is \(|\psi\rangle\) a product state (no entanglement between the \(n\) qudits)? More generally, the “amount of entanglement” allowed is captured by an integer \(r\), the<em> bond dimension</em>, where product state corresponds to \(r=1\), and larger \(r\) allows for more entanglement. This paper then considers the following property testing question: how many copies of \(|\psi\rangle\) are needed to test whether it has bond dimension at most \(r\), or is \(\varepsilon\)-far from every such state (in trace distance)? While the case \(r=1\) had been previously considered, this paper considers the general case; and, in particular, shows a qualitative gap between \(r=1\) (for which a constant number of copies, \(O(1/\varepsilon^2)\), suffice) and \(r\geq 2\) (for which they show the number of states is \(\Omega(\sqrt{n}/\varepsilon^2)\), and \(O(n r^2/\varepsilon^2)\)).</p>



<p><strong>Constant-time one-shot testing of large-scale graph states</strong>, by Hayata Yamasaki and Sathyawageeswar Subramanian (<a href="https://arxiv.org/abs/2201.11127">arXiv</a>). In this paper, the authors consider the task of testing if the physical error rate of a given system is below a given threshold — namely, the threshold below which fault-tolerant measurement-based quantum computation (MBQC) becomes feasible. Casting this into the framework of property testing, the paper shows that measuring very few (a constant number!) of the input state is enough to test whether the error rate is low.</p>



<p>And, to conclude, a paper which escaped us in December, on private distribution testing:</p>



<p><strong>Pure Differential Privacy from Secure Intermediaries</strong>, by Albert Cheu and Chao Yan (<a href="https://arxiv.org/abs/2112.10032">arXiv</a>). Throwback to <a href="https://ptreview.sublinear.info/2020/05/news-for-april-2020/">April 2020</a> and <a href="https://ptreview.sublinear.info/2021/09/news-for-august-2021/">August 2021</a>, which covered results on distribution testing (uniformity testing!) under the <em>shuffle model</em> of differential privacy. Namely, there was an upper bound of $$ O( k^{2/3}/(\alpha^{4/3}\varepsilon^{2/3})\log^{1/3}(1/\delta) + k^{1/2}/(\alpha\varepsilon) \log^{1/2}(1/\delta) + k^{1/2}/\alpha^2)$$ samples for testing uniformity of distributions over \([k]\), to distance \(\alpha\), under \((\varepsilon,\delta)\)<em>–</em>shuffle privacy (so, <em>approximate</em> privacy: \(\delta&gt;0\)). A partial lower bound existed for <em>pure</em> differential privacy, i.e., when \(\delta=0\): however, no upper bound was known for pure shuffle privacy.<br/>Until now: this new paper shows that pure DP basically comes at no cost, by providing an \((\varepsilon,0)\)-shuffle private testing algorithm with sample complexity $$ O( k^{2/3}/(\alpha^{4/3}\varepsilon^{2/3}) + k^{1/2}/(\alpha\varepsilon) + k^{1/2}/\alpha^2)$$ The paper actually does a lot more, focusing on a different problem, private summation; and the testing upper bound is a corollary of the new methods they develop in the process.</p></div>
    </content>
    <updated>2022-02-09T07:05:07Z</updated>
    <published>2022-02-09T07:05:07Z</published>
    <category term="Monthly digest"/>
    <author>
      <name>Clement Canonne</name>
    </author>
    <source>
      <id>https://ptreview.sublinear.info</id>
      <link href="https://ptreview.sublinear.info/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://ptreview.sublinear.info" rel="alternate" type="text/html"/>
      <subtitle>The latest in property testing and sublinear time algorithms</subtitle>
      <title>Property Testing Review</title>
      <updated>2022-02-10T22:52:45Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-72814287285807577</id>
    <link href="http://blog.computationalcomplexity.org/feeds/72814287285807577/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/02/a-book-break.html#comment-form" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/72814287285807577" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/72814287285807577" rel="self" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/02/a-book-break.html" rel="alternate" type="text/html"/>
    <title>A Book Break</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I got the writing bug back while working on my <a href="https://cacm.acm.org/magazines/2022/1/257448-fifty-years-of-p-vs-np-and-the-possibility-of-the-impossible/fulltext">recent CACM article</a> and I'd like to try my hand at another book. Not sure the exact topic but something related to the changing nature of computing and its implications. </p><p>I'll cut down my blogging for a while. I'll still post or tweet when I have something I want to say. Bill will continue to post regularly and keep this blog active.</p><p>Bill asked me if I have time to write this book as dean but he already knew the answer. Writing keeps me sane in a world that seems less and less so.</p></div>
    </content>
    <updated>2022-02-08T23:00:00Z</updated>
    <published>2022-02-08T23:00:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="http://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2022-02-11T00:48:13Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2022/02/08/postdoc-in-quantum-algorithms-at-university-of-latvia-at-centre-for-quantum-computer-science-university-of-latvia-apply-by-march-1-2022/</id>
    <link href="https://cstheory-jobs.org/2022/02/08/postdoc-in-quantum-algorithms-at-university-of-latvia-at-centre-for-quantum-computer-science-university-of-latvia-apply-by-march-1-2022/" rel="alternate" type="text/html"/>
    <title>postdoc in quantum algorithms at University of Latvia at Centre for Quantum Computer Science, University of Latvia (apply by March 1, 2022)</title>
    <summary>Applications are invited for a postdoctoral position at the Centre for Quantum Computer Science (CQCS), University of Latvia, lead by prof. Andris Ambainis. We are looking for candidates who would be interested in quantum algorithms (with background in either quantum information or classical TCS.) The appointment would be for 2 years, starting between September 1, […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Applications are invited for a postdoctoral position at the Centre for Quantum Computer Science (CQCS), University of Latvia, lead by prof. Andris Ambainis. We are looking for candidates who would be interested in quantum algorithms (with background in either quantum information or classical TCS.) The appointment would be for 2 years, starting between September 1, 2022 and January 1, 2023.</p>
<p>Website: <a href="https://quantum.lu.lv/join-us/">https://quantum.lu.lv/join-us/</a><br/>
Email: ambainis@lu.lv</p></div>
    </content>
    <updated>2022-02-08T18:16:56Z</updated>
    <published>2022-02-08T18:16:56Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2022-02-11T14:38:01Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/014</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/014" rel="alternate" type="text/html"/>
    <title>TR22-014 |  Tighter MA/1 Circuit Lower Bounds From Verifier Efficient PCPs for PSPACE | 

	Joshua Cook, 

	Dana Moshkovitz</title>
    <summary>We prove for some constant $a &gt; 1$, for all $k \leq a$,
$$\mathbf{MATIME}[n^{k + o(1)}] / 1 \not \subset \mathbf{SIZE}[O(n^{k})],$$
for some specific $o(1)$ function. This improves on the Santhanam lower bound, which says there exists constant $c$ such that for all $k &gt; 1$:
$$\mathbf{MATIME}[n^{c k}] / 1 \not \subset \mathbf{SIZE}[O(n^{k})].$$
There is inherently no upper bound on $c$ in Santhanam's proof. Using ideas from Murray and Williams, all $k &gt; 1$:
$$\mathbf{MATIME}[n^{10 k^2}] / 1 \not \subset \mathbf{SIZE}[O(n^{k})].$$
    
Our proof uses a new, very efficient $\mathbf{PCP}$ for $\mathbf{PSPACE}$. We construct a $\mathbf{PCP}$ with unbounded proof length for $\mathbf{SPACE}[O(n)]$ that has a $\tilde{O}(n)$ time verifier, $\tilde{O}(n)$ space prover, $O(\log(n))$ queries, and polynomial alphabet size. Prior to this work, $\mathbf{PCP}$s for $\mathbf{SPACE}[O(n)]$ either used $\Omega(n)$ queries or had verifiers that run in $\Omega(n^2)$ time.</summary>
    <updated>2022-02-08T14:57:45Z</updated>
    <published>2022-02-08T14:57:45Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-02-11T14:37:42Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-6817129401606575319</id>
    <link href="http://blog.computationalcomplexity.org/feeds/6817129401606575319/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/02/pspace-is-contained-in-zero-knowledge.html#comment-form" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/6817129401606575319" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/6817129401606575319" rel="self" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/02/pspace-is-contained-in-zero-knowledge.html" rel="alternate" type="text/html"/>
    <title>PSPACE is contained in Zero Knowledge!! How come nobody seems to care?</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>(This post was inspired by Lance's post on Zero Knowledge, <a href="https://blog.computationalcomplexity.org/2022/02/the-beginnings-of-zero-knowledge.html">here</a>, which was inspired by a video he has in the post which was inspired by... (I think this ordering is well founded.))</p><p> ZK= Zero Knowledge.</p><p>When it was shown that NP \subseteq ZK this was a big deal. This was by Goldreich-Micali-Wigderson  (see <a href="https://dl.acm.org/doi/10.1145/116825.116852">her</a>e (FOCS-1986, JACM-1991). In the JACM paper they have the following passage:</p><div><blockquote>Our result that all languages in NP have zero-knowledge proof systems, has been extended to IP, assuming the same assumptions. (The result was first proved by Impagliazzo and Yung, but since their paper [53] contains only a claim of the result, the interested reader is directed to [11] where a (different proof) appears.) In other words, whatever can be efficiently proven can be efficiently proven in a zero-knowledge manner. This may be viewed as the best result possible, since only languages having interactive proof systems can have zero-knowledge interactive proof systems.<br/><br/>11. BEN-OR, M., GOLDREICH, O., GOLDWASSER, S., HASTAD, J., KILLIAN, J., MICALI, S,,  AND ROGAWAY, P. Everything provable is provable in zero-knowledge. In Proceedings of Advances in Cryptology— Crypto88. Lecture Notes in Computer Science, vol. 403. Springer-Verlag, New York, 1990, pp. 37-56.<br/><br/>53.IMPAGLIAZZO. R., AND YUNG, M. Direct minimum-knowledge computations. In C. Pomerance, ed., Proceedings of Advances in Cryptology— Crypto87. Lecture Notes in Computer Science, vol. 293. Springer-Verlag, New York, 1987, pp. 40-51.</blockquote>Later the papers of Lund-Fortnow-Karloff-Nisan and Shamir showed IP=PSPACE. Hence<br/><br/><div style="text-align: center;">PSPACE \subseteq ZK</div><p>When I realized this I thought OH, that's interesting! I then looked around the web and could not find any mention of it. I asked Lance and some people in crypto and yeah, they all knew it was true, but nobody seemed to care.</p><p>Why the apathy? Speculation:</p><p>1) ZK is a notion people actually want to use in real crypto (and there has been some progress on that lately). The prover for ZK in PSPACE has to be way to powerful to be practical. I don't really like this explanation since we are talking about theorists. Even in crypto, which has more of a connection to the real works then, say, Ramsey Theory, there are still plenty of non-useful results. </p><p>2) IP=PSPACE was the big news and  had interesting proof with nice ideas. Nothing crypto-ish about it. So the corollary that PSPACE \subseteq ZK is an afterthought. </p><p>3) SAT in ZK was big news. IP in ZK is nice, but uses mostly the same ideas.</p><p>4) I am WRONG- it is a celebrated result and I somehow missed the celebration.</p><p>5) The proof that ZK is in PSPACE USES two interesting results, but adds NOTHING to the mix. In short, the proof is to easy.</p><p>Any other ideas?</p></div></div>
    </content>
    <updated>2022-02-06T20:19:00Z</updated>
    <published>2022-02-06T20:19:00Z</published>
    <author>
      <name>gasarch</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03004932739846901628</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="http://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2022-02-11T00:48:13Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://scottaaronson.blog/?p=6288</id>
    <link href="https://scottaaronson.blog/?p=6288" rel="alternate" type="text/html"/>
    <link href="https://scottaaronson.blog/?p=6288#comments" rel="replies" type="text/html"/>
    <link href="https://scottaaronson.blog/?feed=atom&amp;p=6288" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">AlphaCode as a dog speaking mediocre English</title>
    <summary xml:lang="en-US">Tonight, I took the time actually to read DeepMind’s AlphaCode paper, and to work through the example contest problems provided, and understand how I would’ve solved those problems, and how AlphaCode solved them. It is absolutely astounding. Consider, for example, the “n singers” challenge (pages 59-60). To solve this well, you first need to parse […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>Tonight, I took the time actually to read DeepMind’s <a href="https://storage.googleapis.com/deepmind-media/AlphaCode/competition_level_code_generation_with_alphacode.pdf">AlphaCode paper</a>, and to work through the example contest problems provided, and understand how I would’ve solved those problems, and how AlphaCode solved them.</p>



<p>It is absolutely astounding.</p>



<p>Consider, for example, the “n singers” challenge (pages 59-60). To solve this well, you first need to parse a somewhat convoluted English description, discarding the irrelevant fluff about singers, in order to figure out that you’re being asked to find a positive integer solution (if it exists) to a linear system whose matrix looks like<br/>1 2 3 4<br/>4 1 2 3<br/>3 4 1 2<br/>2 3 4 1.<br/>Next you need to find a trick for solving such a system without Gaussian elimination or the like (I’ll leave that as an exercise…). Finally, you need to generate code that implements that trick, correctly handling the wraparound at the edges of the matrix, and breaking and returning “NO” for any of multiple possible reasons why a positive integer solution won’t exist.   Oh, and also correctly parse the input.</p>



<p>Yes, I realize that AlphaCode generates a million candidate programs for each challenge, then discards the vast majority by checking that they don’t work on the example data provided, then <em>still</em> has to use clever tricks to choose from among the thousands of candidates remaining. I realize that it was trained on tens of thousands of contest problems and millions of solutions to those problems. I realize that it “only” solves about a third of the contest problems, making it similar to a mediocre human programmer on these problems. I realize that it works only in the artificial domain of programming contests, where a complete English problem specification and example inputs and outputs are always provided.</p>



<p>Forget all that. Judged against where AI was 20-25 years ago, when I was a student, a dog is now holding meaningful conversations in English. And people are complaining that the dog isn’t a very eloquent orator, that it often makes grammatical errors and has to start again, that it took heroic effort to train it, and that it’s unclear how much the dog really understands.</p>



<p>It’s not obvious how you go from solving programming contest problems to conquering the human race or whatever, but I feel pretty confident that we’ve now entered a world where “programming” will look different.</p>



<p><strong>Update:</strong> A colleague of mine points out that one million, the number of candidate programs that AlphaCode needs to generate, could be seen as roughly exponential in the number of lines of the generated programs.  If so, this suggests a perspective according to which DeepMind has created almost the exact equivalent, in AI code generation, of a non-fault-tolerant quantum computer that’s nevertheless competitive on some task (as in the quantum supremacy experiments). I.e., it clearly does something highly nontrivial, but the “signal” is still decreasing exponentially with the number of instructions, necessitating an exponential number of repetitions to extract the signal and imposing a limit on the size of the programs you can scale to.</p></div>
    </content>
    <updated>2022-02-06T09:12:13Z</updated>
    <published>2022-02-06T09:12:13Z</published>
    <category scheme="https://scottaaronson.blog" term="Nerd Interest"/>
    <category scheme="https://scottaaronson.blog" term="The Fate of Humanity"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://scottaaronson.blog/?feed=atom</id>
      <icon>https://scottaaronson.blog/wp-content/uploads/2021/10/cropped-Jacket-32x32.gif</icon>
      <link href="https://scottaaronson.blog" rel="alternate" type="text/html"/>
      <link href="https://scottaaronson.blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2022-02-07T01:34:21Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/013</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/013" rel="alternate" type="text/html"/>
    <title>TR22-013 |  On properties that are non-trivial to test | 

	Nader Bshouty, 

	Oded Goldreich</title>
    <summary>In this note we show that all sets that are neither finite nor too dense are non-trivial to test in the sense that, for every $\epsilon&gt;0$, distinguishing between strings in the set and strings that are $\epsilon$-far from the set requires $\Omega(1/\epsilon)$ queries. 
Specifically, we show that if, for infinitely many $n$'s, the set contains at least one $n$-bit long string and at most $2^{n-\Omega(n)}$ many $n$-bit strings, then it is non-trivial to test.</summary>
    <updated>2022-02-05T16:37:06Z</updated>
    <published>2022-02-05T16:37:06Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-02-11T14:37:42Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2022/02/05/assistant-professor-at-linkoping-university-at-department-of-computer-and-information-science-apply-by-march-1-2022/</id>
    <link href="https://cstheory-jobs.org/2022/02/05/assistant-professor-at-linkoping-university-at-department-of-computer-and-information-science-apply-by-march-1-2022/" rel="alternate" type="text/html"/>
    <title>Assistant professor at Linköping University at Department of Computer and Information Science (apply by March 1 , 2022)</title>
    <summary>Linköping University announces an assistant professor position in computer science that focuses on the borderland between theoretical computer science, mathematics, and artificial intelligence. Website: https://liu.se/en/work-at-liu/vacancies?rmpage=job&amp;rmjob=18113&amp;rmlang=UK Email: peter.jonsson@liu.se</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Linköping University announces an assistant professor position in computer science<br/>
that focuses on the borderland between theoretical computer science, mathematics, and artificial intelligence.</p>
<p>Website: <a href="https://liu.se/en/work-at-liu/vacancies?rmpage=job&amp;rmjob=18113&amp;rmlang=UK">https://liu.se/en/work-at-liu/vacancies?rmpage=job&amp;rmjob=18113&amp;rmlang=UK</a><br/>
Email: peter.jonsson@liu.se</p></div>
    </content>
    <updated>2022-02-05T15:39:01Z</updated>
    <published>2022-02-05T15:39:01Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2022-02-11T14:38:01Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://scottaaronson.blog/?p=6256</id>
    <link href="https://scottaaronson.blog/?p=6256" rel="alternate" type="text/html"/>
    <link href="https://scottaaronson.blog/?p=6256#comments" rel="replies" type="text/html"/>
    <link href="https://scottaaronson.blog/?feed=atom&amp;p=6256" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Scott Aaronson Speculation Grant WINNERS!</title>
    <summary xml:lang="en-US">Two weeks ago, I announced on this blog that, thanks to the remarkable generosity of Jaan Tallinn, and the Speculation Grants program of the Survival and Flourishing Fund that Jaan founded, I had $200,000 to give away to charitable organizations of my choice. So, inspired by what Scott Alexander had done, I invited the readers […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>Two weeks ago, I <a href="https://scottaaronson.blog/?p=6232">announced</a> on this blog that, thanks to the remarkable generosity of Jaan Tallinn, and the Speculation Grants program of the <a href="https://survivalandflourishing.fund/">Survival and Flourishing Fund</a> that Jaan founded, I had $200,000 to give away to charitable organizations of my choice.  So, inspired by what Scott Alexander had <a href="https://astralcodexten.substack.com/p/acx-grants-results">done</a>, I invited the readers of <em>Shtetl-Optimized</em> to pitch their charities, mentioning only some general areas of interest to me (e.g., advanced math education at the precollege level, climate change mitigation, pandemic preparedness, endangered species conservation, and any good causes that would enrage the people who attack me on Twitter).</p>



<p>I’m grateful to have gotten more than twenty well-thought-out pitches; you can read a subset of them in the <a href="https://scottaaronson.blog/?p=6232#comments">comment thread</a>.  Now, having studied them all, I’ve decided—as I hadn’t at the start—to use my entire allotment to make as strong a statement as I can about a single cause: namely, <strong>subject-matter passion and excellence in precollege STEM education</strong>.</p>



<p>I’ll be directing funds to some shockingly cash-starved math camps, math circles, coding outreach programs, magnet schools, and enrichment programs, in Maine and Oregon and England and Ghana and Ethiopia and Jamaica.  The programs I’ve chosen target a variety of ability levels, not merely the “mathematical elite.”  Several explicitly focus on minority and other underserved populations.  But they share a goal of raising every student they work with as high as possible, rather than pushing the students down to fit some standardized curriculum.</p>



<p>Language like that ought to be meaningless boilerplate, but alas, it no longer is.  We live in a time when the state of California, in a misguided pursuit of “modernization” and “equity,” is <a href="https://sites.google.com/view/k12mathmatters/home">poised</a> to eliminate 8th-grade algebra, make it nearly impossible for high-school seniors to take AP Calculus, and shunt as many students as possible from serious mathematical engagement into a “data science pathway” that in practice might teach little more than how to fill in spreadsheets.  (This watering-down effort now <em>itself</em> looks liable to be watered down—but only because of a furious pushback from parents and STEM professionals, pushback in which I’m proud that this blog <a href="https://scottaaronson.blog/?p=6146">played a small role</a>.)  We live in a time when elite universities are racing to eliminate the SAT—thus, for all their highminded rhetoric, effectively slamming the door on thousands of nerdy kids from poor or immigrant backgrounds who know how to think, but not how to shine in a college admissions popularity pageant.  We live in a time when America’s legendary STEM magnet high schools, from Thomas Jefferson in Virginia to Bronx Science to Lowell in San Francisco, rather than being celebrated as the national treasures that they are, or better yet replicated, are bitterly attacked as “elitist” (even while competitive sports and music programs are not similarly attacked)—and are now being forcibly “demagnetized” by bureaucrats, made all but indistinguishable from other high schools, over the desperate pleas of their students, parents, and alumni.</p>



<p>And—alright, fine, on a global scale, arresting climate change is surely a higher-priority issue than protecting the intellectual horizons of a few teenage STEM nerds.  The survival of liberal democracy is a higher-priority issue.  Pandemic preparedness, poverty, malnutrition are higher-priority issues.  Some of my friends strongly believe that <em>the danger of AI becoming super-powerful and taking over the world</em> is the highest-priority issue … and truthfully, with this week’s announcements of <a href="https://deepmind.com/blog/article/Competitive-programming-with-AlphaCode">AlphaCode</a> and <a href="https://openai.com/blog/formal-math/">OpenAI’s theorem prover</a>, which achieve human-competitive performance in elite programming and math competitions respectively, I can’t confidently declare that they’re wrong.</p>



<p>On the other hand, when you think about the astronomical returns on every penny that was invested in setting a teenage Ramanujan or Einstein or Turing or Sofya Kovalevskaya or Norman Borlaug or Mario Molina onto their trajectories in life … and the comically tiny budgets of the world-leading programs that aim to nurture the <em>next</em> Ramanujans, to the point where $10,000 often seems like a windfall to those programs … well, you might come to the conclusion that the “protecting nerds” thing actually isn’t <em>that</em> far down the global priority list!  Like, it probably cracks the top ten.</p>



<p>And there’s more to it than that.  There’s a reason beyond parochialism, it dawned on me, why individual charities tend to specialize in wildlife conservation in Ecuador or deworming in Swaziland or some other little domain, rather than simply casting around for the highest-priority cause on earth.  <em>Expertise matters</em>—since one wants to make, not only good judgments about which stuff to support, but good judgments that most others can’t or haven’t made.  In my case, it would seem sensible to leverage the fact that I’m Scott Aaronson.  I’ve spent much of my career in math/CS education and outreach—mostly, of course, at the university level, but <em>by god</em> did I personally experience the good and the bad in nearly every form of precollege STEM education!  I’m pretty confident in my ability to distinguish the two, and for whatever I don’t know, I have close friends in the area who I trust.</p>



<p>There’s also a practical issue: in order for me to fund something, the recipient has to fill out a somewhat time-consuming application to SFF.  If I’d added, say, another $20,000 drop into the bucket of global health or sustainability or whatever, there’s no guarantee that the intended recipients of my largesse would even notice, or care enough to go through the application process if they did.  With STEM education, by contrast, holy crap!  I’ve got an inbox full of <em>Shtetl-Optimized</em> readers explaining how their little math program is an intellectual oasis that’s changed the lives of hundreds of middle-schoolers in their region, and how $20,000 would mean the difference between their program continuing or not.  <em>That’s</em> someone who I trust to fill out the form.</p>



<p>Without further ado, then, here are the first-ever Scott Aaronson Speculation Grants:</p>



<ul><li>$57,000 for <a href="https://www.mathcamp.org/">Canada/USA Mathcamp</a>, which changed my life when I attended it as a 15-year-old in 1996, and which I returned to as a lecturer in 2008.  The funds will be used for COVID testing to allow Mathcamp to resume in-person this summer, and perhaps scholarships and off-season events as well.</li><li>$30,000 for <a href="https://www.addiscoder.com/">AddisCoder</a>, which has had spectacular success teaching computer science to high-school students in Ethiopia, placing some of its alumni at elite universities in the US, to help them expand to a new “JamCoders” program in Jamaica.  These programs were founded by UC Berkeley’s amazing <a href="https://en.wikipedia.org/wiki/Jelani_Nelson">Jelani Nelson</a>, also with involvement from friend and <em>Shtetl-Optimized</em> semi-regular <a href="https://en.wikipedia.org/wiki/Boaz_Barak">Boaz Barak</a>.</li><li>$30,000 for the <a href="https://www.mssm.org/">Maine School of Science and Mathematics</a>, which seems to offer a curriculum comparable to those of Thomas Jefferson, Bronx Science, or the nation’s other elite magnet high schools, but (1) on a shoestring budget and (2) in rural Maine.  I hadn’t even heard of MSSM before Alex Altair, an alum and <em>Shtetl-Optimized</em> reader, told me about it, but now I couldn’t be prouder to support it.</li><li>$30,000 for the <a href="https://pages.uoregon.edu/nemirovm/emc.html">Eugene Math Circle</a>, which provides a math enrichment lifeline to kids in Oregon, and whose funding was just cut.  This donation will keep the program alive for another year.</li><li>$13,000 for the <a href="https://summerscience.org/">Summer Science Program</a>, which this summer will offer research experiences to high-school juniors in astrophysics, biochemistry, and genomics.</li><li>$10,000 for the <a href="https://misemaths.wordpress.com/">MISE Foundation</a>, which provides math enrichment for the top middle- and high-school students in Ghana.</li><li>$10,000 for <a href="https://www.numberchampions.org.uk/">Number Champions</a>, which provides one-on-one coaching to kids in the UK who struggle with math.</li><li>$10,000 for <a href="https://www.beammath.org/">Bridge to Enter Advanced Mathematics (BEAM)</a>, which runs math summer programs in New York, Los Angeles, and elsewhere for underserved populations.</li><li>$10,000 for <a href="https://powderhouse.org/">Powderhouse</a>, an innovative lab school being founded in Somerville, MA.</li></ul>



<p>While working on this, it crossed my mind that, on my deathbed, I might be at least as happy about having directed funds to efforts like these as about any of my research or teaching.</p>



<p>To the applicants who weren’t chosen: I’m sorry, as many of you had wonderful projects too!  As I said in the earlier post, you remain warmly invited to apply to SFF, and to make your pitch to the other Speculators and/or the main SFF committee.</p>



<p>Needless to say, anyone who feels inspired should add to my (or rather, SFF’s) modest contributions to these STEM programs.  My sense is that, while $200k can go eye-poppingly far in this area, it still hasn’t come <em>close</em> to exhausting even the lowest-hanging fruit.</p>



<p>Also needless to say, the opinions in this post are my own and are not necessarily shared by SFF or by the organizations I’m supporting.  The latter are welcome to disagree with me as long as they keep up their great work!</p>



<p>Huge thanks again to Jaan, to SFF, to my SFF contact Andrew Critch, to everyone (whether chosen or not) who participated in this contest, and to everyone who’s putting in work to broaden kids’ intellectual horizons or otherwise make the world a little less horrible.</p></div>
    </content>
    <updated>2022-02-04T17:26:02Z</updated>
    <published>2022-02-04T17:26:02Z</published>
    <category scheme="https://scottaaronson.blog" term="Announcements"/>
    <category scheme="https://scottaaronson.blog" term="Nerd Interest"/>
    <category scheme="https://scottaaronson.blog" term="The Fate of Humanity"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://scottaaronson.blog/?feed=atom</id>
      <icon>https://scottaaronson.blog/wp-content/uploads/2021/10/cropped-Jacket-32x32.gif</icon>
      <link href="https://scottaaronson.blog" rel="alternate" type="text/html"/>
      <link href="https://scottaaronson.blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2022-02-07T01:34:21Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2022/02/04/postdoc-at-lip-ens-lyon-apply-by-march-1-2022/</id>
    <link href="https://cstheory-jobs.org/2022/02/04/postdoc-at-lip-ens-lyon-apply-by-march-1-2022/" rel="alternate" type="text/html"/>
    <title>postdoc at LIP, ENS Lyon (apply by March 1, 2022)</title>
    <summary>A postdoctoral position in Computer Science is available at LIP, ENS Lyon. Details on the website. Website: http://perso.ens-lyon.fr/edouard.bonnet/postdocOffer.html Email: edouard.bonnet@ens-lyon.fr</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>A postdoctoral position in Computer Science is available at LIP, ENS Lyon. Details on the website.</p>
<p>Website: <a href="http://perso.ens-lyon.fr/edouard.bonnet/postdocOffer.html">http://perso.ens-lyon.fr/edouard.bonnet/postdocOffer.html</a><br/>
Email: edouard.bonnet@ens-lyon.fr</p></div>
    </content>
    <updated>2022-02-04T16:59:38Z</updated>
    <published>2022-02-04T16:59:38Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2022-02-11T14:38:01Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2022/02/04/phd-privacy-by-design-computing-for-iot-data-at-graduate-school-of-technical-sciences-aarhus-university-denmark-apply-by-march-15-2022/</id>
    <link href="https://cstheory-jobs.org/2022/02/04/phd-privacy-by-design-computing-for-iot-data-at-graduate-school-of-technical-sciences-aarhus-university-denmark-apply-by-march-15-2022/" rel="alternate" type="text/html"/>
    <title>Phd – Privacy-by-design Computing for IoT data at Graduate School of Technical Sciences, Aarhus University, Denmark (apply by March 15, 2022)</title>
    <summary>Applications are invited for a PhD fellowship/scholarship at Graduate School of Technical Sciences, Aarhus University, Denmark, within the Electrical and Computer Engineering programme. The position is available from 1 May 2022 or later. Website: https://phd.tech.au.dk/for-applicants/apply-here/saeropslag/privacy-by-design-computing-for-iot-data/ Email: daniel.lucani@ece.au.dk</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Applications are invited for a PhD fellowship/scholarship at Graduate School of Technical Sciences, Aarhus University, Denmark, within the Electrical and Computer Engineering programme. The position is available from 1 May 2022 or later.</p>
<p>Website: <a href="https://phd.tech.au.dk/for-applicants/apply-here/saeropslag/privacy-by-design-computing-for-iot-data/">https://phd.tech.au.dk/for-applicants/apply-here/saeropslag/privacy-by-design-computing-for-iot-data/</a><br/>
Email: daniel.lucani@ece.au.dk</p></div>
    </content>
    <updated>2022-02-04T09:17:46Z</updated>
    <published>2022-02-04T09:17:46Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2022-02-11T14:38:01Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://rjlipton.wpcomstaging.com/?p=19620</id>
    <link href="https://rjlipton.wpcomstaging.com/2022/02/03/next-big-thing/" rel="alternate" type="text/html"/>
    <title>Next Big Thing?</title>
    <summary>Big ideas we tend to like are the ones that seem impossible or crazy—Bill Maris UW History page Margaret O’Mara is a historian at the University of Washington. She specializes in the history of Silicon Valley. Of course we are most interested in the future of Silicon Valley. Today—between history and the future—we channel her […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Big ideas we tend to like are the ones that seem impossible or crazy—Bill Maris</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2022/02/03/next-big-thing/mo/" rel="attachment wp-att-19622"><img alt="" class="alignright wp-image-19622" height="175" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/02/mo.png?resize=140%2C175&amp;ssl=1" width="140"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">UW History <a href="https://history.washington.edu/people/margaret-omara">page</a></font></td>
</tr>
</tbody>
</table>
<p>
Margaret O’Mara is a <a href="https://www.margaretomara.com/">historian</a> at the University of Washington. She specializes in the history of Silicon Valley. Of course we are most interested in the future of Silicon Valley. </p>
<p>
Today—between history and the future—we channel her insights to ask what next-big-things may intersect our fields.<br/>
<span id="more-19620"/></p>
<p>
An <a href="https://www.nytimes.com/2022/01/24/technology/silicon-valley-next-big-thing.html">article</a> last week in the New York Times quotes her on recent developments:</p>
<ol>
<li>
“The age of mobile and cloud computing has created so many new business opportunities,” O’Mara said. “But now there are trickier problems.” <p/>
</li><li>
“Imagine the economic impact of the pandemic had there not been the infrastructure— the hardware and the software— that allowed so many white-collar workers to work from home and so many other parts of the economy to be conducted in a digitally mediated way”, she added.
</li></ol>
<p>
But what’s next?</p>
<p>
</p><p/><h2> The Next Big Idea? </h2><p/>
<p/><p>
The NYT article talks about the future of Silicon Valley as seen by O’Mara and other experts. The main issue is: what are the next big ideas that will come out of Silicon Valley? Big ideas are defined by ones that will change the future and generate billions if not trillions in dollars. Some possible ones are:</p>
<ol>
<li>
Self-driving cars; <p/>
</li><li>
Advanced artificial intelligence; <p/>
</li><li>
Brain implants—to control devices with only thoughts; <p/>
</li><li>
Quantum computing; <p/>
</li><li>
<img alt="{\dots ?}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots+%3F%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>
</li></ol>
<p>
The article quotes Jake Taylor, the chief science officer at the quantum start-up <a href="https://www.riverlane.com">Riverlane</a>, as saying that “building a quantum computer might may be the most difficult task ever undertaken, [one that] defies the physics of everyday life.” </p>
<p/><h2> Next Big Theory Ideas? </h2><p/>
<p/><p>
I am quite interested in hearing what role complexity theory might play in creating the next big thing. If the area is quantum based then perhaps theory could play a major role. It helped start the explosion in interest in quantum computing. The famous results of Peter Shor on <a href="https://en.wikipedia.org/wiki/Shor%27s_algorithm">factoring</a> could no doubt play a major role. But the paradox is that theory does not seem to be central to thoughts on what the next big idea will be? Even if the idea is quantum based. </p>
<p>
What goal, result, breakthrough will make theory play a major role in the next <b>big idea</b>? </p>
<p>
One answer is to search the Internet. We find that Kurt Mehlhorn has had a course on the main ideas of theory. Perhaps we could imagine a direction for the next big idea based on one of these <a href="http://resources.mpi-inf.mpg.de/departments/d1/teaching/ss14/gitcs/syllabus.pdf">ideas</a> from his course:</p>
<ol>
<li>
Time vs. Space, P vs. NP, and More. <p/>
</li><li>
Interactive System, Zero Knowledge Proofs, the PCP Theorem. <p/>
</li><li>
Expander Graphs. <p/>
</li><li>
Learning Theory. <p/>
</li><li>
Streaming Algorithms. <p/>
</li><li>
Public-Key Cryptography. <p/>
</li><li>
Linear Programming. <p/>
</li><li>
Randomness in Computation. <p/>
</li><li>
Introduction to Approximation Algorithms. <p/>
</li><li>
Algorithms for Big Data. <p/>
</li><li>
Algebraic Techniques in Algorithm Design
</li></ol>
<p>
Here are the opening <a href="https://www.anilada.com/courses/15251f18/www/slides/lec1.pdf">slides</a> from a related course at CMU by Anil Ada and Bernhard Haeupler.</p>
<p>
</p><p/><h2> The Next is <img alt="{\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>? </h2><p/>
<p/><p>
Another idea is to search for other groups that have more directly looked at possible next ideas. For example: in 2014, a team of technical leaders from the IEEE Computer Society joined forces to write a technical report, entitled <a href="https://www.computer.org/publications/tech-news/trends/2022-report">IEEE CS 2022</a>, surveying 23 technologies that could potentially change the landscape of computer science and industry by the year 2022. By the way, 23 is special: <i>The famous Hilbert Problems are 23 in number.</i> See <a href="https://en.wikipedia.org/wiki/Hilbert%27s_problems">here</a>.</p>
<p>
Here are some of the top few that we might consider. Note we left out some that seem less special for computer science.  That leaves 14 problems.  OK, 14 is the number of Steve Smale’s problems that are fully or partly unresolved according to <a href="https://en.wikipedia.org/wiki/Smale%27s_problems">this</a>.</p>
<ol>
<li>
Security Cross-Cutting Issues The growth of large data repositories and emergence of data analytics have combined with intrusions by bad actors, governments, and corporations to open a Pandora’s box of issues. How can we balance security and privacy in this environment? <p/>
</li><li>
Sustainability Can electronic cars, LED lighting, new types of batteries and chips, and increasing use of renewables combat rising energy use and an explosion in the uptake of computing? <p/>
</li><li>
Device and Nanotechnology It is clear that MEMS devices, nanoparticles, and their use in applications are here to stay. Nanotechnology has already been useful in manufacturing sunscreen, tires, and medical devices that can be swallowed. <p/>
</li><li>
3D Integrated Circuits The transition from printed circuit boards to 3D-ICs is already underway in the mobile arena, and will eventually spread across the entire spectrum of IT products. <p/>
</li><li>
Photonics Silicon photonics will be a fundamental technology to address the bandwidth, latency, and energy challenges in the fabric of high-end systems. <p/>
</li><li>
Networking and Interconnectivity Developments at all levels of the network stack will continue to drive research and the Internet economy. <p/>
</li><li>
Software-Defined Networks OpenFlow and SDN will make networks more secure, transparent, flexible, and functional. <p/>
</li><li>
High-Performance Computing While some governments are focused on reaching exascale, some researchers are intent on moving HPC to the cloud. <p/>
</li><li>
The Internet of Things From clothes that monitor our movements to smart homes and cities, the Internet of Things knows no bounds, except for our concerns about ensuring privacy amid such convenience. <p/>
</li><li>
Natural User Interfaces The long-held dreams of computers that can interface with us through touch, gesture, and speech are finally coming true, with more radical interfaces on the horizon. <p/>
</li><li>
3D Printing 3D printing promises a revolution in fabrication, with many opportunities to produce designs that would have been prohibitively expensive. <p/>
</li><li>
Big Data and Analytics The growing availability of data and demand for its insights holds great potential to improve many data-driven decisions. <p/>
</li><li>
Machine Learning and Intelligent Systems Machine learning plays an increasingly important role in our lives, whether it’s ranking search results, recommending products, or building better models of the environment. <p/>
</li><li>
Computer Vision and Pattern Recognition Unlocking information in pictures and videos has had a major impact on consumers and more significant advances are in the pipeline.
</li></ol>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Any thoughts? Can theory play a main role in the future? </p>
<p/></font></font></div>
    </content>
    <updated>2022-02-04T04:47:33Z</updated>
    <published>2022-02-04T04:47:33Z</published>
    <category term="All Posts"/>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="ideas"/>
    <category term="Margaret O'Mara"/>
    <category term="Next Big Thing"/>
    <category term="predictions"/>
    <category term="Theory"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wpcomstaging.com</id>
      <logo>https://s0.wp.com/i/webclip.png</logo>
      <link href="https://rjlipton.wpcomstaging.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wpcomstaging.com" rel="alternate" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel's Lost Letter and P=NP</title>
      <updated>2022-02-11T14:37:57Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-1841700560229331052</id>
    <link href="http://blog.computationalcomplexity.org/feeds/1841700560229331052/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/02/the-beginnings-of-zero-knowledge.html#comment-form" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/1841700560229331052" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/1841700560229331052" rel="self" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/02/the-beginnings-of-zero-knowledge.html" rel="alternate" type="text/html"/>
    <title>The Beginnings of Zero-Knowledge</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Wired runs this <a href="https://www.youtube.com/playlist?list=PLibNZv5Zd0dyCoQ6f4pdXUFnpAIlKgm3N">video series</a> where topic expert explain concepts to five levels of difficulty, typically a child, teen, undergrad, grad student and expert. UCLA professor Amit Sahai <a href="https://www.youtube.com/watch?v=fOGdb1CTu5c">took this on</a> for zero-knowledge. </p><p>I'd recommend the whole thing but I'd like to focus on the last segment with USC Professor Shanghua Teng (<a href="https://youtu.be/fOGdb1CTu5c?t=1025">starts at 17:05</a>). Amit nicely summed up the importance of the paper.</p><blockquote><p>What was such a beautiful insight is that the idea of zero-knowledge being something that you can already predict. If you can already predict the answer, then you must not be gaining any knowledge by that interaction. This insight of being able to predict the future accurately, and that being an evidence of a lack of new knowledge.</p></blockquote><p>Like Shanghua I was also assigned the seminal zero-knowledge paper by Goldwasser-Micali-Rackoff from my advisor. In many ways the <a href="https://dl.acm.org/doi/10.1145/22145.22178">original STOC paper</a> was rough. The definitions were buggy, the examples uninspiring. Supposedly the paper didn't even get accepted into a conference in its first try. And yet as you read the paper you realize the potential, the beauty of not one but two new models that would go on to change both cryptography and complexity forever.</p><p>In the fall of 1985 when I started graduate school I took a cryptography class from Manuel Blum. Much of that class was spent on protocols that would convince you that, for example, a number was the product of three primes. By the spring of 1986, Goldreich, Micali and Wigderson distributed <a href="https://dl.acm.org/doi/abs/10.1145/116825.116852">their paper</a> showing, among other things, all NP problems has zero-knowledge proofs, making many of the protocols discussed in Blum's course a few months earlier trivial corollaries.</p><p>But it wasn't just zero-knowledge. Goldwasser, Micali and Rackoff (and independently <a href="https://doi.org/10.1016/0022-0000(88)90028-1">Babai and Moran</a>) developed the notion of interactive proof, a proof system with statistical confidence, a model that would lead to probabilistically checkable proofs and helping us understand the limits of approximation.</p><p>I owe most of my early research to the models developed in the GMR paper and glad that Amit has found a way to share these ideas so well.</p></div>
    </content>
    <updated>2022-02-02T21:46:00Z</updated>
    <published>2022-02-02T21:46:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="http://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2022-02-11T00:48:13Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://lucatrevisan.wordpress.com/?p=4607</id>
    <link href="https://lucatrevisan.wordpress.com/2022/02/02/%e6%81%ad%e5%96%9c%e5%8f%91%e8%b4%a2-13/" rel="alternate" type="text/html"/>
    <title>恭喜发财!</title>
    <summary>新年快乐！</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><figure class="wp-block-image size-full"><a href="https://lucatrevisan.files.wordpress.com/2010/02/calvin-and-hobbes.jpg"><img alt="" class="wp-image-1680" src="https://lucatrevisan.files.wordpress.com/2010/02/calvin-and-hobbes.jpg"/></a></figure>



<p>新年快乐！</p></div>
    </content>
    <updated>2022-02-02T20:15:12Z</updated>
    <published>2022-02-02T20:15:12Z</published>
    <category term="&#x65B0;&#x5E74;"/>
    <author>
      <name>luca</name>
    </author>
    <source>
      <id>https://lucatrevisan.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://lucatrevisan.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://lucatrevisan.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://lucatrevisan.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://lucatrevisan.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>"Marge, I agree with you - in theory. In theory, communism works. In theory." -- Homer Simpson</subtitle>
      <title>in   theory</title>
      <updated>2022-02-11T14:37:13Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2022/02/02/tenure-track-faculty-at-university-of-haifa-at-oranim-campus-apply-by-february-28-2022/</id>
    <link href="https://cstheory-jobs.org/2022/02/02/tenure-track-faculty-at-university-of-haifa-at-oranim-campus-apply-by-february-28-2022/" rel="alternate" type="text/html"/>
    <title>Tenure-Track Faculty at University of Haifa at Oranim Campus (apply by February 28, 2022)</title>
    <summary>The Department of Mathematics-Physics-Computer Science of the University of Haifa at Oranim College invites applications for a tenure-track faculty position in all areas of Computer Science, to begin October 1st 2022. More details on our website. Applications will be considered until the position is filled. Website: https://mathphys.haifa.ac.il/en/announcements/ Email: ackerman@math.haifa.ac.il</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Department of Mathematics-Physics-Computer Science of the University of Haifa at Oranim College invites applications for a tenure-track faculty position in all areas of Computer Science, to begin October 1st 2022. More details on our website.<br/>
Applications will be considered until the position is filled.</p>
<p>Website: <a href="https://mathphys.haifa.ac.il/en/announcements/">https://mathphys.haifa.ac.il/en/announcements/</a><br/>
Email: ackerman@math.haifa.ac.il</p></div>
    </content>
    <updated>2022-02-02T14:47:55Z</updated>
    <published>2022-02-02T14:47:55Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2022-02-11T14:38:01Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2022/02/02/postdoc-at-university-of-bergen-apply-by-february-11-2022/</id>
    <link href="https://cstheory-jobs.org/2022/02/02/postdoc-at-university-of-bergen-apply-by-february-11-2022/" rel="alternate" type="text/html"/>
    <title>Postdoc at University of Bergen (apply by February 11, 2022)</title>
    <summary>Two postdoctoral positions in Algorithmic foundations of data science (in a very broad sense), funded by ERC Consolidator grant of Saket Saurabh. Competitive salary, solid travel funds, and friendly research environment. Website: https://www.jobbnorge.no/en/available-jobs/job/218932/researcher-in-informatics-algorithmic-foundations-of-data-science Email: fedor.fomin@uib.no</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Two postdoctoral positions in Algorithmic foundations of data science (in a very broad sense), funded by ERC Consolidator grant of Saket Saurabh. Competitive salary, solid travel funds, and friendly research environment.</p>
<p>Website: <a href="https://www.jobbnorge.no/en/available-jobs/job/218932/researcher-in-informatics-algorithmic-foundations-of-data-science">https://www.jobbnorge.no/en/available-jobs/job/218932/researcher-in-informatics-algorithmic-foundations-of-data-science</a><br/>
Email: fedor.fomin@uib.no</p></div>
    </content>
    <updated>2022-02-02T12:06:04Z</updated>
    <published>2022-02-02T12:06:04Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2022-02-11T14:38:01Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://gradientscience.org/datamodels-1/</id>
    <link href="https://gradientscience.org/datamodels-1/" rel="alternate" type="text/html"/>
    <title>Predicting Predictions with Datamodels</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a class="bbutton" href="https://arxiv.org/abs/2202.00622" style="float: left; width: 45%;">
<i class="fas fa-file-pdf"/>
    Paper
</a>
<a class="bbutton" href="https://github.com/MadryLab/datamodels-data" style="float: left; width: 45%;">
<i class="fab fa-github"/>
   Data
</a>
<br/>
<em>What drives machine learning (ML) models’ predictions?</em></p>

<p>This question is rarely an easy one to answer. On one hand, we know that predictions are a product of <em>training data</em> and <em>learning algorithms</em>. On the other hand, it is often hard to characterize exactly how these two elements interact.</p>

<p>In our <a href="https://arxiv.org/abs/2202.00622">latest work</a>, we introduce <em>datamodels</em>—a step towards acquiring a more fine-grained understanding of how learning algorithms use training data to make predictions. This post introduces the datamodeling framework, describes its simplest, <em>linear</em> instantiation, and illustrates its success in modeling data-to-prediction mapping for deep neural networks. Our future posts will tour through some of the applications of the datamodeling framework that we are most excited about.</p>

<h2 id="what-is-a-datamodel">What is a datamodel?</h2>

<p>In the standard machine learning setup, we have both a learning algorithm (say, stochastic gradient descent applied to a deep neural network) and a training set to learn from (say, the CIFAR-10 training set).</p>

<p>Now, suppose that we want to evaluate model behavior on a specific input \(x\). For example, \(x\) might be one of the following input-label pairs from the <a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-10</a> test set:</p>



<div class="row">
     <div class="img_holder">
         <img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/horse7.png"/>
         <span>"horse"</span>
     </div>
     <div class="img_holder">
         <img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/dog7.png"/>
         <span>"dog"</span>
     </div>
     <div class="img_holder">
         <img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/ship5.png"/>
         <span>"boat"</span>
     </div>
     <div class="img_holder">
         <img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/truck5.png"/>
         <span>"firetruck"</span>
     </div>
 </div>

<p>A natural question that might arise in this context is: <em>for such an example \(x\), how does the learning algorithm use the training data to arrive at its prediction?</em> Answering this question is difficult—think of the underlying complexity stemming from training  a deep neural network using thousands of stochastic gradient descent (SGD) steps.</p>

<p>Our <em>datamodeling</em> framework is motivated exactly by this challenge. Specifically, the goal of datamodeling is to bypass that complexity of model training entirely, and instead find a <em>simple</em> function that <em>directly</em> maps training data to predictions. So, roughly speaking, a <em>datamodel</em> for a specific example of interest \(x\) is a function \(g(S’)\) that takes as input any subset \(S’\) of the original training \(S\), and as output predicts the outcome of training a model on \(S’\) and then evaluating on \(x\).</p>
<div class="footnote">
Note that “evaluating” is left intentionally vague here as we expect the specific form to be task dependent: one might be interested in, for instance, the predicted label (e.g., in classification tasks), squared error (e.g., in regression tasks), or log-likelihood (e.g., in language modeling tasks).
</div>

<p>For the visual learners out there, datamodels have the following interface:</p>

<p><img src="https://gradientscience.org/images/datamodels/flow.png" style="width: 75%;"/></p>

<p>The hope is to find datamodels that are <em>simple</em> enough to analyze directly, yet <em>accurate</em> enough to faithfully capture model behavior. We then can use such datamodels to gain insight into how the algorithm and data combine <em>through</em> the lens of the training dynamics (but without having to analyze that dynamics directly).</p>

<p>At first glance, this of task of <em>predicting</em> the output of a learning algorithm trained on different subsets of the original training set does not appear any easier than <em>analyzing</em> the learning algorithm on that original training set—in fact, it might seem even harder. At the very least, one would expect that any function approximating such a learning algorithm would need to be rather complicated. It turns out, however, that a (very) simple instantiation of datamodels—as linear functions—is already expressive enough to accurately capture the intended mapping, even for real-world deep neural networks!</p>

<h2 id="linear-datamodels-for-deep-classifiers">Linear datamodels for deep classifiers</h2>

<p>How exactly do we formulate <em>linear datamodels</em>? We represent each subset \(S’\) of the training set as an <em>indicator vector</em> \(\mathbf{1}_{S’}\), and then have our datamodel \(g_\theta\) map such indicator vectors to scalars. Specifically, we parameterize linear datamodels as:</p>

\[g_\theta(S’) = \mathbf{1}_{S’}^\top \theta + \theta_0,\]

<p>where \(\theta\) are our model’s parameters.</p>

<div class="footnote">
An <a href="https://en.wikipedia.org/wiki/Indicator_vector">indicator vector</a>
is a binary vector of dimension equal to the size of the training set, whose
\(i\)-th index is equal to \(1\) if and only if the \(i\)-th training example is present in \(S’\). 
</div>

<h2 id="estimating-linear-datamodels">Estimating linear datamodels</h2>

<p>Now, how do we actually select parameters \(\theta\) for such a linear datamodel? Recall that our goal is to find a \(\theta\) such that our linear datamodel satisfies:</p>

<center>
$$
g_\theta(S’) \approx \mbox{the output on \(x\) of a model trained on \(S’\).}
$$
</center>

<p>Our idea is to frame this task as a <em>supervised learning problem</em> in which we infer \(g_\theta\) from “input-label pairs.” Here, each of these pairs consists of a specific training subset \(S’\) (“input”) and the corresponding model output on \(x\) (“label”). Indeed, obtaining such pairs is rather easy—for a given choice of \(S’\), we retrieve corresponding outputs by just executing the learning algorithm on \(S’\) and evaluating on \(x\).</p>

<p>From this perspective, estimating \(g_\theta\) for a given \(x\) becomes a two-step process:</p>

<ul>
  <li><strong>Collecting our datamodel train set</strong>:  Sample a training subset \(S_i\), train
 a model on \(S_i\), and, finally, add the corresponding “input-label pair”
 \((S_i, \text{trained model output on }x)\) to our datamodel training set. 
 Rinse and repeat (until that training set becomes sufficiently large).</li>
  <li><strong>Datamodel training</strong>: Solve for \(\theta\) by regressing from our “training subsets” \(S_i\) to their corresponding model outputs on \(x\).</li>
</ul>

<p>Now: how many such input-label pairs do we need to be able to solve the corresponding (very high-dimensional) regression problem? (Note that the dimension here is 50k, the size of the training set!) The answer is: a lot. Specifically, to fit CIFAR-10 datamodels we trained a few <em>hundred thousand</em> CIFAR-10 models. (Moreover, looking across all our paper’s experiments, we train more than 4 million such models in total.) To make this task feasible, we designed (and released!) a <a href="https://ffcv.io/">fast fast model training library</a>—you might find this library helpful for your training tasks, however big or small. With our library, we were able to bring CIFAR training down to <em>seconds</em> on a single (A100) GPU, meaning that training hundreds of thousands of models takes (only) a few days (on a single machine).</p>

<div class="footnote">
Use our <i>data release</i>! Both pre-computed datamodels and the predictions of 4 million trained CIFAR models are available for download at <a href="https://github.com/MadryLab/datamodels-data">https://github.com/MadryLab/datamodels-data</a>.
</div>

<h2 id="evaluating-datamodels">Evaluating datamodels</h2>

<p>Now, after all this setup, the key question is: how accurately do such linear datamodels predict model behavior? Following our supervised learning perspective, the gold standard is to evaluate via a held-out test set: a set of (held-out) input-label (or rather, in our case, subset-model output) pairs.</p>

<p>Specifically, we make a <em>datamodel “test set”</em> using the same sampling process employed to generate the datamodel train set. We then compare <em>datamodel-predicted</em> outputs for these (previously unseen) collected subsets to the <em>true outputs</em> (i.e., the output of training a model on the subset and evaluating on the relevant example). It turns out that datamodels predictions predict the result of model training rather well!</p>

<p>
    <img src="https://gradientscience.org/images/datamodels/blog_xy.svg" style="width: 50%;"/>
</p>

<div class="footnote">
    The plotted points range across both choice of training set and target example \(x\). The magnified clusters of the same color each correspond to the same \(x\) for different sampled training sets \(S’\). The output here that we measure is correct-label margin, i.e., the difference between the logit for the correct class and the largest incorrect logit.
</div>

<p>The predicted and actual margins here—even conditioned on a specific \(x\)—correspond nearly one-to-one, despite that our predicted margins come from a linear model, and the actual margins stem from thousands of SGD steps on a ResNet-9!</p>

<h2 id="how-can-we-use-datamodels">How can we use datamodels?</h2>

<p>We’ve already seen that a simple linear model can predict the output of end-to-end model training (for a single target example) relatively well. We found this phenomenon surprising on its own, and hope that studying it further might yield theoretical or empirical insights into the generalization of deep networks (and when applied to new settings, other classes of machine learning models).</p>

<p>That said, in a series of follow up posts we’ll also highlight some of the other direct datamodel applications:</p>

<ul>
  <li>In Part 2, we’ll take a deeper dive into datamodels’ ability to predict outcomes of model training, and find that this ability extends beyond just the subsets sampled from the distribution they were fitted to. We’ll then use this capability to identify <em>brittle predictions</em>, test examples for which model predictions can be flipped by removing just a small number of examples from the training set.</li>
  <li>In Part 3, we’ll discuss how to use datamodels to identify training examples that are similar to any given test example, and will then employ this capability to find (non-trivial) train-test leakage in both CIFAR-10 and FMoW datasets. (FMoW is the other dataset that we investigate in our paper.)</li>
  <li>In Part 4, we’ll explore leveraging linear datamodels as <em>feature representation</em>. Specifically, we find that datamodels yield a natural way to embed every example into a well-behaved representation space. We use the corresponding embeddings to perform clustering and identify <em>model-driven</em> data subpopulations.</li>
</ul>

<p>All of these applications are fully detailed in <a href="https://arxiv.org/abs/2202.00622">our paper</a>, along with more experiments, a more formal introduction to datamodels, and an extensive discussion of the related and future work in this area. Also, check out our <a href="https://github.com/MadryLab/datamodels-data">data release</a> with both pre-computed datamodels and predictions corresponding to million CIFAR-10 models. Stay tuned for more!</p></div>
    </summary>
    <updated>2022-02-02T00:00:00Z</updated>
    <published>2022-02-02T00:00:00Z</published>
    <source>
      <id>https://gradientscience.org/</id>
      <author>
        <name>Gradient Science</name>
      </author>
      <link href="https://gradientscience.org/" rel="alternate" type="text/html"/>
      <link href="https://gradientscience.org/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Research highlights and perspectives on machine learning and optimization from MadryLab.</subtitle>
      <title>gradient science</title>
      <updated>2022-02-10T22:51:25Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/012</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/012" rel="alternate" type="text/html"/>
    <title>TR22-012 |  On List Decoding Transitive Codes From Random Errors | 

	Anup Rao, 

	Oscar Sprumont</title>
    <summary>We study the error resilience of transitive linear codes over $F_2$. We give tight bounds on the weight distribution of every such code $C$, and we show how these bounds can be used to infer bounds on the error rates that $C$ can tolerate on the binary symmetric channel. Using this connection, we show that every transitive code can be list-decoded from random errors. As an application, our results imply list-decoding bounds for Reed-Muller codes even when the rate exceeds the channel capacity.</summary>
    <updated>2022-02-01T22:26:33Z</updated>
    <published>2022-02-01T22:26:33Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-02-11T14:37:42Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2022/02/01/postdoc-at-boston-college-apply-by-february-21-2022/</id>
    <link href="https://cstheory-jobs.org/2022/02/01/postdoc-at-boston-college-apply-by-february-21-2022/" rel="alternate" type="text/html"/>
    <title>Postdoc at Boston College (apply by February 21, 2022)</title>
    <summary>The Computer Science department at Boston College invites applications for a postdoctoral position in the area of graph algorithms (broadly defined, e.g. distributed graph algorithms, local algorithms, dynamic graph algorithms, streaming algorithms, MPC algorithms, and etc) under the supervision of Hsin-Hao Su. Website: https://sites.google.com/site/distributedhsinhao/postdoc-position-on-distributed-graph-algorithms Email: suhx@bc.edu</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Computer Science department at Boston College invites applications for a postdoctoral position in the area of graph algorithms (broadly defined, e.g. distributed graph algorithms, local algorithms, dynamic graph algorithms, streaming algorithms, MPC algorithms, and etc) under the supervision of Hsin-Hao Su.</p>
<p>Website: <a href="https://sites.google.com/site/distributedhsinhao/postdoc-position-on-distributed-graph-algorithms">https://sites.google.com/site/distributedhsinhao/postdoc-position-on-distributed-graph-algorithms</a><br/>
Email: suhx@bc.edu</p></div>
    </content>
    <updated>2022-02-01T19:10:53Z</updated>
    <published>2022-02-01T19:10:53Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2022-02-11T14:38:01Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://nisheethvishnoi.wordpress.com/?p=131</id>
    <link href="https://nisheethvishnoi.wordpress.com/2022/01/31/focs-2021-is-virtually-here/" rel="alternate" type="text/html"/>
    <title>FOCS 2021 is (Virtually) Here!</title>
    <summary>The 62nd Annual IEEE Foundations of Computer Science (FOCS) will be held (virtually) February 7-10, 2022 — this coming Monday! Thanks to the effort of the progam committee, the FOCS 2021 program consists of 118 amazing papers in three parallel sessions. All talks will be live and of the usual length of 20 minutes. The […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The <a href="https://focs2021.cs.colorado.edu/">62nd Annual IEEE Foundations of Computer Science (FOCS)</a> will be held (virtually) February 7-10,  2022 — this coming Monday!</p>



<p>Thanks to the effort of the <a href="https://focs2021.cs.colorado.edu/cfp/">progam committee</a>, the <a href="https://focs2021.cs.colorado.edu/program/">FOCS 2021 program</a> consists of 118 amazing papers in three parallel sessions. All talks will be <strong>live </strong>and of the usual length of 20 minutes. The program has also set aside ample time for breaks to enable the participants to socialize and connect on gather and slack. </p>



<p>FOCS 2021 also has <strong>three exciting workshops</strong> as a part of the main program:<br/><br/>1) <a href="https://sites.google.com/view/focs2021ml/home">Recent directions in Machine Learning</a>: co-organized by <a href="https://www.cs.columbia.edu/~djhsu/">Daniel Hsu</a>, <a href="https://people.csail.mit.edu/madry/">Aleksander Madry</a>, and <a href="http://users.eecs.northwestern.edu/~aravindv/">Aravindan Vijayaraghavan</a>, and and featuring <a href="http://tensorlab.cms.caltech.edu/users/anima/">Anima Anandkumar</a>, <a href="https://causalai.net/">Elias Bareinboim</a>, <a href="http://people.cs.uchicago.edu/~risi/">Risi Kondor</a>, <a href="https://profiles.stanford.edu/chris-manning">Christopher Manning</a>, <a href="https://www.andrew.cmu.edu/user/aristesk/">Andrej Risteski</a>, <a href="http://www.columbia.edu/~cgr2130/">Cynthia Rush</a>, <a href="https://jsteinhardt.stat.berkeley.edu/">Jacob Steinhardt</a>.<br/><br/>2) <a href="https://derezende.github.io/focs21proofcomplexity/index.html">Reflections on Propositional Proofs in Algorithms and Complexity</a>: co-organized by <a href="https://www.cs.toronto.edu/~toni/" rel="noreferrer noopener" target="_blank">Toni Pitassi</a>, <a href="https://derezende.github.io/">Susanna de Rezende</a>, and <a href="https://www.cs.mcgill.ca/~robere/" rel="noreferrer noopener" target="_blank">Robert Robere</a>, and featuring <a href="https://www.math.ucsd.edu/~sbuss/" rel="noreferrer noopener" target="_blank">Sam Buss</a>, <a href="https://home.cs.colorado.edu/~jgrochow/index.html" rel="noreferrer noopener" target="_blank">Joshua Grochow</a>, <a href="https://www.cs.cmu.edu/~praveshk/" rel="noreferrer noopener" target="_blank">Pravesh K. Kothari</a>, <a href="https://www2.karlin.mff.cuni.cz/~krajicek/" rel="noreferrer noopener" target="_blank">Jan Krajíček</a>, <a href="https://www.cs.toronto.edu/~toni/" rel="noreferrer noopener" target="_blank">Toni Pitassi</a>, <a href="https://derezende.github.io/">Susanna de Rezende</a>, <a href="https://www.cs.mcgill.ca/~robere/" rel="noreferrer noopener" target="_blank">Robert Robere</a>, <a href="https://www.cs.ox.ac.uk/people/rahul.santhanam/" rel="noreferrer noopener" target="_blank">Rahul Santhanam</a>, <a href="https://users.math.cas.cz/~thapen/" rel="noreferrer noopener" target="_blank">Neil Thapen</a>.<br/><br/>3) <a href="https://focs2021.cs.colorado.edu/workshop-on-cryptography/">Workshop on Cryptography</a>: co-organized by <a href="https://crypto.stanford.edu/~dabo/">Dan Boneh</a> and <a href="http://web.cs.ucla.edu/~sahai/">Amit Sahai</a>, and featuring <a href="https://cs.idc.ac.il/~elette/">Elette Boyle</a>, <a href="https://sites.google.com/view/aayushjain/home">Aayush Jain</a>, <a href="https://www.cs.technion.ac.il/~yuvali/">Yuval Ishai</a>, <a href="https://homes.cs.washington.edu/~rachel/">Rachel Lin</a>, <a href="https://c.rypto.systems/">Wilson Nguyen</a>, <a href="https://www.cs.cornell.edu/~rafael/">Rafael Pass</a>, <a href="https://simons.berkeley.edu/people/hoeteck-wee">Hoeteck Wee</a>.</p>



<p><a href="https://focs2021.cs.colorado.edu/registration/">Registration </a>is still open and available at a reduced rate of $100-150 for participants. </p>



<p>Thanks to generous support from the National Science Foundation, there will be a total of $15,000 in <a href="https://focs2021.cs.colorado.edu/nsf-awards-for-focs-2021/">support for FOCS 2021</a> for eligible students and postdoctoral fellows towards registration fee. </p>



<p>Looking forward to seeing many of you next week!</p>



<p/>



<p><strong>Update: Junior/Senior Lunches by <a href="https://ccanonne.github.io/">Clement Cannone</a> and <a href="http://www.gautamkamath.com/">Gautam Kamath</a>:<br/></strong></p>



<p>Back by popular demand! As part of FOCS 2021, and in view of the success of similar events in the past, a “junior/senior lunch” will take place on Tuesday February 8, 1:30PM-2:30pm ET. Importantly, this is <strong>not</strong> limited to FOCS attendees! As in previous years, this virtual lunch will be the occasion for senior researchers in the field, broadly construed, to have an informal chat with students, postdocs, and junior faculty, answer their questions, discuss their research, and generally have a nice conversation.</p>



<p>To participate as either a senior or junior researcher, please write your name in <a href="https://docs.google.com/spreadsheets/d/1nrL8I0l2OF1kbMFTKlaBdK1L2LXkOMjR1PKBjEUSA4E/edit?usp=sharing">this spreadsheet</a>. Further instructions will be sent to people who sign up.  If you are on the “senior” side of the lunch, you will be responsible for contacting the corresponding juniors, and provide a Zoom link.</p>



<p/>



<p><br/></p></div>
    </content>
    <updated>2022-01-31T21:33:22Z</updated>
    <published>2022-01-31T21:33:22Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>nisheethvishnoi</name>
    </author>
    <source>
      <id>https://nisheethvishnoi.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://nisheethvishnoi.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://nisheethvishnoi.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://nisheethvishnoi.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://nisheethvishnoi.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Algorithms, Nature, and Society</title>
      <updated>2022-02-11T14:39:15Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2022/01/31/linkage</id>
    <link href="https://11011110.github.io/blog/2022/01/31/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>A happy 75th birthday to Dick Lipton and 1000th post on his blog with Ken Regan, Gödel’s Lost Letter and \(\mathsf{P}=\mathsf{NP}\) (\(\mathbb{M}\)).</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><ul>
  <li>
    <p><a href="https://rjlipton.wpcomstaging.com/2022/01/14/happy-1000th-post-and-75th-birthday-dick/">A happy 75th birthday to Dick Lipton and 1000th post on his blog with Ken Regan, <em>Gödel’s Lost Letter and \(\mathsf{P}=\mathsf{NP}\)</em></a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107634279991786612">\(\mathbb{M}\)</a>).</span></p>
  </li>
  <li>
    <p>A quick round-up of three recent Wikipedia Good Articles <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107640833016660096">\(\mathbb{M}\)</a>):</span></p>

    <ul>
      <li>
        <p><a href="https://en.wikipedia.org/wiki/Factorial">Factorial</a> – you know, <span style="white-space: nowrap;">\(n!\).</span></p>
      </li>
      <li>
        <p><a href="https://en.wikipedia.org/wiki/Jessen%27s_icosahedron">Jessen’s icosahedron</a> – polyhedron with all-right dihedrals despite not having axis-parallel sides; the shape of the “Skwish” tensegrity.</p>
      </li>
      <li>
        <p><a href="https://en.wikipedia.org/wiki/Erd%C5%91s%E2%80%93Straus_conjecture">Erdős–Straus conjecture</a> – the question of whether \(\tfrac4n=\tfrac1x+\tfrac1y+\tfrac1z\) has positive integer solutions for <span style="white-space: nowrap;">all \(n\gt 1\).</span></p>
      </li>
    </ul>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2201.06475">Infinite Hex is a draw</a>, Joel David Hamkins and Davide Leonessi <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107646776817088370">\(\mathbb{M}\)</a>,</span> <a href="http://jdh.hamkins.org/infinite-hex-is-a-draw/">via</a>). The paper uses a winning condition for the infinite game that seems pretty technical: you need a bidirectional infinite path of your pieces, whose two ends eventually stay inside all translations of  two opposite quadrants (NE-SW or NW-SE depending on the player). They give a simple mirroring strategy for drawing, and explain why other winning conditions aren’t as nice.</p>
  </li>
  <li>
    <p><a href="https://fractalkitty.com/2022/01/19/string-art-presentation/">String art from Fractal Kitty</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@fractalkitty/107649797432442304">\(\mathbb{M}\)</a>).</span></p>
  </li>
  <li>
    <p><a href="https://cs.stanford.edu/~knuth/fasc12a+.pdf">The Art of Computer Programming, Volume 4, Pre-Fascicle 12A: Components and Traversal</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107659396275070620">\(\mathbb{M}\)</a>).</span> It’s labeled as “ridiculously preliminary”, but includes interesting material on <a href="https://en.wikipedia.org/wiki/Weak_component">weak components of directed graphs</a>. Strong components are the finest partially ordered vertex sets under reachability; analogously, weak components are the finest total order. Every vertex can reach all vertices in later sets, and none in earlier ones.</p>
  </li>
  <li>
    <p><a href="https://mirtitles.org/2022/01/16/some-applications-of-mechanics-to-mathematics-popular-lectures-in-mathematics-vol-3-uspenskii/"><em>Some Applications Of Mechanics To Mathematics</em> by V. A. Uspenskii</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@jarban/107634117912496403">\(\mathbb{M}\)</a>).</span> Usually it goes the other way around. One of the Mir free book series, translated from Russian into English.</p>
  </li>
  <li>
    <p><a href="https://somethingorotherwhatever.com/jiggraph/">JIGGRAPH</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@christianp/107671629340668489">\(\mathbb{M}\)</a>).</span> A game of holding hands or, if you prefer something more abstract, fitting vertices with known local geometries together into a graph.</p>
  </li>
  <li>
    <p><a href="https://history-of-mathematics.org/">History of Mathematics Project</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107676446199538323">\(\mathbb{M}\)</a>,</span> <a href="https://www.sciencenews.org/article/history-math-online-exhibit-journey">via</a>, <a href="https://www.metafilter.com/194098/Math-History">via2</a>), an online exhibit for MOMATH. I’m not convinced of the soundness of a project whose timeline of prime numbers starts with Eratosthenes instead of Euclid, skips from Greeks to enlightenment Europe completely bypassing Ibn al-Haytham (using an ordinal time scale to hide the gap), and doesn’t mention the prime number theorem, but still this looks interesting or at least entertaining.</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2107.13460">Asymptotics of the number of \(n\)-queens placements</a>, Michael Simkin <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107681952236743192">\(\mathbb{M}\)</a>,</span> <a href="https://news.harvard.edu/gazette/story/2022/01/harvard-mathematician-answers-150-year-old-chess-problem/">via</a>, <a href="https://news.ycombinator.com/item?id=30068680">via2</a>). “The chief innovation is the introduction of limit objects for \(n\)-queens configurations, which we call queenons.”</p>
  </li>
  <li>
    <p><a href="https://theconversation.com/more-women-in-a-stem-field-leads-people-to-label-it-as-a-soft-science-according-to-new-research-173724">More women in a STEM field leads people to label it as a “soft science”</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107687670599777394">\(\mathbb{M}\)</a>).</span> Alysson Light provides a general-audience explanation of <a href="https://doi.org/10.1016/j.jesp.2021.104234">her research with Tessa Benson-Greenwald and Amanda Diekman in <em>J. Experimental Social Psych.</em></a>.</p>
  </li>
  <li>
    <p>Today’s observation on overlooked history of mathematics <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107693041325431974">\(\mathbb{M}\)</a>):</span> The <a href="https://en.wikipedia.org/wiki/Binary_tiling">binary tiling of the hyperbolic plane</a>, generally attributed to a 1974 paper by Károly Böröczky, was already used by M. C. Escher in a 1957 print, <em><a href="https://www.escherinhetpaleis.nl/escher-today/woodblocks-and-the-regular-division-of-the-plane/?lang=en">Regular Division of the Plane VI</a></em>.</p>
  </li>
  <li>
    <p>If the pigeonhole principle is the idea that more than \(n\) items distributed into  containers lead to a container with more than one item <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107706939046931942">\(\mathbb{M}\)</a>),</span> what is the name for the principle that fewer than \(n\) items distributed into  containers lead to an empty container?</p>
  </li>
  <li>
    <p><a href="https://3quarksdaily.com/3quarksdaily/2022/01/do-androids-dream-of-mathematics.html">Do androids dream of mathematics</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107710557994842340">\(\mathbb{M}\)</a>)?</span> A popular-audience essay by algebraic combinatorist Jonathan Kujawa on data vs insight in mathematics, and the use of computers in sifting through piles of data on mathematical objects and their invariants in order to focus on potential relations between them.</p>
  </li>
  <li>
    <p>I upgraded from MacOS 11 to 12.2 recently <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107718968183366763">\(\mathbb{M}\)</a>).</span> Today was our first day of in-person classes. I could not get my laptop working with the lecture hall display. Fortunately I was broadcasting the lecture over Zoom and everyone in the classroom had a laptop so we did it that way. But <a href="https://www.youtube.com/watch?v=C6FyXNfGY0k">this video</a> looks like it describes the problem, and a fix (in System Preferences : Battery : Battery, uncheck “Automatic graphics switching”) — I’m hopeful this will work and I can lecture from the big screen next time.</p>
  </li>
</ul></div>
    </content>
    <updated>2022-01-31T17:14:00Z</updated>
    <published>2022-01-31T17:14:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2022-02-11T02:28:19Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-6013534385390898908</id>
    <link href="http://blog.computationalcomplexity.org/feeds/6013534385390898908/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/01/regan-lipton-celebrates-my-1000th-blog.html#comment-form" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/6013534385390898908" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/6013534385390898908" rel="self" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/01/regan-lipton-celebrates-my-1000th-blog.html" rel="alternate" type="text/html"/>
    <title>Regan Lipton celebrates my 1000th blog post and random thoughts this inspires</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Ken Regan emailed me recently asking if our software could tell how many blogs I had done (not how many Lance+Bill had done). We didn't know how to do that but he managed it anyway. Apparently he was more interested in this question than either Lance or I was. </p><p>But the answer was interesting: My1000th post of Complexityblog was about Betty White dying at just the wrong time to be in those <i>those we say goodbye to</i> articles that appear CLOSE to the end of the year. (I don't know why, but I think the fact that my 1000th post was on Betty White is just awesome!) The post is <a href="https://blog.computationalcomplexity.org/2022/01/did-betty-white-die-in-2021why-do.html">here</a>. He was asking this because he thought (correctly) that I was around 1000 and wanted to do a tribute blog to me (actually it was done by Lipton and Regan- more on that later). And indeed they did do the post, its <a href="https://rjlipton.wpcomstaging.com/2022/01/29/bill-gasarch-also-1000/">here</a>.</p><p>RANDOM THOUGHT ONE</p><p>While preparing it Ken asked me about my papers.  This brings up the more general question: When looking at your old work what do you think? Common reactions are</p><p>1) Gee, I was smarter then. That was very clever. OH, now I remember, my co-author did it. </p><p>2) Gee, I was dumber then. I could do that argument so much better now. </p><p>3) Why did I care about Muffins so much to write a book about it? (Replace <i>Muffins</i> with <i>whatever you</i> <i>worked on</i> and <i>book</i> with the<i> venue it appeared in</i>.) </p><p>Item 3 is probably the most common: As a graduate student one works on things without really have a vision of the field (though the advisor can mitigate this) so what you work on may seem odd later on. And ones tastes can change as well. </p><p>RANDOM THOUGHT TWO</p><p>Ken and Dick write actual posts together. I find that amazing! By contrast, the extent of Lance and my interactions about the blog are: </p><p>a) Someone died. Which of us should do the blog obit? or get a guest blogger.?(Whenever Lance phones me on the telephone I answer <i>who died</i> and usually someone did.) </p><p>b) Which of us does the April Fools Day post this year (we usually alternate, or <a href="https://blog.computationalcomplexity.org/2014/04/i-am-bill-gasarch.html">do we</a>)?</p><p>c) I plan on doing 2 posts close together- a question and an answer, so when do you NOT plan on blogging so I can do that.</p><p>d) Someone proved X. Which of us should blog? Or should we get a guest blogger?</p><p>e) Establish a general rule for the year like <i>Bill will post Sunday's, Lance Thursdays.</i></p><p>f) I ask Lance for technical help on the blog. How do you get rid of the white background when I cut and paste?</p><p>g) Sometimes one of us wants commentary on a blog we are working no- but that is rare. Though I asked Lance for this post and he added a few things to this list.</p><p>h) Sometimes I look at one of his posts before it goes out and offer commentary, or vice versa. Also rare.</p><p>i) Lance writes the end of year posts, but always with my input. We jointly choose the theorem of the year.</p><p>j) The very <a href="https://blog.computationalcomplexity.org/2015/03/leonard-nimoy-1931-2015_2.html">rare</a> <a href="https://blog.computationalcomplexity.org/2017/08/the-crystal-blogaversity.html">joint</a> <a href="https://blog.computationalcomplexity.org/2008/02/wseas-greek-tragedy.html">posts</a>.</p><p>k) If we happen to be in the same place at the same time, like Dagsthul, we'll do a <a href="https://blog.computationalcomplexity.org/search?q=typecast">typecast</a> capturing our conversations. In the past we've also had <a href="https://lance.fortnow.com/blogpodcasts/podcast.xml">podcasts</a> and <a href="https://www.youtube.com/user/fortnow">vidcasts</a> together.</p><p><br/></p><p><br/></p></div>
    </content>
    <updated>2022-01-30T19:50:00Z</updated>
    <published>2022-01-30T19:50:00Z</published>
    <author>
      <name>gasarch</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03004932739846901628</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="http://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2022-02-11T00:48:13Z</updated>
    </source>
  </entry>
</feed>
