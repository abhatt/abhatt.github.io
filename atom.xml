<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2019-02-05T12:22:17Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=92</id>
    <link href="https://gilkalai.wordpress.com/2019/02/05/extremal-combinatorics-v-posets/" rel="alternate" type="text/html"/>
    <title>Extremal Combinatorics V: POSETS</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">This is the remaining post V on partially ordered sets of my series on extremal combinatorics (I,II,III,IV,VI).  We will talk here about POSETS – partially ordered sets. The study of order is very important in many areas of mathematics starting … <a href="https://gilkalai.wordpress.com/2019/02/05/extremal-combinatorics-v-posets/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><em>This is the remaining post V on partially ordered sets of my series on extremal combinatorics (<a href="https://gilkalai.wordpress.com/2008/05/01/extremal-combinatorics-i/">I</a>,<a href="https://gilkalai.wordpress.com/2008/07/17/extermal-combinatorics-ii-some-geometry-and-number-theory/">II</a>,<a href="https://gilkalai.wordpress.com/2008/09/28/extremal-combinatorics-iii-some-basic-theorems/">III</a>,<a href="https://gilkalai.wordpress.com/2008/10/06/extremal-combinatorics-iv-shifting/">IV</a>,<a href="https://gilkalai.wordpress.com/2009/05/21/extremal-combinatorics-vi-the-frankl-wilson-theorem/">VI</a>). </em></p>
<p>We will talk here about POSETS – partially ordered sets. The study of order is very important in many areas of mathematics starting with the order relation on the integers and reals in algebra and in Euclidean geometry. The set of all subsets of a set can be partially ordered by inclusion and this is a very basic example of posets. While the study of order and posets is a separate area on its own, parts of it are very important in extremal combinatorics and we will give a little taste here.</p>
<p style="text-align: center;"><span style="color: #0000ff;"><strong>Dear readers, please contribute your favorite result or problem on partially ordered sets (or Sorting) in the comment session.</strong></span></p>
<p>A chain <img alt="C \subset P" class="latex" src="https://s0.wp.com/latex.php?latex=C+%5Csubset+P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C \subset P"/> in a POSET is a set of elements so that every two of them are comparable. An antichain $A \subset P$ is a set of elements so that every two distinct elemenאs in <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> are incomparable.  (Antichains are also called independent sets.) An immediate but important Lemma is:</p>
<p><strong>The immediate lemma:</strong> The intersection of a chain <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> and an antichain <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/> contains at most one element. <strong><span style="color: #993366;">Walla!</span></strong></p>
<h3>Dilworth’s theorem</h3>
<p>Dilworth’s theorem (DT): Every finite partially ordered <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> set can be covered by <img alt="a(P)" class="latex" src="https://s0.wp.com/latex.php?latex=a%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a(P)"/> chains.</p>
<p>(By the immediate lemma, at least <img alt="a(P)" class="latex" src="https://s0.wp.com/latex.php?latex=a%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a(P)"/> chains are needed.)</p>
<p>Dual Dilworth theorem: Every partially ordedrd sets can be cover by <img alt="c(P)" class="latex" src="https://s0.wp.com/latex.php?latex=c%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c(P)"/> untichains.</p>
<p>(By the immediate lemma, at least <img alt="c(P)" class="latex" src="https://s0.wp.com/latex.php?latex=c%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c(P)"/> antichains are needed.)</p>
<p>The proof of the dual Dilworth theorem is easy. Note that the set <img alt="A_1=MIN(P)" class="latex" src="https://s0.wp.com/latex.php?latex=A_1%3DMIN%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_1=MIN(P)"/> of minimal elements of <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> is an antichain. Let <img alt="A_k = MIN (P\backslash (A_1 \cup A_2 \cup \dots A_{k-1}))" class="latex" src="https://s0.wp.com/latex.php?latex=A_k+%3D+MIN+%28P%5Cbackslash+%28A_1+%5Ccup+A_2+%5Ccup+%5Cdots+A_%7Bk-1%7D%29%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_k = MIN (P\backslash (A_1 \cup A_2 \cup \dots A_{k-1}))"/>. We need two easy observations. First, <img alt="A_k is an antichain" class="latex" src="https://s0.wp.com/latex.php?latex=A_k+is+an+antichain&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_k is an antichain"/> and second: If <img alt="A_k \ne \emptyset" class="latex" src="https://s0.wp.com/latex.php?latex=A_k+%5Cne+%5Cemptyset&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_k \ne \emptyset"/> then there is a chain with one element from <img alt="A_i: 1 \le i\le k" class="latex" src="https://s0.wp.com/latex.php?latex=A_i%3A+1+%5Cle+i%5Cle+k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_i: 1 \le i\le k"/>. <strong><span style="color: #0000ff;">Walla!</span></strong></p>
<p>The proof of Dilworth theorem is by induction on $|P|$. For the induction step you first consider the case where every antichain of maximal size is either <img alt="MAX(P)" class="latex" src="https://s0.wp.com/latex.php?latex=MAX%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="MAX(P)"/> or <img alt="MIN (P)" class="latex" src="https://s0.wp.com/latex.php?latex=MIN+%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="MIN (P)"/>. In this case you consider a chain with one element in <img alt="MAX(P)" class="latex" src="https://s0.wp.com/latex.php?latex=MAX%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="MAX(P)"/> and one element in <img alt="MIN (P)" class="latex" src="https://s0.wp.com/latex.php?latex=MIN+%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="MIN (P)"/> and delete these elements from <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/>. For the resulting post <img alt="Q" class="latex" src="https://s0.wp.com/latex.php?latex=Q&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Q"/>, <img alt="a(Q)=a(P)-1" class="latex" src="https://s0.wp.com/latex.php?latex=a%28Q%29%3Da%28P%29-1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a(Q)=a(P)-1"/> and we can use the induction hypothesis.</p>
<p>Otherwise there is an antichain <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> of maximum size <img alt="t=a(P)" class="latex" src="https://s0.wp.com/latex.php?latex=t%3Da%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t=a(P)"/> which is not <em>MAX(P)</em> or <em>MIN(P)</em>.  Put <img alt="A=\{a_1,a_2,\dots,a_t\}" class="latex" src="https://s0.wp.com/latex.php?latex=A%3D%5C%7Ba_1%2Ca_2%2C%5Cdots%2Ca_t%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A=\{a_1,a_2,\dots,a_t\}"/>. Let <img alt="P^+" class="latex" src="https://s0.wp.com/latex.php?latex=P%5E%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P^+"/> be the set of elements in <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> which are larger or equal some element in <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/>, and let <img alt="P^-" class="latex" src="https://s0.wp.com/latex.php?latex=P%5E-&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P^-"/> be the set of elements in <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> which are smaller or equal some element in <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/>.</p>
<p>Now,</p>
<ol>
<li><img alt="P^+ \cup P^-=P" class="latex" src="https://s0.wp.com/latex.php?latex=P%5E%2B+%5Ccup+P%5E-%3DP&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P^+ \cup P^-=P"/>. Otherwise we could add an element to <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> to form a larger antichain.</li>
<li><img alt="P^+ \cap P^- = A" class="latex" src="https://s0.wp.com/latex.php?latex=P%5E%2B+%5Ccap+P%5E-+%3D+A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P^+ \cap P^- = A"/>. Otherwise, there will be two elements of <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> which are comparable.</li>
</ol>
<p>So by the induction hypothesis <img alt="P^+" class="latex" src="https://s0.wp.com/latex.php?latex=P%5E%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P^+"/> can be covered by <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t"/> chains <img alt="C_1^+, C_2^+, \dots, C_t^+" class="latex" src="https://s0.wp.com/latex.php?latex=C_1%5E%2B%2C+C_2%5E%2B%2C+%5Cdots%2C+C_t%5E%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_1^+, C_2^+, \dots, C_t^+"/> and <img alt="P^-" class="latex" src="https://s0.wp.com/latex.php?latex=P%5E-&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P^-"/> can be covered by <img alt="a(P" class="latex" src="https://s0.wp.com/latex.php?latex=a%28P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a(P"/>$ chains <img alt="C_1^-, C_2^-, \dots, C_t^-" class="latex" src="https://s0.wp.com/latex.php?latex=C_1%5E-%2C+C_2%5E-%2C+%5Cdots%2C+C_t%5E-&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_1^-, C_2^-, \dots, C_t^-"/>. Bu re-indexing we can assume that both <img alt="C_i^+" class="latex" src="https://s0.wp.com/latex.php?latex=C_i%5E%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_i^+"/> and <img alt="C_i^-" class="latex" src="https://s0.wp.com/latex.php?latex=C_i%5E-&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_i^-"/> contains <img alt="a_i" class="latex" src="https://s0.wp.com/latex.php?latex=a_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_i"/>. It follows that <img alt="a_i" class="latex" src="https://s0.wp.com/latex.php?latex=a_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_i"/> is the minimal element in $C_i^+$ and the maximal element in $C_i^-$ and hence <img alt="C_i=:C_i^+ \cup C_i^-" class="latex" src="https://s0.wp.com/latex.php?latex=C_i%3D%3AC_i%5E%2B+%5Ccup+C_i%5E-&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_i=:C_i^+ \cup C_i^-"/> is a chain. The <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t"/> chains <img alt="C_1, C_2, \dots, C_t" class="latex" src="https://s0.wp.com/latex.php?latex=C_1%2C+C_2%2C+%5Cdots%2C+C_t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_1, C_2, \dots, C_t"/> cover <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/>. <span style="color: #993366;"><strong>Sababa!</strong></span></p>
<p>An <strong>important Corollary</strong> both from Dilworth’s theorem and its dual is that</p>
<p style="text-align: center;"><img alt="a(P) c(P) \ge |P|." class="latex" src="https://s0.wp.com/latex.php?latex=a%28P%29+c%28P%29+%5Cge+%7CP%7C.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a(P) c(P) \ge |P|."/></p>
<h3>Erdos-Szekeres theorem</h3>
<p>The fundamental Erdos Szekeres theorem asserts that if <img alt="n=ab+1" class="latex" src="https://s0.wp.com/latex.php?latex=n%3Dab%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n=ab+1"/> then every sequence <img alt="a_1,a_2,\dots ,a_n" class="latex" src="https://s0.wp.com/latex.php?latex=a_1%2Ca_2%2C%5Cdots+%2Ca_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_1,a_2,\dots ,a_n"/> of different real numbers contains a monotone increasing sequence of length <img alt="a+1" class="latex" src="https://s0.wp.com/latex.php?latex=a%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a+1"/> or a monotone decreasing sequence of length <img alt="b+1" class="latex" src="https://s0.wp.com/latex.php?latex=b%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="b+1"/>.</p>
<p>There are simple proofs. For example, associate to every <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/> a pair <img alt="(I_k,D_k)" class="latex" src="https://s0.wp.com/latex.php?latex=%28I_k%2CD_k%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(I_k,D_k)"/> of integers where  <img alt="I_k" class="latex" src="https://s0.wp.com/latex.php?latex=I_k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="I_k"/> is the maximum length of the increasing subsequence starting with <img alt="a_k" class="latex" src="https://s0.wp.com/latex.php?latex=a_k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_k"/> and <img alt="D_k" class="latex" src="https://s0.wp.com/latex.php?latex=D_k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D_k"/> is the maximum length of the deccreasing subsequence starting with <img alt="a_k" class="latex" src="https://s0.wp.com/latex.php?latex=a_k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_k"/>. The result follows from the easy observation that all these pairs are different.</p>
<p>Both Dilworth’ theorem and its easy dual implies easily (in fact we need only the important corollary) the Erdos Szekeres theorem when we define the following partial order: <img alt="i &lt; k" class="latex" src="https://s0.wp.com/latex.php?latex=i+%3C+k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i &lt; k"/> if both <img alt="i&lt;k" class="latex" src="https://s0.wp.com/latex.php?latex=i%3Ck&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i&lt;k"/> and <img alt="a_i &lt; a_k" class="latex" src="https://s0.wp.com/latex.php?latex=a_i+%3C+a_k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_i &lt; a_k"/>.</p>
<h3>Looking at Sperner’s theorem again</h3>
<p>Sperner’s theorem asserts that the maximal size of an antichain of subsets of an <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> elements set is <img alt="{{n} \choose {[n/2]}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7Bn%7D+%5Cchoose+%7B%5Bn%2F2%5D%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{{n} \choose {[n/2]}}"/>. By Dilworth theorem it follows that we can cover all sets by <img alt="{{n} \choose {[n/2]}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7Bn%7D+%5Cchoose+%7B%5Bn%2F2%5D%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{{n} \choose {[n/2]}}"/> chains (and, of course when we exhibit such a covering it reproves Sperner theorem). A symmetric saturated chain decomposition is a partition of <img alt="P(n)" class="latex" src="https://s0.wp.com/latex.php?latex=P%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P(n)"/> (=all subsets of <img alt="[n]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Bn%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="[n]"/>) to saturated chains where each chain has, for some <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>, sets of sizes $k,k+1,\dots,d-k$. You can build such a decomposition inductively.</p>
<p>Start with a decomposition for <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> for each chain <img alt="C_i" class="latex" src="https://s0.wp.com/latex.php?latex=C_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_i"/> create a new chain <img alt="C'_i" class="latex" src="https://s0.wp.com/latex.php?latex=C%27_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C'_i"/> by adding the element <img alt="n+1" class="latex" src="https://s0.wp.com/latex.php?latex=n%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n+1"/> to every set. And then move the top set in <img alt="C'_i" class="latex" src="https://s0.wp.com/latex.php?latex=C%27_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C'_i"/> to <img alt="C_i" class="latex" src="https://s0.wp.com/latex.php?latex=C_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_i"/>.  <strong>Walla!</strong></p>
<p>This is a beginning of a very beautiful story related also to the Dedekind Problem about  number of antichains in <img alt="P(n)" class="latex" src="https://s0.wp.com/latex.php?latex=P%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P(n)"/>.</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/02/untitledgreene-kleitman2.png"><img alt="" class="alignnone size-full wp-image-16834" height="489" src="https://gilkalai.files.wordpress.com/2019/02/untitledgreene-kleitman2.png?w=640&amp;h=489" width="640"/></a></p>
<p><strong><span style="color: #ff0000;">Curtis Greene and Danny Kleitman</span></strong></p>
<h3>The Greene-Kleitman theorem</h3>
<p>Let <img alt="a_k(P)" class="latex" src="https://s0.wp.com/latex.php?latex=a_k%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_k(P)"/> be the maximum size of the union <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X"/> of <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/> antichains in a poset <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/>. For every chain For every chain <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/> we have <img alt="|C \cap X| \le \min\{|C|,k\}" class="latex" src="https://s0.wp.com/latex.php?latex=%7CC+%5Ccap+X%7C+%5Cle+%5Cmin%5C%7B%7CC%7C%2Ck%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|C \cap X| \le \min\{|C|,k\}"/>. Therefore for a partition of <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> to chains <img alt="C_1,C_2,\dots,C_t" class="latex" src="https://s0.wp.com/latex.php?latex=C_1%2CC_2%2C%5Cdots%2CC_t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_1,C_2,\dots,C_t"/> we   have <img alt="\sum\min\{|C_i|,k\ge |X|" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csum%5Cmin%5C%7B%7CC_i%7C%2Ck%5Cge+%7CX%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sum\min\{|C_i|,k\ge |X|"/>. The <a href="https://www.encyclopediaofmath.org/index.php/Greene-Kleitman_theorem">Greene-Kleitman theorem</a> asserts that there always is a decomposition into chains with <img alt="\sum\min\{|C_i|,k\}=a_k(P)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csum%5Cmin%5C%7B%7CC_i%7C%2Ck%5C%7D%3Da_k%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sum\min\{|C_i|,k\}=a_k(P)"/>.</p>
<h3>The perfect graph theorem.</h3>
<p>What is the relation between the very easy dual Dilworth theorem and the harder Dilworth theorem? As it turns out there is a very general theorem, Lovasz’ perfect graph theorem, that show that,  these two theorems are equivalent.</p>
<p>A graph G is perfect if for every induced subgraph H, the chromatic number equals the clique number. Lovasz’ theorem  (conjectured by Claude Berge) asserts that complements of perfect graphs are perfect. The perfectness of the comparability graph of a poset amounts to the dual Dilworth theorem, and for its complement it is the Dilworth theorem. Lovasz in fact proved that perfectness is equivalent to the relation $\latex \omega(H)\cdot \alpha (H) \ge |H|$ for every induced subgraph H. (For posets this is our important corollary above.)</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/02/kahn-linial-saks.png"><img alt="" class="alignnone size-full wp-image-16832" height="239" src="https://gilkalai.files.wordpress.com/2019/02/kahn-linial-saks.png?w=640&amp;h=239" width="640"/></a></p>
<p><strong><span style="color: #ff0000;">Jeff Kahn and Jake Baron </span></strong><span style="color: #ff0000;">(</span><span style="color: #ff0000;"><a href="http://archive.dimacs.rutgers.edu/DIMACS_highlights/tuza/tuza.html">see here on their 2016 asymptotic solution to Tusza’s conjecture</a></span><span style="color: #ff0000;">),</span><strong><span style="color: #ff0000;"> Mike Saks, and Nati Linial</span></strong></p>
<h3>Startling theorems on POSETS: Kahn-Saks,  Linial-Saks, Linial-Kahn, and Kahn-Saks</h3>
<p>Here  some beautiful and important theorems on posets. An order ideas <img alt="I" class="latex" src="https://s0.wp.com/latex.php?latex=I&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="I"/> of a post is a set of elements so that if <img alt="x in I" class="latex" src="https://s0.wp.com/latex.php?latex=x+in+I&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x in I"/> and <img alt="y &lt; x" class="latex" src="https://s0.wp.com/latex.php?latex=y+%3C+x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y &lt; x"/> then <img alt="y \in I" class="latex" src="https://s0.wp.com/latex.php?latex=y+%5Cin+I&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y \in I"/>.</p>
<p><strong>Theorem (Linial-Saks, 1985):</strong> In every poset <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> there is an element which is contained in more than δ and less than 1-δ order ideas of <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/>.  (<a href="http://www.cs.huji.ac.il/~nati/PAPERS/central_element.pdf">Paper</a>)</p>
<p><strong>Theorem (Kahn-Saks, 1984):</strong> For every Poset <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> which is not a chain there are two incomparable elements <img alt="x,y" class="latex" src="https://s0.wp.com/latex.php?latex=x%2Cy&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x,y"/> such that the number of linear extensions of <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> for which <img alt="x&lt;y" class="latex" src="https://s0.wp.com/latex.php?latex=x%3Cy&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x&lt;y"/> is between 3/11 and 8/11. (<a href="https://link.springer.com/article/10.1007/BF00565647">Paper</a>)</p>
<p>A <a href="http://www.cs.huji.ac.il/~nati/PAPERS/brunn_minkowski.pdf">simpler proof</a> was found in the late 80s by Kahn and Linial and by Karzanov and Khachiyan. It  is  based on the Brunn Minkowski theorem gives a weaker constant <img alt="1/2e" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F2e&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/2e"/> .</p>
<p><strong>Theorem (Kahn-Saks, 1987)</strong>: For every finite distributive lattice <img alt="L" class="latex" src="https://s0.wp.com/latex.php?latex=L&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="L"/> the maximum antichain is of size <img alt="o(|L|)" class="latex" src="https://s0.wp.com/latex.php?latex=o%28%7CL%7C%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="o(|L|)"/>. (<a href="https://core.ac.uk/download/pdf/82629369.pdf">Paper</a>)</p>
<p>Lattices are special types of posets with the property that for every set of elements (pairs <img alt="\{x,y\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7Bx%2Cy%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{x,y\}"/> suffice in the finite case), there is a unique minimal elements above them all (denoted for pairs by <i>x</i> ∧ <i>y</i>) and a unique maximal element (denoted for pairs by <i>x</i> ∨ <i>y</i>) below them all.</p>
<p>A <a href="https://en.wikipedia.org/wiki/Distributive_lattice">distributive lattice</a> ia a lattice that satisfies for every <em>x, y</em> and <em>z</em>, the relation</p>
<p style="text-align: center;"><i>x</i> ∧ (<i>y</i> ∨ <i>z</i>) = (<i>x</i> ∧ <i>y</i>) ∨ (<i>x</i> ∧ <i>z</i>)</p>
<p>Birkhoff’s representation theorem asserts that finite distributive lattices can be represented as order ideals of posets (ordered by inclusion).</p>
<p> </p>
<p> </p></div>
    </content>
    <updated>2019-02-05T11:18:54Z</updated>
    <published>2019-02-05T11:18:54Z</published>
    <category term="Combinatorics"/>
    <category term="Claude Berge"/>
    <category term="Curtis Greene"/>
    <category term="Daniel Kleitman"/>
    <category term="Dilworth's theorem"/>
    <category term="Extremal combinatorics"/>
    <category term="Jeff Kahn"/>
    <category term="Laci Lovasz"/>
    <category term="Mike Saks"/>
    <category term="Nati Linial"/>
    <category term="Posets"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-02-05T12:20:50Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://lucatrevisan.wordpress.com/?p=4206</id>
    <link href="https://lucatrevisan.wordpress.com/2019/02/04/%e6%81%ad%e5%96%9c%e5%8f%91%e8%b4%a2-11/" rel="alternate" type="text/html"/>
    <title>恭喜发财!</title>
    <summary>昔年快乐！ Advertisements</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><img alt="8cxnLMGdi" class="alignnone size-full wp-image-4207" src="https://lucatrevisan.files.wordpress.com/2019/02/8cxnlmgdi.png?w=584"/></p>
<p>昔年快乐！</p></div>
    </content>
    <updated>2019-02-05T06:45:35Z</updated>
    <published>2019-02-05T06:45:35Z</published>
    <category term="&#x65B0;&#x5E74;"/>
    <author>
      <name>luca</name>
    </author>
    <source>
      <id>https://lucatrevisan.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://lucatrevisan.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://lucatrevisan.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://lucatrevisan.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://lucatrevisan.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>"Marge, I agree with you - in theory. In theory, communism works. In theory." -- Homer Simpson</subtitle>
      <title>in   theory</title>
      <updated>2019-02-05T12:20:11Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.01334</id>
    <link href="http://arxiv.org/abs/1902.01334" rel="alternate" type="text/html"/>
    <title>Distances between Data Sets Based on Summary Statistics</title>
    <feedworld_mtime>1549324800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tatti:Nikolaj.html">Nikolaj Tatti</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.01334">PDF</a><br/><b>Abstract: </b>The concepts of similarity and distance are crucial in data mining. We
consider the problem of defining the distance between two data sets by
comparing summary statistics computed from the data sets. The initial
definition of our distance is based on geometrical notions of certain sets of
distributions. We show that this distance can be computed in cubic time and
that it has several intuitive properties. We also show that this distance is
the unique Mahalanobis distance satisfying certain assumptions. We also
demonstrate that if we are dealing with binary data sets, then the distance can
be represented naturally by certain parity functions, and that it can be
evaluated in linear time. Our empirical tests with real world data show that
the distance works well.
</p></div>
    </summary>
    <updated>2019-02-05T02:39:44Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-05T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.01331</id>
    <link href="http://arxiv.org/abs/1902.01331" rel="alternate" type="text/html"/>
    <title>Safe projections of binary data sets</title>
    <feedworld_mtime>1549324800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tatti:Nikolaj.html">Nikolaj Tatti</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.01331">PDF</a><br/><b>Abstract: </b>Selectivity estimation of a boolean query based on frequent itemsets can be
solved by describing the problem by a linear program. However, the number of
variables in the equations is exponential, rendering the approach tractable
only for small-dimensional cases. One natural approach would be to project the
data to the variables occurring in the query. This can, however, change the
outcome of the linear program.
</p>
<p>We introduce the concept of safe sets: projecting the data to a safe set does
not change the outcome of the linear program. We characterise safe sets using
graph theoretic concepts and give an algorithm for finding minimal safe sets
containing given attributes. We describe a heuristic algorithm for finding
almost-safe sets given a size restriction, and show empirically that these sets
outperform the trivial projection.
</p>
<p>We also show a connection between safe sets and Markov Random Fields and use
it to further reduce the number of variables in the linear program, given some
regularity assumptions on the frequent itemsets.
</p></div>
    </summary>
    <updated>2019-02-05T02:38:39Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-05T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.01280</id>
    <link href="http://arxiv.org/abs/1902.01280" rel="alternate" type="text/html"/>
    <title>A New Class of Searchable and Provably Highly Compressible String Transformations</title>
    <feedworld_mtime>1549324800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Giancarlo:Raffaele.html">Raffaele Giancarlo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Manzini:Giovanni.html">Giovanni Manzini</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rosone:Giovanna.html">Giovanna Rosone</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sciortino:Marinella.html">Marinella Sciortino</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.01280">PDF</a><br/><b>Abstract: </b>The Burrows-Wheeler Transform is a string transformation that plays a
fundamental role for the design of self-indexing compressed data structures.
Over the years, researchers have successfully extended this transformation
outside the domains of strings. However, efforts to find non-trivial
alternatives of the original, now 25 years old, Burrows-Wheeler string
transformation have met limited success. In this paper we bring new lymph to
this area by introducing a whole new family of transformations that have all
the myriad virtues of the BWT: they can be computed and inverted in linear
time, they produce provably highly compressible strings, and they support
linear time pattern search directly on the transformed string. This new family
is a special case of a more general class of transformations based on context
adaptive alphabet orderings, a concept introduced here. This more general class
includes also the Alternating BWT, another invertible string transforms
recently introduced in connection with a generalization of Lyndon words.
</p></div>
    </summary>
    <updated>2019-02-05T02:25:34Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-05T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.01192</id>
    <link href="http://arxiv.org/abs/1902.01192" rel="alternate" type="text/html"/>
    <title>Advances in the Treatment of Trimmed CAD Models due to Isogeometric Analysis</title>
    <feedworld_mtime>1549324800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Marussig:Benjamin.html">Benjamin Marussig</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.01192">PDF</a><br/><b>Abstract: </b>Trimming is a core technique in geometric modeling. Unfortunately, the
resulting objects do not take the requirements of numerical simulations into
account and yield various problems. This paper outlines principal issues of
trimmed models and highlights different analysis-suitable strategies to address
them. It is discussed that these concepts not only provide important
computational tools for isogeometric analysis, but can also improve the
treatment of trimmed models in a design context.
</p></div>
    </summary>
    <updated>2019-02-05T02:54:29Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-02-05T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.01128</id>
    <link href="http://arxiv.org/abs/1902.01128" rel="alternate" type="text/html"/>
    <title>A Unified Framework for Marketing Budget Allocation</title>
    <feedworld_mtime>1549324800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhao:Kui.html">Kui Zhao</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hua:Junhao.html">Junhao Hua</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yan:Ling.html">Ling Yan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Qi.html">Qi Zhang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/x/Xu:Huan.html">Huan Xu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yang:Cheng.html">Cheng Yang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.01128">PDF</a><br/><b>Abstract: </b>While marketing budget allocation has been studied for decades in traditional
business, nowadays online business brings much more challenges due to the
dynamic environment and complex decision-making process. In this paper, we
present a novel unified framework for marketing budget allocation. By
leveraging abundant data, the proposed data-driven approach can help us to
overcome the challenges and make more informed decisions. In our approach, a
semi-black-box model is built to forecast the dynamic market response and an
efficient optimization method is proposed to solve the complex allocation task.
First, the response in each market-segment is forecasted by exploring
historical data through a semi-black-box model, where the capability of logit
demand curve is enhanced by neural networks. The response model reveals
relationship between sales and marketing cost. Based on the learned model,
budget allocation is then formulated as an optimization problem, and we design
efficient algorithms to solve it in both continuous and discrete settings.
Several kinds of business constraints are supported in one unified optimization
paradigm, including cost upper bound, profit lower bound, or ROI lower bound.
The proposed framework is easy to implement and readily to handle large-scale
problems. It has been successfully applied to many scenarios in Alibaba Group.
The results of both offline experiments and online A/B testing demonstrate its
effectiveness.
</p></div>
    </summary>
    <updated>2019-02-05T02:40:04Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-05T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.01088</id>
    <link href="http://arxiv.org/abs/1902.01088" rel="alternate" type="text/html"/>
    <title>On Prefix-Sorting Finite Automata</title>
    <feedworld_mtime>1549324800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Alanko:Jarno.html">Jarno Alanko</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Policriti:Alberto.html">Alberto Policriti</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Prezza:Nicola.html">Nicola Prezza</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.01088">PDF</a><br/><b>Abstract: </b>Being able to efficiently test the membership of a word in a formal language
is, arguably, one of the most fundamental problems in computer science. In this
paper, we apply string-processing techniques (specifically,
\emph{prefix-sorting}) to speed up solutions for this problem on languages
described by particular finite automata. Prefix sorting can be generalized to
objects more complex than strings: the recent notion of \emph{Wheeler graph}
extends this concept to labeled graphs (for example, finite-state automata). A
Wheeler graph admits a co-lexicographic ordering of its nodes and opens up the
possibility of building fast and small data structures supporting path queries
on the graph. However, while strings and trees can always be prefix-sorted in
linear time, the situation on graphs is more complicated: not all graphs are
Wheeler, and a recent result shows that the problem of identifying them is
NP-complete even for acyclic NFAs. In this paper, we present the following
results: (i) we show that the problem of recognizing and sorting Wheeler DFAs
(even cyclic) can be solved offline in optimal linear time, (ii) when the DFA
is acyclic, we give an online algorithm that, when fed with the DFA's states in
any topological order, with logarithmic delay computes the co-lexicographic
rank of a new incoming state or decides that such an ordering does not exist,
and (iii) we show that also Wheeler 2-NFAs---i.e. those with at most two
equally-labeled transitions leaving any state---admit a polynomial-time
identification and prefix-sorting algorithm. Our algorithms (i)-(ii) generalize
to labeled graphs existing prefix-sorting algorithms on strings and labeled
trees that have been previously described in the literature.
</p></div>
    </summary>
    <updated>2019-02-05T02:26:58Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-05T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.01028</id>
    <link href="http://arxiv.org/abs/1902.01028" rel="alternate" type="text/html"/>
    <title>Can SGD Learn Recurrent Neural Networks with Provable Generalization?</title>
    <feedworld_mtime>1549324800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Allen=Zhu:Zeyuan.html">Zeyuan Allen-Zhu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Yuanzhi.html">Yuanzhi Li</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.01028">PDF</a><br/><b>Abstract: </b>Recurrent Neural Networks (RNNs) are among the most popular models in
sequential data analysis. However, due to the complexity raised by recurrent
structure, they remain one of the least theoretically understood neural-network
models. In particular, existing generalization bounds for RNNs mostly scale
exponentially with the length of the input sequence, which limited their
practical implications. In this paper, we show that if the input labels are
(approximately) realizable by certain classes of (non-linear) functions of the
input sequences, then using the vanilla stochastic gradient descent (SGD), RNNs
can actually learn them $\textit{efficiently}$, meaning that both the training
time and sample complexity only scale $\textit{polynomially}$ with the input
length (or almost polynomially, depending on the classes of non-linearity).
</p></div>
    </summary>
    <updated>2019-02-05T02:38:58Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-05T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.01002</id>
    <link href="http://arxiv.org/abs/1902.01002" rel="alternate" type="text/html"/>
    <title>Ranking Episodes using a Partition Model</title>
    <feedworld_mtime>1549324800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tatti:Nikolaj.html">Nikolaj Tatti</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.01002">PDF</a><br/><b>Abstract: </b>One of the biggest setbacks in traditional frequent pattern mining is that
overwhelmingly many of the discovered patterns are redundant. A prototypical
example of such redundancy is a freerider pattern where the pattern contains a
true pattern and some additional noise events. A technique for filtering
freerider patterns that has proved to be efficient in ranking itemsets is to
use a partition model where a pattern is divided into two subpatterns and the
observed support is compared to the expected support under the assumption that
these two subpatterns occur independently.
</p>
<p>In this paper we develop a partition model for episodes, patterns discovered
from sequential data. An episode is essentially a set of events, with possible
restrictions on the order of events. Unlike with itemset mining, computing the
expected support of an episode requires surprisingly sophisticated methods. In
order to construct the model, we partition the episode into two subepisodes. We
then model how likely the events in each subepisode occur close to each other.
If this probability is high---which is often the case if the subepisode has a
high support---then we can expect that when one event from a subepisode occurs,
then the remaining events occur also close by. This approach increases the
expected support of the episode, and if this increase explains the observed
support, then we can deem the episode uninteresting. We demonstrate in our
experiments that using the partition model can effectively and efficiently
reduce the redundancy in episodes.
</p></div>
    </summary>
    <updated>2019-02-05T02:28:04Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-05T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.00975</id>
    <link href="http://arxiv.org/abs/1902.00975" rel="alternate" type="text/html"/>
    <title>Some Remarks on Real-Time Turing Machines</title>
    <feedworld_mtime>1549324800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Petersen:Holger.html">Holger Petersen</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.00975">PDF</a><br/><b>Abstract: </b>The power of real-time Turing machines using sublinear space is investigated.
In contrast to a claim appearing in the literature, such machines can accept
non-regular languages, even if working in deterministic mode. While maintaining
a standard binary counter appears to be impossible in real-time, we present a
guess and check approach that yields a binary representation of the input
length. Based on this technique, we show that unary encodings of languages
accepted in exponential time can be recognized by nondeterministic real-time
Turing machines.
</p></div>
    </summary>
    <updated>2019-02-05T02:24:53Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-02-05T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.00947</id>
    <link href="http://arxiv.org/abs/1902.00947" rel="alternate" type="text/html"/>
    <title>Stochastic first-order methods: non-asymptotic and computer-aided analyses via potential functions</title>
    <feedworld_mtime>1549324800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Taylor:Adrien.html">Adrien Taylor</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bach:Francis.html">Francis Bach</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.00947">PDF</a><br/><b>Abstract: </b>We provide a novel computer-assisted technique for systematically analyzing
first-order methods for optimization. In contrast with previous works, the
approach is particularly suited for handling sublinear convergence rates and
stochastic oracles. The technique relies on semidefinite programming and
potential functions. It allows simultaneously obtaining worst-case guarantees
on the behavior of those algorithms, and assisting in choosing appropriate
parameters for tuning their worst-case performances. The technique also
benefits from comfortable tightness guarantees, meaning that unsatisfactory
results can be improved only by changing the setting. We use the approach for
analyzing deterministic and stochastic first-order methods under different
assumptions on the nature of the stochastic noise. Among others, we treat
unstructured noise with bounded variance, different noise models arising in
over-parametrized expectation minimization problems, and randomized
block-coordinate descent schemes.
</p></div>
    </summary>
    <updated>2019-02-05T02:20:28Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-02-05T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.00919</id>
    <link href="http://arxiv.org/abs/1902.00919" rel="alternate" type="text/html"/>
    <title>Knapsack Problem With Cardinality Constraint: A Faster FPTAS Through the Lens of Numerical Analysis and Applications</title>
    <feedworld_mtime>1549324800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Wenxin.html">Wenxin Li</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lee:Joohyun.html">Joohyun Lee</a>, Ness Shroff <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.00919">PDF</a><br/><b>Abstract: </b>We study the $K$-item knapsack problem (\ie, $1.5$-dimensional knapsack
problem), which is a generalization of the famous 0-1 knapsack problem (\ie,
$1$-dimensional knapsack problem) in which an upper bound $K$ is imposed on the
number of items selected. This problem is of fundamental importance and is
known to have a broad range of applications in various fields such as computer
science and operation research. It is well known that, there is no FPTAS for
the $d$-dimensional knapsack problem when $d\geq 2$, unless P $=$ NP. While the
$K$-item knapsack problem is known to admit an FPTAS, the complexity of all
existing FPTASs have a high dependency on the cardinality bound $K$ and
approximation error $\varepsilon$, which could result in inefficiencies
especially when $K$ and $\varepsilon^{-1}$ increase. The current best results
are due to \citep{mastrolilli2006hybrid}, in which two schemes are presented
exhibiting a space-time tradeoff--one scheme with time complexity
$O(n+Kz^{2}/\varepsilon^{2})$ and space complexity $O(n+z^{3}/\varepsilon)$,
while another scheme requires a run-time of
$O(n+(Kz^{2}+z^{4})/\varepsilon^{2})$ but only needs $O(n+z^{2}/\varepsilon)$
space, where $z=\min\{K,1/\varepsilon\}$. In this paper we close the space-time
tradeoff exhibited in \citep{mastrolilli2006hybrid} by designing a new FPTAS
with a running time of $O(n)+\widetilde{O}(z^{2}\cdot
\max\{K,\varepsilon^{-2}\})$, while simultaneously reaching the
$O(n+z^{2}/\varepsilon)$ space complexity. Our scheme provides
$\widetilde{O}(\min\{K,\varepsilon^{-2}\})$ and $O(z)$ improvements on the
long-established state-of-the-art algorithms in time and space complexity
respectively. An salient feature of our algorithm is that it is the
\emph{first} FPTAS, which achieves better time and space complexity bounds than
the very first standard FPTAS \emph{over all parameter regimes}.
</p></div>
    </summary>
    <updated>2019-02-05T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-05T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.00911</id>
    <link href="http://arxiv.org/abs/1902.00911" rel="alternate" type="text/html"/>
    <title>Study, representation and applications of hypergraph minimal transversals</title>
    <feedworld_mtime>1549324800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>M. Nidhal Jelassi <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.00911">PDF</a><br/><b>Abstract: </b>This work is part of the field of the hypergraph theory and focuses on
hypergraph minimal transversal. The problem of extracting the minimal
transversals from a hypergraph received the interest of many researchers as
shown the number of algorithms proposed in the literature, and this is mainly
due to the solutions offered by the minimal transversal in various application
areas such as databases, artificial intelligence, e-commerce, semantic web,
etc. In view of the wide range of fields of minimal transversal application and
the interest they generate, the objective of this thesis is to explore new
application paths of minimal transversal by proposing methods to optimize the
extraction. This has led to three proposed contributions in this thesis. The
first approach takes advantage of the emergence of Web 2.0 and, therefore,
social networks using minimal transversal for the detection of important actors
within these networks. The second part of research in this thesis has focused
on reducing the number of hypergraph minimal transversal. A concise and
accurate representation of minimal transversal was proposed and is based on the
construction of an irredundant hypergraph, hence are calculated the irredundant
minimal transversal of the initial hypergraph. An application of this
representation to the dependency inference problem is presented to illustrate
the usefulness of this approach. The last approach includes the hypergraph
decomposition into partial hypergraph the local minimal transversal are
calculated and their Cartesian product can generate all the hypergraph
transversal sets. Different experimental studies have shown the value of these
proposed approaches.
</p></div>
    </summary>
    <updated>2019-02-05T02:26:55Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-05T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.00846</id>
    <link href="http://arxiv.org/abs/1902.00846" rel="alternate" type="text/html"/>
    <title>A Billion Updates per Second Using 30,000 Hierarchical In-Memory D4M Databases</title>
    <feedworld_mtime>1549324800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kepner:Jeremy.html">Jeremy Kepner</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gadepally:Vijay.html">Vijay Gadepally</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Milechin:Lauren.html">Lauren Milechin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Samsi:Siddharth.html">Siddharth Samsi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Arcand:William.html">William Arcand</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bestor:David.html">David Bestor</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bergeron:William.html">William Bergeron</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Byun:Chansup.html">Chansup Byun</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hubbell:Matthew.html">Matthew Hubbell</a>, Micheal Houle, Micheal Jones, Anne Klein, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Michaleas:Peter.html">Peter Michaleas</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mullen:Julie.html">Julie Mullen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Prout:Andrew.html">Andrew Prout</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rosa:Antonio.html">Antonio Rosa</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yee:Charles.html">Charles Yee</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Reuther:Albert.html">Albert Reuther</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.00846">PDF</a><br/><b>Abstract: </b>Analyzing large scale networks requires high performance streaming updates of
graph representations of these data. Associative arrays are mathematical
objects combining properties of spreadsheets, databases, matrices, and graphs,
and are well-suited for representing and analyzing streaming network data. The
Dynamic Distributed Dimensional Data Model (D4M) library implements associative
arrays in a variety of languages (Python, Julia, and Matlab/Octave) and
provides a lightweight in-memory database. Associative arrays are designed for
block updates. Streaming updates to a large associative array requires a
hierarchical implementation to optimize the performance of the memory
hierarchy. Running 34,000 instances of a hierarchical D4M associative arrays on
1,100 server nodes on the MIT SuperCloud achieved a sustained update rate of
1,900,000,000 updates per second. This capability allows the MIT SuperCloud to
analyze extremely large streaming network data sets.
</p></div>
    </summary>
    <updated>2019-02-05T02:33:05Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-05T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.00804</id>
    <link href="http://arxiv.org/abs/1902.00804" rel="alternate" type="text/html"/>
    <title>Itemsets for Real-valued Datasets</title>
    <feedworld_mtime>1549324800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tatti:Nikolaj.html">Nikolaj Tatti</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.00804">PDF</a><br/><b>Abstract: </b>Pattern mining is one of the most well-studied subfields in exploratory data
analysis. While there is a significant amount of literature on how to discover
and rank itemsets efficiently from binary data, there is surprisingly little
research done in mining patterns from real-valued data. In this paper we
propose a family of quality scores for real-valued itemsets. We approach the
problem by considering casting the dataset into a binary data and computing the
support from this data. This naive approach requires us to select thresholds.
To remedy this, instead of selecting one set of thresholds, we treat thresholds
as random variables and compute the average support. We show that we can
compute this support efficiently, and we also introduce two normalisations,
namely comparing the support against the independence assumption and, more
generally, against the partition assumption. Our experimental evaluation
demonstrates that we can discover statistically significant patterns
efficiently.
</p></div>
    </summary>
    <updated>2019-02-05T02:32:47Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-05T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.00732</id>
    <link href="http://arxiv.org/abs/1902.00732" rel="alternate" type="text/html"/>
    <title>Scheduling with Predictions and the Price of Misprediction</title>
    <feedworld_mtime>1549324800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mitzenmacher:Michael.html">Michael Mitzenmacher</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.00732">PDF</a><br/><b>Abstract: </b>In many traditional job scheduling settings, it is assumed that one knows the
time it will take for a job to complete service. In such cases, strategies such
as shortest job first can be used to improve performance in terms of measures
such as the average time a job waits in the system. We consider the setting
where the service time is not known, but is predicted by for example a machine
learning algorithm. Our main result is the derivation, under natural
assumptions, of formulae for the performance of several strategies for queueing
systems that use predictions for service times in order to schedule jobs. As
part of our analysis, we suggest the framework of the "price of misprediction,"
which offers a measure of the cost of using predicted information.
</p></div>
    </summary>
    <updated>2019-02-05T02:28:23Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-05T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.00633</id>
    <link href="http://arxiv.org/abs/1902.00633" rel="alternate" type="text/html"/>
    <title>Computational Complexity of Queries Based on Itemsets</title>
    <feedworld_mtime>1549324800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tatti:Nikolaj.html">Nikolaj Tatti</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.00633">PDF</a><br/><b>Abstract: </b>We investigate determining the exact bounds of the frequencies of
conjunctions based on frequent sets. Our scenario is an important special case
of some general probabilistic logic problems that are known to be intractable.
We show that despite the limitations our problems are also intractable, namely,
we show that checking whether the maximal consistent frequency of a query is
larger than a given threshold is NP-complete and that evaluating the Maximum
Entropy estimate of a query is PP-hard. We also prove that checking consistency
is NP-complete.
</p></div>
    </summary>
    <updated>2019-02-05T02:25:13Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-02-05T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4122</id>
    <link href="https://www.scottaaronson.com/blog/?p=4122" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4122#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4122" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Sabineblogging</title>
    <summary xml:lang="en-US">I’ve of course been following the recent public debate about whether to build a circular collider to succeed the LHC—notably including Sabine Hossenfelder’s New York Times column arguing that we shouldn’t.  (See also the responses by Jeremy Bernstein and Lisa Randall, and the discussion on Peter Woit’s blog, and Daniel Harlow’s Facebook thread, and this Vox […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>I’ve of course been following the recent public debate about whether to build a circular collider to succeed the LHC—notably including <a href="https://www.nytimes.com/2019/01/23/opinion/particle-physics-large-hadron-collider.html">Sabine Hossenfelder’s <em>New York Times</em> column</a> arguing that we shouldn’t.  (See also the <a href="https://www.nytimes.com/2019/02/01/opinion/letters/physics-research-collider-cern.html">responses</a> by Jeremy Bernstein and Lisa Randall, and the <a href="http://www.math.columbia.edu/~woit/wordpress/?p=10768">discussion on Peter Woit’s blog</a>, and <a href="https://www.facebook.com/daniel.harlow.31/posts/10104284984149212">Daniel Harlow’s Facebook thread</a>, and <a href="https://www.vox.com/future-perfect/2019/1/22/18192281/cern-large-hadron-collider-future-circular-collider-physics">this <em>Vox</em> piece</a> by Kelsey Piper.)  Let me blog about this as a way of cracking my knuckles or tuning my violin, just getting back into blog-shape after a long hiatus for travel and family and the beginning of the semester.</p>
<p>Regardless of whether this opinion is widely shared among my colleagues, I like Sabine.  I’ve often found her <a href="http://backreaction.blogspot.com/">blogging</a> funny and insightful, and I wish more non-Lubos physicists would articulate their thoughts for the public the way she does, rather than just standing on the sidelines and criticizing the ones who do. I find it unfortunate that some of the replies to Sabine’s arguments dwelled on her competence and “standing” in physics (even if we set aside—as we should—Lubos’s misogynistic rants, whose predictability could be used to calibrate atomic clocks). It’s like this: if high-energy physics <em>had</em> reached a pathological state of building bigger and bigger colliders for no good reason, then we’d <em>expect</em> that it would take a semi-outsider to say so in public, so then it wouldn’t be a further surprise to find precisely such a person doing it.</p>
<p>Not for the first time, though, I find myself coming down on the opposite side as Sabine. Basically, <em>if</em> civilization could get its act together and find the money, I think it would be pretty awesome to build a new collider to push forward the energy frontier in our understanding of the universe.<br/><!--StartFragment--></p>


<p>Note that I’m not making the much stronger claim that this is the <em>best possible</em> use of $20 billion for science.  Plausibly a thousand $20-million projects could be found that would advance our understanding of reality by more than a new collider would.  But it’s also important to realize that that’s not the question at stake here.  When, for example, the US Congress cancelled the <a href="https://en.wikipedia.org/wiki/Superconducting_Super_Collider">Superconducting Supercollider</a> midway through construction—partly, it’s believed, on the basis of opposition from eminent physicists in other subfields, who argued that they could do equally important science for much cheaper—none of the SSC budget, as in 0% of it, ever <em>did</em> end up redirected to those other subfields.  In practice, then, the question of “whether a new collider is worth it” is probably best considered in absolute terms, rather than relative to other science projects.</p>



<p>What I found most puzzling, in Sabine’s writings on this subject, was the leap in logic from</p>



<ol><li>many theorists expected that superpartners, or other new particles besides the Higgs boson, had a good chance of being discovered at the LHC, based on statistical arguments about “natural” parameter values, and</li><li>the basic soundness of naturalness arguments was always open to doubt, and indeed the LHC results to date offer zero support for them, and</li><li>many of the same theorists now want an even bigger collider, and continue to expect new particles to be found, and haven’t sufficiently reckoned with their previous failed predictions, to …</li><li><strong>therefore</strong> we shouldn’t build the bigger collider.</li></ol>



<p>How do we get from 1-3 to 4: is the idea that we should <em>punish</em> the errant theorists, by withholding an experiment that they want, in order to deter future wrong predictions?  After step 3, it seems to me that Sabine could equally well have gone to: and therefore it’s all the more important that we <em>do</em> build a new collider, in order to establish all the more conclusively that there’s just an energy desert up there—and that I, Sabine, was right to emphasize that possibility, and those other theorists were wrong to downplay it!</p>



<p>Like, I gather that there are independently motivated scenarios where there <em>would</em> be only the Higgs at the LHC scale, and then new stuff at the next energy scale beyond it.  And as an unqualified outsider who enjoys talking to friends in particle physics and binge-reading about it, I’d find it hard to assign the totality of those scenarios less than ~20% credence or more than ~80%—certainly if the actual experts don’t either.</p>



<p>And crucially, it’s not as if <em>raising the collision energy</em> is just one arbitrary direction in which to look for new fundamental physics, among a hundred a-priori equally promising directions.  Basically, there’s raising the collision energy and then there’s everything else.  By raising the energy, you’re not testing one specific idea for physics beyond Standard Model, but a hundred or a thousand ideas in one swoop.</p>



<p>The situation reminds me a little of the quantum computing skeptics who say: scalable QC can never work, in practice and probably even in principle; the mainstream physics community only <em>thinks</em> it can work because of groupthink and hype; therefore, we shouldn’t waste more funds trying to make it work.  With the sole, very interesting exception of Gil Kalai, none of the skeptics ever seem to draw what strikes me as an equally logical conclusion: whoa, let’s go <em>full speed ahead</em> with trying to build a scalable QC, because there’s an epochal revolution in physics to be had here—once the experimenters finally see that I was right and the mainstream was wrong, and they start to unravel the reasons why!</p>



<p>Of course, $20 billion is a significant chunk of change, by the standards of science even if not by the standards of random government wastages (like our recent $11 billion shutdown).  And ultimately, decisions do need to be made about which experiments are most interesting to pursue with limited resources.  And if a future circular collider <em>were</em> built, and if it indeed just found a desert, I think the balance would tilt pretty strongly toward Sabine’s position—that is, toward declining to build an even bigger and more expensive collider after that.  If the Patriots drearily won every Superbowl 13-3, year after year after year, eventually no one would watch anymore and the Superbowl would get cancelled (well, maybe that will happen for other reasons…).</p>



<p>But it’s worth remembering that—correct me if I’m wrong—so far there have been <em>no</em> cases in the history of particle physics of massively expanding the energy frontier and finding absolutely nothing new there (i.e., nothing that at least conveyed multiple bits of information, as the Higgs mass did).  And while my opinion should count for less than a neutrino mass, just thinking it over a-priori, I keep coming back to the question: before we close the energy frontier for good, shouldn’t there have been at least <em>one</em> unmitigated null result, rather than zero?</p></div>
    </content>
    <updated>2019-02-04T12:30:47Z</updated>
    <published>2019-02-04T12:30:47Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Procrastination"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2019-02-04T15:45:24Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-9219479121065296157</id>
    <link href="https://blog.computationalcomplexity.org/feeds/9219479121065296157/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/02/dont-know-football-but-still-want-bet.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/9219479121065296157" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/9219479121065296157" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/02/dont-know-football-but-still-want-bet.html" rel="alternate" type="text/html"/>
    <title>Don't know Football but still want bet on the Superb Owl?</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div>
(Superb Owl is not a typo. I've heard (and it could be wrong) that the  NFL guards their copyright so you can't even say `Buy Beer here for the YOU KNOW WHATl' but instead `Buy Beer here for the big game''. Stephen Colbert a long time ago go around this by calling the game Superb Owl.)</div>
<div>
<br/></div>
<div>
<br/></div>
<div>
If I knew more about football  I might place a bet related to the Superb Owl. What kind of bets can I place?</div>
<div>
<br/></div>
<div>
1) Bet the point spread: Last time I looked the Patriots were a 2.5 point favorite. So either bet that Patriots will win by more than  2.5 or the Rams will lose by less than 2.5 or just win.</div>
<div>
<br/></div>
<div>
2) Over-Under: bet that either the total score will be over 56.5 or under it.</div>
<div>
<br/></div>
<div>
 There are prop-bets-- bets that are ABOUT the game but not related to the final score.</div>
<div>
<br/></div>
<div>
I've seen the following</div>
<div>
<br/></div>
<div>
1) Tom Brady will retire after the game. I wonder if Tom Brady (or a friend of his) could bet on this one knowing some inside information. Not i any state in America, but off-shore...</div>
<div>
<br/></div>
<div>
2) Jamie White will score the first touchdown.</div>
<div>
<br/></div>
<div>
3) Will Gladys Knight's   National Anthem go longer than 1 minute, 50 seconds (it was 1:47 seconds a few days ago but it shifted to 1:50).</div>
<div>
<br/></div>
<div>
Amazingly, this last one is what Josh Hermsmeyer (on Nate Silver's Webpage)  chose to focus on: <a href="https://fivethirtyeight.com/features/the-super-bowls-best-matchup-is-gladys-knight-vs-the-clock/">here</a>. Note that:</div>
<div>
<br/></div>
<div>
1) The people who picked 1 minute 50 seconds as the over-under probably didn't do much research. They might have set it to get the same number of people on both sides, which may explain the shift; however, I can't imagine this bet got that much action. Then again, I'm not that imaginative.</div>
<div>
<br/></div>
<div>
2) Josh DID. He did an  analysis of what is likely (he thinks it will go longer)</div>
<div>
<br/></div>
<div>
3) So- can Josh bet on this an clean up? Can you bet on this and clean up?</div>
<div>
<br/></div>
<div>
4) There is an issue: Some kinds of bets are legal in some places (betting who will WIN or beat a point-spread is legal in Las Vegas-- the Supreme court struck down a federal anti-betting rule). Some prop bets are legal. The Gladys Knight one is not.  Why not? Someone could have inside information! Gladys Knight would!</div>
<div>
<br/></div>
<div>
So you CAN bet  Rams+2.5 beats the Patriots LEGALLY</div>
<div>
<br/></div>
<div>
but to bet Gladys Knight's National Anthem will take more than 1 minute 50 seconds you might need to use  BITCOIN, and go to some offshore account. Too much sugar for a <a href="https://en.bitcoin.it/wiki/Satoshi_(unit)">satoshi</a>.</div>
<div>
<br/></div>
<div>
5) There is another issue- there is no such thing as a sure thing (I blogged on that <a href="https://blog.computationalcomplexity.org/2008/02/there-is-no-such-thing-as-sure-thing.html">here</a>). People who bet on sports for a living (I know one such person and will blog about that later) play THE LONG GAME. So to say</div>
<div>
<br/></div>
<div>
          <i> I will withdraw X dollars (for large X)  from my investments and bet it on </i></div>
<div>
<i>          Gladys Knight's</i><i>  Star Spangled Banner to go more than 1 minute 50 seconds</i></div>
<div>
<i>          because its a sure thing</i></div>
<div>
<br/></div>
<div>
Would be... a very bad idea.<br/>
<br/>
The above was all written the day before Superb Owl. Now its the next day and Gladys Knight has sung the National Anthem. So who won the Gladys Knight Bowl? The answer is not as straightforward as it could be, see <a href="https://www.usatoday.com/story/sports/nfl/super-bowl/2019/02/03/super-bowl-2019-gladys-knight-causes-prop-bet-controversy-anthem/2764778002/">here</a>.</div>
<div>
<br/></div></div>
    </content>
    <updated>2019-02-04T02:36:00Z</updated>
    <published>2019-02-04T02:36:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>https://plus.google.com/101693130490639305932</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-02-05T10:55:52Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.00490</id>
    <link href="http://arxiv.org/abs/1902.00490" rel="alternate" type="text/html"/>
    <title>StaTIX - Statistical Type Inference on Linked Data</title>
    <feedworld_mtime>1549238400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lutov:Artem.html">Artem Lutov</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Roshankish:Soheil.html">Soheil Roshankish</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Khayati:Mourad.html">Mourad Khayati</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cudr=eacute==Mauroux:Philippe.html">Philippe Cudré-Mauroux</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.00490">PDF</a><br/><b>Abstract: </b>Large knowledge bases typically contain data adhering to various schemas with
incomplete and/or noisy type information. This seriously complicates further
integration and post-processing efforts, as type information is crucial in
correctly handling the data. In this paper, we introduce a novel statistical
type inference method, called StaTIX, to effectively infer instance types in
Linked Data sets in a fully unsupervised manner. Our inference technique
leverages a new hierarchical clustering algorithm that is robust, highly
effective, and scalable. We introduce a novel approach to reduce the processing
complexity of the similarity matrix specifying the relations between various
instances in the knowledge base. This approach speeds up the inference process
while also improving the correctness of the inferred types due to the noise
attenuation in the input data. We further optimize the clustering process by
introducing a dedicated hash function that speeds up the inference process by
orders of magnitude without negatively affecting its accuracy. Finally, we
describe a new technique to identify representative clusters from the
multi-scale output of our clustering algorithm to further improve the accuracy
of the inferred types. We empirically evaluate our approach on several
real-world datasets and compare it to the state of the art. Our results show
that StaTIX is more efficient than existing methods (both in terms of speed and
memory consumption) as well as more effective. StaTIX reduces the F1-score
error of the predicted types by about 40% on average compared to the state of
the art and improves the execution time by orders of magnitude.
</p></div>
    </summary>
    <updated>2019-02-04T23:48:39Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.00488</id>
    <link href="http://arxiv.org/abs/1902.00488" rel="alternate" type="text/html"/>
    <title>Grid Graph Reachability</title>
    <feedworld_mtime>1549238400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jain:Rahul.html">Rahul Jain</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tewari:Raghunath.html">Raghunath Tewari</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.00488">PDF</a><br/><b>Abstract: </b>The reachability problem is to determine if there exists a path from one
vertex to the other in a graph. Grid graphs are the class of graphs where
vertices are present on the lattice points of a two-dimensional grid, and an
edge can occur between a vertex and its immediate horizontal or vertical
neighbor only.
</p>
<p>Asano et al. presented the first simultaneous time space bound for
reachability in grid graphs by presenting an algorithm that solves the problem
in polynomial time and $O(n^{1/2 + \epsilon})$ space. In 2018, the space bound
was improved to $\tilde{O}(n^{1/3})$ by Ashida and Nakagawa. In this paper, we
further improve the space bound and present a polynomial time algorithm that
uses $O(n^{1/4 + \epsilon})$ space to solve reachability in a grid graph with
$n$ vertices.
</p></div>
    </summary>
    <updated>2019-02-04T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.00340</id>
    <link href="http://arxiv.org/abs/1902.00340" rel="alternate" type="text/html"/>
    <title>Decentralized Stochastic Optimization and Gossip Algorithms with Compressed Communication</title>
    <feedworld_mtime>1549238400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Koloskova:Anastasia.html">Anastasia Koloskova</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Stich:Sebastian_U=.html">Sebastian U. Stich</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jaggi:Martin.html">Martin Jaggi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.00340">PDF</a><br/><b>Abstract: </b>We consider decentralized stochastic optimization with the objective function
(e.g. data samples for machine learning task) being distributed over $n$
machines that can only communicate to their neighbors on a fixed communication
graph. To reduce the communication bottleneck, the nodes compress (e.g.
quantize or sparsify) their model updates. We cover both unbiased and biased
compression operators with quality denoted by $\omega \leq 1$ ($\omega=1$
meaning no compression). We (i) propose a novel gossip-based stochastic
gradient descent algorithm, CHOCO-SGD, that converges at rate
$\mathcal{O}\left(1/(nT) + 1/(T \delta^2 \omega)^2\right)$ for strongly convex
objectives, where $T$ denotes the number of iterations and $\delta$ the
eigengap of the connectivity matrix. Despite compression quality and network
connectivity affecting the higher order terms, the first term in the rate,
$\mathcal{O}(1/(nT))$, is the same as for the centralized baseline with exact
communication. We (ii) present a novel gossip algorithm, CHOCO-GOSSIP, for the
average consensus problem that converges in time
$\mathcal{O}(1/(\delta^2\omega) \log (1/\epsilon))$ for accuracy $\epsilon &gt;
0$. This is (up to our knowledge) the first gossip algorithm that supports
arbitrary compressed messages for $\omega &gt; 0$ and still exhibits linear
convergence. We (iii) show in experiments that both of our algorithms do
outperform the respective state-of-the-art baselines and CHOCO-SGD can reduce
communication by at least two orders of magnitudes.
</p></div>
    </summary>
    <updated>2019-02-04T23:47:55Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.00257</id>
    <link href="http://arxiv.org/abs/1902.00257" rel="alternate" type="text/html"/>
    <title>An efficient sorting algorithm - Ultimate Heapsort(UHS)</title>
    <feedworld_mtime>1549238400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Feiyang.html">Feiyang Chen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Nan.html">Nan Chen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mao:Hanyang.html">Hanyang Mao</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hu:Hanlin.html">Hanlin Hu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.00257">PDF</a><br/><b>Abstract: </b>Motivated by the development of computer theory, the sorting algorithm is
emerging in an endless stream. Inspired by decrease and conquer method, we
propose a brand new sorting algorithmUltimately Heapsort. The algorithm
consists of two parts: building a heap and adjusting a heap. Through the
asymptotic analysis and experimental analysis of the algorithm, the time
complexity of our algorithm can reach O(nlogn) under any condition. Moreover,
its space complexity is only O(1). It can be seen that our algorithm is
superior to all previous algorithms.
</p></div>
    </summary>
    <updated>2019-02-04T23:45:11Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.00256</id>
    <link href="http://arxiv.org/abs/1902.00256" rel="alternate" type="text/html"/>
    <title>The Application of Bipartite Matching in Assignment Problem</title>
    <feedworld_mtime>1549238400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Feiyang.html">Feiyang Chen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Nan.html">Nan Chen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mao:Hanyang.html">Hanyang Mao</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hu:Hanlin.html">Hanlin Hu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.00256">PDF</a><br/><b>Abstract: </b>The optimized assignment of staff is of great significance for improving the
production efficiency of the society. For specific tasks, the key to optimizing
staffing is personnel scheduling. The assignment problem is classical in the
personnel scheduling. In this paper, we abstract it as an optimal matching
model of a bipartite graph and propose the Ultimate Hungarian Algorithm(UHA).
By introducing feasible labels, iteratively searching for the augmenting path
to get the optimal match(maximum-weight matching). And we compare the algorithm
with the traditional brute force method, then conclude that our algorithm has
lower time complexity and can solve the problems of maximum-weight matching
more effectively.
</p></div>
    </summary>
    <updated>2019-02-04T23:44:36Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.00247</id>
    <link href="http://arxiv.org/abs/1902.00247" rel="alternate" type="text/html"/>
    <title>Sharp Analysis for Nonconvex SGD Escaping from Saddle Points</title>
    <feedworld_mtime>1549238400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fang:Cong.html">Cong Fang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lin:Zhouchen.html">Zhouchen Lin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Tong.html">Tong Zhang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.00247">PDF</a><br/><b>Abstract: </b>In this paper, we prove that the simplest Stochastic Gradient Descent (SGD)
algorithm is able to efficiently escape from saddle points and find an
$(\epsilon, O(\epsilon^{0.5}))$-approximate second-order stationary point in
$\tilde{O}(\epsilon^{-3.5})$ stochastic gradient computations for generic
nonconvex optimization problems, under both gradient-Lipschitz and
Hessian-Lipschitz assumptions. This unexpected result subverts the classical
belief that SGD requires at least $O(\epsilon^{-4})$ stochastic gradient
computations for obtaining an $(\epsilon, O(\epsilon ^{0.5}))$-approximate
second-order stationary point. Such SGD rate matches, up to a polylogarithmic
factor of problem-dependent parameters, the rate of most accelerated nonconvex
stochastic optimization algorithms that adopt additional techniques, such as
Nesterov's momentum acceleration, negative curvature search, as well as
quadratic and cubic regularization tricks. Our novel analysis gives new
insights into nonconvex SGD and can be potentially generalized to a broad class
of stochastic optimization algorithms.
</p></div>
    </summary>
    <updated>2019-02-04T23:20:55Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-02-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.00246</id>
    <link href="http://arxiv.org/abs/1902.00246" rel="alternate" type="text/html"/>
    <title>Counting of Teams in First-Order Team Logics</title>
    <feedworld_mtime>1549238400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Haak:Anselm.html">Anselm Haak</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kontinen:Juha.html">Juha Kontinen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/M=uuml=ller:Fabian.html">Fabian Müller</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vollmer:Heribert.html">Heribert Vollmer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yang:Fan.html">Fan Yang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.00246">PDF</a><br/><b>Abstract: </b>We study descriptive complexity of counting complexity classes in the range
from $\#$P to $\#\cdot$NP. A corollary of Fagin's characterization of NP by
existential second-order logic is that $\#$P can be logically described as the
class of functions counting satisfying assignments to free relation variables
in first-order formulae. In this paper we extend this study to classes beyond
$\#$P and extensions of first-order logic with team semantics. These team-based
logics are closely related to existential second-order logic and its fragments,
hence our results also shed light on the complexity of counting for extensions
of FO in Tarski's semantics. Our results show that the class $\#\cdot$NP can be
logically characterized by independence logic and existential second-order
logic, whereas dependence logic and inclusion logic give rise to subclasses of
$\#\cdot$NP and $\#$P , respectively. Our main technical result shows that the
problem of counting satisfying assignments for monotone Boolean
$\Sigma_1$-formulae is $\#\cdot$NP-complete as well as complete for the
function class generated by dependence logic.
</p></div>
    </summary>
    <updated>2019-02-04T23:25:30Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-02-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.00219</id>
    <link href="http://arxiv.org/abs/1902.00219" rel="alternate" type="text/html"/>
    <title>A note on self-improving sorting with hidden partitions</title>
    <feedworld_mtime>1549238400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cheng:Siu=Wing.html">Siu-Wing Cheng</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chiu:Man=Kwun.html">Man-Kwun Chiu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jin:Kai.html">Kai Jin</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.00219">PDF</a><br/><b>Abstract: </b>We study self-improving sorting with hidden partitions. Our result is an
optimal algorithm which runs in expected time O(H(\pi(I)) + n), where I is the
given input which contains n elements to be sorted, \pi(I) is the output which
are the ranks of all element in I, and H(\pi(I)) denotes the entropy of the
output.
</p></div>
    </summary>
    <updated>2019-02-04T23:49:57Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-02-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.00216</id>
    <link href="http://arxiv.org/abs/1902.00216" rel="alternate" type="text/html"/>
    <title>Linear-size Suffix Tries for Parameterized Strings</title>
    <feedworld_mtime>1549238400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nakashima:Katsuhito.html">Katsuhito Nakashima</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hendrian:Diptarama.html">Diptarama Hendrian</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yoshinaka:Ryo.html">Ryo Yoshinaka</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shinohara:Ayumi.html">Ayumi Shinohara</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.00216">PDF</a><br/><b>Abstract: </b>In this paper, we propose a new indexing structure for parameterized strings,
called parameterized linear-size suffix tries, by generalizing linear-size
suffix tries for ordinary strings. Two parameterized strings are said to match
if there is a bijection between symbols that makes the two coincide.
Parameterized linear-size suffix tries are applicable to the parameterized
pattern matching problem, which is to decide whether the input text has a
substring that matches the input pattern. The size of our proposed structure is
linear in the text size, with which our algorithm solves the problem in linear
time in the pattern size. Our proposed data structure can be seen as a
compacted version of a parameterized suffix trie and an alternative of a
parameterized suffix tree.
</p></div>
    </summary>
    <updated>2019-02-04T23:46:28Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.00196</id>
    <link href="http://arxiv.org/abs/1902.00196" rel="alternate" type="text/html"/>
    <title>Finite semantics of polymorphism, complexity and the power of type fixpoints</title>
    <feedworld_mtime>1549238400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Lê Thành Dũng Nguyên, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pistone:Paolo.html">Paolo Pistone</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Seiller:Thomas.html">Thomas Seiller</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Falco:Lorenzo_Tortora_de.html">Lorenzo Tortora de Falco</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.00196">PDF</a><br/><b>Abstract: </b>Many applications of denotational semantics, such as higher-order model
checking or the complexity of normalization, rely on finite semantics for
monomorphic type systems. We present two constructions of finite semantics for
second-order Multiplicative-Additive Linear Logic (MALL2) and study their
properties. We apply this to understand the gap in expressive power between
MALL2 and its extension with type fixpoints, and to obtain an implicit
characterization of regular languages in Elementary Linear Logic. Furthermore,
some semantic results established here lay the groundwork for a sequel paper
proposing a new approach to sub-polynomial implicit complexity.
</p></div>
    </summary>
    <updated>2019-02-04T23:44:05Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-02-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.00179</id>
    <link href="http://arxiv.org/abs/1902.00179" rel="alternate" type="text/html"/>
    <title>Compressing Gradient Optimizers via Count-Sketches</title>
    <feedworld_mtime>1549238400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Spring:Ryan.html">Ryan Spring</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kyrillidis:Anastasios.html">Anastasios Kyrillidis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mohan:Vijai.html">Vijai Mohan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shrivastava:Anshumali.html">Anshumali Shrivastava</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.00179">PDF</a><br/><b>Abstract: </b>Many popular first-order optimization methods (e.g., Momentum, AdaGrad, Adam)
accelerate the convergence rate of deep learning models. However, these
algorithms require auxiliary parameters, which cost additional memory
proportional to the number of parameters in the model. The problem is becoming
more severe as deep learning models continue to grow larger in order to learn
from complex, large-scale datasets. Our proposed solution is to maintain a
linear sketch to compress the auxiliary variables. We demonstrate that our
technique has the same performance as the full-sized baseline, while using
significantly less space for the auxiliary variables. Theoretically, we prove
that count-sketch optimization maintains the SGD convergence rate, while
gracefully reducing memory usage for large-models. On the large-scale 1-Billion
Word dataset, we save 25% of the memory used during training (8.6 GB instead of
11.7 GB) by compressing the Adam optimizer in the Embedding and Softmax layers
with negligible accuracy and performance loss.
</p></div>
    </summary>
    <updated>2019-02-04T23:45:46Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/014</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/014" rel="alternate" type="text/html"/>
    <title>TR19-014 |  A New Proof of Nonsignalling Multiprover Parallel Repetition Theorem | 

	Himanshu Tyagi, 

	Shun Watanabe</title>
    <summary>We present an information theoretic proof of the nonsignalling multiprover parallel repetition theorem, a recent extension of its two-prover variant that underlies many hardness of approximation results. The original proofs used de Finetti type decomposition for strategies. We present a new proof that is based on a technique we introduced recently for proving strong converse results in multiuser information theory and entails a change of measure after replacing hard information constraints with soft ones.</summary>
    <updated>2019-02-03T12:39:00Z</updated>
    <published>2019-02-03T12:39:00Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-02-05T12:20:46Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=15616</id>
    <link href="https://rjlipton.wordpress.com/2019/02/03/a-strange-horizon/" rel="alternate" type="text/html"/>
    <title>A Strange Horizon</title>
    <summary>Data science of many things including citations Amazon India source Paul Allison is an emeritus professor of sociology at the University of Pennsylvania and the founder and president of the company Statistical Horizons. They provides short courses and seminars for statistical training. Today we have a short seminar on statistics and horizons of effectiveness. Our […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><font color="#0044cc"><br/>
<em>Data science of many things including citations</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2019/02/03/a-strange-horizon/allisonamazon/" rel="attachment wp-att-15619"><img alt="" class="alignright wp-image-15619" height="200" src="https://rjlipton.files.wordpress.com/2019/02/allisonamazon.jpg?w=133&amp;h=200" width="133"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Amazon India <a href="https://www.amazon.in/l/B001H6KWN6">source</a></font></td>
</tr>
</tbody>
</table>
<p>
Paul Allison is an emeritus professor of sociology at the University of Pennsylvania and the founder and president of the company <a href="https://statisticalhorizons.com/">Statistical Horizons</a>. They provides short courses and seminars for statistical training. </p>
<p>
Today we have a short seminar on statistics and horizons of effectiveness. </p>
<p>
Our first topic is about citations. Did we say citations? What are we in research more interested in than citations? Allison co-wrote a paper on a <a href="https://en.wikipedia.org/wiki/Lotka's_law">“law”</a> claimed by Alfred Lotka about how the number of citations behaves. Full details in a moment, but two upshots are: </p>
<ul>
<li>
Over half of the papers are contributed by a few highly prolific authors. <p/>
</li><li>
One-shot authors are roughly <img alt="{61\%}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B61%5C%25%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{61\%}"/> of the population but account for only a tiny proportion of the literature.
</li></ul>
<p>
</p><p/><h2> Allison’s Paper </h2><p/>
<p>Allison co-wrote his <a href="https://statisticalhorizons.com/wp-content/uploads/AllisonEtAl.SSS76.pdf">paper</a>, “Lotka’s Law: A Problem in Its Interpretation and Application,” with Derek de Solla Price, Belver Griffith, Michael Moravcsik, and John Stewart in 1976. Lotka’s law, which is related to George Zipf’s famous <a href="https://en.wikipedia.org/wiki/Zipf's_law">law</a>, alleges that over any time period in any scientific or literary field, the number <img alt="{a(n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a(n)}"/> of authors with <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> contributions obeys </p>
<p align="center"><img alt="\displaystyle  a(n) = \frac{C}{n^2}, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++a%28n%29+%3D+%5Cfrac%7BC%7D%7Bn%5E2%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  a(n) = \frac{C}{n^2}, "/></p>
<p>where <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> is independent of <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>. This suggests a maximum of <img alt="{n_{max} = \sqrt{C}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn_%7Bmax%7D+%3D+%5Csqrt%7BC%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n_{max} = \sqrt{C}}"/> on the range of <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>, since higher <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> give <img alt="{a(n) &lt; 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%28n%29+%3C+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a(n) &lt; 1}"/>, but there is also a probabilistic interpretation: The law says that the total number of papers at <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> is <img alt="{C/n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%2Fn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C/n}"/>, and that gives a positive constant expectation even when <img alt="{n_{max}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn_%7Bmax%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n_{max}}"/> varies as <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/>. Both cases yield that out of the total number <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> of papers, which has <img alt="{T = \Theta(C\log(C))}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT+%3D+%5CTheta%28C%5Clog%28C%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T = \Theta(C\log(C))}"/>, over half of them are contributed by a vanishing percentage of highly prolific authors. Meanwhile, one-shot authors are roughly <img alt="{6/\pi^2 \approx 61\%}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B6%2F%5Cpi%5E2+%5Capprox+61%5C%25%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{6/\pi^2 \approx 61\%}"/> of the population but account for only a <img alt="{1/\log(T)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%2F%5Clog%28T%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1/\log(T)}"/> proportion of the literature.</p>
<p>
However, the paper also remarks on a third case, namely making <img alt="{n_{max}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn_%7Bmax%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n_{max}}"/> a fixed constant—since human time is finite in any field. This puts a sharper <em>horizon</em> on Lotka’s Law and changes the inferences made as the horizon is approached. The paper shows how the <img alt="{n_{max}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn_%7Bmax%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n_{max}}"/> factor intrudes on other inferences they would like to draw, even between the former two cases. And never mind <a href="http://www.revistadestatistica.ro/index.php/the-power-of-lotkas-law-through-the-eyes-of-r/">more</a>–<a href="https://rjlipton.wordpress.com/feed/www.fosareh.net/fa/files/pdf/Osareh-mostafavi-collnet[1].doc">recent</a> <a href="http://www.collnet.de/Berlin-2008/LarsenWIS2008llc.pdf">evidence</a> of <a href="http://www.librarywaves.com/index.php/lw/article/download/51/45/">breakdowns</a> in Lotka’s law. </p>
<p>
</p><p/><h2> Horizons </h2><p/>
<p/><p>
We have mentioned de Solla Price <a href="https://rjlipton.wordpress.com/2012/09/29/why-we-lose-sleep-some-nights/">before</a> in regard to his founding <a href="https://en.wikipedia.org/wiki/Scientometrics">scientometrics</a>. In practice this is mainly concerned with citation analysis and other productivity metrics, but its widely-quoted definition, “the science of measuring and analyzing science,” strikes us as broader. We feel there should be a component for measuring limitations of the effectiveness of the science one is practicing.</p>
<p>
Now of course in statistics there are longstanding measures of statistical <a href="https://en.wikipedia.org/wiki/Power_(statistics)">power</a> and experiment acuity and of <em>noise</em> in general. Nevertheless, the cascading “(non-)reproducibility crisis” argues that more needs to be addressed. The development of software tools to counter “<a href="https://en.wikipedia.org/wiki/Data_dredging">p-hacking</a>” exemplifies a new layer of scientific modeling to do so—which could be called introspective modeling. </p>
<p>
I will exemplify with two “horizons” that are apparent in my own statistical chess research. One involves estimating the Elo rating of “perfect play.” The other involves the level of skill at which my data may cease to be effective. The former has captured popular imagination—it was among the first questions posed to me by Judit Polgar in a broadcast during the 2016 world championship match—but the latter is my concern in practice. We will see that these may be the same horizon, approached either by looking down from the stars or up from the road. </p>
<p>
I am not the first to do this kind of work or face the issue of its resolving power. Matej Guid, Artiz Perez, and Ivan Bratko made it the sole topic of a 2008 followup <a href="https://pdfs.semanticscholar.org/fcdc/9fb1e88c40de12ad9481f0d580f803bc1582.pdf">paper</a> to their 2006 <a href="https://en.chessbase.com/news/2006/world_champions2006.pdf">study</a> of all games in world championship matches. But their indicators strike me as weak. Most simply, they do not try to estimate where their horizon <em>is</em>, just argue that their results are not wholly beyond it. We will try to do more—but speculatively. The first step is rock-solid—it is a big surprise I found last month.</p>
<p>
</p><p/><h2> More Data, More Resolution </h2><p/>
<p/><p>
I use strong chess programs to take two main kinds of data. My full model uses programs in an analysis mode that evaluates all available moves to the same degree of thoroughness and takes roughly 4–6 hours per game. My quicker “screening” tests use programs in their normal playing mode, which gives full shrift only to what’s considered the best move, but shaves the time down to 10–15 minutes. For my AAAI 2011 <a href="https://cse.buffalo.edu/~regan/papers/pdf/ReHa11c.pdf">paper</a> with Guy Haworth, I used over 400,000 positions from 5,700 games at rating levels from Elo 1600 to 2700 only, all run on my office and home PCs. Below Elo 2000 the available data was so scant that noise is evident in the paper’s table.</p>
<p>
Since then, many more games by lower-rated players are being archived—much thanks to the greater availability of chessboards that automatically record moves in the standard <a href="https://en.wikipedia.org/wiki/Portable_Game_Notation">PGN</a> format, and to an upswell in tournaments, for youth in particular. Last year, thanks to the great free bandwidth granted by my university’s Center for Computational Research (<a href="http://www.buffalo.edu/ccr.html">CCR</a>), I took data in the quicker mode from over 10,600,000 moves from just over 400,000 game-sides (counting White and Black separately) in every tournament compiled by <a href="https://en.chessbase.com/">ChessBase</a> as well as some posted only by The Week in Chess (<a href="http://theweekinchess.com/">TWIC</a>) or provided directly by the World Chess Federation (FIDE). My two main test quantities are:</p>
<ul>
<li>
The percentage of the computer’s best move being the one the player chose (“MM%”). <p/>
</li><li>
The average error judged by the computer per move, scaling down large differences (“ASD”).
</li></ul>
<p>
My 2011 paper found strong linear relations of these quantities to the players’ rating, and great ASD fits on a 3-million-move data set are shown graphically in this <a href="https://rjlipton.wordpress.com/2016/11/30/when-data-serves-turkey/">post</a>. With MM% and my new 2018 data, here is what I see when I limit to the 1600–2700 range, grouping in “buckets” of 25 Elo points. All screenshots are taken with Andrew Que’s Polynomial Regression <a href="http://polynomialregression.drque.net/online.php">applet</a>. They all show data taken with Stockfish 9 run to search depth at least 20 and breadth at least 200 million nodes; the similar data for the chess program Komodo 11.3 gives similar results.</p>
<p><a href="https://rjlipton.wordpress.com/2019/02/03/a-strange-horizon/linearmmpfitpart/" rel="attachment wp-att-15620"><img alt="" class="aligncenter wp-image-15620" height="285" src="https://rjlipton.files.wordpress.com/2019/02/linearmmpfitpart.png?w=450&amp;h=285" width="450"/></a></p>
<p>
Even with vastly more data, there still does not appear any reason to reject the simple hypothesis that the relation to rating is linear. Not only is <img alt="{R^2 &gt; 0.99}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%5E2+%3E+0.99%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R^2 &gt; 0.99}"/>, the quality of fit is terrific. The noise under Elo 2000 is minimal.</p>
<p>
But now I have over 14,000 moves in individual buckets clear down to the FIDE minimum 1000 rating; only the 2750 bucket with 11,923 moves and the 2800-level bucket with 6,340 (from just a handful of the world’s elite players) lag behind. When those buckets are added, here is what we see:</p>
<p><a href="https://rjlipton.wordpress.com/2019/02/03/a-strange-horizon/linearmmpfita/" rel="attachment wp-att-15622"><img alt="" class="aligncenter wp-image-15622" height="285" src="https://rjlipton.files.wordpress.com/2019/02/linearmmpfita.png?w=450&amp;h=285" width="450"/></a></p>
<p>
The linear hypothesis is notably less tenable. Instead, a quadratic polynomial fits supremely well:</p>
<p>
<a href="https://rjlipton.wordpress.com/2019/02/03/a-strange-horizon/quadraticmmpfita/" rel="attachment wp-att-15623"><img alt="" class="aligncenter wp-image-15623" height="285" src="https://rjlipton.files.wordpress.com/2019/02/quadraticmmpfita.png?w=450&amp;h=285" width="450"/></a></p>
<p>
Thus it seems I must admit a <em>nonlinearity</em> into my chess model. This may not be just about slightly improving my model’s application to players at the ends of the rating spectrum. Philosophically, nonlinearity can be a game-changer: the way Newtonian physics is fine for flying jets all around the globe but finding your neighbor’s house via <a href="http://physicscentral.com/explore/writers/will.cfm">GPS</a> absolutely requires Einstein. </p>
<p>
</p><p/><h2> The Horizon Issue </h2><p/>
<p/><p>
Let us flip the axes so that <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X}"/> is MM% and <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y}"/> is rating. Then the intercept of <img alt="{X = 100\%}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX+%3D+100%5C%25%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X = 100\%}"/> would give the rating of perfect agreement with the computer. Well, here is what we see:</p>
<p>
<a href="https://rjlipton.wordpress.com/2019/02/03/a-strange-horizon/quadraticmmpfitflipext/" rel="attachment wp-att-15624"><img alt="" class="aligncenter wp-image-15624" height="285" src="https://rjlipton.files.wordpress.com/2019/02/quadraticmmpfitflipext.png?w=450&amp;h=285" width="450"/></a></p>
<p>
Having the rating of perfect agreement be about 1950—which is a amateur A-level in the US—is ludicrous. The greater import is how the increase stops at Elo 3000 with matching just under 75%. The serious implication I draw is that this helps locate the horizon of effectiveness of the data and my methods based on it. Meanwhile, I’ve had the sense from applications that my full model based on smaller higher-quality data is coherent up to about 3100 but cannot tell differences above that. </p>
<p>
Indeed, there is a corroborating indicator of this horizon: The top chess programs, or even different (major) versions of the same program, don’t even match <em>each other</em> over 75% with regularity. Moreover, the <em>same program</em> will fairly often change to a different move when left running for more time or to a greater search depth. If it didn’t change, it wouldn’t improve. Thus my tests, which have no foreknowledge of how long a program used to cheat was running and on how powerful hardware, cannot expect to register positives at a higher rate. The natural agreement rates for human players range from about 35% for novices to upwards of 60% for world champions. </p>
<p>
</p><p/><h2> The Average-Error Case </h2><p/>
<p/><p>
The fit to average scaled error-per-move (ASD) shows the other side of the horizon issue. The ASD measure is more tightly correlated to rating—as the graphs in the above-mentioned <a href="https://rjlipton.wordpress.com/2016/11/30/when-data-serves-turkey/">post</a> suffice to indicate. Here is the corresponding graph on the new data, again with flipped axes:</p>
<p>
<a href="https://rjlipton.wordpress.com/2019/02/03/a-strange-horizon/linearasdfit/" rel="attachment wp-att-15625"><img alt="" class="aligncenter wp-image-15625" height="285" src="https://rjlipton.files.wordpress.com/2019/02/linearasdfit.png?w=450&amp;h=285" width="450"/></a></p>
<p>
Only under 1250 Elo does perfect linearity seem to be countermanded. The issue, however, is at the other end. Committing asymptotically zero error seems to be a more acute indicator of perfection than 100% agreement with a strong program. However, the <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y}"/>-intercept there is given as a rating under 3300, whereas computer programs have been reliably <a href="http://www.computerchess.org.uk/ccrl/404/">rated</a> above 3400, and very recently over 3500. Thus we’d appear to have computers rated higher than perfection.</p>
<p>
One can move from the above indication of my setup losing mojo before 3000 to allege that it is insufficient for fair judgment of human players above 2500, say, so that the intercept is not valid. My counter-argument is that the same intercept is also a robust extrapolation from the range 1500 to 2500 where the linear fit is nearly perfect and the computer’s sufficiency for authoritative judgment of the players is beyond doubt. </p>
<p>
Nevertheless, the above “game-changer” for the move-matching percentage suggests the same for ASD. A quadratic fit to ASD produces the following results:</p>
<p>
<a href="https://rjlipton.wordpress.com/2019/02/03/a-strange-horizon/quadraticasdfitnw/" rel="attachment wp-att-15626"><img alt="" class="aligncenter wp-image-15626" height="285" src="https://rjlipton.files.wordpress.com/2019/02/quadraticasdfitnw.png?w=450&amp;h=285" width="450"/></a></p>
<p>
Now the <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y}"/>-intercept at <img alt="{X = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X = 0}"/> is within error bars of 3500, in agreement with the 3475 figure currently used in my full model and less starkly under the measured ratings.</p>
<p>
</p><p/><h2> One More Riff </h2><p/>
<p/><p>
Let us think of move-matching for a given rating <img alt="{R}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R}"/> as a flip of a biased coin with heads probability <img alt="{p = p_R}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp+%3D+p_R%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p = p_R}"/>. If we plot <img alt="{R}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R}"/> not against <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> but against <img alt="{p\cdot p(1-p)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%5Ccdot+p%281-p%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p\cdot p(1-p)}"/>, we recover a nearly perfect linear fit (the plot shows <img alt="{4p^2 (1-p)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B4p%5E2+%281-p%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{4p^2 (1-p)}"/>):</p>
<p>
<a href="https://rjlipton.wordpress.com/2019/02/03/a-strange-horizon/ppqfit/" rel="attachment wp-att-15627"><img alt="" class="aligncenter wp-image-15627" height="285" src="https://rjlipton.files.wordpress.com/2019/02/ppqfit.png?w=450&amp;h=285" width="450"/></a></p>
<p>
Well, <img alt="{p(1-p)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%281-p%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p(1-p)}"/> is the variance of one coin flip. Why should multiplying <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> by this variance recover a linear fit in the <em>mean</em>? Only multiplying <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> by the square root of <img alt="{p(1-p)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%281-p%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p(1-p)}"/> still leaves a significantly non-linear plot. </p>
<p>
Recovering <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> from <img alt="{p^2(1-p)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%5E2%281-p%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p^2(1-p)}"/> needs solving a cubic equation. The maximum value is at <img alt="{p = \frac{2}{3}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp+%3D+%5Cfrac%7B2%7D%7B3%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p = \frac{2}{3}}"/> and is <img alt="{\frac{4}{27}.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B4%7D%7B27%7D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\frac{4}{27}.}"/> Multiplying by <img alt="{4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{4}"/> as in the plot makes <img alt="{\frac{16}{27} \approx 0.592593}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B16%7D%7B27%7D+%5Capprox+0.592593%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\frac{16}{27} \approx 0.592593}"/> the maximum solvable value. This regression line associates this to a rating of only 2860. This suggests a tangibly lower horizon. It also seems contradicted by the fact of Magnus Carlsen maintaining a rating over 2860 from January 2013 through June 2015, yet his engine agreement did not approach 66.7%.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
We’ve connected the horizon of perfect play to whether the fundamental relationship of rating to agreement with strong computer programs is linear, quadratic, or indirectly cubic. Which relationship is true? What further tests may best ascertain the range of effectiveness of inferences from these data?</p>
<p/></font></font></div>
    </content>
    <updated>2019-02-03T06:37:57Z</updated>
    <published>2019-02-03T06:37:57Z</published>
    <category term="All Posts"/>
    <category term="chess"/>
    <category term="detection"/>
    <category term="Ideas"/>
    <category term="Teaching"/>
    <category term="Alfred Lotka"/>
    <category term="Derek de Solla Price"/>
    <category term="horizons"/>
    <category term="linear regression"/>
    <category term="nonlinearity"/>
    <category term="Paul Allison"/>
    <category term="statistics"/>
    <author>
      <name>KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-02-05T12:20:57Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://theorydish.blog/?p=1490</id>
    <link href="https://theorydish.blog/2019/02/02/stoca-workshop/" rel="alternate" type="text/html"/>
    <title>STOCA workshop</title>
    <summary>For the past few months, we, the STOC 2019 PC, have enjoyed the privilege of reading and discussing a lot of exciting submissions. On Sunday and Monday we will reject most of them. After that, on Tuesday February 5th, we will celebrate with a 1-day workshop hosted at Google. Here is the official website for registration (free!) and other useful infromation: https://sites.google.com/view/stoca19/home</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>For the past few months, we, the STOC 2019 PC, have enjoyed the privilege of reading and discussing a lot of exciting submissions. On Sunday and Monday we will reject most of them. After that, on <strong>Tuesday February 5th</strong>, we will celebrate with a 1-day workshop hosted at Google.</p>
<p>Here is the official website for registration (free!) and other useful infromation:<br/>
<a href="https://sites.google.com/view/stoca19/home">https://sites.google.com/view/stoca19/home</a></p></div>
    </content>
    <updated>2019-02-03T05:31:05Z</updated>
    <published>2019-02-03T05:31:05Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>aviad.rubinstein</name>
    </author>
    <source>
      <id>https://theorydish.blog</id>
      <logo>https://theorydish.files.wordpress.com/2017/03/cropped-nightdish1.jpg?w=32</logo>
      <link href="https://theorydish.blog/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://theorydish.blog" rel="alternate" type="text/html"/>
      <link href="https://theorydish.blog/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://theorydish.blog/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Stanford's CS Theory Research Blog</subtitle>
      <title>Theory Dish</title>
      <updated>2019-02-05T12:21:59Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=16779</id>
    <link href="https://gilkalai.wordpress.com/2019/02/02/konstantin-tikhomrov-the-probability-that-a-bernoulli-matrix-is-singular/" rel="alternate" type="text/html"/>
    <title>Konstantin Tikhomirov: The Probability that a Bernoulli Matrix is Singular</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Konstantin Tikhomirov An old problem in combinatorial random matrix theory is cracked! Singularity of random Bernoulli matrices by Konstantin Tikhomirov Abstract: For each , let be an n×n random matrix with independent ±1 entries. We show that P( is singular}=, … <a href="https://gilkalai.wordpress.com/2019/02/02/konstantin-tikhomrov-the-probability-that-a-bernoulli-matrix-is-singular/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="https://gilkalai.files.wordpress.com/2019/02/tikhomirov.jpg"><img alt="" class="alignnone size-full wp-image-16826" src="https://gilkalai.files.wordpress.com/2019/02/tikhomirov.jpg?w=640"/></a></p>
<p><span style="color: #ff0000;"><strong>Konstantin Tikhomirov</strong></span></p>
<p>An old problem in combinatorial random matrix theory is cracked!</p>
<p><a href="https://arxiv.org/abs/1812.09016"><strong>Singularity of random Bernoulli matrices</strong></a> by <strong>Konstantin Tikhomirov</strong></p>
<p><strong>Abstract</strong>: For each <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>, let <img alt="M_n" class="latex" src="https://s0.wp.com/latex.php?latex=M_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="M_n"/> be an <em>n</em>×<em>n</em> random matrix with independent ±1 entries. We show that</p>
<p style="text-align: center;">P(<img alt="M_n" class="latex" src="https://s0.wp.com/latex.php?latex=M_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="M_n"/> is singular}=<img alt="(1/2+o_n(1))^n" class="latex" src="https://s0.wp.com/latex.php?latex=%281%2F2%2Bo_n%281%29%29%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(1/2+o_n(1))^n"/>,</p>
<p>which settles an old problem. Some generalizations are considered.</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/02/komlos.jpg"><img alt="" class="alignnone size-full wp-image-16821" src="https://gilkalai.files.wordpress.com/2019/02/komlos.jpg?w=640"/></a></p>
<p><span style="color: #ff0000;"><b>János Komlós</b></span></p>
<h3>Background and discussion</h3>
<p>What is the probability <img alt="s(n)" class="latex" src="https://s0.wp.com/latex.php?latex=s%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s(n)"/> that a random n by n matrix with <img alt="\pm 1" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpm+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\pm 1"/> entries is singular? Well, it can be singular if either two rows are identical, or if two columns are identical. This happens with probability</p>
<p style="text-align: center;"><img alt="n(n-1)(1+0(1)) \cdot 2^{-n}" class="latex" src="https://s0.wp.com/latex.php?latex=n%28n-1%29%281%2B0%281%29%29+%5Ccdot+2%5E%7B-n%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n(n-1)(1+0(1)) \cdot 2^{-n}"/>.</p>
<p>Are there other more dominant reasons for singularity? Are most <img alt="\pm 1" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpm+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\pm 1"/> matrices nonsingular as <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> tends to infinity? The first results in this direction are by Janos Komlos who first proved in 1968 that <img alt="s(n)=o(1)" class="latex" src="https://s0.wp.com/latex.php?latex=s%28n%29%3Do%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s(n)=o(1)"/> and later that <img alt="s(n)=O(1/\sqrt n)" class="latex" src="https://s0.wp.com/latex.php?latex=s%28n%29%3DO%281%2F%5Csqrt+n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s(n)=O(1/\sqrt n)"/>. A major breakthrough came in 1995 when  <a href="http://www.ams.org/journals/jams/1995-08-01/S0894-0347-1995-1260107-2/home.html">Kahn , Komlos, and Szemeredi proved</a> that <img alt="s(n) \le 0.999^n" class="latex" src="https://s0.wp.com/latex.php?latex=s%28n%29+%5Cle+0.999%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s(n) \le 0.999^n"/>. Terry Tao and Van Vu improved in 2006 the constant to 0.939 and then to (3/4+o(1)) and the, now broken, world record from 2010 was <img alt="(1/\sqrt 2)+o(1))^n" class="latex" src="https://s0.wp.com/latex.php?latex=%281%2F%5Csqrt+2%29%2Bo%281%29%29%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(1/\sqrt 2)+o(1))^n"/>  by Jean Bourgain, Van Vu and Philip Wood. Congratulations Konstantin!</p>
<p>If you want to tease the Gods of Mathematics you can try to prove that <img alt="s(n) =n(n-1)(1+o(1)) \cdot 2^{-n}" class="latex" src="https://s0.wp.com/latex.php?latex=s%28n%29+%3Dn%28n-1%29%281%2Bo%281%29%29+%5Ccdot+2%5E%7B-n%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s(n) =n(n-1)(1+o(1)) \cdot 2^{-n}"/>? and, as suggested in the Kahn-Komlós-Szemerédi paper,  even prove an expansion  <img alt="s(n) = 2{{n} \choose {2}}(\frac{1}{2})^{n}+2{{n}\choose {4}} (\frac{3}{8})^n\cdots" class="latex" src="https://s0.wp.com/latex.php?latex=s%28n%29+%3D+2%7B%7Bn%7D+%5Cchoose+%7B2%7D%7D%28%5Cfrac%7B1%7D%7B2%7D%29%5E%7Bn%7D%2B2%7B%7Bn%7D%5Cchoose+%7B4%7D%7D+%28%5Cfrac%7B3%7D%7B8%7D%29%5En%5Ccdots&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s(n) = 2{{n} \choose {2}}(\frac{1}{2})^{n}+2{{n}\choose {4}} (\frac{3}{8})^n\cdots"/> based on dependencies between <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-tuples of rows and columns.</p>
<p>Let me mention that  <a href="https://arxiv.org/abs/math/0505156">Kevin Costello, Tao, and Vu, proved in 2005</a> that  random symmetric matrices are almost surely non-singular.  This is related to beautiful mathematics. <a href="https://arxiv.org/abs/0804.2362"> Tao and Vu also proved</a> that the probability for vanishing of the permanent of a Bernoulli matrix is <img alt="o(1)" class="latex" src="https://s0.wp.com/latex.php?latex=o%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="o(1)"/>. I am not sure what is the proven behavior for permanents and one may expect that vanishing of the permanent occurs in probability which is super exponentially small. (Perhaps <img alt="C/\sqrt {n!}" class="latex" src="https://s0.wp.com/latex.php?latex=C%2F%5Csqrt+%7Bn%21%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C/\sqrt {n!}"/>.)</p>
<p>Here are related posts on Tao’s blog What’s New. <a href="https://terrytao.wordpress.com/2007/12/05/milliman-lecture-ii-additive-combinatorics-and-random-matrices/">A post on Tao’s Milliman’s lecture on the additive combinatorics and random matrices</a>; <a href="https://terrytao.wordpress.com/2008/04/16/on-the-permanent-of-a-random-bernoulli-matrix/">On the permamnent of random Bernoulli matrix</a>;</p>
<h3>Determinants and the guaranteed cancellation phenomenon</h3>
<p>The value of the determinant of a Bernoulli matrix is the sum of <em>n!</em> ±1 terms. So we can guess that the expected value will be around <img alt="\sqrt {n!}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csqrt+%7Bn%21%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sqrt {n!}"/>, and with high probability it is near the expected value. There is something special about the determinant which we can call the <strong>Guaranteed Cancellation Phenomenon (GCP)</strong>. The value of the determinant of a Bernoulli  matrix is at most <img alt="n^{n/2}" class="latex" src="https://s0.wp.com/latex.php?latex=n%5E%7Bn%2F2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n^{n/2}"/> which is not that much larger than <img alt="\sqrt {n!}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csqrt+%7Bn%21%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sqrt {n!}"/>. (GCP applies to matrices with real or complex variables with rows with prescribed  <img alt="\ell_2" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\ell_2"/> norms.)  Guaranteed cancellation is a very interesting mathematical phenomenon in various contexts. (For example, the prime number theorem and the Riemann hypothesis are about guaranteed cancellation.) The determinant itself is a polynomial of degree <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> with <img alt="n^2" class="latex" src="https://s0.wp.com/latex.php?latex=n%5E2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n^2"/> variables , and GCP for determinants was one of the starting points in a paper that I wrote with Leonard Schulman on <a href="https://arxiv.org/abs/1804.04828">quasi-random multilinear polynomials</a>. (For other examples of GCP see also this <a href="https://mathoverflow.net/questions/59530/horst-kn%C3%B6rrers-permutation-cancellation-problem">MO question</a> and various posts  on Mobius randomness.) Maybe it is time to ask on MathOverflow for a list of places were GCP  is expected or proven.)</p>
<p>Sperner, the Littlewood-Offord problem, and additive combinatorics</p>
<p>The determinant of a <img alt="\pm 1" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpm+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\pm 1"/> matrix is the signed sum of <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> minors. It follows from Sperner’s theorem that if <img alt="m" class="latex" src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m"/> of these minors are non-zero then the probability that the sum vanishes is <img alt="O(1/\sqrt m)" class="latex" src="https://s0.wp.com/latex.php?latex=O%281%2F%5Csqrt+m%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(1/\sqrt m)"/>. This is the idea behind Komlos’ second proof. The relevant general question (backward <a href="https://en.wikipedia.org/wiki/Littlewood%E2%80%93Offord_problem">Littlewood Offord</a>  problem) which is of much independent interest is “Under which conditions on a sequence <img alt="a_1,a_2, \dots, a_n" class="latex" src="https://s0.wp.com/latex.php?latex=a_1%2Ca_2%2C+%5Cdots%2C+a_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_1,a_2, \dots, a_n"/> we can guarantee that the probability that a signed sum of the sequence vanished (or has a small absolute value) is small.” The famous Erdos-Moser conjecture (solved on the nose by Stanley using the Hard Lefschetz theorem, sharpening a result by Sárközy and Szemerédi) asserts that if the elements of the sequence are distinct then the larger vanishing probability is attained by the sequence of integers between <em>-[n/2]</em> and +<em>[n/2]</em>. In this case (like for any arithmetic progression) the vanishing probability is <img alt="n^{-3/2}" class="latex" src="https://s0.wp.com/latex.php?latex=n%5E%7B-3%2F2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n^{-3/2}"/>.  Kahn, Komlos and Szemeredi relied on (and extended)  a theory by  Gábor Halász for guaranteeing that the vanishing probability is small (exponentially small) and, of course, much work is needed to prove that Halász-type conditions are satisfied.</p>
<p>I was excited by the 2005 solution for symmetric matrices also because it involved a quadratic version of Littlewood-Offord type results which are of much independent interest. I think that there are many interesting remaining open problems.</p>
<p> </p></div>
    </content>
    <updated>2019-02-02T18:37:12Z</updated>
    <published>2019-02-02T18:37:12Z</published>
    <category term="Combinatorics"/>
    <category term="Probability"/>
    <category term="Konstantin Tikhomirov"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-02-05T12:20:51Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-6555947.post-2316741109895040253</id>
    <link href="http://blog.geomblog.org/feeds/2316741109895040253/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://blog.geomblog.org/2019/02/more-fat-blogging.html#comment-form" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/6555947/posts/default/2316741109895040253" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/6555947/posts/default/2316741109895040253" rel="self" type="application/atom+xml"/>
    <link href="http://feedproxy.google.com/~r/TheGeomblog/~3/SO5XVo9kvXw/more-fat-blogging.html" rel="alternate" type="text/html"/>
    <title>More FAT* blogging</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Session 3: <a href="https://algorithmicfairness.wordpress.com/2019/01/30/fat-papers-profiling-and-representation/">Representation and Profiling</a><br/><br/>Session 4: <a href="https://algorithmicfairness.wordpress.com/2019/02/01/fat-papers-fairness-methods/">Fairness methods. </a><img alt="" height="1" src="http://feeds.feedburner.com/~r/TheGeomblog/~4/SO5XVo9kvXw" width="1"/></div>
    </content>
    <updated>2019-02-02T07:46:00Z</updated>
    <published>2019-02-02T07:46:00Z</published>
    <category scheme="http://www.blogger.com/atom/ns#" term="conf-blogs"/>
    <category scheme="http://www.blogger.com/atom/ns#" term="fat*"/><feedburner:origlink xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0">http://blog.geomblog.org/2019/02/more-fat-blogging.html</feedburner:origlink>
    <author>
      <name>Suresh Venkatasubramanian</name>
      <email>noreply@blogger.com</email>
      <uri>https://plus.google.com/112165457714968997350</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-6555947</id>
      <category term="research"/>
      <category term="community"/>
      <category term="miscellaneous"/>
      <category term="soda"/>
      <category term="conferences"/>
      <category term="data-mining"/>
      <category term="socg"/>
      <category term="blogosphere"/>
      <category term="publishing"/>
      <category term="clustering"/>
      <category term="teaching"/>
      <category term="jobs"/>
      <category term="funding"/>
      <category term="humor"/>
      <category term="awards"/>
      <category term="outreach"/>
      <category term="stoc"/>
      <category term="cs.CG"/>
      <category term="focs"/>
      <category term="nsf"/>
      <category term="reviewing"/>
      <category term="socg-2010"/>
      <category term="fairness"/>
      <category term="academy"/>
      <category term="latex"/>
      <category term="stoc2017"/>
      <category term="theoryfest"/>
      <category term="workshops"/>
      <category term="acm"/>
      <category term="conf-blogs"/>
      <category term="writing"/>
      <category term="cs.DS"/>
      <category term="cs.LG"/>
      <category term="geometry"/>
      <category term="p-vs-nc"/>
      <category term="advising"/>
      <category term="sabbatical"/>
      <category term="simons foundation"/>
      <category term="announcement"/>
      <category term="big-data"/>
      <category term="deadline"/>
      <category term="jeff phillips"/>
      <category term="streaming"/>
      <category term="books"/>
      <category term="large-data"/>
      <category term="p-vs-np"/>
      <category term="cra"/>
      <category term="cstheory"/>
      <category term="focs2010"/>
      <category term="icdm"/>
      <category term="math.PR"/>
      <category term="memorial"/>
      <category term="personal"/>
      <category term="posters"/>
      <category term="potd"/>
      <category term="rajeev motwani"/>
      <category term="shonan"/>
      <category term="socg2012"/>
      <category term="software"/>
      <category term="stoc2012"/>
      <category term="GIA"/>
      <category term="SDM"/>
      <category term="alenex"/>
      <category term="alenex2011"/>
      <category term="arxiv"/>
      <category term="career"/>
      <category term="complexity"/>
      <category term="cs.CC"/>
      <category term="deolalikar"/>
      <category term="distributions"/>
      <category term="madalgo"/>
      <category term="nips"/>
      <category term="sdm2011"/>
      <category term="shape"/>
      <category term="talks"/>
      <category term="technology"/>
      <category term="theory.SE"/>
      <category term="travel"/>
      <category term="video"/>
      <category term="8f-cg"/>
      <category term="DBR"/>
      <category term="ICS"/>
      <category term="LISPI"/>
      <category term="acceptances"/>
      <category term="bibtex"/>
      <category term="bregman"/>
      <category term="cfp"/>
      <category term="clustering-book"/>
      <category term="column"/>
      <category term="combinatorial geometry"/>
      <category term="current-distance"/>
      <category term="ecml-pkdd"/>
      <category term="empirical"/>
      <category term="esa"/>
      <category term="fat*"/>
      <category term="focs2012"/>
      <category term="focs2014"/>
      <category term="fwcg"/>
      <category term="game theory"/>
      <category term="godel"/>
      <category term="graphs"/>
      <category term="implementation"/>
      <category term="journals"/>
      <category term="kernels"/>
      <category term="misc"/>
      <category term="models"/>
      <category term="obituary"/>
      <category term="productivity"/>
      <category term="programming"/>
      <category term="society"/>
      <category term="soda2011"/>
      <category term="topology"/>
      <category term="turing"/>
      <category term="tv"/>
      <category term="women-in-theory"/>
      <category term=".02"/>
      <category term="IMA"/>
      <category term="MOOC"/>
      <category term="PPAD"/>
      <category term="accountability"/>
      <category term="active-learning"/>
      <category term="aggregator"/>
      <category term="algorithms"/>
      <category term="ams"/>
      <category term="analco"/>
      <category term="barriers"/>
      <category term="beamer"/>
      <category term="blogging"/>
      <category term="candes"/>
      <category term="civil rights"/>
      <category term="classification"/>
      <category term="coding-theory"/>
      <category term="coffee"/>
      <category term="conjecture"/>
      <category term="cosmos"/>
      <category term="counting"/>
      <category term="cricket"/>
      <category term="cs.DC"/>
      <category term="dagstuhl"/>
      <category term="databuse"/>
      <category term="dimacs"/>
      <category term="dimensionality-reduction"/>
      <category term="distributed-learning"/>
      <category term="double-blind review"/>
      <category term="duality"/>
      <category term="eda"/>
      <category term="embarrassing"/>
      <category term="expanders"/>
      <category term="experiments"/>
      <category term="fake-news"/>
      <category term="fatml"/>
      <category term="fellowships"/>
      <category term="focs2013"/>
      <category term="fonts"/>
      <category term="gct"/>
      <category term="ggplot"/>
      <category term="gpu"/>
      <category term="graph minors"/>
      <category term="gt.game-theory"/>
      <category term="guest-post"/>
      <category term="guitar"/>
      <category term="hangouts"/>
      <category term="hirsch"/>
      <category term="history"/>
      <category term="ipe"/>
      <category term="ita"/>
      <category term="jmm"/>
      <category term="k-12"/>
      <category term="knuth"/>
      <category term="machine-learning"/>
      <category term="massive"/>
      <category term="math.ST"/>
      <category term="media"/>
      <category term="memes"/>
      <category term="metoo"/>
      <category term="metrics"/>
      <category term="morris"/>
      <category term="movies"/>
      <category term="multicore"/>
      <category term="music"/>
      <category term="narrative"/>
      <category term="networks"/>
      <category term="nih"/>
      <category term="parallelism"/>
      <category term="partha niyogi"/>
      <category term="polymath"/>
      <category term="polymath research"/>
      <category term="polytopes"/>
      <category term="postdocs"/>
      <category term="privacy"/>
      <category term="quant-ph"/>
      <category term="quantum"/>
      <category term="randomness"/>
      <category term="review"/>
      <category term="sampling"/>
      <category term="seminars"/>
      <category term="social-networking"/>
      <category term="soda2014"/>
      <category term="students"/>
      <category term="sublinear"/>
      <category term="submissions"/>
      <category term="summer-school"/>
      <category term="superbowl"/>
      <category term="surveys"/>
      <category term="svn"/>
      <category term="television"/>
      <category term="traffic"/>
      <category term="twitter"/>
      <category term="utah"/>
      <category term="wads"/>
      <category term="white elephant"/>
      <category term="xkcd"/>
      <author>
        <name>Suresh Venkatasubramanian</name>
        <email>noreply@blogger.com</email>
      </author>
      <link href="http://blog.geomblog.org/" rel="alternate" type="text/html"/>
      <link href="http://www.blogger.com/feeds/6555947/posts/default?alt=atom&amp;start-index=26&amp;max-results=25&amp;redirect=false" rel="next" type="application/atom+xml"/>
      <link href="http://feeds.feedburner.com/TheGeomblog" rel="self" type="application/atom+xml"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <subtitle>Ruminations on computational geometry, algorithms, theoretical computer science and life</subtitle>
      <title>The Geomblog</title>
      <updated>2019-02-02T07:46:06Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=7467</id>
    <link href="https://windowsontheory.org/2019/02/01/black-holes-a-complexity-theory-perspective/" rel="alternate" type="text/html"/>
    <title>Black Holes, a Complexity Theory perspective</title>
    <summary>Guest post by Chi-Ning Chou and Parth Mehta from the physics and computation seminar. Abstract The firewall paradox (introduced here) is a bewitching thought experiment that mandates a deeper understanding of our reality. As luck would have it, QFT predictions seem sound, GR calculations appear valid, and semi-classical approximations look reasonable: no one is willing […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Guest post by Chi-Ning Chou and Parth Mehta from <a href="https://www.boazbarak.org/fall18seminar/">the physics and computation seminar</a>.</p>
<h3>Abstract</h3>
<p>The firewall paradox (introduced <em>here</em>) is a bewitching thought experiment that mandates a deeper understanding of our reality. As luck would have it, QFT predictions seem sound, GR calculations appear valid, and semi-classical approximations look reasonable: no one is willing to budge! To save Alice from burning in the miserable firewall, therefore, we must come up with a radically new proposal. This blog post aims to map what seems to be a hard, physics dilemma into a Computer Science problem that we can, using the grace of a lazy programmer, show to be hard to solve. In particular, we present an overview of the Harlow-Hayden decoding task and show how it maps the Firewall Paradox to a hard computation on a quantum computer. We end by rigorously defining quantum circuit complexity, Aaronson’s improved proof, AdS/CFT correspondence, and some fascinating homework (open) problems.</p>
<h2>Why all the fuss?</h2>
<p>Have you ever confessed to yourself that you don’t quite understand Black Hole complementarity well? In the past decade or so, physicists realized they did not grasp the concept thoroughly either. The firewall paradox is a natural result of bewildered physicists trying to make sense of reality. Thus far, no satisfying physical explanation reaches people’s consensus. Nevertheless, Daniel Harlow and Patrick Hayden [HH13] proposed a tempting solution to the firewall paradox using Computational Complexity (CC). Concretely, they showed the following.</p>
<p style="text-align: center;"><img alt="\text{A conjecture in CC is true}\Rightarrow\text{Firewalls do not exist}." class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctext%7BA+conjecture+in+CC+is+true%7D%5CRightarrow%5Ctext%7BFirewalls+do+not+exist%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\text{A conjecture in CC is true}\Rightarrow\text{Firewalls do not exist}."/></p>
<p>We elaborate on this deep connection throughout this post.</p>
<h3>Problem Solving: Physics v.s. Computer Science</h3>
<p>The notion of a `conjecture’ has different implications for either field. In Physics, a wrong conjecture often delights physicists since there is more work left to do and better theory required to explain the physical phenomenon under study. For complexity theorists, however, if, say, the famous <img alt="\mathbf{P}\neq\mathbf{NP}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BP%7D%5Cneq%5Cmathbf%7BNP%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{P}\neq\mathbf{NP}"/> is proved to be false, a few consequences follow. First, the authors of the proof win a million dollars (See the <a href="http://www.claymath.org/millennium-problems/p-vs-np-problem" rel="noopener" target="_blank">Millennium problems</a>.). Second, such a result would break almost all the foundations of computational complexity and cryptography. That is, refuting an (important) conjecture in computational complexity is tantamount to resulting in real-world catastrophes! Below in Table 1 is a short summary.</p>
<table style="border: 1px solid black; border-collapse: collapse;">
<tbody>
<tr style="border: 1px solid black;">
<td style="border: 1px solid black;"/>
<td style="border: 1px solid black;">Theoretical Physics</td>
<td style="border: 1px solid black;">Theoretical Computer Science</td>
</tr>
<tr style="border: 1px solid black;">
<td style="border: 1px solid black;">Object</td>
<td style="border: 1px solid black;">Are the mathematical models for our physical world correct?</td>
<td style="border: 1px solid black;">Is our intuition about the mathematical models we defined correct?</td>
</tr>
<tr style="border: 1px solid black;">
<td style="border: 1px solid black;">Consequences of disproving</td>
<td style="border: 1px solid black;">After few days/months/years, physicists will come up with a new model and try to falsify it.</td>
<td style="border: 1px solid black;">The belief system of complexity theorists collapses. Some super algorithms might show up and shake the world.</td>
</tr>
<tr style="border: 1px solid black;">
<td style="border: 1px solid black;">How to prove/disprove</td>
<td style="border: 1px solid black;">Checking mathematical consistency, doing both thought and empirical experiments.</td>
<td style="border: 1px solid black;">Using fancy mathematics or designing super algorithms.</td>
</tr>
</tbody>
</table>
<p style="text-align: center;">Table 1: “Conjecture”, as used in Physics and Computer Science.</p>
<p>We labour above to convince the reader about these differences because the Harlow-Hayden decoding task has vital implications for both, Physics and Computer Science. The connections between Black Holes and Computational Complexity can be thought of as a new <em>testbench</em> for physical models.</p>
<h2>Reckless review: Quantum Information</h2>
<h3>Gates</h3>
<p>In Quantum Computation, gates are unitary operators. Some common gates used in the Quantum Information literature are as follows:</p>
<ul>
<li>
<div>Single-qubit: Pauli matrices (<em>i.e.,</em> <img alt="X,Y,Z" class="latex" src="https://s0.wp.com/latex.php?latex=X%2CY%2CZ&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X,Y,Z"/>), phase operator <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/>, Hadamard matrix <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/>.</div>
</li>
<li>
<div>Two-qubit: CNOT, Toffoli, CZ.</div>
</li>
</ul>
<p>For more details, please refer to [NC02]. Interestingly enough, singe-qubit and two-qubit gates are sufficient to construct any <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>-qubit gates! Such a set of operators is said to be <em>universal</em>. For example, <img alt="\{\text{Toffoli},H,P\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B%5Ctext%7BToffoli%7D%2CH%2CP%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{\text{Toffoli},H,P\}"/> and <img alt="\{\text{CNOT},G\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B%5Ctext%7BCNOT%7D%2CG%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{\text{CNOT},G\}"/> are universal for almost every single-qubit operator. Furthermore, Kitaev and Solovay gave a <em>qualitative</em> version of the universality theorem by showing that getting an <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon"/> approximation to an <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>-qubit operator in trace norm, only <img alt="O(\log^21/\epsilon)" class="latex" src="https://s0.wp.com/latex.php?latex=O%28%5Clog%5E21%2F%5Cepsilon%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(\log^21/\epsilon)"/> gates are needed. A final remark on unitary operators: an <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>-qubit operator is actually a matrix of size <img alt="2^n" class="latex" src="https://s0.wp.com/latex.php?latex=2%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^n"/> by <img alt="2^n" class="latex" src="https://s0.wp.com/latex.php?latex=2%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^n"/>. Namely, it requires <img alt="2^{2n}-2^n" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7B2n%7D-2%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{2n}-2^n"/> complex numbers to describe an <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>-qubit operator. (Note the difference between <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> and <img alt="2^n" class="latex" src="https://s0.wp.com/latex.php?latex=2%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^n"/>.)</p>
<h3>Quantum circuits</h3>
<p>A quantum circuit <img alt="\mathcal{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{C}"/> has inputs consisting of <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>-qubits, potentially with <img alt="m" class="latex" src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m"/> <em><a href="https://en.wikipedia.org/wiki/Ancilla_bit" rel="noopener" target="_blank">ancilla bits</a></em>. The computation is done by interior gates from some universal gate set, <em>e.g., </em><img alt="\{\text{Toffoli},H,P\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B%5Ctext%7BToffoli%7D%2CH%2CP%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{\text{Toffoli},H,P\}"/>. The outputs are <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> qubits with potentially <img alt="m" class="latex" src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m"/> bits of garbage. See the following example of quantum circuit for the <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>-qubit Hadamard operator <img alt="H_n| x\rangle=\sum_{y\in\{0,1\}^n}(-1)^{\langle x,y\rangle}|y\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=H_n%7C+x%5Crangle%3D%5Csum_%7By%5Cin%5C%7B0%2C1%5C%7D%5En%7D%28-1%29%5E%7B%5Clangle+x%2Cy%5Crangle%7D%7Cy%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H_n| x\rangle=\sum_{y\in\{0,1\}^n}(-1)^{\langle x,y\rangle}|y\rangle"/> in Figure 1.</p>
<div class="wp-caption aligncenter" id="attachment_7472" style="width: 413px;"><img alt="hadamard" class="alignnone  wp-image-7472" height="266" src="https://windowsontheory.files.wordpress.com/2019/02/hadamard-e1549002349573.png?w=403&amp;h=266" width="403"/><p class="wp-caption-text">Figure 1: A quantum circuit for the n-qubit Hadamard operator.</p></div>
<p>Similarly, the size of a quantum circuit is defined as the number of interior gates. In Figure 1 for example, the size of the circuit is <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>.</p>
<h3>Quantum circuit complexity: <strong>BQP/poly</strong></h3>
<p>Let <img alt="f:\{0,1\}^n\rightarrow\{0,1\}" class="latex" src="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D%5En%5Crightarrow%5C%7B0%2C1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f:\{0,1\}^n\rightarrow\{0,1\}"/> be a boolean function. Define its quantum circuit complexity as the size of the smallest quantum circuit <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/> such that for any <img alt="x\in\{0,1\}^n" class="latex" src="https://s0.wp.com/latex.php?latex=x%5Cin%5C%7B0%2C1%5C%7D%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x\in\{0,1\}^n"/></p>
<p style="text-align: center;"><img alt="\Pr\left[\mathcal{M}_1(C|x\rangle)=f(x)\right]\geq\frac{2}{3}." class="latex" src="https://s0.wp.com/latex.php?latex=%5CPr%5Cleft%5B%5Cmathcal%7BM%7D_1%28C%7Cx%5Crangle%29%3Df%28x%29%5Cright%5D%5Cgeq%5Cfrac%7B2%7D%7B3%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Pr\left[\mathcal{M}_1(C|x\rangle)=f(x)\right]\geq\frac{2}{3}."/></p>
<p>Let <img alt="\mathbf{BQSIZE}[s(n)]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BBQSIZE%7D%5Bs%28n%29%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{BQSIZE}[s(n)]"/> denote the class of boolean functions of quantum circuit complexity at most <img alt="s(n)" class="latex" src="https://s0.wp.com/latex.php?latex=s%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s(n)"/>. The complexity class <img alt="\mathbf{BQP/poly}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BBQP%2Fpoly%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{BQP/poly}"/> is defined as <img alt="\cup_{c\in\mathbb{N}}\mathbf{BQSIZE}[n^c]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ccup_%7Bc%5Cin%5Cmathbb%7BN%7D%7D%5Cmathbf%7BBQSIZE%7D%5Bn%5Ec%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\cup_{c\in\mathbb{N}}\mathbf{BQSIZE}[n^c]"/>. It immediately follows from definition that <img alt="\mathbf{P/poly}\subseteq\mathbf{BQP/poly}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BP%2Fpoly%7D%5Csubseteq%5Cmathbf%7BBQP%2Fpoly%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{P/poly}\subseteq\mathbf{BQP/poly}"/>. As proving lower bound for <img alt="\mathbf{P/poly}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BP%2Fpoly%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{P/poly}"/> (<em>i.e.,</em> finding a problem that is not in <img alt="\mathbf{P/poly}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BP%2Fpoly%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{P/poly}"/>) is a long-standing extremely difficult problem, it is believed to be hard to prove lower bound against <img alt="\mathbf{BQP/poly}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BBQP%2Fpoly%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{BQP/poly}"/>.</p>
<h3>Uniform quantum circuit complexity: BQP</h3>
<p>As <img alt="\mathbf{BQP/poly}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BBQP%2Fpoly%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{BQP/poly}"/> is too powerful to work with, one might want to define a weaker version of the quantum complexity measure. A natural choice is considering a <em>uniform</em> computational model.</p>
<p>In the classical setting, a uniform computational model is defined using a Turing machine. However, it is not clear how to define the corresponding version, a quantum Turing machine. One way to do so is via <em>uniform circuits</em>, defined as follows. We say a circuit family <img alt="\mathcal{C}=\{C_n\}_{n\in\mathbb{N}}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D%3D%5C%7BC_n%5C%7D_%7Bn%5Cin%5Cmathbb%7BN%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{C}=\{C_n\}_{n\in\mathbb{N}}"/> is <img alt="\mathbf{P}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BP%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{P}"/>-uniform if there exists a polynomial time Turing machine such that on input <img alt="1^n" class="latex" src="https://s0.wp.com/latex.php?latex=1%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1^n"/>, it outputs <img alt="C_n" class="latex" src="https://s0.wp.com/latex.php?latex=C_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_n"/>.</p>
<p>Let <img alt="f:\{0,1\}^n\rightarrow\{0,1\}" class="latex" src="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D%5En%5Crightarrow%5C%7B0%2C1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f:\{0,1\}^n\rightarrow\{0,1\}"/> be a boolean function. Define its uniform quantum circuit complexity as the size of the smallest <strong>uniform</strong> quantum circuit <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/> such that for any <img alt="x\in\{0,1\}^n" class="latex" src="https://s0.wp.com/latex.php?latex=x%5Cin%5C%7B0%2C1%5C%7D%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x\in\{0,1\}^n"/></p>
<p style="text-align: center;"><img alt="\Pr\left[\mathcal{M}_1(C|x\rangle)=f(x)\right]\geq\frac{2}{3}." class="latex" src="https://s0.wp.com/latex.php?latex=%5CPr%5Cleft%5B%5Cmathcal%7BM%7D_1%28C%7Cx%5Crangle%29%3Df%28x%29%5Cright%5D%5Cgeq%5Cfrac%7B2%7D%7B3%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Pr\left[\mathcal{M}_1(C|x\rangle)=f(x)\right]\geq\frac{2}{3}."/></p>
<p>Let <img alt="\mathbf{BQTIME}[s(n)]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BBQTIME%7D%5Bs%28n%29%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{BQTIME}[s(n)]"/> denote the class of boolean functions of quantum circuit complexity at most <img alt="s(n)" class="latex" src="https://s0.wp.com/latex.php?latex=s%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s(n)"/>. The complexity class <img alt="\mathbf{BQP}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BBQP%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{BQP}"/> is defined as <img alt="\cup_{c\in\mathbb{N}}\mathbf{BQTIME}[n^c]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ccup_%7Bc%5Cin%5Cmathbb%7BN%7D%7D%5Cmathbf%7BBQTIME%7D%5Bn%5Ec%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\cup_{c\in\mathbb{N}}\mathbf{BQTIME}[n^c]"/>. It immediately follows from definition that <img alt="\mathbf{P}\subseteq\mathbf{BPP}\subseteq\mathbf{BQP}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BP%7D%5Csubseteq%5Cmathbf%7BBPP%7D%5Csubseteq%5Cmathbf%7BBQP%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{P}\subseteq\mathbf{BPP}\subseteq\mathbf{BQP}"/>.</p>
<h3>Unitary complexity: C(U)</h3>
<p>Let <img alt="U\in\mathbb{C}^{2^n\times2^n}" class="latex" src="https://s0.wp.com/latex.php?latex=U%5Cin%5Cmathbb%7BC%7D%5E%7B2%5En%5Ctimes2%5En%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U\in\mathbb{C}^{2^n\times2^n}"/> be an unitary matrix. Define <img alt="C(U)" class="latex" src="https://s0.wp.com/latex.php?latex=C%28U%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C(U)"/> be the smallest quantum circuit <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/> such that</p>
<p style="text-align: center;"><img alt="\|C-U\|_{\infty}\leq\frac{1}{3}." class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7CC-U%5C%7C_%7B%5Cinfty%7D%5Cleq%5Cfrac%7B1%7D%7B3%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\|C-U\|_{\infty}\leq\frac{1}{3}."/></p>
<p>This unitary complexity can be thought of as a relaxation of the quantum circuit complexity. The reason is that here a unitary matrix <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/> might not compute a boolean function. Thus, proving a lower bound for <img alt="\mathbf{BQSIZE}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BBQSIZE%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{BQSIZE}"/> implies a lower bound for unitary complexity while the converse is not clear. Namely, proving a super-polynomial lower bound for the unitary complexity might be an easier task.</p>
<p>However, no non-trivial<sup>1</sup> lower bound for the unitary complexity is known and there is, unfortunately, no formal <em>barrier result</em> explaining why this is difficult to prove.</p>
<h3>Warm-up: Gottesman-Knill</h3>
<p>We defined quantum circuits above, and we hope you find them exotic – at least start-up investors do. But given how fundamental quantum circuits are to the Harlow-Hayden decoding task, we ask: is it possible to efficiently (classically) simulate a quantum circuit made up of a restricted but non-trivial set of quantum gates? We show below a restricted variant of the popular Gottesman-Knill Theorem:</p>
<blockquote><p><strong>Theorem (Gottesman-Knill).<br/>
</strong><span style="color: #4b4f53; background-color: #ffffff;">1. Given: Clifford circuit <img alt="\mathcal{C}: |\alpha_1\rangle\otimes \cdots \otimes |\alpha_n\rangle \rightarrow \{|0\rangle,|1\rangle\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D%3A+%7C%5Calpha_1%5Crangle%5Cotimes+%5Ccdots+%5Cotimes+%7C%5Calpha_n%5Crangle+%5Crightarrow+%5C%7B%7C0%5Crangle%2C%7C1%5Crangle%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{C}: |\alpha_1\rangle\otimes \cdots \otimes |\alpha_n\rangle \rightarrow \{|0\rangle,|1\rangle\}"/> made up of gates <img alt="\{CNOT, P, H\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7BCNOT%2C+P%2C+H%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{CNOT, P, H\}"/>, where <img alt="\mathcal{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{C}"/> is measured on its first output line.<br/>
</span><span style="color: #4b4f53; background-color: #ffffff;">2.Task: Show that it is possible to (classically) efficiently sample the output distribution of <img alt="\mathcal{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{C}"/>.</span></p></blockquote>
<p><em>Proof:</em></p>
<p><img alt="\Pr(0) = \langle{\psi_0|\mathcal{C}^{\dag}(|0\rangle}\langle0|)\mathcal{C}|\psi_0\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%5CPr%280%29+%3D+%5Clangle%7B%5Cpsi_0%7C%5Cmathcal%7BC%7D%5E%7B%5Cdag%7D%28%7C0%5Crangle%7D%5Clangle0%7C%29%5Cmathcal%7BC%7D%7C%5Cpsi_0%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Pr(0) = \langle{\psi_0|\mathcal{C}^{\dag}(|0\rangle}\langle0|)\mathcal{C}|\psi_0\rangle"/> where <img alt="|\psi_0\rangle = |\alpha_1\rangle\otimes \cdots \otimes |\alpha_n\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi_0%5Crangle+%3D+%7C%5Calpha_1%5Crangle%5Cotimes+%5Ccdots+%5Cotimes+%7C%5Calpha_n%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi_0\rangle = |\alpha_1\rangle\otimes \cdots \otimes |\alpha_n\rangle"/>. Since the projector can be written as <img alt="|0\rangle\langle0|= \frac{I + Z}{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7C0%5Crangle%5Clangle0%7C%3D+%5Cfrac%7BI+%2B+Z%7D%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|0\rangle\langle0|= \frac{I + Z}{2}"/>, we get</p>
<p style="text-align: center;"><img alt="\Pr(0) = \langle\psi_0|\mathcal{C}^{\dag}(\frac{I + Z}{2})\mathcal{C}|\psi_0\rangle =\frac{1}{2}[1 + \langle\psi_0|\mathcal{C}^{\dag}Z_1\mathcal{C}|\psi_0\rangle]" class="latex" src="https://s0.wp.com/latex.php?latex=%5CPr%280%29+%3D+%5Clangle%5Cpsi_0%7C%5Cmathcal%7BC%7D%5E%7B%5Cdag%7D%28%5Cfrac%7BI+%2B+Z%7D%7B2%7D%29%5Cmathcal%7BC%7D%7C%5Cpsi_0%5Crangle+%3D%5Cfrac%7B1%7D%7B2%7D%5B1+%2B+%5Clangle%5Cpsi_0%7C%5Cmathcal%7BC%7D%5E%7B%5Cdag%7DZ_1%5Cmathcal%7BC%7D%7C%5Cpsi_0%5Crangle%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Pr(0) = \langle\psi_0|\mathcal{C}^{\dag}(\frac{I + Z}{2})\mathcal{C}|\psi_0\rangle =\frac{1}{2}[1 + \langle\psi_0|\mathcal{C}^{\dag}Z_1\mathcal{C}|\psi_0\rangle]"/></p>
<p>where <img alt="Z_1 = Z \otimes I\cdots \otimes I" class="latex" src="https://s0.wp.com/latex.php?latex=Z_1+%3D+Z+%5Cotimes+I%5Ccdots+%5Cotimes+I&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Z_1 = Z \otimes I\cdots \otimes I"/> since we only measure the first output line of <img alt="\mathcal{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{C}"/>. At first glance, <img alt="\langle\psi_0|\mathcal{C}^{\dag}Z_1\mathcal{C}|\psi_0\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clangle%5Cpsi_0%7C%5Cmathcal%7BC%7D%5E%7B%5Cdag%7DZ_1%5Cmathcal%7BC%7D%7C%5Cpsi_0%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\langle\psi_0|\mathcal{C}^{\dag}Z_1\mathcal{C}|\psi_0\rangle"/> might look like a monstrous computation to perform since, in general, the operator in the middle is a <img alt="2^n\times 2^n" class="latex" src="https://s0.wp.com/latex.php?latex=2%5En%5Ctimes+2%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^n\times 2^n"/> matrix, so the calculating the inner product would require exponential time classically. However, recognizing that Clifford gates are normalizers of the Pauli Group on <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> qubits, note that <img alt="\mathcal{C}^{\dag}Z_1\mathcal{C} = P_1 \otimes \cdots \otimes P_n" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D%5E%7B%5Cdag%7DZ_1%5Cmathcal%7BC%7D+%3D+P_1+%5Cotimes+%5Ccdots+%5Cotimes+P_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{C}^{\dag}Z_1\mathcal{C} = P_1 \otimes \cdots \otimes P_n"/> where <img alt="P_i" class="latex" src="https://s0.wp.com/latex.php?latex=P_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P_i"/> is some Pauli matrix. It is straightforward to show that these update rules can be computed efficiently. We thus have</p>
<p><img alt="\langle\psi_0|\mathcal{C}^{\dag}Z_1\mathcal{C}|\psi_0\rangle = \langle\psi_0|P_1 \otimes \cdots \otimes P_n|\psi_0\rangle = \prod_{i = 1}^{n} \langle\alpha_i|P_i|\alpha_i\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clangle%5Cpsi_0%7C%5Cmathcal%7BC%7D%5E%7B%5Cdag%7DZ_1%5Cmathcal%7BC%7D%7C%5Cpsi_0%5Crangle+%3D+%5Clangle%5Cpsi_0%7CP_1+%5Cotimes+%5Ccdots+%5Cotimes+P_n%7C%5Cpsi_0%5Crangle+%3D+%5Cprod_%7Bi+%3D+1%7D%5E%7Bn%7D+%5Clangle%5Calpha_i%7CP_i%7C%5Calpha_i%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\langle\psi_0|\mathcal{C}^{\dag}Z_1\mathcal{C}|\psi_0\rangle = \langle\psi_0|P_1 \otimes \cdots \otimes P_n|\psi_0\rangle = \prod_{i = 1}^{n} \langle\alpha_i|P_i|\alpha_i\rangle"/></p>
<p>which is a product of <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> terms. We have thus reduced the (exponentially large) burden of computing a giant <img alt="2^n\times 2^n" class="latex" src="https://s0.wp.com/latex.php?latex=2%5En%5Ctimes+2%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^n\times 2^n"/> matrix<br/>
to computing <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> matrices size <img alt="2\times 2" class="latex" src="https://s0.wp.com/latex.php?latex=2%5Ctimes+2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2\times 2"/>, so we can sample the output distribution efficiently.</p>
<h2>The Firewall paradox and the Harlow-Hayden decoding task</h2>
<h3>Physics to CS</h3>
<div class="wp-caption aligncenter" id="attachment_7468" style="width: 411px;"><img alt="bh" class="alignnone  wp-image-7468" height="417" src="https://windowsontheory.files.wordpress.com/2019/02/bh.png?w=401&amp;h=417" width="401"/><p class="wp-caption-text">Figure 2: A cartoon representing drama (no pun intended) near the Black Hole.</p></div>
<p>All of the black hole physics covered in the previous blog post leads to the moment (we hope) you have been waiting for: a charming resolution of the firewall paradox. Consider the interior of an old, rusty black hole <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> that has radiated away more than half of its matter. Let <img alt="R" class="latex" src="https://s0.wp.com/latex.php?latex=R&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R"/> be the old Hawking radiation, and let <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> represent the fresh Hawking radiation coming right out of the boundary of the Black Hole. Alice is our canonical Ph.D. student who is brave enough to risk her life for physics. Since <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> is a giant information scrambler, we expect to find entanglement between <img alt="R" class="latex" src="https://s0.wp.com/latex.php?latex=R&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R"/> and <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> with overwhelming probability. We know from QFT that there are bell pairs straddling the event horizon of the black hole, so <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> and <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> should be maximally entangled. But this is a problem because <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> cannot be entangled with both <img alt="R" class="latex" src="https://s0.wp.com/latex.php?latex=R&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R"/> and <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/>! The AMPS argument shows that if Alice is able to distill a bell pair between <img alt="R" class="latex" src="https://s0.wp.com/latex.php?latex=R&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R"/> and <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/>, then we should see a firewall of photons at the event horizon, thus violating the no-drama postulate. See Figure 2 for more intuition about the set up. (Note that the <img alt="\cup" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ccup&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\cup"/>‘s represent Bell Pairs, as consistent with the 3D-Quon Language) If we take Black Hole complimentary seriously, then we have an answer! If Alice does not distill a Bell pair between <img alt="R" class="latex" src="https://s0.wp.com/latex.php?latex=R&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R"/> and <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/>, then nothing really happens. However, if Alice does manage to distill the entanglement between <img alt="R" class="latex" src="https://s0.wp.com/latex.php?latex=R&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R"/> and <img alt="B " class="latex" src="https://s0.wp.com/latex.php?latex=B+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B "/>, then we witness a firewall. Is not this answer so very unsatisfactory? Why should the existence of a firewall depend on Alice’s ability to distill entanglement? What is so special about this decoding task?<br/>
The H-H decoding task answers precisely this question. Intuitively, it says that if Alice manages to distill a Bell pair between <img alt="R" class="latex" src="https://s0.wp.com/latex.php?latex=R&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R"/> and <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/>, she could also invert a one-way function, a task we believe is very hard to perform! We conjecture that Alice would take exponential time to decode the entanglement, so the Black Hole would disappear long before Alice even makes a dent in the problem! Before we provide an in depth resolution of the paradox through the H-H decoding, let us (as good philosophers do) briefly review assumptions:</p>
<ol>
<li>The Black Hole <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> can be modelled by a finite collection of qubits, say <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> qubits.</li>
<li>Alice is told that the initial state of <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> is the product basis <img alt="|0\rangle^{\otimes n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7C0%5Crangle%5E%7B%5Cotimes+n%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|0\rangle^{\otimes n}"/>.</li>
<li>Black Hole dynamics are assumed to be unitary, so Alice need not worry about some spooky M-theory that may claim to evolve <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> in a non-unitary fashion.</li>
<li><img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> is a giant information scrambler, represented by some random circuit <img alt="\mathcal{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{C}"/>.</li>
<li>Fresh radiation <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> is a single qubit, w.l.o.g., since any additional qubits could be made a part of <img alt="R" class="latex" src="https://s0.wp.com/latex.php?latex=R&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R"/>.</li>
<li><img alt="|\psi\rangle_{RBH}" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle_%7BRBH%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi\rangle_{RBH}"/> is not Haar-Random. Mini-exercise: prove that if <img alt="|\psi\rangle_{RBH}" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle_%7BRBH%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi\rangle_{RBH}"/> is Haar-Random, our job becomes easy because the circuit complexity of the H-H decoding task grows exponentially with <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>, the size of <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/>.</li>
<li>Alice has access only to circuit <img alt="\mathcal{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{C}"/> and <img alt="R, B" class="latex" src="https://s0.wp.com/latex.php?latex=R%2C+B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R, B"/> but not <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/>. Trivial Mini-exercise: prove that if Alice has access to <img alt="R,B,H, \mathcal{C}" class="latex" src="https://s0.wp.com/latex.php?latex=R%2CB%2CH%2C+%5Cmathcal%7BC%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R,B,H, \mathcal{C}"/>, then it is easy to distill the entanglement between <img alt="R" class="latex" src="https://s0.wp.com/latex.php?latex=R&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R"/> and <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/>.</li>
<li>Alice may be an intellectual Goddess who just knows which unitary to apply, or, more realistically, someone who has exponential time to prepare before the Black Hole forms. Of crucial importance therefore is the circuit complexity of the unitary Alice applies to distill the Bell pair, not so much the process of finding the unitary.</li>
</ol>
<h3>Distilling the B-R Bell pair</h3>
<p>Let us jump into the definition of the <em>Harlow-Hayden decoding task</em>.</p>
<p><strong>Definition (Harlow-Hayden decoding task).</strong><br/>
Given a (polynomial-size) quantum circuit <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/> as input such that <img alt="|\psi\rangle_{RBH}=C|0^n\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle_%7BRBH%7D%3DC%7C0%5En%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi\rangle_{RBH}=C|0^n\rangle"/> where <img alt="R,B,H" class="latex" src="https://s0.wp.com/latex.php?latex=R%2CB%2CH&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R,B,H"/> are three disjoint part of the <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> qubits. Furthermore, it is guaranteed that there exists a unitary operator <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/> acting only on the qubits in <img alt="R" class="latex" src="https://s0.wp.com/latex.php?latex=R&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R"/> such that after applying <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/>, the rightmost bit of <img alt="R" class="latex" src="https://s0.wp.com/latex.php?latex=R&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R"/> and the leftmost bit of <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> forms a bell pair <img alt="\frac{|00\rangle+|11\rangle}{\sqrt{2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B%7C00%5Crangle%2B%7C11%5Crangle%7D%7B%5Csqrt%7B2%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\frac{|00\rangle+|11\rangle}{\sqrt{2}}"/>. The goal of the Harlow-Hayden decoding task is then to find a quantum circuit for such U on the qubits in <img alt="R" class="latex" src="https://s0.wp.com/latex.php?latex=R&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R"/>. See Figure 3.</p>
<div class="wp-caption aligncenter" id="attachment_7474" style="width: 410px;"><img alt="hhd" class="alignnone  wp-image-7474" height="238" src="https://windowsontheory.files.wordpress.com/2019/02/hhd.png?w=400&amp;h=238" width="400"/><p class="wp-caption-text">Figure 3: The Harlow-Hayden decoding task.</p></div>
<p>A necessary condition for the firewall paradox to make sense is that the Harlow-Hayden decoding task should be <em>easy</em>. If Alice cannot distill the entanglement efficiently, the black hole will evaporate before Alice is ready to witness the firewall!</p>
<p>To refute the firewall paradox, Harlow and Hayden proved the following theorem.</p>
<blockquote><p><strong>Theorem 1.<br/>
</strong>If the Harlow-Hayden decoding task can be done in <img alt="\mathbf{BQP/poly}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BBQP%2Fpoly%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{BQP/poly}"/>, then <img alt="\mathbf{SZK}\subseteq\mathbf{BQP/poly}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BSZK%7D%5Csubseteq%5Cmathbf%7BBQP%2Fpoly%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{SZK}\subseteq\mathbf{BQP/poly}"/>.<strong><br/>
</strong></p></blockquote>
<p>We won’t formally define the complexity class <img alt="\mathbf{SZK}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BSZK%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{SZK}"/>. However, it is important to know that the foundation of the lattice-based cryptography, a promising <em>quantum-secure</em> crypto framework, is based on the hardness of some problem in <img alt="\mathbf{SZK}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BSZK%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{SZK}"/>. If <img alt="\mathbf{SZK}\subseteq\mathbf{BQP/poly}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BSZK%7D%5Csubseteq%5Cmathbf%7BBQP%2Fpoly%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{SZK}\subseteq\mathbf{BQP/poly}"/>, then all lattice-based cryptosystems can be broken by polynomial time quantum algorithm!</p>
<p>Instead of a proof for Theorem 1, which is more involved, we give a proof for an improvement of the Harlow-Hayden theorem due to Scott Aaronson. (Aaronson also showed that there might not even exist quantum-secure cryptography if the Harlow-Hayden decoding task can be efficiently solved!)</p>
<h2>Aaronson’s improvement</h2>
<p>In Aaronson’s lecture notes [Aar16], he showed the following improvement on Theorem 1.</p>
<blockquote><p><strong>Theorem 2.</strong><br/>
If the Harlow-Hayden decoding task can be done in <img alt="\mathbf{BQP/poly}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BBQP%2Fpoly%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{BQP/poly}"/>, then quantum-secure injective one-way function does not exist.</p></blockquote>
<p>Before formally defining a one way function, it is paramount to understand its impact: modern cryptosystems are built from some variant of a one-way function. Intuitively, primitives that have the one-way property are (i) easy to implement (<em>e.g.,</em> encrypt) but (ii) hard to invert (<em>e.g.,</em> be attacked). As a result, if there is no quantum-secure injective one-way function, then that is strong evidence that quantum-secure cryptography might not exist.</p>
<p>Now, let us formally define what quantum-secure injective one-way function is and give a formal proof for Theorem 2.</p>
<blockquote><p><strong>Definition 1 (Quantum-secure injective one-way function).<br/>
</strong>A boolean function <img alt="f:\{0,1\}^n\rightarrow\{0,1\}^m" class="latex" src="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D%5En%5Crightarrow%5C%7B0%2C1%5C%7D%5Em&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f:\{0,1\}^n\rightarrow\{0,1\}^m"/> is a quantum-secure injective one-way function if</p>
<ul>
<li><img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> is injective,</li>
<li><img alt="f\in\mathbf{BQP/poly}" class="latex" src="https://s0.wp.com/latex.php?latex=f%5Cin%5Cmathbf%7BBQP%2Fpoly%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f\in\mathbf{BQP/poly}"/>, and</li>
<li>for any polynomial time quantum algorithm <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/></li>
</ul>
<div style="text-align: center;"><img alt="\Pr_{x\in\{0,1\}^n}[f(x)=f(A(f(x)))]\leq\frac{1}{\text{poly}(n)}." class="latex" src="https://s0.wp.com/latex.php?latex=%5CPr_%7Bx%5Cin%5C%7B0%2C1%5C%7D%5En%7D%5Bf%28x%29%3Df%28A%28f%28x%29%29%29%5D%5Cleq%5Cfrac%7B1%7D%7B%5Ctext%7Bpoly%7D%28n%29%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Pr_{x\in\{0,1\}^n}[f(x)=f(A(f(x)))]\leq\frac{1}{\text{poly}(n)}."/></div>
</blockquote>
<p>Note that since <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> is injective, the last condition can actually be phrased as <img alt="x=A(f(x))" class="latex" src="https://s0.wp.com/latex.php?latex=x%3DA%28f%28x%29%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x=A(f(x))"/>. Also, the condition should be read as “on input <img alt="f(x)" class="latex" src="https://s0.wp.com/latex.php?latex=f%28x%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f(x)"/>, the quantum algorithm <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> outputs <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/>”, namely, <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> inverts <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/>.</p>
<div><em>Proof:</em></div>
<div/>
<p>Suppose the Harlow-Hayden decoding task is in <img alt="\mathbf{BQP/poly}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BBQP%2Fpoly%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{BQP/poly}"/>, we are going to show that for any injective <img alt="f:\{0,1\}^n\rightarrow\{0,1\}^m" class="latex" src="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D%5En%5Crightarrow%5C%7B0%2C1%5C%7D%5Em&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f:\{0,1\}^n\rightarrow\{0,1\}^m"/> computable by some polynomial size quantum circuit, there is a polynomial time quantum algorithm that inverts <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/>. Namely, <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> is not a quantum-secure injective one-way function.To get an efficient inverting algorithm for <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/>, let us first prepare a special circuit <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/> from <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> and treat it as an input to the Harlow-Hayden decoding task. The circuit <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/> will simply map the <img alt="|0^{m+2+n}\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7C0%5E%7Bm%2B2%2Bn%7D%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|0^{m+2+n}\rangle"/> to the following state</p>
<p style="text-align: center;"><img alt="\frac{1}{\sqrt{2^{m+2+n}}}\sum_{x\in\{0,1\}^n}\left(|x,0^{m-n},0\rangle_R|0\rangle_B+|f(x),1\rangle_R|1\rangle_B\right)|x\rangle_H." class="latex" src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B%5Csqrt%7B2%5E%7Bm%2B2%2Bn%7D%7D%7D%5Csum_%7Bx%5Cin%5C%7B0%2C1%5C%7D%5En%7D%5Cleft%28%7Cx%2C0%5E%7Bm-n%7D%2C0%5Crangle_R%7C0%5Crangle_B%2B%7Cf%28x%29%2C1%5Crangle_R%7C1%5Crangle_B%5Cright%29%7Cx%5Crangle_H.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\frac{1}{\sqrt{2^{m+2+n}}}\sum_{x\in\{0,1\}^n}\left(|x,0^{m-n},0\rangle_R|0\rangle_B+|f(x),1\rangle_R|1\rangle_B\right)|x\rangle_H."/></p>
<p>Note that as <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> has a polynomial size quantum circuit, the circuit <img alt="\mathcal{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{C}"/> can also be implemented in polynomial size.Next, the easiness of the Harlow-Hayden decoding task guarantees us the existence of a unitary operation <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/> on the qubits in <img alt="R" class="latex" src="https://s0.wp.com/latex.php?latex=R&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R"/> such that for any <img alt="x\in\{0,1\}^n" class="latex" src="https://s0.wp.com/latex.php?latex=x%5Cin%5C%7B0%2C1%5C%7D%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x\in\{0,1\}^n"/></p>
<p style="text-align: center;"><img alt="U\left(\frac{|x,0^{m-n},0\rangle_R+|f(x),1\rangle_R}{\sqrt{2}}\right) = |\phi_x\rangle_R\left(\frac{|0\rangle+|1\rangle}{\sqrt{2}}\right)" class="latex" src="https://s0.wp.com/latex.php?latex=U%5Cleft%28%5Cfrac%7B%7Cx%2C0%5E%7Bm-n%7D%2C0%5Crangle_R%2B%7Cf%28x%29%2C1%5Crangle_R%7D%7B%5Csqrt%7B2%7D%7D%5Cright%29+%3D+%7C%5Cphi_x%5Crangle_R%5Cleft%28%5Cfrac%7B%7C0%5Crangle%2B%7C1%5Crangle%7D%7B%5Csqrt%7B2%7D%7D%5Cright%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U\left(\frac{|x,0^{m-n},0\rangle_R+|f(x),1\rangle_R}{\sqrt{2}}\right) = |\phi_x\rangle_R\left(\frac{|0\rangle+|1\rangle}{\sqrt{2}}\right)"/></p>
<p>for some state <img alt="|\phi_x\rangle_R" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cphi_x%5Crangle_R&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\phi_x\rangle_R"/>. By restricting <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/> on the first <img alt="m" class="latex" src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m"/> qubits, one can get unitary operators <img alt="V" class="latex" src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="V"/> and <img alt="W" class="latex" src="https://s0.wp.com/latex.php?latex=W&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="W"/> such that for all <img alt="x\in\{0,1\}^n" class="latex" src="https://s0.wp.com/latex.php?latex=x%5Cin%5C%7B0%2C1%5C%7D%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x\in\{0,1\}^n"/>,</p>
<p style="text-align: center;"><img alt="V|x,0^{m-n}\rangle=|\phi_x\rangle\text{ and }W|f(x)\rangle=|\phi_x\rangle." class="latex" src="https://s0.wp.com/latex.php?latex=V%7Cx%2C0%5E%7Bm-n%7D%5Crangle%3D%7C%5Cphi_x%5Crangle%5Ctext%7B+and+%7DW%7Cf%28x%29%5Crangle%3D%7C%5Cphi_x%5Crangle.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="V|x,0^{m-n}\rangle=|\phi_x\rangle\text{ and }W|f(x)\rangle=|\phi_x\rangle."/></p>
<p>Thus, <img alt="V^\dagger W" class="latex" src="https://s0.wp.com/latex.php?latex=V%5E%5Cdagger+W&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="V^\dagger W"/> inverts <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> because for any <img alt="x\in\{0,1\}^n" class="latex" src="https://s0.wp.com/latex.php?latex=x%5Cin%5C%7B0%2C1%5C%7D%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x\in\{0,1\}^n"/>,</p>
<p style="text-align: center;"><img alt="V^\dagger W|f(x)\rangle=|x,0^{m-n}\rangle." class="latex" src="https://s0.wp.com/latex.php?latex=V%5E%5Cdagger+W%7Cf%28x%29%5Crangle%3D%7Cx%2C0%5E%7Bm-n%7D%5Crangle.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="V^\dagger W|f(x)\rangle=|x,0^{m-n}\rangle."/></p>
<p>Furthermore, as we are guaranteed that the Harlow-Hayden decoding task is in <img alt="\mathbf{BQP/poly}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BBQP%2Fpoly%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{BQP/poly}"/>, <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/> as well as <img alt="V" class="latex" src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="V"/> and <img alt="W" class="latex" src="https://s0.wp.com/latex.php?latex=W&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="W"/> all have polynomial size quantum circuits! Namely, <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> can be efficiently inverted by a quantum algorithm and thus <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> is not a quantum-secure injective one-way function.</p>
<h2>What’s next?</h2>
<p>The Harlow-Hayden decoding task as well as the Aaronson’s improvement can be interpreted as (strong) evidence that distilling the B-R Bell pair is hard (in the worst-case<sup>2</sup>). One might hope for an <em>average-case</em> hardness for the Harlow-Hayden decoding task and thus infer that <em>most</em> black holes are difficult to distill. However, even if such average-case hardness results existed, physicists would still remain dissatisfied! The foremost grievance a physicist may have is the lack of a coherent causal framework to model reality. That is, what happens if, in the<br/>
very small but non-zero chance, a black hole is easy to distill? Does that mean that a firewall exists in such black hole? How can a unifying theory explain such situation coherently? An ideal theory for theoretical physicists should work for <em>every</em> black hole instead of for <em>most</em> black holes! Second, physicists seem to dislike the abstract, process-theoretic approach undertaken by computer scientists. Here, we have completely ignored talking about the internal dynamics of a black hole or even a full description of its evolving Hilbert space. They would, for instance, like to see a <em>differential equation</em> that captures the difficulty of distilling a black hole throughout its evolution. Resolutions to the firewall paradox or effort towards building a theory of quantum gravity should be somewhat <em>explicit</em> in the sense that one can really instantiate some (toy) examples from the theory and see how the system evolves and examine whether this fits the real experience from the world. In other words, a theory with a black box (<em>i.e.,</em> a complexity conjecture) might not be regarded as a resolution.</p>
<h3>Homework</h3>
<ol>
<li>What powers would Alice need to ensure that she can efficiently distill the B-R bell pair. What if we assume <img alt="\mathbf{P = PSPACE}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BP+%3D+PSPACE%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbf{P = PSPACE}"/>?</li>
<li>Can we show that the decoding is hard on average, rather than for the worst case?</li>
<li>What are some similar deep connections between black holes and complexity theory?</li>
<li>For people interested in the quantum complexity theory, there are many open problems regarding the quantum circuit complexity: consider the <em>unitary synthesis problem</em><sup>3</sup> proposed by Scott Aaronson [Aar16].</li>
<li>Another interesting problem is connecting the difficulty of proving quantum circuit lower bounds to other complexity problem such as classical circuit lower bounds or cryptographic assumptions.</li>
</ol>
<h2>Footnotes</h2>
<p><sup>1</sup>Non-trivial here means the unitary matrix <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/> is explicit in the sense that given <img alt="i,j\in[2^n]]" class="latex" src="https://s0.wp.com/latex.php?latex=i%2Cj%5Cin%5B2%5En%5D%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i,j\in[2^n]]"/>, one can efficiently compute <img alt="U_{ij}" class="latex" src="https://s0.wp.com/latex.php?latex=U_%7Bij%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U_{ij}"/>.<br/>
<sup>2</sup>Hard in worst-case means that there does not exist efficient algorithm that works on <em>every</em> input. Another hardness notion is hard on <em>average</em>, by which we mean there does not exist efficient algorithm the works for <em>most</em> of the input. Showing average-case hardness is in general a more difficult task than proving worst-case hardness.<br/>
<sup>3</sup>Does the following hold: for any unitary matrix <img alt="U\in\mathbb{C}^{2^n\times2^n}" class="latex" src="https://s0.wp.com/latex.php?latex=U%5Cin%5Cmathbb%7BC%7D%5E%7B2%5En%5Ctimes2%5En%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U\in\mathbb{C}^{2^n\times2^n}"/>, there exists a classical oracle <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> such that <img alt="C^A(U)=n^{O(1)}" class="latex" src="https://s0.wp.com/latex.php?latex=C%5EA%28U%29%3Dn%5E%7BO%281%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C^A(U)=n^{O(1)}"/> where <img alt="C^A(U)" class="latex" src="https://s0.wp.com/latex.php?latex=C%5EA%28U%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C^A(U)"/> is the minimum size of quantum circuit that approximates <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/> with oracle access to <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/>.</p>
<h2>References</h2>
<div>[Aar16] Scott Aaronson. The complexity of quantum states and transformations: from quantum money to black holes. <em>arXiv preprint arXiv:1607.05256</em>, 2016.</div>
<div/>
<div>[HH13] Daniel Harlow and Patrick Hayden. Quantum computation vs. firewalls.</div>
<div><em>Journal of High Energy Physics</em>, 2013(6):85, 2013.</div>
<div/>
<div>[NC02] Michael A Nielsen and Isaac Chuang. Quantum computation and quantum information, 2002.</div></div>
    </content>
    <updated>2019-02-01T05:44:24Z</updated>
    <published>2019-02-01T05:44:24Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Chi-Ning Chou</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2019-02-05T12:21:30Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/01/31/linkage</id>
    <link href="https://11011110.github.io/blog/2019/01/31/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>As usual, follow me on Mathstodon to see these as I post them rather than two weeks later.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>As usual, follow <a href="https://mathstodon.xyz/@11011110">me</a> on <a href="https://mathstodon.xyz">Mathstodon</a> to see these as I post them rather than two weeks later.</p>

<ul>
  <li>
    <p><a href="https://montrealgazette.com/news/organizers-fear-visa-issues-may-push-ai-conferences-to-avoid-canada">Half of the 200 people who needed visas to attend one of the satellite workshops of NeurIPS 2018 in Montreal were unable to get them in time</a> (<a href="https://mathstodon.xyz/@11011110/101429260698057077"/>, <a href="https://www.wired.com/story/canada-welcome">see also</a>), making it more likely that future conferences depending on international attendance will avoid Canada.</p>
  </li>
  <li>
    <p>This is not a cinnamon bun (<a href="https://mathstodon.xyz/@11011110/101438594980314031"/>). It’s actually a 160 million year old fossil snail shell from Madagascar, roughly the size of a large fist (or cinnamon bun). I don’t think it’s particularly rare or valuable; I picked it up because I liked its shape.</p>

    <p style="text-align: center;"><img alt="Fossil gastropod" src="https://www.ics.uci.edu/~eppstein/pix/gastropod/gastropod-m.jpg" style="border-style: solid; border-color: black;"/></p>
  </li>
  <li>
    <p><a href="https://www.ics.uci.edu/~nmamano/knightstour.html">Web site for generating knight’s tours of oversized chessboards with approximately-minimum numbers of bends and crossings</a> (<a href="https://mathstodon.xyz/@11011110/101445919833908876"/>). For background on how it works, see the short paper by Besa, Johnson, Mamano, and Osegueda (all UCI students) in <a href="https://doi.org/10.1007/978-3-030-04414-5"><em>Graph Drawing 2018</em></a> pp. 661–663 – unfortunately I don’t know of a non-paywalled link.</p>
  </li>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/Besse_Day">Besse Beulah Day</a> (<a href="https://mathstodon.xyz/@11011110/101451632049375948"/>), in the 1940s, was one of the first to apply the design of experiments to engineering, after previously having learned to use the technique in forestry. Jacqueline Telford wrote about her briefly in <a href="https://www.jhuapl.edu/techdigest/TD/td2703/telford.pdf">a 2007 survey</a>. Searching for the phrase “Besse Day, working at” finds that Telford’s account of Day’s work has been plagiarized by at least six other works. It’s a form of fame, I guess, to be copied so much.</p>
  </li>
  <li>
    <p><a href="https://theconversation.com/how-one-german-city-developed-and-then-lost-generations-of-math-geniuses-106750">The slow rise and rapid fall of Göttingen as the world capital of mathematics</a> (<a href="https://mathstodon.xyz/@11011110/101457036274744941"/>).</p>
  </li>
  <li>
    <p><a href="https://www.quantamagazine.org/carolina-araujo-is-building-a-network-of-women-in-mathematics-20190122/">An interview with Brazilian mathematician Carolina Araujo</a> (<a href="https://mathstodon.xyz/@11011110/101464602401203371"/>) on the gender gap in mathematics and what still needs to be done to close it.</p>
  </li>
  <li>
    <p><a href="https://doi.org/10.1038/s42256-018-0002-3">If you sample enough times from an unknown distribution over an unknown finite subset of , can you (with high probability) produce a finite set of measure at least ?</a> (<a href="https://mathstodon.xyz/@11011110/101470101768702252"/>, <a href="https://twitter.com/johncarlosbaez/status/1083055024119308288">via</a>, <a href="https://www.metafilter.com/178941/Learnability-can-be-undecidable">via2</a>). Your set does not need to consist only of the points you’ve sampled! You can do it if   for finite  but not otherwise.</p>
  </li>
  <li>
    <p><a href="https://agtb.wordpress.com/2019/01/22/guest-post-like-a-swarm-of-locusts-vijay-vazirani/">Vijay Vazirani on the flocking behavior of theoretical computer scientists</a> (<a href="https://mathstodon.xyz/@11011110/101472666044751626"/>). Vijay’s post also includes an announcement for a semester-long <a href="https://simons.berkeley.edu/programs/market2019">program on online and matching-based market design</a> at the Simons Institute in Berkeley.</p>
  </li>
  <li>
    <p>The view from my desk (<a href="https://mathstodon.xyz/@11011110/101478744747251421"/>). Actually my office has lots of windows with a nice view of a well-used plaza, outdoor coffee shop, trees, and distant mountains. But to see that, I have to get up and go over to one of the windows. If I stay at my desk and look up at the window, I see this interesting geometric pattern instead.</p>

    <p style="text-align: center;"><img alt="UC Irvine's CalIT2 building from Donald Bren Hall, room 4082" src="https://www.ics.uci.edu/~eppstein/pix/deskview/deskview-m.jpg" style="border-style: solid; border-color: black;"/></p>
  </li>
  <li>
    <p><a href="https://scholar.social/@GerardWestendorp/101478161346333486">Gerard Westendorp made a snowdecahedron</a> but <a href="https://scholar.social/@GerardWestendorp/101483814063002454">global warming melted it</a>.</p>
  </li>
  <li>
    <p><a href="http://homepages.gac.edu/~jsiehler/games/blocks-start.html">Online sliding block puzzles</a> (<a href="https://mathstodon.xyz/@jsiehler/101472426764291238"/>) by
Jacob Siehler. The goal is to swap the positions of two colored blocks. Even the easy ones are non-obvious.</p>
  </li>
  <li>
    <p>Cute proof of <a href="https://en.wikipedia.org/wiki/Sperner%27s_theorem">Sperner’s theorem</a> (<a href="https://mathstodon.xyz/@11011110/101495343260074941"/>) from a talk by R. P. Stanley: represent subsets of  by strings of<br/>
 parentheses, “)” in position  if  is in the set, “(” otherwise. In each string, flip the first unmatched “(”, grouping the subsets into chains like (()(( – )()(( – )())( – )())). Each chain touches the middle level once, and any other antichain at most once, so the middle level is the biggest antichain.</p>
  </li>
  <li>
    <p>Two triangles in a convex point set can cross or overlap in eight configurations, colorfully named the taco, mariposa, bat, nested, crossing, ears, swords, and david by “<a href="https://www.combinatorics.org/ojs/index.php/eljc/article/view/v26i1p8">More Turán-Type Theorems for Triangles in Convex Point Sets</a>”, a new paper in <em>Elect. J. Comb.</em> by Aronov, Dujmović, Morin, Ooms, and Schultz (<a href="https://mathstodon.xyz/@11011110/101507914773539844"/>). For 246 of the 256 subsets of configurations, they find near-max families of triangles avoiding the subset. The remaining 8 subsets are equivalent to “tripod packing”, which is less well-understood but the subject of another newly published paper, “<a href="https://doi.org/10.1007/s00454-018-0012-2">New Results on Tripod Packings</a>” (<em>Discrete Comput. Geom.</em>, by Östergård and Pöllänen). The tripod problem has a complicated history of independent rediscovery, not all of which was known to Östergård and Pöllänen, so see the <em>EJC</em> paper for a more thorough survey.</p>
  </li>
  <li>
    <p><a href="https://mathvis.academic.wlu.edu/2017/07/13/creating-a-3d-printable-lorenz-attractor/">Creating a 3D-printable Lorenz attractor</a> (<a href="https://mathstodon.xyz/@11011110/101514403573957983"/>). From Elizabeth Denne’s <a href="https://mathvis.academic.wlu.edu">“Visions in Math” blog</a> which, sadly, seems to have gone on hiatus after publishing this in 2017.</p>
  </li>
</ul></div>
    </content>
    <updated>2019-01-31T21:27:00Z</updated>
    <published>2019-01-31T21:27:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-02-01T06:51:08Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-5538403199779655367</id>
    <link href="https://blog.computationalcomplexity.org/feeds/5538403199779655367/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/01/phish-before-turkey.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/5538403199779655367" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/5538403199779655367" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/01/phish-before-turkey.html" rel="alternate" type="text/html"/>
    <title>Phish Before Turkey</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">The Chronicle of Higher Education recently published a story <a href="https://www.chronicle.com/article/Phishing-Scheme-Targets/245535">Phishing Scheme Targets Professors’ Desire to Please Their Deans — All for $500 in Gift Cards</a>. The same thing happened to me last fall.<br/>
<br/>
Twas the day before Thanksgiving and an email went out to most of the faculty in my department.<br/>
<blockquote class="tr_bq">
<b>From: </b>Lance Fortnow &lt;lancefortnow@yahoo.com&gt;<br/>
<b>Sent: </b>Wednesday, November 21, 2018 1:45 PM<br/>
<b>To: </b>[name deleted]<br/>
<b>Subject:</b> </blockquote>
<blockquote class="tr_bq">
Hello,are you available?</blockquote>
At the time I was in New Jersey visiting family. lancefortnow@yahoo.com is not my email. I do own fortnow@yahoo.com but don't email there, I rarely check it.<br/>
<br/>
Some faculty checked with me to see if this is real. One faculty called me to see what I wanted. Once I found out what was happening I sent a message to my entire faculty to ignore those emails.<br/>
<br/>
Some faculty did reply to see what I want. The response:<br/>
<blockquote class="tr_bq">
i need you to help me get an Amazon gifts card from the store,i will reimburse you back when i get to the office.</blockquote>
One of our security faculty decided to follow up and replied "Sure! Let me get them for you. Could you provide more more information? e.g., amount and #cards. I can bring them on Monday." The reply:<br/>
<blockquote class="tr_bq">
The amount i want is $100 each in two (2) piece so that will make it a total of $200 l'll be reimbursing back to you.i need physical cards which you are going to get from the store. When you get them,just scratch it and take a picture of them and attach it to the email then send it to me here ok</blockquote>
<div>
He went a few more rounds before the phisher just stopped responding.</div>
<div>
<br/></div>
<div>
A week later, a different faculty member came to my office and said I wanted to see him but he's been out of town. I said it was nice to see him but I didn't ask to talk to him and we figured out the confusion was the phishing email.</div>
<div>
<br/></div>
<div>
Someone went through the trouble of creating a fake email address in my name, looking up the email addresses of the faculty in the department and individually emailing each of them, without realizing computer science professors won't fall for a gift card phishing attack. Or at least none of them admitted falling for it.</div></div>
    </content>
    <updated>2019-01-31T16:46:00Z</updated>
    <published>2019-01-31T16:46:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>https://plus.google.com/101693130490639305932</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>https://plus.google.com/101693130490639305932</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-02-05T10:55:52Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/013</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/013" rel="alternate" type="text/html"/>
    <title>TR19-013 |  CSPs with Global Modular Constraints: Algorithms and Hardness via Polynomial Representations | 

	Joshua Brakensiek, 

	Sivakanth Gopi, 

	Venkatesan Guruswami</title>
    <summary>We study the complexity of Boolean constraint satisfaction problems (CSPs) when the assignment must have Hamming weight in some congruence class modulo $M$, for various choices of the modulus $M$. Due to the known classification of tractable Boolean CSPs, this mainly reduces to the study of three cases: 2SAT, HornSAT, and LIN-MOD2 (linear equations mod $2$). We classify the moduli $M$ for which these respective problems are polynomial time solvable, and when they are not (assuming the ETH). Our study reveals that this modular constraint lends a surprising richness to these classic, well-studied problems, with interesting broader connections to complexity theory and coding theory. The HornSAT case is connected to the covering complexity of polynomials representing the NAND function mod $M$. The LIN-MOD2 case is tied to the sparsity of polynomials representing the OR function mod $M$, which in turn has connections to modular weight distribution properties of linear codes and locally decodable codes. In both cases, the analysis of our algorithm as well as the hardness reduction rely on these polynomial representations, highlighting an interesting algebraic common ground between hard cases for our algorithms and the gadgets which show hardness. These new complexity measures of polynomial representations merit further study.

The inspiration for our study comes from a recent work by Nägele, Sudakov, and Zenklusen on submodular minimization with a global congruence constraint. Our algorithm for HornSAT has strong similarities to their algorithm, and in particular identical kind of set systems arise in both cases. Our connection to polynomial representations leads to a simpler analysis of such set systems, and also sheds light on (but does not resolve) the complexity of submodular minimization with a congruency requirement modulo a composite $M$.</summary>
    <updated>2019-01-31T15:15:39Z</updated>
    <published>2019-01-31T15:15:39Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-02-05T12:20:46Z</updated>
    </source>
  </entry>
</feed>
