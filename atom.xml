<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2022-02-17T22:55:33Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/019</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/019" rel="alternate" type="text/html"/>
    <title>TR22-019 |  Simulation Methods in Communication Lower Bounds, Revisited | 

	Guangxu Yang, 

	Jiapeng Zhang</title>
    <summary>The notion of lifting theorems is a generic method to lift hardness of one-party functions to two-party lower bounds in communication model. It has many applications in different areas such as proof complexity, game theory, combinatorial optimization. Among many lifting results, a central idea is called Raz-McKenize simulation (FOCS 1997). This simulation provides a systematic way to convert a communication protocol into a corresponding decision tree. Though it is very convenient in many applications, there are still some challenges in this framework. A major problem is that Raz-McKenize simulation requires a very large gadget.

In this paper, we revise Raz-McKenzie simulation. We introduce a white-box simulation, proving lifting theorems for block sensitivity with constant-size gadgets. Concretely, we show there is a constant-size gadget $g$ such that for any Boolean function $f$, the corruption bound of $f\circ g^n$ is lower bounded by $\Omega(\mathrm{bs}(f))$. Combined with a result of Beame et al. (CCC 2005), this implies the randomized communication complexity of $f\circ g^n$ is lower bounded by $\Omega(\mathrm{bs}(f))$. Besides the result itself, we believe our simulation technique may have more applications in diverse areas. We also discuss why our simulation method has a potential to avoid the large-size gadget bottleneck in Raz-McKenzie simulation.</summary>
    <updated>2022-02-17T09:45:11Z</updated>
    <published>2022-02-17T09:45:11Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-02-17T22:53:07Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.08214</id>
    <link href="http://arxiv.org/abs/2202.08214" rel="alternate" type="text/html"/>
    <title>Resolution with Counting: Lower Bounds for Proofs of Membership in the Complement of a Linear Map Image of the Boolean Cube</title>
    <feedworld_mtime>1645056000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Part:Fedor.html">Fedor Part</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.08214">PDF</a><br/><b>Abstract: </b>We propose a new approach to proving lower bounds for sizes of dag-like
proofs in the proof system Res(lin$_{\mathbb{F}_p}$), where $\mathbb{F}_p$ is a
finite field of prime order $p\geq 5$. An exponential lower bound on sizes of
arbitrary dag-like refutations in proof systems Res(lin$_{\mathbb{F}}$) has
previously been proven in (Part, Tzameret, ITCS'20) in case $\mathbb{F}$ is a
field of characteristic $0$ for an instance, which is not CNF: for the binary
value principle $x_1+2x_2+\dots+2^{n-1}x_n = -1$. The proof of this lower bound
substantially uses peculiarities of characteristic $0$ regime and does not give
a clue on how to prove lower bounds neither for finite fields nor for CNFs.
Aiming at constructing a bridge between lower bounds for the binary value
principle and CNF lower bounds we initiate the development of methods for
proving dag-like Res(lin$_{\mathbb{F}_p}$) lower bounds for tautologies of the
form $b\notin A(\{0,1\}^n)$, where $A$ is a linear map. The negation of such a
tautology can be represented in the language of Res(lin$_{\mathbb{F}_p}$) as a
system of linear equations $A\cdot x = b$ unsatisfiable over the boolean
assignments. Instances of this form are in some ways simpler than CNFs, this
makes analysis of their Res(lin$_{\mathbb{F}_p}$) refutations more approachable
and might be aided by tools from linear algebra and additive combinatorics.
</p>
<p>We identify hardness criterions for instances of the form $A\cdot x = b$
using notions of an error correcting code and what we call $(s, r)$-robustness,
a combinatorial, algebraic property of linear systems $A\cdot x = b$, which we
introduce. We prove two lower bounds for fragments of Res(lin$_{\mathbb{F}_p}$)
that capture two complementary aspects of Res(lin$_{\mathbb{F}_p}$) refutations
and constitute a combinatorial toolbox for approaching general dag-like
Res(lin$_{\mathbb{F}_p}$) refutations.
</p></div>
    </summary>
    <updated>2022-02-17T22:44:57Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2022-02-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.08186</id>
    <link href="http://arxiv.org/abs/2202.08186" rel="alternate" type="text/html"/>
    <title>Quantum speedups for treewidth</title>
    <feedworld_mtime>1645056000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Vladislavs Kļevickis, Krišjānis Prūsis, Jevgēnijs Vihrovs <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.08186">PDF</a><br/><b>Abstract: </b>In this paper, we study quantum algorithms for computing the exact value of
the treewidth of a graph. Our algorithms are based on the classical algorithm
by Fomin and Villanger (Combinatorica 32, 2012) that uses $O(2.616^n)$ time and
polynomial space. We show three quantum algorithms with the following
complexity, using QRAM in both exponential space algorithms: $\bullet$
$O(1.618^n)$ time and polynomial space; $\bullet$ $O(1.554^n)$ time and
$O(1.452^n)$ space; $\bullet$ $O(1.538^n)$ time and space. In contrast, the
fastest known classical algorithm for treewidth uses $O(1.755^n)$ time and
space. The first two speed-ups are obtained in a fairly straightforward way.
The first version uses additionally only Grover's search and provides a
quadratic speedup. The second speedup is more time-efficient and uses both
Grover's search and the quantum exponential dynamic programming by Ambainis et
al. (SODA '19). The third version uses the specific properties of the classical
algorithm and treewidth, with a modified version of the quantum dynamic
programming on the hypercube. Lastly, as a small side result, we also give a
new classical time-space tradeoff for computing treewidth in $O^*(2^n)$ time
and $O^*(\sqrt{2^n})$ space.
</p></div>
    </summary>
    <updated>2022-02-17T22:43:33Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2022-02-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.08173</id>
    <link href="http://arxiv.org/abs/2202.08173" rel="alternate" type="text/html"/>
    <title>Distributed k-Means with Outliers in General Metrics</title>
    <feedworld_mtime>1645056000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Enrico Dandolo, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pietracaprina:Andrea.html">Andrea Pietracaprina</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pucci:Geppino.html">Geppino Pucci</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.08173">PDF</a><br/><b>Abstract: </b>Center-based clustering is a pivotal primitive for unsupervised learning and
data analysis. A popular variant is undoubtedly the k-means problem, which,
given a set $P$ of points from a metric space and a parameter $k&lt;|P|$, requires
to determine a subset $S$ of $k$ centers minimizing the sum of all squared
distances of points in $P$ from their closest center. A more general
formulation, known as k-means with $z$ outliers, introduced to deal with noisy
datasets, features a further parameter $z$ and allows up to $z$ points of $P$
(outliers) to be disregarded when computing the aforementioned sum. We present
a distributed coreset-based 3-round approximation algorithm for k-means with
$z$ outliers for general metric spaces, using MapReduce as a computational
model. Our distributed algorithm requires sublinear local memory per reducer,
and yields a solution whose approximation ratio is an additive term $O(\gamma)$
away from the one achievable by the best known sequential (possibly bicriteria)
algorithm, where $\gamma$ can be made arbitrarily small. An important feature
of our algorithm is that it obliviously adapts to the intrinsic complexity of
the dataset, captured by the doubling dimension $D$ of the metric space. To the
best of our knowledge, no previous distributed approaches were able to attain
similar quality-performance tradeoffs for general metrics.
</p></div>
    </summary>
    <updated>2022-02-17T22:50:42Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-02-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.08119</id>
    <link href="http://arxiv.org/abs/2202.08119" rel="alternate" type="text/html"/>
    <title>The Parameterized Complexity of Quantum Verification</title>
    <feedworld_mtime>1645056000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Arunachalam:Srinivasan.html">Srinivasan Arunachalam</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bravyi:Sergey.html">Sergey Bravyi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nirkhe:Chinmay.html">Chinmay Nirkhe</a>, Bryan O'Gorman <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.08119">PDF</a><br/><b>Abstract: </b>We initiate the study of parameterized complexity of $\textsf{QMA}$ problems
in terms of the number of non-Clifford gates in the problem description. We
show that for the problem of parameterized quantum circuit satisfiability,
there exists a classical algorithm solving the problem with a runtime scaling
exponentially in the number of non-Clifford gates but only polynomially with
the system size. This result follows from our main result, that for any
Clifford + $t$ $T$-gate quantum circuit satisfiability problem, the search
space of optimal witnesses can be reduced to a stabilizer subspace isomorphic
to at most $t$ qubits (independent of the system size). Furthermore, we derive
new lower bounds on the $T$-count of circuit satisfiability instances and the
$T$-count of the $W$-state assuming the classical exponential time hypothesis
($\textsf{ETH}$). Lastly, we explore the parameterized complexity of the
quantum non-identity check problem.
</p></div>
    </summary>
    <updated>2022-02-17T22:41:58Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2022-02-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.08106</id>
    <link href="http://arxiv.org/abs/2202.08106" rel="alternate" type="text/html"/>
    <title>Sparse polynomial interpolation and division in soft-linear time</title>
    <feedworld_mtime>1645056000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Giorgi:Pascal.html">Pascal Giorgi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Grenet:Bruno.html">Bruno Grenet</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cray:Armelle_Perret_du.html">Armelle Perret du Cray</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Roche:Daniel_S=.html">Daniel S. Roche</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.08106">PDF</a><br/><b>Abstract: </b>Given a way to evaluate an unknown polynomial with integer coefficients, we
present new algorithms to recover its nonzero coefficients and corresponding
exponents. As an application, we adapt this interpolation algorithm to the
problem of computing the exact quotient of two given polynomials. These methods
are efficient in terms of the bit-length of the sparse representation, that is,
the number of nonzero terms, the size of coefficients, the number of variables,
and the logarithm of the degree. At the core of our results is a new Monte
Carlo randomized algorithm to recover an integer polynomial $f(x)$ given a way
to evaluate $f(\theta) \bmod m$ for any chosen integers $\theta$ and $m$. This
algorithm has nearly-optimal bit complexity, meaning that the total bit-length
of the probes, as well as the computational running time, is softly linear
(ignoring logarithmic factors) in the bit-length of the resulting sparse
polynomial. To our knowledge, this is the first sparse interpolation algorithm
with soft-linear bit complexity in the total output size. For integer
polynomials, the best previously known results have at least a cubic dependency
on the bit-length of the exponents.
</p></div>
    </summary>
    <updated>2022-02-17T22:41:17Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2022-02-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.08066</id>
    <link href="http://arxiv.org/abs/2202.08066" rel="alternate" type="text/html"/>
    <title>Almost-Optimal Sublinear-Time Edit Distance in the Low Distance Regime</title>
    <feedworld_mtime>1645056000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bringmann:Karl.html">Karl Bringmann</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cassis:Alejandro.html">Alejandro Cassis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fischer:Nick.html">Nick Fischer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nakos:Vasileios.html">Vasileios Nakos</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.08066">PDF</a><br/><b>Abstract: </b>We revisit the task of computing the edit distance in sublinear time. In the
$(k,K)$-gap edit distance problem the task is to distinguish whether the edit
distance of two strings is at most $k$ or at least $K$. It has been established
by Goldenberg, Krauthgamer and Saha (FOCS '19), with improvements by Kociumaka
and Saha (FOCS '20), that the $(k,k^2)$-gap problem can be solved in time
$\widetilde O(n/k+\operatorname{poly}(k))$. One of the most natural questions
in this line of research is whether the $(k,k^2)$-gap is best-possible for the
running time $\widetilde O(n/k+\operatorname{poly}(k))$.
</p>
<p>In this work we answer this question by significantly improving the gap.
Specifically, we show that in time $O(n/k+\operatorname{poly}(k))$ we can even
solve the $(k,k^{1+o(1)})$-gap problem. This is the first algorithm that breaks
the $(k,k^2)$-gap in this running time. Our algorithm is almost optimal in the
following sense: In the low distance regime ($k\le n^{0.19}$) our running time
becomes $O(n/k)$, which matches a known $n/k^{1+o(1)}$ lower bound for the
$(k,k^{1+o(1)})$-gap problem up to lower order factors.
</p>
<p>Our result also reveals a surprising similarity of Hamming distance and edit
distance in the low distance regime: For both, the $(k,k^{1+o(1)})$-gap problem
has time complexity $n/k^{1\pm o(1)}$ for small $k$.
</p>
<p>In contrast to previous work, which employed a subsampled variant of the
Landau-Vishkin algorithm, we instead build upon the algorithm of Andoni,
Krauthgamer and Onak (FOCS '10). We first simplify their approach and then show
how to to effectively prune their computation tree in order to obtain a
sublinear-time algorithm in the given time bound. Towards that, we use a
variety of structural insights on the (local and global) patterns that can
emerge during this process and design appropriate property testers to
effectively detect these patterns.
</p></div>
    </summary>
    <updated>2022-02-17T22:45:06Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-02-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.08035</id>
    <link href="http://arxiv.org/abs/2202.08035" rel="alternate" type="text/html"/>
    <title>The Pareto cover problem</title>
    <feedworld_mtime>1645056000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Natura:Bento.html">Bento Natura</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Neuwohner:Meike.html">Meike Neuwohner</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Weltge:Stefan.html">Stefan Weltge</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.08035">PDF</a><br/><b>Abstract: </b>We introduce the problem of finding a set $B$ of $k$ points in $[0,1]^n$ such
that the expected cost of the cheapest point in $B$ that dominates a random
point from $[0,1]^n$ is minimized. We study the case where the coordinates of
the random points are independently distributed and the cost function is
linear. This problem arises naturally in various application areas where
customers' requests are satisfied based on predefined products, each
corresponding to a subset of features. We show that the problem is NP-hard
already for $k=2$ when each coordinate is drawn from $\{0,1\}$, and obtain an
FPTAS for general fixed $k$ under mild assumptions on the distributions.
</p></div>
    </summary>
    <updated>2022-02-17T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2022-02-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.07961</id>
    <link href="http://arxiv.org/abs/2202.07961" rel="alternate" type="text/html"/>
    <title>Identity testing for radical expressions</title>
    <feedworld_mtime>1645056000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Balaji:Nikhil.html">Nikhil Balaji</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nosan:Klara.html">Klara Nosan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shirmohammadi:Mahsa.html">Mahsa Shirmohammadi</a>, James Worrell <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.07961">PDF</a><br/><b>Abstract: </b>We study the \emph{Radical Identity Testing} problem (RIT): Given an
algebraic circuit representing a multivariate polynomial $f(x_1, \dots, x_k)$
and nonnegative integers $a_1, \dots, a_k$ and $d_1, \dots,$ $d_k$, written in
binary, test whether the polynomial vanishes at the \emph{real radicals}
$\sqrt[d_1]{a_1}, \dots,\sqrt[d_k]{a_k}$, i.e., test whether
$f(\sqrt[d_1]{a_1}, \dots, \sqrt[d_k]{a_k}) = 0$. We place the problem in
{\coNP} assuming the Generalised Riemann Hypothesis (GRH), improving on the
straightforward {\PSPACE} upper bound obtained by reduction to the existential
theory of reals. Next we consider a restricted version, called $2$-RIT, where
the radicals are square roots of prime numbers, written in binary. It was known
since the work of Chen and Kao~\cite{chen-kao} that $2$-RIT is at least as hard
as the polynomial identity testing problem, however no better upper bound than
{\PSPACE} was known prior to our work. We show that $2$-RIT is in {\coRP}
assuming GRH and in {\coNP} unconditionally. %While prior work~\cite{blomer98,
chen-kao} on {\rit} relied on methods based on numerical approximation, we use
a symbolic approach and reduce the problem to evaluating the polynomial modulo
suitable prime ideals in the ring of integers of the number field
$\mathbb{Q}(\sqrt[d_1]{a_1}, \dots, \sqrt[d_k]{a_k})$. Our proof relies on
theorems from algebraic and analytic number theory, such as the Chebotarev
density theorem and quadratic reciprocity.
</p></div>
    </summary>
    <updated>2022-02-17T22:44:30Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2022-02-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.07932</id>
    <link href="http://arxiv.org/abs/2202.07932" rel="alternate" type="text/html"/>
    <title>On the Complexity of Scheduling Problems With a Fixed Number of Identical Machines</title>
    <feedworld_mtime>1645056000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jansen:Klaus.html">Klaus Jansen</a>, Kai Kahler <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.07932">PDF</a><br/><b>Abstract: </b>In scheduling, we are given a set of jobs, together with a number of machines
and our goal is to decide for every job, when and on which machine(s) it should
be scheduled in order to minimize some objective function. Different machine
models, job characteristics and objective functions result in a multitude of
scheduling problems and many of them are NP-hard, even for a fixed number of
identical machines. However, using pseudo-polynomial or approximation
algorithms, we can still hope to solve some of these problems efficiently. In
this work, we give conditional running time lower bounds for a large number of
scheduling problems, indicating the optimality of some classical algorithms. In
particular, we show that the dynamic programming algorithm by Lawler and Moore
is probably optimal for $1||\sum w_jU_j$ and $Pm||C_{max}$. Moreover, the FPTAS
by Gens and Levner for $1||\sum w_jU_j$ and the algorithm by Lee and Uzsoy for
$P2||\sum w_jC_j$ are probably optimal as well. There is still small room for
improvement for the $1|Rej\leq Q|\sum w_jU_j$ algorithm by Zhang et al. and the
algorithm for $1||\sum T_j$ by Lawler. We also give a lower bound for
$P2|any|C_{max}$ and improve the dynamic program by Du and Leung from
$\mathcal{O}(nP^2)$ to $\mathcal{O}(nP)$ to match this lower bound. Here, $P$
is the sum of all processing times. The same idea also improves the algorithm
for $P3|any|C_{max}$ by Du and Leung from $\mathcal{O}(nP^5)$ to
$\mathcal{O}(nP^2)$. The lower bounds in this work all either rely on the
(Strong) Exponential Time Hypothesis or the $(\min,+)$-conjecture. While our
results suggest the optimality of some classical algorithms, they also motivate
future research in cases where the best known algorithms do not quite match the
lower bounds.
</p></div>
    </summary>
    <updated>2022-02-17T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-02-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.07885</id>
    <link href="http://arxiv.org/abs/2202.07885" rel="alternate" type="text/html"/>
    <title>An Optimal-Time RLBWT Construction in BWT-runs Bounded Space</title>
    <feedworld_mtime>1645056000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nishimoto:Takaaki.html">Takaaki Nishimoto</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kanda:Shunsuke.html">Shunsuke Kanda</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tabei:Yasuo.html">Yasuo Tabei</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.07885">PDF</a><br/><b>Abstract: </b>The compression of highly repetitive strings (i.e., strings with many
repetitions) has been a central research topic in string processing, and quite
a few compression methods for these strings have been proposed thus far. Among
them, an efficient compression format gathering increasing attention is the
run-length Burrows--Wheeler transform (RLBWT), which is a run-length encoded
BWT as a reversible permutation of an input string on the lexicographical order
of suffixes. State-of-the-art construction algorithms of RLBWT have a serious
issue with respect to (i) non-optimal computation time or (ii) a working space
that is linearly proportional to the length of an input string. In this paper,
we present \emph{r-comp}, the first optimal-time construction algorithm of
RLBWT in BWT-runs bounded space. That is, the computational complexity of
r-comp is $O(n + r \log{r})$ time and $O(r\log{n})$ bits of working space for
the length $n$ of an input string and the number $r$ of equal-letter runs in
BWT. The computation time is optimal (i.e., $O(n)$) for strings with the
property $r=O(n/\log{n})$, which holds for most highly repetitive strings.
Experiments using a real-world dataset of highly repetitive strings show the
effectiveness of r-comp with respect to computation time and space.
</p></div>
    </summary>
    <updated>2022-02-17T22:51:36Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-02-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.07793</id>
    <link href="http://arxiv.org/abs/2202.07793" rel="alternate" type="text/html"/>
    <title>Heuristic computation of exact treewidth</title>
    <feedworld_mtime>1645056000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tamaki:Hisao.html">Hisao Tamaki</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.07793">PDF</a><br/><b>Abstract: </b>We are interested in computing the treewidth $\tw(G)$ of a given graph $G$.
Our approach is to design heuristic algorithms for computing a sequence of
improving upper bounds and a sequence of improving lower bounds, which would
hopefully converge to $\tw(G)$ from both sides. The upper bound algorithm
extends and simplifies Tamaki's unpublished work on a heuristic use of the
dynamic programming algorithm for deciding treewidth due to Bouchitt\'{e} and
Todinca. The lower bound algorithm is based on the well-known fact that, for
every minor $H$ of $G$, we have $\tw(H) \leq \tw(G)$. Starting from a greedily
computed minor $H_0$ of $G$, the algorithm tries to construct a sequence of
minors $H_0$, $H_1$, \ldots $H_k$ with $\tw(H_i) &lt; \tw(H_{i + 1})$ for $0 \leq
i &lt; k$ and hopefully $\tw(H_k) = \tw(G)$.
</p>
<p>We have implemented a treewidth solver based on this approach and have
evaluated it on the bonus instances from the exact treewidth track of PACE 2017
algorithm implementation challenge. The results show that our approach is
extremely effective in tackling instances that are hard for conventional
solvers. Our solver has an additional advantage over conventional ones in that
it attaches a compact certificate to the lower bound it computes.
</p></div>
    </summary>
    <updated>2022-02-17T22:49:59Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-02-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.07777</id>
    <link href="http://arxiv.org/abs/2202.07777" rel="alternate" type="text/html"/>
    <title>Generalizing continuous flexible Kokotsakis belts of the isogonal type</title>
    <feedworld_mtime>1645056000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nawratil:Georg.html">Georg Nawratil</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.07777">PDF</a><br/><b>Abstract: </b>Kokotsakis studied the following problem in 1932: Given is a rigid closed
polygonal line (planar or non-planar), which is surrounded by a polyhedral
strip, where at each polygon vertex three faces meet. Determine the geometries
of these closed strips with a continuous mobility. On the one side, we
generalize this problem by allowing the faces, which are adjacent to polygon
line-segments, to be skew; i.e to be non-planar. But on the other side, we
restrict to the case where the four angles associated with each polygon vertex
fulfill the so-called isogonality condition that both pairs of opposite angles
are equal or supplementary. In more detail, we study the case where the
polygonal line is a skew quad, as this corresponds to a (3x3) building block of
a so-called V-hedra composed of skew quads. The latter also gives a positive
answer to a question posed by Robert Sauer in his book of 1970 whether
continuous flexible skew quad surfaces exist.
</p></div>
    </summary>
    <updated>2022-02-17T22:52:35Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2022-02-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.07761</id>
    <link href="http://arxiv.org/abs/2202.07761" rel="alternate" type="text/html"/>
    <title>Further Collapses in TFNP</title>
    <feedworld_mtime>1645056000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/G=ouml==ouml=s:Mika.html">Mika Göös</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hollender:Alexandros.html">Alexandros Hollender</a>, Siddhartha Jain, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Maystre:Gilbert.html">Gilbert Maystre</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pires:William.html">William Pires</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Robere:Robert.html">Robert Robere</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tao:Ran.html">Ran Tao</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.07761">PDF</a><br/><b>Abstract: </b>We show $\textsf{EOPL}=\textsf{PLS}\cap\textsf{PPAD}$. Here the class
$\textsf{EOPL}$ consists of all total search problems that reduce to the
End-of-Potential-Line problem, which was introduced in the works by Hubacek and
Yogev (SICOMP 2020) and Fearnley et al. (JCSS 2020). In particular, our result
yields a new simpler proof of the breakthrough collapse
$\textsf{CLS}=\textsf{PLS}\cap\textsf{PPAD}$ by Fearnley et al. (STOC 2021). We
also prove a companion result $\textsf{SOPL}=\textsf{PLS}\cap\textsf{PPADS}$,
where $\textsf{SOPL}$ is the class associated with the Sink-of-Potential-Line
problem.
</p></div>
    </summary>
    <updated>2022-02-17T22:42:24Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2022-02-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.07736</id>
    <link href="http://arxiv.org/abs/2202.07736" rel="alternate" type="text/html"/>
    <title>Hardness of the (Approximate) Shortest Vector Problem: A Simple Proof via Reed-Solomon Codes</title>
    <feedworld_mtime>1645056000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bennett:Huck.html">Huck Bennett</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Peikert:Chris.html">Chris Peikert</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.07736">PDF</a><br/><b>Abstract: </b>$\newcommand{\NP}{\mathsf{NP}}\newcommand{\GapSVP}{\textrm{GapSVP}}$We give a
simple proof that the (approximate, decisional) Shortest Vector Problem is
$\NP$-hard under a randomized reduction. Specifically, we show that for any $p
\geq 1$ and any constant $\gamma &lt; 2^{1/p}$, the $\gamma$-approximate problem
in the $\ell_p$ norm ($\gamma$-$\GapSVP_p$) is not in $\mathsf{RP}$ unless $\NP
\subseteq \mathsf{RP}$. Our proof follows an approach pioneered by Ajtai (STOC
1998), and strengthened by Micciancio (FOCS 1998 and SICOMP 2000), for showing
hardness of $\gamma$-$\GapSVP_p$ using locally dense lattices. We construct
such lattices simply by applying "Construction A" to Reed-Solomon codes with
suitable parameters, and prove their local density via an elementary argument
originally used in the context of Craig lattices.
</p>
<p>As in all known $\NP$-hardness results for $\GapSVP_p$ with $p &lt; \infty$, our
reduction uses randomness. Indeed, it is a notorious open problem to prove
$\NP$-hardness via a deterministic reduction. To this end, we additionally
discuss potential directions and associated challenges for derandomizing our
reduction. In particular, we show that a close deterministic analogue of our
local density construction would improve on the state-of-the-art explicit
Reed-Solomon list-decoding lower bounds of Guruswami and Rudra (STOC 2005 and
IEEE Trans. Inf. Theory 2006).
</p>
<p>As a related contribution of independent interest, we also give a
polynomial-time algorithm for decoding $n$-dimensional "Construction A
Reed-Solomon lattices" (with different parameters than those used in our
hardness proof) to a distance within an $O(\sqrt{\log n})$ factor of
Minkowski's bound. This asymptotically matches the best known distance for
decoding near Minkowski's bound, due to Mook and Peikert (IEEE Trans. Inf.
Theory 2022), whose work we build on with a somewhat simpler construction and
analysis.
</p></div>
    </summary>
    <updated>2022-02-17T22:43:34Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2022-02-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.07697</id>
    <link href="http://arxiv.org/abs/2202.07697" rel="alternate" type="text/html"/>
    <title>A new discrete theory of pseudoconvexity</title>
    <feedworld_mtime>1645056000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Keszegh:Bal=aacute=zs.html">Balázs Keszegh</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.07697">PDF</a><br/><b>Abstract: </b>Recently geometric hypergraphs that can be defined by intersections of
pseudohalfplanes with a finite point set were defined in a purely combinatorial
way. This led to extensions of earlier results about points and halfplanes to
pseudohalfplanes, including polychromatic colorings and discrete Helly-type
theorems about pseudohalfplanes.
</p>
<p>Here we continue this line of research and introduce the notion of convex
sets of such pseudohalfplane hypergraphs. In this context we prove several
results corresponding to classical results about convexity, namely Helly
Theorem, Carath\'eodory's Theorem, Kirchberger's Theorem, Separation Theorem,
Radon's Theorem and the Cup-Cap Theorem. These results imply the respective
results about pseudoconvex sets in the plane defined using pseudohalfplanes.
</p>
<p>It turns out that most of our results can be also proved using oriented
matroids and topological affine planes (TAPs) but our approach is different
from both of them. Compared to oriented matroids, our theory is based on a
linear ordering of the vertex set which makes our definitions and proofs quite
different and perhaps more elementary. Compared to TAPs, which are continuous
objects, our proofs are purely combinatorial and again quite different in
flavor. Altogether, we believe that our new approach can further our
understanding of these fundamental convexity results.
</p></div>
    </summary>
    <updated>2022-02-17T22:52:42Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2022-02-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2110.11254</id>
    <link href="http://arxiv.org/abs/2110.11254" rel="alternate" type="text/html"/>
    <title>Quantum Teleportation with One Classical Bit</title>
    <feedworld_mtime>1645056000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Parakh:Abhishek.html">Abhishek Parakh</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2110.11254">PDF</a><br/><b>Abstract: </b>Quantum teleportation allows one to transmit an arbitrary qubit from point A
to point B using a pair of (pre-shared) entangled qubits and classical bits of
information. The conventional protocol for teleportation uses two bits of
classical information and assumes that the sender has access to only one copy
of the arbitrary qubit to the sent. Here, we ask whether we can do better than
two bits of classical information if the sender has access to multiple copies
of the qubit to be teleported. We place no restrictions on the qubit states.
Consequently, we propose a modified quantum teleportation protocol that allows
Alice to reset the state of the entangled pair to its initial state using only
local operations. As a result, the proposed teleportation protocol requires the
transmission of only one classical bit with a probability greater than
one-half. This has implications for efficient quantum communications and
security of quantum cryptographic protocols based on quantum entanglement.
</p></div>
    </summary>
    <updated>2022-02-17T22:44:19Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2022-02-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/018</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/018" rel="alternate" type="text/html"/>
    <title>TR22-018 |  Further Collapses in TFNP | 

	Mika Göös, 

	Alexandros Hollender, 

	Siddhartha Jain, 

	Gilbert Maystre, 

	William Pires, 

	Robert Robere, 

	Ran Tao</title>
    <summary>We show $\text{EOPL}=\text{PLS}\cap\text{PPAD}$. Here the class $\text{EOPL}$ consists of all total search problems that reduce to the End-of-Potential-Line problem, which was introduced in the works by Hubacek and Yogev (SICOMP 2020) and Fearnley et al. (JCSS 2020). In particular, our result yields a new simpler proof of the breakthrough collapse $\text{CLS}=\text{PLS}\cap\text{PPAD}$ by Fearnley et al. (STOC 2021). We also prove a companion result $\text{SOPL}=\text{PLS}\cap\text{PPADS}$, where $\text{SOPL}$ is the class associated with the Sink-of-Potential-Line problem.</summary>
    <updated>2022-02-15T22:05:13Z</updated>
    <published>2022-02-15T22:05:13Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-02-17T22:53:07Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2022/02/15/linkage</id>
    <link href="https://11011110.github.io/blog/2022/02/15/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>Relevant points for nearest-neighbor classification (\(\mathbb{M}\)). The 48-minute extended remix of my SOSA talk, from the New York computational geometry seminar, somehow still going strong decades after I first started attending it in the late 1980s.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><ul>
  <li>
    <p><a href="https://www.youtube.com/watch?v=Vf1m2L2rhkQ">Relevant points for nearest-neighbor classification</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107727015706308147">\(\mathbb{M}\)</a>).</span> The 48-minute extended remix of my SOSA talk, from the New York computational geometry seminar, somehow still going strong decades after I first started attending it in the late 1980s.</p>
  </li>
  <li>
    <p>The journal I recently co-founded, <a href="https://www.cgt-journal.org/index.php/cgt"><em>Computing in Geometry and Topology</em></a>, has published its first paper! It’s “<a href="https://www.cgt-journal.org/index.php/cgt/article/view/4">On the pathwidth of hyperbolic 3-manifolds</a>” by Kristóf Huszár <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107729561681398073">\(\mathbb{M}\)</a>).</span> Hyperbolic 3-manifolds were known to have triangulations of treewidth linear in their hyperbolic volume — the paper improves this to pathwidth. Having small pathwidth, in turn, simplifies certain dynamic programming computations over tree decompositions of the triangulation.</p>
  </li>
  <li>
    <p><a href="https://conwaylife.com/book/"><em>Conway’s Game of Life: Mathematics and Construction</em></a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107738145296241309">\(\mathbb{M}\)</a>).</span> Free online book by Nathaniel Johnston and Dave Greene detailing the engineering behind some of the most complex patterns in Life including universal computers, large variable-speed spaceships and replicators, and metacells that can emulate any other 2d cellular automaton.</p>
  </li>
  <li>
    <p><a href="https://jaydaigle.net/blog/replication-crisis-math/">Why isn’t there a replication crisis in math</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107746496400902945">\(\mathbb{M}\)</a></span>, <a href="https://news.ycombinator.com/item?id=30181696">via</a>)? It’s not like there’s any shortage of papers with incorrect proofs in them; the bigger mystery is why, much of the time, the broken proofs turn out to be fixable.</p>
  </li>
  <li>
    <p><a href="https://doctorow.medium.com/a-bug-in-early-creative-commons-licenses-has-enabled-a-new-breed-of-superpredator-5f6360713299">A bug in the old version-2 Creative Commons licenses spawns a new breed of copyright troll</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107750081780995135">\(\mathbb{M}\)</a></span>, <a href="https://www.metafilter.com/194192/CC-will-have-them-quaking-in-their-boots">via</a>): seed the open web with CC2-licensed stock photography and the like, wait for unsuspecting people to use it without exactly following the proper format of attribution, sue. Cory Doctorow describes being threatened for using one of these images despite attributing it correctly. See also a <a href="https://doctorow.medium.com/an-open-letter-to-pixsy-ceo-kain-jones-who-keeps-sending-me-legal-threats-5dfc54558f2c">later followup from Doctorow</a>.</p>
  </li>
  <li>
    <p><a href="https://mathstodon.xyz/@christianp/107744005909936952">Christian Lawson-Perfect asks for names for the glyph you use to depict holes in tori</a>. Suggestions include donut hole, hologram, omphalos, and some made-up words. Incidentally, trying to re-create it as the image below ran into a bizarre Adobe Illustrator bug where saving an intersection of two circles in svg turned it into an ellipse; instead, I had to keep the top and bottom arcs as separate objects.</p>

    <p style="text-align: center;"><img alt="The hole in a torus" src="https://11011110.github.io/blog/assets/2022/omphalos.svg"/></p>
  </li>
  <li>
    <p><a href="https://www.quantamagazine.org/an-ancient-geometry-problem-falls-to-new-mathematical-techniques-20220208/">Squaring the circle, by cutting a square into fractal pieces and reassembling them into a circle</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107763584211385922">\(\mathbb{M}\)</a>).</span> The original paper, “<a href="https://arxiv.org/abs/2202.01412">Circle squaring with pieces of small boundary and low Borel complexity</a>” by András Máthé, Jonathan A. Noel, and Oleg Pikhurko, is very technical, but the main improvement on earlier work in the same line of research is that now the pieces all have positive measure and their boundaries have dimension less than two. The pretty animation at the start of the <em>Quanta</em> link is a little misleading, though: the number of pieces is huge, around \(10^{200}\).</p>
  </li>
  <li>
    <p>I made a project of illustrating an Erdős–Rényi–Gilbert random graph in which the <a href="https://en.wikipedia.org/wiki/Giant_component">giant component</a> (or at least, a large component) is clearly visible <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107766972074585140">\(\mathbb{M}\)</a>).</span> Used <a href="https://arxiv.org/abs/1209.0748">social gravity</a> to get the component centered and separated from everything else. Came out reasonably well, I think.</p>

    <p style="text-align: center;"><img alt="Random graph on 1000 vertices at the critical edge probability, showing a large component" src="https://11011110.github.io/blog/assets/2022/ERG1000.svg"/></p>
  </li>
  <li>
    <p><a href="https://ar5iv.org">Ar5iv, a project for automatically converting most arXiv preprints (the ones with LaTeX source) into html</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107772439338813071">\(\mathbb{M}\)</a></span>, <a href="https://www.metafilter.com/194267/LaTeX-to-HTML5-at-scale">via</a>). Too bad about the not-up-to-TeX-quality math formula formatting, though. They’re using mathml instead of MathJax, and it shows. For instance, when I view formulas like \(O\bigl(n^{4/3+\varepsilon}+k^{5/3}n^{2/3}\log^{O(1)}n\bigr)\) (from <a href="https://arxiv.org/abs/2110.06163">one of my recent papers</a>) in Firefox, the exponents get at least two inconsistent baselines, maybe four. Fortunately, CLP has a <a href="https://checkmyworking.com/misc/mathjax-bookmarklet/">MathJaxification bookmarklet</a> that can make things better…</p>
  </li>
  <li>
    <p>The lists of accepted papers are now up at the web sites for the <a href="https://www.inf.fu-berlin.de/inst/ag-ti/socg22/socg.html">2022 Symposium on Computational Geometry</a> and <a href="https://eurocg2022.unipg.it/accepted-papers.html">European Workshop on Computational Geometry</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107783558042391525">\(\mathbb{M}\)</a>).</span></p>
  </li>
  <li>
    <p><a href="https://blog.plover.com/math/finding-factors.html">Factoring composite numbers into nearly equal factors</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@mjd/107747910032997935">\(\mathbb{M}\)</a>)</span> turns out to be complete for \(\mathsf{NP}\) under randomized reductions, or properly <span style="white-space: nowrap;">\(\mathsf{NP}\)-complete</span> if the gaps between prime numbers are small enough to allow a deterministic reduction from the subset sum problem to go through.</p>
  </li>
  <li>
    <p><a href="https://terrytao.wordpress.com/2022/02/08/perfectly-packing-a-square-by-squares-of-nearly-harmonic-sidelength/">Perfectly packing a square by squares of nearly harmonic sidelength</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107800881701660495">\(\mathbb{M}\)</a>).</span> Terry Tao attacks an old question of whether inverse-integer squares pack into a single square of area \(\zeta(2)=\pi^2/6\), showing that squares of sides <span style="white-space: nowrap;">1/integer\({}^{1+\varepsilon}\)</span> do pack. A key insight: the high perimeter of not-yet-packed squares is an obstacle, but can be controlled by grouping squares into rough grids before packing. (This is why the epsilon is needed: perimeter diverges without it.)</p>
  </li>
  <li>
    <p>What do you get when you combine an indigenous Australian painting aesthetic with vaguely-Kabbalistic astronomical charts and geometric diagrams <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107805270173949870">\(\mathbb{M}\)</a>)?</span> Answer: <a href="https://www.thisiscolossal.com/2020/03/shane-drinkwater-astronomical-maps/">the art</a> of <a href="https://www.thisiscolossal.com/2022/01/shane-drinkwater-paintings/">Shane Drinkwater</a>.</p>
  </li>
</ul></div>
    </content>
    <updated>2022-02-15T18:19:00Z</updated>
    <published>2022-02-15T18:19:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2022-02-16T06:13:06Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/017</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/017" rel="alternate" type="text/html"/>
    <title>TR22-017 |  Collision-Resistance from Multi-Collision-Resistance | 

	Prashant Nalini Vasudevan, 

	Ron D. Rothblum</title>
    <summary>Collision-resistant hash functions (CRH) are a fundamental and ubiquitous cryptographic primitive. Several recent works have studied a relaxation of CRH called t-way multi-collision-resistant hash functions (t-MCRH). These are families of functions for which it is computationally hard to find a t-way collision, even though such collisions are abundant (and even (t-1)-way collisions may be easy to find). The case of t=2 corresponds to standard CRH, but it is natural to study t-MCRH for larger values of t.

Multi-collision-resistance seems to be a qualitatively weaker property than standard collision-resistance. In particular, Komargodski et al. (Eurocrypt, 2018) showed that there does not exist a blackbox transformation of MCRH into CRH. Nevertheless, in this work we show a non-blackbox transformation of any moderately shrinking t-MCRH, for t in {3,4}, into an (infinitely often secure) CRH. This transformation is non-constructive - we can prove the existence of a CRH but cannot explicitly point out a construction.

Our result partially extends to larger values of t. In particular, we show that for suitable values of t&gt;t', we can transform a t-MCRH into a t'-MCRH, at the cost of reducing the shrinkage of the resulting hash function family and settling for infinitely often security. This result utilizes the list-decodability properties of Reed-Solomon codes.</summary>
    <updated>2022-02-15T15:00:33Z</updated>
    <published>2022-02-15T15:00:33Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-02-17T22:53:07Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/016</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/016" rel="alternate" type="text/html"/>
    <title>TR22-016 |  Super-cubic lower bound for generalized Karchmer-Wigderson games | 

	Alexander Smal, 

	Artur Ignatiev, 

	Ivan Mihajlin</title>
    <summary>In this paper, we prove a super-cubic lower bound on the size of a communication protocol for generalized Karchmer-Wigderson game for some explicit function $f: \{0,1\}^n\to \{0,1\}^{\log n}$. Lower bounds for original Karchmer-Wigderson games correspond to De Morgan formula lower bounds, thus the best known size lower bound is cubic. The generalized Karchmer-Wigderson games are very similar to the original ones, so we hope that our approach can provide an insight for proving better lower bounds on the original Karchmer-Wigderson games, and hence for proving new lower bounds on De Morgan formula size.

To achieve super-cubic lower bound we adapt several techniques used in formula complexity to communication protocols, prove communication complexity lower bound for a composition of several functions with a multiplexer relation, and use a technique from [TR20-117] to extract the "hardest" function from it. As a result, in this setting we are able to show that there is a relatively small set of functions such that at least one of them does not have a small protocol. The resulting lower bound of $\Omega(n^{3.156})$ is significantly better than the bound obtained from the counting argument.</summary>
    <updated>2022-02-15T02:50:42Z</updated>
    <published>2022-02-15T02:50:42Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-02-17T22:53:07Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-8907273297572905957</id>
    <link href="http://blog.computationalcomplexity.org/feeds/8907273297572905957/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/02/belated-happy-80th-allan-borodin.html#comment-form" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/8907273297572905957" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/8907273297572905957" rel="self" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/02/belated-happy-80th-allan-borodin.html" rel="alternate" type="text/html"/>
    <title>Belated happy 80th, Allan Borodin!</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><i/></p><div class="separator" style="clear: both; text-align: center;"><div class="separator" style="clear: both; text-align: center;"><a href="https://www.fields.utoronto.ca/programs/scientific/00-01/borodin/image.jpg" style="clear: right; float: right; margin-bottom: 1em; margin-left: 1em;"><img border="0" height="320" src="https://www.fields.utoronto.ca/programs/scientific/00-01/borodin/image.jpg" width="213"/></a></div><i style="text-align: left;">Guest Post by Aravind Srinivasan</i><span style="text-align: left;"> </span></div><p/><p><a href="https://en.wikipedia.org/wiki/Allan_Borodin">Allan Borodin</a> turned 80 in 2021. This post is to belatedly wish him a very happy 80th, and to give a short personal perspective. </p><p>Three things come to mind when I think of Allan:</p><p/><ol style="text-align: left;"><li>His range of research topics: I was first exposed to his work (Borodin's Gap Theorem) in a complexity-theory class by Hartmanis in Spring 1990, and have since enjoyed reading---at varying levels of depth---his works on algebraic complexity, space complexity and tradeoffs, circuit complexity, lower bounds in general, routing, adversarial queuing, online algorithms, priority algorithms, and E-commerce (I am surely leaving out some areas). This is an amazingly broad sweep!</li><li>His enthusiasm in learning about and developing new models, as our field has evolved greatly over time.</li><li>The enthusiastic embrace he has given to researchers spanning generations. Indeed, I am one of many who have been inspired by various facets of his research and personality.</li></ol><p/><p>Photos from Allan’s 60th can be seen at <a href="http://www.cs.toronto.edu/~bor/birthday/index.htm">Amos Fiat’s page</a>.</p><p>Thank you for everything Allan, and wishing you continued robust health and enjoyment of your academic work! </p></div>
    </content>
    <updated>2022-02-14T13:32:00Z</updated>
    <published>2022-02-14T13:32:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="http://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2022-02-17T08:08:24Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2022/02/13/triangulation-thickens-grids</id>
    <link href="https://11011110.github.io/blog/2022/02/13/triangulation-thickens-grids.html" rel="alternate" type="text/html"/>
    <title>Triangulation thickens grids</title>
    <summary>If you zigzag back and forth through the columns (or rows) of an ordinary two-dimensional grid graph, following a pattern dignified with the fancy name “boustrophedon”, you get a one-dimensional ordering of the vertices that can be used as the basis of a nice planar arc diagram of this graph.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>If you zigzag back and forth through the columns (or rows) of an ordinary two-dimensional grid graph, following a pattern dignified with the fancy name “<a href="https://en.wikipedia.org/wiki/Boustrophedon">boustrophedon</a>”, you get a one-dimensional ordering of the vertices that can be used as the basis of a nice planar <a href="https://en.wikipedia.org/wiki/Arc_diagram">arc diagram</a> of this graph.</p>

<p style="text-align: center;"><img alt="Boustrophedon layout of a 2d grid" src="https://11011110.github.io/blog/assets/2022/boustrophedon.svg" width="80%"/></p>

<p>The same idea works in 3d. You can divide a 3d grid graph into 2d layers, zigzag within each layer, and then reverse the same zigzagging order in alternating layers, to get another nice one-dimensional ordering of the vertices. It doesn’t give a planar drawing (this graph is not planar), but it does allow it to be drawn without crossings on the four half-planes of a four-page <a href="https://en.wikipedia.org/wiki/Book_embedding">book embedding</a>. More generally, any \(d\)-dimensional grid graph can be drawn in the same way as a book embedding with \(2(d-1)\) pages.</p>

<p style="text-align: center;"><img alt="Double boustrophedon layout of a 3d grid" src="https://11011110.github.io/blog/assets/2022/double-boustrophedon.svg" width="80%"/></p>

<p>I’m a coauthor on a new preprint showing that this one-dimensional layout is very sensitive to the way you connect nearby vertices in the 3d grid. If you modify the grid just a little bit, triangulating it by adding a diagonal to each grid square, then the resulting graph no longer has a book embedding with a constant number of pages. Instead, for a triangulated \(n\times n\times n\) grid, \(\Theta(n^{1/3})\) pages are necessary (and sufficient). The preprint is “Three-dimensional graph products with unbounded stack-number”, with Robert Hickingbotham, Laura Merker, Sergey Norin, Michał T. Seweryn, and David R. Wood, <a href="https://arxiv.org/abs/2202.05327">arXiv:2202.05327</a>; the long coauthor list is because it comes from a collaboration that began at the Banff workshop on Graph Product Structure Theory last November.</p>

<p>There are many other related results packed into the same preprint, but rather than summarizing them all I’d rather take a step back and look at the big picture. The result that triangulated grids have high book thickness turns out to follow from a sequence of connections that is closely analogous to results about the high width of 2d grids, and I think the analogies between these connections are very interesting. For 2d grids:</p>

<ul>
  <li>
    <p>Two standard measures of one-dimensionality of graphs are <a href="https://en.wikipedia.org/wiki/Cutwidth">cutwidth</a> and <a href="https://en.wikipedia.org/wiki/Pathwidth">pathwidth</a>. Both can be defined in terms of continuous maps from the graph (considered as a one-dimensional topological space) to a line. A graph has cutwidth at most \(c\) if it has a map in which every point of the line belongs to the images of at most \(c\) edges, and pathwidth at most \(p\) if it has a map in which every point of the line belongs to the images of edges that have at most \(p\) distinct vertices as their left endpoints.</p>
  </li>
  <li>
    <p>For a graph of maximum degree \(d\), at most \(d\) edges can share a left endpoint, so if the graph has cutwidth \(c\) it has pathwidth at least \(c/d\).</p>
  </li>
  <li>
    <p>A complete graph with \(n\) vertices and \(\tbinom{n}{2}\) edges, mapped continuously to a line, always has a point covered by \(\Omega(n^2)\) edges, at the median vertex of the mapping.</p>
  </li>
  <li>
    <p>For a 2d grid graph, we can associate each vertex with a subgraph consisting of the union of the row and column of the grid containing that vertex.</p>

    <p style="text-align: center;"><img alt="Bramble associating each grid vertex with the union of its row and column" src="https://11011110.github.io/blog/assets/2022/grid-bramble.svg" width="50%"/></p>

    <p>This family of subgraphs is a <a href="https://en.wikipedia.org/wiki/Bramble_(graph_theory)">bramble</a>, meaning that all of the subgraphs are connected and touch each other. In this case, they all touch at shared vertices, but brambles also allow subgraphs to touch across edges. In the bramble for an \(n\times n\) grid graph, each graph vertex or edge belongs to \(O(n)\) subgraphs.</p>
  </li>
  <li>
    <p>We can map \(K_{n^2}\) continuously onto the grid, vertex-to-vertex, by mapping each edge of \(K_{n^2}\) onto a path through the two touching subgraphs for its endpoints. This map has low congestion: each grid vertex or edge is in the image of \(O(n)\) vertices or edges of \(K_{n^2}\).</p>
  </li>
  <li>
    <p>Any map of the grid to a line can be composed with the map from \(K_{n^2}\) to the grid, giving a map of \(K_{n^2}\) onto the line. Because of the low congestion of the map to the grid, a point of the line that is covered by \(\Omega(n^2)\) edges of the complete graph must also be covered by \(\Omega(n)\) edges of the grid. Since this is true for all maps to a line, the grid has pathwidth and cutwidth \(\Omega(n)\).</p>
  </li>
</ul>

<p>Now let’s do the same thing, stepped up a dimension!</p>

<ul>
  <li>
    <p>Instead of graphs, let’s consider 2-dimensional simplicial complexes, systems of points, edges, and triangles. And instead of mapping them to a one-dimensional line, let’s map them (topologically, not necessarily linearly) to a two-dimensional plane. We’ll say that the mapping has high thickness if some point is covered by many triangles (corresponding to cutwidth), or by many vertex-disjoint triangles (corresponding to pathwidth).</p>
  </li>
  <li>
    <p>For a graph of maximum  degree \(d\), at most \(\tbinom{d}{2}\) triangles can share a vertex, so a point covered by many triangles will be covered by many vertex-disjoint triangles. More importantly, this is where the book thickness comes in: an argument related to the <a href="https://en.wikipedia.org/wiki/Erd%C5%91s%E2%80%93Szekeres_theorem">Erdős–Szekeres theorem</a> proves that, when a graph has a \(\theta\)-page book embedding, drawn with its vertices on a circle and its edges as chords of the circle, then at most \(\theta^3\) vertex-disjoint triangles in the graph can contain any point within the circle. So if every mapping into the plane produces a system of triangles of thickness \(t\), you also get book thickness \(\Omega(t^{1/3})\).</p>
  </li>
  <li>
    <p>A complete simplicial complex with \(n\) vertices, \(\tbinom{n}{2}\) edges, and \(\tbinom{n}{3}\) triangles, mapped to the plane, always leads to a point covered by \(\Omega(n^3)\) triangles, by a result of Gromov. (This is closely related to the earlier work of Regina Liu on <a href="https://en.wikipedia.org/wiki/Simplicial_depth">simplicial depth</a> but we want to allow any continuous mapping to the plane, whereas simplicial depth involves mappings that are linear on each edge and triangle.)</p>
  </li>
  <li>
    <p>For an \(n\times n\times n\) grid graph, with its squares triangulated to form a 2d complex \(C\), we can associate each vertex with a subcomplex of \(C\) consisting of the union of the 2d grid planes containing that vertex. This family of subcomplexes has connected pairwise unions and simply connected triplewise unions, analogous to the properties of a bramble for a graph.</p>
  </li>
  <li>
    <p>We can map the complete simplicial complex onto the grid, vertex-to-vertex, by mapping each edge onto a path through the union of two subgraphs and each triangle onto a triangulated surface within the union of three subgraphs. This map has low congestion: each grid vertex, edge, or triangle is in the image of \(O(n^2)\) vertices, edges, or triangles of the complete complex.</p>
  </li>
  <li>
    <p>Any map of the triangulated 3d grid onto the plane can be composed with the map from the complete 2-complex to the grid, giving a map of the complete complex onto the plane. Because of the low congestion of the map to the grid, a point of the plane that is covered by \(\Omega(n^3)\) triangles of the complete complex must also be covered by \(\Omega(n)\) triangles of the triangulated grid. Since this is true for all maps to a plane, the triangulated grid has book thickness \(\Omega(n^{1/3})\).</p>
  </li>
</ul>

<p>For details, generalizations to triangulated products of trees and non-grid tessellations of space, matching upper bounds on book thickness, and more, please see the preprint.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/107795266201400204">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2022-02-13T22:54:00Z</updated>
    <published>2022-02-13T22:54:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2022-02-16T06:13:06Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://rjlipton.wpcomstaging.com/?p=19647</id>
    <link href="https://rjlipton.wpcomstaging.com/2022/02/13/inequalities-on-the-gridiron/" rel="alternate" type="text/html"/>
    <title>Inequalities on the Gridiron</title>
    <summary>Q: Why are Buffalo Bills unlike Dollar Bills? A: Dollar Bills are good for 4 quarters Reddit “outsmarting math” source Josh Allen is not appearing in today’s Super Bowl. He led the Buffalo Bills to not just one but two go-ahead touchdowns in the final 2:00 of the game at Kansas City three weeks ago, […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Q: Why are Buffalo Bills unlike Dollar Bills? A: Dollar Bills are good for 4 quarters</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2022/02/13/inequalities-on-the-gridiron/joshallen/" rel="attachment wp-att-19649"><img alt="" class="alignright wp-image-19649" height="128" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/02/JoshAllen.jpg?resize=155%2C128&amp;ssl=1" width="155"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Reddit “outsmarting math” <a href="https://www.reddit.com/r/buffalobills/comments/km67tw/josh_allen_the_entirety_of_math_and_all_of/">source</a></font></td>
</tr>
</tbody>
</table>
<p>
Josh Allen is not appearing in today’s Super Bowl. He led the Buffalo Bills to not just one but two go-ahead touchdowns in the final 2:00 of the game at Kansas City three weeks ago, but the Bills lost both leads and KC won in overtime.</p>
<p>
Today we note an inequality that treats the real numbers like a football gridiron.</p>
<p>
The <a href="https://en.wikipedia.org/wiki/Hurry-up_offense#Two-minute_drill">two-minute drill</a> is the hallmark of quarterback heroism. KC’s Patrick Mahomes, however, demonstrated the <a href="https://dailystatuss.com/13-seconds-meme-13-seconds-chief-nfl-2022/">13-second drill</a> in two plays plus a tying field goal. That is, the Bills were good for 3 quarters plus 14:47. But Mahomes is not in the Super Bowl either. Two weeks ago, he lost the magic touch in both the closing minute of the fourth quarter and the beginning of overtime as KC squandered a big lead and lost to the Cincinnati Bengals. Whose quarterback, Joe Burrow, <i>is</i> playing in today’s Super Bowl, opposite Matthew Stafford of the Los Angeles Rams.</p>
<p>
The American football field is divided into 100 yards, but rarely subdivided beyond that. The announcers may refer to “a long two yards” or “a short 3,” but never 2.5 yards. It is not just the announcers. Official statistics are kept in units of whole yards, more often rounded up than down. A fourth-down quarterback plunge with 3 inches to go still counts as a 1-yard gain. Perhaps it is essential to the yard that it not be divided into dyadic or decimal units, the way the meter is. As the US celebrates an event still enjoyed by “one nation indivisible,” we note the indivisible.</p>
<p>
</p><p/><h2> Inequalities </h2><p/>
<p/><p>
Godfrey Hardy, John Littlewood, George Polya are famous for many things separately and together. All three lent their names to the timeless book <a href="https://mathematicalolympiads.files.wordpress.com/2012/08/inequalities-hardy-littlewood-polya.pdf">Inequalities</a>. It codifies the theory of real inequalities. </p>
<p/><p><br/>
<a href="https://rjlipton.wpcomstaging.com/2022/02/13/inequalities-on-the-gridiron/inequalitiescover/" rel="attachment wp-att-19650"><img alt="" class="aligncenter wp-image-19650" height="250" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/02/InequalitiesCover.jpg?resize=171%2C250&amp;ssl=1" width="171"/></a></p>
<p/><p><br/>
<a href="https://rjlipton.wpcomstaging.com/2022/02/13/inequalities-on-the-gridiron/hlp/" rel="attachment wp-att-19652"><img alt="" class="aligncenter wp-image-19652" height="105" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/02/HLP.png?resize=276%2C105&amp;ssl=1" width="276"/></a></p>
<p>
</p><p/><h2> An Inequality </h2><p/>
<p/><p>
We recently had reason to look at the following inequality: </p>
<blockquote><p><b> </b> <em> If <img alt="{a^2 - b^2 = c&gt;0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%5E2+-+b%5E2+%3D+c%3E0%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/>, then 	</em></p><em>
<p align="center"><img alt="\displaystyle  c \ge a+b. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++c+%5Cge+a%2Bb.+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
</em><p><em/>
</p></blockquote>
<p>We noted that this fails in general: Let <img alt="{a=1/2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%3D1%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and <img alt="{b=1/4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb%3D1%2F4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. Then <img alt="{c=3/16}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc%3D3%2F16%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and 	</p>
<p align="center"><img alt="\displaystyle  3/16 &lt; 1/2 + 1/4. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++3%2F16+%3C+1%2F2+%2B+1%2F4.+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>This is not even close. But wait—the following lemma is true:</p>
<blockquote><p><b>Lemma 1</b> <em> If <img alt="{a^2 - b^2 = c&gt;0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%5E2+-+b%5E2+%3D+c%3E0%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/>, then 	</em></p><em>
<p align="center"><img alt="\displaystyle  c \ge a+b " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++c+%5Cge+a%2Bb+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
</em><p><em>provided <img alt="{a,b,c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%2Cb%2Cc%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/> are integers. </em>
</p></blockquote>
<p/><p>
The proof is quite simple. We note that 	</p>
<p align="center"><img alt="\displaystyle  c = (a-b)(a+b). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++c+%3D+%28a-b%29%28a%2Bb%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>But this shows that <img alt="{a+b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%2Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is a non-zero divisor of <img alt="{c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. But then 	</p>
<p align="center"><img alt="\displaystyle  a+b \le c. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++a%2Bb+%5Cle+c.+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>This proves the inequality. </p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Is this interesting at all? We have an application of the above lemma, which we will discuss in the future. Are there other good examples of inequalities that are general and natural and only hold over the integers? Or is seeking them like trying to “outsmart math itself”?</p>
<p><br/></p>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2022/02/13/inequalities-on-the-gridiron/allenoutsmartsmath/" rel="attachment wp-att-19653"><img alt="" class="aligncenter wp-image-19653" height="177" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/02/AllenOutsmartsMath.jpg?resize=400%2C177&amp;ssl=1" width="400"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">SB Nation <a href="https://www.sbnation.com/nfl/2018/4/24/17271686/josh-allen-nfl-draft-2018-stats-analysis-comparisons">source</a></font>
</td>
</tr>
</tbody></table></font></font></div>
    </content>
    <updated>2022-02-13T21:57:51Z</updated>
    <published>2022-02-13T21:57:51Z</published>
    <category term="All Posts"/>
    <category term="News"/>
    <category term="People"/>
    <category term="Results"/>
    <category term="American football"/>
    <category term="gridiron"/>
    <category term="inequalities"/>
    <category term="Josh Allen"/>
    <category term="Super Bowl"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wpcomstaging.com</id>
      <logo>https://s0.wp.com/i/webclip.png</logo>
      <link href="https://rjlipton.wpcomstaging.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wpcomstaging.com" rel="alternate" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel's Lost Letter and P=NP</title>
      <updated>2022-02-17T22:53:32Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://scottaaronson.blog/?p=6299</id>
    <link href="https://scottaaronson.blog/?p=6299" rel="alternate" type="text/html"/>
    <link href="https://scottaaronson.blog/?p=6299#comments" rel="replies" type="text/html"/>
    <link href="https://scottaaronson.blog/?feed=atom&amp;p=6299" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Happy 70th birthday Dad!</title>
    <summary xml:lang="en-US">When, before covid, I used to travel the world giving quantum computing talks, every once in a while I’d meet an older person who asked whether I had any relation to a 1970s science writer by the name of Steve Aaronson. So, yeah, Steve Aaronson is my dad. He majored in English in Penn State, […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><figure class="wp-block-image size-large"><a href="https://149663533.v2.pressablecdn.com/wp-content/uploads/2022/02/dad70-scaled.jpg"><img alt="" class="wp-image-6302" height="768" src="https://149663533.v2.pressablecdn.com/wp-content/uploads/2022/02/dad70-1024x768.jpg" width="1024"/></a></figure>



<p>When, before covid, I used to travel the world giving quantum computing talks, every once in a while I’d meet an older person who asked whether I had any relation to a 1970s science writer by the name of Steve Aaronson.  So, yeah, Steve Aaronson is my dad.  He majored in English in Penn State, where he was lucky enough to study under the legendary <a href="https://en.wikipedia.org/wiki/William_Tenn">Phil Klass</a>, who wrote under the pen name William Tenn and who basically created the genre of science-fiction comedy, half a century before there were any such things as <em>Futurama</em>.  After graduating, my dad became a popular physics and cosmology writer, who interviewed greats like Steven Weinberg and John Archibald Wheeler and Arno Penzias (discoverer of the cosmic microwave background radiation).  He published not only in science magazines but in <em>Playboy</em> and <em>Penthouse</em>, which (as he explained to my mom) paid better than the science magazines.  When I was growing up, my dad had a <em>Playboy</em> on his office shelf, which I might take down if for example I wanted to show a friend a 2-page article, with an Aaronson byline, about the latest thinking on the preponderance of matter over antimatter in the visible universe.</p>



<p>Eventually, partly motivated by the need to make money to support … well, me, and then my brother, my dad left freelancing to become a corporate science writer at AT&amp;T Bell Labs.  There, my dad wrote speeches, delivered on the floor of Congress, about how breaking up AT&amp;T’s monopoly would devastate Bell Labs, a place that stood with ancient Alexandria and Cambridge University among the human species’ most irreplaceable engines of scientific creativity.  (Being a good writer, my dad didn’t put it in <em>quite</em> those words.)  Eventually, of course, AT&amp;T <em>was</em> broken up, and my dad’s dire warning about Bell Labs turned out to be 100% vindicated … although on the positive side, Americans got much cheaper long distance.</p>



<p>After a decade at Bell Labs, my dad was promoted to be a public relations executive at AT&amp;T itself, where when I was a teenager, he was centrally involved in the launch of the AT&amp;T spinoff <a href="https://en.wikipedia.org/wiki/Lucent">Lucent Technologies</a> (motto: “Bell Labs Innovations”), and then later the Lucent spinoff <a href="https://en.wikipedia.org/wiki/Avaya">Avaya</a>—developments that AT&amp;T’s original breakup had caused as downstream effects.</p>



<p>In the 1970s, somewhere between his magazine stage and his Bell Labs stage, my dad also worked for <a href="https://en.wikipedia.org/wiki/Eugene_Garfield">Eugene Garfield</a>, the pioneer of bibliometrics for scientific papers and founder of the <a href="https://en.wikipedia.org/wiki/Institute_for_Scientific_Information">Institute for Scientific Information</a>, or ISI.  (Sergey Brin and Larry Page would later cite Garfield’s work, on the statistics of the scientific-citation graph, as one of the precedents for the PageRank algorithm at the core of Google.)</p>



<p>My dad’s job at ISI was to supply Eugene Garfield with “raw material” for essays, which the latter would then write and publish in ISI’s journal <em>Current Contents</em> under the byline Eugene Garfield.  Once, though, my dad supplied some “raw material” for a planned essay about “Style in Scientific Writing”—and, well, I’ll let Garfield <a href="http://www.garfield.library.upenn.edu/essays/v3p004y1977-78.pdf">tell</a> the rest:</p>



<blockquote class="wp-block-quote"><p>This topic of style in scientific writing was first proposed as something I should undertake myself, with some research and drafting help from Steve.  I couldn’t, with a clear conscience, have put my name to the “draft” he submitted.  And, though I don’t disagree with much of it, I didn’t want to modify or edit it in order to justify claiming it as my own.  So here is Aaronson’s “draft,” as it was submitted for “review.”  You can say I got a week’s vacation.  After reading what he wrote it required little work to write this introduction.</p></blockquote>



<p>Interested yet?  You can <a href="http://www.garfield.library.upenn.edu/essays/v3p004y1977-78.pdf">read “Style in Scientific Writing” here</a>.  You can, if we’re being honest, tell that this piece was originally intended as “raw material”—but only because of the way it calls forth such a fierce armada of all of history’s awesomest quotations about what makes scientific writing good or bad, like Ben Franklin and William James and the whole gang, which would make it worth the read regardless.  I <em>love</em> eating raw dough, I confess, and I love my dad’s essay.  (My dad, ironically enough, likes everything he eats to be thoroughly cooked.)</p>



<p>When I read that essay, I hear my dad’s voice from my childhood.  “Omit needless words.”  There were countless revisions and pieces of advice on every single thing I wrote, but usually, “omit needless words” was the core of it.  And as terrible as you all know me to be on that count, imagine <em>how much worse</em> it would’ve been if not for my dad!  And I know that as soon as he reads this post, he’ll find needless words to omit.</p>



<p>But hopefully he won’t omit these:</p>



<p>Happy 70th birthday Pops, congrats on beating the cancer, and here’s to many more!</p></div>
    </content>
    <updated>2022-02-12T20:11:04Z</updated>
    <published>2022-02-12T20:11:04Z</published>
    <category scheme="https://scottaaronson.blog" term="Nerd Interest"/>
    <category scheme="https://scottaaronson.blog" term="Self-Referential"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://scottaaronson.blog/?feed=atom</id>
      <icon>https://scottaaronson.blog/wp-content/uploads/2021/10/cropped-Jacket-32x32.gif</icon>
      <link href="https://scottaaronson.blog" rel="alternate" type="text/html"/>
      <link href="https://scottaaronson.blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2022-02-14T19:44:57Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/015</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/015" rel="alternate" type="text/html"/>
    <title>TR22-015 |  Lower Bounds for Unambiguous Automata via Communication Complexity | 

	Mika Göös, 

	Stefan Kiefer, 

	Weiqiang Yuan</title>
    <summary>We use results from communication complexity, both new and old ones, to prove lower bounds for unambiguous finite automata (UFAs). We show three results.

$\textbf{Complement:}$ There is a language $L$ recognised by an $n$-state UFA such that the complement language $\overline{L}$ requires NFAs with $n^{\tilde{\Omega}(\log n)}$ states. This improves on a lower bound by Raskin.

$\textbf{Union:}$ There are languages $L_1$, $L_2$ recognised by $n$-state UFAs such that the union $L_1\cup L_2$ requires UFAs with $n^{\tilde{\Omega}(\log n)}$ states.

$\textbf{Separation:}$ There is a language $L$ such that both $L$ and $\overline{L}$ are recognised by $n$-state NFAs but such that $L$ requires UFAs with $n^{\Omega(\log n)}$ states. This refutes a conjecture by Colcombet.</summary>
    <updated>2022-02-12T16:29:35Z</updated>
    <published>2022-02-12T16:29:35Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-02-17T22:53:07Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://nisheethvishnoi.wordpress.com/?p=147</id>
    <link href="https://nisheethvishnoi.wordpress.com/2022/02/11/focs-2021-talk-videos/" rel="alternate" type="text/html"/>
    <title>FOCS 2021 Talk Videos</title>
    <summary>After more than a year of planning, FOCS 2021 concluded yesterday. In case you missed all or part of the event, the talks for all of 117 papers and for the three workshops are now available on this youtube channel. The full versions of all papers (and videos) are also freely available here. Many thanks […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>After more than a year of planning, FOCS 2021 concluded yesterday. </p>



<p>In case you missed all or part of the event, the talks for all of 117 papers and for the three workshops are now available on <a href="https://www.youtube.com/channel/UClrteoQ-ULzlZZaWi6c6iKw/playlists">this youtube</a> channel.</p>



<p>The full versions of all papers (and videos) are also freely available <a href="https://focs2021.cs.colorado.edu/program/">here</a>.</p>



<p>Many thanks to more than 1000 people, including authors, program committee members, external reviewers, organizers, TCMF members, volunteers, and attendees for making this happen! </p>



<figure class="wp-block-video"/></div>
    </content>
    <updated>2022-02-11T14:30:16Z</updated>
    <published>2022-02-11T14:30:16Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>nisheethvishnoi</name>
    </author>
    <source>
      <id>https://nisheethvishnoi.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://nisheethvishnoi.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://nisheethvishnoi.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://nisheethvishnoi.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://nisheethvishnoi.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Algorithms, Nature, and Society</title>
      <updated>2022-02-17T22:54:54Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://rjlipton.wpcomstaging.com/?p=19636</id>
    <link href="https://rjlipton.wpcomstaging.com/2022/02/10/national-academy-of-engineering-elects/" rel="alternate" type="text/html"/>
    <title>National Academy of Engineering Elects</title>
    <summary>The problem in this business isn’t to keep people from stealing your ideas; it’s making them steal your ideas!—Howard Aiken Composite crop of homepage photos Taher Elgamal and Anna Karlin are among 111 new US members of the National Academy of Engineering (NAE). That’s one-hundred-and-eleven, not seven in binary. Today we congratulate them and all […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>The problem in this business isn’t to keep people from stealing your ideas; it’s making them steal your ideas!—Howard Aiken</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2022/02/10/national-academy-of-engineering-elects/egak/" rel="attachment wp-att-19638"><img alt="" class="alignright size-full wp-image-19638" height="115" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/02/EGAK.png?resize=155%2C115&amp;ssl=1" width="155"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Composite crop of homepage photos</font></td>
</tr>
</tbody>
</table>
<p>
Taher Elgamal and Anna Karlin are among 111 <a href="https://www.nae.edu/270224/National-Academy-of-Engineering-Elects-111-Members-and-22-International-Members">new US members</a> of the National Academy of Engineering (NAE). That’s one-hundred-and-eleven, not seven in binary.</p>
<p>
Today we congratulate them and all the new members.<br/>
<span id="more-19636"/></p>
<p>
Elgamal and Karlin are the two closest to theory, by my reckoning. Elgamal developed the <a href="https://en.wikipedia.org/wiki/ElGamal_encryption">ElGamal</a> encryption scheme. Elgamal spelled his name with a capital G at the time of his famous 1985 <a href="https://caislab.kaist.ac.kr/lecture/2010/spring/cs548/basic/B02.pdf">paper</a> but it is lowercased on his own LinkedIn <a href="https://www.linkedin.com/in/taherelgamal/">page</a>, on Wikipedia, on his RSA conference <a href="https://www.rsaconference.com/experts/dr-taherelgamal">page</a>, and by the NAE. Wikipedia explains that he spells it more simply so that “it is less likely to be mangled in English.” Yet his invention keeps the capital G. Ken and I think a good reason for this is that it uses a large cyclic group <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. The citation also hails his work on <a href="https://en.wikipedia.org/wiki/Transport_Layer_Security#SSL_1.0,_2.0,_and_3.0">SSL</a> and other internet protocols.</p>
<p>
We featured Karlin’s nifty joint paper on the metric TSP problem recently <a href="https://rjlipton.wpcomstaging.com/2020/10/26/a-vast-and-tiny-breakthrough/">here</a>. She is also on the editorial board of the new TheoretiCS <a href="https://rjlipton.wpcomstaging.com/2021/12/01/the-new-journal/">journal</a>. I was glad to serve with her on an NSF committee to promote <a href="https://rjlipton.wpcomstaging.com/2011/07/12/time-chunks-and-theory-nuggets/">nuggets</a> of theory. She holds the Bill and Melinda Gates Chair at the Paul Allen School of Computer Science and Engineering at the University of Washington.</p>
<p>
The new members bring the total US membership in the NAE to 2,388. Joining them are 22 new international members. They include Natarajan Chandrasekaran of Tata Sons for advancing the Indian software industry and Hongjiang Zhang of The Carlyle Group in Beijing for multimedia computing. </p>
<p><a href="https://rjlipton.wpcomstaging.com/2022/02/10/national-academy-of-engineering-elects/nae/" rel="attachment wp-att-19639"><img alt="" class="aligncenter wp-image-19639" height="120" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/02/nae.png?resize=120%2C120&amp;ssl=1" width="120"/></a></p>
<p>
</p><p/><h2> New Members in Computing </h2><p/>
<p/><p>
There are many other new members in areas of computing besides theory. Here are some of the new members that work in computer science—including the citations for Elgamal and Karlin. </p>
<ul>
<p/><li>
Bergeron, Kathleen, vice president, Hardware Engineering, Apple Inc., Los Gatos, Calif. <i>For contributions to and leadership in the invention and engineering product realization of innovative designs.</i><p/>
<p/></li><li>
Bovik, Alan C., Cockrell Family Regents Endowed Chair in Engineering and professor, Electrical and Computer Engineering, University of Texas, Austin. <i>For contributions to the development of tools for image and video quality assessment.</i><p/>
<p/></li><li>
Cohn, John Maxwell, IBM Fellow, MIT-IBM Watson AI Lab, Cambridge, Mass. <i>For improving design productivity of high-performance analog and mixed-signal circuits and for evangelizing STEM education.</i><p/>
<p/></li><li>
Croak, Marian R., vice president, Engineering, Google LLC, Fair Haven, N.J. <i>For technical and managerial leadership in the implementation of packet voice networking and for promotion of minority inclusion in engineering.</i><p/>
<p/></li><li>
Czerwinski, Mary, partner researcher and research manager, Microsoft Research, Redmond, Wash. <i>For the application of psychological principles to the design and understanding of human computer interaction.</i><p/>
<p/></li><li>
Elgamal, Taher, chief technology officer, Security, Salesforce, San Francisco. <i>For contributions to cryptography, e-commerce, and protocols for secure internet transactions.</i><p/>
<p/></li><li>
Fields, Craig I., chairman, Defense Science Board, U.S. Department of Defense, Washington, D.C. <i>For contributions to the development of systems and technology for national security and their transfer to commercial applications.</i><p/>
<p/></li><li>
Hammack, William S., William H. and Janet G. Lycan Professor, Chemical and Biomolecular Engineering, University of Illinois, Urbana-Champaign. <i>For innovations in multidisciplinary engineering education, outreach, and service to the profession through development and communication of internet-delivered content.</i><p/>
<p/></li><li>
Karlin, Anna, Bill and Melinda Gates Chair, Allen School of Computer Science &amp; Engineering, University of Washington, Seattle. <i>For contributions to the design and analysis of randomized algorithms and their impact on computer systems and the internet.</i><p/>
<p/></li><li>
Karniadakis, George Em, Charles Pitts Robinson and John Palmer Barstow Professor, Division of Applied Mathematics and School of Engineering, Brown University, Providence, R.I. <i>For computational tools, from high-accuracy algorithms to machine learning, and applications to complex flows, stochastic processes, and microfluidics.</i><p/>
<p/></li><li>
Levoy, Marc, Vmware Founders Professor (emeritus), Computer Science, Stanford University, Stanford, Calif. <i>For contributions to computer graphics and digital photography.</i><p/>
<p/></li><li>
Mauro, John C., professor, Department of Materials Science and Engineering, Pennsylvania State University, University Park. <i>For developing and applying data-driven models and machine learning that enable high-strength, damage-resistant glasses.</i><p/>
<p/></li><li>
Nadella, Satya, chairman and chief executive officer, Microsoft Corp., Redmond, Wash. <i>For advancing corporate computing infrastructure as a cloud service, and for international leadership on sociotechnical systems and practice.</i> <p/>
<p/></li><li>
Nahrstedt, Klara, Grainger Distinguished Chair, Grainger College of Engineering, University of Illinois, Urbana-Champaign. <i>For contributions to managing quality of service in distributed multimedia systems and networks.</i><p/>
<p/></li><li>
Reiman, Martin I., professor, Department of Industrial Engineering and Operations Research, Columbia University, Murray Hill, N.J. <i>For contributions to network theory and applications in large-scale stochastic systems.</i><p/>
<p/></li><li>
Sahinidis, Nikolaos V., Gary C. Butler Family Chair and Professor, H. Milton Stewart School of Industrial and Systems Engineering, Georgia Institute of Technology, Atlanta. <i>For contributions to global optimization and the development of widely used software for optimization and machine learning.</i><p/>
<p/></li><li>
Sapiro, Guillermo, James B. Duke Distinguished Professor, Electrical and Computer Engineering, Duke University, Durham, N.C. <i>For contributions to the theory and practice of imaging.</i><p/>
<p/></li><li>
Veloso, Manuela M., head, Artificial Intelligence Research, JPMorgan Chase &amp; Co., New York City. <i>For contributions to machine learning and its applications in robotics and the financial services industry.</i><p/>
<p/></li><li>
Whitney, Telle, CEO, Telle Whitney Consulting LLC, Scotts Valley, Calif. <i>For contributions to structured silicon design and for increasing the participation of women in computing careers.</i><p/>
<p/></li><li>
Willcox, Karen E., director, Oden Institute for Computational Engineering and Sciences, University of Texas, Austin. <i>For contributions to computational engineering methods for the design and optimal control of high-dimensional systems with uncertainties.</i><p/>
</li></ul>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
We count 8 women of the 20 above: Bergeron, Croak, Czerwinski, Karlin, Nahrstedt, Veloso, Whitney, and Willcox. That’s quite a lot better than other rations we’ve observed. How can awareness of this success be filtered through? We also note Anna’s <a href="https://medium.com/@karlin_41004/why-women-and-everyone-else-should-code-18e4a0a46a47">essay</a>, “Why Women (and Everyone Else) Should Code.”</p>
<p/></font></font></div>
    </content>
    <updated>2022-02-11T01:40:02Z</updated>
    <published>2022-02-11T01:40:02Z</published>
    <category term="All Posts"/>
    <category term="News"/>
    <category term="People"/>
    <category term="Anna Karlin"/>
    <category term="National Academy of Engineering"/>
    <category term="new members"/>
    <category term="Taher Elgamal"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wpcomstaging.com</id>
      <logo>https://s0.wp.com/i/webclip.png</logo>
      <link href="https://rjlipton.wpcomstaging.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wpcomstaging.com" rel="alternate" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel's Lost Letter and P=NP</title>
      <updated>2022-02-17T22:53:33Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2022/02/10/hereditary-first-order</id>
    <link href="https://11011110.github.io/blog/2022/02/10/hereditary-first-order.html" rel="alternate" type="text/html"/>
    <title>Hereditary first order graph properties can be hard</title>
    <summary>Many natural classes of undirected graphs are hereditary, meaning that if you delete vertices from any graph in the class, the induced subgraph that you get always remains in this class. Every hereditary class of graphs can be defined by its forbidden induced subgraphs, the minimal graphs that do not belong to the class. When there are only finitely many of these forbidden subgraphs, it is possible to define the class by a formula in the first-order logic of graphs describing the graphs that do not have these subgraphs, and to test membership in the class in polynomial time by searching for a forbidden subgraph. Examples include:</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Many natural classes of undirected graphs are <a href="https://en.wikipedia.org/wiki/Hereditary_property">hereditary</a>, meaning that if you delete vertices from any graph in the class, the induced subgraph that you get always remains in this class. Every hereditary class of graphs can be defined by its <a href="https://en.wikipedia.org/wiki/Forbidden_graph_characterization">forbidden induced subgraphs</a>, the minimal graphs that do not belong to the class. When there are only finitely many of these forbidden subgraphs, it is possible to define the class by a formula in the first-order <a href="https://en.wikipedia.org/wiki/Logic_of_graphs">logic of graphs</a> describing the graphs that do not have these subgraphs, and to test membership in the class in polynomial time by searching for a forbidden subgraph. Examples include:</p>

<ul>
  <li>
    <p>The <a href="https://en.wikipedia.org/wiki/Threshold_graph">threshold graphs</a>, whose forbidden subgraphs are a four-vertex path, four-vertex cycle, or four-vertex perfect matching.</p>
  </li>
  <li>
    <p>The <a href="https://en.wikipedia.org/wiki/Cograph">cographs</a>, whose single forbidden subgraph is a four-vertex path.</p>
  </li>
  <li>
    <p>The <a href="https://en.wikipedia.org/wiki/Triangle-free_graph">triangle-free graphs</a>, whose single forbidden subgraph is a <span style="white-space: nowrap;">triangle \(K_3\).</span></p>
  </li>
  <li>
    <p>The <a href="https://en.wikipedia.org/wiki/Claw-free_graph">claw-free graphs</a>, whose single forbidden subgraph is the four-vertex <span style="white-space: nowrap;">tree \(K_{1,3}\).</span></p>
  </li>
  <li>
    <p>The <a href="https://en.wikipedia.org/wiki/Line_graph">line graphs</a>, which have a forbidden subgraph characterization with nine forbidden subgraphs:</p>
  </li>
</ul>

<p style="text-align: center;"><img alt="The nine forbidden induced subgraphs of line graphs" src="https://11011110.github.io/blog/assets/2022/nonline.svg"/></p>

<p>However, there might be infinitely many forbidden subgraphs. In many such cases, it is still possible to recognize these graphs in polynomial time, often by a greedy algorithm that removes vertices one at a time based on some local structure. Additionally, in these cases, it is often possible to describe the property of being one of the forbidden subgraphs by a first-order formula, so that the graph class is the class of graphs none of whose subgraphs model that formula. For instance:</p>

<ul>
  <li>
    <p>The <a href="https://en.wikipedia.org/wiki/Degeneracy_(graph_theory)"><span style="white-space: nowrap;">\(d\)-degenerate</span> graphs</a> are graphs in which no non-empty induced subgraph has all vertices of degree greater <span style="white-space: nowrap;">than \(d\).</span> They can be recognized in polynomial time as the graphs reducible to empty by repeatedly removing low-degree vertices.</p>
  </li>
  <li>
    <p>The <a href="https://en.wikipedia.org/wiki/Distance-hereditary_graph">distance-hereditary graphs</a> are graphs in which every induced subgraph with two or more vertices has a degree-one vertex, or twins, two vertices with equal closed or open neighborhoods. They can be recognized in polynomial time by repeatedly removing degree-one vertices or merging twins.</p>
  </li>
  <li>
    <p>The <a href="https://en.wikipedia.org/wiki/Chordal_graph">chordal graphs</a> are graphs with no induced cycle of more than three vertices, or the graphs in which every non-empty induced subgraph has a simplicial vertex, a vertex whose neighbors are all adjacent. They can be recognized in polynomial time by repeatedly removing simplicial vertices.</p>
  </li>
  <li>
    <p>The <a href="https://en.wikipedia.org/wiki/Perfect_graph">perfect graphs</a> are graphs with no odd induced cycle of more than three vertices, or its complement. They can be recognized in polynomial time but the algorithm is complicated.</p>
  </li>
</ul>

<p>Obviously, not all hereditary classes are like that; one could, for instance, forbid induced cycles whose lengths belong to an undecidable set of integers, and get a hereditary class of graphs whose recognition problem is again undecidable. But this led me to wonder: is there a connection between the first-order recognizability of the forbidden subgraphs and the polynomial recognizability of the graph class itself? Could it be that every hereditary class defined by a first-order set of forbidden subgraphs is polynomially recognizable?</p>

<p>No!</p>

<p>The counterexample I found is the family of graphs whose forbidden subgraphs are the non-empty <a href="https://en.wikipedia.org/wiki/Perfect_graph">cubic (3-regular) graphs</a>. Let’s call these the cubic-free graphs. Being cubic is easily expressed in first-order logic, so the forbidden subgraphs for the cubic-free graphs are first-order recognizable. However, under standard assumptions, the cubic-free graphs themselves are not polynomially recognizable: their recognition problem is <span style="white-space: nowrap;">\(\mathsf{coNP}\)-complete.</span> Put another way, the problem <small>CUBIC INDUCED SUBGRAPH</small> asking whether a given graph has a non-empty cubic induced subgraph is <span style="white-space: nowrap;">\(\mathsf{NP}\)-complete.</span></p>

<p>I found lots of references in the literature to problems of finding non-empty cubic subgraphs (not required to be induced subgraphs; see Garey &amp; Johnson GT32), or to finding cubic induced subgraphs with some constraint on their size, but not to the <small>CUBIC INDUCED SUBGRAPH</small> problem itself. So instead, I found an <span style="white-space: nowrap;">\(\mathsf{NP}\)-completeness</span> reduction myself, from <a href="https://en.wikipedia.org/wiki/3-dimensional_matching"><small>3-DIMENSIONAL MATCHING</small></a>, in which the input is a 3-uniform hypergraph (meaning that each hyperedge touches three hypervertices) and one must find a subset of the hyperedges that touches every hypervertex exactly once. An example of my reduction is shown below, from which I think the general case should be more clear.</p>

<p style="text-align: center;"><img alt="NP-completeness reduction from 3-dimensional matching to cubic induced subgraph" src="https://11011110.github.io/blog/assets/2022/3dm23is.svg"/></p>

<p>The input hypergraph is shown with its hypervertices as large blue disks and its hyperedges as medium-sized yellow disks. Inside each of these disks is shown part of a graph, a gadget into which that piece of the hypergraph is translated to form a piece of a <small>CUBIC INDUCED SUBGRAPH</small> instance. The example hypergraph used in the image is 4-regular (every hypervertex touches four hyperedges) but that’s not essential. Once you start making choices of which vertices to include or exclude in an induced subgraph, you can make a chain of inferences from that choice:</p>
<ul>
  <li>If you have included a vertex that has only three non-excluded neighbors, you must include all three of them.</li>
  <li>If you have included a vertex that has three included neighbors, you must exclude all its other neighbors.</li>
  <li>If some vertex has fewer than three neighbors that are not excluded, you must exclude it.</li>
</ul>

<p>It follows from this sort of reasoning that the only non-empty cubic induced subgraphs are like the ones shown by the dark red vertices in these gadgets: a vertex for each of the the hyperedges in a matching (such as the matching of dark-yellow hyperedges), and a corresponding subset of the vertices in every hypervertex gadget. Because finding a cubic induced subgraph is <span style="white-space: nowrap;">\(\mathsf{NP}\)-complete,</span> its complementary problem, testing whether a graph is cubic-free, is <span style="white-space: nowrap;">\(\mathsf{coNP}\)-complete.</span></p>

<p>(<a href="https://mathstodon.xyz/@11011110/107776994325248199">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2022-02-10T17:40:00Z</updated>
    <published>2022-02-10T17:40:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2022-02-16T06:13:06Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2022/02/10/postdoc-in-computational-complexity-at-imperial-college-london-apply-by-april-15-2022/</id>
    <link href="https://cstheory-jobs.org/2022/02/10/postdoc-in-computational-complexity-at-imperial-college-london-apply-by-april-15-2022/" rel="alternate" type="text/html"/>
    <title>Postdoc in computational complexity at Imperial College London (apply by April 15, 2022)</title>
    <summary>Applications are invited for a postdoctoral position at the Complexity Group, Imperial College London, led by prof. Iddo Tzameret and funded by the ERC. The position is for one year with up to two-year extension. The start date is flexible, and the salary is generous. This position is based at the South Kensington campus in […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Applications are invited for a postdoctoral position at the Complexity Group, Imperial College London, led by prof. Iddo Tzameret and funded by the ERC. The position is for one year with up to two-year extension. The start date is flexible, and the salary is generous. This position is based at the South Kensington campus in the heart of London. Applications will be accepted until position filled.</p>
<p>Website: <a href="https://www.doc.ic.ac.uk/~itzamere/PhD_Postdoc_Post.html">https://www.doc.ic.ac.uk/~itzamere/PhD_Postdoc_Post.html</a><br/>
Email: iddo.tzameret@gmail.com</p></div>
    </content>
    <updated>2022-02-10T17:39:08Z</updated>
    <published>2022-02-10T17:39:08Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2022-02-17T22:53:38Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2022/02/10/tenure-track-assistant-professor-at-university-of-vienna-apply-by-march-15-2022/</id>
    <link href="https://cstheory-jobs.org/2022/02/10/tenure-track-assistant-professor-at-university-of-vienna-apply-by-march-15-2022/" rel="alternate" type="text/html"/>
    <title>Tenure-track assistant professor at University of Vienna (apply by March 15, 2022)</title>
    <summary>The faculty of Computer Science is looking for outstanding internationally recognized early career scientists with a research focus on scalable algorithmic approaches for AI. This competence is documented by publications in top venues in relevant areas, including, but not limited to, – machine learning, – AI, – algorithms, or – high performance computing research. Website: […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The faculty of Computer Science is looking for outstanding internationally recognized early career scientists with a research focus on scalable algorithmic approaches for AI.<br/>
This competence is documented by publications in top venues in relevant areas, including, but not limited to, – machine learning,<br/>
– AI,<br/>
– algorithms, or<br/>
– high performance computing research.</p>
<p>Website: <a href="https://univis.univie.ac.at/ausschreibungstellensuche/flow/bew_ausschreibung-flow?_flowExecutionKey=_c11E8D826-8A93-525D-7F25-64B17F6D4117_k70C7134F-AA27-C4B1-26FA-8A869B87BA6B&amp;tid=89875.28">https://univis.univie.ac.at/ausschreibungstellensuche/flow/bew_ausschreibung-flow?_flowExecutionKey=_c11E8D826-8A93-525D-7F25-64B17F6D4117_k70C7134F-AA27-C4B1-26FA-8A869B87BA6B&amp;tid=89875.28</a><br/>
Email: monika.henzinger@univie.ac.at</p></div>
    </content>
    <updated>2022-02-10T14:34:39Z</updated>
    <published>2022-02-10T14:34:39Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2022-02-17T22:53:38Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=22399</id>
    <link href="https://gilkalai.wordpress.com/2022/02/10/is-hqca-possible-a-conversation-with-michael-brooks/" rel="alternate" type="text/html"/>
    <title>Is HQCA Possible? A conversation with Michael Brooks</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Here is a short email interview from April 2021 with Michael Brooks from “New Scientist”. Dear Professor Kalai, I’m writing a short feature for New Scientist magazine on the theme “Will we ever have a useful quantum computer?”. I’m aware … <a href="https://gilkalai.wordpress.com/2022/02/10/is-hqca-possible-a-conversation-with-michael-brooks/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Here is a short email interview from April 2021 with Michael Brooks from “New Scientist”.</p>
<p><span class="im"><strong>Dear Professor Kalai,</strong> <b>I’m writing a short feature for New Scientist magazine on the theme “Will we ever have a useful quantum computer?”. I’m aware of your work on the problems with noise, and your position that error correction won’t be possible.</b></span></p>
<p>This is correct. My analysis asserts that quality error correction won’t be possible and that even the easier target of <span class="il">HQCA</span> (huge quantum computational advantage) won’t be possible. Here is a <a href="https://arxiv.org/abs/2008.05188">link</a> to my new paper that you may find useful. It refers to recent developments: the Google Sycamore experiment and <span class="il">HQCA</span> claims are discussed in Sections 6 and 7, and there is a new Section 9 regarding the very recent developments.</p>
<p><b>I was wondering whether anything you’ve seen – demonstrations or arguments – in the last few months have done anything to change your mind, or whether you are now more convinced than ever that we won’t ever see truly useful (beyond doing science) quantum computing?  </b></p>
<p>Well, I think that my theory is rather strong but not ironclad. As for the level of my conviction, it does not change often, but roughly speaking there were three stages to my research (and level of conviction):</p>
<p>1) 2005-2013.   What I did was (in hindsight) exploring consequences of the failure of quantum fault tolerance and, on the way, some mistakes in the logic of firmly believing that quantum computers could be built. But, as I often said at that time, I did not think my work then gave a reason for people to change their a priori beliefs.</p>
<p>2) 2013-2019.  Following my work with Guy Kindler I saw a clear scientific argument for why quantum computers will fail. (We first considered the special case of boson sampling and later I extended it in  greater generality.) Since that time, I regard my argument to be strong enough to change people a priori beliefs, and my level of conviction went up as well. But, as I said, it is not an ironclad argument.</p>
<p>3) 2019 – onward.  The experimental claims by Google and later by a group from Hefei, China would, if correct, refute my argument. So, naturally, this casts some doubts also in my mind. However, there are good technical reasons to doubt the fantastic claims by the Hefei group, and on that matter actually my 2014 paper with Kindler comes to play. The situation with the Google experiment is more delicate, but there are reasons to doubt their experimental claims as well.</p>
<p>As for a priori beliefs: In my view the situation is that it is hard to believe that quantum computers are not possible, but it is even harder to believe that quantum computers are possible <img alt="&#x1F642;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f642.png" style="height: 1em;"/> . So much experimental and theoretical research is needed before humankind will crack this puzzle.</p>
<p><span class="im"><b>Also, I was wondering if the retraction of the main paper about creating Majorana fermions (<a href="https://www.nature.com/articles/d41586-021-00612-z" rel="noopener" target="_blank">https://www.nature.com/articles/d41586-021-00612-z</a>) kills topological computing’s hopes of getting us there?</b></span></p>
<p>No, the retraction of a single paper does not kill at all topological computing’s hopes. In fact, the researchers who found the mistake are hopeful that a successful experiment of that kind is possible and are also hopeful regarding further experimental steps towards topological quantum computing.</p>
<p>My general argument does extend to topological quantum computing and asserts that stable topological qubits are not possible.</p>
<p>Thanks for your interest and best wishes,  Gil Kalai</p>
<p><strong>Additional comments:</strong> The (very nice) <a href="https://www.scientiststudy.com/2021/09/why-it-might-be-impossible-to-build.html">article appeared in August 2021</a> and (accurately) refers to my position: “Gil Kalai, a mathematician at the Hebrew University of Jerusalem in Israel, argued that the basic noise level in a quantum computer will always be too high, no matter how many qubits are available. ‘My analysis says that correcting quality errors will not be possible.’ ” The article quotes also <a href="https://researchportal.helsinki.fi/en/persons/sabrina-maniscalco/publications/">Sabrina Maniscalco</a> from the University of Helsinki in Finland who said: “Finding a cure for the effect of environmental noise is not only, in my opinion, a technological problem, but more conceptual and fundamental. I would say that I am optimistic, rather than confident”.</p>
<p>My debate with Aram Harrow over GLL <a href="https://rjlipton.wpcomstaging.com/2012/01/30/perpetual-motion-of-the-21st-century/">started ten years ago</a>. A lot has happened in these ten years! (Here is a <a href="https://rjlipton.wpcomstaging.com/2012/01/30/perpetual-motion-of-the-21st-century/#comment-18029">comment</a> from the debate on my assessment of the situation at that time.)</p>
<p>The researchers who took on themselves the thankless task of putting the Microsoft Majorana claims under scrutiny and found the mistakes are <a href="https://www.physicsandastronomy.pitt.edu/people/sergey-frolov" rel="noopener" target="_blank">Sergey Frolov</a> and <a href="https://www.fqt.unsw.edu.au/staff/vincent-mourik-0" rel="noopener" target="_blank">Vincent Mourik</a>. (See also <a href="https://www.nature.com/articles/d41586-021-00954-8">Frolov’s commentary</a> in “Nature” and <a href="https://www.quantamagazine.org/major-quantum-computing-strategy-suffers-serious-setbacks-20210929/">this article</a> in “Quanta Magazine”.) They drew important conclusions for the need of sharing raw data and other experimental details for such experiments.</p>
<p>For more details:  on my view regarding quantum computers see <a href="https://gilkalai.wordpress.com/2020/12/29/the-argument-against-quantum-computers-a-very-short-introduction/" rel="bookmark">The Argument Against Quantum Computers – A Very Short Introduction</a> (December 2020); and on Google’s supremacy experiment see <a href="https://gilkalai.wordpress.com/2019/11/13/gils-collegial-quantum-supremacy-skepticism-faq/" rel="bookmark">Gil’s Collegial Quantum Supremacy Skepticism FAQ</a> (November 2019).</p></div>
    </content>
    <updated>2022-02-10T09:57:23Z</updated>
    <published>2022-02-10T09:57:23Z</published>
    <category term="Computer Science and Optimization"/>
    <category term="Quantum"/>
    <category term="Aram Harrow"/>
    <category term="Michael Brooks"/>
    <category term="Quantum computers"/>
    <category term="Sabrina Maniscalco"/>
    <category term="Sergey Frolov"/>
    <category term="Vincent Mourik"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2022-02-17T22:53:26Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2022/02/10/postdoc-positions-in-algorithms-complexity-at-university-of-california-san-diego-apply-by-march-31-2022/</id>
    <link href="https://cstheory-jobs.org/2022/02/10/postdoc-positions-in-algorithms-complexity-at-university-of-california-san-diego-apply-by-march-31-2022/" rel="alternate" type="text/html"/>
    <title>Postdoc Positions in Algorithms &amp; Complexity at University of California San Diego (apply by March 31, 2022)</title>
    <summary>Multiple postdoc positions available at UCSD Theory group to work on graph algorithms, randomized and approximation algorithms, fine-grained complexity, and additive combinatorics. Apply directly to barnas@ucsd.edu. Must include your resume, and contact information of three reference writers. Website: https://cstheory.ucsd.edu/home.html Email: barnas@ucsd.edu</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Multiple postdoc positions available at UCSD Theory group to work on graph algorithms, randomized and approximation algorithms, fine-grained complexity, and additive combinatorics. Apply directly to barnas@ucsd.edu. Must include your resume, and contact information of three reference writers.</p>
<p>Website: <a href="https://cstheory.ucsd.edu/home.html">https://cstheory.ucsd.edu/home.html</a><br/>
Email: barnas@ucsd.edu</p></div>
    </content>
    <updated>2022-02-10T08:02:51Z</updated>
    <published>2022-02-10T08:02:51Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2022-02-17T22:53:38Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://tcsplus.wordpress.com/?p=595</id>
    <link href="https://tcsplus.wordpress.com/2022/02/09/tcs-talk-wednesday-february-23-merav-parter-weizmann-institute-of-science/" rel="alternate" type="text/html"/>
    <title>TCS+ talk: Wednesday, February 23 — Merav Parter, Weizmann Institute of Science</title>
    <summary>The first TCS+ talk of 2022 will take place on Wednesday, February 23rd at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 18:00 UTC). Merav Parter from Weizmann Institute of Science will speak about “New Diameter Reducing Shortcuts: Breaking the Barrier” (abstract below). You can reserve a spot as an individual […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The first TCS+ talk of 2022 will take place on Wednesday, February 23rd at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 18:00 UTC). <a href="https://www.weizmann.ac.il/math/parter/home"><strong>Merav Parter</strong></a> from Weizmann Institute of Science will speak about “<em>New Diameter Reducing Shortcuts: Breaking the <img alt="O(\sqrt{n})" class="latex" src="https://s0.wp.com/latex.php?latex=O%28%5Csqrt%7Bn%7D%29&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/> Barrier</em>” (abstract below).</p>
<p>You can reserve a spot as an individual or a group to join us live by signing up on <a href="https://sites.google.com/view/tcsplus/welcome/next-tcs-talk">the online form</a>. Registration is <em>not</em> required to attend the interactive talk, and the link will be posted on the website the day prior to the talk; however, by registering in the form, you will receive a reminder, along with the link. (The recorded talk will also be posted <a href="https://sites.google.com/view/tcsplus/welcome/past-talks">on our website</a> afterwards) As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/view/tcsplus/welcome/suggest-a-talk">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/view/tcsplus/">the website</a>.</p>
<blockquote class="wp-block-quote"><p>Abstract: For an <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/>-vertex digraph <img alt="G=(V,E)" class="latex" src="https://s0.wp.com/latex.php?latex=G%3D%28V%2CE%29&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/>, a <em>shortcut set</em> is a (small) subset of edges <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/> taken from the transitive closure of <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/> that, when added to <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/> guarantees that the diameter of <img alt="G \cup H" class="latex" src="https://s0.wp.com/latex.php?latex=G+%5Ccup+H&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/> is small. Shortcut sets, introduced by Thorup in 1993, have a wide range of applications in algorithm design, especially in the context of parallel, distributed and dynamic computation on directed graphs. A folklore result in this context shows that every <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/>-vertex digraph admits a shortcut set of linear size (i.e., of <img alt="O(n)" class="latex" src="https://s0.wp.com/latex.php?latex=O%28n%29&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/> edges) that reduces the diameter to <img alt="\widetilde{O}(\sqrt{n})" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cwidetilde%7BO%7D%28%5Csqrt%7Bn%7D%29&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/>. Despite extensive research over the years, the question of whether one can reduce the diameter to <img alt="o(\sqrt{n})" class="latex" src="https://s0.wp.com/latex.php?latex=o%28%5Csqrt%7Bn%7D%29&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/> with <img alt="\widetilde{O}(n)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cwidetilde%7BO%7D%28n%29&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/> shortcut edges has been left open.</p>
<p>In this talk, I will present the first improved diameter-sparsity tradeoff for this problem, breaking the <img alt="\sqrt{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csqrt%7Bn%7D&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/> diameter barrier. Specifically, we show an <img alt="O(n^{\omega})" class="latex" src="https://s0.wp.com/latex.php?latex=O%28n%5E%7B%5Comega%7D%29&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/>-time randomized algorithm for computing a linear shortcut set that reduces the diameter of the digraph to <img alt="\widetilde{O}(n^{1/3})" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cwidetilde%7BO%7D%28n%5E%7B1%2F3%7D%29&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/>. We also extend our algorithms to provide improved <img alt="(\beta,\epsilon)" class="latex" src="https://s0.wp.com/latex.php?latex=%28%5Cbeta%2C%5Cepsilon%29&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/> hopsets for <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/>-vertex weighted directed graphs.</p>
<p>Joint work with Shimon Kogan.</p></blockquote></div>
    </content>
    <updated>2022-02-10T04:08:49Z</updated>
    <published>2022-02-10T04:08:49Z</published>
    <category term="Announcements"/>
    <author>
      <name>plustcs</name>
    </author>
    <source>
      <id>https://tcsplus.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://tcsplus.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://tcsplus.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://tcsplus.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://tcsplus.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A carbon-free dissemination of ideas across the globe.</subtitle>
      <title>TCS+</title>
      <updated>2022-02-17T22:54:33Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://ptreview.sublinear.info/?p=1622</id>
    <link href="https://ptreview.sublinear.info/2022/02/news-for-january-2021-2/" rel="alternate" type="text/html"/>
    <title>News for January 2022</title>
    <summary>A slow month to start 2022, as far as property testing (and myself) are concerned — “only” 3 papers, and a delay of several days in posting this. Let’s jump in with quantum testing! Testing matrix product states, by Mehdi Soleimanifar and John Wright (arXiv). Suppose you are given a state \(|\psi\rangle\) of \(n\) qubits, […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>A slow month to start 2022, as far as property testing (and myself) are concerned — “only” 3 papers, and a delay of several days in posting this. Let’s jump in with quantum testing!</p>



<p><strong>Testing matrix product states</strong>, by Mehdi Soleimanifar and John Wright (<a href="https://arxiv.org/abs/2201.01824">arXiv</a>). Suppose you are given a state \(|\psi\rangle\) of \(n\) qubits, and want to know “how entangled” this whole thing is: for instance, is \(|\psi\rangle\) a product state (no entanglement between the \(n\) qudits)? More generally, the “amount of entanglement” allowed is captured by an integer \(r\), the<em> bond dimension</em>, where product state corresponds to \(r=1\), and larger \(r\) allows for more entanglement. This paper then considers the following property testing question: how many copies of \(|\psi\rangle\) are needed to test whether it has bond dimension at most \(r\), or is \(\varepsilon\)-far from every such state (in trace distance)? While the case \(r=1\) had been previously considered, this paper considers the general case; and, in particular, shows a qualitative gap between \(r=1\) (for which a constant number of copies, \(O(1/\varepsilon^2)\), suffice) and \(r\geq 2\) (for which they show the number of states is \(\Omega(\sqrt{n}/\varepsilon^2)\), and \(O(n r^2/\varepsilon^2)\)).</p>



<p><strong>Constant-time one-shot testing of large-scale graph states</strong>, by Hayata Yamasaki and Sathyawageeswar Subramanian (<a href="https://arxiv.org/abs/2201.11127">arXiv</a>). In this paper, the authors consider the task of testing if the physical error rate of a given system is below a given threshold — namely, the threshold below which fault-tolerant measurement-based quantum computation (MBQC) becomes feasible. Casting this into the framework of property testing, the paper shows that measuring very few (a constant number!) of the input state is enough to test whether the error rate is low.</p>



<p>And, to conclude, a paper which escaped us in December, on private distribution testing:</p>



<p><strong>Pure Differential Privacy from Secure Intermediaries</strong>, by Albert Cheu and Chao Yan (<a href="https://arxiv.org/abs/2112.10032">arXiv</a>). Throwback to <a href="https://ptreview.sublinear.info/2020/05/news-for-april-2020/">April 2020</a> and <a href="https://ptreview.sublinear.info/2021/09/news-for-august-2021/">August 2021</a>, which covered results on distribution testing (uniformity testing!) under the <em>shuffle model</em> of differential privacy. Namely, there was an upper bound of $$ O( k^{2/3}/(\alpha^{4/3}\varepsilon^{2/3})\log^{1/3}(1/\delta) + k^{1/2}/(\alpha\varepsilon) \log^{1/2}(1/\delta) + k^{1/2}/\alpha^2)$$ samples for testing uniformity of distributions over \([k]\), to distance \(\alpha\), under \((\varepsilon,\delta)\)<em>–</em>shuffle privacy (so, <em>approximate</em> privacy: \(\delta&gt;0\)). A partial lower bound existed for <em>pure</em> differential privacy, i.e., when \(\delta=0\): however, no upper bound was known for pure shuffle privacy.<br/>Until now: this new paper shows that pure DP basically comes at no cost, by providing an \((\varepsilon,0)\)-shuffle private testing algorithm with sample complexity $$ O( k^{2/3}/(\alpha^{4/3}\varepsilon^{2/3}) + k^{1/2}/(\alpha\varepsilon) + k^{1/2}/\alpha^2)$$ The paper actually does a lot more, focusing on a different problem, private summation; and the testing upper bound is a corollary of the new methods they develop in the process.</p></div>
    </content>
    <updated>2022-02-09T07:05:07Z</updated>
    <published>2022-02-09T07:05:07Z</published>
    <category term="Monthly digest"/>
    <author>
      <name>Clement Canonne</name>
    </author>
    <source>
      <id>https://ptreview.sublinear.info</id>
      <link href="https://ptreview.sublinear.info/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://ptreview.sublinear.info" rel="alternate" type="text/html"/>
      <subtitle>The latest in property testing and sublinear time algorithms</subtitle>
      <title>Property Testing Review</title>
      <updated>2022-02-17T22:55:04Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-72814287285807577</id>
    <link href="http://blog.computationalcomplexity.org/feeds/72814287285807577/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/02/a-book-break.html#comment-form" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/72814287285807577" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/72814287285807577" rel="self" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/02/a-book-break.html" rel="alternate" type="text/html"/>
    <title>A Book Break</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I got the writing bug back while working on my <a href="https://cacm.acm.org/magazines/2022/1/257448-fifty-years-of-p-vs-np-and-the-possibility-of-the-impossible/fulltext">recent CACM article</a> and I'd like to try my hand at another book. Not sure the exact topic but something related to the changing nature of computing and its implications. </p><p>I'll cut down my blogging for a while. I'll still post or tweet when I have something I want to say. Bill will continue to post regularly and keep this blog active.</p><p>Bill asked me if I have time to write this book as dean but he already knew the answer. Writing keeps me sane in a world that seems less and less so.</p></div>
    </content>
    <updated>2022-02-08T23:00:00Z</updated>
    <published>2022-02-08T23:00:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="http://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2022-02-17T08:08:24Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2022/02/08/postdoc-in-quantum-algorithms-at-university-of-latvia-at-centre-for-quantum-computer-science-university-of-latvia-apply-by-march-1-2022/</id>
    <link href="https://cstheory-jobs.org/2022/02/08/postdoc-in-quantum-algorithms-at-university-of-latvia-at-centre-for-quantum-computer-science-university-of-latvia-apply-by-march-1-2022/" rel="alternate" type="text/html"/>
    <title>postdoc in quantum algorithms at University of Latvia at Centre for Quantum Computer Science, University of Latvia (apply by March 1, 2022)</title>
    <summary>Applications are invited for a postdoctoral position at the Centre for Quantum Computer Science (CQCS), University of Latvia, lead by prof. Andris Ambainis. We are looking for candidates who would be interested in quantum algorithms (with background in either quantum information or classical TCS.) The appointment would be for 2 years, starting between September 1, […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Applications are invited for a postdoctoral position at the Centre for Quantum Computer Science (CQCS), University of Latvia, lead by prof. Andris Ambainis. We are looking for candidates who would be interested in quantum algorithms (with background in either quantum information or classical TCS.) The appointment would be for 2 years, starting between September 1, 2022 and January 1, 2023.</p>
<p>Website: <a href="https://quantum.lu.lv/join-us/">https://quantum.lu.lv/join-us/</a><br/>
Email: ambainis@lu.lv</p></div>
    </content>
    <updated>2022-02-08T18:16:56Z</updated>
    <published>2022-02-08T18:16:56Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2022-02-17T22:53:38Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/014</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/014" rel="alternate" type="text/html"/>
    <title>TR22-014 |  Tighter MA/1 Circuit Lower Bounds From Verifier Efficient PCPs for PSPACE | 

	Joshua Cook, 

	Dana Moshkovitz</title>
    <summary>We prove for some constant $a &gt; 1$, for all $k \leq a$,
$$\mathbf{MATIME}[n^{k + o(1)}] / 1 \not \subset \mathbf{SIZE}[O(n^{k})],$$
for some specific $o(1)$ function. This improves on the Santhanam lower bound, which says there exists constant $c$ such that for all $k &gt; 1$:
$$\mathbf{MATIME}[n^{c k}] / 1 \not \subset \mathbf{SIZE}[O(n^{k})].$$
There is inherently no upper bound on $c$ in Santhanam's proof. Using ideas from Murray and Williams, all $k &gt; 1$:
$$\mathbf{MATIME}[n^{10 k^2}] / 1 \not \subset \mathbf{SIZE}[O(n^{k})].$$
    
Our proof uses a new, very efficient $\mathbf{PCP}$ for $\mathbf{PSPACE}$. We construct a $\mathbf{PCP}$ with unbounded proof length for $\mathbf{SPACE}[O(n)]$ that has a $\tilde{O}(n)$ time verifier, $\tilde{O}(n)$ space prover, $O(\log(n))$ queries, and polynomial alphabet size. Prior to this work, $\mathbf{PCP}$s for $\mathbf{SPACE}[O(n)]$ either used $\Omega(n)$ queries or had verifiers that run in $\Omega(n^2)$ time.</summary>
    <updated>2022-02-08T14:57:45Z</updated>
    <published>2022-02-08T14:57:45Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-02-17T22:53:07Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-6817129401606575319</id>
    <link href="http://blog.computationalcomplexity.org/feeds/6817129401606575319/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/02/pspace-is-contained-in-zero-knowledge.html#comment-form" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/6817129401606575319" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/6817129401606575319" rel="self" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/02/pspace-is-contained-in-zero-knowledge.html" rel="alternate" type="text/html"/>
    <title>PSPACE is contained in Zero Knowledge!! How come nobody seems to care?</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>(This post was inspired by Lance's post on Zero Knowledge, <a href="https://blog.computationalcomplexity.org/2022/02/the-beginnings-of-zero-knowledge.html">here</a>, which was inspired by a video he has in the post which was inspired by... (I think this ordering is well founded.))</p><p> ZK= Zero Knowledge.</p><p>When it was shown that NP \subseteq ZK this was a big deal. This was by Goldreich-Micali-Wigderson  (see <a href="https://dl.acm.org/doi/10.1145/116825.116852">her</a>e (FOCS-1986, JACM-1991). In the JACM paper they have the following passage:</p><div><blockquote>Our result that all languages in NP have zero-knowledge proof systems, has been extended to IP, assuming the same assumptions. (The result was first proved by Impagliazzo and Yung, but since their paper [53] contains only a claim of the result, the interested reader is directed to [11] where a (different proof) appears.) In other words, whatever can be efficiently proven can be efficiently proven in a zero-knowledge manner. This may be viewed as the best result possible, since only languages having interactive proof systems can have zero-knowledge interactive proof systems.<br/><br/>11. BEN-OR, M., GOLDREICH, O., GOLDWASSER, S., HASTAD, J., KILLIAN, J., MICALI, S,,  AND ROGAWAY, P. Everything provable is provable in zero-knowledge. In Proceedings of Advances in Cryptology— Crypto88. Lecture Notes in Computer Science, vol. 403. Springer-Verlag, New York, 1990, pp. 37-56.<br/><br/>53.IMPAGLIAZZO. R., AND YUNG, M. Direct minimum-knowledge computations. In C. Pomerance, ed., Proceedings of Advances in Cryptology— Crypto87. Lecture Notes in Computer Science, vol. 293. Springer-Verlag, New York, 1987, pp. 40-51.</blockquote>Later the papers of Lund-Fortnow-Karloff-Nisan and Shamir showed IP=PSPACE. Hence<br/><br/><div style="text-align: center;">PSPACE \subseteq ZK</div><p>When I realized this I thought OH, that's interesting! I then looked around the web and could not find any mention of it. I asked Lance and some people in crypto and yeah, they all knew it was true, but nobody seemed to care.</p><p>Why the apathy? Speculation:</p><p>1) ZK is a notion people actually want to use in real crypto (and there has been some progress on that lately). The prover for ZK in PSPACE has to be way to powerful to be practical. I don't really like this explanation since we are talking about theorists. Even in crypto, which has more of a connection to the real works then, say, Ramsey Theory, there are still plenty of non-useful results. </p><p>2) IP=PSPACE was the big news and  had interesting proof with nice ideas. Nothing crypto-ish about it. So the corollary that PSPACE \subseteq ZK is an afterthought. </p><p>3) SAT in ZK was big news. IP in ZK is nice, but uses mostly the same ideas.</p><p>4) I am WRONG- it is a celebrated result and I somehow missed the celebration.</p><p>5) The proof that ZK is in PSPACE USES two interesting results, but adds NOTHING to the mix. In short, the proof is to easy.</p><p>Any other ideas?</p></div></div>
    </content>
    <updated>2022-02-06T20:19:00Z</updated>
    <published>2022-02-06T20:19:00Z</published>
    <author>
      <name>gasarch</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03004932739846901628</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="http://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2022-02-17T08:08:24Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://scottaaronson.blog/?p=6288</id>
    <link href="https://scottaaronson.blog/?p=6288" rel="alternate" type="text/html"/>
    <link href="https://scottaaronson.blog/?p=6288#comments" rel="replies" type="text/html"/>
    <link href="https://scottaaronson.blog/?feed=atom&amp;p=6288" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">AlphaCode as a dog speaking mediocre English</title>
    <summary xml:lang="en-US">Tonight, I took the time actually to read DeepMind’s AlphaCode paper, and to work through the example contest problems provided, and understand how I would’ve solved those problems, and how AlphaCode solved them. It is absolutely astounding. Consider, for example, the “n singers” challenge (pages 59-60). To solve this well, you first need to parse […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>Tonight, I took the time actually to read DeepMind’s <a href="https://storage.googleapis.com/deepmind-media/AlphaCode/competition_level_code_generation_with_alphacode.pdf">AlphaCode paper</a>, and to work through the example contest problems provided, and understand how I would’ve solved those problems, and how AlphaCode solved them.</p>



<p>It is absolutely astounding.</p>



<p>Consider, for example, the “n singers” challenge (pages 59-60). To solve this well, you first need to parse a somewhat convoluted English description, discarding the irrelevant fluff about singers, in order to figure out that you’re being asked to find a positive integer solution (if it exists) to a linear system whose matrix looks like<br/>1 2 3 4<br/>4 1 2 3<br/>3 4 1 2<br/>2 3 4 1.<br/>Next you need to find a trick for solving such a system without Gaussian elimination or the like (I’ll leave that as an exercise…). Finally, you need to generate code that implements that trick, correctly handling the wraparound at the edges of the matrix, and breaking and returning “NO” for any of multiple possible reasons why a positive integer solution won’t exist.   Oh, and also correctly parse the input.</p>



<p>Yes, I realize that AlphaCode generates a million candidate programs for each challenge, then discards the vast majority by checking that they don’t work on the example data provided, then <em>still</em> has to use clever tricks to choose from among the thousands of candidates remaining. I realize that it was trained on tens of thousands of contest problems and millions of solutions to those problems. I realize that it “only” solves about a third of the contest problems, making it similar to a mediocre human programmer on these problems. I realize that it works only in the artificial domain of programming contests, where a complete English problem specification and example inputs and outputs are always provided.</p>



<p>Forget all that. Judged against where AI was 20-25 years ago, when I was a student, a dog is now holding meaningful conversations in English. And people are complaining that the dog isn’t a very eloquent orator, that it often makes grammatical errors and has to start again, that it took heroic effort to train it, and that it’s unclear how much the dog really understands.</p>



<p>It’s not obvious how you go from solving programming contest problems to conquering the human race or whatever, but I feel pretty confident that we’ve now entered a world where “programming” will look different.</p>



<p><strong>Update:</strong> A colleague of mine points out that one million, the number of candidate programs that AlphaCode needs to generate, could be seen as roughly exponential in the number of lines of the generated programs.  If so, this suggests a perspective according to which DeepMind has created almost the exact equivalent, in AI code generation, of a non-fault-tolerant quantum computer that’s nevertheless competitive on some task (as in the quantum supremacy experiments). I.e., it clearly does something highly nontrivial, but the “signal” is still decreasing exponentially with the number of instructions, necessitating an exponential number of repetitions to extract the signal and imposing a limit on the size of the programs you can scale to.</p></div>
    </content>
    <updated>2022-02-06T09:12:13Z</updated>
    <published>2022-02-06T09:12:13Z</published>
    <category scheme="https://scottaaronson.blog" term="Nerd Interest"/>
    <category scheme="https://scottaaronson.blog" term="The Fate of Humanity"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://scottaaronson.blog/?feed=atom</id>
      <icon>https://scottaaronson.blog/wp-content/uploads/2021/10/cropped-Jacket-32x32.gif</icon>
      <link href="https://scottaaronson.blog" rel="alternate" type="text/html"/>
      <link href="https://scottaaronson.blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2022-02-14T19:44:57Z</updated>
    </source>
  </entry>
</feed>
