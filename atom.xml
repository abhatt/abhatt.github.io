<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2021-09-26T03:22:07Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2109.11538</id>
    <link href="http://arxiv.org/abs/2109.11538" rel="alternate" type="text/html"/>
    <title>A complete and continuous map of the Lattice Isometry Space for all 3-dimensional lattices</title>
    <feedworld_mtime>1632528000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Matthew Bright, Andrew I Cooper, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kurlin:Vitaliy.html">Vitaliy Kurlin</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2109.11538">PDF</a><br/><b>Abstract: </b>This paper extends the recently obtained complete and continuous map of the
Lattice Isometry Space (LISP) to the practical case of dimension 3. A periodic
3-dimensional lattice is an infinite set of all integer linear combinations of
basis vectors in Euclidean 3-space. Motivated by crystal structures determined
in a rigid form, we study lattices up to rigid motion or isometry, which is a
composition of translations, rotations and reflections. The resulting space
LISP consists of infinitely many isometry classes of lattices. In dimension 3,
we parameterise this continuous space LISP by six coordinates and introduce new
metrics satisfying the metric axioms and continuity under all perturbations.
This parameterisation helps to visualise hundreds of thousands of real crystal
lattices from the Cambridge Structural Database for the first time.
</p></div>
    </summary>
    <updated>2021-09-25T23:34:18Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2021-09-24T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2109.11537</id>
    <link href="http://arxiv.org/abs/2109.11537" rel="alternate" type="text/html"/>
    <title>Sparse Regression Faster than $d^\omega$</title>
    <feedworld_mtime>1632528000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Ghadiri:Mehrdad.html">Mehrdad Ghadiri</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Peng:Richard.html">Richard Peng</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vempala:Santosh_S=.html">Santosh S. Vempala</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2109.11537">PDF</a><br/><b>Abstract: </b>The current complexity of regression is nearly linear in the complexity of
matrix multiplication/inversion. Here we show that algorithms for $2$-norm
regression, i.e., standard linear regression, as well as $p$-norm regression
(for $1 &lt; p &lt; \infty$) can be improved to go below the matrix multiplication
threshold for sufficiently sparse matrices. We also show that for some values
of $p$, the dependence on dimension in input-sparsity time algorithms can be
improved beyond $d^\omega$ for tall-and-thin row-sparse matrices.
</p></div>
    </summary>
    <updated>2021-09-25T23:23:50Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-09-24T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2109.11515</id>
    <link href="http://arxiv.org/abs/2109.11515" rel="alternate" type="text/html"/>
    <title>Outlier-Robust Sparse Estimation via Non-Convex Optimization</title>
    <feedworld_mtime>1632528000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cheng:Yu.html">Yu Cheng</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Diakonikolas:Ilias.html">Ilias Diakonikolas</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kane:Daniel_M=.html">Daniel M. Kane</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Ge:Rong.html">Rong Ge</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gupta:Shivam.html">Shivam Gupta</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Soltanolkotabi:Mahdi.html">Mahdi Soltanolkotabi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2109.11515">PDF</a><br/><b>Abstract: </b>We explore the connection between outlier-robust high-dimensional statistics
and non-convex optimization in the presence of sparsity constraints, with a
focus on the fundamental tasks of robust sparse mean estimation and robust
sparse PCA. We develop novel and simple optimization formulations for these
problems such that any approximate stationary point of the associated
optimization problem yields a near-optimal solution for the underlying robust
estimation task. As a corollary, we obtain that any first-order method that
efficiently converges to stationarity yields an efficient algorithm for these
tasks. The obtained algorithms are simple, practical, and succeed under broader
distributional assumptions compared to prior work.
</p></div>
    </summary>
    <updated>2021-09-25T23:28:26Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-09-24T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2109.11505</id>
    <link href="http://arxiv.org/abs/2109.11505" rel="alternate" type="text/html"/>
    <title>Multidimensional Scaling: Approximation and Complexity</title>
    <feedworld_mtime>1632528000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Erik Demaine, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hesterberg:Adam.html">Adam Hesterberg</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Koehler:Frederic.html">Frederic Koehler</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lynch:Jayson.html">Jayson Lynch</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/u/Urschel:John.html">John Urschel</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2109.11505">PDF</a><br/><b>Abstract: </b>Metric Multidimensional scaling (MDS) is a classical method for generating
meaningful (non-linear) low-dimensional embeddings of high-dimensional data.
MDS has a long history in the statistics, machine learning, and graph drawing
communities. In particular, the Kamada-Kawai force-directed graph drawing
method is equivalent to MDS and is one of the most popular ways in practice to
embed graphs into low dimensions. Despite its ubiquity, our theoretical
understanding of MDS remains limited as its objective function is highly
non-convex. In this paper, we prove that minimizing the Kamada-Kawai objective
is NP-hard and give a provable approximation algorithm for optimizing it, which
in particular is a PTAS on low-diameter graphs. We supplement this result with
experiments suggesting possible connections between our greedy approximation
algorithm and gradient-based methods.
</p></div>
    </summary>
    <updated>2021-09-25T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2021-09-24T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2109.11498</id>
    <link href="http://arxiv.org/abs/2109.11498" rel="alternate" type="text/html"/>
    <title>Partitioning an interval graph into subgraphs with small claws</title>
    <feedworld_mtime>1632528000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jiang:Rain.html">Rain Jiang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jiang:Kai.html">Kai Jiang</a>, Minghui Jiang <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2109.11498">PDF</a><br/><b>Abstract: </b>The claw number of a graph $G$ is the largest number $v$ such that $K_{1,v}$
is an induced subgraph of $G$. Interval graphs with claw number at most $v$ are
cluster graphs when $v = 1$, and are proper interval graphs when $v = 2$.
</p>
<p>Let $\kappa(n,v)$ be the smallest number $k$ such that every interval graph
with $n$ vertices admits a vertex partition into $k$ induced subgraphs with
claw number at most $v$. Let $\check\kappa(w,v)$ be the smallest number $k$
such that every interval graph with claw number $w$ admits a vertex partition
into $k$ induced subgraphs with claw number at most $v$. We show that
$\kappa(n,v) = \lfloor\log_{v+1} (n v + 1)\rfloor$, and that $\lfloor\log_{v+1}
w\rfloor + 1 \le \check\kappa(w,v) \le \lfloor\log_{v+1} w\rfloor + 3$.
</p>
<p>Besides the combinatorial bounds, we also present a simple approximation
algorithm for partitioning an interval graph into the minimum number of induced
subgraphs with claw number at most $v$, with approximation ratio $3$ when $1
\le v \le 2$, and $2$ when $v \ge 3$.
</p></div>
    </summary>
    <updated>2021-09-25T23:22:40Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-09-24T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2109.11330</id>
    <link href="http://arxiv.org/abs/2109.11330" rel="alternate" type="text/html"/>
    <title>Quantum algorithms for group convolution, cross-correlation, and equivariant transformations</title>
    <feedworld_mtime>1632528000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Grecia Castelazo, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nguyen:Quynh_T=.html">Quynh T. Nguyen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Palma:Giacomo_De.html">Giacomo De Palma</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Englund:Dirk.html">Dirk Englund</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lloyd:Seth.html">Seth Lloyd</a>, Bobak T. Kiani <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2109.11330">PDF</a><br/><b>Abstract: </b>Group convolutions and cross-correlations, which are equivariant to the
actions of group elements, are commonly used in mathematics to analyze or take
advantage of symmetries inherent in a given problem setting. Here, we provide
efficient quantum algorithms for performing linear group convolutions and
cross-correlations on data stored as quantum states. Runtimes for our
algorithms are logarithmic in the dimension of the group thus offering an
exponential speedup compared to classical algorithms when input data is
provided as a quantum state and linear operations are well conditioned.
Motivated by the rich literature on quantum algorithms for solving algebraic
problems, our theoretical framework opens a path for quantizing many algorithms
in machine learning and numerical methods that employ group operations.
</p></div>
    </summary>
    <updated>2021-09-25T23:32:54Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-09-24T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2109.11244</id>
    <link href="http://arxiv.org/abs/2109.11244" rel="alternate" type="text/html"/>
    <title>An algorithm for reconstructing level-2 phylogenetic networks from trinets</title>
    <feedworld_mtime>1632528000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Iersel:Leo_van.html">Leo van Iersel</a>, Sjors Kole, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Moulton:Vincent.html">Vincent Moulton</a>, Leonie Nipius <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2109.11244">PDF</a><br/><b>Abstract: </b>Evolutionary histories for species that cross with one another or exchange
genetic material can be represented by leaf-labelled, directed graphs called
phylogenetic networks. A major challenge in the burgeoning area of phylogenetic
networks is to develop algorithms for building such networks by amalgamating
small networks into a single large network. The level of a phylogenetic network
is a measure of its deviation from being a tree; the higher the level of
network, the less treelike it becomes. Various algorithms have been developed
for building level-1 networks from small networks. However, level-1 networks
may not be able to capture the complexity of some data sets. In this paper, we
present a polynomial-time algorithm for constructing a rooted binary level-2
phylogenetic network from a collection of 3-leaf networks or trinets. Moreover,
we prove that the algorithm will correctly reconstruct such a network if it is
given all of the trinets in the network as input. The algorithm runs in time
$O(t\cdot n+n^4)$ with $t$ the number of input trinets and $n$ the number of
leaves. We also show that there is a fundamental obstruction to constructing
level-3 networks from trinets, and so new approaches will need to be developed
for constructing level-3 and higher level-networks.
</p></div>
    </summary>
    <updated>2021-09-25T23:26:41Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-09-24T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2109.11203</id>
    <link href="http://arxiv.org/abs/2109.11203" rel="alternate" type="text/html"/>
    <title>Filling Crosswords is Very Hard</title>
    <feedworld_mtime>1632528000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gourv=egrave=s:Laurent.html">Laurent Gourvès</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Harutyunyan:Ararat.html">Ararat Harutyunyan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lampis:Michael.html">Michael Lampis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Melissinos:Nikolaos.html">Nikolaos Melissinos</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2109.11203">PDF</a><br/><b>Abstract: </b>We revisit a classical crossword filling puzzle which already appeared in
Garey\&amp;Jonhson's book. We are given a grid with $n$ vertical and horizontal
slots and a dictionary with $m$ words and are asked to place words from the
dictionary in the slots so that shared cells are consistent. We attempt to
pinpoint the source of intractability of this problem by taking into account
the structure of the grid graph, which contains a vertex for each slot and an
edge if two slots intersect. Our main approach is to consider the case where
this graph has a tree-like structure. Unfortunately, if we impose the common
rule that words cannot be reused, we show that the problem remains NP-hard even
under very severe structural restrictions. The problem becomes slightly more
tractable if word reuse is allowed, as we obtain an $m^{tw}$ algorithm in this
case, where $tw$ is the treewidth of the grid graph. However, even in this
case, we show that our algorithm cannot be improved. More strongly, we show
that under the ETH the problem cannot be solved in time $m^{o(k)}$, where $k$
is the number of horizontal slots of the instance.
</p>
<p>Motivated by these mostly negative results, we consider the much more
restricted case where the problem is parameterized by the number of slots $n$.
Here, we show that the problem becomes FPT, but the parameter dependence is
exponential in $n^2$. We show that this dependence is also justified: the
existence of an algorithm with running time $2^{o(n^2)}$ would contradict the
randomized ETH. Finally, we consider an optimization version of the problem,
where we seek to place as many words on the grid as possible. Here it is easy
to obtain a $\frac{1}{2}$-approximation, even on weighted instances. We show
that this algorithm is also likely to be optimal, as obtaining a better
approximation ratio in polynomial time would contradict the Unique Games
Conjecture.
</p></div>
    </summary>
    <updated>2021-09-25T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-09-24T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2109.11130</id>
    <link href="http://arxiv.org/abs/2109.11130" rel="alternate" type="text/html"/>
    <title>Adversarially Robust Coloring for Graph Streams</title>
    <feedworld_mtime>1632528000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chakrabarti:Amit.html">Amit Chakrabarti</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Ghosh:Prantar.html">Prantar Ghosh</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Stoeckl:Manuel.html">Manuel Stoeckl</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2109.11130">PDF</a><br/><b>Abstract: </b>A streaming algorithm is considered to be adversarially robust if it provides
correct outputs with high probability even when the stream updates are chosen
by an adversary who may observe and react to the past outputs of the algorithm.
We grow the burgeoning body of work on such algorithms in a new direction by
studying robust algorithms for the problem of maintaining a valid vertex
coloring of an $n$-vertex graph given as a stream of edges. Following standard
practice, we focus on graphs with maximum degree at most $\Delta$ and aim for
colorings using a small number $f(\Delta)$ of colors.
</p>
<p>A recent breakthrough (Assadi, Chen, and Khanna; SODA~2019) shows that in the
standard, non-robust, streaming setting, $(\Delta+1)$-colorings can be obtained
while using only $\widetilde{O}(n)$ space. Here, we prove that an adversarially
robust algorithm running under a similar space bound must spend almost
$\Omega(\Delta^2)$ colors and that robust $O(\Delta)$-coloring requires a
linear amount of space, namely $\Omega(n\Delta)$. We in fact obtain a more
general lower bound, trading off the space usage against the number of colors
used. From a complexity-theoretic standpoint, these lower bounds provide
(i)~the first significant separation between adversarially robust algorithms
and ordinary randomized algorithms for a natural problem on insertion-only
streams and (ii)~the first significant separation between randomized and
deterministic coloring algorithms for graph streams, since deterministic
streaming algorithms are automatically robust.
</p>
<p>We complement our lower bounds with a suite of positive results, giving
adversarially robust coloring algorithms using sublinear space. In particular,
we can maintain an $O(\Delta^2)$-coloring using $\widetilde{O}(n
\sqrt{\Delta})$ space and an $O(\Delta^3)$-coloring using $\widetilde{O}(n)$
space.
</p></div>
    </summary>
    <updated>2021-09-25T23:27:52Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-09-24T01:30:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2021/09/25/multilayer-tiles</id>
    <link href="https://11011110.github.io/blog/2021/09/25/multilayer-tiles.html" rel="alternate" type="text/html"/>
    <title>Multilayer tiles</title>
    <summary>You’re probably familiar with the fact that you can draw a convex octagon with corners in an integer grid, fitting into a \(3\times 3\) square. It’s not regular, because its side lengths alternate between \(1\) and \(\sqrt 2\), but it has the same angles as a regular octagon and looks close enough to it for some purposes.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>You’re probably familiar with the fact that you can draw a convex octagon with corners in an integer grid, fitting into a \(3\times 3\) square. It’s not regular, because its side lengths alternate between \(1\) and \(\sqrt 2\), but it has the same angles as a regular octagon and looks close enough to it for some purposes.</p>

<p style="text-align: center;"><img alt="3x3 integer octagon and its 7-ply tiling of the plane" src="https://11011110.github.io/blog/assets/2021/7way-octagon.svg"/></p>

<p>It also has another interesting property: if you place copies of it at every point of the integer grid, then each edge of each copy is also the edge of another copy. Therefore, if you let \(p\) be any point that avoids the edges of the octagons, count the number of octagons that cover any point of the plane, and then slide \(p\) around to another edge-avoiding point, the number of covering octagons always stays unchanged. Whenever \(p\) slides off from one octagon, it slides onto another one. Because the area of the integer octagon is seven units, and you’re placing one octagon for every unit square of the grid, the average covering depth is seven. And since the covering depth stays the same everywhere, it’s seven everywhere. You can think of this collection of octagons as forming a <span style="white-space: nowrap;">\(7\)-ply</span> tiling of the plane, despite the fact that convex octagons cannot tile the plane in the usual \(1\)-ply sense of tiling.</p>

<p>More generally, define a \(k\)-ply tiling to be a covering of the plane by congruent copies of some prototile (allowing rotations, even though these are not necessary for the octagon) such that, except at a subset of the plane of measure zero (the boundaries of the prototiles), every point is covered by exactly \(k\) copies, and define the “ply” of a prototile to be the minimum \(k\) such that it has a \(k\)-ply tiling. The integer octagon has <span style="white-space: nowrap;">ply \(7\):</span> once one octagon is placed anywhere in the plane, the rest of the tiling is forced to follow in the same way around it, in order to avoid creating seams where an octagon edge is not matched by another octagon and the ply changes. The same construction, using centrally symmetric octagons with integer vertices and longer sides, produces for any \(k\ge9\) a convex tile of <span style="white-space: nowrap;">ply \(k\).</span></p>

<p>This is the subject of my new short paper (or maybe extended abstract) “Multifold tiles of polyominoes and convex lattice polygons”, with many coauthors from the 2017 Bellairs Winter Workshop on Computational Geometry: Kota Chida, Erik Demaine, Martin Demaine, Adam Hesterberg, Takashi Horiyama, John Iacono, Hiro Ito, Stefan Langerman, Ryuhei Uehara, and Yushi Uno. You can find it in the <a href="http://www.math.science.cmu.ac.th/tjcdcggg/Book-abstract.pdf">book of abstracts of the 23rd Thailand–Japan Conference on Discrete and Computational Geometry, Graphs, and Games (TJCDCG<sup>3</sup> 2020+1)</a>, which was organized online by Chiang Mai University earlier this month.</p>

<p>As well as the family of octagon \(k\)-ply tilers described above, we found that cutting the bottom row of squares off a \(3\times 3\) octagon produces a \(5\)-ply hexagon tiler, this time requiring \(180^\circ\)-degree rotations for its tiling, and that stretching this hexagon can produce an <span style="white-space: nowrap;">\(8\)-ply</span> convex tiler. We also found polyomino <span style="white-space: nowrap;">\(k\)-ply</span> tilers for <span style="white-space: nowrap;">all \(k\ge 2\),</span> and three heptominoes (the smallest possible polyominoes) that can each form <span style="white-space: nowrap;">\(k\)-ply</span> tilings for all \(k\ge 2\) but not for <span style="white-space: nowrap;">\(k=1\).</span> I imagine the details will become available in a more complete paper at some point but for now the abstract just announces these results and gives pictures of these heptominoes. We still don’t know whether there can exist convex polygons whose ply is one of <span style="white-space: nowrap;">\(\{2,3,4,6\}\).</span></p>

<p>The TJCDCG<sup>3</sup> abstract book has many other intriguing results in discrete geometry, graph theory, and combinatorial game theory, so do check it out if you’re interested. Tiling-related highlights include a variation on Wang tiling adding connectivity constraints and inspired by a dungeon-making mini-game in <em>The Legend of Zelda: Link’s Awakening</em> (“Tiling the Plane Connectively with Wang Tiles”, Chao Yang), signal processing using high-dimensional substitution tilings (“Generating Frames via Discretized Substitution Tilings”, Luis S. Silvestre Jr. and Job A. Nable), a partial classification of edge-to-edge monohedral tilings of the sphere (“Tiling of the Sphere by Congruent Polygons”, Yohji Akama, Hoi Ping Luk, Erxiao Wang, and Min Yan), and tilings that can be used to make arrays of joined-up origami cranes (“Renzuru Tilings with Asymmetric Quadrilaterals”, Takashi Yoshino).</p>

<p>(<a href="https://mathstodon.xyz/@11011110/106995035140693185">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2021-09-25T00:00:00Z</updated>
    <published>2021-09-25T00:00:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2021-09-26T00:06:13Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=5850</id>
    <link href="https://www.scottaaronson.com/blog/?p=5850" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=5850#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=5850" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Was Scientific American Sokal’d?</title>
    <summary xml:lang="en-US">Here’s yesterday’s clickbait offering from Scientific American, the once-legendary home of Martin Gardner’s Mathematical Games column: Why the Term ‘JEDI’ Is Problematic for Describing Programs That Promote Justice, Equity, Diversity and Inclusion The sad thing is, I see few signs that this essay was meant as a Sokal-style parody, although in many ways it’s written […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>Here’s yesterday’s clickbait offering from <em>Scientific American</em>, the once-legendary home of Martin Gardner’s Mathematical Games column:</p>



<p><a href="https://www.scientificamerican.com/article/why-the-term-jedi-is-problematic-for-describing-programs-that-promote-justice-equity-diversity-and-inclusion/">Why the Term ‘JEDI’ Is Problematic for Describing Programs That Promote Justice, Equity, Diversity and Inclusion</a></p>



<p>The sad thing is, I see few signs that this essay was meant as a Sokal-style parody, although in many ways it’s written as one.  The essay actually develops a 100% cogent, reasoned argument: namely, that the ideology of the <em>Star Wars</em> films doesn’t easily fit with the new ideology of militant egalitarianism at the expense of all other human values, including irony, humor, joy, and the nurturing of unusual talents. The authors are merely oblivious to the conclusion that most people would draw from their argument: namely, so much the worse for the militant egalitarianism then!</p>



<p>I predict that this proposal—to send the acronym “JEDI” the way of “mankind,” “blacklist,” and, err, “quantum supremacy”—will meet with opposition even from the wokeists themselves, a huge fraction of whom (in my experience) have soft spots for the <em>Star Wars</em> franchise.  Recall for example that in 2014, Laurie Penny used <em>Star Wars</em> metaphors in her <a href="https://www.newstatesman.com/uncategorized/2014/12/on-nerd-entitlement-rebel-alliance-empire">interesting response</a> to my comment-171, telling male nerds like me that we need to learn to accept that “[we’re] not the Rebel Alliance, [we’re] actually part of the Empire and have been all along.”  Admittedly, I’ve never <em>felt like</em> part of an Empire, although I’ll confess to some labored breathing lately when ascending flights of stairs.</p>



<p>As for me, I spent much of my life opposed in principle to <em>Star Wars</em>—I hated how the most successful “science fiction” franchise of all time became that way <em>precisely</em> by ditching any pretense of science and fully embracing mystical woo—but sure, when the chips are down, I’m crazy and radical enough to take the side of Luke Skywalker, even if a team of woke theorists is earnestly, unironically explaining to me that lightsabers are phallocentric and that Vader ranks higher on the intersectional oppression axis because of his breathing problem.</p>



<p>Meantime, of course, the US continues to <a href="https://l.facebook.com/l.php?u=https%3A%2F%2Fwww.washingtonpost.com%2Fopinions%2F2021%2F09%2F23%2Frobert-kagan-constitutional-crisis">careen toward its worst Constitutional crisis since the Civil War</a>, as Trump prepares to run again in 2024, and as this time around, the Republicans are systematically purging state governments of their last Brad Raffenspergers, of anyone who might stand in the way of them simply setting aside the vote totals and declaring Trump the winner regardless of the actual outcome.  It’s good to know that my fellow progressives have their eyes on the ball—so that when that happens, at least universities will no longer be using offensive acronyms like “JEDI”!</p></div>
    </content>
    <updated>2021-09-24T19:41:19Z</updated>
    <published>2021-09-24T19:41:19Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Obviously I'm Not Defending Aaronson"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Rage Against Doofosity"/>
    <category scheme="https://www.scottaaronson.com/blog" term="The Fate of Humanity"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="http://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2021-09-24T22:05:29Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2021/09/24/which-integer-sequences</id>
    <link href="https://11011110.github.io/blog/2021/09/24/which-integer-sequences.html" rel="alternate" type="text/html"/>
    <title>Which integer sequences form denominators of Egyptian fractions?</title>
    <summary>I have a new paper out: “Egyptian Fractions with Denominators from Sequences Closed Under Doubling”, in the Journal of Integer Sequences. (There should also be an arXiv version soon but despite my long association with arXiv they made me get an endorser before I could upload to the number theory category, slowing down my submission there.)</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I have a new paper out: “<a href="https://cs.uwaterloo.ca/journals/JIS/VOL24/Eppstein/eppstein2.html">Egyptian Fractions with Denominators from Sequences Closed Under Doubling</a>”, in the <em>Journal of Integer Sequences</em>. (There should also be an arXiv version soon but despite my long association with arXiv they made me get an endorser before I could upload to the number theory category, slowing down my submission there.)</p>

<p>Anyway, it’s basically a journal version of an old blog post here, “<a href="https://11011110.github.io/blog/2016/11/20/egyptian-fractions-with.html">Egyptian fractions with practical denominators</a>”. That post concerned the <a href="https://en.wikipedia.org/wiki/Practical_number">practical numbers</a>, positive integers \(n\) such that all other positive integers up to \(n\) can be represented as sums of distinct divisors of \(n\). This definition gives the practical numbers a natural connection to <a href="https://en.wikipedia.org/wiki/Egyptian_fraction">Egyptian fractions</a>, representations of rational numbers as sums of distinct unit fractions: if you represent a number \(k&lt;n\) by a sum of distinct divisors of \(n\), and then divide everything by \(n\), you get an Egyptian fraction for \(k/n\). Zhi-Wei Sun asked whether the practical numbers and Egyptian fractions were connected in a different way, with every positive integer having an Egyptian fraction representation in which all denominators are practical, and my blog post provides a positive answer to Sun’s question.</p>

<p>The new paper simplifies the presentation of the solution, compared to the blog post, by providing direct formulas for the representation rather than an iterative computational method for finding it. But beyond that, it also shows that the same method (based on dividing by a large power of two and dealing separately with the quotient and remainder) works for many other integer sequences beyond the practical numbers. All it needs from an integer sequence is two simple properties:</p>

<ul>
  <li>
    <p>The sequence should include a multiple of every integer. In order to represent \(k/p\) as an Egyptian fraction, when \(p\) is prime, the denominators must include at least one multiple of \(p\), so the requirement of including multiples is pretty natural in this context.</p>
  </li>
  <li>
    <p>For every number \(n\) that belongs to the sequence, \(2n\) should also belong to the sequence. This is the “closed under doubling” of the new article’s title, and is closely connected to the method used by the article involving division by powers of two.</p>
  </li>
</ul>

<p>Whenever a sequence \(S\) of positive integers has both properties, we can find Egyptian fractions for all positive rationals up to \(\sum_{x\in S}1/x\), the natural limiting value for such representations. When \(\sum_{x\in S}1/x\) diverges, we get all positive rationals. As well as the practical numbers, this works for some other nice sequences including the <a href="https://en.wikipedia.org/wiki/Odious_number">odious</a> and <a href="https://en.wikipedia.org/wiki/Evil_number">evil</a> numbers, the <a href="https://oeis.org/A001013">orders of isomorphism groups of trees</a>, and the <a href="https://oeis.org/A003714">fibbinary numbers</a>, numbers whose binary representation avoids consecutive ones. Because they’re based on binary representations, the doubling property of odious, evil, and fibbinary numbers follows from their definitions; the existence of multiples of other integers in these sequences is less obvious but was more or less already known. Isomorphism groups of trees have orders that are the products of factorials, from which (because 2 is a factorial and \(n!\) is a multiple of \(n\)) both properties follow immediately.</p>

<p>Although these two properties are sufficient for a sequence to form Egyptian fractions for rationals up to its natural limit, they are not necessary. Ron Graham’s PhD dissertation was on the same topic, and showed that the sequence of squares greater than one has the same property. (The sequence of all squares, including one, is a little more complicated: its sums of distinct reciprocals can represent all rationals in the intervals \([0,\pi^2/6-1)\) and \([1,\pi^2/6)\) but can’t cover the gap between these two intervals.) Characterizing which sequences do or do not form representations of this type more generally seems like an interesting question, but one that I don’t have much idea how to attack at this point.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/106989108978976649">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2021-09-24T15:47:00Z</updated>
    <published>2021-09-24T15:47:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2021-09-26T00:06:13Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/139</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/139" rel="alternate" type="text/html"/>
    <title>TR21-139 |  Punctured Large Distance Codes, and Many Reed-Solomon Codes, Achieve List-Decoding Capacity | 

	Venkatesan Guruswami, 

	Jonathan Mosheiff</title>
    <summary>We prove the existence of Reed-Solomon codes of any desired rate $R \in (0,1)$ that are combinatorially list-decodable up to a radius approaching  $1-R$, which is the information-theoretic limit. This is established by starting with the full-length $[q,k]_q$ Reed-Solomon code over a field $\mathbb{F}_q$ that is polynomially larger than the desired dimension $k$, and "puncturing" it by including $k/R$ randomly chosen codeword positions. 
		
Our puncturing result is more general and applies to any code with large minimum distance: we show that a random rate $R$ puncturing of an $\mathbb{F}_q$-linear "mother" code whose relative distance is close enough to $1-1/q$ is list-decodable up to a radius approaching the $q$-ary list-decoding capacity bound $h_q^{-1}(1-R)$. In fact, for large $q$, or under a stronger assumption of low-bias of the mother-code, we prove that the threshold rate for list-decodability with a specific list-size (and more generally, any "local" property) of the random puncturing approaches that of fully random linear codes. Thus, all current (and future) list-decodability bounds shown for random linear codes extend automatically to random puncturings of any low-bias (or large alphabet) code. This can be viewed as a general derandomization result applicable to random linear codes. 
		
To obtain our conclusion about Reed-Solomon codes, we establish some hashing properties of field trace maps that allow us to reduce the list-decodability of RS codes to its associated trace (dual-BCH) code, and then apply our puncturing theorem to the latter. Our approach implies, essentially for free, optimal rate list-recoverability of punctured RS codes as well.</summary>
    <updated>2021-09-24T02:44:57Z</updated>
    <published>2021-09-24T02:44:57Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-09-26T03:20:25Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://tcsplus.wordpress.com/?p=570</id>
    <link href="https://tcsplus.wordpress.com/2021/09/23/tcs-talk-wednesday-september-29-audra-mcmillan-apple/" rel="alternate" type="text/html"/>
    <title>TCS+ talk: Wednesday, September 29 — Audra McMillan, Apple</title>
    <summary>The next TCS+ talk (and first of the semester!) will take place this coming Wednesday, September 29th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC: check your time zone!). We’re excited to have Audra McMillan from Apple speak about “Hiding among the clones: a simple and nearly optimal […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The next TCS+ talk (and first of the semester!) will take place this coming Wednesday, September 29th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC: check your time zone!). We’re excited to have <a href="https://audramarymcmillan.wixsite.com/mysite"><strong>Audra McMillan</strong> </a>from Apple speak about “<em>Hiding among the clones: a simple and nearly optimal analysis of privacy amplification by shuffling</em>” (abstract below).</p>
<p>You can reserve a spot as an individual or a group to join us live by signing up on <a href="https://sites.google.com/view/tcsplus/welcome/next-tcs-talk">the online form</a>. Due to security concerns, <em>registration is required</em> to attend the interactive talk. (The recorded talk will also be posted <a href="https://sites.google.com/view/tcsplus/welcome/past-talks">on our website</a> afterwards, so people who did not sign up will still be able to watch the talk)</p>
<p>As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/view/tcsplus/welcome/suggest-a-talk">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/view/tcsplus/">the website</a>.</p>
<blockquote class="wp-block-quote"><p>Abstract: Differential privacy (DP) is a model of privacy-preserving machine learning that has garnered significant interest in recent years due to its rigorous privacy guarantees. An algorithm differentially private if the output is stable under small changes in the input database. While DP has been adopted in a variety of applications, most applications of DP in industry actually satisfy a stronger notion called local differential privacy. In local differential privacy data subjects perturb their data before it reaches the data analyst. While this requires less trust, it comes a substantial cost to accuracy. Recent work of Erlingsson, Feldman, Mironov, Raghunathan, Talwar, and Thakurta [EFMRTT19] demonstrated that random shuffling amplifies differential privacy guarantees of locally randomized data. Such amplification implies substantially stronger privacy guarantees for systems in which data is contributed anonymously [BEMMRLRKTS17] and has led to significant interest in the shuffle model of privacy [CSUZZ19, EFMRTT19]. In this talk, we will discuss a new result on privacy amplification by shuffling, which achieves the asymptotically optimal dependence in the local privacy parameter. Our result is based on a new proof strategy which is simpler than previous approaches, and extends to a lightly weaker notion known as approximate differential privacy with nearly the same guarantees.</p>
<p>Based on joint work with Vitaly Feldman and Kunal Talwar (<a href="https://arxiv.org/abs/2012.12803">https://arxiv.org/abs/2012.12803</a>).</p></blockquote></div>
    </content>
    <updated>2021-09-23T21:57:43Z</updated>
    <published>2021-09-23T21:57:43Z</published>
    <category term="Announcements"/>
    <author>
      <name>plustcs</name>
    </author>
    <source>
      <id>https://tcsplus.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://tcsplus.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://tcsplus.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://tcsplus.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://tcsplus.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A carbon-free dissemination of ideas across the globe.</subtitle>
      <title>TCS+</title>
      <updated>2021-09-26T03:21:16Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-2703071019388552512</id>
    <link href="http://blog.computationalcomplexity.org/feeds/2703071019388552512/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2021/09/why-conferences.html#comment-form" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/2703071019388552512" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/2703071019388552512" rel="self" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2021/09/why-conferences.html" rel="alternate" type="text/html"/>
    <title>Why Conferences?</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>An <a href="https://arxiv.org/abs/2109.06438">undergrad thesis</a> from North Carolina State University tries to tackle the question as to why computer science has used conferences as its main and most prestigious publication venues. The author Elijah Bouma-Sims gives a synopsis with some interesting follow up conversation in this <a href="https://twitter.com/ElijahBoumaSims/status/1439041100111548419">Twitter thread</a>.</p><p>The upshot is that the conference culture grew organically early in computing and just took hold as the field grew. My personal non-scientific theory is that technology not available to earlier fields, namely jet airplanes, allowed CS to have national and international meetings that researchers could regularly attend. Before that conferences in more established fields like math were held either locally (<a href="http://www.ams.org/meetings/sectional/sectional.html">AMS sectional meetings</a>) or less often (<a href="https://www.mathunion.org/icm/icm-2022">ICM</a> held every four years), traditions that continue to this day.</p><p>Covid has temporarily suspended fully on-site conferences, and new technologies allow us to have virtual meetings. It's still not clear what will be the new normal for conferences. I hope we get to the model where we have more virtual meetings and rarer in-person meetings that people make more of an effort to attend. Conferences focused on networking instead of publications.</p><p>The culture of conference publications has been slowly changing. Many subfields in CS, though not no much theory, have moved to a hybrid model where papers are submitted to a journal and those accepted are invited to be presented at a conference.</p><p>Conferences used to be the first place you would hear about new results but that's no longer the case. Papers posted on <a href="https://arxiv.org/">arXiv</a> get noticed and Google Scholar doesn't distinguished citations to an arXiv paper differently from any other publication venue. </p><p>Now you don't even need a presentation or a paper, just a promise of one. How many of you are excited about linear-size locally testable codes based on a <a href="https://simons.berkeley.edu/events/breakthroughs-locally-testable-codes-constant-rate-distance-and-locality">talk announcement</a> alone?</p></div>
    </content>
    <updated>2021-09-23T12:54:00Z</updated>
    <published>2021-09-23T12:54:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="http://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2021-09-26T02:57:50Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=8202</id>
    <link href="https://windowsontheory.org/2021/09/23/nominate-papers-to-sigact-research-highlights/" rel="alternate" type="text/html"/>
    <title>Nominate papers to SIGACT Research highlights</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">TL;DR: Know of a great recent paper that should be highlighted to the theory community and beyond? Email a nomination to sigact.highlights.nominations@outlook.com by Friday, Oct 22, 2021. The goal of the SIGACT Research Highlights Committee is to help promotetop computer science theory research via identifying results that are ofhigh quality and broad appeal to the … <a class="more-link" href="https://windowsontheory.org/2021/09/23/nominate-papers-to-sigact-research-highlights/">Continue reading <span class="screen-reader-text">Nominate papers to SIGACT Research highlights</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><strong>TL;DR:</strong> Know of a great recent paper that should be highlighted to the theory community and beyond? Email a nomination to <a href="mailto:sigact.highlights.nominations@outlook.com" rel="noreferrer noopener" target="_blank">sigact.highlights.nominations@outlook.com</a> by <strong>Friday, Oct 22, 2021</strong>.</p>



<p>The goal of the<a href="https://www.sigact.org/articles/news.html"> SIGACT Research Highlights Committee </a>is to help promote<br/>top computer science theory research via identifying results that are of<br/>high quality and broad appeal to the general computer science audience.<br/>These results would then be recommended for consideration for the <a href="http://cacm.acm.org/">CACM</a> <em>Research Highlights</em> section as well as other general-audience computer science research outlets.</p>



<p><strong>Nomination and Selection Process:</strong></p>



<p>The committee solicits two types of nominations:</p>



<p>1) <strong>Conference nominations.</strong> Each year, the committee will ask the PC<br/>chairs of theoretical computer science conferences to send a selection<br/>of up to three top papers from these conferences (selected based on both<br/>their technical merit and breadth of interest to non-theory audience)<br/>and forwarding them to the committee for considerations.</p>



<p>2) <strong>Community nominations. </strong>The committee will accept nominations from the members of the community. Each such nomination should summarize the contribution of the nominated paper and also argue why this paper is<br/>suitable for broader outreach. The nomination should be no more than a<br/>page in length and can be submitted at any time by emailing it to<br/><a href="mailto:sigact.highlights.nominations@outlook.com" rel="noreferrer noopener" target="_blank">sigact.highlights.nominations@outlook.com</a>. Self-nominations are<br/>discouraged.</p>



<p>The nomination deadline is <strong>Friday, Oct 22, 2021 </strong>.</p>



<p><strong>Committee:</strong></p>



<p>The SIGACT Research Highlights Committee currently comprises the<br/>following members:</p>



<p>Irit Dinur, Weizmann Institute of Science<br/>Yuval Ishai, Technion<br/>Jelani Nelson, UC Berkeley (chair)<br/>Ronald de Wolf, CWI Amsterdam</p></div>
    </content>
    <updated>2021-09-23T12:41:35Z</updated>
    <published>2021-09-23T12:41:35Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2021-09-26T03:20:50Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/138</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/138" rel="alternate" type="text/html"/>
    <title>TR21-138 |  Iterated Lower Bound Formulas: A Diagonalization-Based Approach to Proof Complexity | 

	Rahul Santhanam, 

	Iddo  Tzameret</title>
    <summary>We propose a diagonalization-based approach to several important questions in proof complexity. We illustrate this approach in the context of the algebraic proof system IPS and in the context of propositional proof systems more generally.

We give an explicit sequence of CNF formulas $\{\phi_n\}$ such that VNP$\neq$VP iff there are no polynomial-size IPS proofs for the formulas $\phi_n$. This provides the first natural equivalence between proof complexity lower bounds and standard algebraic complexity lower bounds. Our proof of this fact uses the implication from IPS lower bounds to algebraic complexity lower bounds due to Grochow and Pitassi together with a diagonalization argument: the formulas $\phi_n$ themselves assert the non-existence of short IPS proofs for formulas encoding VNP$\neq$VP at a different input length. Our result also has meta-mathematical implications: it gives evidence for the difficulty of proving strong lower bounds for IPS within IPS.

More generally, for any strong enough propositional proof system $R$ we propose a new explicit hard candidate, the iterated $R$-lower bound formulas, which inductively asserts the non-existence of short $R$ proofs for formulas encoding this same statement at a different input length. We show that these formulas are unconditionally hard for Resolution following recent results of Atserias and Muller and of Garlik. We further give evidence in favour of this hypothesis for other proof systems.</summary>
    <updated>2021-09-22T23:41:52Z</updated>
    <published>2021-09-22T23:41:52Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-09-26T03:20:25Z</updated>
    </source>
  </entry>

  <entry>
    <id>http://benjamin-recht.github.io/2021/09/21/models-are-wrong/</id>
    <link href="http://benjamin-recht.github.io/2021/09/21/models-are-wrong/" rel="alternate" type="text/html"/>
    <title>All Statistical Models Are Wrong. Are Any Useful?</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Though I singled out a mask study <a href="https://www.argmin.net/2021/09/13/effect-size/">in the last post</a>, I’ve had a growing discomfort with statistical modeling and significance more generally. Statistical models explicitly describe the probability of outcomes of experiments in terms of specific variables of individuals from a population. Such statistical models bring with them a host of assumptions and powers. But when are they appropriate for deducing significance of the outcomes of experiments? Here, I’ll argue that they are almost never appropriate in most settings, and, moreover, they can result in confidence intervals that rarely contain the correct parameters.</p>

<p>Note that in order to sample from some population, we need not assume that the population is <em>itself</em> random. An experimenter can choose to sample one individual from a larger pool at random even when the pool is a deterministic collection. Similarly, the experimenter can randomly assign each member of the pool to a group for experimentation even when the pool is deterministic. We need not build a statistical model of our population in order to study it experimentally.</p>

<p>But the convention in much scientific practice entangles the randomness used in survey and experiment design with the randomness of the natural world. The dominant convention in experimental sciences is to assert the existence of a probability distribution from which all observations in an experiment are samples. That is, most analyses begin with the assumption that the population is itself a stochastic entity whose statistical properties can be accurately modeled. Such probabilistic modeling is immediately problematic. We are forced to confront the notion of probability itself. What does the probability of an event mean? Is a Bayesian or Frequentist viewpoint more correct? What does it mean to sample a natural process?</p>

<p>My perspective on the pitfalls of probabilistic modeling has been heavily influenced by the writings of David Freedman. Freedman advocates for a pragmatic approach to statistical modeling. “<a href="https://www.stat.berkeley.edu/~stark/Preprints/611.pdf">Probability is just a property of a mathematical model intended to describe some features of the natural world. For the model to be useful, it must be shown to be in good correspondence with the system it describes.</a>” This is the less pithy, but more prescriptive version of Box’s famous and tiresome aphorism “All models are wrong, but some are useful.”</p>

<p>Model building and validation requires deep domain knowledge for a task at hand. One of my favorite models is Ohm’s law, which states that the current that flows across a conductive material is proportional to the voltage drop across the resistor. Due to thermal noise, the actual model is</p>

\[\small{
  \text{current} = \text{material constant} \times \text{voltage} + \text{noise}}\]

<p>And the noise is Gaussian white noise. This model has been extensively tested and is a foundation of all circuit design. Remarkably, this simple formula describes complex electronic behavior. Physics is full of amazing examples of statistical models that accurately predict the outcome of experiments to a dozen significant figures.</p>

<p>But in biology, medicine, social science, and economics, our models are much less accurate and less grounded in natural laws. Most of the time, models are selected because they are convenient, not because they are plausible, well motivated from phenomenological principles, or even empirically validated. Freedman built a cottage industry around pointing out how poorly motivated many of the common statistical models are.</p>

<p>A particular example called out by Freedman is the <a href="https://www.jstor.org/stable/27645896">ubiquitous logistic regression model</a>. Freedman observed that in a variety of randomized control trials, experimenters would “correct” the estimates of their randomized controlled trials by “controlling for fixed effects” with logistic regression. Controlling for fixed effects is pernicious jargon that means “set up a regression problem with all of the variables that one thinks make their effect size look too small, and then solve the regression as an attempt to remove the influence of these variables.” It is most common in observational studies, but many insist it is appropriate in the context of randomized controlled trials as well. This convention of correction persists in the present, and I highlighted similar corrections in my last post. Freedman argues that such corrections are misguided, especially in the context of randomized trials.</p>

<p>To understand the motivation for using logistic in the first place, I need to tell you what an odds ratio is. Experiments are often interested in estimating an odds ratio of particular outcomes. The odds of an outcome is the number of individuals with a positive outcome divided by the number of individuals with a negative outcome. If the odds of winning a lottery are one million to one, that means that for every person that wins, one million people lose.</p>

<p>In the context of randomized experiments, let’s suppose that when given a treatment, M out of N individuals will have a favorable outcome, and without treatment only Q out of N will have a positive outcome Then the odds ratio is simply the ratio of the odds of the outcome with and without treatment</p>

\[\small{
\frac{M}{N-M} \cdot \frac{N-Q}{Q}\,.}\]

<p>When the odds ratio is large, we deem a treatment to be highly effective.</p>

<p>Logistic regression posits that individuals have a vector of features $Z$ that influence the odds of the effectiveness of treatment. Specifically, if $Y$ is the indicator of the desired outcome and $X$ is indicator of treatment, the logistic regression model asserts the log of the odds the outcome is a linear function of the treatment and the selected features. Since the model assumes the population is random, we can write the fraction of individuals with a positive outcome as probability. With this identification, the assumption of logistic regression is</p>

\[\small{
\log  \frac{p(Y=1 | X,Z ) }{ 1-p(Y=1 | X,Z) } = \beta X + \gamma^\top Z + \alpha \,.}\]

<p>This model is convenient if we are interested in odds ratios. In the logistic model, no matter what the covariate $Z$, the odds ratio is</p>

\[\small{
\frac{p(Y=1 | X=1,Z ) } {1-p(Y=1| X=1,Z) }  \cdot \frac{1-p(Y=1 | X=0, Z)}{p(Y=1 | X=0, Z)} = e^\beta\,.}\]

<p>Hence, if we can estimate beta, we can estimate the odds ratio. And if we can estimate the variance of beta, we can compute confidence intervals over our odds ratio estimates.</p>

<p>But all of this assumes that the model is correct! If the logistic model is not correct, then our confidence intervals are meaningless. Or at least, they are not confidence intervals around any true notion of odds ratios.</p>

<p>It’s almost always reasonable to be suspicious of this logistic model. It is first asserting that the odds ratio is a constant for a fixed covariate $Z$. That is, all subjects experience the same proportional effect of treatment. Even less realistically, the model asserts that the outcome is positive for an individual $i$ with treatment value $X_i$ and covariate value $Z_i$ if</p>

\[\small{
  U_i  \leq \alpha + \beta X_i + \gamma^\top Z_i\,,}\]

<p>where $U_i$ is a random variable sampled from the logistic distribution. The model assumes the $U_i$ are independent of the treatment and the covariates, the $U_i$ are independent across all of the individuals, and the $U_i$ have a common logistic distribution. The only thing that differs between treatment and control is the value of the threshold on the left hand side. These are a lot of assumptions, and they are seldom verified or tested in papers where logistic regression is applied.</p>

<p>The question remains: does this matter? Do these modeling assumptions actually affect our inferences about effect size? Freedman provides an elegant argument demonstrating that logistic regression always overestimates the true odds ratio, and sometimes can do so quite poorly. He also shows that simply computing a plugin estimator of the odds ratio with no covariate adjustment at all is consistent in randomized controlled trials. That is, there is no need to adjust for covariates in randomized controlled trials if you want an accurate estimate of the odds ratio. Furthermore, covariate adjustments can lead to significant overestimation of the treatment’s effect size.</p>

<p>Rather than going through Freedman’s theoretical argument, it’s a bit more evocative to give an example. The following is gleaned from a helpful discussion with Joel Middleton. Suppose you sample 10000 children from a larger population where each child in the population has an equal chance of liking and disliking vegetables. We propose a treatment of bribing kids with a cookie to eat their veggies, and randomly assign this treatment to half of the subjects. Left untreated, veggie haters have a 20% probability of finishing their veggies, but veggie lovers have an 80% probability of eating their greens. When bribed with a cookie, veggie haters and veggie lovers have 25% and 85% of eating their vegetables, respectively.</p>

<p>An average child in the study has a probability of 50% of eating their veggies if in control and 55% if in treatment. The log odds ratio is thus</p>

\[\small{
  \log \frac{.55}{1−.55}−\log\frac{.5}{1−.5} \approx 0.2\,.}\]

<p>Now, when you instead run logistic regression, the coefficient of the treatment variable is larger than 0.2. Indeed, <a href="https://nbviewer.jupyter.org/url/argmin.net/code/logistic_logodds_example.ipynb">when I try this in python</a>, running 1000 synthetic experiments, I find that the median point estimate is 0.32, which is, as promised, larger than the true log odds. Even more worrisome is the 95% confidence interval contains 0.2 only 38% of the time. Clearly, the confidence intervals are not accurate when the model is wrong.</p>

<p>When the true effect size is large, this discrepancy between the logistic regression estimate and the true log odds might not be that big a deal: your error bars are wrong, but the effect size is estimated in the correct direction. But the results of such logistic regression analyzes are regularly quoted as estimates of odds ratios (For example, look at any  observational study of vaccine effectiveness). The precision of these estimates is unfortunately lacking and misleading.</p>

<p>Even if the model <em>was</em> true, the same argument shows that the coefficient of the treatment variable overestimates the log-odds. This is demonstrated in the <a href="https://nbviewer.jupyter.org/url/argmin.net/code/logistic_logodds_example.ipynb">second example in the python notebook</a>. Even when the model is true, the coefficient of the treatment variable is an overestimate of the true log odds. If the model was true, one could at least say they had constructed a reasonable estimate of the change in odds for an individual under treatment. But if the model is wrong, there’s nothing we can say at all other than we have overestimated the effect size and our error bars might not contain the true odds with any certainty.</p>

<p>So what is the remedy here? The thing is, we already know the answer: if we randomized the assignment, we can estimate log odds by counting the number of positive outcomes under treatment and control, and then just plugging these values into the odds ratio. If you do this, you find an estimate whose median is precisely equal to the true log odds. No covariate adjustment is required.</p>

<p>This is merely one example showing why it is critical to decouple the randomness used to probe a system from the randomness inherent in its system itself. Statistical models are not necessary for statistical inference, but randomness itself is amazingly… let’s say… <em>useful</em> for understanding natural phenomena. I will spend the next few blogs reminding myself and you faithful blog readers that proper experiments, machine learning predictions, and statistical summarizations can all be designed without statistical models of populations. Perhaps the mathematical formalizations of randomized algorithms can suggest paths to reform conventional experimental formalism.</p></div>
    </summary>
    <updated>2021-09-21T00:00:00Z</updated>
    <published>2021-09-21T00:00:00Z</published>
    <source>
      <id>http://benjamin-recht.github.io/</id>
      <author>
        <name>Ben Recht</name>
      </author>
      <link href="http://benjamin-recht.github.io/" rel="alternate" type="text/html"/>
      <link href="http://benjamin-recht.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Musings on systems, information, learning, and optimization.</subtitle>
      <title>arg min blog</title>
      <updated>2021-09-25T23:36:03Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://decentralizedthoughts.github.io/2021-09-20-optimal-communication-complexity-of-authenticated-byzantine-agreement/</id>
    <link href="https://decentralizedthoughts.github.io/2021-09-20-optimal-communication-complexity-of-authenticated-byzantine-agreement/" rel="alternate" type="text/html"/>
    <title>Optimal Communication Complexity of Authenticated Byzantine Agreement</title>
    <summary>Communication complexity of Byzantine Agreement (BA) has been studied for decades. Dolev and Reischuk showed that quadratic communication is necessary for BA with perfect security, i.e., without error. Berman, Garay, and Perry showed that this lower bound is tight for the unauthenticated setting (without signatures) with $f &lt; n/3$. However,...</summary>
    <updated>2021-09-20T19:28:00Z</updated>
    <published>2021-09-20T19:28:00Z</published>
    <source>
      <id>https://decentralizedthoughts.github.io</id>
      <author>
        <name>Decentralized Thoughts</name>
      </author>
      <link href="https://decentralizedthoughts.github.io" rel="alternate" type="text/html"/>
      <link href="https://decentralizedthoughts.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Decentralized thoughts about decentralization</subtitle>
      <title>Decentralized Thoughts</title>
      <updated>2021-09-25T23:36:37Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://decentralizedthoughts.github.io/2021-09-20-information-theoretic-hotstuff-it-hs-part-one/</id>
    <link href="https://decentralizedthoughts.github.io/2021-09-20-information-theoretic-hotstuff-it-hs-part-one/" rel="alternate" type="text/html"/>
    <title>Information Theoretic HotStuff (IT-HS): Part One</title>
    <summary>This post is the first of two on Information Theoretic HotStuff (IT-HS). Information Theoretic HotStuff is a Byzantine Consensus protocol in the partially synchronous model. It replaces all of HotStuff’s cryptographic signatures with simple information theoretic message passing techniques over authenticated channels. Information theoretic protocols are often easy to reason...</summary>
    <updated>2021-09-20T12:07:00Z</updated>
    <published>2021-09-20T12:07:00Z</published>
    <source>
      <id>https://decentralizedthoughts.github.io</id>
      <author>
        <name>Decentralized Thoughts</name>
      </author>
      <link href="https://decentralizedthoughts.github.io" rel="alternate" type="text/html"/>
      <link href="https://decentralizedthoughts.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Decentralized thoughts about decentralization</subtitle>
      <title>Decentralized Thoughts</title>
      <updated>2021-09-25T23:36:37Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-8953224762580714055</id>
    <link href="http://blog.computationalcomplexity.org/feeds/8953224762580714055/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2021/09/the-new-jeopardy-champion-is-a-cs-grad.html#comment-form" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/8953224762580714055" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/8953224762580714055" rel="self" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2021/09/the-new-jeopardy-champion-is-a-cs-grad.html" rel="alternate" type="text/html"/>
    <title>The New Jeopardy Champion is a `A CS grad student from a school in New Haven'</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p> As of Sept 17, Matt Amodio has won 23 straight games in a row on Jeopardy and won over $800,000 in regular play. The following website is not quite up to date, but its close: <a href="https://www.jeopardy.com/contestant-zone/hall-of-fame">here</a>. Of course, that website will change. </p><p>1) They refer to him as <i>A CS grad student from a school in New Haven</i>. My first thought was <i>probably</i> <i>Yale, but whatever it is, they should just say it. </i>I looked it up and it is Yale. So why aren't they just saying <i>A CS grad student from Yale?  </i>If someone works for <i>an airline company</i> they do not tell you which airline- prob to avoid giving that airline free publicity. But I would think a school is different. And I remember (perhaps incorrectly) that they DO say what school someone teaches at or is a student at. </p><p>(ADDED LATER: a colleague of mine who was on Jeop (he lost his only game) tells me that YES, you re NOT ALLOWED to say the company you work for. He was from <i>Riverdale Park, MD </i>which might make some people think there is a <i>Univ of MD at Riverdale Park</i> . He also told me that when he was on the show the following happened:  <i>On One of the shows of the game before I  played, Alex was curious which LA area restaurant somebody worked at (to see if he had eaten there--- he hadn't), and sure enough, they edited the name of the restaurant out.)</i></p><p>2) Longest streak: Ken Jennings: 74. Also most money in reg play: roughly 2.5 Mill</p><p>    2nd longest: James Holzhauer: 32. Also  2nd most money in reg play: roughly 2.4 Mill</p><p>    3rd longest: Matt Amodio: 23. Also  3rd most money in reg play: roughly 0.8 Mill</p><p>3) I do not think Matt will move into second place on any of these categories. He bets big on the daily doubles and it has paid off but either (a) he will miss and it will lead to a loss, or (b) he will just not get the daily double and be against a very good opponent. Item (b) happened to James H- and the person who beat him did have a good enough win streak to be in the Tournament of Champions. I wonder if they try to stop a long streak by picking really good opponents. I also wonder if they can even tell who will be a really good opponent. </p><p>4) Matt has played in front of (or will- counting tomorrow) six hosts: Robin Roberts, LeVar Burton, David Faber, Joe Buck, Mike Richards, and Mayim Bialik. Six is a record which I suspect won't be broken, except possibly by Matt himself if he also plays in front of Ken Jennings (the rest of 2021 will be Mayim B and Ken J as hosts, see <a href="https://www.npr.org/2021/09/16/1037930905/mayim-bialik-ken-jennings-host-jeopardy">here</a>.</p><p>5) Matt works in AI. When he gets his PhD and is on the job market will his Jeopardy success help him, hurt him, or neither?  </p><p>6) James H and Matt A are both very good at calculating how much to bet. I think Ken J is not quite as good but still good. Generally the players on Jeop are not that good at that aspect. I had the chance to ask some a champions (not any of those three) why that was and she said that most people get into because of the trivia-aspect, not the betting aspect. I wonder if just as players now study lots of facts to prep, they will also learn how to bet better. </p><p>7) Ken J as host is a bit odd in that, if he says (as Alex T did sometimes) <i>That category looks hard </i>I won't believe him. I also have this suspicion that when a contestant gets something wrong Ken might be thinking <i>what a moron; </i>however, (a) by all accounts Ken is a nice guy, and (b)  I might be projecting. </p></div>
    </content>
    <updated>2021-09-20T00:35:00Z</updated>
    <published>2021-09-20T00:35:00Z</published>
    <author>
      <name>gasarch</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03004932739846901628</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="http://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2021-09-26T02:57:50Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/09/19/faculty-at-ben-gurion-university-apply-by-february-1-2022/</id>
    <link href="https://cstheory-jobs.org/2021/09/19/faculty-at-ben-gurion-university-apply-by-february-1-2022/" rel="alternate" type="text/html"/>
    <title>Postdoc at Ben-Gurion University (apply by February 1, 2022)</title>
    <summary>I (Dean Doron) invite applicants for a postdoctoral position at Ben-Gurion University’s Computer Science department. Candidates with a strong background in TCS whose research interests include pseudorandomness, complexity, coding theory, or related combinatorial constructions, are welcome to apply. Start date is flexible. To apply, please email me your CV and 2-3 representative papers. Website: https://www.cs.bgu.ac.il/~deand […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I (Dean Doron) invite applicants for a postdoctoral position at Ben-Gurion University’s Computer Science department.<br/>
Candidates with a strong background in TCS whose research interests include pseudorandomness, complexity, coding theory, or related combinatorial constructions, are welcome to apply.<br/>
Start date is flexible. To apply, please email me your CV and 2-3 representative papers.</p>
<p>Website: <a href="https://www.cs.bgu.ac.il/~deand">https://www.cs.bgu.ac.il/~deand</a><br/>
Email: deand@bgu.ac.il</p></div>
    </content>
    <updated>2021-09-19T09:53:31Z</updated>
    <published>2021-09-19T09:53:31Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-09-26T03:20:37Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://rjlipton.wpcomstaging.com/?p=19128</id>
    <link href="https://rjlipton.wpcomstaging.com/2021/09/17/happy-unbirthday-ken/" rel="alternate" type="text/html"/>
    <title>Happy UnBirthday Ken</title>
    <summary>Mad Hatter: Now, statistics prove, prove that you’ve one birthday. March Hare: Imagine, just one birthday every year. Mad Hatter: Ah, but there are three hundred and sixty four unbirthdays! March Hare: Precisely why we’re gathered here to cheer. Ken Regan just had his birthday the other day. Today is another unbirthday. Please join me […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><em>Mad Hatter: Now, statistics prove, prove that you’ve one birthday.<br/>
March Hare: Imagine, just one birthday every year.<br/>
Mad Hatter: Ah, but there are three hundred and sixty four unbirthdays!<br/>
March Hare: Precisely why we’re gathered here to cheer.</em></p>
<p>
Ken Regan just had his birthday the other day. Today is another <a href="https://en.wikipedia.org/wiki/Unbirthday">unbirthday</a>. </p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2021/09/17/happy-unbirthday-ken/kr/" rel="attachment wp-att-19131"><img alt="" class="aligncenter size-medium wp-image-19131" height="300" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/09/kr.jpg?resize=205%2C300&amp;ssl=1" width="205"/></a></p>
<p>
Please join me in wishing Ken many more happy birthdays as well as many many more unbirthdays.</p>
<p>
</p><p><b> Ken is a Mathematician </b></p>
<p/><p>
Ken is of course a co-author of this blog. We try to cover computer science and mathematics, but we are open to other areas. Ken started his career in Mathematics; he obtained a PhD in math from Oxford University in 1986. It was under Dominic Welsh and was tilted: <i>On the separation of complexity classes</i>. Welsh’s family tree is <a href="https://users.monash.edu.au/~davidwo/files/Welsh-FamilyTree.pdf">here</a>. </p>
<p>
</p><p><b> Ken is a Programmer </b></p>
<p/><p>
Ken is of course famous for being one of the world’s top chess cheating detectors. Recall to cheat at chess is to use a computer program to make your moves in a game against a human opponent. This is strictly illegal. </p>
<p>
Ken was featured on the cover in <a href="https://cse.buffalo.edu/~regan/personal/JuneCLarticleKWR.pdf">chess review</a>. His work gets critic review <a href="https://kar.kent.ac.uk/44719/">here</a> by David Barnes and Julio Hernandez-Castro in the 2015 article <i>On the limits of engine analysis for cheating detection in chess</i> in the journal Computers and Security.</p>
<p>
</p><p><b> Ken is Unique </b></p>
<p/><p>
Ken is special in many ways. He is smart, he is a wonderful partner, and he is a great friend. I would claim that he is one of the few people that have the following three properties:</p>
<ol>
<li> He is an international master in chess of rating <img alt="{2372}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2372%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>;
</li><li> He is a strong researcher in complexity theory;
</li><li> He is a terrific programmer.
</li></ol>
<p>
The last I would claim is pretty remarkable. There are many strong chess players, there are many of us working in complexity theory. But few have written as much production quality code as Ken has. For his work on chess cheating he has had to write thousands of lines of code. This code must run fast, and be correct. The latter, correctness, is really important. This since his work on detecting cheating has led players to be suspended from chess for years. It also has helped protect players who did not cheat, even though many thought they had. </p>
<p>
</p><p><b> Open Problems </b></p>
<p/><p>
Again I wish him a wonderful unbirthday day.</p>
<p/></div>
    </content>
    <updated>2021-09-17T13:45:15Z</updated>
    <published>2021-09-17T13:45:15Z</published>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wpcomstaging.com</id>
      <logo>https://s0.wp.com/i/webclip.png</logo>
      <link href="https://rjlipton.wpcomstaging.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wpcomstaging.com" rel="alternate" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel's Lost Letter and P=NP</title>
      <updated>2021-09-26T03:20:33Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-27705661.post-5589824032420181390</id>
    <link href="http://processalgebra.blogspot.com/feeds/5589824032420181390/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=27705661&amp;postID=5589824032420181390" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/5589824032420181390" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/5589824032420181390" rel="self" type="application/atom+xml"/>
    <link href="http://processalgebra.blogspot.com/2021/09/phd-scholarship-in-data-science-for.html" rel="alternate" type="text/html"/>
    <title>PhD scholarship in Data Science for sustainability at Reykjavik University</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p style="text-align: center;"><b>Department of Computer Science, Reykjavik University </b></p><p style="text-align: center;"><b>PhD scholarship in Data Science for sustainability by predicting food consumption to reduce food waste </b></p><p>The Department of Computer Science at Reykjavík University is looking for a PhD student to build, apply and evaluate a global model that predicts future food consumption by geographic area. The goal of the project is twofold:      Reduce food waste in restaurants and grocery stores by using global machine learning algorithms.     Understand food consumption trends in restaurants and grocery stores by analyzing the global model’s input data and their results.  The ideal candidate should possess data science expertise, be passionate about sustainability and enthusiastic about research.  The project is a collaboration with <a href="https://greenbytes.is" target="_blank">GreenBytes</a> and will be carried out in Reykjavik, Iceland. </p><p>See <a href="https://jobs.50skills.com/ru/en/10068">https://jobs.50skills.com/ru/en/10068</a> for full details and for information on how to apply.</p></div>
    </content>
    <updated>2021-09-16T12:23:00Z</updated>
    <published>2021-09-16T12:23:00Z</published>
    <author>
      <name>Luca Aceto</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/01092671728833265127</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-27705661</id>
      <author>
        <name>Luca Aceto</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/01092671728833265127</uri>
      </author>
      <link href="http://processalgebra.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://processalgebra.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Papers I find interesting---mostly, but not solely, in Process Algebra---, and some fun stuff in Mathematics and Computer Science at large and on general issues related to research, teaching and academic life.</subtitle>
      <title>Process Algebra Diary</title>
      <updated>2021-09-16T12:26:30Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/09/16/faculty-equivalent-of-tenure-track-at-university-of-sydney-apply-by-november-30-2021/</id>
    <link href="https://cstheory-jobs.org/2021/09/16/faculty-equivalent-of-tenure-track-at-university-of-sydney-apply-by-november-30-2021/" rel="alternate" type="text/html"/>
    <title>Faculty (equivalent of tenure-track) at University of Sydney (apply by November 30, 2021)</title>
    <summary>The School of Computer Science at the University of Sydney (Australia) is seeking applications for several academic positions at all levels. Successful applicants will have an excellent research record and be able to teach in a range of courses. Website: https://usyd.wd3.myworkdayjobs.com/en-US/USYD_EXTERNAL_CAREER_SITE/job/Camperdown-Campus/Multiple-Continuing-Academic-Positions–School-of-Computer-Science_0085639 Email: hr.recruitmentcampaign@sydney.edu.au</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The School of Computer Science at the University of Sydney (Australia) is seeking applications for several academic positions at all levels. Successful applicants will have an excellent research record and be able to teach in a range of courses.</p>
<p>Website: <a href="https://usyd.wd3.myworkdayjobs.com/en-US/USYD_EXTERNAL_CAREER_SITE/job/Camperdown-Campus/Multiple-Continuing-Academic-Positions--School-of-Computer-Science_0085639">https://usyd.wd3.myworkdayjobs.com/en-US/USYD_EXTERNAL_CAREER_SITE/job/Camperdown-Campus/Multiple-Continuing-Academic-Positions–School-of-Computer-Science_0085639</a><br/>
Email: hr.recruitmentcampaign@sydney.edu.au</p></div>
    </content>
    <updated>2021-09-16T04:01:14Z</updated>
    <published>2021-09-16T04:01:14Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-09-26T03:20:37Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=5843</id>
    <link href="https://www.scottaaronson.com/blog/?p=5843" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=5843#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=5843" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">My ACM TechTalk on quantum supremadvantage</title>
    <summary xml:lang="en-US">This Erev Yom Kippur, I wish to repent for not putting enough quantum computing content on this blog. Of course, repentance is meaningless unless accompanied by genuine reform. That being the case, please enjoy the YouTube video of my ACM TechTalk from last week about quantum supremacy—although, as you’ll see if you watch the thing, […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>This Erev Yom Kippur, I wish to repent for not putting enough quantum computing content on this blog.  Of course, repentance is meaningless unless accompanied by genuine reform.  That being the case, please enjoy the <a href="https://www.youtube.com/watch?v=QnLmGfNKCLU">YouTube video of my ACM TechTalk from last week about quantum supremacy</a>—although, as you’ll see if you watch the thing, I oscillate between quantum supremacy and other terms like “quantum advantage” and even “quantum supremadvantage.”  This represents the first time ever that I got pushback about a talk before I’d delivered it for political reasons—the social-justice people, it turns out, are <em>actually serious</em> about wanting to <a href="https://www.scottaaronson.com/blog/?p=4450">ban the term “quantum supremacy”</a>—but my desire to point out all the difficulties with their proposal competed with my desire not to let that issue overshadow my talk.</p>



<p>And there’s plenty to talk about!  While regular <em>Shtetl-Optimized</em> readers will have already heard (or read) most of what I say, I make some new comments, including about the <a href="https://arxiv.org/abs/2109.03494">new paper from last week</a>, the night before my talk (!), by the USTC group in China, where they report a quantum supremacy experiment based on random circuit sampling with a superconducting chip, this time with a record-setting 60 qubits and 24 layers of gates.  On the other hand, I also stress how increasing the circuit fidelity has become a <em>much</em> more urgent issue than further increasing the number of qubits (or in the case of BosonSampling, the number of photons), if our goal is for these experiments to remain a couple steps ahead of classical spoofing algorithms.</p>



<p>Anyway, I hope you enjoy my lovingly handcrafted visuals.  Over the course of this pandemic, I’ve become a full convert to writing out my talks with a stylus pen rather than PowerPointing them—not only is it faster for me, not only does it allow for continuous scrolling rather than arbitrary divisions into slides, but it enforces simplicity and concision in ways they <em>should</em> be enforced.</p>



<p>While there was only time for me to field a few questions at the end of the talk, I later supplied <a href="https://on.acm.org/t/quantum-computational-supremacy/2106/2?u=acm-learning">written answers to 52 questions (!!) that I hadn’t gotten to</a>.  If <em>you</em> have a question, please check to see if it’s already there, and otherwise ask away in the comments!</p>



<p>Thanks so much to Yan Timanovsky for inviting and organizing this talk, and to whurley for hosting it.</p></div>
    </content>
    <updated>2021-09-15T23:12:40Z</updated>
    <published>2021-09-15T23:12:40Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Complexity"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Quantum"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="http://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2021-09-24T22:05:29Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2021/09/15/linkage</id>
    <link href="https://11011110.github.io/blog/2021/09/15/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>Does anyone but me find it odd that car tire sizes are measured in millimeters for width, inches for inner radius, and a dimensionless number expressed as a percentage for (difference between inner and outer radius)/width (\(\mathbb{M}\))? Imagine the fun if we tried to do solid geometry this way.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><ul>
  <li>
    <p>Does anyone but me find it odd that <a href="https://en.wikipedia.org/wiki/Tire_code">car tire sizes</a> are measured in millimeters for width, inches for inner radius, and a dimensionless number expressed as a percentage for (difference between inner and outer radius)/width <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/106864082094813780">\(\mathbb{M}\)</a>)?</span> Imagine the fun if we tried to do solid geometry this way.</p>
  </li>
  <li>
    <p><a href="https://aas.org/press/aas-journals-open-access">American Astronomical Society switches to open source for all its journals</a> (<a href="https://mathstodon.xyz/@11011110/106871073920675993">\(\mathbb{M}\)</a>, <a href="https://news.ycombinator.com/item?id=28379917">via</a>). The fine print is a <a href="https://journals.aas.org/oa/#charge_comparison">hefty &gt;$1000-paper publication charge</a>
with only a vague hope of waivers for some journals and not even that for one of them. Publication is not without cost, but comparing this with the <a href="https://www.dagstuhl.de/en/publications/lipics/processing-charge/">actual-cost 
€60/paper charges of LIPIcs</a> suggests that there’s a lot of profit/overhead built into the AAS fees.</p>
  </li>
  <li>
    <p>You may have heard that <a href="https://www.math3ma.com/blog/fibonacci-sequence">Fibonacci numbers form a meet-semilattice under divisibility, and that the map from \(n\) to \(F_n\) is a meet-semilattice homomorphism</a> (<a href="https://mathstodon.xyz/@11011110/106880573772645015">\(\mathbb{M}\)</a>). But did you know they’re actually a lattice, almost the same as the positive integer divisibility lattice (an infinite-dimensional grid with a dimension per prime), but missing one element at the index \(2\) (because \(F_2=F_1=1\))? Unfortunately, because of the missing grid element, \(F\) is not a lattice homomorphism.</p>

    <p style="text-align: center;"><img alt="Divisibility lattice of Fibonacci numbers" src="https://11011110.github.io/blog/assets/2021/Fibonacci-divisibility.svg"/></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2109.00022">Point sets with no four collinear and no large visible island</a> (<a href="https://mathstodon.xyz/@11011110/106883568827068806">\(\mathbb{M}\)</a>). If you project a 
\(3\times 3\times \cdots\times 3\) grid linearly into the plane, for a generic projection, then there are no four points in a row. But if you choose the projection carefully, you can get another property: every convex subset of the plane that hits more than a constant number of points includes at least one three-point line. New preprint by UCSD undergrad Sophie Leuchtner and Andrew Suk.</p>
  </li>
  <li>
    <p><a href="https://britishorigami.info/lister/egypt.php">Possibly the earliest known example of folding</a> (<a href="https://mathstodon.xyz/@11011110/106889063469591427">\(\mathbb{M}\)</a>): an Egyptian map from over 3000 years ago. The link unfortunately lacks pictures but they can be found on <a href="https://en.wikipedia.org/wiki/Turin_Papyrus_Map">the Wikipedia article on the same map</a>, which however suggests an alternative hypothesis than folding for its markings.</p>
  </li>
  <li>
    <p><a href="https://retractionwatch.com/2021/09/07/authors-object-after-springer-nature-journal-cedes-to-publisher-frontiers-demand-for-retraction/">Springer journal <em>Scientometrics</em> retracts a journal paper on predatory publishing after predatory publisher Frontiers objects to its use of a list of predatory publishers that lists Frontiers as a predatory publisher</a> (<a href="https://mathstodon.xyz/@11011110/106891442309422502">\(\mathbb{M}\)</a>). A followup comment connects the dots: “Notably, Springer owns a stake in Frontiers, although they rarely mention this publicly”. Editors of the Springer journal call the retraction misconduct and consider resigning from its board in protest.</p>
  </li>
  <li>
    <p><a href="https://www.getrevue.co/profile/shift-happens/issues/moire-no-more-688319">Removing halftoning artifacts from images by FFT+masking</a> (<a href="https://mathstodon.xyz/@11011110/106900166239796915">\(\mathbb{M}\)</a>, <a href="https://www.metafilter.com/192541/pure-old-fashioned-math-and-science">via</a>). A nice illustration of how the right piece of mathematics can seem like “some sort of witchcraft that should not be possible”. The original uses a piece of software I haven’t used called <a href="https://imagej.net/software/fiji/">Fiji</a>, but there’s also <a href="http://ft.rognemedia.no/">the “Pattern Suppressor” Photoshop plugin for similar manipulations</a>.</p>
  </li>
  <li>
    <p><a href="https://www.wired.com/story/one-womans-mission-to-rewrite-nazi-history-wikipedia/">Ksenia Coffman’s work stomping out Nazi-glorification on Wikipedia</a> (<a href="https://mathstodon.xyz/@11011110/106905799003035925">\(\mathbb{M}\)</a>, <a href="https://www.metafilter.com/192594/One-Womans-Mission-to-Rewrite-Nazi-History-on-Wikipedia">see also</a>).</p>
  </li>
  <li>
    <p><a href="https://www.quantamagazine.org/new-math-book-rescues-landmark-topology-proof-20210909/">Quanta has a new article</a> (<a href="https://mathstodon.xyz/@11011110/106911678317985799">\(\mathbb{M}\)</a>, <a href="https://mathoverflow.net/questions/87674/independent-evidence-for-the-classification-of-topological-4-manifolds">see also</a>) on the book <em>The Disc Embedding Theorem</em> by Behrens, Kalmar, Kim, Powell, and Ray, attempting to clarify Freedman’s early-1980s 4-manifold classification, which many found insufficiently rigorous. But it’s not the only book on this; there’s also Calegari’s <a href="https://math.uchicago.edu/~dannyc/books/4dpoincare/4dpoincare.html"><em>The 4-Dimensional Poincaré Conjecture</em></a>, and Freedman’s <em>Topology of 4-manifolds</em> (with Frank Quinn, 1990). Third time’s the charm?</p>
  </li>
  <li>
    <p><a href="https://thereader.mitpress.mit.edu/perils-of-publication-and-citation-bias/">Citation bias</a> (<a href="https://mathstodon.xyz/@11011110/106917424161901510">\(\mathbb{M}\)</a>): how the tendency to cite certain types of results over others (e.g. positive more than negative) and academic games of telephone can herd the research community towards a distorted view of what the scientific record has actually established.</p>
  </li>
  <li>
    <p>The annual Graph Drawing symposium really loves hybrid formats (<a href="https://mathstodon.xyz/@11011110/106921800901735764">\(\mathbb{M}\)</a>). <a href="https://algo.inf.uni-tuebingen.de/gd2021/">This year’s symposium</a> will be held  this Wednesday through Friday as a hybrid of a small in-person meeting in Tübingen and online for those like me still not traveling. And, as in past years, the proceedings is a hybrid of a Springer LNCS volume (not yet out) and <a href="https://arxiv.org/abs/2109.04863">an arXiv copy, newly up at arXiv:2109.04863</a>. If anything the arXiv version is better: more timely, with appendices and color both allowed.</p>
  </li>
  <li>
    <p><a href="https://www.bridgetownrb.com/future/rip-jekyll/">Death of the Jekyll static site generator proclaimed</a> (<a href="https://mathstodon.xyz/@11011110/106928704495143550">\(\mathbb{M}\)</a>, <a href="https://news.ycombinator.com/item?id=28514029">via</a>), because of some open source politics I don’t understand. Meanwhile for those of us using it as a static site generator and github-pages blog springboard, Jekyll still largely just works as it always has without much need for development. Indeed, a big reason for the lack of momentum for going from Jekyll 3 to 4 is that it was an unnecessary incompatible update that would have broken too much stuff.</p>
  </li>
  <li>
    <p><a href="https://www.thomasclausen.net/en/but-this-is-a-weird-bibliography/">Why would someone plagiarize the bibliography of their journal paper</a> (<a href="https://mathstodon.xyz/@11011110/106934028229929325">\(\mathbb{M}\)</a>), by copying someone else’s bibliography on a totally unrelated topic, in an inconsistent format to the references in the main text of the paper (no doubt copied from somewhere else)? Thomas Clausen looks more deeply than necessary at the garbage pile that is predatory publishing, triggered by an odd citation alert.</p>
  </li>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/Existential_theory_of_the_reals">\(\exists\mathbb{R}\), the problem of testing the existence of solutions to polynomial real equations</a> is only a little harder than \(\mathsf{NP}\), but \(\exists\mathbb{Z}\) is undecidable (Matiyasevich). Today I learned from <a href="https://arxiv.org/abs/2107.11663">Marcus Schaefer’s GD talk</a> that <a href="https://en.wikipedia.org/wiki/RAC_drawing">right-angle-crossing graph drawing</a> is \(\exists\mathbb{R}\)-complete but that requiring in addition that the vertices have integer coordinates makes it \(\exists\mathbb{Q}\)-complete (<a href="https://mathstodon.xyz/@11011110/106936348796765483">\(\mathbb{M}\)</a>). That means we don’t know whether it’s decidable!</p>
  </li>
</ul></div>
    </content>
    <updated>2021-09-15T14:57:00Z</updated>
    <published>2021-09-15T14:57:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2021-09-26T00:06:13Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=5837</id>
    <link href="https://www.scottaaronson.com/blog/?p=5837" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=5837#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=5837" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Open Problems Related to Quantum Query Complexity</title>
    <summary xml:lang="en-US">Way back in 2005, I posed Ten Semi-Grand Challenges for Quantum Computing Theory, on at least half of which I’d say there’s been dramatic progress in the 16 years since (most of the challenges were open-ended, so that it’s unclear when to count them as “solved”). I posed more open quantum complexity problems in 2010, […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>Way back in 2005, I posed <a href="https://www.scottaaronson.com/writings/qchallenge.html">Ten Semi-Grand Challenges for Quantum Computing Theory</a>, on at least half of which I’d say there’s been dramatic progress in the 16 years since (most of the challenges were open-ended, so that it’s unclear when to count them as “solved”).  I posed <a href="https://www.scottaaronson.com/blog/?p=471">more open quantum complexity problems</a> in 2010, and some <a href="https://www.scottaaronson.com/blog/?p=663">classical complexity problems</a> in 2011.  In the latter cases, I’d say there’s been dramatic progress on about a third of the problems.  I won’t go through the problems one by one, but feel free to ask in the comments about any that interest you.</p>



<p>Shall I push my luck as a problem-poser?  Shall or shall not, I have.</p>



<p>My impetus, this time around, was a kind invitation by Travis Humble, the editor-in-chief of the new <em><a href="https://dl.acm.org/journal/tqc">ACM Transactions on Quantum Computing</a></em>, to contribute a perspective piece to that journal on the occasion of my <a href="https://www.scottaaronson.com/blog/?p=5448">ACM Prize</a>.  I agreed—but only on the condition that, rather than ponderously pontificate about the direction of the field, I could simply discuss a bunch of open problems that I wanted to see solved.  The result is below.  It’s coming soon to an arXiv near you, but <em>Shtetl-Optimized</em> readers get it first.</p>



<blockquote class="wp-block-quote"><p><strong><a href="https://www.scottaaronson.com/papers/open.pdf">Open Problems Related to Quantum Query Complexity</a></strong>  (11 pages, PDF)</p><p>by Scott Aaronson</p><p><em>Abstract:</em> I offer a case that quantum query complexity still has loads of enticing and fundamental open problems—from relativized QMA versus QCMA and BQP versus IP, to time/space tradeoffs for collision and element distinctness, to polynomial degree versus quantum query complexity for partial functions, to the Unitary Synthesis Problem and more.</p></blockquote>



<p>Some of the problems on my new hit-list are ones that I and others have flogged for years or even decades, but others, as far as I know, appear here for the first time.  If your favorite quantum query complexity open problem, or a problem I’ve discussed in the past, is missing, that doesn’t mean that it’s been solved or is no longer interesting—it might mean I simply ran out of time or energy before I got to it.</p>



<p>Enjoy!  And tell me what I missed or got wrong or has a trivial solution that I overlooked.</p></div>
    </content>
    <updated>2021-09-15T04:09:31Z</updated>
    <published>2021-09-15T04:09:31Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Complexity"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Quantum"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="http://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2021-09-24T22:05:29Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/137</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/137" rel="alternate" type="text/html"/>
    <title>TR21-137 |  Affine extractors and AC0-Parity | 

	Xuangui Huang, 

	Peter Ivanov, 

	Emanuele Viola</title>
    <summary>We study a simple and general template for constructing affine extractors by composing a linear transformation with resilient functions. Using this we show that good affine extractors can be computed by non-explicit circuits of various types, including AC0-Xor circuits: AC0 circuits with a layer of parity gates at the input. We also show that one-sided extractor can be computed by small DNF-Xor circuits, and separate these circuits from other well-studied classes. As a further motivation for studying DNF-Xor circuits we show that if they can approximate inner product then small AC0-Xor circuits can compute it exactly – a long-standing open problem.</summary>
    <updated>2021-09-14T16:42:45Z</updated>
    <published>2021-09-14T16:42:45Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-09-26T03:20:25Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2021/09/13/ideal-special-quarter-fall-2021-robustness-in-high-dimensional-statistics-and-machine-learning/</id>
    <link href="https://cstheory-events.org/2021/09/13/ideal-special-quarter-fall-2021-robustness-in-high-dimensional-statistics-and-machine-learning/" rel="alternate" type="text/html"/>
    <title>IDEAL Special Quarter Fall 2021 (Robustness in High-dimensional Statistics and Machine Learning)</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">September 21 – December 10, 2021 Virtual https://www.ideal.northwestern.edu/special-quarters/fall-2021/ IDEAL – The Institute for Data, Econometrics, Algorithms, and Learning (an NSF-funded collaborative institute across Northwestern, TTIC and U Chicago) is organizing a Fall 2021 special quarter on “Robustness in High-dimensional Statistics and Machine Learning”. The special-quarter activities include mini-workshops, seminars, graduate courses, and a reading group. … <a class="more-link" href="https://cstheory-events.org/2021/09/13/ideal-special-quarter-fall-2021-robustness-in-high-dimensional-statistics-and-machine-learning/">Continue reading <span class="screen-reader-text">IDEAL Special Quarter Fall 2021 (Robustness in High-dimensional Statistics and Machine Learning)</span></a></div>
    </summary>
    <updated>2021-09-13T22:47:27Z</updated>
    <published>2021-09-13T22:47:27Z</published>
    <category term="workshop"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2021-09-26T03:21:19Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://rjlipton.wpcomstaging.com/?p=19094</id>
    <link href="https://rjlipton.wpcomstaging.com/2021/09/13/texas-sized-problems/" rel="alternate" type="text/html"/>
    <title>Texas-Sized Problems</title>
    <summary>Mathematical edges to edgy laws Cropped from Lex Fridman podcast Scott Aaronson is one of the top researchers in complexity theory and especially in quantum computing. He is famous for more than his research, he is famous also for his blog Shtetl-Optimized. Its scope includes just about everything that touches on complexity theory, but includes […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Mathematical edges to edgy laws</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2021/09/13/texas-sized-problems/scottfridmanpodcast/" rel="attachment wp-att-19096"><img alt="" class="alignright wp-image-19096" height="155" src="https://i1.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/09/ScottFridmanPodcast.jpg?resize=150%2C155&amp;ssl=1" width="150"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Cropped from Lex Fridman <a href="https://lexfridman.com/scott-aaronson-2/">podcast</a></font></td>
</tr>
</tbody>
</table>
<p>
Scott Aaronson is one of the top researchers in complexity theory and especially in quantum computing. He is famous for more than his research, he is famous also for his blog <a href="https://www.scottaaronson.com/blog/?m=202109">Shtetl-Optimized</a>. Its scope includes just about everything that touches on complexity theory, but includes many topics that span just about anything that is interesting these days.</p>
<p>
For a whole week, he has had the topic: <i>Exciting opportunities at Kabul University!</i> </p>
<p>
Scott is kidding about Kabul of course. Rather, his topic is the recent Texas law against abortion. Here are his initial comments: </p>
<blockquote><p>
Now, of course, Texas has effectively outlawed abortion—well, after the 6th week, which is before many women even realize they’re pregnant, and when the fetus is still the size of a grain of rice…</p>
<p>
There are no exceptions for rape or incest, and—this is the “novel” part—there’s a bounty system, with $10,000 fines for anyone who helps in any way with an abortion, payable to anyone who snitches on them. Texas has openly defied Roe v. Wade and, for the first time in half a century, has gotten five Supreme Court justices (three appointed by Donald Trump) to go along with it. Roe v. Wade is de facto no longer the law of the United States.
</p></blockquote>
<p>
We will not talk about abortion, but rather the novel aspect of the Texas law. This will not lead to quantum computing, not even along lines of a famous SMBC <a href="https://www.smbc-comics.com/comic/the-talk-3">cartoon</a> that Scott created with Zach Weinersmith, from which we give the second panel:</p>
<p/><p><br/>
<a href="https://rjlipton.wpcomstaging.com/2021/09/13/texas-sized-problems/the-talk/" rel="attachment wp-att-19098"><img alt="" class="aligncenter wp-image-19098" height="270" src="https://i2.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/09/the-talk.jpg?resize=480%2C270&amp;ssl=1" width="480"/></a></p>
<p>
We promise it will lead to some math, however.</p>
<p>
</p><p/><h2> The Texas Law </h2><p/>
<p/><p>
What can we do to stop the Texas law? Many are worried that the fact that the US Supreme Court has refused to even temporarily block the Texas law is unheard of. Does this mean that the new Texas law somehow is valid? Does this mean that abortions will be made illegal? Not clear.</p>
<p>
One part of the Texas law is clever—we can disagree with it and still note that the new law is clever. The law does not give the usual suspects to the local law enforcement, who are usually the ones responsible to enforce the law. Rather the law insists that anyone can raise the issue that X has violated the law against an abortion. Say S raises that X helped make an abortion happen. Then S gets $10,000 payment provided the case is upheld in court. Scott calls S the <i>snitches</i>. </p>
<p>
As recognized by the Emergency Medical Network (Emnet), this step in moving the enforcement from the usual police to the general public is one of the reasons the Texas law is so hard to fight. The usual way to challenge a new law is to immediately file some counter suit stopping those charged with enforcement. This seems to be impossible with this trick. Who can be S?—by construction that could be just about anyone. There is no single body to force to defend the law in court. Clever.</p>
<p>
</p><p/><h2> The Texas Law—The Trick </h2><p/>
<p/><p>
We are experts in theory of computation. Can we use that ability to find a way to attack the new <a href="https://legiscan.com/TX/text/SB8/id/2395961">law</a>? Can we see any weakness that is inherent in the law? Some trick? Or is the Texas idea somehow a breakthrough in ways to state a law against abortion?</p>
<p>
Ken and I have an insight. A standard trick in theory is given a new idea can we generalize it. If we can use the new idea to solve other problems then we should shed some light on the new idea. If the idea is too powerful, then we essentially prove that it cannot work in general. If it does work elsewhere, then we can use it to solve previous unsolved problems. </p>
<p>
</p><p/><h2> The Texas Law for Speeding </h2><p/>
<p/><p>
Cars speeding is a serious problem just about everywhere. I live in a rural area and it is 35 mph here. </p>
<p/><p><br/>
<a href="https://rjlipton.wpcomstaging.com/2021/09/13/texas-sized-problems/attachment/35/" rel="attachment wp-att-19100"><img alt="" class="aligncenter size-full wp-image-19100" height="114" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/09/35.png?resize=196%2C114&amp;ssl=1" width="196"/></a></p>
<p>
Yet when I am driving I am often passed by cars that cross a yellow line going 50 or faster. The issue is that the laws insist that some officer witness a violation. But since that rarely happens, the speeders almost always get no ticket.</p>
<p>
Let’s use the same trick that is used in the new Texas law. If a car races by me then I will send a digital message to the police that says: “Today I was driving my car number <b>1236335356</b> at time <b>11:19.42am</b> and witnessed a car with plate number <b>ERRW5365</b> speeding at <b>55.11mph</b> while passing me. I was at location …</p>
<p>
This would be sent to the police and they would then have the task of checking it out. Provided it checks out, I would be awarded a bounty of $500, say. And the speeder would get a fine and …</p>
<p>
How could I prove the speed? I wouldn’t have time to take a video in the moment. But Ken’s smartphone—and those of many of his colleagues—have an app that is solving problems of this type 24/7. His is a University at Buffalo product but there are many similar ones. Quoting the <a href="https://engineering.buffalo.edu/computer-science-engineering/pocketcares.html">website</a> makes everything quickly clear:</p>
<blockquote><p><b> </b> <em> PocketCare S is a bluetooth low energy (BLE) solution which enables smartphones to send and receive anonymous beacon signals. It checks the distance between a smartphone and another beacon (or smartphone running PocketCare S) … [and] … records the duration a close encounter with another beacon. PocketCare S is designed to report social distance information without collecting or revealing any personally identifiable information about any specific individual. </em>
</p></blockquote>
<p/><p>
The car would only need to have a detectable beacon, not the same app—and the info giving proof of speed over said duration might already be in the authorities’ data banks even before the complaint is filed.</p>
<p>
</p><p/><h2> Bipartite Epidemiology? </h2><p/>
<p/><p>
Of course, what we are trying to say is that this kind of lawsuit would become a new kind of virus. It might extend to many other transgressions besides speeding. What strikes us further is that this would assume a binary structure that we do not know to exist in medical pandemics.</p>
<p>
The first point is that the people who voted for the Texas law believe they are not the ones who would be violating it. Call them Team A. The remaining people—Team 2—would want to get back at them. Maybe speeding is an equal vice for those two teams, so that wouldn’t work. We’ve seen suggestions like Team B suing for open-carry of firearms. Let us just suppose Team B finds something.</p>
<p>
The second point is that a “snitch” lawsuit is like one person infecting another. But unlike our present pandemic, it’s one where people in A can only infect those in B, and vice versa. We have a bipartite graph <img alt="{(A,B)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28A%2CB%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. How does this change the math?</p>
<p>
One issue noted by Scott in a <a href="https://www.scottaaronson.com/blog/?p=5807#comment-1908708">comment</a> is whether the law allows someone to be sued multiple times. If not, then being sued once would be like acquiring immunity. The US recognizes principles of “no double jeopardy” but the Texas law appears to avoid them. </p>
<p>
We’ve tried to look for related analysis of the popular college “Humans Versus Zombies” (<a href="https://humansvszombies.org/">HvZ</a>) game. But in that game, the zombies only increase. <em>Scientific American</em> once published an <a href="https://blogs.scientificamerican.com/lab-rat/modelling-a-werewolf-epidemic-2/">analysis</a> titled, “Modelling a werewolf epidemic” that also mentioned zombies. But it did not say the werewolves could only infect zombies and vice-versa. </p>
<p>
Binary infection situations do of course exist when two groups of people suddenly mix, each having already acquired resistance to a disease that infects the other. There have been great tragedies when the mixing was a relatively small number of A colonizing into B. But we still do not know of models that would apply when the kinds of “infections” involve spontaneously arise <em>en masse</em> in the manner of a pandemic with high <img alt="{R_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> factor—as might happen if the courts really legitimize this kind of “snitch suit” law.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Is this type of snitching a viable adjunct to law enforcement for speeding? Could it save lives? What about the associated dimension of propagating personal information into massive repositories?</p>
<p/></font></font></div>
    </content>
    <updated>2021-09-13T21:26:10Z</updated>
    <published>2021-09-13T21:26:10Z</published>
    <category term="All Posts"/>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="epidemiology"/>
    <category term="law"/>
    <category term="privacy"/>
    <category term="public advocacy"/>
    <category term="Scott Aaronson"/>
    <category term="security"/>
    <category term="speeding"/>
    <category term="vigilantism"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wpcomstaging.com</id>
      <logo>https://s0.wp.com/i/webclip.png</logo>
      <link href="https://rjlipton.wpcomstaging.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wpcomstaging.com" rel="alternate" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel's Lost Letter and P=NP</title>
      <updated>2021-09-26T03:20:33Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/136</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/136" rel="alternate" type="text/html"/>
    <title>TR21-136 |  LCC and LDC: Tailor-made distance amplification and a refined separation | 

	Gil Cohen, 

	Tal Yankovitz</title>
    <summary>The Alon-Edmonds-Luby distance amplification procedure (FOCS 1995) is an algorithm that transforms a code with vanishing distance to a code with constant distance. AEL was invoked by Kopparty, Meir, Ron-Zewi, and Saraf (J. ACM 2017) for obtaining their state-of-the-art LDC, LCC and LTC. Cohen and Yankovitz (CCC 2021) devised a  procedure that can amplify inverse-polynomial distances, exponentially extending the regime of distances that can be amplified by AEL. However, the improved procedure only works for LDC and assuming rate $1-\frac1{\mathrm{poly} \log n}$.

In this work we devise a distance amplification procedure for LCC with inverse-polynomial distances even for vanishing rate $\frac1{\mathrm{poly} \log\log n}$. For LDC, we obtain a more modest improvement and require rate $1-\frac1{\mathrm{poly} \log\log n}$. Thus, the tables have turned and it is now LCC that can be better amplified. Our key idea for accomplishing this, deviating from prior work, is to tailor the distance amplification procedure to the code at hand.

Our second result concerns the relation between linear LDC and LCC. We prove the existence of linear LDC that are not LCC, qualitatively extending a separation by Kaufman and Viderman (RANDOM 2010).</summary>
    <updated>2021-09-13T14:58:00Z</updated>
    <published>2021-09-13T14:58:00Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-09-26T03:20:25Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/09/13/tenured-tenure-track-positions-in-computer-science-at-nyu-shanghai-apply-by-february-1-2022/</id>
    <link href="https://cstheory-jobs.org/2021/09/13/tenured-tenure-track-positions-in-computer-science-at-nyu-shanghai-apply-by-february-1-2022/" rel="alternate" type="text/html"/>
    <title>Tenured/Tenure-track Positions in Computer Science at NYU Shanghai (apply by February 1, 2022)</title>
    <summary>NYU Shanghai invites applications for open rank Tenured/Tenure-Track positions in Computer Science. We seek candidates who have completed a Ph.D. in Computer Science, or closely related discipline. We welcome candidates in all subfields of CS, with particular interest in Human-Computer Interaction (HCI), Operating and Distributed Systems, Blockchain, Quantum Computing, and Deep Learning. Website: https://apply.interfolio.com/93616 Email: […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>NYU Shanghai invites applications for open rank Tenured/Tenure-Track positions in Computer Science. We seek candidates who have completed a Ph.D. in Computer Science, or closely related discipline. We welcome candidates in all subfields of CS, with particular interest in Human-Computer Interaction (HCI), Operating and Distributed Systems, Blockchain, Quantum Computing, and Deep Learning.</p>
<p>Website: <a href="https://apply.interfolio.com/93616">https://apply.interfolio.com/93616</a><br/>
Email: shanghai.faculty.recruitment@nyu.edu</p></div>
    </content>
    <updated>2021-09-13T14:14:22Z</updated>
    <published>2021-09-13T14:14:22Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-09-26T03:20:37Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/135</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/135" rel="alternate" type="text/html"/>
    <title>TR21-135 |  Strong (D)QBF Dependency Schemes via Implication-free Resolution Paths | 

	Tomáš Peitl, 

	Olaf Beyersdorff, 

	Joshua Blinkhorn</title>
    <summary>We suggest a general framework to study dependency schemes for dependency quantified Boolean formulas (DQBF). As our main contribution, we exhibit a new infinite collection of implication-free DQBF dependency schemes that generalise the reflexive resolution path dependency scheme. We establish soundness of all these schemes, implying that they can be used in any DQBF proof system. We further explore the power of QBF and DQBF resolution systems parameterised by implication-free dependency schemes and show that the hierarchical structure naturally present among the dependency schemes translates isomorphically to a hierarchical structure of parameterised proof systems with respect to p-simulation. As a special case, we demonstrate that our new schemes are exponentially stronger than the reflexive resolution path dependency scheme when used in Q-resolution, thus resulting in the strongest QBF dependency schemes known to date.</summary>
    <updated>2021-09-13T10:56:05Z</updated>
    <published>2021-09-13T10:56:05Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-09-26T03:20:25Z</updated>
    </source>
  </entry>

  <entry>
    <id>http://benjamin-recht.github.io/2021/09/13/effect-size/</id>
    <link href="http://benjamin-recht.github.io/2021/09/13/effect-size/" rel="alternate" type="text/html"/>
    <title>Effect size is significantly more important than statistical significance.</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="https://www.poverty-action.org/sites/default/files/publications/Mask_RCT____Symptomatic_Seropositivity_083121.pdf">A massive cluster-randomized controlled trial run in Bangladesh to test the efficacy of mask wearing on reducing coronavirus transmission</a> released its initial results and the covid pundits have been buzzing with excitement. There have already been too many hot takes on the report, but, after wrangling with the 94 pages, I came to a different conclusion than most who have used this study as evidence for their mask predilections. I worry that because of statistical ambiguity, there’s not much that can be deduced at all.</p>

<p>The Bangladesh mask study was a cluster-randomized controlled trial. Rather than randomizing patients, this study randomized villages. Though the sample size looked enormous (340,000 individuals), the effective number of samples was only 600 because the treatment was applied to individual villages. Villages were paired using demographic attributes and one of each pair was randomly assigned to an intervention and the other to no intervention. The 300 intervention villages received free masks, information on the importance of masking, role modeling by community leaders, and in-person reminders for 8 weeks. The 300 villages in the control group did not receive any interventions.</p>

<p>The goal was to determine how much these interventions contributed to patients who both reported symptoms, subsequently consented to antibody testing, and tested positive. The study reports the precise number of people who report symptoms down to the single person (13,273 in treatment, 13,893 in control). The study reports the precise number of symptomatic people who consented to blood draws (5,414 in treatment, 5,538 in control). And the study reports the precise number of blood draws that were tested for covid antibodies (5,006  in treatment, 4,971 in control). But here’s where the picture gets murky: The number of actual positive tests appears nowhere in the preprint.</p>

<p>The study reports that 0.76% of the people in the control villages were symptomatic and seropositive whereas 0.69% of the people in the treatment villages were symptomatic and seropositive. This corresponds to about a 1.1 fold reduction in risk, and this result was deemed by the authors to be statistically significant.</p>

<p>Where do these seropositivity percentages come from? The paper does not make clear what is being counted. Do the authors compute the number of cases in treatment divided by the number of individuals treated? Or do they compute the prevalence in each cluster and average these up? These two different estimates of prevalence can give different answers. For instance, we can imagine a simplified scenario with two clusters. Let’s say one treatment-control pair consists of two villages with 10,000 people each and pair two consists of villages with 6,000 people. In the larger treatment village, there is an outbreak with 136 cases, but in the smaller treatment village there are no cases. In the control villages, the larger village observes 75 cases and the smaller 46 cases. If we count over the number of individuals, then the prevalence ratio is 1.1 in favor of the control arm. However, if we first compute prevalence at the village level and then average these estimates, we find a prevalence ratio of 1.1 in favor of the treatment arm. But which is better? Reducing prevalence at the village level or the population level? This question is especially difficult when the actual magnitude of the outcome is so small. In either case we are talking about a difference of 15 cases between the treatment and control villages in a population of 32,000 individuals.</p>

<p class="center"><img alt="illustration of how different summary statistics can yield different effect sizes." src="http://www.argmin.net/assets/mask_cluster.png" width="75%"/></p>

<p>When effect sizes are small and sensitive to measurement, convention compels us to find refuge in an argument over statistical significance. So let’s then examine how significance is derived in the working paper. The authors say that they model the count of symptomatic seropositive individuals as a “a generalized linear model (GLM) with a normal family and identity link.” This is a fancy way of saying that they modeled the count as if it were sampled from a normal distribution and ran ordinary least-squares regression. Based on the captions on the tables, it appears that they modeled the rate of symptomatic seroprevalence in each village as a normal distribution whose mean is a function of the village cluster and some other covariates. They then apparently computed estimates of village level seroprevalence under the model and averaged these estimates to yield a final estimate of seroprevalence in treatment and control.</p>

<p>While the Gaussian model made the authors’ coding simple and allowed them to report results in standard econometric formatting, the model is also certainly wrong. Counts cannot be normally distributed as normal random variables as they cannot take negative values. Indeed, 36 out of the 300 villages had zero infections, and such an event is exceedingly unlikely when the distribution is well-approximated by a Gaussian. Rather than adjust their modeling assumptions, the authors just removed these villages from the regression, leading to an overestimate of the average seroprevalence.</p>

<p>The report computes p-values and confidence intervals from these regressions. What exactly do these quantities mean? P-values and confidence intervals associated with a regression are valid <em>only if the model is true</em>. What if the model is not true? If the model is wrong, the error bars are meaningless. And if the confidence intervals and p-values are meaningless, then I’m not sure what we can conclude.</p>

<p>The authors provided several robustness checks to fend off claims like mine. They also estimated the effect using a non-preregistered model which modeled the count as being Poisson distributed and found the effects were similar. Again, however, modeling infectious diseases with Poisson distributions is not realistic. A Poisson distribution models independent events that occur with some fixed rate. Such models are reasonable for modeling noninfectious diseases such as heart attacks, but we know that infections do not occur as random independent events: interactions with other sick individuals creates complex dynamic spread and the epidemic curves we see far too often thrown around online. Mathematically, it is not surprising that two models yield the same estimated effect sizes: they are both generalized linear models and their estimates are computed with similar algorithms.  But since both models are wrong, it’s not clear why including both provides much in the way of reassurance.</p>

<p>Rather than providing all of this statistical analysis, why not report the unadjusted counts of positive individuals for the reader to interpret? Especially considering that symptoms were reported precisely down to the person.</p>

<p>It’s useful to compare this mask study to the RCTs for vaccines. Vaccine studies are fortunate to be the purest of randomized controlled trials. If RCTs are a “gold standard” for causal inference, then vaccine studies are the “gold standard” of RCTs. Vaccines trials are easy to blind, almost always have clinical equipoise, only measure direct effects on individuals that can be nearly uniformly sampled from the world’s population, and are trivial to verify statistically. Looking at the example of the Pfizer vaccine, the effect size was enormous (20x risk reduction) and the confidence intervals were just based on exact calculations for independent, binary random variables. And the CIs didn’t matter much because the effect size was so large. You could just stare at the Kaplan-Meier curve and bask in the amazing effectiveness of MRNA vaccines.</p>

<p>Unfortunately, of course, most effect sizes are not factor of 20. Indeed, they are usually less than a factor of 2. As we saw in the mask study, the effect size was less than a factor of 1.1. I’m picking on the mask study only because it has been so attention grabbing.  It’s a convenient example to illustrate how statistical modeling can muddy the waters in randomized control trials. But it is only one of many examples I’ve come across in the past few months. If you pick a random paper out of the New England Journal of Medicine or the American Economic Review, you will likely find similar statistical muddiness.</p>

<p>We lose sight of the forest for the trees when we fight over p-values rather than considering effect sizes. Ernest Rutherford is famously quoted proclaiming “If your experiment needs statistics, you ought to have done a better experiment.” Rutherford, who discovered the structure of the atom, and is famous for pioneering innovations in experiment design and measurement for amplifying small effects. He was not opposed to probing the minuscule, but was interested in how to best produce empirical evidence.</p>

<p>I think a milder version of Rutherford’s aphorism should guide scientific investigation: If the effect size is so small that we need sophisticated statistics, maybe that means the effect isn’t real. Using sophisticated statistical scaffolding clouds our judgement. We end up using statistical methods as a crutch, not to dig signals out of noise, but to convince ourselves of signals when there are none. And this matters for recommendations on policy. If the effects of an intervention are modest at best, and only manifest themselves after statistical correction, how can we use such a study to guide policy?</p>

<p>Misapplication of statistics can lead to bad policy decisions. <a href="https://www.wsj.com/articles/SB121867148093738861">Medical devices can be approved even when the statistics are done in error</a>.  And statistical errors can even <a href="https://www.statnews.com/2021/03/23/astrazeneca-may-have-used-outdated-information-in-announcing-covid19-vaccine-results/">dampen confidence in effective vaccines</a>.</p>

<p>Of course, there is an existential problem arguing for large effect sizes. If most effect sizes are small or zero, then most interventions are useless. And this forces us scientists to confront our cosmic impotence, which remains a humbling and frustrating experience.</p>

<p>I’ve probably been thinking too much about statistics and models. I’m not the first mid-career professor to realize that statistical modeling is widely misapplied (For example <a href="https://www.bmj.com/content/308/6924/283">Doug Altman</a>, <a href="https://www.cambridge.org/core/books/statistical-models-and-causal-inference/7CE8D4957FF6E9615AAAC4128FA8246E">David Freedman</a>, or <a href="http://home.uchicago.edu/~amshaikh/webfiles/multiplereview.pdf">Joseph Romano</a>, among many others). But I’m hoping to write more about this with a bit of an algorithmic lens, discussing some of the earlier worries about modeling in the process. Can we revisit suggestions for improving our evidentiary framework with contemporary computational statistics tools? Where might this lead us in both the experimental sciences and in machine learning?</p></div>
    </summary>
    <updated>2021-09-13T00:00:00Z</updated>
    <published>2021-09-13T00:00:00Z</published>
    <source>
      <id>http://benjamin-recht.github.io/</id>
      <author>
        <name>Ben Recht</name>
      </author>
      <link href="http://benjamin-recht.github.io/" rel="alternate" type="text/html"/>
      <link href="http://benjamin-recht.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Musings on systems, information, learning, and optimization.</subtitle>
      <title>arg min blog</title>
      <updated>2021-09-25T23:36:03Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-7838316154561259915</id>
    <link href="http://blog.computationalcomplexity.org/feeds/7838316154561259915/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2021/09/review-of-blog-book-based-on-less-wrong.html#comment-form" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/7838316154561259915" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/7838316154561259915" rel="self" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2021/09/review-of-blog-book-based-on-less-wrong.html" rel="alternate" type="text/html"/>
    <title>Review of A Blog Book based on the Less Wrong Blog</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>There is a blog called <a href="https://www.lesswrong.com/">lesswrong</a>. Many people contribute to it (how many people must contribute to a website before it stops being called a blog and starts being called... Not sure what?). The theme is rationality. They (not sure who they are) have made a best-of collection from lesswrong which is named</p><p><i><b>A Map that Reflects the Territory (available <a href="https://www.lesswrong.com/books">here</a>)</b></i></p><p>Actually, its not one book, but five mini-books. I quote the titles and paraphrase the first sentence of each:</p><p><i>Epistemology</i>:  How we come to know the world.</p><p><i>Agency</i>: The ability to take action in the world and control the future.</p><p><i>Coordination</i>:  The ability of multiple agents to work together.</p><p><i>Curiosity</i>: The desire to understand how the world works.</p><p><i>Alignment</i>: The problem of aligning the thoughts and goals.</p><p>I have written a review of the the book. The book was my first exposure to the blog, except sometimes reading<i> about </i>the blog, probably on Scott's blog.</p><p>I am posting this to both complexity blog and to lesswrong, though with lesswrong I will have a different intro since they know lesswrong but might not know complextyblog. </p><p>My review is <a href="https://www.cs.umd.edu/~gasarch/BLOGPAPERS/lesswrong.pdf">here</a>.</p><p>I would appreciate intelligent comments and suggestions, which I will use to improve the review.</p></div>
    </content>
    <updated>2021-09-12T19:38:00Z</updated>
    <published>2021-09-12T19:38:00Z</published>
    <author>
      <name>gasarch</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03004932739846901628</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="http://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2021-09-26T02:57:50Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/134</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/134" rel="alternate" type="text/html"/>
    <title>TR21-134 |  A refinement of the Meyer-McCreight Union Theorem | 

	Siddharth Bhaskar</title>
    <summary>For a function $t : 2^\star \to 1^\star$, let $C_t$ be the set of problems decidable on input $x$ in time at most $t(x)$ almost everywhere.  The Union Theorem of Meyer and McCreight asserts that any union $\bigcup_{i &lt; \omega} C_{t_i}$ for a uniformly recursive sequence of bounds $t_i$ is equal to $C_L$ for some single recursive function $L$. In particular the class PTIME of polynomial-time relations can be expressed as $C_L$ for some total recursive function $L : 2^\star \to 1^\star$. By controlling the complexity of the construction, we show that in fact PTIME equals $C_L$ for some $L$ computable in quasi-polynomial time.</summary>
    <updated>2021-09-12T12:21:11Z</updated>
    <published>2021-09-12T12:21:11Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-09-26T03:20:25Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/133</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/133" rel="alternate" type="text/html"/>
    <title>TR21-133 |  Testing Distributions of Huge Objects | 

	Oded Goldreich, 

	Dana Ron</title>
    <summary>We initiate a study of a new model of property testing that is a hybrid of testing properties of distributions and testing properties of strings. 
Specifically, the new model refers to testing properties of distributions, but these are distributions over huge objects (i.e., very long strings). 
Accordingly, the model accounts for the total number of local probes into these objects (resp., queries to the strings)as well as for the distance between objects (resp., strings).
Specifically, the distance between distributions is defined as the earth mover's distance with respect to the relative Hamming distance between strings.

We study the query complexity of testing in this new model, focusing on three directions.
First, we try to relate the query complexity of testing properties in the new model to the sample complexity of testing these properties in the standard distribution testing model.
Second, we consider the complexity of testing properties that arise naturally in the new model (e.g., distributions that capture random variations of fixed strings).
Third, we consider the complexity of testing properties that were extensively studied in the standard distribution testing model: Two such cases are uniform distributions
and pairs of identical distributions, where we obtain the following results.

\begin{itemize}
\item
Testing whether a distribution over $n$-bit long strings is uniform on some set of size $m$ can be tested with query complexity ${\widetilde O}(m/\epsilon^3)$, where $\epsilon&gt;(\log_2m)/n$ is the proximity parameter.
\item
Testing whether two distribution over $n$-bit long strings that have support size at most $m$ are identical can be tested  with query complexity ${\widetilde O}(m^{2/3}/\epsilon^3)$.
\end{itemize}
Both upper bounds are pretty tight; that is, for $\epsilon=\Omega(1)$, the first task requires $\Omega(m^c)$ queries for any $c&lt;1$ and $n=\omega(\log m)$, whereas the second task requires $\Omega(m^{2/3})$ queries.
Note that the query complexity of the first task is higher than the sample complexity of the corresponding task in the standard distribution testing model, whereas in the case of the second task the bounds almost match.</summary>
    <updated>2021-09-12T11:24:05Z</updated>
    <published>2021-09-12T11:24:05Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-09-26T03:20:25Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/132</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/132" rel="alternate" type="text/html"/>
    <title>TR21-132 |  Pseudo-random functions and uniform learnability | 

	Eric Binnendyk</title>
    <summary>Boolean circuits are a model of computation. A class of Boolean circuits is called a polynomial class if the number of nodes is bounded by a polynomial function of the number of input variables. A class $C_n[s(n)]$ of Boolean functions is called learnable if there are algorithms that can approximate functions in $C_n[s(n)]$ when given oracle access to the function. A distribution $D$ of functions is called pseudorandom against a circuit class $C[t(n)]$ if any oracle circuit $C^f$ from $C[t(n)]$ outputs 1 with the same probability if the oracle $f$ is chosen from $D$ as it would if the oracle were random. It is known that a polynomial class of circuits is learnable if and only if it contains no pseudorandom distributions of functions. However, there is no known algorithm to produce the learner given the number of inputs the circuits have (the learner is non-uniform). I investigate a uniform version of the min-max theorem as a possible tool to find an algorithm for such learners.</summary>
    <updated>2021-09-12T07:27:36Z</updated>
    <published>2021-09-12T07:27:36Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-09-26T03:20:25Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://dstheory.wordpress.com/?p=99</id>
    <link href="https://dstheory.wordpress.com/2021/09/10/thursday-sept-23rd-christos-papadimitriou-from-columbia-university/" rel="alternate" type="text/html"/>
    <title>Thursday Sept 23rd — Christos Papadimitriou  from Columbia University</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">The next Foundations of Data Science virtual talk will take place on Thursday, Sept 23rd at 10:00 AM Pacific Time (13:00 Eastern Time, 18:00 Central European Time, 17:00 UTC).  Christos Papadimitriou from Columbia Univeristy will speak about “How does the brain beget the mind?” Please register here to join the virtual talk. Abstract: How do molecules, cells<a class="more-link" href="https://dstheory.wordpress.com/2021/09/10/thursday-sept-23rd-christos-papadimitriou-from-columbia-university/">Continue reading <span class="screen-reader-text">"Thursday Sept 23rd — Christos Papadimitriou  from Columbia University"</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p class="has-text-align-justify">The next <a href="https://sites.google.com/view/dstheory/home" rel="noreferrer noopener" target="_blank">Foundations of Data Science</a> virtual talk will take place on <strong>Thursday, Sept</strong> <strong>23</strong>rd at <strong>10:00 AM Pacific Time</strong> (13:00 Eastern Time, 18:00 Central European Time, 17:00 UTC).  <strong><a href="https://www.engineering.columbia.edu/faculty/christos-papadimitriou" rel="noreferrer noopener" target="_blank"/><a href="https://www.google.com/url?q=https%3A%2F%2Fwww.engineering.columbia.edu%2Ffaculty%2Fchristos-papadimitriou&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNG2ooEJfi_Bp9C9dcEJ47YOAxSQFw" rel="noreferrer noopener" target="_blank">Christos Papadimitriou</a></strong> from<strong> Columbia Univeristy</strong> will speak about “How does the brain beget the mind?”</p>



<p><a href="https://sites.google.com/view/dstheory" rel="noreferrer noopener" target="_blank">Please register here to join the virtual talk.</a></p>



<p class="has-text-align-justify"><strong>Abstract</strong>: How do molecules, cells and synapses effect reasoning, intelligence, planning, language? Despite dazzling progress in experimental neuroscience, as well as in cognitive science at the other extreme of scale, we do not seem to be making progress in the overarching question: the gap is huge and a completely new approach seems to be required. As Richard Axel recently put it: “We don’t have a logic for the transformation of neural activity into thought […].”</p>



<p>What kind of formal system would qualify as this “logic”?</p>



<p class="has-text-align-justify">I will introduce the Assembly Calculus (AC), a computational system which appears to be a promising bridge between neurons and cognition. Through this programming framework, a Parser was recently implemented which (a) can handle reasonably complex sentences of English and other languages, and (b) works exclusively through the spiking of neurons.</p>



<p>The series is supported by the <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1934846&amp;HistoricalAwards=false">NSF HDR TRIPODS Grant 1934846</a>.</p></div>
    </content>
    <updated>2021-09-10T22:39:48Z</updated>
    <published>2021-09-10T22:39:48Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>dstheory</name>
    </author>
    <source>
      <id>https://dstheory.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://dstheory.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://dstheory.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://dstheory.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://dstheory.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Foundation of Data Science – Virtual Talk Series</title>
      <updated>2021-09-26T03:21:59Z</updated>
    </source>
  </entry>
</feed>
