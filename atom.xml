<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2021-12-01T04:21:36Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/11/30/associate-or-full-professor-uc-san-diego-cse-at-university-of-california-san-diego-apply-by-january-1-2022/</id>
    <link href="https://cstheory-jobs.org/2021/11/30/associate-or-full-professor-uc-san-diego-cse-at-university-of-california-san-diego-apply-by-january-1-2022/" rel="alternate" type="text/html"/>
    <title>Associate or Full Professor – UC San Diego CSE at University of California – San Diego (apply by January 1, 2022)</title>
    <summary>The UC San Diego Department of Computer Science and Engineering (CSE) invites applications for multiple tenured faculty positions at the Associate or Full Professor rank. The department is looking for exceptional candidates in all areas of Computer Science and Engineering. Applicants must have a Ph.D. in computer science or a related area at the time […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The UC San Diego Department of Computer Science and Engineering (CSE) invites applications for multiple tenured faculty positions at the Associate or Full Professor rank. The department is looking for exceptional candidates in all areas of Computer Science and Engineering. Applicants must have a Ph.D. in computer science or a related area at the time of application.</p>
<p>Website: <a href="https://apol-recruit.ucsd.edu/JPF03001">https://apol-recruit.ucsd.edu/JPF03001</a><br/>
Email: nherrera@eng.ucsd.edu</p></div>
    </content>
    <updated>2021-11-30T21:36:33Z</updated>
    <published>2021-11-30T21:36:33Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-12-01T04:20:34Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/11/30/assistant-professor-at-uc-san-diego-cse-at-university-of-california-san-diego-apply-by-january-1-2022/</id>
    <link href="https://cstheory-jobs.org/2021/11/30/assistant-professor-at-uc-san-diego-cse-at-university-of-california-san-diego-apply-by-january-1-2022/" rel="alternate" type="text/html"/>
    <title>Assistant Professor at UC San Diego CSE at University of California – San Diego (apply by January 1, 2022)</title>
    <summary>The UC San Diego Department of Computer Science and Engineering (CSE) invites applications for multiple tenure-track faculty positions at the Assistant Professor rank. The department is looking for exceptional candidates in all areas of Computer Science &amp; Engineering. A Ph.D. or advancement to candidacy in Computer Science &amp; Engineering or related disciplines is required at […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The UC San Diego Department of Computer Science and Engineering (CSE) invites applications for multiple tenure-track faculty positions at the Assistant Professor rank. The department is looking for exceptional candidates in all areas of Computer Science &amp; Engineering. A Ph.D. or advancement to candidacy in Computer Science &amp; Engineering or related disciplines is required at the time of application</p>
<p>Website: <a href="https://apol-recruit.ucsd.edu/JPF03000">https://apol-recruit.ucsd.edu/JPF03000</a><br/>
Email: nherrera@eng.ucsd.edu</p></div>
    </content>
    <updated>2021-11-30T21:33:34Z</updated>
    <published>2021-11-30T21:33:34Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-12-01T04:20:34Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2021/11/30/linkage</id>
    <link href="https://11011110.github.io/blog/2021/11/30/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>Joanne Cohn and the email list that led to arXiv (\(\mathbb{M}\)). If, like me, you thought arXiv was started by Paul Ginsparg, you’re mistaken. Ginsparg deserves a lot of credit for setting up most of arXiv’s infrastructure but he only did it after Cohn gave him a ball to run with.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><ul>
  <li>
    <p><a href="https://doi.org/10.1063/PT.6.4.20211108a">Joanne Cohn and the email list that led to arXiv</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107291497920204652">\(\mathbb{M}\)</a>).</span> If, like me, you thought arXiv was started by Paul Ginsparg, you’re mistaken. Ginsparg deserves a lot of credit for setting up most of arXiv’s infrastructure but he only did it after Cohn gave him a ball to run with.</p>
  </li>
  <li>
    <p>I ran across a reference to French mathematical artist Sylvie Pic in Étienne Ghys’ online book ‘‘<a href="https://arxiv.org/abs/1612.06373">A Singular Mathematical Promenade</a>’’ <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107297267002982515">\(\mathbb{M}\)</a>)</span> and am intrigued by her work but can only find snippets here and there. A few links: <a href="https://les-traces-habiles.org/tag/sylvie-pic/">les traces habiles</a>, <a href="http://www.documentsdartistes.org/artistes/pic/repro7-1.html">documents d’artistes</a>, <a href="https://artuk.org/discover/artists/pic-sylvie-b-1957">Sucharda’s Still Life (2006)</a>, and a Google Books link to an essay by Pic about her work: <a href="https://books.google.com/books?id=i2qnl1P9pyEC&amp;pg=PA253">“Some Aspects of the Use of Geometry in My Artistic Work”, in ‘‘The Visual Mind II’’</a>.</p>
  </li>
  <li>
    <p><a href="https://www.youtube.com/watch?v=w2T12mnk7tg">Colouring Graphs and Fermat’s Conjecture</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107302448008422359">\(\mathbb{M}\)</a>).</span> How Issai Schur used graph Ramsey theory to prove that the Fermat equation \(x^n+y^n=z^n\) has solutions <span style="white-space: nowrap;">modulo \(p\)</span> for all but finitely many <span style="white-space: nowrap;">primes \(p\).</span> Another Some1 math-explainer video, I think?</p>
  </li>
  <li>
    <p><a href="https://discrete-notes.github.io/contraction-sequences">Contraction sequences</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107308282315835268">\(\mathbb{M}\)</a>).</span> This introduces twin-width, a hot topic in graph structure theory and structure-based algorithms, more broadly than you might get from its research papers. Twin-width is based on repeated merging pairs of vertices with similar neighborhoods, aiming for each cluster to be nonuniformly connected to very few other clusters, but other kinds of width can be formulated in this way and this view leads to an alternative proof of Courcelle’s theorem.</p>
  </li>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/Szemer%C3%A9di_regularity_lemma">Szemerédi regularity lemma</a> now <a href="https://www.isa-afp.org/entries/Szemeredi_Regularity.html">formalized in Isabelle</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107314263241628934">\(\mathbb{M}\)</a>, <a href="https://twitter.com/wtgowers/status/1459271456865591298">via</a>).</span> This is the result that every graph’s vertices can be partitioned into few subsets so that the subgraph between most pairs of subsets resemble random graphs of varying densities. It’s not the Robertson–Seymour theorem or the strong perfect graph theorem, but still it’s good to see some serious graph theory getting attention from the proof assistant crowd.</p>
  </li>
  <li>
    <p><a href="http://gallery.bridgesmathart.org/exhibitions/2022-joint-mathematics-meetings">The 2022 JMM mathematical art gallery is already online</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107319825945929357">\(\mathbb{M}\)</a>),</span> although I’m not sure, maybe it’s still being populated with more to come later. The <a href="http://gallery.bridgesmathart.org/exhibitions/2022-joint-mathematics-meetings/kkshir">rotating hexagon cluster mechanism by Khushbu Kshirsagar</a> makes me want to see something like it for a <a href="https://en.wikipedia.org/wiki/Smoothed_octagon">rotating cluster of smoothed octagons</a>, but I guess that would require a more complicated design.</p>
  </li>
  <li>
    <p>This is a symmetric view of the <a href="https://en.wikipedia.org/wiki/Whitehead_link">Whitehead link</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107325158960438533">\(\mathbb{M}\)</a>),</span> which in its more usual view (an alternating link formed by overlaying a circle and a figure-eight) is not as obviously symmetric. Redrawn from Fig.22 of <a href="https://arxiv.org/abs/2001.01472v1">Skopenkov’s “A user’s guide to basic knot and link theory”</a> and also available <a href="https://commons.wikimedia.org/wiki/File:Symmetric_Whitehead_link.svg">in more garish colors at Wikimedia commons</a>.</p>

    <p style="text-align: center;"><img alt="Symmetric Whitehead link" src="https://11011110.github.io/blog/assets/2021/symmetric-Whitehead-link.svg"/></p>
  </li>
  <li>
    <p><a href="https://cameroncounts.wordpress.com/2021/11/23/two-pointers/">Two pointers</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107330222887192739">\(\mathbb{M}\)</a>).</span> Peter Cameron warns that accessibility requirements for course lecture notes and the ability to format mathematics in those notes may be on a collision course, because the non-mathematicians who formulate accessibility requirements don’t realize how inadequate non-LaTeX solutions are. Also that requirements for making research data public are being taken to silly levels for research in fields like mathematics where there may well be no data to make public.</p>
  </li>
  <li>
    <p><a href="https://blog.plover.com/math/consecutive-squarefull.html">Consecutive squareful numbers</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@mjd/107324651548000153">\(\mathbb{M}\)</a>).</span> It’s easy to prove by Chinese remaindering that arbitrarily long sequences of non-squarefree numbers exist, but there’s some interesting work on how to find the first such sequence quickly.</p>
  </li>
  <li>
    <p><a href="https://www.youtube.com/watch?v=JvhSRCfCHb4">Strategy on an infinite chessboard between an angel and a devil</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@FreddyR/107334208631308281">\(\mathbb{M}\)</a>).</span> Video clearly explaining the solution to Conway’s angel vs devil problem. There’s a strategy-stealing trick in there, so although you get an explicit algorithm for the angel to escape a weaker adversary, this method only proves the existence of an algorithm for escaping the devil without showing how.</p>
  </li>
  <li>
    <p>Three new Wikipedia Good Articles <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107347230356711269">\(\mathbb{M}\)</a>):</span></p>

    <ul>
      <li>
        <p><a href="https://en.wikipedia.org/wiki/Feedback_arc_set">Feedback arc set</a>, edges touching all cycles in a digraph, with applications to sports ranking, chemical engineering, baboon psychology, etc.</p>
      </li>
      <li>
        <p><a href="https://en.wikipedia.org/wiki/Opaque_set">Opaque set</a>, points or curves blocking all visibility across a shape, with the shortest solution mostly still unknown.</p>
      </li>
      <li>
        <p><a href="https://en.wikipedia.org/wiki/No-three-in-line_problem">No-three-in-line problem</a>, the largest grid set without three points in line, conjecturally \(\approx 1.814n\) despite all experimental evidence pointing <span style="white-space: nowrap;">to \(2n\).</span></p>
      </li>
    </ul>
  </li>
  <li>
    <p>Fractal Kitty, newly on Mathstodon, <a href="https://fractalkitty.com/mathbirbs/">makes playing cards with birds for numbers and plane curves, knots, graphs, and groups as suits</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@fractalkitty/107345972732518709">\(\mathbb{M}\)</a>).</span></p>
  </li>
  <li>
    <p><a href="https://www.gwern.net/Variables">Top-ten underused Greek letter variables on arXiv</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107359400309951476">\(\mathbb{M}\)</a>, <a href="https://news.ycombinator.com/item?id=2">via</a>).</span></p>
  </li>
  <li>
    <p>You’re probably familiar with <a href="https://littlefreelibrary.org/">Little Free Libraries</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107363373181037563">\(\mathbb{M}\)</a>),</span> outdoor bookshelf-boxes on sticks that have popped up like mushrooms all over neighborhoods like mine (we have five) to make it easy to find good homes for books you’d like others to find or don’t want to keep yourself. One of our neighbors has taken it a step further, making a little free dog-stick library, in active use judging by its changing numbers of sticks from week to week.</p>

    <p style="text-align: center;"><img alt="Dog stick library in University Hills, Irvine, California" src="https://www.ics.uci.edu/~eppstein/pix/dsl/DogStickLibrary-m.jpg" style="border-style: solid; border-color: black;"/></p>
  </li>
  <li>
    <p><a href="https://theoretics.episciences.org/">TheoretiCS</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107369179583359231">\(\mathbb{M}\)</a>)</span> is a new diamond-open-access journal in all areas of theoretical computer science. It is being run as an overlay of arXiv, through the Episciences platform for such overlays, with Javier Esparza and Uri Zwick as editors-in-chief and a large and distinguished editorial board.</p>
  </li>
</ul></div>
    </content>
    <updated>2021-11-30T18:39:00Z</updated>
    <published>2021-11-30T18:39:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2021-12-01T02:40:53Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/11/30/assistant-professor-in-computer-science-at-faculty-of-computer-science-hse-university-apply-by-january-9-2022/</id>
    <link href="https://cstheory-jobs.org/2021/11/30/assistant-professor-in-computer-science-at-faculty-of-computer-science-hse-university-apply-by-january-9-2022/" rel="alternate" type="text/html"/>
    <title>Assistant Professor in Computer Science at Faculty of Computer Science, HSE University (apply by January 9, 2022)</title>
    <summary>We welcome applications for full-time, tenure-track positions of assistant professor in all areas of computer science. Candidates must hold a recent PhD in computer science or related fields by an internationally recognized university; Teaching experience is strongly desirable; Knowledge of Russian is not required. Website: https://iri.hse.ru/ru/TTfcs_21_22AP Email: iri@hse.ru</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>We welcome applications for full-time, tenure-track positions of assistant professor in all areas of computer science.<br/>
Candidates must hold a recent PhD in computer science or related fields by an internationally recognized university; Teaching experience is strongly desirable;<br/>
Knowledge of Russian is not required.</p>
<p>Website: <a href="https://iri.hse.ru/ru/TTfcs_21_22AP">https://iri.hse.ru/ru/TTfcs_21_22AP</a><br/>
Email: iri@hse.ru</p></div>
    </content>
    <updated>2021-11-30T10:48:38Z</updated>
    <published>2021-11-30T10:48:38Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-12-01T04:20:34Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.14196</id>
    <link href="http://arxiv.org/abs/2111.14196" rel="alternate" type="text/html"/>
    <title>Subexponential Parameterized Algorithms for Cut and Cycle Hitting Problems on H-Minor-Free Graphs</title>
    <feedworld_mtime>1638230400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bandyapadhyay:Sayan.html">Sayan Bandyapadhyay</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lochet:William.html">William Lochet</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lokshtanov:Daniel.html">Daniel Lokshtanov</a>, Saket Saurabh, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/x/Xue:Jie.html">Jie Xue</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.14196">PDF</a><br/><b>Abstract: </b>We design the first subexponential-time (parameterized) algorithms for
several cut and cycle-hitting problems on $H$-minor free graphs. In particular,
we obtain the following results (where $k$ is the solution-size parameter).
</p>
<p>1. $2^{O(\sqrt{k}\log k)} \cdot n^{O(1)}$ time algorithms for Edge
Bipartization and Odd Cycle Transversal;
</p>
<p>2. a $2^{O(\sqrt{k}\log^4 k)} \cdot n^{O(1)}$ time algorithm for Edge
Multiway Cut and a $2^{O(r \sqrt{k} \log k)} \cdot n^{O(1)}$ time algorithm for
Vertex Multiway Cut, where $r$ is the number of terminals to be separated;
</p>
<p>3. a $2^{O((r+\sqrt{k})\log^4 (rk))} \cdot n^{O(1)}$ time algorithm for Edge
Multicut and a $2^{O((\sqrt{rk}+r) \log (rk))} \cdot n^{O(1)}$ time algorithm
for Vertex Multicut, where $r$ is the number of terminal pairs to be separated;
</p>
<p>4. a $2^{O(\sqrt{k} \log g \log^4 k)} \cdot n^{O(1)}$ time algorithm for
Group Feedback Edge Set and a $2^{O(g \sqrt{k}\log(gk))} \cdot n^{O(1)}$ time
algorithm for Group Feedback Vertex Set, where $g$ is the size of the group.
</p>
<p>5. In addition, our approach also gives $n^{O(\sqrt{k})}$ time algorithms for
all above problems with the exception of $n^{O(r+\sqrt{k})}$ time for
Edge/Vertex Multicut and $(ng)^{O(\sqrt{k})}$ time for Group Feedback
Edge/Vertex Set.
</p>
<p>We obtain our results by giving a new decomposition theorem on graphs of
bounded genus, or more generally, an $h$-almost-embeddable graph for any fixed
constant $h$. In particular we show the following. Let $G$ be an
$h$-almost-embeddable graph for a constant $h$. Then for every
$p\in\mathbb{N}$, there exist disjoint sets $Z_1,\dots,Z_p \subseteq V(G)$ such
that for every $i \in \{1,\dots,p\}$ and every $Z'\subseteq Z_i$, the treewidth
of $G/(Z_i\backslash Z')$ is $O(p+|Z'|)$. Here $G/(Z_i\backslash Z')$ is the
graph obtained from $G$ by contracting edges with both endpoints in $Z_i
\backslash Z'$.
</p></div>
    </summary>
    <updated>2021-11-30T22:44:05Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-11-30T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.14148</id>
    <link href="http://arxiv.org/abs/2111.14148" rel="alternate" type="text/html"/>
    <title>Computational Complexity of Normalizing Constants for the Product of Determinantal Point Processes</title>
    <feedworld_mtime>1638230400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Ohsaka:Naoto.html">Naoto Ohsaka</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Matsuoka:Tatsuya.html">Tatsuya Matsuoka</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.14148">PDF</a><br/><b>Abstract: </b>We consider the product of determinantal point processes (DPPs), a point
process whose probability mass is proportional to the product of principal
minors of multiple matrices, as a natural, promising generalization of DPPs. We
study the computational complexity of computing its normalizing constant, which
is among the most essential probabilistic inference tasks. Our
complexity-theoretic results (almost) rule out the existence of efficient
algorithms for this task unless the input matrices are forced to have favorable
structures. In particular, we prove the following:
</p>
<p>(1) Computing $\sum_S\det({\bf A}_{S,S})^p$ exactly for every (fixed)
positive even integer $p$ is UP-hard and Mod$_3$P-hard, which gives a negative
answer to an open question posed by Kulesza and Taskar.
</p>
<p>(2) $\sum_S\det({\bf A}_{S,S})\det({\bf B}_{S,S})\det({\bf C}_{S,S})$ is
NP-hard to approximate within a factor of $2^{O(|I|^{1-\epsilon})}$ or
$2^{O(n^{1/\epsilon})}$ for any $\epsilon&gt;0$, where $|I|$ is the input size and
$n$ is the order of the input matrix. This result is stronger than the
#P-hardness for the case of two matrices derived by Gillenwater.
</p>
<p>(3) There exists a $k^{O(k)}n^{O(1)}$-time algorithm for computing
$\sum_S\det({\bf A}_{S,S})\det({\bf B}_{S,S})$, where $k$ is the maximum rank
of $\bf A$ and $\bf B$ or the treewidth of the graph formed by nonzero entries
of $\bf A$ and $\bf B$. Such parameterized algorithms are said to be
fixed-parameter tractable.
</p>
<p>These results can be extended to the fixed-size case. Further, we present two
applications of fixed-parameter tractable algorithms given a matrix $\bf A$ of
treewidth $w$:
</p>
<p>(4) We can compute a $2^{\frac{n}{2p-1}}$-approximation to $\sum_S\det({\bf
A}_{S,S})^p$ for any fractional number $p&gt;1$ in $w^{O(wp)}n^{O(1)}$ time.
</p>
<p>(5) We can find a $2^{\sqrt n}$-approximation to unconstrained MAP inference
in $w^{O(w\sqrt n)}n^{O(1)}$ time.
</p></div>
    </summary>
    <updated>2021-11-30T22:43:48Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-11-30T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.14071</id>
    <link href="http://arxiv.org/abs/2111.14071" rel="alternate" type="text/html"/>
    <title>Distributionally robust possibilistic optimization problems</title>
    <feedworld_mtime>1638230400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Guillaume:Romain.html">Romain Guillaume</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kasperski:Adam.html">Adam Kasperski</a>, Pawel Zielinski <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.14071">PDF</a><br/><b>Abstract: </b>In this paper a class of optimization problems with uncertain linear
constraints is discussed. It is assumed that the constraint coefficients are
random vectors whose probability distributions are only partially known.
Possibility theory is used to model the imprecise probabilities. In one of the
interpretations, a possibility distribution (a membership function of a fuzzy
set) in the set of coefficient realizations induces a necessity measure, which
in turn defines a family of probability distributions in this set. The
distributionally robust approach is then used to transform the imprecise
constraints into deterministic counterparts. Namely, the uncertain left-had
side of each constraint is replaced with the expected value with respect to the
worst probability distribution that can occur. It is shown how to represent the
resulting problem by using linear or second order cone constraints. This leads
to problems which are computationally tractable for a wide class of
optimization models, in particular for linear programming.
</p></div>
    </summary>
    <updated>2021-11-30T22:38:30Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-11-30T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.14033</id>
    <link href="http://arxiv.org/abs/2111.14033" rel="alternate" type="text/html"/>
    <title>On Lower Bounds of Approximating Parameterized $k$-Clique</title>
    <feedworld_mtime>1638230400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lin:Bingkai.html">Bingkai Lin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Ren:Xuandi.html">Xuandi Ren</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sun:Yican.html">Yican Sun</a>, Xiuhan Wang <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.14033">PDF</a><br/><b>Abstract: </b>Given a simple graph $G$ and an integer $k$, the goal of $k$-Clique problem
is to decide if $G$ contains a complete subgraph of size $k$. We say an
algorithm approximates $k$-Clique within a factor $g(k)$ if it can find a
clique of size at least $k / g(k)$ when $G$ is guaranteed to have a $k$-clique.
Recently, it was shown that approximating $k$-Clique within a constant factor
is W[1]-hard [Lin21].
</p>
<p>We study the approximation of $k$-Clique under the Exponential Time
Hypothesis (ETH). The reduction of [Lin21] already implies an
$n^{\Omega(\sqrt[6]{\log k})}$-time lower bound under ETH. We improve this
lower bound to $n^{\Omega(\log k)}$. Using the gap-amplification technique by
expander graphs, we also prove that there is no $k^{o(1)}$ factor
FPT-approximation algorithm for $k$-Clique under ETH.
</p>
<p>We also suggest a new way to prove the Parameterized Inapproximability
Hypothesis (PIH) under ETH. We show that if there is no $n^{O(\frac{k}{\log
k})}$ algorithm to approximate $k$-Clique within a constant factor, then PIH is
true.
</p></div>
    </summary>
    <updated>2021-11-30T22:37:56Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2021-11-30T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.14030</id>
    <link href="http://arxiv.org/abs/2111.14030" rel="alternate" type="text/html"/>
    <title>Reconfiguration Problems on Submodular Functions</title>
    <feedworld_mtime>1638230400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Ohsaka:Naoto.html">Naoto Ohsaka</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Matsuoka:Tatsuya.html">Tatsuya Matsuoka</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.14030">PDF</a><br/><b>Abstract: </b>Reconfiguration problems require finding a step-by-step transformation
between a pair of feasible solutions for a particular problem. The primary
concern in Theoretical Computer Science has been revealing their computational
complexity for classical problems.
</p>
<p>This paper presents an initial study on reconfiguration problems derived from
a submodular function, which has more of a flavor of Data Mining. Our
submodular reconfiguration problems request to find a solution sequence
connecting two input solutions such that each solution has an objective value
above a threshold in a submodular function $f: 2^{[n]} \to \mathbb{R}_+$ and is
obtained from the previous one by applying a simple transformation rule. We
formulate three reconfiguration problems: Monotone Submodular Reconfiguration
(MSReco), which applies to influence maximization, and two versions of
Unconstrained Submodular Reconfiguration (USReco), which apply to determinantal
point processes. Our contributions are summarized as follows:
</p>
<p>1. We prove that MSReco and USReco are both $\mathsf{PSPACE}$-complete.
</p>
<p>2. We design a $\frac{1}{2}$-approximation algorithm for MSReco and a
$\frac{1}{n}$-approximation algorithm for (one version of) USReco.
</p>
<p>3. We devise inapproximability results that approximating the optimum value
of MSReco within a $(1-\frac{1+\epsilon}{n^2})$-factor is
$\mathsf{PSPACE}$-hard, and we cannot find a
$(\frac{5}{6}+\epsilon)$-approximation for USReco.
</p>
<p>4. We conduct numerical study on the reconfiguration version of influence
maximization and determinantal point processes using real-world social network
and movie rating data.
</p></div>
    </summary>
    <updated>2021-11-30T22:48:42Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-11-30T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.14005</id>
    <link href="http://arxiv.org/abs/2111.14005" rel="alternate" type="text/html"/>
    <title>A polynomial kernel for vertex deletion into bipartite permutation graphs</title>
    <feedworld_mtime>1638230400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Derbisz:Jan.html">Jan Derbisz</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.14005">PDF</a><br/><b>Abstract: </b>A permutation graph can be defined as an intersection graph of segments whose
endpoints lie on two parallel lines $\ell_1$ and $\ell_2$, one on each. A
bipartite permutation graph is a permutation graph which is bipartite.
</p>
<p>In the the bipartite permutation vertex deletion problem we ask for a given
$n$-vertex graph, whether we can remove at most $k$ vertices to obtain a
bipartite permutation graph. This problem is NP-complete but it does admit an
FPT algorithm parameterized by $k$.
</p>
<p>In this paper we study the kernelization of this problem and show that it
admits a polynomial kernel with $O(k^{99})$ vertices.
</p></div>
    </summary>
    <updated>2021-11-30T22:38:23Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-11-30T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.13989</id>
    <link href="http://arxiv.org/abs/2111.13989" rel="alternate" type="text/html"/>
    <title>Clustering Geometrically-Modeled Points in the Aggregated Uncertainty Model</title>
    <feedworld_mtime>1638230400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Keikha:Vahideh.html">Vahideh Keikha</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Aghamolaei:Sepideh.html">Sepideh Aghamolaei</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mohades:Ali.html">Ali Mohades</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Ghodsi:Mohammad.html">Mohammad Ghodsi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.13989">PDF</a><br/><b>Abstract: </b>The $k$-center problem is to choose a subset of size $k$ from a set of $n$
points such that the maximum distance from each point to its nearest center is
minimized. Let $Q=\{Q_1,\ldots,Q_n\}$ be a set of polygons or segments in the
region-based uncertainty model, in which each $Q_i$ is an uncertain point,
where the exact locations of the points in $Q_i$ are unknown. The geometric
objects segments and polygons can be models of a point set. We define the
uncertain version of the $k$-center problem as a generalization in which the
objective is to find $k$ points from $Q$ to cover the remaining regions of $Q$
with minimum or maximum radius of the cluster to cover at least one or all
exact instances of each $Q_i$, respectively. We modify the region-based model
to allow multiple points to be chosen from a region and call the resulting
model the aggregated uncertainty model. All these problems contain the point
version as a special case, so they are all NP-hard with a lower bound 1.822. We
give approximation algorithms for uncertain $k$-center of a set of segments and
polygons. We also have implemented some of our algorithms on a data-set to show
our theoretical performance guarantees can be achieved in practice.
</p></div>
    </summary>
    <updated>2021-11-30T22:58:28Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2021-11-30T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.13986</id>
    <link href="http://arxiv.org/abs/2111.13986" rel="alternate" type="text/html"/>
    <title>Scheduling Appointments Online:\\ The Power of Deferred Decision-Making</title>
    <feedworld_mtime>1638230400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Devin Smedira, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shmoys:David_B=.html">David B. Shmoys</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.13986">PDF</a><br/><b>Abstract: </b>The recently introduced online Minimum Peak Appointment Scheduling (MPAS)
problem is a variant of the online bin-packing problem that allows for deferred
decision making. Specifically, it allows for the problem to be split into an
online phase where a stream of appointment requests arrive requiring a
scheduled time, followed by an offline phase where those appointments are
scheduled into rooms. Similar to the bin-packing problem, the aim is to use the
minimum number of rooms in the final configuration. This model more accurately
captures scheduling appointments than bin packing. For example, a dialysis
patient needs to know what time to arrive for an appointment, but does not need
to know the assigned station ahead of time.
</p>
<p>Previous work developed a randomized algorithm for this problem which
achieved an asymptotic competitive ratio of at most 1.5, proving that online
MPAS was fundamentally different from the online bin-packing problem. Our main
contribution is to develop a new randomized algorithm for the problem that
achieves an asymptotic competitive ratio under 1.455, indicating the potential
for further progress. This improvement is attained by modifying the process for
scheduling appointments to increase the density of the packing in the worst
case, along with utilizing the dual of the bin-packing linear programming
relaxation to perform the analysis. We also present the first known lower bound
of 1.2 on the asymptotic competitive ratio of both deterministic and randomized
online MPAS algorithm. These results demonstrate how deferred decision-making
can be leveraged to yield improved worst-case performance, a phenomenon which
should be investigated in a broader class of settings.
</p></div>
    </summary>
    <updated>2021-11-30T22:48:56Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-11-30T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.13985</id>
    <link href="http://arxiv.org/abs/2111.13985" rel="alternate" type="text/html"/>
    <title>Projection-based Classification of Surfaces for 3D Human Mesh Sequence Retrieval</title>
    <feedworld_mtime>1638230400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pierson:Emery.html">Emery Pierson</a>, Juan-Carlos Alvarez Paiva, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Daoudi:Mohamed.html">Mohamed Daoudi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.13985">PDF</a><br/><b>Abstract: </b>We analyze human poses and motion by introducing three sequences of easily
calculated surface descriptors that are invariant under reparametrizations and
Euclidean transformations. These descriptors are obtained by associating to
each finitely-triangulated surface two functions on the unit sphere: for each
unit vector u we compute the weighted area of the projection of the surface
onto the plane orthogonal to u and the length of its projection onto the line
spanned by u. The L2 norms and inner products of the projections of these
functions onto the space of spherical harmonics of order k provide us with
three sequences of Euclidean and reparametrization invariants of the surface.
The use of these invariants reduces the comparison of 3D+time surface
representations to the comparison of polygonal curves in R^n. The experimental
results on the FAUST and CVSSP3D artificial datasets are promising. Moreover, a
slight modification of our method yields good results on the noisy CVSSP3D real
dataset.
</p></div>
    </summary>
    <updated>2021-11-30T22:49:36Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2021-11-30T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.13936</id>
    <link href="http://arxiv.org/abs/2111.13936" rel="alternate" type="text/html"/>
    <title>Is Causal Reasoning Harder than Probabilistic Reasoning?</title>
    <feedworld_mtime>1638230400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Milan Mossé, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Ibeling:Duligur.html">Duligur Ibeling</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Icard:Thomas.html">Thomas Icard</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.13936">PDF</a><br/><b>Abstract: </b>Many tasks in statistical and causal inference can be construed as problems
of \emph{entailment} in a suitable formal language. We ask whether those
problems are more difficult, from a computational perspective, for
\emph{causal} probabilistic languages than for pure probabilistic (or
"associational") languages. Despite several senses in which causal reasoning is
indeed more complex -- both expressively and inferentially -- we show that
causal entailment (or satisfiability) problems can be systematically and
robustly reduced to purely probabilistic problems. Thus there is no jump in
computational complexity. Along the way we answer several open problems
concerning the complexity of well known probability logics, in particular
demonstrating the $\exists\mathbb{R}$-completeness of a polynomial probability
calculus, as well as a seemingly much simpler system, the logic of comparative
conditional probability.
</p></div>
    </summary>
    <updated>2021-11-30T22:37:27Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2021-11-30T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.13912</id>
    <link href="http://arxiv.org/abs/2111.13912" rel="alternate" type="text/html"/>
    <title>On approximating shortest paths in weighted triangular tessellations</title>
    <feedworld_mtime>1638230400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bose:Prosenjit.html">Prosenjit Bose</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Esteban:Guillermo.html">Guillermo Esteban</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Orden:David.html">David Orden</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Silveira:Rodrigo_I=.html">Rodrigo I. Silveira</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.13912">PDF</a><br/><b>Abstract: </b>We study the quality of weighted shortest paths when a continuous
2-dimensional space is discretized by a weighted triangular tessellation. In
order to evaluate how well the tessellation approximates the 2-dimensional
space, we study three types of shortest paths: a weighted shortest path~$
\mathit{SP_w}(s,t) $, which is a shortest path from $ s $ to $ t $ in the
space; a weighted shortest vertex path $ \mathit{SVP_w}(s,t) $, which is a
shortest path where the vertices of the path are vertices of the tessellation;
and a weighted shortest grid path~$ \mathit{SGP_w}(s,t) $, which is a shortest
path whose edges are edges of the tessellation. The ratios $ \frac{\lVert
\mathit{SGP_w}(s,t)\rVert}{\lVert \mathit{SP_w}(s,t)\rVert} $, $ \frac{\lVert
\mathit{SVP_w}(s,t)\rVert}{\lVert \mathit{SP_w}(s,t)\rVert} $, $ \frac{\lVert
\mathit{SGP_w}(s,t)\rVert}{\lVert \mathit{SVP_w}(s,t)\rVert} $ provide
estimates on the quality of the approximation.
</p>
<p>Given any arbitrary weight assignment to the faces of a triangular
tessellation, we prove upper and lower bounds on the estimates that are
independent of the weight assignment. Our main result is that $ \frac{\lVert
\mathit{SGP_w}(s,t)\rVert}{\lVert \mathit{SP_w}(s,t)\rVert} =
\frac{2}{\sqrt{3}} \approx 1.15 $ in the worst case, and this is tight.
</p></div>
    </summary>
    <updated>2021-11-30T22:50:55Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2021-11-30T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.13762</id>
    <link href="http://arxiv.org/abs/2111.13762" rel="alternate" type="text/html"/>
    <title>A Note on Sanitizing Streams with Differential Privacy</title>
    <feedworld_mtime>1638230400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kaplan:Haim.html">Haim Kaplan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Stemmer:Uri.html">Uri Stemmer</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.13762">PDF</a><br/><b>Abstract: </b>The literature on data sanitization aims to design algorithms that take an
input dataset and produce a privacy-preserving version of it, that captures
some of its statistical properties. In this note we study this question from a
streaming perspective and our goal is to sanitize a data stream. Specifically,
we consider low-memory algorithms that operate on a data stream and produce an
alternative privacy-preserving stream that captures some statistical properties
of the original input stream.
</p></div>
    </summary>
    <updated>2021-11-30T22:39:04Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-11-30T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.13748</id>
    <link href="http://arxiv.org/abs/2111.13748" rel="alternate" type="text/html"/>
    <title>A Unified Framework of Light Spanners II: Fine-Grained Optimality</title>
    <feedworld_mtime>1638230400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Le:Hung.html">Hung Le</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Solomon:Shay.html">Shay Solomon</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.13748">PDF</a><br/><b>Abstract: </b>Seminal works on light spanners over the years provide spanners with optimal
lightness in various graph classes, such as in general graphs, Euclidean
spanners, and minor-free graphs. Three shortcomings of previous works on light
spanners are: (1) The techniques are ad hoc per graph class, and thus can't be
applied broadly. (2) The runtimes of these constructions are almost always
sub-optimal, and usually far from optimal. (3) These constructions are optimal
in the standard and crude sense, but not in a refined sense that takes into
account a wider range of involved parameters.
</p>
<p>This work aims at addressing these shortcomings by presenting a unified
framework of light spanners in a variety of graph classes. Informally, the
framework boils down to a transformation from sparse spanners to light
spanners; since the state-of-the-art for sparse spanners is much more advanced
than that for light spanners, such a transformation is powerful. Our framework
is developed in two papers. The current paper is the second of the two -- it
builds on the basis of the unified framework laid in the first paper, and then
strengthens it to achieve more refined optimality bounds for several graph
classes. Among various applications and implications of our framework, we
highlight here the following:
</p>
<p>For $K_r$-minor-free graphs, we provide a $(1+\epsilon)$-spanner with
lightness $\tilde{O}_{r,\epsilon}( \frac{r}{\epsilon} + \frac{1}{\epsilon^2})$,
improving the lightness bound $\tilde{O}_{r,\epsilon}( \frac{r}{\epsilon^3})$
of Borradaile, Le and Wulff-Nilsen. We complement our upper bound with a lower
bound construction, for which any $(1+\epsilon)$-spanner must have lightness
$\Omega(\frac{r}{\epsilon} + \frac{1}{\epsilon^2})$. We note that the quadratic
dependency on $1/\epsilon$ we proved here is surprising, as the prior work
suggested that the dependency on $\epsilon$ should be $1/\epsilon$.
</p></div>
    </summary>
    <updated>2021-11-30T22:43:11Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-11-30T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/11/29/assistant-professor-at-university-of-toronto-apply-by-january-10-2022/</id>
    <link href="https://cstheory-jobs.org/2021/11/29/assistant-professor-at-university-of-toronto-apply-by-january-10-2022/" rel="alternate" type="text/html"/>
    <title>Assistant Professor at University of Toronto (apply by January 10, 2022)</title>
    <summary>The Department of Computer Science at the University of Toronto is conducting three open-area searches for full-time tenure stream positions. The appointment will be at the rank of Assistant Professor and will commence on July 1, 2022, or shortly thereafter. We start reviewing applications on December 6, 2021. Website: https://academicjobsonline.org/ajo/jobs/19687 Email: recruit@cs.toronto.edu</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Department of Computer Science at the University of Toronto is conducting three open-area searches for full-time tenure stream positions. The appointment will be at the rank of Assistant Professor and will commence on July 1, 2022, or shortly thereafter. We start reviewing applications on December 6, 2021.</p>
<p>Website: <a href="https://academicjobsonline.org/ajo/jobs/19687">https://academicjobsonline.org/ajo/jobs/19687</a><br/>
Email: recruit@cs.toronto.edu</p></div>
    </content>
    <updated>2021-11-29T16:38:44Z</updated>
    <published>2021-11-29T16:38:44Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-12-01T04:20:34Z</updated>
    </source>
  </entry>

  <entry>
    <id>http://benjamin-recht.github.io/2021/11/29/cluster-power/</id>
    <link href="http://benjamin-recht.github.io/2021/11/29/cluster-power/" rel="alternate" type="text/html"/>
    <title>The cult of statistical significance and the Bangladesh Mask RCT.</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>In the last post, <a href="https://www.argmin.net/2021/11/23/mask-rct-revisited/">I argued that the effect size in the Bangladesh Mask RCT was too small to inform policy making</a>. I deliberately avoided diving into statistical significance as arguments about p-values quickly devolve into scientific gish gallop. Statistical validity is the most overrated form of experimental validity, and it crowds out more important questions of effect size, bias, design, and applicability.</p>

<p>But shoot, sometimes Byzantine academic arguments are fun. And, though they are always wrong, sometimes they are useful. In this blog I want to discuss how we analyze statistical validity in cluster randomized controlled trials. It is quite subtle and sensitive, and should give us pause about these experimental designs. The sample sizes needed for validating large effects in cluster randomized trials can be absurdly high, and running a clean trial with millions of participants is likely impossibly difficult and almost never worth doing.</p>

<p>To review in the <a href="https://www.poverty-action.org/sites/default/files/publications/Mask_Second_Stage_Paper_20211108.pdf.pdf">Bangladesh Mask RCT</a> there were $n_C=$163,861 individuals from $k_C=$300 villages in the control group. There were $n_T=$178,322 individuals from $k_T=$300 villages in the intervention group. The main end point of the study was whether their intervention reduced the number of individuals who reported covid-like symptoms and tested seropositive at some point during the trial. There were $i_C=$1,106 symptomatic individuals confirmed seropositive in the control group and $i_T=$1,086 such individuals in the treatment group.</p>

<p>What can we say about the statistical significance of this 20 case difference? Most would guess this difference is not significant. Indeed, in a balanced design with $n_T=n_C$ and 180,000 individuals in each arm, this study would not be statistically significant. Let’s imagine we ran an experiment where we could treat the outcomes of each individual as independent, identically distributed random variables. What is the p-value associated with the null hypothesis that the prevalence of infections in the control group is less than or equal to the prevalence in the treatment group? A simple statistical test of this hypothesis is the z-test for proportions. For the z-test, the p-value when the groups are balanced is 0.3.</p>

<p>The authors claim a balanced design, but, though the number of treatment and control villages are indeed equal, the number of <em>individuals</em> in the treatment group is 1.1x bigger than the control group. <a href="https://www.argmin.net/2021/11/23/mask-rct-revisited/">As I mentioned in the previous post</a>, this discrepancy can likely be explained by the large differential in response rates between the groups: 1.05x fewer households were approached for surveys in control and the control group responded at 1.07x lower rate than treatment. The most significant difference between the treatment and control group may very well be the consent rate of the household survey. For the medical statistics experts, <a href="https://en.wikipedia.org/wiki/Intention-to-treat_analysis">the intention to treat principle</a> says that the  individuals who are unreachable or who refuse to be surveyed must be counted in the study. Omitting them invalidates the study.</p>

<p>But the issues of significance remain even if we forgive this large imbalance in the study. If we re-run the z-test with the $n_C$ and $n_T$ in the study data, the p-value is now 0.009, which would be quite significant at the standard p &lt; 0.05 threshold. However, the individual outcomes are <em>not</em> independent. The trial was cluster-randomized, so everyone in the same village received the same intervention. This means that the outcomes inside a village are correlated, and they are likely more correlated inside a village than outside.</p>

<p>To capture the correlation among intra-cluster participants, statisticians use the notion of the <a href="https://www.povertyactionlab.org/resource/power-calculations"><em>intra-cluster correlation coefficient</em></a> $\rho$. $\rho$ is a scalar between 0 and 1 that measures the relative variance within clusters and between clusters. When $\rho=1$, all of the responses in each cluster are identical. When $\rho=0$, the clustering has no effect, and we can treat our assignment as purely randomized. Once we know $\rho$ we can compute an <em>effective sample size</em>: if the villages are completely correlated, the number of samples in the study would be 600. If they were independent, the number of samples would be over 340,000. The number of effective samples is equal to the total number of samples divided by the <em>design effect</em>:</p>

\[{\small
    DE = 1+\left(\frac{n_T+n_C}{k_T+k_C}-1\right)\rho \,.
}\]

<p>What is the design effect of the Bangladesh RCT? Measuring the intra-cluster correlation $\rho$ is nontrivial: the true value of $\rho$ depends on both potential outcomes in an experiment and needs to be estimated using some side experiment or previous trials at baseline. $\rho$ is often inferred from secondary covariates of earlier experiments on a similar population. We don’t have a pre-specified estimate, but can cheat a bit here and estimate $\rho$ from the provided data in the control villages. A standard ANOVA calculation says that the observed symptomatic seropositivity in the control villages has an intra-village correlation of $\rho=$0.007. This value isn’t particularly unreasonable. Some practitioners suggest that because of behavioral contagion alone, $\rho$ should be <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1466680">between 0.01 and 0.02 for human studies.</a> <a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0013998#pone.0013998-Carrat2">This cluster RCT on mask use to prevent influenza in households</a> uses $\rho=$0.24.  As a sanity check, the intra-village correlation of reported systems is 0.03. So let’s stick with $\rho=$0.007 and see where it takes us.</p>

<p>For the Bangladesh RCT, assuming $\rho=$0.007, the design effect is about 5. This reduces the effective sample size from over 340,000 to just under 70,000. What happens with our z-test? We simply take the z-score and divide by the square root of the design effect, yielding a p-value of 0.14. The result is not statistically significant once we take into account the intra-cluster correlation. In order to “achieve” statistical significance, $\rho$ would need to be less than 0.001 and the design effect would have to be less than 2.2.</p>

<p>We can also do similar design-effect adjustments for relative risk reduction. Recall the relative risk reduction is the ratio of the rate of infection in the treatment group to the rate of infection in the control group</p>

\[{\small
    RR = \frac{i_T/n_T}{i_C/n_C}\,.
}\]

<p>A small $RR$ corresponds to a large reduction in risk. For the mask study, the estimated risk reduction is $RR=$0.9.  If the assignments of every individual to treatment and control were random, we could compute error bars on the log of the risk ratio. The log risk ratio is</p>

\[{\small
    \ell RR = \log \frac{i_T/n_T}{i_C/n_C}\,,
}\]

<p>and <a href="https://en.wikipedia.org/wiki/Relative_risk#Inference">a standard estimate of the standard error $SE$ of $\ell RR$</a> is</p>

\[{\small
    SE = \sqrt{ \frac{1}{i_T} + \frac{1}{i_C} - \frac{1}{n_T}- \frac{1}{n_C}}\,.
}\]

<p>In the mask study, $SE=$0.043. Using a Gaussian approximation, our confidence interval would then be</p>

\[{\scriptsize
    [\exp(\ell RR - 1.96 SE), \exp(\ell RR + 1.96 SE)] = [0.83, 0.98]\,.
}\]

<p>The way we interpret the confidence interval (and I’ll likely screw this up) is that if the Gaussian approximation were true, and all of the individual assignments to treatment and control were independent, and we repeated the experiment many times, the true risk ratio would fall inside the confidence interval 95% of the time. This calculation suggests that the confidence interval (barely) excludes a risk ratio of 1. However, this calculation does not take into account the cluster effects.  Assuming again that $\rho=$0.007, when we adjust our confidence intervals for cluster effects, we get the larger interval</p>

\[{\scriptsize
    \left[\exp(\ell RR - 1.96 SE \sqrt{DE}), \exp(\ell RR + 1.96 SE \sqrt{DE} )\right] = [0.75, 1.09]\,.
}\]

<p>Again, a standard cluster RCT analysis would not be able to reject a null effect for the complex masking intervention. In terms of my most-loathed statistic of efficacy, the confidence interval ranges from -9% to 25% after adjustment.</p>

<p>Note that even the strong claims made in the paper about subgroups are not significant once intra-cluster correlation is accounted for. A commonly quoted result is that surgical masks dramatically reduced infections for individuals over 60 years old. In this case, $n_C =$14,826, $n_T$=16,088, $i_C=$157 and $i_T=$124. The estimated effectiveness is 27%. However, with a design effect of 5, the p-value for the z-test here is 0.13 and the confidence intervals for the efficacy are -23% to 57%. So again, one can’t rest on statistical significance to argue this effect is real.</p>

<p>As a last statistical grumble, all of these corrections don’t even account for the multiple hypothesis testing in the manuscript where nearly 200 hypotheses were evaluated. <strong>After a <a href="https://en.wikipedia.org/wiki/Bonferroni_correction">Bonferroni correction</a> and accounting for design effect, none of the p-values would be less than 0.5.</strong></p>

<p>How large would the trial have to be in order to have statistical significance? We can focus on the z-test, and ask how many samples would be needed to reject the null hypothesis 95% of the time when the relative risk is 0.9, the prevalence in the control group is 0.076, and the intra-cluster correlation is 0.007. The answer is <strong><em>1.1 million people</em></strong>, over 3 times larger than the actual study size.</p>

<p>When a power calculation reveals a trial needs more than a million subjects, researchers need to pause to think if they are asking the right question. It is likely impossible to conduct a precise experiment that rules out all confounding at such a scale. The number of people needed to run such a trial is huge, and maintaining data quality would be both prohibitively difficult and expensive. Any trial has potential harms to its subjects, and the larger the sample size, the more likely harm may occur. Ensuring beneficence and informed consent at this scale is likely impossible. And if one really expects the clinical significance to be this small, why invest all of these resources into running an RCT instead of looking for more powerful interventions?</p>

<p><em>For those interested in seeing how I computed all of the numbers in this post and the <a href="https://www.argmin.net/2021/11/23/mask-rct-revisited/">last post</a>, <a href="https://nbviewer.jupyter.org/url/argmin.net/code/revisiting-bd-mask-rct.ipynb">here is a Jupyter notebook.</a></em></p></div>
    </summary>
    <updated>2021-11-29T00:00:00Z</updated>
    <published>2021-11-29T00:00:00Z</published>
    <source>
      <id>http://benjamin-recht.github.io/</id>
      <author>
        <name>Ben Recht</name>
      </author>
      <link href="http://benjamin-recht.github.io/" rel="alternate" type="text/html"/>
      <link href="http://benjamin-recht.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Musings on systems, information, learning, and optimization.</subtitle>
      <title>arg min blog</title>
      <updated>2021-11-30T23:00:59Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-6105624713426867173</id>
    <link href="http://blog.computationalcomplexity.org/feeds/6105624713426867173/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2021/11/open-4-colorability-for-graphs-of.html#comment-form" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/6105624713426867173" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/6105624713426867173" rel="self" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2021/11/open-4-colorability-for-graphs-of.html" rel="alternate" type="text/html"/>
    <title>Open: 4  colorability for graphs of bounded genus or bounded crossing number (has this been asked before?)</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p> I have  co-authored (with Nathan Hayes, Anthony Ostuni, Davin Park) an open problems column  on the topic of this post. It is <a href="https://www.cs.umd.edu/users/gasarch/open/cross.pdf">here</a>.</p><p>Let g(G) be the genus of a graph and cr(G) be the crossing number of a graph.</p><p>As usual chi(G) is the chromatic number of a graph. </p><p>KNOWN to most readers of this blog:</p><p>{G: \chi(G) \le 2} is in P</p><p>{G: \chi(G) \le 3 and g(G)\le 0 } is NPC (planar graph 3-col)</p><p>{G : \chi(G) \le 4 and g(G) \le 0} is in P (it's trivial since all planar graphs are 4-col)</p><p>{G: \chi(G) \le 3 and cr(G) \le 0} is NPC (planar graph 3-col)</p><p>{G: \chi(G) \le 4 and cr(G) \le 0} is in P (trivial since all planar graphs are 4-col)</p><p>LESS WELL KNOWN BUT TRUE (and brought to my attention by my co-authors and also Jacob Fox and Marcus Schaefer) </p><p>For all g\ge 0 and r\ge 5, {G : \chi(G) \le r and g(G) \le g} is in P</p><p>For all c\ge 0 and r\ge 5, {G : \chi(G) \le r and cr(G) \le c} is in P </p><p>SO I asked the question: for various r,g,c what is the complexity of the following sets:</p><p>{G: \chi(G) \le r AND g(G) \le g} </p><p>{G: \chi(G) \le r AND cr(G) \le c}</p><p>SO I believe the status of the following sets is open</p><p>{G : \chi(G) \le 4 and g(G)\le 1} (replace 1 with 2,3,4,...)</p><p>{G : \chi(G) \le 4 and cr(G)\le 1} (replace 1 with 2,3,4...) </p><p><br/></p><p>QUESTIONS</p><p>1) If anyone knows the answer to these open questions, please leave comments. </p><p>2) The paper pointed to above mentions all of the times I read of someone asking questions like this. There are not many, and the problem does not seem to be out there. Why is that?</p><p>a) It's hard to find out who-asked-what-when. Results are published, open problems often are not. My SIGACT News open problems column gives me (and others) a chance to write down open problems; however, such venues are rare. So it's possible that someone without a blog or an open problems column raised these questions before. (I checked cs stack exchange- not there- and I posted there but didn't get much of a response.) </p><p>b) Proving NPC seems hard since devising gadgets with only one crossing is NOT good enough since you use the gadget many times. This may have discouraged people from thinking about it. </p><p>c) Proving that the problems are in P (for the r\ge 6 case) was the result of using a hard theorem in graph theory from 2007. The authors themselves did not notice the algorithmic result. The first published account of the algorithmic result might be my open problems column.  This may be a case of the graph theorists and complexity theorists not talking to each other, though that is surprising since there is so much overlap that I thought there was no longer a distinction. </p><p>d) While I think this is a natural question to ask, I may be wrong. See <a href="https://blog.computationalcomplexity.org/2021/05/what-is-natural-question-who-should.html">here</a> for a blog post about when I had a natural question and found out why I may be wrong about the problems naturalness. </p><p><br/></p></div>
    </content>
    <updated>2021-11-28T21:47:00Z</updated>
    <published>2021-11-28T21:47:00Z</published>
    <author>
      <name>gasarch</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03004932739846901628</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="http://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2021-11-30T21:06:41Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/170</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/170" rel="alternate" type="text/html"/>
    <title>TR21-170 |  Pseudorandom Self-Reductions for NP-Complete Problems | 

	Reyad Abed Elrazik, 

	Robert Robere, 

	Assaf Schuster, 

	Gal Yehuda</title>
    <summary>A language $L$ is random-self-reducible if deciding membership in $L$ can be reduced (in polynomial time) to deciding membership in $L$ for uniformly random instances. It is known that several "number theoretic" languages (such as computing the permanent of a matrix) admit random self-reductions. Feigenbaum and Fortnow showed that NP-complete languages are not non-adaptively random-self-reducible unless the polynomial-time hierarchy collapses, giving suggestive evidence that NP may not admit random self-reductions. Hirahara and Santhanam introduced a weakening of random self-reductions that they called pseudorandom self-reductions, in which a language $L$ is reduced to a distribution that is computationally indistinguishable from the uniform distribution. They then showed that the Minimum Circuit Size Problem (MCSP) admits a non-adaptive pseudorandom self-reduction, and suggested that this gave further evidence that MCSP is "distinguished" from standard NP-Complete problems.

We show that, in fact, the NP-Complete Clique problem admits a non-adaptive pseudorandom self-reduction, assuming the planted clique conjecture. More generally we show the following. Call a property of graphs $\pi$ hereditary if $G \in \pi$ implies $H \in \pi$ for every induced subgraph of $G$. We show that for any infinite hereditary property $\pi$, the problem of finding a maximum induced subgraph $H \in \pi$ of a given graph $G$ admits a non-adaptive pseudorandom self-reduction.</summary>
    <updated>2021-11-28T10:18:31Z</updated>
    <published>2021-11-28T10:18:31Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-12-01T04:20:24Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://tcsplus.wordpress.com/?p=585</id>
    <link href="https://tcsplus.wordpress.com/2021/11/25/tcs-talk-wednesday-december-1-william-kuszmaul-mit/" rel="alternate" type="text/html"/>
    <title>TCS+ talk: Wednesday, December 1 — William Kuszmaul, MIT</title>
    <summary>The next TCS+ talk will take place this coming Wednesday, December 1th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 18:00 UTC). William Kuszmaul from MIT will speak about “Linear Probing Revisited: Tombstones Mark the Demise of Primary Clustering” (abstract below). You can reserve a spot as an individual or […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The next TCS+ talk will take place this coming Wednesday, December 1th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 18:00 UTC). <a href="https://sites.google.com/site/williamkuszmaul"><strong>William Kuszmaul</strong></a> from MIT will speak about “<em>Linear Probing Revisited: Tombstones Mark the Demise of Primary Clustering</em>” (abstract below).</p>
<p>You can reserve a spot as an individual or a group to join us live by signing up on <a href="https://sites.google.com/view/tcsplus/welcome/next-tcs-talk">the online form</a>. Registration is <em>not</em> required to attend the interactive talk, and the link will be posted on the website the day prior to the talk; however, by registering in the form, you will receive a reminder, along with the link. (The recorded talk will also be posted <a href="https://sites.google.com/view/tcsplus/welcome/past-talks">on our website</a> afterwards) As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/view/tcsplus/welcome/suggest-a-talk">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/view/tcsplus/">the website</a>.</p>
<blockquote class="wp-block-quote"><p>Abstract: The linear-probing hash table is one of the oldest and most widely used data structures in computer science. However, linear probing also famously comes with a major drawback: as soon as the hash table reaches a high memory utilization, elements within the hash table begin to cluster together, causing insertions to become slow. This phenomenon, now known as “primary clustering”, was first captured by Donald Knuth in 1963; at a load factor of <img alt="1 - 1/x" class="latex" src="https://s0.wp.com/latex.php?latex=1+-+1%2Fx&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/>, the expected time per insertion becomes <img alt="\Theta(x^2)" class="latex" src="https://s0.wp.com/latex.php?latex=%5CTheta%28x%5E2%29&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/>, rather than the more desirable <img alt="\Theta(x)" class="latex" src="https://s0.wp.com/latex.php?latex=%5CTheta%28x%29&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/>.</p>
<p>We show that there is more to the story than the classic analysis would seem to suggest. It turns out that small design decisions in how deletions are implemented have dramatic effects on the asymptotic performance of insertions. If these design decisions are made correctly, then even a hash table that is continuously at a load factor <img alt="1 - \Theta(1/x)" class="latex" src="https://s0.wp.com/latex.php?latex=1+-+%5CTheta%281%2Fx%29&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/> can achieve average insertion time <img alt="\tilde{O}(x)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctilde%7BO%7D%28x%29&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/>. A key insight is that the tombstones left behind by deletions cause a surprisingly strong “anti-clustering” effect, and that when insertions and deletions are one-for-one, the anti-clustering effects of deletions actually overpower the clustering effects of insertions.</p>
<p>We also present a new variant of linear probing, which we call “graveyard hashing”, that completely eliminates primary clustering on any sequence of operations. If, when an operation is performed, the current load factor is <img alt="1 - 1/x" class="latex" src="https://s0.wp.com/latex.php?latex=1+-+1%2Fx&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/> for some <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/>, then the expected cost of the operation is <img alt="O(x)" class="latex" src="https://s0.wp.com/latex.php?latex=O%28x%29&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/>. One corollary is that, in the external-memory model with a data block size of <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/>, graveyard hashing offers the following remarkable guarantee: at any load factor <img alt="1-1/x" class="latex" src="https://s0.wp.com/latex.php?latex=1-1%2Fx&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/> satisfying <img alt="x = o(B)" class="latex" src="https://s0.wp.com/latex.php?latex=x+%3D+o%28B%29&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/>, graveyard hashing achieves <img alt="1 + o(1)" class="latex" src="https://s0.wp.com/latex.php?latex=1+%2B+o%281%29&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/> expected block transfers per operation. Past external-memory hash tables have only been able to offer a <img alt="1+o(1)" class="latex" src="https://s0.wp.com/latex.php?latex=1%2Bo%281%29&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/> guarantee when the block size <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/> is at least <img alt="\Omega(x^2)" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega%28x%5E2%29&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/>.</p>
<p>Based on joint work with Michael A. Bender and Bradley C. Kuszmaul (<a href="https://tcsplus.wordpress.com/feed/_wp_link_placeholder">arXiv:2107.01250</a>). To appear in FOCS 2021.</p></blockquote></div>
    </content>
    <updated>2021-11-25T22:02:37Z</updated>
    <published>2021-11-25T22:02:37Z</published>
    <category term="Announcements"/>
    <author>
      <name>plustcs</name>
    </author>
    <source>
      <id>https://tcsplus.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://tcsplus.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://tcsplus.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://tcsplus.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://tcsplus.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A carbon-free dissemination of ideas across the globe.</subtitle>
      <title>TCS+</title>
      <updated>2021-12-01T04:21:06Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://rjlipton.wpcomstaging.com/?p=19356</id>
    <link href="https://rjlipton.wpcomstaging.com/2021/11/24/best-to-dean-mynatt/" rel="alternate" type="text/html"/>
    <title>Best To Dean Mynatt</title>
    <summary>Plus updates on gender disparity, equity, and POPL 2022 IPaT page Beth Mynatt is heading north to become the new Dean of Computer Science at Northeastern University. Georgia Tech will miss her; she has been a key part of Tech for over twenty years. Northeastern is getting a great leader, a valued colleague, and an […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Plus updates on gender disparity, equity, and POPL 2022</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2021/11/24/best-to-dean-mynatt/bm/" rel="attachment wp-att-19358"><img alt="" class="alignright wp-image-19358" height="150" src="https://i1.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/11/bm.png?resize=150%2C150&amp;ssl=1" width="150"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">IPaT <a href="https://news.gatech.edu/expert/elizabeth-mynatt">page</a></font></td>
</tr>
</tbody>
</table>
<p>
Beth Mynatt is heading north to become the new Dean of Computer Science at Northeastern University. Georgia Tech will miss her; she has been a key part of Tech for over twenty years. Northeastern is getting a great leader, a valued colleague, and an excellent PhD graduate of Georgia Tech.</p>
<p>
Today we hail her work on solving problems of <em>aging</em> and compare to what we do in theory. These musings wend toward solving problems of the kind raised in our previous <a href="https://rjlipton.wpcomstaging.com/2021/11/13/popl-2022-et-tu-brute/">post</a>, on which we have an update from POPL General Chair Rajeev Alur that comes full circle to a Dean at Northeastern.</p>
<p>
One aspect of aging is having a long memory of a field. When Ken and I were young, it was all about what humans can do with computers. Now it is much more about what computers can do with humans. <em>With</em> humans, not just <em>for</em> humans—the aspect of collaboration is key. </p>
<p>
</p><p/><h2> Aging… </h2><p/>
<p/><p>
Beth worked on various projects over her time at Tech. In 1999–2000, she was part of a team that launched the Aware Home Research Initiative (<a href="https://www.cc.gatech.edu/fce/house/house.html">AHRI</a>), “whose goal is to develop the requisite technologies to create a home environment that can both perceive and assist its occupants.” She has led the Institute of People and Technology (IPaT) since 2011, its inaugural year, where her team has helped to support numerous, impactful research programs for faculty across Georgia Tech. </p>
<p>
To show how leadership and persistent work pay dividends, she is a co-PI on a new multi-institution grant led by Tech’s Sonia Chernova to build intelligent systems that support aging. The five-year, $20 million grant from the National Science Foundation, sponsored also by Amazon and Google, will go to create the NSF AI Institute for Collaborative Assistance and Responsive Interaction for Networked Groups (<a href="http://ai-caring.org/">AI-CARING</a>). The <a href="https://www.cc.gatech.edu/news/649114/new-ai-institute-builds-tech-support-aging">announcement</a> says:</p>
<blockquote><p><b> </b> <em> The institute aims to develop new longitudinal, collaborative AI systems that work with aging adults including those diagnosed with mild cognitive impairment, and their caregivers. </em>
</p></blockquote>
<p/><p>
The AI-CARING front page says that they </p>
<blockquote><p><b> </b> <em> “will develop a discipline focused on personalized, longitudinal, collaborative AI, enabling the development of AI systems that learn personalized models of user behavior, understand how people’s behavior changes over time, and integrate that knowledge to support people and AIs working together. These networked Human-AI teams will work with elderly adults and their caregivers in order to provide sustainable long-term care solutions.” </em>
</p></blockquote>
<p>
</p><p>
As someone who is not young, I can definitely see why this is important. </p>
<p>
</p><p/><h2> Missed the … </h2><p/>
<p/><p>
I sometimes feel that we in theory have missed the boat. The issue is that our problems are weighty—P=NP anyone?—but they do not directly impact practical computing. The areas that Beth is interested in, such as <a href="https://en.wikipedia.org/wiki/Ubiquitous_computing">ubiquitous computing</a>, have by definition had a large impact on real computing. The snippet from MIT’s <a href="http://oxygen.csail.mit.edu/Overview.html">Project Oxygen</a> quoted by Wikipedia expresses the direction of impact:</p>
<blockquote><p><b> </b> <em> In the future, computation will be human centered. It will be freely available everywhere, like batteries and power sockets, or oxygen in the air we breathe. … [C]onfigurable generic devices, either handheld or embedded in the environment, will bring computation to us, whenever we need it and wherever we might be. … We won’t have to type, click, or learn new computer jargon. Instead, we’ll communicate naturally, using speech and gestures that describe our intent … and leave it to the computer to carry out our will. </em>
</p></blockquote>
<p/><p>
This may conjure a “Star Trek” vision, but some people already live with substantial parts of this reality. Is there a market for P=NP? On the “equals” side, we can think of a <a href="https://en.wikipedia.org/wiki/Sneakers_(1992_film)">couple</a> of <a href="https://en.wikipedia.org/wiki/Travelling_Salesman_(2012_film)">movies</a> featuring interested parties. For the “not equal” side, not so much?</p>
<p>
If pressed to think of a theory result that “launched a thousand ships” of practical effort, Peter Shor’s theorem about factoring belonging to quantum polynomial time springs to mind. But the ship of universal quantum computing needed to get it under steam won’t come in for decades.  It is <em>quantum devices with rudimentary computational features</em> that we see ruling in the meantime, while quantum communication protocols backed by quantum information theory are <a href="https://thequantuminsider.com/2021/06/23/11-global-banks-probing-the-wonderful-world-of-quantum-technologies/">banked on</a> now. </p>
<p>
</p><p/><h2> The Solutions Business </h2><p/>
<p/><p>
I, Ken writing from here, have often winced at the way the word “solutions” is used in business advertising. To a theorist, <em>solutions</em> are what make a conjecture become a theorem, what we grade in theory courses, what enjoyers of puzzles pursue for recreation. </p>
<p>
I described a <em>solution</em> of the more practical kind in my “Pandemic Lag” <a href="https://rjlipton.wpcomstaging.com/2021/07/30/pandemic-lag/">post</a> last July. It solves the problem of estimating the true current strength of rapidly developing young players (such as I was once) whose official ratings have been largely frozen for over a year and a half by the lack of in-person chess during the pandemic. Online play is not officially rated. </p>
<p>
For example, if a preteen’s frozen rating is <b>1575</b>, my formula will currently add 25 Elo points times 19 months of the pandemic to make <b>2050</b>. Players with higher ratings and longer track records are adjusted less. In some recent instances, when such kids have defeated players with more-established ratings near 2200, people seeing the 1500s rating in the official tournament table have raised questions. My answer is based on the average performance of <em>many</em> children keen enough to compete in similar-level championship events. Thus my computer-intensive studies are safeguarding the welfare of minors.</p>
<p>
</p><p/><h2> Gender Gap and Pipeline in Chess </h2><p/>
<p/><p>
My rating solution raises another problem of the kind addressed in our last <a href="https://rjlipton.wpcomstaging.com/2021/11/13/popl-2022-et-tu-brute/">post</a>. For a fresh instance, on Monday I submitted my final report on the European Team Championship. This ten-day tournament finished Sunday with the <a href="https://www.chess.com/news/view/alireza-firouzja-youngest-chess-player-ever-to-break-2800">sensation</a> of Alireza Firouzja becoming the youngest player ever rated over 2800, six months younger than world champion Magnus Carlsen was in 2009. (Carlsen will <a href="https://www.fide.com/news/1445">defend</a> his title starting Friday in Dubai against the Russian Ian Nepomniachtchi.)</p>
<p>
My intrinsic rating performance projections for the men’s/open section were all accurate to within 10 Elo points, within two-sigma error bars about <img alt="{\pm 25}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpm+25%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. When restricted to the 32 juniors (out of 191 total players) whose ratings I adjusted, all projections were within 23 Elo points of the results and their average was within <b>2</b> Elo points—on adjustments averaging 80 Elo points per the 32 players. </p>
<p>
In the women’s section, my gender-neutral formula adjusted up 39 of the 153 female players by an average of 169 Elo. The prescribed amount was larger because their ratings (average 2168) were lower than the 32 junior males’ ratings (average 2419) to begin with. The formula overshot their performance by 113 Elo, and accounted for the bulk of a 36 Elo average shortfall of my projections for the women’s section overall. This continues a pattern of observing not only a lower starting point, but also a lower first derivative when compared to males of the <em>same</em> rating, in tournaments with high junior participation where my adjustments are involved.</p>
<p>
The <em>Queen’s Gambit</em> miniseries magnified awareness of the disparity—witness the <a href="https://womensagenda.com.au/latest/whats-behind-the-gender-imbalance-in-top-level-chess/">article</a> a year ago by the Australian economist and grandmaster David Smerdon, “What’s behind the gender imbalance in top-level chess?” My work offers a new way to pinpoint when and where the male and female pipelines diverge. I do not see how it could <em>solve</em> the disparity, however. Even converting my big spreadsheets of test results into publications is a tall ask—for one, they are considered sensitive data. </p>
<p>
I have discoursed about the theory of my predictive model on this blog, and could say more about the thrill of empirical success in ways much of theory doesn’t reach. But this is still short of solving human problems in the manner of Dick’s intro, let alone solving the gender gap. On that, we’re grateful to have a communication from Rajeev Alur, General Chair of POPL, on how the statistics we noted came about and what the conference is doing.</p>
<p>
</p><p/><h2> More About POPL 2022 </h2><p/>
<p/><p>
Rajeev began by observing that POPL PCs in previous years have been closer to the percentages we quoted for STOC and FOCS: </p>
<ul>
<li>
2021: 15.4% (8/52) <p/>
</li><li>
2020: 14.8% (8/54) <p/>
</li><li>
2019: 11.5% (6/52) <p/>
</li><li>
2018: 23.1% (12/52) <p/>
</li><li>
2017: 17.2% (5/29) <p/>
</li><li>
2016: 21.4% (6/28) <p/>
</li><li>
2015: 20.0% (6/30)
</li></ul>
<p>
A more private figure that he gave us permission to divulge is that the proportion of PC <em>invitations</em> this year was just under 20% for women. Had they accepted at the same rate as the men, there would have been 12 women on the committee this year, as there was in the first year the PC size was expanded in 2018. </p>
<p>
He went on to note an issue also raised in comments to our last post, namely that among the smaller population of women the same people are asked multiple times, leading to more declines. We can put the scaling problem another way: nearly doubling the committee size in 2018 also doubled the ratio of women being invited to their total number. Not all effects of scaling-up keep equal proportion. The root cause of course is not only the smaller population but its smaller first derivative: as Rajeev noted, the latest figures from the Computing Research Association in 2019 show that out of 417 PhDs in POPL-core areas, only 42 (10%) were female.</p>
<p>
The main thing that they are doing is to take the kind of steps pointed up in the quotation from Valerie King in our post. As shown in the POPL 2022 Overview schedule on their <a href="https://popl22.sigplan.org/">front page</a>, they have special lunch and breakfast events for women and LGTBQ attendees (the latter held since <a href="https://popl20.sigplan.org/track/POPL-2020-lgbtq-lunch">2020</a>) and mentoring workshops for graduate and undergraduate level students. POPL 2022 is the first to appoint a special Chair for organizing these events, Jennifer Paykin, who we note gave a special quantum-for-POPL <a href="https://www.youtube.com/watch?v=nVMm0PrF-j8">presentation</a> in 2020. </p>
<p>
Next year’s POPL PC will be chaired by <a href="https://www.khoury.northeastern.edu/people/amal-ahmed/">Amal Ahmed</a>. Coincidentally, she is Associate Dean for Graduate Programs at Northeastern’s Khoury College where Beth Mynatt will be Dean. <a href="https://alexandrasilva.org/#/main.html">Alexandra Silva</a>, who was on the POPL 2020 PC and on the POPL 2021 Organizing Committee as Accessibility Chair, is one of three Keynote Speakers this year. Hope for the pipeline picking up was raised by the 2021 SIGPLAN Robin Milner Award for Junior Researchers going to <a href="https://homes.cs.washington.edu/~emina/">Emina Torlak</a> of UW. </p>
<p>
Of course, it will take a long time to translate the promotion of opportunity into closer parity. The low dip this year is what we noticed, but the long time effect is what our post highlighted at the end. Again we thank Rajeev for bringing both the time range and effort by SIGPLAN and POPL into greater context.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
We’ve tried to “zoom out” where theory people are used to zooming in. How can that change perspectives on our field?</p>
<p>
We are also thankful for how our field has branched out and wish everyone a happy Thanksgiving.</p>
<p/><p><br/>
[fixed name in POPL section]</p></font></font></div>
    </content>
    <updated>2021-11-25T04:48:54Z</updated>
    <published>2021-11-25T04:48:54Z</published>
    <category term="All Posts"/>
    <category term="chess"/>
    <category term="detection"/>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="People"/>
    <category term="aging"/>
    <category term="assistive computing"/>
    <category term="Beth Mynatt"/>
    <category term="Gender equity"/>
    <category term="gender gap"/>
    <category term="POPL 2022"/>
    <category term="Problems"/>
    <category term="projections"/>
    <category term="Rajeev Alur"/>
    <category term="solutions"/>
    <category term="Thanksgiving"/>
    <category term="Theory"/>
    <category term="women in computing"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wpcomstaging.com</id>
      <logo>https://s0.wp.com/i/webclip.png</logo>
      <link href="https://rjlipton.wpcomstaging.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wpcomstaging.com" rel="alternate" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel's Lost Letter and P=NP</title>
      <updated>2021-12-01T04:20:31Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-27705661.post-6494812234459505156</id>
    <link href="http://processalgebra.blogspot.com/feeds/6494812234459505156/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=27705661&amp;postID=6494812234459505156" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/6494812234459505156" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/6494812234459505156" rel="self" type="application/atom+xml"/>
    <link href="http://processalgebra.blogspot.com/2021/11/inria-innovation-prize-2021-to-mateescu.html" rel="alternate" type="text/html"/>
    <title>Inria Innovation Prize 2021 to Mateescu, Garavel, Lang and Serwe</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I just learnt that <a href="https://convecs.inria.fr/people/Radu.Mateescu/">Radu Mateescu</a>, <a href="http://convecs.inria.fr/people/Hubert.Garavel/">Hubert Garavel</a>, <a href="http://convecs.inria.fr/people/Frederic.Lang/">Frédéric Lang</a> and <a href="http://convecs.inria.fr/people/Wendelin.Serwe/">Wendelin Serwe</a> from the <a href="http://convecs.inria.fr/">Construction of Verified Concurrent Systems</a> (Convecs) project team at INRIA Grenoble – Rhône-Alpes Centre have been recently awarded the <a href="https://www.inria.fr/en/convecs-team-safety-modeling-distributed-parallel-systems" target="_blank">Inria Innovation Prize – Académie des sciences – Dassault Systèmes</a>. Their work contributes to the development of the <a href="https://cadp.inria.fr/" target="_blank">CADP toolbox</a> for modelling and verifying parallel and distributed systems. The aim of that project is to automatically detect design flaws in highly complex systems. </p><p>Readers of this blog will be as delighted as I am by this news. <a href="https://en.wikipedia.org/wiki/Construction_and_Analysis_of_Distributed_Processes" target="_blank">CADP</a> is one of the tools from the concurrency community that has the longest history, dating back to its early releases in 1989. It has been used to good effect in a variety of applications, is still under continuous development and makes excellent use  in practice of classic tools from concurrency theory. By way of example, let me mention the recent successes by the Convecs team in dealing with difficult challenges posed by <a href="http://ls5-www.cs.tu-dortmund.de/cms/de/mitarbeiter/prof/Bernhard_Steffen.html" target="_blank">Bernhard Steffen</a> and his team on the evaluation of CTL and LTL formulae on large products of automata. (See, for instance, the news items <a href="http://cadp.inria.fr/news12.html" target="_blank">here</a> and <a href="http://cadp.inria.fr/news13.html#section-3" target="_blank">here</a>.) Traditional model checkers fail on those challenges because the state space of the product automata is too large for them. However, a wise use of bisimulations and congruence results allows CADP to solve many of those challenges. Interested readers might also wish to peruse the slides at </p><ul style="text-align: left;"><li><a href="http://cadp.inria.fr/ftp/presentations/Mazzanti-RERS-18.pdf">http://cadp.inria.fr/ftp/presentations/Mazzanti-RERS-18.pdf</a> </li><li><a href="http://cadp.inria.fr/ftp/presentations/Lang-RERS-19.pdf">http://cadp.inria.fr/ftp/presentations/Lang-RERS-19.pdf</a> and</li><li><a href="http://cadp.inria.fr/ftp/presentations/Lang-RERS-20.pdf">http://cadp.inria.fr/ftp/presentations/Lang-RERS-20.pdf</a>. </li></ul>Congratulations to the whole CADP team and to the concurrency community for this award!</div>
    </content>
    <updated>2021-11-24T22:50:00Z</updated>
    <published>2021-11-24T22:50:00Z</published>
    <author>
      <name>Luca Aceto</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/01092671728833265127</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-27705661</id>
      <author>
        <name>Luca Aceto</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/01092671728833265127</uri>
      </author>
      <link href="http://processalgebra.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://processalgebra.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Papers I find interesting---mostly, but not solely, in Process Algebra---, and some fun stuff in Mathematics and Computer Science at large and on general issues related to research, teaching and academic life.</subtitle>
      <title>Process Algebra Diary</title>
      <updated>2021-11-25T09:25:45Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/169</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/169" rel="alternate" type="text/html"/>
    <title>TR21-169 |  Hypercontractivity on High Dimensional Expanders: a Local-to-Global Approach for Higher Moments | 

	Max Hopkins, 

	Mitali Bafna, 

	Tali Kaufman, 

	Shachar Lovett</title>
    <summary>Hypercontractivity is one of the most powerful tools in Boolean function analysis. Originally studied over the discrete hypercube, recent years have seen increasing interest in extensions to settings like the $p$-biased cube, slice, or Grassmannian, where variants of hypercontractivity have found a number of breakthrough applications including the resolution of Khot’s 2-2 Games Conjecture (Khot, Minzer, Safra FOCS 2018). In this work, we develop a new theory of hypercontractivity on high dimensional expanders (HDX), an important class of expanding complexes that has recently seen similarly impressive applications in both coding theory and approximate sampling. Our results lead to a new understanding of the structure of Boolean functions on HDX, including a tight analog of the KKL Theorem and a new characterization of non-expanding sets. 

Unlike previous settings satisfying hypercontractivity, HDX can be asymmetric, sparse, and very far from products, which makes the application of traditional proof techniques challenging. We handle these barriers with the introduction of two new tools of independent interest: a new explicit combinatorial Fourier basis for HDX that behaves well under restriction, and a new local-to-global method for analyzing higher moments. Interestingly, unlike analogous second moment methods that apply equally across all types of expanding complexes, our tools rely inherently on simplicial structure. This suggests a new distinction among high dimensional expanders based upon their behavior beyond the second moment.</summary>
    <updated>2021-11-24T08:19:32Z</updated>
    <published>2021-11-24T08:19:32Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-12-01T04:20:24Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/168</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/168" rel="alternate" type="text/html"/>
    <title>TR21-168 |  Hypercontractivity on High Dimensional Expanders: Approximate Efron-Stein Decompositions for $\epsilon$-Product Spaces | 

	Tom Gur, 

	Noam Lifshitz, 

	Siqi Liu</title>
    <summary>We prove hypercontractive inequalities on high dimensional expanders. As in the settings of the p-biased hypercube, the symmetric group, and the Grassmann scheme, our inequalities are effective for global functions, which are functions that are not significantly affected by a restriction of a small set of coordinates. As applications, we obtain Fourier concentration, small-set expansion, and Kruskal-Katona theorems for high dimensional expanders. Our techniques rely on a new approximate Efron-Stein decomposition for high dimensional link expanders.</summary>
    <updated>2021-11-24T08:10:52Z</updated>
    <published>2021-11-24T08:10:52Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-12-01T04:20:24Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/167</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/167" rel="alternate" type="text/html"/>
    <title>TR21-167 |  Post-Quantum Zero Knowledge, Revisited (or: How to Do Quantum Rewinding Undetectably) | 

	Alex Lombardi, 

	Fermi Ma, 

	Nicholas Spooner</title>
    <summary>A major difficulty in quantum rewinding is the fact that measurement is destructive: extracting information from a quantum state irreversibly changes it. This is especially problematic in the context of zero-knowledge simulation, where preserving the adversary's state is essential.
    
    In this work, we develop new techniques for quantum rewinding in the context of extraction and zero-knowledge simulation:
    
1. We show how to extract information from a quantum adversary by rewinding it without disturbing its internal state. We use this technique to prove that important interactive protocols, such as the Goldreich-Micali-Wigderson protocol for graph non-isomorphism and the Feige-Shamir protocol for NP, are zero-knowledge against quantum adversaries. 

2. We prove that the Goldreich-Kahan protocol for NP is post-quantum zero knowledge using a simulator that can be seen as a natural quantum extension of the classical simulator. 

Our results achieve (constant-round) black-box zero-knowledge with negligible simulation error, appearing to contradict a recent impossibility result due to Chia-Chung-Liu-Yamakawa (FOCS 2021). This brings us to our final contribution:

3. We introduce coherent-runtime expected quantum polynomial time, a computational model that (a) captures all of our zero-knowledge simulators, (b) cannot break any polynomial hardness assumptions, and (c) is not subject to the CCLY impossibility. In light of our positive results and the CCLY negative results, we propose coherent-runtime simulation to be the right quantum analogue of classical expected polynomial-time simulation.</summary>
    <updated>2021-11-23T11:09:07Z</updated>
    <published>2021-11-23T11:09:07Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-12-01T04:20:24Z</updated>
    </source>
  </entry>

  <entry>
    <id>http://benjamin-recht.github.io/2021/11/23/mask-rct-revisited/</id>
    <link href="http://benjamin-recht.github.io/2021/11/23/mask-rct-revisited/" rel="alternate" type="text/html"/>
    <title>Revisiting the Bangladesh Mask RCT.</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>In an earlier post, <a href="https://www.argmin.net/2021/09/13/effect-size/">I raised a few issues</a> with a <a href="https://www.poverty-action.org/sites/default/files/publications/Mask_Second_Stage_Paper_20211108.pdf.pdf">large-scale RCT run in Bangladesh aimed at estimating the effectiveness of masks on reducing the spread of the coronavirus</a>. In particular, I was a bit dismayed that the authors did not post the raw number of seropositive cases in their study, preventing me from computing standard statistical analyses of their results. I also objected to the number of statistical regressions run to pull signals out of a very complex intervention.</p>

<p>Recently, the authors were kind enough to release their <a href="https://gitlab.com/emily-crawford/bd-mask-rct">code and data</a>. I send nothing but kudos to them in this regard. Releasing code and data can help disambiguate questions that are not always answerable from papers alone. In fact, I was immediately able to answer my question by querying their data. In this post, I will walk through a simple analysis to estimate the efficacy of their proposed intervention.</p>

<p>In the Bangladesh Mask RCT, there were $n_C=$163,861 individuals from 300 villages in the control group. There were $n_T=$178,322 individuals from 300 villages in the intervention group. The main end point of the study was whether their intervention reduced the number of individuals who both reported covid-like symptoms and tested seropositive at some point during the trial. The number of such individuals appears nowhere in their paper, and one has to compute this from the data they kindly provided: There were $i_C=$1,106 symptomatic individuals confirmed seropositive in the control group and $i_T=$1,086 such individuals in the treatment group. The difference between the two groups was small: only <em>20 cases</em> out of over 340,000 individuals over a span of 8 weeks.</p>

<p>I have a hard time going from these numbers to the assured conclusions that “masks work” that was <a href="https://www.theatlantic.com/ideas/archive/2021/09/masks-were-working-all-along/619989/">promulgated</a> <a href="https://www.nature.com/articles/d41586-021-02457-y">by</a> <a href="https://www.nbcnews.com/science/science-news/largest-study-masks-yet-details-importance-fighting-covid-19-rcna1858">the</a> <a href="https://www.washingtonpost.com/world/2021/09/01/masks-study-covid-bangladesh/">media</a> or <a href="https://www.nytimes.com/2021/09/26/opinion/do-masks-work-for-covid-prevention.html">the authors</a> after this preprint appeared. This study was not blinded, as it’s impossible to blind a study on masks. The intervention was highly complex and included a mask promotion campaign and education about other mitigation measures including social distancing. Moreover, individuals were only added to the study if they consented to allow the researchers to visit and survey their household. There was a large differential between the control and treatment groups here, with 95% consenting in the treatment group but only 92% consenting in control. <em>This differential alone could wash away the difference in observed cases.</em> Finally, symptomatic seropositivity is a crude measure of covid as the individuals could have been infected before the trial began.</p>

<p>Given the numerous caveats and confounders, the study still only found a tiny effect size. My takeaway is that a complex intervention including an educational program, free masks, encouraged mask wearing, and surveillance in a poor country with low population immunity and no vaccination showed at best modest reduction in infection. I think this summary is fair to the study authors. And this is valuable information to have! It reaffirms my priors that non-pharmaceutical interventions are challenging to implement and have only modest benefits in the presence of a highly contagious respiratory infection. But your mileage may vary.</p>

<p>As I mentioned, of course, this was not the message that the majority of the media took away from this study. Instead we were told that this trial finally confirmed that masks worked. I think one of the key confusing points was <a href="http://www.argmin.net/2021/08/13/relative-risk/">using “efficacy” instead of relative risk</a> as a measure of intervention power.</p>

<p>One of the dark tricks of biostatistics is moving away from absolute case counts to  measures of risk such as relative risk reduction, efficacy, or the odds ratio. All of these measures are relative, and they tend to exaggerate effects. The relative risk reduction is the ratio of the rate of infection in the treatment group to the rate of infection in the control group</p>

\[{\small
    RR = \frac{i_T/n_T}{i_C/n_C}\,.
}\]

<p>A small $RR$ corresponds to a large reduction in risk. For the mask study, $RR=$0.9. That’s not a lot of risk reduction: in this study, community masking improved an individual’s risk of infection by a factor of only 1.1x. As a convenient comparator, the $RR$ in the MRNA vaccine trials was 0.05. In this case, vaccines reduce the risk of symptomatic infection by a factor of 20x.</p>

<p>The academic vaccine community unfortunately uses “efficacy” or “effectiveness” to describe relative risk reduction. <a href="http://www.argmin.net/xxx">Efficacy is a confusing, commonly misinterpreted metric</a>. Efficacy in a trial is one minus the relative risk reduction:</p>

\[{\small
EFF = 1-RR\,,
}\]

<p>reported as a percentage. So if the $RR=$0.9, then $EFF=$10%.</p>

<p>The important thing to realize about efficacy is that the range from 0% to 20% is barely better than nothing. Here, even a 20% efficacy corresponds to a reduction of risk by a factor of 1.25x. 1.25x is not literally nothing, but it’s also not enough to halt a highly contagious respiratory infection. For what it’s worth, a vaccine with 20% efficacy would not be approved. Another major flaw of using efficacy as a metric is that it is highly nonlinear. The difference between 10% and 20% efficacy is very small whereas the difference between 85% and 95% is huge, corresponding to a 7-fold and 20-fold risk reduction respectively. Efficacy is a nonlinear metric, but these percentages are bandied around as if they are linear effects, and this adds confusion to the public dialogue.</p>

<p class="center"><img alt="The relationship between effectiveness and risk reduction is highly nonlinear" src="http://www.argmin.net/assets/eff_v_rr.png" width="65%"/></p>

<p>To further dive into the absurdity of efficacy, let’s examine the claim that “cloth masks” worked less well than “surgical masks.” This is too strong an observation to be gleaned from the data. The preprint provides two stratified calculations to estimate the efficacy of types of masks. In the first case, the authors analyzed villages randomized to only be given surgical masks and their matched control villages. In this case there were 190 pairs of villages consisting of $n_C=$103,247 individuals in the control group and $n_T=$113,082 individuals in the treatment group. They observed $i_C=$774 symptomatic and seropositive individuals in the control group and $i_T=$756 symptomatic and seropositive individuals in the treatment group. <em>This is a difference of 18 individuals.</em> The corresponding efficacy is 11%, still woefully low.</p>

<p>We can do a similar analysis for the villages only given cloth masks. There were 96 pairs of villages consisting of $n_C=$53,691 individuals in the control group and $n_T=$57,415 individuals in the treatment group. They observed $i_C=$332 symptomatic and seropositive individuals in the control group and $i_T=$330 symptomatic and seropositive individuals in the treatment group. <em>This is a difference of only 2 individuals.</em> Certainly, no one would put much faith in an intervention where we see a difference of 2 cases in a study with over one hundred thousand people. However, to further demonstrate the absurdity of the notion of efficacy, the observed efficacy for cloth masks in this study is 7%. I think in many people’s minds, the difference between 7% and 11% is small. And 7% should be considered “no effect” as should 11%. <del>As a final absurd comparison, the study data shows cloth masks are more efficacious than purple surgical masks where the estimated efficacy is 0% ($n_C=$27,918, $n_T=$29,541, $i_C=$177, $i_T=$187)!</del> (<em>Ed note: turns out the purple masks were cloth. So the cloth purple masks did nothing, but the red masks “work.” Indeed, red masks were more effective than surgical masks!)</em> Certainly, comparing a bunch of such small effects is not telling us much.</p>

<p>Anyone who spends too much time around statisticians will note that I never once tried to compute a p-value for any of these results. As I’ve belabored, obsession with statistical significance distracts us from discussing effect sizes. We should be able to just look at the effect size and conclude the study did not find a significant impact of masks on coronavirus spread. We don’t need a p-value to tell us 10% efficacy is not helpful in this context. But it’s also important to note that you can’t just run a standard binomial test on this data because it is cluster-randomized and the subjects are anything but independent. <a href="http://www.argmin.net/2021/11/29/cluster-power/">In the next blog</a>, just for the sake of academic navel gazing, I’ll discuss the lack of statistical significance of this study and show why cluster randomized trials are inherently more challenging to interpret than standard RCTs.</p></div>
    </summary>
    <updated>2021-11-23T00:00:00Z</updated>
    <published>2021-11-23T00:00:00Z</published>
    <source>
      <id>http://benjamin-recht.github.io/</id>
      <author>
        <name>Ben Recht</name>
      </author>
      <link href="http://benjamin-recht.github.io/" rel="alternate" type="text/html"/>
      <link href="http://benjamin-recht.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Musings on systems, information, learning, and optimization.</subtitle>
      <title>arg min blog</title>
      <updated>2021-11-30T23:00:59Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-4583902398250806221</id>
    <link href="http://blog.computationalcomplexity.org/feeds/4583902398250806221/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2021/11/finding-element-with-nonadaptive.html#comment-form" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/4583902398250806221" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/4583902398250806221" rel="self" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2021/11/finding-element-with-nonadaptive.html" rel="alternate" type="text/html"/>
    <title>Finding an element with nonadaptive questions</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Suppose you have a non-empty subset S of {1,...N} and want to find an element of S. You can ask arbitrary questions of the form "Does S contain an element in A?" for some A a subset of {1,...N}. How many questions do you need?</p><p>Of course you can use binary search, using questions of the form "is there number greater than <i>m</i> in S?". This takes log N questions and it's easy to show that's tight.</p><p>What if you have to ask all the questions ahead of time before you get any of the answers? Now binary search won't work. If |S|=1 you can ask "is there a number in S whose <i>i</i>th bit is one?" That also takes log N questions.</p><p>For arbitrary S the situation is trickier. With randomness you still don't need too many questions. <a href="https://doi.org/10.1007/BF02579206">Mulmuley, Vazirani and Vazirani</a>'s isolating lemma works as follows: For each i &lt;= log N, pick a random weight w<sub>i</sub> between 1 and 2 log N. For each element m in S, let the weight of m be the sum of the weights of the bits of m that are 1. With probability at least 1/2 there will be an m with an unique minimum weight. There's a <a href="https://blog.computationalcomplexity.org/2015/07/new-proof-of-isolation-lemma.html">cool proof</a> of an isolating lemma by Noam Ta-Shma.</p><p>Once you have this lemma, you can ask questions of the form "Given a list of w<sub>i</sub>'s and a value v, is there an m in S of weight v whose jth bit is 1?" Choosing w<sub>i</sub> and v at random you have a 1/O(log N) chance of a single m whose weight is v, and trying all j will give you a witness. </p><p>Randomness is required. The X-search problem described by <a href="https://doi.org/10.1016/0022-0000(88)90027-X">Karp, Upfal and Wigderson</a> shows that any deterministic procedure requires essentially N queries. </p><p>This all came up because Bill had some colleagues looking a similar problems testing machines for errors. </p><p>I've been interested in the related question of finding satisfying assignments using non-adaptive NP queries. The results are similar to the above. In particular, you can randomly find a satisfying assignment with high probability using a polynomial number of non-adaptive NP queries. It follows from the techniques above, and even earlier papers, but I haven't been able to track down a reference for the first paper to do so.</p></div>
    </content>
    <updated>2021-11-22T20:39:00Z</updated>
    <published>2021-11-22T20:39:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="http://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2021-11-30T21:06:41Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://emanueleviola.wordpress.com/?p=964</id>
    <link href="https://emanueleviola.wordpress.com/2021/11/22/phd-in-complexity-theory-with-me/" rel="alternate" type="text/html"/>
    <title>PhD in complexity theory with me</title>
    <summary>This is around the time when people start applying for PhD programs, at least judging from my inbox. If you are applying, consider that we have an amazing theory group , are highly ranked, have tons of resources, and I am looking for students.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>This is around the time when people start applying for PhD programs, at least judging from my inbox.  If you are applying, consider that we have an <a href="https://www2.ccs.neu.edu/theory/">amazing theory group </a>, are <a href="http://csrankings.org/#/index?all&amp;us">highly ranked</a>, have <a href="https://philanthropynewsdigest.org/news/northeastern-receives-50-million-for-college-of-computer-sciences">tons </a>of <a href="https://mainestartupsinsider.com/roux-institute-receives-another-100m-gift-to-support-its-high-tech-education-initiative-in-portland/">resources</a>, and I am looking for students.</p></div>
    </content>
    <updated>2021-11-22T19:31:33Z</updated>
    <published>2021-11-22T19:31:33Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Manu</name>
    </author>
    <source>
      <id>https://emanueleviola.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://emanueleviola.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://emanueleviola.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://emanueleviola.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://emanueleviola.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>by Manu</subtitle>
      <title>Thoughts</title>
      <updated>2021-12-01T04:20:50Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/11/22/assistant-professors-theory-positions-at-uestc-chengdu-china-apply-by-february-28-2022/</id>
    <link href="https://cstheory-jobs.org/2021/11/22/assistant-professors-theory-positions-at-uestc-chengdu-china-apply-by-february-28-2022/" rel="alternate" type="text/html"/>
    <title>Assistant Professors, theory positions at UESTC, Chengdu, China (apply by February 28, 2022)</title>
    <summary>The theory group at the cs school invites applications for Assistant Professor positions. The school is a top school in China and competitive at the world stage. We thrive to become among the best theoretical computer science groups in China. By joining us, you work with experienced, young, exciting, curiosity driven researchers and talented students. […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The theory group at the cs school invites applications for Assistant Professor positions. The school is a top school in China and competitive at the world stage. We thrive to become among the best theoretical computer science groups in China. By joining us, you work with experienced, young, exciting, curiosity driven researchers and talented students. Life is exciting &amp; remuneration is generous.</p>
<p>Website: <a href="https://tcs.uestc.edu.cn/">https://tcs.uestc.edu.cn/</a><br/>
Email: bmk@uestc.edu.cn</p></div>
    </content>
    <updated>2021-11-22T12:07:31Z</updated>
    <published>2021-11-22T12:07:31Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-12-01T04:20:34Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/11/21/research-fellow-at-university-of-oxford-apply-by-november-29-2021/</id>
    <link href="https://cstheory-jobs.org/2021/11/21/research-fellow-at-university-of-oxford-apply-by-november-29-2021/" rel="alternate" type="text/html"/>
    <title>Research Fellow at University of Oxford (apply by November 29, 2021)</title>
    <summary>The Department of Computer Science is pleased to invite applications for the Glasstone Fellowship in Computer Science—a three-year postdoctoral fellowship supported by the Glasstone Bequest. Candidates should be completing or have recently (i.e. normally within the past 3 years) completed a doctorate in Computer Science or a closely related discipline. Website: https://www.cs.ox.ac.uk/news/1984-full.html Email: james.worrell@cs.ox.ac.uk</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Department of Computer Science is pleased to invite applications for the Glasstone Fellowship in Computer Science—a three-year<br/>
postdoctoral fellowship supported by the Glasstone Bequest. Candidates should be completing or have recently (i.e. normally within the past 3 years) completed a doctorate in<br/>
Computer Science or a closely related discipline.</p>
<p>Website: <a href="https://www.cs.ox.ac.uk/news/1984-full.html">https://www.cs.ox.ac.uk/news/1984-full.html</a><br/>
Email: james.worrell@cs.ox.ac.uk</p></div>
    </content>
    <updated>2021-11-21T18:32:47Z</updated>
    <published>2021-11-21T18:32:47Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-12-01T04:20:34Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/166</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/166" rel="alternate" type="text/html"/>
    <title>TR21-166 |  Average-case Hardness of NP and PH from Worst-case Fine-grained Assumptions | 

	Lijie Chen, 

	Shuichi Hirahara, 

	Neekon Vafa</title>
    <summary>What is a minimal worst-case complexity assumption that implies non-trivial average-case hardness of NP or PH? This question is well motivated by the theory of fine-grained average-case complexity and fine-grained cryptography. In this paper, we show that several standard worst-case complexity assumptions are sufficient to imply non-trivial average-case hardness of NP or PH:
    
    1. NTIME[$n$] cannot be solved in quasi-linear time on average if UP is not in DTIME[$2^{\widetilde{O}\left(\sqrt{n}\right)}$].
    
    2. $\Sigma_2$TIME[$n$] cannot be solved in quasi-linear time on average if $\Sigma_k$SAT cannot be solved in time $2^{\widetilde{O}\left(\sqrt{n}\right)}$ for some constant $k$. Previously, it was not known if even average-case hardness of $\Sigma_3$SAT implies the average-case hardness of $\Sigma_2$TIME[$n$].
    
    3. Under the Exponential-Time Hypothesis (ETH), there is no average-case $n^{1+\varepsilon}$-time algorithm for NTIME[$n$] whose running time can be estimated in time $n^{1+\varepsilon}$ for some constant $\varepsilon &gt; 0$.
    
    Our results are given by generalizing the non-black-box worst-case-to-average-case connections presented by Hirahara (STOC 2021) to the settings of fine-grained complexity. To do so, we construct quite efficient complexity-theoretic pseudorandom generators under the assumption that the nondeterministic linear time is easy on average, which may be of independent interest.</summary>
    <updated>2021-11-21T01:35:02Z</updated>
    <published>2021-11-21T01:35:02Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-12-01T04:20:24Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/165</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/165" rel="alternate" type="text/html"/>
    <title>TR21-165 |  Improved Merlin-Arthur Protocols for Central Problems in Fine-Grained Complexity | 

	Shyan Akmal, 

	Lijie Chen, 

	Ce Jin, 

	Malvika Raj, 

	Ryan Williams</title>
    <summary>In a Merlin-Arthur proof system, the proof verifier (Arthur) accepts valid proofs (from Merlin) with probability $1$, and rejects invalid proofs with probability arbitrarily close to $1$. The running time of such a system is defined to be the length of Merlin's proof plus the running time of Arthur.  We provide new Merlin-Arthur proof systems for some key problems in fine-grained complexity. In several cases our proof systems have optimal running time. Our main results include:

$\bullet$ Certifying that a list of $n$ integers has no 3-SUM solution can be done in Merlin-Arthur time $\tilde{O}(n)$. Previously, Carmosino et al. [ITCS 2016] showed that the problem has a nondeterministic algorithm running in $\tilde{O}(n^{1.5})$  time (that is, there is a proof system with proofs of length $\tilde{O}(n^{1.5})$ and a deterministic verifier running in $\tilde{O}(n^{1.5})$ time).

$\bullet$ Counting the number of $k$-cliques with total edge weight equal to zero in an $n$-node graph can be done in Merlin-Arthur time $\tilde O(n^{\lceil k/2\rceil })$ (where $k\ge 3$). For odd $k$, this bound can be further improved for sparse graphs: for example, counting the number of zero-weight triangles in an $m$-edge graph can be done in Merlin-Arthur time $\tilde O(m)$. Previous Merlin-Arthur protocols by Williams [CCC'16] and Bj\"orklund and Kaski [PODC'16] could only count $k$-cliques in unweighted graphs, and had worse running times for small $k$.

$\bullet$ Computing the All-Pairs Shortest Distances matrix for an $n$-node graph can be done in Merlin-Arthur time $\tilde{O}(n^2)$. Note this is optimal, as the matrix can have $\Omega(n^2)$ nonzero entries in general. Previously, Carmosino et al. [ITCS 2016] showed that this problem has an $\tilde{O}(n^{2.94})$ nondeterministic time algorithm.

$\bullet$ Certifying that an $n$-variable $k$-CNF is unsatisfiable can be done in Merlin-Arthur time $2^{n/2 - n/O(k)}$. We also observe an algebrization barrier for the previous $2^{n/2}\cdot \mathrm{poly}(n)$-time Merlin-Arthur protocol of R. Williams [CCC'16] for $\#$SAT: in particular, his protocol algebrizes, and we observe there is no algebrizing protocol for $k$-UNSAT running in $2^{n/2}/n^{\omega(1)}$ time. Therefore we have to exploit non-algebrizing properties to obtain our new protocol.


$\bullet$ Certifying a Quantified Boolean Formula is true can be done in Merlin-Arthur time $2^{4n/5}\cdot \mathrm{poly}(n)$. Previously, the only nontrivial result known along these lines was an Arthur-Merlin-Arthur protocol (where Merlin's proof depends on some of Arthur's coins) running in $2^{2n/3}\cdot\mathrm{poly}(n)$ time. 

Due to the centrality of these problems in fine-grained complexity, our results have consequences for many other problems of interest. For example, our work implies that certifying there is no Subset Sum solution to $n$ integers can be done in Merlin-Arthur time $2^{n/3}\cdot\mathrm{poly}(n)$, improving on the previous best protocol by Nederlof [IPL 2017] which took $2^{0.49991n}\cdot\mathrm{poly}(n)$ time.</summary>
    <updated>2021-11-21T00:21:01Z</updated>
    <published>2021-11-21T00:21:01Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-12-01T04:20:24Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/11/20/assistant-associate-professors-at-aalto-university-apply-by-january-12-2022/</id>
    <link href="https://cstheory-jobs.org/2021/11/20/assistant-associate-professors-at-aalto-university-apply-by-january-12-2022/" rel="alternate" type="text/html"/>
    <title>Assistant &amp; Associate Professors at Aalto University (apply by January 12, 2022)</title>
    <summary>We invite applications for tenure-track positions at the Assistant Professor level, and tenured positions at the Associate Professor level. We are a diverse community welcoming applications in ALL AREAS of Computer Science. Our CS Theory group (https://research.cs.aalto.fi/theory/) has e.g. received the best paper awards in FOCS 2019 and ICALP 2017, as well as ERC starting […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>We invite applications for tenure-track positions at the Assistant Professor level, and tenured positions at the Associate Professor level. We are a diverse community welcoming applications in ALL AREAS of Computer Science. Our CS Theory group (<a href="https://research.cs.aalto.fi/theory/">https://research.cs.aalto.fi/theory/</a>) has e.g. received the best paper awards in FOCS 2019 and ICALP 2017, as well as ERC starting grants in 2014 and 2017.</p>
<p>Website: <a href="https://bit.ly/aalto-csprof">https://bit.ly/aalto-csprof</a><br/>
Email: laura.kuusisto-noponen@aalto.fi</p></div>
    </content>
    <updated>2021-11-20T19:20:40Z</updated>
    <published>2021-11-20T19:20:40Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-12-01T04:20:34Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/11/19/simons-berkeley-fellowships-for-fall-2022-and-spring-2023-at-simons-institute-for-the-theory-of-computing-apply-by-december-15-2021/</id>
    <link href="https://cstheory-jobs.org/2021/11/19/simons-berkeley-fellowships-for-fall-2022-and-spring-2023-at-simons-institute-for-the-theory-of-computing-apply-by-december-15-2021/" rel="alternate" type="text/html"/>
    <title>Simons-Berkeley Fellowships for Fall 2022 and Spring 2023 at Simons Institute for the Theory of Computing (apply by December 15, 2021)</title>
    <summary>The Simons Institute for the Theory of Computing invites applications for Simons-Berkeley Research Fellowships for the Fall 2022 and Spring 2023 semesters. The Institute will host programs on “Data-Driven Decision Processes” and “Graph Limits and Processes on Networks: From Epidemics to Misinformation” in Fall 2022 and “Meta-Complexity in Spring 2023. Website: https://simons.berkeley.edu/simons-berkeley-research-fellowship-call-applications Email: simonsvisitorservices@berkeley.edu</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Simons Institute for the Theory of Computing invites applications for Simons-Berkeley Research Fellowships for the Fall 2022 and Spring 2023 semesters. The Institute will host programs on “Data-Driven Decision Processes” and “Graph Limits and Processes on Networks: From Epidemics to Misinformation” in Fall 2022 and “Meta-Complexity in Spring 2023.</p>
<p>Website: <a href="https://simons.berkeley.edu/simons-berkeley-research-fellowship-call-applications">https://simons.berkeley.edu/simons-berkeley-research-fellowship-call-applications</a><br/>
Email: simonsvisitorservices@berkeley.edu</p></div>
    </content>
    <updated>2021-11-19T22:07:32Z</updated>
    <published>2021-11-19T22:07:32Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-12-01T04:20:34Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://scottaaronson.blog/?p=6129</id>
    <link href="https://scottaaronson.blog/?p=6129" rel="alternate" type="text/html"/>
    <link href="https://scottaaronson.blog/?p=6129#comments" rel="replies" type="text/html"/>
    <link href="https://scottaaronson.blog/?feed=atom&amp;p=6129" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">The Acrobatics of BQP</title>
    <summary xml:lang="en-US">Just in case anyone is depressed this afternoon and needs something to cheer them up, students William Kretschmer, DeVon Ingram, and I have finally put out a new paper: The Acrobatics of BQP Abstract: We show that, in the black-box setting, the behavior of quantum polynomial-time (BQP) can be remarkably decoupled from that of classical […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>Just in case anyone is depressed this afternoon and needs something to cheer them up, students <a href="https://www.cs.utexas.edu/~kretsch/">William Kretschmer</a>, <a href="https://www.quantitativebiology.northwestern.edu/2021/02/23/three-students-awarded-prizes-in-the-great-math-challenge-in-biology-contest/">DeVon Ingram</a>, and I have finally put out a new paper:</p>



<blockquote class="wp-block-quote"><p><strong><a href="https://eccc.weizmann.ac.il/report/2021/164/">The Acrobatics of BQP</a></strong></p><p><strong>Abstract:</strong> We show that, in the black-box setting, the behavior of quantum polynomial-time (BQP) can be remarkably decoupled from that of classical complexity classes like NP.  Specifically:</p><p>– There exists an oracle relative to which NP<sup>BQP</sup>⊄BQP<sup>PH</sup>, resolving a 2005 problem of Fortnow. Interpreted another way, we show that AC<sup>0</sup> circuits cannot perform useful homomorphic encryption on instances of the Forrelation problem. As a corollary, there exists an oracle relative to which P=NP but BQP≠QCMA.</p><p>– Conversely, there exists an oracle relative to which BQP<sup>NP</sup>⊄PH<sup>BQP</sup>.</p><p>– Relative to a random oracle, PP=PostBQP is not contained in the “QMA hierarchy” QMA<sup>QMA^QMA^…</sup>, and more generally PP⊄(MIP*)<sup>(MIP*)^(MIP*)^…</sup> (!), despite the fact that MIP*=RE in the unrelativized world. This result shows that there is no black-box quantum analogue of Stockmeyer’s approximate counting algorithm.</p><p>– Relative to a random oracle, Σ<sub>k+1</sub>⊄BQP<sup>Σ_k</sup> for every k.</p><p>– There exists an oracle relative to which BQP=P<sup>#P</sup> and yet PH is infinite. (By contrast, if NP⊆BPP, then PH collapses relative to all oracles.)</p><p>– There exists an oracle relative to which P=NP≠BQP=P<sup>#P</sup>.</p><p>To achieve these results, we build on the 2018 achievement by Raz and Tal of an oracle relative to which BQP⊄PH, and associated results about the Forrelation problem. We also introduce new tools that might be of independent interest. These include a “quantum-aware” version of the random restriction method, a concentration theorem for the block sensitivity of AC<sup>0</sup> circuits, and a (provable) analogue of the Aaronson-Ambainis Conjecture for sparse oracles.</p></blockquote>



<p>Incidentally, particularly when I’ve worked on a project with students, I’m often tremendously excited and want to shout about it from the rooftops for the students’ sake … but then I also don’t want to use this blog to privilege my own papers “unfairly.”  Can anyone suggest a principle that I should follow going forward?</p></div>
    </content>
    <updated>2021-11-19T21:48:06Z</updated>
    <published>2021-11-19T21:48:06Z</published>
    <category scheme="https://scottaaronson.blog" term="Complexity"/>
    <category scheme="https://scottaaronson.blog" term="Quantum"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://scottaaronson.blog/?feed=atom</id>
      <icon>https://scottaaronson.blog/wp-content/uploads/2021/10/cropped-Jacket-32x32.gif</icon>
      <link href="https://scottaaronson.blog" rel="alternate" type="text/html"/>
      <link href="https://scottaaronson.blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2021-11-19T21:48:06Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/11/19/postdoc-at-georgia-institute-of-technology-apply-by-december-15-2021/</id>
    <link href="https://cstheory-jobs.org/2021/11/19/postdoc-at-georgia-institute-of-technology-apply-by-december-15-2021/" rel="alternate" type="text/html"/>
    <title>PostDoc at Georgia Institute of Technology (apply by December 15, 2021)</title>
    <summary>Algorithms and Randomness Center (ARC) at Georgia Tech is seeking postdoctoral fellows starting Fall 2022. ARC has faculty associated with many departments including CS, Math, ISyE. The selected candidate may work on any aspect of algorithms, optimization, broadly interpreted. Qualified applicants must possess a PhD in CS, Math, OR or a related field. Apply by […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Algorithms and Randomness Center (ARC) at Georgia Tech is seeking postdoctoral fellows starting Fall 2022. ARC has faculty associated with many departments including CS, Math, ISyE. The selected candidate may work on any aspect of algorithms, optimization, broadly interpreted. Qualified applicants must possess a PhD in CS, Math, OR or a related field. Apply by December 15, 2021.</p>
<p>Website: <a href="http://arc.gatech.edu/node/384">http://arc.gatech.edu/node/384</a><br/>
Email: ftonge3@cc.gatech.edu</p></div>
    </content>
    <updated>2021-11-19T20:01:19Z</updated>
    <published>2021-11-19T20:01:19Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-12-01T04:20:34Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://toc4fairness.org/?p=1968</id>
    <link href="https://toc4fairness.org/our-2022-postdoc-program-is-up/" rel="alternate" type="text/html"/>
    <title>Our 2022 Postdoc Program is up</title>
    <summary>We are excited to announce our new postdoc program. We are seeking strong candidates from a diverse set of academic backgrounds and personal experiences who want to work with one ...</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>We are excited to announce <a href="https://toc4fairness.org/postdoc-opportunities/">our new postdoc program</a>. We are seeking strong candidates from a diverse set of academic backgrounds and personal experiences who want to work with one or more of the PIs on algorithmic fairness and responsible computing more broadly. We expect to be extending multiple offers.  </p></div>
    </content>
    <updated>2021-11-19T13:45:11Z</updated>
    <published>2021-11-19T13:45:11Z</published>
    <category term="Blog"/>
    <author>
      <name>Omer Reingold</name>
    </author>
    <source>
      <id>https://toc4fairness.org</id>
      <logo>https://i1.wp.com/toc4fairness.org/wp-content/uploads/2020/10/cropped-favicon.png?fit=32%2C32&amp;ssl=1</logo>
      <link href="https://toc4fairness.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://toc4fairness.org" rel="alternate" type="text/html"/>
      <subtitle>a simons collaboration project</subtitle>
      <title>TOC for Fairness</title>
      <updated>2021-12-01T04:21:33Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/164</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/164" rel="alternate" type="text/html"/>
    <title>TR21-164 |  The Acrobatics of BQP | 

	Scott Aaronson, 

	DeVon Ingram, 

	William Kretschmer</title>
    <summary>We show that, in the black-box setting, the behavior of quantum polynomial-time (${BQP}$) can be remarkably decoupled from that of classical complexity classes like ${NP}$. Specifically:

-There exists an oracle relative to which ${NP}^{{BQP}}\not \subset {BQP}^{{PH}}$, resolving a 2005 problem of Fortnow. Interpreted another way, we show that ${AC^0}$ circuits cannot perform useful homomorphic encryption on instances of the Forrelation problem. As a corollary, there exists an oracle relative to which ${P} = {NP}$ but ${BQP} \neq {QCMA}$.
-Conversely, there exists an oracle relative to which ${BQP}^{{NP}}\not \subset {PH}^{{BQP}}$.
-Relative to a random oracle, ${PP} = {PostBQP}$ is not contained in the "${QMA}$ hierarchy" ${QMA}^{{QMA}^{{QMA}^{\cdots}}}$, and more generally ${PP} \not\subset ({MIP}^*)^{({MIP}^*)^{({MIP}^*)^{\cdots}}}$ (!), despite the fact that ${MIP}^{\ast}={RE}$ in the unrelativized world. This result shows that there is no black-box quantum analogue of Stockmeyer's approximate counting algorithm.
-Relative to a random oracle, ${\Sigma}_{k+1}^{P} \not\subset {BQP}^{{\Sigma}_{k}^{P}}$ for every $k$.
-There exists an oracle relative to which ${BQP} = {P^{\# P}}$ and yet ${PH}$ is infinite. (By contrast, if ${NP}\subseteq{BPP}$, then ${PH}$ collapses relative to all oracles.)
-There exists an oracle relative to which ${P}={NP} \neq {BQP}={P}^{{\#P}}$.

To achieve these results, we build on the 2018 achievement by Raz and Tal of an oracle relative to which ${BQP}\not \subset {PH}$, and associated results about the Forrelation problem. We also introduce new tools that might be of independent interest. These include a "quantum-aware" version of the random restriction method, a concentration theorem for the block sensitivity of ${AC^0}$ circuits, and a (provable) analogue of the Aaronson-Ambainis Conjecture for sparse oracles.</summary>
    <updated>2021-11-19T13:02:40Z</updated>
    <published>2021-11-19T13:02:40Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-12-01T04:20:24Z</updated>
    </source>
  </entry>
</feed>
