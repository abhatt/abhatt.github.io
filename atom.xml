<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2020-07-07T00:21:52Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/100</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/100" rel="alternate" type="text/html"/>
    <title>TR20-100 |  Streaming Verification for Graph Problems: Optimal Tradeoffs and Nonlinear Sketches | 

	Amit Chakrabarti, 

	Prantar Ghosh, 

	Justin Thaler</title>
    <summary>We study graph computations in an enhanced data streaming setting, where a space-bounded client reading the edge stream of a massive graph may delegate some of its work to a cloud service. We seek algorithms that allow the client to verify a purported proof sent by the cloud service that the work done in the cloud is correct.
  A line of work starting with Chakrabarti et al. (ICALP 2009) has provided such algorithms, which we call schemes, for several statistical and graph-theoretic problems, many of which exhibit a tradeoff between the length of the proof and the space used by the streaming verifier.
  
  This work designs new schemes for a number of basic graph problems---including triangle counting, maximum matching, topological sorting, and single-source shortest paths---where past work had either failed to obtain smooth tradeoffs between these two key complexity measures or only obtained suboptimal tradeoffs. Our key innovation is having the verifier compute certain nonlinear sketches of the input stream, leading to either new or improved tradeoffs. In many cases, our schemes in fact provide optimal tradeoffs up to logarithmic factors. 

  Specifically, for most graph problems that we study, it is known that the product of the verifier's space cost $v$ and the proof length $h$ must be at least $\Omega(n^2)$ for $n$-vertex graphs. However, matching upper bounds are only known for a handful of settings of $h$ and $v$ on the curve $h \cdot v=\tilde{\Theta}(n^2)$. For example, for counting triangles and maximum matching, schemes with costs lying on this curve are only known for $(h=\tilde{O}(n^2), v=\tilde{O}(1))$, $(h=\tilde{O}(n), v=\tilde{O}(n))$, and the trivial $(h=\tilde{O}(1), v=\tilde{O}(n^2))$. A major message of this work is that by exploiting nonlinear sketches, a significant ``portion'' of costs on the tradeoff curve $h \cdot v = n^2$ can be achieved.</summary>
    <updated>2020-07-06T17:16:45Z</updated>
    <published>2020-07-06T17:16:45Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-07-07T00:20:37Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/099</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/099" rel="alternate" type="text/html"/>
    <title>TR20-099 |  KRW Composition Theorems via Lifting | 

	Susanna de Rezende, 

	Or Meir, 

	Jakob Nordström, 

	Toniann Pitassi, 

	Robert Robere</title>
    <summary>One of the major open problems in complexity theory is proving super-logarithmic lower bounds on the depth of circuits (i.e., $\mathbf{P}\not\subseteq\mathbf{NC}^1$). Karchmer, Raz, and Wigderson (Computational Complexity 5(3/4), 1995) suggested to approach this problem by proving that depth complexity behaves “as expected” with respect to the composition of functions $f \diamond g$. They showed that the validity of this conjecture would imply that $\mathbf{P}\not\subseteq\mathbf{NC}^1$.

Several works have made progress toward resolving this conjecture by proving special cases. In particular, these works proved the KRW conjecture for every outer function $f$, but only for few inner functions $g$. Thus, it is an important challenge to prove the KRW conjecture for a wider range of inner functions.

In this work, we extend significantly the range of inner functions that can be handled. First, we consider the $\textit{monotone}$ version of the KRW conjecture. We prove it for every monotone inner function $g$ whose depth complexity can be lower bounded via a query-to-communication lifting theorem. This allows us to handle several new and well-studied functions such as the $s\textbf{-}t$-connectivity, clique, and generation functions.

In order to carry this progress back to the $\textit{non-monotone}$ setting, we introduce a new notion of $\textit{semi-monotone}$ composition, which combines the non-monotone complexity of the outer function $f$ with the monotone complexity of the inner function $g$. In this setting, we prove the KRW conjecture for a similar selection of inner functions $g$, but only for a specific choice of the outer function $f$.</summary>
    <updated>2020-07-06T11:22:16Z</updated>
    <published>2020-07-06T11:22:16Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-07-07T00:20:37Z</updated>
    </source>
  </entry>

  <entry>
    <id>http://offconvex.github.io/2020/07/06/GAN-min-max/</id>
    <link href="http://offconvex.github.io/2020/07/06/GAN-min-max/" rel="alternate" type="text/html"/>
    <title>Training GANs - From Theory to Practice</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>GANs, originally discovered in the context of unsupervised learning, have had far reaching implications to science, engineering, and society. However, training GANs remains challenging (in part) due to the lack of convergent algorithms for nonconvex-nonconcave min-max optimization. In this post, we present a <a href="https://arxiv.org/abs/2006.12376">new first-order algorithm</a> for min-max optimization which is particularly suited to GANs. This algorithm is guaranteed to converge to an equilibrium, is competitive in terms of time and memory with gradient descent-ascent and, most importantly, GANs trained using it seem to be stable.</p>

<h2 id="gans-and-min-max-optimization">GANs and min-max optimization</h2>

<p>Starting with the work of <a href="http://papers.nips.cc/paper/5423-generative-adversarial-nets">Goodfellow et al.</a>, Generative Adversarial Nets (GANs) have become a critical component in various ML systems; for prior posts on GANs, see <a href="https://www.offconvex.org/2018/03/12/bigan/">here</a> for a post on  GAN architecture, and <a href="https://www.offconvex.org/2017/03/15/GANs/">here</a> and <a href="https://www.offconvex.org/2017/07/06/GANs3/">here</a> for posts which discuss  some of the many difficulties arising when training GANs.</p>

<p>Mathematically, a GAN consists of a generator neural network $\mathcal{G}$ and a discriminator neural network $\mathcal{D}$ that are competing against each other in a way that, together, they learn the unknown distribution from which a given dataset arises.  The generator takes a random “noise” vector as input and maps this vector to a sample; for instance, an image. The discriminator takes samples – “fake” ones produced by the generator and “real” ones from the given dataset – as inputs.  The discriminator then tries to classify these samples as “real” or “fake”. As a designer, we would like the generated samples to be indistinguishable from those of the dataset. Thus, our goal is to choose weights $x$ for the generator network that allow it to generate samples which are difficult for <em>any</em> discriminator to tell apart from real samples. This leads to a min-max optimization problem where we look for weights $x$ which <em>minimize</em> the rate (measured by a loss function $f$) at which any discriminator correctly classifies the real and fake samples. And, we seek weights $y$ for the discriminator network which <em>maximize</em> this rate.</p>

<blockquote>
  <p><strong>Min-max formulation of GANs</strong> <br/> <br/></p>

  

  

  <p>where $\zeta$ is a random sample from the dataset, and $\xi \sim N(0,I_d)$ is a noise vector which the generator maps to a “fake” sample.  $f_{\zeta, \xi}$ measures how accurately the discriminator $\mathcal{D}(y;\cdot)$ distinguishes $\zeta$ from $\mathcal{G}(x;\xi)$ produced by the generator using the input noise $\xi$.</p>
</blockquote>

<p>In this formulation, there are several choices that we have to make as a GAN designer, and an important one is that of a loss function. One concrete choice is from the paper of Goodfellow et al.: the cross-entropy loss function:</p>



<p>See <a href="https://machinelearningmastery.com/generative-adversarial-network-loss-functions/">here</a> for a summary and comparison of different loss functions.</p>

<p>Once we fix the loss function (and the architecture of the generator and discriminator), we can compute unbiased estimates of the value of $f$ and its gradients $\nabla_x f$ and $\nabla_y f$ using batches consisting of random Gaussian noise vectors $\xi_1,\ldots, \xi_n \sim N(0,I_d)$ and random samples from the dataset $\zeta_1, \ldots, \zeta_n$.  For example, the stochastic batch gradient</p>



<p>gives us an unbiased estimate for $\nabla_x f(x,y)$.</p>

<blockquote>
  <p>But how do we solve the min-max optimization problem above using such a first-order access to $f$?</p>
</blockquote>

<h2 id="gradient-descent-ascent-and-variants">Gradient descent-ascent and variants</h2>

<p>Perhaps the simplest algorithm we can try for min-max optimization is gradient descent-ascent (GDA). As the generator wants to minimize with respect to $x$ and the discriminator wants to maximize with respect to $y$, the idea is to do descent steps for $x$ and ascent steps for $y$. How exactly to do this is not clear, and one strategy is to let the generator and discriminator alternate:</p>





<p>Other variants include, for instance, <a href="https://arxiv.org/abs/1311.1869">optimistic mirror descent</a> (OMD) (see also <a href="https://arxiv.org/abs/1807.02629">here</a> and  <a href="https://arxiv.org/abs/1711.00141">here</a> for applications of OMD to GANs, and <a href="https://arxiv.org/abs/1901.08511">here</a> for an analysis of OMD and related methods)</p>





<p>The advantage of such algorithms is that they are quite practical. The problem, as we discuss next, is that they are not always guaranteed to converge. Most of these guarantees only hold for special classes of loss functions $f$ that satisfy properties such as concavity (see <a href="https://papers.nips.cc/paper/9430-efficient-algorithms-for-smooth-minimax-optimization.pdf">here</a> and <a href="https://arxiv.org/abs/1906.00331">here</a>) or <a href="https://papers.nips.cc/paper/9631-solving-a-class-of-non-convex-min-max-games-using-iterative-first-order-methods.pdf">monotonicity</a>, or under the assumptions that these algorithms are provided with special starting points (see <a href="https://arxiv.org/abs/1706.08500">here</a>, <a href="https://arxiv.org/abs/1910.07512">here</a>).</p>

<h2 id="convergence-problems-with-current-algorithms">Convergence problems with current algorithms</h2>

<p>Unfortunately there are simple functions for which some min-max optimization algorithms may never converge to <em>any</em> point.  For instance GDA may not converge on $f(x,y) = xy$  (see Figure 1, and our <a href="https://www.offconvex.org/2020/06/24/equilibrium-min-max/">previous post</a> for a more detailed discussion).</p>

<div>
<img alt="" src="http://www.offconvex.org/assets/GDA_spiral_2.gif"/>
<br/>
<b>Figure 1.</b> GDA on $f(x,y) = xy, \, \, \, \, x,y \in [-5,5]$ (the red line is the set of global min-max points). GDA is non-convergent from almost every initial point. 
</div>
<p><br/></p>

<p>As for examples relevant to ML, when using GDA to train a GAN on a dataset consisting of points sampled from a mixture of four Gaussians in $\mathbb{R}^2$, we observe that GDA tends to cause the generator to cycle between different modes corresponding to the four Gaussians. We also used GDA to train a GAN on the subset of the MNIST digits which have “0” or “1” as their label, which we refer to as the 0-1 MNIST dataset.  We observed a cycling behavior for this dataset as well: After learning how to generate images of $0$’s, the GAN trained by GDA then forgets how to generate $0$’s for a long time and only generates $1$’s.</p>

<div>
<img alt="" src="http://www.offconvex.org/assets/GDA_Gaussian.gif" style="width: 400px;"/>
<img alt="" src="http://www.offconvex.org/assets/GDA_MNIST.gif" style="width: 400px;"/>
<br/>
<b>Figure 2.</b> Mode oscillation when GDA is used to train GANs on the four Guassian mixture dataset (left) and the 0-1 MNIST dataset (right).
</div>

<p><br/></p>

<p>In algorithms such as GDA where the discriminator only makes local updates, cycling can happen for the following reason: Once the discriminator learns to identify one of the modes (say mode “A”), the generator can update $x$ in a way that greatly decreases f, by (at least temporarily) ìfoolingî the discriminator. The generator does this by learning to generate samples from a different mode (say mode “B”) which the discriminator has not yet learned to identify, and stops generating samples from mode A. However, after many iterations, the discriminator ìcatches upî to the generator and learns how to identify mode B. Since the generator is no longer generating samples from mode A, the discriminator may then ìforgetî how to identify samples from this mode. And this can cause the generator to switch back to generating only mode A.</p>

<h2 id="our-first-order-algorithm">Our first-order algorithm</h2>

<p>To solve the min-max optimization problem, at any point $(x,y)$, we should ideally allow the discriminator to find the global maximum, $\max_z f(x,z)$. However, this may be hard for nonconcave $f$. But we could still let the discriminator run a convergent algorithm (such as gradient ascent) until it reaches a <strong>first-order stationary point</strong>, allowing it to compute an approximation $h$ for the global max function.  (Note that even though $\max_z f(x,z)$ is only a function of $x$, since $h$ is a “local’’ approximation it could also depend on the initial point $y$ where we start gradient ascent.) And we also empower the generator to simulate the discriminator’s update by running gradient ascent (see <a href="https://arxiv.org/abs/2006.12376">our paper</a> for discriminators with access to a more general class of first-order algorithms).</p>

<blockquote>
  <p><strong>Idea 1: Use a local approximation to global max</strong>
<br/><br/>
Starting at the point $(x,y)$, update $y$ by computing multiple gradient ascent steps for $y$ until a point $w$ is reached where  is close to zero and define $h(x,y) := f(x,w)$.</p>
</blockquote>

<p>We would like the generator to minimize $h(\cdot,y)$. To minimize $h$, we would ideally like to update $x$ in the direction $-\nabla_x h$.  However, $h$ may be discontinuous in $x$ (see our <a href="https://www.offconvex.org/2020/06/24/equilibrium-min-max/">previous post</a> for why this can happen). Moreover, even at points where $h$ is differentiable, computing the gradient of $h$ can take a long time and requires a large amount of memory.</p>

<p>Thus, realistically, we only have access to the value of $h$. A naive approach to minimizing $h$ would be to propose a random update to $x$, for instance an update sampled from a standard Gaussian, and then only accept this update if it causes the value of $h$ to decrease. Unfortunately, this does not lead to fast algorithms as even at points where $h$ is differentiable, in high dimensions, a random Gaussian step will be almost orthogonal to the steepest descent direction $-\nabla_x h(x,y)$, making the progress slow.</p>

<p>Another idea is to have the generator propose at each iteration an update in the direction of the gradient $-\nabla_x f(x,y)$, and to then have the discriminator update $y$ using gradient ascent. To see why this may be a reasonable thing to do, notice that once the generator proposes an update $v$ to $x$, the discriminator will only make updates which increase the value of f or, $h(x+v,y) \geq f(x+v,y)$. And, since $y$ is a first-order stationary point for $f(x, \cdot)$ (because $y$ was computed using gradient ascent in the <em>previous</em> iteration), we also have that $h(x,y)=f(x,y)$. Hence,</p>



<p><em>This means that decreasing $h$ requires us to decrease $f$ (the converse is not true). So it indeed makes sense to move in the direction $-\nabla_x f(x,y)$!</em></p>

<p>While making updates using $-\nabla_x f(x,y)$ may allow the generator to decrease $h$ more quickly than updating in a random direction, it is not always the case that updating in the direction of $-\nabla_x f$ will lead to a decrease in $h$ (and doing so may even lead to an increase in $h$!). Instead, our algorithm has the generator perform a random search by proposing an update in the direction of a batch gradient with mean $-\nabla_x f$, and accepts this move only if the value of $h$ (the local approximation) decreases. The accept-reject step prevents our algorithm from cycling between modes, and using the batch gradient for the random search allows our algorithm to be competitive with prior first-order methods in terms of running time.</p>

<blockquote>
  <p><strong>Idea 2: Use zeroth-order optimization with batch gradients</strong>
<br/><br/>
Sample a batch gradient $v$ with mean $-\nabla_x f(x,y)$.
<br/>
If $h(x+ v, y) &lt; h(x,y) $ accept the step $x+v$; otherwise reject it.</p>
</blockquote>

<p>A final issue, that applies even in the special case of minimization, is that converging to a <em>local</em> minimum point does not mean that point is desirable from an application standpoint. The same is true for the more general setting of min-max optimization. To help our algorithm escape undesirable local min-max equilibria, we use a randomized accept-reject rule inspired by <a href="https://towardsdatascience.com/optimization-techniques-simulated-annealing-d6a4785a1de7">simulated annealing</a>. Simulated annealing algorithms seek to minimize a function via a randomized search, while gradually decreasing the acceptance probability of this search; in some cases this allows one to reach the global minimum of a nonconvex function (see for instance <a href="https://arxiv.org/abs/1711.02621">this paper</a>). These three ideas lead us to our algorithm.</p>

<blockquote>
  <p><strong>Our algorithm</strong>
<br/><br/>
<em>Input</em>: Initial point $(x,y)$, $f: \mathbb{R}^d \times \mathbb{R}^d\rightarrow \mathbb{R}$
<br/>
<em>Output:</em> A local min-max equilibrium $(x,y)$</p>

  <p><br/> <br/></p>

  <p>For $i = 1,2, \ldots$ <br/>
<br/>
<strong>Step 1:</strong> Generate a batch gradient $v$ with mean $-\nabla_x f(x,y)$ and propose the generator update $x+v$.
<br/><br/>
<strong>Step 2:</strong> Compute $h(x+v, y) = f(x+v, w)$, by simulating a discriminator update $w$ via gradient ascent on $f(x+v, \cdot)$ starting at $y$.
<br/><br/>
<strong>Step 3:</strong>  If $h(x+v, y)$ is less than $h(x,y) = f(x,y)$, accept both updates: $(x,y) = (x+v, w)$. Else, accept both updates with some small probability.</p>
</blockquote>

<p>In our paper, we show that our algorithm is guaranteed to converge to a type of local min-max equilibrium in $\mathrm{poly}(\frac{1}{\varepsilon},d, b, L)$ time whenever $f$ is bounded by some $b&gt;0$ and has $L$-Lipschitz gradients. Our algorithm does not require any special starting points, or any additional assumptions on $f$ such as convexity or monotonicity. (See Definition 3.2 and Theorem 3.3 in our paper.)</p>

<div>
<img alt="" src="http://www.offconvex.org/assets/GDA_spiral_2.gif" style="width: 400px;"/>
<img alt="" src="http://www.offconvex.org/assets/OurAlgorithm_surface_run1.gif" style="width: 400px;"/>
<br/>
<b>Figure 3.</b> GDA (left) and a version of our algorithm (right) on $f(x,y) = xy, \, \, \, \, x,y \in [-5,5]$. While GDA is non-convergent from almost every initial point, our algorithm converges to the set of global min-max points (the red line). To ensure it converges to a (local) equilibrium, our algorithm's generator proposes multiple updates, simulates the discriminator's response, and rejects updates which do not lead to a net decrease in $f$. It only stops if it can't find such an update after many attempts. (To stay inside $[-5,5]\times [-5,5]$ this version of our algorithm uses <i>projected</i> gradients.)
</div>

<p><br/></p>

<h2 id="so-how-does-our-algorithm-perform-in-practice">So, how does our algorithm perform in practice?</h2>

<p>When training a GAN on the mixture of four Gaussians dataset, we found that our algorithm avoids the cycling behavior observed in GDA. We ran each algorithm multiple times, and evaluated the results visually. By the 1500’th iteration GDA learned only one mode in 100% of the runs, and tended to cycle between two or more modes. In contrast, our algorithm was able to learn all four modes 68% of the runs, and three modes 26% of the runs.</p>

<div>
<img alt="" src="http://www.offconvex.org/assets/Both_algorithms_Gaussian.gif"/>
<br/>
<b>Figure 4.</b> GAN trained using GDA and our algorithm on a four Gaussian mixture dataset. While GDA cycles between the Gaussian modes (red dots), our algorithm learns all four modes.
</div>
<p><br/></p>

<p>When training on the 0-1 MNIST dataset, we found that GDA tends to briefly generate shapes that look like a combination of $0$’s and $1$’s, then switches to generating only $1$’s, and then re-learns how to generate $0$’s. In contrast, our algorithm seems to learn how to generate both $0$’s and $1$’s early on and does not stop generating either digit. We repeated this simulation multiple times for both algorithms, and visually inspected the images at the 1000’th iteration. GANs trained using our algorithm generated both digits by the 1000’th iteration in 86% of the runs, while those trained using GDA only did so in 23% of the runs.</p>

<div>
<img alt="" src="http://www.offconvex.org/assets/MNIST_bothAlgorithms.gif"/>
<br/>
<b>Figure 5.</b> We trained a GAN with GDA and our algorithm on the
0-1 MNIST dataset.  During the first 1000 iterations, GDA (left)
forgets how to generate $0$'s, while our algorithm (right) learns how to
generate both $0$'s and $1$'s early on and does not stop generating either digit.
</div>

<p><br/></p>

<p>While here we have focused on comparing our algorithm to GDA, in our paper we also include a comparison to <a href="https://arxiv.org/abs/1611.02163">Unrolled GANs</a>, which exhibits cycling between modes. We also present results for CIFAR-10 (see Figures 3 and 7 in our paper), where we compute FID scores to track the progress of our algorithm. See our paper for more details; the code is available on <a href="https://github.com/mangoubi/Min-max-optimization-algorithm-for-training-GANs">GitHub</a>.</p>

<h2 id="conclusion">Conclusion</h2>

<p>In this post we have shown how to develop a practical and convergent first-order algorithm for training GANs. Our algorithm synthesizes an approximation to the global max function based on first-order algorithms, random search using batch gradients, and simulated annealing. Our simulations show that a version of this algorithm can lead to more stable training of GANs. And yet the amount of memory and time required by each iteration of our algorithm is competitive with GDA. This post, together with the <a href="https://www.offconvex.org/2020/06/24/equilibrium-min-max/">previous post</a>, show that different local approximations to the global max function $\max_z f(x,z)$ can lead to different types of convergent algorithms for min-max optimization. We believe that this idea should be useful in other applications of min-max optimization.</p></div>
    </summary>
    <updated>2020-07-06T09:00:00Z</updated>
    <published>2020-07-06T09:00:00Z</published>
    <source>
      <id>http://offconvex.github.io/</id>
      <author>
        <name>Off the Convex Path</name>
      </author>
      <link href="http://offconvex.github.io/" rel="alternate" type="text/html"/>
      <link href="http://offconvex.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Algorithms off the convex path.</subtitle>
      <title>Off the convex path</title>
      <updated>2020-07-06T23:36:11Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://decentralizedthoughts.github.io/2020-07-05-the-first-blockchain-or-how-to-time-stamp-a-digital-document/</id>
    <link href="https://decentralizedthoughts.github.io/2020-07-05-the-first-blockchain-or-how-to-time-stamp-a-digital-document/" rel="alternate" type="text/html"/>
    <title>The First Blockchain or How to Time-Stamp a Digital Document</title>
    <summary>This post is about the work of Stuart Haber and W. Scott Stornetta from 1991 on How to Time-Stamp a Digital Document and their followup paper Improving the Efficiency and Reliability of Digital Time-Stamping. In many ways, this work introduced the idea of a chain of hashes to create a...</summary>
    <updated>2020-07-06T02:58:00Z</updated>
    <published>2020-07-06T02:58:00Z</published>
    <source>
      <id>https://decentralizedthoughts.github.io</id>
      <author>
        <name>Decentralized Thoughts</name>
      </author>
      <link href="https://decentralizedthoughts.github.io" rel="alternate" type="text/html"/>
      <link href="https://decentralizedthoughts.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Decentralized thoughts about decentralization</subtitle>
      <title>Decentralized Thoughts</title>
      <updated>2020-07-06T23:36:47Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-3270621784797289581</id>
    <link href="https://blog.computationalcomplexity.org/feeds/3270621784797289581/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/07/a-table-for-matrix-mortality-what-i.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/3270621784797289581" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/3270621784797289581" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/07/a-table-for-matrix-mortality-what-i.html" rel="alternate" type="text/html"/>
    <title>A table for Matrix Mortality- what I wanted for Hilbert's 10th problem</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">In <a href="https://blog.computationalcomplexity.org/2020/05/why-is-there-no-dn-grid-for-hilberts.html">this post</a> I speculated on why I could not find anywhere a table of which cases of Hilbert's 10th problem were solvable, unsolvable, and unknown. (I then made such a table. It was very clunky,  which may answer the question.)<br/>
<br/>
I told my formal lang theory class about Hilbert's 10th problem as a natural example of an undecidable question- that is, an example that had nothing to do with Turing Machines. On the final I asked<br/>
<br/>
<i>Give an example of an undecidable problem that has nothing to do with Turing Machines.</i><br/>
<br/>
Because of the pandemic this was a 2-day take home final which was open-book, open-notes, open-web. So they could have looked at my slides.<br/>
<br/>
And indeed, most of them did give Hilbert's 10 problem (more formally, the set of all polynomials in many vars over Z which have a Diophantine solution).<br/>
<br/>
But some did not. Some said there could never be such a problem (this is an incorrect answer), Some were incoherent. One just wrote ``Kruskal Trees''  (not sure if he was referring to MSTs or WQOs or to something that Clyde Kruskal did in class one day).<br/>
<br/>
One student said that the problem of, given a CFG G, is the complement of L(G) also CFG.<br/>
This is indeed undecidable and does not have to do with TMs. I doubt the student could have proven that. I doubt I could have proven that. I do not doubt that my advisor Harry Lewis could have proven that, and indeed I emailed him asking for a proof and he emailed me a sketch, which I wrote out in more detail <a href="https://www.cs.umd.edu/users/gasarch/COURSES/452/S20/notes/undcfg.pdf">here</a>.<br/>
<br/>
The most interesting answer was given by some students who apparently looked at the web (rather than at my slides) for lists of problems and found the following called Matrix Mortality:<br/>
<br/>
{ (M_1,...,M_L) : such that some product of these matrices (you are allowed to use a matrix many times) is the 0 matrix}<br/>
<br/>
Why was this the most interesting? The TA did not know this problem was undecidable until he saw it on the exams and looked it up. I did not know it was undecidable until my TA told me.<br/>
<br/>
I then raised the question: How many matrices to you need and how big do their dimensions have to be?<br/>
<br/>
Unlike H10, there IS a table of this. In <a href="https://arxiv.org/abs/1404.0644">this paper</a> they have such a table. I state some results:<br/>
<br/>
Undecidable:<br/>
6 matrices, 3x3<br/>
4 matrices, 5x5<br/>
3 matrices 9x9<br/>
2 matrices 15x15<br/>
<br/>
Decidable<br/>
2 matrices 2x2<br/>
<br/>
So there are some gaps to fill, but there is not the vast gulf that exists between dec and undec for Hilberts 10th problem. I also note that the paper was about UNDEC but mentioned the DEC results, where as the papers on H10 about UNDEC seem to never mention the DEC.<br/>
<br/>
I am glad to know another natural Undec problem and I will likely tell my students about it next spring. And much like H10, I won't be proving it.<br/>
<br/>
An open problem in education: how come some of my students got it wrong? gave an answer that was not in my notes or slides? One student told me it was easier to google<br/>
<br/>
<i>Natural Undecidable Questions</i><br/>
<br/>
then look through my slides. Another one said:<br/>
<br/>
<i>In class you said `this is a natural undecidable problem'.</i><br/>
<i><br/></i>
<i>On the exam you said `a problem that does not mention Turing Machines'</i><br/>
<i><br/></i>
<i>I did not know they were the same. </i><br/>
<br/>
That student submitted the Matrix problem stated above. It IS a fair point that `natural' is an<br/>
undefined term.  But the problem on the final used the well defined concept `does not mention Turing Machines'<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/></div>
    </content>
    <updated>2020-07-06T02:19:00Z</updated>
    <published>2020-07-06T02:19:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2020-07-06T17:42:45Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.01834</id>
    <link href="http://arxiv.org/abs/2007.01834" rel="alternate" type="text/html"/>
    <title>Universality of the Bottleneck Distance for Extended Persistence Diagrams</title>
    <feedworld_mtime>1593993600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bauer:Ulrich.html">Ulrich Bauer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Botnan:Magnus_Bakke.html">Magnus Bakke Botnan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fluhr:Benedikt.html">Benedikt Fluhr</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.01834">PDF</a><br/><b>Abstract: </b>The extended persistence diagram is an invariant of piecewise linear
functions, introduced by Cohen-Steiner, Edelsbrunner, and Harer. The bottleneck
distance has been introduced by the same authors as an extended pseudometric on
the set of extended persistence diagrams, which is stable under perturbations
of the function. We address the question whether the bottleneck distance is the
largest possible stable distance, providing an affirmative answer.
</p></div>
    </summary>
    <updated>2020-07-06T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-07-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.01779</id>
    <link href="http://arxiv.org/abs/2007.01779" rel="alternate" type="text/html"/>
    <title>The combined basic LP and affine IP relaxation for promise VCSPs on infinite domains</title>
    <feedworld_mtime>1593993600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Viola:Caterina.html">Caterina Viola</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zivny:Stanislav.html">Stanislav Zivny</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.01779">PDF</a><br/><b>Abstract: </b>Convex relaxations have been instrumental in solvability of constraint
satisfaction problems (CSPs), as well as in the three different generalisations
of CSPs: valued CSPs, infinite-domain CSPs, and most recently promise CSPs. In
this work, we extend an existing tractability result to the three
generalisations of CSPs combined: We give a sufficient condition for the
combined basic linear programming and affine integer programming relaxation for
exact solvability of promise valued CSPs over infinite-domains. This extends a
result of Brakensiek and Guruswami [SODA'20] for promise (non-valued) CSPs (on
finite domains).
</p></div>
    </summary>
    <updated>2020-07-06T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-07-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.01753</id>
    <link href="http://arxiv.org/abs/2007.01753" rel="alternate" type="text/html"/>
    <title>A Complete List of All Convex Polyhedra Made by Gluing Regular Pentagons</title>
    <feedworld_mtime>1593993600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Arseneva:Elena.html">Elena Arseneva</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Langerman:Stefan.html">Stefan Langerman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zolotov:Boris.html">Boris Zolotov</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.01753">PDF</a><br/><b>Abstract: </b>We give a complete description of all convex polyhedra whose surface can be
constructed from several congruent regular pentagons by folding and gluing them
edge to edge. Our method of determining the graph structure of the polyhedra
from a gluing is of independent interest and can be used in other similar
settings.
</p></div>
    </summary>
    <updated>2020-07-06T23:31:28Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-07-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.01686</id>
    <link href="http://arxiv.org/abs/2007.01686" rel="alternate" type="text/html"/>
    <title>Sublinear Explicit Incremental Planar Voronoi Diagrams</title>
    <feedworld_mtime>1593993600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Arseneva:Elena.html">Elena Arseneva</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Iacono:John.html">John Iacono</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Koumoutsos:Grigorios.html">Grigorios Koumoutsos</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Langerman:Stefan.html">Stefan Langerman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zolotov:Boris.html">Boris Zolotov</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.01686">PDF</a><br/><b>Abstract: </b>A data structure is presented that explicitly maintains the graph of a
Voronoi diagram of $N$ point sites in the plane or the dual graph of a convex
hull of points in three dimensions while allowing insertions of new
sites/points. Our structure supports insertions in $\tilde O (N^{3/4})$
expected amortized time, where $\tilde O$ suppresses polylogarithmic terms.
This is the first result to achieve sublinear time insertions; previously it
was shown by Allen et al. that $\Theta(\sqrt{N})$ amortized combinatorial
changes per insertion could occur in the Voronoi diagram but a sublinear-time
algorithm was only presented for the special case of points in convex position.
</p></div>
    </summary>
    <updated>2020-07-06T23:27:35Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-07-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.01673</id>
    <link href="http://arxiv.org/abs/2007.01673" rel="alternate" type="text/html"/>
    <title>On girth and the parameterized complexity of token sliding and token jumping</title>
    <feedworld_mtime>1593993600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bartier:Valentin.html">Valentin Bartier</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bousquet:Nicolas.html">Nicolas Bousquet</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dallard:Cl=eacute=ment.html">Clément Dallard</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lomer:Kyle.html">Kyle Lomer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mouawad:Amer_E=.html">Amer E. Mouawad</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.01673">PDF</a><br/><b>Abstract: </b>In the Token Jumping problem we are given a graph $G = (V,E)$ and two
independent sets $S$ and $T$ of $G$, each of size $k \geq 1$. The goal is to
determine whether there exists a sequence of $k$-sized independent sets in $G$,
$\langle S_0, S_1, \ldots, S_\ell \rangle$, such that for every $i$, $|S_i| =
k$, $S_i$ is an independent set, $S = S_0$, $S_\ell = T$, and $|S_i \Delta
S_{i+1}| = 2$. In other words, if we view each independent set as a collection
of tokens placed on a subset of the vertices of $G$, then the problem asks for
a sequence of independent sets which transforms $S$ to $T$ by individual token
jumps which maintain the independence of the sets. This problem is known to be
PSPACE-complete on very restricted graph classes, e.g., planar bounded degree
graphs and graphs of bounded bandwidth. A closely related problem is the Token
Sliding problem, where instead of allowing a token to jump to any vertex of the
graph we instead require that a token slides along an edge of the graph. Token
Sliding is also known to be PSPACE-complete on the aforementioned graph
classes. We investigate the parameterized complexity of both problems on
several graph classes, focusing on the effect of excluding certain cycles from
the input graph. In particular, we show that both Token Sliding and Token
Jumping are fixed-parameter tractable on $C_4$-free bipartite graphs when
parameterized by $k$. For Token Jumping, we in fact show that the problem
admits a polynomial kernel on $\{C_3,C_4\}$-free graphs. In the case of Token
Sliding, we also show that the problem admits a polynomial kernel on bipartite
graphs of bounded degree. We complement these positive results by showing that,
for any constant $p \geq 4$, both problems are W[1]-hard on $C_\ell$-free
graphs, where $4 \leq \ell \leq p$, and Token Sliding remains W[1]-hard even on
bipartite graphs.
</p></div>
    </summary>
    <updated>2020-07-06T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-07-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.01578</id>
    <link href="http://arxiv.org/abs/2007.01578" rel="alternate" type="text/html"/>
    <title>volesti: Volume Approximation and Sampling for Convex Polytopes in R</title>
    <feedworld_mtime>1593993600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chalkis:Apostolos.html">Apostolos Chalkis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fisikopoulos:Vissarion.html">Vissarion Fisikopoulos</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.01578">PDF</a><br/><b>Abstract: </b>Sampling from high dimensional distributions and volume approximation of
convex bodies are fundamental operations that appear in optimization, finance,
engineering and machine learning. In this paper we present volesti, a C++
package with an R interface that provides efficient, scalable algorithms for
volume estimation, uniform and Gaussian sampling from convex polytopes. volesti
scales to hundreds of dimensions, handles efficiently three different types of
polyhedra and provides non existing sampling routines to R. We demonstrate the
power of volesti by solving several challenging problems using the R language.
</p></div>
    </summary>
    <updated>2020-07-06T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-07-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.01533</id>
    <link href="http://arxiv.org/abs/2007.01533" rel="alternate" type="text/html"/>
    <title>Finding Densest $k$-Connected Subgraphs</title>
    <feedworld_mtime>1593993600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bonchi:Francesco.html">Francesco Bonchi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Garc=iacute=a=Soriano:David.html">David García-Soriano</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Miyauchi:Atsushi.html">Atsushi Miyauchi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tsourakakis:Charalampos_E=.html">Charalampos E. Tsourakakis</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.01533">PDF</a><br/><b>Abstract: </b>Dense subgraph discovery is an important graph-mining primitive with a
variety of real-world applications. One of the most well-studied optimization
problems for dense subgraph discovery is the densest subgraph problem, where
given an edge-weighted undirected graph $G=(V,E,w)$, we are asked to find
$S\subseteq V$ that maximizes the density $d(S)$, i.e., half the weighted
average degree of the induced subgraph $G[S]$. This problem can be solved
exactly in polynomial time and well-approximately in almost linear time.
However, a densest subgraph has a structural drawback, namely, the subgraph may
not be robust to vertex/edge failure. Indeed, a densest subgraph may not be
well-connected, which implies that the subgraph may be disconnected by removing
only a few vertices/edges within it. In this paper, we provide an algorithmic
framework to find a dense subgraph that is well-connected in terms of
vertex/edge connectivity. Specifically, we introduce the following problems:
given a graph $G=(V,E,w)$ and a positive integer/real $k$, we are asked to find
$S\subseteq V$ that maximizes the density $d(S)$ under the constraint that
$G[S]$ is $k$-vertex/edge-connected. For both problems, we propose
polynomial-time (bicriteria and ordinary) approximation algorithms, using
classic Mader's theorem in graph theory and its extensions.
</p></div>
    </summary>
    <updated>2020-07-06T23:22:32Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-07-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.01445</id>
    <link href="http://arxiv.org/abs/2007.01445" rel="alternate" type="text/html"/>
    <title>Minimizing Convex Functions with Integral Minimizers</title>
    <feedworld_mtime>1593993600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jiang:Haotian.html">Haotian Jiang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.01445">PDF</a><br/><b>Abstract: </b>Given a separation oracle $\mathsf{SO}$ for a convex function $f$ that has an
integral minimizer inside a box with radius $R$, we show how to efficiently
find a minimizer of $f$ using at most $O(n (n + \log(R)))$ calls to
$\mathsf{SO}$. When the set of minimizers of $f$ has integral extreme points,
our algorithm outputs an integral minimizer of $f$. This improves upon the
previously best oracle complexity of $O(n^2 (n + \log(R)))$ obtained by an
elegant application of [Frank and Tardos, Combinatorica 1987] due to Dadush. We
conjecture that our oracle complexity is tight up to constant factors.
</p>
<p>Our result immediately implies a strongly polynomial algorithm for the
Submodular Function Minimization problem that makes at most $O(n^3)$ calls to
an evaluation oracle. This improves upon the previously best $O(n^3 \log^2(n))$
oracle complexity for strongly polynomial algorithms given in [Lee, Sidford and
Wong, FOCS 2015] and [Dadush, V{\'e}gh and Zambelli, SODA 2018], and an
exponential time algorithm with oracle complexity $O(n^3 \log(n))$ given in the
former work, answering two open problems posted therein.
</p>
<p>Our result is achieved by an application of the LLL algorithm [Lenstra,
Lenstra and Lov\'asz, Math. Ann. 1982] for the shortest lattice vector problem.
We show how an approximately shortest vector of certain lattice can be used to
reduce the dimension of the problem, and how the oracle complexity of such a
procedure is advantageous compared with the method that uses the Frank-Tardos
framework. Our analysis of the oracle complexity is based on a potential
function that captures simultaneously the size of the search set and the
density of the lattice. To achieve the $O(n^2)$ term in the oracle complexity,
technical ingredients from convex geometry are applied.
</p></div>
    </summary>
    <updated>2020-07-06T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-07-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.01428</id>
    <link href="http://arxiv.org/abs/2007.01428" rel="alternate" type="text/html"/>
    <title>Medial Axis Isoperimetric Profiles</title>
    <feedworld_mtime>1593993600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Paul.html">Paul Zhang</a>, Daryl Deford, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Solomon:Justin.html">Justin Solomon</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.01428">PDF</a><br/><b>Abstract: </b>Recently proposed as a stable means of evaluating geometric compactness, the
isoperimetric profile of a planar domain measures the minimum perimeter needed
to inscribe a shape with prescribed area varying from 0 to the area of the
domain. While this profile has proven valuable for evaluating properties of
geographic partitions, existing algorithms for its computation rely on
aggressive approximations and are still computationally expensive. In this
paper, we propose a practical means of approximating the isoperimetric profile
and show that for domains satisfying a "thick neck" condition, our
approximation is exact. For more general domains, we show that our bound is
still exact within a conservative regime and is otherwise an upper bound. Our
method is based on a traversal of the medial axis which produces efficient and
robust results. We compare our technique with the state-of-the-art
approximation to the isoperimetric profile on a variety of domains and show
significantly tighter bounds than were previously achievable.
</p></div>
    </summary>
    <updated>2020-07-06T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-07-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.01409</id>
    <link href="http://arxiv.org/abs/2007.01409" rel="alternate" type="text/html"/>
    <title>A (Slightly) Improved Approximation Algorithm for Metric TSP</title>
    <feedworld_mtime>1593993600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Karlin:Anna_R=.html">Anna R. Karlin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Klein:Nathan.html">Nathan Klein</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gharan:Shayan_Oveis.html">Shayan Oveis Gharan</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.01409">PDF</a><br/><b>Abstract: </b>For some $\epsilon &gt; 10^{-36}$ we give a $3/2-\epsilon$ approximation
algorithm for metric TSP.
</p></div>
    </summary>
    <updated>2020-07-06T23:24:32Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-07-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.01394</id>
    <link href="http://arxiv.org/abs/2007.01394" rel="alternate" type="text/html"/>
    <title>Robust Linear Regression: Optimal Rates in Polynomial Time</title>
    <feedworld_mtime>1593993600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bakshi:Ainesh.html">Ainesh Bakshi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Prasad:Adarsh.html">Adarsh Prasad</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.01394">PDF</a><br/><b>Abstract: </b>We obtain a robust and computationally efficient estimator for Linear
Regression that achieves statistically optimal convergence rate under mild
distributional assumptions. Concretely, we assume our data is drawn from a
$k$-hypercontractive distribution and an $\epsilon$-fraction is adversarially
corrupted. We then describe an estimator that converges to the optimal
least-squares minimizer for the true distribution at a rate proportional to
$\epsilon^{2-2/k}$, when the noise is independent of the covariates. We note
that no such estimator was known prior to our work, even with access to
unbounded computation. The rate we achieve is information-theoretically optimal
and thus we resolve the main open question in Klivans, Kothari and Meka
[COLT'18]. Our key insight is to identify an analytic condition relating the
distribution over the noise and covariates that completely characterizes the
rate of convergence, regardless of the noise model. In particular, we show that
when the moments of the noise and covariates are negatively-correlated, we
obtain the same rate as independent noise. Further, when the condition is not
satisfied, we obtain a rate proportional to $\epsilon^{2-4/k}$, and again match
the information-theoretic lower bound. Our central technical contribution is to
algorithmically exploit independence of random variables in the
"sum-of-squares" framework by formulating it as a polynomial identity.
</p></div>
    </summary>
    <updated>2020-07-06T23:25:15Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-07-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2020/07/05/shape-wankel-rotor</id>
    <link href="https://11011110.github.io/blog/2020/07/05/shape-wankel-rotor.html" rel="alternate" type="text/html"/>
    <title>The shape of the Wankel rotor</title>
    <summary>I’ve written a number of posts about curvilinear triangles that are not the Reuleaux triangle, including MIT’s Kresge Auditorium, triforce string art, valve covers, a patio table, and the logo of Whale Cove, Nunavut. I’ve long intended to write about another obvious topic in this theme, the curved-triangle rotor of the Wankel engine, but was finally pushed into doing so by seeing that two recent popular mathematics books, How Round Is Your Circle? (2008) and Icons of Mathematics (2011) repeat the falsehood that Wankel rotors are Reuleaux triangles. They are not.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I’ve written a number of posts about curvilinear triangles that are not the <a href="https://en.wikipedia.org/wiki/Reuleaux_triangle">Reuleaux triangle</a>, including <a href="https://11011110.github.io/blog/2016/04/30/shape-of-kresge.html">MIT’s Kresge Auditorium</a>, <a href="https://web.archive.org/web/20190217225035/https://plus.google.com/100003628603413742554/posts/DpF5krEaU9u">triforce string art</a>, <a href="https://11011110.github.io/blog/2018/04/17/mythical-reuleaux-manhole.html">valve covers</a>, <a href="https://11011110.github.io/blog/2018/06/24/la-maddalena-non-reuleaux.html">a patio table</a>, and <a href="https://11011110.github.io/blog/2020/06/30/linkage.html">the logo of Whale Cove, Nunavut</a>. I’ve long intended to write about another obvious topic in this theme, the curved-triangle rotor of the <a href="https://en.wikipedia.org/wiki/Wankel_engine">Wankel engine</a>, but was finally pushed into doing so by seeing that two recent popular mathematics books, <em><a href="https://en.wikipedia.org/wiki/How_Round_Is_Your_Circle">How Round Is Your Circle?</a></em> (2008) and <em><a href="https://en.wikipedia.org/wiki/Icons_of_Mathematics">Icons of Mathematics</a></em> (2011) repeat the falsehood that Wankel rotors are Reuleaux triangles. They are not.</p>

<p>Wikipedia has <a href="https://commons.wikimedia.org/wiki/File:Wankel_Cycle_anim_en.gif">a good visualization of how Wankel engines work</a>, which I’ve copied below. They go through the same four steps as a conventional <a href="https://en.wikipedia.org/wiki/Four-stroke_engine">four-stroke combustion engine</a>, in which a piston pulls away from the combustion chamber, sucking in a mixture of fuel and air, pushes back towards the chamber, compressing the mixture, ignites the mixture, pushing the piston back out and applying force to the drive shaft, and then pushes back towards the chamber, pushing the exhaust out. The difference is that in a Wankel engine, these four steps happen at four different locations within the combustion chamber, as the gases within it are pushed around by a curved triangular piston, the rotor of the engine.</p>

<p style="text-align: center;"><img alt="Animation of a Wankel engine by Y tambe from https://commons.wikimedia.org/wiki/File:Wankel_Cycle_anim_en.gif" src="https://11011110.github.io/blog/assets/2020/animated-wankel.gif"/></p>

<p>The driveshaft in the engine is the fixed smaller gear in the center of the animation; in the actual engine, this gearwheel would itself be spinning, but this is not shown. The triangular rotor connects to the driveshaft by an eccentric planetary gear, and spins around the driveshaft like a hula hoop around a spinning dancer. The gears have teeth and radii in the ratio 3:2, causing the driveshaft to spin three times faster than the rotor. As it does so, the three corners of the rotor (the “apex seals”) stay in contact with the outer wall of the engine, called its stator, so that the gases in the engine do not leak between different phases.</p>

<p>The shape of the stator is not determined by the curve of the rotor itself, but only by the trajectory of the moving apex seals. This trajectory is a curve called an <a href="https://en.wikipedia.org/wiki/Epitrochoid">epitrochoid</a>. If you’ve ever played with a spirograph, you know what an epitroichoid is: it’s what you get by fixing one circular disk, letting another circular disk rotate around it, placing a point somewhere within the rotating disk, and tracing the curve that it follows. Here’s <a href="https://commons.wikimedia.org/wiki/File:EpitrochoidIn3.gif">another Wikipedia animation</a>:</p>

<p style="text-align: center;"><img alt="Animation of an epitrochoid by Sam Derbyshire from https://commons.wikimedia.org/wiki/File:EpitrochoidIn3.gif" src="https://11011110.github.io/blog/assets/2020/animated-epitrochoid.gif"/></p>

<p>Different ratios of radii between the inner and outer disk give you different numbers of lobes in the curve, and different placements of the moving point in the outer disk (closer to or farther from the disk center) give you curves that are closer to a circle or more curvy. Placing the moving point on the outer circle itself gives you pointy rather than curvy epitrochoids, and placing it even farther out turns the inner bulges of these curves into self-crossing loops.</p>

<p>Spirograph trajectories differ from rotating apex seal trajectories in at least three ways: in the Wankel engine, the central circle (the driveshaft) rotates rather than being held stationary, the outer circle (the planetary gear) surrounds the central circle rather than being outside it, and the point whose motion is being traced (the apex seal) is outside the outer circle rather than inside it. Nevertheless, the shape is still a two-lobed epitrochoid; see the “double generation theorem” of the Bernoullis, as described by Nash,<sup id="fnref:nash"><a class="footnote" href="https://11011110.github.io/blog/2020/07/05/shape-wankel-rotor.html#fn:nash">1</a></sup> for why the same curve can be generated in multiple ways. Modulo the scale of the whole system, there is one free parameter controlling the precise shape of this epitrochoid: the ratio of the distances from the center of the rotor to the apex seals and to the planetary gear. If the apex seals are too close in, the planetary gear will bash into into the stator; if they are too far out, the stator will be close to circular and there will be little change in pressure from one part of the combustion cycle to another, losing engine efficiency. The choice made in actual engines is not the one that places the apex seals as close as possible, but seems to involve more careful optimization that considers the shape and size of the regions formed by the rotor and stator at different stages of the combustion cycle.</p>

<p>Once the stator shape has been determined, one can then proceed to answer the question we started with: what is the shape of the rotor? The main design constraint is that it should touch or at least stay close to the inner bulge of the stator (on its “side seals”), to prevent exhaust gas from flowing back around to the intake. The shape that achieves this can be understood by a thought experiment in which we imagine the rotor as somehow being fixed in space while the vehicle containing it rotates around it, rather than vice versa. As the vehicle rotates, its stator passes through parts of the space that cannot be occupied by the rotor. The parts of space that remain untouched by the rotating stator are available to be used by the rotor, and should be used by it if we want a rotor that stays in contact with the stator on its side seals. Mathematically, this is described as an “envelope” of the positions of the rotating stator with respect to the fixed rotor. This envelope is a curved triangle, but not a Reuleaux triangle. Its curves are flatter than a Reuleaux triangle’s arcs, but also they are not circular arcs. As an envelope of algebraic curves, they are presumably algebraic themselves, but of higher order; trigonometric formulas are given by Shung and Pennock.<sup id="fnref:sp"><a class="footnote" href="https://11011110.github.io/blog/2020/07/05/shape-wankel-rotor.html#fn:sp">2</a></sup></p>

<p>In practice, the rotor shape varies from its ideal envelope-of-epitrochoid form, in a couple of different ways. First, as Drogosz explains,<sup id="fnref:drogosz"><a class="footnote" href="https://11011110.github.io/blog/2020/07/05/shape-wankel-rotor.html#fn:drogosz">3</a></sup> for ease of manufacturing it is often approximated by circular arcs rather than exactly following the envelope shape. As long as the approximation stays within the envelope, the rotor will avoid colliding with the stator, and the side seal contact is not so important near the corners of the triangle, so that’s where the approximation is most noticeable. Second, real Wankel rotors often have scoops taken out from the middles of their sides, to form mini-combustion chambers that guide and shape the combustion gases within the engine.</p>

<p>For more details of all this, see:</p>

<div class="footnotes">
  <ol>
    <li id="fn:nash">
      <p>Nash, David H. (1977), “Rotary engine geometry”, <em>Mathematics Magazine</em> 2: 87–89, <a href="https://doi.org/doi:10.1080/0025570X.1977.11976621">doi:10.1080/0025570X.1977.11976621</a>, <a href="https://www.jstor.org/stable/2689731">JSTOR:2689731</a> <a class="reversefootnote" href="https://11011110.github.io/blog/2020/07/05/shape-wankel-rotor.html#fnref:nash">↩</a></p>
    </li>
    <li id="fn:sp">
      <p>Shung, J. B. &amp; Pennock, G. R. (1994), “Geometry for trochoidal-type machines with conjugate envelopes”, <em>Mechanism and Machine Theory</em> 29 (1): 25–42, <a href="https://doi.org/10.1016/0094-114X(94)90017-5">doi:10.1016/0094-114X(94)90017-5</a> <a class="reversefootnote" href="https://11011110.github.io/blog/2020/07/05/shape-wankel-rotor.html#fnref:sp">↩</a></p>
    </li>
    <li id="fn:drogosz">
      <p>Drogosz, P. (2010), “Geometry of the Wankel rotary engine”, <em>Journal of KONES</em> 17 (3): 69–74, <a href="http://yadda.icm.edu.pl/yadda/element/bwmeta1.element.baztech-article-BUJ5-0031-0018">http://yadda.icm.edu.pl/yadda/element/bwmeta1.element.baztech-article-BUJ5-0031-0018</a> <a class="reversefootnote" href="https://11011110.github.io/blog/2020/07/05/shape-wankel-rotor.html#fnref:drogosz">↩</a></p>
    </li>
  </ol>
</div>

<p>(<a href="https://mathstodon.xyz/@11011110/104464015428969365">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2020-07-05T14:59:00Z</updated>
    <published>2020-07-05T14:59:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2020-07-06T00:35:22Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/098</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/098" rel="alternate" type="text/html"/>
    <title>TR20-098 |  Impossibility of Derandomizing the Isolation Lemma for all Families | 

	Rohit Gurjar, 

	Thomas Thierauf, 

	Manindra Agrawal</title>
    <summary>The Isolation Lemma states that when random weights are assigned to the elements of a finite set $E$, then in any given family of subsets of $E$, exactly one set has the minimum weight, with high probability. In this note, we present two proofs for the fact that it is impossible to efficiently derandomize the Isolation Lemma for arbitrary families.

The first proof is from Chari, Rohatgi and Srinivasan and uses the potential method. An alternate proof is due to the first author of this note. It uses the polynomial method. However, it is not written anywhere. The main purpose of this note is to present that proof. Additionally we show that the above lower bounds are almost tight with respect to various parameters.</summary>
    <updated>2020-07-05T06:22:25Z</updated>
    <published>2020-07-05T06:22:25Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-07-07T00:20:37Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=17257</id>
    <link href="https://rjlipton.wordpress.com/2020/07/04/intellectual-fireworks/" rel="alternate" type="text/html"/>
    <title>Intellectual Fireworks?</title>
    <summary>Some different ideas for marking the Fourth “Founding Frenemies” source John Adams and Thomas Jefferson did not use Zoom. Their correspondence, from 1777 up to their deaths hours apart on July 4, 1826, fills a 600-page book. Today, Independence Day in the US, we consider the kind of intellectual fireworks represented by the correspondence. Jefferson […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Some different ideas for marking the Fourth</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2020/07/list-coincidence-adams-jefferson-2.jpg"><img alt="" class="alignright wp-image-17259" height="90" src="https://rjlipton.files.wordpress.com/2020/07/list-coincidence-adams-jefferson-2.jpg?w=180&amp;h=90" width="180"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">“Founding Frenemies” <a href="https://www.history.com/news/jefferson-adams-founding-frenemies">source</a></font></td>
</tr>
</tbody>
</table>
<p>
John Adams and Thomas Jefferson did not use Zoom. Their correspondence, from 1777 up to their deaths hours apart on July 4, 1826, fills a 600-page <a href="https://www.amazon.com/Adams-Jefferson-Letters-Complete-Correspondence-Jefferson/dp/0807842303">book</a>. </p>
<p>
Today, Independence Day in the US, we consider the kind of intellectual fireworks represented by the correspondence.</p>
<p>
Jefferson and Adams were intellectual opposites as well as political rivals. Adams favored a strong central government to bridle human passions, whereas Jefferson’s support for the French Revolution continued beyond its devolution into the Reign of Terror. They debated many other points of politics, philosophy, and culture. </p>
<p>
Abigail Adams, the wife of John, joined in some of the exchanges. Because she often stayed in Massachusetts while he was in Philadelphia or New York or elsewhere, the husband and wife exchanged many letters—over 1,100 in all. His letter to her on July 3, 1776, instituted the use of fireworks to celebrate anniversaries of the Declaration of Independence.</p>
<p>
Today there is not much in the way of fireworks displays. Most have been canceled because we cannot allow crowds to view them. In the Buffalo area, some townships are having small displays with limited access, and some displays are being set on high points for possible area viewing. So we felt we should write about fireworks of a different kind, a kind that is not restricted by the pandemic and might thrive through it. But first we’ll make a point about the history of fireworks.</p>
<p>
</p><p/><h2> Fireworks: Ancient, Early, and Modern </h2><p/>
<p/><p>
Fireworks go back at least 1,100 years to China, where chemists discovered the fun of stuffing volatile compounds into tubes of bamboo or paper and setting them off. Some have pyrotechnics going back another 1,000 years, to about 200 BCE, insofar as bamboo was known to pop with a loud sound when dried and heated. Gunpowder traveled best of the compounds and made its way into Europe at least by the 1200s. The first recorded wide-scale fireworks display in England was in 1486 for the wedding of King Henry VII to Elizabeth of York, which ended the Wars of the Roses. Shakespeare mentions fireworks in <em>Love’s Labours Lost</em>. The Mughals in India from the 1500s to the 1800s made fireworks a diversion for noble women on the Diwali holiday:</p>
<p/><p/>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2020/07/diwali_570_850.jpg"><img alt="" class="aligncenter size-medium wp-image-17260" height="254" src="https://rjlipton.files.wordpress.com/2020/07/diwali_570_850.jpg?w=300&amp;h=254" width="300"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Cleveland Museum of Art <a href="https://www.clevelandart.org/art/1971.82">source</a></font>
</td>
</tr>
</tbody></table>
<p>
Our point is that 1776 isn’t even halfway back to the beginning of using fireworks for celebrations, even just in the West. Can we even call it “Early”? Lavish displays to mark major events were common by the mid-1700s. A royal display in 1749 was accompanied by orchestral music commissioned from George Frideric Handel and went ahead despite rain. Over 12,000 people also paid to attend the main rehearsal six days earlier, many braving an hours-long traffic jam on approaches to the London Bridge. That feels quite modern to us. Adams’s <a href="https://founders.archives.gov/documents/Adams/04-02-02-0016">letter</a> mentioned other social features we know today:</p>
<blockquote><p><b> </b> <em> It ought to be solemnized with Pomp and Parade, with Shews, Games, Sports, Guns, Bells, Bonfires and Illuminations from one End of this Continent to the other from this Time forward forever more. </em>
</p></blockquote>
<p/><p>
The pandemic has curtailed others of these. The major North American team sports have not resumed either. Some parades have been run in “reverse” mode: the floats and performers stay put while spectators drive by slowly in cars.</p>
<p>
Adams’s letter has another, earlier, passage that chills today. The letter begins by saying that the Declaration was supposed to have been made in December, 1775, and enumerates plans the colonies had made contingent on this. He then says that what caused the plans to be aborted was an outbreak of disease:</p>
<blockquote><p><b> </b> <em> All these Causes however in Conjunction would not have disappointed Us, if it had not been for a Misfortune, which could not be foreseen, and perhaps could not have been prevented, I mean the Prevalence of the small Pox among our Troops. . . . This fatal Pestilence compleated our Destruction.—It is a Frown of Providence upon Us, which We ought to lay to heart. </em>
</p></blockquote>
<p/><p>
The ellipsis is in the letter—as Ken’s children have pointed out, trailing off thought with dots in letters or e-mails or Facebook posts or texts is a distinctive habit of us older folk. Thus a specific outbreak of a contagious disease changed our history then as now.</p>
<p>
</p><p/><h2> Ideas: Ancient, Early, and Modern </h2><p/>
<p/><p>
We have <a href="https://rjlipton.wordpress.com/2020/06/21/some-real-and-some-virtual-news/">remarked</a> on how the pandemic has affected opportunities to exchange ideas and how to compensate. One impacted series that both of us intended to visit this spring has been the series of workshops at the Simons Institute in Berkeley. </p>
<p>
Still, the Simons Foundation has continued its other ways to stimulate ideas. Here we offer our congratulations to Venkatesan Guruswami, Omer Reingold, and David Woodruff, who have just been <a href="https://www.simonsfoundation.org/grant/simons-investigators/?tab=awardees&amp;filter_years=2020">appointed</a> as Simons investigators for 2020. </p>
<p>
In briefly talking about their work, we want to make a point about how the pandemic enables <em>taking the long view</em> of ideas—in a way that appointments such as these promote. It is easy to get wrapped up in immediate aspects of a current hot problem and not be aware that it has a history. The history may not involve exactly the same ideas as the problem, but related ideas whose importance was appreciated much earlier. “Early” may not mean the Middle Ages or the 1700s as with fireworks, but it can mean times before any of us were born.</p>
<p>
Venkatesan and Omer and David each have done some stellar research, broadly in various parts of theory. They each have many results, but we thought we would highlight just one result each. We picked a result that we think is representative, is deep, is beautiful, and is one that we personally admire the most.</p>
<p>
</p><p/><h3> “Ancient” Times </h3><p/>
<p/><p>
Venkatesan did important work on a problem that was created before complexity theory existed. Our favorite is his ground-breaking work on list decoding.</p>
<p>
What is the best way to encode data to protect it against various kinds of errors? This is still open. But Venkatesan changed the landscape. </p>
<p>
The questions about error correcting codes go back to the 1940’s. Usually the first results are <a href="https://en.wikipedia.org/wiki/Error_detection_and_correction">credited</a> to Richard Hamming in 1947. Soon the notion of list decoding was introduced. The cool idea is that doing not require an answer, but allow a list of possible answers. The hope is that with other information about the message we might be able to select <i>the</i> answer.</p>
<p>
Venkatesan and Ken’s colleague Atri Rudra found explicit <a href="https://en.wikipedia.org/wiki/List_decoding">codes</a> that achieve list-decoding capacity, that is, they have optimal redundancy. </p>
<p>
What we like so much is the model is so natural and so powerful. There are many applications of list decoding to complexity theory. See Madhu Sudan’s <a href="http://people.csail.mit.edu/madhu/papers/noneed/ifip-journ.ps">survey</a> for some additional comments. </p>
<p>
</p><p/><h3> Early Times </h3><p/>
<p/><p>
Omer did his most important work on problems that were first studied in the early days of complexity theory. Our favorite is his beautiful work on small-memory deterministic graph <a href="https://en.wikipedia.org/wiki/SL_(complexity)">walks</a>. </p>
<p>
Is <img alt="{\mathsf{L &lt; NL}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BL+%3C+NL%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{L &lt; NL}}"/>? This is still <a href="https://en.wikipedia.org/wiki/NL_(complexity)">open</a>. But Omer made a huge contribution to our understanding of fundamental complexity classes. Romas Aleliunas, Dick Karp, Laszlo Lovasz, and Charlie Rackoff proved earlier that random small space could navigate undirected graphs provided they could flip coins. In a sense Omer removed the coins to get his result that undirected graph connectivity is in <img alt="{\mathsf{L}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BL%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{L}}"/>. The previous result was easy—I can say that because I (Dick) was a co-author on it—but Omer’s theorem is deep.</p>
<p>
Omer’s <a href="https://omereingold.files.wordpress.com/2014/10/sl.pdf">proof</a> drew heavily on expander graphs and the zig-zag product from his earlier work with Salil Vadhan and Avi Wigderson for creating them. </p>
<p>
</p><p/><h3> Modern Times </h3><p/>
<p/><p>
David did his most important work on problems that were only created relatively recently. Our favorite is his work on approximately <a href="http://www.cs.cmu.edu/afs/cs/user/dwoodruf/www/knw10b.pdf">counting</a> distinct elements. This work is joint with Daniel Kane and Jelani Nelson and appeared at PODS 2010. It was the first streaming algorithm with an optimal combination of space usage and update time. Here is the relevant table from their paper (KNW):</p>
<p><a href="https://rjlipton.files.wordpress.com/2020/07/algtable.jpg"><img alt="" class="aligncenter wp-image-17261" height="163" src="https://rjlipton.files.wordpress.com/2020/07/algtable.jpg?w=500&amp;h=163" width="500"/></a></p>
<p>
Streaming algorithms are relatively new and parts of data science are newer. But working with data is old, as old as codes. This finally leads us to pose an outlandish question:</p>
<blockquote><p><b> </b> <em> Can all of this work be usefully interpreted from the standpoint of coding theory? </em>
</p></blockquote>
<p/><p>
This is outlandish, because the word “code” does not even appear in either Reingold’s paper or KNW. But part of holding coding theory to be a paradigm, as both Ken and I experienced in graduate school, is that its perspective should expand. Is this capable of creating intellectual fireworks? We’ll see.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Have a safe and happy fourth of July.</p>
<p>
[some small fixes]</p></font></font></div>
    </content>
    <updated>2020-07-05T00:41:25Z</updated>
    <published>2020-07-05T00:41:25Z</published>
    <category term="All Posts"/>
    <category term="History"/>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="coding theory"/>
    <category term="David Woodruff"/>
    <category term="fireworks"/>
    <category term="Fourth of July"/>
    <category term="John Adams"/>
    <category term="Omer Reingold"/>
    <category term="pandemic"/>
    <category term="Simons Foundation"/>
    <category term="Thomas Jefferson"/>
    <category term="Venkatesan Guruswami"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2020-07-07T00:20:48Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/07/03/postdoc-in-quantum-computing-at-nagoya-and-mie-universities-apply-by-july-15-2020/</id>
    <link href="https://cstheory-jobs.org/2020/07/03/postdoc-in-quantum-computing-at-nagoya-and-mie-universities-apply-by-july-15-2020/" rel="alternate" type="text/html"/>
    <title>Postdoc in quantum computing at Nagoya and Mie Universities (apply by July 15, 2020)</title>
    <summary>Nagoya and Mie Universities (Japan) are looking for several postdoctoral researchers to work on quantum computing, especially on the following subjects: 1) quantum algorithms, 2) quantum complexity theory, 3) theoretical aspects of quantum programming languages, 4) development of software verification tools for quantum programs, 5) quantum information theory. Website: http://francoislegall.com/jobs.html Email: legall@math.nagoya-u.ac.jp</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Nagoya and Mie Universities (Japan) are looking for several postdoctoral researchers to work on quantum computing, especially on the following subjects:</p>
<p>1) quantum algorithms,<br/>
2) quantum complexity theory,<br/>
3) theoretical aspects of quantum programming languages,<br/>
4) development of software verification tools for quantum programs,<br/>
5) quantum information theory.</p>
<p>Website: <a href="http://francoislegall.com/jobs.html">http://francoislegall.com/jobs.html</a><br/>
Email: legall@math.nagoya-u.ac.jp</p></div>
    </content>
    <updated>2020-07-03T11:18:55Z</updated>
    <published>2020-07-03T11:18:55Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-07-07T00:20:51Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4888</id>
    <link href="https://www.scottaaronson.com/blog/?p=4888" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4888#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4888" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Scott’s Zoom tip: Email the link!</title>
    <summary xml:lang="en-US">Like many academics, I’ve now been regularly “attending” conferences and giving talks via Zoom for four months. Naturally, I’ve learned a lot about how to use this platform—one that, despite numerous quirks and flaws, actually works well enough that it could probably replace at least 2/3 of in-person talks and meetings after the covid crisis […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>Like many academics, I’ve now been regularly “attending” conferences and giving talks via Zoom for four months.  Naturally, I’ve learned a lot about how to use this platform—one that, despite numerous quirks and flaws, <em>actually works</em> well enough that it could probably replace at least 2/3 of in-person talks and meetings after the covid crisis is over.  But one particular lesson is so important that I thought I’d make a public service announcement of it.  So without further ado:</p>



<p><strong>Email the link.</strong></p>



<p>You know, the thing like</p>



<p>https://us02web.zoom.us/jblahblah</p>



<p>that you actually click to get to the actual conversation.  <em>Definitely</em> email the link to the speaker (!).  But also email it to whomever said they plan to attend.  Resend the link between a day and an hour in advance, so that it doesn’t get buried, but turns up right away when people search their inboxes.  If possible, put the link in <em>every single email</em> about the meeting or lecture.  Even if you already sent the link for previous iterations of the meeting and it hasn’t changed, send it again.  Don’t assume people will find the link on the web.  Don’t make them click through five other links or open an attached PDF for it.  Don’t send ten emails that explain every possible detail of the meeting except how to get to it.  Just <strong>email the link.</strong>  That’s all.  Thanks!</p></div>
    </content>
    <updated>2020-07-03T06:43:42Z</updated>
    <published>2020-07-03T06:43:42Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Announcements"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2020-07-03T06:45:45Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=7759</id>
    <link href="https://windowsontheory.org/2020/07/02/crowdsourcing-masters-program/" rel="alternate" type="text/html"/>
    <title>Crowdsourcing Masters program</title>
    <summary>Going directly from undergraduate to Ph.D can be a good idea for many students interested in research, but it’s not the only route or the best choice for everyone. As I wrote before, for students that discovered their interest in theoretical CS late in their undergrad, or perhaps after they graduated, a research Masters, can […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Going directly from undergraduate to Ph.D can be a good idea for many students interested in research, but it’s not the only route or the best choice for everyone.</p>



<p>As <a href="https://windowsontheory.org/2018/02/20/research-masters/">I wrote before</a>, for students that discovered their interest in theoretical CS late in their undergrad, or perhaps after they graduated, a research Masters, can be a great option. This is particularly the case if the program is funded (i.e., students get a stipend and don’t need to pay tuition). Such programs are not common in the U.S., but there are some excellent choices around the world.</p>



<p>Since (as far as I know) there is no single source listing such programs, I thought a crowdsourced Google spreadsheet might be useful and so created one here: <a href="http://tiny.cc/tcsmasters" rel="nofollow">http://tiny.cc/tcsmasters</a></p>



<p>If you know of more places, please fill out this form: <a href="https://forms.gle/qfnbEZYYYDtFCDpx9" rel="nofollow">https://forms.gle/qfnbEZYYYDtFCDpx9</a> </p></div>
    </content>
    <updated>2020-07-02T19:26:22Z</updated>
    <published>2020-07-02T19:26:22Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2020-07-07T00:21:04Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/06/30/postdoc-at-university-of-oxford-apply-by-september-11-2020/</id>
    <link href="https://cstheory-jobs.org/2020/06/30/postdoc-at-university-of-oxford-apply-by-september-11-2020/" rel="alternate" type="text/html"/>
    <title>postdoc at University of Oxford (apply by September 11, 2020)</title>
    <summary>All Souls College Oxford are advertising a 5 year postdoctoral research fellowship in theoretical computer science, with a tentative start date 1 Oct 2021. This is an exceptional opportunity for a first-rate early career researcher in theoretical computer science. Website: https://www.asc.ox.ac.uk/post-doctoral-research-fellowships-2020-further-particulars Email: pdrf.admin@all-souls.ox.ac.uk</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>All Souls College Oxford are advertising a 5 year postdoctoral research fellowship in theoretical computer science, with a tentative start date 1 Oct 2021. This is an exceptional opportunity for a first-rate early career researcher in theoretical computer science.</p>
<p>Website: <a href="https://www.asc.ox.ac.uk/post-doctoral-research-fellowships-2020-further-particulars">https://www.asc.ox.ac.uk/post-doctoral-research-fellowships-2020-further-particulars</a><br/>
Email: pdrf.admin@all-souls.ox.ac.uk</p></div>
    </content>
    <updated>2020-06-30T16:27:02Z</updated>
    <published>2020-06-30T16:27:02Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-07-07T00:20:51Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2020/06/30/linkage</id>
    <link href="https://11011110.github.io/blog/2020/06/30/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>The five bridges puzzle (). Sort of like the bridges of Königsberg, but stochastic. A cute puzzle with a connection to percolation theory and connection games.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><ul>
  <li>
    <p><a href="https://scilogs.spektrum.de/hlf/the-five-bridges-puzzle/">The five bridges puzzle</a> (<a href="https://mathstodon.xyz/@11011110/104357604444143899"/>). Sort of like the bridges of Königsberg, but stochastic. A cute puzzle with a connection to percolation theory and connection games.</p>
  </li>
  <li>
    <p>Dubious journal publisher MDPI provides special-issue editors with some number of no-publication-charge slots, but requires that priority for these slots be given to first-world scholars, because they are the ones with “more abundant scientific research resources” (read: funds to pay publication charges). This didn’t sit well with three environmental health failure researchers, who <a href="https://retractionwatch.com/2020/06/16/failure-fails-as-publisher-privileges-the-privileged/">resigned their guest editorship over it</a> (<a href="https://mathstodon.xyz/@11011110/104363585936972806"/>, <a href="https://wash.leeds.ac.uk/what-the-f-how-we-failed-to-publish-a-journal-special-issue-on-failures/">see also</a>).</p>
  </li>
  <li>
    <p>On today’s edition of <a href="https://11011110.github.io/blog/2018/06/24/la-maddalena-non-reuleaux.html">not the Reuleaux triangle</a>, we have <a href="https://twitter.com/Nukaq/status/1273803547574972416">the logo of Whale Cove, Nunavut</a> (<a href="https://mathstodon.xyz/@11011110/104368587916436396"/>, <a href="https://www.metafilter.com/187552/Nunavut-Aesthetics">via</a>).  The sides of the triangle are straighter than a Reuleaux triangle would be, and its corners are slightly narrower than equilateral. Cool logo, though.</p>

    <p style="text-align: center;"><img alt="Logo of Whale Cove, Nunavut" src="https://11011110.github.io/blog/assets/2020/beluga-reuleaux.png"/></p>
  </li>
  <li>
    <p><a href="https://computerhistory.org/blog/discovering-dennis-ritchies-lost-dissertation/">Discovering Dennis Ritchie’s lost dissertation</a> (<a href="https://mathstodon.xyz/@11011110/104375200069651123"/>, <a href="https://news.ycombinator.com/item?id=23582070">via</a>). Ritchie’s doctoral committee signed off in 1968, but the Harvard Library wanted a bound copy and he was unwilling to pay the binding costs so he never officially received his Ph.D. According to the post, the thesis defines a simple model of computation characterizing primitive recursion, within which one can prove that the complexity and growth rates of primitive recursive functions are equal.</p>
  </li>
  <li>
    <p><a href="https://mathstodon.xyz/@tpfto/104376254903441351">J.M. redraws the xkcd golden spiral in Mathematica</a>. The thing that annoys me about it is the non-monotonic curvature, but that appears to be unavoidable.</p>
  </li>
  <li>
    <p><a href="https://www.youtube.com/playlist?list=PLn0nrSd4xjjadfcMd5xvmJ_GNSLDi1ATn">Playlist of talk videos from this year’s Symposium on Theory of Computing</a> (<a href="https://mathstodon.xyz/@11011110/104389387469883738"/>).</p>
  </li>
  <li>
    <p><a href="https://www.youtube.com/watch?v=wujEE3PRVUo">Video on the projective geometry of sidewalk trompe-l’oeil chalk art</a> (<a href="https://mathstodon.xyz/@11011110/104397742913356589"/>), and <a href="https://www.youtube.com/watch?v=L95cNBEfi5I">another one with less mathematics, more flying pigs and cute space aliens</a>.</p>
  </li>
  <li>
    <p><a href="https://www.makeuseof.com/tag/reduce-video-file-size-without-sacrificing-quality/">Some advice I needed on how to reduce video file size</a> (<a href="https://mathstodon.xyz/@11011110/104402114011362297"/>). Their suggestion of Handbrake worked well on its default settings and easily reached the file size I needed to reach, without sacrificing quality. (This was for a video of voice over still slides, so it should have been easy to compress, but iMovie couldn’t do it.)</p>
  </li>
  <li>
    <p><a href="https://blogs.ams.org/beyondreviews/2020/06/29/the-mathematics-genealogy-project-moves-to-the-cloud/">The Mathematics Genealogy Project rises into the clouds</a> (<a href="https://mathstodon.xyz/@11011110/104407629370705734"/>) like a phoenix from the flames of its dead former server. Or maybe not quite as poetically as that, but I use this resource daily in Wikipedia biography editing, so it’s a relief to learn that it’s back after its recent outage.</p>
  </li>
  <li>
    <p><a href="https://dl.acm.org/doi/10.1145/3357713.3384232">QCSP monsters and the demise of the Chen conjecture</a> (<a href="https://mathstodon.xyz/@11011110/104414859746330563"/>, <a href="https://www.youtube.com/watch?v=c2HjFlcTjQ0">talk video</a>). In STOC’20, Zhuk and Martin show that <a href="https://en.wikipedia.org/wiki/Schaefer%27s_dichotomy_theorem">dichotomy for constraint satisfaction</a> gets messier for quantified CSP. Chen conjectured that QCSP problems are either in NP or PSPACE-complete, but this new paper shows that coNP-completeness can happen for 3 elements and more elements lead to even more classes. Relatedly, <a href="http://eatcs.org/index.php/component/content/article/1-news/2849-the-eatcs-bestows-the-presburger-award-2020">Zhuk just won the Presburger Award</a>.</p>
  </li>
  <li>
    <p>I learned while writing <a href="https://en.wikipedia.org/wiki/Doyle_spiral">a Wikipedia article on Doyle spirals</a> (<a href="https://mathstodon.xyz/@11011110/104418935123493700"/>) that although the pure-mathematics work in this area dates to Coxeter in 1968 and the work of Thurston and his followers in the 1980s and 1990s, the use of spiral patterns of tangent circles to model plant growth can be traced back much earlier, to Gerrit van Iterson in 1907. The image below, which I used as the lead for the article, is an illustration of phylogeny from <a href="https://archive.org/details/popularsciencemo79newy/page/450/mode/2up">a 1911 <em>Popular Science</em> story about mathematical patterns in nature</a>.</p>

    <p style="text-align: center;"><img alt="Doyle spiral from _Popular Science_, 1911" src="https://11011110.github.io/blog/assets/2020/Doyle.png"/></p>
  </li>
  <li>
    <p><a href="https://www.lms.ac.uk/news-entry/26062020-1657/lms-prize-winners-2020">This year’s London Math Soc. prizewinners</a> (<a href="https://mathstodon.xyz/@11011110/104431647996227722"/>, <a href="https://twitter.com/hollykrieger/status/1276590144628416512">via</a>). For some reason they keep the <a href="https://www.lms.ac.uk/prizes/louisbachelierprize">Louis Bachelier Prize in a separate listing</a>. These results have already led me to add to Wikipedia brief articles on <a href="https://en.wikipedia.org/wiki/Maria_Bruna">Maria Bruna</a> (a Whitehead Prize winner) and <a href="https://en.wikipedia.org/wiki/Pauline_Barrieu">Pauline Barrieu</a> (Bachelier 2018).</p>
  </li>
  <li>
    <p><a href="https://www.chronicle.com/article/georgia-s-top-down/249095">A power struggle between the Georgia state university system and state government blocks Georgia Tech and other campuses from enacting any coronavirus safety rules</a> (<a href="https://mathstodon.xyz/@11011110/104435200227063842"/>).</p>
  </li>
</ul></div>
    </content>
    <updated>2020-06-30T16:06:00Z</updated>
    <published>2020-06-30T16:06:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2020-07-06T00:35:22Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/097</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/097" rel="alternate" type="text/html"/>
    <title>TR20-097 |  6-Uniform Maker-Breaker Game Is PSPACE-Complete | 

	Md Lutfar Rahman, 

	Thomas Watson</title>
    <summary>In a STOC 1976 paper, Schaefer proved that it is PSPACE-complete to determine the winner of the so-called Maker-Breaker game on a given set system, even when every set has size at most 11. Since then, there has been no improvement on this result. We prove that the game remains PSPACE-complete even when every set has size 6.</summary>
    <updated>2020-06-30T15:23:11Z</updated>
    <published>2020-06-30T15:23:11Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-07-07T00:20:37Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://kamathematics.wordpress.com/?p=188</id>
    <link href="https://kamathematics.wordpress.com/2020/06/30/virtual-stoc-2020-behind-the-screens/" rel="alternate" type="text/html"/>
    <title>Virtual STOC 2020 – Behind the Screens</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">In order to assist organizers of other virtual conferences, the general chairs of STOC 2020 (myself, Konstantin Makarychev, Yury Makarychev and Madhur Tulsiani, with input from PC chair Julia Chuzhoy) wrote a detailed document describing the design and execution of the conference. I personally felt the conference went about as well as it could have … <a class="more-link" href="https://kamathematics.wordpress.com/2020/06/30/virtual-stoc-2020-behind-the-screens/">Continue reading<span class="screen-reader-text"> "Virtual STOC 2020 – Behind the Screens"</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>In order to assist organizers of other virtual conferences, the general chairs of STOC 2020 (myself, Konstantin Makarychev, Yury Makarychev and Madhur Tulsiani, with input from PC chair Julia Chuzhoy) wrote a detailed document describing the design and execution of the conference. I personally felt the conference went about as well as it could have gone, and despite many moving parts, there were minimal technical difficulties.</p>



<p>The guide is available here: <a href="https://docs.google.com/document/d/1nzyvfdsXLzqYXxxdjw1y_OHAYwGolHCZUkRVmlxG9BE/edit?ts=5efa758c" rel="noreferrer noopener" target="_blank">Virtual STOC 2020 – Behind the Screens</a>.</p>



<p>If you have any questions or comments, feel free to comment below, or join in the conversation on <a href="https://twitter.com/thegautamkamath/status/1277959908168695808">Twitter</a>.</p></div>
    </content>
    <updated>2020-06-30T13:13:16Z</updated>
    <published>2020-06-30T13:13:16Z</published>
    <category term="Events"/>
    <author>
      <name>Gautam</name>
    </author>
    <source>
      <id>https://kamathematics.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://kamathematics.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://kamathematics.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://kamathematics.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://kamathematics.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Kamathematics</title>
      <updated>2020-07-07T00:21:46Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4886</id>
    <link href="https://www.scottaaronson.com/blog/?p=4886" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4886#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4886" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">David Poulin</title>
    <summary xml:lang="en-US">2020 sucks. Yesterday I learned that David Poulin, a creative and widely-beloved quantum computing and information theorist, has died at age 43, of an aggressive brain cancer. After studying under many of the field’s legends—Gilles Brassard, Wojciech Zurek, Ray Laflamme, Gerard Milburn, John Preskill—David became a professor at the University of Sherbrooke in Quebec. There […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><div class="wp-block-image"><figure class="aligncenter"><img alt="100+ &quot;Dave Poulin&quot; profiles | LinkedIn" src="https://media-exp1.licdn.com/dms/image/C4E03AQG9DmvmxhU3RA/profile-displayphoto-shrink_200_200/0?e=1597276800&amp;v=beta&amp;t=wav_nmh_CgU1IgzEbc89IQlfL5fNg0k6lcxs9_F_6qk"/></figure></div>



<p>2020 sucks.</p>



<p>Yesterday I learned that <a href="https://www.cifar.ca/cifarnews/2020/06/18/a-quantum-festschrift-for-david-poulin">David Poulin</a>, a creative and widely-beloved quantum computing and information theorist, has died at age 43, of an aggressive brain cancer.  After studying under many of the field’s legends—Gilles Brassard, Wojciech Zurek, Ray Laflamme, Gerard Milburn, John Preskill—David became a professor at the University of Sherbrooke in Quebec.  There he played a leading role in CIFAR (the Canadian Institute For Advanced Research), eventually co-directing its quantum information science program with Aephraim Steinberg.  Just this fall (!), David moved to Microsoft Research to start a new phase of his career.  He’s survived by a large family.</p>



<p>While I can’t claim any deep knowledge of David’s work—he and I pursued very different problems—it seems appropriate to mention some of his best-known contributions.  With David Kribs, Ray Laflamme, and Maia Lesosky, he <a href="https://arxiv.org/abs/quant-ph/0504189">introduced</a> the formalism of operator quantum error correction, and made many other contributions to the theory of quantum error-correction and fault-tolerance (including the estimation of thresholds).  He and coauthors <a href="https://www.nature.com/articles/ncomms1147">showed</a> in a <em>Nature</em> paper how to do quantum state tomography on 1D matrix product states efficiently.  With Pavithran Iyer, he <a href="https://arxiv.org/abs/1310.3235">proved</a> that optimal decoding of stabilizer codes is #P-hard.</p>



<p>And if none of that makes a sufficient impression on <em>Shtetl-Optimized</em> readers: well, back in 2013, when D-Wave was claiming to have achieved huge quantum speedups, David Poulin was one of the few experts willing to take a clear skeptical stance in public (including right in my comment section—see <a href="https://www.scottaaronson.com/blog/?p=1400#comment-79596">here</a> for example).</p>



<p>I vividly remember being officemates with David back in 2003, at the Perimeter Institute in Waterloo—before Perimeter had its sleek black building, when it still operated out of a converted tavern.  (My and David’s office was in the basement, reached via a narrow staircase.)  David liked to tease me: for example, if I found him in conversation with someone else and asked what it was about, he’d say, “oh, nothing to do with computational efficiency, no reason for you to care.”  (And yet, much of David’s work ultimately <em>would</em> have to do with computational efficiency.)</p>



<p>David was taken way too soon and will be missed by everyone who knew him.  Feel free to share David stories in the comments.</p></div>
    </content>
    <updated>2020-06-30T04:47:23Z</updated>
    <published>2020-06-30T04:47:23Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Announcements"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Quantum"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2020-07-03T06:45:45Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=17244</id>
    <link href="https://rjlipton.wordpress.com/2020/06/29/taking-a-problem-down-a-peg/" rel="alternate" type="text/html"/>
    <title>Taking a Problem Down a Peg</title>
    <summary>By blowing up its objects Composite crop of src1, src2 Joshua Greene and Andrew Lobb proved last month that every smooth Jordan curve in the plane and real , there are four points on the curve that form a rectangle with sides of ratio . Today we explain how this result relates to Otto Toeplitz’s […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>By blowing up its objects</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2020/06/29/taking-a-problem-down-a-peg/greenelobb/" rel="attachment wp-att-17246"><img alt="" class="alignright wp-image-17246" height="120" src="https://rjlipton.files.wordpress.com/2020/06/greenelobb.png?w=183&amp;h=120" width="183"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Composite crop of <a href="https://math.berkeley.edu/people/faculty/joshua-evan-greene">src1</a>, <a href="https://groups.oist.jp/mathprog/andrew-lobb">src2</a></font></td>
</tr>
</tbody>
</table>
<p>
Joshua Greene and Andrew Lobb <a href="https://arxiv.org/pdf/2005.09193.pdf">proved</a> last month that every <em>smooth</em> Jordan curve in the plane and real <img alt="{r \leq 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br+%5Cleq+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r \leq 1}"/>, there are four points on the curve that form a rectangle with sides of ratio <img alt="{r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r}"/>.</p>
<p>
Today we explain how this result relates to Otto Toeplitz’s famous “square peg conjecture,” which is the case <img alt="{r = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r = 1}"/> when the curve need not be smooth.</p>
<p><span id="more-17244"/></p>
<p>
We noticed this via an <a href="https://www.quantamagazine.org/new-geometric-perspective-cracks-old-problem-about-rectangles-20200625/">article</a> last Thursday by Kevin Hartnett for <em>Quanta</em>. Hartnett describes this research advance as a product of the pandemic inducing them to take time for deeper reflection on fundamental problems. We wonder how much is bubbling on hard problems in our own field—this is one reason for our last post’s <a href="https://rjlipton.wordpress.com/2020/06/21/some-real-and-some-virtual-news">interest</a> in (good kinds of) “gossip.”  He also gives great diagrams for the geometrical intuition.</p>
<p>
We will portray this advance instead along lines of things we’ve said recently about how to attack hard problems by seeking and solving simpler ones or special cases as stepping stones. Dick wrote a <a href="https://rjlipton.wordpress.com/2018/10/21/the-inscribed-square-problem/">post</a> two years ago on the original Toeplitz problem, which this work still leaves open. That post focused on ways general Jordan curves can be nasty. This one needs an extra niceness condition but proves a stronger result for all <img alt="{r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r}"/>. How much can progress on “nice” inform problems with “nasty”? That kind of question comes up in complexity theory all the time.</p>
<p>
</p><p/><h2> Pegging Rectangles </h2><p/>
<p/><p>
A <em>Jordan curve</em> is the image of a continuous 1-1 map <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/> from the circle to the plane. The condition of being 1-1 prevents the image from intersecting itself, so it is a single closed loop. By the Jordan curve <a href="https://en.wikipedia.org/wiki/Jordan_curve_theorem">theorem</a>, the loop always partitions the rest of the plane into two connected regions, exactly one of which is bounded. Amazingly, a Jordan curve <a href="https://en.wikipedia.org/wiki/Osgood_curve">can</a> have positive Lebesgue measure, yet cannot fill all of <img alt="{\mathbb{R}^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BR%7D%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathbb{R}^2}"/>. Such curves can, however, approach the kind of space-filling curves defined by Giuseppe Peano, and thus have any Lebesgue density less than <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>, as was noted also by William Osgood in his 1903 <a href="https://www.jstor.org/stable/pdf/1986455.pdf">paper</a>.</p>
<p>
The Toeplitz conjecture is that every Jordan curve has four points that form a square. As noted in Dick’s post, the positive-area case is actually an easy yes-case. Nasty cases are where the curve is nowhere-differentiable with zero area. Thus far, the problem has been answered <em>yes</em> only in the presence of some uniformity condition that limits the local nastiness of the curve. The simplest one is for the curve to be <em>smooth</em> in that <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/> has a continuous first derivative. Here is a smooth curve that is not convex, so that the square need not be “inside” the curve:</p>
<p/><p/>
<p><a href="https://rjlipton.wordpress.com/2020/06/29/taking-a-problem-down-a-peg/matschkefig2/" rel="attachment wp-att-17247"><img alt="" class="aligncenter size-full wp-image-17247" src="https://rjlipton.files.wordpress.com/2020/06/matschkefig2.jpg?w=600"/></a></p>
<p>
This diagram is from Benjamin Matchske’s wonderful recent <a href="https://www.ams.org/notices/201404/rnoti-p346.pdf">survey</a> of the peg problem in the <em>AMS Notices</em>. Four months ago we’d have said it looks like a thin heart or fat boomerang. <i>Now</i> it looks to us like a face mask.</p>
<p>
As the survey notes, it is easy to show that every Jordan curve has <em>some</em> rectangle. The rectangle problem is to show that rectangles of <i>every</i> aspect ratio <img alt="{r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r}"/> can be pegged to the curve. There are two main reasons the square and rectangle problems are hard and harder:</p>
<ol>
<li>
Although any Jordan curve can be written as a limit of nice ones, the squares in the nice ones can degenerate to a single point in the limit. <p/>
</li><li>
Even for nice curves, a parity property that holds for squares can fail for rectangles.
</li></ol>
<p>
The property in the second point enables arguments of the kind: <em>for generic curves the number of squares is odd, therefore it is nonzero</em>. This then carries over to sufficiently nice curves in the generic closure. The failure of this property for rectangles is a main reason the results by Greene and Lobb are new.</p>
<p>
</p><p/><h2> The Paper </h2><p/>
<p/><p>
The new paper is written tersely at a high level, and we must confess not being able to catch all details in compressed time. But we can highlight some aspects of the argument. First, as we have said, it exemplifies:</p>
<ul>
<li>
<em>Solve a Simpler Problem</em>.
</li></ul>
<p>
This is however coupled with a second aspect:</p>
<ul>
<li>
<em>Bring Up the Reserves</em>.
</li></ul>
<p>
It may be that the rectangle conjecture is not only true but “equally true” in the sense that the fundamental reason applies equally well to the case of rectangles. The parity argument that works for cases involving squares may be a crutch that misses the deepest explanations. Promoting arguments that avoid this crutch may marshal resources needed to make a breakthrough on the main problem for completely general Jordan curves.</p>
<p>
This runs somewhat counter to what we have said about <img alt="{\mathsf{NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{NP}}"/> versus <img alt="{\mathsf{P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{P}}"/> proof attempts recently. The reason for <img alt="{\mathsf{P &lt; NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%3C+NP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{P &lt; NP}}"/> believed by most is that problems like SAT require <em>exponential</em> time, not just super-polynomial time. Yet no one knows even a <em>super-linear</em> lower bound, apart from barely-superlinear bounds that exploit grainy aspects of the multitape Turing machine model and apply only to it. Nor is any super-linear lower bound known on Boolean circuit size. Maybe it is a viable strategy also to “bring up reserves” by finding restricted cases where (conditional) exponential lower bounds can be proven, as well as to explore contingencies like <a href="https://en.wikipedia.org/wiki/Exponential_time_hypothesis">SETH</a>, as we covered <a href="https://rjlipton.wordpress.com/2015/06/01/puzzling-evidence/">here</a>. But both of use have always felt that the super-linear frontier holds the buried keys to further progress.</p>
<p>
The Greene-Lobb proof has two aspects that may also resonate in complexity:</p>
<ul>
<li>
<em>Blow Up the Objects</em>.
</li></ul>
<p>
The <a href="https://www.quantamagazine.org/new-geometric-perspective-cracks-old-problem-about-rectangles-20200625/">article</a> in <em>Quanta</em> has great diagrams illustrating how the set of pairs of points on the curve corresponds to a Möbius strip in a related space. Cole Hugelmeyer, a graduate student at Princeton, <a href="https://arxiv.org/pdf/1911.07336.pdf">proved</a> last year how to get rectangles covering at least one-third of possible values <img alt="{r \in (0,1]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br+%5Cin+%280%2C1%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r \in (0,1]}"/> by embedding the Möbius strips in a four-dimensional space. Intersections between a strip and a rotated copy yield rectangles on the original Jordan curve. </p>
<p>
That led Greene and Lobb to consider larger objects with properties like pairs of Möbius strips in the larger space. The Klein bottle is the natural next thing to consider and led to a feature of their proof that made the desired conclusion pop out:</p>
<ul>
<li>
<em>Identify and Rule Out Obstructions</em>.
</li></ul>
<p>
The clever point pivots on the fact that a Klein bottle cannot be smoothly embedded into the complex plane <img alt="{\mathbb{C}^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BC%7D%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathbb{C}^2}"/> as a Lagrangian submanifold. The proof shows that for any prescribed aspect ratio <img alt="{r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r}"/> one can construct a mapping that almost succeeds in embedding such a Klein bottle. The fact that it must fail means that the image must yield a point of intersection witnessing the failure. The presence of this point then yields the construction of four other points on the Jordan curve that form the vertices of the needed rectangle.</p>
<p>
We have briefly <a href="https://rjlipton.wordpress.com/2018/06/06/princeton-is-invariant/">mentioned</a> how the concept of <em>obstructions</em> is integral to the <a href="https://en.wikipedia.org/wiki/Geometric_complexity_theory">Geometric</a> <a href="https://dl.acm.org/doi/10.1145/1944345.1944346">Complexity</a> <a href="http://gct.cs.uchicago.edu/">Theory</a> attack on <img alt="{\mathsf{P &lt; NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%3C+NP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{P &lt; NP}}"/>. Closer to home, however, is how László Babai's graph isomorphism algorithm and proof works by identifying a subclass of graphs called Johnson graphs as obstructions to a simpler algorithm, as we highlighted <a href="https://rjlipton.wordpress.com/2017/01/06/snow-and-theory/">here</a>.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Can you find more lessons from the new advance on the Toeplitz problem?  Dick and I have considered ideas of blowing up from languages to pairs of languages (and making <i>reductions</i> between problems the fundamental units of analysis) but this has not gone beyond dreamwork.</p>
<p/></font></font></div>
    </content>
    <updated>2020-06-29T21:20:08Z</updated>
    <published>2020-06-29T21:20:08Z</published>
    <category term="All Posts"/>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="Proofs"/>
    <category term="Results"/>
    <category term="Andrew Lobb"/>
    <category term="Cole Hugelmeyer"/>
    <category term="computational geometry"/>
    <category term="conjecture"/>
    <category term="geometry"/>
    <category term="Joshua Greene"/>
    <category term="Toeplitz"/>
    <author>
      <name>KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2020-07-07T00:20:48Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-7761235140481153504</id>
    <link href="https://blog.computationalcomplexity.org/feeds/7761235140481153504/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/06/can-you-name-famous-living-chemist-can.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7761235140481153504" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7761235140481153504" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/06/can-you-name-famous-living-chemist-can.html" rel="alternate" type="text/html"/>
    <title>Can you name a famous living Chemist? Can anyone?</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><br/>
I was re-watching the  Greatest-of-all-time Jeopardy championship and the following happen (I paraphrase)<br/>
<br/>
----------------------<br/>
Alex Trebek: The category is Chemistry and we have a special guest reading the clues.<br/>
<br/>
Darling: I wonder who that will be.<br/>
<br/>
Bill: Hmm. I assume some famous chemist.<br/>
------------------------<br/>
<br/>
So who was it? Bryan Cranston, the actor who PLAYED chemist Walter White on <i>Breaking Bad.</i><br/>
<br/>
Why couldn't they get a famous living chemist to read the clues?<br/>
<br/>
My guess: there are no famous living chemists.<br/>
<br/>
The number of famous living scientists is fairly short and they are often known for things that are not quite their science. Some are famous because the popularize science (deGrasse Tyson, Dawkins) or because of something unusual about their life (Hawkings when he was alive) or for something else entirely that they did (Ted Kaczynski).  Are any famous for the actual work that they do in the science?<br/>
<br/>
Andrew Wiles was famous for a brief time, and even made People Magazine's <i>25 most intriguing people of the year</i> list in the early 1990's (after he solved Fermat's Last Theorem). So he was famous but it was short lived.<br/>
<br/>
Terry Tao was on the Colbert Report (see <a href="http://www.cc.com/video-clips/6wtwlg/the-colbert-report-terence-tao">here</a>) after he won the Fields Medal, the MacAuthor Genius award, and the Breakthrough prize. And even that fame was short lived.<br/>
<br/>
I looked at the web page of Nobel Prize winners, <a href="https://www.nobelprize.org/prizes/lists/all-nobel-prizes">here</a>.<br/>
<br/>
The only Chemistry Nobel's I recognized were Marie Curie,  Irene Joilet-Curie (Marie's Daughter), and Erst Rutherford.<br/>
<br/>
The only Physics Nobel's I recognized were<br/>
<br/>
Richard Feynman,<br/>
<br/>
 Eugene Wigner (for writing about <a href="https://www.dartmouth.edu/~matc/MathDrama/reading/Wigner.html">The unreasonable effectiveness of mathematics in the natural sciences</a>),<br/>
<br/>
Richard Hofstadter (since he was the father of Douglas H and an uncle of Leonard H)<br/>
<br/>
 Andrew Geim (since he won  both an Ig-Noble prize and a Nobel prize, see  <a href="https://blog.computationalcomplexity.org/2010/10/noble-and-ig-noble-prizes.html">here</a>)<br/>
<br/>
Wolfgang Pauli (I've heard the term `Pauli Principle" though I did not know what it was until I looked it up while preparing this blog. I prob still don't really know what it means.)<br/>
<br/>
Enrico Fermi<br/>
<br/>
Erwin Schrodinger<br/>
<br/>
Paul Dirac<br/>
<br/>
Robert Millikan<br/>
<br/>
Albert Einstein<br/>
<br/>
Max Karl Ernest Ludwig Planck (I thought his last name was `Institute')<br/>
<br/>
Johannes Diderik van der Waals<br/>
<br/>
Pierre Curie<br/>
<br/>
Marie Curie<br/>
<br/>
<br/>
So, some questions:<br/>
<br/>
a) Am I wrong? Are there famous living chemists I never heard of? Are there any famous living scientists who are famous for their work in science?<br/>
<br/>
b) If I am right then was there ever a time when there were famous scientists?<br/>
<br/>
c) If there was such a time, what changed?<br/>
<br/>
(I ask all of this non-rhetorically and with no agenda to push.)<br/>
<br/>
<br/>
<br/>
<br/>
<br/></div>
    </content>
    <updated>2020-06-29T20:36:00Z</updated>
    <published>2020-06-29T20:36:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2020-07-06T17:42:45Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/06/29/postdocs-phd-students-in-the-theory-of-distributed-parallel-computing-at-aalto-university-apply-by-august-31-2020/</id>
    <link href="https://cstheory-jobs.org/2020/06/29/postdocs-phd-students-in-the-theory-of-distributed-parallel-computing-at-aalto-university-apply-by-august-31-2020/" rel="alternate" type="text/html"/>
    <title>Postdocs &amp; PhD students in the theory of distributed &amp; parallel computing at Aalto University (apply by August 31, 2020)</title>
    <summary>The research groups of Jukka Suomela and Jara Uitto at Aalto University (Helsinki, Finland) are looking for several postdoctoral researchers and/or doctoral students to work on the foundations of distributed and parallel computing. Website: https://research.cs.aalto.fi/da/jobs/ Email: jukka.suomela@aalto.fi and jara.uitto@aalto.fi</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The research groups of Jukka Suomela and Jara Uitto at Aalto University (Helsinki, Finland) are looking for several postdoctoral researchers and/or doctoral students to work on the foundations of distributed and parallel computing.</p>
<p>Website: <a href="https://research.cs.aalto.fi/da/jobs/">https://research.cs.aalto.fi/da/jobs/</a><br/>
Email: jukka.suomela@aalto.fi and jara.uitto@aalto.fi</p></div>
    </content>
    <updated>2020-06-29T16:00:22Z</updated>
    <published>2020-06-29T16:00:22Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-07-07T00:20:51Z</updated>
    </source>
  </entry>

  <entry>
    <id>http://benjamin-recht.github.io/2020/06/29/tour-revisited/</id>
    <link href="http://benjamin-recht.github.io/2020/06/29/tour-revisited/" rel="alternate" type="text/html"/>
    <title>What We've Learned to Control</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I’m giving a keynote address at the <a href="https://www.ifac2020.org/">virtual IFAC congress this July</a>, and I submitted an abstract that forces me to reflect on the current state of research at the intersection of machine learning and control. 2020 is particularly appropriate for reflection: For personal reasons, I’ve been working in this space for about half a decade now and <a href="https://www.argmin.net/2018/06/25/outsider-rl/">wrote a blog series on the topic two years ago</a> and it seemed like ideal timing. For the broader community, 2020 happens to be the year we were promised fleets of self-driving cars. Of course, for a myriad of reasons, we’re nowhere close to achieving this goal. Full self-driving has been a key motivator of work in learning-enabled autonomous systems, and it’s important to note this example as a marker of how difficult problems this space really are.</p>

<p>The research community has come to terms with this difficulty, and has committed itself to address the many pressing challenges. Over the last year I attended several great meetings on this topic, including an <a href="https://ajwagen.github.io/adsi_learning_and_control/">NSF funded workshop at UW</a>, a plenary session at <a href="https://ita.ucsd.edu/ws/">ITA</a>, a workshop on intersections of <a href="https://www.ipam.ucla.edu/programs/workshops/intersections-between-control-learning-and-optimization/?tab=overview">learning, control, and optimization at IPAM</a>, and the <a href="https://sites.google.com/berkeley.edu/l4dc/home">second annual conference on Learning for Dynamics and Control</a>. There is clearly a ton of enthusiasm from researchers in a many different disciplines, and we’re seeing fascinating results mixing techniques from machine learning, computer science, and control. Obviously, I’m going to be leaving out many incredible papers, but, focusing on the theoretical end of the spectrum, perhaps I could highlight <a href="https://arxiv.org/abs/1912.11899">new work on policy optimization</a> that demonstrates how simple optimization techniques can efficiently solve classic, nonconvex control-design problems or <a href="https://arxiv.org/abs/1902.08721">work connecting regret minimization and adaptive control</a> that provides nonasymptotic bounds.</p>

<p>This work has been very useful for establishing language to bridge communication between the diverse research camps interested in the space of learning, dynamics and automation. But, as I’ll discuss shortly, I’d argue that it hasn’t provided many promising approaches to improving large-scale autonomy. That’s ok! These problems are incredibly difficult and aren’t going to be solved by wishing for them to be solved. But I also think it might be worth taking a moment to reflect on which problems we are working on. It’s always a bit too easy for theorists to focus  on improving technical results and lose sight of why someone proved those results in the first place.</p>

<p>As an illustrative example, my research group spent a lot of time studying the <a href="http://www.argmin.net/2018/02/08/lqr/">Linear Quadratic Regulator</a> (LQR). The point of this work was initially to establish baselines: LQR has a closed form solution when the model is known, so we wanted to understand how different algorithms might perform when the underlying model was unknown. It turns out that if you are willing to collect enough data, the best thing you can do for LQR is <a href="https://arxiv.org/abs/1902.07826">estimate the dynamical model, and then exploit this model as if it were true</a>. This so-called “certainty equivalent control” is what practitioners have been doing since the mid-60s to fly satellites and solve other optimal control problems. Proving this result required a bunch of new mathematical insights that established connections between high dimensional statistics and automatic control theory. But it did not bring us closer to solving new challenges in robotics or autonomous systems. Our work here merely showed that what the controls community had been doing for 50 years was already about as well as we could do for this important baseline problem.</p>

<p>So what are the ways forward? Are there things that theory-minded folks can work on short term that might help us understand paths towards improving learning systems in complex feedback loops? Let me suggest a few challenges that I see as both very pressing, but also ones where we might be able to make near-term progress.</p>

<h2 id="machine-learning-is-still-not-reliable-technology">Machine Learning is still not reliable technology</h2>

<p>At the aforementioned <a href="https://www.ipam.ucla.edu/programs/workshops/intersections-between-control-learning-and-optimization/?tab=overview">IPAM meeting</a>, Richard Murray gave a <a href="https://www.youtube.com/watch?v=Wi8Y---ce28">fantastic survey of the sorts of standards of reliability imposed in aerospace engineering</a>. Go watch it! I don’t want to spoil it for you, but his discussion of Ram Air Turbines is gripping. Richard covers what is needed to get to the sorts of reliability we’d like in autonomous systems. Unfortunately, having <a href="https://arxiv.org/abs/2003.08237">88.5% Top-1 accuracy on ImageNet</a>—while a stunning achievement—doesn’t tell us how to get to systems with failure rates on the order of 1 in a billion. As Boeing has tragically shown, cutting corners on autonomous system safety standards has horrible, tragic consequences.</p>

<p>How can we make machine learning more robust? How can we approach the failure rates needed for safe, reliable autonomy? And how can we establish testing protocols to assure we have such low failure rates?</p>

<h2 id="prediction-systems-in-feedback-loops">Prediction systems in feedback loops</h2>

<p>One particular aspect that I think is worth considering is how supervised learning systems can function as “sensors” in feedback loops. Even if you know everything about a dynamical system, when you observe the state via an estimator generated by a learned component, it’s not clear how to best take action on this observation. Most classic control and planning assumes that your errors in state-estimation are Gaussian or nicely uniformly bounded. Of course, the errors from machine learning systems are neither of these (I recommend checking out the <a href="https://youtu.be/A0cb7wZVFf4">crazy videos</a> of the <a href="https://twitter.com/greentheonly/status/1130956365063761920">confusion</a> that comes out of Tesla Autopilot’s vision systems). How to properly characterize the errors of machine learning systems for control applications seems like a useful, understudied problem. Using off-the-shelf machine learing analysis, it’s unavoidable to have to densely sample all of the possible scenarios in advance in order to guarantee the sort of uniform error bounds desired by control algorithms. This isn’t practical, and, indeed, it’s clear that this sort of sensor characterization is not needed to make reasonable demos work. Though it’s a bit mundane, I think a huge contribution lies in understanding how much data we need to quantify the uncertainty in learned perception components. It’s still not clear to me if this is a machine learning question or a closed-loop design question, and I suspect both views of the problem will be needed to make progress.</p>

<h2 id="why-are-we-all-sleeping-on-model-predictive-control">Why are we all sleeping on model predictive control?</h2>

<p>I still remain baffled by how <a href="http://www.argmin.net/2018/05/02/adp/">model predictive control</a> (MPC) is consistently under appreciated. We’ll commonly see the same tasks in the same meeting, one task done on a robot using some sort of deep reinforcement learning and the other done using model predictive control, and the disparity in performance is stark. It’s like the difference between watching an Olympic level sprinter and me jogging in my neighborhood with a set of orthotics.</p>

<p>Here’s an example from the IPAM workshop. Martin Riedmiller presented work at DeepMind to catch a ball in a cup:</p>



<p>This system uses two cameras, has a rather large “cup,” (it’s a wastepaper basket) and yet still takes 3 days to train on the robot. Francesco Borrelli presented a different approach. Using only a single camera and basic, simple Newtonian physics, and MPC they were able to achieve this performance on the standard-sized “ball-in-a-cup” toy:</p>



<p>If you only saw these two videos, I can’t fathom why would you invest all of your assets into deep RL. I understand there are still a lot of diehards out there, and I know this will offend them. But I want to make a constructive point: so many theorists are spending a lot of time studying RL algorithms, but few in the ML community are analyzing MPC and why it’s so successful. We should rebalance our allocation of mental resources!</p>

<p>Now, while the basic idea of MPC is very simple, the theory gets very hairy very quickly. It definitely takes some time and effort to learn about how to prove convergence of MPC protocols. I’d urge the MPC crowd to connect more with the learning theory crowd to see if a common ground can be found to better understand how MPC works and how we might push its performance even farther.</p>

<h2 id="perhaps-we-should-stop-taking-cues-from-alphago">Perhaps we should stop taking cues from AlphaGo?</h2>

<p>One of the grand goals in RL is to use function approximation algorithms to estimate value functions. The conventional wisdom asserts that the world is a giant Markov Decision Process and once you have its value function, you can just greedily maximize it and you’ll win at life. Now, this sort of approach clearly doesn’t work for robots, and I’m perplexed by why people still think it will work at all. Part of the motivation is that this approach was used to solve Go. But at some point I think we all have to come to terms with the fact that games are not the real world.</p>

<p>Now, I’d actually argue that RL <em>does</em> work in the real world, but it’s in systems that most people don’t actively think of as RL systems. Greedy value function estimation and exploitation is <em>literally</em> how all internet revenue is made. Systems simply use past data to estimate value functions and then choose the action that maximizes the value at the next step. Though seldom described as such, these are instances of the “greedy contextual bandit” algorithm, and this algorithm makes tech companies tons of money. But many researchers have also pointed out that this algorithm leads to misinformation, polarization, and radicalization.</p>

<p>Everyone tries to motivate RL by the success of AlphaGo, but they should be using the success of Facebook and Google instead. And if they did this, I think it would be a lot more clear why RL is terrifying and dangerous, and one whose limitations we desperately need to understand so that we can build safer tools.</p>

<h2 id="lessons-from-the-70s-about-optimal-control">Lessons from the 70s about optimal control</h2>

<p>I have one set of ideas along these lines that, while I think is important, I still am having a hard time articulating. Indeed, I might just take a few blog posts to work through my thoughts on this, but let me close this blog with a teaser of discussions to come. As I mentioned above, optimal control was a guiding paradigm for a variety of control applications in the 60s and 70s. During this time, it seemed like there might even be hidden benefits to a full-on optimization paradigm: though you’d optimize a single, simple objective, you would often get additional robustness guarantees for free. However, it turned out that this was very misleading and that <a href="https://ieeexplore.ieee.org/document/1101812">there were no guarantees of robustness even for simple optimal control problems</a>. This shouldn’t be too surprising, as if you devote a lot of resources towards one objective, you are likely neglecting some other objective. But showing how and why these fragilities arise is quite delicate. It’s not always obvious how you <em>should</em> be devoting your resources.</p>

<p>Trying to determine how to allocate engineering resources to balance safety and performance is the heart of “robust control.” One thing I’m fascinated by moving forward is if any of the early developments in robust control might transfer over for a new kind of “robust ML.” Unfortunately for all of us, robust control is a rather encrypted literature. There is a lot of mathematics, but often not clear statements about <em>why</em> we study particular problems or what are the fundamental limits of feedback. While diligent young learning theorists have been scouring classic control theory text books for insights, these books don’t always articulate what we can and cannot do and what are the problems that control theory might help solve. We still have a lot of work to do in communicating what we know and what problems remain challenging. I think it would be useful for control theorists to think of how to best communicate the fundamental concepts of robust control. I hope to take up this challenge in the next few months on this blog.</p>

<p><em>I’d like to thank Sarah Dean, Horia Mania, Nik Matni, and Ludwig Schmidt for their helpful feedback on this post. I’d also like to thank John Doyle for several inspiring conversations about robustness in optimal control and on the encrypted state of the control theory literature.</em></p></div>
    </summary>
    <updated>2020-06-29T00:00:00Z</updated>
    <published>2020-06-29T00:00:00Z</published>
    <source>
      <id>http://benjamin-recht.github.io/</id>
      <author>
        <name>Ben Recht</name>
      </author>
      <link href="http://benjamin-recht.github.io/" rel="alternate" type="text/html"/>
      <link href="http://benjamin-recht.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Musings on systems, information, learning, and optimization.</subtitle>
      <title>arg min blog</title>
      <updated>2020-07-06T23:36:19Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2020/06/28/sorting-integer-offsets</id>
    <link href="https://11011110.github.io/blog/2020/06/28/sorting-integer-offsets.html" rel="alternate" type="text/html"/>
    <title>Sorting with integer offsets</title>
    <summary>Here’s a cute exercise for the next time you’re teaching radix sorting in an algorithms class:</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Here’s a cute exercise for the next time you’re teaching radix sorting in an algorithms class:</p>

<p>Suppose you’re given as input a set of real numbers , and an integer parameter . Describe an algorithm for sorting the  numbers  in time . You can assume that standard arithmetic operations on real numbers (including comparisons and rounding down to an integer) take constant time per operation.</p>

<p>Models of computation that mix constant-time real arithmetic and rounding operations can be problematic, as by building up and then rounding numbers with unlimited precision you can access a level of computational power beyond what actual computers can do, but I don’t think that’s a concern here. If someone wants to use bit-packing tricks to implement a crazy but fast sorting algorithm in this model, they’re beyond the level of this exercise.</p>

<p>The same method (which I’m not going to describe, to preserve its value as an exercise) more generally allows you to take as input pairs  and sort the numbers  in time  where . But it relies heavily on the fact that you’re adding integers to the ’s. For a problem that can’t be handled in this way, consider instead sorting the numbers  where we multiply instead of adding. Or, if you prefer to view this as a type of <a href="https://en.wikipedia.org/wiki/X_%2B_Y_sorting"> sorting</a> problem, take logs in your favorite base and sort the numbers . It’s not at all obvious to me whether this can be done in the same  time bound.</p>

<p>The motivation for looking at all this is <a href="https://cstheory.stackexchange.com/q/47120/95">a question about how to implement the greedy set cover quickly</a>. You can find the unweighted <a href="https://en.wikipedia.org/wiki/Set_cover_problem#Greedy_algorithm">greedy set cover</a> in linear time (linear in the sum of the sizes of the input sets; this is an exercise in CLRS), and you can approximate the weighted greedy set cover very accurately in linear time using similar ideas. If you could sort  quickly you could use the sorted order to compute the weighted greedy set cover exactly in the same time as the sorting algorithm. Which is totally useless because the greedy cover is already an approximation, so a fast and accurate approximation to the greedy cover is good enough. But I think the question of sorting  is interesting despite its uselessness in this application.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/104424777130789257">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2020-06-28T17:54:00Z</updated>
    <published>2020-06-28T17:54:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2020-07-06T00:35:22Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-8890204.post-2151790274753933095</id>
    <link href="http://mybiasedcoin.blogspot.com/feeds/2151790274753933095/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=8890204&amp;postID=2151790274753933095" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/8890204/posts/default/2151790274753933095" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/8890204/posts/default/2151790274753933095" rel="self" type="application/atom+xml"/>
    <link href="http://mybiasedcoin.blogspot.com/2020/06/stoc-workshop-on-algorithms-with.html" rel="alternate" type="text/html"/>
    <title>STOC Workshop on "Algorithms with Predictions"</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">The STOC workshop on Algorithms with Predictions was on Friday, and I thought it went really well!  I can't speak for my talk, but the other 3 talks (Tim Roughgarden, Edith Cohen, Ravi Kumar) were fantastic and inspiring, and I really recommend them for anyone with an interest in "Beyond Worst-Case Analysis".   <br/><br/>The talks are <a href="https://www.youtube.com/watch?v=byKYJwN6XKw&amp;feature=youtu.be">all on Youtube</a>.  And the <a href="https://www.mit.edu/~vakilian/stoc-workshop.html">workshop page</a> is full of useful links and information. </div>
    </content>
    <updated>2020-06-27T18:06:00Z</updated>
    <published>2020-06-27T18:06:00Z</published>
    <author>
      <name>Michael Mitzenmacher</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/02161161032642563814</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-8890204</id>
      <category term="conferences"/>
      <category term="research"/>
      <category term="society"/>
      <category term="algorithms"/>
      <category term="administration"/>
      <category term="teaching"/>
      <category term="Harvard"/>
      <category term="papers"/>
      <category term="graduate students"/>
      <category term="funding"/>
      <category term="talks"/>
      <category term="blogs"/>
      <category term="codes"/>
      <category term="jobs"/>
      <category term="reviews"/>
      <category term="personal"/>
      <category term="travel"/>
      <category term="undergraduate students"/>
      <category term="books"/>
      <category term="open problems"/>
      <category term="PCs"/>
      <category term="consulting"/>
      <category term="randomness"/>
      <category term="CCC"/>
      <category term="blog book project"/>
      <category term="research labs"/>
      <category term="ISIT"/>
      <category term="tenure"/>
      <category term="comments"/>
      <category term="recommendations"/>
      <category term="outreach"/>
      <category term="students"/>
      <author>
        <name>Michael Mitzenmacher</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06738274256402616703</uri>
      </author>
      <link href="http://mybiasedcoin.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/8890204/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://mybiasedcoin.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/8890204/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">My take on computer science -- <br/> 
algorithms, networking, information theory -- <br/> 
and related items.</div>
      </subtitle>
      <title>My Biased Coin</title>
      <updated>2020-06-27T18:06:03Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=7756</id>
    <link href="https://windowsontheory.org/2020/06/26/stoc-2020-slack-channel-open-from-madhur-tulsiani/" rel="alternate" type="text/html"/>
    <title>STOC 2020 slack channel open (from Madhur Tulsiani)</title>
    <summary>Madhur writes: Thanks to all who participated in STOC 2020! Since the discussions on some of the topics from the business meeting, on SafeToC, and  on the papers/workshops are still ongoing, we will keep the Slack workspace open till July 31st (instead of just one week after the conference, as announced earlier). Also, if any […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Madhur writes:</p>



<p>Thanks to all who participated in STOC 2020! Since the discussions on some of the topics from the business meeting, on SafeToC, and  on the papers/workshops are still ongoing, we will keep the Slack workspace open till <strong>July 31st</strong> (instead of just one week after the conference, as announced earlier). Also, if any members of the community are interested in joining the discussions, they are welcome to email us (<a>stoc2020@ttic.edu</a>) and we can send them an invitation to join the workspace.</p>



<p>Of course the organizers may not always be able to quickly respond to help messages during the next month. However, all members are welcome to participate in discussions, create new topics or channels as needed, and use the workspace as they prefer.</p>



<p>TheoryFest organization team (<a href="mailto:stoc2020@ttic.edu" rel="noreferrer noopener" target="_blank">stoc2020@ttic.edu</a>)</p></div>
    </content>
    <updated>2020-06-27T01:37:25Z</updated>
    <published>2020-06-27T01:37:25Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2020-07-07T00:21:04Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=19925</id>
    <link href="https://gilkalai.wordpress.com/2020/06/26/to-cheer-you-up-in-difficult-times-6-play-rani-sharims-two-player-games-of-life-read-maya-bar-hillel-presentation-on-catching-lies-with-statistics-and-more/" rel="alternate" type="text/html"/>
    <title>To cheer you up in difficult times 6:  Play Rani Sharim’s two-player games of life,  read Maya Bar-Hillel presentation on catching lies with statistics, and more.</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Sorry for the long blog silence. In this post I wish to give a few links each of which probably deserves a full post. I will start with Rani Sharim’s two-player variants of John Conway’s game-of-life Here is a web-page … <a href="https://gilkalai.wordpress.com/2020/06/26/to-cheer-you-up-in-difficult-times-6-play-rani-sharims-two-player-games-of-life-read-maya-bar-hillel-presentation-on-catching-lies-with-statistics-and-more/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Sorry for the long blog silence. In this post I wish to give a few links each of which probably deserves a full post. I will start with</p>
<h2>Rani Sharim’s two-player variants of John Conway’s game-of-life</h2>
<p><a href="https://ranisharim.github.io/game_of_life_2_players/">Here is a web-page</a> by a student in my “Game Theory” course where you can play several two-players variants of John Conway’s game-of-life.  (A couple of variants were considered before. See, e.g. <a href="https://arxiv.org/abs/cond-mat/0207679">this  paper</a>.)</p>
<p>I really enjoyed playing Rani’s games and it can certainly cheer you up in difficult times. Questions about the game, remarks, and suggestions for improvements and for new features, are most welcome.</p>
<h2>How to catch lies with statistics, a 2006  presentation by Maya Bar-Hillel</h2>
<p><a href="https://gilkalai.files.wordpress.com/2020/06/mayesther.png"><img alt="" class="alignnone size-full wp-image-19929" src="https://gilkalai.files.wordpress.com/2020/06/mayesther.png?w=640"/></a></p>
<p>Maya Bar-Hillel (left) and Ester Samuel-Cahn</p>
<p>Here is an interesting 2006 <a href="https://gilkalai.files.wordpress.com/2020/06/ester.ppt">power point presentation entitled <strong><em>How to detect lies with statistics</em></strong> by Maya Bar-Hillel.</a>  This was a talk given by Maya at the <a href="http://www.esterconference.huji.ac.il/">conference</a> honoring Prof. Ester Samuel- Cahn , Jerusalem, December 18-20, 2006, and it described a planned research project of Maya Bar-Hillel with Yossi Rinott, David Budescu and myself. At the end we did not pursue it, mainly because each of us was involved in various other projects (but also because we were skeptical about some aspects of it.)  Ester Samuel-Cahn (1933-2015) was a famous Israeli statistician. (Here is a <a href="http://www.sci-princess.info/archives/291">post by Yosi Levy in Hebrew</a> about the conference and about Ester.)</p>
<p>The lecture starts with “Last year, <em>Statistical Science</em> celebrated 50 years for `How to Lie with Statistics’ the book [by Durell Huff] whose title inspired this talk.”</p>
<p>And here are a few other quotes from Maya’s presentation</p>
<p>“We are not sure a general toolkit for detecting lies with statistics can be developed. Perhaps that explains why none yet exists.  We have shown just a collection of anecdotes. But they can be classified and categorized. Some do seem generalizeable, at least to some extent.”</p>
<p>and the conclusion</p>
<blockquote><p>A famous quip by Fred Mosteller: “It is easy to lie with statistics, but easier to lie without them.”</p>
<p>Likewise, we should say:  “It is possible to detect (some) lies with statistics, but easier to detect them with other means”.</p></blockquote>
<h2>New bounds for Ryser’s conjecture and related problems</h2>
<p>Peter Keevash, Alexey Pokrovskiy, Benny Sudakov, and Liana Yepremyan’s paper  <a href="https://arxiv.org/abs/2005.00526">New bounds for Ryser’s conjecture and related problems,</a> describes remarkable progress very old questions regarding transversals in Latin square.</p>
<h2>Topological Tverberg news</h2>
<p>I came across a very interesting paper <a href="https://arxiv.org/abs/2005.05251">The topological Tverberg problem beyond <span class="search-hit mathjax">prime</span> powers</a> by Florian Frick and Pablo Soberón with new bounds and a new method for topological Tverberg theorem in the non prime-power case.</p>
<h2>Jeager’s conjecture refuted</h2>
<p>A year ago I came across <a href="https://www.facebook.com/photo.php?fbid=2114324995342352&amp;set=a.507523926022475&amp;type=3&amp;theater">this cool facebook post</a> by Rupei Xu</p>
<blockquote><p>OMG! Just learned that Jaeger’s conjecture is false for every t&gt;=3. An interesting consequence of it is that a specific version of Goddyn’s conjecture on thin spanning trees is false, which shows some negative evidence that the thin spanning tree approaches may fail to lead to a constant factor approximation algorithm for ATSP!</p></blockquote>
<h2>A cool rainbow post <a href="http://matroidunion.org/?p=2541">Short rainbow cycles in graphs and matroids</a> by Tony Huynh</h2>
<h2>More on the game of life</h2>
<p>Let me mention two problems I posted 6-7 years ago about Conway’s game of life. <a class="question-hyperlink" href="https://mathoverflow.net/questions/132402/conways-game-of-life-for-random-initial-position">Conway’s game of life for random initial position</a> and <a class="question-hyperlink" href="https://cstheory.stackexchange.com/questions/17914/does-a-noisy-version-of-conways-game-of-life-support-universal-computation">Does a noisy version of Conway’s game of life support universal computation?</a></p>
<div class="left-sidebar js-pinned-left-sidebar ps-relative" id="left-sidebar">
<div class="left-sidebar--sticky-container js-sticky-leftnav"/>
</div>
<p> </p>
<p> </p></div>
    </content>
    <updated>2020-06-25T21:21:45Z</updated>
    <published>2020-06-25T21:21:45Z</published>
    <category term="Combinatorics"/>
    <category term="Games"/>
    <category term="Rationality"/>
    <category term="Maya Bar Hillel"/>
    <category term="Rani Sharim"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2020-07-07T00:20:42Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-8890204.post-5732832478359389342</id>
    <link href="http://mybiasedcoin.blogspot.com/feeds/5732832478359389342/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=8890204&amp;postID=5732832478359389342" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/8890204/posts/default/5732832478359389342" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/8890204/posts/default/5732832478359389342" rel="self" type="application/atom+xml"/>
    <link href="http://mybiasedcoin.blogspot.com/2020/06/writing-code-for-paper-note-to-students.html" rel="alternate" type="text/html"/>
    <title>Writing Code for a Paper :  A Note to Students</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">This post both relates to some of the stuff I'll be presenting at Friday's STOC workshop on Algorithms with Predictions, but is also for future students in my classes, who sometimes wonder why I have them write code on theory material.  (Somehow this might be a theme for a lecture in my grad class next semester, so maybe these are a first attempt at notes for the lecture.  Comments  and  suggestions welcome.)<br/><br/>Some of the work I'm doing is looking at how queueing systems perform with various sorts of predictions on the times the jobs take.  This particular work I'm doing on my own.  (While most of my research has been and is with collaborators, and it's one of the things I enjoy about computer science -- we're a very collaborative field!, which seems to surprise many people -- I still sometimes like to do research projects on my own.  I've looked at queueing systems since my PhD thesis, and it's a bit outside the research interest of most of my collaborator pool, and it's "fun" sometimes to do my own thing.  The reason why "fun" is in quotes is described below.)  <br/><br/>Often in my work in queueing I'm looking at mean-field limits (meant to model infinite systems of queues, which provides a good approximation for large finite systems under reasonable assumptions), where I can derive families of differential equations describing the system behavior.  I can also simulate the large finite system directly, and make sure the results match.  I generally do this for all of these types of papers.<br/><br/>Now the numbers I get from simulating the system directly and from simulating the differential equations should match (say within 1% or so).  If they don't, something is wrong.  In an effort to avoid wrongness, I won't consider the paper ready for outside consumption until I get a match.  Unfortunately, there are three ways things can go wrong.<br/><br/>1.  My simulation code for the queueing system might have bugs.<br/>2.  My code to evaluate the differential equations might have bugs.<br/>3.  My equations themselves might have bugs.<br/><br/>And I find there are two main categories of bugs.  Sometimes the bugs are simple/standard coding mistakes -- I'm off by 1 on an index, or I cut and paste and forget to change an i++ to a j++ in one my double loops, or I type x instead of a y.  Usually it's pretty easy to find these things, although I've had times where a hidden typo took hours to find.  But sometimes the bug is a thinking mistake -- I've forgotten a subcase and so my equations aren't complete (and so my code evaluating the equations won't give the right answer), or I've not handled a subcase correctly in my simulation.  That type usually takes longer. <br/><br/>Usually, the first time through, most all of these types of bugs happen -- my math is off, I've typed some stuff wrong, it can all happen.  And then, like coders everywhere, I go through and fix it.  And it's painful.  Sometimes everything goes right, a quick check or two and everything works.  For more complicated stuff, it's more time figuring out what went wrong than setting up the code to begin with.  And being the personality type to not let things sit, that can mean late nights figuring out what went wrong.<br/><br/>For my talk this week, there was one last problem I wanted to include, which meant finally taking the model and writing the equations and code.  I didn't even need it for the talk, but it's also the last bit before I put a paper draft on arxiv, so taking advantage of a deadline, I figured now was the time.  Which means the last 2 days, I've spent many hours (and a late night) trying to remove the disagreements.<br/><br/>On the plus side, when everything finally works, it's a wonderful feeling.  And it always makes me feel better when I have worked to verify my math this way;  this time, what kept me up well past midnight and took several hours to track down was actually a boundary case I had left out of the equations.  (I had looked at the equations over and over again without noticing I had left out the subcase;  I had to step through numbers from the differential equations one time step at a time to track down what was missing, and then the numbers told me what I had done wrong.)<br/><br/>On the down side, it's work, and debugging is never particularly fun.<br/><br/>For students out there, maybe I'm just explaining that I understand the pain that I am putting you through.  You may wonder why I have you do simulations that take a few hours if you do them well, but days if you don't think through the best approach.  But using programming and theory together can be powerful;  it's helped me countless times in my research.<br/><br/>(Related: on theory and experiments that <a href="https://cacm.acm.org/magazines/2015/9/191184-theory-without-experiments/fulltext">I've written on before</a>, along with <a href="https://cacm.acm.org/magazines/2015/9/191183-experiments-as-research-validation/fulltext">a viewpoint by Jeffrey Ullman</a>.)<br/><br/><br/></div>
    </content>
    <updated>2020-06-25T17:35:00Z</updated>
    <published>2020-06-25T17:35:00Z</published>
    <author>
      <name>Michael Mitzenmacher</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/02161161032642563814</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-8890204</id>
      <category term="conferences"/>
      <category term="research"/>
      <category term="society"/>
      <category term="algorithms"/>
      <category term="administration"/>
      <category term="teaching"/>
      <category term="Harvard"/>
      <category term="papers"/>
      <category term="graduate students"/>
      <category term="funding"/>
      <category term="talks"/>
      <category term="blogs"/>
      <category term="codes"/>
      <category term="jobs"/>
      <category term="reviews"/>
      <category term="personal"/>
      <category term="travel"/>
      <category term="undergraduate students"/>
      <category term="books"/>
      <category term="open problems"/>
      <category term="PCs"/>
      <category term="consulting"/>
      <category term="randomness"/>
      <category term="CCC"/>
      <category term="blog book project"/>
      <category term="research labs"/>
      <category term="ISIT"/>
      <category term="tenure"/>
      <category term="comments"/>
      <category term="recommendations"/>
      <category term="outreach"/>
      <category term="students"/>
      <author>
        <name>Michael Mitzenmacher</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06738274256402616703</uri>
      </author>
      <link href="http://mybiasedcoin.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/8890204/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://mybiasedcoin.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/8890204/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">My take on computer science -- <br/> 
algorithms, networking, information theory -- <br/> 
and related items.</div>
      </subtitle>
      <title>My Biased Coin</title>
      <updated>2020-06-27T18:06:03Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://emanueleviola.wordpress.com/?p=775</id>
    <link href="https://emanueleviola.wordpress.com/2020/06/25/we-dont-need-no-education/" rel="alternate" type="text/html"/>
    <title>We don’t need no education</title>
    <summary>Around us, educational systems whose primary emphasis is on social rather than intellectual skills are simply disintegrating. Unequipped for content delivery, teachers spray parents with a mixture of links and credentials whose collection is a complete waste of everybody’s time. Suggestion: What about assigning homework and let teachers provide feedback? To all the school-age kids […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Around us, educational systems whose primary emphasis is on social rather than intellectual skills are simply disintegrating.  Unequipped for content delivery, teachers spray parents with a mixture of links and credentials whose collection is a complete waste of everybody’s time.  Suggestion: What about assigning <em>homework </em>and let teachers provide <em>feedback</em>?</p>



<p>To all the school-age kids stuck at home doing some fun coding, <a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=&amp;cad=rja&amp;uact=8&amp;ved=2ahUKEwio8MDa4JvqAhWfVhUIHSAIABgQyCkwAHoECBUQBw&amp;url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DYR5ApYxkU-U&amp;usg=AOvVaw0s6Ai-o5-CNtyqFC7uHT_4">this immortal song is for you</a>.</p></div>
    </content>
    <updated>2020-06-25T10:29:13Z</updated>
    <published>2020-06-25T10:29:13Z</published>
    <category term="Uncategorized"/>
    <category term="Utopia"/>
    <author>
      <name>Manu</name>
    </author>
    <source>
      <id>https://emanueleviola.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://emanueleviola.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://emanueleviola.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://emanueleviola.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://emanueleviola.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>by Manu</subtitle>
      <title>Thoughts</title>
      <updated>2020-07-07T00:21:10Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/06/25/postdoc-in-experimental-algorithms-at-national-university-of-singapore-apply-by-august-15-2020/</id>
    <link href="https://cstheory-jobs.org/2020/06/25/postdoc-in-experimental-algorithms-at-national-university-of-singapore-apply-by-august-15-2020/" rel="alternate" type="text/html"/>
    <title>Postdoc in Experimental Algorithms at National University of Singapore (apply by August 15, 2020)</title>
    <summary>A one-year postdoc position (with a possibility of extension for another year) in experimental (/practical) algorithms is available at NUS. The position will be jointly hosted by Diptarka Chakraborty and Kuldeep S. Meel. Applications are invited from candidates who have solid background in algorithm design/formal methods, mathematics. A prior experience in programming would be a […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>A one-year postdoc position (with a possibility of extension for another year) in experimental (/practical) algorithms is available at NUS. The position will be jointly hosted by Diptarka Chakraborty and Kuldeep S. Meel. Applications are invited from candidates who have solid background in algorithm design/formal methods, mathematics. A prior experience in programming would be a plus.</p>
<p>Website: <a href="https://sites.google.com/view/diptarka/postdoc-advertisement">https://sites.google.com/view/diptarka/postdoc-advertisement</a><br/>
Email: diptarka@comp.nus.edu.sg</p></div>
    </content>
    <updated>2020-06-25T06:10:01Z</updated>
    <published>2020-06-25T06:10:01Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-07-07T00:20:51Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/06/25/postdoc-in-tcs-at-national-university-of-singapore-apply-by-august-15-2020-2/</id>
    <link href="https://cstheory-jobs.org/2020/06/25/postdoc-in-tcs-at-national-university-of-singapore-apply-by-august-15-2020-2/" rel="alternate" type="text/html"/>
    <title>Postdoc in TCS at National University of Singapore (apply by August 15, 2020)</title>
    <summary>A one-year postdoc position (with a possibility of extension for another year, subject to availability of fund) in theoretical computer science is available in the research group of Diptarka Chakraborty at NUS. Applications are invited from candidates who have solid background in algorithm design, computational complexity and mathematics. Website: https://sites.google.com/view/diptarka/postdoc-advertisement Email: diptarka@comp.nus.edu.sg</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>A one-year postdoc position (with a possibility of extension for another year, subject to availability of fund) in theoretical computer science is available in the research group of Diptarka Chakraborty at NUS. Applications are invited from candidates who have solid background in algorithm design, computational complexity and mathematics.</p>
<p>Website: <a href="https://sites.google.com/view/diptarka/postdoc-advertisement">https://sites.google.com/view/diptarka/postdoc-advertisement</a><br/>
Email: diptarka@comp.nus.edu.sg</p></div>
    </content>
    <updated>2020-06-25T06:05:34Z</updated>
    <published>2020-06-25T06:05:34Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-07-07T00:20:51Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/06/25/postdoc-in-tcs-at-national-university-of-singapore-apply-by-august-15-2020/</id>
    <link href="https://cstheory-jobs.org/2020/06/25/postdoc-in-tcs-at-national-university-of-singapore-apply-by-august-15-2020/" rel="alternate" type="text/html"/>
    <title>Postdoc in TCS at National University of Singapore (apply by August 15, 2020)</title>
    <summary>A one-year postdoc position (with a possibility of extension for another year, subject to availability of fund) in theoretical computer science is available in the research group of Diptarka Chakraborty at NUS. Applications are invited from candidates who have solid background in algorithm design, computational complexity and mathematics. Website: https://sites.google.com/view/diptarka/postdoc-advertisement Email: diptarka@comp.nus.edu.sg</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>A one-year postdoc position (with a possibility of extension for another year, subject to availability of fund) in theoretical computer science is available in the research group of Diptarka Chakraborty at NUS. Applications are invited from candidates who have solid background in algorithm design, computational complexity and mathematics.</p>
<p>Website: <a href="https://sites.google.com/view/diptarka/postdoc-advertisement">https://sites.google.com/view/diptarka/postdoc-advertisement</a><br/>
Email: diptarka@comp.nus.edu.sg</p></div>
    </content>
    <updated>2020-06-25T06:05:03Z</updated>
    <published>2020-06-25T06:05:03Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-07-07T00:20:51Z</updated>
    </source>
  </entry>
</feed>
