<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2019-03-02T07:21:55Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/028</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/028" rel="alternate" type="text/html"/>
    <title>TR19-028 |  From DNF compression to sunflower theorems via regularity | 

	Jiapeng Zhang, 

	Shachar Lovett, 

	Noam Solomon</title>
    <summary>The sunflower conjecture is one of the most well-known open problems in combinatorics. It has several applications in theoretical computer science, one of which is DNF compression, due to Gopalan, Meka and Reingold [Computational Complexity 2013]. In this paper, we show that improved bounds for DNF compression imply improved bounds for the sunflower conjecture, which is the reverse direction of [Computational Complexity 2013]. The main approach is based on regularity of set systems and a structure-vs-pseudorandomness approach to the sunflower conjecture.</summary>
    <updated>2019-03-02T02:49:44Z</updated>
    <published>2019-03-02T02:49:44Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-03-02T07:20:40Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/027</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/027" rel="alternate" type="text/html"/>
    <title>TR19-027 |  Sign-Rank Can Increase Under Intersection | 

	Mark Bun, 

	Nikhil Mande, 

	Justin Thaler</title>
    <summary>The communication class $UPP^{cc}$ is a communication analog of the Turing Machine complexity class $PP$. It is characterized by a matrix-analytic complexity measure called sign-rank (also called dimension complexity), and is essentially the most powerful communication class against which we know how to prove lower bounds.

For a communication problem $f$, let $f \wedge f$ denote the function that evaluates $f$ on two disjoint inputs and outputs the AND of the results.  We exhibit a communication problem $f$ with $UPP(f)= O(\log n)$, and $UPP(f \wedge f) = \Theta(\log^2 n)$. 
This is the first result showing that $UPP$ communication complexity can increase by more than a constant factor under intersection. We view this as a first step toward showing that $UPP^{cc}$, the class of problems with polylogarithmic-cost $UPP$ communication protocols, is not closed under intersection.

Our result shows that the function class consisting of intersections of two majorities on $n$ bits has dimension complexity $n^{\Omega(\log n)}$. This matches an upper bound of  (Klivans, O'Donnell, and Servedio, FOCS 2002), who used it to give a quasipolynomial time algorithm for PAC learning intersections of polylogarithmically many majorities. Hence, fundamentally new techniques will be needed to learn this class of functions in polynomial time.</summary>
    <updated>2019-03-02T01:18:16Z</updated>
    <published>2019-03-02T01:18:16Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-03-02T07:20:40Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/03/01/postdoc-at-university-of-vienna-apply-by-march-22-2019/</id>
    <link href="https://cstheory-jobs.org/2019/03/01/postdoc-at-university-of-vienna-apply-by-march-22-2019/" rel="alternate" type="text/html"/>
    <title>Postdoc at University of Vienna (apply by March 22, 2019)</title>
    <summary>We are looking for a strong candidate in efficient algorithms and data structures starting fall 2019 (flexible). Website: https://taa.cs.univie.ac.at/ Email: monika.henzinger@univie.ac.at</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>We are looking for a strong candidate in efficient algorithms and data structures starting fall 2019 (flexible).</p>
<p>Website: <a href="https://taa.cs.univie.ac.at/">https://taa.cs.univie.ac.at/</a><br/>
Email: monika.henzinger@univie.ac.at</p></div>
    </content>
    <updated>2019-03-01T13:24:51Z</updated>
    <published>2019-03-01T13:24:51Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-03-02T07:20:51Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/026</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/026" rel="alternate" type="text/html"/>
    <title>TR19-026 |  Lower Bounds on Balancing Sets and Depth-2 Threshold Circuits | 

	Pavel Hrubes, 

	Sivaramakrishnan Natarajan Ramamoorthy, 

	Anup  Rao, 

	Amir Yehudayoff</title>
    <summary>There are various notions of balancing set families that appear in combinatorics and computer science. For example, a family of proper non-empty subsets $S_1,\ldots,S_k \subset [n]$ is balancing if for every subset $X \subset \{1,2,\ldots,n\}$ of size $n/2$, there is an $i \in [k]$ so that $|S_i \cap X| = |S_i|/2$. We extend and simplify the framework developed by Hegedüs for proving lower bounds on the size of balancing set families. We prove that if $n=2p$ for a prime $p$, then $k \geq p$. For arbitrary values of $n$, we show that $k \geq n/2 - o(n)$.

We then exploit the connection between balancing families and depth-2 threshold circuits. This connection helps resolve a question raised by Kulikov and Podolskii on the fan-in of depth-2 majority circuits computing the majority function on $n$ bits. We show that any depth-2 threshold circuit that computes the majority on $n$ bits has at least one gate with fan-in at least $n/2 - o(n)$. We also prove a sharp lower bound on the fan-in of depth-2 threshold circuits computing a specific weighted threshold function.</summary>
    <updated>2019-03-01T07:12:49Z</updated>
    <published>2019-03-01T07:12:49Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-03-02T07:20:40Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.11281</id>
    <link href="http://arxiv.org/abs/1902.11281" rel="alternate" type="text/html"/>
    <title>Fair Dimensionality Reduction and Iterative Rounding for SDPs</title>
    <feedworld_mtime>1551398400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Morgenstern:Jamie.html">Jamie Morgenstern</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Samadi:Samira.html">Samira Samadi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Singh:Mohit.html">Mohit Singh</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tantipongpipat:Uthaipon.html">Uthaipon Tantipongpipat</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vempala:Santosh.html">Santosh Vempala</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.11281">PDF</a><br/><b>Abstract: </b>We model "fair" dimensionality reduction as an optimization problem. A
central example is the fair PCA problem: the input data is divided into $k$
groups, and the goal is to find a single $d$-dimensional representation for all
groups for which the maximum variance (or minimum reconstruction error) is
optimized for all groups in a fair (or balanced) manner, e.g., by maximizing
the minimum variance over the $k$ groups of the projection to a $d$-dimensional
subspace. This problem was introduced by Samadi et al. (2018) who gave a
polynomial-time algorithm which, for $k=2$ groups, returns a
$(d+1)$-dimensional solution of value at least the best $d$-dimensional
solution. We give an exact polynomial-time algorithm for $k=2$ groups. The
result relies on extending results of Pataki (1998) regarding rank of extreme
point solutions to semi-definite programs. This approach applies more generally
to any monotone concave function of the individual group objectives. For $k&gt;2$
groups, our results generalize to give a $(d+\sqrt{2k+0.25}-1.5)$-dimensional
solution with objective value as good as the optimal $d$-dimensional solution
for arbitrary $k,d$ in polynomial time. Using our extreme point
characterization result for SDPs, we give an iterative rounding framework for
general SDPs which generalizes the well-known iterative rounding approach for
LPs. It returns low-rank solutions with bounded violation of constraints. We
obtain a $d$-dimensional projection where the violation in the objective can be
bounded additively in terms of the top $O(\sqrt{k})$-singular values of the
data matrices. We also give an exact polynomial-time algorithm for any fixed
number of groups and target dimension via the algorithm of Grigoriev and
Pasechnik (2005). In contrast, when the number of groups is part of the input,
even for target dimension $d=1$, we show this problem is NP-hard.
</p></div>
    </summary>
    <updated>2019-03-01T23:27:39Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-03-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.11257</id>
    <link href="http://arxiv.org/abs/1902.11257" rel="alternate" type="text/html"/>
    <title>Efficient classical simulation of Clifford circuits with nonstabilizer input states</title>
    <feedworld_mtime>1551398400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bu:Kaifeng.html">Kaifeng Bu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Koh:Dax_Enshan.html">Dax Enshan Koh</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.11257">PDF</a><br/><b>Abstract: </b>We investigate the problem of evaluating the output probabilities of Clifford
circuits with nonstabilizer product input states. First, we consider the case
when the input state is mixed, and give an efficient classical algorithm to
approximate the output probabilities, with respect to the $l_1$ norm, of a
large fraction of Clifford circuits. The running time of our algorithm
decreases as the inputs become more mixed. Second, we consider the case when
the input state is a pure nonstabilizer product state, and show that a similar
efficient algorithm exists to approximate the output probabilities, when a
suitable restriction is placed on the number of qubits measured. This
restriction depends on a magic monotone that we call the Pauli rank. We apply
our results to give an efficient output probability approximation algorithm for
some restricted quantum computation models, such as Clifford circuits with
solely magic state inputs (CM), Pauli-based computation (PBC) and instantaneous
quantum polynomial time (IQP) circuits.
</p></div>
    </summary>
    <updated>2019-03-01T23:21:47Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-03-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.11202</id>
    <link href="http://arxiv.org/abs/1902.11202" rel="alternate" type="text/html"/>
    <title>Unifying computational entropies via Kullback-Leibler divergence</title>
    <feedworld_mtime>1551398400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Agrawal:Rohit.html">Rohit Agrawal</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Yi=Hsiu.html">Yi-Hsiu Chen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Horel:Thibaut.html">Thibaut Horel</a>, Salil Vadhan <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.11202">PDF</a><br/><b>Abstract: </b>We introduce KL-hardness, a new notion of hardness for search problems which
on the one hand is satisfied by all one-way functions and on the other hand
implies both next-block pseudoentropy and inaccessible-entropy, two forms of
computational entropy used in recent constructions of pseudorandom generators
and statistically hiding commitment schemes, respectively. Thus, KL-hardness
unifies the latter two notions of computational entropy and sheds light on the
apparent "duality" between them. Additionally, it yields a more modular and
illuminating proof that one-way functions imply next-block inaccessible
entropy, similar in structure to the proof that one-way functions imply
next-block pseudoentropy (Vadhan and Zheng, STOC '12).
</p></div>
    </summary>
    <updated>2019-03-01T23:26:11Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-03-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.11169</id>
    <link href="http://arxiv.org/abs/1902.11169" rel="alternate" type="text/html"/>
    <title>Dynamic Planar Convex Hull</title>
    <feedworld_mtime>1551398400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jacob:Riko.html">Riko Jacob</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Brodal:Gerth_St=oslash=lting.html">Gerth Stølting Brodal</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.11169">PDF</a><br/><b>Abstract: </b>In this article, we determine the amortized computational complexity of the
planar dynamic convex hull problem by querying.
</p>
<p>We present a data structure that maintains a set of n points in the plane
under the insertion and deletion of points in amortized O(log n) time per
operation. The space usage of the data structure is O(n). The data structure
supports extreme point queries in a given direction, tangent queries through a
given point, and queries for the neighboring points on the convex hull in O(log
n) time. The extreme point queries can be used to decide whether or not a given
line intersects the convex hull, and the tangent queries to determine whether a
given point is inside the convex hull.
</p>
<p>We give a lower bound on the amortized asymptotic time complexity that
matches the performance of this data structure.
</p></div>
    </summary>
    <updated>2019-03-01T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-03-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.11149</id>
    <link href="http://arxiv.org/abs/1902.11149" rel="alternate" type="text/html"/>
    <title>Algorithm and Hardness results on Liar's Dominating Set and $k$-tuple Dominating Set</title>
    <feedworld_mtime>1551398400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Banerjee:Sandip.html">Sandip Banerjee</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bhore:Sujoy.html">Sujoy Bhore</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.11149">PDF</a><br/><b>Abstract: </b>Given a graph $G=(V,E)$, the dominating set problem asks for a minimum subset
of vertices $D\subseteq V$ such that every vertex $u\in V\setminus D$ is
adjacent to at least one vertex $v\in D$. That is, the set $D$ satisfies the
condition that $|N[v]\cap D|\geq 1$ for each $v\in V$, where $N[v]$ is the
closed neighborhood of $v$. In this paper, we study two variants of the
classical dominating set problem: $k$-tuple dominating set ($k$-DS) problem and
Liar's dominating set (LDS) problem, and obtain several algorithmic and
hardness results. On the algorithmic side, we present a constant factor
($\frac{11}{2}$)-approximation algorithm for the Liar's dominating set problem
on unit disk graphs. Then, we obtain a PTAS for the $k$-tuple dominating set
problem on unit disk graphs. On the hardness side, we show a $\Omega (n^2)$
bits lower bound for the space complexity of any (randomized) streaming
algorithm for Liar's dominating set problem as well as for the $k$-tuple
dominating set problem. Furthermore, we prove that the Liar's dominating set
problem on bipartite graphs is W[2]-hard.
</p></div>
    </summary>
    <updated>2019-03-01T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-03-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.11105</id>
    <link href="http://arxiv.org/abs/1902.11105" rel="alternate" type="text/html"/>
    <title>Quantum walk inspired algorithm for graph similarity and isomorphism</title>
    <feedworld_mtime>1551398400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Callum Schofield, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Jingbo_B=.html">Jingbo B. Wang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Yuying.html">Yuying Li</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.11105">PDF</a><br/><b>Abstract: </b>Large scale complex systems, such as social networks, electrical power grid,
database structure, consumption pattern or brain connectivity, are often
modeled using network graphs. Valuable insight can be gained by measuring the
similarity between network graphs in order to make quantitative comparisons.
Since these networks can be very large, scalability and efficiency of the
algorithm are key concerns. More importantly, for graphs with unknown labeling,
this graph similarity problem requires exponential time to solve using existing
algorithms. In this paper, we propose a quantum walk inspired algorithm, which
provides a solution to the graph similarity problem without prior knowledge on
graph labeling. This algorithm is capable of distinguishing between minor
structural differences, such as between strongly regular graphs with the same
parameters. The algorithm has polynomial complexity, scaling with $O(n^9)$.
</p></div>
    </summary>
    <updated>2019-03-01T23:26:39Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-03-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.11047</id>
    <link href="http://arxiv.org/abs/1902.11047" rel="alternate" type="text/html"/>
    <title>Ratio-Balanced Maximum Flows</title>
    <feedworld_mtime>1551398400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Hannaneh Akrami, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mehlhorn:Kurt.html">Kurt Mehlhorn</a>, Tommy Odland <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.11047">PDF</a><br/><b>Abstract: </b>When a loan is approved for a person or company, the bank is subject to
\emph{credit risk}; the risk that the lender defaults. To mitigate this risk, a
bank will require some form of \emph{security}, which will be collected if the
lender defaults. Accounts can be secured by several securities and a security
can be used for several accounts. The goal is to fractionally assign the
securities to the accounts so as to balance the risk.
</p>
<p>This situation can be modelled by a bipartite graph. We have a set $S$ of
securities and a set $A$ of accounts. Each security has a \emph{value} $v_i$
and each account has an \emph{exposure} $e_j$. If a security $i$ can be used to
secure an account $j$, we have an edge from $i$ to $j$. Let $f_{ij}$ be part of
security $i$'s value used to secure account $j$. We are searching for a maximum
flow that send at most $v_i$ units out of node $i \in S$ and at most $e_j$
units into node $j \in A$. Then $s_j = e_j - \sum_i f_{ij}$ is the unsecured
part of account $j$. We are searching for the maximum flow that minimizes
$\sum_j s_j^2/e_j$.
</p></div>
    </summary>
    <updated>2019-03-01T23:39:45Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-03-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.11044</id>
    <link href="http://arxiv.org/abs/1902.11044" rel="alternate" type="text/html"/>
    <title>On the Area Requirements of Planar Straight-Line Orthogonal Drawings of Ternary Trees</title>
    <feedworld_mtime>1551398400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Covella:Barbara.html">Barbara Covella</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Frati:Fabrizio.html">Fabrizio Frati</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Patrignani:Maurizio.html">Maurizio Patrignani</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.11044">PDF</a><br/><b>Abstract: </b>In this paper, we study the area requirements of planar straight-line
orthogonal drawings of ternary trees. We prove that every ternary tree admits
such a drawing in sub-quadratic area. Further, we present upper bounds, the
outcomes of an experimental evaluation, and a conjecture on the area
requirements of planar straight-line orthogonal drawings of complete ternary
trees. Finally, we present a polynomial lower bound on the length of the
minimum side of any planar straight-line orthogonal drawing of a complete
ternary tree.
</p></div>
    </summary>
    <updated>2019-03-01T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-03-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.11006</id>
    <link href="http://arxiv.org/abs/1902.11006" rel="alternate" type="text/html"/>
    <title>A Hierarchy of Polynomial Kernels</title>
    <feedworld_mtime>1551398400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Witteveen:Jouke.html">Jouke Witteveen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bottesch:Ralph.html">Ralph Bottesch</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Torenvliet:Leen.html">Leen Torenvliet</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.11006">PDF</a><br/><b>Abstract: </b>In parameterized algorithmics, the process of kernelization is defined as a
polynomial time algorithm that transforms the instance of a given problem to an
equivalent instance of a size that is limited by a function of the parameter.
As, afterwards, this smaller instance can then be solved to find an answer to
the original question, kernelization is often presented as a form of
preprocessing. A natural generalization of kernelization is the process that
allows for a number of smaller instances to be produced to provide an answer to
the original problem, possibly also using negation. This generalization is
called Turing kernelization. Immediately, questions of equivalence occur or,
when is one form possible and not the other. These have been long standing open
problems in parameterized complexity. In the present paper, we answer many of
these. In particular, we show that Turing kernelizations differ not only from
regular kernelization, but also from intermediate forms as truth-table
kernelizations. We achieve absolute results by diagonalizations and also
results on natural problems depending on widely accepted complexity theoretic
assumptions. In particular, we improve on known lower bounds for the kernel
size of compositional problems using these assumptions.
</p></div>
    </summary>
    <updated>2019-03-01T23:20:39Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-03-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.10995</id>
    <link href="http://arxiv.org/abs/1902.10995" rel="alternate" type="text/html"/>
    <title>Fast Concurrent Data Sketches</title>
    <feedworld_mtime>1551398400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Arik Rinberg, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Spiegelman:Alexander.html">Alexander Spiegelman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bortnikov:Edward.html">Edward Bortnikov</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hillel:Eshcar.html">Eshcar Hillel</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Keidar:Idit.html">Idit Keidar</a>, Hadar Serviansky <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.10995">PDF</a><br/><b>Abstract: </b>Data sketches are approximate succinct summaries of long streams. They are
widely used for processing massive amounts of data and answering statistical
queries about it in real-time. Existing libraries producing sketches are very
fast, but do not allow parallelism for creating sketches using multiple threads
or querying them while they are being built. We present a generic approach to
parallelising data sketches efficiently, while bounding the error that such
parallelism introduces. Utilising relaxed semantics and the notion of strong
linearisability we prove our algorithm's correctness and analyse the error it
induces in two specific sketches. Our implementation achieves high scalability
while keeping the error small.
</p></div>
    </summary>
    <updated>2019-03-01T23:38:09Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-03-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.10983</id>
    <link href="http://arxiv.org/abs/1902.10983" rel="alternate" type="text/html"/>
    <title>Graph and String Parameters: Connections Between Pathwidth, Cutwidth and the Locality Number</title>
    <feedworld_mtime>1551398400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Casel:Katrin.html">Katrin Casel</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Day:Joel_D=.html">Joel D. Day</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fleischmann:Pamela.html">Pamela Fleischmann</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kociumaka:Tomasz.html">Tomasz Kociumaka</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Manea:Florin.html">Florin Manea</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schmid:Markus_L=.html">Markus L. Schmid</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.10983">PDF</a><br/><b>Abstract: </b>We investigate the locality number, a recently introduced structural
parameter for strings (with applications in pattern matching with variables),
and its connection to two important graph-parameters, cutwidth and pathwidth.
These connections allow us to show that computing the locality number is
NP-hard but fixed parameter tractable (when the locality number or the alphabet
size is treated as a parameter), and can be approximated with ratio
$O(\sqrt{\log{opt}} \log n)$. As a by-product, we also relate cutwidth via the
locality number to pathwidth, which is of independent interest, since it
improves the currently best known approximation algorithm for cutwidth. In
addition to these main results, we also consider the possibility of
greedy-based approximation algorithms for the locality number.
</p></div>
    </summary>
    <updated>2019-03-01T23:32:56Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-03-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.10966</id>
    <link href="http://arxiv.org/abs/1902.10966" rel="alternate" type="text/html"/>
    <title>Probabilistic smallest enclosing ball in high dimensions via subgradient sampling</title>
    <feedworld_mtime>1551398400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Amer Krivošija, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Munteanu:Alexander.html">Alexander Munteanu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.10966">PDF</a><br/><b>Abstract: </b>We study a variant of the median problem for a collection of point sets in
high dimensions. This generalizes the geometric median as well as the
(probabilistic) smallest enclosing ball (pSEB) problems. Our main objective and
motivation is to improve the previously best algorithm for the pSEB problem by
reducing its exponential dependence on the dimension to linear. This is
achieved via a novel combination of sampling techniques for clustering problems
in metric spaces with the framework of stochastic subgradient descent. As a
result, the algorithm becomes applicable to shape fitting problems in Hilbert
spaces of unbounded dimension via kernel functions. We present an exemplary
application by extending the support vector data description (SVDD) shape
fitting method to the probabilistic case. This is done by simulating the pSEB
algorithm implicitly in the feature space induced by the kernel function.
</p></div>
    </summary>
    <updated>2019-03-01T23:48:47Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-03-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.10935</id>
    <link href="http://arxiv.org/abs/1902.10935" rel="alternate" type="text/html"/>
    <title>Lower Bounds for Multiplication via Network Coding</title>
    <feedworld_mtime>1551398400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Afshani:Peyman.html">Peyman Afshani</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Freksen:Casper_Benjamin.html">Casper Benjamin Freksen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kamma:Lior.html">Lior Kamma</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Larsen:Kasper_Green.html">Kasper Green Larsen</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.10935">PDF</a><br/><b>Abstract: </b>Multiplication is one of the most fundamental computational problems, yet its
true complexity remains elusive. The best known upper bound, by F\"{u}rer,
shows that two $n$-bit numbers can be multiplied via a boolean circuit of size
$O(n \lg n \cdot 4^{\lg^*n})$, where $\lg^*n$ is the very slowly growing
iterated logarithm. In this work, we prove that if a central conjecture in the
area of network coding is true, then any constant degree boolean circuit for
multiplication must have size $\Omega(n \lg n)$, thus almost completely
settling the complexity of multiplication circuits. We additionally revisit
classic conjectures in circuit complexity, due to Valiant, and show that the
network coding conjecture also implies one of Valiant's conjectures.
</p></div>
    </summary>
    <updated>2019-03-01T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-03-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.10851</id>
    <link href="http://arxiv.org/abs/1902.10851" rel="alternate" type="text/html"/>
    <title>Analysis of Quantum Multi-Prover Zero-Knowledge Systems: Elimination of the Honest Condition and Computational Zero-Knowledge Systems for QMIP*</title>
    <feedworld_mtime>1551398400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kinoshita:Yusuke.html">Yusuke Kinoshita</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.10851">PDF</a><br/><b>Abstract: </b>Zero-knowledge and multi-prover systems are both central notions in classical
and quantum complexity theory. There is, however, little research in quantum
multi-prover zero-knowledge systems. This paper studies complexity-theoretical
aspects of the quantum multi-prover zero-knowledge systems. This paper has two
results:
</p>
<p>1.QMIP* systems with honest zero-knowledge can be converted into general
zero-knowledge systems without any assumptions.
</p>
<p>2.QMIP* has computational quantum zero-knowledge systems if a natural
computational conjecture holds.
</p>
<p>One of the main tools is a test (called the GHZ test) that uses GHZ states
shared by the provers, which prevents the verifier's attack in the above two
results. Another main tool is what we call the Local Hamiltonian based
Interactive protocol (LHI protocol). The LHI protocol makes previous research
for Local Hamiltonians applicable to check the history state of interactive
proofs, and we then apply Broadbent et al.'s zero-knowledge protocol for QMA
\cite{BJSW} to quantum multi-prover systems in order to obtain the second
result.
</p></div>
    </summary>
    <updated>2019-03-01T23:21:56Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-03-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.10829</id>
    <link href="http://arxiv.org/abs/1902.10829" rel="alternate" type="text/html"/>
    <title>Improved algorithms for Correlation Clustering with local objectives</title>
    <feedworld_mtime>1551398400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Sanchit Kalhan, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Makarychev:Konstantin.html">Konstantin Makarychev</a>, Timothy Zhou <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.10829">PDF</a><br/><b>Abstract: </b>Correlation Clustering is a powerful graph partitioning model that aims to
cluster items based on the notion of similarity between items. An instance of
the Correlation Clustering problem consists of a graph $G$ (not necessarily
complete) whose edges are labeled by a binary classifier as "similar" and
"dissimilar". Classically, we are tasked with producing a clustering that
minimizes the number of disagreements: an edge is in disagreement if it is a
"similar" edge and is present across clusters or if it is a "dissimilar" edge
and is present within a cluster. Define the disagreements vector to be an $n$
dimensional vector indexed by the vertices, where the $v$-th index is the
number of disagreements at vertex $v$. Recently, Puleo and Milenkovic (ICML
'16) initiated the study of the Correlation Clustering framework in which the
objectives were more general functions of the disagreements vector. In this
paper, we study algorithms for minimizing $\ell_q$ norms $(q \geq 1)$ of the
disagreements vector for both arbitrary and complete graphs. We present the
first known algorithm for minimizing the $\ell_q$ norm of the disagreements
vector on arbitrary graphs and also provide an improved algorithm for
minimizing the $\ell_q$ norm $(q \geq 1)$ of the disagreements vector on
complete graphs. Finally, we compliment these two algorithmic results with some
hardness results.
</p></div>
    </summary>
    <updated>2019-03-01T23:34:21Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-03-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.10812</id>
    <link href="http://arxiv.org/abs/1902.10812" rel="alternate" type="text/html"/>
    <title>Padovan heaps</title>
    <feedworld_mtime>1551398400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Majerech:Vladan.html">Vladan Majerech</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.10812">PDF</a><br/><b>Abstract: </b>We analyze priority queues of Fibonacci family. The paper is inspired by
Violation heap [1], where A. Elmasry saves one pointer in representation of
Fibonacci heap nodes while achieving the same amortized bounds as Fibonacci
heaps [2] of M. L. Fredman and R. E. Tarjan. Unfortunately author forces the
heaps to be wide, what goes against optimal heap principles. Our goal is to
achieve the same result, but with much narrower heaps. We follow the principle
of superexpensive comparison so we try to remember results of all comparisons
and never compare elements that cannot be minimal. We delay comparisons as long
as possible. Actually I have always want to share superexpensive comparison
principle ideas, discovery of Padovan heaps allowed me to do so. Of course
saving one pointer is not that big goal, but I hope the presented reasoning and
amortized analysis of the resulting heaps is worth a publication.
</p></div>
    </summary>
    <updated>2019-03-01T23:38:04Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-03-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.10773</id>
    <link href="http://arxiv.org/abs/1902.10773" rel="alternate" type="text/html"/>
    <title>An exponential lower bound for the degrees of invariants of cubic forms and tensor actions</title>
    <feedworld_mtime>1551398400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Derksen:Harm.html">Harm Derksen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Makam:Visu.html">Visu Makam</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.10773">PDF</a><br/><b>Abstract: </b>Using the Grosshans Principle, we develop a method for proving lower bounds
for the maximal degree of a system of generators of an invariant ring. This
method also gives lower bounds for the maximal degree of a set of invariants
that define Hilbert's null cone. We consider two actions: The first is the
action of ${\rm SL}(V)$ on ${\rm Sym}^3(V)^{\oplus 4}$, the space of $4$-tuples
of cubic forms, and the second is the action of ${\rm SL}(V) \times {\rm SL}(W)
\times {\rm SL}(Z)$ on the tensor space $(V \otimes W \otimes Z)^{\oplus 9}$.
In both these cases, we prove an exponential lower degree bound for a system of
invariants that generate the invariant ring or that define the null cone.
</p></div>
    </summary>
    <updated>2019-03-01T23:26:27Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-03-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.10765</id>
    <link href="http://arxiv.org/abs/1902.10765" rel="alternate" type="text/html"/>
    <title>Reconfiguration of Connected Graph Partitions</title>
    <feedworld_mtime>1551398400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Akitaya:Hugo_A=.html">Hugo A. Akitaya</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jones:Matthew_D=.html">Matthew D. Jones</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Korman:Matias.html">Matias Korman</a>, Christopher Meierfrankenfeld, Michael J. Munje, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Souvaine:Diane_L=.html">Diane L. Souvaine</a>, Michael Thramann, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/T=oacute=th:Csaba_D=.html">Csaba D. Tóth</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.10765">PDF</a><br/><b>Abstract: </b>Motivated by recent computational models for redistricting and detection of
gerrymandering, we study the following problem on graph partitions. Given a
graph $G$ and an integer $k\geq 1$, a $k$-district map of $G$ is a partition of
$V(G)$ into $k$ nonempty subsets, called districts, each of which induces a
connected subgraph of $G$. A switch is an operation that modifies a
$k$-district map by reassigning a subset of vertices from one district to an
adjacent district; a 1-switch is a switch that moves a single vertex. We study
the connectivity of the configuration space of all $k$-district maps of a graph
$G$ under 1-switch operations. We give a combinatorial characterization for the
connectedness of this space that can be tested efficiently. We prove that it is
NP-complete to decide whether there exists a sequence of 1-switches that takes
a given $k$-district map into another; and NP-hard to find the shortest such
sequence (even if a sequence of polynomial length is known to exist). We also
present efficient algorithms for computing a sequence of 1-switches that takes
a given $k$-district map into another when the space is connected, and show
that these algorithms perform a worst-case optimal number of switches up to
constant factors.
</p></div>
    </summary>
    <updated>2019-03-01T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-03-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.10731</id>
    <link href="http://arxiv.org/abs/1902.10731" rel="alternate" type="text/html"/>
    <title>Private Center Points and Learning of Halfspaces</title>
    <feedworld_mtime>1551398400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Beimel:Amos.html">Amos Beimel</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Moran:Shay.html">Shay Moran</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nissim:Kobbi.html">Kobbi Nissim</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Stemmer:Uri.html">Uri Stemmer</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.10731">PDF</a><br/><b>Abstract: </b>We present a private learner for halfspaces over an arbitrary finite domain
$X\subset \mathbb{R}^d$ with sample complexity $mathrm{poly}(d,2^{\log^*|X|})$.
The building block for this learner is a differentially private algorithm for
locating an approximate center point of $m&gt;\mathrm{poly}(d,2^{\log^*|X|})$
points -- a high dimensional generalization of the median function. Our
construction establishes a relationship between these two problems that is
reminiscent of the relation between the median and learning one-dimensional
thresholds [Bun et al.\ FOCS '15]. This relationship suggests that the problem
of privately locating a center point may have further applications in the
design of differentially private algorithms.
</p>
<p>We also provide a lower bound on the sample complexity for privately finding
a point in the convex hull. For approximate differential privacy, we show a
lower bound of $m=\Omega(d+\log^*|X|)$, whereas for pure differential privacy
$m=\Omega(d\log|X|)$.
</p></div>
    </summary>
    <updated>2019-03-01T23:45:29Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-03-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.10710</id>
    <link href="http://arxiv.org/abs/1902.10710" rel="alternate" type="text/html"/>
    <title>High probability generalization bounds for uniformly stable algorithms with nearly optimal rate</title>
    <feedworld_mtime>1551398400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Feldman:Vitaly.html">Vitaly Feldman</a>, Jan Vondrak <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.10710">PDF</a><br/><b>Abstract: </b>Algorithmic stability is a classical approach to understanding and analysis
of the generalization error of learning algorithms. A notable weakness of most
stability-based generalization bounds is that they hold only in expectation.
Generalization with high probability has been established in a landmark paper
of Bousquet and Elisseeff (2002) albeit at the expense of an additional
$\sqrt{n}$ factor in the bound. Specifically, their bound on the estimation
error of any $\gamma$-uniformly stable learning algorithm on $n$ samples and
range in $[0,1]$ is $O(\gamma \sqrt{n \log(1/\delta)} +
\sqrt{\log(1/\delta)/n})$ with probability $\geq 1-\delta$. The $\sqrt{n}$
overhead makes the bound vacuous in the common settings where $\gamma \geq
1/\sqrt{n}$. A stronger bound was recently proved by the authors (Feldman and
Vondrak, 2018) that reduces the overhead to at most $O(n^{1/4})$. Still, both
of these results give optimal generalization bounds only when $\gamma =
O(1/n)$.
</p>
<p>We prove a nearly tight bound of $O(\gamma \log(n)\log(n/\delta) +
\sqrt{\log(1/\delta)/n})$ on the estimation error of any $\gamma$-uniformly
stable algorithm. It implies that algorithms that are uniformly stable with
$\gamma = O(1/\sqrt{n})$ have essentially the same estimation error as
algorithms that output a fixed function. Our result leads to the first
high-probability generalization bounds for multi-pass stochastic gradient
descent and regularized ERM for stochastic convex problems with nearly optimal
rate --- resolving open problems in prior work. Our proof technique is new and
we introduce several analysis tools that might find additional applications.
</p></div>
    </summary>
    <updated>2019-03-01T23:29:58Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-03-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.10369</id>
    <link href="http://arxiv.org/abs/1902.10369" rel="alternate" type="text/html"/>
    <title>Counting to Ten with Two Fingers: Compressed Counting with Spiking Neurons</title>
    <feedworld_mtime>1551398400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hitron:Yael.html">Yael Hitron</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Parter:Merav.html">Merav Parter</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.10369">PDF</a><br/><b>Abstract: </b>We consider the task of measuring time with probabilistic threshold gates
implemented by bio-inspired spiking neurons. In the model of spiking neural
networks, network evolves in discrete rounds, where in each round, neurons fire
in pulses in response to a sufficiently high membrane potential. This potential
is induced by spikes from neighboring neurons that fired in the previous round,
which can have either an excitatory or inhibitory effect. We first consider a
deterministic implementation of a neural timer and show that $\Theta(\log t)$
(deterministic) threshold gates are both sufficient and necessary. This raised
the question of whether randomness can be leveraged to reduce the number of
neurons. We answer this question in the affirmative by considering neural
timers with spiking neurons where the neuron $y$ is required to fire for $t$
consecutive rounds with probability at least $1-\delta$, and should stop firing
after at most $2t$ rounds with probability $1-\delta$ for some input parameter
$\delta \in (0,1)$. Our key result is a construction of a neural timer with
$O(\log\log 1/\delta)$ spiking neurons. Interestingly, this construction uses
only one spiking neuron, while the remaining neurons can be deterministic
threshold gates. We complement this construction with a matching lower bound of
$\Omega(\min\{\log\log 1/\delta, \log t\})$ neurons. This provides the first
separation between deterministic and randomized constructions in the setting of
spiking neural networks. Finally, we demonstrate the usefulness of compressed
counting networks for synchronizing neural networks.
</p></div>
    </summary>
    <updated>2019-03-01T23:32:37Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-03-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-27705661.post-6262255604237177078</id>
    <link href="http://processalgebra.blogspot.com/feeds/6262255604237177078/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=27705661&amp;postID=6262255604237177078" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/6262255604237177078" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/6262255604237177078" rel="self" type="application/atom+xml"/>
    <link href="http://processalgebra.blogspot.com/2019/02/grundfos-associate-professorship-in.html" rel="alternate" type="text/html"/>
    <title>GRUNDFOS ASSOCIATE PROFESSORSHIP IN COMPUTER SCIENCE, AALBORG UNIVERSITY</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><i>Kim G. Larsen asked me to distribute this call for a very attractive associate professorship at Aalborg University. I trust that this might be of interest to some of the readers of this blog.</i><br/><br/><span>GRUNDFOS ASSOCIATE PROFESSORSHIP IN COMPUTER SCIENCE, AALBORG UNIVERSITY</span><br/><br/><div class="x_MsoNormal"><b><span style="font-family: Helvetica, sans-serif, serif, EmojiFont; font-size: 10.5pt; letter-spacing: 2.25pt;">ASSOCIATE PROFESSORSHIP AT AALBORG UNIVERSITY</span></b><span style="font-family: Helvetica, sans-serif, serif, EmojiFont; font-size: 10.5pt; letter-spacing: 2.25pt;"><br/></span><span style="background: white; font-family: Helvetica, sans-serif, serif, EmojiFont; font-size: 9pt;">At the Technical Faculty of IT and Design, Department of Computer Science, an Associate Professorship in Computer Science is open for appointment starting August 1, 2019 or soon thereafter. The position is enabled by a generous grant from the Poul Due Jensen Foundation and supports the focus areas “Internet of Things and Cyber-Physical Systems”.</span></div><div class="x_MsoNormal"><b><span style="font-family: Helvetica, sans-serif, serif, EmojiFont; font-size: 10.5pt; letter-spacing: 2.25pt;">APPLICATION DEADLINE</span></b><span style="background: white; color: #6a7783; font-family: Helvetica, sans-serif, serif, EmojiFont; font-size: 9pt;"><br/></span><span style="background: white; font-family: Helvetica, sans-serif, serif, EmojiFont; font-size: 9pt;">15/03/2019</span></div><div class="x_MsoNormal"><b><span style="font-family: Helvetica, sans-serif, serif, EmojiFont; font-size: 10.5pt; letter-spacing: 2.25pt;">JOB DESCRIPTION</span></b><span style="background: white; font-family: Helvetica, sans-serif, serif, EmojiFont; font-size: 9pt;">The objective of the position is to strengthen the department’s activities in the broad range from theory to applications in the area of distributed, embedded, and intelligent systems. Here, current research and teaching span topics such as semantic theories; algorithms and tools for verification and validation; model-driven development, analysis and optimization; and probabilistic models and algorithms for decision making and machine learning.</span></div><div class="x_MsoNormal"><span style="background: white; font-family: Helvetica, sans-serif, serif, EmojiFont; font-size: 9pt;">The position includes funding to recruit an assistant researcher within the research field of the successful applicant. The assistant researcher position is for four man-years and is also funded by the Poul Due Jensen Foundation.</span></div><div class="x_MsoNormal"><span style="background: white; font-family: Helvetica, sans-serif, serif, EmojiFont; font-size: 9pt;">We are seeking ambitious and talented applicants aiming at forming their own research group. Both the Foundation and the Technical Faculty will support the successful applicant with guidance on research and funding strategies etc. in the pursuit of a Full Professorship.</span></div><div><span style="font-family: Helvetica, sans-serif, serif, EmojiFont; font-size: 9pt;">The formal announcement including information about qualification requirements may be found at<a href="https://www.vacancies.aau.dk/show-vacancy/?vacancy=1020716" rel="noopener noreferrer" target="_blank">https://www.vacancies.aau.dk/show-vacancy/?vacancy=1020716</a></span></div><div class="x_MsoNormal"><span style="background: white; font-family: Helvetica, sans-serif, serif, EmojiFont; font-size: 9pt;">You may obtain further professional information from Professor Kim Guldstrand Larsen, phone +4522171159,          email:<span> </span><a href="mailto:kgl@cs.aau.dk" rel="noopener noreferrer" target="_blank"><span style="color: windowtext;">kgl@cs.aau.dk</span></a>.</span></div><div class="x_MsoNormal"><b><span style="font-family: Helvetica, sans-serif, serif, EmojiFont; font-size: 10.5pt; letter-spacing: 2.25pt;">CS AT AALBORG UNIVERSITY</span></b><span style="font-family: Helvetica, sans-serif, serif, EmojiFont; font-size: 10.5pt; letter-spacing: 2.25pt;"><br/></span><span style="background: white; font-family: Helvetica, sans-serif, serif, EmojiFont; font-size: 9pt;">The Department of Computer Science at Aalborg University is ranked #1 in Denmark according to the Leiden Ranking.</span></div><div><span style="background: white; font-family: Helvetica, sans-serif, serif, EmojiFont; font-size: 9pt;">The research at the department features a broad range of synergistic activities within research and education in the general area of computer science, including curiosity-driven research and targeted research in collaboration with industrial partners, as well as traditional university education, with a unique problem- and project-based focus, and continued education and knowledge dissemination. For more information see<a href="http://www.cs.aau.dk/" rel="noopener noreferrer" target="_blank"><span style="color: windowtext;">www.cs.aau.dk</span></a>.</span></div><div class="x_MsoNormal"><br/></div></div>
    </content>
    <updated>2019-02-28T17:12:00Z</updated>
    <published>2019-02-28T17:12:00Z</published>
    <author>
      <name>Luca Aceto</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/01092671728833265127</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-27705661</id>
      <author>
        <name>Luca Aceto</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/01092671728833265127</uri>
      </author>
      <link href="http://processalgebra.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://processalgebra.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Papers I find interesting---mostly, but not solely, in Process Algebra---, and some fun stuff in Mathematics and Computer Science at large and on general issues related to research, teaching and academic life.</subtitle>
      <title>Process Algebra Diary</title>
      <updated>2019-02-28T17:12:49Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=15662</id>
    <link href="https://rjlipton.wordpress.com/2019/02/28/phrases-that-drive-me-crazy/" rel="alternate" type="text/html"/>
    <title>Phrases That Drive Me Crazy</title>
    <summary>Some irksome phrases that appear on the web [ Jimmy Wales ] Jimmy Wales is the co-founder of Wikipedia. Of course this is the wonderful online non-profit encyclopedia we all know and love. Today I want to talk about using the web to search for math information. I do a huge amount of research on […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Some irksome phrases that appear on the web</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2019/02/28/phrases-that-drive-me-crazy/unknown-118/" rel="attachment wp-att-15667"><img alt="" class="alignright size-full wp-image-15667" src="https://rjlipton.files.wordpress.com/2019/02/unknown-1.jpeg?w=600"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">[ Jimmy Wales ]</font></td>
</tr>
</tbody>
</table>
<p>
Jimmy Wales is the co-founder of Wikipedia. Of course this is the wonderful online non-profit encyclopedia we all know and love.</p>
<p>
Today I want to talk about using the web to search for math information. </p>
<p>
I do a huge amount of research on the web. Years ago I would spend hours and hours each week in the library. I looked for books and articles on various math issues. No more. Today it’s all web-based resources. What has happened is that primary sources—research papers—have become as easily browsable as Wikipedia. Many of them, anyway.</p>
<p>
Wikipedia often does not include proofs of mathematical theorems—those are linked to primary papers or authoritative surveys or books. There is a website <a href="https://proofwiki.org/wiki/Main_Page">Proof Wiki</a> which tries to bridge the gap without the reader needing to follow links into papers. Right now they are <a href="https://proofwiki.org/wiki/Euclid's_Theorem">featuring</a> Euclid’s Theorem on the infinitude of primes—which we have posted about <a href="https://rjlipton.wordpress.com/2019/01/29/primes-and-polynomials/">recently</a> and <a href="https://rjlipton.wordpress.com/2018/07/11/you-cannot-do-that/">before</a>. They have style guides for how the reasoning is laid out.</p>
<p>
There are also many style guides around the web for writing good mathematics and computer science papers. But the guides seem to stop short of the level of the phrases that irk me. When those phrases show up in the primary sources, there’s no fallback. Let’s take a look.</p>
<p>
</p><p/><h2> The Phrases </h2><p/>
<p/><p>
Here are a few top ones. I omit the well known ones, the ones that are obvious, and some that are in preparation for a future post—just kidding. </p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <i>It is well known</i>. Not by me. The reason I am searching for papers on this subject is that I do not know the basics of the area. If you must say this phrase please add a possible reference. That would be extremely helpful.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <i>Clear from the proof of the theorem</i>. Not by me. This means that the author did not state the proof in the greatest generality possible. We all do this, but it may help if this is avoided.</p>
<p>
<img alt="{\bullet}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet}"/> <i>It is easy to see</i>. Similar to the last item. Ken vividly remembers a seminar in the early 1980s by Peter Neumann at Oxford that showed excerpts from a French mathematician in which the phrase “Il est aisé de voir” appeared often. The French phrase even reads just like the English one. But that mathematician had a reasonable excuse. He was Évariste Galois, and he had a duel early the next morning.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <i>Proof omitted</i>. Please no.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <i>Easy calculation</i>. Not by me. The reason it usually is avoided is that it is too difficult a computation. </p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <i>This case is the same as the previous case</i>. Not always. This has been the source of errors for me and others over the years. Good place to check the argument. Maybe a suggestion that there should be a Lemma that covers both cases.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <i>In our paper in preparation</i>. Please no. I cannot read a paper that does not exist yet.</p>
<p>
Finally the worst in my opinion.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <i>It costs $37.95</i>. Oh no. Many times we find papers that are behind a pay-wall. I always hate this. The authors of course wish to make they work available to all possible. But the reality is that often papers are protected. Thanks to our friends at Wikipedia and Arxiv that this is not the case for lots of stuff. </p>
<p>
<a href="https://rjlipton.wordpress.com/2019/02/28/phrases-that-drive-me-crazy/bill-2/" rel="attachment wp-att-15665"><img alt="" class="aligncenter size-full wp-image-15665" src="https://rjlipton.files.wordpress.com/2019/02/bill.png?w=600"/></a></p>
<p>
But I have wondered who ever pays the crazy amount of $37.95? Does anyone ever pay that? Is it equivalent to saying: This paper is not available.</p>
<p>
</p><p/><h2> Ken’s Examples </h2><p/>
<p/><p>
Ken has one example that has driven him crazy for years and again these past two weeks. Many of you have probably used it often.</p>
<p>
<img alt="{\bullet}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet}"/> <i>This procedure runs in polynomial time.</i> Excuse me, <em>what</em> polynomial time? At least tell us the best exponent you know…</p>
<p>
A related matter is attending to “edge cases” of theorems. Sometimes the edge cases are meant to be excluded. For example, “Let <img alt="{\alpha &gt; 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha+%3E+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha &gt; 0}"/>” excludes <img alt="{\alpha = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha = 0}"/>; maybe nothing more needs to be said. But in other cases it is not so clear. A theorem may suggest limits and it is nice to say what happens if one tries to take those limits. </p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
What are you favorite phrases that drive you crazy?</p></font></font></div>
    </content>
    <updated>2019-02-28T14:55:16Z</updated>
    <published>2019-02-28T14:55:16Z</published>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="Proofs"/>
    <category term="complaint"/>
    <category term="research rules"/>
    <category term="web search"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-03-02T07:20:50Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/02/28/linkage</id>
    <link href="https://11011110.github.io/blog/2019/02/28/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>This seems like a good time to throw in a word of appreciation for archive.org and their wayback machine for making it so easy to make permanent links to online resources that might otherwise go away, such as other people’s Google+ posts. Just search for the link on archive.org and, if it’s not archived already, it will give you a convenient link to immediately archive it. There’s one of those hiding in the links below, and more among the older links on my blog.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>This seems like a good time to throw in a word of appreciation for <a href="https://archive.org/">archive.org</a> and their wayback machine for making it so easy to make permanent links to online resources that might otherwise go away, such as other people’s Google+ posts. Just search for the link on archive.org and, if it’s not archived already, it will give you a convenient link to immediately archive it. There’s one of those hiding in the links below, and more among the older links on my blog.</p>

<ul>
  <li>
    <p>Elsevier news roundup (<a href="https://mathstodon.xyz/@11011110/101604919533994937"/>): <a href="https://www.nature.com/articles/d41586-019-00492-4">German, Hungarian, and Swedish academics have been cut off from Elsevier journals</a> after subscription negotiations broke down. <a href="https://www.insidehighered.com/quicktakes/2019/02/01/talks-continue-between-u-california-and-elsevier">Negotiations with the University of California are ongoing</a> after a missed deadline. <a href="https://www.nature.com/news/german-scientists-regain-access-to-elsevier-journals-1.21482">Access to Germany was restored</a> but without any long-term agreement. And <a href="https://www.nature.com/articles/d41586-019-00135-8">the editorial board of <em>Informetrics</em> resigned</a> to protest Elsevier’s open access policies.</p>
  </li>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/Rado_graph">The Rado graph</a> (<a href="https://mathstodon.xyz/@11011110/101608978698250480"/>). Choose a random graph with countably infinite vertices by flipping a coin to decide whether to include each edge. Or, construct a graph with binary numbers as vertices, with an edge — when  and the th bit of  is one. Or, construct a graph on primes congruent to 1 mod 4, with an edge when one is a quadratic residue mod the other. They’re all the same graph, and it has many other amazing properties.</p>
  </li>
  <li>
    <p><a href="https://www.cbc.ca/news/health/cihr-gender-bias-1.5009611">A comparison of two parallel Canadian grant funding tracks</a> (<a href="https://mathstodon.xyz/@11011110/101617210700627060"/>) shows that when reviewers are told to focus on the investigator rather than the proposed investigation, they are significantly more biased against women.</p>
  </li>
  <li>
    <p>Paul Erdős died in 1996, but <a href="http://www.math.ucsd.edu/~ronspubs/pre_tres_egyptian.pdf">his most recent paper</a> is from 2015, nearly 20 years later! (<a href="https://mathstodon.xyz/@11011110/101623126848928532"/>, <a href="https://www.simonsfoundation.org/2015/12/10/new-erdos-paper-solves-egyptian-fraction-problem/">see also</a>). It’s about Egyptian fractions – representations of rationals as sums of distinct unit fractions – and is motivated by the conjecture that it’s always possible for all denominators to be semiprime. That’s still open, but they prove that every integer has a representation with all denominators products of three primes.</p>
  </li>
  <li>
    <p><a href="https://www.quantamagazine.org/mobius-strips-defy-a-link-with-infinity-20190220/">You can’t pack uncountably many Möbius strips into 3d space</a> (<a href="https://mathstodon.xyz/@11011110/101625917417129970"/>). Known since the early 1960s for polyhedral embeddings, this has been recently generalized to arbitrarily messy topological embeddings, and to higher dimensions, in two papers <a href="https://doi.org/10.1142/S0218216518420051">by Olga Frolkina</a> and <a href="https://arxiv.org/abs/1810.04089">by Sergey Melikhov</a>.</p>
  </li>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/YBC_7289">YBC 7289</a> (<a href="https://mathstodon.xyz/@11011110/101638091102582421"/>). This Babylonian tablet from 1800 BC – 1600 BC shows the sides and diagonals of a square with a very accurate sexagesimal approximation to the square root of two, “the greatest known computational accuracy … in the ancient world”. Now a Good Article on Wikipedia.</p>
  </li>
  <li>
    <p><a href="https://abcnews.go.com/Technology/nasa-names-facility-hidden-figures-inspiration-katherine-johnson/story">NASA names a building after <em>Hidden Figures</em> subject Katherine Johnson</a> (<a href="https://mathstodon.xyz/@btcprox/101638679662393655"/>).</p>
  </li>
  <li>
    <p><a href="https://mathstodon.xyz/@christianp/101651770581756631">Christian Lawson-Perfect 3d-prints interconnecting Herschel enneahedra</a>. This is <a href="https://en.wikipedia.org/wiki/Herschel_graph">the simplest non-Hamiltonian polyhedron</a>. I <a href="https://11011110.github.io/blog/2016/11/30/linkage.html">wrote a couple years ago</a> about Lawson-Perfect’s quest for a nice polyhedral realization for these shapes; now they exist in tangible form.</p>
  </li>
  <li>
    <p><a href="https://mathlesstraveled.com/2019/02/20/goldilogs-and-the-n-bears/">Goldilogs and the  bears: a parable of algorithmic efficiency</a> (<a href="https://mathstodon.xyz/@11011110/101655938940308411"/>).</p>
  </li>
  <li>
    <p><a href="http://eatcs.org/index.php/presburger">Karl Bringmann and Kasper Green Larsen have won the 2019 Presberger Award</a> (<a href="https://mathstodon.xyz/@11011110/101665972353816294"/>), for outstanding contributions by young scientists in theoretical computer science, to be presented later this year at ICALP. The award laudatio appears not to be ready yet but <a href="https://web.archive.org/web/20190227203235/https://plus.google.com/+JukkaSuomela/posts/HfEVeR44Bww">committee chair Jukka Suomela writes that it is “for their groundbreaking work on lower bounds”</a>.</p>
  </li>
  <li>
    <p><a href="http://cgshop.ibr.cs.tu-bs.de/">The Computational Geometry Week Optimization Challenge</a> (<a href="https://mathstodon.xyz/@11011110/101667406212632110"/>, <a href="https://sites.google.com/stonybrook.edu/cgweek2019-workshop/">via</a>) is a contest to solve a hard problem in computational geometry, finding a simple polygon of minimum or maximum area with a given point set as its vertices. The 247 challenge instances are now online, with a deadline of May 31 for solving them.</p>
  </li>
  <li>
    <p><a href="https://www.worldscientific.com/worldscibooks/10.1142/11261"><em>Problems with a Point: Exploring Math and Computer Science</em></a> (<a href="https://mathstodon.xyz/@11011110/101672038034600757"/>, <a href="https://blog.computationalcomplexity.org/2019/02/problems-with-point-exploring-math-and.html">via</a>), a new book of mathematical essays from Bill Gasarch and Clyde Kruskal, based on expanded and cleaned-up versions of Bill’s blog posts at the Computational Complexity blog.</p>
  </li>
</ul></div>
    </content>
    <updated>2019-02-28T14:41:00Z</updated>
    <published>2019-02-28T14:41:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-02-28T23:21:25Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-4197054057663794908</id>
    <link href="https://blog.computationalcomplexity.org/feeds/4197054057663794908/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/02/flying-pigs-unsafe-at-any-speed.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/4197054057663794908" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/4197054057663794908" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/02/flying-pigs-unsafe-at-any-speed.html" rel="alternate" type="text/html"/>
    <title>Flying Pigs Unsafe at Any Speed</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Take a moment and imagine a flying pig. Do you see a pig with tiny wings lazily guiding along. But pigs are not particularly slow animals as anyone has seen a <a href="https://youtu.be/-eMV1jxfl40?t=73">pig race</a> at a county fair can attest to that. So why not in the air shouldn't a pig go faster than an unladen African swallow?<br/>
<br/>
I have a point discussing the fastness of a flying pig. Consider my favorite flying pig, P = NP. I would put more probability on an actual flying pig (thanks CRISPR) than polynomial-time algorithms for traveling salesman.<br/>
<br/>
Sometimes I get in the following conversation:<br/>
<br/>
<b>AI person</b>: The P v NP problem is irrelevant as we have machine learning and SAT solvers and we can for all practical purposes solve NP-complete problems.<br/>
<b>Me</b>: If P = NP we can solve AI!<br/>
<b>AI</b>: If P = NP it's likely to have a very slow poly-time algorithm with high exponents and constants and be for all practical purposes useless.<br/>
<br/>
Let's break that down. The claim is E(running time of SAT|running time of SAT is poly) = cn<sup>k</sup> for some large c and k. First of all you are conditioning on a probability zero event. Beyond that nearly all the known problems we know that sit in polynomial time have practical efficient solutions. So under the assumption that SAT is one of these problems, why shouldn't the same rule apply. You've already made the assumption we can reduce its running time from exponential to polynomial, so why would it stop at some high polynomial?<br/>
<br/>
If we are going to talk about the hypothetical flying pig P = NP world, let my algorithms run fast.</div>
    </content>
    <updated>2019-02-28T13:50:00Z</updated>
    <published>2019-02-28T13:50:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>https://plus.google.com/101693130490639305932</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>https://plus.google.com/101693130490639305932</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-03-02T06:40:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://tcsplus.wordpress.com/?p=341</id>
    <link href="https://tcsplus.wordpress.com/2019/02/27/tcs-talk-wednesday-march-6th-shayan-oveis-gharan-university-of-washington/" rel="alternate" type="text/html"/>
    <title>TCS+ talk: Wednesday, March 6th, Shayan Oveis Gharan, University of Washington</title>
    <summary>The next TCS+ talk will take place this coming Wednesday, March 6th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 18:00 UTC). Shayan Oveis Gharan from University of Washington will speak about “Strongly log concave polynomials, high dimensional simplicial complexes, and an FPRAS for counting Bases of Matroids” (abstract below). Please […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The next TCS+ talk will take place this coming Wednesday, March 6th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 18:00 UTC). <strong>Shayan Oveis Gharan</strong> from University of Washington will speak about “<em>Strongly log concave polynomials, high dimensional simplicial complexes, and an FPRAS for counting Bases of Matroids</em>” (abstract below).</p>
<p>Please make sure you reserve a spot for your group to join us live by signing up on <a href="https://sites.google.com/site/plustcs/livetalk/live-seat-reservation">the online form</a>. As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/site/plustcs/suggest">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/site/plustcs/">the website</a>.</p>
<blockquote><p>Abstract: A matroid is an abstract combinatorial object which generalizes the notions of spanning trees, and linearly independent sets of vectors. I will talk about an efficient algorithm based on the Markov Chain Monte Carlo technique to approximately count the number of bases of any given matroid.</p>
<p>The proof is based on a new connections between high dimensional simplicial complexes, and a new class of multivariate polynomials called completely log-concave polynomials. In particular, we exploit a fundamental fact from our previous work that the bases generating polynomial of any given matroid is a log-concave function over the positive orthant.</p>
<p>Based on joint works with Nima Anari, Kuikui Liu, and Cynthia Vinzant.</p></blockquote>
<p> </p></div>
    </content>
    <updated>2019-02-28T04:15:45Z</updated>
    <published>2019-02-28T04:15:45Z</published>
    <category term="Announcements"/>
    <author>
      <name>plustcs</name>
    </author>
    <source>
      <id>https://tcsplus.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://tcsplus.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://tcsplus.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://tcsplus.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://tcsplus.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A carbon-free dissemination of ideas across the globe.</subtitle>
      <title>TCS+</title>
      <updated>2019-03-02T07:21:41Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/025</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/025" rel="alternate" type="text/html"/>
    <title>TR19-025 |  On Nonadaptive Reductions to the Set of Random Strings and Its Dense Subsets | 

	Shuichi Hirahara, 

	Osamu Watanabe</title>
    <summary>We investigate the computational power of an arbitrary distinguisher for (not necessarily computable) hitting set generators as well as the set of Kolmogorov-random strings. This work contributes to (at least) two lines of research. One line of research is the study of the limits of black-box reductions to some distributional NP problem. We show that a black-box nonadaptive randomized reduction to any distinguisher for (not only polynomial-time but even) exponential-time computable hitting set generators can be simulated in AM $\cap$ coAM; we also show an upper bound of $\mathrm{S_2^{NP}}$ even if there is no computational bound on a hitting set generator. These results further strengthen the evidence that the recent worst-case to average-case reductions within NP shown by Hirahara (2018, FOCS) are inherently non-black-box. As an application, we show that GapMCSP $\in$ P/poly implies that GapMCSP is low for $\mathrm{S_2^p}$, which is proved by combining our proof techniques with the non-black-box reductions.

Another line of research concerns the computational power of nonadaptive deterministic polynomial-time reductions to the set of Kolmogorov-random strings. It was conjectured by Allender (CiE, 2012) and others that the computational power is exactly characterized by BPP, intuitively because nonadaptive deterministic reductions could only make use of Kolmogorov-random strings as a source of pseudorandomness.

We present strong evidence *against* this conjecture by showing that every language in the exponential-time hierarchy is reducible to the set of Kolmogorov-random strings under PH reductions; in particular, the conjecture is false unless the exponential-time hierarchy collapses to BPEXP. Moreover, our reduction cannot be regarded as a black-box reduction to avoiding hitting set generators (unless the exponential-time hierarchy collapses to the second level), thereby showing that nonadaptive deterministic efficient reductions can exploit the power of Kolmogorov-random strings not just as a distinguisher for hitting set generators.</summary>
    <updated>2019-02-28T03:10:24Z</updated>
    <published>2019-02-28T03:10:24Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-03-02T07:20:40Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/024</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/024" rel="alternate" type="text/html"/>
    <title>TR19-024 |  The Surprising Power of Constant Depth Algebraic Proofs | 

	Sasank Mouli, 

	Russell Impagliazzo, 

	Toniann Pitassi</title>
    <summary>A major open problem in proof complexity is to prove super-polynomial lower bounds for AC^0[p]-Frege proofs. This system is the analog of AC^0[p], the class of bounded depth circuits with prime modular counting gates. Despite strong lower bounds for this class dating back thirty years (Razborov, '86 and Smolensky, '87), there are no significant lower bounds for AC^0[p]-Frege. Significant and extensive *degree* lower bounds have been obtained for a variety of subsystems of AC^0[p]-Frege, including Nullstellensatz (Beame et. al. '94), Polynomial Calculus (Clegg et. al. '96), and SOS (Griegoriev and Vorobjov, '01). However to date there has been no progress on AC^0[p]-Frege lower bounds.
In this paper we study constant-depth extensions of the Polynomial Calculus introduced by Griegoriev and Hirsch, '03. We show that these extensions are much more powerful than was previously known. Our main result is that small depth Polynomial Calculus (over a sufficiently large field) can polynomially simulate all of the well-studied semialgebraic proof systems: Cutting Planes, Sherali-Adams and Sum-of-Squares, and they can also quasi-polynomially simulate AC^0[p]-Frege as well as TC^0-Frege. Thus, proving strong lower bounds for AC^0[p]-Frege would seem to require proving lower bounds for systems as strong as TC^0-Frege.</summary>
    <updated>2019-02-27T21:48:32Z</updated>
    <published>2019-02-27T21:48:32Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-03-02T07:20:40Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4129</id>
    <link href="https://www.scottaaronson.com/blog/?p=4129" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4129#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4129" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">De-sneering my life</title>
    <summary xml:lang="en-US">If I’m being honest, the most exciting recent development in my life is this: a little over a month ago, I stopped checking “SneerClub” (a place I’d previously resolved not even to name here, but I think an exception is warranted now). Permanently, cold turkey. I won’t even visit to read their sneers about this […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>If I’m being honest, the most exciting recent development in my life is this: a little over a month ago,<strong> I stopped checking “SneerClub”</strong> (a place I’d previously resolved not even to name here, but I think an exception is warranted now).  Permanently, cold turkey.  I won’t even visit to read their sneers about this post.  I’ve made progress cutting down on other self-destructive social media fixations as well.  Many friends suggested this course to me, and I thank them all, though I ultimately had to follow my own path to the obvious.</p>



<p>Ironically, <em>the SneerClubbers themselves</em> begged me to stop reading them (!), so presumably for once they’ll be okay with something I did (but if not, I don’t care).  If any of them still have something to say to me, they can come to <em>this</em> blog, or email me, or if they pass through Austin, set up a time to hash it out over chips and queso (my treat).  What I’ll no longer do is spend hours every week binge-reading a forum of people who’ve adopted nastiness and bad faith as their explicit principles.  I’ll no longer toss and turn at night wondering how it came about that two thousand Redditors hate Scott Aaronson so much, and what I could say or do (short of total self-abnegation) that would make them hate me less.  I plan to spend the freed-up time <em>being</em> Scott Aaronson.</p>



<p>Resolving to ignore one particular online hate pit—and then <em>sticking</em> to the resolution, as so far I have—has been a pure, unmitigated improvement to my quality of life.  If you don’t believe me, ask my wife and kids.  I recommend this course to anyone.</p>



<p>You could sensibly ask: why did I <em>ever</em> spend time worrying about an anti-nerds-like-me forum that’s so poisonous for its targets and participants alike?  After long introspection, I think the answer is: there’s a part of me, perhaps a gift from the childhood bullies, that’s so obsessed with “society’s hatred of STEM nerds,” that it <em>constantly seeks out evidence to confirm that its fears are justified—</em>evidence that it can then wave in front of the rest of my brain to say “you see??  what did I always tell you?”  And alas, whenever that part of my brain seeks such evidence, the world dutifully supplies mountains of it.  It’s never once disappointed.</p>



<p>Now the SneerClubbers—who are perceptive and talented in their cruelty, if in nothing else—notice this about me, and gleefully ridicule me for it.  But they’re oblivious to the central irony: that unlike the vast majority of humankind, or even the vast majority of social justice activists, they (the SneerClubbers) <em>really do</em> hate everyone like me.  They’re <em>precisely</em> what the paranoid part of my brain wrongly fears that everyone else I meet is secretly like.  They’re like someone who lectures you about your hilariously overblown fear of muggers, <em>while simultaneously mugging you</em>.</p>



<p>But at least they’re not the contented and self-confident bullies of my childhood nightmares, kicking dirt down at nerds from atop their pinnacle of wokeness and social adeptness.  If you spend enough time studying them, they themselves come across as angry, depressed, pathetic.  So for example: <a href="https://www.reddit.com/r/math/comments/aexi9v/michael_atiyah_has_passed_away/edtrcc5/">here’s</a> one of my most persistent attackers, popping up on a math thread commemorating Michael Atiyah (one of the great mathematicians of the 20th century), just to insult Atiyah—randomly, gratuitously, and a few days after Atiyah had died.  Almost everything posted all over Reddit by this individual—who uses the accurate tagline “unpleasantly radical”—has the same flavor.  Somehow seeing this made it click for me: wait a second, <em>these</em> are the folks are lecturing <em>me</em> about my self-centeredness and arrogance and terrible social skills?  Like, at least I <em><a href="https://www.quora.com/Why-is-Scott-Aaronson-so-nice">try</a></em> to be nice.</p>


<hr/>
<p>Scott Alexander, who writes the <a href="https://slatestarcodex.com/">world’s best blog</a> and is a more central target of SneerClub than I’ve been, <a href="https://slatestarcodex.com/2019/02/22/rip-culture-war-thread/">recently announced</a> that he asked the moderators of <a href="https://www.reddit.com/r/slatestarcodex/">r/ssc</a> to close its notorious “Culture War” thread, and they’ve done so—moving the thread to a new home on Reddit called <a href="https://www.reddit.com/r/TheMotte/">“TheMotte.”</a></p>
<p>For those who don’t know: r/ssc is the place on Reddit to discuss Scott’s SlateStarCodex blog, though Scott himself was never too involved as more than a figurehead.  The Culture War thread was the place within r/ssc to discuss race, gender, immigration, and other hot-button topics.  The thread, which filled up with a bewildering thousands of comments per week (!), attracted the, err … <em>full range</em> of political views, including leftists, libertarians, and moderates but also alt-righters, neoreactionaries, and white nationalists. Predictably, SneerClub treated the thread as a gift from heaven: a constant source of inflammatory material that they could use to smear Scott personally (even if most of the time, Scott hadn’t even <em>seen</em> the offending content, let alone endorsing it).</p>


<p>Four months ago, I was one of the apparently many friends who told Scott that I felt he should dissociate the Culture War thread from his brand.  So I congratulate him on his decision, which (despite his eloquently-expressed misgivings) I feel confident was the right one.  Think about it this way: nobody’s freedom of speech has been curtailed—the thread continues full steam at TheMotte, for anyone who enjoys it—but meanwhile, the sneerers have been deprived of a golden weapon with which to slime Scott.  Meanwhile, while the sneerers themselves might never change their minds about anything, Scott has demonstrated to third parties that he’s open and reasonable and ready to compromise, like the debater who happily switches to his opponent’s terminology.  What’s not to like?</p>


<hr/>
<p>A couple weeks ago, while in Albuquerque for the <a href="http://physics.unm.edu/SQuInT/2019/index.php">SQuInT</a> conference, I visited the excellent <a href="https://www.nuclearmuseum.org/">National Museum of Nuclear Science and History</a>.  It was depressing, as it should have been, to tour the detailed exhibits about the murderous events surrounding the birth of the nuclear era: the Holocaust, the Rape of Nanking, the bombings of Hiroshima and Nagasaki. It was depressing in a different way to tour the exhibits about the early Atomic Age, and see the boundless optimism that ‘unleashing the power of the atom’ would finally usher in a near-utopia of space travel and clean energy—and then to compare that vision to where we are now, with climate change ravaging the planet and (in a world-historic irony) the people who care most about the environment having denounced and marginalized the most reliable source of carbon-free energy, the one that probably had the best chance to avert our planet’s terrifying future.</p>


<p>But on the bright side: how wonderful to have born into a time and place when, for the most part, those who hate you have only the power to destroy your life that you yourself grant them.  How wonderful when one can blunt their knives by simply refusing to open a browser tab.</p></div>
    </content>
    <updated>2019-02-27T21:26:37Z</updated>
    <published>2019-02-27T21:26:37Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Adventures in Meatspace"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Nerd Interest"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Procrastination"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Self-Referential"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2019-02-27T22:48:01Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2019/02/27/caleidoscope-complexity-as-a-kaleidoscope/</id>
    <link href="https://cstheory-events.org/2019/02/27/caleidoscope-complexity-as-a-kaleidoscope/" rel="alternate" type="text/html"/>
    <title>Caleidoscope : Complexity as a Kaleidoscope</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">June 17-21, 2019 Paris, France https://caleidoscope.sciencesconf.org/ Research school in computational complexity. 17-21 June 2019, Institut Henri Poincaré, Paris. LECTURES The Caleidoscope school will be comprise of four main lecture courses, based on some of the most developed approaches to computational complexity today. 1. Boolean circuits and lower bounds. (Rahul Santhanam, University of Oxford). 2. Algebraic … <a class="more-link" href="https://cstheory-events.org/2019/02/27/caleidoscope-complexity-as-a-kaleidoscope/">Continue reading <span class="screen-reader-text">Caleidoscope : Complexity as a Kaleidoscope</span></a></div>
    </summary>
    <updated>2019-02-27T20:20:18Z</updated>
    <published>2019-02-27T20:20:18Z</published>
    <category term="school"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2019-03-02T07:21:44Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-27705661.post-248160526006611455</id>
    <link href="http://processalgebra.blogspot.com/feeds/248160526006611455/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=27705661&amp;postID=248160526006611455" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/248160526006611455" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/248160526006611455" rel="self" type="application/atom+xml"/>
    <link href="http://processalgebra.blogspot.com/2019/02/call-for-prize-nominations-prize-for.html" rel="alternate" type="text/html"/>
    <title>Call for Prize Nominations: Prize for Innovation in Distributed Computing 2020</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><i>Michele Flammini asked me to distrbute this call for nominations. Sharpen your pencils and nominate one of the many worthy candidates from the SIROCCO community!</i><br/><br/><span>Call for Prize Nominations:</span><br/><span>Prize for Innovation in Distributed Computing 2020</span><br/><span>------------------------------</span><span>----</span><br/><br/><span>Awarded by the Colloquium on Structural Information and Communication Complexity (SIROCCO).</span><br/><br/><span>Deadline for nominations: April 30, 2019.</span><br/><br/><span>Nominations are requested for the Prize for Innovation In Distributed Computing. This prize was established to recognize individuals whose research contributions expanded the collective investigative horizon in SIROCCO's area of interest. That is, they formulated new problems, or identified new research areas, that were at the time of their introduction, unorthodox and outside the mainstream, but later attracted the interest of the SIROCCO community.</span><br/><br/><span>This community is interested in the relationships between information and efficiency in decentralized computing. The prize recognizes originality, innovation, and creativity -- the qualities that reflect the spirit of the SIROCCO conference.</span><br/><br/><span>The winner of the Prize for Innovation in Distributed Computing 2020 is expected to give an invited talk at SIROCCO 2020. The winner of the 2019 edition of the prize (Paola Flocchini) will give a talk at SIROCCO 2019 which is going to be held on July 1-4, in L’Aquila, Italy.</span><br/><br/><span>Past prize winners are Nicola Santoro, Jean-Claude Bermond, David Peleg, Roger Wattenhofer, Andrzej Pelc, Pierre Fraigniaud, Michel Raynal, Masafumi Yamashita, Shmuel Zaks,  Zvi Lotker and Paola Flocchini.</span><br/><br/><span>The prize may not necessarily be awarded every year.</span><br/><br/><br/><span>Eligibility</span><br/><span>-----------</span><br/><br/><span>The following conditions must be met by the nominees to be eligible for the prize. It is requested that a nomination letter explains and demonstrates how the nominee matches these conditions.</span><br/><br/><span>(1) The original innovative contribution was introduced by the nominee(s) for the first time in a publication at least five years before the nomination deadline, and the publication must have appeared in a conference proceedings or a scientific journal.</span><br/><br/><span>(2) At least one paper (co)authored by the nominee(s), either the original</span><br/><span>paper, or a paper closely related to the innovative contribution, must have</span><br/><span>appeared in a SIROCCO proceedings.</span><br/><br/><span>A nomination letter should identify the paper(s) that make(s) the nominee eligible according to conditions (1) and (2) above, as well as explain the contribution, its originality, and its significance.</span><br/><br/><span>Past SIROCCO papers and authors can be found at indexing sites, e.g. Google Scholar or </span><a href="http://www.informatik.uni-trier.de/~ley/db/conf/sirocco/index.html" target="_blank">http://www.informatik.uni-trier.de/~ley/db/conf/sirocco/index.html</a><span>.</span><br/><br/><span>Selection process</span><br/><span>------------------</span><br/><br/><span>The prize winners are selected by the Award Committee composed of the current Steering Committee (SC) Chair of the SIROCCO conference, the PC chairs, including co-chairs, of the three SIROCCO conferences immediately preceding the nominations deadline, plus one additional member of the Advisory Board, or one past winner, selected by the Steering Committee for the current year.</span><br/><br/><span>The Award Committee of the Prize for Innovation in Distributed Computing 2020 consists of: Shantanu Das (Aix-Marseille Université),</span><br/><span>Zvi Lotker (Ben Gurion University of the Negev), Boaz Patt-Shamir (Tel Aviv University), Andrzej Pelc - chair (Université du Québec en Outaouais), Michel Raynal (IRISA), Jukka Suomela (Aalto University) and Sébastien Tixeuil (Sorbonne Université).</span><br/><br/><span>Nominations can be made by any member of the scientific community.</span><br/><br/><span>DEADLINE : The deadline for nominations is April 30, 2019.</span><br/><span>Please send the nomination to the prize committee chair, Andrzej Pelc, by e-mail </span><a href="mailto:pelc@uqo.ca" target="_blank">pelc@uqo.ca</a></div>
    </content>
    <updated>2019-02-27T09:43:00Z</updated>
    <published>2019-02-27T09:43:00Z</published>
    <author>
      <name>Luca Aceto</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/01092671728833265127</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-27705661</id>
      <author>
        <name>Luca Aceto</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/01092671728833265127</uri>
      </author>
      <link href="http://processalgebra.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://processalgebra.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Papers I find interesting---mostly, but not solely, in Process Algebra---, and some fun stuff in Mathematics and Computer Science at large and on general issues related to research, teaching and academic life.</subtitle>
      <title>Process Algebra Diary</title>
      <updated>2019-02-28T17:12:49Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-25562705.post-2251645165874378750</id>
    <link href="http://aaronsadventures.blogspot.com/feeds/2251645165874378750/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=25562705&amp;postID=2251645165874378750" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/25562705/posts/default/2251645165874378750" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/25562705/posts/default/2251645165874378750" rel="self" type="application/atom+xml"/>
    <link href="http://aaronsadventures.blogspot.com/2019/02/impossibility-results-in-fairness-as.html" rel="alternate" type="text/html"/>
    <title>Impossibility Results in Fairness as Bayesian Inference</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">One of the most striking results about fairness in machine learning is the impossibility result that <a href="https://www.liebertpub.com/doi/full/10.1089/big.2016.0047">Alexandra Chouldechova</a>, and separately<a href="https://arxiv.org/abs/1609.05807"> Jon Kleinberg, Sendhil Mullainathan, and Manish Raghavan</a> discovered a few years ago. These papers say something very crisp. I'll focus here on the binary classification setting that Alex studies because it is much simpler. There are (at least) three reasonable properties you would want your "fair" classifiers to have. They are:<br/><div><ol><li><b>False Positive Rate Balance</b>: The rate at which your classifier makes errors in the positive direction (i.e. labels negative examples positive) should be the same across groups.</li><li><b>False Negative Rate Balance</b>:  The rate at which your classifier makes errors in the negative direction (i.e. labels positive examples negative) should be the same across groups.</li><li><b>Predictive Parity</b>: The statistical "meaning" of a positive classification should be the same across groups (we'll be more specific about what this means in a moment)</li></ol><div>What Chouldechova and KMR show is that if you want all three, you are out of luck --- unless you are in one of two very unlikely situations: Either you have a <i>perfect</i> classifier that never errs, or the <i>base rate</i> is exactly the same for both populations --- i.e. both populations have exactly the same frequency of positive examples. If you don't find yourself in one of these two unusual situations, then you have to give up on properties 1, 2, or 3. </div></div><div><br/></div><div>This is discouraging, because there are good reasons to want each of properties 1, 2, and 3. And these aren't measures made up in order to formulate an impossibility result --- they have their root in the <a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing">Propublica/COMPASS controversy</a>. Roughly speaking, Propublica discovered that the COMPASS recidivism prediction algorithm violated false positive and negative rate balance, and they took the position that this made the classifier <i>unfair</i>. Northpointe (the creators of the COMPASS algorithm) responded by saying that their algorithm satisfied predictive parity, and took the position that this made the classifier fair. They were seemingly talking past each other by using two different definitions of what "fair" should mean. What the impossibility result says is that there is no way to satisfy both sides of this debate. </div><div><br/></div><div>So why is this result true? The proof in Alex's paper can't be made simpler --- its already a one liner, following from an algebraic identity. But the first time I read it I didn't have a great intuition for <i>why</i> it held. Viewing the statement through the lens of Bayesian inference made the result very intuitive (at least for me). With this viewpoint, all the impossibility result is saying is: "If you have different <i>priors</i> about some event (say that a released inmate will go on to commit a crime) for two different populations, and you receive evidence of the same strength for both populations, then you will have different posteriors as well". This is now bordering on obvious --- because your posterior belief about an event is a combination of your prior belief and the new evidence you have received, weighted by the strength of that evidence.  </div><div><br/></div><div>Lets walk through this. Suppose we have two populations, call them $A$s and $B$s. Individuals $x$ from these populations have some true binary label $\ell(x) \in \{0,1\}$ which we are trying to predict. Individuals from the two populations are drawn from different distributions, which we'll call $D_A$ and $D_B$. We have some classifier that predicts labels $\hat\ell(x)$, and we would like it to satisfy the three fairness criteria defined above. First, lets define some terms:<br/><br/>The <i>base rate</i> for a population $i$ is just the frequency of positive labels:<br/>$$p_i = \Pr_{x \sim D_i}[\ell(x) = 1].$$<br/>The <i>false positive </i>and <i>false negative </i>rates of the classifier are:<br/>$$FPR_i = \Pr_{x \sim D_i}[\hat\ell(x) = 1 | \ell(x) = 0] \ \ \ \ FNR_i = \Pr_{x \sim D_i}[\hat\ell(x) = 0 | \ell(x) = 1].$$<br/>And the <i>positive predictive value</i> of the classifier is:<br/>$$PPV_i = \Pr_{x \sim D_i}[\ell(x) = 1 | \hat\ell(x)=1].$$</div><div>Satisfying all three fairness constraints just means finding a classifier such that $FPR_A = FPR_B$, $FNR_A = FNR_B$, and $PPV_A = PPV_B$.<br/><br/>How should we prove that this is impossible? All three of these quantities are conditional probabilities, so we are essentially obligated to apply Bayes Rule:<br/>$$PPV_i =  \Pr_{x \sim D_i}[\ell(x) = 1 | \hat\ell(x)=1] = \frac{ \Pr_{x \sim D_i}[\hat\ell(x)=1 | \ell(x) = 1]\cdot \Pr_{x \sim D_i} [\ell(x) = 1]}{ \Pr_{x \sim D_i}[\hat \ell(x) = 1]}$$<br/>But now these quantities on the right hand side are things we have names for. Substituting in, we get:<br/>$$PPV_i  = \frac{p_i(1-FNR_i)}{p_i(1-FNR_i) + (1-p_i)FPR_i}$$<br/><br/>And so now we see the problem. Suppose we have $FNR_A = FNR_B$ and $FPR_A = FPR_B$. Can we have $PPV_A = PPV_B$? There are only two ways. If $p_A = p_B$, then we are done, because the right hand side is the same for either $i \in \{A,B\}$. But if the base rates are different, then the only way to make these two quantities equal is if $FNR_i = FPR_i = 0$ --- i.e. if our classifier is perfect.<br/><br/>The piece of intuition here is that the base rate is our prior belief that $\ell(x) = 1$, before we see the output of the classifier. The positive predictive value is our <i>posterior</i> belief that $\ell(x) = 1$, after we see the output of the classifier. And all we need to know about the classifier in order to apply Bayes rule to derive our posterior from our prior is its false positive rate and its false negative rate --- these fully characterize the "strength of the evidence." Hence: "If our prior probabilities differ, and we see evidence of a positive label of the same strength, then our posterior probabilities will differ as well."<br/><br/>Once you realize this, then you can generalize the fairness impossibility result to other settings by making equally obvious statements about probability elsewhere. :-)<br/><br/>For example, suppose we generalize the labels to be real valued instead of binary --- so when making decisions, we can model individuals using shades of gray. (e.g. in college admissions, we don't have to model individuals as "qualified" or not, but rather can model talent as a real value.) Lets fix a model for concreteness, but the particulars are not important. (The model here is related to my paper with <a href="https://www.cis.upenn.edu/~kannan/">Sampath Kannan</a> and<a href="http://www.its.caltech.edu/~jziani/"> Juba Ziani </a>on <a href="https://arxiv.org/abs/1808.09004">the downstream effects of affirmative action</a>)<br/><br/>Suppose that in population $i$, labels are distributed according to a Gaussian distribution with mean $\mu_i$: $\ell(x) \sim N(\mu_i, 1)$. For an individual from group $i$, we have a test that gives an unbiased estimator of their label, with some standard deviation $\sigma_i$: $\hat \ell(x) \sim N(\ell(x), \sigma_i)$.<br/><br/>In a model like this, we have analogues of our fairness desiderata in the binary case:<br/><br/><ul><li><b>Analogue of Error Rate Balance</b><i style="font-weight: bold;">: </i>We would like our test to be equally informative about both populations: $\sigma_A = \sigma_B$. </li><li><b>Analogue of Predictive Parity</b>: Any test score $t$ should induce the same posterior expectation on true labels across populations: $$E_{D_A}[\ell(x) | \hat \ell(x) = t] = E_{D_B}[\ell(x) | \hat \ell(x) = t]$$ </li></ul><div>Can we satisfy both of these conditions at the same time? Because the normal distribution is <i>self conjugate</i> (that's why we chose it!) Bayes Rule simplifies to have a nice closed form, and we can compute our posteriors as follows:</div><div>$$E_{D_i}[\ell(x) | \hat \ell(x) = t] = \frac{\sigma_i^2}{\sigma_i^2 + 1}\cdot \mu_i + \frac{1}{\sigma_i^2 + 1}\cdot t$$</div><div>So there are only two ways we can achieve both properties:</div><div><ol><li>We can of course satisfy both conditions if the prior distributions are the same for both groups: $\mu_A = \mu_B$. Then we can set $\sigma_A = \sigma_B$ and observe that the right hand side of the above expression is identical for $i \in \{A, B\}$.</li><li>We can also satisfy both conditions if the prior means are different, but the signal is perfect: i.e. $\sigma_A = \sigma_B = 0$. (Then both posterior means are just $t$, independent of the prior means). </li></ol></div>But we can see from inspection these are the only two cases. If $\sigma_A = \sigma_B$, but the prior means are different, then the posterior means will be different for every $t$. This is really the same impossibility result as in the binary case: all it is saying is that if I have different priors about different groups, but the evidence I receive has the same strength, then my posteriors will also be different.<br/><br/>So the mathematical fact is simple --- but its implications remain deep. It means we have to choose between equalizing a decision maker's posterior about the label of an individual, or providing an equally accurate signal about each individual, and that we cannot have both. Unfortunately, living without either one of these conditions can lead to real harm.<br/><br/></div><div><br/></div></div>
    </content>
    <updated>2019-02-26T20:41:00Z</updated>
    <published>2019-02-26T20:41:00Z</published>
    <author>
      <name>Aaron Roth</name>
      <email>noreply@blogger.com</email>
      <uri>https://plus.google.com/111805394598997130229</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-25562705</id>
      <category term="game theory"/>
      <category term="news"/>
      <author>
        <name>Aaron Roth</name>
        <email>noreply@blogger.com</email>
      </author>
      <link href="http://aaronsadventures.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/25562705/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://aaronsadventures.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/25562705/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <title>Adventures in Computation</title>
      <updated>2019-02-27T06:33:17Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-4283341625722054774</id>
    <link href="https://blog.computationalcomplexity.org/feeds/4283341625722054774/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/02/problems-with-point-exploring-math-and.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/4283341625722054774" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/4283341625722054774" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/02/problems-with-point-exploring-math-and.html" rel="alternate" type="text/html"/>
    <title>Problems with a Point: Exploring Math and Computer Science</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><br/>
As you can see from Lance's tweet<br/>
<br/>
<br/>
               Problems with a Point: Exploring Math and Computer Science<br/>
               by Gasarch and Kruskal<br/>
<br/>
(ADDED LATER- the World scientific website has more info than amazon and has a table of contents, so here it is: <a href="https://www.worldscientific.com/worldscibooks/10.1142/11261#t=toc">here</a>)<br/>
<br/>
is now available! The tweet says its $68.00 but that's hardcover- paperback is $38.00 (are covers that expensive) and if you like your books already broken in, there are some used copies for $89.00. Makes sense to me (no it doesn't!). Could be the topic of a blog post (probably already was).<br/>
<br/>
Okay, so whats in the book?  One of my favorite types of blog posts is when I make a point ABOUT math and then do some math to underscore that point.  I went through all of my blogs (all? No, I doubt I did that) and picked out blogs of that type. With Clyde's help we EXPANDED and POLISHED and GOT THE MATH RIGHT (in some cases I didn't have any math so we had to supply it).<br/>
<br/>
When I first got a copy (about a month ago) I just couldn't stop reading it. I really like it! This is a non-trivial remark -- often authors get tired of their book, or after a while and wonder things like ``why did I write 300 page on the muffin problem? What was I thinking?'' So the fact that I am very pleased with it is not obvious. Does it mean you will?<br/>
<br/>
If you ever thought `I wish bill would clean up his posts spelling and grammar AND expand on the math AND make it a more cohesive whole' then buy the book!<br/>
<br/>
I will in future posts describe more about writing the book, but this is probably my last post where I plug the book.<br/>
<br/>
bill g.</div>
    </content>
    <updated>2019-02-26T17:20:00Z</updated>
    <published>2019-02-26T17:20:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>https://plus.google.com/101693130490639305932</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-03-02T06:40:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/023</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/023" rel="alternate" type="text/html"/>
    <title>TR19-023 |  Smooth and Strong PCPs | 

	Orr Paradise</title>
    <summary>Probabilistically checkable proofs (PCPs) can be verified based only on a constant amount of random queries, such that any correct claim has a proof that is always accepted, and incorrect claims are rejected with high probability (regardless of the given alleged proof). We consider two possible features of PCPs:
- A PCP is *strong* if it rejects an alleged proof of a correct claim with probability proportional to its distance from some correct proof of that claim.
- A PCP is *smooth* if each location in a proof is queried with equal probability.

We prove that all sets in $\mathcal{NP}$ have a smooth and strong PCP of polynomial length that can be verified based on a constant number of queries. We do so by following the proof of the PCP theorem of Arora, Lund, Motwani, Sudan and Szegedy (JACM, 1998), providing a stronger analysis of the Hadamard and Reed--Muller based PCPs and a refined PCP composition theorem. In fact, we show that any set in $\mathcal{NP}$ has a smooth strong *canonical* PCP of Proximity (PCPP), meaning that there is an efficiently computable bijection of $\mathcal{NP}$ witnesses to correct proofs.
	
This improves on the recent result of Dinur, Gur and Goldreich (ITCS, 2019) that constructs strong canonical PCPPs that are inherently non-smooth. Our result implies the hardness of approximating the satisfiability of "stable" 3CNF formulae with bounded variable occurrence, proving a hypothesis used in the work of Friggstad, Khodamoradi and Salavatipour (SODA, 2019). Here *stability* means that the number of clauses violated by an assignment is proportional to its distance from a satisfying assignment (in the relative Hamming metric).</summary>
    <updated>2019-02-25T22:38:50Z</updated>
    <published>2019-02-25T22:38:50Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-03-02T07:20:40Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=16934</id>
    <link href="https://gilkalai.wordpress.com/2019/02/23/karim-adiprasito-the-g-conjecture-for-vertex-decomposible-spheres/" rel="alternate" type="text/html"/>
    <title>Karim Adiprasito: The g-Conjecture for Vertex Decomposible Spheres</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">J Scott Provan (site) The following post was kindly contributed by Karim Adiprasito. (Here is the link to Karim’s paper.) Update: See Karim’s comment on the needed ideas for extend the proof to the general case. See also  in the … <a href="https://gilkalai.wordpress.com/2019/02/23/karim-adiprasito-the-g-conjecture-for-vertex-decomposible-spheres/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="https://gilkalai.files.wordpress.com/2019/02/scott_provan.jpg"><img alt="" class="alignnone size-full wp-image-16958" src="https://gilkalai.files.wordpress.com/2019/02/scott_provan.jpg?w=640"/></a></p>
<p><strong><span style="color: #ff0000;">J Scott Provan </span></strong><span style="color: #ff0000;"><a href="https://stat-or.unc.edu/people/emeritus/j-scott-provan">(site)</a></span></p>
<p><em>The following post was kindly contributed by Karim Adiprasito. (Here is<a href="https://arxiv.org/abs/1812.10454"> the link to Karim’s paper</a>.) Update: See <a href="https://gilkalai.wordpress.com/2019/02/23/karim-adiprasito-the-g-conjecture-for-vertex-decomposible-spheres/#comment-50716">Karim’s comment</a> on the needed ideas for extend the proof to the general case. See also  in the comment section references to papers by <a href="https://www.math.ubc.ca/~karu/papers/simple.pdf">Balin and Fleming</a> and by <a href="https://arxiv.org/abs/1309.7064">Jensen and Yu</a>.</em></p>
<p>So, Gil asked me to say a little bit about my <a href="https://gilkalai.wordpress.com/2018/12/25/amazing-karim-adiprasito-proved-the-g-conjecture-for-spheres/">proof of the <em>g</em>-conjecture</a> (and some other conjectures in discrete geometry) on his blog, and since he bought me <a href="https://gilkalai.files.wordpress.com/2018/05/cubring.png">many</a>  <a href="https://gilkalai.wordpress.com/2018/06/20/beyond-the-g-conjecture-algebraic-combinatorics-of-cellular-spaces-i/">coffees </a>to explain it to him (or if he is to be believed, the department paid), I am happy to oblige.</p>
<p>So, I want to explain a special, but critical case to the proof. It contains the some shadow of the core ideas necessary, but needs some more tricks I will remark on afterwards.</p>
<p>Also, I wanted to take this opportunity to mention something marvelous that I learned from <a href="https://www.ccny.cuny.edu/profiles/leonid-gurvits">Leonid Gurvits</a> recently that increased my own understanding of one of the key tricks used indefinitely. That trick is the following cool lemma.</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/02/image.png"><img alt="" class="alignnone size-full wp-image-16959" src="https://gilkalai.files.wordpress.com/2019/02/image.png?w=640"/></a></p>
<p><span style="color: #ff0000;"><strong>Leonid Gurvits</strong></span></p>
<h2>Perturbation lemma</h2>
<p><strong>PERTURBATION LEMMA:</strong> Consider two linear maps</p>
<p style="text-align: center;"><img alt="\alpha, \beta: X\ \longrightarrow\ Y" class="latex" src="https://s0.wp.com/latex.php?latex=%5Calpha%2C+%5Cbeta%3A+X%5C+%5Clongrightarrow%5C+Y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\alpha, \beta: X\ \longrightarrow\ Y"/></p>
<p>of two real vector spaces <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X"/> and <img alt="Y" class="latex" src="https://s0.wp.com/latex.php?latex=Y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y"/>. Assume that</p>
<p><img alt="\beta (\ker \alpha ) \cap \rm{im}~ \alpha =\{0\} \subset Y." class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbeta+%28%5Cker+%5Calpha+%29+%5Ccap+%5Crm%7Bim%7D%7E+%5Calpha+%3D%5C%7B0%5C%7D+%5Csubset+Y.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\beta (\ker \alpha ) \cap \rm{im}~ \alpha =\{0\} \subset Y."/></p>
<p>Then a generic linear combination <img alt="\alpha ``+&quot;\beta" class="latex" src="https://s0.wp.com/latex.php?latex=%5Calpha+%60%60%2B%22%5Cbeta&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\alpha ``+&quot;\beta"/> of <img alt="\alpha" class="latex" src="https://s0.wp.com/latex.php?latex=%5Calpha&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\alpha"/> and <img alt="\beta" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbeta&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\beta"/>  has kernel<br/>
<img alt="\ker (\alpha&#xA0; ``+&quot; \beta )= \ker \alpha \cap \ker \beta." class="latex" src="https://s0.wp.com/latex.php?latex=%5Cker+%28%5Calpha%C2%A0+%60%60%2B%22+%5Cbeta+%29%3D+%5Cker+%5Calpha+%5Ccap+%5Cker+%5Cbeta.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\ker (\alpha&#xA0; ``+&quot; \beta )= \ker \alpha \cap \ker \beta."/></p>
<p>Cool, no? <strong>Proof, then:</strong> Find a subspace <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> of <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X"/> such that</p>
<p><img alt="\alpha A\ =\ \alpha X\quad \text{and}\ \quad X\ \cong\ A \oplus \ker\alpha" class="latex" src="https://s0.wp.com/latex.php?latex=%5Calpha+A%5C+%3D%5C+%5Calpha+X%5Cquad+%5Ctext%7Band%7D%5C+%5Cquad+X%5C+%5Ccong%5C+A+%5Coplus+%5Cker%5Calpha&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\alpha A\ =\ \alpha X\quad \text{and}\ \quad X\ \cong\ A \oplus \ker\alpha"/></p>
<p>so that in particular <img alt="\alpha" class="latex" src="https://s0.wp.com/latex.php?latex=%5Calpha&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\alpha"/> is injective on <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/>. Then, for <img alt="\epsilon \ge 0" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon+%5Cge+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon \ge 0"/> small enough, the image of</p>
<p><img alt="\alpha\ +\ \epsilon \beta{:}\ X\ \longrightarrow\ Y" class="latex" src="https://s0.wp.com/latex.php?latex=%5Calpha%5C+%2B%5C+%5Cepsilon+%5Cbeta%7B%3A%7D%5C+X%5C+%5Clongrightarrow%5C+Y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\alpha\ +\ \epsilon \beta{:}\ X\ \longrightarrow\ Y"/></p>
<p>is</p>
<p><img alt="(\alpha\ +\ \epsilon \beta)(A)\ +\ \beta\ker\alpha\ \subset\ Y." class="latex" src="https://s0.wp.com/latex.php?latex=%28%5Calpha%5C+%2B%5C+%5Cepsilon+%5Cbeta%29%28A%29%5C+%2B%5C+%5Cbeta%5Cker%5Calpha%5C+%5Csubset%5C+Y.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(\alpha\ +\ \epsilon \beta)(A)\ +\ \beta\ker\alpha\ \subset\ Y."/></p>
<p>But if we norm <img alt="Y" class="latex" src="https://s0.wp.com/latex.php?latex=Y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y"/> in any way, then <img alt="(\alpha+\epsilon \beta)(A)" class="latex" src="https://s0.wp.com/latex.php?latex=%28%5Calpha%2B%5Cepsilon+%5Cbeta%29%28A%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(\alpha+\epsilon \beta)(A)"/> approximates <img alt="\alpha A" class="latex" src="https://s0.wp.com/latex.php?latex=%5Calpha+A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\alpha A"/> as <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon"/> tends to zero, which is linearly independent from <img alt="\beta\, \ker\alpha" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbeta%5C%2C+%5Cker%5Calpha&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\beta\, \ker\alpha"/> by assumption. <span style="color: #993366;"><strong>WALLA</strong></span></p>
<p>Now, how is this used.</p>
<h2>Face rings</h2>
<p>Let me set up some of the basic objects.</p>
<p>If <img alt="\Delta" class="latex" src="https://s0.wp.com/latex.php?latex=%5CDelta&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Delta"/> is an abstract simplicial complex on ground-set <img alt="[n]:= \{1,\cdots,n\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Bn%5D%3A%3D+%5C%7B1%2C%5Ccdots%2Cn%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="[n]:= \{1,\cdots,n\}"/>, let <img alt="I_\Delta := \langle \textbf{x}^{\textbf{a}}: supp (\textbf{a})\notin\Delta\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=I_%5CDelta+%3A%3D+%5Clangle+%5Ctextbf%7Bx%7D%5E%7B%5Ctextbf%7Ba%7D%7D%3A+supp+%28%5Ctextbf%7Ba%7D%29%5Cnotin%5CDelta%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="I_\Delta := \langle \textbf{x}^{\textbf{a}}: supp (\textbf{a})\notin\Delta\rangle"/> denote the nonface ideal in <img alt="\mathbb{R}[\mathbf{x}]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5B%5Cmathbf%7Bx%7D%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb{R}[\mathbf{x}]"/>, where <img alt="\mathbb{R}[\mathbf{x}]=\mathbb{R}[x_1,\cdots,x_n]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5B%5Cmathbf%7Bx%7D%5D%3D%5Cmathbb%7BR%7D%5Bx_1%2C%5Ccdots%2Cx_n%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb{R}[\mathbf{x}]=\mathbb{R}[x_1,\cdots,x_n]"/>.</p>
<p>Let <img alt="\mathbb{R}^\ast[\Delta]:= \mathbb{R}[\mathbf{x}]/I_\Delta" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5E%5Cast%5B%5CDelta%5D%3A%3D+%5Cmathbb%7BR%7D%5B%5Cmathbf%7Bx%7D%5D%2FI_%5CDelta&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb{R}^\ast[\Delta]:= \mathbb{R}[\mathbf{x}]/I_\Delta"/> denote the face ring of <img alt="\Delta" class="latex" src="https://s0.wp.com/latex.php?latex=%5CDelta&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Delta"/>. A collection of linear forms <img alt="\Theta=(\theta_1,\cdots,\theta_l)" class="latex" src="https://s0.wp.com/latex.php?latex=%5CTheta%3D%28%5Ctheta_1%2C%5Ccdots%2C%5Ctheta_l%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Theta=(\theta_1,\cdots,\theta_l)"/> in the polynomial ring <img alt="\mathbb{R}[\textbf{x}]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5B%5Ctextbf%7Bx%7D%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb{R}[\textbf{x}]"/> is a <strong>partial linear system of parameters</strong> if</p>
<p><img alt="\dim_{\rm{Krull}} {\mathbb{R}^\ast[\Delta]}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdim_%7B%5Crm%7BKrull%7D%7D+%7B%5Cmathbb%7BR%7D%5E%5Cast%5B%5CDelta%5D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\dim_{\rm{Krull}} {\mathbb{R}^\ast[\Delta]}"/> <img alt="{\Theta \mathbb{R}^\ast[\Delta]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CTheta+%5Cmathbb%7BR%7D%5E%5Cast%5B%5CDelta%5D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{\Theta \mathbb{R}^\ast[\Delta]}"/> <img alt="=\dim_{\rm{Krull}} \mathbb{R}^\ast[\Delta]-l," class="latex" src="https://s0.wp.com/latex.php?latex=%3D%5Cdim_%7B%5Crm%7BKrull%7D%7D+%5Cmathbb%7BR%7D%5E%5Cast%5B%5CDelta%5D-l%2C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="=\dim_{\rm{Krull}} \mathbb{R}^\ast[\Delta]-l,"/></p>
<p>for <img alt="\dim_{\rm{Krull}}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdim_%7B%5Crm%7BKrull%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\dim_{\rm{Krull}}"/> the Krull dimension. If <img alt="l=\dim_{\rm{Krull}} \mathbb{R}^\ast[\Delta] = \dim \Delta +1" class="latex" src="https://s0.wp.com/latex.php?latex=l%3D%5Cdim_%7B%5Crm%7BKrull%7D%7D+%5Cmathbb%7BR%7D%5E%5Cast%5B%5CDelta%5D+%3D+%5Cdim+%5CDelta+%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="l=\dim_{\rm{Krull}} \mathbb{R}^\ast[\Delta] = \dim \Delta +1"/>, then <img alt="\Theta" class="latex" src="https://s0.wp.com/latex.php?latex=%5CTheta&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Theta"/> is simply a <strong>linear system of parameters</strong>, and the corresponding quotient <img alt="A(\Delta)={\mathbb{R}^\ast[\Delta]}/{\Theta \mathbb{R}^\ast[\Delta]}" class="latex" src="https://s0.wp.com/latex.php?latex=A%28%5CDelta%29%3D%7B%5Cmathbb%7BR%7D%5E%5Cast%5B%5CDelta%5D%7D%2F%7B%5CTheta+%5Cmathbb%7BR%7D%5E%5Cast%5B%5CDelta%5D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A(\Delta)={\mathbb{R}^\ast[\Delta]}/{\Theta \mathbb{R}^\ast[\Delta]}"/> is called an <strong>Artinian reduction</strong> of <img alt="\mathbb{R}^\ast[\Delta]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5E%5Cast%5B%5CDelta%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb{R}^\ast[\Delta]"/>.</p>
<h2>The <em>g</em>-conjecture</h2>
<p>The <em>g</em>-conjecture (as <a href="https://gilkalai.wordpress.com/2009/04/02/eran-nevo-the-g-conjecture-i/">described</a> <a href="https://gilkalai.wordpress.com/2009/04/04/how-the-g-conjecture-came-about/">earlier</a> <a href="https://gilkalai.wordpress.com/tag/g-conjecture/"> in Gil’s blog</a>) is implied by the following property:</p>
<p><strong>(HL)</strong> For every sphere <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S"/> of even dimension <img alt="d-1=2k" class="latex" src="https://s0.wp.com/latex.php?latex=d-1%3D2k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d-1=2k"/>, there is an Artinian reduction <img alt="A(S)" class="latex" src="https://s0.wp.com/latex.php?latex=A%28S%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A(S)"/> and a degree one element <img alt="\ell" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\ell"/> such that the map</p>
<p><img alt="A^k(S) \ \xrightarrow{\ \cdot \ell\ }\ A^{k+1}(S) " class="latex" src="https://s0.wp.com/latex.php?latex=A%5Ek%28S%29+%5C+%5Cxrightarrow%7B%5C+%5Ccdot+%5Cell%5C+%7D%5C+A%5E%7Bk%2B1%7D%28S%29+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A^k(S) \ \xrightarrow{\ \cdot \ell\ }\ A^{k+1}(S) "/></p>
<p>is an isomorphism.</p>
<p>This is quite a reasonable demand. Indeed, Graebe proved that <img alt="A^d(S) \cong \mathbb{R}" class="latex" src="https://s0.wp.com/latex.php?latex=A%5Ed%28S%29+%5Ccong+%5Cmathbb%7BR%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A^d(S) \cong \mathbb{R}"/> and that the resulting pairing</p>
<p><img alt="A^k(S) \times A^{k+1}(S)\rightarrow \mathbb{R} " class="latex" src="https://s0.wp.com/latex.php?latex=A%5Ek%28S%29+%5Ctimes+A%5E%7Bk%2B1%7D%28S%29%5Crightarrow+%5Cmathbb%7BR%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A^k(S) \times A^{k+1}(S)\rightarrow \mathbb{R} "/></p>
<p>is perfect, so <img alt="A^k(S)" class="latex" src="https://s0.wp.com/latex.php?latex=A%5Ek%28S%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A^k(S)"/> and <img alt="A^{k+1}(S)" class="latex" src="https://s0.wp.com/latex.php?latex=A%5E%7Bk%2B1%7D%28S%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A^{k+1}(S)"/> are isomorphic as vector spaces. We shall call this property <strong>(PD)</strong>, because it is a special case of Poincaré pairing.</p>
<p>(HL) is a special case of the Hard Lefschetz Theorem I prove in my paper, and we will prove it for a subset of all triangulated spheres here. Proving it for all spheres implies the <img alt="g" class="latex" src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g"/>-conjecture (and other conjectures, such as the Grünbaum conjecture), and proving the hard Lefschetz theorem in full generality is not much harder.</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/02/image-1.png"><img alt="" class="alignnone size-full wp-image-16960" src="https://gilkalai.files.wordpress.com/2019/02/image-1.png?w=640"/></a></p>
<p><span style="color: #ff0000;"><strong>Lou Billera</strong></span></p>
<h2>Vertex-decomposable spheres</h2>
<p>Lets recall a cool notion due to Provan and Billera: A pure simplicial <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/>-complex is <strong>vertex decomposable</strong> if it is a simplex, or there exists a vertex whose link is vertex decomposable of dimension <img alt="d-1" class="latex" src="https://s0.wp.com/latex.php?latex=d-1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d-1"/> and its deletion is vertex decomposable of dimension <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/>.</p>
<p>We restrict our attention to vertex decomposable spheres and disks and assume the boundary of the link is vertex decomposable as well in every step.</p>
<p><strong>THEOREM:</strong> Vertex decomposable spheres satisfy (HL).</p>
<p>We prove this theorem by induction on dimension, the base case of zero-dimensional spheres <img alt="(k=0)" class="latex" src="https://s0.wp.com/latex.php?latex=%28k%3D0%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(k=0)"/> being clear.</p>
<p>Lets label the vertices of <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S"/> in order of their vertex decomposition, from <img alt="1" class="latex" src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1"/> to <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>. Now, <img alt="\ell" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\ell"/> will be a linear combination of indeterminates, so lets assume we have constructed an element <img alt="\ell_i" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\ell_i"/> that uses just the first <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/> of them, and such that <img alt="\ell_i" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\ell_i"/> itself is as close to a Lefschetz element as possible for its kind, that is, the kernel of</p>
<p><img alt="A^k(S) \ \xrightarrow{\ \cdot \ell_i\ }\ A^{k+1}(S) " class="latex" src="https://s0.wp.com/latex.php?latex=A%5Ek%28S%29+%5C+%5Cxrightarrow%7B%5C+%5Ccdot+%5Cell_i%5C+%7D%5C+A%5E%7Bk%2B1%7D%28S%29+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A^k(S) \ \xrightarrow{\ \cdot \ell_i\ }\ A^{k+1}(S) "/></p>
<p>is the intersection of kernels of the maps</p>
<p><img alt="A^k(S) \ \xrightarrow{\ \cdot x_j\ }\ A^{k+1}(S) " class="latex" src="https://s0.wp.com/latex.php?latex=A%5Ek%28S%29+%5C+%5Cxrightarrow%7B%5C+%5Ccdot+x_j%5C+%7D%5C+A%5E%7Bk%2B1%7D%28S%29+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A^k(S) \ \xrightarrow{\ \cdot x_j\ }\ A^{k+1}(S) "/></p>
<p>where <img alt="j" class="latex" src="https://s0.wp.com/latex.php?latex=j&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="j"/> ranges from <img alt="1" class="latex" src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1"/> to <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/>.</p>
<p>We want to construct a map <img alt="\ell_{i+1}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell_%7Bi%2B1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\ell_{i+1}"/> with this property (which I call the <strong>transversal prime property</strong>}. To this effect, we want to apply the perturbation lemma to the maps <img alt="\beta x_{i+1}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbeta+x_%7Bi%2B1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\beta x_{i+1}"/>, <img alt="\alpha=\ell_i" class="latex" src="https://s0.wp.com/latex.php?latex=%5Calpha%3D%5Cell_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\alpha=\ell_i"/>, and with respect to the spaces <img alt="X=A^k(S)" class="latex" src="https://s0.wp.com/latex.php?latex=X%3DA%5Ek%28S%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X=A^k(S)"/> and <img alt="Y=A^{k+1}(S)" class="latex" src="https://s0.wp.com/latex.php?latex=Y%3DA%5E%7Bk%2B1%7D%28S%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y=A^{k+1}(S)"/>. Let us denote by <img alt="D" class="latex" src="https://s0.wp.com/latex.php?latex=D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D"/> the ball given as the union of neighborhoods of the first <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/> vertices.</p>
<p>For this, we have to find out the kernel of <img alt="\ell_i" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\ell_i"/>. But this is the the ideal in <img alt="A(S)" class="latex" src="https://s0.wp.com/latex.php?latex=A%28S%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A(S)"/> generated by the monomials of faces which are not in the neighborhood of any of the first <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/> vertices. Lets call it <img alt="K" class="latex" src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K"/>. Lets also look at the image <img alt="I" class="latex" src="https://s0.wp.com/latex.php?latex=I&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="I"/> of <img alt="\ell_i" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\ell_i"/>, which by Graebe’s theorem is exactly the span of the images of the maps the maps</p>
<p><img alt="A^k(S) \ \xrightarrow{\ \cdot x_j\ }\ A^{k+1}(S) " class="latex" src="https://s0.wp.com/latex.php?latex=A%5Ek%28S%29+%5C+%5Cxrightarrow%7B%5C+%5Ccdot+x_j%5C+%7D%5C+A%5E%7Bk%2B1%7D%28S%29+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A^k(S) \ \xrightarrow{\ \cdot x_j\ }\ A^{k+1}(S) "/></p>
<p>where <img alt="j" class="latex" src="https://s0.wp.com/latex.php?latex=j&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="j"/> ranges from <img alt="1" class="latex" src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1"/> to <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/>.</p>
<p>But then, <img alt="x_{i+1}K \cap I" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7Bi%2B1%7DK+%5Ccap+I&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{i+1}K \cap I"/> is <img alt="0" class="latex" src="https://s0.wp.com/latex.php?latex=0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="0"/> in degree <img alt="k+1" class="latex" src="https://s0.wp.com/latex.php?latex=k%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k+1"/> if and only if <img alt="A(st_{i+1} \partial D)" class="latex" src="https://s0.wp.com/latex.php?latex=A%28st_%7Bi%2B1%7D+%5Cpartial+D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A(st_{i+1} \partial D)"/> is <img alt="0" class="latex" src="https://s0.wp.com/latex.php?latex=0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="0"/> in degree <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>. Why is that? Because with respect to the Poincaré pairing, <img alt="x_{i+1}K \cap I" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7Bi%2B1%7DK+%5Ccap+I&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{i+1}K \cap I"/> (in degree <img alt="k+1" class="latex" src="https://s0.wp.com/latex.php?latex=k%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k+1"/>) and <img alt="A(st_{i+1} \partial D)" class="latex" src="https://s0.wp.com/latex.php?latex=A%28st_%7Bi%2B1%7D+%5Cpartial+D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A(st_{i+1} \partial D)"/> (in degree <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>) are dual.<br/>
The ring <img alt="A(st_{i+1} \partial D)" class="latex" src="https://s0.wp.com/latex.php?latex=A%28st_%7Bi%2B1%7D+%5Cpartial+D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A(st_{i+1} \partial D)"/> is obtained by taking <img alt="\mathbb{R}[st_{i+1} \partial D]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5Bst_%7Bi%2B1%7D+%5Cpartial+D%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb{R}[st_{i+1} \partial D]"/>, seen as a quotient of <img alt="\mathbb{R}[S]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5BS%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb{R}[S]"/> and modding out by the ideal generated by the linear system <img alt="\Theta" class="latex" src="https://s0.wp.com/latex.php?latex=%5CTheta&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Theta"/>. But that is of length <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/>, even though <img alt="st_{i+1} \partial D" class="latex" src="https://s0.wp.com/latex.php?latex=st_%7Bi%2B1%7D+%5Cpartial+D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="st_{i+1} \partial D"/> is only of dimension <img alt="d-2" class="latex" src="https://s0.wp.com/latex.php?latex=d-2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d-2"/>. We can remove the vertex <img alt="i+1" class="latex" src="https://s0.wp.com/latex.php?latex=i%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i+1"/> for the price of removing one of the linear forms, but then we have the same issue, having a <img alt="(d-3)" class="latex" src="https://s0.wp.com/latex.php?latex=%28d-3%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(d-3)"/>-sphere <img alt="st_{i+1} \partial D" class="latex" src="https://s0.wp.com/latex.php?latex=st_%7Bi%2B1%7D+%5Cpartial+D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="st_{i+1} \partial D"/> and a system <img alt="\Theta'" class="latex" src="https://s0.wp.com/latex.php?latex=%5CTheta%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Theta'"/> of length <img alt="d-1" class="latex" src="https://s0.wp.com/latex.php?latex=d-1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d-1"/>. Still, one too many! Taking a subsystem of length <img alt="d-2" class="latex" src="https://s0.wp.com/latex.php?latex=d-2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d-2"/>, we obtain an Artinian reduction for <img alt="\mathbb{R}[lk_{i+1} \partial D]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5Blk_%7Bi%2B1%7D+%5Cpartial+D%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb{R}[lk_{i+1} \partial D]"/> via a linear system <img alt="\Theta''" class="latex" src="https://s0.wp.com/latex.php?latex=%5CTheta%27%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Theta''"/>, but what happens to the additional linear form of <img alt="\Theta'" class="latex" src="https://s0.wp.com/latex.php?latex=%5CTheta%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Theta'"/> not in <img alt="\Theta''" class="latex" src="https://s0.wp.com/latex.php?latex=%5CTheta%27%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Theta''"/>? It has to act as a Lefschetz element on <img alt="\mathbb{R}[lk_{i+1} \partial D]/\Theta''\mathbb{R}[lk_{i+1} \partial D]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5Blk_%7Bi%2B1%7D+%5Cpartial+D%5D%2F%5CTheta%27%27%5Cmathbb%7BR%7D%5Blk_%7Bi%2B1%7D+%5Cpartial+D%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb{R}[lk_{i+1} \partial D]/\Theta''\mathbb{R}[lk_{i+1} \partial D]"/> if we want</p>
<p><img alt="A(st_{i+1} \partial D)\ \cong\ \mathbb{R}[lk_{i+1} \partial D]/\Theta'\mathbb{R}[lk_{i+1} \partial D]" class="latex" src="https://s0.wp.com/latex.php?latex=A%28st_%7Bi%2B1%7D+%5Cpartial+D%29%5C+%5Ccong%5C+%5Cmathbb%7BR%7D%5Blk_%7Bi%2B1%7D+%5Cpartial+D%5D%2F%5CTheta%27%5Cmathbb%7BR%7D%5Blk_%7Bi%2B1%7D+%5Cpartial+D%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A(st_{i+1} \partial D)\ \cong\ \mathbb{R}[lk_{i+1} \partial D]/\Theta'\mathbb{R}[lk_{i+1} \partial D]"/></p>
<p>to be trivial in degree <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>. But we may assume so by induction! Hence, we can choose <img alt="\ell_{i+1}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell_%7Bi%2B1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\ell_{i+1}"/> as the generic sum of <img alt="\ell_i" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\ell_i"/> and <img alt="x_{i+1}" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7Bi%2B1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{i+1}"/> by the perturbation lemma.</p>
<p>So, ultimately, we can construct a map <img alt="\ell_n" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\ell_n"/> with the transversal prime property. But then its kernel is the intersection of the kernels of</p>
<p><img alt="A^k(S) \ \xrightarrow{\ \cdot x_j\ }\ A^{k+1}(S) " class="latex" src="https://s0.wp.com/latex.php?latex=A%5Ek%28S%29+%5C+%5Cxrightarrow%7B%5C+%5Ccdot+x_j%5C+%7D%5C+A%5E%7Bk%2B1%7D%28S%29+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A^k(S) \ \xrightarrow{\ \cdot x_j\ }\ A^{k+1}(S) "/>,</p>
<p>where <img alt="j" class="latex" src="https://s0.wp.com/latex.php?latex=j&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="j"/> ranges from <img alt="1" class="latex" src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1"/> to <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>. But that is <img alt="0" class="latex" src="https://s0.wp.com/latex.php?latex=0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="0"/>.  <strong><span style="color: #993366;">SABABA</span>.</strong></p>
<h2>And beyond?</h2>
<p>Now, we have the Lefschetz theorem for a special class, but that is less than what we want in the end, since vertex decomposable spheres are few and in between (do you see a reason why? there are many). So, what do we do? For a long time, I tried to extend the perturbation lemma to combine more than two maps.<br/>
Recently (depending on when Gil puts this post on the blog), I met Leonid Gurvits for the first time on a marvelous little conference at the Simons Institute. I knew that the problem is related to Hall’s Marriage Theorem for operators (I explain this connection a bit further in my paper), but Leonid enlightened this further by pointing me towards several nice papers, starting with <a href="https://arxiv.org/abs/quant-ph/0201022">his work on Quantum Matching Theory</a>. Indeed, finding a good extension to three and more maps would essentially mean that we could also find Hall Marriage Type Theorems for 3-regular hypergraphs, which we know for complexity reasons to be unlikely.</p>
<p>So what can we do instead? Well, it turns out that I only really needed to look at the <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-skeleton of <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S"/> above, and there is no need to be vertex decomposable. It is enough to find another nicely decomposable <img alt="d-1" class="latex" src="https://s0.wp.com/latex.php?latex=d-1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d-1"/>-manifold that contains it the <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-skeleton of <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S"/>, and then use some technical topological tricks to connect the local picture to global homological properties.</p>
<p> </p>
<p> </p>
<p> </p></div>
    </content>
    <updated>2019-02-23T16:19:11Z</updated>
    <published>2019-02-23T16:19:11Z</published>
    <category term="Combinatorics"/>
    <category term="Convex polytopes"/>
    <category term="Geometry"/>
    <category term="Guest blogger"/>
    <category term="g-conjecture"/>
    <category term="J Scott Provan"/>
    <category term="Karim Adiprasito"/>
    <category term="Leonid Gurvits"/>
    <category term="Lou Billera"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-03-02T07:20:46Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=15657</id>
    <link href="https://rjlipton.wordpress.com/2019/02/22/making-a-mapping-injective/" rel="alternate" type="text/html"/>
    <title>Making A Mapping Injective</title>
    <summary>Finding a set of nearly independent objects Wikipedia bio source Giuseppe Vitali was the mathematician who famously used the Axiom of Choice, in 1905, to give the first example of a non-measurable subset of the real numbers. Today I want to discuss another of his results that is a powerful tool. The existence of a […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Finding a set of nearly independent objects</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2019/02/330px-giuseppe_vitali.jpg"><img alt="" class="alignright size-thumbnail wp-image-15658" height="150" src="https://rjlipton.files.wordpress.com/2019/02/330px-giuseppe_vitali.jpg?w=118&amp;h=150" width="118"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Wikipedia bio <a href="https://en.wikipedia.org/wiki/Giuseppe_Vitali">source</a></font></td>
</tr>
</tbody>
</table>
<p>
Giuseppe Vitali was the mathematician who famously used the Axiom of Choice, in 1905, to give the first example of a non-measurable subset of the real numbers.</p>
<p>
Today I want to discuss another of his results that is a powerful tool.<span id="more-15657"/></p>
<p>
The existence of a set that cannot properly be assigned a measure was a surprise at the time, and still is a surprise. It is a wonderful example of the power of the Axiom of Choice. See <a href="https://en.wikipedia.org/wiki/Vitali_set">this</a> for details. </p>
<p>
We are interested in another of his results that is more a theorem about coverings. It is the Vitali covering theorem–see <a href="https://en.wikipedia.org/wiki/Vitali_covering_lemma">this</a>. The theorem shows that a certain type of covering—ah, we will explain the theorem in a moment.</p>
<p>
The power of this theorem is that it can be used to construct various objects in analysis. There are now many applications of this theorem. It is a powerful tool that can be used to prove many nice results. I do not know of any—many?—applications of the existence of a non-measurable set. Do you know any?</p>
<p>
</p><p/><h2> Making A Mapping Injective </h2><p/>
<p/><p>
Let’s look at an application of the Vitali theorem that may be new. But in any case it may help explain what the Vitali theorem is all about.</p>
<p>
Suppose that <img alt="{F:X \rightarrow Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%3AX+%5Crightarrow+Y%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F:X \rightarrow Y}"/>. We can make the map surjective if we restrict <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y}"/> to be equal to <img alt="{F(X)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F(X)}"/>. It is not so simple to make the map injective, but we can in general do that also. </p>
<blockquote><p><b>Theorem 1</b> <em><a name="choice"/> Let <img alt="{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{F}"/> be a surjective function from <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{X}"/> to <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{Y}"/>. Then there is a subset <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{S}"/> of <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{X}"/> so that <img alt="{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{F}"/> is injective from <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{S}"/> to <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{Y}"/>. </em>
</p></blockquote>
<p/><p>
<em>Proof:</em>  For each <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y}"/> in <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y}"/> select one <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> from the set <img alt="{F^{-1}(y)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%5E%7B-1%7D%28y%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F^{-1}(y)}"/> and place it into <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/>. Recall <img alt="{F^{-1}(y)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%5E%7B-1%7D%28y%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F^{-1}(y)}"/> is the set of <img alt="{z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bz%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{z}"/> so that <img alt="{F(z)=y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%28z%29%3Dy%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F(z)=y}"/>.This of course uses the Axiom of Choice to make the choices of which <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> to choose. Then clearly <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> is the required set. <img alt="\Box" class="latex" src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Box"/></p>
<p>
The difficulty with this trivial theorem is that <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> cannot be controlled easily if it is constructed via the Axiom of Choice. It could be a very complicated set. Our goal is to see how well we can control <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> if we assume that the mapping <img alt="{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F}"/> is smooth. </p>
<p>
How can we do better? The answer is quite a bit better if we assume that <img alt="{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F}"/> is a “nice” function. We give up surjectivity onto <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y}"/> but only by a null set.</p>
<blockquote><p><b>Theorem 2</b> <em><a name="injective"/> Suppose that <img alt="{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{F}"/> is a surjective smooth map from <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{X}"/> to <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{Y}"/> where <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{X}"/> and <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{Y}"/> are open subsets of <img alt="{{\mathbb R}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb+R%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{{\mathbb R}}"/>. Also suppose that <img alt="{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{F}"/> locally is invertible. Then there is a subset <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{S}"/> of <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{X}"/> so that </em></p><em>
<ol>
<li>
The complement of <img alt="{F(S)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%28S%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{F(S)}"/> is a null set. <p/>
</li><li>
The map <img alt="{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{F}"/> is injective from <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{S}"/> to <img alt="{F(S)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%28S%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{F(S)}"/>.
</li></ol>
</em><p><em>That is that for all distinct points <img alt="{\boldsymbol{a}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cboldsymbol%7Ba%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\boldsymbol{a}}"/> and <img alt="{\boldsymbol{b}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cboldsymbol%7Bb%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\boldsymbol{b}}"/> in <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{S}"/>, <img alt="{F(\boldsymbol{a}) \neq F(\boldsymbol{b})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%28%5Cboldsymbol%7Ba%7D%29+%5Cneq+F%28%5Cboldsymbol%7Bb%7D%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{F(\boldsymbol{a}) \neq F(\boldsymbol{b})}"/>. Moreover the map from <img alt="{F(S)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%28S%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{F(S)}"/> to <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{S}"/> is smooth. </em>
</p></blockquote>
<p>
</p><p/><h2> Set Coverings </h2><p/>
<p/><p>
How can we prove this theorem? An obvious idea is to do the following. Pick an open interval <img alt="{U=[a,b]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU%3D%5Ba%2Cb%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{U=[a,b]}"/> in <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X}"/> so that <img alt="{F(U) = V}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%28U%29+%3D+V%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F(U) = V}"/> for an open set in <img alt="{V}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BV%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{V}"/> and so that <img alt="{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F}"/> is injective from <img alt="{U}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{U}"/> to <img alt="{V}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BV%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{V}"/>. Setting <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> to <img alt="{U}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{U}"/> clearly works: the map <img alt="{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F}"/> is injective on <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/>. This is far from the large set that we wish to have, but it is a start. The intuition is to select another open interval <img alt="{U'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{U'}"/> that is disjoint from <img alt="{U}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{U}"/> so that again <img alt="{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F}"/> is injective from <img alt="{U'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{U'}"/> to <img alt="{V'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BV%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{V'}"/>. We can then add <img alt="{U'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{U'}"/> to our <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/>. </p>
<p>
We can continue in this way and collect many open sets that we add to <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/>. Can we arrange that the union of these sets yield a <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> so that <img alt="{F(S)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%28S%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F(S)}"/> is most of <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y}"/>? In general the answer is no. Suppose that the intervals are the following: 	</p>
<p align="center"><img alt="\displaystyle  [k,k+1.1] " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Bk%2Ck%2B1.1%5D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  [k,k+1.1] "/></p>
<p>for <img alt="{k=0,1,2,\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%3D0%2C1%2C2%2C%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k=0,1,2,\dots}"/> Roughly we can only get about half of the space that the intervals cover and keep the chosen intervals disjoint. If we select <img alt="{ [k,k+1.1] }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Bk%2Ck%2B1.1%5D+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ [k,k+1.1] }"/> then we cannot select <img alt="{[k+1,k+1+1.1]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Bk%2B1%2Ck%2B1%2B1.1%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{[k+1,k+1+1.1]}"/> since 	</p>
<p align="center"><img alt="\displaystyle  [k,k+1.1] \cap [k+1,k+1+1.1] \neq \emptyset. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Bk%2Ck%2B1.1%5D+%5Ccap+%5Bk%2B1%2Ck%2B1%2B1.1%5D+%5Cneq+%5Cemptyset.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  [k,k+1.1] \cap [k+1,k+1+1.1] \neq \emptyset. "/></p>
<p>Vitali’s theorem comes to the rescue. It allows us to avoid his problem, by insisting that intervals have an additional property.</p>
<p>
</p><p/><h2> The Vitali Covering Theorem </h2><p/>
<p/><p>
The trick is to use a refinement of a set cover that allows a disjoint cover to exist for almost all of the target set. The next definition is critical to the Vitali covering theorem. </p>
<blockquote><p><b>Definition 3</b> <em> Let <img alt="{U}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{U}"/> be a subset of <img alt="{{\mathbb R}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb+R%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{{\mathbb R}}"/>. Let <img alt="{[a_{\lambda},b_{\lambda}]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ba_%7B%5Clambda%7D%2Cb_%7B%5Clambda%7D%5D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{[a_{\lambda},b_{\lambda}]}"/> be intervals over <img alt="{\lambda}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\lambda}"/> in some index set <img alt="{I}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BI%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{I}"/>. We say these intervals are a <b>cover</b> of <img alt="{U}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{U}"/> proved <img alt="{U}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{U}"/> is a subset of the union of all the intervals. Say the intervals also are a <b>Vitali</b> cover of <img alt="{U}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{U}"/> provided for all points <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{x}"/> in <img alt="{U}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{U}"/> and all <img alt="{\epsilon &gt; 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon+%3E+0%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\epsilon &gt; 0}"/>, there is an interval <img alt="{[c,d]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Bc%2Cd%5D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{[c,d]}"/> that contains <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{x}"/> and <img alt="{0 &lt; d-c &lt; \epsilon}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0+%3C+d-c+%3C+%5Cepsilon%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{0 &lt; d-c &lt; \epsilon}"/>. </em>
</p></blockquote>
<p/><p>
The Vitali theorem is the following: </p>
<blockquote><p><b>Theorem 4</b> <em> Let <img alt="{U}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{U}"/> be a subset of <img alt="{{\mathbb R}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb+R%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{{\mathbb R}}"/>. Let <img alt="{[a_{\lambda},b_{\lambda}]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ba_%7B%5Clambda%7D%2Cb_%7B%5Clambda%7D%5D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{[a_{\lambda},b_{\lambda}]}"/> be intervals for <img alt="{\lambda}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\lambda}"/> in some index set <img alt="{I}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BI%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{I}"/>. Assume that the family is a Vitali cover of <img alt="{U}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{U}"/>. Then there is a countable subfamily of disjoints intervals in the family so that they cover all of <img alt="{U}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{U}"/> except for possibly a null set. </em>
</p></blockquote>
<p/><p>
The Vitali theorem can be extended to any finite dimensional space <img alt="{{\mathbb R}^{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb+R%7D%5E%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{\mathbb R}^{n}}"/>. Then intervals become disks and so on.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Do you see how to prove Theorem <a href="https://rjlipton.wordpress.com/feed/#injective">2</a> from Vitali’s theorem? The insight is now one can set up a Vitali covering of the space <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y}"/>. </p></font></font></div>
    </content>
    <updated>2019-02-23T04:58:34Z</updated>
    <published>2019-02-23T04:58:34Z</published>
    <category term="All Posts"/>
    <category term="History"/>
    <category term="Proofs"/>
    <category term="analysis"/>
    <category term="axiom of choice"/>
    <category term="Giuseppe Vitali"/>
    <category term="set coverings"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-03-02T07:20:49Z</updated>
    </source>
  </entry>
</feed>
