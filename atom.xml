<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2020-04-22T00:21:51Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.08847</id>
    <link href="http://arxiv.org/abs/2004.08847" rel="alternate" type="text/html"/>
    <title>Minimizing Total Interference in Asymmetric Sensor Networks</title>
    <feedworld_mtime>1587513600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Abu=Affash:A=_Karim.html">A. Karim Abu-Affash</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Carmi:Paz.html">Paz Carmi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Katz:Matthew_J=.html">Matthew J. Katz</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.08847">PDF</a><br/><b>Abstract: </b>The problem of computing a connected network with minimum interference is a
fundamental problem in wireless sensor networks. Several models of interference
have been studied in the literature. The most common model is the
receiver-centric, in which the interference of a node $p$ is defined as the
number of other nodes whose transmission range covers $p$. In this paper, we
study the problem of assigning a transmission range to each sensor, such that
the resulting network is strongly connected and the total interference of the
network is minimized. For the one-dimensional case, we show how to solve the
problem optimally in $O(n^3)$ time. For the two-dimensional case, we show that
the problem is NP-complete and give a polynomial-time 2-approximation algorithm
for the problem.
</p></div>
    </summary>
    <updated>2020-04-21T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-04-21T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://agtb.wordpress.com/?p=3472</id>
    <link href="https://agtb.wordpress.com/2020/04/21/ec-2020-will-be-virtual/" rel="alternate" type="text/html"/>
    <title>SIGecom Announcement: EC 2020 will be virtual</title>
    <summary>As many of you have probably anticipated, due to concerns regarding the novel coronavirus COVID-19, the 2020 ACM Conference on Economics and Computation (EC 2020) will be held virtually. This change of format will of course present us with difficult challenges, but we believe it will offer exciting new opportunities as well.  (And not to […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>As many of you have probably anticipated, due to concerns regarding the novel coronavirus COVID-19, the <a href="http://ec20.sigecom.org/">2020 ACM Conference on Economics and Computation (EC 2020)</a> will be held virtually.</p>
<p>This change of format will of course present us with difficult challenges, but we believe it will offer exciting new opportunities as well.  (And not to worry, your opportunity to attend EC in Budapest is just deferred to 2021.)</p>
<p>The <a href="http://sigecom.org/officers.html">SIGecom Executive Committee</a> has appointed and will serve on a Virtual Transition Team that additionally includes the following new conference officers:</p>
<ul>
<li>Virtual General Chair: <a href="https://sites.northwestern.edu/hartline/">Jason Hartline</a></li>
<li>Virtual Local Chair: <a href="https://yannai.gonch.name/">Yannai Gonczarowski</a></li>
<li>Virtual Global Outreach Chairs: <a href="https://www.cs.cornell.edu/~red/">Rediet Abebe</a> and <a href="https://research.fb.com/people/sodomka-eric/">Eric Sodomka</a></li>
</ul>
<p>This team is working with the <a href="http://ec20.sigecom.org/committees-acm/organizing-committee/">EC 2020 organizing committee</a> and <a href="http://ec20.sigecom.org/committees-acm/program-committee/">EC 2020 PC chairs</a> to put together a plan that leverages the opportunities of the virtual format to the fullest extent. Though these plans are still in the works, we have identified the following “minimal commitment” for authors of accepted papers to the main EC conference: at least one author will need to</p>
<ul>
<li>register for the conference;</li>
<li>be available virtually on the conference dates (July 14-16);</li>
<li>provide a camera-ready paper or abstract by the camera-ready deadline;</li>
<li>provide a pre-recorded talk presenting the paper two weeks in advance (by June 28).</li>
</ul>
<p>We are optimistic that, while a virtual EC may lack some of the positive features of a classical conference, the format will also provide opportunities that improve on the classical experience.  As with any conference there will be opportunities to participate beyond the “minimal commitment.”  We hope that speakers and participants will join in other activities, which may include preview sessions for talks before the conference proper, watch parties for speakers and attendees, and mechanisms for reaching a wider audience with the technical program. With many academic interactions moving virtual, the barriers to collaboration with distant colleagues have lowered, and we hope that EC 2020 will kindle and rekindle global collaborations.</p>
<div>
<p>Further details about these activities as well as the minimal requirements will be circulated by June 1.</p>
<p>Tutorial speakers and workshop organizers will receive separate emails from the Tutorial and Workshop Chairs about plans for moving these events online.</p>
</div></div>
    </content>
    <updated>2020-04-21T14:05:08Z</updated>
    <published>2020-04-21T14:05:08Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Jason Hartline</name>
    </author>
    <source>
      <id>https://agtb.wordpress.com</id>
      <logo>https://secure.gravatar.com/blavatar/52ef314e11e379febf97d1a97547f4cd?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fbuttonw-com.png</logo>
      <link href="https://agtb.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://agtb.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://agtb.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://agtb.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Computation, Economics, and Game Theory</subtitle>
      <title>Turing's Invisible Hand</title>
      <updated>2020-04-22T00:20:31Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://kamathematics.wordpress.com/?p=118</id>
    <link href="https://kamathematics.wordpress.com/2020/04/21/a-primer-on-private-statistics-part-ii/" rel="alternate" type="text/html"/>
    <title>A Primer on Private Statistics – Part II</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">By Gautam Kamath and Jonathan Ullman The second part of our brief survey of differentially private statistics. This time, we show how to privately estimate the CDF of a distribution (i.e., estimate the distribution in Kolmogorov distance), and conclude with pointers to some other work in the space. The first part of this series is here, and you … <a class="more-link" href="https://kamathematics.wordpress.com/2020/04/21/a-primer-on-private-statistics-part-ii/">Continue reading<span class="screen-reader-text"> "A Primer on Private Statistics – Part II"</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>By <a href="http://www.gautamkamath.com/">Gautam Kamath</a> and <a href="http://www.ccs.neu.edu/home/jullman/">Jonathan Ullman</a></p>
<p>The second part of our brief survey of differentially private statistics. This time, we show how to privately estimate the CDF of a distribution (i.e., estimate the distribution in Kolmogorov distance), and conclude with pointers to some other work in the space.</p>
<p>The first part of this series is <a href="https://kamathematics.wordpress.com/2020/04/14/a-primer-on-private-statistics-part-i/">here</a>, and you can download both parts in PDF form <a href="http://www.gautamkamath.com/writings/primer.pdf">here</a>.</p>
<p><b>1. CDF Estimation for Discrete, Univariate Distributions </b></p>
<p>Suppose we have a distribution <img alt="{P}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{P}"/> over the ordered, discrete domain <img alt="{\{1,\dots,D\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B1%2C%5Cdots%2CD%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{1,\dots,D\}}"/> and let <img alt="{\mathcal{P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{P}}"/> be the family of all such distributions. The CDF of the distribution is the function <img alt="{\Phi_{P} : \{1,\dots,D\} \rightarrow [0,1]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CPhi_%7BP%7D+%3A+%5C%7B1%2C%5Cdots%2CD%5C%7D+%5Crightarrow+%5B0%2C1%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Phi_{P} : \{1,\dots,D\} \rightarrow [0,1]}"/> given by</p>
<p align="center"><img alt="\displaystyle \Phi_{P}(j) = \mathop{\mathbb P}(P \leq j). \ \ \ \ \ (1)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5CPhi_%7BP%7D%28j%29+%3D+%5Cmathop%7B%5Cmathbb+P%7D%28P+%5Cleq+j%29.+%5C+%5C+%5C+%5C+%5C+%281%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \Phi_{P}(j) = \mathop{\mathbb P}(P \leq j). \ \ \ \ \ (1)"/></p>
<p>A natural measure of distance between CDFs is the <img alt="{\ell_\infty}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell_%5Cinfty%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\ell_\infty}"/> distance, as this is the sort of convergence guarantee that the empirical CDF satisfies. That is, in the non-private setting, the empirical CDF will achieve the minimax rate, which it known by [<a href="https://kamathematics.wordpress.com/feed/#DKW56">DKW56</a>, <a href="https://kamathematics.wordpress.com/feed/#Mas90">Mas90</a>] to be <a name="eqdkw"/></p>
<p><a name="eqdkw"/></p>
<p><a name="eqdkw"/></p>
<p align="center"><img alt="\displaystyle \max_{P \in \mathcal{P}} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| \Phi_{X} - \Phi_{P} \|_{\infty}) = O\left(\sqrt{\frac{1}{n}} \right). \ \ \ \ \ (2)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmax_%7BP+%5Cin+%5Cmathcal%7BP%7D%7D+%5Cmathop%7B%5Cmathbb+E%7D_%7BX_%7B1+%5Ccdots+n%7D+%5Csim+P%7D%28%5C%7C+%5CPhi_%7BX%7D+-+%5CPhi_%7BP%7D+%5C%7C_%7B%5Cinfty%7D%29+%3D+O%5Cleft%28%5Csqrt%7B%5Cfrac%7B1%7D%7Bn%7D%7D+%5Cright%29.+%5C+%5C+%5C+%5C+%5C+%282%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \max_{P \in \mathcal{P}} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| \Phi_{X} - \Phi_{P} \|_{\infty}) = O\left(\sqrt{\frac{1}{n}} \right). \ \ \ \ \ (2)"/></p>
<p><a name="eqdkw"/><a name="eqdkw"/><a name="eqdkw"/></p>
<p><b> 1.1. Private CDF Estimation </b></p>
<blockquote><p><b>Theorem 1</b> <em> <a name="thmcdf-ub"/> For every <img alt="{n \in {\mathbb N}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn+%5Cin+%7B%5Cmathbb+N%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n \in {\mathbb N}}"/> and every <img alt="{\epsilon,\delta &gt; 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%2C%5Cdelta+%3E+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\epsilon,\delta &gt; 0}"/>, there exists an <img alt="{(\epsilon,\delta)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28%5Cepsilon%2C%5Cdelta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(\epsilon,\delta)}"/>-differentially private mechanism <img alt="{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M}"/> such that </em></p>
<p align="center"><img alt="\displaystyle \max_{P \in \mathcal{P}} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| M(X_{1 \cdots n}) - \Phi_{P} \|_{\infty}) = O\left(\sqrt{\frac{1}{n}} + \frac{\log^{3/2}(D) \log^{1/2}(1/\delta)}{\epsilon n} \right). \ \ \ \ \ (3)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmax_%7BP+%5Cin+%5Cmathcal%7BP%7D%7D+%5Cmathop%7B%5Cmathbb+E%7D_%7BX_%7B1+%5Ccdots+n%7D+%5Csim+P%7D%28%5C%7C+M%28X_%7B1+%5Ccdots+n%7D%29+-+%5CPhi_%7BP%7D+%5C%7C_%7B%5Cinfty%7D%29+%3D+O%5Cleft%28%5Csqrt%7B%5Cfrac%7B1%7D%7Bn%7D%7D+%2B+%5Cfrac%7B%5Clog%5E%7B3%2F2%7D%28D%29+%5Clog%5E%7B1%2F2%7D%281%2F%5Cdelta%29%7D%7B%5Cepsilon+n%7D+%5Cright%29.+%5C+%5C+%5C+%5C+%5C+%283%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \max_{P \in \mathcal{P}} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| M(X_{1 \cdots n}) - \Phi_{P} \|_{\infty}) = O\left(\sqrt{\frac{1}{n}} + \frac{\log^{3/2}(D) \log^{1/2}(1/\delta)}{\epsilon n} \right). \ \ \ \ \ (3)"/></p>
</blockquote>
<p><em>Proof:</em> Assume without loss of generality that <img alt="{D = 2^{d}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD+%3D+2%5E%7Bd%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D = 2^{d}}"/> for an integer <img alt="{d \geq 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd+%5Cgeq+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d \geq 1}"/>. Let <img alt="{X_{1 \cdots n} \sim P}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_%7B1+%5Ccdots+n%7D+%5Csim+P%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X_{1 \cdots n} \sim P}"/> be a sample. By the triangle inequality, we have</p>
<p align="center"><img alt="\displaystyle \begin{array}{rll} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}{\| M(X_{1 \cdots n}) - \Phi_{P} \|_{\infty}} &amp;\leq{} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| \Phi_{X} - \Phi_{P} \|_{\infty} + \| M(X_{1 \cdots n}) - \Phi_{X} \|_{\infty}) \\ &amp;\leq{} O(\sqrt{1/n}) + \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| M(X_{1 \cdots n}) - \Phi_{X} \|_{\infty}), \end{array} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cbegin%7Barray%7D%7Brll%7D+%5Cmathop%7B%5Cmathbb+E%7D_%7BX_%7B1+%5Ccdots+n%7D+%5Csim+P%7D%7B%5C%7C+M%28X_%7B1+%5Ccdots+n%7D%29+-+%5CPhi_%7BP%7D+%5C%7C_%7B%5Cinfty%7D%7D+%26%5Cleq%7B%7D+%5Cmathop%7B%5Cmathbb+E%7D_%7BX_%7B1+%5Ccdots+n%7D+%5Csim+P%7D%28%5C%7C+%5CPhi_%7BX%7D+-+%5CPhi_%7BP%7D+%5C%7C_%7B%5Cinfty%7D+%2B+%5C%7C+M%28X_%7B1+%5Ccdots+n%7D%29+-+%5CPhi_%7BX%7D+%5C%7C_%7B%5Cinfty%7D%29+%5C%5C+%26%5Cleq%7B%7D+O%28%5Csqrt%7B1%2Fn%7D%29+%2B+%5Cmathop%7B%5Cmathbb+E%7D_%7BX_%7B1+%5Ccdots+n%7D+%5Csim+P%7D%28%5C%7C+M%28X_%7B1+%5Ccdots+n%7D%29+-+%5CPhi_%7BX%7D+%5C%7C_%7B%5Cinfty%7D%29%2C+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \begin{array}{rll} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}{\| M(X_{1 \cdots n}) - \Phi_{P} \|_{\infty}} &amp;\leq{} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| \Phi_{X} - \Phi_{P} \|_{\infty} + \| M(X_{1 \cdots n}) - \Phi_{X} \|_{\infty}) \\ &amp;\leq{} O(\sqrt{1/n}) + \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| M(X_{1 \cdots n}) - \Phi_{X} \|_{\infty}), \end{array} "/></p>
<p>so we will focus on constructing <img alt="{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M}"/> to approximate <img alt="{\Phi_{X}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CPhi_%7BX%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Phi_{X}}"/>.</p>
<p>For any <img alt="{\ell = 0,\dots,d-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell+%3D+0%2C%5Cdots%2Cd-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\ell = 0,\dots,d-1}"/> and <img alt="{j = 1,\dots,2^{d - \ell}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bj+%3D+1%2C%5Cdots%2C2%5E%7Bd+-+%5Cell%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{j = 1,\dots,2^{d - \ell}}"/>, consider the statistics</p>
<p align="center"><img alt="\displaystyle f_{\ell,j}(X_{1 \cdots n}) = \frac{1}{n} \sum_{i=1}^{n} {\bf 1}\{ (j-1)2^{\ell} + 1 \leq X_i \leq j 2^{\ell} \}. \ \ \ \ \ (4)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+f_%7B%5Cell%2Cj%7D%28X_%7B1+%5Ccdots+n%7D%29+%3D+%5Cfrac%7B1%7D%7Bn%7D+%5Csum_%7Bi%3D1%7D%5E%7Bn%7D+%7B%5Cbf+1%7D%5C%7B+%28j-1%292%5E%7B%5Cell%7D+%2B+1+%5Cleq+X_i+%5Cleq+j+2%5E%7B%5Cell%7D+%5C%7D.+%5C+%5C+%5C+%5C+%5C+%284%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle f_{\ell,j}(X_{1 \cdots n}) = \frac{1}{n} \sum_{i=1}^{n} {\bf 1}\{ (j-1)2^{\ell} + 1 \leq X_i \leq j 2^{\ell} \}. \ \ \ \ \ (4)"/></p>
<p>Let <img alt="{f : \{1,\dots,D\}^n \rightarrow [0,1]^{2D - 2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf+%3A+%5C%7B1%2C%5Cdots%2CD%5C%7D%5En+%5Crightarrow+%5B0%2C1%5D%5E%7B2D+-+2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f : \{1,\dots,D\}^n \rightarrow [0,1]^{2D - 2}}"/> be the function whose output consists of all <img alt="{2D-2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2D-2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2D-2}"/> such counts. To decipher this notation, for a given <img alt="{\ell}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\ell}"/>, the counts <img alt="{f_{\ell,\cdot}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_%7B%5Cell%2C%5Ccdot%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_{\ell,\cdot}}"/> form a histogram of <img alt="{X_{1 \cdots n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_%7B1+%5Ccdots+n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X_{1 \cdots n}}"/> using consecutive bins of width <img alt="{2^{\ell}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5E%7B%5Cell%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2^{\ell}}"/>, and we consider the <img alt="{\log(D)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog%28D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\log(D)}"/> histograms of geometrically increasing width <img alt="{1,2,4,\dots,D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%2C2%2C4%2C%5Cdots%2CD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1,2,4,\dots,D}"/>. First, we claim that the function <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/> has low sensitivity—for adjacent samples <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X}"/> and <img alt="{X'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X'}"/>,</p>
<p align="center"><img alt="\displaystyle \| f(X) - f(X') \|_2^2 \leq \frac{2 \log(D)}{n^2}. \ \ \ \ \ (5)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5C%7C+f%28X%29+-+f%28X%27%29+%5C%7C_2%5E2+%5Cleq+%5Cfrac%7B2+%5Clog%28D%29%7D%7Bn%5E2%7D.+%5C+%5C+%5C+%5C+%5C+%285%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \| f(X) - f(X') \|_2^2 \leq \frac{2 \log(D)}{n^2}. \ \ \ \ \ (5)"/></p>
<p>Thus, we can use the Gaussian mechanism:</p>
<p align="center"><img alt="\displaystyle M'(X_{1 \cdots n}) = f(X_{1 \cdots n}) + \mathcal{N}\left(0, \frac{2 \log(D) \log(1/\delta)}{\epsilon^2 n^2} \cdot \mathbb{I}_{2D \times 2D}\right). \ \ \ \ \ (6)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+M%27%28X_%7B1+%5Ccdots+n%7D%29+%3D+f%28X_%7B1+%5Ccdots+n%7D%29+%2B+%5Cmathcal%7BN%7D%5Cleft%280%2C+%5Cfrac%7B2+%5Clog%28D%29+%5Clog%281%2F%5Cdelta%29%7D%7B%5Cepsilon%5E2+n%5E2%7D+%5Ccdot+%5Cmathbb%7BI%7D_%7B2D+%5Ctimes+2D%7D%5Cright%29.+%5C+%5C+%5C+%5C+%5C+%286%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle M'(X_{1 \cdots n}) = f(X_{1 \cdots n}) + \mathcal{N}\left(0, \frac{2 \log(D) \log(1/\delta)}{\epsilon^2 n^2} \cdot \mathbb{I}_{2D \times 2D}\right). \ \ \ \ \ (6)"/></p>
<p>As we will argue, there exists a matrix <img alt="{A \in {\mathbb R}^{2D \times 2D}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA+%5Cin+%7B%5Cmathbb+R%7D%5E%7B2D+%5Ctimes+2D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A \in {\mathbb R}^{2D \times 2D}}"/> such that <img alt="{\Phi_{X} = A \cdot f(X_{1 \cdots n})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CPhi_%7BX%7D+%3D+A+%5Ccdot+f%28X_%7B1+%5Ccdots+n%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Phi_{X} = A \cdot f(X_{1 \cdots n})}"/>. We will let <img alt="{M(X_{1 \cdots n}) = A \cdot M'(X_{1 \cdots n})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%28X_%7B1+%5Ccdots+n%7D%29+%3D+A+%5Ccdot+M%27%28X_%7B1+%5Ccdots+n%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M(X_{1 \cdots n}) = A \cdot M'(X_{1 \cdots n})}"/>. Since differential privacy is closed under post-processing, <img alt="{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M}"/> inherits the privacy of <img alt="{M'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M'}"/>.</p>
<p>We will now show how to construct the matrix <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/> and analyze the error of <img alt="{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M}"/>. For any <img alt="{j = 1,\dots,D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bj+%3D+1%2C%5Cdots%2CD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{j = 1,\dots,D}"/>, we can form the interval <img alt="{\{1,\dots,j\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B1%2C%5Cdots%2Cj%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{1,\dots,j\}}"/> as the union of at most <img alt="{\log D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog+D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\log D}"/> disjoint intervals of the form we’ve computed, and therefore we can obtain <img alt="{\Phi_{X}(j)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CPhi_%7BX%7D%28j%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Phi_{X}(j)}"/> as the sum of at most <img alt="{\log D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog+D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\log D}"/> of the entries of <img alt="{f(X)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(X)}"/>. For example, if <img alt="{j = 5}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bj+%3D+5%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{j = 5}"/> then we can write</p>
<p align="center"><img alt="\displaystyle \{1,\dots,7\} = \{1,\dots,4\} \cup \{5,6\} \cup \{7\} \ \ \ \ \ (7)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5C%7B1%2C%5Cdots%2C7%5C%7D+%3D+%5C%7B1%2C%5Cdots%2C4%5C%7D+%5Ccup+%5C%7B5%2C6%5C%7D+%5Ccup+%5C%7B7%5C%7D+%5C+%5C+%5C+%5C+%5C+%287%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \{1,\dots,7\} = \{1,\dots,4\} \cup \{5,6\} \cup \{7\} \ \ \ \ \ (7)"/></p>
<p>and</p>
<p align="center"><img alt="\displaystyle \Phi_{X}(5) = f_{2,1} + f_{1,3} + f_{0,7}. \ \ \ \ \ (8)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5CPhi_%7BX%7D%285%29+%3D+f_%7B2%2C1%7D+%2B+f_%7B1%2C3%7D+%2B+f_%7B0%2C7%7D.+%5C+%5C+%5C+%5C+%5C+%288%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \Phi_{X}(5) = f_{2,1} + f_{1,3} + f_{0,7}. \ \ \ \ \ (8)"/></p>
<p>See the following diagram for a visual representation of the decomposition.</p>
<p><img alt="bin-tree-mech" class=" wp-image-142 aligncenter" height="300" src="https://kamathematics.files.wordpress.com/2020/04/bin-tree-mech.png?w=547&amp;h=300" width="547"/></p>
<p>This shows hierarchical decomposition of the domain <img alt="{\{1,\dots,8\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B1%2C%5Cdots%2C8%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{1,\dots,8\}}"/> using 14 intervals. The highlighted squares represent the interval <img alt="{\{1,\dots,7\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B1%2C%5Cdots%2C7%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{1,\dots,7\}}"/> and the highlighted circles show the decomposition of this interval into a union of <img alt="{3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{3}"/> intervals in the tree.</p>
<p>Thus we can construct the matrix <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/> using this information. Note that each entry of <img alt="{A f(X)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA+f%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A f(X)}"/> is the sum of at most <img alt="{\log(D)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog%28D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\log(D)}"/> entries of <img alt="{f(X)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(X)}"/>. Thus, if we use the output of <img alt="{M'(X_{1 \cdots n})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%27%28X_%7B1+%5Ccdots+n%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M'(X_{1 \cdots n})}"/> in place of <img alt="{f(X_{1 \cdots n})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28X_%7B1+%5Ccdots+n%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(X_{1 \cdots n})}"/>, for every <img alt="{j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{j}"/> we obtain</p>
<p align="center"><img alt="\displaystyle \Phi_{X}(j) + \mathcal{N}(0, \sigma^2) \quad \textrm{for} \quad \sigma^2 = \frac{ 2 \log^2(D) \log(1/\delta)}{\epsilon^2 n^2}. \ \ \ \ \ (9)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5CPhi_%7BX%7D%28j%29+%2B+%5Cmathcal%7BN%7D%280%2C+%5Csigma%5E2%29+%5Cquad+%5Ctextrm%7Bfor%7D+%5Cquad+%5Csigma%5E2+%3D+%5Cfrac%7B+2+%5Clog%5E2%28D%29+%5Clog%281%2F%5Cdelta%29%7D%7B%5Cepsilon%5E2+n%5E2%7D.+%5C+%5C+%5C+%5C+%5C+%289%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \Phi_{X}(j) + \mathcal{N}(0, \sigma^2) \quad \textrm{for} \quad \sigma^2 = \frac{ 2 \log^2(D) \log(1/\delta)}{\epsilon^2 n^2}. \ \ \ \ \ (9)"/></p>
<p>Applying standard bounds on the expected supremum of a Gaussian process, we have</p>
<p align="center"><img alt="\displaystyle \mathop{\mathbb E}(\| M(X_{1 \cdots n}) - \Phi_{X} \|_{\infty}) = O( \sigma \sqrt{\log D}) = O\left(\frac{\log^{3/2}(D) \log^{1/2}(1/\delta)}{\epsilon n} \right). \ \ \ \ \ (10)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmathop%7B%5Cmathbb+E%7D%28%5C%7C+M%28X_%7B1+%5Ccdots+n%7D%29+-+%5CPhi_%7BX%7D+%5C%7C_%7B%5Cinfty%7D%29+%3D+O%28+%5Csigma+%5Csqrt%7B%5Clog+D%7D%29+%3D+O%5Cleft%28%5Cfrac%7B%5Clog%5E%7B3%2F2%7D%28D%29+%5Clog%5E%7B1%2F2%7D%281%2F%5Cdelta%29%7D%7B%5Cepsilon+n%7D+%5Cright%29.+%5C+%5C+%5C+%5C+%5C+%2810%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \mathop{\mathbb E}(\| M(X_{1 \cdots n}) - \Phi_{X} \|_{\infty}) = O( \sigma \sqrt{\log D}) = O\left(\frac{\log^{3/2}(D) \log^{1/2}(1/\delta)}{\epsilon n} \right). \ \ \ \ \ (10)"/></p>
<p><img alt="\Box" class="latex" src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Box"/></p>
<p><b> 1.2. Why Restrict the Domain? </b></p>
<p>A drawback of the estimator we constructed is that it only applies to distributions of finite support <img alt="{\{1,2,\dots,D\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B1%2C2%2C%5Cdots%2CD%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{1,2,\dots,D\}}"/>, albeit with a relatively mild dependence on the support size. If privacy isn’t a concern, then no such restriction is necessary, as the bound <a href="https://kamathematics.wordpress.com/feed/#eqdkw">(2)</a> applies equally well to any distribution over <img alt="{{\mathbb R}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb+R%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{\mathbb R}}"/>. Can we construct a differentially private estimator for distributions with infinite support?</p>
<p>Perhaps surprisingly, the answer to this question is no! Any differentially private estimator for the CDF of the distribution has to have a rate that depends on the support size, and cannot give non-trivial rates for distributions with infinite support.</p>
<blockquote><p><b>Theorem 2 ([<a href="https://kamathematics.wordpress.com/feed/#BNSV15">BNSV15</a>])</b> <em> <a name="thmcdf-lb"/> If <img alt="{\mathcal{P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{P}}"/> consists of all distributions on <img alt="{\{1,\dots,D\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B1%2C%5Cdots%2CD%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{1,\dots,D\}}"/>, then </em></p>
<p align="center"><img alt="\displaystyle \min_{M \in \mathcal{M}_{1, \frac{1}{n}}} \max_{P \in \mathcal{P}} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| M(X_{1 \cdots n}) - \Phi_{P} \|_{\infty}) = \Omega\left(\frac{\log^* D}{n} \right). \ \ \ \ \ (11)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmin_%7BM+%5Cin+%5Cmathcal%7BM%7D_%7B1%2C+%5Cfrac%7B1%7D%7Bn%7D%7D%7D+%5Cmax_%7BP+%5Cin+%5Cmathcal%7BP%7D%7D+%5Cmathop%7B%5Cmathbb+E%7D_%7BX_%7B1+%5Ccdots+n%7D+%5Csim+P%7D%28%5C%7C+M%28X_%7B1+%5Ccdots+n%7D%29+-+%5CPhi_%7BP%7D+%5C%7C_%7B%5Cinfty%7D%29+%3D+%5COmega%5Cleft%28%5Cfrac%7B%5Clog%5E%2A+D%7D%7Bn%7D+%5Cright%29.+%5C+%5C+%5C+%5C+%5C+%2811%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \min_{M \in \mathcal{M}_{1, \frac{1}{n}}} \max_{P \in \mathcal{P}} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| M(X_{1 \cdots n}) - \Phi_{P} \|_{\infty}) = \Omega\left(\frac{\log^* D}{n} \right). \ \ \ \ \ (11)"/></p>
</blockquote>
<p>The notation <img alt="{\log^* D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog%5E%2A+D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\log^* D}"/> refers to the <a href="https://en.wikipedia.org/wiki/Iterated_logarithm">iterated logarithm</a>.</p>
<p>We emphasize that this theorem shouldn’t meet with too much alarm, as <img alt="{\log^* D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog%5E%2A+D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\log^* D}"/> grows remarkably slowly with <img alt="{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D}"/>. There are differentially private CDF estimators that achieve very mild dependence on <img alt="{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D}"/> [<a href="https://kamathematics.wordpress.com/feed/#BNS13">BNS13</a>, <a href="https://kamathematics.wordpress.com/feed/#BNSV15">BNSV15</a>], including one nearly matching the lower bound in Theorem <a href="https://kamathematics.wordpress.com/feed/#thmcdf-lb">2</a>. Moreover, if we want to estimate a distribution over <img alt="{{\mathbb R}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb+R%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{\mathbb R}}"/>, and are willing to make some mild regularity conditions on the distribution, then we can approximate it by a distribution with finite support and only increase the rate slightly. However, what Theorem <a href="https://kamathematics.wordpress.com/feed/#thmcdf-lb">2</a> shows is that there is no “one-size-fits-all” solution to private CDF estimation that achieves similar guarantees to the empirical CDF. That is, the right algorithm has to be tailored somewhat to the application and the assumptions we can make about the distribution.</p>
<p><b>2. More Private Statistics </b></p>
<p>Of course, the story doesn’t end here! There’s a whole wide world of differentially private statistics beyond what we’ve mentioned already. We proceed to survey just a few other directions of study in private statistics.</p>
<p><b> 2.1. Parameter and Distribution Estimation </b></p>
<p>A number of the early works in differential privacy give methods for differentially private statistical estimation for i.i.d. data. The earliest works [<a href="https://kamathematics.wordpress.com/feed/#DN03">DN03</a>, <a href="https://kamathematics.wordpress.com/feed/#DN04">DN04</a>, <a href="https://kamathematics.wordpress.com/feed/#BDMN05">BDMN05</a>, <a href="https://kamathematics.wordpress.com/feed/#DMNS06">DMNS06</a>], which introduced the Gaussian mechanism, among other foundational results, can be thought of as methods for estimating the mean of a distribution over the hypercube <img alt="{\{0,1\}^d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B0%2C1%5C%7D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{0,1\}^d}"/> in the <img alt="{\ell_\infty}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell_%5Cinfty%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\ell_\infty}"/> norm. Tight lower bounds for this problem follow from the tracing attacks introduced in [<a href="https://kamathematics.wordpress.com/feed/#BUV14">BUV14</a>, <a href="https://kamathematics.wordpress.com/feed/#DSSUV15">DSSUV15</a>, <a href="https://kamathematics.wordpress.com/feed/#BSU17">BSU17</a>, <a href="https://kamathematics.wordpress.com/feed/#SU17a">SU17a</a>, <a href="https://kamathematics.wordpress.com/feed/#SU17b">SU17b</a>]. A very recent work of Acharya, Sun, and Zhang [<a href="https://kamathematics.wordpress.com/feed/#ASZ20">ASZ20</a>] adapts classical tools for proving estimation and testing lower bounds (lemmata of Assouad, Fano, and Le Cam) to the differentially private setting. Steinke and Ullman [<a href="https://kamathematics.wordpress.com/feed/#SU17b">SU17b</a>] give tight minimax lower bounds for the weaker guarantee of selecting the largest coordinates of the mean, which were refined by Cai, Wang, and Zhang [<a href="https://kamathematics.wordpress.com/feed/#CWZ19">CWZ19</a>] to give lower bounds for sparse mean-estimation problems.</p>
<p>Nissim, Raskhodnikova, and Smith introduced the highly general sample-and-aggregate paradigm, which they apply to several learning problems (e.g., learning mixtures of Gaussians) [<a href="https://kamathematics.wordpress.com/feed/#NRS07">NRS07</a>]. Later, Smith [<a href="https://kamathematics.wordpress.com/feed/#Smi11">Smi11</a>] showed that this paradigm can be used to transform any estimator for any asymptotically normal, univariate statistic over a bounded data domain into a differentially private one with the same asymptotic convergence rate.</p>
<p>Subsequent work has focused on both relaxing the assumptions in [<a href="https://kamathematics.wordpress.com/feed/#Smi11">Smi11</a>], particularly boundedness, and on giving finite-sample guarantees. Karwa and Vadhan investigated the problem of Gaussian mean estimation, proving the first near-optimal bounds for this setting [<a href="https://kamathematics.wordpress.com/feed/#KV18">KV18</a>]. In particular, exploiting concentration properties of Gaussian data allows us to achieve non-trivial results even with unbounded data, which is impossible in general. Following this, Kamath, Li, Singhal, and Ullman moved to the multivariate setting, investigating the estimation of Gaussians and binary product distributions in total variation distance [<a href="https://kamathematics.wordpress.com/feed/#KLSU19">KLSU19</a>]. In certain cases (i.e., Gaussians with identity covariance), this is equivalent to mean estimation in <img alt="{\ell_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\ell_2}"/>-distance, though not always. For example, for binary product distribution, one must estimate the mean in a type of <img alt="{\chi^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cchi%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\chi^2}"/>-distance instead. The perspective of distribution estimation rather than parameter estimation can be valuable. Bun, Kamath, Steinke, and Wu [<a href="https://kamathematics.wordpress.com/feed/#BKSW19">BKSW19</a>] develop a primitive for private hypothesis selection, which they apply to learn any coverable class of distributions under pure differential privacy. Through the lens of distribution estimation, their work implies an upper bound for mean estimation of binary product distributions that bypasses lower bounds for the same problem in the empirical setting. In addition to work on mean estimation in the sub-Gaussian setting, such as the results discussed earlier, mean estimation has also been studied under weaker moment conditions [<a href="https://kamathematics.wordpress.com/feed/#BS19">BS19</a>, <a href="https://kamathematics.wordpress.com/feed/#KSU20">KSU20</a>]. Beyond these settings, there has also been study of estimation of discrete multinomials, including estimation in Kolmogorov distance [<a href="https://kamathematics.wordpress.com/feed/#BNSV15">BNSV15</a>] and in total variation distance for structured distributions [<a href="https://kamathematics.wordpress.com/feed/#DHS15">DHS15</a>], and parameter estimation of Markov Random Fields [<a href="https://kamathematics.wordpress.com/feed/#ZKKW20">ZKKW20</a>].</p>
<p>A different approach to constructing differentially private estimators is based on robust statistics. This approah begins with the influential work of Dwork and Lei [<a href="https://kamathematics.wordpress.com/feed/#DL09">DL09</a>], which introduced the propose-test-release framework, and applied to estimating robust statistics such as the median and interquartile range. While the definitions in robust statistics and differential privacy are semantically similar, formal connections between the two remain relatively scant, which suggests a productive area for future study.</p>
<p><b> 2.2. Hypothesis Testing </b></p>
<p>An influential work of Homer et al. [<a href="https://kamathematics.wordpress.com/feed/#HSRDTMPSNC08">HSRDTMPSNC08</a>] demonstrated the vulnerability of classical statistics in a genomic setting, showing that certain <img alt="{\chi^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cchi%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\chi^2}"/>-statistics on many different variables could allow an attacker to determine the presence of an individual in a genome-wide association study (GWAS). Motivated by these concerns, an early line of work from the statistics community focused on addressing these issues [<a href="https://kamathematics.wordpress.com/feed/#VS09">VS09</a>, <a href="https://kamathematics.wordpress.com/feed/#USF13">USF13</a>, <a href="https://kamathematics.wordpress.com/feed/#YFSU14">YFSU14</a>].</p>
<p>More recently, work on private hypothesis testing can be divided roughly into two lines. The first focuses on the minimax sample complexity, in a line initiated by Cai, Daskalakis, and Kamath [<a href="https://kamathematics.wordpress.com/feed/#CDK17">CDK17</a>], who give an algorithm for privately testing goodness-of-fit (more precisely, a statistician might refer to this problem as one-sample testing of multinomial data). A number of subsequent works have essentially settled the complexity of this problem [<a href="https://kamathematics.wordpress.com/feed/#ASZ18">ASZ18</a>, <a href="https://kamathematics.wordpress.com/feed/#ADR18">ADR18</a>], giving tight upper and lower bounds. Other papers in this line study related problems, including the two-sample version of the problem, independence testing, and goodness-of-fit testing for multivariate product distributions [<a href="https://kamathematics.wordpress.com/feed/#ASZ18">ASZ18</a>, <a href="https://kamathematics.wordpress.com/feed/#ADR18">ADR18</a>, <a href="https://kamathematics.wordpress.com/feed/#ADKR19">ADKR19</a>, <a href="https://kamathematics.wordpress.com/feed/#CKMUZ19">CKMUZ19</a>]. A related paper studies the minimax sample complexity of property <em>estimation</em>, rather than testing of discrete distributions, including support size and entropy [<a href="https://kamathematics.wordpress.com/feed/#AKSZ18">AKSZ18</a>]. Other recent works in this vein focus on testing of simple hypotheses [<a href="https://kamathematics.wordpress.com/feed/#CKMTZ18">CKMTZ18</a>, <a href="https://kamathematics.wordpress.com/feed/#CKMSU19">CKMSU19</a>]. In particular [<a href="https://kamathematics.wordpress.com/feed/#CKMSU19">CKMSU19</a>] proves an analogue of the Neyman-Pearson Lemma for differentially private testing of simple hypotheses. A paper of Awan and Slavkovic [<a href="https://kamathematics.wordpress.com/feed/#AS18">AS18</a>] gives a universally optimal test when the domain size is two, however Brenner and Nissim [<a href="https://kamathematics.wordpress.com/feed/#BN14">BN14</a>] shows that such universally optimal tests cannot exist when the domain has more than two elements. A related problem in this space is private change-point detection [<a href="https://kamathematics.wordpress.com/feed/#CKMTZ18">CKMTZ18</a>, <a href="https://kamathematics.wordpress.com/feed/#CKMSU19">CKMSU19</a>, <a href="https://kamathematics.wordpress.com/feed/#CKLZ19">CKLZ19</a>] — in this setting, we are given a time series of datapoints which are sampled from a distribution, which at some point, changes to a different distribution. The goal is to (privately) determine when this point occurs.</p>
<p>Complementary to minimax hypothesis testing, a line of work [<a href="https://kamathematics.wordpress.com/feed/#WLK15">WLK15</a>, <a href="https://kamathematics.wordpress.com/feed/#GLRV16">GLRV16</a>, <a href="https://kamathematics.wordpress.com/feed/#KR17">KR17</a>, <a href="https://kamathematics.wordpress.com/feed/#KSF17">KSF17</a>, <a href="https://kamathematics.wordpress.com/feed/#CBRG18">CBRG18</a>, <a href="https://kamathematics.wordpress.com/feed/#SGGRGB19">SGGRGB19</a>, <a href="https://kamathematics.wordpress.com/feed/#CKSBG19">CKSBG19</a>] designs differentially private versions of popular test statistics for testing goodness-of-fit, closeness, and independence, as well as private ANOVA, focusing on the performance at small sample sizes. Work by Wang et al. [<a href="https://kamathematics.wordpress.com/feed/#WKLK18">WKLK18</a>] focuses on generating statistical approximating distributions for differentially private statistics, which they apply to hypothesis testing problems.</p>
<p><b> 2.3. Differential Privacy on Graphs </b></p>
<p>There is a significant amount of work on differentially private analysis of graphs. We remark that these algorithms can satisfy either edge or node differential privacy. The former (easier) guarantee defines a neighboring graph to be one obtained by adding or removing a single edge, while in the latter (harder) setting, a neighboring graph is one that can be obtained by modifying the set of edges connected to a single node. The main challenge in this area is that most graph statistics can have high sensitivity in the worst-case.</p>
<p>The initial works in this area focused on the empirical setting, and goals range from counting subgraphs [<a href="https://kamathematics.wordpress.com/feed/#KRSY11">KRSY11</a>, <a href="https://kamathematics.wordpress.com/feed/#BBDS13">BBDS13</a>, <a href="https://kamathematics.wordpress.com/feed/#KNRS13">KNRS13</a>, <a href="https://kamathematics.wordpress.com/feed/#CZ13">CZ13</a>, <a href="https://kamathematics.wordpress.com/feed/#RS16">RS16</a>] to outputting a privatized graph which approximates the original [<a href="https://kamathematics.wordpress.com/feed/#GRU12">GRU12</a>, <a href="https://kamathematics.wordpress.com/feed/#BBDS12">BBDS12</a>, <a href="https://kamathematics.wordpress.com/feed/#Upa13">Upa13</a>, <a href="https://kamathematics.wordpress.com/feed/#AU19">AU19</a>, <a href="https://kamathematics.wordpress.com/feed/#EKKL20">EKKL20</a>]. In contrast to the setting discussed in most of this series, it seems that there are larger qualitative differences between the study of empirical and population statistics due to the fact that many graph statistics have high worst-case sensitivity, but may have smaller sensitivity on typical graphs from many natural models.</p>
<p>In the population statistics setting, recent work has focused on parameter estimation of the underlying random graph model. So far this work has given estimators for the <img alt="{\beta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\beta}"/>-model [<a href="https://kamathematics.wordpress.com/feed/#KS16">KS16</a>] and graphons [<a href="https://kamathematics.wordpress.com/feed/#BCS15">BCS15</a>,<a href="https://kamathematics.wordpress.com/feed/#BCSZ18">BCSZ18</a>]. Graphons are a generalization of the stochastic block model, which is, in turn, a generalization of the Erdös-Rényi model. Interestingly, the methods of Lipschitz-extensions introduced in the empirical setting by [<a href="https://kamathematics.wordpress.com/feed/#BBDS13">BBDS13</a>, <a href="https://kamathematics.wordpress.com/feed/#KNRS13">KNRS13</a>] are the main tool used in the statistical setting as well. While the first works on private graphon estimation were not computationally efficient, a recent focus has been on obviating these issues for certain important cases, such as the Erdös-Rényi setting [<a href="https://kamathematics.wordpress.com/feed/#SU19">SU19</a>].</p>
<p><b>Bibliography</b></p>
<p><a name="ADKR19"/>[ADKR19] Maryam Aliakbarpour, Ilias Diakonikolas, Daniel M. Kane, and Ronitt Rubinfeld. Private testing of distributions via sample permutations. NeurIPS ’19.</p>
<p><a name="ADR18"/>[ADR18] Maryam Aliakbarpour, Ilias Diakonikolas, and Ronitt Rubinfeld. Differentially private identity and closeness testing of discrete distributions. ICML ’18.</p>
<p><a name="AKSZ18"/>[AKSZ18] Jayadev Acharya, Gautam Kamath, Ziteng Sun, and Huanyu Zhang. Inspectre: Privately estimating the unseen. ICML ’18.</p>
<p><a name="AS18"/>[AS18] Jordan Awan and Aleksandra Slavković. Differentially private uniformly most powerful tests for binomial data. NeurIPS ’18.</p>
<p><a name="ASZ18"/>[ASZ18] Jayadev Acharya, Ziteng Sun, and Huanyu Zhang. Differentially private testing of identity and closeness of discrete distributions. NeurIPS ’18.</p>
<p><a name="ASZ20"/>[ASZ20] Jayadev Acharya, Ziteng Sun, and Huanyu Zhang. Differentially private Assouad, Fano, and Le Cam. arXiv, 2004.06830, 2020.</p>
<p><a name="AU19"/>[AU19] Raman Arora and Jalaj Upadhyay. On differentially private graph sparsification and applications. NeurIPS ’19.</p>
<p><a name="BBDS12"/>[BBDS12] Jeremiah Blocki, Avrim Blum, Anupam Datta, and Or Sheffet. The Johnson-Lindenstrauss transform itself preserves differential privacy. FOCS ’12.</p>
<p><a name="BBDS13"/>[BBDS13] Jeremiah Blocki, Avrim Blum, Anupam Datta, and Or Sheffet. Differentially private data analysis of social networks via restricted sensitivity. ITCS ’13.</p>
<p><a name="BCS15"/>[BCS15] Christian Borgs, Jennifer Chayes, and Adam Smith. Private graphon estimation for sparse graphs. NIPS ’15.</p>
<p><a name="BCSZ18"/>[BCSZ18] Christian Borgs, Jennifer Chayes, Adam Smith, and Ilias Zadik. Revealing network structure, confidentially: Improved rates for node-private graphon estimation. FOCS ’18.</p>
<p><a name="BDMN05"/>[BDMN05] Avrim Blum, Cynthia Dwork, Frank McSherry, and Kobbi Nissim. Practical privacy: The SuLQ framework. PODS ’05.</p>
<p><a name="BKSW19"/>[BKSW19] Mark Bun, Gautam Kamath, Thomas Steinke, and Zhiwei Steven Wu. Private hypothesis selection. NeurIPS ’19.</p>
<p><a name="BN14"/>[BN14] Hai Brenner and Kobbi Nissim. Impossibility of differentially private universally optimal mechanisms. SIAM Journal on Computing, 43(5), 2014.</p>
<p><a name="BNS13"/>[BNS13] Amos Beimel, Kobbi Nissim, and Uri Stemmer. Private learning and sanitization: Pure vs. approximate differential privacy. APPROX-RANDOM ’13.</p>
<p><a name="BNSV15"/>[BNSV15] Mark Bun, Kobbi Nissim, Uri Stemmer, and Salil Vadhan. Differentially private release and learning of threshold functions. FOCS ’15.</p>
<p><a name="BS19"/>[BS19] Mark Bun and Thomas Steinke. Average-case averages: Private algorithms for smooth sensitivity and mean estimation. NeurIPS ’19.</p>
<p><a name="BSU17"/>[BSU17] Mark Bun, Thomas Steinke, and Jonathan Ullman. Make up your mind: The price of online queries in differential privacy. SODA ’17.</p>
<p><a name="BUV14"/>[BUV14] Mark Bun, Jonathan Ullman, and Salil Vadhan. Fingerprinting codes and the price of approximate differential privacy. STOC ’14.</p>
<p><a name="CBRG18"/>[CBRG18] Zachary Campbell, Andrew Bray, Anna Ritz, and Adam Groce. Differentially private ANOVA testing. ICDIS ’18.</p>
<p><a name="CDK17"/>[CDK17] Bryan Cai, Constantinos Daskalakis, and Gautam Kamath. Priv’it: Private and sample efficient identity testing. ICML ’17.</p>
<p><a name="CKLZ19"/>[CKLZ19] Rachel Cummings, Sara Krehbiel, Yuliia Lut, and Wanrong Zhang. Privately detecting changes in unknown distributions. arXiv, 1910.01327, 2019.</p>
<p><a name="CKMSU19"/>[CKMSU19] Clément L. Canonne, Gautam Kamath, Audra McMillan, Adam Smith, and Jonathan Ullman. The structure of optimal private tests for simple hypotheses. STOC ’19.</p>
<p><a name="CKMTZ18"/>[CKMTZ18] Rachel Cummings, Sara Krehbiel, Yajun Mei, Rui Tuo, and Wanrong Zhang. Differentially private change-point detection. NeurIPS ’18.</p>
<p><a name="CKMUZ19"/>[CKMUZ19] Clément L. Canonne, Gautam Kamath, Audra McMillan, Jonathan Ullman, and Lydia Zakynthinou. Private identity testing for high-dimensional distributions. arXiv, 1905.11947, 2019.</p>
<p><a name="CKSBG19"/>[CKSBG19] Simon Couch, Zeki Kazan, Kaiyan Shi, Andrew Bray, and Adam Groce. Differentially private nonparametric hypothesis testing. CCS ’19.</p>
<p><a name="CWZ19"/>[CWZ19] T. Tony Cai, Yichen Wang, and Linjun Zhang. The cost of privacy: Optimal rates of convergence for parameter estimation with differential privacy. arXiv, 1902.04495, 2019.</p>
<p><a name="CZ13"/>[CZ13] Shixi Chen and Shuigeng Zhou. Recursive mechanism: Towards node differential privacy and unrestricted joins. SIGMOD ’13.</p>
<p><a name="DHS15"/>[DHS15] Ilias Diakonikolas, Moritz Hardt, and Ludwig Schmidt. Differentially private learning of structured discrete distributions. NIPS ’15.</p>
<p><a name="DKW56"/>[DKW56] Aryeh Dvoretzky, Jack Kiefer, and Jacob Wolfowitz. Asymptotic minimax character of the sample distribution function and of the classical multinomial estimator. The Annals of Mathematical Statistics, 27(3), 1956.</p>
<p><a name="DL09"/>[DL09] Cynthia Dwork and Jing Lei. Differential privacy and robust statistics. STOC ’09.</p>
<p><a name="DMNS06"/>[DMNS06] Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith. Calibrating noise to sensitivity in private data analysis. TCC ’06.</p>
<p><a name="DN03"/>[DN03] Irit Dinur and Kobbi Nissim. Revealing information while preserving privacy. PODS ’03.</p>
<p><a name="DN04"/>[DN04] Cynthia Dwork and Kobbi Nissim. Privacy-preserving datamining on vertically partitioned databases. CRYPTO ’04.</p>
<p><a name="DSSUV15"/>[DSSUV15] Cynthia Dwork, Adam Smith, Thomas Steinke, Jonathan Ullman, and Salil Vadhan. Robust traceability from trace amounts. FOCS ’15.</p>
<p><a name="EKKL20"/>[EKKL20] Marek Eliáš, Michael Kapralov, Janardhan Kulkarni, and Yin Tat Lee. Differentially private release of synthetic graphs. SODA ’20.</p>
<p><a name="GLRV16"/>[GLRV16] Marco Gaboardi, Hyun-Woo Lim, Ryan M. Rogers, and Salil P. Vadhan. Differentially private chi-squared hypothesis testing: Goodness of fit and independence testing. ICML ’16.</p>
<p><a name="GRU12"/>[GRU12] Anupam Gupta, Aaron Roth, and Jonathan Ullman. Iterative constructions and private data release. TCC ’12.</p>
<p><a name="HSRDTMPSNC08"/>[HSRDTMPSNC08] Nils Homer, Szabolcs Szelinger, Margot Redman, David Duggan, Waibhav Tembe, Jill Muehling, John V. Pearson, Dietrich A. Stephan, Stanley F. Nelson, and David W. Craig. PLoS Genetics, 4(8), 2008.</p>
<p><a name="KLSU19"/>[KLSU19] Gautam Kamath, Jerry Li, Vikrant Singhal, and Jonathan Ullman. Privately learning high-dimensional distributions. COLT ’19.</p>
<p><a name="KNRS13"/>[KNRS13] Shiva Prasad Kasiviswanathan, Kobbi Nissim, Sofya Raskhodnikova, and Adam Smith. Analyzing graphs with node differential privacy. TCC ’13.</p>
<p><a name="KR17"/>[KR17] Daniel Kifer and Ryan M. Rogers. A new class of private chi-square tests. AISTATS ’17.</p>
<p><a name="KRSY11"/>[KRSY11] Vishesh Karwa, Sofya Raskhodnikova, Adam Smith, and Grigory Yaroslavtsev. Private analysis of graph structure. VLDB ’11.</p>
<p><a name="KS16"/>[KS16] Vishesh Karwa and Aleksandra Slavković. Inference using noisy degrees: Differentially private β-model and synthetic graphs. The Annals of Statistics, 44(1), 2016.</p>
<p><a name="KSF17"/>[KSF17] Kazuya Kakizaki, Jun Sakuma, and Kazuto Fukuchi. Differentially private chi-squared test by unit circle mechanism. ICML ’17.</p>
<p><a name="KSU20"/>[KSU20] Gautam Kamath, Vikrant Singhal, and Jonathan Ullman. Private mean estimation of heavy-tailed distributions. arXiv, 2002.09464, 2020.</p>
<p><a name="KV18"/>[KV18] Vishesh Karwa and Salil Vadhan. Finite sample differentially private confidence intervals. ITCS ’18.</p>
<p><a name="Mas90"/>[Mas90] Pascal Massart. The tight constant in the Dvoretzky-Kiefer-Wolfowitz inequality. The Annals of Probability, 18(3), 1990.</p>
<p><a name="NRS07"/>[NRS07] Kobbi Nissim, Sofya Raskhodnikova, and Adam Smith. Smooth sensitivity and sampling in private data analysis. STOC ’07.</p>
<p><a name="RS16"/>[RS16] Sofya Raskhodnikova and Adam D. Smith. Lipschitz extensions for node-private graph statistics and the generalized exponential mechanism. FOCS ’16.</p>
<p><a name="Smi11"/>[Smi11] Adam Smith. Privacy-preserving statistical estimation with optimal convergence rates. STOC ’11.</p>
<p><a name="SGGRGB19"/>[SGGRGB19] Marika Swanberg, Ira Globus-Harris, Iris Griffith, Anna Ritz, Adam Groce, and Andrew Bray. Improved differentially private analysis of variance. PETS ’19.</p>
<p><a name="SU17a"/>[SU17a] Thomas Steinke and Jonathan Ullman. Between pure and approximate differential privacy. Journal of Privacy and Confidentiality, 7(2), 2017.</p>
<p><a name="SU17b"/>[SU17b] Thomas Steinke and Jonathan Ullman. Tight lower bounds for differentially private selection. FOCS ’17.</p>
<p><a name="SU19"/>[SU19] Adam Sealfon and Jonathan Ullman. Efficiently estimating Erdos-Renyi graphs with node differential privacy. NeurIPS ’19.</p>
<p><a name="Upa13"/>[Upa13] Jalaj Upadhyay. Random projections, graph sparsification, and differential privacy. ASIACRYPT ’13.</p>
<p><a name="USF13"/>[USF13] Caroline Uhler, Aleksandra Slavković, and Stephen E. Fienberg. Privacy-preserving data sharing for genome-wide association studies. The Journal of Privacy and Confidentiality, 5(1), 2013.</p>
<p><a name="VS09"/>[VS09] Duy Vu and Aleksandra Slavković. Differential privacy for clinical trial data: Preliminary evaluations. ICDMW ’09.</p>
<p><a name="WKLK18"/>[WKLK18] Yue Wang, Daniel Kifer, Jaewoo Lee, and Vishesh Karwa. Statistical approximating distributions under differential privacy. The Journal of Privacy and Confidentiality, 8(1), 2018.</p>
<p><a name="WLK15"/>[WLK15] Yue Wang, Jaewoo Lee, and Daniel Kifer. Revisiting differentially private hypothesis tests for categorical data. arXiv, 1511.03376, 2015.</p>
<p><a name="YFSU14"/>[YFSU14] Fei Yu, Stephen E. Fienberg, Aleksandra B. Slavković, and Caroline Uhler. Scalable privacy-preserving data sharing methodology for genome-wide association studies. Journal of Biomedical Informatics, 50, 2014.</p>
<p><a name="ZKKW20"/>[ZKKW20] Huanyu Zhang, Gautam Kamath, Janardhan Kulkarni, and Zhiwei Steven Wu. Privately learning Markov random fields. arXiv, 2002.09463, 2020.</p></div>
    </content>
    <updated>2020-04-21T13:36:53Z</updated>
    <published>2020-04-21T13:36:53Z</published>
    <category term="Technical"/>
    <author>
      <name>Gautam</name>
    </author>
    <source>
      <id>https://kamathematics.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://kamathematics.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://kamathematics.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://kamathematics.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://kamathematics.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Kamathematics</title>
      <updated>2020-04-22T00:21:46Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.09304</id>
    <link href="http://arxiv.org/abs/2004.09304" rel="alternate" type="text/html"/>
    <title>From graph cuts to isoperimetric inequalities: Convergence rates of Cheeger cuts on data clouds</title>
    <feedworld_mtime>1587427200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Nicolas Garcia Trillos, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Murray:Ryan.html">Ryan Murray</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Thorpe:Matthew.html">Matthew Thorpe</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.09304">PDF</a><br/><b>Abstract: </b>In this work we study statistical properties of graph-based clustering
algorithms that rely on the optimization of balanced graph cuts, the main
example being the optimization of Cheeger cuts. We consider proximity graphs
built from data sampled from an underlying distribution supported on a generic
smooth compact manifold $M$. In this setting, we obtain high probability
convergence rates for both the Cheeger constant and the associated Cheeger cuts
towards their continuum counterparts. The key technical tools are careful
estimates of interpolation operators which lift empirical Cheeger cuts to the
continuum, as well as continuum stability estimates for isoperimetric problems.
To our knowledge the quantitative estimates obtained here are the first of
their kind.
</p></div>
    </summary>
    <updated>2020-04-21T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-04-21T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.09238</id>
    <link href="http://arxiv.org/abs/2004.09238" rel="alternate" type="text/html"/>
    <title>The complexity of approximating averages on bounded-degree graphs</title>
    <feedworld_mtime>1587427200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Galanis:Andreas.html">Andreas Galanis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Stefankovic:Daniel.html">Daniel Stefankovic</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vigoda:Eric.html">Eric Vigoda</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.09238">PDF</a><br/><b>Abstract: </b>We prove that, unless P=NP, there is no polynomial-time algorithm to
approximate within some multiplicative constant the average size of an
independent set in graphs of maximum degree 6. This is a special case of a more
general result for the hard-core model defined on independent sets weighted by
a parameter $\lambda&gt;0$. In the general setting, we prove that, unless P=NP,
for all $\Delta\geq 3$, all $\lambda&gt;\lambda_c(\Delta)$, there is no FPTAS
which applies to all graphs of maximum degree $\Delta$ for computing the
average size of the independent set in the Gibbs distribution, where
$\lambda_c(\Delta)$ is the critical point for the uniqueness/non-uniqueness
phase transition on the $\Delta$-regular tree. Moreover, we prove that for
$\lambda$ in a dense set of this non-uniqueness region the problem is NP-hard
to approximate within some constant factor. Our work extends to the
antiferromagnetic Ising model and generalizes to all 2-spin antiferromagnetic
models, establishing hardness of computing the average magnetization in the
tree non-uniqueness region.
</p>
<p>Previously, Schulman, Sinclair and Srivastava (2015) showed that it is
#P-hard to compute the average magnetization exactly, but no hardness of
approximation results were known. Hardness results of Sly (2010) and Sly and
Sun (2014) for approximating the partition function do not imply hardness of
computing averages. The new ingredient in our reduction is an intricate
construction of pairs of rooted trees whose marginal distributions at the root
agree but their derivatives disagree. The main technical contribution is
controlling what marginal distributions and derivatives are achievable and
using Cauchy's functional equation to argue existence of the gadgets.
</p></div>
    </summary>
    <updated>2020-04-21T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-04-21T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.09220</id>
    <link href="http://arxiv.org/abs/2004.09220" rel="alternate" type="text/html"/>
    <title>Parameterized Study of Steiner Tree on Unit Disk Graphs</title>
    <feedworld_mtime>1587427200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bhore:Sujoy.html">Sujoy Bhore</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Carmi:Paz.html">Paz Carmi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kolay:Sudeshna.html">Sudeshna Kolay</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zehavi:Meirav.html">Meirav Zehavi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.09220">PDF</a><br/><b>Abstract: </b>We study the Steiner Tree problem on unit disk graphs. Given a $n$ vertex
unit disk graph $G$, a subset $R\subseteq V(G)$ of $t$ vertices and a positive
integer $k$, the objective is to decide if there exists a tree $T$ in $G$ that
spans over all vertices of $R$ and uses at most $k$ vertices from $V\setminus
R$. The vertices of $R$ are referred to as terminals and the vertices of
$V(G)\setminus R$ as Steiner vertices. First, we show that the problem is
NP-Hard. Next, we prove that the Steiner Tree problem on unit disk graphs can
be solved in $n^{O(\sqrt{t+k})}$ time. We also show that the Steiner Tree
problem on unit disk graphs parameterized by $k$ has an FPT algorithm with
running time $2^{O(k)}n^{O(1)}$. In fact, the algorithms are designed for a
more general class of graphs, called clique-grid graphs. We mention that the
algorithmic results can be made to work for the Steiner Tree on disk graphs
with bounded aspect ratio. Finally, we prove that the Steiner Tree on disk
graphs parameterized by $k$ is W[1]-hard.
</p></div>
    </summary>
    <updated>2020-04-21T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-04-21T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.09163</id>
    <link href="http://arxiv.org/abs/2004.09163" rel="alternate" type="text/html"/>
    <title>Efficient Route Planning with Temporary Driving Bans, Road Closures, and Rated Parking Areas</title>
    <feedworld_mtime>1587427200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kleff:Alexander.html">Alexander Kleff</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schulz:Frank.html">Frank Schulz</a>, Jakob Wagenblatt, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zeitz:Tim.html">Tim Zeitz</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.09163">PDF</a><br/><b>Abstract: </b>We study the problem of planning routes in road networks when certain streets
or areas are closed at certain times. For heavy vehicles, such areas may be
very large since many European countries impose temporary driving bans during
the night or on weekends. In this setting, feasible routes may require waiting
at parking areas, and several feasible routes with different trade-offs between
waiting and driving detours around closed areas may exist. We propose a novel
model in which driving and waiting are assigned abstract costs, and waiting
costs are location-dependent to reflect the different quality of the parking
areas. Our goal is to find Pareto-optimal routes with regards to arrival time
at the destination and total cost. We investigate the complexity of the model
and determine a necessary constraint on the cost parameters such that the
problem is solvable in polynomial time. We present a thoroughly engineered
implementation and perform experiments on a production-grade real world data
set. The experiments show that our implementation can answer realistic queries
in around a second or less which makes it feasible for practical application.
</p></div>
    </summary>
    <updated>2020-04-21T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-21T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.09136</id>
    <link href="http://arxiv.org/abs/2004.09136" rel="alternate" type="text/html"/>
    <title>Robust and efficient tool path generation for poor-quality triangular mesh surface machining</title>
    <feedworld_mtime>1587427200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zou:Qiang.html">Qiang Zou</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.09136">PDF</a><br/><b>Abstract: </b>This paper presents a new method to generate iso-scallop tool paths for
triangular mesh surfaces. With the popularity of 3D scanning techniques,
scanning-derived mesh surfaces have seen a significant increase in their
application to machining. Quite often, such mesh surfaces exhibit defects such
as noises, which differentiate them from the good-quality mesh surfaces
previous research work focuses on. To generate tool paths for such poor-quality
mesh surfaces, the primary challenge lies in robustness against the defects. In
this work, a robust tool path generation method is proposed for poor-quality
mesh surfaces. In addition to robustness, the method is quite efficient,
providing the benefit of faster iterations and improved integration between
scanning and machining. The fundamental principle of the method is to convert
the tool path generation problem to the heat diffusion problem that has robust
and efficient algorithms available. The effectiveness of the method will be
demonstrated by a series of case studies and comparisons.
</p></div>
    </summary>
    <updated>2020-04-21T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-04-21T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.09129</id>
    <link href="http://arxiv.org/abs/2004.09129" rel="alternate" type="text/html"/>
    <title>Distributed Weighted Min-Cut in Nearly-Optimal Time</title>
    <feedworld_mtime>1587427200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dory:Michal.html">Michal Dory</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Efron:Yuval.html">Yuval Efron</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mukhopadhyay:Sagnik.html">Sagnik Mukhopadhyay</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nanongkai:Danupon.html">Danupon Nanongkai</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.09129">PDF</a><br/><b>Abstract: </b>Minimum-weight cut (min-cut) is a basic measure of a network's connectivity
strength. While the min-cut can be computed efficiently in the sequential
setting [Karger STOC'96], there was no efficient way for a distributed network
to compute its own min-cut without limiting the input structure or dropping the
output quality: In the standard CONGEST model, existing algorithms with
nearly-optimal time (e.g. [Ghaffari, Kuhn, DISC'13; Nanongkai, Su, DISC'14])
can guarantee a solution that is $(1+\epsilon)$-approximation at best while the
exact $\tilde O(n^{0.8}D^{0.2} + n^{0.9})$-time algorithm [Ghaffari, Nowicki,
Thorup, SODA'20] works only on $\textit{simple}$ networks (no weights and no
parallel edges). Throughout, $n$ and $D$ denote the network's number of
vertices and hop-diameter, respectively. For the weighted case, the best bound
was $\tilde O(n)$ [Daga et al. STOC'19].
</p>
<p>In this paper, we provide an $\textit{exact}$ $\tilde O(\sqrt n + D)$-time
algorithm for computing min-cut on $\textit{weighted}$ networks. Our result
improves even the previous algorithm that works only on simple networks. Its
time complexity matches the known lower bound up to polylogarithmic factors. At
the heart of our algorithm are a combination of two kinds of
tree-decompositions and a novel structural theorem that generalizes a theorem
in Mukhopadhyay-Nanongkai [STOC'20] and, in turn, helps simplify their
algorithms.
</p></div>
    </summary>
    <updated>2020-04-21T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-21T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.09099</id>
    <link href="http://arxiv.org/abs/2004.09099" rel="alternate" type="text/html"/>
    <title>Dynamic Matching Algorithms in Practice</title>
    <feedworld_mtime>1587427200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Henzinger:Monika.html">Monika Henzinger</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Khan:Shahbaz.html">Shahbaz Khan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Paul:Richard.html">Richard Paul</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schulz:Christian.html">Christian Schulz</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.09099">PDF</a><br/><b>Abstract: </b>In recent years, significant advances have been made in the design and
analysis of fully dynamic maximal matching algorithms. However, these
theoretical results have received very little attention from the practical
perspective. Few of the algorithms are implemented and tested on real datasets,
and their practical potential is far from understood. In this paper, we attempt
to bridge the gap between theory and practice that is currently observed for
the fully dynamic maximal matching problem. We engineer several algorithms and
empirically study those algorithms on an extensive set of dynamic instances.
</p></div>
    </summary>
    <updated>2020-04-21T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-21T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.09083</id>
    <link href="http://arxiv.org/abs/2004.09083" rel="alternate" type="text/html"/>
    <title>Rapid Mixing of Glauber Dynamics up to Uniqueness via Contraction</title>
    <feedworld_mtime>1587427200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Zongchen.html">Zongchen Chen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liu:Kuikui.html">Kuikui Liu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vigoda:Eric.html">Eric Vigoda</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.09083">PDF</a><br/><b>Abstract: </b>For general antiferromagnetic 2-spin systems, including the hardcore model
and the antiferromagnetic Ising model, there is an $\mathsf{FPTAS}$ for the
partition function on graphs of maximum degree $\Delta$ when the infinite
regular tree lies in the uniqueness region by Li et al. (2013). Moreover, in
the tree non-uniqueness region, Sly (2010) showed that there is no
$\mathsf{FPRAS}$ to estimate the partition function unless
$\mathsf{NP}=\mathsf{RP}$. The algorithmic results follow from the correlation
decay approach due to Weitz (2006) or the polynomial interpolation approach
developed by Barvinok (2016). However the running time is only polynomial for
constant $\Delta$. For the hardcore model, recent work of Anari et al. (2020)
establishes rapid mixing of the simple single-site Markov chain known as the
Glauber dynamics in the tree uniqueness region. Our work simplifies their
analysis of the Glauber dynamics by considering the total pairwise influence of
a fixed vertex $v$ on other vertices, as opposed to the total influence on $v$,
thereby extending their work to all 2-spin models and improving the mixing
time.
</p>
<p>More importantly our proof ties together the three disparate algorithmic
approaches: we show that contraction of the tree recursions with a suitable
potential function, which is the primary technique for establishing efficiency
of Weitz's correlation decay approach and Barvinok's polynomial interpolation
approach, also establishes rapid mixing of the Glauber dynamics. We emphasize
that this connection holds for all 2-spin models (both antiferromagnetic and
ferromagnetic), and existing proofs for correlation decay or polynomial
interpolation immediately imply rapid mixing of Glauber dynamics. Our proof
utilizes that the graph partition function divides that of Weitz's
self-avoiding walk trees, leading to new tools for analyzing influence of
vertices.
</p></div>
    </summary>
    <updated>2020-04-21T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-21T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.09079</id>
    <link href="http://arxiv.org/abs/2004.09079" rel="alternate" type="text/html"/>
    <title>Isotropy and Log-Concave Polynomials: Accelerated Sampling and High-Precision Counting of Matroid Bases</title>
    <feedworld_mtime>1587427200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Anari:Nima.html">Nima Anari</a>, Michał Dereziński <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.09079">PDF</a><br/><b>Abstract: </b>We define a notion of isotropy for discrete set distributions. If $\mu$ is a
distribution over subsets $S$ of a ground set $[n]$, we say that $\mu$ is in
isotropic position if $P[e \in S]$ is the same for all $e\in [n]$. We design a
new approximate sampling algorithm that leverages isotropy for the class of
distributions $\mu$ that have a log-concave generating polynomial; this class
includes determinantal point processes, strongly Rayleigh distributions, and
uniform distributions over matroid bases. We show that when $\mu$ is in
approximately isotropic position, the running time of our algorithm depends
polynomially on the size of the set $S$, and only logarithmically on $n$. When
$n$ is much larger than the size of $S$, this is significantly faster than
prior algorithms, and can even be sublinear in $n$. We then show how to
transform a non-isotropic $\mu$ into an equivalent approximately isotropic form
with a polynomial-time preprocessing step, accelerating subsequent sampling
times. The main new ingredient enabling our algorithms is a class of negative
dependence inequalities that may be of independent interest.
</p>
<p>As an application of our results, we show how to approximately count bases of
a matroid of rank $k$ over a ground set of $n$ elements to within a factor of
$1+\epsilon$ in time $ O((n+1/\epsilon^2)\cdot poly(k, \log n))$. This is the
first algorithm that runs in nearly linear time for fixed rank $k$, and
achieves an inverse polynomially low approximation error.
</p></div>
    </summary>
    <updated>2020-04-21T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-21T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.09051</id>
    <link href="http://arxiv.org/abs/2004.09051" rel="alternate" type="text/html"/>
    <title>Black-White Array: A New Data Structure for Dynamic Data Sets</title>
    <feedworld_mtime>1587427200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mou:Z=_George.html">Z. George Mou</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.09051">PDF</a><br/><b>Abstract: </b>A new array based data structure named black-white array (BWA) is introduced
as an effective and efficient alternative to the list or tree based data
structures for dynamic data set. It consists of two sub-arrays, one white and
one black of half of the size of the white. Both of them are conceptually
partitioned into segments of different ranks with the sizes grow in geometric
sequence. The layout of BWA allows easy calculation of the meta-data about the
segments, which are used extensively in the algorithms for the basic operations
of the dynamic sets. The insertion of a sequence of unordered numbers into BWA
takes amortized time logarithmic to the length of the sequence. It is also
proven that when the searched or deleted value is present in the BWA, the
asymptotic amortized cost for the operations is O(log(n)); otherwise, the time
will fall somewhere between O(log(n)) and O(log^2(n)). It is shown that the
state variable total, which records the number of values in the BWA captures
the dynamics of state transition of BWA. This fact is exploited to produce
concise, easy- to-understand, and efficient coding for the operations. As it
uses arrays as the underlying structure for dynamic set, a BWA need neither the
space to store the pointers referencing other data nodes nor the time to chase
the pointers as with any linked data structures. A C++ implementation of the
BWA is completed. The performance data were gathered and plotted, which
confirmed the theoretic analysis. The testing results showed that the amortized
time for the insert, search, and delete operations is all just between 105.949
and 5720.49 nanoseconds for BWAs of sizes ranging from 210 to 229 under various
conditions.
</p></div>
    </summary>
    <updated>2020-04-21T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-21T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.09002</id>
    <link href="http://arxiv.org/abs/2004.09002" rel="alternate" type="text/html"/>
    <title>The Quantum Approximate Optimization Algorithm Needs to See the Whole Graph: A Typical Case</title>
    <feedworld_mtime>1587427200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Farhi:Edward.html">Edward Farhi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gamarnik:David.html">David Gamarnik</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gutmann:Sam.html">Sam Gutmann</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.09002">PDF</a><br/><b>Abstract: </b>The Quantum Approximate Optimization Algorithm can naturally be applied to
combinatorial search problems on graphs. The quantum circuit has p applications
of a unitary operator that respects the locality of the graph. On a graph with
bounded degree, with p small enough, measurements of distant qubits in the
state output by the QAOA give uncorrelated results. We focus on finding big
independent sets in random graphs with dn/2 edges keeping d fixed and n large.
Using the Overlap Gap Property of almost optimal independent sets in random
graphs, and the locality of the QAOA, we are able to show that if p is less
than a d-dependent constant times log n, the QAOA cannot do better than finding
an independent set of size .854 times the optimal for d large. Because the
logarithm is slowly growing, even at one million qubits we can only show that
the algorithm is blocked if p is in single digits. At higher p the algorithm
"sees" the whole graph and we have no indication that performance is limited.
</p></div>
    </summary>
    <updated>2020-04-21T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-04-21T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.08993</id>
    <link href="http://arxiv.org/abs/2004.08993" rel="alternate" type="text/html"/>
    <title>Summarizing Diverging String Sequences, with Applications to Chain-Letter Petitions</title>
    <feedworld_mtime>1587427200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Patty Commins, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liben=Nowell:David.html">David Liben-Nowell</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liu:Tina.html">Tina Liu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tomlinson:Kiran.html">Kiran Tomlinson</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.08993">PDF</a><br/><b>Abstract: </b>Algorithms to find optimal alignments among strings, or to find a
parsimonious summary of a collection of strings, are well studied in a variety
of contexts, addressing a wide range of interesting applications. In this
paper, we consider chain letters, which contain a growing sequence of
signatories added as the letter propagates. The unusual constellation of
features exhibited by chain letters (one-ended growth, divergence, and
mutation) make their propagation, and thus the corresponding reconstruction
problem, both distinctive and rich. Here, inspired by these chain letters, we
formally define the problem of computing an optimal summary of a set of
diverging string sequences. From a collection of these sequences of names, with
each sequence noisily corresponding to a branch of the unknown tree $T$
representing the letter's true dissemination, can we efficiently and accurately
reconstruct a tree $T' \approx T$? In this paper, we give efficient exact
algorithms for this summarization problem when the number of sequences is
small; for larger sets of sequences, we prove hardness and provide an efficient
heuristic algorithm. We evaluate this heuristic on synthetic data sets chosen
to emulate real chain letters, showing that our algorithm is competitive with
or better than previous approaches, and that it also comes close to finding the
true trees in these synthetic datasets.
</p></div>
    </summary>
    <updated>2020-04-21T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-21T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.08949</id>
    <link href="http://arxiv.org/abs/2004.08949" rel="alternate" type="text/html"/>
    <title>Quantum algorithms for computational geometry problems</title>
    <feedworld_mtime>1587427200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Ambainis:Andris.html">Andris Ambainis</a>, Nikita Larka <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.08949">PDF</a><br/><b>Abstract: </b>We study quantum algorithms for problems in computational geometry, such as
POINT-ON-3-LINES problem. In this problem, we are given a set of lines and we
are asked to find a point that lies on at least $3$ of these lines.
POINT-ON-3-LINES and many other computational geometry problems are known to be
3SUM-HARD. That is, solving them classically requires time
$\Omega(n^{2-o(1)})$, unless there is faster algorithm for the well known 3SUM
problem (in which we are given a set $S$ of $n$ integers and have to determine
if there are $a, b, c \in S$ such that $a + b + c = 0$). Quantumly, 3SUM can be
solved in time $O(n \log n)$ using Grover's quantum search algorithm. This
leads to a question: can we solve POINT-ON-3-LINES and other 3SUM-HARD problems
in $O(n^c)$ time quantumly, for $c&lt;2$? We answer this question affirmatively,
by constructing a quantum algorithm that solves POINT-ON-3-LINES in time
$O(n^{1 + o(1)})$. The algorithm combines recursive use of amplitude
amplification with geometrical ideas. We show that the same ideas give $O(n^{1
+ o(1)})$ time algorithm for many 3SUM-HARD geometrical problems.
</p></div>
    </summary>
    <updated>2020-04-21T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-04-21T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.08854</id>
    <link href="http://arxiv.org/abs/2004.08854" rel="alternate" type="text/html"/>
    <title>Planar Bichromatic Bottleneck Spanning Trees</title>
    <feedworld_mtime>1587427200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Abu=Affash:A=_Karim.html">A. Karim Abu-Affash</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bhore:Sujoy.html">Sujoy Bhore</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Carmi:Paz.html">Paz Carmi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mitchell:Joseph_S=_B=.html">Joseph S. B. Mitchell</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.08854">PDF</a><br/><b>Abstract: </b>Given a set $P$ of $n$ red and blue points in the plane, a \emph{planar
bichromatic spanning tree} of $P$ is a spanning tree of $P$, such that each
edge connects between a red and a blue point, and no two edges intersect. In
the bottleneck planar bichromatic spanning tree problem, the goal is to find a
planar bichromatic spanning tree $T$, such that the length of the longest edge
in $T$ is minimized. In this paper, we show that this problem is NP-hard for
points in general position. Moreover, we present a polynomial-time
$(8\sqrt{2})$-approximation algorithm, by showing that any bichromatic spanning
tree of bottleneck $\lambda$ can be converted to a planar bichromatic spanning
tree of bottleneck at most $8\sqrt{2}\lambda$.
</p></div>
    </summary>
    <updated>2020-04-21T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-04-21T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.08828</id>
    <link href="http://arxiv.org/abs/2004.08828" rel="alternate" type="text/html"/>
    <title>Faster Algorithms for Quantitative Analysis of Markov Chains and Markov Decision Processes with Small Treewidth</title>
    <feedworld_mtime>1587427200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Asadi:Ali.html">Ali Asadi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chatterjee:Krishnendu.html">Krishnendu Chatterjee</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Goharshady:Amir_Kafshdar.html">Amir Kafshdar Goharshady</a>, Kiarash Mohammadi, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pavlogiannis:Andreas.html">Andreas Pavlogiannis</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.08828">PDF</a><br/><b>Abstract: </b>Discrete-time Markov Chains (MCs) and Markov Decision Processes (MDPs) are
two standard formalisms in system analysis. Their main associated quantitative
objectives are hitting probabilities, discounted sum, and mean payoff. Although
there are many techniques for computing these objectives in general MCs/MDPs,
they have not been thoroughly studied in terms of parameterized algorithms,
particularly when treewidth is used as the parameter. This is in sharp contrast
to qualitative objectives for MCs, MDPs and graph games, for which
treewidth-based algorithms yield significant complexity improvements.
</p>
<p>In this work, we show that treewidth can also be used to obtain faster
algorithms for the quantitative problems. For an MC with $n$ states and $m$
transitions, we show that each of the classical quantitative objectives can be
computed in $O((n+m)\cdot t^2)$ time, given a tree decomposition of the MC that
has width $t$. Our results also imply a bound of $O(\kappa\cdot (n+m)\cdot
t^2)$ for each objective on MDPs, where $\kappa$ is the number of
strategy-iteration refinements required for the given input and objective.
Finally, we make an experimental evaluation of our new algorithms on
low-treewidth MCs and MDPs obtained from the DaCapo benchmark suite. Our
experimental results show that on MCs and MDPs with small treewidth, our
algorithms outperform existing well-established methods by one or more orders
of magnitude.
</p></div>
    </summary>
    <updated>2020-04-21T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-21T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.08818</id>
    <link href="http://arxiv.org/abs/2004.08818" rel="alternate" type="text/html"/>
    <title>Preprocessing Vertex-Deletion Problems: Characterizing Graph Properties by Low-Rank Adjacencies</title>
    <feedworld_mtime>1587427200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jansen:Bart_M=_P=.html">Bart M. P. Jansen</a>, Jari J. H. de Kroon <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.08818">PDF</a><br/><b>Abstract: </b>We consider the $\Pi$-free Deletion problem parameterized by the size of a
vertex cover, for a range of graph properties $\Pi$. Given an input graph $G$,
this problem asks whether there is a subset of at most $k$ vertices whose
removal ensures the resulting graph does not contain a graph from $\Pi$ as
induced subgraph. Many vertex-deletion problems such as Perfect Deletion,
Wheel-free Deletion, and Interval Deletion fit into this framework. We
introduce the concept of characterizing a graph property $\Pi$ by low-rank
adjacencies, and use it as the cornerstone of a general kernelization theorem
for $\Pi$-Free Deletion parameterized by the size of a vertex cover. The
resulting framework captures problems such as AT-Free Deletion, Wheel-free
Deletion, and Interval Deletion. Moreover, our new framework shows that the
vertex-deletion problem to perfect graphs has a polynomial kernel when
parameterized by vertex cover, thereby resolving an open question by Fomin et
al. [JCSS 2014]. Our main technical contribution shows how linear-algebraic
dependence of suitably defined vectors over $\mathbb{F}_2$ implies
graph-theoretic statements about the presence of forbidden induced subgraphs.
</p></div>
    </summary>
    <updated>2020-04-21T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-21T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.08783</id>
    <link href="http://arxiv.org/abs/2004.08783" rel="alternate" type="text/html"/>
    <title>Decision Problems in Information Theory</title>
    <feedworld_mtime>1587427200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Khamis:Mahmoud_Abo.html">Mahmoud Abo Khamis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kolaitis:Phokion_G=.html">Phokion G. Kolaitis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Ngo:Hung_Q=.html">Hung Q. Ngo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Suciu:Dan.html">Dan Suciu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.08783">PDF</a><br/><b>Abstract: </b>Constraints on entropies are considered to be the laws of information theory.
Even though the pursuit of their discovery has been a central theme of research
in information theory, the algorithmic aspects of constraints on entropies
remain largely unexplored. Here, we initiate an investigation of decision
problems about constraints on entropies by placing several different such
problems into levels of the arithmetical hierarchy. We establish the following
results on checking the validity over all almost-entropic functions: first,
validity of a Boolean information constraint arising from a monotone Boolean
formula is co-recursively enumerable; second, validity of "tight" conditional
information constraints is in $\Pi^0_3$. Furthermore, under some restrictions,
validity of conditional information constraints "with slack" is in
$\Sigma^0_2$, and validity of information inequality constraints involving max
is Turing equivalent to validity of information inequality constraints (with no
max involved). We also prove that the classical implication problem for
conditional independence statements is co-recursively enumerable.
</p></div>
    </summary>
    <updated>2020-04-21T23:23:03Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-04-21T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.08777</id>
    <link href="http://arxiv.org/abs/2004.08777" rel="alternate" type="text/html"/>
    <title>Faster Dynamic Range Mode</title>
    <feedworld_mtime>1587427200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sandlund:Bryce.html">Bryce Sandlund</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/x/Xu:Yinzhan.html">Yinzhan Xu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.08777">PDF</a><br/><b>Abstract: </b>In the dynamic range mode problem, we are given a sequence $a$ of length
bounded by $N$ and asked to support element insertion, deletion, and queries
for the most frequent element of a contiguous subsequence of $a$. In this work,
we devise a deterministic data structure that handles each operation in
worst-case $\tilde{O}(N^{0.655994})$ time, thus breaking the $O(N^{2/3})$
per-operation time barrier for this problem. The data structure is achieved by
combining the ideas in Williams and Xu (SODA 2020) for batch range mode with a
novel data structure variant of the Min-Plus product.
</p></div>
    </summary>
    <updated>2020-04-21T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-21T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.08716</id>
    <link href="http://arxiv.org/abs/2004.08716" rel="alternate" type="text/html"/>
    <title>Fewer colors for perfect simulation of proper colorings</title>
    <feedworld_mtime>1587427200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Huber:Mark.html">Mark Huber</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.08716">PDF</a><br/><b>Abstract: </b>Given a graph $G$ and color set $\{1, \ldots, k\}$, a $\textit{proper
coloring}$ is an assignment of a color to each vertex of $G$ such that no two
vertices connected by an edge are given the same color. The problem of drawing
a proper coloring exactly uniformly from the set of proper colorings is
well-studied. Most recently, Bhandari and Chakraborty developed a polynomial
expected time randomized algorithm for obtaining such draws when $k &gt; 3\Delta$,
where $\Delta$ is the maximum degree of the graph. Their approach used a
bounding chain together with the coupling from the past protocol. Here a new
randomized algorithm is presented based upon the randomness recycler protocol
introduced by the author and Fill at FOCS 2000. Given $n$ vertices, this method
takes $O(n \ln (n))$ expected steps when $k &gt; 2.27(\Delta - 1)$ for all $\Delta
\geq 2$.
</p></div>
    </summary>
    <updated>2020-04-21T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-04-21T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.08703</id>
    <link href="http://arxiv.org/abs/2004.08703" rel="alternate" type="text/html"/>
    <title>Stochastic Weighted Matching: $(1-\epsilon)$ Approximation</title>
    <feedworld_mtime>1587427200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Behnezhad:Soheil.html">Soheil Behnezhad</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Derakhshan:Mahsa.html">Mahsa Derakhshan</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.08703">PDF</a><br/><b>Abstract: </b>Let $G=(V, E)$ be a given edge-weighted graph and let its {\em realization}
$\mathcal{G}$ be a random subgraph of $G$ that includes each edge $e \in E$
independently with probability $p$. In the {\em stochastic matching} problem,
the goal is to pick a sparse subgraph $Q$ of $G$ without knowing the
realization $\mathcal{G}$, such that the maximum weight matching among the
realized edges of $Q$ (i.e. graph $Q \cap \mathcal{G}$) in expectation
approximates the maximum weight matching of the whole realization
$\mathcal{G}$.
</p>
<p>In this paper, we prove that for any desirably small $\epsilon \in (0, 1)$,
every graph $G$ has a subgraph $Q$ that guarantees a
$(1-\epsilon)$-approximation and has maximum degree only $O_{\epsilon, p}(1)$.
That is, the maximum degree of $Q$ depends only on $\epsilon$ and $p$ (both of
which are known to be necessary) and not for example on the number of nodes in
$G$, the edge-weights, etc.
</p>
<p>The stochastic matching problem has been studied extensively on both weighted
and unweighted graphs. Previously, only existence of (close to)
half-approximate subgraphs was known for weighted graphs [Yamaguchi and
Maehara, SODA'18; Behnezhad et al., SODA'19]. Our result substantially improves
over these works, matches the state-of-the-art for unweighted graphs [Behnezhad
et al., STOC'20], and essentially settles the approximation factor.
</p></div>
    </summary>
    <updated>2020-04-21T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-21T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.08681</id>
    <link href="http://arxiv.org/abs/2004.08681" rel="alternate" type="text/html"/>
    <title>Effective gaps are not effective: quasipolynomial classical simulation of obstructed stoquastic Hamiltonians</title>
    <feedworld_mtime>1587427200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Jacob Bringewatt, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jarret:Michael.html">Michael Jarret</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.08681">PDF</a><br/><b>Abstract: </b>All known examples confirming the possibility of an exponential separation
between classical simulation algorithms and stoquastic adiabatic quantum
computing (AQC) exploit symmetries that constrain adiabatic dynamics to
effective, symmetric subspaces. The symmetries produce large effective
eigenvalue gaps, which in turn make adiabatic computation efficient. We present
a classical algorithm to efficiently sample from the effective subspace of a
$k$-local stoquastic Hamiltonian $H$, without a priori knowledge of its
symmetries (or near-symmetries). Our algorithm maps any $k$-local Hamiltonian
to a graph $G=(V,E)$ with $\lvert V \rvert = O\left(\mathrm{poly}(n)\right)$
where $n$ is the number of qubits. Given the well-known result of Babai, we
exploit graph isomorphism to study the automorphisms of $G$ and arrive at an
algorithm quasi-polynomial in $\lvert V\rvert$ for producing samples from the
effective subspace eigenstates of $H$. Our results rule out exponential
separations between stoquastic AQC and classical computation that arise from
hidden symmetries in $k$-local Hamiltonians. Furthermore, our graph
representation of $H$ is not limited to stoquastic Hamiltonians and may rule
out corresponding obstructions in non-stoquastic cases, or be useful in
studying additional properties of $k$-local Hamiltonians.
</p></div>
    </summary>
    <updated>2020-04-21T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-21T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.08634</id>
    <link href="http://arxiv.org/abs/2004.08634" rel="alternate" type="text/html"/>
    <title>A Strongly Polynomial Label-Correcting Algorithm for Linear Systems with Two Variables per Inequality</title>
    <feedworld_mtime>1587427200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Koh:Zhuan_Khye.html">Zhuan Khye Koh</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Natura:Bento.html">Bento Natura</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/V=eacute=gh:L=aacute=szl=oacute=_A=.html">László A. Végh</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.08634">PDF</a><br/><b>Abstract: </b>We present a strongly polynomial label-correcting algorithm for solving the
feasibility of linear systems with two variables per inequality (2VPI). The
algorithm is based on the Newton-Dinkelbach method for fractional combinatorial
optimization. We extend and strengthen previous work of Madani (2002) that
showed a weakly polynomial bound for a variant of the Newton-Dinkelbach method
for solving deterministic Markov decision processes (DMDPs), a special class of
2VPI linear programs. For a 2VPI system with $n$ variables and $m$ constraints,
our algorithm runs in $O(mn)$ iterations. Every iteration takes $O(m + n\log
n)$ time for DMDPs, and $O(mn)$ time for general 2VPI systems.
</p>
<p>The key technical idea is a new analysis of the Newton-Dinkelbach method
exploiting gauge symmetries of the algorithm. This also leads to an
acceleration of the Newton-Dinkelbach method for general fractional
combinatorial optimization problems. For the special case of linear fractional
combinatorial optimization, our method converges in $O(m\log m)$ iterations,
improving upon the previous best bound of $O(m^2\log m)$ by Wang et al. (2006).
</p></div>
    </summary>
    <updated>2020-04-21T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-21T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.08604</id>
    <link href="http://arxiv.org/abs/2004.08604" rel="alternate" type="text/html"/>
    <title>UDDSketch: Accurate Tracking of Quantiles in Data Streams</title>
    <feedworld_mtime>1587427200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Epicoco:Italo.html">Italo Epicoco</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Melle:Catiuscia.html">Catiuscia Melle</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cafaro:Massimo.html">Massimo Cafaro</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pulimeno:Marco.html">Marco Pulimeno</a>, Giuseppe Morleo <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.08604">PDF</a><br/><b>Abstract: </b>We present UDDSketch (Uniform DDSketch), a novel sketch for fast and accurate
tracking of quantiles in data streams. This sketch is heavily inspired by the
recently introduced DDSketch, and is based on a novel bucket collapsing
procedure that allows overcoming the intrinsic limits of the corresponding
DDSketch procedures. Indeed, the DDSketch bucket collapsing procedure does not
allow the derivation of formal guarantees on the accuracy of quantile
estimation for data which does not follow a sub-exponential distribution. On
the contrary, UDDSketch is designed so that accuracy guarantees can be given
over the full range of quantiles and for arbitrary distribution in input.
Moreover, our algorithm fully exploits the budgeted memory adaptively in order
to guarantee the best possible accuracy over the full range of quantiles.
Extensive experimental results on synthetic datasets confirm the validity of
our approach.
</p></div>
    </summary>
    <updated>2020-04-21T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-21T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.08454</id>
    <link href="http://arxiv.org/abs/2004.08454" rel="alternate" type="text/html"/>
    <title>Counterexamples to the Low-Degree Conjecture</title>
    <feedworld_mtime>1587427200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Holmgren:Justin.html">Justin Holmgren</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wein:Alexander_S=.html">Alexander S. Wein</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.08454">PDF</a><br/><b>Abstract: </b>A conjecture of Hopkins (2018) posits that for certain high-dimensional
hypothesis testing problems, no polynomial-time algorithm can outperform
so-called "simple statistics", which are low-degree polynomials in the data.
This conjecture formalizes the beliefs surrounding a line of recent work that
seeks to understand statistical-versus-computational tradeoffs via the
low-degree likelihood ratio. In this work, we refute the conjecture of Hopkins.
However, our counterexample crucially exploits the specifics of the noise
operator used in the conjecture, and we point out a simple way to modify the
conjecture to rule out our counterexample. We also give an example illustrating
that (even after the above modification), the symmetry assumption in the
conjecture is necessary. These results do not undermine the low-degree
framework for computational lower bounds, but rather aim to better understand
what class of problems it is applicable to.
</p></div>
    </summary>
    <updated>2020-04-21T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-21T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.08444</id>
    <link href="http://arxiv.org/abs/2004.08444" rel="alternate" type="text/html"/>
    <title>On the Approximate Nearest Neighbor Queries among Curves under the Fr\'echet Distance</title>
    <feedworld_mtime>1587427200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mirzanezhad:Majid.html">Majid Mirzanezhad</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.08444">PDF</a><br/><b>Abstract: </b>Approximate nearest neighbor search (\textsc{ANNS}) is a long-studied problem
in computational geometry that has received considerable attentions by
researchers in the community. In this paper, we revisit the problem in the
presence of curves under the Fr\'echet distance. Given a set ${\cal P}$ of $n$
curves of size at most $m$ each in $\mathbb{R}^d$ and a real $\delta&gt;0$, we aim
to preprocess ${\cal P}$ into a data structure so that for any given query
curve $Q$ of size $k$, report all curves in ${\cal P}$ whose Fr\'echet
distances to $Q$ are at most $\delta$. In case that $k$ is known in the
preprocessing stage we propose a fully deterministic data structure whose space
is $O(n({32d^{1/2}/\varepsilon^3})^{d(k+1)} )$ and can answer the
\textsc{$(1+\varepsilon)\delta$-ANNS} queries in $O(kd)$ query time.
Considering $k$ as part of the query slightly changes the space to $O(
n({64d^{1/2}/\varepsilon^3})^{md} )$ with $O(kd)$ query time within
$5(1+\varepsilon)$ approximation factor. We also show that our data structure
could give an alternative treatment of the approximate subtrajectory range
counting (\textsc{ASRC}) problem studied by de Berg et al.~\cite{bcg-ffq-13}.
</p></div>
    </summary>
    <updated>2020-04-21T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-04-21T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.08434</id>
    <link href="http://arxiv.org/abs/2004.08434" rel="alternate" type="text/html"/>
    <title>Projection-Cost-Preserving Sketches: Proof Strategies and Constructions</title>
    <feedworld_mtime>1587427200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Musco:Cameron.html">Cameron Musco</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Musco:Christopher.html">Christopher Musco</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.08434">PDF</a><br/><b>Abstract: </b>In this note we illustrate how common matrix approximation methods, such as
random projection and random sampling, yield projection-cost-preserving
sketches, as introduced in [FSS13, CEM+15]. A projection-cost-preserving sketch
is a matrix approximation which, for a given parameter $k$, approximately
preserves the distance of the target matrix to all $k$-dimensional subspaces.
Such sketches have applications to scalable algorithms for linear algebra, data
science, and machine learning. Our goal is to simplify the presentation of
proof techniques introduced in [CEM+15] and [CMM17] so that they can serve as a
guide for future work. We also refer the reader to [CYD19], which gives a
similar simplified exposition of the proof covered in Section 2.
</p></div>
    </summary>
    <updated>2020-04-21T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-21T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.08432</id>
    <link href="http://arxiv.org/abs/2004.08432" rel="alternate" type="text/html"/>
    <title>Fully-Dynamic Graph Sparsifiers Against an Adaptive Adversary</title>
    <feedworld_mtime>1587427200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bernstein:Aaron.html">Aaron Bernstein</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Brand:Jan_van_den.html">Jan van den Brand</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gutenberg:Maximilian_Probst.html">Maximilian Probst Gutenberg</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nanongkai:Danupon.html">Danupon Nanongkai</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Saranurak:Thatchaphol.html">Thatchaphol Saranurak</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sidford:Aaron.html">Aaron Sidford</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sun:He.html">He Sun</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.08432">PDF</a><br/><b>Abstract: </b>Designing dynamic graph algorithms against an adaptive adversary is a major
goal in the field of dynamic graph algorithms. While a few such algorithms are
known for spanning trees, matchings, and single-source shortest paths, very
little was known for an important primitive like graph sparsifiers. The
challenge is how to approximately preserve so much information about the graph
(e.g., all-pairs distances and all cuts) without revealing the algorithms'
underlying randomness to the adaptive adversary.
</p>
<p>In this paper we present the first non-trivial efficient adaptive algorithms
for maintaining spanners and cut sparisifers. These algorithms in turn imply
improvements over existing algorithms for other problems. Our first algorithm
maintains a polylog$(n)$-spanner of size $\tilde{O}(n)$ in polylog$(n)$
amortized update time. The second algorithm maintains an $O(k)$-approximate cut
sparsifier of size $\tilde{O}(n)$ in $\tilde{O}(n^{1/k})$ amortized update
time, for any $k\ge1$, which is polylog$(n)$ time when $k=\log(n)$. The
amortized update time of both algorithms can be made worst-case by paying some
sub-polynomial factors. Prior to our result, there were near-optimal algorithms
against oblivious adversaries (e.g. Baswana et al. [TALG'12] and Abraham et al.
[FOCS'16]), but the only non-trivial adaptive dynamic algorithm requires $O(n)$
amortized update time to maintain $3$- and $5$-spanner of size $O(n^{1+1/2})$
and $O(n^{1+1/3})$, respectively [Ausiello et al. ESA'05].
</p>
<p>Our results are based on two novel techniques. First of all, we show a
generic black-box reduction that allows us to assume that the graph undergoes
only edge deletions and, more importantly, remains an expander with
almost-uniform degree. The second is a new technique called proactive
resampling. [Abstract was shortened]
</p></div>
    </summary>
    <updated>2020-04-21T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-21T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.08381</id>
    <link href="http://arxiv.org/abs/2004.08381" rel="alternate" type="text/html"/>
    <title>Enumerating Chemical Graphs with Two Disjoint Cycles Satisfying Given Path Frequency Specifications</title>
    <feedworld_mtime>1587427200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yamashita:Kyousuke.html">Kyousuke Yamashita</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Masui:Ryuji.html">Ryuji Masui</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhou:Xiang.html">Xiang Zhou</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Chenxi.html">Chenxi Wang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shurbevski:Aleksandar.html">Aleksandar Shurbevski</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nagamochi:Hiroshi.html">Hiroshi Nagamochi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Akutsu:Tatsuya.html">Tatsuya Akutsu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.08381">PDF</a><br/><b>Abstract: </b>Enumerating chemical graphs satisfying given constraints is a fundamental
problem in mathematical and computational chemistry, and plays an essential
part in a recently proposed framework for the inverse QSAR/QSPR. In this paper,
constraints are given by feature vectors each of which consists of the
frequencies of paths in a given set of paths. We consider the problem of
enumerating chemical graphs that satisfy the path frequency constraints, which
are given by a pair of feature vectors specifying upper and lower bounds of the
frequency of each path. We design a branch-and-bound algorithm for enumerating
chemical graphs of bi-block 2-augmented structure, that is, graphs that contain
two edge-disjoint cycles. We present some computational experiments with an
implementation of our proposed algorithm.
</p></div>
    </summary>
    <updated>2020-04-21T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-21T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4768</id>
    <link href="https://www.scottaaronson.com/blog/?p=4768" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4768#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4768" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">AirToAll: Another guest post by Steve Ebin</title>
    <summary xml:lang="en-US">Scott’s foreword: Today I’m honored to host another guest post by friend-of-the-blog Steve Ebin, who not only published a beautiful essay here a month ago (the one that I titled “First it came from Wuhan”), but also posted an extremely informative timeline of what he understood when about the severity of the covid crisis, from […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p><strong><span class="has-inline-color has-vivid-red-color">Scott’s foreword:</span></strong> Today I’m honored to host another guest post by friend-of-the-blog Steve Ebin, who not only published a <a href="https://www.scottaaronson.com/blog/?p=4675">beautiful essay</a> here a month ago (the one that I titled “First it came from Wuhan”), but also posted an extremely informative <a href="https://www.scottaaronson.com/blog/?p=4695#comment-1834991">timeline</a> of what he understood when about the severity of the covid crisis, from early January until March 31st.  By the latter date, Steve had quit his job, having made a hefty sum shorting airline stocks, and was devoting his full time to a new nonprofit to manufacture low-cost ventilators, called AirToCall.  A couple weeks ago, Steve was kind enough to include me in one of AirToAll’s regular Zoom meetings; I learned more about pistons than I had in my entire previous life (admittedly, still not much).  Which brings me to what Steve wants to talk about today: what he and others are doing and how <em>you</em> can help.</p>



<p><strong><span class="has-inline-color has-vivid-red-color">Without further ado, Steve’s guest post:</span></strong></p>



<p>In my <a href="https://www.scottaaronson.com/blog/?p=4675">last essay</a> on Coronavirus, I argued that Coronavirus will radically change society.  In this blog post, I’d like to propose a structure for how we can organize to fight the virus.  I will also make a call to action for readers of this blog to help a non-profit I co-founded, <a href="http://airtoall.org">AirToAll</a>, build safe, low-cost ventilators and other medical devices and distribute them across the world at scale.</p>



<p>There are four ways we can help fight coronavirus:</p>



<ol><li><strong>Reduce exposure to the virus. </strong>Examples: learn where the virus is through better testing; attempt to be where the virus isn’t through social distancing, quarantining, and other means.</li><li><strong>Reduce the chance of exposure leading to infection.</strong> Examples: Wash your hands; avoid touching your face; wear personal protective equipment.</li><li><strong>Reduce the chance of infection leading to serious illness. </strong>Examples: improve your aerobic and pulmonary health; make it more difficult for coronavirus’s spike protein to bind to ACE-2 receptors; scale antibody therapies; consume adequate vitamin D; get more sleep; develop a vaccine.</li><li><strong>Reduce the chance of serious illness leading to death. </strong>Examples: ramp up the production and distribution of certain drugs; develop better drugs; build more ventilators; help healthcare workers.</li></ol>



<p>Obviously, not every example I listed is practical, advisable, or will work, and some options, like producing a vaccine, may be better solutions than others. But we must pursue all approaches.</p>



<p>I’ve been devoting my own time to pursuing the fourth approach, reducing the chance that the illness will lead to death.  Specifically, along with Neil Thanedar, I co-founded AirToAll, a nonprofit that helps bring low-cost, reliable, and clinically tested ventilators to market.  I know lots of groups are working on this problem, so I thought I’d talk about it briefly.</p>



<p>First, like many groups, we’re designing our own ventilators.  Although designing ventilators and bringing them to market at scale poses unique challenges, particularly in an environment where supply chains are strained, this is <em>much </em>easier than it must have been to build iron lungs in the early part of the 20th century, when Zoom conferencing wasn’t yet invented.  When it comes to the ventilators we’re producing, we’re focused on safety and clinical validation rather than speed to market.  We are not the farthest along here, but we’ve made good progress.</p>



<p>Second, our nonprofit is helping other groups produce safe and reliable ventilators by doing direct consultations with them and also by producing <a href="https://591654b2-a393-4da6-9d87-f168fb514898.filesusr.com/ugd/9fa1d3_9f8fa025b877468e91b8ba575c054815.pdf">whitepapers</a> to help them think through the issues at hand (h/t to Harvey Hawes, Abdullah Saleh, and our friends at <a href="https://icchange.ca/">ICChange</a>).</p>



<p>Third, we’re working to increase the manufacturing capacity for currently approved ventilators.</p>



<p>The current shortage of ventilators is a symptom of a greater underlying problem: namely, the world is not good at recognizing healthcare crises early and responding to them quickly.  While our nonprofit helps bring more ventilators to market, we are also trying to solve this greater underlying problem.  I look at our work in ventilator-land as a first step towards our ultimate goal of making medical devices cheaper and more available through an open-source nonprofit model.</p>



<p>I am writing this post as a call to action to you, dear <em>Shtetl-Optimized</em> reader, to get involved.</p>



<p>You don’t have to be an engineer, pulmonologist, virologist, or epidemiologist to help us, although those skillsets are of course helpful and if you are we’d love to have you.  If you have experience in data science and modeling, supply chain and manufacturing, public health, finance, operations, community management, or anything else a rapidly scaling organization needs, you can help us too. </p>



<p>We are a group of 700+ volunteers and growing rapidly.  If you’d like to help, we’d love to have you.  If you might be interested in volunteering, click <a href="https://airtoall.org/community/">here</a>.  Donors click <a href="https://airtoall.org/donate/">here</a>.  Everyone else, please email me at <a href="mailto:steven@airtoall.org">steven@airtoall.org</a> and include a clear subject line so I can direct you to the right person.</p></div>
    </content>
    <updated>2020-04-20T22:41:43Z</updated>
    <published>2020-04-20T22:41:43Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Announcements"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Nerd Interest"/>
    <category scheme="https://www.scottaaronson.com/blog" term="The Fate of Humanity"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2020-04-20T22:43:03Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2020/04/20/workshop-on-local-algorithms/</id>
    <link href="https://cstheory-events.org/2020/04/20/workshop-on-local-algorithms/" rel="alternate" type="text/html"/>
    <title>Workshop on Local Algorithms</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">July 20-21, 2020 Virtual (8am — 12pm Pacific Time) https://www.mit.edu/~mahabadi/workshops/WOLA-2020.html Submission deadline: May 15, 2020 Registration deadline: June 30, 2020 Due to the current situation with COVID-19, we have decided to hold a virtual and shorter version of WOLA this year. WOLA 2020 will run for two days between 8am – 12pm PT to maximize … <a class="more-link" href="https://cstheory-events.org/2020/04/20/workshop-on-local-algorithms/">Continue reading <span class="screen-reader-text">Workshop on Local Algorithms</span></a></div>
    </summary>
    <updated>2020-04-20T20:26:48Z</updated>
    <published>2020-04-20T20:26:48Z</published>
    <category term="workshop"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2020-04-22T00:21:22Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/053</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/053" rel="alternate" type="text/html"/>
    <title>TR20-053 |  Understanding the Relative Strength of QBF CDCL Solvers and QBF Resolution | 

	Benjamin Böhm, 

	Olaf Beyersdorff</title>
    <summary>QBF solvers implementing the QCDCL paradigm are powerful algorithms that
successfully tackle many computationally complex applications. However, our
theoretical understanding of the strength and limitations of these QCDCL
solvers is very limited.

In this paper we suggest to formally model QCDCL solvers as proof systems. We
define different policies that can be used for decision heuristics and unit
propagation and give rise to a number of sound and complete QBF proof systems
(and hence new QCDCL algorithms). With respect to the standard policies used
in practical QCDCL solving, we show that the corresponding QCDCL proof system
is incomparable (via exponential separations) to Q-resolution, the classical
QBF resolution system used in the literature. This is in stark contrast to the
propositional setting where CDCL and resolution are known to be p-equivalent.

This raises the question what formulas are hard for standard QCDCL, since
Q-resolution lower bounds do not necessarily apply to QCDCL as we show here.
In answer to this question we prove several lower bounds for QCDCL, including
exponential lower bounds for a large class of random QBFs.

We also introduce a strengthening of the decision heuristic used in classical
QCDCL, which does not necessarily decide variables in order of the prefix, but
still allows to learn asserting clauses. We show that with this decision
policy, QCDCL can be exponentially faster on some formulas.

We further exhibit a QCDCL proof system that is p-equivalent to Q-resolution.
In comparison to classical QCDCL, this new QCDCL version adapts both decision
and unit propagation policies.</summary>
    <updated>2020-04-20T19:05:12Z</updated>
    <published>2020-04-20T19:05:12Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-04-22T00:20:26Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-515246364372918249</id>
    <link href="https://blog.computationalcomplexity.org/feeds/515246364372918249/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/04/the-summer-virtual-conference-season.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/515246364372918249" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/515246364372918249" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/04/the-summer-virtual-conference-season.html" rel="alternate" type="text/html"/>
    <title>The Summer Virtual Conference Season</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Both <a href="http://acm-stoc.org/stoc2020/">STOC</a> and <a href="https://computationalcomplexity.org/">Complexity</a> have announced they will go virtual for the summer. <a href="https://icalp2020.saarland-informatics-campus.de/">ICALP</a> moved from Beijing to Stuttgart to online. I expect every major summer conference and workshop will be cancelled, postponed or virtualized.<br/>
<div>
<br/></div>
<div>
Most CS conferences serve as publication venues and can't be cancelled or postponed. So how do we virtualize a conference? The ACM has an evolving <a href="https://people.clarkson.edu/~jmatthew/acm/VirtualConferences_GuideToBestPractices_CURRENT.pdf">virtual conferences best practices guide</a>. Putting the talks and poster sessions online is not trivial, but relatively straightforward. Personally I go to conferences mostly not for the talks but for the interactions with other participants--the receptions, meal time and just hanging in the hallways. The ACM document describes some approaches like Dagstuhl-style randomized virtual dinner tables. The IEEE VR conference <a href="https://www.cccblog.org/2020/04/02/computing-researchers-respond-to-covid-19-running-a-virtual-conference/">tried virtual reality</a> through <a href="https://hubs.mozilla.com/#/">Mozilla hubs</a>. None of these can truly replicate the on-site experience.</div>
<div>
<br/></div>
<div>
Let me mention two other meetings the <a href="https://games2020.hu/">Game Theory Congress</a> held every four years due to be held in Budapest and the <a href="https://cra.org/conference-at-snowbird/">CRA Snowbird Conference</a>, a meeting of CS department chairs and computing leadership, held every other summer in Utah. Both meetings are not archival publications venues though have several talks and panels. But the main purpose of both is mostly to bring people together, game theorists and CS leaders. I hope they postpone rather than virtualize these meetings. Rather get together a year late than pretend to get together now.</div></div>
    </content>
    <updated>2020-04-20T13:57:00Z</updated>
    <published>2020-04-20T13:57:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2020-04-21T16:27:33Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4762</id>
    <link href="https://www.scottaaronson.com/blog/?p=4762" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4762#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4762" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Lockdown day 39</title>
    <summary xml:lang="en-US">This is really getting depressing. One of the only things that makes it bearable—even though in some sense it shouldn’t—is that most of humanity is in this together. For once, there’s no question of “why me?” Having watched the eighth and final episode of Devs, the thought occurred to me: if I’d had the opportunity […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><ol><li>This is <em>really</em> getting depressing.  One of the only things that makes it bearable—even though in some sense it shouldn’t—is that most of humanity is in this together.  For once, there’s no question of “why me?”</li><li>Having watched the eighth and final episode of <em>Devs</em>, the thought occurred to me: if I’d had the opportunity to restart the world from 8 months ago, even inside a simulation, I’d seize the chance and never look back.</li><li>I think I finally figured out how to explain the issue with <em>Devs</em> to my literary sophisticate readers.  Namely: <em>Devs</em> consists, precisely, of the <strong>cultural appropriation </strong>of quantum computing.  Now, I never felt like cultural appropriation was the world’s worst problem—not even <em>before</em> a pandemic started overflowing the morgues—so I wouldn’t say I was <em>offended</em> by Alex Garland appropriating the images and buzzwords of my quantum computing tribe for a basically unrelated purpose, but it is what it is.  Again: <em>Devs</em> is the show for you, if you want a haunting, slow-paced, well-produced meditation about free will and determinism and predicting the future and parallel worlds and “what if the whole universe is a simulation?,” and the various ideas I would’ve had about such topics around the age of 11.  It’s just not a show about quantum computing.  I hope that makes it clear.</li><li>I read with interest <a href="https://project-evidence.github.io/">this anonymous but PGP-signed article</a>, laying out the case that it’s <em>plausible</em> that covid accidentally leaked from either the Wuhan Institute of Virology or the Wuhan CDC, rather than originating at the Huanan seafood market.  Or, as an intermediate hypothesis, that an infected animal from one of those labs ended up at the seafood market.  (Note that this is completely different from the hypothesis that covid was purposefully engineered—the authors of the article find that totally implausible, and I agree with them.)  Notably, the Wuhan labs are known to have experimented with bat coronaviruses very much like covid, and are known to have performed “gain-of-function” experiments on them, and were probably the central labs in China for such experiments.  And viruses are known to have leaked from other labs in China on other occasions, and the nature → seafood market route has unresolved issues, like where exactly the crossover from bats to pangolins (or some other intermediate species) is supposed to have happened, such that people would only start getting infected at the seafood market and not at its faraway suppliers, and … well, anyway, read the article and form your own judgment!</li><li>I find it interesting that three months ago, I would’ve hesitated even to share such a link, because my internal critic would’ve screamed “this looks too much like tinfoil-hat stuff—are you ready for all the people you respect sneering at you?”  But the me of three months ago is not the me of today.  I make no apologies for adapting my thoughts to the freak branch of the multiverse where I actually find myself.</li></ol>



<p/></div>
    </content>
    <updated>2020-04-19T22:51:16Z</updated>
    <published>2020-04-19T22:51:16Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Procrastination"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Quantum"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2020-04-20T22:43:03Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2020/04/19/stretch-average-stretch</id>
    <link href="https://11011110.github.io/blog/2020/04/19/stretch-average-stretch.html" rel="alternate" type="text/html"/>
    <title>Stretch, average stretch, and expected stretch of spanning trees</title>
    <summary>The graph below is a series-parallel graph. It can be put together from four smaller series-parallel graphs, each constructed recursively in the same way, by performing a series composition of two pairs and then a parallel composition of the two results.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The graph below is a <a href="https://en.wikipedia.org/wiki/Series-parallel_graph">series-parallel graph</a>. It can be put together from four smaller series-parallel graphs, each constructed recursively in the same way, by performing a series composition of two pairs and then a parallel composition of the two results.</p>

<p style="text-align: center;"><img alt="Series-parallel graph for which all spanning trees have high stretch" src="https://11011110.github.io/blog/assets/2020/binserpar.svg"/></p>

<p>This family of graphs (although not the radial layout I’m using for it) comes from a paper “Cuts, trees and -embeddings of graphs”, by Anupam Gupta, Ilan Newman, Yuri Rabinovich, and Alistair Sinclair, <em>Combinatorica</em> 2004, <a href="https://doi.org/10.1007/s00493-004-0015-x">doi:10.1007/s00493-004-0015-x</a> (see Figure 3, p. 261). They used it to show a lower bound on the average stretch of any spanning tree for these graphs.</p>

<p>Here, given a graph , any edge  of , and any subgraph  of , the stretch of  with respect to  is how much farther you have to go in  to find a path connecting the endpoints of , relative to the unit distance between these endpoints in . For instance, in a cycle graph , every spanning tree is formed by deleting one edge from the cycle. The deleted edge has stretch  (you have to go the long way around to connect its endpoints), but all other edges have stretch , so the average stretch is . More strongly, if you choose the edge to delete randomly, the resulting distribution over spanning trees of  gives every edge expected stretch .</p>

<p>But for the series-parallel graphs of Gupta, Newman, Rabinovich, and Sinclair, such low stretch is not possible. If there are  vertices, then there are  edges. Each edge has stretch at least one.
There are  four-cycles, each of which has at least one missing edge,
with stretch at least three; added to the one unit of stretch that we’ve already counted, the extra stretch from these missing edges is at least .
Removing one edge from each four-cycle leaves  eight-cycles, each of which has at least one more missing edge. The edge that is removed in this way, and the other missing edge from the same four-cycle, have stretch at least seven, adding another ten units per eight-cycle, or  overall, to the total stretch. And so on; at each level of recursion the number of cycles goes down by a factor of four, but the number of edges that need to be cut to break each cycle doubles, as does their length. Therefore, the contribution per level of the recursive construction ends up being linear, and the total stretch is . Thus, as Gupta et al. show, the average stretch for their graphs is .</p>

<p>This result is the background to my newest preprint, “Low-stretch spanning trees of graphs with bounded width” (with Cora Borradaile, Erin Chambers, Will Maxwell, and Amir Nayyeri, <a href="https://arxiv.org/abs/2004.08375">arXiv:2004.08375</a>, to appear at SWAT). From the result of Gupta, we know that having bounded treewidth is not enough to ensure bounded average stretch, or bounded expected stretch. What is? We show that bounded bandwidth is enough to find a distribution over spanning trees with bounded expected stretch, and that bounded cutwidth is enough to find a single spanning tree with bounded average stretch.</p>

<p>This leaves open the question for pathwidth. It was known from another previous work, “Pathwidth, trees, and random embeddings” (James Lee and Tasos Sidiropoulos, <em>Combinatorica</em> 2013, <a href="https://doi.org/10.1007/s00493-013-2685-8">doi:10.1007/s00493-013-2685-8</a>) that graphs of bounded pathwidth can be mapped to a random distribution over trees with bounded expected stretch per edge, but the trees of this distribution are not spanning trees. Our new paper includes a conjecture that bounded-pathwidth graphs have distributions over spanning trees with constant average stretch, which if true would generalize our results for both bandwidth and cutwidth.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/104028326751044483">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2020-04-19T18:10:00Z</updated>
    <published>2020-04-19T18:10:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2020-04-20T01:32:31Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://tcsplus.wordpress.com/?p=415</id>
    <link href="https://tcsplus.wordpress.com/2020/04/19/tcs-talk-wednesday-april-22-huacheng-yu-princeton/" rel="alternate" type="text/html"/>
    <title>TCS+ talk: Wednesday, April 22 — Huacheng Yu, Princeton</title>
    <summary>The next TCS+ talk will take place this coming Wednesday, April 22nd at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). Huacheng Yu from Princeton will speak about a “Nearly Optimal Static Las Vegas Succinct Dictionary” (abstract below). You can reserve a spot as an individual or a group […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The next TCS+ talk will take place this coming Wednesday, April 22nd at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). <strong>Huacheng Yu</strong> from Princeton will speak about a “<em>Nearly Optimal Static Las Vegas Succinct Dictionary</em>” (abstract below).</p>
<p>You can reserve a spot as an individual or a group to join us live by signing up on <a href="https://sites.google.com/site/plustcs/livetalk">the online form</a>. Due to security concerns, <strong>registration is required</strong> to attend the interactive talk. (The link to the YouTube livestream will also be posted <a>on our website</a> on the day of the talk, so people who did not sign up will still be able to watch the talk live.) As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/site/plustcs/suggest">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/site/plustcs/">the website</a>.</p>
<blockquote><p>Abstract: Given a set <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=fff&amp;fg=444444&amp;s=0" title="S"/> of <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=fff&amp;fg=444444&amp;s=0" title="n"/> (distinct) keys from key space <img alt="[U]" class="latex" src="https://s0.wp.com/latex.php?latex=%5BU%5D&amp;bg=fff&amp;fg=444444&amp;s=0" title="[U]"/>, each associated with a value from <img alt="\Sigma" class="latex" src="https://s0.wp.com/latex.php?latex=%5CSigma&amp;bg=fff&amp;fg=444444&amp;s=0" title="\Sigma"/>, the <em>static dictionary problem</em> asks to preprocess these (key, value) pairs into a data structure, supporting value-retrieval queries: for any given <img alt="x \in [U]" class="latex" src="https://s0.wp.com/latex.php?latex=x+%5Cin+%5BU%5D&amp;bg=fff&amp;fg=444444&amp;s=0" title="x \in [U]"/>, valRet<img alt="(x)" class="latex" src="https://s0.wp.com/latex.php?latex=%28x%29&amp;bg=fff&amp;fg=444444&amp;s=0" title="(x)"/> must return the value associated with <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=fff&amp;fg=444444&amp;s=0" title="x"/> if <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=fff&amp;fg=444444&amp;s=0" title="x"/> is in <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=fff&amp;fg=444444&amp;s=0" title="S"/>, or return “N/A” if <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=fff&amp;fg=444444&amp;s=0" title="x"/> is not in <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=fff&amp;fg=444444&amp;s=0" title="S"/>. The special case where <img alt="|\Sigma|=1" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5CSigma%7C%3D1&amp;bg=fff&amp;fg=444444&amp;s=0" title="|\Sigma|=1"/> is called the membership problem. The “textbook” solution is to use a hash table, which occupies linear space and answers each query in constant time. On the other hand, the minimum possible space to encode all (key, value) pairs is only <img alt="\textrm{OPT} := \lg \binom{U}{n} + n \lg |\Sigma|" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctextrm%7BOPT%7D+%3A%3D+%5Clg+%5Cbinom%7BU%7D%7Bn%7D+%2B+n+%5Clg+%7C%5CSigma%7C&amp;bg=fff&amp;fg=444444&amp;s=0" title="\textrm{OPT} := \lg \binom{U}{n} + n \lg |\Sigma|"/> bits, which could be much less.</p>
<p>In this talk, we will talk about a randomized dictionary data structure using <img alt="\textrm{OPT}+\textrm{poly}\lg n+O(\lg\lg\cdots\lg U)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctextrm%7BOPT%7D%2B%5Ctextrm%7Bpoly%7D%5Clg+n%2BO%28%5Clg%5Clg%5Ccdots%5Clg+U%29&amp;bg=fff&amp;fg=444444&amp;s=0" title="\textrm{OPT}+\textrm{poly}\lg n+O(\lg\lg\cdots\lg U)"/> bits of space and expected constant query time, assuming the query algorithm have access to an external data-independent lookup table of size <img alt="n^{0.001}" class="latex" src="https://s0.wp.com/latex.php?latex=n%5E%7B0.001%7D&amp;bg=fff&amp;fg=444444&amp;s=0" title="n^{0.001}"/>. Previously, even for membership queries and when <img alt="U\leq n^{O(1)}" class="latex" src="https://s0.wp.com/latex.php?latex=U%5Cleq+n%5E%7BO%281%29%7D&amp;bg=fff&amp;fg=444444&amp;s=0" title="U\leq n^{O(1)}"/>, the best known data structure with constant query time requires <img alt="\textrm{OPT}+n/\textrm{poly} \lg n" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctextrm%7BOPT%7D%2Bn%2F%5Ctextrm%7Bpoly%7D+%5Clg+n&amp;bg=fff&amp;fg=444444&amp;s=0" title="\textrm{OPT}+n/\textrm{poly} \lg n"/> bits of space (due to Pagh [Pagh’01] and Pătraşcu [Pat’08]). It has <img alt="O(\lg n)" class="latex" src="https://s0.wp.com/latex.php?latex=O%28%5Clg+n%29&amp;bg=fff&amp;fg=444444&amp;s=0" title="O(\lg n)"/> query time when the space is at most <img alt="\textrm{OPT}+n^{0.999}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctextrm%7BOPT%7D%2Bn%5E%7B0.999%7D&amp;bg=fff&amp;fg=444444&amp;s=0" title="\textrm{OPT}+n^{0.999}"/>.</p></blockquote></div>
    </content>
    <updated>2020-04-19T18:01:40Z</updated>
    <published>2020-04-19T18:01:40Z</published>
    <category term="Announcements"/>
    <author>
      <name>plustcs</name>
    </author>
    <source>
      <id>https://tcsplus.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://tcsplus.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://tcsplus.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://tcsplus.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://tcsplus.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A carbon-free dissemination of ideas across the globe.</subtitle>
      <title>TCS+</title>
      <updated>2020-04-22T00:21:19Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=19738</id>
    <link href="https://gilkalai.wordpress.com/2020/04/19/to-cheer-you-up-in-difficult-times-ii-mysterious-matching-news-by-gal-beniamini-naom-nisan-vijay-vazirani-and-thorben-trobst/" rel="alternate" type="text/html"/>
    <title>To cheer you up in difficult times II: Mysterious matching news by Gal Beniamini, Naom Nisan, Vijay Vazirani and Thorben Tröbst!</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Matching is one of the richest gold mines for ideas and results in mathematics, computer science and other areas.  Today I want to briefly tell you about a curious, surprising, mysterious, and cheerful recent result by Gal Beniamini and Noam … <a href="https://gilkalai.wordpress.com/2020/04/19/to-cheer-you-up-in-difficult-times-ii-mysterious-matching-news-by-gal-beniamini-naom-nisan-vijay-vazirani-and-thorben-trobst/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Matching is one of the richest gold mines for ideas and results in mathematics, computer science and other areas.  Today I want to briefly tell you about a curious, surprising, mysterious, and <a href="https://arxiv.org/abs/2001.07642">cheerful recent result</a> by Gal Beniamini and Noam Nisan and a subsequent work of Vijay Vazirani. It is a result that will cheer up combinatorialists on both sides of the aisle: graph theorists and researchers in extremal and probabilistic combinatorics as well as algebraic and enumerative combinatorialists.  (And it is related to query complexity, Eulerian lattices, Birkhoff’s polytope, a theorem of Lou Billera and Aravamuthan Sarangarajan, evasiveness, analysis of Boolean functions, and various other things.) At the end of the post I will remind you of a central problem in matching theory: that of extending Lovasz’ randomized algorithm for matching to general graphs. (Perhaps methods from algebraic combinatorics can help.)</p>
<p>I will start with sad news. <a href="https://en.wikipedia.org/wiki/John_Horton_Conway">John Horton Conway</a>, an amazing mathematical hero,  passed away a few days ago. There are very nice posts on Conway’s work <a href="https://www.scottaaronson.com/blog/?p=4732">by Scott Aaronson</a> (with many nice memories in the comments section), <a href="https://terrytao.wordpress.com/2020/04/12/john-conway/">by Terry Tao</a>, and by <a href="https://rjlipton.wordpress.com/2020/04/14/john-horton-conway-1937-2020/">Dick Lipton and Ken Regan</a>. And<a href="https://xkcd.com/2293/"> a moving obituary on xkcd</a> with a touch of ingenuity of Conway’s style. (There is also a question on MO  “<a href="https://mathoverflow.net/questions/357197/conways-lesser-known-results">Conway’s less known results</a>,” and two questions on the game of life (<a href="https://mathoverflow.net/questions/132402/conways-game-of-life-for-random-initial-position">I</a>, <a href="https://cstheory.stackexchange.com/questions/17914/does-a-noisy-version-of-conways-game-of-life-support-universal-computation">II</a>).)</p>
<p>Another reading material to cheer you up is my paper: <a href="https://gilkalai.files.wordpress.com/2020/04/laws-blog.pdf">The argument against quantum computers, the quantum laws of nature, and Google’s supremacy claims.</a> It is for <em>Laws, Rigidity and Dynamics,</em> Proceedings of the <a href="https://gilkalai.wordpress.com/2018/06/10/conference-in-singapore-vietnam-appeasement-restorative-justice-laws-of-history-and-neutrinos/">ICA workshops</a> 2018 &amp; 2019 in Singapore and Birmingham. <span style="color: #993366;">Remarks are most welcome.</span></p>
<p><strong>Update:</strong> starting today, <a href="https://sites.google.com/view/acow2020/home">the algebraic combinatorics online workshop.</a>  Here is the schedule <a href="https://drive.google.com/file/d/17us1_lpZk1XLdQ1IewxS9cp-fBPA6TKw/view">for the first week</a>, and <a href="https://drive.google.com/file/d/1wJlUyLkdQ1Uvz5OxZGCNuE2SWyRk5_te/view">for the second week</a>.</p>
<p> </p>
<p><a href="https://gilkalai.files.wordpress.com/2020/04/mt.jpg"><img alt="" class="alignnone size-full wp-image-19748" src="https://gilkalai.files.wordpress.com/2020/04/mt.jpg?w=640"/></a></p>
<p><span style="color: #ff0000;">Matching theory by Lovasz and Plummer is probably one of the best mathematics books ever written. </span></p>
<h2>Bipartite Perfect Matching as a Real Polynomial</h2>
<p><a href="https://arxiv.org/abs/2001.07642">Bipartite Perfect Matching as a Real Polynomial,</a> by Gal Beniamini and Noam Nisan</p>
<p><strong>Abstract:</strong> We obtain a description of the Bipartite Perfect Matching decision problem as a multilinear polynomial over the Reals. We show that it has full degree and <img alt="(1-o_n(1))\cdot 2^{n^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%281-o_n%281%29%29%5Ccdot+2%5E%7Bn%5E2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(1-o_n(1))\cdot 2^{n^2}"/>  monomials with non-zero coefficients. In contrast, we show that in the dual representation (switching the roles of 0 and 1) the number of monomials is only exponential in <img alt="\Theta(n \log n)" class="latex" src="https://s0.wp.com/latex.php?latex=%5CTheta%28n+%5Clog+n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Theta(n \log n)"/>  Our proof relies heavily on the fact that the lattice of graphs which are “matching-covered” is Eulerian.</p>
<p>And here is how the paper starts</p>
<p>Every Boolean function <img alt="f:\{0,1\}^n\to\{0,1\}" class="latex" src="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D%5En%5Cto%5C%7B0%2C1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f:\{0,1\}^n\to\{0,1\}"/> can be represented in a unique way as a Real multilinear polynomial. This representation and related ones (e.g. using the {1,−1} basis rather than {0,1}– the “Fourier transform” over the hypercube, or approximation variants) have many applications for various complexity and algorithmic purposes. See, e.g., [O’D14] for a recent textbook. In this paper we derive the representation of the bipartite-perfect-matching decision problem as a Real polynomial.</p>
<p><strong>Deﬁnition.</strong> The Boolean function <img alt="BPM_n(x_{1,1},\dots,x_{n,n})" class="latex" src="https://s0.wp.com/latex.php?latex=BPM_n%28x_%7B1%2C1%7D%2C%5Cdots%2Cx_%7Bn%2Cn%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="BPM_n(x_{1,1},\dots,x_{n,n})"/> is deﬁned to be 1 if and only if the bipartite graph whose edges are<img alt="\{(i,j):x_{i,j}=1\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B%28i%2Cj%29%3Ax_%7Bi%2Cj%7D%3D1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{(i,j):x_{i,j}=1\}"/> has a perfect matching, and 0 otherwise.</p>
<p>And here are the two main theorems regarding this polynomial and the polynomial for the dual representation:</p>
<p><a href="https://gilkalai.files.wordpress.com/2020/04/bn2.png"><img alt="" class="alignnone size-full wp-image-19769" height="138" src="https://gilkalai.files.wordpress.com/2020/04/bn2.png?w=640&amp;h=138" width="640"/></a></p>
<p>(For the second theorem you need the notion of totally ordered bipartite graphs.)</p>
<p><a href="https://gilkalai.files.wordpress.com/2020/04/bn3.png"><img alt="" class="alignnone size-full wp-image-19770" height="143" src="https://gilkalai.files.wordpress.com/2020/04/bn3.png?w=640&amp;h=143" width="640"/></a></p>
<p>And here is a nice picture!</p>
<p><a href="https://gilkalai.files.wordpress.com/2020/04/bn4.png"><img alt="" class="alignnone size-full wp-image-19771" height="421" src="https://gilkalai.files.wordpress.com/2020/04/bn4.png?w=640&amp;h=421" width="640"/></a></p>
<p>A very interesting open problem is:</p>
<p><strong>Problem:</strong> Can the Beniamini-Nisan results be extended to general (non-bipartite) graphs</p>
<p>This reminds me of an old great problem:</p>
<p><strong>Problem:</strong> Does Lovasz’ randomized algorithm for matching extend to the non-bipartite case?</p>
<p>For both problems methods of algebraic combinatorics may be helpful.</p>
<h2>An Extension by Vijay Vazirani and Thorben Tröbst</h2>
<p class="title mathjax"><a href="https://arxiv.org/abs/2003.08917">A Real Polynomial for Bipartite Graph Minimum Weight Perfect Matchings,</a> Thorben Tröbst, Vijay V. Vazirani</p>
<p><strong>Abstract:</strong></p>
<p>In a recent paper, Beniamini and Nisan gave a closed-form formula for the unique multilinear polynomial for the Boolean function determining whether a given bipartite graph <img alt="G \subset K_{n,n}" class="latex" src="https://s0.wp.com/latex.php?latex=G+%5Csubset+K_%7Bn%2Cn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G \subset K_{n,n}"/> has a perfect matching, together with an efficient algorithm for computing the coefficients of the monomials of this polynomial. We give the following generalization: Given an arbitrary non-negative weight function <span class="MathJax" id="MathJax-Element-2-Frame"><span class="math" id="MathJax-Span-12"><span class="mrow" id="MathJax-Span-13"><span class="mi" id="MathJax-Span-14">w</span></span></span></span> on the edges of <img alt="K_{n,n}" class="latex" src="https://s0.wp.com/latex.php?latex=K_%7Bn%2Cn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K_{n,n}"/>, consider its set of minimum weight perfect matchings. We give the real multilinear polynomial for the Boolean function which determines if a graph <img alt="G \subset K_{n,n}" class="latex" src="https://s0.wp.com/latex.php?latex=G+%5Csubset+K_%7Bn%2Cn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G \subset K_{n,n}"/> contains one of these minimum weight perfect matchings.</p>
<h3>Three more remarks about VVV</h3>
<p>Three more VVV remarks: in the Tel Aviv theory <del>fast</del> fest three months ago (it seems like ages ago) Vijay Vazirani gave a lecture about matching. Here is the link to <a href="https://youtu.be/DFGsIOVGOIs">Vijay’s lecture</a>, and to <a href="https://www.youtube.com/playlist?list=PLGRBwz8taWHgpFOqbKQLvm-eAaZz33zM7">all plenary lectures</a>.  At the end, I asked him how he explains that matching theory is such inexhaustable gold mine and Vijay mentioned the fact that a polynomial-time algorithm for the assignment problem (which is closely related to matching) was <a href="http://www.lix.polytechnique.fr/~ollivier/JACOBI/presentationlEngl.htm">already found by Jacobi in 1890</a>. (Unfortunately VJ’s inspiring answer was not recorded). A few years ago Vijay<a href="https://arxiv.org/abs/1210.4594"> published a simplified proof</a> of a fantastic famous result he first proved with Silvio Micaly 34 years earlier. And here is a most amazing story: a few years ago I went to the beach in Tel Aviv and I discovered Vijay swimming just next to me.  We were quite happy to see each other and Vijay told me a few things about matching, economics and biology. This sounds now like a truly surrealistic story, and perhaps we even shook hands.</p>
<h3/>
<p> </p>
<p> </p>
<p> </p></div>
    </content>
    <updated>2020-04-19T08:47:01Z</updated>
    <published>2020-04-19T08:47:01Z</published>
    <category term="Combinatorics"/>
    <category term="Computer Science and Optimization"/>
    <category term="Gal Beniamini"/>
    <category term="Naom Nisan"/>
    <category term="Thorben Tr&#xF6;bst"/>
    <category term="Vijay Vazirani"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2020-04-22T00:20:30Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16965</id>
    <link href="https://rjlipton.wordpress.com/2020/04/18/proof-and-cake-envy/" rel="alternate" type="text/html"/>
    <title>Proof and Cake Envy</title>
    <summary>Our proofs can be big too [Mackenzie and Aziz] Haris Aziz and Simon Mackenzie are computer scientists at UNSW and CMU respectively. Of course UNSW is the University of New South Wales and CMU is the Carnegie Mellon University. Today we will discuss cake cutting and more. Aziz and Mackenzie have solved an open problem […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Our proofs can be big too</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2020/04/18/proof-and-cake-envy/screen-shot-2020-04-18-at-12-47-07-pm/" rel="attachment wp-att-16968"><img alt="" class="alignright size-medium wp-image-16968" height="163" src="https://rjlipton.files.wordpress.com/2020/04/screen-shot-2020-04-18-at-12.47.07-pm.png?w=300&amp;h=163" width="300"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">[Mackenzie and Aziz]</font></td>
</tr>
</tbody>
</table>
<p>
Haris Aziz and Simon Mackenzie are computer scientists at UNSW and CMU respectively. Of course UNSW is the University of New South Wales and CMU is the Carnegie Mellon University. </p>
<p>
Today we will discuss cake cutting and more.</p>
<p>
Aziz and Mackenzie have solved an open problem concerning how to cut cakes. Their <a href="https://cacm.acm.org/magazines/2020/4/243651-a-bounded-and-envy-free-cake-cutting-algorithm/fulltext">paper</a> is in the April issue of the CACM: “A Bounded and Envy-Free Cake Cutting Algorithm.” </p>
<p/><p/>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.wordpress.com/2020/04/18/proof-and-cake-envy/cake/" rel="attachment wp-att-16970"><img alt="" class="aligncenter size-full wp-image-16970" src="https://rjlipton.files.wordpress.com/2020/04/cake.jpg?w=600"/></a>
</td>
</tr>
<tr>

</tr>
</tbody></table>
<p>
</p><p/><h2> Why Cake Cutting? </h2><p/>
<p/><p>
Before we talk about cake cutting from a theory viewpoint let’s take a look at why it is interesting. The real answer probably is it is a beautiful math problem. It is easy to state without lots of background. It is simple like Fermat’s Last Theorem: 	</p>
<p align="center"><img alt="\displaystyle  x^{n} + y^{n} = z^{n} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++x%5E%7Bn%7D+%2B+y%5E%7Bn%7D+%3D+z%5E%7Bn%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  x^{n} + y^{n} = z^{n} "/></p>
<p>has no solutions over the integers with <img alt="{xyz \neq 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bxyz+%5Cneq+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{xyz \neq 0}"/> and <img alt="n&gt;2" class="latex" src="https://s0.wp.com/latex.php?latex=n%3E2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n&gt;2"/>. Cake cutting is hard. We like problems that strike back: problems that are not easy to solve. This is a strange view. In real life we might prefer problems that we can easily solve. But not in math. We like problems that are not trivial. The cake cutting problem is hard, so we like it. </p>
<p>
</p><p/><h2> Cutting Cakes </h2><p/>
<p/><p>
We are theorists so our cakes are one-dimensional line segments. The problem involves a finite set of agents, say Alice, Bob, and so on. They want to divide the cake, the line segment, into a finite number of pieces. The pieces are then allocated to the agents. The goal is to get a fair division of the cake. </p>
<p>
The notion of “fair” is what makes the problem interesting. Often agents will not have the same tastes: Some like icing more than others, some like the end pieces, while others do not. The fact that the agents assign different values to a piece of the cake is what makes the problem challenging. </p>
<p>
If there are two agents the problem has long been solved. Let Bob divide the cake into two pieces, so that he is happy to get either of these pieces. Then have Alice chose which piece she wants. It is easy to see that both Bob and Alice are happy. Both are <i>envy-free</i>: neither would exchange their piece for the others piece. </p>
<p/><p/>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.wordpress.com/2020/04/18/proof-and-cake-envy/two/" rel="attachment wp-att-16971"><img alt="" class="aligncenter size-medium wp-image-16971" height="144" src="https://rjlipton.files.wordpress.com/2020/04/two.png?w=300&amp;h=144" width="300"/></a>
</td>
</tr>
<tr>

</tr>
</tbody></table>
<p>
There is a large literature on the <a href="https://en.wikipedia.org/wiki/Fair_cake-cutting">cake-cutting</a> problem. Its creator, Hugo Steinhaus, noted:</p>
<blockquote><p><b> </b> <em> Interesting mathematical problems arise if we are to determine the minimal numbers of “cuts” necessary for fair division. </em>
</p></blockquote>
<p/><p>
We have taken the quote from an <a href="https://medium.com/cantors-paradise/envy-free-cake-cutting-procedures-de3cf13c5d3d">article</a> on <em>Medium</em> that neatly conveys details on various protocols. Some main results are: </p>
<ul>
<li>
The Selfridge-Conway discrete procedure produces an envy-free division for <img alt="{3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{3}"/> people using at most <img alt="{5}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B5%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{5}"/> cuts. <p/>
</li><li>
The Brams-Taylor-Zwicker moving knives procedure produces an envy-free division for <img alt="{4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{4}"/> people using at most <img alt="{11}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B11%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{11}"/> cuts. <p/>
</li><li>
Three different procedures produce an envy-free division for <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> people. Both algorithms require a finite but unbounded number of cuts. That is to say, the number of cuts may depend on details of their preference functions. <p/>
</li><li>
The procedure by Aziz and Mackenzie finds an envy-free division for <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> people in a bounded number of cuts.
</li></ul>
<p>The last is the result in the CACM paper. Note, the number of cuts can be large: 	</p>
<p align="center"><img alt="\displaystyle  n^{n^{n^{n^{n^{n}}}}}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++n%5E%7Bn%5E%7Bn%5E%7Bn%5E%7Bn%5E%7Bn%7D%7D%7D%7D%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  n^{n^{n^{n^{n^{n}}}}}. "/></p>
<p>Even for <img alt="{n=2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%3D2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n=2}"/> this is immense, galactic. This should be compared to the best lower bound that is order <img alt="{n^{2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%5E%7B2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n^{2}}"/>. This gap is even larger than the usual gaps we find in complexity theory. The P=NP question is only one exponential not five.</p>
<p>
This has started me thinking: what exactly is the relationship between this and <em>proof complexity</em>? The latter has well-established relationships to complexity-class questions. The link from proofs in various systems of <a href="https://en.wikipedia.org/wiki/Bounded_arithmetic">bounded arithmetic</a> goes through the heart of P=NP. See for instance these <a href="https://www.math.ucsd.edu/~sbuss/ResearchWeb/StPetersburg_BoundedArith_2016/talkAllSlides_Corrected.pdf">slides</a> by Sam Buss and <a href="https://www.math.ucsd.edu/~sbuss/ResearchWeb/Barbados95Notes/reporte.pdf">notes</a> that were scribed by Ken and others. What I am puzzled by is that in most cases the blowup is only one or two exponentials. The setting with cake-cutting is different, but how different? </p>
<p>
</p><p/><h2> Easy Cases </h2><p/>
<p/><p>
The Aziz and Mackenzie algorithm takes a long time. It is a nontrivial result, but not one that applies in any practical case. It always takes way too long. The cake will be stale by the time the agents have agreed on their pieces. </p>
<p>
This raises a question, that also applies to many computational problems. Is there a way cut a cake faster on some interesting examples? We can explain this by the analogy to sorting. The fastest sorting algorithms run in <img alt="{O(n \log n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%28n+%5Clog+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{O(n \log n)}"/> time where there are <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> objects. But what happens if the objects are already in sorted order? Or at least close to sorted order? The answer is it depends:</p>
<ol>
<li>
Some sorting algorithms always take the same time, independent of the input structure. <p/>
</li><li>
There are other sorting algorithms that can take advantage of the nature of the input.
</li></ol>
<p>
That is some sorting algorithms can run say in linear time if the input is almost sorted. For the cake cutting problem we ask:</p>
<blockquote><p><b> </b> <em> <i>Is there a way to cut cakes that is envy-free when the agents have some property <img alt="{P}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{P}"/>?</i> </em>
</p></blockquote>
<p/><p>
We do not know the answer, but we think it is an interesting question. Here is an example. Suppose that the agents have the same measures. That is, they evaluate every piece of cake in the same way. </p>
<p>
If we <em>know</em> this—and if we continue our supposition above that Bob can cut with exact precision—then there is an easy answer: Have Bob do the cuts. Then all agents will be equally happy since they have the same measures. The question is, what if we do not know? I believe there should be some theorem like this:</p>
<blockquote><p><b>Theorem 1 (Conjecture)</b> <em> There is an envy-free algorithm that operates in <img alt="{O(n^{2})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%28n%5E%7B2%7D%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{O(n^{2})}"/> time the algorithm so that either: </em></p><em>
<ol>
<li>
It yields an envy-free solution, or <p/>
</li><li>
It determines that some agents have different measures.
</li></ol>
</em><p><em/>
</p></blockquote>
<p/><p>
In the second case the cake will be cut as before. </p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
I originally planned on discussing size and complexity of proofs. This is driven by the complexity of the cake cutting algorithms. They tend to have lots of cases and are difficult to understand.<br/>
<a href="https://rjlipton.wordpress.com/2020/04/18/proof-and-cake-envy/over/" rel="attachment wp-att-16973"><img alt="" class="aligncenter size-full wp-image-16973" src="https://rjlipton.files.wordpress.com/2020/04/over.png?w=600"/></a><br/>
They are also difficult to find—this is why cake cutting questions have been resistance to progress. More on this in the future. </p>
<p>[Edit <img alt="n&gt;2" class="latex" src="https://s0.wp.com/latex.php?latex=n%3E2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n&gt;2"/> in Fermat example]</p></font></font></div>
    </content>
    <updated>2020-04-18T16:59:55Z</updated>
    <published>2020-04-18T16:59:55Z</published>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="Open Problems"/>
    <category term="P=NP"/>
    <category term="People"/>
    <category term="Proofs"/>
    <category term="Algorithms"/>
    <category term="cake-cutting"/>
    <category term="galactic algorithms"/>
    <category term="open problems"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2020-04-22T00:20:40Z</updated>
    </source>
  </entry>
</feed>
