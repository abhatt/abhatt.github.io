<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2021-06-03T03:21:56Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.00657</id>
    <link href="http://arxiv.org/abs/2106.00657" rel="alternate" type="text/html"/>
    <title>Parameterized algorithms for identifying gene co-expression modules via weighted clique decomposition</title>
    <feedworld_mtime>1622592000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Madison Cooley, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Greene:Casey_S=.html">Casey S. Greene</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Issac:Davis.html">Davis Issac</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pividori:Milton.html">Milton Pividori</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sullivan:Blair_D=.html">Blair D. Sullivan</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.00657">PDF</a><br/><b>Abstract: </b>We present a new combinatorial model for identifying regulatory modules in
gene co-expression data using a decomposition into weighted cliques. To capture
complex interaction effects, we generalize the previously-studied weighted edge
clique partition problem. As a first step, we restrict ourselves to the
noise-free setting, and show that the problem is fixed parameter tractable when
parameterized by the number of modules (cliques). We present two new algorithms
for finding these decompositions, using linear programming and integer
partitioning to determine the clique weights. Further, we implement these
algorithms in Python and test them on a biologically-inspired synthetic corpus
generated using real-world data from transcription factors and a latent
variable analysis of co-expression in varying cell types.
</p></div>
    </summary>
    <updated>2021-06-02T22:51:21Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-06-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.00623</id>
    <link href="http://arxiv.org/abs/2106.00623" rel="alternate" type="text/html"/>
    <title>A 4-Approximation Algorithm for Maximum Independent Set of Rectangles</title>
    <feedworld_mtime>1622592000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Waldo Galvez, Arindam Khan, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mari:Mathieu.html">Mathieu Mari</a>, Tobias Momke, Madhusudhan Reddy, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wiese:Andreas.html">Andreas Wiese</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.00623">PDF</a><br/><b>Abstract: </b>We study the Maximum Independent Set of Rectangles(MISR) problem, where we
are given a set of axis-parallel rectangles in the plane and the goal is to
select a subset of non-overlapping rectangles of maximum cardinality. In a
recent breakthrough, Mitchell obtained the first constant-factor approximation
algorithm for MISR. His algorithm achieves an approximation ratio of 10 and it
is based on a dynamic program that intuitively recursively partitions the input
plane into special polygons called corner-clipped rectangles (CCRs).
</p>
<p>In this paper, we present a 4-approximation algorithm for MISR which is based
on a similar recursive partitioning scheme. However, we use a more general
class of polygons -- polygons that are horizontally or vertically convex --
which allows us to provide an arguably simpler analysis and already improve the
approximation ratio. Using a new fractional charging argument and fork-fences
to guide the partitions, we improve the approximation ratio even more to 4. We
hope that our ideas will lead to further progress towards a PTAS for MISR.
</p></div>
    </summary>
    <updated>2021-06-02T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2021-06-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.00604</id>
    <link href="http://arxiv.org/abs/2106.00604" rel="alternate" type="text/html"/>
    <title>Optimal Stopping with Behaviorally Biased Agents: The Role of Loss Aversion and Changing Reference Points</title>
    <feedworld_mtime>1622592000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Jon Kleinberg, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kleinberg:Robert.html">Robert Kleinberg</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Oren:Sigal.html">Sigal Oren</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.00604">PDF</a><br/><b>Abstract: </b>People are often reluctant to sell a house, or shares of stock, below the
price at which they originally bought it. While this is generally not
consistent with rational utility maximization, it does reflect two strong
empirical regularities that are central to the behavioral science of human
decision-making: a tendency to evaluate outcomes relative to a reference point
determined by context (in this case the original purchase price), and the
phenomenon of loss aversion in which people are particularly prone to avoid
outcomes below the reference point. Here we explore the implications of
reference points and loss aversion in optimal stopping problems, where people
evaluate a sequence of options in one pass, either accepting the option and
stopping the search or giving up on the option forever. The best option seen so
far sets a reference point that shifts as the search progresses, and a biased
decision-maker's utility incurs an additional penalty when they accept a later
option that is below this reference point.
</p>
<p>We formulate and study a behaviorally well-motivated version of the optimal
stopping problem that incorporates these notions of reference dependence and
loss aversion. We obtain tight bounds on the performance of a biased agent in
this model relative to the best option obtainable in retrospect (a type of
prophet inequality for biased agents), as well as tight bounds on the ratio
between the performance of a biased agent and the performance of a rational
one. We further establish basic monotonicity results, and show an exponential
gap between the performance of a biased agent in a stopping problem with
respect to a worst-case versus a random order. As part of this, we establish
fundamental differences between optimal stopping problems for rational versus
biased agents, and these differences inform our analysis.
</p></div>
    </summary>
    <updated>2021-06-02T22:44:30Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-06-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.00508</id>
    <link href="http://arxiv.org/abs/2106.00508" rel="alternate" type="text/html"/>
    <title>Differentially Private Densest Subgraph</title>
    <feedworld_mtime>1622592000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Farhadi:Alireza.html">Alireza Farhadi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hajiaghayi:MohammadTaghi.html">MohammadTaghi Hajiaghayi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shi:Elaine.html">Elaine Shi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.00508">PDF</a><br/><b>Abstract: </b>Given a graph, the densest subgraph problem asks for a set of vertices such
that the average degree among these vertices is maximized. Densest subgraph has
numerous applications in learning, e.g., community detection in social
networks, link spam detection, correlation mining, bioinformatics, and so on.
Although there are efficient algorithms that output either exact or approximate
solutions to the densest subgraph problem, existing algorithms may violate the
privacy of the individuals in the network, e.g., leaking the
existence/non-existence of edges.
</p>
<p>In this paper, we study the densest subgraph problem in the framework of the
differential privacy, and we derive the first upper and lower bounds for this
problem. We show that there exists a linear-time $\epsilon$-differentially
private algorithm that finds a $2$-approximation of the densest subgraph with
an extra poly-logarithmic additive error. Our algorithm not only reports the
approximate density of the densest subgraph, but also reports the vertices that
form the dense subgraph.
</p>
<p>Our upper bound almost matches the famous $2$-approximation by Charikar both
in performance and in approximation ratio, but we additionally achieve
differential privacy. In comparison with Charikar's algorithm, our algorithm
has an extra poly-logarithmic additive error. We partly justify the additive
error with a new lower bound, showing that for any differentially private
algorithm that provides a constant-factor approximation, a sub-logarithmic
additive error is inherent.
</p>
<p>We also practically study our differentially private algorithm on real-world
graphs, and we show that in practice the algorithm finds a solution which is
very close to the optimal
</p></div>
    </summary>
    <updated>2021-06-02T22:52:08Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-06-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.00463</id>
    <link href="http://arxiv.org/abs/2106.00463" rel="alternate" type="text/html"/>
    <title>Instance-optimal Mean Estimation Under Differential Privacy</title>
    <feedworld_mtime>1622592000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Huang:Ziyue.html">Ziyue Huang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liang:Yuting.html">Yuting Liang</a>, Ke Yi <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.00463">PDF</a><br/><b>Abstract: </b>Mean estimation under differential privacy is a fundamental problem, but
worst-case optimal mechanisms do not offer meaningful utility guarantees in
practice when the global sensitivity is very large. Instead, various heuristics
have been proposed to reduce the error on real-world data that do not resemble
the worst-case instance. This paper takes a principled approach, yielding a
mechanism that is instance-optimal in a strong sense. In addition to its
theoretical optimality, the mechanism is also simple and practical, and adapts
to a variety of data characteristics without the need of parameter tuning. It
easily extends to the local and shuffle model as well.
</p></div>
    </summary>
    <updated>2021-06-02T22:49:03Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-06-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.00399</id>
    <link href="http://arxiv.org/abs/2106.00399" rel="alternate" type="text/html"/>
    <title>Computing Least and Greatest Fixed Points in Absorptive Semirings</title>
    <feedworld_mtime>1622592000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Naaf:Matthias.html">Matthias Naaf</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.00399">PDF</a><br/><b>Abstract: </b>We present two methods to algorithmically compute both least and greatest
solutions of polynomial equation systems over absorptive semirings (with
certain completeness and continuity assumptions), such as the tropical
semiring. Both methods require a polynomial number of semiring operations,
including semiring addition, multiplication and an infinitary power operation.
</p>
<p>Our main result is a closed-form solution for least and greatest fixed points
based on the fixed-point iteration. The proof builds on the notion of (possibly
infinite) derivation trees; a careful analysis of the shape of these trees
allows us to collapse the fixed-point iteration to a linear number of steps.
</p>
<p>The second method is an iterative symbolic computation in the semiring of
absorptive polynomials, largely based on results on Kleene algebras.
</p></div>
    </summary>
    <updated>2021-06-02T22:37:40Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2021-06-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.00374</id>
    <link href="http://arxiv.org/abs/2106.00374" rel="alternate" type="text/html"/>
    <title>Fault-Tolerant Labeling and Compact Routing Schemes</title>
    <feedworld_mtime>1622592000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dory:Michal.html">Michal Dory</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Parter:Merav.html">Merav Parter</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.00374">PDF</a><br/><b>Abstract: </b>The paper presents fault-tolerant (FT) labeling schemes for general graphs,
as well as, improved FT routing schemes. For a given $n$-vertex graph $G$ and a
bound $f$ on the number of faults, an $f$-FT connectivity labeling scheme is a
distributed data structure that assigns each of the graph edges and vertices a
short label, such that given the labels of the vertices $s$ and $t$, and at
most $f$ failing edges $F$, one can determine if $s$ and $t$ are connected in
$G \setminus F$. The primary complexity measure is the length of the individual
labels. Since their introduction by [Courcelle, Twigg, STACS '07], compact FT
labeling schemes have been devised only for a limited collection of graph
families. In this work, we fill in this gap by proposing two (independent) FT
connectivity labeling schemes for general graphs, with a nearly optimal label
length. This serves the basis for providing also FT approximate distance
labeling schemes, and ultimately also routing schemes. Our main results for an
$n$-vertex graph and a fault bound $f$ are:
</p>
<p>-- There is a randomized FT connectivity labeling scheme with a label length
of $O(f+\log n)$ bits, hence optimal for $f=O(\log n)$. This scheme is based on
the notion of cycle space sampling [Pritchard, Thurimella, TALG '11].
</p>
<p>-- There is a randomized FT connectivity labeling scheme with a label length
of $O(\log^3 n)$ bits (independent of the number of faults $f$). This scheme is
based on the notion of linear sketches of [Ahn et al., SODA '12].
</p>
<p>-- For $k\geq 1$, there is a randomized routing scheme that routes a message
from $s$ to $t$ in the presence of a set $F$ of faulty edges, with stretch
$O(|F|^2 k)$ and routing tables of size $\tilde{O}(f^3 n^{1/k})$.
</p>
<p>This significantly improves over the state-of-the-art bounds by [Chechik,
ICALP '11], providing the first scheme with sub-linear FT labeling and routing
schemes for general graphs.
</p></div>
    </summary>
    <updated>2021-06-02T22:42:10Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-06-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.00323</id>
    <link href="http://arxiv.org/abs/2106.00323" rel="alternate" type="text/html"/>
    <title>Boosting the Search Performance of B+-tree for Non-volatile Memory with Sentinels</title>
    <feedworld_mtime>1622592000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Chongnan Ye, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Chundong.html">Chundong Wang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.00323">PDF</a><br/><b>Abstract: </b>The next-generation non-volatile memory (NVM) is striding into computer
systems as a new tier as it incorporates both DRAM's byte-addressability and
disk's persistency. Researchers and practitioners have considered building
persistent memory by placing NVM on the memory bus for CPU to directly load and
store data. As a result, cache-friendly data structures have been developed for
NVM. One of them is the prevalent B+-tree. State-of-the-art in-NVM B+-trees
mainly focus on the optimization of write operations (insertion and deletion).
However, search is of vital importance for B+-tree. Not only search-intensive
workloads benefit from an optimized search, but insertion and deletion also
rely on a preceding search operation to proceed. In this paper, we attentively
study a sorted B+-tree node that spans over contiguous cache lines. Such cache
lines exhibit a monotonically increasing trend and searching a target key
across them can be accelerated by estimating a range the key falls into. To do
so, we construct a probing Sentinel Array in which a sentinel stands for each
cache line of B+-tree node. Checking the Sentinel Array avoids scanning
unnecessary cache lines and hence significantly reduces cache misses for a
search. A quantitative evaluation shows that using Sentinel Arrays boosts the
search performance of state-of-the-art in-NVM B+-trees by up to 48.4% while the
cost of maintaining of Sentinel Array is low.
</p></div>
    </summary>
    <updated>2021-06-02T22:39:35Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-06-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.00308</id>
    <link href="http://arxiv.org/abs/2106.00308" rel="alternate" type="text/html"/>
    <title>Fast Splitting Algorithms for Sparsity-Constrained and Noisy Group Testing</title>
    <feedworld_mtime>1622592000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Price:Eric.html">Eric Price</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Scarlett:Jonathan.html">Jonathan Scarlett</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tan:Nelvin.html">Nelvin Tan</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.00308">PDF</a><br/><b>Abstract: </b>In group testing, the goal is to identify a subset of defective items within
a larger set of items based on tests whose outcomes indicate whether at least
one defective item is present. This problem is relevant in areas such as
medical testing, DNA sequencing, communication protocols, and many more. In
this paper, we study (i) a sparsity-constrained version of the problem, in
which the testing procedure is subjected to one of the following two
constraints: items are finitely divisible and thus may participate in at most
$\gamma$ tests; or tests are size-constrained to pool no more than $\rho$ items
per test; and (ii) a noisy version of the problem, where each test outcome is
independently flipped with some constant probability. Under each of these
settings, considering the for-each recovery guarantee with asymptotically
vanishing error probability, we introduce a fast splitting algorithm and
establish its near-optimality not only in terms of the number of tests, but
also in terms of the decoding time. While the most basic formulations of our
algorithms require $\Omega(n)$ storage for each algorithm, we also provide
low-storage variants based on hashing, with similar recovery guarantees.
</p></div>
    </summary>
    <updated>2021-06-02T22:46:52Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-06-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.00287</id>
    <link href="http://arxiv.org/abs/2106.00287" rel="alternate" type="text/html"/>
    <title>Junta Distance Approximation with Sub-Exponential Queries</title>
    <feedworld_mtime>1622592000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Iyer:Vishnu.html">Vishnu Iyer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tal:Avishay.html">Avishay Tal</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Whitmeyer:Michael.html">Michael Whitmeyer</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.00287">PDF</a><br/><b>Abstract: </b>Leveraging tools of De, Mossel, and Neeman [FOCS, 2019], we show two
different results pertaining to the \emph{tolerant testing} of juntas. Given
black-box access to a Boolean function $f:\{\pm1\}^{n} \to \{\pm1\}$, we give a
$poly(k, \frac{1}{\varepsilon})$ query algorithm that distinguishes between
functions that are $\gamma$-close to $k$-juntas and $(\gamma+\varepsilon)$-far
from $k'$-juntas, where $k' = O(\frac{k}{\varepsilon^2})$.
</p>
<p>In the non-relaxed setting, we extend our ideas to give a
$2^{\tilde{O}(\sqrt{k/\varepsilon})}$ (adaptive) query algorithm that
distinguishes between functions that are $\gamma$-close to $k$-juntas and
$(\gamma+\varepsilon)$-far from $k$-juntas. To the best of our knowledge, this
is the first subexponential-in-$k$ query algorithm for approximating the
distance of $f$ to being a $k$-junta (previous results of Blais, Canonne, Eden,
Levi, and Ron [SODA, 2018] and De, Mossel, and Neeman [FOCS, 2019] required
exponentially many queries in $k$).
</p>
<p>Our techniques are Fourier analytical and make use of the notion of
"normalized influences" that was introduced by Talagrand [AoP, 1994].
</p></div>
    </summary>
    <updated>2021-06-02T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-06-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.00279</id>
    <link href="http://arxiv.org/abs/2106.00279" rel="alternate" type="text/html"/>
    <title>$L_0$ Isotonic Regression With Secondary Objectives</title>
    <feedworld_mtime>1622592000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Stout:Quentin_F=.html">Quentin F. Stout</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.00279">PDF</a><br/><b>Abstract: </b>We provide algorithms for isotonic regression minimizing $L_0$ error (Hamming
distance). This is also known as monotonic relabeling, and is applicable when
labels have a linear ordering but not necessarily a metric. There may be
exponentially many optimal relabelings, so we look at secondary criteria to
determine which are best. For arbitrary ordinal labels the criterion is
maximizing the number of labels which are only changed to an adjacent label
(and recursively apply this). For real-valued labels we minimize the $L_p$
error. For linearly ordered sets we also give algorithms which minimize the sum
of the $L_p$ and weighted $L_0$ errors, a form of penalized (regularized)
regression. We also examine $L_0$ isotonic regression on multidimensional
coordinate-wise orderings. Previous algorithms took $\Theta(n^3)$ time, but we
reduce this to $o(n^{3/2})$.
</p></div>
    </summary>
    <updated>2021-06-02T22:48:38Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-06-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.00274</id>
    <link href="http://arxiv.org/abs/2106.00274" rel="alternate" type="text/html"/>
    <title>Analysis of classifiers robust to noisy labels</title>
    <feedworld_mtime>1622592000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Alex Díaz, Damian Steele <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.00274">PDF</a><br/><b>Abstract: </b>We explore contemporary robust classification algorithms for overcoming
class-dependant labelling noise: Forward, Importance Re-weighting and
T-revision. The classifiers are trained and evaluated on class-conditional
random label noise data while the final test data is clean. We demonstrate
methods for estimating the transition matrix in order to obtain better
classifier performance when working with noisy data. We apply deep learning to
three data-sets and derive an end-to-end analysis with unknown noise on the
CIFAR data-set from scratch. The effectiveness and robustness of the
classifiers are analysed, and we compare and contrast the results of each
experiment are using top-1 accuracy as our criterion.
</p></div>
    </summary>
    <updated>2021-06-02T22:48:33Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-06-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.00232</id>
    <link href="http://arxiv.org/abs/2106.00232" rel="alternate" type="text/html"/>
    <title>Multimodal Transportation with Ridesharing of Personal Vehicles</title>
    <feedworld_mtime>1622592000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gu:Qian=Ping.html">Qian-Ping Gu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liang:Jiajian_Leo.html">Jiajian Leo Liang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.00232">PDF</a><br/><b>Abstract: </b>The current public transportation system is unable to keep up with the
growing passenger demand as the population grows in urban areas. The slow or
lack of improvements for public transportation pushes people to use private
transportation modes, such as carpooling and ridesharing. However, the
occupancy rate of personal vehicles has been dropping in many cities. In this
paper, we propose a centralized transit system that integrates public transit
and ridesharing, which is capable of matching drivers and public transit riders
such that the riders would result in shorter travel time. The optimization goal
of the system is to assign as many riders to drivers as possible for
ridesharing. We describe an exact approach and approximation algorithms to
achieve the optimization goal. We conduct an extensive computational study to
show the effectiveness of the transit system for different approximation
algorithms. Our experiments are based on the real-world traffic data in Chicago
City; the data sets include both public transit and ridesharing trip
information. The experiment results show that our system is able to assign more
than 60% of riders to drivers, leading to a substantial increase in occupancy
rate of personal vehicles and reducing riders' travel time.
</p></div>
    </summary>
    <updated>2021-06-02T22:50:44Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-06-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.00220</id>
    <link href="http://arxiv.org/abs/2106.00220" rel="alternate" type="text/html"/>
    <title>Integer Coordinates for Intrinsic Geometry Processing</title>
    <feedworld_mtime>1622592000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Mark Gillespie, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sharp:Nicholas.html">Nicholas Sharp</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Crane:Keenan.html">Keenan Crane</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.00220">PDF</a><br/><b>Abstract: </b>In this work, we present a general, efficient, and provably robust
representation for intrinsic triangulations. These triangulations have emerged
as a powerful tool for robust geometry processing of surface meshes, taking a
low-quality mesh and retriangulating it with high-quality intrinsic triangles.
However, existing representations either support only edge flips, or do not
offer a robust procedure to recover the common subdivision, that is, how the
intrinsic triangulation sits along the original surface. To build a
general-purpose robust structure, we extend the framework of normal
coordinates, which have been deeply studied in topology, as well as the more
recent idea of roundabouts from geometry processing, to support a variety of
mesh processing operations like vertex insertions, edge splits, etc. The basic
idea is to store an integer per mesh edge counting the number of times a curve
crosses that edge. We show that this paradigm offers a highly effective
representation for intrinsic triangulations with strong robustness guarantees.
The resulting data structure is general and efficient, while offering a
guarantee of always encoding a valid subdivision. Among other things, this
allows us to generate a high-quality intrinsic Delaunay refinement of all
manifold meshes in the challenging Thingi10k dataset for the first time. This
enables a broad class of existing surface geometry algorithms to be applied
out-of-the-box to low-quality triangulations.
</p></div>
    </summary>
    <updated>2021-06-02T23:01:02Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2021-06-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.00185</id>
    <link href="http://arxiv.org/abs/2106.00185" rel="alternate" type="text/html"/>
    <title>Construction of Simplicial Complexes with Prescribed Degree-Size Sequences</title>
    <feedworld_mtime>1622592000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yen:Tzu=Chi.html">Tzu-Chi Yen</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.00185">PDF</a><br/><b>Abstract: </b>We study the realizability of simplicial complexes with a given pair of
integer sequences, representing the node degree distribution and facet size
distribution, respectively. While the $s$-uniform variant of the problem is
$\mathsf{NP}$-complete when $s \geq 3$, we identify two populations of input
sequences, most of which can be solved in polynomial time using a recursive
algorithm that we contribute. Combining with a sampler for the simplicial
configuration model [Young $\textit{et al.}$, Phys. Rev. E $\textbf{96}$,
032312 (2017)], we facilitate efficient sampling of simplicial ensembles from
arbitrary degree and size distributions. We find that, contrary to expectations
based on dyadic networks, increasing nodes' degrees reduces the number of loops
in simplicial complexes. Our work unveils a fundamental constraint on the
degree-size sequences and sheds light on further analysis of higher-order
phenomena based on local structures.
</p></div>
    </summary>
    <updated>2021-06-02T22:42:04Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-06-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.00157</id>
    <link href="http://arxiv.org/abs/2106.00157" rel="alternate" type="text/html"/>
    <title>Scalar Field Comparison with Topological Descriptors: Properties and Applications for Scientific Visualization</title>
    <feedworld_mtime>1622592000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yan:Lin.html">Lin Yan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Masood:Talha_Bin.html">Talha Bin Masood</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sridharamurthy:Raghavendra.html">Raghavendra Sridharamurthy</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rasheed:Farhan.html">Farhan Rasheed</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Natarajan:Vijay.html">Vijay Natarajan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hotz:Ingrid.html">Ingrid Hotz</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Bei.html">Bei Wang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.00157">PDF</a><br/><b>Abstract: </b>In topological data analysis and visualization, topological descriptors such
as persistence diagrams, merge trees, contour trees, Reeb graphs, and
Morse-Smale complexes play an essential role in capturing the shape of scalar
field data. We present a state-of-the-art report on scalar field comparison
using topological descriptors. We provide a taxonomy of existing approaches
based on visualization tasks associated with three categories of data: single
fields, time-varying fields, and ensembles. These tasks include symmetry
detection, periodicity detection, key event/feature detection, feature
tracking, clustering, and structure statistics. Our main contributions include
the formulation of a set of desirable mathematical and computational properties
of comparative measures, and the classification of visualization tasks and
applications that are enabled by these measures.
</p></div>
    </summary>
    <updated>2021-06-02T23:01:21Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2021-06-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.00124</id>
    <link href="http://arxiv.org/abs/2106.00124" rel="alternate" type="text/html"/>
    <title>Multidimensional Included and Excluded Sums</title>
    <feedworld_mtime>1622592000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/x/Xu:Helen.html">Helen Xu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fraser:Sean.html">Sean Fraser</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Leiserson:Charles_E=.html">Charles E. Leiserson</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.00124">PDF</a><br/><b>Abstract: </b>This paper presents algorithms for the included-sums and excluded-sums
problems used by scientific computing applications such as the fast multipole
method. These problems are defined in terms of a $d$-dimensional array of $N$
elements and a binary associative operator~$\oplus$ on the elements. The
included-sum problem requires that the elements within overlapping boxes
cornered at each element within the array be reduced using $\oplus$. The
excluded-sum problem reduces the elements outside each box. The weak versions
of these problems assume that the operator $\oplus$ has an inverse $\ominus$,
whereas the strong versions do not require this assumption. In addition to
studying existing algorithms to solve these problems, we introduce three new
algorithms.
</p>
<p>The bidirectional box-sum (BDBS) algorithm solves the strong included-sums
problem in $\Theta(d N)$ time, asymptotically beating the classical summed-area
table (SAT) algorithm, which runs in $\Theta(2^d N)$ and which only solves the
weak version of the problem. Empirically, the BDBS algorithm outperforms the
SAT algorithm in higher dimensions by up to $17.1\times$.
</p>
<p>The \defn{box-complement} algorithm can solve the strong excluded-sums
problem in $\Theta(d N)$ time, asymptotically beating the state-of-the-art
corners algorithm by Demaine et al., which runs in $\Omega(2^d N)$ time. In 3
dimensions the box-complement algorithm empirically outperforms the corners
algorithm by about $1.4\times$ given similar amounts of space.
</p>
<p>The weak excluded-sums problem can be solved in $\Theta(d N)$ time by the
bidirectional box-sum complement (BDBSC) algorithm, which is a trivial
extension of the BDBS algorithm. Given an operator inverse $\ominus$, BDBSC can
beat box-complement by up to a factor of $4$.
</p></div>
    </summary>
    <updated>2021-06-02T22:40:18Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-06-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.00091</id>
    <link href="http://arxiv.org/abs/2106.00091" rel="alternate" type="text/html"/>
    <title>Optimal Algorithms for Multiwinner Elections and the Chamberlin-Courant Rule</title>
    <feedworld_mtime>1622592000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Munagala:Kamesh.html">Kamesh Munagala</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shen:Zeyu.html">Zeyu Shen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Kangning.html">Kangning Wang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.00091">PDF</a><br/><b>Abstract: </b>We consider the algorithmic question of choosing a subset of candidates of a
given size $k$ from a set of $m$ candidates, with knowledge of voters' ordinal
rankings over all candidates. We consider the well-known and classic scoring
rule for achieving diverse representation: the Chamberlin-Courant (CC) or
$1$-Borda rule, where the score of a committee is the average over the voters,
of the rank of the best candidate in the committee for that voter; and its
generalization to the average of the top $s$ best candidates, called the
$s$-Borda rule.
</p>
<p>Our first result is an improved analysis of the natural and well-studied
greedy heuristic. We show that greedy achieves a $\left(1 -
\frac{2}{k+1}\right)$-approximation to the maximization (or satisfaction)
version of CC rule, and a $\left(1 - \frac{2s}{k+1}\right)$-approximation to
the $s$-Borda score. Our result improves on the best known approximation
algorithm for this problem. We show that these bounds are almost tight.
</p>
<p>For the dissatisfaction (or minimization) version of the problem, we show
that the score of $\frac{m+1}{k+1}$ can be viewed as an optimal benchmark for
the CC rule, as it is essentially the best achievable score of any
polynomial-time algorithm even when the optimal score is a polynomial factor
smaller (under standard computational complexity assumptions). We show that
another well-studied algorithm for this problem, called the Banzhaf rule,
attains this benchmark.
</p>
<p>We finally show that for the $s$-Borda rule, when the optimal value is small,
these algorithms can be improved by a factor of $\tilde \Omega(\sqrt{s})$ via
LP rounding. Our upper and lower bounds are a significant improvement over
previous results, and taken together, not only enable us to perform a finer
comparison of greedy algorithms for these problems, but also provide analytic
justification for using such algorithms in practice.
</p></div>
    </summary>
    <updated>2021-06-02T22:49:18Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-06-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.00001</id>
    <link href="http://arxiv.org/abs/2106.00001" rel="alternate" type="text/html"/>
    <title>Privately Learning Subspaces</title>
    <feedworld_mtime>1622592000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Singhal:Vikrant.html">Vikrant Singhal</a>, Thomas Steinke <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.00001">PDF</a><br/><b>Abstract: </b>Private data analysis suffers a costly curse of dimensionality. However, the
data often has an underlying low-dimensional structure. For example, when
optimizing via gradient descent, the gradients often lie in or near a
low-dimensional subspace. If that low-dimensional structure can be identified,
then we can avoid paying (in terms of privacy or accuracy) for the high ambient
dimension.
</p>
<p>We present differentially private algorithms that take input data sampled
from a low-dimensional linear subspace (possibly with a small amount of error)
and output that subspace (or an approximation to it). These algorithms can
serve as a pre-processing step for other procedures.
</p></div>
    </summary>
    <updated>2021-06-02T22:41:54Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-06-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-27705661.post-9052295508162981109</id>
    <link href="http://processalgebra.blogspot.com/feeds/9052295508162981109/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=27705661&amp;postID=9052295508162981109" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/9052295508162981109" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/9052295508162981109" rel="self" type="application/atom+xml"/>
    <link href="http://processalgebra.blogspot.com/2021/06/frank-p-ramsey-on-research-and.html" rel="alternate" type="text/html"/>
    <title>Frank P. Ramsey on research and publication rates</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Spurred by the excellent 1978 radio programme <a href="https://sms.cam.ac.uk/media/20145" target="_blank">'Better than the Stars'</a> by <a href="https://en.wikipedia.org/wiki/Hugh_Mellor" target="_blank">D. H. Mellor</a> about <a href="https://plato.stanford.edu/entries/ramsey/" target="_blank">Frank Ramsey</a> and by the <a href="https://traffic.libsyn.com/secure/philosophybites/Cheryl_Misak_on_Frank_Ramsey_and_Ludwig_Wittgenstein.mp3" target="_blank">Philosophy Bites interview with Cheryl Misak on Frank Ramsey and Ludwig Wittgenstein</a>, I started reading <a href="https://www.cherylmisak.com/" target="_blank">Cheryl Misak</a>'s <a href="https://global.oup.com/academic/product/frank-ramsey-9780198755357?cc=is&amp;lang=en&amp;" target="_blank">biography of Frank Ramsey</a>. (FWIW, I strongly recommend the radio programme, the podcast and the book.)<br/></p><p>The following quote from pages 169-170 of Cheryl Misak's book describes Ramsey's views on publications and research, as stated in a letter to his father Arthur:<br/></p><div style="margin-left: 40px; text-align: left;">Arthur tried a different tack, suggesting that Frank was going to be in trouble for wasting all this time on analysis, rather than on his career. On 24 September, in what seems to be his last letter home before he left Vienna, Frank wrote: </div><blockquote style="margin-left: 80px; text-align: left;">I don’t see how there can be any such inquisition into my conduct in Vienna as you suppose seem to want to guard against.... No one can suppose that you can’t research for six months without having a paper ready by the end. If everyone wrote a paper every six months the amount of trivial literature would swell beyond all bounds. Given time I shall produce a good paper. But if I hurry it will be ill written and unintelligible and unconvincing. <br/></blockquote><blockquote style="margin-left: 80px; text-align: left;">It seems to me perfectly proper to spend a scholarship being analysed, as it is likely to make me cleverer in the future, and discoveries of importance are made by remarkable people not by remarkable diligence. </blockquote><div style="margin-left: 40px; text-align: left;"> While it may not be persuasive that psychoanalysis makes one cleverer, Frank was prescient that the numbers of journal articles would eventually swell and he was right that diligence isn't enough to produce discoveries of importance.</div><div style="margin-left: 40px; text-align: left;"> </div><div style="text-align: left;">Of course, academia has changed since those times and I do value "remarkable diligence". However, I will try to remember Ramsey's words next time someone proposes to make academic hirings and promotions conditional to having a certain number of papers or citations or whatever per year on average. <br/></div></div>
    </content>
    <updated>2021-06-01T21:42:00Z</updated>
    <published>2021-06-01T21:42:00Z</published>
    <author>
      <name>Luca Aceto</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/01092671728833265127</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-27705661</id>
      <author>
        <name>Luca Aceto</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/01092671728833265127</uri>
      </author>
      <link href="http://processalgebra.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://processalgebra.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Papers I find interesting---mostly, but not solely, in Process Algebra---, and some fun stuff in Mathematics and Computer Science at large and on general issues related to research, teaching and academic life.</subtitle>
      <title>Process Algebra Diary</title>
      <updated>2021-06-01T21:43:16Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=5536</id>
    <link href="https://www.scottaaronson.com/blog/?p=5536" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=5536#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=5536" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Three updates</title>
    <summary xml:lang="en-US">Hooray, I’m today’s “Featured ACM Member”! Which basically means, yet another interview with me about quantum computing, with questions including what’s most surprised me about the development of QC, and what students should do to get into the field. I’m proud to announce that An Automated Approach to the Collatz Conjecture, a paper by Emre […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><ol><li>Hooray, I’m <a href="https://www.acm.org/articles/people-of-acm/2021/scott-aaronson">today’s “Featured ACM Member”</a>!  Which basically means, yet another interview with me about quantum computing, with questions including what’s most surprised me about the development of QC, and what students should do to get into the field.</li><li>I’m proud to announce that <a href="https://arxiv.org/abs/2105.14697">An Automated Approach to the Collatz Conjecture</a>, a paper by Emre Yolcu, myself, and Marijn Heule that we started working on over four years ago, is finally available on the arXiv, and will be presented at the 2021 <a href="https://www.cs.cmu.edu/~mheule/CADE28/">Conference on Automated Deduction</a>.  Long story short: no, we didn’t prove <a href="https://en.wikipedia.org/wiki/Collatz_conjecture">Collatz</a>, but we have an approach that can for the first time prove certain Collatz-like statements in a fully automated way, so hopefully that’s interesting!  There was also a <a href="https://www.quantamagazine.org/can-computers-solve-the-collatz-conjecture-20200826/"><em>Quanta</em> article</a> even before our paper had come out (I wasn’t thrilled about the timing).</li><li>The legendary <a href="https://en.wikipedia.org/wiki/Baba_Brinkman">Baba Brinkman</a> has a <a href="https://www.youtube.com/watch?v=kVcOx9Bg3a4">new rap about quantum computing</a> (hat tip to blog commenter YD).  Having just watched the music video, I see it as one of the better popularization efforts our field has seen in the past 25 years—more coherent than the average journalistic account and with a <em>much</em> better backbeat.  (I do, however, take a more guarded view than Brinkman of the potential applications, especially to e.g. autonomous driving and supply-chain optimization.)</li></ol>



<p/></div>
    </content>
    <updated>2021-06-01T20:00:21Z</updated>
    <published>2021-06-01T20:00:21Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Announcements"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Quantum"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2021-06-01T20:00:21Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://agtb.wordpress.com/?p=3526</id>
    <link href="https://agtb.wordpress.com/2021/06/01/wine21-call-for-papers/" rel="alternate" type="text/html"/>
    <title>WINE’21 Call for Papers</title>
    <summary>WINE 2021: The 17th Conference on Web and Internet Economics  December 14-17, 2021Hasso Plattner Institute, Potsdam, Germany Overview Over the past two decades, researchers in theoretical computer science, artificial intelligence, operations research, and economics have joined forces to understand the interplay of incentives and computation. These issues are of particular importance in the Web and […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><strong>WINE 2021: The 17th Conference on Web and Internet Economics </strong></p>



<p><strong>December 14-17, 2021</strong><br/><strong>Hasso Plattner Institute, Potsdam, Germany</strong></p>



<p/><blockquote class="wp-embedded-content"><a href="https://hpi.de/wine2021/">Overview</a></blockquote><p/>



<p>Over the past two decades, researchers in theoretical computer science, artificial intelligence, operations research, and economics have joined forces to understand the interplay of incentives and computation. These issues are of particular importance in the Web and the Internet that enable the interaction of large and diverse populations. The Conference on Web and Internet Economics (WINE) is an interdisciplinary forum for the exchange of ideas and results on incentives and computation arising from these various fields. WINE 2021 continues the successful tradition of the Conference on Web and Internet Economics (named Workshop on Internet &amp; Network Economics until 2013), which was held annually from 2005 to present.</p>



<p>The program will feature invited talks, tutorials, paper presentations, and a poster session. All paper submissions will be peer-reviewed and evaluated on the basis of the quality of their contribution, originality, soundness, and significance. Submissions are invited in, but not limited to, the following topics:</p>



<ul><li>Algorithmic Game Theory</li><li>Algorithmic Mechanism Design</li><li>Auction Algorithms and Analysis</li><li>Computational Advertising</li><li>Computational Aspects of Equilibria</li><li>Computational Social Choice</li><li>Learning in Markets and Mechanism Design</li><li>Learning under Strategic Behavior</li><li>Coalitions, Coordination, and Collective Action</li><li>Economic Aspects of Security and Privacy</li><li>Economic Aspects of Distributed Computing and Cryptocurrencies</li><li>Econometrics, ML, and Data Science</li><li>Behavioral Economics and Behavioral Modeling</li><li>Fairness and Trust in Games and Markets</li><li>Price Differentiation and Price Dynamics</li><li>Revenue Management</li><li>Social Networks and Network Games</li></ul>



<p><strong>Authors of the accepted papers will have a choice to attend the conference virtually.</strong></p>



<p><strong>Important Dates</strong></p>



<p>Paper submission deadline: July 12, 2021, 11:59pm Pacific Time</p>



<p>Author notification: September (exact date TBA)</p>



<p><strong>Submission Format</strong></p>



<p>Authors are invited to submit extended abstracts presenting original research on any of the research fields related to WINE 2021.</p>



<p>An extended abstract submitted to WINE 2021 should start with the title of the paper, each author’s name, affiliation and e-mail address, followed by a one-paragraph summary of the results to be presented. This should then be followed by a technical exposition of the main ideas and techniques used to achieve these results, including motivation and a clear comparison with related work.</p>



<p>The extended abstract should not exceed 18 single-spaced pages (excluding references) using reasonable margins (at least one-inch margins all around) and at least 11-point font. If the authors believe that more details are essential to substantiate the claims of the paper, they may include a clearly marked appendix (with no space limit) that will be read at the discretion of the Program Committee. It is strongly recommended that submissions adhere to the specified format and length. Submissions that are clearly too long may be rejected immediately. The above specifications are meant to provide more freedom to the authors at the time of submission. Note that accepted papers will be allocated 14 pages (including references) in the LNCS format in the proceedings (see below).</p>



<p>The proceedings of the conference will be published by Springer-Verlag in the ARCoSS/LNCS series, and will be available for distribution at the conference. Accepted papers will be allocated 14 pages total in the LNCS format in the proceedings. Submissions are encouraged, though not required, to follow the LNCS format (Latex, Word). More information about the LNCS format can be found on the <a href="https://www.springer.com/cn/computer-science/lncs/conference-proceedings-guidelines" rel="noreferrer noopener" target="_blank">author instructions page of Springer-Verlag</a>. </p>



<p><strong>Best Paper Award</strong></p>



<p>The program committee will decide upon a best paper award and a best student paper award.</p>



<p><strong>Important Notice</strong></p>



<p>To accommodate the publishing traditions of different fields, authors of accepted papers can ask that only a one-page abstract of the paper appear in the proceedings, along with a URL pointing to the full paper. The authors should guarantee the link to be reliable for at least two years. This option is available to accommodate subsequent publication in journals that would not consider results that have been published in preliminary form in conference proceedings. Such papers must be submitted and formatted just like papers submitted for full-text publication.</p>



<p>Simultaneous submission of results to another conference with published proceedings is not allowed. Results previously published or presented at another archival conference prior to WINE 2021, or published (or accepted for publication) at a journal prior to the submission deadline of WINE 2021, will not be considered. Simultaneous submission of results to a journal is allowed only if the authors intend to publish the paper as a one-page abstract in WINE 2021. Papers that are accepted and appear as a one-page abstract can be subsequently submitted for publication in a journal but may not be submitted to any other conference that has a published proceeding.</p>



<p>Program PC co-chairs: Michal Feldman (chair), Hu Fu and Inbal Talgam-Cohen</p></div>
    </content>
    <updated>2021-06-01T09:39:25Z</updated>
    <published>2021-06-01T09:39:25Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>michalfeldman</name>
    </author>
    <source>
      <id>https://agtb.wordpress.com</id>
      <logo>https://secure.gravatar.com/blavatar/52ef314e11e379febf97d1a97547f4cd?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fbuttonw-com.png</logo>
      <link href="https://agtb.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://agtb.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://agtb.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://agtb.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Computation, Economics, and Game Theory</subtitle>
      <title>Turing's Invisible Hand</title>
      <updated>2021-06-03T03:20:30Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://toc4fairness.org/?p=1768</id>
    <link href="https://toc4fairness.org/forc-2021-is-coming-up/" rel="alternate" type="text/html"/>
    <title>FORC 2021 is coming up!</title>
    <summary>The Second annual Symposium on the Foundations of Responsible Computing (FORC) will be held virtually (on Gather.town) June 9-11, 2021. Registration is free, but required, by June 7. Instructions for ...</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Second annual Symposium on the Foundations of Responsible Computing (FORC) will be held virtually (on Gather.town) June 9-11, 2021.<a href="https://docs.google.com/forms/d/e/1FAIpQLSfELj0MvgcI83dmYThUPiynqWj8-G9Xve2dVf84EqKzgXXsHQ/viewform" rel="noreferrer noopener" target="_blank"> Registration is free, but required, by June 7</a>. Instructions for joining the event will be emailed to registered participants and posted online on June 8.</p>



<p>The program will feature 24 papers, six exciting panel discussions, three social hours featuring interactive board games, keynotes by Julie Owono (of the Facebook Oversight Board) and Kate Crawford (on her new book, the Atlas of AI), and a mentoring meetup.</p>



<p>The full program is here: <a href="https://responsiblecomputing.org/forc-2021-program/" rel="noreferrer noopener" target="_blank">https://responsiblecomputing.org/forc-2021-program/</a></p>



<p>The Symposium on Foundations of Responsible Computing (FORC) is a forum for mathematical research in computation and society writ large. The Symposium aims to catalyze the formation of a community supportive of the application of theoretical computer science, statistics, economics and other relevant analytical fields to problems of pressing and anticipated societal concern.</p>



<figure class="wp-block-image size-large"><img alt="" class="wp-image-1770" height="858" src="https://i2.wp.com/toc4fairness.org/wp-content/uploads/2021/05/white-logo-no-background.png?resize=800%2C858&amp;ssl=1" width="800"/></figure></div>
    </content>
    <updated>2021-06-01T06:49:04Z</updated>
    <published>2021-06-01T06:49:04Z</published>
    <category term="Blog"/>
    <author>
      <name>galoosh33</name>
    </author>
    <source>
      <id>https://toc4fairness.org</id>
      <logo>https://i1.wp.com/toc4fairness.org/wp-content/uploads/2020/10/cropped-favicon.png?fit=32%2C32&amp;ssl=1</logo>
      <link href="https://toc4fairness.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://toc4fairness.org" rel="alternate" type="text/html"/>
      <subtitle>a simons collaboration project</subtitle>
      <title>TOC for Fairness</title>
      <updated>2021-06-03T03:21:56Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2021/05/31/linkage</id>
    <link href="https://11011110.github.io/blog/2021/05/31/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>Ememem’s mosaic interventions in the potholes of Lyon (\(\mathbb{M}\), see also, and also). I find this kind of urban kintsugi pleasing, not just for its aspect of guerilla art, but for the sharp geometric patterns of the mosaics and the rough boundaries where they meet the landscape around them.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><ul>
  <li>
    <p><a href="https://www.thisiscolossal.com/2021/05/ememem-street-mosaics/">Ememem’s mosaic interventions in the potholes of Lyon</a> (<a href="https://mathstodon.xyz/@11011110/106251596474278206">\(\mathbb{M}\)</a>, <a href="https://www.ememem-flacking.net/flacking">see also</a>, <a href="https://boingboing.net/2021/05/17/this-artist-repairs-damaged-sidewalks-with-beautiful-mosaic-tiles.html">and also</a>). I find this kind of urban kintsugi pleasing, not just for its aspect of guerilla art, but for the sharp geometric patterns of the mosaics and the rough boundaries where they meet the landscape around them.</p>
  </li>
  <li>
    <p><a href="https://tilings.math.uni-bielefeld.de/">Tilings encyclopedia</a> (<a href="https://mathstodon.xyz/@11011110/106255097813445827">\(\mathbb{M}\)</a>). An online collection of many pretty substitution tilings. What’s missing to make it closer to OEIS in usefulness is a way to search by tiling rather than by keyword in the description of the tiling.</p>
  </li>
  <li>
    <p>At UC Irvine, we’ve been using Piazza for online course forums, but Piazza insists on serving ads to students (despite being paid), so we’re moving to <a href="https://edstem.org/us/">Ed Discussion</a> instead (<a href="https://mathstodon.xyz/@11011110/106258490049583719">\(\mathbb{M}\)</a>). You can see similar moves at <a href="https://rtl.berkeley.edu/news/piazza-and-new-online-discussion-platform-update">Berkeley</a> and <a href="https://news.psu.edu/story/641227/2020/12/07/academics/piazza-class-discussion-platform-start-displaying-advertisements">Penn State</a>. Usually I mistrust campus choices of software infrastructure — they tend to go for big crufty hard-to-use packages that are a poor fit for our needs — but this appears to be for good reason and I support it.</p>
  </li>
  <li>
    <p><a href="https://www.quantamagazine.org/mathematicians-answer-old-question-about-odd-graphs-20210519/"><em>Quanta</em> highlights one of my UCI colleagues, Asaf Ferber, for his work with Michael Krivelevich proving that every graph without isolated vertices has an induced subgraph of \(\Omega(n)\) vertices in which all vertices have odd degree</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/106265785749549559">\(\mathbb{M}\)</a>).</span> As usual, they also get important details wrong, forgetting to mention that the subgraphs must be induced, and also not mentioning the requirement of no isolated vertices. For the actual preprint see <a href="https://arxiv.org/abs/2009.05495">arXiv:2009.05495</a>.</p>
  </li>
  <li>
    <p><a href="https://www.insidehighered.com/news/2021/05/20/unc-chapel-hill-board-doesnt-approve-tenure-noted-journalist">Academic freedom dead at  U. of North Carolina</a> (<a href="https://mathstodon.xyz/@11011110/106269430445568583">\(\mathbb{M}\)</a>, <a href="https://www.metafilter.com/191525/Nikole-Hannah-Jones-Denied-Tenure-at-UNC">via</a>, <a href="https://www.nytimes.com/2021/05/19/business/media/nikole-hannah-jones-unc.html">see also</a>): right-wing board of trustees cancel-cultures MacArthur and Pulitzer winner Nikole Hannah-Jones for racist/political reasons (they don’t want anyone to talk about US slavery and ongoing systemic racism). To be clear, she still has a position at UNC; after the trustees denied her tenure, her department gave her a five-year-renewable spot not requiring trustee approval.</p>
  </li>
  <li>
    <p><a href="https://gilkalai.wordpress.com/2021/05/20/to-cheer-you-up-in-difficult-times-25-some-mathematical-news-part-2/">Some mathematical news</a> (<a href="https://mathstodon.xyz/@11011110/106277146476845581">\(\mathbb{M}\)</a>). Gil Kalai rounds up a lot of recent developments in knot recognition complexity, exotic spheres, numbers of fixed points, graph theory, and additive combinatorics.</p>
  </li>
  <li>
    <p><a href="https://www34.homepage.villanova.edu/robert.jantzen/notes/torus/cavatappo20/">Tilted cavatappo surfaces</a> (<a href="https://mathstodon.xyz/@11011110/106280088634102191">\(\mathbb{M}\)</a>). Robert Jantzen studies the shape of <a href="https://en.wikipedia.org/wiki/Cavatappi">corkscrew tube pasta</a> and of shortest paths on its surface. See also his preprints <a href="https://arxiv.org/abs/1301.0013">arXiv:1301.0013</a> and <a href="https://arxiv.org/abs/1402.3284">arXiv:1402.3284</a>.</p>
  </li>
  <li>
    <p>Here’s an unexpected property of hyperbolic geometry (<a href="https://mathstodon.xyz/@11011110/106288718744948273">\(\mathbb{M}\)</a>), or at least, it struck me as counterintuitive: all lines through two opposite quadrants of two perpendicular lines pass near their crossing, within distance \(\ln(1+\sqrt2)\). The figure below uses the upper halfplane model to show two quadrants (dark yellow), their convex hull (light yellow, from which the lines cannot escape), and a circle of radius \(\ln(1+\sqrt2)\) centered at the crossing, separating the quadrants.</p>

    <p style="text-align: center;"><img alt="Convex hull of the quadrants formed in the hyperbolic plane by two perpendicular lines, and a circle centered at the crossing separating the quadrants" src="https://11011110.github.io/blog/assets/2021/double-wedge-hull.svg"/></p>
  </li>
  <li>
    <p><a href="https://www.youtube.com/watch?v=HeQX2HjkcNo">Veritaserium on Cantor, Gödel, and Turing</a> (<a href="https://mathstodon.xyz/@gnivasch/106290995069247640">\(\mathbb{M}\)</a>).</p>
  </li>
  <li>
    <p>At a time when national borders have largely shut down, significantly decreasing the opportunities for higher education for people with the misfortune to be born in the wrong part of the world, <a href="https://www.latimes.com/california/story/2021-05-25/bold-plan-for-uc-admissions-reduce-out-of-state-students">California’s legislators are pushing to enact the same barriers to education across state lines</a> (<a href="https://mathstodon.xyz/@11011110/106297102605074297">\(\mathbb{M}\)</a>), preventing access to education and hurting the state itself by discouraging the best and brightest from coming here.</p>
  </li>
  <li>
    <p>Cellphone snapshot of the UC Irvine Ecological Preserve on a recent cloudy day (<a href="https://mathstodon.xyz/@11011110/106305347918888735">\(\mathbb{M}\)</a>). The foreground is mostly mustard, of no particular ecological significance; the ecological part is the coastal sage scrub on the sunny hillside in the background.</p>

    <p style="text-align: center;"><img alt="UCI Ecological Preserve" src="https://www.ics.uci.edu/~eppstein/pix/uciep2/DriedMustard-m.jpg" style="border-style: solid; border-color: black;" width="80%"/></p>
  </li>
  <li>
    <p><a href="https://doi.org/10.1007/BF02764015">Aperiodic tilings of the hyperbolic plane by convex polygons</a> (<a href="https://mathstodon.xyz/@11011110/106314334930093898">\(\mathbb{M}\)</a>), Margulis and Mozes, 1998. I knew about the <a href="https://en.wikipedia.org/wiki/Binary_tiling">binary tilings</a> but not this, which gets aperiodicity differently: if a tile’s area isn’t a rational multiple of \(\pi\), it cannot be periodic. This works even for certain hyperbolic rhombi, with angles chosen so they can tile. The tilings can still have 1d symmetry. If some single tile  avoids all symmetries, I don’t know about it.</p>
  </li>
  <li>
    <p><a href="http://www.geometrictomography.com/">Geometric tomography</a> (<a href="https://mathstodon.xyz/@11011110/106317414925334494">\(\mathbb{M}\)</a>). A nicely presented brief web survey of this subject, on the reconstruction of 3d shapes from 2d information (such as its brightness function, the areas of its perpendicular projections), by Richard J. Gardner based on his 1995 book of the same title.</p>
  </li>
  <li>
    <p><a href="https://cacm.acm.org/magazines/2021/6/252840-collusion-rings-threaten-the-integrity-of-computer-science-research/fulltext">Collusion rings threaten the integrity of computer science research</a> (<a href="https://mathstodon.xyz/@11011110/106320077489874249">\(\mathbb{M}\)</a>), Michael L. Littman, CACM. Relatedly: <a href="https://www.chemistryworld.com/news/publishers-grapple-with-an-invisible-foe-as-huge-organised-fraud-hits-scientific-journals/4013652.article">“huge organised fraud” in scientific journals</a>, <a href="https://retractionwatch.com/2021/05/29/weekend-reads-gibberish-papers-persist-the-academic-who-faked-cherokee-heritage-organised-fraud-hits-scientific-journals/">via Retraction Watch</a>.</p>
  </li>
  <li>
    <p><a href="https://www.youtube.com/watch?v=8Sv_FaEN8zE">Five talks from CanaDAM 2021 introducing graph product structure theory and its applications</a> (<a href="https://mathstodon.xyz/@patmorin/106300452133561408">\(\mathbb{M}\)</a>).</p>
  </li>
  <li>
    <p><a href="https://isohedral.ca/heesch-numbers-of-unmarked-polyforms/">Big progress in classifying polyforms by their Heesch numbers, obtained by using a SAT solver in place of an ad-hoc backtracking search for tilings</a> (<a href="https://mathstodon.xyz/@11011110/106331731989277653">\(\mathbb{M}\)</a>, <a href="https://www.metafilter.com/191587/TikTok-teen-points-to-inside-elbow-bites-lip-Heeeeeeeesch">via</a>). See also <a href="https://twitter.com/mathpuzzle/status/1397040707706236928">Ed Pegg on an infinite set of polyforms with Heesch = 3</a>.</p>
  </li>
</ul></div>
    </content>
    <updated>2021-05-31T14:09:00Z</updated>
    <published>2021-05-31T14:09:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2021-05-31T21:10:15Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-6576209065051505306</id>
    <link href="https://blog.computationalcomplexity.org/feeds/6576209065051505306/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2021/05/what-is-natural-question-who-should.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/6576209065051505306" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/6576209065051505306" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2021/05/what-is-natural-question-who-should.html" rel="alternate" type="text/html"/>
    <title>What is a natural question? Who should decide?</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><br/></p><p>(Thanks to Timothy Chow for inspiring this post.)</p><p>My survey on Hilbert's Tenth Problem(see  <a href="https://arxiv.org/abs/2104.07220">here</a>) is about variants of the problem. One of them is as follows: </p><p>For which degrees d and number-of-vars n, is Hilbert's tenth problem decidable? undecidable? unknown? </p><p> I wondered why there was not a website with this information. More generally, the problem didn't seem to be getting much attention. (My survey does report on the attention it has gotten.) </p><p>I got several emails telling me it was the wrong question. I didn't quite know what they meant until Timothy Chow emailed me the following eloquent explanation:</p><p>-----------------------------------</p><p><i>One reason there isn't already a website of the type you envision is that from a number-theoretic (or decidability) point of view, parameterization by  degree and number of variables is not as natural as it might seem at first glance. The most fruitful lines of research have been geometric, and so geometric concepts such as smoothness, dimension, and genus are more natural than, say, degree. A nice survey by a number theorist is the book Rational Points on Varieties by Bjorn Poonen. Much of it is highly technical; however, reading the preface is very enlightening. Roughly speaking, the current state of the art is that there is really only one known way to prove that a system of Diophantine equations has no rational solution.</i></p><p>----------------------------------</p><p>AGAINST THE NUMBER THEORISTS VIEWPOINT:</p><p>1) ALICE: Why are you looking for your keys under the lamppost instead of where you dropped them?</p><p>   BOB: The light is better here.</p><p>2) I can imagine the following conversation:</p><p>BILL: I want to know about what happens with degree 3, and number of variables 3.</p><p>MATHPERSON: That's the wrong question you moron. The real question is what happens for fixed length of cohomology subchains.</p><p>BILL: Why is that more natural?</p><p>MATHPERSON: Because that is what we can solve. And besides, I've had 10 papers on it.</p><p><br/></p><p>FOR THE NUMBER THEORISTS VIEWPOINT</p><p>1) They are working on really hard problems so it is natural to gravitate towards those that can be solved.</p><p>2) I suspect that the math that comes out of studying classes of equations based on smoothness, dimension, genus is more interesting than what comes out of degree and number of vars. Or at least it has been so far. </p><p>META QUESTION</p><p>Who gets to decide what problems are natural?</p><p>People outside the field (me in this case) are asking the kind of questions that a layperson would ask and there is some merit to that.</p><p>People inside the field KNOW STUFF and hence their opinion of what's interesting to study has some merit. But they can also mistake `I cannot solve X' for `X is not interesting'</p><div><br/></div></div>
    </content>
    <updated>2021-05-30T23:31:00Z</updated>
    <published>2021-05-30T23:31:00Z</published>
    <author>
      <name>gasarch</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03004932739846901628</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2021-06-03T01:51:45Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=21758</id>
    <link href="https://gilkalai.wordpress.com/2021/05/30/to-cheer-you-up-in-difficult-times-24-borodins-colouring-conjecture/" rel="alternate" type="text/html"/>
    <title>To Cheer You Up in Difficult times 24: Borodin’s colouring conjecture!</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">An acyclic colouring of a graph is a colouring of its vertices so that the subgraph spanned on union of every two colour classes is acyclic (a forest). Grunbaum conjectured in 1973 that Every planar graph has acyclic colouring with … <a href="https://gilkalai.wordpress.com/2021/05/30/to-cheer-you-up-in-difficult-times-24-borodins-colouring-conjecture/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>An <a href="https://en.wikipedia.org/wiki/Acyclic_coloring">acyclic colouring</a> of a graph is a colouring of its vertices so that the subgraph spanned on union of every two colour classes is acyclic (a forest). Grunbaum conjectured in 1973 that </p>



<p class="has-text-align-center"><strong><span class="has-inline-color" style="color: #a30042;">Every planar graph has acyclic colouring with five colours.</span> </strong></p>



<p>This was proved by Borodin in 1976.</p>



<p>Borodin made the following stronger conjecture. Recall that a graph is <img alt="r" class="latex" src="https://s0.wp.com/latex.php?latex=r&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/>-degenerate if every  subgraph has a vertex of degree at most <img alt="r" class="latex" src="https://s0.wp.com/latex.php?latex=r&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/>. </p>



<p class="has-text-align-center"><strong><span class="has-inline-color" style="color: #a3001e;">Every planar graph <em>G</em> can be coloured with five colours so that the union of every <em>k</em> colour classes, <img alt="1 \le k \le 4" class="latex" src="https://s0.wp.com/latex.php?latex=1+%5Cle+k+%5Cle+4&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/> induces a <em>(k-1)</em>-degenerate graph. </span></strong></p>



<p>Let me mention an intermediate conjecture in-between Grunbaum’s conjecture and Borodin’s </p>



<p class="has-text-align-center"><strong><span class="has-inline-color" style="color: #a30011;">Every planar graph <em>G</em> can be coloured with five colours so that the union of every <em>k</em> colour classes, <img alt="1 \le k \le 4" class="latex" src="https://s0.wp.com/latex.php?latex=1+%5Cle+k+%5Cle+4&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/> induces a stress free graph for generic embedding into <img alt="R^{k-1}" class="latex" src="https://s0.wp.com/latex.php?latex=R%5E%7Bk-1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/>.</span></strong> <br/><br/></p>



<p>Grunbaum’s 1973 paper <a href="https://idp.springer.com/authorize/casa?redirect_uri=https://link.springer.com/article/10.1007/BF02764716&amp;casa_token=vnWD-T_S73sAAAAA:mUenckyg9cyx5mrJI0hGdRqZ5WznXX-keyu4jYW61z-CkI1pslMA4w7SheVILEa1g1yHmjmFrP63EoqPODY">Acyclic<strong> </strong>colorings of planar graphs‏</a> is a very imaginative and highly cited paper. It was the first paper I ever refereed and I remember spending a lot of time reading it.  Here is the link to Borodin’s paper <a href="https://www.sciencedirect.com/science/article/pii/0012365X79900773">On acyclic colorings of planar graphs‏</a>. I am not sure what is the current world-record for the number of colours.</p></div>
    </content>
    <updated>2021-05-30T20:44:18Z</updated>
    <published>2021-05-30T20:44:18Z</published>
    <category term="Combinatorics"/>
    <category term="Branko Grunbaum"/>
    <category term="Oleg Borodin"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2021-06-03T03:20:28Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://theorydish.blog/?p=2235</id>
    <link href="https://theorydish.blog/2021/05/26/few-lessons-from-the-history-of-multiparty-computation/" rel="alternate" type="text/html"/>
    <title>A few lessons from the history of multiparty computation</title>
    <summary>As part of my Ph.D. qualifying exam, I gave a survey talk on some of the recent progress in practical multi-party computation (MPC). After the talk, Omer Reingold asked me why so much progress on MPC happened in the last decade or so, given that the main theoretical groundwork for multiparty computation was laid out in the 1980s.  Omer’s question got me interested, so I looked at some MPC papers from over the years and talked to a few people who have been working on MPC for some time now. In this post, I want to share some of what I’ve learned about the history of the progress of MPC, a few answers to Omer’s question, and potentially a few takeaways on progress in science more broadly. To give a bit of background, MPC is one of the most fundamental problems in cryptography. In particular, MPC protocols allow a set of parties, each of which holds its private input, to compute a joint function over their inputs, in a way that protects the confidentiality and integrity of the computation from an adversary that controls a subset of the parties and the communication channels. Defining this precisely requires a lot of [...]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>As part of my Ph.D. qualifying exam, I gave a survey talk on some of the recent progress in practical multi-party computation (MPC). After the talk, Omer Reingold asked me why so much progress on MPC happened in the last decade or so, given that the main theoretical groundwork for multiparty computation was laid out in the 1980s.  Omer’s question got me interested, so I looked at some MPC papers from over the years and talked to a few people who have been working on MPC for some time now. In this post, I want to share some of what I’ve learned about the history of the progress of MPC, a few answers to Omer’s question, and potentially a few takeaways on progress in science more broadly.</p>



<p>To give a bit of background, MPC is one of the most fundamental problems in cryptography. In particular, MPC protocols allow a set of parties, each of which holds its private input, to compute a joint function over their inputs, in a way that protects the confidentiality and integrity of the computation from an adversary that controls a subset of the parties and the communication channels. Defining this precisely requires a lot of care, yet for now, you can think of an MPC protocol as being secure, if the adversary can only cause as much damage as it can in an “ideal world” in which the computation is performed with the aid of a trusted incorruptible party. Intuitively, in such an ideal world, the adversary cannot do much more than choose its inputs, modify its output, or choose not to participate in the computation at all. </p>



<p>In the 1980s, a <a href="https://ieeexplore.ieee.org/abstract/document/4568207">sequence</a> <a href="https://dl.acm.org/doi/10.1145/28395.28420">of</a> <a href="https://dl.acm.org/doi/10.1145/62212.62213">works</a> <a href="https://dl.acm.org/doi/10.1145/62212.62214">initiated</a> the study of multiparty computation and established very powerful and general results, showing the feasibility of constructing protocols for securely computing any multi-party functionality in a variety of settings. Those results were mostly theoretical. In contrast, the last 15 years saw a growing interest in MPC from a more practical perspective. To put this rising interest in context, consider the following two graphs (data for the graphs is <a href="https://docs.google.com/spreadsheets/d/1IzfKDRqv6C9hSeD9TyosvCl9fknN2V3Ja4tQjy54y0A/edit?usp=sharing">here</a>).</p>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-2245" height="372" src="https://theorydish.files.wordpress.com/2021/05/comptime.png?w=620" width="620"/></figure></div>



<p>This graph shows the time of a two-party secure computation of the AES block cipher over the years. That is the time it takes to evaluate AES(k,x), where one party holds a 128-bit key k to the block cipher, the other party holds a 256-bit data block x, and the output is 256-bit long. The measurements are from the original papers. There are different variants of this “benchmark”, in terms of the number of parties (2PC/MPC), the number of corrupted parties (honest/dishonest majority), precise security model (semi-honest/fully malicious), hardware, network (LAN/WAN), and cost model (single/batch execution), but, for concreteness, the graph only includes results in the batch-evaluation setting in the fully malicious two-party setting. </p>



<p class="has-text-align-center"><img height="375" src="https://lh4.googleusercontent.com/lfa7-L5D3d5U8ZCHbAmUoqRH-RVaUmpFfSiFhBl7yF38ieoUmdo-LL0xH-gzXEaPauRXkCUmOYWDovfJvE792a0ikVxojM6g4P7EFD-mg4A2XbvzJWAslBug8UE6W4CnRhtIt4el" width="624"/></p>



<p>The second graph shows the number of papers on two-party computation, over the years. This is not a very well-defined characterization, but for simplicity, I looked at all the papers referenced from the relevant chapters in the <a href="https://securecomputation.org/">book on MPC</a> by Evans, Kolesnikov, and Rosulek. Admittedly, these are not all the papers in the area, there might be valuable indirect contributions that are missing, and, more importantly, the number of papers is a bit of a superficial metric. Yet, even with these caveats, I think this is helpful to get a general picture. On top of the flurry of academic research, MPC has also been thriving in the industry, with companies like <a href="https://www.curv.co/">Curv</a>, <a href="https://partisia.com/">Partisia</a>, <a href="https://sharemind.cyber.ee/">Sharemind</a>, <a href="https://www.unboundsecurity.com/">Unbound</a>, and others building MPC-based products and services.</p>



<p>The first graph shows quite impressive progress. In less than a decade, the time to securely compute AES in the two-party setting decreased by more than 60,000x, from more than 10 minutes to less than 10 milliseconds. (For reference, in the same period, CPU speeds increased <a href="https://www.cpubenchmark.net/cpu.php?cpu=Intel+Core+i7-975+%40+3.33GHz&amp;id=841">roughly</a> <a href="https://www.cpubenchmark.net/cpu.php?cpu=Intel+Core+i7-7740X+%40+4.30GHz&amp;id=3041">twofold</a>, and typical local-area network speeds increased from 1GB/S to 10GB/S.) The second graph illustrates the increase in the volume of research, which has enabled this progress. This includes advances such as <a href="https://dl.acm.org/doi/10.1145/100216.100287">various</a> <a href="https://dl.acm.org/doi/10.1145/336992.337028">increasingly</a> <a href="https://link.springer.com/chapter/10.1007/978-3-540-70583-3_40">efficient</a> <a href="https://link.springer.com/chapter/10.1007/978-3-662-46803-6_8">garbling</a> <a href="https://dl.acm.org/doi/10.1145/3133956.3134053">techniques</a>, <a href="https://link.springer.com/chapter/10.1007%2F11745853_30">more</a> <a href="https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.140.2627&amp;rep=rep1&amp;type=pdf">efficient</a> <a href="https://link.springer.com/chapter/10.1007/978-3-540-72540-4_4">cut</a>–<a href="https://link.springer.com/chapter/10.1007/978-3-642-20465-4_22">and</a>–<a href="https://link.springer.com/chapter/10.1007/978-3-642-19571-6_20">choose</a> <a href="https://link.springer.com/chapter/10.1007/978-3-642-40084-1_3">techniques</a> <a href="https://link.springer.com/chapter/10.1007/978-3-642-00457-5_22">for</a> <a href="https://dl.acm.org/doi/10.1145/2508859.2516698">malicious security</a>, <a href="https://link.springer.com/chapter/10.1007/978-3-642-20465-4_11">protocols</a> <a href="https://link.springer.com/chapter/10.1007/978-3-642-32009-5_38">based on</a> <a href="https://link.springer.com/chapter/10.1007/978-3-642-32009-5_40">information-theoretic</a> <a href="https://dl.acm.org/doi/10.1145/2976749.2978357">message-authentication</a> <a href="https://link.springer.com/chapter/10.1007/978-3-319-78372-7_6">codes</a>, <a href="https://crypto.stanford.edu/craig/craig-thesis.pdf">homomorphic</a> <a href="https://dl.acm.org/doi/10.1145/2090236.2090262">encryption</a>, and many others. (See the EKR book for an overview of these techniques and more references.) The second graph also clearly shows the inflection point that happened about 15 years ago. This inflection point illustrates the premise of the question that has triggered this blog post.</p>



<p>I use the term inflection point, since progress in MPC never really stopped between the late 80s and the mid-2000s, and there was a lot of research in the interim period. For example, <a href="https://eprint.iacr.org/2005/187.pdf">oblivious</a> <a href="https://dl.acm.org/doi/10.1145/1008908.1008920">transfer</a>–one of the fundamental primitives used <a href="https://dl.acm.org/doi/10.1145/3812.3818">to</a> <a href="https://link.springer.com/content/pdf/10.1007%2F3-540-47721-7_17.pdf">build</a> <a href="https://dl.acm.org/doi/10.1145/62212.62215">MPC</a>–<a href="https://link.springer.com/chapter/10.1007/3-540-44750-4_9">received</a> <a href="https://dl.acm.org/doi/abs/10.1145/237814.237996">a</a> <a href="https://link.springer.com/article/10.1007/BF00208002">lot</a> <a href="https://link.springer.com/chapter/10.1007/BFb0054139">of</a> <a href="https://dl.acm.org/doi/10.1145/301250.301312">attention</a> <a href="https://link.springer.com/chapter/10.1007/3-540-44987-6_8">and</a> <a href="https://dl.acm.org/doi/abs/10.5555/365411.365502">saw</a> <a href="https://link.springer.com/chapter/10.1007/978-3-540-45146-4_9">significant</a> <a href="https://link.springer.com/chapter/10.1007/978-3-540-40061-5_27">progress</a>. There <a href="https://link.springer.com/article/10.1007/BF02252866">have</a> <a href="https://link.springer.com/chapter/10.1007/3-540-38424-3_6">been</a> <a href="https://link.springer.com/article/10.1007/BF00196771">many</a> <a href="https://link.springer.com/chapter/10.1007/3-540-46766-1_32">works</a> <a href="https://dl.acm.org/doi/10.1145/167088.167109">developing</a> <a href="https://dl.acm.org/doi/abs/10.1145/195058.195408">the</a> <a href="https://dl.acm.org/doi/10.1145/259380.259412">theoretical</a> <a href="https://link.springer.com/chapter/10.1007/3-540-44598-6_5">framework</a> <a href="https://dl.acm.org/doi/10.1145/352600.352639">of</a> <a href="https://link.springer.com/chapter/10.1007/3-540-44448-3_13">secure</a> <a href="https://dl.acm.org/doi/abs/10.1145/380752.380855">computation</a>, studying <a href="https://eprint.iacr.org/2000/067">secure composition</a>, and <a href="https://dl.acm.org/doi/10.1145/72981.72995">reducing</a> <a href="https://dl.acm.org/doi/10.1145/100216.100287">the</a> <a href="https://link.springer.com/chapter/10.1007/3-540-38424-3_5">round</a> <a href="https://ieeexplore.ieee.org/document/595170">complexity</a> <a href="https://ieeexplore.ieee.org/document/814630">of</a> <a href="https://link.springer.com/chapter/10.1007/3-540-45022-X_43">secure</a> <a href="https://link.springer.com/chapter/10.1007/3-540-45539-6_23">multiparty</a> <a href="https://ieeexplore.ieee.org/abstract/document/892118">computation</a> <a href="https://dl.acm.org/doi/10.5555/646766.704286">protocols</a>. Other works developed special-purpose secure computation protocols for concrete applications such as <a href="https://ieeexplore.ieee.org/document/502223">secure auctions</a> and  <a href="https://dl.acm.org/doi/10.1145/293347.293350">private information retrieval</a>. Many of the techniques and ideas in these works were instrumental for the more recent progress.</p>



<p>Having said that, there still seems to have been a dip in the attention devoted to MPC for a certain period. One explanation that I’ve found interesting is that the powerful feasibility results from the early days made the problem seem “solved” from a theoretical point of view. As a result, interest in MPC within the theory community decreased. It took time before the interest ramped up again, this time more within the more-practically oriented crypto community. (Interestingly, since then, MPC found renewed interest in the theoretical cryptography community as well.)</p>



<p>One work that, to me, is a key point in the transition of MPC from theory to practice is the 2004 <a href="https://www.usenix.org/conference/13th-usenix-security-symposium/fairplay%E2%80%94-secure-two-party-computation-system">Fairplay paper</a>. This was the first full-fledged system that implemented generic secure function evaluation. I believe that, together with other early implementations of MPC-based systems (such as <a href="https://link.springer.com/chapter/10.1007/978-3-642-03549-4_20">the system</a> developed for the Danish sugar-beet auction and the <a href="https://link.springer.com/chapter/10.1007/978-3-540-88313-5_13">Sharemind system</a>), it played a pivotal role in accelerating practical research. I view it as a lesson on the value of “first systems”: they help to identify bottlenecks and discover new concerns, which are hard to predict without building an actual system. Moreover, such systems put “theory problems” on the radar of practitioners and demonstrate which ideas are closer to being practical.  In some sense, a system is an evidence that “the constants in the big-O have been worked out…and they are not astronomical.” Furthermore, when code is made public, follow-up works can build upon an initial system and improve on it more rapidly. A first system can mark the transition of an idea from pure theory to practice. It’s still fair to ask what determines the timing of the appearance of such a first system. One answer is that it often takes the right type of collaboration of researchers from different research communities, as seems to have been the case with “Fairplay”. </p>



<p>I think that external factors also played a role in the timing of events. Specifically, the growth of the Internet and the demand for security on the Internet stimulated a lot of interest and progress in applied cryptography. The late 1990s saw large-scale adoption of public-key cryptography with the successful development and deployment of SSL. More complex Internet applications began to appear later, including those that are inherently security-sensitive, like e-commerce. These applications stimulated interest in more advanced cryptographic tools, MPC being one of them. Indeed, MPC papers from that period discuss new Internet-driven applications as part of their motivation. </p>



<p>A final factor that I want to mention ties back to the first graph above. The fact that many works demonstrate their performance by measuring AES evaluation is, to me, an example of the value of standardized benchmarks. Such benchmarks help to evaluate new techniques and ideas within a certain area and can help progress on a particular dimension, partly because of the competitive element they add. As with any measurement, there is a risk of overfitting to the benchmark, rather than focusing on the true goal, but I think they are very helpful overall.</p>



<p>I am sure there are other valuable lessons to be learned from this case study. Moreover, I am quite certain that folks with more experience in the area have a much better perspective on the history of these developments than I do. I will be very happy to hear other perspectives!</p>



<p><strong>Acknowledgements:</strong> I would like to thank my quals committee, Dan Boneh, Omer Reingold, and Mary Wootters, for an interesting discussion that has led to this blog post. I am grateful to Yuval Ishai and Benny Pinkas for interesting conversations on the progress of MPC and to Henry Corrigan-Gibbs and Saba Eskandarian for providing me with helpful comments.</p></div>
    </content>
    <updated>2021-05-27T01:29:16Z</updated>
    <published>2021-05-27T01:29:16Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Dima Kogan</name>
    </author>
    <source>
      <id>https://theorydish.blog</id>
      <logo>https://theorydish.files.wordpress.com/2017/03/cropped-nightdish1.jpg?w=32</logo>
      <link href="https://theorydish.blog/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://theorydish.blog" rel="alternate" type="text/html"/>
      <link href="https://theorydish.blog/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://theorydish.blog/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Stanford's CS Theory Research Blog</subtitle>
      <title>Theory Dish</title>
      <updated>2021-06-03T03:21:26Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://rjlipton.wpcomstaging.com/?p=18791</id>
    <link href="https://rjlipton.wpcomstaging.com/2021/05/26/the-voting-paradox/" rel="alternate" type="text/html"/>
    <title>The Voting Paradox</title>
    <summary>Trust, but verify—Ronald Reagan are researchers in the area of voting security. Some have worked in this area for decades, others for years, and some are new to the area. But they all signed a letter about election security—right after the last presidential election. The body of the letter is also below. Today I thought […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Trust, but verify—Ronald Reagan</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<p><a href="https://rjlipton.wpcomstaging.com/2021/05/26/the-voting-paradox/group-3/" rel="attachment wp-att-18806"><img alt="" class="aligncenter size-medium wp-image-18806" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/05/group.png?w=200&amp;ssl=1"/></a></p>
<p>
are researchers in the area of voting security. Some have worked in this area for decades, others for years, and some are new to the area. But they all signed a letter about election security—right after the last presidential election. The body of <a href="https://electionlawblog.org/?p=118718">the letter</a> is also below.</p>
<p>
Today I thought we might look into the main paradox surrounding voting security.</p>
<p>
Peter G. Neumann and Rebecca Mercuri just published a <a href="https://cacm.acm.org/magazines/2021/6/252836-the-risks-of-election-believability-or-lack-thereof/fulltext">paper</a> in the CACM on voting security. It is titled <i>The Risks of Election Believability (or Lack Thereof)</i>. </p>
<p>They say: </p>
<blockquote><p><b> </b> <em> Trustworthiness in elections is inherently a total-system problem <img alt="{\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/> </em>
</p></blockquote>
<p>
</p><p>
So let’s look at election security.</p>
<p>
</p><p/><h2> The Paradox </h2><p/>
<p/><p>
<i>The people who cast the votes don’t decide an election, the people who count the votes do—Joseph Stalin</i></p>
<p>
I am reluctant in citing Stalin. But I believe that he hit the mark. The key in any election, in the US or elsewhere, is how and by whom the votes are counted.  </p>
<p>
The issue with the letter, with the recent paper, and more is that the researchers seem to be caught in the middle between two points of view:</p>
<ul>
<li>
There is no evidence of voter fraud in the last presidential election. None. Zero. <p/>
</li><li>
There is no proof of voting security in the last presidential election. None. Zero.
</li></ul>
<p>
This is the problem. We would like to believe that voting is fair and secure. We would like to believe that our election—especially for president—is fair and correct. But we really have no proof that this is true. We are left with desire to make elections safer, but take the position that there is no issue with them. </p>
<p>
Good luck.</p>
<p>
</p><p/><h2> The Letter </h2><p/>
<p/><p>
Here is the letter. I think they miss saying things as bluntly as Stalin does. But they do say essentially the same.</p>
<blockquote><p><b> </b> <em> We are specialists in election security, having studied the security of voting machines, voting systems, and technology used for government elections for decades.</em></p><em>
<p>
We and other scientists have warned for many years that there are security weaknesses in voting systems and have advocated that election systems be better secured against malicious attack. As the National Academies recently concluded, “There is no realistic mechanism to fully secure vote casting and tabulation computer systems from cyber threats.” However, notwithstanding these serious concerns, we have never claimed that technical vulnerabilities have actually been exploited to alter the outcome of any US election.</p>
<p>
Anyone asserting that a US election was “rigged” is making an extraordinary claim, one that must be supported by persuasive and verifiable evidence. Merely citing the existence of technical flaws does not establish that an attack occurred, much less that it altered an election outcome. It is simply speculation.</p>
<p>
The presence of security weaknesses in election infrastructure does not by itself tell us that any election has actually been compromised. Technical, physical, and procedural safeguards complicate the task of maliciously exploiting election systems, as does monitoring of likely adversaries by law enforcement and the intelligence community. Altering an election outcome involves more than simply the existence of a technical vulnerability.</p>
<p>
We are aware of alarming assertions being made that the 2020 election was “rigged” by exploiting technical vulnerabilities. However, in every case of which we are aware, these claims either have been unsubstantiated or are technically incoherent. To our collective knowledge, no credible evidence has been put forth that supports a conclusion that the 2020 election outcome in any state has been altered through technical compromise.</p>
</em><p><em>
That said, it is imperative that the US continue working to bolster the security of elections against sophisticated adversaries. At a minimum, all states should employ election security practices and mechanisms recommended by experts to increase assurance in election outcomes, such as post-election risk-limiting audits. </em>
</p></blockquote>
<p/><p>
The letter is well written, but <img alt="{\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> They say in the letter: </p>
<blockquote><p><b> </b> <em> However, notwithstanding these serious concerns, we have never claimed that technical vulnerabilities have actually been exploited to alter the outcome of any US election. </em>
</p></blockquote>
<p>This seems to be a problem. How do you get people to <i>look both ways when crossing the street</i>, when you have also basically asserted: “No one has ever been hit by a car when crossing the street.”</p>
<p><a href="https://rjlipton.wpcomstaging.com/2021/05/26/the-voting-paradox/cs/" rel="attachment wp-att-18795"><img alt="" class="aligncenter size-full wp-image-18795" height="183" src="https://i1.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/05/cs.png?resize=276%2C183&amp;ssl=1" width="276"/></a></p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
We believe that election security is a real issue. Perhaps our single point is: Even if we do not believe that any fraud happen in the past, we must agree to make the voting process secure. We must use all our insights to make elections not only fair, but believed to be fair.</p>
<p>
Look both ways. </p>
<p>
Ken notes that “Trust but verify” was first the Russian proverb <i>Doveryay no proveryay</i>, but that its origins are <a href="https://www.rbth.com/lifestyle/330521-reagan-trust-but-verify-chernobyl">unclear</a> even to Russians.  He adds that besides <i>how</i> and <i>by whom</i> there is also the issue of <i>when</i> votes are counted.  The warnings he gave in our election-eve <a href="https://rjlipton.wpcomstaging.com/2020/11/03/the-election-night-time-warp/">post</a> were reflected in <a href="https://www.factcheck.org/2020/12/false-claim-about-bidens-win-probability/">claims</a> made in the early December Texas attorney general filing.</p></font></font></div>
    </content>
    <updated>2021-05-27T00:01:00Z</updated>
    <published>2021-05-27T00:01:00Z</published>
    <category term="History"/>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="Open Problems"/>
    <category term="People"/>
    <category term="Andrew Appel"/>
    <category term="elections"/>
    <category term="Peter G. Neumann"/>
    <category term="Rebecca Mercuri"/>
    <category term="security"/>
    <category term="voting"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wpcomstaging.com</id>
      <logo>https://s0.wp.com/i/webclip.png</logo>
      <link href="https://rjlipton.wpcomstaging.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wpcomstaging.com" rel="alternate" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel's Lost Letter and P=NP</title>
      <updated>2021-06-03T03:20:34Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/05/26/postdoc-opportunity-in-algebraic-complexity-at-boston-college-apply-by-july-30-2021/</id>
    <link href="https://cstheory-jobs.org/2021/05/26/postdoc-opportunity-in-algebraic-complexity-at-boston-college-apply-by-july-30-2021/" rel="alternate" type="text/html"/>
    <title>Postdoc Opportunity in Algebraic Complexity at Boston College (apply by July 30, 2021)</title>
    <summary>The Computer Science department at Boston College invites applications for a postdoctoral position in the area of algebraic complexity under the supervision of Ilya Volkovich. See attached pamphlet for more information. Please direct any inquiries to Ilya Volkovich (Email: ilya.volkovich@bc.edu) Website: https://sites.google.com/site/ilyavv/Postdoc%20add.pdf Email: ilya.volkovich@bc.edu</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Computer Science department at Boston College invites applications for a postdoctoral position in the area of algebraic complexity under the supervision of Ilya Volkovich.</p>
<p>See attached pamphlet for more information.</p>
<p>Please direct any inquiries to Ilya Volkovich (Email: ilya.volkovich@bc.edu)</p>
<p>Website: <a href="https://sites.google.com/site/ilyavv/Postdoc%20add.pdf">https://sites.google.com/site/ilyavv/Postdoc%20add.pdf</a><br/>
Email: ilya.volkovich@bc.edu</p></div>
    </content>
    <updated>2021-05-26T21:04:52Z</updated>
    <published>2021-05-26T21:04:52Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-06-03T03:20:36Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-27705661.post-8805390553192485548</id>
    <link href="http://processalgebra.blogspot.com/feeds/8805390553192485548/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=27705661&amp;postID=8805390553192485548" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/8805390553192485548" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/8805390553192485548" rel="self" type="application/atom+xml"/>
    <link href="http://processalgebra.blogspot.com/2021/05/course-on-ethics-and-accountability-in.html" rel="alternate" type="text/html"/>
    <title>Course on Ethics and Accountability in Computer Science</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>About one year ago, I became aware of the course "Ethics and Accountability in Computer Science" designed and taught by <a href="https://riceacademy.rice.edu/junior-fellows/dr-rodrigo-ferreira" target="_blank">Rodrigo Ferreira</a> and <a href="https://www.cs.rice.edu/~vardi/" target="_blank">Moshe Y. Vardi</a> at Rice University. The goals and high-level structure of the course, as well as its context, are described in an informative and thoughtful <a href="https://www.cs.rice.edu/~vardi/papers/sigcse21.pdf" target="_blank">paper</a> by Moshe and Rodrigo that appears in the <a href="https://dl.acm.org/doi/proceedings/10.1145/3408877" target="_blank">Proceedings of the  52nd ACM Technical Symposium on Computer Science Education (SIGCSE ’21)</a>, which I strongly recommend. You can also read a <a href="https://www.pdcnet.org/tej/content/tej_2021_0999_3_31_87" target="_blank">journal paper</a> reporting on one of their course assignments, which was designed to make students focus on practising <a href="https://medium.com/@the_jennitaur/how-to-do-nothing-57e100f59bbb" target="_blank">"deep attention"</a> in the sense of artist and academic <a href="https://www.jennyodell.com/" target="_blank">Jenny Odell</a>.</p><p>I was smitten by the underlying tenet for their course, namely that "social justice is  the single  most important issue  confronting computer science  students today." That tenet is also very much in line with a reflection on the impact that digital technology has on social justice that the <a href="https://www.gssi.it/institute/organization" target="_blank">Scientific Advisory Board of the Gran Sasso Science Institute</a> asked the Computer Science group at that institute to undertake. Therefore, after having invited Rodrigo to deliver a <a href="http://www.google.com/url?q=http%3A%2F%2Ficetcs.ru.is%2Fwebinars%2Fdeep_ethics.mp4&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNH9ux4zX7PThxWzwoNa_yyZNa-ILA" target="_blank">webinar on the course</a> at the <a href="https://sites.google.com/gssi.it/csgssi/seminars-and-events/joint-ice-tcs-csgssi-virtual-seminar" target="_blank">ICE-TCS+GSSI webinar series</a>, I decided that, as an experiment, I would offer a version of the Rice University course to master students in computer science, language technology and software engineering at Reykjavik University during our spring semester 2021. </p><p>Mine was a foolhardy decision for a variety of reasons. However, I have always believed that computer scientists should strive to be the 21st century Renaissance men and women, and bridge the gap between C. P. Snow's <a href="https://en.wikipedia.org/wiki/The_Two_Cultures" target="_blank">"two cultures"</a>. Indeed, to quote <a href="https://ptolemy.berkeley.edu/~eal/" target="_blank">Edward A. Lee</a> freely, to my mind technologists ought to be amongst the greatest humanists of our age. Despite my other commitments, offering a version of the Ferreira-Vardi course at Reykjavik University felt like the right thing to do at this time. </p><p>I taught the course over twelve weeks to a varied group of eight students, in cooperation with <a href="http://claudiopedica.com/" target="_blank">Claudio Pedica</a>. Thanks to the constant support I received from Rodrigo Ferreira, I lived to tell the tale and I hope that I managed to do some justice to the truly excellent course that Moshe and Rodrigo put together. Having a dream team of students with a variety of cultural backgrounds made the course extremely interesting and a learning experience for me. I had to refresh my memory of the philosophy I studied at high school in Italy in a previous life, learn some modern moral philosophy I had not met at school (such as the work by <a href="https://plato.stanford.edu/entries/anscombe/" target="_blank">Elisabeth Anscombe</a> and <a href="https://plato.stanford.edu/entries/philippa-foot/" target="_blank">Philippa Foot</a>, amongst others), read a substantial amount of new material (some of it fresh off the press as the course was unfolding) and broaden my horizons. I could not have asked for a better intellectual experience and the students in the course, from Denmark, France, Germany, Iceland and the Netherlands taught me well, kept me on my toes and stimulated me to keep reading material related to ethics even now that the course is over. <br/></p><p>Teaching the course reinforced my belief that a course on ethics and on the impact that our field has on social justice should be required for all students in computer science. If you plan to run such a course, I strongly recommend that you consider the Ferreira-Vardi course as a blueprint. <br/></p><p><br/></p><p><br/></p><p><br/></p></div>
    </content>
    <updated>2021-05-26T19:04:00Z</updated>
    <published>2021-05-26T19:04:00Z</published>
    <author>
      <name>Luca Aceto</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/01092671728833265127</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-27705661</id>
      <author>
        <name>Luca Aceto</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/01092671728833265127</uri>
      </author>
      <link href="http://processalgebra.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://processalgebra.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Papers I find interesting---mostly, but not solely, in Process Algebra---, and some fun stuff in Mathematics and Computer Science at large and on general issues related to research, teaching and academic life.</subtitle>
      <title>Process Algebra Diary</title>
      <updated>2021-06-01T21:43:16Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-8240675027790472002</id>
    <link href="https://blog.computationalcomplexity.org/feeds/8240675027790472002/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2021/05/does-university-matter.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/8240675027790472002" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/8240675027790472002" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2021/05/does-university-matter.html" rel="alternate" type="text/html"/>
    <title>Does the university matter?</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>As we come out of a pandemic with online teaching and research collaborations, how much do we actually need the university?</p><p>Theoretical research in computer science, math and elsewhere it hardly slowed down with everyone hunkered down at home, and when it did it was more because of supervising kids with their on-line learning than being away from the university. Collaborating with those around the world was basically the same as collaborating with your colleagues on campus.</p><p>Many courses, especially the larger ones, worked about as well on-line as they do in person.</p><p>The pandemic is accelerating changes already in place. Before say 1960, the fastest travel for the masses was on train and boats and fast communication limited to expensive phone calls. You needed strong colleagues, a strong library and a strong support staff to be a successful academic. Traveling to meet colleagues and attend conferences was a luxury that few could do often.</p><p>The 60's gave us air travel though it wasn't until the 90's that we could readily send academic papers electronically. It's really only recently that we have the infrastructure to allow high-quality teaching and research collaboration online.</p><p>Suppose universities now just disappeared. Professors would be free agents, supported by grants and tuition from students taking their on-line courses and consulting. Students would pick and choose courses from the best instructors, their "transcript" being recorded on a blockchain-like database. PhD students would be more of an apprenticeship, a low salary in exchange for personalized mentoring from a professor. </p><p>For the experimental sciences, there would be a set of national labs that professors could join.</p><p>Startups would create apps to enable all these things, professors would just become yet another piece of the gig economy. Superstar academics can pull in large salaries, the rest would struggle to make a decent wage--not that different from actors and musicians. </p><p>Don't worry, universities aren't going anywhere soon. Or are they?</p></div>
    </content>
    <updated>2021-05-25T17:21:00Z</updated>
    <published>2021-05-25T17:21:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2021-06-03T01:51:45Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=5517</id>
    <link href="https://www.scottaaronson.com/blog/?p=5517" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=5517#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=5517" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">In which I answer more quantum computing questions</title>
    <summary xml:lang="en-US">Yesterday, I had fun doing an open-ended Q&amp;A at the Astral Codex Ten weekly online meetup. See here for the YouTube video. The questions were mainly about quantum computing, but ranged over various other topics as well, including education policy, the Great Stagnation, and what my biggest disagreements with Scott Alexander are. In other news, […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>Yesterday, I had fun doing an open-ended Q&amp;A at the <a href="https://astralcodexten.substack.com/">Astral Codex Ten</a> weekly online meetup.  <a href="https://www.youtube.com/watch?v=DEYUt1tJlck">See here</a> for the YouTube video.  The questions were mainly about quantum computing, but ranged over various other topics as well, including education policy, the Great Stagnation, and what my biggest disagreements with Scott Alexander are.</p>



<p>In other news, last week I gave my talk about quantum supremacy at the (virtual, of course) <a href="https://quantumscienceseminar.com/videos/">Quantum Science Seminar</a>, organized by Sebastian Blatt and others.  <a href="https://www.youtube.com/watch?v=EeF7T9Bc1B0">See here</a> for the YouTube video.  Since I (alas) needed to leave after an hour sharp, the organizers asked if they could send me additional questions in writing and have me answer them.  I said sure, as long as I could also post the Q&amp;A on this blog!  So without further ado…</p>



<p><strong>Q:</strong> As you said, in computer science it’s difficult to prove that things are hard. From a computer science perspective, to what extent is “quantum supremacy” something absolute, and to what extent is it a shifting bar that depends on how good our classical hardware and algorithms are?</p>



<p><strong>SCOTT:</strong> It’s kind of like the question “can computers beat the best humans at chess?” The latter question also involves a non-absolute shifting bar – maybe humans are getting better! Or maybe they simply haven’t figured out how to beat the computers yet! So how can we say “computer supremacy” has been decisively achieved? Nevertheless, one can clearly see a phase transition, with Deep Blue in 1996-1997, where the burden of proof shifted massively from one side to the other, and has stayed there ever since. Even if humans are getting better, the computers have also gotten better, and at such an insane rate that humans seem to have no chance of ever again catching up.</p>



<p>From a theoretical standpoint, that’s exactly what we might expect to happen with quantum supremacy experiments – simply because they involve tasks that have polynomial scaling for quantum computers, but (as far as we know) exponential scaling for classical computers, where each additional qubit roughly doubles the classical resources required. In analyzing concrete quantum supremacy experiments, I’d say that the goal is not to pin down the exact factor by which they’re beating this or that classical simulation (the answers will change rapidly anyway, and depend on all sorts of low-level details), but simply to figure out whether or not we’ve entered that phase transition.</p>



<p><strong>Q:</strong> What do you generally think about improvements in tensor network methods as a challenge to quantum supremacy and the recent simulation of the supremacy result in Beijing?</p>



<p><strong>SCOTT:</strong> I <a href="https://www.scottaaronson.com/blog/?p=5371">blogged about this here</a>. It was a clever paper, which showed that if you focus narrowly on spoofing the linear cross-entropy benchmark used by Google, then there’s a classical algorithm to do that much faster than had been previously pointed out, by generating many samples that all share most of their bits in common (e.g., that all agree on the first 30 of the 53 bits). But many people remain unaware that, if you just changed the benchmark – for example, if you insisted that the returned samples not only pass the linear cross-entropy benchmark, but also be sufficiently different – then this classical spoofing strategy wouldn’t work and we’d be back to the previous status quo.</p>



<p><strong>Q:</strong> Why do you need a random circuit to test the device, and also why is this more interesting/useful than doing something very specific many times to test the device?</p>



<p><strong>SCOTT:</strong> The reasons to use random quantum circuits are simply that<br/>(1) they generate complicated entangled states on all the qubits nearly as rapidly as it’s possible to do so – indeed, we now have theoretical results that give a detailed understanding of this process, and<br/>(2) random circuits seem to have about as little “usable structure” (which a classical simulation might exploit) as it’s possible to have.<br/>Eventually, of course, we’d like to run actually useful circuits (say, those that arise in Shor’s factoring algorithm), which will typically have regular patterns and be extremely far from random! But then more qubits will be needed to get an advantage over classical computers. It’s not terribly surprising for the <em>first</em> advantage over classical to be via random quantum circuits, which in some sense “maximally exploit” the hardware resources available.</p>



<p><strong>Q:</strong> Have you heard of/what do you think about the <a href="https://www.nature.com/articles/s41467-021-21119-1">recent NP-verification experiment</a> using a quantum optical setup from Paris?</p>



<p><strong>SCOTT:</strong> That experiment was actually based on a protocol that Beigi, Fefferman, Drucker, Shor, and I <a href="https://arxiv.org/abs/0804.0802">proposed back in 2008</a>. It’s crucial for people to understand that there’s no claimed speedup here for <em>solving</em> any NP-complete problem. We’re talking about a more arcane task: namely, proving to someone that an NP-complete problem has a solution by sending them a small number of qubits. Even there, the protocol depends on the ability to send two quantum states that are guaranteed <em>not</em> to be entangled with each other; also, the communication savings is “only” polynomial rather than exponential (in our original protocol, roughly √n qubits where n classical bits would have been needed). Nevertheless, it’s always fun to see a real experiment implementing some version of something that you worked out on paper, even if you already knew it would work!</p>



<p><strong>Q:</strong> If the difficulty for classical simulation is related to the Hilbert space dimension, has it been formally proven that an ideal analog classical computer cannot outperform a quantum computer?</p>



<p><strong>SCOTT:</strong> This is not a question of “formal proof” but of physics. In my view, we already know deep reasons why, in our universe, analog classical computers are unlikely to be able to do anything that can’t be efficiently simulated using a standard digital computer. (In other words, why analog classical computers don’t violate the “Extended Church-Turing Thesis.”) Those reasons have to do with nonlinear dynamics chaotically amplifying even the tiniest errors in an analog device. Or, if you really want to push this discussion to the bitter end, they have to do with the breakdown in our picture of a smooth spacetime that’s expected to occur at the Planck scale, of ~10<sup>-33</sup> centimeters and ~10<sup>-43</sup> seconds, for reasons of black hole thermodynamics and quantum gravity. Crucially, neither of these issues apply to quantum computation. The former doesn’t apply because of quantum error correction  and fault-tolerance, which have the effect of “discretizing” continuous errors; while the latter doesn’t apply because as far as anyone knows today, quantum mechanics (unlike theories that assume a smooth spacetime) is exactly true.</p>



<p><strong>Q:</strong> [In the comparison between quantum and classical computation], what do we mean by “classical resources” here? Do we mean something parochial like “resources obeying non-quantum laws that are available to us humans on Earth?” Or is any classical resource fair game, no matter its size and classical equations of motion? In that case, doesn’t demonstrating quantum supremacy require demonstrating that the quantum computer exceeds the capabilities of, say, a classical computer the size of the solar system that exploits some CTC (closed timelike curve)?</p>



<p><strong>SCOTT:</strong> If CTCs were possible, that would be a revolution in physics even greater than quantum mechanics! Leaving CTCs aside, though, cosmology and quantum gravity seem to impose a limit of roughly 10<sup>122</sup> on the number of bits (and the number of operations on the bits) that any computer that fit inside the observable universe could possibly have. And if you envision that cosmological computer as a classical one, then it shouldn’t take impossibly long for us to build quantum computers that can outperform it on some tasks: indeed, a device with ~400 qubits should already be enough! But of course we’re not there yet: with 50-60 qubits, QCs right now are “merely” challenging the largest classical computers currently available on earth (again, on contrived sampling tasks), rather than the largest that could fit in the observable universe.</p>



<p><strong>Q:</strong> Why is a quantum state (superposition or entangled state) inherently more fragile than a classical state?</p>



<p><strong>SCOTT:</strong> Because when information from the state (say, whether a qubit is 0 or 1, or which path a photon takes through a beamsplitter network) “leaks out” into the environment, the information effectively becomes entangled with the environment, which damages the state in a measurable way.  Indeed, it now appears to an observer as a mixed state rather than a pure state, so that interference between the different components can no longer happen. This is a fundamental, justly-famous feature of quantum information that’s not shared by classical information.</p>



<p><strong>Q:</strong> Given that we have noisy-intermediate scale quantum devices, what do you see as the fundamental role of noise in the discussion on quantum advantage or quantum supremacy. Is it simply a question of less noise is better, or are there things that cannot be done if there is noise?</p>



<p><strong>SCOTT:</strong> There will always be <em>some</em> noise. The big question, about any given platform, is whether the noise is low enough that you can start usefully error-correcting it away, or whether the noise is so high that there’s no point (i.e., whether you’re above or below the “fault-tolerance threshold”).  Until you start doing error-correction, most experts believe there’s a severe limit to how far you can scale: probably to quantum computations involving a few hundred qubits at most. Whereas once you have error-correction, at least in principle the sky’s the limit.</p>



<p><strong>Q:</strong> You used the Wright brothers as an example where an airplane that was not practically useful itself pioneered the path to useful flight. In what sense to the sampling experiments of Google and USTC also pioneer that path for what we need for the future of quantum computing, or to what extent do you see them as niche examples of quantum supremacy?</p>



<p><strong>SCOTT:</strong> I think the majority of what Google did, in integrating 53 superconducting qubits, making them programmable, etc. – and especially in characterizing the noise in a system at that scale – will be directly useful going forward. Indeed, that’s a large part of why they did it!  Likewise, a lot of what USTC did, in integrating hundreds of beamsplitters, photon sources, and photodetectors, could be directly relevant to building a universal optical quantum computer. On the other hand, it’s true that both groups took shortcuts with the immediate goal of quantum supremacy in mind. As an example, Google’s chip uses a particular 2-qubit gate that was chosen, not because it shows up naturally in any application, but simply because it’s extra-hard to simulate using tensor network contraction algorithms, so it let them get to quantum supremacy faster than if they’d used a more conventional 2-qubit gate like the CNOT.</p>



<p><strong>Q:</strong> To what extent does the measured circuit fidelity of 0.2% in the Google experiment limit the usability of this system for other computations?</p>



<p><strong>SCOTT:</strong> Oh, we don’t know of anything particularly useful to do with Google’s Sycamore chip – that is, anything that you couldn’t do much more easily without it – other than<br/>(1) quantum supremacy demonstrations,<br/>(2) <em>possibly</em> the generation of cryptographically certified random bits, and<br/>(3) of course, calibration experiments that tell you about the behavior of integrated superconducting qubits and thereby help you iterate to the next device.<br/>But things are developing rapidly – the best circuit fidelity that was achievable in 2019 is not necessarily the best now, or the best that will be achieved in another year or two.</p>



<p><strong><span class="has-inline-color has-vivid-red-color">Update (May 25):</span></strong> <strong>Please, no new questions</strong>; just discussion of the existing questions and answers! I had hoped to get some work done today; I hadn’t planned on another ask-me-anything session. Thanks!</p></div>
    </content>
    <updated>2021-05-24T21:45:46Z</updated>
    <published>2021-05-24T21:45:46Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Quantum"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2021-06-01T20:00:21Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://rjlipton.wpcomstaging.com/?p=18770</id>
    <link href="https://rjlipton.wpcomstaging.com/2021/05/24/acm-athena-lecturer-award/" rel="alternate" type="text/html"/>
    <title>ACM Athena Lecturer Award</title>
    <summary>It was never about winning medals or being famous—Nancy Kerrigan Award page Ayanna Howard is this year’s winner of the ACM Athena Lecturer Award. She works in robotics and is Dean of Engineering at Ohio State. She was previously Chair of the School of Interactive Computing at Georgia Tech. Today Ken and I congratulate her […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><font color="#0044cc"><br/>
<em>It was never about winning medals or being famous—Nancy Kerrigan</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2021/05/24/acm-athena-lecturer-award/ah-2/" rel="attachment wp-att-18783"><img alt="" class="alignright wp-image-18783" height="138" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/05/ah-1.png?resize=154%2C138&amp;ssl=1" width="154"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Award <a href="https://awards.acm.org/about/2021-athena">page</a></font></td>
</tr>
</tbody>
</table>
<p>
Ayanna Howard is this year’s winner of the ACM Athena Lecturer <a href="https://awards.acm.org/athena">Award</a>. She works in robotics and is <a href="https://engineering.osu.edu/about/office-dean/about-dean-ayanna-howard">Dean</a> of Engineering at Ohio State. She was previously Chair of the School of Interactive Computing at Georgia Tech.</p>
<p>
Today Ken and I congratulate her and also recognize past winners of the award.</p>
<p>
The award is not for lecturing. Here is the description:</p>
<blockquote><p><b> </b> <em> Initiated in 2006, the ACM Athena Lecturer Award celebrates women researchers who have made fundamental contributions to computer science. The award carries a cash prize of $25,000, with financial support provided by Two Sigma. The Athena Lecturer gives an invited talk at a major ACM conference of her choice. </em>
</p></blockquote>
<p>
</p><h2> Howard’s Research </h2><p/>
<p>
Ayanna Howard’s research spans three interconnected areas of robotics:</p>
<ul>
<li>
<b>Outer Space Robotics:</b> She did early work for NASA’s Jet Propulsion Laboratory. Here is a 2002 <a href="https://www.nasa.gov/vision/universe/roboticexplorers/ayanna_howard.html">article</a> that leads with her work on the “Safe Navigation Rover.” <p/>
</li><li>
<b>Inner Space Robotics:</b> This work involves interaction and assistive technologies. It includes her co-founding the company <a href="http://zyrobotics.com/about/">Zyrobotics</a>, which creates mobile therapy and educational technology tools for children. <p/>
</li><li>
<b>Inner Mindspace Robotics:</b> On what grounds can we <em>trust</em> robots? How can they be programmed to avoid biases in their interactions with human beings? Can the algorithms they use be certified for <em>fairness?</em> (We had some recent <a href="https://rjlipton.wpcomstaging.com/2021/03/10/making-algorithms-fair/">thoughts</a> of our own on the last subject.)
</li></ul>
<p>
There are technical connections that flow from a whole-situation/whole-person approach. Her NASA landing and navigation systems were not designed simply to solve a computer-vision and calculus problem of finding the flattest terrain. Instead, the design expressly maps visual and sensor readings into a knowledge and logic-based system of human reasoning. Then the system either judges or makes recommendations to human controllers. This kind of approach naturally flows into assessing the robotic judgments for blind spots and bias. Most in particular, she tries to combat a human tendency of uncritical acceptance of personal assistants. She wants to facilitate humans to challenge the robots and have the robots modulate their reasoning and behavior accordingly.</p>
<p>
She was inspired as a child by the TV show <a href="https://en.wikipedia.org/wiki/The_Bionic_Woman">The Bionic Woman</a>. Adding “-nic” after “bio” took what could have been influence to go into medicine into an avenue that channeled her childhood love of mathematics.</p>
<p>
</p><h2> A Puzzle </h2><p/>
<p>
I designed a word-search puzzle by feeding terms from the award to a web app for creating them. We wondered if it was silly to include it. But maybe the puzzle is not so silly—besides that it was created by a ‘bot—if you think in these terms:</p>
<blockquote><p><b> </b> <em> How might a robot get the most out of solving it? </em>
</p></blockquote>
<p>
Here is the grid—see if you can find the words in it. The key is at the end.</p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2021/05/24/acm-athena-lecturer-award/pu/" rel="attachment wp-att-18774"><img alt="" class="aligncenter wp-image-18774" height="400" src="https://i1.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/05/pu.png?resize=400%2C400&amp;ssl=1" width="400"/></a></p>
<p>
From a human standpoint, three minutes is award level. But for a robot:</p>
<ul>
<li>
Of course, a robot could solve the puzzle in three microseconds by brute-force string matching along every row, column, and diagonal. But there is no challenge in that—it is not what we think of as human <em>reading</em>. <p/>
</li><li>
To be human fun, the puzzle should be fairly dense and have a “wordscape” where parallel rows, columns, and diagonals are used. Once we find one word, we can often find neighbors more quickly, and that feels rewarding.
</li></ul>
<p>
That’s what we’re asking: is there a way to teach robots to solve these puzzles in more human ways? OK, it’s too simple. But we like to put a peg down on a simple example, then run a line into the heart of the work, and ask: at what point does it cross the threshold of being nontrivial?</p>
<p>
</p><h2> All Athena Winners </h2><p/>
<p>
Here are links to all the winners of this award:</p>
<p>
2021 <a href="https://awards.acm.org/award_winners/howard_5736184">Ayanna Howard</a></p>
<p>
2020 <a href="https://awards.acm.org/award_winners/kraus_4452744">Sarit Kraus</a></p>
<p>
2019 <a href="https://awards.acm.org/award_winners/bertino_2269926">Elisa Bertino</a></p>
<p>
2018 <a href="https://awards.acm.org/award_winners/goldsmith_5482565">Andrea Goldsmith</a></p>
<p>
2017 <a href="https://awards.acm.org/award_winners/kavraki_3691391">Lydia Kavraki</a></p>
<p>
2016 <a href="https://awards.acm.org/award_winners/rexford_4157665">Jennifer Rexford</a></p>
<p>
2015 <a href="https://awards.acm.org/award_winners/widom_2272011">Jennifer Widom</a></p>
<p>
2014 <a href="https://awards.acm.org/award_winners/dumais_2360550">Susan Dumais</a></p>
<p>
2013 <a href="https://awards.acm.org/award_winners/yelick_3873601">Katherine Yelick</a></p>
<p>
2012 <a href="https://awards.acm.org/award_winners/lynch_2276129">Nancy Lynch</a></p>
<p>
2011 <a href="https://awards.acm.org/award_winners/olson_2607695">Judith Olson</a></p>
<p>
2010 <a href="https://awards.acm.org/award_winners/irwin_1411388">Mary Jane Irwin</a></p>
<p>
2009 <a href="https://awards.acm.org/award_winners/eggers_1922665">Susan Eggers</a></p>
<p>
2008 <a href="https://awards.acm.org/award_winners/goldwasser_8627889">Shafi Goldwasser</a></p>
<p>
2007 <a href="https://awards.acm.org/award_winners/sparck-jones_7172364">Karen Sparck-Jones</a></p>
<p>
2006 <a href="https://awards.acm.org/award_winners/estrin_1782044">Deborah Estrin</a></p>
<p>
</p><h2> Open Problems </h2><p/>
<p>
Lynch and Goldwasser are the only theory researchers. This is less than <img alt="{10 \%}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B10+%5C%25%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. </p>
<p>
The puzzle key:</p>
<p><a href="https://rjlipton.wpcomstaging.com/2021/05/24/acm-athena-lecturer-award/key/" rel="attachment wp-att-18773"><img alt="" class="aligncenter wp-image-18773" height="425" src="https://i1.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/05/key.png?resize=400%2C425&amp;ssl=1" width="400"/></a></p></font></font></div>
    </content>
    <updated>2021-05-24T16:27:05Z</updated>
    <published>2021-05-24T16:27:05Z</published>
    <category term="History"/>
    <category term="News"/>
    <category term="People"/>
    <category term="ACM"/>
    <category term="Algorithms"/>
    <category term="Ayanna Howard"/>
    <category term="fairness"/>
    <category term="knowledge representation"/>
    <category term="Prize"/>
    <category term="puzzle"/>
    <category term="robotics"/>
    <category term="winner"/>
    <category term="word game"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wpcomstaging.com</id>
      <logo>https://s0.wp.com/i/webclip.png</logo>
      <link href="https://rjlipton.wpcomstaging.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wpcomstaging.com" rel="alternate" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel's Lost Letter and P=NP</title>
      <updated>2021-06-03T03:20:34Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/072</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/072" rel="alternate" type="text/html"/>
    <title>TR21-072 |  Arithmetic Circuit Complexity of Division and Truncation | 

	Gorav Jindal, 

	Pranjal Dutta, 

	Anurag Pandey, 

	Amit Sinhababu</title>
    <summary>Given polynomials $f,g,h\,\in \mathbb{F}[x_1,\ldots,x_n]$ such that $f=g/h$, where both $g$ and $h$ are computable by arithmetic circuits of size $s$, we show that $f$ can be computed by a circuit of size  $\poly(s,\deg(h))$.  This solves a special case of division elimination for high-degree circuits (Kaltofen'87 \&amp; WACT'16). The result is an exponential improvement over Strassen's classic result (Strassen'73) when $\deg(h)$ is $\poly(s)$ and $\deg(f)$ is $\exp(s)$, since the latter gives an upper bound of $\poly(s, \deg(f))$.

Further, we show that any univariate polynomial family $(f_d)_d$, defined by the initial segment of the power series expansion of rational function $g_d(x)/h_d(x)$ up to degree $d$ (i.e.~$f_d = g_d/h_d \bmod x^{d+1}$), where circuit size of $g$ is $s_d$ and degree of $g_d$ is at most $d$, can be computed by a circuit of size $\poly(s_d,\deg(h_d),\log d)$.
We also show a hardness result when the degrees of the rational functions are high (i.e.~$\Omega (d)$), assuming hardness of the integer factorization problem.</summary>
    <updated>2021-05-24T13:20:40Z</updated>
    <published>2021-05-24T13:20:40Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-06-03T03:20:22Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/071</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/071" rel="alternate" type="text/html"/>
    <title>TR21-071 |  On the Algorithmic Content of Quantum Measurements | 

	Samuel Epstein</title>
    <summary>We show that given a quantum measurement, for an overwhelming majority of pure states, no meaningful information is produced. This is independent of the number of outcomes of the quantum measurement. Due to conservation inequalities, such random noise cannot be processed into coherent data.</summary>
    <updated>2021-05-23T14:21:48Z</updated>
    <published>2021-05-23T14:21:48Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-06-03T03:20:22Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=5510</id>
    <link href="https://www.scottaaronson.com/blog/?p=5510" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=5510#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=5510" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">On turning 40 today</title>
    <summary xml:lang="en-US">Holy crap. In case you’re wondering how I spent such a milestone of a day: well, I spent hours of it at an important virtual grant review meeting with the Department of Defense. Alas, when it came time for my own big presentation at that meeting—about what my students and I had done over the […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>Holy crap.</p>



<p>In case you’re wondering how I spent such a milestone of a day: well, I spent hours of it at an important virtual grant review meeting with the Department of Defense.  Alas, when it came time for my own big presentation at that meeting—about what my students and I had done over the past five years to lay the theoretical foundations for the recent achievement of quantum computational supremacy—I’d uploaded the completely wrong PowerPoint file (it was something.pptx rather than something.ppt, where they <em>weren’t</em> two versions of the same presentation).  Sorting this out took about 10 minutes, destroyed my momentum, and wasted everyone’s time.  I partly blame the Microsoft Teams platform, whose limitations as conferencing software compared to Zoom necessitated emailing my presentation in the first place.  But of course, part of the blame rests with me.</p>



<p>I had to explain apologetically to the US Department of Defense that I’m no good with tech stuff—being a mere computer science PhD.  And unlike many of my colleagues (who I envy), back in my youth—for at age 40 I’m no longer young—I never had enough time to become <em>both</em> the kind of person who might earn a big grant to do quantum computing theory, <em>and</em> the kind of person who’d be minimally competent at the logistics of a review meeting for such a grant.</p>



<p/><hr/><p/>



<p>Forty years.  Seven-eighths of those years, aware of the finiteness of the speed of light and of its value.  Four-fifths of them, aware of the grislier details of the Holocaust.  Three-quarters of them, aware of what it means to write code.  Two-thirds of them, aware of polynomial versus exponential time.  More than half of them trying to understand the capabilities and limitations of quantum computers as my day job.  And then, rounding the corner, more than a third of the years writing this blog, a third of them being a professor, a quarter of them married, a fifth of them raising kids, a thirtieth of them in the midst of a global pandemic.</p>



<p>I didn’t even come <em>close </em>to achieving everything I hoped I would in my thirties.  At least a half-dozen major papers, ones I expected would’ve been finished years ago (on the mixing of coffee and cream, on complexity and firewalls and AdS/CFT, on certified random numbers from sampling-based quantum supremacy experiments, on the implications of the Raz-Tal oracle separation, …), still need to be revised or even written.  Other projects (e.g., the graphic novel about teaching math to Lily) were excitedly announced and then barely even started.  I never wrote most of my promised blog post about the continuum hypothesis, <em>or</em> the one about Stephen Wolfram’s recrudescent claims of a unified theory of physics.  And covid, which determined the world’s working conditions while we were running out the clock, turned out <em>not</em> to be a hyper-productive time for me.  That’s how you know I’m not Newton (well, it’s the not the only way you know).</p>



<p>Anyway, during the runup to it, one’s 40th birthday feels like a temporal singularity, where you have to compress more and more of what you’d hoped to achieve before age 40 as you get closer and closer to it, because what the hell is there on the other side? <em> The</em>y<em>‘re</em> over-40 and hence “old”; <em>you’re</em> under-40 and hence still “young.”</p>



<p>OK, but here I am on the other side right now, <em>the “old” side</em>, and I’m still here, still thinking and writing and feeling fairly continuous with my pre-singularity embodiment!  And so far, in 16 hours on this side, the most senile thing I’ve done has been to email the wrong file attachment and thereby ruin an important funding presenta… you know what, let’s not even go there.</p>



<p>If you feel compelled to give me a 40<sup>th</sup> birthday present, then just make it a comment on this post, as short or long as you like, about what anything I said or did meant for you.  I’m a total softie for that stuff.</p></div>
    </content>
    <updated>2021-05-21T20:44:41Z</updated>
    <published>2021-05-21T20:44:41Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Adventures in Meatspace"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Nerd Interest"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Self-Referential"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2021-06-01T20:00:21Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2021/05/21/international-school-conference-in-algorithms-combinatorics-and-complexity/</id>
    <link href="https://cstheory-events.org/2021/05/21/international-school-conference-in-algorithms-combinatorics-and-complexity/" rel="alternate" type="text/html"/>
    <title>International School-conference in Algorithms, Combinatorics, and Complexity</title>
    <summary>May 24-28, 2021 Online https://indico.eimi.ru/event/199/ An advanced school for young researchers featuring three minicourses in vibrant areas of mathematics and computer science. The target audience includes graduate, master, and senior bachelor students of any mathematical speciality.</summary>
    <updated>2021-05-21T09:14:41Z</updated>
    <published>2021-05-21T09:14:41Z</published>
    <category term="school"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2021-06-03T03:21:24Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://tcsplus.wordpress.com/?p=562</id>
    <link href="https://tcsplus.wordpress.com/2021/05/20/tcs-talk-wednesday-may-26-kira-goldner-columbia-university/" rel="alternate" type="text/html"/>
    <title>TCS+ talk: Wednesday, May 26 — Kira Goldner, Columbia University</title>
    <summary>The next TCS+ talk will take place this coming Wednesday, May 26th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). Kira Goldner from Columbia University will speak about “An Overview of Using Mechanism Design for Social Good” (abstract below). You can reserve a spot as an individual or […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The next TCS+ talk will take place this coming Wednesday, May 26th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). <a href="https://www.kiragoldner.com/"><strong>Kira Goldner</strong></a> from Columbia University will speak about “<em>An Overview of Using Mechanism Design for Social Good</em>” (abstract below).</p>
<p>You can reserve a spot as an individual or a group to join us live by signing up on <a href="https://sites.google.com/view/tcsplus/welcome/next-tcs-talk">the online form</a>. Due to security concerns, <em>registration is required</em> to attend the interactive talk. (The recorded talk will also be posted <a href="https://sites.google.com/view/tcsplus/welcome/past-talks">on our website</a> afterwards, so people who did not sign up will still be able to watch the talk) As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/view/tcsplus/welcome/suggest-a-talk">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/view/tcsplus/">the website</a>.</p>
<blockquote class="wp-block-quote"><p>Abstract: In order to accurately predict an algorithm’s outcome and quality when it interacts with participants who have a stake in the outcome, we must design it to be robust to strategic manipulation. This is the subject of algorithmic mechanism design, which borrows ideas from game theory and economics to design robust algorithms. In this talk, I will show how results from the theoretical foundations of algorithmic mechanism design can be used to solve problems of societal concern.</p>
<p>I will overview recent work in this area in many different applications — housing, labor markets, carbon license allocations, health insurance markets, and more — as well as discuss open problems and directions ripe for tools from both mechanism design and general TCS.</p></blockquote></div>
    </content>
    <updated>2021-05-20T21:53:27Z</updated>
    <published>2021-05-20T21:53:27Z</published>
    <category term="Announcements"/>
    <author>
      <name>plustcs</name>
    </author>
    <source>
      <id>https://tcsplus.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://tcsplus.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://tcsplus.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://tcsplus.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://tcsplus.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A carbon-free dissemination of ideas across the globe.</subtitle>
      <title>TCS+</title>
      <updated>2021-06-03T03:21:21Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-5273315380945865876</id>
    <link href="https://blog.computationalcomplexity.org/feeds/5273315380945865876/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2021/05/emerging-from-pandemic.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/5273315380945865876" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/5273315380945865876" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2021/05/emerging-from-pandemic.html" rel="alternate" type="text/html"/>
    <title>Emerging from the Pandemic</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The City of Chicago yesterday agreed with the latest CDC guidelines that those of us fully vaccinated no longer have to wear masks in most settings. Lollapalooza, the big Chicago music festival, will be held in full capacity this summer. There are still some restrictions but barring any surprise setbacks should be mostly gone by the Fourth of July.</p><p>It's not appropriate to call the pandemic over. Too many countries are suffering and lack good access to vaccines or strong health care. But in most of the US vaccinations are readily available and it really feels like we are putting the pandemic in the past.</p><p>Variants that beat the vaccines could emerge. Vaccines could become ineffective over time. Too many still need to be vaccinated and too many don't want to do so. Typically problems start small and quickly get big by exponential growth but likely with enough warning if we need boosters or extra precautions. And all those who cut in line to get shots early are now my canaries for the effects wearing off.</p><p>What will this post-pandemic world look like? Continued virtual meetings from people who don't want to spend the 10-15 minutes to get across campus or to come to campus at all. A bigger move to casual dress, even in the corporate world. No more snow days. Changes in ways we won't expect. </p><p>We all have our different attitudes but I'm ready to move on. Time to start the "after times".</p></div>
    </content>
    <updated>2021-05-20T14:07:00Z</updated>
    <published>2021-05-20T14:07:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2021-06-03T01:51:45Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=21532</id>
    <link href="https://gilkalai.wordpress.com/2021/05/20/to-cheer-you-up-in-difficult-times-25-some-mathematical-news-part-2/" rel="alternate" type="text/html"/>
    <title>To cheer you up in difficult times 25: some mathematical news! (Part 2)</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Topology Quasi-polynomial algorithms for telling if a knot is trivial Marc Lackenby announced a quasi-polynomial time algorithm to decide whether a given knot is the unknot! This is a big breakthrough. This question is known to be both in NP … <a href="https://gilkalai.wordpress.com/2021/05/20/to-cheer-you-up-in-difficult-times-25-some-mathematical-news-part-2/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><h2>Topology</h2>



<p/>


<h3>Quasi-polynomial algorithms for telling if a knot is trivial</h3>


<p>Marc Lackenby announced a quasi-polynomial time algorithm to decide whether a given knot is the unknot! This is a big breakthrough. This question is known to be both in NP and in coNP. See <a href="https://gilkalai.wordpress.com/2012/04/10/greg-kuperberg-it-is-in-np-to-tell-if-a-knot-is-knotted-under-grh/">this post</a>, and updates there in the <a href="https://gilkalai.wordpress.com/2012/04/10/greg-kuperberg-it-is-in-np-to-tell-if-a-knot-is-knotted-under-grh/#comment-43442">comment section</a>.</p>



<h4>Topology seminar, UC Davis, February 2021 and Oxford, March 2021 and <strong>today, May 20!</strong> <strong>16:00 CET</strong>, in the Copenhagen-Jerusalem combinatorics seminar (see details at the end of the post).</h4>



<p><a href="http://people.maths.ox.ac.uk/lackenby/quasipolynomial-talk-oxford.pdf">Unknot recognition in quasi-polynomial time</a> (The link is to the slides)</p>


<h3>NP hardness for related questions regarding knots</h3>


<p>This is a talk by Martin Tancer given at the  Copenhagen-Jerusalem  combinatorics seminar.</p>



<p>Title:  <a href="https://arxiv.org/abs/1810.03502">The unbearable hardness of unknotting</a>  (link to the 2018 arXive paper)</p>



<p>Abstract: </p>



<p>During the talk, I will sketch a proof that deciding if a diagram of the unknot can be untangled using at most k Riedemeister moves (where k is part of the input) is NP-hard. (This is not the same as the unknot recognition but it reveals some difficulties.) Similar ideas can be also used for proving that several other similar invariants are NP-hard to recognize on links.</p>



<p>Joint work with A. de Mesmay, Y. Rieck and E. Sedgwick.</p>



<h3>An approach toward exotic differentiable 4-dim spheres</h3>



<figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"><div class="wp-block-embed__wrapper">
<div class="embed-twitter"><blockquote class="twitter-tweet"><p dir="ltr" lang="en">Show one of these 21 links is smoothly slice and collect your Fields medal. <a href="https://twitter.com/hashtag/RBG?src=hash&amp;ref_src=twsrc%5Etfw">#RBG</a> <a href="https://t.co/Uem6CcXp7h">https://t.co/Uem6CcXp7h</a> <a href="https://t.co/eIPYVRktR0">pic.twitter.com/eIPYVRktR0</a></p>— Ian Agol (@agolian) <a href="https://twitter.com/agolian/status/1360269132822835201?ref_src=twsrc%5Etfw">February 12, 2021</a></blockquote></div>
</div></figure>



<p/>



<h3>Monumental work on Arnold’s conjecture</h3>



<p><a href="https://arxiv.org/abs/2103.01507">Arnold Conjecture and Morava K-theory</a> by Mohammed Abouzaid, Andrew J. Blumberg</p>



<figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"><div class="wp-block-embed__wrapper">
<div class="embed-twitter"><blockquote class="twitter-tweet"><p dir="ltr" lang="en">This is a big deal:<a href="https://t.co/CDGhu0GRZ3">https://t.co/CDGhu0GRZ3</a></p>— Justin Curry (@currying) <a href="https://twitter.com/currying/status/1367090561849696261?ref_src=twsrc%5Etfw">March 3, 2021</a></blockquote></div>
</div></figure>



<p>(I heard it from a retweet by Alex Kontorovich.)</p>



<p>Lower bound for the number of fixed points  of a map is a central theme in topology (and other areas) with many great results. The Lefshetz fixed point theorem tells you that a certain signed sum of the fixed points is bounded from below . For symplectic manifold Arnold’s conjecture asserts that the number of fixed point is bounded below from the sun of Betti numbers. This have led and is connected to tremendous mathematics.</p>



<blockquote class="wp-block-quote"><p><em>Abstract (part): We prove that the rank of the cohomology of a closed symplectic manifold with coefficients in a field of characteristic p is smaller than the number of periodic orbits of any non-degenerate Hamiltonian flow.</em></p></blockquote>



<h2>Graph theory</h2>



<h3><a href="https://arxiv.org/abs/2009.05495">Large spanning graphs with odd degrees</a></h3>



<p>Asaf Ferber and Michael Krivelevich solved an old conjecture in Graph theory. (In a 1994 paper by Yair Caro the problem is already referred to as part of the folklore of graph theory.)</p>



<p><strong>Abstract</strong>: We prove that every graph G on n vertices with no isolated vertices contains an induced subgraph of size at least n/10000 with all degrees odd. This solves an old and well-known conjecture in graph theory.</p>



<p>Here is <a href="https://www.quantamagazine.org/mathematicians-answer-old-question-about-odd-graphs-20210519/">an article about it in Quanta Magazine</a>. And here is a <a href="https://www.quantamagazine.org/new-proof-reveals-that-graphs-with-no-pentagons-are-fundamentally-different-20210426/">Quanta Magazine article</a> on the solution of the Erdos-Hajnal conjecture for pentagon-free graphs (that I mentioned in <a href="https://gilkalai.wordpress.com/2021/01/29/possible-future-polymath-projects-2009-2021/">this post</a>).</p>



<p/>



<h3><a href="https://arxiv.org/abs/2011.10939">The Betti numbers of the independence complex of a ternary graph</a></h3>



<p>A ternary graph (aka Trinity graph)  has no induced cycles of length divisible by three. Chudnovsky, Scott, Seymour and Spirkl <a href="https://arxiv.org/abs/1810.00065">proved</a> that for any ternary graph <em>G</em>, the number of independent sets with even cardinality and the independent sets with odd cardinality differ by at most 1. <a href="https://arxiv.org/search/?searchtype=author&amp;query=Wu%2C+H">Hehui Wu</a> and <a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhang%2C+W">Wentao Zhang</a> <a href="https://arxiv.org/abs/2101.07131">proved the stronger conjecture</a> that for ternary graphs, the sum of Betti numbers of the independent complex is at most one. (Both conjectures were proposed by Roy Meshulam and me.) Congratulations to Hehui and Wentao and all other people mentioned in this post. </p>



<p>For related advances see <a href="https://arxiv.org/search/?searchtype=author&amp;query=Engstrom%2C+A">Alexander Engstrom</a>, <a href="https://arxiv.org/abs/2009.11077">On the topological Kalai-Meshulam conjecture</a>;  <a href="https://arxiv.org/search/?searchtype=author&amp;query=Kim%2C+J">Jinha Kim,</a> <a href="https://arxiv.org/abs/2101.07131">The homotopy type of the independence complex of graphs with no induced cycle of length divisible by three </a> <br/><br/>Here is <a href="https://web.math.princeton.edu/~pds/papers/chibounded/paper.pdf">a very nice survey by Paul Seymour and Alex Scott on chi-boundedness</a>. Here is an <a href="https://gilkalai.wordpress.com/2014/12/19/when-a-few-colors-suffice/">earlier post on Trinity graphs and chi-boundedness.</a></p>



<p/>



<p> </p>



<h2>A breakthrough in additive combinatorics<br/><br/></h2>



<figure class="wp-block-image is-resized"><img alt="THP" class="wp-image-21752" height="140" src="https://gilkalai.files.wordpress.com/2021/05/thp.jpg" width="96"/><strong>Huy Tuan Pham</strong></figure>



<p><a href="http://www.its.caltech.edu/~dconlon/">David Conlon</a>, <a href="https://stanford.edu/~jacobfox/">Jacob Fox</a> and <a href="https://web.stanford.edu/~huypham/">Huy Tuan Pham</a> used a new unified approach to solve a variety of open problems around subset sums including the open problems of Burr and Erdős on Ramsey complete sequences (Erdős offered $350 for their solutions) and a problem of Alon and Erdős on estimating the minimum number <img alt="f(n)" class="latex" src="https://s0.wp.com/latex.php?latex=f%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/> of colors needed to color the positive integers less than <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/> so that <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/> cannot be written as a sum of elements of the same color. Conlon, Fox and Pham  proved that <img alt="f(n)" class="latex" src="https://s0.wp.com/latex.php?latex=f%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/> is within a constant factor of <em>n<sup>4/3</sup>φ(n)<sup>-1</sup>(log n)<sup>-1/3</sup>(loglog n)<sup>-2/3</sup></em>, where <em>φ(n)</em> is the Euler totient function. The paper is: </p>



<h3>The paper is: <a href="https://arxiv.org/abs/2104.14766">Subset sums, completeness and colorings</a>,</h3>



<h2><br/>P-adic local Langlands</h2>



<h3><a href="https://www.galoisrepresentations.com/2021/03/09/test-your-intuition-p-adic-local-langlands-edition/">Test Your Intuition: p-adic local Langlands edition</a>!</h3>



<p>This post over Persiflage will test your intuition about 2-dimensional crystalline deformation rings. Since I couldn’t understand even the first sentence, I decided to ask my FB and HUJI friend to explain it to me, so I may try to write about it later. Actually, a better idea is that  Persiflage will try to give a vastly non-technical  explanation from scratch on p-adic local Langlands conjecture, and where it stands and why it matters. (To be clear, I am sure it is a great staff! And perhaps it is not possible to explain it to a wide audience. But it worth a try.)<br/><br/>Meanwhile it reminded me of the following story to which I apparently was a witness.</p>



<p>At the time of my birth, the medical approach was that mother and child needed to stay at the hospital for at least four nights and even for an entire whole week. After two nights at the hospital, my mother decided  that she was ready to go home and got into a lengthy discussion with her doctor about it. At some point the exhausted doctor told her “Madam, I studied seven years in medical school, and I know what is good for you.” My mother was not impressed and replied: “Had I studied seven years in medical school, I would  have been a medical doctor as well. And now, let me go home.” At the end, my mother (and myself) left the hospital on the third day. Years later this became the medical standard. (My own approach is <em>to follow </em>medical doctor’s instructions.)</p>



<h2>Mathematics over the media</h2>



<h3><a href="http://www.ramanujanmachine.com/">Ramanujan machine</a>: machine learning for producing mathematical conjectures</h3>



<p>This is a cool and very interesting direction by very very young Israeli mathematicians  that was reported all over the media. (See, <a href="https://www.nature.com/articles/s41586-021-03229-4">here for a Nature article</a>.)</p>



<p>(There are various groups all over the world attempting to use machine learning to produce mathematical conjectures.)</p>



<h3>A new approach for solving quadratic equations</h3>



<p>I heard it (I think it was a year ago) from a Facebook post written by the prime minister of Singapore! And then I saw it in other places all over the media (<a href="https://www.nytimes.com/2020/02/05/science/quadratic-equations-algebra.html">here on the NYT</a>). I like it, and, in fact, I like the many things <a href="https://www.math.cmu.edu/~ploh/cmu.shtml">Po-Shen Loh</a> (who is my grand academic nephew) does in the service of mathematics.</p>



<p/>



<p>***************</p>



<p><strong>Copenhagen-Jerusalem Combinatorics Seminar</strong><br/><br/>It is my pleasure to invite you to the following talk:<br/>**************************************************************************<br/><a>Thursday, May 20</a> Time: <a>16:00-18:00 CET, Jerusalem +1<br/></a> Location: Zoom: <a href="https://ucph-ku.zoom.us/j/69204766431" rel="noreferrer noopener" target="_blank"/><a href="https://ucph-ku.zoom.us/j/69204766431" rel="noreferrer noopener" target="_blank">https://ucph-ku.zoom.us/j/69204766431</a></p>



<p>************************************************************************** </p>



<p>Marc Lackenby:  Unknot recognition in quasi-polynomial time<br/>**************************************************************************<br/><br/>Abstract: </p>



<p>I will outline a new algorithm for unknot recognition that runs in quasi-polynomial time. The input is a diagram of a knot with n crossings, and the running time is 2^{O((log n)^3)}. The algorithm uses a wide variety of tools from 3-manifold theory, including normal surfaces, hierarchies and Heegaard splittings. In my talk, I will explain this background theory, as well as explain how it fits into the algorithm.</p>



<pre class="wp-block-preformatted"/>



<p/></div>
    </content>
    <updated>2021-05-20T11:56:34Z</updated>
    <published>2021-05-20T11:56:34Z</published>
    <category term="Algebra"/>
    <category term="Combinatorics"/>
    <category term="Geometry"/>
    <category term="Number theory"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2021-06-03T03:20:28Z</updated>
    </source>
  </entry>
</feed>
