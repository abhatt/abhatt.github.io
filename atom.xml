<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2019-04-24T08:21:47Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.10215</id>
    <link href="http://arxiv.org/abs/1904.10215" rel="alternate" type="text/html"/>
    <title>Maximizing Communication Throughput in Tree Networks</title>
    <feedworld_mtime>1556064000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Emek:Yuval.html">Yuval Emek</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gavril:Fanica.html">Fanica Gavril</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kutten:Shay.html">Shay Kutten</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shalom:Mordechai.html">Mordechai Shalom</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zaks:Shmuel.html">Shmuel Zaks</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.10215">PDF</a><br/><b>Abstract: </b>A widely studied problem in communication networks is that of finding the
maximum number of communication requests that can be concurrently scheduled,
provided that there are at most $k$ requests that pass through any given edge
of the network. In this work we consider the problem of finding the largest
number of given subtrees of a tree that satisfy given load constraints. This is
an extension of the problem of finding a largest induced $k$-colorable subgraph
of a chordal graph (which is the intersection graph of subtrees of a tree). We
extend a greedy algorithm that solves the latter problem for interval graphs,
and obtain an $M$-approximation for chordal graphs where $M$ is the maximum
number of leaves of the subtrees in the representation of the chordal graph.
This implies a 2-approximation for \textsc{Vpt}} graphs (vertex-intersection
graphs of paths in a tree), and an optimal algorithm for the class of directed
path graphs (vertex-intersection graphs of paths in a directed tree) which in
turn extends the class of interval graphs.
</p>
<p>In fact, we consider a more general problem that is defined on the subtrees
of the representation of chordal graphs, in which we allow any set of different
bounds on the vertices and edges. Thus our algorithm generalizes the known one
in two directions: first, it applies to more general graph classes, and second,
it does not require the same bound for all the edges (of the representation).
Last, we present a polynomial-time algorithm for the general problem where
instances are restricted to paths in a star.
</p></div>
    </summary>
    <updated>2019-04-24T01:26:08Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-24T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.10210</id>
    <link href="http://arxiv.org/abs/1904.10210" rel="alternate" type="text/html"/>
    <title>Hierarchical b-Matching</title>
    <feedworld_mtime>1556064000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Emek:Yuval.html">Yuval Emek</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kutten:Shay.html">Shay Kutten</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shalom:Mordechai.html">Mordechai Shalom</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zaks:Shmuel.html">Shmuel Zaks</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.10210">PDF</a><br/><b>Abstract: </b>A matching of a graph is a subset of edges no two of which share a common
vertex, and a maximum matching is a matching of maximum cardinality. In a
$b$-matching every vertex $v$ has an associated bound $b_v$, and a maximum
$b$-matching is a maximum set of edges, such that every vertex $v$ appears in
at most $b_v$ of them. We study an extension of this problem, termed {\em
Hierarchical b-Matching}. In this extension, the vertices are arranged in a
hierarchical manner. At the first level the vertices are partitioned into
disjoint subsets, with a given bound for each subset. At the second level the
set of these subsets is again partitioned into disjoint subsets, with a given
bound for each subset, and so on. In an {\em Hierarchical b-matching} we look
for a maximum set of edges, that will obey all bounds (that is, no vertex $v$
participates in more than $b_v$ edges, then all the vertices in one subset do
not participate in more that that subset's bound of edges, and so on
hierarchically). We propose a polynomial-time algorithm for this new problem,
that works for any number of levels of this hierarchical structure.
</p></div>
    </summary>
    <updated>2019-04-24T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-24T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.10011</id>
    <link href="http://arxiv.org/abs/1904.10011" rel="alternate" type="text/html"/>
    <title>Computational Complexity of Restricted Diffusion Limited Aggregation</title>
    <feedworld_mtime>1556064000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Nicolas Bitar, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Goles:Eric.html">Eric Goles</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Montealegre:Pedro.html">Pedro Montealegre</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.10011">PDF</a><br/><b>Abstract: </b>We introduce a restricted version of the Diffusion Limited Aggregation (DLA)
model. DLA is a cluster growth model that consists in series of particles that
are thrown one by one from the top edge of a two (on more) dimensional grid,
where they undergo a random walk until they join the cluster. In our restricted
version, particles are limited to move in a subset of the possible directions.
</p>
<p>We study the restricted DLA model in the context of Computational Complexity,
defining a decision problem consisting in computing whether a given cell in the
grid will be occupied after the deterministic dynamics have taken place. We
find that depending on the imposed restrictions, this problem can be either
efficiently parallelizable of inherently sequential. More precisely, we show
that the prediction problem associated with particles allowing two or more
movement directions is P-Complete, as it can simulate arbitrary Boolean
circuits. On the hand, the prediction problem associated to particles
restricted to move in one direction is much more limited, despite still having
non-trivial computational capabilities. Indeed, in this case we show that the
prediction problem can be solved by a fast parallel algorithm.
</p></div>
    </summary>
    <updated>2019-04-24T01:23:02Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-04-24T01:30:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/04/23/euler-characteristics-nonmanifold</id>
    <link href="https://11011110.github.io/blog/2019/04/23/euler-characteristics-nonmanifold.html" rel="alternate" type="text/html"/>
    <title>Euler characteristics of non-manifold polycubes</title>
    <summary>From a block of cubes, remove two non-adjacent and non-opposite cubes. The resulting polycube has a boundary that is not a manifold: between the two removed cubes, there is an edge shared by four squares, but a two-dimensional manifold can only have two faces per edge. Nevertheless, we can compute its Euler characteristic as the number of vertices () minus the number of edges () plus the number of square faces (). , the same number we would expect for the Euler characteristic of a topological sphere! What does it mean?</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>From a  block of cubes, remove two non-adjacent and non-opposite cubes. The resulting polycube has a boundary that is not a <a href="https://en.wikipedia.org/wiki/Manifold">manifold</a>: between the two removed cubes, there is an edge shared by four squares, but a two-dimensional manifold can only have two faces per edge. Nevertheless, we can compute its Euler characteristic as the number of vertices () minus the number of edges () plus the number of square faces (). , the same number we would expect for the Euler characteristic of a topological sphere! What does it mean?</p>

<p style="text-align: center;"><img alt="Removing two non-adjacent and non-opposite cubes from a 2x2 block of cubes" src="https://11011110.github.io/blog/assets/2019/nonmanifold-polycube.svg"/></p>

<p>Any finite union of cubes of the integer lattice (not even necessarily connected) has as its boundary a set of vertices, edges, and squares, with each edge incident to an even number of squares. We can define the Euler characteristic to be the number of vertices minus edges plus squares, in the usual way. But we can also compute it in a different, more intrinsic and topological, way. For any  in the range , define the “shrunken interior” of the polycube to be the set of points of the interior farther than  from the boundary, and define the “shrunken exterior” in the same way. Then the shrunken interior and shrunken exterior both have (possibly disconnected) 2-manifolds as boundaries. We can define their Euler characteristics in the standard way from any cell decomposition of these boundaries (it doesn’t matter which cell decomposition we choose). Then the Euler characteristic of the polycube is the average of the Euler characteristics of the shrunken interior and shrunken exterior!</p>

<p>In the case of the mutilated  block, the shrunken interior and shrunken exterior are both topological balls (ignoring the puncture at infinity as it doesn’t have a boundary), so the average of their Euler characteristics is the Euler characteristic of a sphere, as we calculated.</p>

<p>There’s probably a simpler and more conceptual way of doing it, but here’s an explanation for why the Euler characteristic of the polycube boundary is the average of the Euler characteristics of the interior and exterior. Form a cell complex on the boundary of the interior and exterior, together, in the following way: expand each square of the polycube boundary to a cuboid with thickness 0.1, expand each edge into a cylinder with diameter 0.2 (big enough to enclose all the intersections of two expanded squares), and expand each vertex into a sphere with diameter 0.3 (big enough to enclose all the intersections of two cylinders but small enough that no two of these spheres touch). Remove the union of these expanded shapes from the space, and consider what’s left. It has the same topology as the union of the shrunken interior and exterior, and its boundary is now naturally divided up into cells: offset squares patches on the sides of each expanded square face, cylindrical patches on each expanded edge, and spherical patches on each expanded vertex, with curves where two patches meet.</p>

<p>Let’s calculate the Euler characteristic of this cell complex. Each square of the polycube leads to two offset square patches, so the  squares contribute   to the Euler characteristic. Each edge  of the polycube might be adjacent to two or four squares; call this number . Then the cylinder around  includes  surface patches between pairs of squares and  curves connecting them to the square patches. The patches count  and the curves count  for a total contribution to the Euler characteristic of .</p>

<p>Finally, each vertex of the polycube becomes a sphere, subdivided by the patches and curves of the complex. These spheres also contain all the vertices of the complex. The Euler characteristic of a subdivided sphere would be , but the vertex spheres have some parts of their subdivision removed. Where each edge cylinder or expanded square comes into the sphere, a patch of surfaces is removed, and the curves between these removed patches are also removed. An edge  with degree  contributes to the removal of  curves and  patches (one for itself and  for each adjacent square). So if there are  vertices in the polycube, the  contribution from the Euler characteristics of the subdivided spheres is modified by subtracting  for each incident edge. The total modification at both endpoints of each edge is . The  that we calculated here is cancelled by the  on the cylinder for , and we are left with a total modification of  where  is the number of polycube edges.</p>

<p>Putting all the pieces of this calculation together, the complex we have constructed on the union of the shrunken interior and exterior has Euler characteristic . Therefore, the Euler characteristic of the polycube boundary itself, , equals the average of the characteristics of the interior and exterior. The same reasoning shows more generally that whenever you have a finite cell complex embedded into , dividing space up into chambers, the Euler characteristic of the complex equals half the sum of Euler characteristics of the manifolds bounding shrunken chambers.</p>

<p>Although Euler characteristics of 2-manifolds embedded without boundary in  are always even, this averaging method can produce non-manifold surfaces with odd Euler characteristic. For instance, consider mutilating the  block in a different way, by removing two opposite cubes. The interior and exterior of the resulting polycube are both connected, but the interior is a solid torus and the exterior is a ball. So the Euler characteristic of the polycube should be the average of the torus and sphere, . And if we actually calculate it we get .</p>

<p>As this example shows, it’s possible for a polycube to have different topologies of surface on the interior and exterior, and it’s also possible to have different numbers of surfaces: for instance, two cubes attached vertex-to-vertex produce two interior surfaces but only one exterior. For cell complexes in , there appears to be no restriction on which combinations of surfaces are possible. But for cell complexes in other spaces (other 3-manifolds than Euclidean space) it may be possible to embed 2-manifolds with odd Euler characteristic. When this happens, the number of odd chambers of a cell complex must always be even. For, the parity of the sum of the Euler characteristics of the chambers must be even, in order to be able to divide by two and get an integer as the Euler characteristic of the cell complex.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/101978143052398446">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2019-04-23T16:37:00Z</updated>
    <published>2019-04-23T16:37:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-04-23T23:43:50Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=17325</id>
    <link href="https://gilkalai.wordpress.com/2019/04/23/an-invitation-to-a-conference-visions-in-mathematics-towards-2000/" rel="alternate" type="text/html"/>
    <title>An Invitation to a Conference: Visions in Mathematics towards 2000</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Let me invite you to a conference. The conference took place in 1999 but only recently the 57 videos of the lectures and the discussion sessions are publicly available. (I thank Vitali Milman for telling me about it.) One novel … <a href="https://gilkalai.wordpress.com/2019/04/23/an-invitation-to-a-conference-visions-in-mathematics-towards-2000/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Let me invite you to a conference. The conference took place in 1999 but only recently <a href="https://www.youtube.com/playlist?list=PLP0YToNcfAwLBd8yibTtjv3aHfcbT4GBA">the 57 videos of the lectures and the discussion sessions are publicly available.</a> (I thank Vitali Milman for telling me about it.) One novel idea of Vitali Milman was to hold discussion sessions and they were quite interesting. (But, I am biased, I like discussions.) I will invite you to one of the heated discussions in the next post. There were very many nice talks and very many nice visions. And it is fun to watch the videos and judge the ideas in the perspective of time.</p>
<p>The proceedings appeared as GAFA special volumes, but alas the articles are not electronically available even to GAFA’s subscribers. Let me encourage both Birkhauser and the contributors to make them more available. My talk was: <a href="https://youtu.be/Wjg1_QwjUos">An invitation to Tverberg’s theorem</a>, and my own contribution to the Proceedings <a href="http://www.ma.huji.ac.il/~kalai/VIS.pdf">Combinatorics with a Geometric Flavor </a>is probably the widest scope survey article I ever wrote.  At the end of each section I added a brief philosophical thought about mathematics and those are collected in the post “<a href="https://gilkalai.wordpress.com/2008/10/12/about-mathematics/">about mathematics</a>“.</p>
<p>Two more things: The conference (and few others organized by Vitali) was  in Tel Aviv with a few days at the dead see and this worked very nicely.  Vitali also organized in the mid 90s another very successful geometry conference unofficially celebrating Gromov’s 50th birthday with, among others, a very nice lecture by Gregory Perelman. If videos will become available I will be delighted to invite you to that conference as well. Update from Vitali: It was also the week of Jeff Cheeger’s 50th birthday which was also celebrated. Grisha Perelman gave an absolutely excellent talk  talk on works of Cheeger.  Lectures were not videotaped.</p>
<p/>
<p><span style="color: #ff0000;">Avi Wigderson’s lecture</span></p>
<p><span style="color: #ff0000;">Are so called “natural questions” good for mathematics. Specifically is Kepler’s questions about the densest packing of unit balls in 3-space interesting? Watch a discussion of Misha Gromov, Noga Alon, Laci Lovasz and others. (next post)</span></p>
<h2/>
<h2><a href="https://gilkalai.files.wordpress.com/2019/04/vis99-p1.png"><img alt="" class="alignnone size-full wp-image-17362" height="363" src="https://gilkalai.files.wordpress.com/2019/04/vis99-p1.png?w=640&amp;h=363" width="640"/></a></h2>
<p><span style="color: #ff0000;">We were all so much younger!  (And in that old millennium,  we were also all men <img alt="&#x1F626;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f626.png" style="height: 1em;"/> )</span></p>
<p><a href="https://gilkalai.files.wordpress.com/2019/04/misha5.png"><img alt="" class="alignnone size-full wp-image-17366" height="614" src="https://gilkalai.files.wordpress.com/2019/04/misha5.png?w=640&amp;h=614" width="640"/></a></p>
<p><span style="color: #ff0000;">Misha Gromov argues passionately that natural problems are bad problems (see next post)</span></p>
<p>Pictures of most participants ad two slides are below</p>
<p><span id="more-17325"/><br/>
<a href="https://gilkalai.files.wordpress.com/2019/04/vim1.png"><img alt="VIM1.png" class="alignnone size-full wp-image-17372" src="https://gilkalai.files.wordpress.com/2019/04/vim1.png?w=640" style="font-size: 12px;"/></a><br/>
<img alt="VIM2.png" class="alignnone size-full wp-image-17373" src="https://gilkalai.files.wordpress.com/2019/04/vim2.png?w=640"/><img alt="VIM3.png" class="alignnone size-full wp-image-17374" src="https://gilkalai.files.wordpress.com/2019/04/vim3.png?w=640"/><img alt="VIM5.png" class="alignnone size-full wp-image-17376" src="https://gilkalai.files.wordpress.com/2019/04/vim5.png?w=640"/><img alt="VIM6.png" class="alignnone size-full wp-image-17377" src="https://gilkalai.files.wordpress.com/2019/04/vim6.png?w=640"/><img alt="VIM7.png" class="alignnone size-full wp-image-17378" src="https://gilkalai.files.wordpress.com/2019/04/vim7.png?w=640"/><a href="https://gilkalai.files.wordpress.com/2019/04/vim4.png"><img alt="VIM4.png" class="alignnone size-full wp-image-17375" src="https://gilkalai.files.wordpress.com/2019/04/vim4.png?w=640"/></a></p></div>
    </content>
    <updated>2019-04-23T15:40:47Z</updated>
    <published>2019-04-23T15:40:47Z</published>
    <category term="Combinatorics"/>
    <category term="Conferences"/>
    <category term="What is Mathematics"/>
    <category term="Vitali Milman"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-04-24T08:20:43Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-8139226761048070665</id>
    <link href="https://blog.computationalcomplexity.org/feeds/8139226761048070665/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/04/quiz-show-scandalsadmissions.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/8139226761048070665" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/8139226761048070665" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/04/quiz-show-scandalsadmissions.html" rel="alternate" type="text/html"/>
    <title>Quiz Show Scandals/Admissions Scandal/Stormy Daniels/Beer names:being  a lawyer would drive me nuts!!!!!!</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">0) Charles van Doren (see <a href="https://en.wikipedia.org/wiki/Charles_Van_Doren">here</a>) passed away recently. For those who don't know he he was (prob most of you) he was one of the contestants involved in RIGGED quiz shows in the 1950's.  While there was a Grand Jury Hearing about Quiz Shows being rigged, nobody went to jail since TV was new and it was not clear if rigging quiz shows was illegal. Laws were then passed to make them it illegal.<br/>
<br/>
So why are today's so-called reality shows legal? I ask non-rhetorically.<br/>
<br/>
(The person he beat in a rigged game show- Herb Stempel (see <a href="https://en.wikipedia.org/wiki/Herb_Stempel">here</a>) is still alive.)<br/>
<br/>
1) The college admissions scandal. I won't restate the details and how awful it is since you can get that elsewhere and I doubt I can add much to it.  One thing I've heard in the discussions about it is a question that is often posted rhetorically but I want to pose for real:<br/>
<br/>
There are people whose parents give X dollars to a school and they get admitted even though they are not qualified. Why is that legal?<br/>
<br/>
I ask that question without an ax to grind and without anger. Why is out-right bribery of this sort legal?<br/>
<br/>
Possibilities:<br/>
<br/>
a) Its transparent. So being honest about bribery makes it okay?<br/>
<br/>
b) My question said `even though they are not qualified' - what if they explicitly or implicitly said `having parents give money to our school is one of our qualifications'<br/>
<br/>
c) The money they give is used to fund scholarships for students who can't afford to go. This is an argument for why its not immoral, not why its not illegal.<br/>
<br/>
But here is my question: Really, what is the legal issue here? It still seems like bribery.<br/>
<br/>
2) Big Oil gives money to congressman Smith, who then votes against a carbon tax. This seems like outright bribery<br/>
<br/>
Caveat:<br/>
<br/>
a) If Congressman Smith is normally a anti-regulation then he could say correctly that he was given the money because they agree with his general philosophy, so it's  not bribery.<br/>
<br/>
b) If Congressman smith is normally pro-environment and has no problem with voting for taxes then perhaps it is bribery.<br/>
<br/>
3) John Edwards a while back and Donald Trump now are claiming (not quite) that the money used to pay off their mistress to be quiet is NOT a campaign contribution, but was to keep the affair from his wife. (I don't think Donald Trump has admitted the affair so its harder to know what his defense is). But lets take a less controversial example of `what is a campaign contribution'<br/>
<br/>
I throw a party for my wife's 50th birthday and I invite Beto O'Rourke and many voters and some Dem party big-wigs to the party. The party costs me $50,000.  While I claim it's for my wife's bday it really is for Beto to make connections to voters and others. So is that a campaign contribution?<br/>
<br/>
4) The creators of HUGE ASS BEER are suing GIANT ASS BEER for trademark infringement. I am not making this up- see <a href="https://thetakeout.com/huge-giant-ass-beer-lawsuit-new-orleans-1832989913">here</a><br/>
<br/>
---------------------------------------------------------<br/>
<br/>
All of these cases involve ill defined questions (e.g., `what is a bribe'). And the people arguing either side are not unbiased. The cases also illustrate why I prefer mathematics: nice clean questions that (for the most part) have answers. We may have our biases as to which way they go, but if it went the other way we would not sue in a court of law.</div>
    </content>
    <updated>2019-04-23T03:24:00Z</updated>
    <published>2019-04-23T03:24:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-04-23T22:51:55Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://lucatrevisan.wordpress.com/?p=4233</id>
    <link href="https://lucatrevisan.wordpress.com/2019/04/22/the-more-things-change-the-more-they-stay-the-same/" rel="alternate" type="text/html"/>
    <title>The more things change the more they stay the same</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">From a 1981 (!!) New York Times Article titled “Changing San Francisco is foreseen as a haven for wealthy and childless”: A major reason for the exodus of the middle class from San Francisco, demographers say, is the high cost … <a href="https://lucatrevisan.wordpress.com/2019/04/22/the-more-things-change-the-more-they-stay-the-same/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>From a 1981 (!!) <a href="https://www.nytimes.com/1981/06/09/us/changing-san-francisco-is-foreseen-as-a-haven-for-wealthy-and-childless.html">New York Times Article</a> titled “Changing San Francisco is foreseen as a haven for wealthy and childless”:</p>
<blockquote><p>
A major reason for the exodus of the middle class from San Francisco, demographers say, is the high cost of housing, the highest in the mainland United States. Last month, the median cost of a dwelling in the San Francisco Standard Metropolitan Statistical Area was $129,000, according to the Federal Home Loan Bank Board in Washington, D.C. The comparable figure for New York, Newark and Jersey City was $90,400, and for Los Angeles, the second most expensive city, $118,400.</p>
<p>”This city dwarfs anything I’ve ever seen in terms of housing prices,” said Mr. Witte. Among factors contributing to high housing cost, according to Mr. Witte and others, is its relative scarcity, since the number of housing units has not grown significantly in a decade; the influx of Asians, whose first priority is usually to buy a home; the high incidence of adults with good incomes and no children, particularly homosexuals who pool their incomes to buy homes, and the desirability of San Francisco as a place to live.
</p></blockquote>
<p>$129,000 in 1981 dollars is $360,748 in 2019 dollars.</p></div>
    </content>
    <updated>2019-04-23T01:52:32Z</updated>
    <published>2019-04-23T01:52:32Z</published>
    <category term="history"/>
    <category term="San Francisco"/>
    <author>
      <name>luca</name>
    </author>
    <source>
      <id>https://lucatrevisan.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://lucatrevisan.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://lucatrevisan.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://lucatrevisan.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://lucatrevisan.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>"Marge, I agree with you - in theory. In theory, communism works. In theory." -- Homer Simpson</subtitle>
      <title>in   theory</title>
      <updated>2019-04-24T08:20:22Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.09958</id>
    <link href="http://arxiv.org/abs/1904.09958" rel="alternate" type="text/html"/>
    <title>Almost Optimal Testers for Concise Representations</title>
    <feedworld_mtime>1555977600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bshouty:Nader_H=.html">Nader H. Bshouty</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.09958">PDF</a><br/><b>Abstract: </b>We give improved and almost optimal testers for several classes of Boolean
functions on $n$ inputs that have concise representation in the uniform and
distribution-free model. Classes, such as $k$-junta, $k$-linear functions,
$s$-term DNF, $s$-term monotone DNF, $r$-DNF, decision list, $r$-decision list,
size-$s$ decision tree, size-$s$ Boolean formula, size-$s$ branching programs,
$s$-sparse polynomials over the binary field and function with Fourier degree
at most $d$. The method can be extended to several other classes of functions
over any domain that can be approximated by functions that have a small number
of relevant variables.
</p></div>
    </summary>
    <updated>2019-04-23T23:30:08Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.09854</id>
    <link href="http://arxiv.org/abs/1904.09854" rel="alternate" type="text/html"/>
    <title>A Triangle Algorithm for Semidefinite Version of Convex Hull Membership Problem</title>
    <feedworld_mtime>1555977600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kalantari:Bahman.html">Bahman Kalantari</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.09854">PDF</a><br/><b>Abstract: </b>Given a subset $\mathbf{S}=\{A_1, \dots, A_m\}$ of $\mathbb{S}^n$, the set of
$n \times n$ real symmetric matrices, we define its {\it spectrahull} as the
set $SH(\mathbf{S}) = \{p(X) \equiv (Tr(A_1 X), \dots, Tr(A_m X))^T : X \in
\mathbf{\Delta}_n\}$, where ${\bf \Delta}_n$ is the {\it spectraplex}, $\{ X
\in \mathbb{S}^n : Tr(X)=1, X \succeq 0 \}$. We let {\it spectrahull
membership} (SHM) to be the problem of testing if a given $b \in \mathbb{R}^m$
lies in $SH(\mathbf{S})$. On the one hand when $A_i$'s are diagonal matrices,
SHM reduces to the {\it convex hull membership} (CHM), a fundamental problem in
LP. On the other hand, a bounded SDP feasibility is reducible to SHM. By
building on the {\it Triangle Algorithm} (TA) \cite{kalchar,kalsep}, developed
for CHM and its generalization, we design a TA for SHM, where given
$\varepsilon$, in $O(1/\varepsilon^2)$ iterations it either computes a
hyperplane separating $b$ from $SH(\mathbf{S})$, or $X_\varepsilon \in
\mathbf{\Delta}_n$ such that $\Vert p(X_\varepsilon) - b \Vert \leq \varepsilon
R$, $R$ maximum error over $\mathbf{\Delta}_n$. Under certain conditions
iteration complexity improves to $O(1/\varepsilon)$ or even $O(\ln
1/\varepsilon)$. The worst-case complexity of each iteration is $O(mn^2)$, plus
testing the existence of a pivot, shown to be equivalent to estimating the
least eigenvalue of a symmetric matrix. This together with a semidefinite
version of Carath\'eodory theorem allow implementing TA as if solving a CHM,
resorting to the {\it power method} only as needed, thereby improving the
complexity of iterations. The proposed Triangle Algorithm for SHM is simple,
practical and applicable to general SDP feasibility and optimization. Also, it
extends to a spectral analogue of SVM for separation of two spectrahulls.
</p></div>
    </summary>
    <updated>2019-04-23T23:24:40Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-04-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.09841</id>
    <link href="http://arxiv.org/abs/1904.09841" rel="alternate" type="text/html"/>
    <title>Low-Rank Approximation from Communication Complexity</title>
    <feedworld_mtime>1555977600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Musco:Cameron.html">Cameron Musco</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Musco:Christopher.html">Christopher Musco</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Woodruff:David_P=.html">David P. Woodruff</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.09841">PDF</a><br/><b>Abstract: </b>In low-rank approximation with missing entries, given $A\in
\mathbb{R}^{n\times n}$ and binary $W \in \{0,1\}^{n\times n}$, the goal is to
find a rank-$k$ matrix $L$ for which: $$cost(L)=\sum_{i=1}^{n}
\sum_{j=1}^{n}W_{i,j}\cdot (A_{i,j} - L_{i,j})^2\le OPT+\epsilon \|A\|_F^2,$$
where $OPT=\min_{rank-k\ \hat{L}}cost(\hat L)$. This problem is also known as
matrix completion and, depending on the choice of $W$, captures low-rank plus
diagonal decomposition, robust PCA, low-rank recovery from monotone missing
data, and a number of other important problems. Many of these problems are
NP-hard, and while algorithms with provable guarantees are known in some cases,
they either 1) run in time $n^{\Omega(k^2/\epsilon)}$, or 2) make strong
assumptions, e.g., that $A$ is incoherent or that $W$ is random.
</p>
<p>In this work, we consider $bicriteria\ algorithms$, which output $L$ with
rank $k' &gt; k$. We prove that a common heuristic, which simply sets $A$ to $0$
where $W$ is $0$, and then computes a standard low-rank approximation, achieves
the above approximation bound with rank $k'$ depending on the $communication\
complexity$ of $W$. Namely, interpreting $W$ as the communication matrix of a
Boolean function $f(x,y)$ with $x,y\in \{0,1\}^{\log n}$, it suffices to set
$k'=O(k\cdot 2^{R^{1-sided}_{\epsilon}(f)})$, where $R^{1-sided}_{\epsilon}(f)$
is the randomized communication complexity of $f$ with $1$-sided error
probability $\epsilon$. For many problems, this yields bicriteria algorithms
with $k'=k\cdot poly((\log n)/\epsilon)$.
</p>
<p>We prove a similar bound using the randomized communication complexity with
$2$-sided error. Further, we show that different models of communication yield
algorithms for natural variants of the problem. E.g., multi-player
communication complexity connects to tensor decomposition and non-deterministic
communication complexity to Boolean low-rank factorization.
</p></div>
    </summary>
    <updated>2019-04-23T23:26:38Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.09710</id>
    <link href="http://arxiv.org/abs/1904.09710" rel="alternate" type="text/html"/>
    <title>Robust Clustering Oracle and Local Reconstructor of Cluster Structure of Graphs</title>
    <feedworld_mtime>1555977600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Peng:Pan.html">Pan Peng</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.09710">PDF</a><br/><b>Abstract: </b>Due to the massive size of modern network data, local algorithms that run in
sublinear time for analyzing the cluster structure of the graph are receiving
growing interest. Two typical examples are local graph clustering algorithms
that find a cluster from a seed node with running time proportional to the size
of the output set, and clusterability testing algorithms that decide if a graph
can be partitioned into a few clusters in the framework of property testing.
</p>
<p>In this work, we develop sublinear time algorithms for analyzing the cluster
structure of graphs with noisy partial information. By using conductance based
definitions for measuring the quality of clusters and the cluster structure, we
formalize a definition of noisy clusterable graphs with bounded maximum degree.
The algorithm is given query access to the adjacency list to such a graph. We
then formalize the notion of robust clustering oracle for a noisy clusterable
graph, and give an algorithm that builds such an oracle in sublinear time,
which can be further used to support typical queries (e.g., IsOutlier($s$),
SameCluster($s,t$)) regarding the cluster structure of the graph in sublinear
time. All the answers are consistent with a partition of $G$ in which all but a
small fraction of vertices belong to some good cluster. We also give a local
reconstructor for a noisy clusterable graph that provides query access to a
reconstructed graph that is guaranteed to be clusterable in sublinear time. All
the query answers are consistent with a clusterable graph which is guaranteed
to be close to the original graph.
</p></div>
    </summary>
    <updated>2019-04-23T23:29:41Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.09690</id>
    <link href="http://arxiv.org/abs/1904.09690" rel="alternate" type="text/html"/>
    <title>Dynamic Time Warping in Strongly Subquadratic Time: Algorithms for the Low-Distance Regime and Approximate Evaluation</title>
    <feedworld_mtime>1555977600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kuszmaul:William.html">William Kuszmaul</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.09690">PDF</a><br/><b>Abstract: </b>Dynamic time warping distance (DTW) is a widely used distance measure between
time series. The best known algorithms for computing DTW run in near quadratic
time, and conditional lower bounds prohibit the existence of significantly
faster algorithms. The lower bounds do not prevent a faster algorithm for the
special case in which the DTW is small, however. For an arbitrary metric space
$\Sigma$ with distances normalized so that the smallest non-zero distance is
one, we present an algorithm which computes $\operatorname{dtw}(x, y)$ for two
strings $x$ and $y$ over $\Sigma$ in time $O(n \cdot \operatorname{dtw}(x,
y))$. We also present an approximation algorithm which computes
$\operatorname{dtw}(x, y)$ within a factor of $O(n^\epsilon)$ in time
$\tilde{O}(n^{2 - \epsilon})$ for $0 &lt; \epsilon &lt; 1$. The algorithm allows for
the strings $x$ and $y$ to be taken over an arbitrary well-separated tree
metric with logarithmic depth and at most exponential aspect ratio. Extending
our techniques further, we also obtain the first approximation algorithm for
edit distance to work with characters taken from an arbitrary metric space,
providing an $n^\epsilon$-approximation in time $\tilde{O}(n^{2 - \epsilon})$,
with high probability. Additionally, we present a simple reduction from
computing edit distance to computing DTW. Applying our reduction to a
conditional lower bound of Bringmann and K\"unnemann pertaining to edit
distance over $\{0, 1\}$, we obtain a conditional lower bound for computing DTW
over a three letter alphabet (with distances of zero and one). This improves on
a previous result of Abboud, Backurs, and Williams. With a similar approach, we
prove a reduction from computing edit distance to computing longest LCS length.
This means that one can recover conditional lower bounds for LCS directly from
those for edit distance, which was not previously thought to be the case.
</p></div>
    </summary>
    <updated>2019-04-23T23:26:33Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.09667</id>
    <link href="http://arxiv.org/abs/1904.09667" rel="alternate" type="text/html"/>
    <title>Scheduling to Approximate Minimization Objectives on Identical Machines</title>
    <feedworld_mtime>1555977600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Moseley:Benjamin.html">Benjamin Moseley</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.09667">PDF</a><br/><b>Abstract: </b>This paper considers scheduling on identical machines. The scheduling
objective considered in this paper generalizes most scheduling minimization
problems. In the problem, there are $n$ jobs and each job $j$ is associated
with a monotonically increasing function $g_j$. The goal is to design a
schedule that minimizes $\sum_{j \in [n]} g_{j}(C_j)$ where $C_j$ is the
completion time of job $j$ in the schedule. An $O(1)$-approximation is known
for the single machine case. On multiple machines, this paper shows that if the
scheduler is required to be either non-migratory or non-preemptive then any
algorithm has an unbounded approximation ratio. Using preemption and migration,
this paper gives a $O(\log \log nP)$-approximation on multiple machines, the
first result on multiple machines. These results imply the first non-trivial
positive results for several special cases of the problem considered, such as
throughput minimization and tardiness.
</p>
<p>Natural linear programs known for the problem have a poor integrality gap.
The results are obtained by strengthening a natural linear program for the
problem with a set of covering inequalities we call job cover inequalities.
This linear program is rounded to an integral solution by building on
quasi-uniform sampling and rounding techniques.
</p></div>
    </summary>
    <updated>2019-04-23T23:31:17Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.09618</id>
    <link href="http://arxiv.org/abs/1904.09618" rel="alternate" type="text/html"/>
    <title>Trace Reconstruction: Generalized and Parameterized</title>
    <feedworld_mtime>1555977600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Krishnamurthy:Akshay.html">Akshay Krishnamurthy</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mazumdar:Arya.html">Arya Mazumdar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/McGregor:Andrew.html">Andrew McGregor</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pal:Soumyabrata.html">Soumyabrata Pal</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.09618">PDF</a><br/><b>Abstract: </b>In the beautifully simple-to-state problem of trace reconstruction, the goal
is to reconstruct an unknown binary string $x$ given random "traces" of $x$
where each trace is generated by deleting each coordinate of $x$ independently
with probability $p&lt;1$. The problem is well studied both when the unknown
string is arbitrary and when it is chosen uniformly at random. For both
settings, there is still an exponential gap between upper and lower sample
complexity bounds and our understanding of the problem is still surprisingly
limited. In this paper, we consider natural parameterizations and
generalizations of this problem in an effort to attain a deeper and more
comprehensive understanding.
</p>
<p>We prove that $\exp(O(n^{1/4} \sqrt{\log n}))$ traces suffice for
reconstructing arbitrary matrices. In the matrix version of the problem, each
row and column of an unknown $\sqrt{n}\times \sqrt{n}$ matrix is deleted
independently with probability $p$. Our results contrasts with the best known
results for sequence reconstruction where the best known upper bound is
$\exp(O(n^{1/3}))$. An optimal result for random matrix reconstruction: we show
that $\Theta(\log n)$ traces are necessary and sufficient. This is in contrast
to the problem for random sequences where there is a super-logarithmic lower
bound and the best known upper bound is $\exp({O}(\log^{1/3} n))$. We show that
$\exp(O(k^{1/3}\log^{2/3} n))$ traces suffice to reconstruct $k$-sparse
strings, providing an improvement over the best known sequence reconstruction
results when $k = o(n/\log^2 n)$. We show that $\textrm{poly}(n)$ traces
suffice if $x$ is $k$-sparse and we additionally have a "separation" promise,
specifically that the indices of 1's in $x$ all differ by $\Omega(k \log n)$.
</p></div>
    </summary>
    <updated>2019-04-23T23:25:46Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.09562</id>
    <link href="http://arxiv.org/abs/1904.09562" rel="alternate" type="text/html"/>
    <title>An Improved FPTAS for 0-1 Knapsack</title>
    <feedworld_mtime>1555977600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jin:Ce.html">Ce Jin</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.09562">PDF</a><br/><b>Abstract: </b>The 0-1 knapsack problem is an important NP-hard problem that admits fully
polynomial-time approximation schemes (FPTASs). Previously the fastest FPTAS by
Chan (2018) with approximation factor $1+\varepsilon$ runs in $\tilde O(n +
(1/\varepsilon)^{12/5})$ time, where $\tilde O$ hides polylogarithmic factors.
In this paper we present an improved algorithm in $\tilde
O(n+(1/\varepsilon)^{9/4})$ time, with only a $(1/\varepsilon)^{1/4}$ gap from
the quadratic conditional lower bound based on $(\min,+)$-convolution. Our
improvement comes from a multi-level extension of Chan's number-theoretic
construction, and a greedy lemma that reduces unnecessary computation spent on
cheap items.
</p></div>
    </summary>
    <updated>2019-04-23T23:29:48Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.09561</id>
    <link href="http://arxiv.org/abs/1904.09561" rel="alternate" type="text/html"/>
    <title>Proceedings Twelfth Workshop on Developments in Computational Models and Ninth Workshop on Intersection Types and Related Systems</title>
    <feedworld_mtime>1555977600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pagani:Michele.html">Michele Pagani</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Alves:Sandra.html">Sandra Alves</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.09561">PDF</a><br/><b>Abstract: </b>This volume contains a final and revised selection of papers presented at
Twelfth Workshop on Developments in Computational Models (DCM 2018) and the
Ninth Workshop on Intersection Types and Related Systems (ITRS 2018), held on
July 8, 2018 in Oxford, in affiliation with FLOC 2018.
</p></div>
    </summary>
    <updated>2019-04-23T23:24:28Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-04-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.09526</id>
    <link href="http://arxiv.org/abs/1904.09526" rel="alternate" type="text/html"/>
    <title>Constructive Polynomial Partitioning for Algebraic Curves in $\mathbb{R}^3$ with Applications</title>
    <feedworld_mtime>1555977600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Aronov:Boris.html">Boris Aronov</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Ezra:Esther.html">Esther Ezra</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zahl:Joshua.html">Joshua Zahl</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.09526">PDF</a><br/><b>Abstract: </b>In 2015, Guth proved that for any set of $k$-dimensional varieties in
$\mathbb{R}^d$ and for any positive integer $D$, there exists a polynomial of
degree at most $D$ whose zero-set divides $\mathbb{R}^d$ into open connected
"cells," so that only a small fraction of the given varieties intersect each
cell. Guth's result generalized an earlier result of Guth and Katz for points.
</p>
<p>Guth's proof relies on a variant of the Borsuk-Ulam theorem, and for $k&gt;0$,
it is unknown how to obtain an explicit representation of such a partitioning
polynomial and how to construct it efficiently. In particular, it is unknown
how to effectively construct such a polynomial for curves (or even lines) in
$\mathbb{R}^3$.
</p>
<p>We present an efficient algorithmic construction for this setting. Given a
set of $n$ input curves and a positive integer $D$, we efficiently construct a
decomposition of space into $O(D^3\log^3{D})$ open cells, each of which meets
$O(n/D^2)$ curves from the input. The construction time is $O(n^2)$. For the
case of lines in $3$-space we present an improved implementation, whose running
time is $O(n^{4/3} \operatorname{polylog} n)$. The constant of proportionality
in both time bounds depends on $D$ and the maximum degree of the polynomials
defining the input curves.
</p>
<p>As an application, we revisit the problem of eliminating depth cycles among
non-vertical lines in $3$-space, recently studied by Aronov and Sharir (2018),
and show an algorithm that cuts $n$ such lines into $O(n^{3/2+\varepsilon})$
pieces that are depth-cycle free, for any $\varepsilon &gt; 0$. The algorithm runs
in $O(n^{3/2+\varepsilon})$ time, which is a considerable improvement over
previously known algorithms.
</p></div>
    </summary>
    <updated>2019-04-23T23:32:16Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-04-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.09470</id>
    <link href="http://arxiv.org/abs/1904.09470" rel="alternate" type="text/html"/>
    <title>Cluster Deletion on Interval Graphs and Split Related Graphs</title>
    <feedworld_mtime>1555977600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Konstantinidis:Athanasios_L=.html">Athanasios L. Konstantinidis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Papadopoulos:Charis.html">Charis Papadopoulos</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.09470">PDF</a><br/><b>Abstract: </b>In the {\sc Cluster Deletion} problem the goal is to remove the minimum
number of edges of a given graph, such that every connected component of the
resulting graph constitutes a clique. It is known that the decision version of
{\sc Cluster Deletion} is NP-complete on ($P_5$-free) chordal graphs, whereas
{\sc Cluster Deletion} is solved in polynomial time on split graphs. However,
the existence of a polynomial-time algorithm of {\sc Cluster Deletion} on
interval graphs, a proper subclass of chordal graphs, remained a well-known
open problem. Our main contribution is that we settle this problem in the
affirmative, by providing a polynomial-time algorithm for {\sc Cluster
Deletion} on interval graphs. Moreover, despite the simple formulation of the
algorithm on split graphs, we show that {\sc Cluster Deletion} remains
NP-complete on a natural and slight generalization of split graphs that
constitutes a proper subclass of $P_5$-free chordal graphs. To complement our
results, we provide two polynomial-time algorithms for {\sc Cluster Deletion}
on subclasses of such generalizations of split graphs.
</p></div>
    </summary>
    <updated>2019-04-23T23:29:52Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.09438</id>
    <link href="http://arxiv.org/abs/1904.09438" rel="alternate" type="text/html"/>
    <title>Decomposing a Graph into Unigraphs</title>
    <feedworld_mtime>1555977600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Horiyama:Takashi.html">Takashi Horiyama</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kawahara:Jun.html">Jun Kawahara</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Minato:Shin=ichi.html">Shin-ichi Minato</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nakahata:Yu.html">Yu Nakahata</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.09438">PDF</a><br/><b>Abstract: </b>Unigraphs are graphs uniquely determined by their own degree sequence up to
isomorphism. There are many subclasses of unigraphs such as threshold graphs,
split matrogenic graphs, matroidal graphs, and matrogenic graphs. Unigraphs and
these subclasses are well studied in the literature. Nevertheless, there are
few results on superclasses of unigraphs. In this paper, we introduce two types
of generalizations of unigraphs: $k$-unigraphs and $k$-strong unigraphs. We say
that a graph $G$ is a $k$-unigraph if $G$ can be partitioned into $k$
unigraphs. $G$ is a $k$-strong unigraph if not only each subgraph is a unigraph
but also the whole graph can be uniquely determined up to isomorphism, by using
the degree sequences of all the subgraphs in the partition. We describe a
relation between $k$-strong unigraphs and the subgraph isomorphism problem. We
show some properties of $k$-(strong) unigraphs and algorithmic results on
calculating the minimum $k$ such that a graph $G$ is a $k$-(strong) unigraph.
This paper will open many other research topics.
</p></div>
    </summary>
    <updated>2019-04-23T23:28:52Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.09433</id>
    <link href="http://arxiv.org/abs/1904.09433" rel="alternate" type="text/html"/>
    <title>Can Machine Learning Model with Static Features be Fooled: an Adversarial Machine Learning Approach</title>
    <feedworld_mtime>1555977600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Rahim Taheri, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Javidan:Reza.html">Reza Javidan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shojafar:Mohammad.html">Mohammad Shojafar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/P:Vinod.html">Vinod P</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Conti:Mauro.html">Mauro Conti</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.09433">PDF</a><br/><b>Abstract: </b>The widespread adoption of smartphones dramatically increases the risk of
attacks and the spread of mobile malware, especially on the Android platform.
Machine learning based solutions have been already used as a tool to supersede
signature based anti-malware systems. However, malware authors leverage
attributes from malicious and legitimate samples to estimate statistical
difference in-order to create adversarial examples. Hence, to evaluate the
vulnerability of machine learning algorithms in malware detection, we propose
five different attack scenarios to perturb malicious applications (apps). By
doing this, the classification algorithm inappropriately fits discriminant
function on the set of data points, eventually yielding a higher
misclassification rate. Further, to distinguish the adversarial examples from
benign samples, we propose two defense mechanisms to counter attacks. To
validate our attacks and solutions, we test our model on three different
benchmark datasets. We also test our methods using various classifier
algorithms and compare them with the state-of-the-art data poisoning method
using the Jacobian matrix. Promising results show that generated adversarial
samples can evade detection with a very high probability. Additionally, evasive
variants generated by our attacks models when used to harden the developed
anti-malware system improves the detection rate.
</p></div>
    </summary>
    <updated>2019-04-23T23:21:09Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-04-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.09378</id>
    <link href="http://arxiv.org/abs/1904.09378" rel="alternate" type="text/html"/>
    <title>A General Neural Network Architecture for Persistence Diagrams and Graph Classification</title>
    <feedworld_mtime>1555977600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Carri=egrave=re:Mathieu.html">Mathieu Carrière</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chazal:Fr=eacute=d=eacute=ric.html">Frédéric Chazal</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Ike:Yuichi.html">Yuichi Ike</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lacombe:Th=eacute=o.html">Théo Lacombe</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Royer:Martin.html">Martin Royer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/u/Umeda:Yuhei.html">Yuhei Umeda</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.09378">PDF</a><br/><b>Abstract: </b>Graph classification is a difficult problem that has drawn a lot of attention
from the machine learning community over the past few years. This is mainly due
to the fact that, contrarily to Euclidean vectors, the inherent complexity of
graph structures can be quite hard to encode and handle for traditional
classifiers. Even though kernels have been proposed in the literature, the
increase in the dataset sizes has greatly limited the use of kernel methods
since computation and storage of kernel matrices has become impracticable. In
this article, we propose to use extended persistence diagrams to efficiently
encode graph structure. More precisely, we show that using the so-called heat
kernel signatures for the computation of these extended persistence diagrams
allows one to quickly and efficiently summarize the graph structure. Then, we
build on the recent development of neural networks for point clouds to define
an architecture for (extended) persistence diagrams which is modular and
easy-to-use. Finally, we demonstrate the usefulness of our approach by
validating our architecture on several graph datasets, on which the obtained
results are comparable to the state-of-the-art for graph classification.
</p></div>
    </summary>
    <updated>2019-04-23T23:31:38Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-04-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.09354</id>
    <link href="http://arxiv.org/abs/1904.09354" rel="alternate" type="text/html"/>
    <title>Submodular Maximization Beyond Non-negativity: Guarantees, Fast Algorithms, and Applications</title>
    <feedworld_mtime>1555977600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Harshaw:Christopher.html">Christopher Harshaw</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Feldman:Moran.html">Moran Feldman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Ward:Justin.html">Justin Ward</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Karbasi:Amin.html">Amin Karbasi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.09354">PDF</a><br/><b>Abstract: </b>It is generally believed that submodular functions -- and the more general
class of $\gamma$-weakly submodular functions -- may only be optimized under
the non-negativity assumption $f(S) \geq 0$. In this paper, we show that once
the function is expressed as the difference $f = g - c$, where $g$ is monotone,
non-negative, and $\gamma$-weakly submodular and $c$ is non-negative modular,
then strong approximation guarantees may be obtained. We present an algorithm
for maximizing $g - c$ under a $k$-cardinality constraint which produces a
random feasible set $S$ such that $\mathbb{E} \left[ g(S) - c(S) \right] \geq
(1 - e^{-\gamma} - \epsilon) g(OPT) - c(OPT)$, whose running time is $O
(\frac{n}{\epsilon} \log^2 \frac{1}{\epsilon})$, i.e., independent of $k$. We
extend these results to the unconstrained setting by describing an algorithm
with the same approximation guarantees and faster $O(\frac{n}{\epsilon}
\log\frac{1}{\epsilon})$ runtime. The main techniques underlying our algorithms
are two-fold: the use of a surrogate objective which varies the relative
importance between $g$ and $c$ throughout the algorithm, and a geometric sweep
over possible $\gamma$ values. Our algorithmic guarantees are complemented by a
hardness result showing that no polynomial-time algorithm which accesses $g$
through a value oracle can do better. We empirically demonstrate the success of
our algorithms by applying them to experimental design on the Boston Housing
dataset and directed vertex cover on the Email EU dataset.
</p></div>
    </summary>
    <updated>2019-04-23T23:24:53Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://lucatrevisan.wordpress.com/?p=4230</id>
    <link href="https://lucatrevisan.wordpress.com/2019/04/22/online-optimization-post-0-definitions/" rel="alternate" type="text/html"/>
    <title>Online Optimization Post 0: Definitions</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Online convex optimization deals with the following setup: we want to design an algorithm that, at each discrete time step , comes up with a solution , where is a certain convex set of feasible solution. After the algorithm has … <a href="https://lucatrevisan.wordpress.com/2019/04/22/online-optimization-post-0-definitions/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
 Online convex optimization deals with the following setup: we want to design an algorithm that, at each discrete time step <img alt="{t=1,2,\ldots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%3D1%2C2%2C%5Cldots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t=1,2,\ldots}"/>, comes up with a solution <img alt="{x_t \in K}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_t+%5Cin+K%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x_t \in K}"/>, where <img alt="{K}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BK%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{K}"/> is a certain convex set of feasible solution. After the algorithm has selected its solution <img alt="{x_t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x_t}"/>, a convex cost function <img alt="{f_t : K \rightarrow {\mathbb R}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_t+%3A+K+%5Crightarrow+%7B%5Cmathbb+R%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_t : K \rightarrow {\mathbb R}}"/>, coming from a known restricted set of admissible cost functions <img alt="{{\cal F}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Ccal+F%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{\cal F}}"/>, is revealed, and the algorithm pays the loss <img alt="{f_t (x_t)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_t+%28x_t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_t (x_t)}"/>. </p>
<p>
Again, the algorithm has to come up with a solution <em>without knowing what cost functions it is supposed to be optimizing</em>. Furthermore, we will think of the sequence of cost functions <img alt="{f_1,f_2, \ldots,f_t,\ldots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_1%2Cf_2%2C+%5Cldots%2Cf_t%2C%5Cldots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_1,f_2, \ldots,f_t,\ldots}"/> not as being fixed in advanced and unknown to the algorithm, but as being dynamically generated by an adversary, after seeing the solutions provided by the algorithm. (This resilience to adaptive adversaries will be important in most of the applications.)</p>
<p>
The <em>offline optimum</em> after <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> steps is the total cost that the best possible fixed solution would have incurred when evaluated against the cost functions seen by the algorithm, that is, it is a solution to </p>
<p align="center"><img alt="\displaystyle  \min_{x\in K} \ \ \sum_{t=1}^T f_t (x) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmin_%7Bx%5Cin+K%7D+%5C+%5C+%5Csum_%7Bt%3D1%7D%5ET+f_t+%28x%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \min_{x\in K} \ \ \sum_{t=1}^T f_t (x) "/></p>
<p>
The <em>regret</em> after <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> steps is the difference between the loss suffered by the algorithm and the offline optimum, that is, </p>
<p/><p align="center"><img alt="\displaystyle  {\rm Regret}_T = \sum_{t=1}^T f_t (x_t) - \min_{x\in K} \ \ \sum_{t=1}^T f_t (x) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7B%5Crm+Regret%7D_T+%3D+%5Csum_%7Bt%3D1%7D%5ET+f_t+%28x_t%29+-+%5Cmin_%7Bx%5Cin+K%7D+%5C+%5C+%5Csum_%7Bt%3D1%7D%5ET+f_t+%28x%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  {\rm Regret}_T = \sum_{t=1}^T f_t (x_t) - \min_{x\in K} \ \ \sum_{t=1}^T f_t (x) "/></p>
<p>
The remarkable results that we will review give algorithms that achieve regret</p>
<p/><p align="center"><img alt="\displaystyle  {\rm Regret}_T \leq O_{K, {\cal F}} (\sqrt T) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7B%5Crm+Regret%7D_T+%5Cleq+O_%7BK%2C+%7B%5Ccal+F%7D%7D+%28%5Csqrt+T%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  {\rm Regret}_T \leq O_{K, {\cal F}} (\sqrt T) "/></p>
<p> that is, for fixed <img alt="{K}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BK%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{K}"/> and <img alt="{{\cal F}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Ccal+F%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{\cal F}}"/>, the regret-per-time-step goes to zero with the number of steps, as <img alt="{O\left( \frac 1 {\sqrt T} \right)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%5Cleft%28+%5Cfrac+1+%7B%5Csqrt+T%7D+%5Cright%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{O\left( \frac 1 {\sqrt T} \right)}"/>. It is intuitive that our bounds will have to depend on how big is the “diameter” of <img alt="{K}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BK%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{K}"/> and how large is the “magnitude” and “smoothness” of the functions <img alt="{f\in {\cal F}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%5Cin+%7B%5Ccal+F%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f\in {\cal F}}"/>, but depending on how we choose to formalize these quantities we will be led to define different algorithms. </p>
<p/></div>
    </content>
    <updated>2019-04-22T21:35:44Z</updated>
    <published>2019-04-22T21:35:44Z</published>
    <category term="theory"/>
    <category term="online optimization"/>
    <author>
      <name>luca</name>
    </author>
    <source>
      <id>https://lucatrevisan.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://lucatrevisan.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://lucatrevisan.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://lucatrevisan.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://lucatrevisan.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>"Marge, I agree with you - in theory. In theory, communism works. In theory." -- Homer Simpson</subtitle>
      <title>in   theory</title>
      <updated>2019-04-24T08:20:22Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=15778</id>
    <link href="https://rjlipton.wordpress.com/2019/04/21/pnp-proofs/" rel="alternate" type="text/html"/>
    <title>P=NP Proofs</title>
    <summary>Advice to claimers The Claimers The Claimers are a gang on the hit AMC television series The Walking Dead. They are the main antagonists in the second half of the zombie-apocalypse show’s Season 4. According to Wikipedia’s description, they “live by the philosophy of ‘claiming’.” Today Ken and I discuss issues about ‘claiming’ and give […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Advice to claimers</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2019/04/21/pnp-proofs/claimers3/" rel="attachment wp-att-15790"><img alt="" class="alignright size-medium wp-image-15790" height="191" src="https://rjlipton.files.wordpress.com/2019/04/claimers3.png?w=300&amp;h=191" width="300"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2"><a href="https://the-walking-dead-tvseries.fandom.com/wiki/The_Claimers">The Claimers</a></font></td>
</tr>
</tbody>
</table>
<p>
The Claimers are a gang on the hit AMC television <a href="https://en.wikipedia.org/wiki/The_Walking_Dead_(TV_series)">series</a> <em>The Walking Dead</em>. They are the main antagonists in the second half of the zombie-apocalypse show’s Season 4. According to Wikipedia’s <a href="https://en.wikipedia.org/wiki/The_Walking_Dead_(season_4)#The_Claimers">description</a>, they “live by the philosophy of ‘claiming’.”</p>
<p>
Today Ken and I discuss issues about ‘claiming’ and give advice on how to present your claims—or not.</p>
<p>
Yes, this post is about our own “claimers” in complexity theory. It is especially about those who claim to have a solution to P=NP. We will not give any names today. You know who you are.</p>
<p>
The TV Claimers meet a grisly end. We will not say any more about it. We want to be nice. But we would like to not keep seeing the same level of zombie claims raised again and again.</p>
<p>
<b>Please: Do not stop reading.</b> Yes we know that it is likely that no claimer really has such a proof. However, our suggestions apply to all of us when we have a non-trivial result. Especially a result that has been open, even if the result is not a major open problem. So please keep reading today.</p>
<p>
</p><p/><h2> So You Can Prove P=NP </h2><p/>
<p/><p>
This is a list of ideas for anyone who claims to have solved P=NP or some similar hard open problem in mathematics. There are already lots of suggestions online about what you should do, so this is just a list of additional thoughts. We hope they are helpful.</p>
<p>
</p><p/><h3> You are being pretty arrogant </h3><p/>
<p/><p>
In order to succeed in mathematics research one has to be a bit arrogant. It is quite difficult to prove new things without some swagger. However, proving or resolving P=NP requires a very non-humble attitude. I think many claimers have not thought how arrogant they are being. The P=NP problem is a huge open problem. Thousands and thousands of researchers have spent years thinking about it. Why do you, the claimer, think you see the light and we remain in the dark?</p>
<p>
It might be useful for the claimers to ponder: <i>Why did I succeed where all others have failed?</i> It might be useful to be a bit humble and at least think what did they see that we all missed? If they can say something like:</p>
<blockquote><p><b> </b> <em> The reason I succeeded in finding an algorithm for P=NP is that I noticed that <img alt="{\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\dots}"/> No one else seems to see that this insight is very powerful. It is very useful since it implies <img alt="{\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\dots}"/> </em>
</p></blockquote>
<p>
</p><p/><h3> Working alone </h3><p/>
<p/><p>
I think the vast majority of claimers of P=NP or other big results have almost always worked alone. This is okay, but the average number of authors these days of a theory paper is pretty large. So any paper that is sole authored, perhaps, leads the community think it is unusual—and is wrong. Another point is that being part of a team may help control the arrogance. It can also be invaluable in detecting errors. </p>
<p>
</p><p/><h3> Show them the money </h3><p/>
<p/><p>
There is an advantage in “proving” P=NP over other major problems. There is the Clay prize of a million dollars. I wonder if claimers could use the prize money in some interesting way. How about saying: If you read the my proof and repair it or make it more readable and it is correct, then you get something. A certain dollar amount. Or a percentage of the prize. Or—you get the idea.</p>
<p>
</p><p/><h3> The role of code </h3><p/>
<p/><p>
Many claimers have also supplied working code for their algorithm. That is they also supply a program that claims to solve some NP-complete problem. I have several thoughts about this. In some cases it seems that it could be possible to have code that works for small size problems, but not in the general case. This seems to be possible for the claims by some that they can solve the Traveling Salesman Problem, for example. Their algorithm could be correct for small instances.</p>
<p>
Mathematics is filled with surprises like: This effect works for all values of <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X}"/> less than some bound. If the claimers give a program, our expectation based on experience is that it may work for small cases but will probably fail in general. </p>
<p>
The last point is that working code could actually be valuable. If the code can be used to solve SAT problems how about using your program to enter a SAT contest and win it. A win, or even a good showing, would help tremendously in convincing people to read the paper. Or use the code to break some known cryptosystem. That would also convince people that they need to read your paper.</p>
<p>
</p><p/><h2> Writing Your Paper </h2><p/>
<p/><p>
Okay we all dream about solving a major open problem. Or even a minor one. Here we give an outline of how to write up such a paper. </p>
<p/><h3> How to write up the proof </h3><p/>
<p>
I would suggest that you not have any statements about why P=NP is an important problem. None. No history of the problem. No literature survey is needed. None. You goal is to get an expert to read and believe the proof. They will just skip over the above. Also please no statements of how your algorithm that solves P=NP is going to change the world. Just give us the proof.</p>
<p>
</p><p/><h3> How to get them to read the proof </h3><p/>
<p/><p>
This is really hard. Hard. I have read a number of claimers’ papers. I try to be helpful. However, many of us do not have the time to look at such papers. Years ago, before Fermat’s Last Theorem was solved, a famous mathematician once made up a post-card that looked like this:</p>
<p>
<a href="https://rjlipton.wordpress.com/2019/04/21/pnp-proofs/postcard/" rel="attachment wp-att-15784"><img alt="" class="aligncenter size-medium wp-image-15784" height="221" src="https://rjlipton.files.wordpress.com/2019/04/postcard.png?w=300&amp;h=221" width="300"/></a></p>
<p>
I think that we all have a mental version of this card. There are definitely ways to help induce someone to read a paper and its proof. Look at some recent top theory papers. Even the authors of these papers, often well known authors, work hard to motivate potential readers. The authors often do several things:</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <em>They often sketch the proof.</em> By leaving out details they may help get a reader interested. </p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <em>They often explain the new trick—or tricks.</em> The goal here is to explain some new insight that is used in the proof. We are very self-oriented: If I see that your new trick could be useful in my research that is a huge motivator for me to understand the proof. People are very excited about a strong result, but they are even more excited about a new trick. Explain what is new in your proof. If there is nothing new, no new trick or method, then hmmmm<img alt="{\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\dots}"/></p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <em>They often first prove a weaker result.</em> That is, they show that their method can already make progress. If you could prove that the zeta function has all its nontrivial zeros on the critical line, that would be apocalyptic—the famous Riemann Hypothesis, of course. But if you could merely prove that there is no zero in some new region, then that would still be <em>wonderful</em>. And also probably more believable. If you could prove that there is no zero <img alt="{z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bz%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{z}"/> with its real part <img alt="{0.99999}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0.99999%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0.99999}"/> that would be huge. If the proof of this is simpler, then use it to get readers excited about your full result. </p>
<p>
An observation related to the last point is: </p>
<blockquote><p><b> </b> <em> <i>Why do all claims of progress on P=NP give a polynomial time bound?</i> </em>
</p></blockquote>
<p>How about just getting a better bound of say <img alt="{2^{n/10}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5E%7Bn%2F10%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2^{n/10}}"/> for the Traveling Salesman Problem? Or a better bound for factoring? Or a better bound for your favorite problem?</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p>I hope these points help. One last pointer is to double-check dependencies. If your proof relies on a result by someone else, make sure the result really gives what you need. Terms may be defined differently from what you expect, or you may really need a feature of the proof rather than the mere statement. A mis-attributed result can become “undead.”</p></font></font></div>
    </content>
    <updated>2019-04-22T03:25:39Z</updated>
    <published>2019-04-22T03:25:39Z</published>
    <category term="Open Problems"/>
    <category term="P=NP"/>
    <category term="People"/>
    <category term="Proofs"/>
    <category term="claimed proofs"/>
    <category term="claims"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-04-24T08:20:48Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/062</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/062" rel="alternate" type="text/html"/>
    <title>TR19-062 |  Quantum Lower Bounds for Approximate Counting via Laurent Polynomials | 

	Scott Aaronson, 

	Robin Kothari, 

	William Kretschmer, 

	Justin Thaler</title>
    <summary>This paper proves new limitations on the power of quantum computers to solve approximate counting---that is, multiplicatively estimating the size of a nonempty set $S\subseteq [N]$.

Given only a membership oracle for $S$, it is well known that approximate counting takes $\Theta(\sqrt{N/|S|})$ quantum queries. But what if a quantum algorithm is also given "QSamples"---i.e., copies of the state $|S\rangle = \sum_{i\in S}|i\rangle$---or even the ability to apply reflections about $|S\rangle$? Our first main result is that, even then, the algorithm needs either $\Theta(\sqrt{N/|S|})$ queries or else $\Theta(\min\{|S|^{1/3},\sqrt{N/|S|}\})$ reflections or samples. We also give matching upper bounds.

We prove the lower bound using a novel generalization of the polynomial method of Beals et al. to Laurent polynomials, which can have negative exponents. We lower-bound Laurent polynomial degree using two methods: a new "explosion argument" and a new formulation of the dual polynomials method.

Our second main result rules out the possibility of a black-box Quantum Merlin-Arthur (or QMA) protocol for proving that a set is large. We show that, even if Arthur can make $T$ quantum queries to the set $S$, and also receives an $m$-qubit quantum witness from Merlin in support of $S$ being large, we have $Tm=\Omega(\min\{|S|,\sqrt{N/|S|}\})$. This resolves the open problem of giving an oracle separation between SBP and QMA.

Note that QMA is "stronger" than the queries+QSamples model in that Merlin's witness can be anything, rather than just the specific state $|S\rangle$, but also "weaker" in that Merlin's witness cannot be trusted. Intriguingly, Laurent polynomials also play a crucial role in our QMA lower bound, but in a completely different manner than in the queries+QSamples lower bound. This suggests that the "Laurent polynomial method" might be broadly useful in complexity theory.</summary>
    <updated>2019-04-21T13:57:29Z</updated>
    <published>2019-04-21T13:57:29Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-04-24T08:20:41Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/061</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/061" rel="alternate" type="text/html"/>
    <title>TR19-061 |  A Quantum Query Complexity Trichotomy for Regular Languages | 

	Daniel Grier, 

	Luke Schaeffer, 

	Scott Aaronson</title>
    <summary>We present a trichotomy theorem for the quantum query complexity of regular languages. Every regular language has quantum query complexity $\Theta(1)$, $\tilde{\Theta}(\sqrt n)$, or $\Theta(n)$. The extreme uniformity of regular languages prevents them from taking any other asymptotic complexity. This is in contrast to even the context-free languages, which we show can have query complexity $\Theta(n^c)$ for all computable $c \in [1/2,1]$. Our result implies an equivalent trichotomy for the approximate degree of regular languages, and a dichotomy---either $\Theta(1)$ or $\Theta(n)$---for sensitivity, block sensitivity, certificate complexity, deterministic query complexity, and randomized query complexity.

The heart of the classification theorem is an explicit quantum algorithm which decides membership in any star-free language in $\tilde{O}(\sqrt n)$ time. This well-studied family of the regular languages admits many interesting characterizations, for instance, as those languages expressible as sentences in first-order logic over the natural numbers with the less-than relation. Therefore, not only do the star-free languages capture functions such as OR, they can also express functions such as ``there exist a pair of 2's such that everything between them is a 0."  

Thus, we view the algorithm for star-free languages as a nontrivial generalization of Grover's algorithm which extends the quantum quadratic speedup to a much wider range of string-processing algorithms than was previously known.  We show a variety of applications---new quantum algorithms for dynamic constant-depth Boolean formulas, balanced parentheses nested constantly many levels deep, binary addition, a restricted word break problem, and path-discovery in narrow grids---all obtained as immediate consequences of our classification theorem.</summary>
    <updated>2019-04-21T13:56:47Z</updated>
    <published>2019-04-21T13:56:47Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-04-24T08:20:41Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=17317</id>
    <link href="https://gilkalai.wordpress.com/2019/04/21/the-random-matrix-and-more/" rel="alternate" type="text/html"/>
    <title>The (Random) Matrix and more</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Three pictures, and a few related links. Van Vu Spoiler: In one of the most intense scenes, the protagonist, with his bare hands and against all odds, took care of the mighty Wigner semi-circle law in two different ways. (From … <a href="https://gilkalai.wordpress.com/2019/04/21/the-random-matrix-and-more/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Three pictures, and a few related links.</p>
<h3>Van Vu</h3>
<p><a href="https://gilkalai.files.wordpress.com/2019/04/thematrixvv.jpg"><img alt="" class="alignnone size-full wp-image-17318" height="989" src="https://gilkalai.files.wordpress.com/2019/04/thematrixvv.jpg?w=640&amp;h=989" width="640"/></a></p>
<p><span style="color: #ff0000;">Spoiler: In one of the most intense scenes, the protagonist, with his bare hands and against all odds, took care of the mighty Wigner semi-circle law in two different ways. (From VV’s FB)</span></p>
<p><a href="https://math.virginia.edu/ims/lectures/van-vu/">More information on Van Vu’s series of lectures</a>. <a href="http://campuspress.yale.edu/vanvu/">Van Vu’s home page</a>; Related posts: <a href="https://www.scottaaronson.com/blog/?p=3482">did physicists really just prove that the universe is not a computer simulation—that we can’t be living in the Matrix?</a> (Shtetl-Optimized); A <a href="https://terrytao.wordpress.com/2012/02/02/random-matrices-the-universality-phenomenon-for-wigner-ensembles/">related 2012 post</a> on What’s New;</p>
<p>Two more pictures the first also from FB<span id="more-17317"/></p>
<h3>Saharon Shelah</h3>
<p><a href="https://gilkalai.files.wordpress.com/2019/04/saharon75.jpg"><img alt="" class="alignnone size-full wp-image-17320" height="498" src="https://gilkalai.files.wordpress.com/2019/04/saharon75.jpg?w=640&amp;h=498" width="640"/></a></p>
<p>Shaharon Shelah ICM 1974 (Vancouver) (Mohammad Golshani over FB)</p>
<p>See my post <a href="https://gilkalai.wordpress.com/2012/01/18/a-theorem-about-infinite-cardinals-everybody-should-know/" rel="bookmark">A theorem about infinite cardinals everybody should know</a>; Gowers’s post <a href="https://gowers.wordpress.com/2017/09/19/two-infinities-that-are-surprisingly-equal/">Two infinities that are surprisingly equal </a>about a recent breakthrough result by <a href="https://en.wikipedia.org/wiki/Maryanthe_Malliaris">Maryanthe Malliaris</a> and <a href="https://en.wikipedia.org/wiki/Saharon_Shelah">Saharon Shelah</a>; and <a href="https://arxiv.org/abs/1806.04917">a recent 4-page solution to a conjecture of Spencer</a> on finitary Hindman numbers by <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Mohsenipour%2C+S">Shahram Mohsenipour</a> and Shelah.  More information on the last paper: (1) It is an Iranian-Israeli collaboration (2) Spencer asked Shelah the question during the workshop: Combinatorics: Challenges and Applications, celebrating Noga Alon’s <a href="https://gilkalai.wordpress.com/2015/08/10/nogafest-nogaformulas-and-amazing-cash-prizes/">60th birthday</a>, Tel Aviv University, January 17-21, 2016. (3) This is paper 1146 in Shelah’s (main) <a href="http://shelah.logic.at/">list of publications</a>. Shelah’s 1974 lecture was called “Why There Are Many Nonisomorphic Models for Unsuperstable Theories.”</p>
<h3>Sándor Szalai,  Catherine Rényi, Alfréd Rényi András Hajnal and Paul Erdős</h3>
<p><a href="https://gilkalai.files.wordpress.com/2019/04/matrahazaszalairenyihajnalerdos1958.jpg"><img alt="" class="alignnone size-full wp-image-17314" height="434" src="https://gilkalai.files.wordpress.com/2019/04/matrahazaszalairenyihajnalerdos1958.jpg?w=640&amp;h=434" width="640"/></a></p>
<p>From left: Sándor Szalai,  Catherine Rényi, Alfréd Rényi, András Hajnal and Paul Erdős (Matrahaza ) The picture is from Janos Pach’s Lancaster lecture, who also discussed how Szalai came up with Ramsey’s theorem. (See also Noga Alon and Michel Krivelevich’s chapter <a href="http://www.cs.tau.ac.il/~nogaa/PDFS/epc7.pdf" rel="noopener" target="_blank" title="opens in a new window">Extremal and Probabilistic Combinatorics, In: Princeton Companion to Mathematics, W. T. Gowers, Ed., Princeton University Press 2008, pp. 562-575.</a>)</p>
<p>In the course of an examination of friendship between children some fifty years ago, the Hungarian sociologist Sandor Szalai observed that among any group of about twenty children he checked he could always find four children any two of whom were friends, or else four children no two of whom were friends. Despite the temptation to try to draw sociological conclusions, Szalai realized that this might well be a mathematical phenomenon rather than sociological one.  He got interested in the problem, discussed it with  Erdős, Rényi , and Turán and in a short time he came up with a number of interesting constructions. In fact, he obtained record lower bound estimates for several Ramsey numbers.</p>
<p>(Janos’ further remarks: “Sandor (Alexander) Szalai was a well known Hungarian sociologist and a famously bright and witty man. I am not sure whether he was the first to notice and study the the laws of clique- and anti-clique formation among groups of schoolchildren, but I suspect that he was not. The sociology of small groups used to be a popular alternative to more “dangerous” Marxist theories of classes in the 50-ies and 60-ies. My guess would be that Szalai discussed these issues and was fascinated by this subject some time around 1960. It is fair to say that he independently<em> conjectured</em> Ramsey’s theorem.”)</p></div>
    </content>
    <updated>2019-04-21T06:33:41Z</updated>
    <published>2019-04-21T06:33:41Z</published>
    <category term="Combinatorics"/>
    <category term="People"/>
    <category term="What is Mathematics"/>
    <category term="Alfr&#xE9;d R&#xE9;nyi"/>
    <category term="Andr&#xE1;s Hajnal"/>
    <category term="Catherine R&#xE9;nyi"/>
    <category term="Paul Erdos"/>
    <category term="Saharon Shelah"/>
    <category term="S&#xE1;ndor Szalai"/>
    <category term="Van Vu"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-04-24T08:20:44Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4172</id>
    <link href="https://www.scottaaronson.com/blog/?p=4172" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4172#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4172" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Not yet retired from research</title>
    <summary xml:lang="en-US">Last night, two papers appeared on the quantum physics arXiv that my coauthors and I have been working on for more than a year, and that I’m pretty happy about. The first paper, with Guy Rothblum, is Gentle Measurement of Quantum States and Differential Privacy (85 pages, to appear in STOC’2019). This is Guy’s first […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>Last night, two papers appeared on the quantum physics arXiv that my coauthors and I have been working on for more than a year, and that I’m pretty happy about.</p>



<p>The first paper, with Guy Rothblum, is <a href="https://arxiv.org/abs/1904.08747">Gentle Measurement of Quantum States and Differential Privacy</a> (85 pages, to appear in STOC’2019).  This is Guy’s first paper that has anything to do with quantum, and also my first paper that has anything to do with privacy.  (What do I care about privacy?  I just share everything on this blog…)  The paper has its origin when I gave a talk at the Weizmann Institute about “shadow tomography” (a task where you have to measure quantum states very carefully to avoid destroying them), and Guy was in the audience, and he got all excited that the techniques sounded just like what they use to ensure privacy in data-mining, and I figured it was just some wacky coincidence and brushed him off, but he persisted, and it turned out that he was 100% right, and our two fields were often studying the same problems from different angles and we could prove it.  Anyway, here’s the abstract:</p>



<blockquote>In <i>differential privacy (DP)</i>, we want to query a database about n users, in a way that “leaks at most ε about any individual user,” even conditioned on any outcome of the query.  Meanwhile, in <i>gentle measurement</i>, we want to measure n quantum states, in a way that “damages the states by at most α,” even conditioned on any outcome of the measurement.  In both cases, we can achieve the goal by techniques like deliberately adding noise to the outcome before returning it.  This paper proves a new and general connection between the two subjects.  Specifically, we show that on products of n quantum states, any measurement that is α-gentle for small α is also O(α)-DP, and any product measurement that is ε-DP is also O(ε√n)-gentle.
<p>Illustrating the power of this connection, we apply it to the recently studied problem of <i>shadow tomography</i>.  Given an unknown d-dimensional quantum state ρ, as well as known two-outcome measurements E<sub>1</sub>,…,E<sub>m</sub>, shadow tomography asks us to estimate Pr[E<sub>i</sub> accepts ρ], for <i>every</i> i∈[m], by measuring few copies of ρ.  Using our connection theorem, together with a quantum analog of the so-called <i>private multiplicative weights</i> algorithm of Hardt and Rothblum, we give a protocol to solve this problem using O((log m)<sup>2</sup>(log d)<sup>2</sup>) copies of ρ, compared to Aaronson’s previous bound of ~O((log m)<sup>4</sup>(log d)).  Our protocol has the advantages of being <i>online</i> (that is, the E<sub>i</sub>‘s are processed one at a time), gentle, and conceptually simple.
</p><p>Other applications of our connection include new <i>lower</i> bounds for shadow tomography from lower bounds on DP, and a result on the safe use of estimation algorithms as subroutines inside larger quantum algorithms.</p></blockquote>



<p>The second paper, with Robin Kothari, UT Austin PhD student William Kretschmer, and Justin Thaler, is <a href="https://arxiv.org/abs/1904.08914">Quantum Lower Bounds for Approximate Counting via Laurent Polynomials</a>.  Here’s the abstract:</p>



<blockquote>Given only a membership oracle for S, it is well-known that approximate counting takes Θ(√(N/|S|)) quantum queries.  But what if a quantum algorithm is also given “QSamples”—i.e., copies of the state |S〉=Σ<sub>i∈S</sub>|i〉—or even the ability to apply reflections about |S〉?  Our first main result is that, even then, the algorithm needs either Θ(√(N/|S|)) queries or else Θ(min{|S|<sup>1/3</sup>,√(N/|S|)}) reflections or samples.  We also give matching upper bounds.

<p>We prove the lower bound using a novel generalization of the polynomial method of Beals et al. to <i>Laurent polynomials</i>, which can have negative exponents.  We lower-bound Laurent polynomial degree using two methods: a new “explosion argument” that pits the positive- and negative-degree parts of the polynomial against each other, and a new formulation of the dual polynomials method.

</p><p>Our second main result rules out the possibility of a black-box Quantum Merlin-Arthur (or QMA) protocol for proving that a set is large. More precisely, we show that, even if Arthur can make T quantum queries to the set S⊆[N], and also receives an m-qubit quantum
witness from Merlin in support of S being large, we have Tm=Ω(min{|S|,√(N/|S|)}).  This resolves the open problem of giving an oracle separation between SBP, the complexity class that captures
approximate counting, and QMA.

</p><p>Note that QMA is “stronger” than the queries+QSamples model in that Merlin’s witness can be anything, rather than just the specific state |S〉, but also “weaker” in that Merlin’s witness cannot be trusted.  Intriguingly, Laurent polynomials <i>also</i> play a crucial role in our QMA lower bound, but in a completely different
manner than in the queries+QSamples lower bound.  This suggests that the “Laurent polynomial method” might be broadly useful in complexity theory.</p></blockquote>



<p>I need to get ready for our family’s Seder now, but after that, I’m happy to answer any questions about either of these papers in the comments.</p>



<p>Meantime, the biggest breakthrough in quantum complexity theory of the past month isn’t either of the above: it’s the <a href="https://arxiv.org/abs/1904.05870">paper by Anand Natarajan and John Wright</a> showing that MIP*, or multi-prover interactive proof systems with entangled provers, contains NEEXP, or nondeterministic <strong>doubly</strong>-exponential time (!!).  I’ll try to blog about this later, but if you can’t wait, check out <a href="https://mycqstate.wordpress.com/2019/04/14/randomness-and-interaction-entanglement-ups-the-game/">this excellent post by Thomas Vidick</a>.</p></div>
    </content>
    <updated>2019-04-19T21:16:21Z</updated>
    <published>2019-04-19T21:16:21Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Complexity"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Quantum"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2019-04-19T21:17:59Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=15768</id>
    <link href="https://rjlipton.wordpress.com/2019/04/18/a-reason-why-circuit-lower-bounds-are-hard/" rel="alternate" type="text/html"/>
    <title>A Reason Why Circuit Lower Bounds Are Hard</title>
    <summary>And a possible approach to avoid this obstacle Valentine Kabanets is a famous complexity theorist from Simon Fraser University. He has been at the forefront of lower bounds for over two decades. Today we draw attention to this work and raise an idea about trying to unravel what makes circuit lower bounds hard. He is […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>And a possible approach to avoid this obstacle</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<p><a href="https://rjlipton.files.wordpress.com/2019/04/kabanetssfu.jpg"><img alt="" class="alignright wp-image-15769" height="200" src="https://rjlipton.files.wordpress.com/2019/04/kabanetssfu.jpg?w=129&amp;h=200" width="129"/></a></p>
<p>
Valentine Kabanets is a famous complexity theorist from Simon Fraser University. He has been at the forefront of lower bounds for over two decades. </p>
<p>
Today we draw attention to this work and raise an idea about trying to unravel what makes circuit lower bounds hard.<span id="more-15768"/></p>
<p>
He is the common author on <a href="https://eccc.weizmann.ac.il/report/2019/022/">two</a> new <a href="https://eccc.weizmann.ac.il/report/2019/018/">papers</a> on the Minimum Circuit Size Problem (MCSP), which belongs to <img alt="{\mathsf{NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{NP}}"/> but is not known to be complete or in <img alt="{\mathsf{P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{P}}"/>. We <a href="https://rjlipton.wordpress.com/2015/03/05/news-on-intermediate-problems/">posted</a> on MCSP four years ago and mentioned his 1999 <a href="http://eccc.hpi-web.de/report/1999/045">paper</a> with Jin-Yi Cai, which gives evidence for MCSP truly being neither complete nor in <img alt="{\mathsf{P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{P}}"/>. This “intermediate” status and the problem’s simplicity have raised hopes that direct attacks might succeed. The new papers prove direct lower bounds against some restricted circuit/formula models, including constant-depth circuits with mod-<img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> gates for <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> prime. But they stop short of mod-<img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m}"/> for <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m}"/> composite and other barrier cases.</p>
<p>
He has a nifty research <a href="https://www.cs.sfu.ca/~kabanets/research.html">statement</a> on his home page. It shows how derandomization, pseudorandomness, circuit complexity, and crypto combine into his two current projects. In a clickable tab for the third heading, he puts the meta-issue in pithy terms:</p>
<blockquote><p><b> </b> <em> <i>Why is proving circuit lower bounds so difficult?</i> </em>
</p></blockquote>
<p/><p>
His first answer tab speaks a connection we have also often emphasized here:</p>
<blockquote><p><b> </b> <em> Traditionally, designing efficient algorithms is the subject of the theory of algorithms, while lower bounds are sought in complexity theory. It turns out, however, that there is a deep connection between the two directions: better algorithms (for a certain class of problems) also yield strong lower bounds (for related problems), and vice versa: strong lower bounds translate into more efficient algorithms. </em>
</p></blockquote>
<p/><p>
Of course we agree, and we love connections shown in the new papers to problems such as distinguishing a very slightly biased coin from a true one. But we will try to supplement the algorithmic view of circuit lower bounds with a direct look at the underlying logic.</p>
<p>
</p><p/><h2> Logical Structure of Lower Bounds </h2><p/>
<p/><p>
Okay we all know that circuit lower bounds are hard. For all Kabanets’ success and beautiful work—he like the rest of the complexity field—are unable to prove what we believe is true. They cannot in the full circuit model prove anything close to what is believed to be true for at least a half a century: There are explicit Boolean functions that cannot be computed by any linear size circuit.</p>
<p>
We feel that the logical structure of lower bounds statements gives insight into their difficulty. Perhaps this is almost a tautology. Of course the logical structure of any mathematical statement helps us understand its inherent difficulty. But we believe more: That this structure can reveal quite a bit about lower bounds. Let’s take a look at lower bounds and see if this belief holds up.</p>
<p>
In particular let’s compare the two main approaches to proving lower bounds: non-uniform and uniform. Our claim is that they have different logical structure, and that this difference explains why there is such a gap between the two. While lower bounds—non-uniform or uniform—are hard, uniform ones are at least possible now. Non-uniform lower bounds are really very difficult.</p>
<p>
Here is one example. To prove an explicit size lower bound for Boolean circuits—we’ll be content with just a linear one—we must give a particular family of Boolean functions <img alt="{f_{n}(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_%7Bn%7D%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_{n}(x)}"/> (each of <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> inputs) so that:</p>
<ol>
<li>
Given <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> and <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> we can evaluate <img alt="{f_{n}(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_%7Bn%7D%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_{n}(x)}"/> in polynomial time; <p/>
</li><li>
There is no Boolean circuit of size <img alt="{\alpha n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha n}"/> that correctly computes <img alt="{f_{n}(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_%7Bn%7D%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_{n}(x)}"/> on all <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> of length <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>.
</li></ol>
<p>
Here <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> is a constant and <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> is assumed to be large enough. The terrific <a href="http://www.wisdom.weizmann.ac.il/~ranraz/publications/P5nlb.pdf">paper</a> of Kazuo Iwama, Oded Lachish, Hiroki Morizumi, and Ran Raz gives explicit Boolean functions whose size for circuits with the usual <em>not</em> and binary <em>and</em> and <em>or</em> operators exceeds <img alt="{5n-o(n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B5n-o%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{5n-o(n)}"/>. </p>
<p>
</p><p/><h2> An Approach </h2><p/>
<p/><p>
Let’s look at the above example more carefully. Suppose that in place of a single Boolean function on <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> inputs we have a list of them: </p>
<p align="center"><img alt="\displaystyle  f_{n,1}(x),\dots,f_{n,m}(x). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++f_%7Bn%2C1%7D%28x%29%2C%5Cdots%2Cf_%7Bn%2Cm%7D%28x%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  f_{n,1}(x),\dots,f_{n,m}(x). "/></p>
<p>Can we prove the following? </p>
<p align="center"><img alt="\displaystyle  \exists n_{0}\ \forall n &gt; n_{0} \ \exists f_{n,k} \ \forall C \in \mathsf{SIZE}(\alpha n) \ \neg\mathsf{compute}(C,f_{n,k}). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cexists+n_%7B0%7D%5C+%5Cforall+n+%3E+n_%7B0%7D+%5C+%5Cexists+f_%7Bn%2Ck%7D+%5C+%5Cforall+C+%5Cin+%5Cmathsf%7BSIZE%7D%28%5Calpha+n%29+%5C+%5Cneg%5Cmathsf%7Bcompute%7D%28C%2Cf_%7Bn%2Ck%7D%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \exists n_{0}\ \forall n &gt; n_{0} \ \exists f_{n,k} \ \forall C \in \mathsf{SIZE}(\alpha n) \ \neg\mathsf{compute}(C,f_{n,k}). "/></p>
<p>The first thing to note is the effect of letting the number <img alt="{\bf m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbf+m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bf m}"/> of functions vary:</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> If <img alt="{\bf m = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbf+m+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bf m = 1}"/>, this just becomes our original explicit circuit lower bound problem. </p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> If <img alt="{\bf m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbf+m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bf m}"/> is a huge value, however, this becomes the exponential lower bound shown by Claude Shannon—a known quantity. </p>
<p>
In our terms, the latter takes <img alt="{\bf m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbf+m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bf m}"/> equal to <img alt="{2^{2^{n}}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5E%7B2%5E%7Bn%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2^{2^{n}}}"/>, so that given <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> our function list is just the list of all Boolean functions. If all we care about is an <img alt="{\alpha n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha n}"/> lower bound, then the high end of the range can be something like <img alt="{m = 2^{2\alpha n\log(n)} = n^{2\alpha n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm+%3D+2%5E%7B2%5Calpha+n%5Clog%28n%29%7D+%3D+n%5E%7B2%5Calpha+n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m = 2^{2\alpha n\log(n)} = n^{2\alpha n}}"/>. So at the high end we have a simple counting argument for the proof but have traded away explicitness. The question will be about the tradeoffs for <img alt="{\bf m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbf+m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bf m}"/> in-between the extremes.</p>
<p>
</p><p/><h2> An Analogy </h2><p/>
<p/><p>
The above idea that we can model the lower bound methods by controlling the length of the list of the functions is the key to our approach. Perhaps it may help to note an analogy to other famous hard problems of constructing explicit objects. In particular, let’s look at constructing transcendental numbers. Recall these are real numbers that are not algebraic: they are not roots of polynomials with integer coefficients. They include <img alt="{\pi = 3.14159\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi+%3D+3.14159%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\pi = 3.14159\dots}"/> and <img alt="{e = 2.71828\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Be+%3D+2.71828%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{e = 2.71828\dots}"/></p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> The <a href="https://en.wikipedia.org/wiki/Liouville_number">Liouville</a> numbers of Joseph Liouville. 	</p>
<p align="center"><img alt="\displaystyle  x = \sum_{k=1}^\infty \frac{a_k}{b^{k!}}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++x+%3D+%5Csum_%7Bk%3D1%7D%5E%5Cinfty+%5Cfrac%7Ba_k%7D%7Bb%5E%7Bk%21%7D%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  x = \sum_{k=1}^\infty \frac{a_k}{b^{k!}}. "/></p>
<p>These are explicit numbers that were proved by him in 1844 to be transcendental. In terms of our model <img alt="{\bf m=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbf+m%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bf m=1}"/>.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> The great <img alt="{\pi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\pi}"/> and <img alt="{e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Be%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{e}"/> puzzle. This is the observation that of <img alt="{\pi + e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi+%2B+e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\pi + e}"/> or <img alt="{\pi - e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi+-+e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\pi - e}"/>, at least one is a transcendental number. In our terms this gives <img alt="{\bf m=2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbf+m%3D2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bf m=2}"/>.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> The famous theorem of Georg Cantor—read as proving the existence of transcendental numbers since algebraic ones are countable.</p>
<p>
Here the high end of the range is as extreme as can be. Cantor’s `list’ of numbers is uncountable—in our model, <img alt="{\bf m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbf+m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bf m}"/> is the cardinality of the real numbers. Note, the fact that his <img alt="{\bf m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbf+m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bf m}"/> is huge, really huge, may explain why some at the time were unimpressed by this result. They wanted the ‘list’ to be small, actually they wanted <img alt="{\bf m=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbf+m%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bf m=1}"/>. See <a href="https://www.jstor.org/stable/2975129?seq=1#page_scan_tab_contents">this</a> for a discussion of the history of these ideas.</p>
<p>
<img alt="{\bullet}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet}"/> The theorem by Waim Zudilin, in a 2001 <a href="https://iopscience.iop.org/article/10.1070/RM2001v056n04ABEH000427/meta">paper</a>, that at least one of the numbers <img alt="{\zeta(5), \zeta(7), \zeta(9), \zeta(11)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Czeta%285%29%2C+%5Czeta%287%29%2C+%5Czeta%289%29%2C+%5Czeta%2811%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\zeta(5), \zeta(7), \zeta(9), \zeta(11)}"/> must be irrational. It is for “irrational” not “transcendental,” but exemplified <img alt="{\bf m = 4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbf+m+%3D+4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bf m = 4}"/> in a highly nontrivial manner. The technical point that makes this work is interactions among these numbers that cannot be captured just by considering any one of them separately. This has <img alt="{\bf m = 4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbf+m+%3D+4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bf m = 4}"/>.</p>
<p>
</p><p/><h2> Joining Functions </h2><p/>
<p/><p>
The issue is this: Suppose that we have a list of several boolean functions <img alt="{f_{1}(x),\dots,f_{m}(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_%7B1%7D%28x%29%2C%5Cdots%2Cf_%7Bm%7D%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_{1}(x),\dots,f_{m}(x)}"/>. Then we can join them together to form one function <img alt="{g(x,y)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%28x%2Cy%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{g(x,y)}"/> so that 	</p>
<p align="center"><img alt="\displaystyle  g(x,1) = f_{1}(x), \cdots, g(x,m) = f_{m}(x). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++g%28x%2C1%29+%3D+f_%7B1%7D%28x%29%2C+%5Ccdots%2C+g%28x%2Cm%29+%3D+f_%7Bm%7D%28x%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  g(x,1) = f_{1}(x), \cdots, g(x,m) = f_{m}(x). "/></p>
<p>Clearly the function <img alt="{g(x,y)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%28x%2Cy%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{g(x,y)}"/> is easy implies that all of the <img alt="{f_{y}(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_%7By%7D%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_{y}(x)}"/> are easy. This join trick shows that we can encode several boolean functions into one function. Note, we can even make <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y}"/> have only order <img alt="{\log(n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\log(n)}"/> where <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> has <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> bits.</p>
<p>
Thus we can join any collection of functions to make a “universal” one that is at least as hard as the worst of the single functions. More precisely, 	</p>
<p align="center"><img alt="\displaystyle  \mathsf{complexity}(g) \ge \mathsf{complexity}(f_{y}) \text{ for } y=1,\dots,m. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathsf%7Bcomplexity%7D%28g%29+%5Cge+%5Cmathsf%7Bcomplexity%7D%28f_%7By%7D%29+%5Ctext%7B+for+%7D+y%3D1%2C%5Cdots%2Cm.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \mathsf{complexity}(g) \ge \mathsf{complexity}(f_{y}) \text{ for } y=1,\dots,m. "/></p>
<p>Here <img alt="{\mathsf{complexity}(h)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7Bcomplexity%7D%28h%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{complexity}(h)}"/> is the circuit complexity of the boolean function <img alt="{h}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bh%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{h}"/>.</p>
<p>
If <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m}"/> is bigger than <img alt="{2^{O(n)}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5E%7BO%28n%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2^{O(n)}}"/>, that is if <img alt="{m = 2^{\omega(n)}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm+%3D+2%5E%7B%5Comega%28n%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m = 2^{\omega(n)}}"/>, then the joined function has more than linearly many variables. Can we possibly establish nontrivial interactions among so many functions, say <img alt="{{\bf m} = n^{2n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cbf+m%7D+%3D+n%5E%7B2n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{\bf m} = n^{2n}}"/>?</p>
<p>
One can also try to get this effect with fewer or no additional variables by taking the XOR of some subset of functions in the list. If this is done randomly for each input length <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> then one can expect hard functions to show up for many <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>. If this process can then be <em>de-randomized</em>, then this may yield an explicit hard function. We wonder how this idea might meld with Andy Yao’s famous XOR Lemma and conditions to <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.441.2818&amp;rep=rep1&amp;type=pdf">de-randomize</a> it.</p>
<p>
</p><p/><h2> Joining Numbers </h2><p/>
<p/><p>
Ken and I thought about the above simple fact about joins, which seems special to functions. Joining by interleaving the decimal expansions is not an arithmetic operation. However, it appears that there may be a similar result possible for transcendental numbers. </p>
<blockquote><p><b>Lemma 1</b> <em> Suppose that <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\alpha}"/> and <img alt="{\beta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\beta}"/> are real numbers. Then 	</em></p><em>
<p align="center"><img alt="\displaystyle  \alpha + i\beta " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Calpha+%2B+i%5Cbeta+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="\displaystyle  \alpha + i\beta "/></p>
</em><p><em>is a transcendental complex number if at least one of <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\alpha}"/> or <img alt="{\beta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\beta}"/> are transcendental. </em>
</p></blockquote>
<p/><p>
<em>Proof:</em>  Let <img alt="{\gamma = \alpha + i\beta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cgamma+%3D+%5Calpha+%2B+i%5Cbeta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\gamma = \alpha + i\beta}"/> be an algebraic number. Thus there must be a polynomial <img alt="{q(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q(x)}"/> with integer coefficients so that 	</p>
<p align="center"><img alt="\displaystyle  q(\gamma) = q(\alpha + i\beta) = 0. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++q%28%5Cgamma%29+%3D+q%28%5Calpha+%2B+i%5Cbeta%29+%3D+0.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  q(\gamma) = q(\alpha + i\beta) = 0. "/></p>
<p>Then it follows by complex conjugation that 	</p>
<p align="center"><img alt="\displaystyle  q(\alpha - i\beta) = 0. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++q%28%5Calpha+-+i%5Cbeta%29+%3D+0.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  q(\alpha - i\beta) = 0. "/></p>
<p>	 Therefore <img alt="{\alpha + i\beta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha+%2B+i%5Cbeta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha + i\beta}"/> and <img alt="{\alpha -i\beta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha+-i%5Cbeta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha -i\beta}"/> are both algebraic; thus, so is their sum which is <img alt="{2\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2\alpha}"/>. Thus <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> is algebraic. It follows that <img alt="{\beta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\beta}"/> is also algebraic. This shows that <img alt="{\gamma}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cgamma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\gamma}"/> is transcendental. <img alt="\Box" class="latex" src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Box"/></p>
<p>
A question: Can we show that we can do a “join” operation for three or more numbers? That is given numbers <img alt="{x_{1},\dots,x_{m}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_%7B1%7D%2C%5Cdots%2Cx_%7Bm%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x_{1},\dots,x_{m}}"/> can we construct a number <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y}"/> that is transcendental if and only if at least one of <img alt="{x_{i}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_%7Bi%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x_{i}}"/> is transcendental?</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Is the <img alt="{\bf m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbf+m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bf m}"/> model useful? Is it possible for it to succeed where a direct explicit argument (<img alt="{{\bf m} = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cbf+m%7D+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{\bf m} = 1}"/>) does not? Does it need <img alt="{{\bf m} \gg 2^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cbf+m%7D+%5Cgg+2%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{\bf m} \gg 2^n}"/> to rise above technical dependence on the <img alt="{\bf m = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbf+m+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bf m = 1}"/> case via the join construction?</p>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2019/04/valentine-sandan-test-action-small.jpeg"><img alt="" class="aligncenter wp-image-15770" height="158" src="https://rjlipton.files.wordpress.com/2019/04/valentine-sandan-test-action-small.jpeg?w=235&amp;h=158" width="235"/></a>
</td>
</tr>
<tr>
<td class="caption alignright">
<font size="-2">Maybe the barriers just need 3-Dan martial-arts treatment.  <a href="https://www.vancouverwestaikikai.com/programs/intro-beginner.shtml">Source</a>—our congrats.<br/>
</font>
</td>
</tr>
</tbody></table></font></font></div>
    </content>
    <updated>2019-04-18T22:16:11Z</updated>
    <published>2019-04-18T22:16:11Z</published>
    <category term="All Posts"/>
    <category term="Ideas"/>
    <category term="P=NP"/>
    <category term="People"/>
    <category term="circuit complexity"/>
    <category term="circuits"/>
    <category term="lower bounds"/>
    <category term="transcendental numbers"/>
    <category term="Valentine Kabanets"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-04-24T08:20:47Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-27705661.post-4286404438772500234</id>
    <link href="http://processalgebra.blogspot.com/feeds/4286404438772500234/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=27705661&amp;postID=4286404438772500234" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/4286404438772500234" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/4286404438772500234" rel="self" type="application/atom+xml"/>
    <link href="http://processalgebra.blogspot.com/2019/04/the-complexity-of-identifying.html" rel="alternate" type="text/html"/>
    <title>The Complexity of Identifying Characteristic Formulae</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">One of the classic results in concurrency theory is the Hennessy-Milner Theorem. This result states that<br/><ol><li>two bisimilar states in a labelled transition system satisfy exactly the same formulae in a multi-modal logic now called Hennessy-Milner logic, and </li><li>two states in a labelled transition system that satisfy a mild finiteness constraint (called image finiteness)  and enjoy the same properties expressible in Hennessy-Milner logic are bisimilar.</li></ol>See, for instance, Section 1.2 in <a href="http://homepages.inf.ed.ac.uk/cps/chapbisim.pdf">these notes by Colin Stirling</a> for an exposition of that result. A consequence of the Hennessy-Milner Theorem is that whenever two states <i>p </i>and <i>q </i>in a labelled transition system are <i>not</i> bisimilar, one can come up with a formula in Hennessy-Milner logic that <i>p </i>satisfies, but<i> q </i>does not<i>. </i>Moreover, for each state <i>p </i>in a finite, loop-free labelled transition systems, it is possible to construct a formula <i>F(p) </i>in Hennessy-Milner logic that completely characterizes <i>p</i> up to bisimilarity. This means that, for each state <i>q</i>, <i>p</i> is bisimilar to <i>q</i> if, and only if, <i>q</i> satisfies <i>F(p)</i>. The formula<i> F(p) </i>is called a characteristic formula for<i> p </i>up to bisimilarity.<i> </i>One can obtain a similar result for states in finite labelled transition systems by extending Hennessy-Milner logic with greatest fixed points. <i><br/></i><br/><br/>Characteristic formulae have a long history in concurrency theory. However, to be best of my knowledge, the complexity of determining whether a formula is characteristic had not been studied before <a href="https://sites.google.com/view/antonisachilleos">Antonis Achilleos</a> first addressed the problem in <a href="https://arxiv.org/abs/1605.01004">this conference paper</a>. In that paper, Antonis focused on the complexity of the problem of determining whether a formula <i>F</i> is complete, in the sense that, for each formula <i>G</i>, it can derive either <i>G</i> or its negation.<br/><br/>Our recent preprint    <a href="http://icetcs.ru.is/theofomon/CharFormComplexity.pdf"><i>The   Complexity of Identifying Characteristic Formulae</i></a> extends the results originally obtained by Antonis to a variety of modal logics, possibly including least and greatest fixed-point operators. In the paper, we show that completeness, characterization, and validity have the same complexity — with some exceptions for which there are, in general, no complete formulae. So, for most modal logics of interest, the problem is coNP-complete or PSPACE-complete, and becomes EXPTIME-complete for modal logics with fixed points. To prove our upper bounds, we present a nondeterministic procedure with an oracle for validity that combines tableaux and a test for bisimilarity, and determines whether a formula is complete.<br/><br/>I think that there is still a lot of work that can be done in studying this problem, with respect to a variety of other notions of equivalence considered in concurrency theory, so stay tuned for further updates. </div>
    </content>
    <updated>2019-04-18T17:19:00Z</updated>
    <published>2019-04-18T17:19:00Z</published>
    <author>
      <name>Luca Aceto</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/01092671728833265127</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-27705661</id>
      <author>
        <name>Luca Aceto</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/01092671728833265127</uri>
      </author>
      <link href="http://processalgebra.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://processalgebra.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Papers I find interesting---mostly, but not solely, in Process Algebra---, and some fun stuff in Mathematics and Computer Science at large and on general issues related to research, teaching and academic life.</subtitle>
      <title>Process Algebra Diary</title>
      <updated>2019-04-22T08:46:05Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/060</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/060" rel="alternate" type="text/html"/>
    <title>TR19-060 |  Gentle Measurement of Quantum States and Differential Privacy | 

	Scott Aaronson, 

	Guy Rothblum</title>
    <summary>In differential privacy (DP), we want to query a database about $n$ users, in a way that "leaks at most $\varepsilon$ about any individual user," even conditioned on any outcome of the query.  Meanwhile, in gentle measurement, we want to measure $n$ quantum states, in a way that "damages the states by at most $\alpha$," even conditioned on any outcome of the measurement.  In both cases, we can achieve the goal by techniques like deliberately adding noise to the outcome before returning it.  This paper proves a new and general connection between the two subjects. Specifically, we show that on products of $n$ quantum states, any measurement that is $\alpha$-gentle for small $\alpha$ is also $O( \alpha)$-DP, and any product measurement that is $\varepsilon$-DP is also $O(\varepsilon\sqrt{n})$-gentle.

Illustrating the power of this connection, we apply it to the recently studied problem of shadow tomography.  Given an unknown $d$-dimensional quantum state $\rho$, as well as known two-outcome measurements $E_{1},\ldots,E_{m}$, shadow tomography asks us to estimate $\Pr\left[  E_{i}\text{ accepts }\rho\right]  $, for every $i\in\left[ m\right]  $, by measuring few copies of $\rho$. Using our connection theorem, together with a quantum analog of the so-called private multiplicative weights algorithm of Hardt and Rothblum, we give a protocol to solve this problem using $O\left( \left(  \log m\right)  ^{2}\left(  \log d\right)  ^{2}\right)$ copies of $\rho$, compared to Aaronson's previous bound of $\widetilde{O} \left(\left(  \log m\right) ^{4}\left( \log d\right)\right) $.  Our protocol has the advantages of being online (that is, the $E_{i}$'s are processed one at a time), gentle, and conceptually simple.

Other applications of our connection include new lower bounds for shadow tomography from lower bounds on DP, and a result on the safe use of estimation algorithms as subroutines inside larger quantum algorithms.</summary>
    <updated>2019-04-18T12:48:21Z</updated>
    <published>2019-04-18T12:48:21Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-04-24T08:20:41Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-2053726780224405945</id>
    <link href="https://blog.computationalcomplexity.org/feeds/2053726780224405945/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/04/physics-of-everday-life.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/2053726780224405945" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/2053726780224405945" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/04/physics-of-everday-life.html" rel="alternate" type="text/html"/>
    <title>Physics of Everday Life</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Based on <a href="https://www.scottaaronson.com/blog/?p=3654">Scott's review</a>, I read through Stephen Pinker's <a href="https://www.amazon.com/Enlightenment-Now-Science-Humanism-Progress-ebook/dp/B073TJBYTB/ref=as_li_ss_tl?crid=2O1U6VZR84R2Q&amp;keywords=enlightenment+now&amp;qid=1554897483&amp;s=gateway&amp;sprefix=engligh,aps,597&amp;sr=8-1&amp;linkCode=ll1&amp;tag=computation09-20&amp;linkId=8f668f77297b7cd8b57a85dca27802b0&amp;language=en_US">Enlightenment Now</a>. I can't top Scott's exposition of the book, but it is pretty incredible how far humanity has gone when you step back to look at the big picture.<br/>
<br/>
One line intrigued me, one that Pinker credits to a book called <a href="https://www.amazon.com/Big-Picture-Origins-Meaning-Universe/dp/1101984252/ref=as_li_ss_tl?ie=UTF8&amp;linkCode=ll1&amp;tag=computation09-20&amp;linkId=6c644c72e1d0c1f818a5907f9b221ce1&amp;language=en_US">The Big Picture</a> by Sean Carroll<br/>
<blockquote class="tr_bq">
The laws of physics underlying everyday life (that is excluding extreme values of energy and gravitation like black holes, dark matter and the Big Bang) are <i>completely known.</i></blockquote>
Hasn't this statement almost always been true, in the sense that the leading minds would make this claim at many times in history. The ancient Greeks probably believed they understood physics that underlies everyday life. So did physicists after Newton. Life back then not today. My everyday life involves using a GPS device that requires understanding relativistic effects and computer chips that needed other scientific advances.<br/>
<br/>
Is it possible we could do more in everyday life if we knew more physics? I'd certainly use a teleporter in everyday life.<br/>
<br/>
And is the statement even true today? We all use public key cryptography, even to read this blog. It's not completely clear if we understand the physics enough to know how or if large-scale quantum computers capable of breaking those systems can be built.<br/>
<br/>
Everday life is relative.</div>
    </content>
    <updated>2019-04-18T11:40:00Z</updated>
    <published>2019-04-18T11:40:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-04-23T22:51:55Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/059</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/059" rel="alternate" type="text/html"/>
    <title>TR19-059 |  Samplers and extractors for unbounded functions | 

	Rohit Agrawal</title>
    <summary>Blasiok (SODA'18) recently introduced the notion of a subgaussian sampler, defined as an averaging sampler for approximating the mean of functions $f:\{0,1\}^m \to \mathbb{R}$ such that $f(U_m)$ has subgaussian tails, and asked for explicit constructions. In this work, we give the first explicit constructions of subgaussian samplers (and in fact averaging samplers for the broader class of subexponential functions) that match the best-known constructions of averaging samplers for $[0,1]$-bounded functions in the regime of parameters where the approximation error $\varepsilon$ and failure probability $\delta$ are subconstant. Our constructions are established via an extension of the standard notion of randomness extractor (Nisan and Zuckerman, JCSS'96) where the error is measured by an arbitrary divergence rather than total variation distance, and a generalization of Zuckerman's equivalence (Random Struct. Alg.'97) between extractors and samplers. We believe that the framework we develop, and specifically the notion of an extractor for the Kullback-Leibler (KL) divergence, are of independent interest. In particular, KL-extractors are stronger than both standard extractors and subgaussian samplers, but we show that they exist with essentially the same parameters (constructively and non-constructively) as standard extractors.</summary>
    <updated>2019-04-18T00:27:56Z</updated>
    <published>2019-04-18T00:27:56Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-04-24T08:20:41Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4166</id>
    <link href="https://www.scottaaronson.com/blog/?p=4166" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4166#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4166" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Just says in P</title>
    <summary xml:lang="en-US">Recently a Twitter account started called justsaysinmice. The only thing this account does, is to repost breathless news articles about medical research breakthroughs that fail to mention that the effect in question was only observed in mice, and then add the words “IN MICE” to them. Simple concept, but it already seems to be changing […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>Recently a Twitter account started called <a href="https://twitter.com/justsaysinmice">justsaysinmice</a>.  The only thing this account does, is to repost breathless news articles about medical research breakthroughs that fail to mention that the effect in question was only observed in mice, and then add the words “IN MICE” to them.  Simple concept, but it already seems to be changing the conversation about science reporting.</p>



<p>It occurred to me that we could do something analogous for quantum computing.  While my own deep-seated aversion to Twitter prevents me from doing it myself, which of my readers is up for starting an account that just reposts one overhyped QC article after another, while appending the words “A CLASSICAL COMPUTER COULD ALSO DO THIS” to each one?</p></div>
    </content>
    <updated>2019-04-17T19:14:17Z</updated>
    <published>2019-04-17T19:14:17Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Procrastination"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Quantum"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Rage Against Doofosity"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Speaking Truth to Parallelism"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2019-04-19T21:17:59Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=17286</id>
    <link href="https://gilkalai.wordpress.com/2019/04/17/gothenburg-stockholm-lancaster-mitzpe-ramon-and-israeli-election-day-2019/" rel="alternate" type="text/html"/>
    <title>Gothenburg, Stockholm, Lancaster, Mitzpe Ramon, and Israeli Election Day 2019</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Lancaster – Watching the outcomes of the Israeli elections (photo: Andrey Kupavskii) Sweden I just came back from a trip to Sweden and the U.K. I was invited to Gothenburg to be the opponent for a Ph. D. Candidate  Malin … <a href="https://gilkalai.wordpress.com/2019/04/17/gothenburg-stockholm-lancaster-mitzpe-ramon-and-israeli-election-day-2019/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="https://gilkalai.files.wordpress.com/2019/04/dsc5390.jpg"><img alt="" class="alignnone size-medium wp-image-17287" height="200" src="https://gilkalai.files.wordpress.com/2019/04/dsc5390.jpg?w=300&amp;h=200" width="300"/></a> <a href="https://gilkalai.files.wordpress.com/2019/04/hand.png"><img alt="" class="alignnone size-medium wp-image-17288" height="251" src="https://gilkalai.files.wordpress.com/2019/04/hand.png?w=300&amp;h=251" width="300"/></a></p>
<p><span style="color: #ff0000;">Lancaster – Watching the outcomes of the Israeli elections (photo: Andrey Kupavskii)</span></p>
<h3>Sweden</h3>
<p>I just came back from a trip to Sweden and the U.K. I was invited to Gothenburg to be the opponent for a Ph. D. Candidate  Malin Palö Forsström (by now Dr. Malin Palö Forsström),  who wrote her excellent Ph. D. thesis under the supervision of Jeff Steif in Chalmers University. We also used the opportunity for a lovely mini-mini-workshop</p>
<p>From Gothenburg I took the train to Stockholm to spend the weekend with Anders Björner and we talked about some old projects regarding algebraic shifting.  We had dinner with several colleagues including Svante Linusson who is a candidate for the European parliament!</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/04/acg80s.jpeg"><img alt="" class="alignnone size-full wp-image-17296" src="https://gilkalai.files.wordpress.com/2019/04/acg80s.jpeg?w=640"/></a> <a href="https://gilkalai.files.wordpress.com/2019/04/20190407_194045.jpg"><img alt="" class="alignnone size-medium wp-image-17297" height="168" src="https://gilkalai.files.wordpress.com/2019/04/20190407_194045.jpg?w=300&amp;h=168" width="300"/></a></p>
<p><span style="color: #ff0000;">Stockholm: With Anders and Cristins in the late 80s (left, I think this was also when I was an opponent), Svante Linusson ten days ago (right)</span></p>
<h3>The United Kingdom</h3>
<p>The <a href="https://www.lancaster.ac.uk/maths/bmc2019/">British Mathematical Colloquium at Lancaster</a> was a lovely 4-day general meeting, an opportunity to meet some old and new friends (and Internet MO friend <a href="https://mathoverflow.net/users/763/yemon-choi">Yemon Choi</a> in real life), and to learn about various new developments. I am aware of the fact that my list of unfulfilled promises is longer than those of most politicians, but I do hope to come back to some mathematics from this trip to Sweden and to Lancaster.</p>
<h3>Election Day</h3>
<p>Last week’s Tuesday was election day in Israel,  and as much as I like to participate (and to devote a post to election day here on the blog – in <a href="https://gilkalai.wordpress.com/2009/02/10/majority-rules-the-story-of-achnais-oven/">2009</a>, <a href="https://gilkalai.wordpress.com/2013/01/22/election-day/">2012</a>, and <a href="https://gilkalai.wordpress.com/2015/03/17/election-day-2/">2015</a>) I had to miss the election, for the first time since 1985. (I still tried to follow the outcomes in real time.)</p>
<h3>The Negev, Israel</h3>
<p>And we are now spending a three-day vacation and doing some mild hiking in Mitzpe Ramon, in the Negev, the Israeli desert.  The view around here is spectacular. I first fell in love with the sights of the Negev when I spent six months here when I was 19 (in the army). Since then we have been caming here many times over the years, and in 2002 the annual meeting of the Israeli Mathematical Union took place here, in the same hotel.</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/04/img-20190416-wa0036.jpg"><img alt="" class="alignnone size-medium wp-image-17298" height="300" src="https://gilkalai.files.wordpress.com/2019/04/img-20190416-wa0036.jpg?w=169&amp;h=300" width="169"/></a> <a href="https://gilkalai.files.wordpress.com/2019/04/fb_img_1555444073776-e1555444196265.jpg"> <img alt="" class="alignnone size-medium wp-image-17299" height="165" src="https://gilkalai.files.wordpress.com/2019/04/fb_img_1555444073776-e1555444196265.jpg?w=300&amp;h=165" width="300"/></a></p>
<p><span style="color: #ff0000;">Ein Ovdat (left). The 2002 Annual meeting of the IMU (right). A large number of Israeli mathematicians come to a substantial fraction of these annual events.</span></p>
<h3>The stance of the main Israeli parties on quantum computing</h3>
<p>One anecdote about the Israeli election is that both major political parties of Israel, the Likud, led by Benjamin (Bibi) Netanyahu that won 35 seats in the parliament and will probably lead the coalition, and the newly formed “Blue-and-White” party, led by Benny (Benjamin) Gantz that also won 35 seats and will probably lead the opposition, stand behind quantum computing! <img alt="&#x1F642;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f642.png" style="height: 1em;"/></p>
<p><a href="https://gilkalai.files.wordpress.com/2019/03/bw-quantum.png"><img alt="" class="alignnone size-medium wp-image-17121" height="233" src="https://gilkalai.files.wordpress.com/2019/03/bw-quantum.png?w=300&amp;h=233" width="300"/></a><a href="https://gilkalai.files.wordpress.com/2019/04/qcbibi.png"> <img alt="" class="alignnone size-medium wp-image-17302" height="258" src="https://gilkalai.files.wordpress.com/2019/04/qcbibi.png?w=300&amp;h=258" width="300"/></a></p>
<p><span style="color: #ff0000;">Left – A paragraph from “Blue and White’s” charter with a pledge to quantum computing (I thank Noam Lifshitz for telling me about it). Right –  a news item (<a href="https://en.globes.co.il/en/article-government-allocates-nis-300m-for-quantum-computing-1001244244">click for the article</a>) about the quantum computing vision of Netanyahu and the Likud party.</span></p>
<p> </p></div>
    </content>
    <updated>2019-04-17T19:10:12Z</updated>
    <published>2019-04-17T19:10:12Z</published>
    <category term="Combinatorics"/>
    <category term="Probability"/>
    <category term="Updates"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-04-24T08:20:44Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://lucatrevisan.wordpress.com/?p=4227</id>
    <link href="https://lucatrevisan.wordpress.com/2019/04/17/online-optimization-for-complexity-theorists/" rel="alternate" type="text/html"/>
    <title>Online Optimization for Complexity Theorists</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Last year I took some time off to study online convex optimization in some detail. The reason for doing that was similar to the reason why at some point I took time off to study spectral graph theory: it was … <a href="https://lucatrevisan.wordpress.com/2019/04/17/online-optimization-for-complexity-theorists/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
 Last year I took some time off to study online convex optimization in some detail. The reason for doing that was similar to the reason why at some point I took time off to study spectral graph theory: it was coming up in several papers that I wanted to understand, and I felt that I was missing out by not mastering an important tool. In particular, I wanted to understand: </p>
<ol>
<li> The <a href="https://dl.acm.org/citation.cfm?id=1496770.1496899">Barak-Hardt-Kale</a> proof of the <a href="https://ieeexplore.ieee.org/document/492584">Impagliazzo hard-core lemma</a>.
</li><li> The online convex optimization viewpoint on the <a href="https://ieeexplore.ieee.org/document/548459">Frieze-Kannan weak regularity lemma</a>, on the dense model theorem of <a href="https://ieeexplore.ieee.org/document/4690942">(RTTV)</a>, and on the abstract weak regularity lemma of <a href="https://ieeexplore.ieee.org/document/5231258">(TTV)</a> that were described to me by Madhur Tulsiani a few years ago. Furthermore, I wanted to see if Russel Impagliazzo’s subsequent improvements to the dense model theorem and to the abstract weak regularity lemma could be recovered from this point of view.
</li><li> The <a href="https://dl.acm.org/citation.cfm?doid=2906142.2837020">Arora-Kale</a> algorithms for semidefinite programming, including their nearly linear-time algorithm for approximating the Goemans-Williamson relaxation of Max Cut.
</li><li> The meaning of the sentence “multiplicative weights and gradient descent are both special cases of follow-the-regularized-leader, using negative entropy and <img alt="{\ell_2^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell_2%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\ell_2^2}"/> as regularizer, respectively.”
</li><li> The <a href="https://arxiv.org/abs/1506.04838">AllenZhu-Liao-Orecchia</a> online optimization proof of the Batson-Spielman-Srivastava sparsification result.
</li></ol>
<p>
I am happy to say that, except for the “furthermore” part of (2), I achieved my goals. To digest this material a bit better, I came up with the rather ambitious plan of writing a series of posts, in which I would alternate between (i) explaining a notion or theorem from online convex optimization (at a level that someone learning about optimization or machine learning might find useful) and (ii) explaining a complexity-theoretic application. Now that a very intense Spring semester is almost over, I plan to get started on this plan, although it is not clear that I will see it through the end. So stay tuned for the forthcoming first episode, which will be about the good old multiplicative weights algorithm.</p>
<p/></div>
    </content>
    <updated>2019-04-17T15:27:23Z</updated>
    <published>2019-04-17T15:27:23Z</published>
    <category term="theory"/>
    <category term="online optimization"/>
    <author>
      <name>luca</name>
    </author>
    <source>
      <id>https://lucatrevisan.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://lucatrevisan.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://lucatrevisan.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://lucatrevisan.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://lucatrevisan.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>"Marge, I agree with you - in theory. In theory, communism works. In theory." -- Homer Simpson</subtitle>
      <title>in   theory</title>
      <updated>2019-04-24T08:20:22Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://lucatrevisan.wordpress.com/?p=4224</id>
    <link href="https://lucatrevisan.wordpress.com/2019/04/16/the-early-years-of-computing-in-italy/" rel="alternate" type="text/html"/>
    <title>The Early Years of Computing in Italy</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Here are in theory‘s first ever book reviews! The books are Giorgio Garuzzo Quando in Italia si facevano i computer Available for free at Amazon.com and Amazon.it. Giorgio Ausiello The Making of a New Science Available from Springer, as a … <a href="https://lucatrevisan.wordpress.com/2019/04/16/the-early-years-of-computing-in-italy/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Here are <i>in theory</i>‘s first ever book reviews! The books are</p>
<p>Giorgio Garuzzo<br/>
<i>Quando in Italia si facevano i computer</i><br/>
Available for free at <a href="https://www.amazon.com/gp/product/B017PTTUKY">Amazon.com</a> and <a href="https://www.amazon.it/Quando-facevano-computer-Giorgio-Garuzzo-ebook/dp/B017PTTUKY">Amazon.it</a>.</p>
<p>Giorgio Ausiello<br/>
<i>The Making of a New Science</i><br/>
Available from <a href="https://www.springer.com/us/book/9783319626796">Springer</a>, as a DRM-free PDF through your academic library.</p>
<p>Both books talk about the early years of computing in Italy, on the industrial and academic side, respectively. They briefly intersect with the story of Olivetti’s Elea computer.</p>
<p><span id="more-4224"/></p>
<p>Olivetti was a company that was founded in 1908 to make typewriters, and then branched out to other office/business machines and avionics. In the 1930s, Adriano Olivetti, a son of the founder Camillo Olivetti, took over the company. Adriano Olivetti was an unusual figure of entrepreneur deeply interested in arts, humanities and social sciences, with a utopian vision of a company reinvesting its profits in its community. In the 1950s, he led the company to develop the Elea, the first Italian computer. The Elea was made with transistors, and it came out before IBM had built its own first transistor-based computer.</p>
<p>The development of Elea was led by Mario Tchou. Mario Tchou was a Chinese-Italian born and raised in Rome, who studied electrical engineering at the Sapienza University of Rome and then at Brooklyn Polytechnic, eventually becoming an assistant professor at Columbia University. Olivetti persuaded Tchou to move back to Italy and lead the development of Elea, whose first prototype came out in 1957. </p>
<p>As production was ramping up, tragedy struck: Adriano Olivetti died in 1960, and Mario Tchou died in 1961. To shore up the finances of the company, the new CEO Roberto Olivetti brought in a series of new investors, who pushed to spin off the computer business.</p>
<p>At that point, Olivetti was working on another revolutionary machine, the P101, a programmable desktop calculator billed as the “first desktop computer,” which came out in 1964, attracting huge interest. Nonetheless the company spun off its “computer” division into a joint venture with GE, eventually divesting of it completely. Fortunately, they kept control of the P101 project, because those working on it were careful in branding it internally as a “calculator” (not part of the of deal with GE) rather than a “computer.”</p>
<p>These events are narrated, with a fascinating insider view, in Garuzzo’s book.</p>
<p>Giorgio Ausiello is one of the founding fathers of academic computer science in Italy. His book is a professional memoir that starts in the 1960s, at the time in which he started working on his undergraduate thesis at the Istituto Nazionale per le Applicazioni del Calcolo (INAC, later renamed IAC) at the National Research Council in Rome. At that point INAC had one of Italy’s few computers, a machine bought in 1954 from the Ferranti company in Manchester (when it was installed, it was Italy’s <i>second</i> computer).</p>
<p>As narrated in a <a href="https://lucatrevisan.wordpress.com/2017/10/23/corrado-bohm/">previous post</a>, Mauro Picone, the mathematician who was leading INAC, brought Corrado Bohm to Rome to work on this computer, and Ausiello started to work with Bohm at the time in which he was just starting to think about models of computation and lambda-calculus.</p>
<p>Later, Ausiello visited Berkeley in the 1968-69 academic year, when Manuel Blum and Dick Karp had just joined the faculty. Ausiello took part in the first STOC, which was held in Marina del Rey in May 1969, and, later that month, he witnessed the occupation of <a href="https://en.wikipedia.org/wiki/People%27s_Park_(Berkeley)">People’s Park</a> in Berkeley.</p>
<p>The Fall of 1969 marks the start of the first Italian undergraduate programs in Computer Science, in just <del>four</del> three universities:  Bari, <del datetime="2019-04-17T11:04:18-07:00">Milan,</del> Pisa and Torino. Back in Italy from Berkeley, Ausiello continued to work at the National Research Council in Rome.</p>
<p>The book continues with a behind-the-scene narration of the events that led to the founding of the EATCS professional society, the ICALP conference and the TCS journal. There is also another trip to Berkeley in the 1980s, featuring Silvio Micali and Vijay Vazirani working on their matching algorithm, and Shafi Goldwasser just arriving in Berkeley.</p>
<p>Methodically documented and very detail-oriented, the book is a fascinating read, although it leaves you sometimes wanting to hear more about the personalities and the stories of the people involved and less about the attendance lists of certain meetings.</p>
<p>Even when it comes to the dryer details, however, I am happy that the books documents them and makes them available to future generations that will not have any living memory of the 1960s and 1970s.</p>
<p>I should also mention that Alon Rosen has recently interviewed <a href="https://www.youtube.com/watch?v=vKCE7QnsFcw&amp;t=67s">Christos Papadimitriou</a> and <a href="https://www.youtube.com/watch?v=-GQnK6ys6C0&amp;t=20s">Avi Wigderson</a> and those (<i>long</i>) interviews are full of good stories. Finally, the Simons Foundation site has an <a href="https://www.simonsfoundation.org/2013/02/14/laszlo-lovasz/">interview of Laszlo Lovasz</a> in conversation with Avi Wigderson which I very highly recommend everybody to watch.</p></div>
    </content>
    <updated>2019-04-17T00:52:21Z</updated>
    <published>2019-04-17T00:52:21Z</published>
    <category term="Berkeley"/>
    <category term="history"/>
    <category term="Italy"/>
    <category term="theory"/>
    <category term="Elea"/>
    <category term="Giorgio Ausiello"/>
    <category term="Giorgio Garuzzo"/>
    <category term="Mario Tchou"/>
    <category term="Olivetti"/>
    <category term="P101"/>
    <author>
      <name>luca</name>
    </author>
    <source>
      <id>https://lucatrevisan.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://lucatrevisan.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://lucatrevisan.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://lucatrevisan.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://lucatrevisan.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>"Marge, I agree with you - in theory. In theory, communism works. In theory." -- Homer Simpson</subtitle>
      <title>in   theory</title>
      <updated>2019-04-24T08:20:22Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/058</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/058" rel="alternate" type="text/html"/>
    <title>TR19-058 |  Extractors for small zero-fixing sources | 

	Pavel Pudlak, 

	Vojtech Rodl</title>
    <summary>A random variable $X$ is an $(n,k)$-zero-fixing source if for some subset $V\subseteq[n]$, $X$ is the uniform distribution on the strings $\{0,1\}^n$ that are zero on every coordinate outside of $V$. An $\epsilon$-extractor for $(n,k)$-zero-fixing sources is a mapping $F:\{0,1\}^n\to\{0,1\}^m$, for some $m$, such that $F(X)$ is $\epsilon$-close in statistical distance to the uniform distribution on $\{0,1\}^m$ for every $(n,k)$-zero-fixing source $X$. Zero-fixing sources were introduced by Cohen and Shinkar in~2015 in connection with the previously studied extractors for bit-fixing sources. They constructed, for every $\mu&gt;0$, an efficiently computable extractor that extracts a positive fraction of entropy, i.e., $\Omega(k)$ bits, from $(n,k)$-zero-fixing sources where $k\geq(\log\log n)^{2+\mu}$. 

In this paper we present two different constructions of extractors for zero-fixing sources that are able to extract a positive fraction of entropy for $k$ essentially smaller than $\log\log n$. The first extractor works for $k\geq C\log\log\log n$, for some constant $C$. The second extractor extracts a positive fraction of entropy for $k\geq \log^{(i)}n$ for any fixed $i\in \N$, where $\log^{(i)}$ denotes $i$-times iterated logarithm. The fraction of extracted entropy decreases with $i$. The first extractor is a function computable in polynomial time in~$n$ (for $\epsilon=o(1)$, but not too small); the second one is computable in polynomial time when $k\leq\alpha\log\log n/\log\log\log n$, where $\alpha$ is a positive constant.</summary>
    <updated>2019-04-16T15:10:03Z</updated>
    <published>2019-04-16T15:10:03Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-04-24T08:20:41Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2019/04/16/tensors-algebra-computation-applications/</id>
    <link href="https://cstheory-events.org/2019/04/16/tensors-algebra-computation-applications/" rel="alternate" type="text/html"/>
    <title>Tensors: Algebra-Computation-Applications</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">June 3-14, 2019 U. Colorado Boulder and Colorado State U https://thetensor.space/workshops/2019/02/13/TACA-2019.html The Department of Mathematics at Colorado State University and the Department of Computer Science at the University of Colorado, Boulder invite interested participants to attend a workshop and conference on Tensors: Algebra, Computation, and Applications (TACA). The central theme of tensors is meant to … <a class="more-link" href="https://cstheory-events.org/2019/04/16/tensors-algebra-computation-applications/">Continue reading <span class="screen-reader-text">Tensors: Algebra-Computation-Applications</span></a></div>
    </summary>
    <updated>2019-04-16T15:01:44Z</updated>
    <published>2019-04-16T15:01:44Z</published>
    <category term="workshop"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2019-04-24T08:21:28Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/04/15/linkage</id>
    <link href="https://11011110.github.io/blog/2019/04/15/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>“You know how the \hat command in LaTeΧ puts a caret above a letter? … Well I was thinking it would be funny if someone made a package that made the \hat command put a picture of an actual hat on the symbol instead?” And then Matthew Scroggs and Adam Townsend went ahead and did it ().</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><ul>
  <li>
    <p><a href="https://aperiodical.com/2019/03/realhats-writing-a-latex-package/">“You know how the \hat command in LaTeΧ puts a caret above a letter? … Well I was thinking it would be funny if someone made a package that made the \hat command put a picture of an actual hat on the symbol instead?”</a>
And then Matthew Scroggs and Adam Townsend went ahead and <a href="https://ctan.org/pkg/realhats">did it</a> (<a href="https://mathstodon.xyz/@11011110/101849504150959463"/>).</p>
  </li>
  <li>
    <p><a href="https://syntopia.github.io/Polytopia/polytopes.html">Generating 4d polyhedra from their symmetries</a> (<a href="https://mathstodon.xyz/@11011110/101860652773207990"/>, <a href="https://web.archive.org/web/20190306075446/https://plus.google.com/+RoiceNelson/posts/13EEovjAjh3">via</a>), by Mikael Hvidtfeldt Christensen.</p>
  </li>
  <li>
    <p><a href="https://windowsontheory.org/2019/04/03/focs-2019-real-website-and-submission-server/">Windows on Theory</a> and <a href="https://www.scottaaronson.com/blog/?p=4154">Scott Aaronson</a> both warn about a fake web site for <a href="http://focs2019.cs.jhu.edu/">FOCS 2019</a>, whose submission deadline just passed (<a href="https://mathstodon.xyz/@11011110/101864693573223236"/>).</p>
  </li>
  <li>
    <p><a href="http://service.ifam.uni-hannover.de/~geometriewerkstatt/gallery/index.html">GeometrieWerkstatt Gallery</a> (<a href="https://mathstodon.xyz/@11011110/101872198999374479"/>). A collection of weirdly-shaped mathematical surfaces, mostly of constant mean curvature.</p>
  </li>
  <li>
    <p><a href="http://focs2019.cs.jhu.edu/awards/">Sandi Irani wins IEEE TCMF Distinguished Service Award</a> (<a href="https://mathstodon.xyz/@11011110/101877216457233962"/>). The award recognizes her work chairing the <a href="https://www.ics.uci.edu/~irani/safetoc.html">ad hoc committee to combat harassment and discrimination in the theory of computing community</a>, and then getting many theory conferences to follow its recommendations.</p>
  </li>
  <li>
    <p><a href="http://web.colby.edu/thegeometricviewpoint/2014/04/25/periodic-billiard-paths/">Periodic billiard paths</a> (<a href="https://mathstodon.xyz/@11011110/101883476235740072"/>). If the boundary of a given polygon is made of mirrors, these are paths that a laser beam could take that would eventually reflect back to the starting point and angle and then repeat infinitely. It remains a heavily-studied open question whether such paths exist in every triangle. This blog post from 2014 provides a proof that they do exist in polygons whose vertex angles are all rational multiples of .</p>
  </li>
  <li>
    <p><a href="https://retractionwatch.com/2019/04/08/with-a-badly-handled-tweet-plos-angers-scientists-after-a-blog-disappears/">PLOS disappears one (or maybe more) of its hosted blogs</a> (<a href="https://mathstodon.xyz/@11011110/101894568161561631"/>) without any warning to the blog author, without any attempt at keeping old blog links still working, and with only a belated apology.</p>
  </li>
  <li>
    <p><a href="https://slate.com/news-and-politics/2019/03/scotus-gerrymandering-case-mathematicians-brief-elena-kagan.html">The Supreme Court’s math problem</a> (<a href="https://mathstodon.xyz/@11011110/101900050555580515"/>, <a href="https://www.metafilter.com/180163/The-Supreme-Courts-Math-Problem">via</a>). Jordan Ellenberg explains why, in testing for gerrymandering, asking about deviation from proportional representation is the wrong question. Democratic systems naturally concentrate power to the majority rather than being proportional. The right question is whether that concentration is at the natural level, or is artificially accelerated in one direction or another.</p>
  </li>
  <li>
    <p><a href="https://blog.archive.org/2019/04/10/official-eu-agencies-falsely-report-more-than-550-archive-org-urls-as-terrorist-content/">EU falsely calls Internet Archive’s major collection pages, scholarly articles, and copies of US government publications “terrorism” and demands they be taken down from the internet</a> (<a href="https://mathstodon.xyz/@11011110/101908397856087187"/>, <a href="https://boingboing.net/2019/04/11/one-hour-service.html">see also</a>). The EU is about to vote to require terrorism takedowns to happen within an hour, and these requests are coming on European times when all Internet Archive employees (in California) are asleep, making manual review of these bad takedowns difficult.</p>
  </li>
  <li>
    <p><a href="https://www.siam.org/Conferences/CM/Main/apocs20">SIAM-ACM Conference on Algorithmic Principles of Computer Systems, APOCS</a> (<a href="https://mathstodon.xyz/@11011110/101909431804808574"/>). This is a new conference to be held with SODA, next January in Salt Lake City, covering “all areas of algorithms and architectures that offer insight into the performance and design of computer systems”. Submission titles and abstracts are due August 9 (with full papers due a week later) so if this is an area you’re interested in there’s still plenty of time to come up with something to submit.</p>
  </li>
  <li>
    <p><a href="https://blog.computationalcomplexity.org/2019/04/elwyn-berlekamp-died-april-9-2019.html">Sad news from Berkeley</a>: <a href="https://en.wikipedia.org/wiki/Elwyn_Berlekamp">Elwyn Berlekamp</a> has died (<a href="https://mathstodon.xyz/@11011110/101921251002340100"/>, <a href="https://aperiodical.com/2019/04/elwyn-berlekamp-has-left-us/">see also</a>). Berlekamp made significant contributions to combinatorial game theory (motivated, as I understand it, by the mathematical study of Go endgames), coding theory, and algorithms for polynomials.</p>
  </li>
  <li>
    <p><a href="https://www.berlintransitmap.de/">An unofficially-proposed new Berlin transit map replaces stylized axis-parallel and diagonal line segments with smooth curves</a> (<a href="https://mathstodon.xyz/@11011110"/>, <a href="https://www.metafilter.com/180431/Berlin-Transit-Map-now-with-pleasing-Curves">via</a>). The old design was seen as “out of style”, “too robotized”, and too difficult to follow routes. There’s still a strong preference for axis-parallel and diagonal lines in the new map, but the connections between them have been smoothed out.</p>
  </li>
</ul></div>
    </content>
    <updated>2019-04-15T17:43:00Z</updated>
    <published>2019-04-15T17:43:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-04-23T23:43:50Z</updated>
    </source>
  </entry>
</feed>
