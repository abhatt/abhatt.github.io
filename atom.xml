<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2019-08-09T16:22:16Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=17820</id>
    <link href="https://gilkalai.wordpress.com/2019/08/09/two-important-quantum-announcements/" rel="alternate" type="text/html"/>
    <title>Two Important Quantum Announcements!</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">I am very happy to announce two quantum events. First, I would like to announce a course “Computation, quantization, symplectic geometry, and information” in the first 2019/2020 semester  at the Hebrew University of Jerusalem (HUJI). The course will by on … <a href="https://gilkalai.wordpress.com/2019/08/09/two-important-quantum-announcements/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I am very happy to announce two quantum events. First, I would like to announce a course “Computation, quantization, symplectic geometry, and information” in the first 2019/2020 semester  at the Hebrew University of Jerusalem (HUJI). The course will by on Sundays 14:00-16:00. Second, I would also like to announce The 4th Advanced School in Computer Science and Engineering on <a href="http://ias.huji.ac.il/SchoolCSE4">The Mathematics of Quantum Computation </a> on December 15 – December 19, 2019, at IIAS HUJI.</p>
<h2><a href="https://gilkalai.files.wordpress.com/2019/08/ghen.png"><img alt="" class="alignnone size-medium wp-image-17833" height="190" src="https://gilkalai.files.wordpress.com/2019/08/ghen.png?w=300&amp;h=190" width="300"/></a></h2>
<p><span style="color: #ff0000;">Emmy Noether (left) Grete Hermann (right)</span></p>
<h2>A quantum “Kazhdan’s seminar” at HUJI: Computation, quantization, symplectic geometry, and information.</h2>
<p>“In the fall of 2019 Dorit Aharonov, Gil Kalai, Guy Kindler and Leonid Polterovich intend to run a new one semester course (as a Kazhdan seminar) attempting to connect questions about noise and complexity in quantum computation, with ideas and methods about “classical-quantum correspondence”.that are well studied in symplectic geometry. The course will be highly research-oriented, and will attempt to teach the basics in both areas, and define and clarify the interesting research questions related to the connections between these areas, with the hope that this will lead to interesting insights.  The course is oriented to grad students (and faculty), with reasonable background in mathematics, and with interest in the connections between mathematical and computational aspects of quantum mechanics. (See below for a full description.)”</p>
<p>The course will by on Sundays 14:00-16:00 in Ross building.</p>
<p>See also the post  <a href="https://gilkalai.wordpress.com/2013/01/01/symplectic-geometry-quantization-and-quantum-noise/" rel="bookmark">Symplectic Geometry, Quantization, and Quantum Noise</a> from January 2013. (The seminar was initially planned to 2014 but some bumps in the road delayed it to 2019.)</p>
<h2>A winter school at IIAS: The Mathematics of Quantum Computation</h2>
<p><a href="http://ias.huji.ac.il/SchoolCSE4">The Mathematics of Quantum Computation</a><br/>
The 4th Advanced School in Computer Science and Engineering<br/>
Event date: December 15 – December 19, 2019</p>
<p>“We will be organizing a math-oriented quantum computation school in the IIAS at the Hebrew university. No prior knowledge on quantum will be assumed.  The school will introduce TCS and math students and faculty, who are interested in the more mathematical side of the area, to the beautiful and fascinating mathematical open questions in quantum computation, starting from scratch. We hope to reach a point where participants gain initial tools and basic perspective to start working in this area. (See below for a full description.)</p>
<p>Organizers: Dorit Aharonov, Zvika Brakerski, Or Sattath, Amnon Ta-Shma,</p>
<p dir="LTR"><strong>Main (confirmed) Speakers: </strong>Sergey Bravyi, Matthias Christandl, Sandy Irani, Avishay Tal, Thomas Vidick, (1-2 additional speakers may be added later).</p>
<p dir="LTR"><strong>Additional (confirmed) lectures will be given by: </strong>Dorit Aharonov,  Zvika Brakerski,  and/ Or Sattath. (1-2 additional speakers may be added later).”</p>
<p dir="LTR">The Isreali Institute of Advanced Study hosted already a 2014 <a href="http://www.as.huji.ac.il/schools/phys31">school about quantum information</a> as part of its legendary physics series of schools, and also hosted <a href="https://gilkalai.wordpress.com/2013/04/12/qstart/">QSTART</a> in 2013.</p>
<h2>More details</h2>
<p><span id="more-17820"/></p>
<h3><strong><span style="color: #ff0000;">Kazhdan’s seminar: Computation, quantization, symplectic geometry, and information.</span></strong></h3>
<p>In the fall of 2019 Aharonov, Kalai, Kindler and Polterovich intend to run a new<br/>
one semester course (as a Kazhdan seminar) attempting to connect questions about noise and complexity in quantum computation, with ideas and methods about “classical-quantum correspondence”.that are well studied in symplectic geometry. The course will be<br/>
highly research-oriented, and will attempt to teach the basics in both areas, and define and clarify the interesting research questions related to the connections between these areas, with the hope that this will lead to interesting insights.</p>
<p>The course is oriented to grad students (and faculty), with reasonable background in mathematics, and with interest in the connections between mathematical and computational aspects of quantum mechanics. Students who attend it will be awarded two N”Z after passing an exam. The goal of the course is to initiate and lead to new connections between the seemingly unrelated areas of quantum computation and symplectic geometry.</p>
<p>The topics will include:</p>
<p>– Introduction to quantum computation, quantum universality, quantum algorithms<br/>
and quantum computational complexity classes such as BQP and Quantum NP (QMA)</p>
<p>– quantum measurement and quantum noise explained using the standard quantum computational model.</p>
<p>– questions about quantum error correction and quantum noise – fault tolerance,<br/>
quantum error correcting codes, and the breakdown of robustness when the locality of<br/>
the noise does not hold.</p>
<p>– quantum measurement/quantum information (noise and speed limit) having classical counterparts, studied from the symplectic geometry perspective.</p>
<p>– Konsevich theorem and quantization,</p>
<p>– towards a the semi classical approximation of quantum computers.</p>
<p>Examples of questions we would like to initiate research on are:</p>
<p>1) what would be a semi classical model of quantum computation, and what would be<br/>
its computational power?</p>
<p>2) what is a good notion of complexity in a symplextic geometry computational model?</p>
<p>3) What can we learn from basic symplectic geometry results (such as non squeezing)<br/>
about the limitations on quantum computation in the semi classical limit?</p>
<p>4) Can noise in quantum computation be related in any way with the semi classical limit<br/>
of quantum computing systems?</p>
<p>5) can we learn anything about the possible noise models in quantum computers,<br/>
using our knowledge from symplectic geometry?</p>
<p>Hope to see you in the course!</p>
<h3><span style="color: #ff0000;"><strong>The Mathematics of Quantum Computation -The 4th Advanced School in Computer Science and Engineering</strong></span></h3>
<p>On 15-19 December 2019, we will be organizing a math-oriented quantum computation school in the IIAS at the Hebrew university. No prior knowledge on quantum will be assumed.  The school will introduce TCS and math students and faculty, who are interested in the more mathematical side of the area, to the beautiful and fascinating mathematical open questions in quantum computation, starting from scratch. We hope to reach a point where participants gain initial tools and basic perspective to start working in this area.</p>
<p>To achieve this, we will have several mini-courses, each of two or three hours, about central topics in the area.   These will include quantum algorithms, quantum error correction, quantum supremacy, delegation and verification, interactive proofs, cryptography, and Hamiltonian complexity. We will emphasize concepts, open questions, and links to mathematics. We will have daily TA sessions with hands-on exercises, to allow for a serious process of learning.</p>
<p>There will be two rounds of registration. The first deadline is 23rd of August. If there is room, there will be another deadline sometime in October; please follow <a href="http://ias.huji.ac.il/SchoolCSE4">this page</a> for further announcements.</p>
<p>Hope to see you this coming December!</p></div>
    </content>
    <updated>2019-08-09T08:58:55Z</updated>
    <published>2019-08-09T08:58:55Z</published>
    <category term="Computer Science and Optimization"/>
    <category term="Conferences"/>
    <category term="Quantum"/>
    <category term="Teaching"/>
    <category term="Quantization"/>
    <category term="Quantum computers"/>
    <category term="Quantum mechanics"/>
    <category term="Symplectic geometry"/>
    <category term="Theory of Computing"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-08-09T16:20:38Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/08/08/complexity-postdoctoral-fellowship-at-santa-fe-institute-apply-by-october-27-2019/</id>
    <link href="https://cstheory-jobs.org/2019/08/08/complexity-postdoctoral-fellowship-at-santa-fe-institute-apply-by-october-27-2019/" rel="alternate" type="text/html"/>
    <title>Complexity Postdoctoral Fellowship at Santa Fe Institute (apply by October 27, 2019)</title>
    <summary>The SFI Complexity Postdoctoral Fellowships offer early-career scholars the opportunity to join a collaborative research community that nurtures creative, transdisciplinary thought in pursuit of key insights about the complex systems that matter most for science &amp; society. SFI offers a competitive salary, discretionary research/travel funds, paid family leave, &amp; professional development. Website: https://santafe.edu/sfifellowship Email: sfifellowship@santafe.edu</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The SFI Complexity Postdoctoral Fellowships offer early-career scholars the opportunity to join a collaborative research community that nurtures creative, transdisciplinary thought in pursuit of key insights about the complex systems that matter most for science &amp; society. SFI offers a competitive salary, discretionary research/travel funds, paid family leave, &amp; professional development.</p>
<p>Website: <a href="https://santafe.edu/sfifellowship">https://santafe.edu/sfifellowship</a><br/>
Email: sfifellowship@santafe.edu</p></div>
    </content>
    <updated>2019-08-08T19:38:52Z</updated>
    <published>2019-08-08T19:38:52Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-08-09T16:20:52Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/08/08/faculty-at-chennai-mathematical-institute-chennai-india-apply-by-september-30-2019/</id>
    <link href="https://cstheory-jobs.org/2019/08/08/faculty-at-chennai-mathematical-institute-chennai-india-apply-by-september-30-2019/" rel="alternate" type="text/html"/>
    <title>Faculty at Chennai Mathematical Institute, Chennai, India. (apply by September 30, 2019)</title>
    <summary>We are looking for faculty in the areas of Optimization, Algorithms, Machine learning, Data Sciences, Cryptography, Quantum computing/ information, Complexity theory, Formal Verification, Logic and Automata. Website: http://www.cmi.ac.in Email: registrar@cmi.ac.in</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>We are looking for faculty in the areas of Optimization, Algorithms, Machine learning, Data Sciences, Cryptography, Quantum computing/ information, Complexity theory, Formal Verification, Logic and Automata.</p>
<p>Website: <a href="http://www.cmi.ac.in">http://www.cmi.ac.in</a><br/>
Email: registrar@cmi.ac.in</p></div>
    </content>
    <updated>2019-08-08T03:48:33Z</updated>
    <published>2019-08-08T03:48:33Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-08-09T16:20:52Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-337501791513204418</id>
    <link href="https://blog.computationalcomplexity.org/feeds/337501791513204418/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/08/obstacles-to-improving-classical.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/337501791513204418" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/337501791513204418" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/08/obstacles-to-improving-classical.html" rel="alternate" type="text/html"/>
    <title>Obstacles to improving Classical Factoring Algorithms</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">In Samuel Wagstaff's excellent book The Joy of Factoring (see <a href="https://mathcs.clarku.edu/~fgreen/SIGACTReviews/bookrev/47-2.pdf">here</a> for a review) there is a discussion towards the end about why factoring algorithms have not made much progress recently. I<br/>
paraphrase it:<br/>
<br/>
<br/>
--------------------------------------------------------<br/>
<br/>
The time complexities of the fastest known algorithms can be expressed as a formula of the following form (where N is the number to be factored):<br/>
<br/>
(*)                      exp(c(ln N)^t (ln(ln N))^{1-t})<br/>
<br/>
for some constants c and for 0 &lt; t &lt; 1.  For the Quadratic Sieve (QS) and Elliptic Curve Method (ECM) t=1/2. For the Number Field Sieve (NFS) t=1/3. The reason for this shape for the time complexity is the requirement of finding one or more smooth numbers (numbers that have only small primes as factors).<br/>
<br/>
----------------------------------------------------------<br/>
<br/>
This got me thinking: Okay, there may not be a drastic improvement anytime soon but what about just improving t? Is there a mathematical reason<br/>
why an algorithm with (say) t=1/4 has not been discovered? In an earlier era I would have had to write a letter to Dr. Wagstaff to ask him. Buy an envelope, buy a  stamp, find his address, the whole nine yards (my younger readers should ask their grandparents what envelopes and stamps were). In the current era I emailed him. And got a response.<br/>
<br/>
<br/>
Samuel Wagstaff:<br/>
<br/>
The fastest known factoring algorithms find smooth numbers subject to parameter choice(s).  In all these algorithms, one parameter choice is the smoothness bound B:  a number is smooth if all its prime factors are &lt; B. The NFS has the degree of a polynomial as an additional parameter.<br/>
<br/>
One analyzes the complexity of these algorithms by estimating the total work required (to find enough smooth numbers) for an arbitrary parameter choice using Dickman's function to predict the density of smooth numbers.  Then one uses calculus to find the parameter choice(s) that minimize the total work function.  Calculus also yields the optimal values for the parameter(s).<br/>
<br/>
If you have k parameters to choose, you will get the time complexity (*) with t = 1/(1+k).  If you have no parameters (k = 0),you get (*) with t = 1, basically exponential time N^c.  With one parameter to optimize, as in CFRAC  (continued fractions algorithm) and QS, you get t = 1/2.  NFS has two parameters, so t = 1/3. ECM also has t = 1/2 because it uses only one parameter, the smoothness bound B. If you want to get t = 1/4, you have to find a third parameter to optimize.  No one has found one yet. That is the answer to your question.<br/>
<br/>
Note that some choices made in some factoring algorithms don't count as parameters.  For example, the number of polynomials used in the multiple-polynomial quadratic sieve, and the upper bound on large primes kept, don't affect t.  They affect the running time only in making c smaller.  So you have to find a third parameter that matters in order to get (*) with t = 1/4.  Or find three completely different new parameters.<br/>
<br/>
<br/></div>
    </content>
    <updated>2019-08-07T19:27:00Z</updated>
    <published>2019-08-07T19:27:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-08-09T12:27:36Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/08/07/report-from-wads</id>
    <link href="https://11011110.github.io/blog/2019/08/07/report-from-wads.html" rel="alternate" type="text/html"/>
    <title>Report from WADS</title>
    <summary>I’m in Edmonton, Canada for WADS, which just finished, and CCCG, which is just about to begin.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I’m in Edmonton, Canada for <a href="http://wads.org/">WADS</a>, which just finished, and <a href="http://cccg.ca/">CCCG</a>, which is just about to begin.</p>

<p>The three invited talks at WADS were by Rasmus Pagh, Bob Tarjan, and me. Pagh spoke on methods for representing sets of elements by concise sketches so that the size of intersections or unions of the sets could be rapidly and accurately estimated. A famous method for this is <a href="https://en.wikipedia.org/wiki/MinHash">MinHash</a>, in which one represents a set by the  elements with the smallest values of some hash function; the size of the overlap in representations is then an accurate estimator for the <a href="https://en.wikipedia.org/wiki/Jaccard_index">Jaccard similarity</a> of pairs of sets. New to me were -bit variations of MinHash, in which you can get almost as accurate a representation in much less space by mapping each element of the MinHash set to  by another hash function. This works well when the Jaccard similarity is bounded away from both  and , and Pagh spoke about some recent research he and others had done on finding even more accurate methods when it is near  or near .</p>

<p>Tarjan spoke about <a href="https://arxiv.org/abs/1812.06177">parallel algorithms for connected components in graphs</a>, an old area but one in which apparently there have been frequent published mistakes. He presented a modular analysis of the algorithms in this area according to some basic operations they perform (hooking together roots of trees on components, propagating that root information downwards through the trees, flattening the trees to make the information propagate more quickly, and the like) and showed that simple combinations of these operations lead to new, simple, efficient and more importantly provably-correct algorithms.</p>

<p>My talk, “Graphs in Nature”, was about finding graph-theoretic characterizations of surface-embedded graphs arising in natural processes, and using those characterizations to find algorithms to reconstruct synthetic geometric structures of the same type from their graphs. I also gave roughly the same talk a month earlier, at the Symposium on Geometry Processing in Milan. <a href="https://www.ics.uci.edu/~eppstein/pubs/Epp-WADS-19.pdf">I’ve put my talk slides online</a> in case anyone else is interested.</p>

<p>The best paper award went to Hüseyin Acan, Sankardeep Chakraborty, Seungbum Jo and Srinivasa Rao Satti for their paper “<a href="https://arxiv.org/abs/1902.09228">Succinct Data Structures for Families of Interval Graphs</a>”. I can’t tell you much about the talk because, unfortunately, I missed it. I didn’t know it was the best paper until the business meeting that evening, so I went to the other parallel session instead.</p>

<p>I think the contributed talk from Tuesday that most stood out to me was Bryce Sandlund’s, on offline dynamic graph algorithms. This is a type of problem <a href="https://doi.org/10.1006/jagm.1994.1033">I worked on long ago for minimum spanning trees</a> in which you get as input a whole sequence of edge insertions and deletions in a graph, and must produce as output the sequence of changes to the solution to whatever you’re trying to solve. <a href="http://doi.org/10.1007/978-3-030-24766-9_40">Bryce’s new paper with Peng and Sleator</a> solves similar problems for higher-order graph connectivity. The main idea is to hierarchically decompose the update sequence into intervals, and then represent the non-dynamic part of the graph within each interval by a smaller equivalent replacement graph whose size is proportional to the interval length. At the end of his talk, Bryce hinted that he could also solve incremental problems (where the updates are given one at a time rather than all in advance, but are only insertions) using similar methods in a forthcoming paper.</p>

<p>I was inspired by Caleb Levy’s talk on <a href="https://en.wikipedia.org/wiki/Splay_tree">splay trees</a> (in which he showed that <a href="https://arxiv.org/abs/1907.06309">inserting elements in either the preorder or postorder of another binary search tree takes linear time</a>) to ask the following question: we know either by time-reversing the tree rotation operations or from the <a href="https://en.wikipedia.org/wiki/Geometry_of_binary_search_trees">geometric model of dynamic search trees</a> that any given access sequence should have the same optimal cost as its reverse. So from the <a href="https://en.wikipedia.org/wiki/Optimal_binary_search_tree">dynamic optimality conjecture</a> it should also be true that (up to constant factors) splay trees have the same performance on the reverse of any access sequence as they do on the unreversed sequence. Can this be proven?</p>

<p>From the business meeting, we learned that attendance and paper submissions were down by around 15% from the previous WADS. The acceptance rate is roughly the same, just under 50%. I suspect the smaller size is because the location is not as appealing, but it turns out to be a perfectly pleasant place to have a conference: the weather in Edmonton is pleasant this time of year (except for the thunderstorm), and there are abundant restaurants, good coffee shops, and lodging within walking distance of the conference center. WADS alternates with SWAT, which next year will be in the Faroe Islands. And then WADS 2021 (and CCCG 2021) will be in Halifax, Nova Scotia, which is both more touristy than Edmonton and easier to reach from the east coast and Europe. So I suspect the numbers will improve again.</p>

<p>WADS is moving towards a more democratically elected steering committee formed from some combination of past PC chairs and at-large elections. They have already started implementing the <a href="https://www.ics.uci.edu/~irani/safetoc.html">SafeTOC recommendations</a> for combatting harassment and discrimination in theory conferences. And in a show of hands at the business meeting, the attendees were strongly in favor of moving towards double blind peer review for submissions. The conference is not really open access, though (its proceedings are published by Springer LNCS with special issues in Springer’s <em>Algorithmica</em> and Elsevier’s <em>Computational Geometry</em>) and there seems to be little pressure for that to change any time soon.</p>

<p>On to CCCG!</p>

<p>(<a href="https://mathstodon.xyz/@11011110/102578298917323647">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2019-08-07T17:27:00Z</updated>
    <published>2019-08-07T17:27:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-08-07T23:31:12Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16143</id>
    <link href="https://rjlipton.wordpress.com/2019/08/06/code-it-up/" rel="alternate" type="text/html"/>
    <title>Code It Up</title>
    <summary>So you think you have a proof that P=NP Randi 2014 documentary source James Randi is a magician who has challenged paranormal claims of all kinds. Today Ken and I want to make a suggestion to those who claim they have proved P=NP. No the claim to have a proof that P=NP is not a […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>So you think you have a proof that P=NP</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://dickken.files.wordpress.com/2019/08/anhonestliarposter.png"><img alt="" class="alignright wp-image-18" height="192" src="https://dickken.files.wordpress.com/2019/08/anhonestliarposter.png?w=144&amp;h=192" width="144"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Randi 2014 documentary <a href="https://en.wikipedia.org/wiki/An_Honest_Liar">source</a></font></td>
</tr>
</tbody>
</table>
<p>
James Randi is a magician who has challenged paranormal claims of all kinds.</p>
<p>
Today Ken and I want to make a suggestion to those who claim they have proved P=NP.</p>
<p>
No the claim to have a proof that P=NP is not a paranormal claim. But such claims are related to Randi—or the Amazing Randi as he is called. We talked about him before <a href="https://rjlipton.wordpress.com/2012/02/23/an-amazing-result/">here</a>.</p>
<p>
Randi once helped run a contest to see who could find gold with their dowsing rod. He explained why he doubted one contestant: </p>
<blockquote><p><b> </b> <em> If they really could find gold, why were they dressed so poorly, and why were they so interested in winning the prize? </em>
</p></blockquote>
<p/><p>
I have the same question about those who claim that they have a proof that P=NP. Usually the proof is constructive and I agree with Randi:</p>
<blockquote><p><b> </b> <em> If they really could solve P=NP, why <img alt="{\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\dots}"/> </em>
</p></blockquote>
<p/><p>
You get the idea.</p>
<p>
Ken adds the obvious remark that if a foreign power or intelligence agency discovered P=NP, or factoring in P, they would still keep the lean-and-hungry look. But they are not the kind we are addressing here.</p>
<p>
</p><p/><h2> Coding Helps </h2><p/>
<p/><p>
Let’s look at a claims that P=NP is resolved. Yes, such a result is unlikely—many would say impossible. But we do get claims like this:</p>
<blockquote><p><b> </b> <em> The following <img alt="{\cal H}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+H%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\cal H}"/> is known to be a NP-complete problem; the following <img alt="{\cal E}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+E%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\cal E}"/> is known to be a polynomial time problem. I can reduce <img alt="{\cal H}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+H%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\cal H}"/> to <img alt="{\cal E}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+E%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\cal E}"/> in polynomial time. </em>
</p></blockquote>
<p/><p>
Usually the reduction is the reason their proof fails. Their claims about <img alt="{\cal H}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+H%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\cal H}"/> and <img alt="{\cal E}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+E%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\cal E}"/> are usually correct, since they are in the literature. </p>
<p>
The reduction is often complicated, often poorly defined, often defined by example. Giving a precise definition for the reduction is critical. This is the reason we suggest the following: </p>
<blockquote><p><b> </b> <em> <i>Write the reduction down in code.</i> </em>
</p></blockquote>
<p>Even better, write it as a program in a real language such as Python. </p>
<p>
There are two advantages in doing this. </p>
<ul>
<li>
Writing it as a program in a real language will likely force one to define it precisely. <p/>
</li><li>
Writing it down will also allow one to run the program on examples.
</li></ul>
<p>
The later point is the key point. Even trying your method on tiny examples is useful. Even better if you can say the following we might read the proof: </p>
<blockquote><p><b> </b> <em> <i>I have tried my code on the following public set of difficult SAT problems. The code solved all in less than three minutes each.</i> </em>
</p></blockquote>
<p>This claim would greatly improve the likelihood that people might take your claims seriously. That your code worked correctly, forgetting the running time, would improve confidence. Greatly. </p>
<p>
</p><p/><h2> The Animal Farm View<img alt="{\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\dots}"/> </h2><p/>
<p/><p>
Ken worries that some NP-complete problems are more equal than others. That is some problems, even though they are NP-complete may require reductions that blow up when encoding SAT. </p>
<p>
We wrote about this <a href="https://rjlipton.wordpress.com/2012/04/22/the-travelling-salesmans-power/">before</a> regarding the “Power Index” idea of Richard Stearns and Harry Hunt III. In their <a href="http://www.cs.albany.edu/~res/powerindex.pdf">paper</a> they gave evidence that the reductions from SAT <em>to</em> many familiar NP-complete problems <em>must</em> expand the size of instances quadratically, insofar as those problems have <em>power index</em> <img alt="{0.5}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0.5%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0.5}"/>. This was based on their “SAT Hypothesis” which anticipated current forms of the Exponential Time Hypothesis, which we have <a href="https://rjlipton.wordpress.com/2015/06/01/puzzling-evidence/">discussed</a>.</p>
<p>
Ken ponders a related issue. Even problems with power index <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/> run into the success of practical solvers. This means: </p>
<blockquote><p><b> </b> <em> Anyone citing algorithmic success as evidence toward a claim of P=NP must compete with the real-world success of algorithms that do not represent claims of P=NP. </em>
</p></blockquote>
<p/><p>
We have <a href="https://rjlipton.wordpress.com/2014/02/28/practically-pnp/">several</a> <a href="https://rjlipton.wordpress.com/2015/10/22/rankings-versus-ratings/">times</a> <a href="https://rjlipton.wordpress.com/2016/07/10/the-world-turned-upside-down/">discussed</a> the practical success of SAT-solvers on myriad real-world instances. </p>
<p>
This situation has become real in the argument over achieving quantum <a href="https://en.wikipedia.org/wiki/Quantum_supremacy">supremacy</a>. One who claims that quantum is superior to classic must worry that that classical algorithms can improve without making P=NP. A headline example from last year was when Ewin Tang—as a high-school senior—<a href="https://arxiv.org/abs/1807.04271">found</a> a classical way to remove a plausible quantum advantage in a matrix-completion problem that <a href="https://www.quantamagazine.org/teenager-finds-classical-alternative-to-quantum-recommendation-algorithm-20180731/">underlies</a> recommender systems.  There are many “industrial strength” examples in this argument—see this May 2019 <a href="https://www.technologyreview.com/s/613507/the-new-benchmark-quantum-computers-must-beat-to-achieve-quantum-supremacy/">story</a> for a start.</p>
<p>
</p><p/><h2> But… </h2><p/>
<p/><p>
Ken’s insightful comments aside, the key point is still: </p>
<blockquote><p><b> </b> <em> <i>Coding up your claimed algorithm for that NP-complete problem will still enhance belief.</i> </em>
</p></blockquote>
<p>This will happen even if the algorithm only succeeds on tiny examples. Indeed, if you cannot do this then I suggest that you will have an impossible time getting anyone to listen.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
How useful is this advice for the vast majority of us who are <em>not</em> claiming P=NP or the opposite?</p>
<p/></font></font></div>
    </content>
    <updated>2019-08-06T20:45:04Z</updated>
    <published>2019-08-06T20:45:04Z</published>
    <category term="algorithms"/>
    <category term="All Posts"/>
    <category term="P=NP"/>
    <category term="People"/>
    <category term="Proofs"/>
    <category term="claims"/>
    <category term="complexity"/>
    <category term="heuristic algorithms"/>
    <category term="James Randi"/>
    <category term="programming"/>
    <category term="quantum advantage"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-08-09T16:20:43Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2019/08/06/machine-learning-for-communication-systems-and-networks/</id>
    <link href="https://cstheory-events.org/2019/08/06/machine-learning-for-communication-systems-and-networks/" rel="alternate" type="text/html"/>
    <title>Machine Learning for Communication Systems and Networks</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">September 2-4, 2019 Trinity College Dublin, Dublin, Ireland https://connectcentre.ie/summer-school/ The Summer School will include a technical track with lectures and workshops on various aspects of Machine Learning, as well as associated training in areas such as research ethics, career development, communicating research, innovation, and public engagement. It will also include social and networking events. Speakers … <a class="more-link" href="https://cstheory-events.org/2019/08/06/machine-learning-for-communication-systems-and-networks/">Continue reading <span class="screen-reader-text">Machine Learning for Communication Systems and Networks</span></a></div>
    </summary>
    <updated>2019-08-06T18:49:21Z</updated>
    <published>2019-08-06T18:49:21Z</published>
    <category term="school"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2019-08-09T16:21:36Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/101</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/101" rel="alternate" type="text/html"/>
    <title>TR19-101 |  Streaming Verification of Graph Computations via Graph Structure | 

	Amit Chakrabarti, 

	Prantar Ghosh</title>
    <summary>We give new algorithms in the annotated data streaming setting---also known as verifiable data stream computation---for certain graph problems. This setting is meant to model outsourced computation, where a space-bounded verifier limited to sequential data access seeks to overcome its computational limitations by engaging a powerful prover, without needing to trust the prover. As is well established, several problems that admit no sublinear-space algorithms under traditional streaming do allow protocols using a sublinear amount of prover/verifier communication and sublinear-space verification.  We give algorithms for many well-studied graph problems including triangle counting, its generalization to subgraph counting, maximum matching, problems about the existence (or not) of short paths, finding the shortest path between two vertices, and testing for an independent set. While some of these problems have been studied before, our results achieve new tradeoffs between space and communication costs that were hitherto unknown. In particular, two of our results disprove explicit conjectures of Thaler (ICALP, 2016) by giving triangle counting and maximum matching algorithms for $n$-vertex graphs, using $o(n)$ space and $o(n^2)$ communication.</summary>
    <updated>2019-08-05T16:44:36Z</updated>
    <published>2019-08-05T16:44:36Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-08-09T16:20:32Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/08/05/full-professor-on-the-interface-of-computer-science-and-mathematics-at-university-of-warwick-apply-by-september-1-2019/</id>
    <link href="https://cstheory-jobs.org/2019/08/05/full-professor-on-the-interface-of-computer-science-and-mathematics-at-university-of-warwick-apply-by-september-1-2019/" rel="alternate" type="text/html"/>
    <title>Full Professor on the interface of Computer Science and Mathematics at University of Warwick (apply by September 1, 2019)</title>
    <summary>The Department of Computer Science at the University of Warwick and the Warwick Mathematics Institute invite applications for a full Professor post in the areas on the interface of Computer Science and Mathematics, including Discrete Mathematics, Algorithms and Complexity, Theoretical Computer Science. Website: https://warwick.ac.uk/fac/sci/dcs/jobs/?newsItem=8a1785d86c613bc7016c614a2c0f0046 Email: R.S.Lazic@warwick.ac.uk</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Department of Computer Science at the University of Warwick and the Warwick Mathematics Institute invite applications for a full Professor post in the areas on the interface of Computer Science and Mathematics, including Discrete Mathematics, Algorithms and Complexity, Theoretical Computer Science.</p>
<p>Website: <a href="https://warwick.ac.uk/fac/sci/dcs/jobs/?newsItem=8a1785d86c613bc7016c614a2c0f0046">https://warwick.ac.uk/fac/sci/dcs/jobs/?newsItem=8a1785d86c613bc7016c614a2c0f0046</a><br/>
Email: R.S.Lazic@warwick.ac.uk</p></div>
    </content>
    <updated>2019-08-05T10:31:02Z</updated>
    <published>2019-08-05T10:31:02Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-08-09T16:20:52Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/08/05/faculty-openings-in-computer-science-at-the-open-university-of-israel-apply-by-october-31-2019/</id>
    <link href="https://cstheory-jobs.org/2019/08/05/faculty-openings-in-computer-science-at-the-open-university-of-israel-apply-by-october-31-2019/" rel="alternate" type="text/html"/>
    <title>Faculty Openings in Computer Science at The Open University of Israel (apply by October 31, 2019)</title>
    <summary>The Department of Mathematics and Computer Science at the Open University of Israel invites applications in all areas of computer science for several senior faculty positions at all ranks (assistant professor, associate professor, professor) Website: https://www.openu.ac.il/about/departments/academic_secretary/messages/FacultyOpeningsCS.aspx Email: search@openu.ac.il</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Department of Mathematics and Computer Science at the Open University of Israel invites applications in all areas of computer science for several senior faculty positions at all ranks (assistant professor, associate professor, professor)</p>
<p>Website: <a href="https://www.openu.ac.il/about/departments/academic_secretary/messages/FacultyOpeningsCS.aspx">https://www.openu.ac.il/about/departments/academic_secretary/messages/FacultyOpeningsCS.aspx</a><br/>
Email: search@openu.ac.il</p></div>
    </content>
    <updated>2019-08-05T05:39:39Z</updated>
    <published>2019-08-05T05:39:39Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-08-09T16:20:52Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://emanueleviola.wordpress.com/?p=658</id>
    <link href="https://emanueleviola.wordpress.com/2019/08/04/because-of-pollution-conferences-should-be-virtual/" rel="alternate" type="text/html"/>
    <title>Because of pollution, conferences should be virtual</title>
    <summary>Perhaps conferences made sense fifty years ago. We did not have internet, and the pollution was not as bad. Today, we can have effective virtual meetings, while the pollution has reached a level of crisis, see this moving talk by Greta_Thunberg. Moving to a system of virtual conferences is I believe a duty of every […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Perhaps conferences made sense fifty years ago. We did not have internet, and the pollution was not as bad. Today, we can have effective virtual meetings, while the pollution has reached a level of crisis, see this <a href="https://www.ted.com/talks/greta_thunberg_school_strike_for_climate_save_the_world_by_changing_the_rules/transcript?language=en">moving talk by Greta_Thunberg</a>. Moving to a system of virtual conferences is I believe a duty of every scientist. Doing so will cut the significant air travel emissions that come from shipping scientists across the world. To attend a climate summit in the USofA, <a href="https://www.forbes.com/sites/davidebanis/2019/07/29/gretha-thunberg-will-sail-across-the-atlantic-to-attend-un-climate-conferences/#27e93f87c3b2">Greta will sail across the Atlantic ocean on a zero emission boat</a><a href="https://www.ted.com/talks/greta_thunberg_school_strike_for_climate_save_the_world_by_changing_the_rules/transcript?language=en">.</a></p>
<p>We can keep everything the way it is, but simply give the talks online. This change doesn’t involve anybody higher up in the political ladder. It only involves us, the program chairs, the steering committees.</p>
<p>While we wait for that, we can begin by virtualizing the physical STOC/FOCS PC meetings,<a href="https://emanueleviola.wordpress.com/2017/07/28/stocfocs-pc-meetings-does-nature-of-decisions-justify-cost/"> whose added value over a virtual meeting, if any, does not justify the cost</a>; and by holding conferences where the center of mass is, instead of exotic places where one can combine the trip with a vacation at the expense of tax payers’ money and everybody’s health. And that is also why I put a bid to hold the 2021 Conference on Computational Complexity in Boston.</p>
<p>NSF panels, making decisions worth millions, routinely have virtual panelists (I was the last few times). So why do we insist on shipping scientists across the globe multiple times a year to give 15-minute talks which to most people are less useful than spending 20 minutes reading the paper on the arxiv?</p></div>
    </content>
    <updated>2019-08-04T22:58:28Z</updated>
    <published>2019-08-04T22:58:28Z</published>
    <category term="Uncategorized"/>
    <category term="health"/>
    <category term="Utopia"/>
    <author>
      <name>Manu</name>
    </author>
    <source>
      <id>https://emanueleviola.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://emanueleviola.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://emanueleviola.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://emanueleviola.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://emanueleviola.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>by Manu</subtitle>
      <title>Thoughts</title>
      <updated>2019-08-09T16:21:19Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=17603</id>
    <link href="https://gilkalai.wordpress.com/2019/08/04/avi-wigdersons-integrating-computational-modeling-algorithms-and-complexity-into-theories-of-nature-marks-a-new-scientific-revolution-an-invitation-for-a-discussion/" rel="alternate" type="text/html"/>
    <title>Avi Wigderson’s: “Integrating computational modeling, algorithms, and complexity into theories of nature, marks a new scientific revolution!” (An invitation for a discussion.)</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">  The cover of Avi Wigderson’s book “Mathematics and computation” as was first exposed to the public in Avi’s Knuth Prize videotaped lecture. (I had trouble with 3 of the words: What is EGDE L WONK 0?  what is GCAAG?GTAACTC … <a href="https://gilkalai.wordpress.com/2019/08/04/avi-wigdersons-integrating-computational-modeling-algorithms-and-complexity-into-theories-of-nature-marks-a-new-scientific-revolution-an-invitation-for-a-discussion/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p> </p>
<p><a href="https://gilkalai.files.wordpress.com/2019/07/avi-book-cover.png"><img alt="" class="alignnone size-full wp-image-17611" src="https://gilkalai.files.wordpress.com/2019/07/avi-book-cover.png?w=640"/></a></p>
<p><span style="color: #ff0000;">The cover of Avi Wigderson’s book “Mathematics and computation” as was first exposed to the public in <a href="https://drive.google.com/file/d/1zxctNw-mA3hOT1tktE_dYjnmvOzZmC_A/view">Avi’s Knuth Prize videotaped lecture</a>. (I had trouble with 3 of the words: What is EGDE L WONK 0?  what is GCAAG?GTAACTC ?  TACGTTC ?  I only figured out the first.)</span></p>
<p>Avi Wigderson’s book  “<span style="color: #000000;"><a href="https://www.math.ias.edu/avi/book">Mathematics and computation, a theory revolutionizing technology and science</a>” is about to be published by Princeton University Press. The link is to a free copy of the book which will always be available on Avi’s homepage. (See also <a href="https://gilkalai.wordpress.com/2017/10/27/must-read-book-by-avi-wigderson/">this re-blogged post here</a> of Boaz Barak.)</span></p>
<p><span style="color: #000000;">One main theme of the book is the rich connection between the theory of computing and other areas (in fact, most areas) of mathematics. See also this self contained survey (based on Chapter 13 of the book) by Avi <a href="https://arxiv.org/abs/1710.09780">Interactions of Computational Complexity Theory and Mathematics,</a> which in 27 pages overviews relations to number theory, Geometry, Operator Theory, Metric Geometry, Group Theory, Statistical Physics, Analysis and Probability, Lattice Theory and Invariant Theory. Of course, Avi himself is among the main heroes in finding many paths between mathematics and the theory of computing over the last four decades.</span></p>
<p><span style="color: #000000;">Another theme of the book and of several talks by Avi is that the theory of computing has revolutionary connections with many fields of science and technology. Again, this theme is present in the entire book and is emphasized in Chapter 20, which also appeared as a self contained paper  “<a href="http://www.math.ias.edu/~avi/PUBLICATIONS/Wigderson2018.pdf">On the nature of the Theory of Computation (ToC).</a>”  Let me quote one sentence from Avi’s book that I propose for discussion. (For the complete quote see the end of the post.)</span></p>
<p> </p>
<blockquote>
<h3>The intrinsic study of computation transcends human-made artifacts, and its expanding connections and interactions with all sciences, integrating computational modeling, algorithms,  and complexity into theories of nature and society, marks a new scientific revolution!</h3>
</blockquote>
<p>Of course, <span style="color: #000000;">similar ideas were also expressed by several other prominent scientists, and let me mention Bernard Chazelle’s essay: <a href="https://www.cs.princeton.edu/~chazelle/pubs/algorithm.html">The Algorithm: Idiom of Modern Science</a>. (Feel free to give further examples and links in the comment section.)</span></p>
<h3>Let’s discuss:  Integrating computational modeling, algorithms,  and complexity into theories of nature, marks a new scientific revolution!</h3>
<p><span style="color: #000000;">I propose to discuss in the comment section the idea that the theory of computing offers a scientific revolution. Very nice cases to examine are the computational study of randomness and connections to statistics, connections with economy and connections with biology. Comments on the relations between the theory of computation and other areas of mathematics are also very welcome.</span></p>
<p><a href="https://gilkalai.files.wordpress.com/2019/08/avi-c-3.png"><img alt="" class="alignnone size-full wp-image-17795" height="329" src="https://gilkalai.files.wordpress.com/2019/08/avi-c-3.png?w=640&amp;h=329" width="640"/></a></p>
<p><span style="color: #ff0000;">Avi’s concluding slide compared these three great theories of human understanding.</span></p>
<p><span style="color: #000000;"> (Previous attempts of open discussions were made in the following posts on this blog: </span><a href="https://gilkalai.wordpress.com/2019/03/26/10-milestones-in-the-history-of-mathematics-according-to-nati-and-me/" rel="bookmark">10 Milestones in the History of Mathematics according to Nati and Me</a>; <a href="https://gilkalai.wordpress.com/2013/05/23/why-is-mathematics-possible/" rel="bookmark">Why is mathematics possible?</a> (and a <a href="https://gilkalai.wordpress.com/2013/06/19/why-is-mathematics-possible-tim-gowerss-take-on-the-matter/">follow up post</a>); <a href="https://gilkalai.wordpress.com/2010/03/06/when-it-rains-it-pours/">When it rains it pours</a>;  <a href="https://gilkalai.wordpress.com/2019/03/31/is-it-legitimate-ethical-for-google-to-close-google/" rel="bookmark">Is it Legitimate/Ethical for Google to close Google+?</a>; <a href="https://gilkalai.wordpress.com/2009/03/25/an-open-discussion-and-polls-around-roths-theorem/" rel="bookmark">An Open Discussion and Polls: Around Roth’s Theorem</a>; <a href="https://gilkalai.wordpress.com/2008/05/25/is-mathematics-a-science/" rel="bookmark">Is Mathematics a Science?</a>)</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/07/avi-c3.png"><img alt="" class="alignnone size-full wp-image-17640" height="317" src="https://gilkalai.files.wordpress.com/2019/07/avi-c3.png?w=640&amp;h=317" width="640"/></a></p>
<p><span style="color: #ff0000;">Avi promotes the idea of the central place of the theory of computing in his talks and writings</span><span id="more-17603"/></p>
<p><a href="https://gilkalai.files.wordpress.com/2019/07/avi-c2.png"><img alt="" class="alignnone size-full wp-image-17639" height="229" src="https://gilkalai.files.wordpress.com/2019/07/avi-c2.png?w=640&amp;h=229" width="640"/></a></p>
<p><span style="color: #ff0000;">And at the same time he is also humorously skeptical about it. (And mainly emphasizes that his far reaching claim requires careful discussion and ample evidence.)   </span></p>
<p> </p>
<h3>The full quote of Avi:</h3>
<blockquote><p><em>The Theory of Computation is as revolutionary, fundamental and beautiful as major theories of mathematics, physics, biology, economics… that are regularly hailed as such. Its impact has been similarly staggering. The mysteries still baffling ToC are as challenging as those left open in other fields. And quite uniquely, the theory of computation is central to most other sciences. In creating the theoretical foundations of computing systems ToC has already played, and continues to play a major part in one of the greatest scientific and technological revolutions in human history. But the intrinsic study of computation transcends man-made artifacts. ToC has already established itself as an important mathematical discipline, with growing connections to nearly all mathematical areas. And its expanding connections and interactions with all sciences, naturally integrating computational modeling, algorithms and complexity into theories of nature and society, marks the beginning of another scientific revolution!</em></p></blockquote>
<h3>More related material:</h3>
<ol>
<li>Avi’s talk <a href="https://youtu.be/Z4nhNbpx_u0">Scientific revolutions, ToC and PCP</a>  at the Tel Aviv PCP meeting and an <a href="https://youtu.be/-GQnK6ys6C0">interview of Avi by Alon Rosen</a>.</li>
<li><a href="https://video.ias.edu/csdm/stepanov"> A talk by Avi on the Stepanov method</a></li>
<li>The recent works on polytopes arising from moment maps and related optimization problems and algorithmic aspects.  <a href="https://drive.google.com/file/d/1zxctNw-mA3hOT1tktE_dYjnmvOzZmC_A/view">Avi’s Knuth prize videotaped lecture</a>; Avi’s lecture  <a href="http://www.fields.utoronto.ca/talks/Complexity-Optimization-and-Math-or-Can-we-prove-P-NP-gradient-descent">Complexity, Optimization and Math (or, Can we prove that P != NP by gradient descent?)</a> in the recent conference honoring Bill Cook. (I plan to come back to this fascinating topic.)</li>
<li><span style="color: #000000;">An essay by Oded Goldreich and Avi Wigderson (essentially from 1996) <a href="http://www.wisdom.weizmann.ac.il/~oded/PDF/toc-sp2.pdf">“The theory of computing –  a scientific perspective.”</a></span></li>
</ol>
<p><a href="https://gilkalai.files.wordpress.com/2019/08/blog-comments.png"><img alt="" class="alignnone size-medium wp-image-17771" height="300" src="https://gilkalai.files.wordpress.com/2019/08/blog-comments.png?w=300&amp;h=300" width="300"/></a></p>
<p><span style="color: #ff0000;">The volume of comments in the first decade of this blog was modest. I recently read, however, wordpress’s advice on how to reply to blog comments like a pro. </span></p>
<p>And finally, EGDE L WONK 0 is 0-knowledge.</p></div>
    </content>
    <updated>2019-08-04T20:14:01Z</updated>
    <published>2019-08-04T20:14:01Z</published>
    <category term="Academics"/>
    <category term="Combinatorics"/>
    <category term="Computer Science and Optimization"/>
    <category term="Open discussion"/>
    <category term="Philosophy"/>
    <category term="What is Mathematics"/>
    <category term="Avi Wigderson"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-08-09T16:20:37Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>http://ptreview.sublinear.info/?p=1144</id>
    <link href="https://ptreview.sublinear.info/?p=1144" rel="alternate" type="text/html"/>
    <title>News for July 2019</title>
    <summary>We saw quite an activity last month, with a total of 9 papers on property testing or related areas. Let’s start with a paper on PCPs:Revisiting Alphabet Reduction in Dinur’s PCP, by Venkatesan Guruswami, Jakub Opršal, and Sai Sandeep (ECCC). As mentioned in the title, this work provides an alternate proof of one of the […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>We saw quite an activity last month, with a total of 9 papers on property testing or related areas.</p>



<p>Let’s start with a paper on PCPs:<br/><strong>Revisiting Alphabet Reduction in Dinur’s PCP</strong>, by Venkatesan Guruswami, Jakub Opršal, and Sai Sandeep  (<a href="https://eccc.weizmann.ac.il/report/2019/092/">ECCC</a>). As mentioned in the title, this work provides an alternate proof of one of the two parts of the Dinur’s PCP theorem proof. In that proof, the argument goes by alternating two main steps: (i) amplifying the soundness gap, at the price of increasing the alphabet size (and the instance size); (ii) reducing the alphabet size, at the price of increasing the  instance size. From the observation that step (i) creates some structure in the instances that can be leveraged, the authors provide an alternative construction for (ii), leading to an arguably simpler analysis of the soundness of the underlying test. A nice throwback to some of the roots of property testing.</p>



<p>Then, four papers on distribution testing:<br/><strong>Testing Mixtures of Discrete Distributions</strong>, by Maryam Aliakbarpour, Ravi Kumar, Ronitt Rubinfeld (<a href="https://arxiv.org/abs/1907.03190">arXiv</a>). One of the most studied problems in distribution testing is <em>identity testing</em> (a.k.a., goodness-of-fit): given a reference distribution \(q\) over a domain of size \(n\) and i.i.d. samples from an unknown \(p\), decide between \(p=q\) and \(d_\textrm{TV}(p,q) &gt; \varepsilon\). While this is now well-understood and can be done with a strongly sublinear number of samples (namely, \(\sqrt{n})\)), the case of <em>tolerant</em> testing is much sadder: Valiant and Valiant proved that \(\Theta(n/\log n)\) samples were required for distinguishing \(d_\textrm{TV}(p,q) &lt; \varepsilon/2\) from \(d_\textrm{TV}(p,q) &gt; \varepsilon\). So, noise-tolerance is almost as hard as it gets… <em>except</em>, as this works suggests and studies, if one has some guarantees on the noise! What if the noise in the completeness case was just that \(q\) is perturbed by some (known, or available via samples as well) noise coming from a second distribution \(\eta\)? I.e., the question is now to test whether \(p\) if of the form \(\alpha q + (1-\alpha) \eta\) for some \(\alpha\in [0,1]\), or if it is \(\varepsilon\)-far from all mixtures of \(q\) and \(\eta\). The authors have various results on this question and some extensions, but the upshot is: “with structured noise, strongly sublinear sample complexity is once again possible.”<br/><strong><br/>Can Distributed Uniformity Testing Be Local?</strong>, by Uri Meir, Dor Mintzer, and Rotem Oshman (<a href="https://dl.acm.org/citation.cfm?id=3331613">ACM PODC Proceedings</a>). More on identity testing, specifically uniformity testing. No noise here, but another constraint: the samples are distributed. There are \(k\) players, each holding \(q\) i.i.d. samples from a distribution \(p\) over \([n]\); each can send \(\ell=1\) bit to a central referee, in a non-interactive fashion. Is \(p\) the uniform distribution, or is it \(\varepsilon\)-far from it? The authors here consider the case where \(k,n,\varepsilon\) are fixed, and prove lower bounds on the number \(q=q(k,n,\varepsilon)\) of samples each player must hold in order to perform this uniformity testing task. (Note: their lower bounds hold even in the public-randomness setting.) Motivated by the LOCAL model, they focus on 3 cases of interest, for which they obtain tight or near-tight bounds on \(q\) (in view of upper bounds from previous work of a subset of the authors): (1)  when the referee’s decision has to be the \(\textsf{AND}\) of all \(n\) bits she receives; (2) when the referee can do something more involved, and use a threshold function; and (3) when the referee can use an arbitrary function of those \(n\) messages. Underlying those lower bounds is a neat application of Boolean Fourier analysis, recasting the analysis of the standard “Paninski” lower bound instance and the player’s decision functions as a question on Boolean functions.<br/><br/><strong>Domain Compression and its Application to Randomness-Optimal  Distributed Goodness-of-Fit</strong>, by Jayadev Acharya, Clément Canonne, Yanjun Han, Ziteng Sun, and Himanshu Tyagi (<a href="https://arxiv.org/abs/1907.08743">arXiv</a>,<a href="https://eccc.weizmann.ac.il/report/2019/098/">ECCC</a>). Remember the paper just above? Now, focus on the case (3), where the referee can use any function of the message, allow each player to send \(\ell\) bits instead of one, but give only one sample (instead of \(q\)) to each player. This becomes a setting we have talked about before on this blog (specifically, with three papers on <a href="https://ptreview.sublinear.info/?p=990">these</a> <a href="https://ptreview.sublinear.info/?p=1030">three</a> <a href="https://ptreview.sublinear.info/?p=1075">months</a>). Those three papers established the optimal number of player \(k\), in terms of  the domain size \(n\), the distance parameter \(\varepsilon\), and the number of bits per player \(\ell\), in both the private-coin and public-coin settings. This new work interpolates between those two extremes, and gives the tight answer to the general question: if there are \( 0\leq s \leq \log n\) bits of public randomness available, what is the optimal number of players to perform identity testing? Behind the upper bounds is a new notion of (randomness-efficient) <em>domain compression</em> they introduce: how to reduce the domain size of the probability distributions while preserving the \(\ell_1\) distances between them as much as possible?<br/><br/><strong>Towards Testing Monotonicity of Distributions Over General Posets</strong>, by Maryam Aliakbarpour, Themis Gouleakis, John Peebles, Ronitt Rubinfeld, and Anak Yodpinyanee (<a href="https://arxiv.org/abs/1907.03182">arXiv</a>). Away from identity testing, let’s now consider another central question, testing <em>monotonicity</em> of distributions. Specifically, a distribution \(p\) over a given poset \((\mathcal{X}, \prec)\) is said to be monotone if \(p(x) \leq p(y)\) whenever \(x\prec y\). While the question is fully understood for the familiar case of the line \(\mathcal{X} = \{1,2,\dots,n\}\), the case of general posets is much murkier, and more or less uncharted. This paper initiates a general study of the question, improving on previously known bounds for the matching poset and Boolean hypercube, and providing several new results and techniques for the general case, to establish both upper and lower bounds on the sample complexity.</p>



<p>And now… graphs!<br/><strong>Expansion Testing using Quantum Fast-Forwarding and Seed Sets</strong>, by Simon Apers (<a href="https://arxiv.org/abs/1907.02369">arXiv</a>). This paper is concerned with (bicriteria) testing of vertex expansion of a given graph \(G=(V,E)\) in the bounded-degree graph model. Loosely speaking, given a value \(\Phi\) and query access <em>(i.e., sampling a node u.a.r., querying the degree of a node, and querying the \(i\)-th neighbor of a node) </em>to a graph \(G\) with maximum degree \(d=\Theta(1)\), the goal is to distinguish between (i) \(G\) has vertex expansion at most \(\Phi\) and (ii) \(G\) is \(\varepsilon\)-far from any \(G’\) with vertex expansion at most \(\Phi^2\) <em>(simplifying and dropping some technicalities)</em>. The previous state-of-the-art was a \(\tilde{O}_{\varepsilon}(n^{1/2}/\Phi^2)\) query complexity for classical algorithms, and a \(\tilde{O}_{\varepsilon}(\min(n^{1/3}/\Phi^2),n^{1/2}/\Phi^2))\) query complexity upper bound for quantum testers. The current work improves on this by providing a \(\tilde{O}_{\varepsilon}(n^{1/3}/\Phi)\) quantum tester. Graphs expand—and so does the gap between classical and quantum testing.<br/><br/><strong>Walking Randomly, Massively, and Efficiently</strong>, by Jakub Łącki, Slobodan Mitrović, Krzysztof Onak, and Piotr Sankowski  (<a href="https://arxiv.org/abs/1907.05391">arXiv</a>). One very useful primitive, in many graph property testing results and of course well beyond property testing, is the ability to perform random walks on graphs. In the case of large, distributed (or merely impractically massive) graphs, however, it is not clear how to implement this primitive efficiently. This work addresses this question in the MPC (Massive Parallel Computation) model, and shows how to perform independently, from all of the \(n\) nodes of a graph (i.e., machine), an \(\ell\)-length random walk with only \(O(\log \ell)\) rounds of communication and \(O(n^\alpha)\) space per machine, for any constant \(\alpha \in(0,1)\). This round complexity matches a known (conditional) lower bound, and thus the result is as good as it gets — further, the authors obtain such MPC algorithms for both undirected and directed graph, somehow leveraging the latter case to handle the (significantly more complicated) directed case. As an application of this efficient random walk primitive, they provide MPC property testing algorithms for both bipartiteness and vertex expansion<em> (same definition as in the paper above: vertex expansion \(\Phi\) vs. \(\varepsilon\)-far from any \(G’\) with vertex expansion \(\Phi^2\))</em> in the general graph model. (Beyond property testing, another application—the main one in the paper— is computing PageRank in both graphs and directed graphs.)<br/><strong><br/>A Lower Bound on Cycle-Finding in Sparse Digraphs</strong>, by Xi Chen, Tim Randolph, Rocco Servedio, and Timothy Sun (<a href="https://arxiv.org/abs/1907.12106">arXiv</a>). In this paper, the authors tackle the problem of one-sided testing of acyclicity of directed graphs, in the bounded-degree graph model (equivalently, on the task of finding a cycle in a digraph promised to be far from acyclic). Previously, an \(\Omega(\sqrt{n})\) lower bound for this task had been shown by Bender and Ron, based on a birthday-paradox-type argument; this work improves on this hardness result, showing that \(\tilde{\Omega}(n^{5/9})\) queries are necessary. Interestingly, whether achieving any \(o(n)\) query complexity is possible remains open.<br/><br/><strong>Constant-Time Dynamic \((\Delta+1)\)-Coloring and Weight Approximation for  Minimum Spanning Forest: Dynamic Algorithms Meet Property Testing</strong>, by Monika Henzinger and Pan Peng (<a href="https://arxiv.org/abs/1907.04745">arXiv</a>). Finally, the last paper covered this month is concerned with <em>dynamic graph algorithms</em>: where updates to a graph (which can be both edge additions <em>and</em> deletions) come sequentially, and the objective is to maintain, e.g., a coloring, or an approximation of some function of the graph, at any time using as little time per update. This paper advocates the use of techniques from property testing <em>(loosely speaking, as their locality and query-efficiency translates to fast update times)</em> to design better dynamic graph algorithms. It illustrates this idea by obtaining several new results, in particular an (amortized) \(O(1)\)-update-time randomized algorithm to maintain a \((\Delta+1)\)-coloring in a graph with degree bound \(\Delta\). The algorithm relies on a random ranking of the nodes which, combined with a suitable randomized update rule for recoloring a vertex when needed, ensure that the recolorings will not (with high probability) “propagate” to much. This is the first time that this idea, previously used in several testing and sublinear-time papers, is used in the context of dynamic graph algorithms—adding an edge between the two areas, hopefully only the first of many.<br/></p>



<p><em>If we missed a paper this month, or represented some result above, please mention it in the comments.</em></p></div>
    </content>
    <updated>2019-08-04T00:56:33Z</updated>
    <published>2019-08-04T00:56:33Z</published>
    <category term="Monthly digest"/>
    <author>
      <name>Clement Canonne</name>
    </author>
    <source>
      <id>https://ptreview.sublinear.info</id>
      <link href="https://ptreview.sublinear.info/?feed=rss2" rel="self" type="application/atom+xml"/>
      <link href="https://ptreview.sublinear.info" rel="alternate" type="text/html"/>
      <subtitle>The latest in property testing and sublinear time algorithms</subtitle>
      <title>Property Testing Review</title>
      <updated>2019-08-08T23:23:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16133</id>
    <link href="https://rjlipton.wordpress.com/2019/08/02/the-electoral-college-is-it-good/" rel="alternate" type="text/html"/>
    <title>The Electoral College: Is It Good?</title>
    <summary>A old unpublished result, some new published results [ Playbill ] Alexander Hamilton was a framer of the U.S. Constitution. He wrote the bulk of the Federalist Papers (FP) defending the Constitution. Today he is best known for the playbill—the musical on his life—and the bill, the US ten dollar bill. Today I thought we […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>A old unpublished result, some new published results</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2019/08/02/the-electoral-college-is-it-good/96902-11/" rel="attachment wp-att-16136"><img alt="" class="alignright size-medium wp-image-16136" height="300" src="https://rjlipton.files.wordpress.com/2019/08/96902-11.jpg?w=194&amp;h=300" width="194"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">[ Playbill ]</font></td>
</tr>
</tbody>
</table>
<p>
Alexander Hamilton was a framer of the U.S. Constitution. He wrote the bulk of the <a href="https://en.wikipedia.org/wiki/The_Federalist_Papers">Federalist Papers</a> (FP) defending the Constitution. Today he is best known for the playbill—the <a href="https://en.wikipedia.org/wiki/Hamilton_(musical)">musical</a> on his life—and the bill, the US ten dollar bill.</p>
<p>
Today I thought we would discuss the U.S. electoral college (EC).<br/>
<span id="more-16133"/></p>
<p>
We are in the midst of the run-up to next year’s President election. An on-going discussion is the issue of the EC. Should it be modified? Should it be replaced? Is it a good idea? </p>
<p>
So let’s recall how the EC works. Then we will look at it from a theory viewpoint. </p>
<p>
</p><p/><h2> The College </h2><p/>
<p/><p>
The electoral college is how every four years we elect the President of the United States. It is not a direct popular vote. The Constitution created it as a compromise between a direct popular vote and a vote by the members of Congress. Back then, the framers of the Constitution, including Hamilton, did not trust the electorate. Hence, the rationale for the EC.</p>
<p>
Today the EC consists of 538 electors. Voters in each state pick electors, who then vote in EC for the President. Thus by high math, 270 electors are required to win. A state gets one electoral vote for each member in the House of Representatives plus two. The latter rule ensures that no state gets too few votes. It is some times called the “two-plus rule”.</p>
<p>
The arguments for the EC are distilled in FP <a href="https://en.wikipedia.org/wiki/Federalist_No._68">No. 68</a>. Although the collaboration/authorship status of numerous FP remains unclear, Hamilton’s claim in his last testament to sole authorship of FP 68 is not seriously disputed. <a href="https://en.wikipedia.org/wiki/Federalist_No._68">Quoting</a> Wikipedia:</p>
<blockquote><p><b> </b> <em> Entitled “The Mode of Electing the President”, No. 68 describes a perspective on the process of selecting the Chief Executive of the United States. In writing this essay, the author sought to convince the people of New York of the merits of the proposed Constitution. Number 68 is the second in a series of 11 essays discussing the powers and limitations of the Executive branch and the only one to describe the method of selecting the president. </em>
</p></blockquote>
<p/><p>
Opponents today argue against the EC. They point out that it allows one to win without getting the most votes. This has happened in two of the last five elections, in 2000 and 2016. The EC rewards uneven allocations of campaigning to the few “swing-states”. It also gives voters in less populated states more voting power. A vote from Wyoming has over three times the influence on the EC tally as a vote from California. The battle over FP 68 has even been <a href="https://securingdemocracy.gmfus.org/hamilton-68">internationalized</a>.</p>
<p>
</p><p/><h2> My College </h2><p/>
<p/><p>
Years ago. Decades ago. Eons ago. When I was in college, I almost flunked a required one-credit course in my senior year. The course was on issues of the election that year of the President. No it did not involve Hamilton. </p>
<p>
The grade of the course was based on a term paper. Mine, which got a <img alt="{\cal D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\cal D}"/>, was based on an argument for the EC. Thankfully, the grade was just enough to get me a pass in the course, and allow me to graduate. I did not take the course seriously—my attendance was spotty, at best.</p>
<p>
My idea was that there was an argument for the EC based on a connection with the ability to manage elections. My central thesis was: </p>
<blockquote><p><b> </b> <em> <i>The ability to accurately predict the outcome of a Presidential election is inherently undesirable</i>. </em>
</p></blockquote>
<p/><p>
Let’s agree that we will call this the <i>Prediction Assumption</i> (PA). Predicting the outcome of elections may not be a good idea. If predictions could be accurate, then one could argue that this would allow candidates to manipulate the election. I think you could make the case that this could be a problem. Candidates would be able to manage their opinions to optimize their chances of winning the election. </p>
<p>
In any event I then proved a result that showed that given PA, one could argue that the EC was better than a popular election. Note, the usual math arguments against the EC are based on the power of individual voters. See <a href="https://www.siam.org/Portals/0/Publications/SIURO/Vol12/S01616.pdf?ver=2019-02-12-215230-620">here</a> and <a href="https://blogs.scientificamerican.com/guest-blog/the-funky-math-of-the-electoral-college/">here</a> for some of their insights.</p>
<p>
</p><p/><h2> My College Paper </h2><p/>
<p/><p>
The central point of my paper was informally this:</p>
<blockquote><p><b>Theorem:</b> <em> Prediction of an election using EC is more difficult than one using the popular vote. </em>
</p></blockquote>
<p/><p>
A simple example should help. Imagine an election with three states: Northeast, West, and South. Let them each have one electoral vote. Clearly <img alt="{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2}"/> are needed to win. Suppose the states are arranged like this:</p>
<ul>
<li>
Northeast: Almost all for A; <p/>
</li><li>
West: Almost all for B; <p/>
</li><li>
South: Close between A and B.
</li></ul>
<p>
Then prediction requires the polling to be able to tell the outcome of the South vote. The point is:</p>
<blockquote><p><b> </b> <em> The smaller the number of voters in the ensemble being predicted, the more uncertain the prediction. </em>
</p></blockquote>
<p/><p>
Ken argues that simply having a multiplicity of component elections—one in each state plus DC—also increases the uncertainty. This may happen technically just because the result is a kind of average over unequal-sized averages. </p>
<p>
</p><p/><h2> Their Papers </h2><p/>
<p/><p>
Modern results in Boolean function theory actually have studied the noise sensitivity of the EC. They have studied how errors in voting can flip an election. Look at Gil Kalai’s 2010 <a href="http://www.ma.huji.ac.il/~kalai/CHAOS.pdf">paper</a>, “Noise Sensitivity And Chaos In Social Choice Theory.” He shows that majority is more stable in the presence of noise than the EC. Look at Ryan O’Donnell’s <a href="https://www.cs.cmu.edu/~odonnell/papers/analysis-survey.pdf">paper</a>, “Some Topics in Analysis of Boolean Functions.” He shows a related point that errors in EC—in a simple model—can increase the chance that errors flip the election factor of about <img alt="{5.7}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B5.7%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{5.7}"/>.</p>
<p>
Neither paper strikes me as studying whether predictions are easier with the simple majority rule than with the EC.<br/>
I believe that their new results can be used to prove the same type of theorems on prediction. </p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Did I deserve a better grade than a <img alt="{\cal D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\cal D}"/>? Or should I have flunked? Should I have published something?</p>
<p>
For comparison, the college term paper which eventually became the <a href="https://en.wikipedia.org/wiki/Twenty-seventh_Amendment_to_the_United_States_Constitution">27th Amendment</a> to the Constitution received a better grade: <img alt="{\cal C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\cal C}"/>. Oh well.</p>
<p/></font></font></div>
    </content>
    <updated>2019-08-02T14:32:54Z</updated>
    <published>2019-08-02T14:32:54Z</published>
    <category term="Oldies"/>
    <category term="People"/>
    <category term="Proofs"/>
    <category term="Results"/>
    <category term="Boolean functions"/>
    <category term="Boolean sensitivity conjecture"/>
    <category term="election"/>
    <category term="electoral college"/>
    <category term="old result"/>
    <category term="predictions"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-08-09T16:20:45Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2019/08/01/the-mathematics-of-quantum-computation-iiashuji-israel/</id>
    <link href="https://cstheory-events.org/2019/08/01/the-mathematics-of-quantum-computation-iiashuji-israel/" rel="alternate" type="text/html"/>
    <title>The Mathematics of Quantum Computation (IIAS@HUJI, Israel)</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">December 15-19, 2019 IIAS @ Hebrew University of Jerusalem, Israel http://ias.huji.ac.il/SchoolCSE4 Registration deadline: August 23, 2019 The school will introduce TCS and math students and faculty, who are interested in the theoretical aspects of quantum computation, to the beautiful and fascinating mathematical and computational open questions in the area, starting from scratch. No prior knowledge … <a class="more-link" href="https://cstheory-events.org/2019/08/01/the-mathematics-of-quantum-computation-iiashuji-israel/">Continue reading <span class="screen-reader-text">The Mathematics of Quantum Computation (IIAS@HUJI, Israel)</span></a></div>
    </summary>
    <updated>2019-08-01T08:19:47Z</updated>
    <published>2019-08-01T08:19:47Z</published>
    <category term="school"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2019-08-09T16:21:36Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/07/31/linkage</id>
    <link href="https://11011110.github.io/blog/2019/07/31/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>A little out of order because it made more sense that way:</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>A little out of order because it made more sense that way:</p>

<ul>
  <li>
    <p><a href="https://mathstodon.xyz/@jeffgerickson/102453558801250536">A triangulated polygon, from <em>Les Amusemens Mathématiques</em> by André-Joseph Mancoucke, 1749</a>. Jeff Erickson delves once again into the history of mathematics, to find what might be the first statement of the theorem that every simple polygon has a triangulation.</p>
  </li>
  <li>
    <p><a href="https://daringfireball.net/linked/2019/06/13/dropbox-sucks">The new Dropbox sucks</a> (<a href="https://mathstodon.xyz/@11011110/102459317265416759"/>). At least, it does if all you want is low-fuss synchronization of files between your computers. If you want cloud backup, a <a href="https://twitter.com/sandofsky/status/1138686582859239425">resource-intensive</a> desktop app, or easy collaboration between multiple users, it might still be ok for you.</p>

    <p>After getting annoyed with Dropbox’s mission creep and bloat, I’ve started trying <a href="https://syncthing.net/">syncthing</a> as a replacement (<a href="https://mathstodon.xyz/@11011110/102500777811510032"/>, <a href="https://news.ycombinator.com/item?id=20466469">via</a>). It seems like a pretty good replacement, without the bells and whistles that I don’t want or need.</p>
  </li>
  <li>
    <p><a href="https://www.thisiscolossal.com/2019/07/manmade-patterns-and-uncanny-shadows-photographed-from-above-by-jp-and-mike-andrews/">Abstract aerial photography by JP and Mike Andrews</a> (<a href="https://mathstodon.xyz/@11011110/102463616656875898"/>).</p>
  </li>
  <li>
    <p><a href="https://sympa.inria.fr/sympa/arc/compgeom-announce/2019-07/msg00006.html">Godfried Toussaint has died</a> (<a href="https://mathstodon.xyz/@11011110/102469388912273069"/>). Godfried “<a href="https://en.wikipedia.org/wiki/Godfried_Toussaint">is considered to be the father of computational geometry in Canada</a>”. This comes as a bit of a shock to me as he seemed healthy enough when I saw him last spring in Barbados. For more, see <a href="https://godfriedtoussaint.blogspot.com/">his memorial web site</a>.</p>
  </li>
  <li>
    <p><a href="https://www.chronicle.com/article/How-Should-Professors-Cite/246675">How should academics cite their transgender colleagues’ work produced under past identities?</a> (<a href="https://mathstodon.xyz/@11011110/102478166860077268"/>).    This article has more questions than answers but the advice at the end (when in doubt, ask them what they prefer) seems like a good idea.</p>
  </li>
  <li>
    <p><em><a href="https://archive.org/details/LesElementsDeLArtArabeBourgoin/page/n1">Les Éléments de l’Art Arabe</a></em> (<a href="https://mathstodon.xyz/@11011110/102482369062908993"/>, <a href="https://www.metafilter.com/181967/geometry-and-ornament-in-Islamic-architecture">via</a>). Lots of plates of pretty geometric girih patterns, from an 1879 book by Jules Bourgoin.</p>
  </li>
  <li>
    <p><a href="https://doi.org/10.1016/j.respol.2018.04.013">A walk on the wild side: Predatory journals and information asymmetries in scientific evaluations</a> (<a href="https://mathstodon.xyz/@11011110/102489353679943016"/>, <a href="https://ideas.repec.org/a/eee/respol/v48y2019i2p462-477.html">non-paywalled version</a>, <a href="https://www.openaccessrepository.it/record/23448">talk slides</a>). A study of which Italian researchers use predatory journals, why, and how prevalent they are. One conclusion surprised me: 40% of Scopus-listed journals show symptoms of being predatory. See also <a href="https://en.wikipedia.org/wiki/Wikipedia:WikiProject_Academic_Journals/Journals_cited_by_Wikipedia/Questionable1">a list of dubious journals aimed at helping Wikipedia editors identify bad sources</a>.</p>
  </li>
  <li>
    <p><a href="https://gilkalai.wordpress.com/2019/07/09/imre-barany-limit-shape/">Limit shapes and affine perimeters</a> (<a href="https://mathstodon.xyz/@11011110/102495315622469118"/>), guest post on Gil Kalai’s blog by Imre Bárány. The affine perimeter of a convex curve is an affine-equivariant number in units of length, zero for polygons and larger for smooth curves. And the limit shape of a convex set is what you get by taking a uniformly random convex subset of a grid within the set, in the limit as the grid becomes very fine; it turns out to be the max-affine-perimeter curve contained in the set.</p>
  </li>
  <li>
    <p><a href="https://blog.bonnieeisenman.com/projects/clojure-puzzles/">Voronoi diagrams + irregular line segment replacement curves + Clojure + SVG + laser cutter = jigsaw puzzles</a> (<a href="https://mathstodon.xyz/@11011110/102506299092731515"/>, <a href="https://news.ycombinator.com/item?id=20531861">via</a>).</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1906.11808">Non-concentration of the chromatic number of a random graph</a> (<a href="https://mathstodon.xyz/@11011110/102512091234238124"/>, <a href="ttps://gilkalai.wordpress.com/2019/06/28/another-sensation-annika-heckel-non-concentration-of-the-chromatic-number-of-a-random-graph/">via</a>).
<a href="https://doi.org/10.1007/BF02579208">Shamir &amp; Spencer ‘87</a> and <a href="https://doi.org/10.1007/10.1007/BF01215914">Alon &amp; Krivelevich ‘97</a> proved that random graphs  with  have almost surely only two possible chromatic numbers. But now Annika Heckel has shown that dense random graphs have a significantly wider spread in colors.</p>
  </li>
  <li>
    <p><a href="https://medium.com/open-glam/the-great-wave-what-hokusais-masterpiece-tells-us-about-museums-copyright-and-online-da0f25bd4ed2">The Great Wave: what Hokusai’s masterpiece tells us about museums, copyright and online collections today</a> (<a href="https://mathstodon.xyz/@11011110/102516638326312168"/>, <a href="https://www.metafilter.com/182234/The-Great-Save">via</a>). An interesting comparison of different museum policies on re-use of images of their artworks, and availability of high-resolution images, when the art itself is old enough to be out of copyright but photos of the art might still be copyrighted depending on different national laws. The Library of Congress and Rijksmuseum get high marks.</p>
  </li>
  <li>
    <p><a href="http://www.mathamaze.co.uk/artwork/">Helena Verrill’s mathematical/geometric art</a> (<a href="https://mathstodon.xyz/@11011110/102534506175667851"/>), mostly involving arrangements of circles.</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1907.13086">Atomic embeddability, clustered planarity, and thickenability</a> (<a href="https://mathstodon.xyz/@11011110/102537368093048271"/>). Rado Fulek and Csaba Tóth announce a polynomial time algorithm for <a href="https://en.wikipedia.org/wiki/Clustered_planarity">clustered planarity</a> (given a graph and a hierarchical clustering of its vertices, draw the graph planarly with clusters as simple closed curves and no unnecessary cluster-edge crossings). If this holds up, it’s big: the problem has been open since 1995 and a lot of people have worked on it with only modest progress until now.</p>
  </li>
</ul></div>
    </content>
    <updated>2019-07-31T23:16:00Z</updated>
    <published>2019-07-31T23:16:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-08-07T23:31:12Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=17714</id>
    <link href="https://gilkalai.wordpress.com/2019/08/01/an-interview-with-noga-alon/" rel="alternate" type="text/html"/>
    <title>An interview with Noga Alon</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Update: and here is a great interview of Noga in English and the interviewer is Narkis Alon, Noga’s youngest daughter and Amalya Duek. I was very happy to interview my academic doctoral  twin and long-time friend Noga Alon.  The interview … <a href="https://gilkalai.wordpress.com/2019/08/01/an-interview-with-noga-alon/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><strong>Update</strong>: and here is a <a href="http://www.careeryoga.life/440ebcdf?fbclid=IwAR2BWeyMdhTg2fbdHp5U-D9gCy2oqLZBk2ljRBMhjtyAEtSgqBCt7kMlSFk">great interview</a> of Noga in English and the interviewer is Narkis Alon, Noga’s youngest daughter and Amalya Duek.</p>
<p>I was very happy to interview my academic doctoral  twin and long-time friend Noga Alon.  <a href="https://youtu.be/9PhckP9eJhg">The interview</a> is an initiative of the Israel Academy of Sciences and Humanities. (This is my second interview of this kind. See <a href="https://gilkalai.wordpress.com/2018/06/15/an-interview-with-yisrael-robert-aumann/">here</a> for an interview with Yisrael Aumann.) The interview is in Hebrew. (Update: Automatically-produced  English subtitles are available.)</p>
<p/>
<p>For our English speaking readers here is a recent <a href="https://youtu.be/rwiEiGqgetU">Numberphile video</a> with Noga.</p>
<p>We agreed in advance that most of the interview would be about mathematics, and  most of the time  we courageously (and perhaps somewhat recklessly)  tried to explain to a large audience  (starting from scratch) some of Noga’s research directions and results. We hope that people will enjoy the beauty of it even with the missing details and background.</p>
<h3>Noga’s parents, family and childhood</h3>
<p>In the first part of the  interview  Noga talked about his family, his parents, Dror and Hemda, his great uncle <a href="https://en.wikipedia.org/wiki/Yigal_Allon">Yigal Alon</a>, his early childhood, and his early interest in mathematics. Noga liked to solve mathematical riddles from a young age. One reason Noga was drawn to mathematics is that unlike other topics, in mathematics there are absolute truths, and a mathematical proof (when such exists)  is perhaps the only way you can settle a debate. Noga gave an amusing example from his youth regarding the Eurovision song context. Then he mentioned the <a href="https://www.reali.org.il/en/%d7%9e%d7%90%d7%94-%d7%a9%d7%a0%d7%95%d7%aa-%d7%a8%d7%99%d7%90%d7%9c%d7%99/">Hebrew Reali school in Haifa</a>, a mathematics teacher there, Yaakov Kaplan,  newly immigrated from the former Soviet Union, who greatly influenced Noga. Noga also talked about his participation in the Israeli Mathematical Olympiad where the two of us first met 45 years ago.  Next, the two of us met during our military service, and in parallel to his service, Noga finished his M. Sc. and Ph. D with Micha A. Perles, who was also my supervisor.</p>
<h3>An hour of mathematics</h3>
<p>The mathematical part of the video starts with Noga’s  overview of combinatorics. Then we moved to specific topics.</p>
<p>(22:40- 33:30) Noga’s negative solution to Shannon’s conjecture about the capacity of two graphs (and a little about Claude Shannon and information theory)</p>
<p>(33:30- 40:25) The combinatorial nullstellensatz and the polynomial method and a little about the game SET</p>
<p>(40:25 – 46:50) The probabilistic method and a little on the history of probability and about Paul Erdos.</p>
<p>(46:50-  54:50)  Streaming algorithms, a topic introduced by Noga Alon, Yossi Matias, and Mario Szegedy, and more generally, about positive and negative results in computer science, and their practical applications.</p>
<p>(54:50 – 59:25)    Expander graphs and “spectroscopy of graphs”</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/07/noga1.png"><img alt="" class="alignnone size-large wp-image-17717" height="326" src="https://gilkalai.files.wordpress.com/2019/07/noga1.png?w=640&amp;h=326" width="640"/></a></p>
<p>59:25  -1:05:40 Ramsey theory</p>
<p>1:05:40-1:12:20 Factoring integers with quantum computers and with classical methods</p>
<p>1:12:00-1:20:00 Combinatorics, economics and game theory:  Noga’s theorem that large committees require a large budget!</p>
<h3>Going back from mathematics to life itself</h3>
<p>After a full hour of mathematics, we returned to life itself. Memories from our years as postdocs at MIT, and our 1993 conference in Jerusalem. Noga talked a little about women in science and in society, about his three daughters, about  the possibility that science, like sport,  can bridge different groups and different peoples, and about politics and prospects for better relations with our Arab neighbors and Iran (Noga is somewhat optimistic and so am I),  prospects about getting old (we are hopeful about it), and advice to young researchers. Noga’s message at the end was that there are many paths to mathematical research and he encouraged young people that like mathematics to follow and enjoy them.</p>
<p> </p>
<p><a href="https://gilkalai.files.wordpress.com/2019/07/alon-ramsey1.png"><img alt="" class="alignnone size-medium wp-image-17740" height="266" src="https://gilkalai.files.wordpress.com/2019/07/alon-ramsey1.png?w=300&amp;h=266" width="300"/>  </a><a href="https://gilkalai.files.wordpress.com/2019/07/alon-ramsey2.png"><img alt="" class="alignnone size-medium wp-image-17737" height="275" src="https://gilkalai.files.wordpress.com/2019/07/alon-ramsey2.png?w=300&amp;h=275" width="300"/></a></p>
<p> </p>
<p><a href="https://gilkalai.files.wordpress.com/2019/07/alon-ramsey3.png"><img alt="" class="alignnone size-medium wp-image-17738" height="204" src="https://gilkalai.files.wordpress.com/2019/07/alon-ramsey3.png?w=300&amp;h=204" width="300"/></a></p>
<p><span style="color: #ff0000;">Ramsey theory and a conjecture by Erdos and Sos</span></p>
<p><a href="https://gilkalai.files.wordpress.com/2019/07/alon-prob-1.png"><img alt="" class="alignnone size-large wp-image-17743" height="272" src="https://gilkalai.files.wordpress.com/2019/07/alon-prob-1.png?w=640&amp;h=272" width="640"/></a></p>
<p><span style="color: #ff0000;">Probability theory and the probabilistic method</span></p>
<p><span id="more-17714"/></p>
<p><a href="https://gilkalai.files.wordpress.com/2019/07/noga3.png"><img alt="" class="alignnone size-medium wp-image-17718" height="195" src="https://gilkalai.files.wordpress.com/2019/07/noga3.png?w=300&amp;h=195" width="300"/>  </a><a href="https://gilkalai.files.wordpress.com/2019/07/noga2.png"><img alt="" class="alignnone size-medium wp-image-17720" height="148" src="https://gilkalai.files.wordpress.com/2019/07/noga2.png?w=300&amp;h=148" width="300"/></a></p>
<p> </p>
<p><a href="https://gilkalai.files.wordpress.com/2019/07/noga4.png"><img alt="" class="alignnone size-large wp-image-17722" height="311" src="https://gilkalai.files.wordpress.com/2019/07/noga4.png?w=640&amp;h=311" width="640"/></a></p>
<p><span style="color: #ff0000;">Pictures from our late twenties and a conversation about getting old.</span></p>
<p><a href="https://gilkalai.files.wordpress.com/2019/07/noga5.png"><img alt="" class="alignnone size-medium wp-image-17723" height="186" src="https://gilkalai.files.wordpress.com/2019/07/noga5.png?w=300&amp;h=186" width="300"/>   </a><a href="https://gilkalai.files.wordpress.com/2019/07/noga6.png"><img alt="" class="alignnone size-medium wp-image-17725" height="154" src="https://gilkalai.files.wordpress.com/2019/07/noga6.png?w=300&amp;h=154" width="300"/></a></p>
<p><span style="color: #ff0000;">Some advice to the young</span></p>
<p> </p>
<p><a href="https://gilkalai.files.wordpress.com/2019/08/alon-ramsey4.png"><img alt="" class="alignnone size-large wp-image-17780" height="370" src="https://gilkalai.files.wordpress.com/2019/08/alon-ramsey4.png?w=640&amp;h=370" width="640"/></a></p>
<p><span style="color: #ff0000;">Added later: As it turns out You tube has automatic translation to English which is reasonable. It does translate “Noga” to “Venus”.</span></p>
<p> </p>
<p/></div>
    </content>
    <updated>2019-07-31T21:09:15Z</updated>
    <published>2019-07-31T21:09:15Z</published>
    <category term="Combinatorics"/>
    <category term="Computer Science and Optimization"/>
    <category term="People"/>
    <category term="Noga Alon"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-08-09T16:20:37Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/100</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/100" rel="alternate" type="text/html"/>
    <title>TR19-100 |  Nonnegative rank measures and monotone algebraic branching programs | 

	Hervé Fournier, 

	Guillaume Malod, 

	Maud Szusterman, 

	Sébastien Tavenas</title>
    <summary>Inspired by Nisan's characterization of noncommutative complexity (Nisan 1991), we study different notions of nonnegative rank, associated complexity measures and their link with monotone computations. In particular we answer negatively an open question of Nisan asking whether nonnegative rank characterizes monotone noncommutative complexity for algebraic branching programs. We also prove a rather tight lower bound for the computation of elementary symmetric polynomials by algebraic branching programs in the monotone setting or, equivalently, in the homogeneous syntactically multilinear setting.</summary>
    <updated>2019-07-31T16:19:30Z</updated>
    <published>2019-07-31T16:19:30Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-08-09T16:20:32Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://adamsheffer.wordpress.com/?p=5424</id>
    <link href="https://adamsheffer.wordpress.com/2019/07/31/updates/" rel="alternate" type="text/html"/>
    <title>Updates</title>
    <summary>I did not post anything for almost five months – life has been very busy lately! I hope to get back to posting regularly relatively soon. In the meantime, I wanted to at least have a brief updates post. I just made a revision of my book about incidences and polynomial methods. Joshua Zahl and […]</summary>
    <updated>2019-07-31T02:25:50Z</updated>
    <published>2019-07-31T02:25:50Z</published>
    <category term="Incidences"/>
    <category term="Math events"/>
    <author>
      <name>Adam Sheffer</name>
    </author>
    <source>
      <id>https://adamsheffer.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://adamsheffer.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://adamsheffer.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://adamsheffer.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://adamsheffer.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Discrete geometry and other typos</subtitle>
      <title>Some Plane Truths</title>
      <updated>2019-08-09T16:21:29Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4278</id>
    <link href="https://www.scottaaronson.com/blog/?p=4278" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4278#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4278" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Links, proofs, talks, jokes</title>
    <summary xml:lang="en-US">For those who haven’t yet seen it, Erica Klarreich has a wonderful article in Quanta on Hao Huang’s proof of the Sensitivity Conjecture. This is how good popular writing about math can be. Klarreich quotes my line from this blog, “I find it hard to imagine that even God knows how to prove the Sensitivity […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>For those who haven’t yet seen it, Erica Klarreich has a <a href="https://www.quantamagazine.org/mathematician-solves-computer-science-conjecture-in-two-pages-20190725/">wonderful article in </a><em><a href="https://www.quantamagazine.org/mathematician-solves-computer-science-conjecture-in-two-pages-20190725/">Quanta</a></em> on Hao Huang’s proof of the Sensitivity Conjecture.  <em>This</em> is how good popular writing about math can be.</p>



<p>Klarreich quotes my line from this blog, “I find it hard to imagine that even God knows how to prove the Sensitivity Conjecture in any simpler way than this.”  However, even if God doesn’t know a simpler proof, that of course doesn’t rule out the possibility that <strong>Don Knuth</strong> does!  And indeed, a couple days ago Knuth posted <a href="https://www.cs.stanford.edu/~knuth/papers/huang.pdf">his own variant of Huang’s proof</a> on his homepage—in Knuth’s words, fleshing out the <a href="https://www.scottaaronson.com/blog/?p=4229#comment-1813084">argument</a> that Shalev Ben-David previously posted on this blog—and then left a <a href="https://www.scottaaronson.com/blog/?p=4229#comment-1815290">comment</a> about it here, the first comment by Knuth that I know about on this blog or any other blog.  I’m honored—although as for whether the variants that avoid the Cauchy Interlacing Theorem are actually “simpler,” I guess I’ll leave that between Huang, Ben-David, Knuth, and God.</p>



<p>In <em>Communications of the ACM</em>, Samuel Greengard has a <a href="https://cacm.acm.org/magazines/2019/8/238339-the-algorithm-that-changed-quantum-machine-learning/fulltext?mobile=false">good, detailed article</a> on Ewin Tang and her dequantization of the quantum recommendation systems algorithm.  One warning (with thanks to commenter Ted): the sentence “The only known provable separation theorem between quantum and classical is sqrt(<em>n</em>) vs. <em>n</em>” is mistaken, though it gestures in the direction of a truth.  In the <em>black-box</em> setting, we can rigorously prove all sorts of separations: sqrt(<em>n</em>) vs. <em>n</em> (for Grover search), exponential (for period-finding), and more.  In the non-black-box setting, we can’t prove any such separations at all.</p>



<p>Last week I returned to the US from the <a href="https://fqxi.org/conference/home/2019">FQXi meeting</a> in the Tuscan countryside.  This year’s theme was “Mind Matters: Intelligence and Agency in the Physical World.”  I gave a talk entitled “The Search for Physical Correlates of Consciousness: Lessons from the Failure of Integrated Information Theory” (<a href="https://www.scottaaronson.com/talks/iitfail.ppt">PowerPoint slides here</a>), which reprised my <a href="https://www.scottaaronson.com/blog/?p=1799">blog</a> <a href="https://www.scottaaronson.com/blog/?p=1823">posts</a> critical of IIT from five years ago.  There were thought-provoking talks by many others who might be known to readers of this blog, including Sean Carroll, David Chalmers, Max Tegmark, Seth Lloyd, Carlo Rovelli, Karl Friston … you can see the full schedule <a href="https://fqxi.org/conference/schedule/2019">here</a>.  Apparently video of the talks is not available yet but will be soon.</p>



<p>Let me close this post by sharing two important new insights about quantum mechanics that emerged from my conversations at the FQXi meeting:</p>



<p>(1) In Hilbert space, no one can hear you scream. Unless, that is, you scream the exact same way everywhere, or unless you split into separate copies, one for each different way of screaming.</p>



<p>(2) It’s true that, as a matter of logic, the <a href="https://en.wikipedia.org/wiki/Schr%C3%B6dinger_equation">Schrödinger equation</a> does not imply the <a href="https://en.wikipedia.org/wiki/Born_rule">Born Rule</a>.  Having said that, if the Schrödinger equation were leading a rally, and the crowd started a chant of “BORN RULE! BORN RULE! BORN RULE!”—the Schrödinger equation would just smile and wait 13 seconds for the chant to die down before continuing.</p></div>
    </content>
    <updated>2019-07-30T14:15:03Z</updated>
    <published>2019-07-30T14:15:03Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Announcements"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Complexity"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Quantum"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2019-07-31T11:08:23Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/07/29/zipless-polycube</id>
    <link href="https://11011110.github.io/blog/2019/07/29/zipless-polycube.html" rel="alternate" type="text/html"/>
    <title>A zipless polycube</title>
    <summary>My latest arXiv preprint is “Some polycubes have no edge-unzipping” (arXiv:1907.08433, with Erik and Marty Demaine and Joe O’Rourke). It’s about polyhedral unfolding, the problem of cutting a polyhedron along some of its edges into a surface that unfolds into a flat polygon in the plane (a “net”). Although it dates back to the work of Albrecht Dürer, we still don’t know a lot about this problem, in general. We don’t know whether every convex polyhedron has an unfolding, and we don’t know whether every polycube has a folding (allowing cuts in the middle of flat faces as long as they are on boundary edges of the cubes making up the polycube).</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>My latest arXiv preprint is “Some polycubes have no edge-unzipping” (<a href="https://arxiv.org/abs/1907.08433">arXiv:1907.08433</a>, with Erik and Marty Demaine and Joe O’Rourke). It’s about <a href="https://en.wikipedia.org/wiki/Net_(polyhedron)">polyhedral unfolding</a>, the problem of cutting a polyhedron along some of its edges into a surface that unfolds into a flat polygon in the plane (a “net”). Although it dates back to the work of Albrecht Dürer, we still don’t know a lot about this problem, in general. We don’t know whether every convex polyhedron has an unfolding, and we don’t know whether every polycube has a folding (allowing cuts in the middle of flat faces as long as they are on boundary edges of the cubes making up the polycube).</p>

<p>The preprint is about a variation of unfolding in which the cut has to form a path through the graph of vertices and edges. If the polyhedron has the topology of a sphere and there are no flat vertices (with a full  total angle of surrounding faces) then all vertices must be touched by a cut, and it’s the same thing to ask for an unfolding that forms a Hamiltonian path. These zipper-unfoldings have previously been studied, notably in joint work by two parent-child groups, <a href="https://11011110.github.io/blog/2010/08/12/more-from-cccg.html">Marty and his son Erik, and Anna Lubiw and her two sons Arlo and Jonah from CCCG 2010</a>. The new preprint shows that they don’t always exist for (topologically spherical) polycubes. In particular, the following shape has no flat vertices, but its graph is bipartite and unbalanced enough that it also has no Hamiltonian path.</p>

<p style="text-align: center;"><img alt="A zipless polycube" src="https://11011110.github.io/blog/assets/2019/zipless.png"/></p>

<p>It does have an unfolding, though (figure made by Erik using <a href="https://github.com/amandaghassaei/OrigamiSimulator">OrigamiSimulator</a>):</p>

<p style="text-align: center;"><img alt="Unfolding a zipless polycube" src="https://11011110.github.io/blog/assets/2019/zipless.gif"/></p>

<p>The paper also has a smaller example that’s a little tricker to prove zipless. It’s a small enough advance that we probably won’t bother trying to turn it into a conference or journal paper. (If it were just me, I’d probably have just made a blog post about it. And here we are!)</p>

<p>(<a href="https://mathstodon.xyz/@11011110/102528987575312068">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2019-07-29T23:11:00Z</updated>
    <published>2019-07-29T23:11:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-08-07T23:31:12Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/099</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/099" rel="alternate" type="text/html"/>
    <title>TR19-099 |  Nearly Optimal Pseudorandomness From Hardness | 

	Dean Doron, 

	David Zuckerman, 

	Dana Moshkovitz, 

	Justin Oh</title>
    <summary>Existing proofs that deduce $\mathbf{BPP}=\mathbf{P}$ from circuit lower bounds convert randomized algorithms into deterministic algorithms with a large polynomial slowdown. We convert randomized algorithms into deterministic ones with little slowdown. Specifically, assuming exponential lower bounds against nondeterministic circuits, we convert any randomized algorithm over inputs of length $n$ running in time $t \ge n$ to a deterministic one running in time $t^{2+\alpha}$ for an arbitrarily small constant $\alpha &gt; 0$. Such a slowdown is nearly optimal, as, under complexity-theoretic assumptions, there are problems with an inherent quadratic derandomization slowdown. We also convert any randomized algorithm that errs rarely into a deterministic algorithm having a similar running time (with pre-processing).

Our results follow from a new, nearly optimal, explicit pseudorandom generator fooling circuits of size $s$ with seed length $(1+\alpha)\log s$, under the assumption that there exists a function $f \in \mathbf{E}$ that requires nondeterministic circuits of size at least $2^{(1-\alpha')n}$, where $\alpha = O(\alpha')$. The construction uses, among other ideas, a new connection between pseudoentropy generators and locally list recoverable codes.</summary>
    <updated>2019-07-29T19:55:04Z</updated>
    <published>2019-07-29T19:55:04Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-08-09T16:20:32Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-5104220537083628124</id>
    <link href="https://blog.computationalcomplexity.org/feeds/5104220537083628124/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/07/turing-to-be-on-bank-of-england-50.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/5104220537083628124" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/5104220537083628124" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/07/turing-to-be-on-bank-of-england-50.html" rel="alternate" type="text/html"/>
    <title>Turing to be on the Bank of England 50 pound note, giving me an excuse to talk about Turing</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">BILL: Darling, guess who is soon going to be on the Bank of England 50 pound note?<br/>
<br/>
DARLING: Alan Turing. <br/>
<br/>
BILL: How did you deduce that? (She is right, see  <a href="https://www.bbc.com/news/business-48962557">here</a>.)<br/>
<br/>
DARLING: Since you asked it, it couldn't be a member of the Royal Family (you don't care about that) or some British Politician (you don't care about that either). It had to be a mathematician or computer scientist.<br/>
<br/>
BILL: It could have been Hardy. I wonder if Ramanujan could qualify---do they need to be British? At <a href="https://www.bankofengland.co.uk/banknotes/banknote-characters">this website</a> it says<br/>
<br/>
<br/>
<br/>
<i>Of course, banknotes need to be universally accepted. We therefore look for UK characters who have made an important contribution to our society and culture through their innovation, leadership or values. We do not include fictional characters, or people who are still living (except the monarch on the front of the note). Finally, we need to have a suitable portrait of the person which will be easy to recognise.</i><br/>
<br/>
(They spell <i>recognise</i> with an s instead of a z, so spellcheck flagged it, but I won't change it.) <br/>
<br/>
Note that people on the banknotes have to be <i>UK characters</i>. I honestly don't know if that means they must be citizens.<br/>
<br/>
OKAY, so here are a few thoughts on Turing.<br/>
<br/>
1) When I visited Bletchley Park there was a booklet that bragged about the fact that Bletchley Park was much better at cracking codes than Germany because  they allowed people to work there based only on ability (unlike Germany) - women worked there, Turing who was Gay worked there. I think this is simplistic. Did any Jews work there (anti-semitism was widespread in England, and the world, at the time)? I doubt any blacks worked there since if they did that would be well known by now (if I am wrong let me know). Women DID work there but was their work respected and used? (I honestly don't know). Did Germany also use women at their codebreaking centers? Was Turing known to be gay (if not then Bletchley gets no points for tolerating him). Was JUST having Turing the reason they could crack codes. Plus I am sure there were other factors aside from merit-only.<br/>
<br/>
2) Turing was given a Pardon for his ``crimes'' in August 2014. When I see things like this I wonder who was against it and why and if they were an obstacle.<br/>
<br/>
a) Human Rights Advocate Peter Tatchell noted that its wrong to just single out Turing. Other people prosecuted under that law who did not help beat the German's in WW II should also be pardoned. The government later DID such a pardon in 2017.<br/>
<br/>
b) Judge Minister Lord McNally objected to the pardon:<br/>
<br/>
<i>A posthumous pardon was not considered appropriate as Alan Turing was properly convicted of what at the time was a criminal offence. He would have known that his offence was against the law and that he would be prosecuted. It is tragic that Alan Turing was convicted of an offence that now seems both cruel and absurd—particularly poignant given his outstanding contribution to the war effort. However, the law at the time required a prosecution and, as such, long-standing policy has been to accept that such convictions took place and, rather than trying to alter the historical context and to put right what cannot be put right, ensure instead that we never again return to those times.<br/>
</i><br/>
<br/>
While I disagree with him, I do note that, based on what he wrote and his general record, I think he is not saying this from being anti-gay.  There is  a hard general question here: how does a society right past wrongs? I think pardoning and apologizing is certainly fine, but frankly it seems to weak. What else could a society due? Financial renumeration to living relatives? I don't think giving Inagh Payne (Turing's niece, who I think is still alive) would really help here.<br/>
<br/>
c) <i>At the bill's second reading in the House of Commons on 29 November 2013, Conservative MP Christopher Chope objected to the bill, delaying its passage<br/>
</i><br/>
<br/>
I couldn't find Chope's reasons. On the one hand, they may be similar to McNally's. On the other hand he is against same sex marriage so its possible (though I do not know this) that he anti-gay and that is why he is against the pardon. If someone can find what his explanation for blocking the Turing bill is, or other evidence that he is anti-gay, please leave it in the comments.<br/>
<br/>
3) Did the delay matter? I was surprised to find out---Yes. Here is the full passage from Wikipedia:<br/>
<br/>
<br/>
<i>At the bill's second reading in the House of Commons on 29 November 2013, Conservative MP Christopher Chope objected to the bill, delaying its passage. The bill was due to return to the House of Commons on 28 February 2014,[175] but before the bill could be debated in the House of Commons,[176] the government elected to proceed under the royal prerogative of mercy. On 24 December 2013, Queen Elizabeth II signed a pardon for Turing's conviction for "gross indecency", with immediate effect.[17] Announcing the pardon, Lord Chancellor Chris Grayling said Turing deserved to be "remembered and recognised for his fantastic contribution to the war effort" and not for his later criminal conviction.[16][18] The Queen officially pronounced Turing pardoned in August 2014.[177] The Queen's action is only the fourth royal pardon granted since the conclusion of the Second World War.[178] Pardons are normally granted only when the person is technically innocent, and a request has been made by the family or other interested party; neither condition was met in regard to Turing's conviction.[179]</i><br/>
<br/>
This amazed me! I thought the Queen had NO power (too bad--- I wish she could just say NO BREXIT). Or that she formally has power but if she ever used it, it might be blocked somehow and  taken away. So I am surprised she has a power she can use at all.<br/>
<br/>
4) I wonder if the Pardon had to happen before they put him on the Banknote. I have been told that this is a very American Question--- England has no Constitution and operates more on Custom and Tradition than on written rules. <br/>
<br/>
5) I had always assumed that Turing committed suicide. Without going into detail, the Wikipedia site on Turing does give intelligent counterarguments to this. See <a href="https://en.wikipedia.org/wiki/Alan_Turing#Death">here</a><br/></div>
    </content>
    <updated>2019-07-29T00:46:00Z</updated>
    <published>2019-07-29T00:46:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-08-09T12:27:36Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/07/28/any-order-puzzle</id>
    <link href="https://11011110.github.io/blog/2019/07/28/any-order-puzzle.html" rel="alternate" type="text/html"/>
    <title>Any-order puzzle deduction</title>
    <summary>I recently wrote here about a complication in puzzle-solving where, in using deductive rules based on the assumption that the puzzle has a unique solution, the ordering of the rules could make a difference in how far you get in the solution. And avoiding this ordering issue by keeping track of more information than just the state of the partially solved puzzle leads to its own difficulties. It seemed like keeping this information could lose you in a maze of undecidable modal logic. For instance in the map coloring puzzle described in that post, we might record information about a partial solution like “I don’t know that this cell is forced to be red, but it is necessary for it to be red in order to prevent a non-unique solution”, with the complexity of these statements growing as the solution progressed. Instead, what I wanted was a way to make decisions without worrying about the order of deduction while only remembering a finite amount of state for each puzzle cell. In the ensuing discussion, @axiom suggested that the extra information should be the order of deductions. That’s not a constant amount of information per cell, but as we’ll see below it works to simplify this even more and remember only which cells were the initial givens and which were deduced later.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I recently wrote here about a complication in puzzle-solving where, in using deductive rules based on the assumption that the puzzle has a unique solution, <a href="https://11011110.github.io/blog/2019/06/07/little-knowledge-can.html">the ordering of the rules could make a difference in how far you get in the solution</a>. And avoiding this ordering issue by keeping track of more information than just the state of the partially solved puzzle leads to its own difficulties. It seemed like keeping this information could lose you in a maze of undecidable <a href="https://11011110.github.io/blog/2019/07/13/connectivity-finiteness-modal.html">modal logic</a>. For instance in the map coloring puzzle described in that post, we might record information about a partial solution like “I don’t know that this cell is forced to be red, but it is necessary for it to be red in order to prevent a non-unique solution”, with the complexity of these statements growing as the solution progressed. Instead, what I wanted was a way to make decisions without worrying about the order of deduction while only remembering a finite amount of state for each puzzle cell. In <a href="https://mathstodon.xyz/@11011110/102234384857906663">the ensuing discussion</a>, @axiom suggested that the extra information should be the order of deductions.
That’s not a constant amount of information per cell, but as we’ll see below it works to simplify this even more and remember only which cells were the initial givens and which were deduced later.</p>

<p>To clarify the intuition that deduction order should not matter, I want to formalize the state of a partially-solved puzzle as a collection of bits, initially all true. In map coloring, each bit could represent the possibility that a given cell is a particular color, and we want to eventually have one true bit per cell and the rest false. A deduction is a change to a single bit. Each deduction is triggered by a rule, which typically searches for certain patterns in the state. For instance, in map coloring, the pattern that one cell has only one remaining color whose bit is true can trigger the deduction that the same color’s bit in a neighboring cell must be false. Any given deduction could be triggered by more than one rule, or by more than one instance of the same rule. Then these rules and deductions should obey some natural properties:</p>

<ul>
  <li>
    <p>The deductions can only go in one direction. If we deduce that a bit is false, we won’t later change it back to true.</p>
  </li>
  <li>
    <p>The deductions are always valid for the intended puzzle. That is, when a puzzle has a unique solution, we won’t ever deduce anything inconsistent with that solution. (However, when that assumption is violated, anything can happen.)</p>
  </li>
  <li>
    <p>It should be possible to efficiently identify all deductions that can be triggered from the current state. Ideally this should take polynomial time.</p>
  </li>
  <li>
    <p>If a deduction is triggered by one of the rules, it remains triggered until that deduction step is performed.</p>
  </li>
</ul>

<p>I’m not assuming that the deduction system is complete, i.e., that it will  reach the intended puzzle solution for all puzzles. For most natural puzzle types and most efficiently-searchable sets of deduction rules, it won’t be complete, and most likely (because of NP-completeness or related complexity issues) cannot be both complete and efficiently searchable. But nevertheless, a system of rules obeying these properties always reaches a unique state, independent of deduction order. It is the last of these properties that enforces this order-invariance. By induction on the values in the triggering patterns, each deduction that could be made by some order of deduction steps will eventually be made by a greedy algorithm that chooses deductions in an arbitrary order until it gets stuck.</p>

<p>The “remains triggered until performed” criterion should sound familiar. It is the defining property of an <a href="https://en.wikipedia.org/wiki/Antimatroid">antimatroid</a>, a collection of orderings of items (here, orderings of deductions that could be made by the greedy algorithm) with the property that once an item becomes available to be added to an ordering, it remains available until it actually is added. The antimatroid name is a bit technical and off-putting, but these structures come up all the time in many different applications. I’ve written here about
<a href="https://11011110.github.io/blog/2006/06/18/reverse-search-for.html">listing all small antimatroids</a>, <a href="https://11011110.github.io/blog/2006/07/20/upright-quad-drawing.html">visualizing their structure</a>, <a href="https://11011110.github.io/blog/2006/08/30/antimatroids-as-algebras.html">algebraic axiomatization</a>, <a href="https://11011110.github.io/blog/2007/02/18/pruning-antimatroids-is.html">hardness of finding weighted feasible sets</a>, the <a href="https://11011110.github.io/blog/2007/02/20/two-partial-cubes.html">swap structure on orderings</a>, <a href="https://11011110.github.io/blog/2011/11/16/which-infinite-graphs.html">infinite antimatroids</a>, <a href="https://11011110.github.io/blog/2013/02/25/antimatroids-and-balanced.html">informative comparisons</a>, <a href="https://11011110.github.io/blog/2015/03/05/nearest-neighbor-in.html">nearest neighbors</a>, and the applications of antimatroids to <a href="https://11011110.github.io/blog/2007/02/17/shelling-and-pseudotriangulation.html">pseudotriangulation</a>, <a href="https://11011110.github.io/blog/2007/12/29/formal-knot-theory.html">knot theory</a>, <a href="https://11011110.github.io/blog/2008/03/30/how-to-implement.html">computerized education</a>, <a href="https://11011110.github.io/blog/2008/12/02/parts-assembly-and.html">parts assembly</a>, <a href="https://11011110.github.io/blog/2009/01/30/antimatroids-from-sorting.html">sorting networks</a>, <a href="https://11011110.github.io/blog/2013/10/26/rhyme-scheme-antimatroid.html">rhyme schemes</a>, <a href="https://11011110.github.io/blog/2016/04/17/local-and-inductive.html">hereditary graph properties</a>, <a href="https://11011110.github.io/blog/2017/01/17/course-prerequisites-are.html">course prerequisites</a>, and <a href="https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors.html">hierarchical clustering</a>. So why not add puzzle deduction to the list?</p>

<p>A nice side-effect of using deduction rules with these properties is that, if the rules are ordered by difficulty, then a greedy algorithm that always chooses the easiest rule at each step will automatically find a deduction sequence minimizing the difficulty of the hardest rule that it uses. This can be helpful in <a href="http://arxiv.org/abs/cs.DS/0507053">using deduction algorithms to automatically estimate the difficulty of a puzzle for a human solver</a>.</p>

<p>A natural way to achieve the “remains triggered until performed” property for a deduction rule is to use a pattern in the form of a monotonic Boolean combination of state bits (a function that can be expressed using only Boolean and and or operations, without negation) and to trigger a deduction when that combination becomes false. In this way, we achieve a stronger property, that once triggered the deduction remains triggered forever (even after it has already been performed). But as we’ll see below, other kinds of rules can also have the same property.</p>

<p>Now back to map coloring.</p>

<p>We saw in <a href="https://11011110.github.io/blog/2019/06/07/little-knowledge-can.html">my earlier post</a> that it doesn’t work well to use rules like “if one cell has already-colored neighbors of two colors, and only one uncolored neighbor, then that neighbor cannot be either of the same two colors”. These rules are valid (under the assumption that the puzzle solution is unique) but lose information about why the deduction on the neighboring vertex was made, preventing later deductions from being made.</p>

<p>Instead, the insight I ended up using involves <a href="https://en.wikipedia.org/wiki/Kempe_chain">Kempe chains</a>. A Kempe chain, in a colored map, is a maximal connected subset of the cells of two of the colors. If the coloring is to be unique, every Kempe chain must be anchored by one of the original givens of the puzzle, for otherwise we could swap the two colors in the chain without affecting the rest of the graph. So, I’ve started using rules of the form “if this Kempe chain in the partially colored map is not yet anchored, and can reach an anchor only by extending through this other cell, then that cell cannot be a third color”. Here, the Kempe chains that I examine to trigger this rule are maximal connected subsets of the cells whose colors are limited to some set of two colors, allowing cells that are already known to have only one of those two colors. Until we add the extension cell to the chain, the same rule will continue to be triggered, so this passes the any-order requirements above.</p>

<p>This deduction method also fits well into the visualization tools available for manual puzzle-solving in <a href="https://www.chiark.greenend.org.uk/~sgtatham/puzzles/">Simon Tatham’s puzzle collection</a>, where I found the map puzzle. This collection’s implementation of the map puzzle shows the givens and solved cells as solid colors, and allows unsolved cells to be marked by dots of any combination of the four colors. So I’ve been using these dots to indicate the remaining colors available for each cell, in cases when the deductions get complicated enough that I can’t just remember them without marking them. A cell that has dots of only one color rather than a solid color is effectively solved (we know what color it is going to end up being) but might still belong to some unanchored Kempe chains. Once all three Kempe chains through a cell of known color have been anchored, I color that cell as solid. In this way, the parts of the solution that might include unanchored Kempe chains typically remain small and distinctively colored, making the chains easy to spot.</p>

<p style="text-align: center;"><img alt="Screenshot of the map puzzle from Simon Tatham's puzzle collection" src="https://11011110.github.io/blog/assets/2019/map-puzzle-kempe-chain.png"/></p>

<p>The image above shows an example, from one of the hardest built-in difficulty levels of the puzzle (“20x15, 30 regions, Unreasonable”). An orange-brown Kempe chain can be seen in the bottom left, in the two cells colored by orange and brown dots. (Yes, I know these two colors are hard to tell apart; I can’t change them.) Its only escape cell has yellow and brown neighbors, and cannot be green (leaving the orange-brown chain unanchored), so it must be orange. This set of deductions allows us in turn to infer the colors of the other two cells in the chain, and to make them solid (their three Kempe chains all become anchored). The orange escape cell becomes dotted rather than solid, because it is part of a different Kempe chain (colored orange-green) that remains unanchored.</p>

<p style="text-align: center;"><img alt="Screenshot of the map puzzle from Simon Tatham's puzzle collection" src="https://11011110.github.io/blog/assets/2019/map-puzzle-kempe-chain-2.png"/></p>

<p>This extended deduction rule seems to be working well for the puzzles I’ve tried it on. And by obeying the requirement that deductions remain triggered until performed, it gives me confidence that I’m not hiding any usable information by doing my deductions in the wrong order. There is no wrong order: any order in which I make my deductions will eventually lead me to the same state.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/102521934491138847">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2019-07-28T17:19:00Z</updated>
    <published>2019-07-28T17:19:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-08-07T23:31:12Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/098</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/098" rel="alternate" type="text/html"/>
    <title>TR19-098 |  Domain Compression and its Application to Randomness-Optimal Distributed Goodness-of-Fit | 

	Clement Canonne, 

	Jayadev Acharya, 

	Himanshu Tyagi, 

	Ziteng Sun, 

	Yanjun Han</title>
    <summary>We study goodness-of-fit of discrete distributions in the distributed setting, where samples are divided between multiple users who can only release a limited amount of information about their samples due to various information constraints. Recently, a subset of the authors showed that having access to a common random seed (i.e., shared randomness) leads to a significant reduction in the sample complexity of this problem. In this work, we provide a complete understanding of the interplay between the amount of shared randomness available, the stringency of information constraints, and the sample complexity of the testing problem by characterizing a tight trade-off between these three parameters. We provide a general distributed goodness-of-fit protocol that as a function of the amount of shared randomness interpolates smoothly between the private- and public-coin sample complexities. We complement our upper bound with a general framework to prove lower bounds on the sample complexity of this testing problems under limited shared randomness. Finally, we instantiate our bounds for the two archetypal information constraints of communication and local privacy, and show that our sample complexity bounds are optimal as a function of all the parameters of the problem, including the amount of shared randomness.

A key component of our upper bounds is a new primitive of domain compression, a tool that allows us to map distributions to a much smaller domain size while preserving their pairwise distances, using a limited amount of randomness.</summary>
    <updated>2019-07-28T10:17:48Z</updated>
    <published>2019-07-28T10:17:48Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-08-09T16:20:32Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://lucatrevisan.wordpress.com/?p=4251</id>
    <link href="https://lucatrevisan.wordpress.com/2019/07/27/three-stories-about-u-c-administration/" rel="alternate" type="text/html"/>
    <title>Three stories about U.C. administration</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">A few months ago, I was delighted to see the University of California holding on to its demands in its negotiations with Elsevier. The U.C. wanted to renegotiate its contract so that, in addition to having access to the subscribed … <a href="https://lucatrevisan.wordpress.com/2019/07/27/three-stories-about-u-c-administration/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>A few months ago, I was delighted to see the University of California <a href="https://www.theatlantic.com/science/archive/2019/03/uc-elsevier-publisher/583909/">holding on to its demands</a> in its negotiations with Elsevier. The U.C. wanted to renegotiate its contract so that, in addition to having access to the subscribed journals, U.C. scholars could publish in them with open access (that is, so that anybody in the world would have free access to the articles written by U.C. scholars).</p>
<p>This seemed like a reasonable model to balance profitability for publishers and open access, but there was no way to agree on it with Elsevier. Meanwhile, U.C. has not renewed its Elsevier subscriptions and Elsevier has cut off access to U.C. libraries.</p>
<p>I was very impressed to see the University of California central administration do something right, so I wondered if this was the kind of portent that is a harbinger of the apocalypse, or just a fluke. Subsequent events suggest the latter.</p>
<p>The University of California has spent a lot of time and money to build a centralized system for job applications and for job applicant review. I was first made aware of this when I chaired the recruiting committee for the Simons Director position. At first we were told that we could solicit applications through the (vastly superior) EECS-built system for job applications and reviews. After the application deadline passed, we were told that, in fact, we could <i>not</i> use the EECS system, and so the already overworked EECS faculty HR person had to manually copy all the data in the central campus system. </p>
<p>The American Mathematical Society has created a wonderfully functional system, called <a href="https://www.mathjobs.org/jobs">Mathjobs</a> where applicants for academic mathematics jobs (ranging from postdocs to professorship) can upload their application material once, and their recommenders can upload their letters once, and then all the universities that the candidate applies to have access to this material. Furthermore, if needed, both applicants and recommenders can tailor-make their material for a particular university or universities, if they want to.</p>
<p>Everybody was living happily, but not ever after, because the U.C. central campus administration decided that <i>everybody</i> in the University of California had to use the centralized system for <i>all</i> jobs. Both the AMS and U.C. mathematicians tried to find a reasonable accommodation, such as allowing the U.C. system to access the letters posted on mathjobs. The campus administration reasoned response was roughly “sucks to be you.” There is more of the story in an <a href="https://www.ams.org/journals/notices/201907/rnoti-p1085.pdf">AMS notices article</a> by the chair of math at U.C. Davis.</p>
<p>Finally, this year <a href="https://www.sfchronicle.com/nation/article/UC-Berkeley-booted-from-U-S-News-World-Report-14189464.php">U.C. Berkeley</a> will not be listed in the US News and World Report rankings because it has submitted wrong data in the past.</p></div>
    </content>
    <updated>2019-07-27T22:06:35Z</updated>
    <published>2019-07-27T22:06:35Z</published>
    <category term="Berkeley"/>
    <category term="things that are terrible"/>
    <category term="University of California"/>
    <author>
      <name>luca</name>
    </author>
    <source>
      <id>https://lucatrevisan.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://lucatrevisan.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://lucatrevisan.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://lucatrevisan.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://lucatrevisan.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>"Marge, I agree with you - in theory. In theory, communism works. In theory." -- Homer Simpson</subtitle>
      <title>in   theory</title>
      <updated>2019-08-09T16:20:15Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-7683541918979097623</id>
    <link href="https://blog.computationalcomplexity.org/feeds/7683541918979097623/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/07/the-advisoradvisee-relationship.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7683541918979097623" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7683541918979097623" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/07/the-advisoradvisee-relationship.html" rel="alternate" type="text/html"/>
    <title>The Advisor/Advisee Relationship</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">I've always felt a strong advisor/advisee relationship is the single most important factor in a successful PhD career. At its best, the advisor works closely with the student to successful research agenda and help mentor them through their graduate career and beyond. The advisor/advisee relationship can feel like a parent/child relationship that lasts an entire career. Nothing gives me more pleasure as an academic than to see the success of my current and former students.<br/>
<br/>
Take your time when picking an advisor. Don't choose an advisor based solely on research area or because they are "famous". Pick the advisor that will best guide you to a successful academic career.<br/>
<br/>
At its worst, a bad advisor/advisee relationship will destroy your graduate career, making you feel miserable, perhaps dropping out of graduate school or worse, particularly if a student doesn't feel like they are being treated fairly.<br/>
<br/>
Two incidents prompted this post. On TCS-Stack Exchange, a student has <a href="https://cstheory.stackexchange.com/questions/42704/single-author-papers-against-my-advisors-will/42711">authorship issues</a> with their advisor. Unfortunately these kinds of incidents happen more often than one suspects. If you can't work it out with the advisor, go talk to someone about it, another faculty, the graduate or department chair, a grad student ombudsperson if your institution has one. We care about our students, and will work hard to resolve problems.<br/>
<br/>
In a much more <a href="https://medium.com/@huixiangvoice/the-hidden-story-behind-the-suicide-phd-candidate-huixiang-chen-236cd39f79d3">tragic event</a>, a student felt it easier to take his own life than feeling that he had to cover up potential academic misconduct. Again, if you ever find yourself in such a situation please reach out. Giving up is never the answer.</div>
    </content>
    <updated>2019-07-25T20:39:00Z</updated>
    <published>2019-07-25T20:39:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-08-09T12:27:36Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16124</id>
    <link href="https://rjlipton.wordpress.com/2019/07/25/discrepancy-games-and-sensitivity/" rel="alternate" type="text/html"/>
    <title>Discrepancy Games and Sensitivity</title>
    <summary>Can we connect the talks that closed this month’s Random Structures and Algorithms conference? Cropped from NYU homepage Joel Spencer gave the closing talk of last week’s Random Structures and Algorithms conference at ETH Zurich. Today we discuss his talk and the one that preceded it, which was by Hao Huang on his proof this […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Can we connect the talks that closed this month’s Random Structures and Algorithms conference?</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2019/07/joelspencerhomepageinrussia.jpg"><img alt="" class="alignright wp-image-16126" height="200" src="https://rjlipton.files.wordpress.com/2019/07/joelspencerhomepageinrussia.jpg?w=137&amp;h=200" width="137"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Cropped from NYU <a href="https://cs.nyu.edu/spencer/">homepage</a></font></td>
</tr>
</tbody>
</table>
<p>
Joel Spencer gave the closing talk of last week’s Random Structures and Algorithms <a href="https://math.ethz.ch/fim/conferences/19th-int-conf-random-structures-algorithms/schedule.html">conference</a> at ETH Zurich.</p>
<p>
Today we discuss his talk and the one that preceded it, which was by Hao Huang on his proof this month of the Boolean sensitivity conjecture.</p>
<p>
Spencer’s <a href="https://ethz.ch/content/dam/ethz/special-interest/math/mathematical-research/fim-dam/Conferences/2019/19th Int Conf on Random Structures and Algorithms/Abstracts/Spencer_Joel.pdf">talk</a> was titled “Four Discrepancies” and based on a joint <a href="https://arxiv.org/pdf/1903.06898.pdf">paper</a> with Nikhil Bansal. The main new result in the talk was a case where a bound of <img alt="{O(\sqrt{n\log n})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%28%5Csqrt%7Bn%5Clog+n%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{O(\sqrt{n\log n})}"/> arising from reasoning about normal distribution can, surprisingly, be improved to a sharp <img alt="{O(\sqrt{n})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%28%5Csqrt%7Bn%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{O(\sqrt{n})}"/>. </p>
<p>
We will talk about this first, but then progress to the talk that preceded Spencer’s. It was by Hao Huang, who was extended an invitation right after his announced <a href="http://www.mathcs.emory.edu/~hhuan30/papers/sensitivity_1.pdf">proof</a> of the Boolean Sensitivity Conjecture earlier this month. Our ulterior purpose is to ask whether any concrete connections can be found besides both talks addressing problems on the <img alt="{\{-1,+1\}^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B-1%2C%2B1%5C%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{-1,+1\}^n}"/> hypercube.<span id="more-16124"/></p>
<p>
</p><p/><h2> Discrepancy Games </h2><p/>
<p/><p>
First suppose you get a stream of single bits <img alt="{v_t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bv_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{v_t}"/>, each <img alt="{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-1}"/> or <img alt="{+1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{+1}"/>. For each bit, you can say “Keep it” or “Flip it.” In the latter case, your bit <img alt="{w_t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{w_t}"/> is <img alt="{-v_t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-v_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-v_t}"/>. Your goal is to keep the sum <img alt="{\sum_{k=1}^t w_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csum_%7Bk%3D1%7D%5Et+w_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\sum_{k=1}^t w_k}"/> within a bounded range. OK, this is easy: you can make the sum always be <img alt="{+1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{+1}"/> when <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t}"/> is odd and <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/> when <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t}"/> is even by flipping when needed.</p>
<p>
Now suppose the bits come in pairs <img alt="{(v_{t,1},v_{t,2})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28v_%7Bt%2C1%7D%2Cv_%7Bt%2C2%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(v_{t,1},v_{t,2})}"/> and your goal is to keep the sum in each coordinate bounded. Again there is a simple strategy: There are four kinds of vectors. For each kind, every time you see it for the second time, flip it. That keeps the contribution of each kind within <img alt="{-1 \ldots +1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-1+%5Cldots+%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-1 \ldots +1}"/> in each coordinate. Thus simple reasoning says each coordinate stays within <img alt="{-4 \ldots +4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-4+%5Cldots+%2B4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-4 \ldots +4}"/>. </p>
<p>
The trouble with extending this idea to vectors of length <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> is that the number of kinds is <img alt="{2^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2^n}"/> and our simple-minded bounds, while constant in terms of the number <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> of vectors given, are exponential in <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>. Well, we can certainly do better. Going back to the <img alt="{n = 2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn+%3D+2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n = 2}"/> case, we can maintain a policy of never letting both coordinates become <img alt="{+2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%2B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{+2}"/> or both become <img alt="{-2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-2}"/>. This keeps both sums within <img alt="{-2 \ldots +2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-2+%5Cldots+%2B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-2 \ldots +2}"/> regardless of the sequence of the vectors. But for larger vector lengths <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>, how large can the <em>discrepancy</em> among the <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> coordinate sums—relative to zero or to each other—become?</p>
<p>
A final help is if we know the number <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> of vectors in any sequence we might be given is bounded. In fact, Spencer’s paper with Bhansal first considers the case <img alt="{T = n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT+%3D+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T = n}"/>. There are two main questions about randomness:</p>
<ol>
<li>
Does it matter whether the sequence of vectors given is random or worst-case? <p/>
</li><li>
Can you do better than choosing “keep” or “flip” randomly?
</li></ol>
<p>
Long back, Spencer <a href="https://cs.nyu.edu/spencer/sixsigma.pdf">proved</a> that if you can see the whole sequence of <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> vectors in advance, then you can always keep the sums within <img alt="{-5.32 \sqrt{n} \ldots +5.32\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-5.32+%5Csqrt%7Bn%7D+%5Cldots+%2B5.32%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-5.32 \sqrt{n} \ldots +5.32\sqrt{n}}"/>, whatever the sequence. If not—if you must decide “keep” or “flip” for each vector before seeing the next—then Spencer had also <a href="https://books.google.com/books?hl=en&amp;lr=&amp;id=HTxo3kP7_5gC&amp;oi=fnd&amp;pg=PP2&amp;dq=Ten+Lectures+on+the+Probabilistic+Method+Spencer&amp;ots=hGDS5tiCgB&amp;sig=qP53Ty3AQgVJF2J4wzcmT948mmY#v=onepage&amp;q=Ten Lectures on the Probabilistic Method Spencer&amp;f=false">proved</a>:</p>
<blockquote><p><b>Theorem 1</b> <em> If an adversary can choose the next vector based on your current sums, then the best bound <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{B}"/> such that you can keep all your sums within absolute value <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{B}"/> grows as <img alt="{\Theta(\sqrt{n\log n})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CTheta%28%5Csqrt%7Bn%5Clog+n%7D%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\Theta(\sqrt{n\log n})}"/>. Moreover, up to the constant in the “<img alt="{\Theta,}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CTheta%2C%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\Theta,}"/>” with high probability you cannot do any better than choosing the sign for each vector randomly. </em>
</p></blockquote>
<p/><p>
See also his famous <a href="https://www.wiley.com/en-us/The+Probabilistic+Method/+4th+Edition-p-9781119061953">book</a>, <em>The Probabilistic Method</em>, with Noga Alon. The new theorem is:</p>
<blockquote><p><b>Theorem 2</b> <em> If the adversary presents vectors uniformly at random, then you <b>can</b> achieve <img alt="{B = O(\sqrt{n})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB+%3D+O%28%5Csqrt%7Bn%7D%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{B = O(\sqrt{n})}"/> with high probability—and not by choosing the signs randomly. </em>
</p></blockquote>
<p/><p>
The algorithm defines a kind of <em>potential function</em> and has you play “keep” or “flip” according to which has the lesser growth in potential. The analysis is quite complicated. As usual we refer to the <a href="https://arxiv.org/pdf/1903.06898.pdf">paper</a> for details. Instead we ask: are there insights to mine here for further advances on the Boolean sensitivity problem?</p>
<p>
</p><p/><h2> Boolean Sensitivity </h2><p/>
<p/><p>
We didn’t talk about Boolean sensitivity in our previous <a href="https://rjlipton.wordpress.com/2019/07/12/tools-and-sensitivity/">post</a> on it. Our purpose now is to convey how many concepts are related, hence how they might connect to discrepancy on the hypercube. </p>
<p>
To get the idea of sensitivity, first consider the parity function <img alt="{f_{\oplus}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_%7B%5Coplus%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_{\oplus}}"/>. If you change one bit of any argument <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> you change the value of <img alt="{f_{\oplus}(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_%7B%5Coplus%7D%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_{\oplus}(x)}"/>. Define <img alt="{x^i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%5Ei%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x^i}"/> to mean <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> with bit <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/> flipped. Then for any <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> and <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/>, <img alt="{f_{\oplus}(x^i) \neq f_{\oplus}(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_%7B%5Coplus%7D%28x%5Ei%29+%5Cneq+f_%7B%5Coplus%7D%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_{\oplus}(x^i) \neq f_{\oplus}(x)}"/>. This means parity is extremely sensitive.</p>
<p>
The OR function <img alt="{f_{\vee}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_%7B%5Cvee%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_{\vee}}"/> is intuitively less sensitive, but it too has an argument <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> such that <img alt="{f_{\vee}(x^i) \neq f_{\vee}(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_%7B%5Cvee%7D%28x%5Ei%29+%5Cneq+f_%7B%5Cvee%7D%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_{\vee}(x^i) \neq f_{\vee}(x)}"/> for all <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/>, namely <img alt="{x = 0^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx+%3D+0%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x = 0^n}"/>. For any Boolean function <img alt="{f: \{0,1\}^n \rightarrow \{0,1\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%3A+%5C%7B0%2C1%5C%7D%5En+%5Crightarrow+%5C%7B0%2C1%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f: \{0,1\}^n \rightarrow \{0,1\}}"/> define its <em>sensitivity</em> (at <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>) by </p>
<p align="center"><img alt="\displaystyle  s(f) = s_n(f) = \max_{x \in \{0,1\}^n} ||\{i: f(x^i) \neq f(x)\}||. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++s%28f%29+%3D+s_n%28f%29+%3D+%5Cmax_%7Bx+%5Cin+%5C%7B0%2C1%5C%7D%5En%7D+%7C%7C%5C%7Bi%3A+f%28x%5Ei%29+%5Cneq+f%28x%29%5C%7D%7C%7C.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  s(f) = s_n(f) = \max_{x \in \{0,1\}^n} ||\{i: f(x^i) \neq f(x)\}||. "/></p>
<p>The OR-of-AND function <img alt="{f_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_2}"/> is less sensitive. Say it is an OR of <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m}"/> blocks, each of <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/> variables, and the blocks use disjoint variables so <img alt="{n = km}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn+%3D+km%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n = km}"/>. If <img alt="{f_2(x) = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_2%28x%29+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_2(x) = 1}"/>, then some block is all <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>, so flipping any other bit makes no difference, and the most sensitive we can get is <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/>. If <img alt="{f_2(x) = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_2%28x%29+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_2(x) = 0}"/> then the most sensitive case is when all blocks have exactly one 0. So <img alt="{s(f_2) = \max\{k,m\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%28f_2%29+%3D+%5Cmax%5C%7Bk%2Cm%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s(f_2) = \max\{k,m\}}"/>. When <img alt="{k = m = \sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk+%3D+m+%3D+%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k = m = \sqrt{n}}"/>, <img alt="{s_n(f) = \sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs_n%28f%29+%3D+%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s_n(f) = \sqrt{n}}"/>.</p>
<p>
If we make each block of <img alt="{f_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_2}"/> return <em>true</em> if exactly one bit is <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>, then we again get sensitivity <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> on the all-<img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/> assignment. Now, however, consider the related function <img alt="{f'_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%27_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f'_2}"/> (with <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/> even, <img alt="{k = 2\ell}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk+%3D+2%5Cell%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k = 2\ell}"/>) that is still an OR over blocks, but each block is true when some consecutive pair <img alt="{x_{2\ell - 1},x_{2\ell}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_%7B2%5Cell+-+1%7D%2Cx_%7B2%5Cell%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x_{2\ell - 1},x_{2\ell}}"/> are both <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/> with all other pairs being both <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/>. Then we can’t do the same trick with the all-<img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/> assignment changing just one bit. So when <img alt="{n = 4\ell^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn+%3D+4%5Cell%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n = 4\ell^2}"/> and <img alt="{m = k = 2\ell}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm+%3D+k+%3D+2%5Cell%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m = k = 2\ell}"/> we again get sensitivity (no more than) <img alt="{\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\sqrt{n}}"/>. </p>
<p>
We can, however, consider <img alt="{f'_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%27_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f'_2}"/> to be more sensitive if we can flip more than one bit at a time. Partition <img alt="{[n]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Bn%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{[n]}"/> into <em>blocks</em> <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B}"/> of two consecutive bit-places each, and given any <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/>, define <img alt="{x^B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%5EB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x^B}"/> to be the result of flipping the bits in <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B}"/>. We get <img alt="{n/2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n/2}"/> blocks, and the all-<img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/> assignment becomes a <em>true</em> case of <img alt="{f'_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%27_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f'_2}"/> if any block is flipped. Generally define the <em>block sensitivity</em> by considering any partitions <img alt="{\mathcal{B} = \{B_j\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BB%7D+%3D+%5C%7BB_j%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{B} = \{B_j\}}"/> of <img alt="{[n]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Bn%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{[n]}"/> into disjoint subsets and writing </p>
<p align="center"><img alt="\displaystyle  bs(f) = \max_{x,\mathcal{B}} ||\{j: f(x^{B_j}) \neq f(x)\}||. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++bs%28f%29+%3D+%5Cmax_%7Bx%2C%5Cmathcal%7BB%7D%7D+%7C%7C%5C%7Bj%3A+f%28x%5E%7BB_j%7D%29+%5Cneq+f%28x%29%5C%7D%7C%7C.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  bs(f) = \max_{x,\mathcal{B}} ||\{j: f(x^{B_j}) \neq f(x)\}||. "/></p>
<p>Note that not every member of the partition has to flip the function—we can discard the ones that don’t flip and count only the disjoint subsets that do flip the value. So back to our example, we have </p>
<p align="center"><img alt="\displaystyle  bs(f'_2) = \frac{n}{2} = \frac{1}{2}s(f'_2)^2. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++bs%28f%27_2%29+%3D+%5Cfrac%7Bn%7D%7B2%7D+%3D+%5Cfrac%7B1%7D%7B2%7Ds%28f%27_2%29%5E2.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  bs(f'_2) = \frac{n}{2} = \frac{1}{2}s(f'_2)^2. "/></p>
<p>Andris Ambainis and Xiaoming Sun <a href="https://arxiv.org/abs/1108.3494">improved</a> the constant from <img alt="{\frac{1}{2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B1%7D%7B2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\frac{1}{2}}"/> asymptotically to <img alt="{\frac{2}{3}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B2%7D%7B3%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\frac{2}{3}}"/>, but their relation is still quadratic.</p>
<p>
</p><p/><h2> Some Boolean Complexity Connections </h2><p/>
<p/><p>
This <a href="https://link.springer.com/article/10.1007/BF01200762">example</a> of quadratic discrepancy is still the best known lower bound on <img alt="{bs(f)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bbs%28f%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{bs(f)}"/> in terms of <img alt="{s(f)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%28f%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s(f)}"/>. But no one had proved anything better than an exponential upper bound until Huang’s result, from which it follows that:</p>
<blockquote><p><b>Theorem 3</b> <em><a name="Huang"/> For all Boolean functions <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{f}"/>, <img alt="{bs(f) \leq 2s(f)^4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bbs%28f%29+%5Cleq+2s%28f%29%5E4%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{bs(f) \leq 2s(f)^4}"/>. </em>
</p></blockquote>
<p/><p>
This bound is concrete, not just asymptotic. It still leaves a gap between quadratic and quartic. It is, however, the combination of two quadratic upper bounds. One was shown by Nisan and Szegedy in their <a href="https://www.researchgate.net/publication/2508255_On_the_Degree_of_Boolean_Functions_as_Real_Polynomials">paper</a>: </p>
<p align="center"><img alt="\displaystyle  bs(f) \leq 2\deg(f)^2, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++bs%28f%29+%5Cleq+2%5Cdeg%28f%29%5E2%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  bs(f) \leq 2\deg(f)^2, "/></p>
<p>where <img alt="{\deg(f)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdeg%28f%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\deg(f)}"/> means the degree of the unique multi-linear real polynomial that agrees with <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/> on the cube <img alt="{\{-1,1\}^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B-1%2C1%5C%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{-1,1\}^n}"/> with <img alt="{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-1}"/> for <em>true</em>. The other is the conjecture </p>
<p align="center"><img alt="\displaystyle  \deg(f) \leq s(f)^2 " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cdeg%28f%29+%5Cleq+s%28f%29%5E2+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \deg(f) \leq s(f)^2 "/></p>
<p>in a 1992 <a href="https://www.sciencedirect.com/science/article/pii/0097316592900608">paper</a> by Craig Gotsman and Nati Linial. Huang proved this by exploiting a connection to graphs that was also shown by Gotsman and Linial. Consider any red-or-white coloring of the <img alt="{2^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2^n}"/> nodes of the hypercube, let <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> be the graph induced by the red nodes, and define <img alt="{g(x) = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%28x%29+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{g(x) = 1}"/> if node <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> is red, <img alt="{g(x) = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%28x%29+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{g(x) = 0}"/> otherwise. Now if the maximum degree <img alt="{d(G)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d(G)}"/> of a node in <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> is small then every red node has many white neighbors, so the Boolean function <img alt="{g}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{g}"/> is very sensitive. However, going to each neighbor in the hypercube flips the parity. Hence the function </p>
<p align="center"><img alt="\displaystyle  g'(x) = g(x) \oplus f_{\oplus}(x) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++g%27%28x%29+%3D+g%28x%29+%5Coplus+f_%7B%5Coplus%7D%28x%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  g'(x) = g(x) \oplus f_{\oplus}(x) "/></p>
<p>is <b>not</b> very sensitive. Moreover, it has the same sensitivity as the function <img alt="{h'(x) = h(x) \oplus f_{\oplus}(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bh%27%28x%29+%3D+h%28x%29+%5Coplus+f_%7B%5Coplus%7D%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{h'(x) = h(x) \oplus f_{\oplus}(x)}"/> where <img alt="{h(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bh%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{h(x)}"/> is true on the white nodes. This nice duality between <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> and the graph <img alt="{H}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{H}"/> induced by the white nodes enables us to fix “<img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/>” to mean whichever of the two has more nodes in the following theorem statement: </p>
<blockquote><p><b>Theorem 4</b> <em> Provided <img alt="{m &gt; 2^{n-1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm+%3E+2%5E%7Bn-1%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{m &gt; 2^{n-1}}"/>, every graph <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{G}"/> induced by <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{m}"/> nodes of the <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n}"/>-cube has <img alt="{d(G) \geq \sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%28G%29+%5Cgeq+%5Csqrt%7Bn%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{d(G) \geq \sqrt{n}}"/> if and only if every Boolean function <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{f}"/> has <img alt="{\deg(f) \leq s(f)^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdeg%28f%29+%5Cleq+s%28f%29%5E2%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\deg(f) \leq s(f)^2}"/>. </em>
</p></blockquote>
<p/><p>
The proof uses some Fourier analysis with <img alt="{f = g'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf+%3D+g%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f = g'}"/> as above. It, too, takes only one page of a really short paper. </p>
<p>
The main open question now is whether the 4th-power upper bound in Huang’s theorem <a href="https://rjlipton.wordpress.com/feed/#Huang">3</a> can be improved to quadratic. It is possible that a deeper application of Fourier analysis may show that cases of quadratic separation from <em>block-sensitivity</em> to <em>degree</em> and <em>degree</em> to <em>sensitivity</em> cannot “amplify” any more than quadratic. This is where there might be some commonality with discrepancy. </p>
<p>
There is a much wider suite of Boolean complexity measures besides <img alt="{s(f)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%28f%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s(f)}"/>, <img alt="{bs(f)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bbs%28f%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{bs(f)}"/>, and <img alt="{\deg(f)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdeg%28f%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\deg(f)}"/> discussed here. For example, consider how many bits of <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> you need to fix in order to preserve the value <img alt="{f(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(x)}"/>. That is, define <img alt="{C(f)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%28f%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C(f)}"/> to be the maximum over <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> of the minimum size of a set <img alt="{I \subseteq [n]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BI+%5Csubseteq+%5Bn%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{I \subseteq [n]}"/> such that whenever <img alt="{x'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x'}"/> agrees with <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> on <img alt="{I}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BI%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{I}"/>, <img alt="{f(x') = f(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28x%27%29+%3D+f%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(x') = f(x)}"/>. Clearly <img alt="{I}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BI%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{I}"/> needs to include at least one bit from each <img alt="{B_j.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB_j.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B_j.}"/> This proves <img alt="{C(f) \geq bs(f)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%28f%29+%5Cgeq+bs%28f%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C(f) \geq bs(f)}"/>. There are many other relations that might be improved. We end by considering ways of broadening Huang’s techniques.</p>
<p>
</p><p/><h2> Weak Adjacency Matrices </h2><p/>
<p/><p>
We—that is Ken and I—have been thinking about how to build on Huang’s proof. We take a somewhat more-general approach compared to the paper and Ken’s <a href="https://rjlipton.wordpress.com/2019/07/12/tools-and-sensitivity/">post</a>.</p>
<blockquote><p><b>Definition 5</b> <em> Let <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{G}"/> be a graph on <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n}"/> vertices. The <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n}"/> by <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n}"/> matrix <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{A}"/> is a <b>weak adjacency</b> matrix of <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{G}"/> provided </em></p><em>
<ol>
<li>
Every entry <img alt="{A_{x,y}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_%7Bx%2Cy%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{A_{x,y}}"/> is bounded by <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{1}"/> in absolute value; <p/>
</li><li>
For all <img alt="{x,y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%2Cy%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{x,y}"/> if <img alt="{x \rightarrow y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx+%5Crightarrow+y%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{x \rightarrow y}"/> is not an edge in <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{G}"/>, then <img alt="{A_{x,y}=0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_%7Bx%2Cy%7D%3D0%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{A_{x,y}=0}"/>.
</li></ol>
</em><p><em/>
</p></blockquote>
<p/><p>
As usual the maximum degree of <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> is denoted by <img alt="{\deg(G)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdeg%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\deg(G)}"/>. The following is almost the same proof as the classic result on adjacency matrices. </p>
<blockquote><p><b>Lemma 6 (H-Lemma)</b> <em> Suppose that <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{A}"/> is a weak adjacency matrix of <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{G}"/>. Then if <img alt="{\lambda}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\lambda}"/> is an eigenvalue of <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{A}"/>, 	</em></p><em>
<p align="center"><img alt="\displaystyle  | \lambda | \le \deg(G). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7C+%5Clambda+%7C+%5Cle+%5Cdeg%28G%29.+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="\displaystyle  | \lambda | \le \deg(G). "/></p>
</em><p><em/>
</p></blockquote>
<p/><p>
<em>Proof:</em>  By the definition of eigenvalue, there is some non-zero vector <img alt="{v}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bv%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{v}"/> so that <img alt="{Av = \lambda v}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BAv+%3D+%5Clambda+v%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Av = \lambda v}"/>. Let <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/> be an index so that <img alt="{|v_{k}|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7Cv_%7Bk%7D%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|v_{k}|}"/> maximum. Then 	</p>
<p align="center"><img alt="\displaystyle  |\lambda v_{k}| =|(A v)_{k}|= \left|\sum_{y=1}^{n} A_{k,y}v_{y} \right| \leq \sum_{y=1}^{n} |A_{k,y}| \cdot |v_{k}|. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7C%5Clambda+v_%7Bk%7D%7C+%3D%7C%28A+v%29_%7Bk%7D%7C%3D+%5Cleft%7C%5Csum_%7By%3D1%7D%5E%7Bn%7D+A_%7Bk%2Cy%7Dv_%7By%7D+%5Cright%7C+%5Cleq+%5Csum_%7By%3D1%7D%5E%7Bn%7D+%7CA_%7Bk%2Cy%7D%7C+%5Ccdot+%7Cv_%7Bk%7D%7C.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  |\lambda v_{k}| =|(A v)_{k}|= \left|\sum_{y=1}^{n} A_{k,y}v_{y} \right| \leq \sum_{y=1}^{n} |A_{k,y}| \cdot |v_{k}|. "/></p>
<p>But then the last sum is upper bounded by 	</p>
<p align="center"><img alt="\displaystyle  D|v_{k}|, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++D%7Cv_%7Bk%7D%7C%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  D|v_{k}|, "/></p>
<p>where <img alt="{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D}"/> is the number of <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y}"/> so that <img alt="{A_{k,y}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_%7Bk%2Cy%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_{k,y}}"/> is not zero. This uses property (1) of the definition of a weak adjacency matrix. Property (2) implies that <img alt="{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D}"/> is at most the degree of vertex <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/> is <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/>. Thus 	</p>
<p align="center"><img alt="\displaystyle  |\lambda v_{k}| \leq D |v_{k}| \leq \deg(G) |v_{k}|. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7C%5Clambda+v_%7Bk%7D%7C+%5Cleq+D+%7Cv_%7Bk%7D%7C+%5Cleq+%5Cdeg%28G%29+%7Cv_%7Bk%7D%7C.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  |\lambda v_{k}| \leq D |v_{k}| \leq \deg(G) |v_{k}|. "/></p>
<p>Dividing by <img alt="{|v_{k}|&gt;0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7Cv_%7Bk%7D%7C%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|v_{k}|&gt;0}"/> yields the lemma. <img alt="\Box" class="latex" src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Box"/></p>
<p>
Let <img alt="{G-k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG-k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G-k}"/> be the graph that results after we delete the vertex <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/> from <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/>. Let <img alt="{A-k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA-k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A-k}"/> be the matrix that results after we delete the column and row <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/> from <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/>. </p>
<blockquote><p><b>Lemma 7</b> <em> Suppose that <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{A}"/> is a weak adjacency matrix of <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{G}"/>. Then for any vertex <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{k}"/>, <img alt="{A-k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA-k%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{A-k}"/> is a weak adjacency matrix of <img alt="{G-k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG-k%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{G-k}"/>. </em>
</p></blockquote>
<p/><p>
<em>Proof:</em>  The bound on the entries of <img alt="{A-k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA-k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A-k}"/> is immediate. Whenever <img alt="{G-k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG-k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G-k}"/> has no edge from <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> to <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y}"/>, then <img alt="{(A-k)_{x,y}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28A-k%29_%7Bx%2Cy%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(A-k)_{x,y}}"/> must be zero. <img alt="\Box" class="latex" src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Box"/></p>
<blockquote><p><b>Lemma 8</b> <em> Suppose that <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{G}"/> a <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n}"/>-graph has a real symmetric weak adjacency matrix <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{A}"/> with <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{m}"/> of the top eigenvalues greater than <img alt="{B \ge 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB+%5Cge+0%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{B \ge 0}"/>. Then every induced subgraph <img alt="{H}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{H}"/> of <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{G}"/> with at least <img alt="{n-m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn-m%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n-m}"/> vertices has degree at least <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{B}"/>. </em>
</p></blockquote>
<p>
</p><blockquote><p><b>Definition 9</b> <em> The <b>hypercube</b> <img alt="{C_{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_%7Bn%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{C_{n}}"/> is the graph on <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n}"/> bit vectors so that two vertices are adjacent if they differ in one bit position. </em>
</p></blockquote>
<p>
</p><blockquote><p><b>Theorem 10</b> <em> The hypercube <img alt="{C_{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_%7Bn%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{C_{n}}"/> has a real symmetric weak adjacency matrix with all its eigenvalues <img alt="{\pm \sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpm+%5Csqrt%7Bn%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\pm \sqrt{n}}"/>. </em>
</p></blockquote>
<p/><p>
<em>Proof:</em>  Let <img alt="{A_{1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_%7B1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_{1}}"/> be 	</p>
<p align="center"><img alt="\displaystyle  \begin{bmatrix}   0 &amp; 1 \\   1 &amp; 0  \end{bmatrix}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Bbmatrix%7D+%09%090+%26+1+%5C%5C+%09%091+%26+0+%09%5Cend%7Bbmatrix%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \begin{bmatrix}   0 &amp; 1 \\   1 &amp; 0  \end{bmatrix}. "/></p>
<p>and <img alt="{A_{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_{n}}"/> be 	</p>
<p align="center"><img alt="\displaystyle  \begin{bmatrix}   A_{n-1} &amp; I \\   I &amp; -A_{n-1}  \end{bmatrix}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Bbmatrix%7D+%09%09A_%7Bn-1%7D+%26+I+%5C%5C+%09%09I+%26+-A_%7Bn-1%7D+%09%5Cend%7Bbmatrix%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \begin{bmatrix}   A_{n-1} &amp; I \\   I &amp; -A_{n-1}  \end{bmatrix}. "/></p>
<p>
Induction shows that <img alt="{A_{n}^{2} = nI}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_%7Bn%7D%5E%7B2%7D+%3D+nI%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_{n}^{2} = nI}"/>. It follows that 	</p>
<p align="center"><img alt="\displaystyle  A_{n}x = \lambda x, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++A_%7Bn%7Dx+%3D+%5Clambda+x%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  A_{n}x = \lambda x, "/></p>
<p>implies that 	</p>
<p align="center"><img alt="\displaystyle  nx = \lambda Ax. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++nx+%3D+%5Clambda+Ax.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  nx = \lambda Ax. "/></p>
<p>Thus 	</p>
<p align="center"><img alt="\displaystyle  nx = \lambda^{2}x. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++nx+%3D+%5Clambda%5E%7B2%7Dx.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  nx = \lambda^{2}x. "/></p>
<p>So the eigenvalues are <img alt="{\pm \sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpm+%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\pm \sqrt{n}}"/> and by trace same number of each.</p>
<p>
The upper-left and lower-right blocks of <img alt="{A_{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_{n}}"/> correspond to the two <img alt="{n-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n-1}"/> dimensional subcubes of <img alt="{C_{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_{n}}"/>, and the two identity blocks correspond to the perfect matching connecting these two subcubes. So <img alt="{A_{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_{n}}"/> is a weak adjacency matrix for <img alt="{C_{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_{n}}"/>. <img alt="\Box" class="latex" src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Box"/></p>
<blockquote><p><b>Corollary 11</b> <em> Every induced subgraph <img alt="{H}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{H}"/> of <img alt="{C_{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_%7Bn%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{C_{n}}"/> with at least <img alt="{2^{n-1}+1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5E%7Bn-1%7D%2B1%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{2^{n-1}+1}"/> vertices has degree at least <img alt="{\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7Bn%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\sqrt{n}}"/>. </em>
</p></blockquote>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Can the last two talks at the conference be further connected?</p>
<p/></font></font></div>
    </content>
    <updated>2019-07-25T20:35:29Z</updated>
    <published>2019-07-25T20:35:29Z</published>
    <category term="All Posts"/>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="Open Problems"/>
    <category term="People"/>
    <category term="Proofs"/>
    <category term="algoritrhms"/>
    <category term="Boolean functions"/>
    <category term="Boolean sensitivity conjecture"/>
    <category term="discrepancy"/>
    <category term="Hao Huang"/>
    <category term="hypercube"/>
    <category term="Joel Spencer"/>
    <category term="Nikhil Bansal"/>
    <category term="randomized algorithms"/>
    <category term="randomness"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-08-09T16:20:46Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=17669</id>
    <link href="https://gilkalai.wordpress.com/2019/07/25/tyi-39-can-a-coalition-of-children-guarantees-being-in-the-same-class/" rel="alternate" type="text/html"/>
    <title>TYI 39 : Can a coalition of children guarantees all being in the same class?</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">There is a class of children that have just finished elementary school. Now they all move from elementary school to high school and classes are reshuffled. Each child lists three friends, and the assignment of children into classes ensures that … <a href="https://gilkalai.wordpress.com/2019/07/25/tyi-39-can-a-coalition-of-children-guarantees-being-in-the-same-class/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="https://gilkalai.files.wordpress.com/2019/07/class_school.jpg"><img alt="" class="alignnone size-medium wp-image-17676" height="213" src="https://gilkalai.files.wordpress.com/2019/07/class_school.jpg?w=300&amp;h=213" width="300"/></a></p>
<p>There is a class of children that have just finished elementary school. Now they all move from elementary school to high school and classes are reshuffled. Each child lists three friends, and the assignment of children into classes ensures that each child will have at least one of these three friends in his class.</p>
<p>One of the children heard from five of his schoolmates that they found that they can make their selections in a way that will ensure that all five will be assigned to the same class!</p>
<h3><span style="color: #993366;">Test your intuition: Is there a strategy for five of the children that will ensure that all five will be assigned to the same class?</span></h3>
<p>Can a larger group of children coordinate their choices to ensure that they will all necessarily be assigned to the same class?</p>
<a name="pd_a_10371327"/><div class="CSS_Poll PDS_Poll" id="PDI_container10371327" style="display: inline-block;"/><div id="PD_superContainer"/><noscript>&lt;a href="https://polldaddy.com/p/10371327" target="_blank"&gt;Take Our Poll&lt;/a&gt;</noscript>
<p><span id="more-17669"/></p>
<p><strong>Bonus question:</strong> In case that every child lists only two friends and one of them is guaranteed to be in the same class. Is there a strategy of five children that will ensure they are in the same class?</p>
<p><strong>Answer to Bonus question</strong>: Yes. For three children you let every one choose the other two. For the remaining children you let each one choose two among the three.</p></div>
    </content>
    <updated>2019-07-25T12:59:05Z</updated>
    <published>2019-07-25T12:59:05Z</published>
    <category term="Combinatorics"/>
    <category term="Economics"/>
    <category term="Mathematics to the rescue"/>
    <category term="Test your intuition"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-08-09T16:20:38Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/097</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/097" rel="alternate" type="text/html"/>
    <title>TR19-097 |  Reversible Pebble Games and the Relation Between Tree-Like and General Resolution Space | 

	Florian Wörz, 

	Jacobo Toran</title>
    <summary>We show a new connection between the space measure in tree-like resolution and the reversible pebble game in graphs. Using this connection we provide several formula classes for which there is a logarithmic factor separation between the space complexity measure in tree-like and general resolution. We show that these separations are almost optimal by proving upper bounds for tree-like resolution space in terms of general resolution clause and variable space. In particular we show that for any formula F, its tree-like resolution is upper bounded by space(?)log time(?) where ? is any general resolution refutation of F. This holds considering as space(?) the clause space of the refutation as well as considering its variable space. For the concrete case of Tseitin formulas we are able to improve this bound to the optimal bound space(?)log(n), where n is the number of vertices of the corresponding graph.</summary>
    <updated>2019-07-24T12:09:27Z</updated>
    <published>2019-07-24T12:09:27Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-08-09T16:20:33Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/096</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/096" rel="alternate" type="text/html"/>
    <title>TR19-096 |  On the $\text{AC}^0[\oplus]$ complexity of Andreev&amp;#39;s Problem | 

	Aditya Potukuchi</title>
    <summary>Andreev's Problem asks the following: Given an integer $d$ and a subset of $S \subseteq \mathbb{F}_q \times \mathbb{F}_q$, is there a polynomial $y = p(x)$ of degree at most $d$ such that  for every $a \in \mathbb{F}_q$, $(a,p(a)) \in S$? We show an $\text{AC}^0[\oplus]$ lower bound for this problem. 

This problem appears to be similar to the list recovery problem for degree $d$-Reed-Solomon codes over $\mathbb{F}_q$ which asks the following: Given subsets $A_1,\ldots,A_q$ of $\mathbb{F}_q$, output all (if any) Reed-Solomon codewords contained in $A_1\times \cdots \times A_q$. For our purpose, we study this problem when $A_1, \ldots, A_q$ are random subsets of a given size, which may be of independent interest.</summary>
    <updated>2019-07-23T17:29:25Z</updated>
    <published>2019-07-23T17:29:25Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-08-09T16:20:33Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=17642</id>
    <link href="https://gilkalai.wordpress.com/2019/07/23/matan-harel-frank-mousset-and-wojciech-samotij-and-the-the-infamous-upper-tail-problem/" rel="alternate" type="text/html"/>
    <title>Matan Harel, Frank Mousset, and Wojciech Samotij and the “the infamous upper tail” problem</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Let me report today on a major breakthrough in random graph theory and probabilistic combinatorics. Congratulations to Matan, Frank, and Vojtek! Artist: Heidi Buck. “Catch a Dragon by the Tail 2” ( source ) Upper tails via high moments and entropic … <a href="https://gilkalai.wordpress.com/2019/07/23/matan-harel-frank-mousset-and-wojciech-samotij-and-the-the-infamous-upper-tail-problem/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Let me report today on a major breakthrough in random graph theory and probabilistic combinatorics. Congratulations to Matan, Frank, and Vojtek!</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/07/dragon_tail_2_web.png"><img alt="" class="alignnone size-full wp-image-17644" height="496" src="https://gilkalai.files.wordpress.com/2019/07/dragon_tail_2_web.png?w=640&amp;h=496" width="640"/></a></p>
<p>Artist: Heidi Buck.<strong><span style="color: #ff0000;"> “Catch a Dragon by the Tail 2”</span></strong> ( <a href="https://www.hbdragon.com/main/content/catch-dragon-tail-2">source</a> )</p>
<p class="title mathjax"><a href="https://arxiv.org/abs/1904.08212">Upper tails via high moments and entropic stability</a> by Matan Harel, Frank Mousset, and Wojciech Samotij</p>
<p><strong>Abstract:</strong></p>
<p>Suppose that <em>X</em> is a bounded-degree polynomial with nonnegative coefficients on the <em>p</em>-biased discrete hypercube. Our main result gives sharp estimates on the logarithmic upper tail probability of X whenever an associated extremal problem satisfies a certain entropic stability property. We apply this result to solve two long-standing open problems in probabilistic combinatorics: the upper tail problem for the number of arithmetic progressions of a fixed length in the <em>p</em>-random subset of the integers and the upper tail problem for the number of cliques of a fixed size in the random graph <img alt="G_{n,p}" class="latex" src="https://s0.wp.com/latex.php?latex=G_%7Bn%2Cp%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G_{n,p}"/>. We also make significant progress on the upper tail problem for the number of copies of a fixed regular graph <em>H</em> in <img alt="G_{n,p}." class="latex" src="https://s0.wp.com/latex.php?latex=G_%7Bn%2Cp%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G_{n,p}."/> To accommodate readers who are interested in learning the basic method, we include a short, self-contained solution to the upper tail problem for the number of triangles in <img alt="G_{n,p}" class="latex" src="https://s0.wp.com/latex.php?latex=G_%7Bn%2Cp%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G_{n,p}"/> for all <em>p=p(n)</em> satisfying <img alt="\frac {\log n}{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cfrac+%7B%5Clog+n%7D%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\frac {\log n}{n}"/> <img alt="\ll" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cll&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\ll"/> <img alt="p \ll 1" class="latex" src="https://s0.wp.com/latex.php?latex=p+%5Cll+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p \ll 1"/>.</p>
<p>The introduction does a very nice job of presenting the rich history of the problem.  Here is a 2002 paper by Svante Janson and Andrzej Ruciński on <a href="https://onlinelibrary.wiley.com/doi/pdf/10.1002/rsa.10031?casa_token=7FoHUVq0w5IAAAAA:AqmK_4tpjDzXErWnGh4qnE2kn4NTupyoW27eSXW7Uwr5l0JgpBP5SG7PaVnJ6Lvr4JhCaSIH2HPv-QTsUg">the infamous upper tail</a>.  (And a lot has happened since then with regard to this problem and on non linear large deviation theory). Following, there is a lovely section with a short solution for the case of triangles.</p>
<p>Forthcoming reference [48] talks about lower tails! Stay tuned!</p></div>
    </content>
    <updated>2019-07-23T06:51:02Z</updated>
    <published>2019-07-23T06:51:02Z</published>
    <category term="Combinatorics"/>
    <category term="Probability"/>
    <category term="Frank Mousset"/>
    <category term="Matan Harel"/>
    <category term="Wojciech Samotij"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-08-09T16:20:37Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-7828284719883166611</id>
    <link href="https://blog.computationalcomplexity.org/feeds/7828284719883166611/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/07/answer-to-both-infinite-hats-problems.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7828284719883166611" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7828284719883166611" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/07/answer-to-both-infinite-hats-problems.html" rel="alternate" type="text/html"/>
    <title>Answer to both Infinite Hats Problems from the last post</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><br/>
(This is a joint post with David Marcus. You'll see why later.)<br/>
<br/>
In a prior  I posed two infinite hat problems. Today I post the solutions. Actually this is a copy of my last post with the solutions added, so it is self contained.<br/>
<br/>
A Hat Problem that you have probably seen:<br/>
<br/>
1) There are an infinite number of people, numbered 1,2,3,...  There are 2 colors of hats. They can all see everyone's hat but their own. <br/>
<br/>
2) The adversary is going to put hats on all the people. They will guess their own hat color<i> at the same time</i>. <br/>
<br/>
3) The people can discuss strategy ahead of time, but must use a deterministic strategy and the adversary knows the strategy.<br/>
<br/>
4) The people want to minimize how many they get wrong. <br/>
<br/>
5) The adversary puts on hats to maximize how many they get wrong.<br/>
<br/>
I ask two questions (the answers are in a document I point to) and one meta-question:<br/>
<br/>
Q1: Is there a solution where they get all but a finite number of the guesses right? (If you have read my prior post on hat puzzles, <a href="https://blog.computationalcomplexity.org/2017/07/two-hat-problems-you-may-or-may-not.html">here</a> then you can do this one.) <br/>
<br/>
Q2: Is there a solution where they get all but at most (say) 18 wrong.<br/>
<br/>
<br/>
Answers to Q1 and Q2 are <a href="https://www.cs.umd.edu/users/gasarch/BLOGPAPERS/infinitehats.pdf">here</a>.<br/>
<br/>
How did I get into this problem? I was looking at hat problems a while back. Then  I began discussing Q1 and Q2 by email  (Does the term <i>discussing</i> have as a default that it is by email?) with David Marcus who had just read the chapter of <a href="https://www.amazon.com/Problems-Point-Exploring-Computer-Science/dp/9813279974">Problems with a Point</a> on hat puzzles. After a few emails back and fourth, he began looking on the web for answers. He found one. There is a website of hat puzzles! It was MY website papers on  Hat Puzzles! It is  <a href="https://www.cs.umd.edu/users/gasarch/TOPICS/hats/hats.html">here</a>. And on it was a relevant paper <a href="https://www.cs.umd.edu/users/gasarch/TOPICS/hats/infinite-hats-and-ac.pdf">here</a>. We did not find any other source of the problem or its solution. <br/>
<br/>
Q3: How well known is problem Q2 and the solution?  I've seen Q1 around but the only source on Q2 that I know of is that paper, and now this blog post. So, please leave a comment telling me if you have seen Q2 and/or the solution someplace else, and if so where.<br/>
<br/>
The responses to my last post indicated that YES the problem was out there, but the proof that you could not get all-but-18 was not well known. <br/>
<br/>
I THINK that all of the proofs that you can't do all-but-18 in the comment of the last post were essentially the same as the solution I pointed to in this blog. I would be interested if there is an alternative proof. <br/></div>
    </content>
    <updated>2019-07-22T03:00:00Z</updated>
    <published>2019-07-22T03:00:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-08-09T12:27:36Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/095</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/095" rel="alternate" type="text/html"/>
    <title>TR19-095 |  Unambiguous Catalytic Computation | 

	Chetan Gupta, 

	Rahul Jain, 

	Vimal Raj Sharma, 

	Raghunath Tewari</title>
    <summary>The catalytic Turing machine is a model of computation defined by Buhrman, Cleve,
Kouck, Loff, and Speelman (STOC 2014). Compared to the classical space-bounded Turing
machine, this model has an extra space which is filled with arbitrary content in addition
to the clean space. In such a model we study if this additional filled space can be used to
increase the power of computation or not, with the condition that the initial content of this
extra filled space must be restored at the end of the computation.
In this paper, we define the notion of unambiguous catalytic Turing machine and prove
that under a standard derandomization assumption, the class of problems solved by an
unambiguous catalytic Turing machine is same as the class of problems solved by a general
nondeterministic catalytic Turing machine in the logspace setting.</summary>
    <updated>2019-07-21T11:21:02Z</updated>
    <published>2019-07-21T11:21:02Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-08-09T16:20:33Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=17574</id>
    <link href="https://gilkalai.wordpress.com/2019/07/20/isabella-novik-and-hailun-zheng-neighborly-centrally-symmetric-spheres-exist-in-all-dimensions/" rel="alternate" type="text/html"/>
    <title>Isabella Novik and Hailun Zheng: Neighborly centrally symmetric spheres exist in all dimensions!</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">A tweet-long summary: The cyclic polytope is wonderful and whenever we construct an analogous object we are happy. Examples: Neighborly cubic polytopes; The amplituhedron; and as of last week, the Novik-Zheng new construction of neighborly centrally symmetric spheres! At last: … <a href="https://gilkalai.wordpress.com/2019/07/20/isabella-novik-and-hailun-zheng-neighborly-centrally-symmetric-spheres-exist-in-all-dimensions/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><span style="color: #0000ff;">A tweet-long summary: The cyclic polytope is wonderful and whenever we construct an analogous object we are happy. Examples: Neighborly cubic polytopes; The amplituhedron; and as of last week, the Novik-Zheng new construction of neighborly centrally symmetric spheres!</span></p>
<h2>At last: Neighborly CS spheres!</h2>
<p>The news: Isabella Novik and Hailun Zheng’ paper  <a href="https://arxiv.org/abs/1907.06115">Highly neighborly centrally symmetric spheres</a>, resolves an old standing problem in this field.</p>
<p>Here is the abstract:</p>
<blockquote><p>In 1995, Jockusch constructed an infinite family of centrally symmetric 3-dimensional simplicial spheres that are cs-<em>2</em>-neighborly. Here we generalize his construction and show that for all d ≥ 4 and n ≥ d, there exists a centrally symmetric (d − 1)-dimensional simplicial sphere with <em>2n</em> vertices that is cs-[d/2]-neighborly. This result combined with work of Adin and Stanley completely resolves the upper bound problem for centrally symmetric simplicial spheres.</p></blockquote>
<p>Congratulations to Isabella and Hailun!</p>
<h2>Some background to the Novik and Zheng breakthrough</h2>
<p><strong>Centrally symmetric bodies:</strong> A centrally symmetric (cs) polytope convex body in <img alt="\mathbb R^d" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb R^d"/> satisfies <img alt="x \in P" class="latex" src="https://s0.wp.com/latex.php?latex=x+%5Cin+P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x \in P"/> implies <img alt="-x \in P" class="latex" src="https://s0.wp.com/latex.php?latex=-x+%5Cin+P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="-x \in P"/>. Centrally symmetric bodies are the unit balls of normed spaces.</p>
<p><strong>Centrally symmetric simplicial spheres:</strong> A triangulation <img alt="K" class="latex" src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K"/> of a  <img alt="(d-1)" class="latex" src="https://s0.wp.com/latex.php?latex=%28d-1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(d-1)"/>-dimensional sphere with a set <img alt="V" class="latex" src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="V"/> of vertices is centrally symmetric if there is an involution <img alt="\phi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cphi&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\phi"/> on <img alt="V" class="latex" src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="V"/> that <img alt="\phi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cphi&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\phi"/> maps a face of <img alt="K" class="latex" src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K"/> to a face of <img alt="K" class="latex" src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K"/> and for every vertex <img alt="v" class="latex" src="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="v"/>, <img alt="\phi(v) \ne v" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cphi%28v%29+%5Cne+v&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\phi(v) \ne v"/> and <img alt="\{v , \phi (v)\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7Bv+%2C+%5Cphi+%28v%29%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{v , \phi (v)\}"/> is not an edge of <img alt="K" class="latex" src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K"/>.  The boundary complex of a cs <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/>-polytopes is a cs triangulation of <img alt="S^{d-1}" class="latex" src="https://s0.wp.com/latex.php?latex=S%5E%7Bd-1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S^{d-1}"/>.</p>
<p><strong>Neighborliness.</strong> A simplicial complex <img alt="K" class="latex" src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K"/>  is <img alt="m" class="latex" src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m"/>-neighborly of every set of <img alt="m" class="latex" src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m"/> vertices of <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> form a face.  (The definition was first considered  for simplicial <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/>-polytopes <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/>.) The cyclic <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/>-polytope with <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> vertices is <img alt="[d/2]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Bd%2F2%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="[d/2]"/>-neighborly. (The only (<img alt="[d/2]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Bd%2F2%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="[d/2]"/>+1)-neighborly simplicial <img alt="(d-1)" class="latex" src="https://s0.wp.com/latex.php?latex=%28d-1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(d-1)"/>-sphere is the simplex. There are many other <img alt="[d/2]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Bd%2F2%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="[d/2]"/>-neighborly simplicial <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/>-polytopes and <img alt="(d-1)" class="latex" src="https://s0.wp.com/latex.php?latex=%28d-1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(d-1)"/>-spheres.</p>
<p><strong>cs-Neighborliness. </strong>Let <img alt="K" class="latex" src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K"/> be a simplicial complex with an involution <img alt="\phi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cphi&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\phi"/> on its vertices which acts on <img alt="K" class="latex" src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K"/> (maps faces to faces) and has the property that <img alt="\phi(v)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cphi%28v%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\phi(v)"/> is not adjacent to <img alt="v" class="latex" src="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="v"/> (and <img alt="\phi (v) \ne v" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cphi+%28v%29+%5Cne+v&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\phi (v) \ne v"/>). We will call <img alt="v" class="latex" src="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="v"/> and <img alt="\phi (v)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cphi+%28v%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\phi (v)"/> <strong>antipodal</strong>. <img alt="K" class="latex" src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K"/> is cs-<img alt="m" class="latex" src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m"/>-neighborly if every set of <img alt="m" class="latex" src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m"/> vertices that contains no pair of antipodal vertices is a face of <img alt="K" class="latex" src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K"/>. The only cs-<img alt="m" class="latex" src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m"/>-neighborly simplicial sphere is the boundary complex of the cross polytope.</p>
<p><strong>The existence of cs-<img alt="[d/2]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Bd%2F2%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="[d/2]"/>-neighborly spheres. </strong>It was an important open question whether  cs <img alt="[d/2]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Bd%2F2%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="[d/2]"/>-neighborly simplicial spheres exist. (The only cs-<img alt="([d/2]+1)" class="latex" src="https://s0.wp.com/latex.php?latex=%28%5Bd%2F2%5D%2B1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="([d/2]+1)"/>-neighborly spheres is the boundary complex of the cross polytope.)  The first example (which is not a cross polytope) was given by Grünbaum in 1969 in his paper “The importance of being straight(?).” In 1995  Jockusch constructed an infinite family cs-2-neighborly centrally symmetric 3-dimensional simplicial spheres. This problem has now been solved by Novik and Zheng.</p>
<p><strong>Neighborly centrally symmetric polytopes.  </strong>In the 1960s Grünbaum noted the big difference between neighborly centrally symmetric spheres and centrally symmetric polytopes. He proved (This is Theorem 4.1 in his book “Convex polytopes”) that no cs-2-neighborly 4 polytope with 12 vertices exists.  This is an example of the important themes of “straightening” or “linearizing” combimatorial objects and  of extending theorems from the “straight” or “linear” case to more general combinatorial settings.)</p>
<p>This result by Grünbaum was extended in various directions. Let me mention two major results in the field:</p>
<p><strong>Theorem</strong> McMullen and Shephard (1968): A cs <em>d</em>-dimensional polytope with <em>2(d + 2)</em> vertices cannot be more than cs-<em>⌊(d + 1)/3⌋</em>-neighborly.</p>
<p><strong>Theorem</strong> <a href="https://arxiv.org/abs/math/0507280">Linial and Novik (2006):</a> A cs-2-neighborly <em>d</em>-dimensional polytope has at most  <img alt="2^d" class="latex" src="https://s0.wp.com/latex.php?latex=2%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^d"/>;</p>
<p>Novik (2017) <a href="https://arxiv.org/abs/1712.09489">constructed</a>  cs-2-neighborly d polytopes with <img alt="2^{d-1}+1" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7Bd-1%7D%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{d-1}+1"/> vertices. She used a 2017 <a href="https://arxiv.org/abs/1709.03411">breakthrough construction</a> by Gerencsér–Harang of an acute set of size <img alt="2^{d-1}+1" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7Bd-1%7D%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{d-1}+1"/> in <img alt="\mathbb R^d" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb R^d"/>. (A set <em>S</em> is <em>acute</em> if every three points from <em>S </em>determine an acute triangle.)</p>
<p><strong>Face numbers of centrally-symmetric polytopes and spheres. </strong>As the abstract asserts the new construction is related to questions about face numbers of centrally symmetric polytopes, spheres and other cellular objects. In fact, this was the next item in our planned posts on algebraic combinatorics of cellular objects. (The first and only post so far<a href="https://gilkalai.wordpress.com/2018/06/20/beyond-the-g-conjecture-algebraic-combinatorics-of-cellular-spaces-i/"> is here</a>.) Here is a recent survey by Isabella Novik  <a href="https://arxiv.org/abs/1711.09310">A tale on centrally symmetric  polytopes and spheres</a>.</p>
<p><strong>Upper bound theorems.</strong> Neighborly polytopes and spheres are the equality cases of the upper bound theorem (proved by McMullen for polytopes and by Stanley for spheres). A version of the upper bound inequality for centrally symmetric spheres was proved by Adin and Stanley and the new construction shows that the Adin-Stanley inequality is tight. For more on the upper bound theorem and neighborliness see Section 2 of my 2000 survey  <a href="http://www.ma.huji.ac.il/~kalai/VIS.pdf">Combinatorics with geometric flavor. </a> See also the post <a href="https://gilkalai.wordpress.com/2009/04/04/how-the-g-conjecture-came-about/">How the g-conjecture came about</a> and  the post <a href="https://gilkalai.wordpress.com/2013/09/10/how-the-proof-of-the-upper-bound-theorem-for-spheres-was-found/" rel="bookmark">Richard Stanley: How the Proof of the Upper Bound Theorem (for spheres) was Found.</a></p>
<p> </p>
<p> </p></div>
    </content>
    <updated>2019-07-20T18:33:03Z</updated>
    <published>2019-07-20T18:33:03Z</published>
    <category term="Combinatorics"/>
    <category term="Convexity"/>
    <category term="Hailun Zheng"/>
    <category term="Isabella Novik"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-08-09T16:20:38Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4267</id>
    <link href="https://www.scottaaronson.com/blog/?p=4267" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4267#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4267" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Fake it till you make it (to the moon)</title>
    <summary xml:lang="en-US">While I wait to board a flight at my favorite location on earth—Philadelphia International Airport—I figured I might as well blog something to mark the 50th anniversary of Apollo 11. (Thanks also to Joshua Zelinsky for a Facebook post that inspired this.) I wasn’t alive for Apollo, but I’ve been alive for 3/4 of the […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>While I wait to board a flight at my favorite location on earth—Philadelphia International Airport—I figured I might as well blog something to mark the 50<sup>th</sup> anniversary of Apollo 11.  (Thanks also to Joshua Zelinsky for a Facebook post that inspired this.)</p>



<p>I wasn’t alive for Apollo, but I’ve been alive for 3/4 of the time <em>after</em> it, even though it now seems like ancient history—specifically, like a Roman cathedral being gawked at by a medieval peasant, like an achievement by some vanished, more cohesive civilization that we can’t even replicate today, let alone surpass.</p>



<p>Which brings me to a depressing mystery: why do so many people now deny that humans walked on the moon at all?  Like, why <em>that</em> specifically?  While they’re at it, why don’t they also deny that WWII happened, or that the Beatles existed?</p>



<p>Surprisingly, skepticism of the reality of Apollo seems to have gone all the way back to the landings themselves.  One of my favorite stories growing up was of my mom, as a teenager, working as a waitress at an Israeli restaurant in Philadelphia, on the night of Apollo 11 landing.  My mom asked for a few minutes off to listen to news of the landing on the radio.  The owners wouldn’t grant it—explaining that it was all Hollywood anyway, just some actors in spacesuits on a sound stage, and obviously my mom wasn’t so naïve as to think anyone was <em>actually</em> walking to the moon?</p>



<p>Alas, as we get further and further from the event, with no serious prospect of ever replicating it past the stage of announcing an optimistic timetable (nor, to be honest, any scientific <em>reason</em> to replicate it), as the people involved die off, and as our civilization becomes ever more awash in social-media-fueled paranoid conspiracies, I fear that moon-landing denalism will become more common.</p>



<p>Because here’s the thing: Apollo could happen, but <em>only</em> because of a wildly improbable, once-in-history confluence of social and geopolitical factors.  It was economically insane, taking 100,000 people and 4% of the US federal budget for some photo-ops, a flag-planting, some data and returned moon rocks that had genuine scientific value but could’ve been provided much more cheaply by robots.  It was dismantled immediately afterwards like a used movie set, rather than leading to any greater successes. Indeed, manned spaceflight severely <em>regressed</em> afterwards, surely mocking the expectations of every last science fiction fan and techno-utopian who was alive at that time.</p>



<p>One could summarize the situation by saying that, in certain respects, the Apollo program really <strong>was</strong> “faked.”  It’s just that the way they “faked” it, involved actually landing people on the moon!</p></div>
    </content>
    <updated>2019-07-19T21:40:43Z</updated>
    <published>2019-07-19T21:40:43Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Nerd Interest"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Procrastination"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2019-07-31T11:08:23Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://blogs.princeton.edu/imabandit/?p=1397</id>
    <link href="https://blogs.princeton.edu/imabandit/2019/07/17/guest-post-by-julien-mairal-a-kernel-point-of-view-on-convolutional-neural-networks-part-ii/" rel="alternate" type="text/html"/>
    <title>Guest post by Julien Mairal: A Kernel Point of View on Convolutional Neural Networks, part II</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>This is a continuation of Julien Mairal‘s guest post on CNNs, see part I here. Stability to deformations of convolutional neural networks In their ICML paper Zhang et al. introduce a functional space for CNNs with one layer, by noticing … <a href="https://blogs.princeton.edu/imabandit/2019/07/17/guest-post-by-julien-mairal-a-kernel-point-of-view-on-convolutional-neural-networks-part-ii/">Continue reading <span class="meta-nav">→</span></a></p></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a class="liimagelink" href="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/uploads/sites/122/2019/07/Mairal2.jpg?ssl=1"><img alt="" class="alignnone wp-image-1399" height="324" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/uploads/sites/122/2019/07/Mairal2.jpg?resize=639%2C324&amp;ssl=1" width="639"/></a></p>
<p>This is a continuation of <a class="liinternal" href="https://lear.inrialpes.fr/people/mairal/">Julien Mairal</a>‘s guest post on CNNs, see <a class="liinternal" href="https://blogs.princeton.edu/imabandit/2019/07/10/guest-post-by-julien-mairal-a-kernel-point-of-view-on-convolutional-neural-networks-part-i/">part I here.</a></p>
<p><strong>Stability to deformations of convolutional neural networks</strong></p>
<p>In their <a class="lipdf" href="http://proceedings.mlr.press/v70/zhang17f/zhang17f.pdf">ICML paper</a> Zhang et al. introduce a functional space for CNNs with one layer, by noticing that for some dot-product kernels, smoothed variants of rectified linear unit activation functions (ReLU) live in the corresponding RKHS, see also <a class="lipdf" href="http://proceedings.mlr.press/v48/zhangd16.pdf">this paper</a> and <a class="lipdf" href="https://www.cs.cornell.edu/~sridharan/sicomp.pdf">that one</a>. By following a similar reasoning with multiple layers, it is then possible to show that the functional space described in <a class="liinternal" href="https://blogs.princeton.edu/imabandit/2019/07/10/guest-post-by-julien-mairal-a-kernel-point-of-view-on-convolutional-neural-networks-part-i/">part I</a> <img alt="\{ f_w: x \mapsto \langle w , \Phi_n(x_0) \rangle; w \in L^2(\Omega,\mathcal{H}_n) \}" class="ql-img-inline-formula " height="20" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-3e321e5f0406c9879f25b6b1d69a5fc3_l3.png?resize=298%2C20&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="298"/> contains CNNs with such smoothed ReLU, and that the norm <img alt="\|f_w\|" class="ql-img-inline-formula " height="19" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-62e1a48032624994ba16c4e26421676e_l3.png?resize=34%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="34"/> of such networks can be controlled by the spectral norms of filter matrices. This is consistent with previous measures of complexity for CNNs, see <a class="lipdf" href="https://papers.nips.cc/paper/7204-spectrally-normalized-margin-bounds-for-neural-networks.pdf">this paper</a> by Bartlett et al.</p>
<p>A perhaps more interesting finding is that the abstract representation <img alt="\Phi_n(x)" class="ql-img-inline-formula " height="18" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-3ca9a5351b772e88bebe85e7e4a13632_l3.png?resize=45%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="45"/>, which only depends on the network architecture, may provide near-translation invariance and stability to small image deformations while preserving information—that is, <img alt="x" class="ql-img-inline-formula " height="8" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-1b9fbfb207b6d17d74b33c6d8342a1a4_l3.png?resize=10%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="10"/> can be recovered from <img alt="\Phi_n(x)" class="ql-img-inline-formula " height="18" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-3ca9a5351b772e88bebe85e7e4a13632_l3.png?resize=45%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="45"/>. The original characterization we use was introduced by Mallat in <a class="lipdf" href="https://www.di.ens.fr/~mallat/papiers/ScatCPAM.pdf">his paper</a> on the scattering transform—a multilayer architecture akin to CNNs based on wavelets, and was extended to <img alt="\Phi_n" class="ql-img-inline-formula " height="16" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-273242b8e92b3a9f4dc13c62b2785bd3_l3.png?resize=21%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="21"/> by Alberto Bietti, who should be credited for all the hard work here.</p>
<p>Our goal is to understand under which conditions it is possible to obtain a representation that (i) is near-translation invariant, (ii) is stable to deformations, (iii) preserves signal information. Given a <img alt="C^1" class="ql-img-inline-formula " height="15" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-2e9ea203bbd77c5cd8bee967e2729d8b_l3.png?resize=20%2C15&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="20"/>-diffeomorphism <img alt="\tau: \mathbb{R}^2 \to \mathbb{R}^2" class="ql-img-inline-formula " height="16" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c6f8f1dde2ee4682653c2a6b37d8a42d_l3.png?resize=93%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="93"/> and denoting by <img alt="L_\tau x(u) = x(u-\tau(u))" class="ql-img-inline-formula " height="18" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-835d9f864f712213ee317332b3f3675a_l3.png?resize=167%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="167"/> its action operator (for an image defined on the continuous domain <img alt="\mathbb{R}^2" class="ql-img-inline-formula " height="15" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-d5abe0f29e8cc710ae26f4f0af5a0859_l3.png?resize=20%2C15&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="20"/>), the main stability bound we obtain is the following one, see Theorem 7 in <a class="lipdf" href="https://www.di.ens.fr/~mallat/papiers/ScatCPAM.pdf">Mallat’s paper</a> if <img alt="\|\nabla \tau\|_\infty \leq 1/2" class="ql-img-inline-formula " height="19" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-758b3cac273166048ed1879acf427860_l3.png?resize=104%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="104"/>, for all <img alt="x" class="ql-img-inline-formula " height="8" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-1b9fbfb207b6d17d74b33c6d8342a1a4_l3.png?resize=10%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="10"/>,</p>
<p class="ql-center-displayed-equation" style="line-height: 43px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\[ \| \Phi_n(L_\tau x) - \Phi_n(x)\| \leq \left ( C_1 (1+n) \|\nabla \tau\|_\infty + \frac{C_2}{\sigma_n} \|\tau\|_\infty \right) \|x\|, \]" class="ql-img-displayed-equation " height="43" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-51041d0067a72066938e31b1f00529fa_l3.png?resize=455%2C43&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="455"/></p>
<p>where <img alt="C_1, C_2" class="ql-img-inline-formula " height="16" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-08d1f29fa9c0981e916619b6c6bc7eee_l3.png?resize=48%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="48"/> are universal constants, <img alt="\sigma_n" class="ql-img-inline-formula " height="11" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c0142846a2999e170f7beec7be1523f2_l3.png?resize=18%2C11&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="18"/> is the scale parameter of the pooling operator <img alt="A_n" class="ql-img-inline-formula " height="15" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-e1872c7d7a65e0dc92f8a4a04608b88a_l3.png?resize=21%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="21"/> corresponding to the “amount of pooling” performed up to the last layer, <img alt="\|\tau\|_\infty" class="ql-img-inline-formula " height="19" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c1a5effb150d36de3c7074eaa980c357_l3.png?resize=39%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="39"/> is the maximum pixel displacement and <img alt="\|\nabla \tau\|_\infty" class="ql-img-inline-formula " height="19" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-ab4c5d3fe8fd25af25beb4f58a55c938_l3.png?resize=53%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="53"/> represents the maximum amount of deformation, see <a class="lipdf" href="https://www.di.ens.fr/~mallat/papiers/ScatCPAM.pdf">the paper</a> for the precise definitions of all these quantities. Note that when <img alt="C_2/\sigma_n \to 0" class="ql-img-inline-formula " height="18" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-b732bf857c5f04c7d10dda247f1a5022_l3.png?resize=85%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="85"/>, the representation <img alt="\Phi_n" class="ql-img-inline-formula " height="16" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-273242b8e92b3a9f4dc13c62b2785bd3_l3.png?resize=21%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="21"/> becomes translation invariant: indeed, consider the particular case of <img alt="\tau" class="ql-img-inline-formula " height="8" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-3af6c51247895b176bb502f0ee0857ee_l3.png?resize=10%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="10"/> being a translation, then <img alt="\nabla \tau=0" class="ql-img-inline-formula " height="14" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-aa1278a7149925a4f299de0dbb85cec0_l3.png?resize=57%2C14&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="57"/> and <img alt="\|\Phi_n(L_\tau x) - \Phi_n(x)\| \to 0" class="ql-img-inline-formula " height="19" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-cd1d650abd9970e357384c0653960577_l3.png?resize=186%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="186"/>.</p>
<p>The stability bound and a few additional results tell us a few things about the network architecture: (a) small patches lead to more stable representations (the dependency is hidden in <img alt="C_1" class="ql-img-inline-formula " height="16" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-782c65cbd411fb8862688afc92bc1eea_l3.png?resize=19%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="19"/>); (b) signal preservation for discrete signals requires small subsampling factors (and thus small pooling) between layers. In such a setting, the scale parameter <img alt="\sigma_n" class="ql-img-inline-formula " height="11" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c0142846a2999e170f7beec7be1523f2_l3.png?resize=18%2C11&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="18"/> still grows exponentially with <img alt="n" class="ql-img-inline-formula " height="8" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-a63eb5ff0272d3119fa684be6e7acce8_l3.png?resize=11%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="11"/> and near translation invariance may be achieved with several layers.</p>
<p>Interestingly, we may now come back to the Cauchy-Schwarz inequality from part 1, and note that if <img alt="\Phi_n" class="ql-img-inline-formula " height="16" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-273242b8e92b3a9f4dc13c62b2785bd3_l3.png?resize=21%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="21"/> is stable, the RKHS norm <img alt="\|f\|" class="ql-img-inline-formula " height="19" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-afe70184469e7e3a14405a7193eedf29_l3.png?resize=24%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="24"/> is then a natural quantity that provides stability to deformations to the prediction function <img alt="f" class="ql-img-inline-formula " height="16" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c7d97b919a3b73617cf2fbb375fff3b1_l3.png?resize=10%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="10"/>, in addition to measuring model complexity in a traditional sense.</p>
<p><strong>Feature learning in RKHSs and convolutional kernel networks</strong></p>
<p>The previous paragraph is devoted to the characterization of convolutional architectures such as CNNs but the previous kernel construction can in fact be used to derive more traditional kernel methods. After all, why should one spend efforts defining a kernel between images if not to use it?</p>
<p>This can be achieved by considering finite-dimensional approximations of the previous feature maps. In order to shorten the presentation, we simply describe the main idea based on the Nystrom approximation and refer to <a class="lipdf" href="http://papers.nips.cc/paper/6184-end-to-end-kernel-learning-with-supervised-convolutional-kernel-networks.pdf">the paper</a> for more details. Approximating the infinite-dimensional feature maps <img alt="x_k" class="ql-img-inline-formula " height="11" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-3ad23c5c360c3f33031a5d000d37416f_l3.png?resize=17%2C11&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="17"/> (see the figure at the top of <a class="liinternal" href="https://blogs.princeton.edu/imabandit/2019/07/10/guest-post-by-julien-mairal-a-kernel-point-of-view-on-convolutional-neural-networks-part-i/">part I</a>) can be done by projecting each point in <img alt="\mathcal{H}_k" class="ql-img-inline-formula " height="15" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-bc26f0de4084a72b9e625a080bd5d674_l3.png?resize=22%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="22"/> onto a <img alt="p_k" class="ql-img-inline-formula " height="12" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-5c72bc331dc0008f57d454e7071dc39e_l3.png?resize=17%2C12&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="17"/>-dimensional subspace <img alt="\mathcal{F}_k" class="ql-img-inline-formula " height="16" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-b08b176c0bf0adbd9cbe41b31147e1f7_l3.png?resize=20%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="20"/> leading to a finite-dimensional feature map <img alt="\tilde{x}_k" class="ql-img-inline-formula " height="15" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-5f55b75318f3b8da67917ee0b0e190ce_l3.png?resize=17%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="17"/> akin to CNNs, see the figure at the top of the post.</p>
<p>By parametrizing <img alt="\mathcal{F}_k=\text{span}(\varphi_k(z_1),\varphi_k(z_2),\ldots,\varphi_k(z_{p_k}))" class="ql-img-inline-formula " height="20" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-5dd8802df8efddb9acc5056af47339d7_l3.png?resize=297%2C20&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="297"/> with <img alt="p_k" class="ql-img-inline-formula " height="12" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-5c72bc331dc0008f57d454e7071dc39e_l3.png?resize=17%2C12&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="17"/> anchor points <img alt="Z=[z_1,\ldots,z_{p_k}]" class="ql-img-inline-formula " height="19" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-4614e1cdba47dc6a6db7957fb1d82632_l3.png?resize=123%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="123"/>, and using a dot-product kernel, a patch <img alt="z" class="ql-img-inline-formula " height="8" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-d9d772a59543419785ce66946592259a_l3.png?resize=9%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="9"/> from <img alt="\tilde{x}_{k-1}" class="ql-img-inline-formula " height="16" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-6419748397a324cd2a2ebc3f119b7f80_l3.png?resize=35%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="35"/> is encoded through the mapping function</p>
<p class="ql-center-displayed-equation" style="line-height: 43px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\[ \psi_k(z) = \|z\| \kappa_k( Z^\top Z)^{-1/2} \kappa_k\left( Z^\top \frac{z}{\|z\|} \right), \]" class="ql-img-displayed-equation " height="43" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-cc43da382f024d96cb50e3dc3f051d6f_l3.png?resize=306%2C43&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="306"/></p>
<p>where <img alt="\kappa_k" class="ql-img-inline-formula " height="11" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-684fcf23472c51919624049fb4e0129a_l3.png?resize=17%2C11&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="17"/> is applied pointwise. Then, computing <img alt="\tilde{x}_k" class="ql-img-inline-formula " height="15" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-5f55b75318f3b8da67917ee0b0e190ce_l3.png?resize=17%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="17"/> from <img alt="\tilde{x}_{k-1}" class="ql-img-inline-formula " height="16" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-6419748397a324cd2a2ebc3f119b7f80_l3.png?resize=35%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="35"/> admits a CNN interpretation, where only the normalization and the matrix multiplication by <img alt="\kappa_k( Z^\top Z)^{-1/2}" class="ql-img-inline-formula " height="21" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-a74cffbbd51922298a13f864fbedaa98_l3.png?resize=103%2C21&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="103"/> are not standard operations. It remains now to choose the anchor points:</p>
<ul>
<li><strong>kernel approximation:</strong> a first approach consists of using a variant of the Nystrom method, see <a class="lipdf" href="https://papers.nips.cc/paper/1866-using-the-nystrom-method-to-speed-up-kernel-machines.pdf">this paper</a> and <a class="lipdf" href="http://home.cse.ust.hk/~twinsen/nystrom.pdf">that one</a>. When plugging the corresponding image representation in a linear classifier, the resulting approach behaves as a classical kernel machine. Empirically, we observe that the higher the number of anchor points, the better the kernel approximation, and the higher the accuracy. For instance, a two-layer network with a <img alt="300k" class="ql-img-inline-formula " height="13" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-81a4466abb5fecba81f8a3aa055a1a14_l3.png?resize=36%2C13&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="36"/>-dimensional representations achieves about <img alt="86\%" class="ql-img-inline-formula " height="15" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-0eea28372ada596bc618b4b94fee69ec_l3.png?resize=32%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="32"/> accuracy on CIFAR-10 without data augmentation (see <a class="liinternal" href="https://gitlab.inria.fr/mairal/ckn-cudnn-matlab">here</a>).</li>
<li><strong>back-propagation, feature selection</strong>: learning the anchor points <img alt="Z" class="ql-img-inline-formula " height="12" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-cc9f8fff9fd24060bc054e78f01d5bfb_l3.png?resize=12%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="12"/> can also be done as in a traditional CNN, by optimizing them end-to-end. This allows using deeper lower-dimensional architectures and empirically seems to perform better when enough data is available, e.g., <img alt="92\%" class="ql-img-inline-formula " height="15" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-659ab3cccda2422f955af880d20646cf_l3.png?resize=32%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="32"/> accuracy on CIFAR-10 with simple data augmentation. There, the subspaces <img alt="\mathcal{F}_k" class="ql-img-inline-formula " height="16" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-b08b176c0bf0adbd9cbe41b31147e1f7_l3.png?resize=20%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="20"/> are not learned anymore to provide the best kernel approximation, but the model seems to perform a sort of feature selection in each layer’s RKHS <img alt="\mathcal{H}_k" class="ql-img-inline-formula " height="15" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-bc26f0de4084a72b9e625a080bd5d674_l3.png?resize=22%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="22"/>, which is not well understood yet (This feature selection interpretation is due to my collaborator Laurent Jacob).</li>
</ul>
<p>Note that the first CKN model published <a class="lipdf" href="https://papers.nips.cc/paper/5348-convolutional-kernel-networks.pdf">here</a> was based on a different approximation principle, which was not compatible with end-to-end training. We found this to be less scalable and effective.</p>
<p><strong>Other links between neural networks and kernel methods</strong></p>
<p>Finally, other links between kernels and infinitely-wide neural networks with random weights are classical, but they were not the topic of this blog post (they should be the topic of another one!). In a nutshell, for a large collection of weights distributions and nonlinear functions <img alt="s: \mathbb{R} \to \mathbb{R}" class="ql-img-inline-formula " height="13" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-b4680e3f9e8274687d2d04f0a262ed00_l3.png?resize=76%2C13&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="76"/>, the following quantity admits an analytical form</p>
<p class="ql-center-displayed-equation" style="line-height: 22px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\[ K(x,x') = \E_{w}[ s(w^\top x) s(w^\top x')], \]" class="ql-img-displayed-equation " height="22" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-9144f2d0b847adb69db90629ed805148_l3.png?resize=229%2C22&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="229"/></p>
<p>where the terms <img alt="s(w^\top x)" class="ql-img-inline-formula " height="19" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-da82e444bbc3a5e594b7edbf0b1ba3a0_l3.png?resize=56%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="56"/> may be seen as an infinitely-wide single-layer neural network. The first time such a relation appears is likely to be in <a class="liexternal" href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.446.9306&amp;rep=rep1&amp;type=pdf">the PhD thesis</a> of Radford Neal with a Gaussian process interpretation, and it was revisited later by <a class="lipdf" href="http://proceedings.mlr.press/v2/leroux07a/leroux07a.pdf">Le Roux and Bengio</a> and by <a class="lipdf" href="http://papers.nips.cc/paper/3628-kernel-methods-for-deep-learning.pdf">Cho and Saul</a> with multilayer models.</p>
<p>In particular, when <img alt="s" class="ql-img-inline-formula " height="8" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-3bcfb3f0b6b04be3b598743cd774dd78_l3.png?resize=8%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="8"/> is the rectified linear unit and <img alt="w" class="ql-img-inline-formula " height="8" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-78d46af3f19bae0d88ac0cabd450a296_l3.png?resize=13%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="13"/> follows a Gaussian distribution, it is known that we recover the arc-cosine kernel. We may also note that <a class="lipdf" href="http://papers.nips.cc/paper/3182-random-features-for-large-scale-kernel-machines.pdf">random Fourier features</a> also yield a similar interpretation.</p>
<p>Other important links have also been drawn recently between kernel regression and strongly over-parametrized neural networks, see <a class="lipdf" href="http://papers.nips.cc/paper/8076-neural-tangent-kernel-convergence-and-generalization-in-neural-networks.pdf">this paper</a> and <a class="lipdf" href="https://arxiv.org/pdf/1812.07956.pdf">that one</a>, which is another exciting story.</p></div>
    </content>
    <updated>2019-07-17T16:02:03Z</updated>
    <published>2019-07-17T16:02:03Z</published>
    <category term="Machine learning"/>
    <author>
      <name>Sebastien Bubeck</name>
    </author>
    <source>
      <id>https://blogs.princeton.edu/imabandit</id>
      <link href="https://blogs.princeton.edu/imabandit/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://blogs.princeton.edu/imabandit" rel="alternate" type="text/html"/>
      <subtitle>Random topics in optimization, probability, and statistics. By Sébastien Bubeck</subtitle>
      <title>I’m a bandit</title>
      <updated>2019-08-08T23:22:23Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://minimizingregret.wordpress.com/?p=207</id>
    <link href="https://minimizingregret.wordpress.com/2019/07/17/boosting-for-dynamical-systems/" rel="alternate" type="text/html"/>
    <title>Boosting for Dynamical Systems</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">by Nataly Brukhim, Naman Agarwal and Elad Hazan, based on this paper  In a famous 1906 competition at a local fair in Plymouth, England, participants were asked to guess the weight of an ox. Out of a crowd of hundreds, no one came close to the ox’s actual weight, but the average of all guesses was … <a class="more-link" href="https://minimizingregret.wordpress.com/2019/07/17/boosting-for-dynamical-systems/">Continue reading <span class="screen-reader-text">Boosting for Dynamical Systems</span> <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><em>by Nataly Brukhim, Naman Agarwal and Elad Hazan, based on <a href="https://arxiv.org/abs/1906.08720">this paper</a> </em></p>
<p>In a famous 1906 competition at a local fair in Plymouth, England, participants were asked to guess the weight of an ox. Out of a crowd of hundreds, no one came close to the ox’s actual weight, but the average of all guesses was almost correct. How is it that combining the opinions of laymen can somehow arrive at highly reasoned decisions, despite the weak judgment of individual members? This concept of harnessing wisdom from weak rules of thumb to form a highly accurate prediction rule, is the basis of ensemble methods and <b>boosting</b>. Boosting is a theoretically sound methodology that has transformed machine learning across a variety of applications; in classification and regression tasks, online learning, and many more.</p>
<p>In the case of online learning, examples for training a predictor are not available in advance, but are revealed one at a time. Online boosting combines a set of online prediction rules, or <i>weak learners. </i>At every time step, each weak learner outputs a prediction, suffers some loss and is then updated accordingly. The performance of an online learner is measured using the <i>regret</i> criterion, which compares the accumulated loss over time with that of the best fixed decision in hindsight. A <i>Boosting</i> algorithm can choose which examples are fed to each of the weak learners, as well as the losses they incur. Intuitively, the online booster can encourage some weak learners to become really good in predicting certain common cases, while allowing others to focus on edge cases that are harder to predict. Overall, the <a href="http://proceedings.mlr.press/v37/beygelzimer15.pdf">online</a> <a href="https://arxiv.org/abs/1506.04820">boosting</a> framework can achieve low regret guarantees based on the learners’ individual regret values.</p>
<p>However, online learning can become more challenging when our actions have consequences on the environment. This can be illustrated with the following experiment: imagine learning to balance a long pole on your hand. When you move your hand slightly, the pole tilts. You then move your hand in the opposite direction, and it bounces back and tilts to the other side. One jerk the wrong way might have you struggling for a good few seconds to rebalance. In other words, a <u>sequence of decisions</u> you made earlier determines whether or not the pole is balanced at any given time, rather than the single decision you make at that point.<img alt="" class=" aligncenter" height="129" src="https://minimizingregret.files.wordpress.com/2019/07/image.jpeg?w=136&amp;h=129" title="" width="136"/></p>
<p>More generally, consider cases when our environment has a <b>state, </b>and is in some sense “remembering” our past choices. A stateful framework, able to model a wide range of such phenomena, is a <i>dynamical system</i>. A dynamical system can be thought of as a function that determines, given the current state, what the state of the system will be in the next time step. Think of the physical dynamics that determines our pole’s position based on sequential hand movements. Other intuitive examples are the fluctuations of stock prices in the stock market, or the local weather temperatures; these can all be modeled with dynamical systems.</p>
<p>So how can boosting help us make better predictions for a dynamical system? In <a href="https://arxiv.org/abs/1906.08720">recent work</a> we propose an algorithm, which we refer to as DynaBoost, that achieves this goal. In the paper we provide theoretical regret bounds, as well as an empirical evaluation in a variety of applications, such as online control and time-series prediction.</p>
<p><b>Learning for Online Control</b></p>
<p>Control theory is a field of applied mathematics that deals with the control of various physical processes and engineering systems. The objective is to design an action rule, or <i>controller</i>, for a dynamical system such that steady state values are achieved quickly, and the system maintains stability.</p>
<p>Consider a simple Linear Dynamical System (LDS):</p>
<p style="text-align: center;"><img alt="x_{t+1} = A x_t + B u_t + w_t" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7Bt%2B1%7D+%3D+A+x_t+%2B+B+u_t+%2B+w_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="x_{t+1} = A x_t + B u_t + w_t"/></p>
<p>where <img alt="x_t,u_t" class="latex" src="https://s0.wp.com/latex.php?latex=x_t%2Cu_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="x_t,u_t"/> are the state and control values at time t, respectively. Assume a known transition dynamics specified by the matrices A and B, and an arbitrary disturbance to the system given by <img alt="w_t" class="latex" src="https://s0.wp.com/latex.php?latex=w_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="w_t"/>. The goal of the controller is to minimize a convex cost function <img alt="c_t(x_t,u_t)" class="latex" src="https://s0.wp.com/latex.php?latex=c_t%28x_t%2Cu_t%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="c_t(x_t,u_t)"/>.</p>
<p>A provably optimal controller for the Gaussian noise case (where <img alt="w_t" class="latex" src="https://s0.wp.com/latex.php?latex=w_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="w_t"/> are normally distributed) and when the cost functions are quadratic, is the Linear Quadratic Regulator (LQR). LQR computes a pre-fixed matrix K such that <img alt="u_t^{LQR} = K x_t" class="latex" src="https://s0.wp.com/latex.php?latex=u_t%5E%7BLQR%7D+%3D+K+x_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="u_t^{LQR} = K x_t"/>. In other words, LQR computes a linear controller – which linearly maps the state into a control at every time step.</p>
<p>A <a href="http://proceedings.mlr.press/v97/agarwal19c/agarwal19c.pdf">recent advancement</a> in online control considers <i>arbitrary</i> disturbances, as opposed to normally distributed noise. In this more general setting, there is no closed form for the optimal controller. Instead, it is proposed to use a weighted sum of previously observed noises, i.e., <img alt="u_t^{WL} = K x_t + \sum_{i=1}^H M_i w_{t-i} " class="latex" src="https://s0.wp.com/latex.php?latex=u_t%5E%7BWL%7D+%3D+K+x_t+%2B+%5Csum_%7Bi%3D1%7D%5EH+M_i+w_%7Bt-i%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="u_t^{WL} = K x_t + \sum_{i=1}^H M_i w_{t-i} "/> , where <img alt="M_1,...,M_H" class="latex" src="https://s0.wp.com/latex.php?latex=M_1%2C...%2CM_H&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="M_1,...,M_H"/> are learned parameters, updated in an online fashion. This method is shown to attain vanishing average regret compared to the best fixed linear controller in hindsight, and is applicable for general convex cost functions as opposed to only quadratics.</p>
<p>Crucially, the state-dependent term <img alt="Kx_t" class="latex" src="https://s0.wp.com/latex.php?latex=Kx_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="Kx_t"/> is not learned. Since the learned parameters of the above controller therefore considers only a fixed number of recent disturbances, we can apply existing <a href="http://ocobook.cs.princeton.edu/">online convex optimization</a> techniques developed for <a href="https://papers.nips.cc/paper/6025-online-learning-for-adversaries-with-memory-price-of-past-mistakes">learning with loss functions that have bounded memory</a>.</p>
<p><strong>Boosting for Online Control</strong></p>
<p>Using the insights described above to remove state in online control, we can now use techniques from online boosting. DynaBoost maintains multiple copies of the base-controller above, with each copy corresponding to one stage in boosting. At every time step, the control <img alt="u_t" class="latex" src="https://s0.wp.com/latex.php?latex=u_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="u_t"/> is obtained from a convex combination of the base-controllers’ outputs <img alt="u_t^{WL(1)},...,u_t^{WL(N)}" class="latex" src="https://s0.wp.com/latex.php?latex=u_t%5E%7BWL%281%29%7D%2C...%2Cu_t%5E%7BWL%28N%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="u_t^{WL(1)},...,u_t^{WL(N)}"/>. To update each base-controller’s parameters, DynaBoost feeds each controller with a <i>residual</i> <i>proxy </i>cost function, and seeks to obtain a minimizing point in the direction of the residual loss function’s gradient. Stability ensures that minimizing regret over the proxy costs (which have finite memory) suffices to minimize overall regret. See <a href="https://arxiv.org/abs/1906.08720">our paper</a> for the detailed description of the algorithm and its regret guarantees.</p>
<p><strong>Sanity check experiment</strong></p>
<p>We first conducted experiments for the standard LQR setting with i.i.d. Gaussian noise and known dynamics. We applied our boosting method to the non-optimal controller with learned parameters (Control-WL), and we observe that boosting improves its loss and achieves near-optimal performance (here the optimal controller is given by the fixed LQR solution). We have tested an LDS of different dimensions <img alt="d = 1,10,100" class="latex" src="https://s0.wp.com/latex.php?latex=d+%3D+1%2C10%2C100&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="d = 1,10,100"/>, and averaged results over multiple runs.</p>
<p><img alt="" height="182" src="https://minimizingregret.files.wordpress.com/2019/07/null.png?w=624&amp;h=182" title="" width="624"/></p>
<p><strong>Correlated noise experiment</strong></p>
<p>When the disturbances are not independently drawn, the LQR controller is not guaranteed to perform optimally. We experimented with two LDS settings with correlated disturbances in which (a) the disturbances <img alt="w_t" class="latex" src="https://s0.wp.com/latex.php?latex=w_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="w_t"/> are generated from a Gaussian random-walk, and (b) where they are generated by a sine function applied to the time index. In these cases, boosted controllers perform better compared to the “weak” learned controller, and can also outperform the fixed LQR solution. We have also tested a Recurrent Neural Network, and observed that boosting is effective for RNNs as well.</p>
<p><img alt="" height="266" src="https://minimizingregret.files.wordpress.com/2019/07/null-1.png?w=624&amp;h=266" title="" width="624"/></p>
<p><strong>Inverted Pendulum experiment</strong></p>
<p>A more challenging experiment with a non-linear dynamical system is the Inverted Pendulum experiment. This is very similar to the pole balancing example we discussed above, and is a standard benchmark for control methods. The goal is to balance the inverted pendulum by applying torque that will stabilize it in a vertically upright position, in the presence of noise. In our experiments, we used correlated disturbances from a Gaussian random-walk. We follow the dynamics implemented in <a href="https://gym.openai.com/">OpenAI Gym</a>, and test the performance of different controllers: LQR, a learned controller, and boosting. The video below visualizes this experiment:</p>
<div class="jetpack-video-wrapper"/>
<p>When averaging the loss value over multiple experiment runs, we get the following plot:</p>
<p style="text-align: center;"><img alt="" height="276" src="https://minimizingregret.files.wordpress.com/2019/07/null-2.png?w=369&amp;h=276" title="" width="369"/></p>
<p>It can be seen that the learned controller performs much better than the LQR in the presence of correlated noise, and that boosting can improve its stability and achieve lower average loss.</p>
<p><b>Boosting for Time-Series Prediction</b></p>
<p>Similarly to the control setting, in time-series prediction tasks it is sufficient to use fixed horizons, and online boosting can be efficiently applied here as well. In time-series prediction, the data is often assumed to be generated from an autoregressive moving average (ARMA) model:</p>
<p style="text-align: center;"><img alt="x_{t} = \sum_{i=1}^k \alpha_i x_{t-i} + \sum_{j=1}^q \beta_j w_j + w_t" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7Bt%7D+%3D+%5Csum_%7Bi%3D1%7D%5Ek+%5Calpha_i+x_%7Bt-i%7D+%2B+%5Csum_%7Bj%3D1%7D%5Eq+%5Cbeta_j+w_j+%2B+w_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="x_{t} = \sum_{i=1}^k \alpha_i x_{t-i} + \sum_{j=1}^q \beta_j w_j + w_t"/></p>
<p>In words, each data point <img alt="x_t" class="latex" src="https://s0.wp.com/latex.php?latex=x_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="x_t"/> is given by a weighted sum of previous points, previous noises and a new noise term <img alt="w_t" class="latex" src="https://s0.wp.com/latex.php?latex=w_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="w_t"/>, where <img alt="\alpha,\beta" class="latex" src="https://s0.wp.com/latex.php?latex=%5Calpha%2C%5Cbeta&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\alpha,\beta"/> are the coefficients vectors.</p>
<p>To test our boosting method, We experimented with 4 simulated settings: 1) normally distributed noises, 2) coefficients of the dynamical system slowly change over time, 3) a single, abrupt, change of the coefficients, and, 4) correlated noise: Gaussian random walk.</p>
<p>The weak learners tested here are the ARMA-ONS (online newton step) and ARMA-OGD (online gradient descent) algorithms for time-series prediction (See <a href="http://proceedings.mlr.press/v30/Anava13.pdf">this</a> paper for more details). We applied our boosting method, as well as a fast version of it, which applies to quadratic loss functions (we used squared difference in this case).</p>
<p><i><b>1) Gaussian Noise </b></i> <i><b>2) Changing Coefficients</b></i></p>
<p><img alt="" height="217" src="https://minimizingregret.files.wordpress.com/2019/07/null-3.png?w=289&amp;h=217" title="" width="289"/><img alt="" height="217" src="https://minimizingregret.files.wordpress.com/2019/07/null-4.png?w=289&amp;h=217" title="" width="289"/><img alt="" height="218" src="https://minimizingregret.files.wordpress.com/2019/07/null-5.png?w=292&amp;h=218" title="" width="292"/><img alt="" height="217" src="https://minimizingregret.files.wordpress.com/2019/07/null-6.png?w=290&amp;h=217" title="" width="290"/></p>
<p><i><b>3) Abrupt Change </b></i> <i><b>4) Correlated Noise</b></i></p>
<p>We can see in the plots above that all weak learners’ loss values (red) can be improved by online boosting methods (blue). A similar observation arises when experimenting with real-world data; we experimented with the Air Quality dataset from the <a href="https://archive.ics.uci.edu/ml/index.php">UCI Machine Learning repository</a>, that contains hourly averaged measurements of air quality properties from an Italian city throughout one year, as measured by chemical sensors. We apply similar weak learners to this task, as well as our boosting algorithms. Here we again obtain better averaged losses for boosted methods (blue) compared to the baselines (red).</p>
<p style="text-align: center;"><img alt="" height="373" src="https://minimizingregret.files.wordpress.com/2019/07/null-7.png?w=498&amp;h=373" title="" width="498"/></p></div>
    </content>
    <updated>2019-07-17T14:24:42Z</updated>
    <published>2019-07-17T14:24:42Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Elad Hazan</name>
    </author>
    <source>
      <id>https://minimizingregret.wordpress.com</id>
      <logo>https://minimizingregret.files.wordpress.com/2017/08/cropped-pu1.png?w=32</logo>
      <link href="https://minimizingregret.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://minimizingregret.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://minimizingregret.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://minimizingregret.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Google Princeton AI and Hazan Lab @ Princeton University</subtitle>
      <title>Minimizing Regret</title>
      <updated>2019-08-09T16:21:55Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=17564</id>
    <link href="https://gilkalai.wordpress.com/2019/07/17/dan-romik-on-the-riemann-zeta-function/" rel="alternate" type="text/html"/>
    <title>Dan Romik on the Riemann zeta function</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">This post, about the Riemann zeta function, which is among the most important and mysterious mathematical objects was kindly written by Dan Romik. It is related to his paper Orthogonal polynomial expansions for the Riemann xi function,  that we mentioned … <a href="https://gilkalai.wordpress.com/2019/07/17/dan-romik-on-the-riemann-zeta-function/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><em>This post, about the Riemann zeta function, which is among the most important and mysterious mathematical objects was kindly written by Dan Romik. It is related to his paper <a href="https://arxiv.org/abs/1902.06330">Orthogonal polynomial expansions for the Riemann xi function</a>,  that we mentioned in <a href="https://gilkalai.wordpress.com/2019/02/28/dan-romik-studies-the-riemanns-zeta-function-and-other-zeta-news/">this post</a>.</em></p>
<h2>Dan Romik on the Riemann zeta function</h2>
<p>Recently when I was thinking about the Riemann zeta function, I had the double thrill of discovering some new results about it, and then later finding out that my new ideas were closely related to some very classical ideas due to two icons of twentieth-century mathematics, George Pólya and Pál Turán. When you are trying to stand on the shoulders of giants, it’s nice to see other giants right there beside you trying to do the same!</p>
<p>It all goes back to one of the most famous problems in mathematics, the Riemann Hypothesis (RH). Both Pólya and Turán were rather enamored with this problem and published about it extensively; Pólya was said to have been preoccupied with the problem to the very end of his life.(1) And they both recognized that an important first step in trying to prove something about the zeros of the zeta function is having a good representation<br/>
for the Riemann zeta function. After all, there are many different formulas that can be used to define or compute the zeta function. If you don’t choose the right one, you probably won’t get very far with your analysis.</p>
<p>Pólya in one of his famous attacks on the problem considered the representation of the zeta function (or more precisely of the Riemann xi function, which is a symmetrized and better-behaved version of the zeta function; see below) as a Fourier transform—a standard representation due (essentially) to Riemann. I’ll have more to say about that later.</p>
<p>Turán also looked at the Riemann xi function, and instead of working with one of the standard “named” representations such as the Fourier transform or Taylor series, looked around a bit more intentionally for a representation of the function that seemed particularly suited to answering the specific question of whether the zeros all lie on a line. In a 1950 address to the Hungarian Academy of Sciences, he put forward his ideas about what he thought was the correct representation to look at: the infinite series expansion of the xi function in the Hermite polynomials. About eighty years after Turán’s discovery, my own investigations led me to discover [5] that the Hermite polynomials are not the only polynomials in which it’s interesting to expand the Riemann xi function. It turns out that there are at least two other families of polynomials for which the respective expansions are no less (and, in some ways, more) well-behaved. My motto for these polynomial families, which are known to experts in special functions but have until now been somewhat esoteric (though I hope that is about to change), is that they are “the coolest polynomials that you never heard of.”</p>
<p>Let’s look at some of the technical details so that I can explain why these new expansions are interesting, and how they relate to Turán’s work and ultimately back to Pólya’s ideas and one of the particular threads that grew out of them. First, define the Riemann xi function as</p>
<p><img alt="\displaystyle \xi(s) = \frac12 s(s-1) \pi^{-s/2} \Gamma\left(\frac{s}{2}\right) \zeta(s) \qquad (s\in\mathbb{C}), " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cxi%28s%29+%3D+%5Cfrac12+s%28s-1%29+%5Cpi%5E%7B-s%2F2%7D+%5CGamma%5Cleft%28%5Cfrac%7Bs%7D%7B2%7D%5Cright%29+%5Czeta%28s%29+%5Cqquad+%28s%5Cin%5Cmathbb%7BC%7D%29%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \xi(s) = \frac12 s(s-1) \pi^{-s/2} \Gamma\left(\frac{s}{2}\right) \zeta(s) \qquad (s\in\mathbb{C}), "/></p>
<p>where <img alt="{\Gamma(z)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CGamma%28z%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Gamma(z)}"/> is the Euler gamma function and <img alt="{\zeta(s)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Czeta%28s%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\zeta(s)}"/> is the Riemann zeta function. It’s also common to denote<br/>
<img alt="\displaystyle \Xi(t) = \xi\left(\frac12+it\right) \qquad (t\in\mathbb{C}). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5CXi%28t%29+%3D+%5Cxi%5Cleft%28%5Cfrac12%2Bit%5Cright%29+%5Cqquad+%28t%5Cin%5Cmathbb%7BC%7D%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \Xi(t) = \xi\left(\frac12+it\right) \qquad (t\in\mathbb{C}). "/></p>
<p>This is Riemann’s “capital xi” function, which is still usually referred to as Riemann’s xi function. (This seems reasonable: the two functions are the same up to a trivial linear change of variables.) The main point of these definitions is that <img alt="{\Xi(t)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CXi%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Xi(t)}"/> is an entire function of the complex variable <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t}"/>, and that RH can now be reformulated as the statement that the zeros of <img alt="{\Xi(t)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CXi%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Xi(t)}"/> all lie on the real line. Moreover, the famous functional equation satisfied by the Riemann zeta function maps to the statement that <img alt="{\Xi(t)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CXi%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Xi(t)}"/> is an even function.<br/>
Now consider the following four ways of representing the xi function:</p>
<p><img alt="\displaystyle \Xi(t) = \sum_{n=0}^\infty (-1)^n a_{2n} t^{2n},~~~~~(1)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5CXi%28t%29+%3D+%5Csum_%7Bn%3D0%7D%5E%5Cinfty+%28-1%29%5En+a_%7B2n%7D+t%5E%7B2n%7D%2C%7E%7E%7E%7E%7E%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle \Xi(t) = \sum_{n=0}^\infty (-1)^n a_{2n} t^{2n},~~~~~(1)"/></p>
<p><img alt="\displaystyle \Xi(t) = \sum_{n=0}^\infty (-1)^n b_{2n} H_{2n}(t),~~~~~(2)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5CXi%28t%29+%3D+%5Csum_%7Bn%3D0%7D%5E%5Cinfty+%28-1%29%5En+b_%7B2n%7D+H_%7B2n%7D%28t%29%2C%7E%7E%7E%7E%7E%282%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle \Xi(t) = \sum_{n=0}^\infty (-1)^n b_{2n} H_{2n}(t),~~~~~(2)"/></p>
<p><img alt="\displaystyle\Xi(t) = \sum_{n=0}^\infty (-1)^n c_{2n} f_{2n}\left(\frac{t}{2}\right),~~~~~(3)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%5CXi%28t%29+%3D+%5Csum_%7Bn%3D0%7D%5E%5Cinfty+%28-1%29%5En+c_%7B2n%7D+f_%7B2n%7D%5Cleft%28%5Cfrac%7Bt%7D%7B2%7D%5Cright%29%2C%7E%7E%7E%7E%7E%283%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle\Xi(t) = \sum_{n=0}^\infty (-1)^n c_{2n} f_{2n}\left(\frac{t}{2}\right),~~~~~(3)"/></p>
<p><img alt="\displaystyle \Xi(t) = \sum_{n=0}^\infty (-1)^n d_{2n} g_{2n}\left(\frac{t}{2}\right).~~~~~(4)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5CXi%28t%29+%3D+%5Csum_%7Bn%3D0%7D%5E%5Cinfty+%28-1%29%5En+d_%7B2n%7D+g_%7B2n%7D%5Cleft%28%5Cfrac%7Bt%7D%7B2%7D%5Cright%29.%7E%7E%7E%7E%7E%284%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle \Xi(t) = \sum_{n=0}^\infty (-1)^n d_{2n} g_{2n}\left(\frac{t}{2}\right).~~~~~(4)"/></p>
<p>Here, the first representation (1) is simply the Taylor expansion of <img alt="{\Xi(t)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CXi%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Xi(t)}"/>, which contains only even terms since <img alt="{\Xi(t)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CXi%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Xi(t)}"/> is an even function. The numbers <img alt="{a_{2n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba_%7B2n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a_{2n}}"/> are (up to the <img alt="{(-1)^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28-1%29%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(-1)^n}"/> sign factor) the Taylor coefficients. Some attempts have been made to understand them, and one interesting and fairly trivial observation (again going back to facts already known to Riemann) is that they are all positive. Some additional and less trivial things can be said—see for example Section 6.1 of my paper [5], and the recent paper by Griffin, Ono, Rolen and Zagier [2]. But at the end of the day, no one has yet succeeded in using the Taylor expansion to prove anything new about the location of the zeros.</p>
<p>The second representation (2) is the infinite series expansion of <img alt="{\Xi(t)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CXi%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Xi(t)}"/> in the classical sequence of Hermite polynomials, defined by the well-known formula</p>
<p><img alt="\displaystyle H_n(t) = (-1)^n e^{t^2} \frac{d^n}{dt^n} \left( e^{-t^2} \right). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+H_n%28t%29+%3D+%28-1%29%5En+e%5E%7Bt%5E2%7D+%5Cfrac%7Bd%5En%7D%7Bdt%5En%7D+%5Cleft%28+e%5E%7B-t%5E2%7D+%5Cright%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle H_n(t) = (-1)^n e^{t^2} \frac{d^n}{dt^n} \left( e^{-t^2} \right). "/></p>
<p>This is the representation whose use was advocated by Turán. His reasoning was that expanding a function of a complex variable (for example, in the simplest case, a polynomial) in monomials <img alt="{t^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t^n}"/> doesn’t provide useful information to easily decide if the function has only real zeros, because the monomials have, roughly speaking, radial symmetry: their level curves are concentric circles. The Hermite polynomials on the other hand, at least heuristically, have level curves that are closer to being straight lines parallel to the real axis, Turán argued; thus, they are more suited to the geometry of the problem we are trying to solve.</p>
<p>Turán’s case for supporting the Hermite polynomials as the right basis to use is quite detailed—you can read about it in his papers [6,7,8] (and no, he was not able to actually prove anything about the zeros of <img alt="{\Xi(t)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CXi%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Xi(t)}"/>; this is a common theme in most of the attacks on RH to date…). I’ll simply mention that again one interesting and fairly easy observation is that the coefficients <img alt="{b_{2n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb_%7B2n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{b_{2n}}"/> in the expansion (2)—adjusted through the introduction of the sign factor <img alt="{(-1)^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28-1%29%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(-1)^n}"/>—end up being positive numbers. Their asymptotic behavior can also be analyzed: I prove a result about this in my paper (though it’s not particularly pretty).</p>
<p>Now comes the part that to me seems the most exciting, involving the expansions (3) and (4). These are the expansions in the more exotic families of polynomials</p>
<p><img alt="\displaystyle f_n(x)=(-i)^n \sum_{k=0}^n 2^k\binom{n+\frac12}{n-k}\binom{-\frac34+ix}{k}," class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+f_n%28x%29%3D%28-i%29%5En+%5Csum_%7Bk%3D0%7D%5En+2%5Ek%5Cbinom%7Bn%2B%5Cfrac12%7D%7Bn-k%7D%5Cbinom%7B-%5Cfrac34%2Bix%7D%7Bk%7D%2C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle f_n(x)=(-i)^n \sum_{k=0}^n 2^k\binom{n+\frac12}{n-k}\binom{-\frac34+ix}{k},"/></p>
<p><img alt="\displaystyle g_n(x)= (-i)^n \sum_{k=0}^n \frac{(n+k+1)!}{(n-k)!(3/2)_k^2} \binom{-\frac34+ix}{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+g_n%28x%29%3D+%28-i%29%5En+%5Csum_%7Bk%3D0%7D%5En+%5Cfrac%7B%28n%2Bk%2B1%29%21%7D%7B%28n-k%29%21%283%2F2%29_k%5E2%7D+%5Cbinom%7B-%5Cfrac34%2Bix%7D%7Bk%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle g_n(x)= (-i)^n \sum_{k=0}^n \frac{(n+k+1)!}{(n-k)!(3/2)_k^2} \binom{-\frac34+ix}{k}"/></p>
<p>(where <img alt="{(3/2)_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%283%2F2%29_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(3/2)_n}"/> is a <a href="https://en.wikipedia.org/wiki/Falling_and_rising_factorials">Pochhammer symbol</a>), mildly rescaled by replacing <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/>  with <img alt="{t/2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t/2}"/>. In the terminology of the theory of orthogonal polynomials, the family <img alt="{f_n(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_n%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_n(x)}"/> is a special case of a two-parameter family <img alt="{P_n^{(\lambda)}(x;\phi)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP_n%5E%7B%28%5Clambda%29%7D%28x%3B%5Cphi%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{P_n^{(\lambda)}(x;\phi)}"/> known as the Meixner-Pollaczek polynomials, with the parameters taking the particular values <img alt="{\phi=\frac{\pi}{2}, \lambda=\frac{3}{4}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%3D%5Cfrac%7B%5Cpi%7D%7B2%7D%2C+%5Clambda%3D%5Cfrac%7B3%7D%7B4%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\phi=\frac{\pi}{2}, \lambda=\frac{3}{4}}"/>. Similarly, the family <img alt="{g_n(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg_n%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{g_n(x)}"/> is a special case of the four-parameter family <img alt="{p_n(x;a,b,c,d)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_n%28x%3Ba%2Cb%2Cc%2Cd%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p_n(x;a,b,c,d)}"/> known as the continuous Hahn polynomials, with the parameters taking the particular values <img alt="{a=b=c=d=\frac{3}{4}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%3Db%3Dc%3Dd%3D%5Cfrac%7B3%7D%7B4%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a=b=c=d=\frac{3}{4}}"/>. Their main characterizing property is that they are orthogonal sequences of polynomials for two specific weight functions on <img alt="{\mathbb{R}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BR%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathbb{R}}"/>: the <img alt="{f_n(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_n%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_n(x)}"/> are orthogonal with respect to the weight function <img alt="{w_1(x)=\left|\Gamma\left(\frac34+ix\right)\right|^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw_1%28x%29%3D%5Cleft%7C%5CGamma%5Cleft%28%5Cfrac34%2Bix%5Cright%29%5Cright%7C%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{w_1(x)=\left|\Gamma\left(\frac34+ix\right)\right|^2}"/>, and the <img alt="{g_n(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg_n%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{g_n(x)}"/> are orthogonal with respect to <img alt="{w_2(x)=\left|\Gamma\left(\frac34+ix\right)\right|^4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw_2%28x%29%3D%5Cleft%7C%5CGamma%5Cleft%28%5Cfrac34%2Bix%5Cright%29%5Cright%7C%5E4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{w_2(x)=\left|\Gamma\left(\frac34+ix\right)\right|^4}"/>. Again, fairly esoteric. But interesting!</p>
<p>There are several things that make the expansions (3)–(4) well-behaved. First, the coefficients <img alt="{c_{2n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc_%7B2n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c_{2n}}"/>, <img alt="{d_{2n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd_%7B2n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d_{2n}}"/> are again positive. This actually seems pretty relevant for questions like RH: for example, if we consider “toy” versions of (1)–(3) in which the coefficient sequences <img alt="{a_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a_n}"/>, <img alt="{b_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{b_n}"/> and <img alt="{c_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c_n}"/> are replaced by the sequence <img alt="{\alpha^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha^n}"/> for fixed <img alt="{0&lt;\alpha&lt;1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%3C%5Calpha%3C1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0&lt;\alpha&lt;1}"/>, all three expansions sum up to rescaled cosines, which are entire functions that of course have only real zeros. (Without the <img alt="{(-1)^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28-1%29%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(-1)^n}"/> factor, we would get a hyperbolic cosine, which has imaginary zeros.)</p>
<p>Second, one can derive asymptotics for <img alt="{c_{2n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc_%7B2n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c_{2n}}"/> and <img alt="{d_{2n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd_%7B2n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d_{2n}}"/>, and they are quite a bit nicer than the asymptotic formulas for the Taylor and Hermite expansion coefficients. In my paper, I proved that <img alt="\displaystyle c_{2n} \sim A \sqrt{n} e^{-B \sqrt{n}}, \qquad d_{2n} \sim C n^{4/3} e^{-D n^{2/3}} \qquad \textrm{as }n\rightarrow\infty, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+c_%7B2n%7D+%5Csim+A+%5Csqrt%7Bn%7D+e%5E%7B-B+%5Csqrt%7Bn%7D%7D%2C+%5Cqquad+d_%7B2n%7D+%5Csim+C+n%5E%7B4%2F3%7D+e%5E%7B-D+n%5E%7B2%2F3%7D%7D+%5Cqquad+%5Ctextrm%7Bas+%7Dn%5Crightarrow%5Cinfty%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle c_{2n} \sim A \sqrt{n} e^{-B \sqrt{n}}, \qquad d_{2n} \sim C n^{4/3} e^{-D n^{2/3}} \qquad \textrm{as }n\rightarrow\infty, "/> where <img alt="{A,B,C,D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%2CB%2CC%2CD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A,B,C,D}"/> are the constants <img alt="\displaystyle A = 16\sqrt{2}\pi^{3/2}, \qquad B = 4\sqrt{\pi}, \qquad C = \frac{128 \times 2^{1/3} \pi^{2/3} e^{-2\pi /3}}{\sqrt{3}}, \qquad D = 3 (4\pi)^{1/3}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+A+%3D+16%5Csqrt%7B2%7D%5Cpi%5E%7B3%2F2%7D%2C+%5Cqquad+B+%3D+4%5Csqrt%7B%5Cpi%7D%2C+%5Cqquad+C+%3D+%5Cfrac%7B128+%5Ctimes+2%5E%7B1%2F3%7D+%5Cpi%5E%7B2%2F3%7D+e%5E%7B-2%5Cpi+%2F3%7D%7D%7B%5Csqrt%7B3%7D%7D%2C+%5Cqquad+D+%3D+3+%284%5Cpi%29%5E%7B1%2F3%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle A = 16\sqrt{2}\pi^{3/2}, \qquad B = 4\sqrt{\pi}, \qquad C = \frac{128 \times 2^{1/3} \pi^{2/3} e^{-2\pi /3}}{\sqrt{3}}, \qquad D = 3 (4\pi)^{1/3}. "/></p>
<p>Third, the expansions have some conceptual meaning: (3) turns out to be equivalent to the expansion of the elementary function <img alt="{\frac{d^2}{du^2} (u \coth(\pi u))}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7Bd%5E2%7D%7Bdu%5E2%7D+%28u+%5Ccoth%28%5Cpi+u%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\frac{d^2}{du^2} (u \coth(\pi u))}"/>, <img alt="{u&gt;0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u&gt;0}"/>, in an orthogonal basis of functions related to the Laguerre polynomials <img alt="{L_n^{1/2}(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_n%5E%7B1%2F2%7D%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_n^{1/2}(x)}"/>. And analogously, (4) arises out of the expansion of a certain auxiliary function <img alt="{\tilde{\nu}(u)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctilde%7B%5Cnu%7D%28u%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\tilde{\nu}(u)}"/> (I won’t define it here) in yet another classical family of orthogonal polynomials, the Chebyshev polynomials of the second kind.</p>
<p>Fourth (and fifth, sixth, …): the expansions are just… nice, in the sense that they arise in a way that seems natural when one asks certain questions, that they have excellent convergence properties, and that the coefficients <img alt="{c_{2n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc_%7B2n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c_{2n}}"/> and <img alt="{d_{2n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd_%7B2n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d_{2n}}"/> have several elegant formulas, each revealing something interesting about them. Read the paper to understand more.</p>
<p>I said I will get back to Pólya’s work on RH. This post is already quite long so I will say only a little bit about this. One of Pólya’s major discoveries was that there are operations on entire functions that (under certain mild assumptions) preserve the property of the function having only real zeros. Specifically this is the case for the operation of multiplying the Fourier transform of the function by the factor <img alt="{e^{\lambda u^2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Be%5E%7B%5Clambda+u%5E2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{e^{\lambda u^2}}"/> for <img alt="{\lambda&gt;0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\lambda&gt;0}"/>  (where <img alt="{u}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u}"/> is the frequency variable). This opens the way to defining a family of deformations <img alt="{\Xi_\lambda(t)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CXi_%5Clambda%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Xi_\lambda(t)}"/> of the Riemann xi function arising out of this operation, and trying to generalize RH by asking for which values of <img alt="{\lambda}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\lambda}"/> it is the case that <img alt="{\Xi_\lambda(t)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CXi_%5Clambda%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Xi_\lambda(t)}"/> has only real zeros. Since Pólya’s work, and important later extensions of it by De Bruijn and Newman, this has become a very active topic of research, nowadays referred to under the name of the De Bruijn-Newman constant.<br/>
See the recent survey of Newman and Wu [3], a 2018 paper by Rodgers and Tao [4] proving a major conjecture of Newman, and the recent paper [9] by the <a href="https://terrytao.wordpress.com/2018/12/28/polymath-15-eleventh-thread-writing-up-the-results-and-exploring-negative-t/">Polymath15 project</a> (mentioned by Gil in his <a href="https://gilkalai.wordpress.com/2019/02/28/dan-romik-studies-the-riemanns-zeta-function-and-other-zeta-news/">earlier post</a>), for the latest on this subject.</p>
<p>The connection I found between this topic and the idea of expanding the Riemann xi function in families of orthogonal polynomials is the following: expansions such as (2)–(4) suggest yet another natural way of “deforming” the Riemann xi function by adding a parameter <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/>: simply multiply the <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>th term in the expansion by <img alt="{\alpha^{2n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%5E%7B2n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha^{2n}}"/> (the linear operator that does this is called the Poisson kernel, and generalizes the standard Poisson kernel from complex analysis and the theory of harmonic functions). It turns out—and is actually easy to prove, and really isn’t terribly surprising in the grand scheme of things—that in the case of the Hermite expansion (2), this family of deformations is the same, up to some trivial reparametrization, as the family of deformations <img alt="{\Xi_\lambda(t)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CXi_%5Clambda%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Xi_\lambda(t)}"/> that was studied in connection with the work of Pólya, De Bruijn, Newman and their successors. A nice connection between two threads of research that were not previously recognized as being related to each other, I think. Furthermore, this suggests that the Poisson kernel and associated deformations may yet have an important role to play in the context of the new expansions in the orthogonal polynomial families <img alt="{f_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_n}"/> and <img alt="{g_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{g_n}"/>, where we get genuinely new families of deformations of the Riemann xi function. I explore this idea in my paper and it leads to some interesting things.</p>
<p>So let’s summarize. The key questions you are no doubt wondering about are: where does any of this lead? And do these new ideas say anything really useful or especially relevant for the Riemann hypothesis? The answer is that I don’t know (and I’m wondering about the same things). That being said, these orthogonal polynomial expansions seem quite interesting in their own right. The Riemann zeta function is a mysterious object, and there are <a href="https://en.wikipedia.org/wiki/Lindel%C3%B6f_hypothesis">other things</a> we wish to understand about it beside where its zeros are, so it’s always good to have additional points of view from which to approach it. Moreover, even on the question of the zeros there are reasons to be cautiously optimistic that this approach may have something useful to offer; see Chapter 7 of my paper for a brief discussion of why that is the case.</p>
<h2/>
<h2>References</h2>
<p>[1] D. Albers and G. L. Alexanderson, editors. Mathematical People: Profiles and Interviews. A K Peters, 2008.</p>
<p>[2] M. Griffin, K. Ono, L. Rolen and D. Zagier. Jensen polynomials for the Riemann zeta function and other sequences. Preprint (2019), <a href="https://arxiv.org/abs/1902.07321">arXiv:1902.07321</a>.</p>
<p>[3] C. M. Newman. Constants of de Bruijn-Newman type in analytic number theory and statistical physics. To appear in Bull. Amer. Math. Soc.</p>
<p>[4] B. Rodgers and T. Tao. The De Bruijn-Newman constant is nonnegative. Preprint (2018), <a href="https://arxiv.org/abs/1801.05914">arXiv:1801.05914</a>.</p>
<p>[5] D. Romik. <a href="https://arxiv.org/abs/1902.06330">Orthogonal polynomial expansions for the Riemann xi function</a>. Preprint (2019), <a href="https://arxiv.org/abs/1902.06330">arXiv:1902.06330</a>.</p>
<p>[6] P. Turán. Sur l’algèbre fonctionelle. Pages 279–290 in: Comptes Rendus du Premier Congrès des Mathématiciens Hongrois, 27 Août–2 Septembre 1950. Akadémiai Kiadó, 1952. Reprinted in Collected Papers of Paul Turán, Ed. P. Erdos, Vol. 1, pp. 677–688. Akadémiai Kiadó, 1990. An English translation of the paper by Dan Romik <a href="http://math.ucdavis.edu/~romik/data/uploads/misc/turan1952-english.pdf">On functional algebra</a>.</p>
<p>[7] P. Turán. Hermite-expansion and strips for zeros of polynomials. Arch. Math. 5 (1954), 148–152. Reprinted in Collected Papers of Paul Turán, Ed. P. Erdos, Vol. 1, pp. 738–742. Akadémiai Kiadó, 1990.</p>
<p>[8]  P. Turán. To the analytical theory of algebraic equations. Bulgar. Akad. Nauk. Otd. Mat. Fiz. Nauk. Izv. Mat. Inst. 3 (1959), 123–137. Reprinted in Collected Papers of Paul Turán, Ed. P. Erdos, Vol. 2, pp. 1080–1090. Akadémiai Kiadó, 1990.</p>
<p>[9] D.H.J. Polymath. Effective approximation of heat flow evolution of the Riemann ξ function, and a new upper bound for the de Bruijn-Newman constant. Preprint (2019), <a href="https://arxiv.org/abs/1904.12438">arXiv:1904.12438</a>.</p>
<h2>Notes:</h2>
<p>(1) Alexanderson writes in [1, p. 259]: “A week or so before he died, Pólya asked me to look on his desk at home for some papers on which he said he had written down some interesting ideas he had for proving RH. Of course I could find no such notes, but until the day he died he was thinking about that famous problem.”</p>
<p> </p>
<p>(2) Turán’s Hungarian Academy of Sciences talk was published in a rather obscure French-language paper [6] that seems to have been largely forgotten. It’s an interesting read nonetheless, and to make it more accessible to anyone who may be interested, I recently translated it to English.</p>
<p> </p>
<p>(3) Turán mentions in [8] that he discovered the results on the Hermite expansion in 1938–39, but they were not published until much later. Clearly this was not a convenient time in history for publishing such discoveries; Turán, a Hungarian Jew, spent much of World War II interned in labor camps in Hungary.</p></div>
    </content>
    <updated>2019-07-17T06:22:33Z</updated>
    <published>2019-07-17T06:22:33Z</published>
    <category term="Combinatorics"/>
    <category term="Guest blogger"/>
    <category term="Number theory"/>
    <category term="Dan Romik"/>
    <category term="George Polya"/>
    <category term="Paul Turan"/>
    <category term="Riemann Hypothesis"/>
    <category term="Riemann zeta function"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-08-09T16:20:37Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16114</id>
    <link href="https://rjlipton.wordpress.com/2019/07/16/summer-reading-in-theory/" rel="alternate" type="text/html"/>
    <title>Summer Reading in Theory</title>
    <summary>Some formative books in mathematics and computing theory LSE source: “Calculus on Clay?” Norman Biggs is the author of the wonderful book Algebraic Graph Theory. Both Ken and I read it long ago, and both of us have it out now because of its relevance to Hao Huang’s beautiful short proof of the Boolean Sensitivity […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Some formative books in mathematics and computing theory</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2019/07/biggs-norman-150x150.jpg"><img alt="" class="alignright size-full wp-image-16115" src="https://rjlipton.files.wordpress.com/2019/07/biggs-norman-150x150.jpg?w=600"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">LSE <a href="https://blogs.lse.ac.uk/maths/2016/04/15/norman-biggs-calculus-on-clay/">source</a>: <i>“Calculus on Clay?”</i></font></td>
</tr>
</tbody>
</table>
<p>
Norman Biggs is the author of the wonderful <a href="https://www.cambridge.org/core/books/algebraic-graph-theory/6C70471342F19680068C35EF174075DC">book</a> <em>Algebraic Graph Theory</em>. Both Ken and I read it long ago, and both of us have it out now because of its relevance to Hao Huang’s beautiful short <a href="http://www.mathcs.emory.edu/~hhuan30/papers/sensitivity_1.pdf">proof</a> of the Boolean Sensitivity Conjecture. </p>
<p>
Today we wish to ask, <i>What are your top five favorite books on mathematics and theory for summer reading?</i><br/>
<span id="more-16114"/></p>
<p>
There’s an <a href="https://en.wikipedia.org/wiki/Aporia">aporia</a> in that question. A working definition of aporia is: “a self-contradiction that isn’t.” The point is that books for summer reading should be new, so how would you already know which are your favorites? Well, we are thinking of books that are so rich you can always find new things in them—and that also played formative roles earlier in our careers.</p>
<p>
Ken knew Biggs during his first year at Oxford when Biggs was visiting there from London. He took part in a weekly sitting-room seminar organized by Peter Neumann. Biggs’s book was a central reference for Ken’s undergraduate senior thesis at Princeton, and both he and Ken presented material based on it. </p>
<p>
</p><p/><h2> Best Five Books—Dick </h2><p/>
<p/><p>
Here are my votes for all-time best books in mathematics and in computer science theory.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <a href="https://www.cambridge.org/core/books/algebraic-graph-theory/6C70471342F19680068C35EF174075DC"><i>Algebraic Graph Theory</i></a>, by Norman Biggs. A wonderful book. First appeared in 1974.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <a href="https://www.amazon.com/Introduction-Probability-Theory-Applications-Vol/dp/0471257087/ref=sr_1_1?keywords=William+Feller&amp;qid=1563190401&amp;s=books&amp;sr=1-1"><i> An Introduction to Probability Theory and Its Applications, Vol. 1</i></a>, by William Feller. This is the book I used to learn probability theory.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <a href="https://www.amazon.com/gp/product/0199219869/ref=as_li_tl?ie=UTF8&amp;tag=mathblog05-20&amp;camp=1789&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=0199219869&amp;linkId=a71963a143733e948f50588526d624c0"><i> An Introduction to the Theory of Numbers</i></a>, by Godfrey Hardy and Edward Wright. Now updated by Andrew Wiles, Roger Heath-Brown, and Joseph Silverman. </p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <a href="https://www.amazon.com/Elements-Number-Theory-Dover-Mathematics/dp/0486781658/ref=sr_1_1?keywords=Vinogradov&amp;qid=1563190340&amp;s=books&amp;sr=1-1"><i>Elements of Number Theory</i></a>, by Ivan Vinogradov. Another small book that is loaded with ideas. </p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <a href="https://www.abebooks.com/Paul-Erds-Art-Counting-Erdos-Joel/13380002114/bd"><i>The Art of Counting</i></a>, by Paul Erdős and Joel Spencer. This book changed my life. Today the book is of course <a href="https://www.amazon.com/dp/0470170204/?tag=stackoverfl08-20"><i>The Probabilistic Method</i></a>, by Noga Alon and Joel Spencer. </p>
<p>
</p><p/><h2> Best Five Books—Ken </h2><p/>
<p/><p>
Ken reaches back to his teen years but it’s still the same span of years as my list. Here he tells it:</p>
<p>
<img alt="{\bullet}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet}"/> All books by Martin Gardner—in particular, the books of collections of his “Mathematical Games” columns in <em>Scientific American</em>. Here is an <a href="https://blogs.scientificamerican.com/guest-blog/the-top-10-martin-gardner-scientific-american-articles/">overview</a>.</p>
<p>
<img alt="{\bullet}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet}"/> <a href="https://www.lybrary.com/scarne-on-dice-p-655.html"><i>Scarne on Dice</i></a> and <a href="https://www.lybrary.com/scarne-on-cards-p-759.html"><i> Scarne on Cards</i></a>. Originally it was neither of these books—nor John Scarne’s <em>Complete Guide to Gambling</em>—but a different book on in which both Scarne and Gardner figured prominently. Alas I, Ken, cannot trace it. That’s what I used to learn probability theory.</p>
<p>
<img alt="{\bullet}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet}"/> <a href="https://www.amazon.com/Spectra-Graphs-Application-Applied-Mathematics/dp/0121951502"><i>Spectra of Graphs</i></a>, by Dragoš Cvetković, Michael Doob, and Horst Sachs. I could put Biggs’s book here, but this is the one that got me on to the whole subject just before my senior year at Princeton. It was fresh out in 1980—I recall the tactile sensation of the dark green spanking new cover in the Fine Hall Library’s copy. A great book with pictures and algebra. </p>
<p>
<img alt="{\bullet}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet}"/> <a href="https://www.amazon.com/Ideals-Varieties-Algorithms-Computational-Undergraduate/dp/0387356509"><i> Ideals, Varieties, and Algorithms</i></a>, by David Cox, John Little, and Donal O’Shea. Fast forward to 1997. Having realized that techniques from algebraic geometry could surmount the “Natural Proofs” <a href="https://rjlipton.wordpress.com/2009/03/25/whos-afraid-of-natural-proofs/">barrier</a> (see also <a href="https://en.wikipedia.org/wiki/Geometric_complexity_theory">GCT</a>), I went whole-hog after it. See “Manic Monomials” in this <a href="https://rjlipton.wordpress.com/2012/07/04/july-fourth-sale-of-ideas/">post</a> for one thing that tripped it up. The book remains incredibly stimulating. It has a <a href="https://www.amazon.com/Using-Algebraic-Geometry-Graduate-Mathematics/dp/0387984879/">sequel</a>, <em>Using Algebraic Geometry</em>.</p>
<p>
<img alt="{\bullet}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet}"/> <a href="https://en.wikipedia.org/wiki/Quantum_Computation_and_Quantum_Information"><i>Quantum Computation and Quantum Information</i></a> by Michael Nielsen and Isaac Chuang. As with Hardy and Wright, it has its own Wikipedia page. Dick and I can say this is nominating a competitor, but Chaung &amp; Nielsen is really in a class by itself for the sheer richness and writing style. One odd mark of its influence: In 2006 when I reacted to the sensational and frightening accusations of cheating at the world championship <a href="https://en.wikipedia.org/wiki/World_Chess_Championship_2006">match</a>, my first thought was to apply distributional distance measures of the kind used in its later chapters. Among such measures is (quantum) <a href="https://en.wikipedia.org/wiki/Fidelity_of_quantum_states">fidelity</a>, and although I focused more on Jensen-Shannon divergence before deciding on simpler stuff, my chess research <a href="https://cse.buffalo.edu/~regan/chess/fidelity/">website</a> retains “fidelity” in its name as part of a multi-way reference to <a href="https://en.wikipedia.org/wiki/FIDE">FIDE</a>, faith, and playing in good faith.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
What books most influenced you? What are your votes for the best books that might influence others?	 </p></font></font></div>
    </content>
    <updated>2019-07-17T04:26:38Z</updated>
    <published>2019-07-17T04:26:38Z</published>
    <category term="All Posts"/>
    <category term="History"/>
    <category term="Ideas"/>
    <category term="Oldies"/>
    <category term="Teaching"/>
    <category term="algebraic"/>
    <category term="books"/>
    <category term="Hao Huang"/>
    <category term="Norman Biggs"/>
    <category term="probabilistic"/>
    <category term="spectral graph theory"/>
    <category term="summer reading"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-08-09T16:20:45Z</updated>
    </source>
  </entry>
</feed>
