<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2020-09-30T07:21:25Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.14191</id>
    <link href="http://arxiv.org/abs/2009.14191" rel="alternate" type="text/html"/>
    <title>Multidimensional Stable Roommates with Master List</title>
    <feedworld_mtime>1601424000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bredereck:Robert.html">Robert Bredereck</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Heeger:Klaus.html">Klaus Heeger</a>, Dušan Knop, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Niedermeier:Rolf.html">Rolf Niedermeier</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.14191">PDF</a><br/><b>Abstract: </b>Since the early days of research in algorithms and complexity, the
computation of stable matchings is a core topic. While in the classic setting
the goal is to match up two agents (either from different "gender" (this is
Stable Marriage) or "unrestricted" (this is Stable Roommates)), Knuth [1976]
triggered the study of three- or multidimensional cases. Here, we focus on the
study of Multidimensional Stable Roommates, known to be NP-hard since the early
1990's. Many NP-hardness results, however, rely on very general input instances
that do not occur in at least some of the specific application scenarios. With
the quest for identifying islands of tractability, we look at the case of
master lists. Here, as natural in applications where agents express their
preferences based on "objective" scores, one roughly speaking assumes that all
agent preferences are "derived from" a central master list, implying that the
individual agent preferences shall be similar. Master lists have been
frequently studied in the two-dimensional (classic) stable matching case, but
seemingly almost never for the multidimensional case. This work, also relying
on methods from parameterized algorithm design and complexity analysis,
performs a first systematic study of Multidimensional Stable Roommates under
the assumption of master lists.
</p></div>
    </summary>
    <updated>2020-09-30T01:20:30Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-09-30T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.14043</id>
    <link href="http://arxiv.org/abs/2009.14043" rel="alternate" type="text/html"/>
    <title>Online Simple Knapsack with Reservation Costs</title>
    <feedworld_mtime>1601424000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Hans-Joachim Boeckenhauer, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Burjons:Elisabet.html">Elisabet Burjons</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hromkovic:Juraj.html">Juraj Hromkovic</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lotze:Henri.html">Henri Lotze</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rossmanith:Peter.html">Peter Rossmanith</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.14043">PDF</a><br/><b>Abstract: </b>In the Online Simple Knapsack Problem we are given a knapsack of unit size 1.
Items of size smaller or equal to 1 are presented in an iterative fashion and
an algorithm has to decide whether to permanently include or reject each item
into the knapsack without any knowledge about the rest of the instance. The
goal is then to pack the knapsack as full as possible. In this work, we
introduce a third option additional to those of packing and rejecting an item,
namely that of reserving an item for the cost of a fixed fraction $\alpha$ of
its size. An algorithm may pay this fraction in order to postpone its decision
on whether to include or reject the item until after the last item of the
instance was presented.
</p>
<p>While the classical Online Simple Knapsack Problem does not admit any
constantly bounded competitive ratio in the deterministic setting, we find that
adding the possibility of reservation makes the problem constantly competitive,
with varying competitive ratios depending on the value of $\alpha$. We give
upper and lower bounds for the whole range of reservation costs, with tight
bounds for costs up to $1/6$---an area that is strictly 2-competitive---and for
costs between $\sqrt{2}-1$ and $0.5$---an area that is
$(2+\alpha)$-competitive.
</p>
<p>With our analysis, we find a counterintuitive characteristic of the problem:
Intuitively, one would expect that the possibility of rejecting items becomes
more and more helpful for an online algorithm with growing reservation costs.
However, for higher reservation costs between $\sqrt{2}-1$ and $0.5$, an
algorithm that is unable to reject any items tightly matches the lower bound
and is thus the best possible. On the other hand, for any positive reservation
cost smaller than $1/6$, any algorithm that is unable to reject any items
performs considerably worse than one that is able to reject.
</p></div>
    </summary>
    <updated>2020-09-30T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-09-30T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.14004</id>
    <link href="http://arxiv.org/abs/2009.14004" rel="alternate" type="text/html"/>
    <title>On the mixing time of coordinate Hit-and-Run</title>
    <feedworld_mtime>1601424000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Narayanan:Hariharan.html">Hariharan Narayanan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Srivastava:Piyush.html">Piyush Srivastava</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.14004">PDF</a><br/><b>Abstract: </b>We obtain a polynomial upper bound on the mixing time $T_{CHR}(\epsilon)$ of
the coordinate Hit-and-Run random walk on an $n-$dimensional convex body, where
$T_{CHR}(\epsilon)$ is the number of steps needed in order to reach within
$\epsilon$ of the uniform distribution with respect to the total variation
distance, starting from a warm start (i.e., a distribution which has a density
with respect to the uniform distribution on the convex body that is bounded
above by a constant). Our upper bound is polynomial in $n, R$ and
$\frac{1}{\epsilon}$, where we assume that the convex body contains the unit
$\Vert\cdot\Vert_\infty$-unit ball $B_\infty$ and is contained in its
$R$-dilation $R\cdot B_\infty$. Whether coordinate Hit-and-Run has a polynomial
mixing time has been an open question.
</p></div>
    </summary>
    <updated>2020-09-30T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-09-30T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.13998</id>
    <link href="http://arxiv.org/abs/2009.13998" rel="alternate" type="text/html"/>
    <title>Simultaneous Greedys: A Swiss Army Knife for Constrained Submodular Maximization</title>
    <feedworld_mtime>1601424000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Feldman:Moran.html">Moran Feldman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Harshaw:Christopher.html">Christopher Harshaw</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Karbasi:Amin.html">Amin Karbasi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.13998">PDF</a><br/><b>Abstract: </b>In this paper, we present SimultaneousGreedys, a deterministic algorithm for
constrained submodular maximization. At a high level, the algorithm maintains
$\ell$ solutions and greedily updates them in a simultaneous fashion, rather
than a sequential one. SimultaneousGreedys achieves the tightest known
approximation guarantees for both $k$-extendible systems and the more general
$k$-systems, which are $(k+1)^2/k = k + \mathcal{O}(1)$ and $(1 + \sqrt{k+2})^2
= k + \mathcal{O}(\sqrt{k})$, respectively. This is in contrast to previous
algorithms, which are designed to provide tight approximation guarantees in one
setting, but not both. Furthermore, these approximation guarantees further
improve to $k+1$ when the objective is monotone. We demonstrate that the
algorithm may be modified to run in nearly linear time with an arbitrarily
small loss in the approximation. This leads to the first nearly linear time
algorithm for submodular maximization over $k$-extendible systems and
$k$-systems. Finally, the technique is flexible enough to incorporate the
intersection of $m$ additional knapsack constraints, while retaining similar
approximation guarantees, which are roughly $k + 2m + \mathcal{O}(\sqrt{k+m})$
for $k$-systems and $k+2m + \mathcal{O}(\sqrt{m})$ for $k$-extendible systems.
To complement our algorithmic contributions, we provide a hardness result which
states that no algorithm making polynomially many queries to the value and
independence oracles can achieve an approximation better than $k + 1/2 +
\varepsilon$.
</p></div>
    </summary>
    <updated>2020-09-30T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-09-30T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.13989</id>
    <link href="http://arxiv.org/abs/2009.13989" rel="alternate" type="text/html"/>
    <title>Nonlinear Monte Carlo methods with polynomial runtime for high-dimensional iterated nested expectations</title>
    <feedworld_mtime>1601424000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Beck:Christian.html">Christian Beck</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jentzen:Arnulf.html">Arnulf Jentzen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kruse:Thomas.html">Thomas Kruse</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.13989">PDF</a><br/><b>Abstract: </b>The approximative calculation of iterated nested expectations is a recurring
challenging problem in applications. Nested expectations appear, for example,
in the numerical approximation of solutions of backward stochastic differential
equations (BSDEs), in the numerical approximation of solutions of semilinear
parabolic partial differential equations (PDEs), in statistical physics, in
optimal stopping problems such as the approximative pricing of American or
Bermudan options, in risk measure estimation in mathematical finance, or in
decision-making under uncertainty. Nested expectations which arise in the above
named applications often consist of a large number of nestings. However, the
computational effort of standard nested Monte Carlo approximations for iterated
nested expectations grows exponentially in the number of nestings and it
remained an open question whether it is possible to approximately calculate
multiply iterated high-dimensional nested expectations in polynomial time. In
this article we tackle this problem by proposing and studying a new class of
full-history recursive multilevel Picard (MLP) approximation schemes for
iterated nested expectations. In particular, we prove under suitable
assumptions that these MLP approximation schemes can approximately calculate
multiply iterated nested expectations with a computational effort growing at
most polynomially in the number of nestings $ K \in \mathbb{N} = \{1, 2, 3,
\ldots \} $, in the problem dimension $ d \in \mathbb{N} $, and in the
reciprocal $\frac{1}{\varepsilon}$ of the desired approximation accuracy $
\varepsilon \in (0, \infty) $.
</p></div>
    </summary>
    <updated>2020-09-30T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-09-30T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.13949</id>
    <link href="http://arxiv.org/abs/2009.13949" rel="alternate" type="text/html"/>
    <title>Improved FPT Algorithms for Deletion to Forest-like Structures</title>
    <feedworld_mtime>1601424000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gowda:Kishen_N=.html">Kishen N. Gowda</a>, Aditya Lonkar, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Panolan:Fahad.html">Fahad Panolan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Patel:Vraj.html">Vraj Patel</a>, Saket Saurabh <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.13949">PDF</a><br/><b>Abstract: </b>The Feedback Vertex Set problem is undoubtedly one of the most well-studied
problems in Parameterized Complexity. In this problem, given an undirected
graph $G$ and a non-negative integer $k$, the objective is to test whether
there exists a subset $S\subseteq V(G)$ of size at most $k$ such that $G-S$ is
a forest. After a long line of improvement, recently, Li and Nederlof [SODA,
2020] designed a randomized algorithm for the problem running in time
$\mathcal{O}^{\star}(2.7^k)$. In the Parameterized Complexity literature,
several problems around Feedback Vertex Set have been studied. Some of these
include Independent Feedback Vertex Set (where the set $S$ should be an
independent set in $G$), Almost Forest Deletion and Pseudoforest Deletion. In
Pseudoforest Deletion, each connected component in $G-S$ has at most one cycle
in it. However, in Almost Forest Deletion, the input is a graph $G$ and
non-negative integers $k,\ell \in \mathbb{N}$, and the objective is to test
whether there exists a vertex subset $S$ of size at most $k$, such that $G-S$
is $\ell$ edges away from a forest. In this paper, using the methodology of Li
and Nederlof [SODA, 2020], we obtain the current fastest algorithms for all
these problems. In particular we obtain following randomized algorithms.
</p>
<p>1) Independent Feedback Vertex Set can be solved in time
$\mathcal{O}^{\star}(2.7^k)$.
</p>
<p>2) Pseudo Forest Deletion can be solved in time
$\mathcal{O}^{\star}(2.85^k)$.
</p>
<p>3) Almost Forest Deletion can be solved in $\mathcal{O}^{\star}(\min\{2.85^k
\cdot 8.54^\ell,2.7^k \cdot 36.61^\ell,3^k \cdot 1.78^\ell\})$.
</p></div>
    </summary>
    <updated>2020-09-30T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-09-30T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.13768</id>
    <link href="http://arxiv.org/abs/2009.13768" rel="alternate" type="text/html"/>
    <title>In-Order Sliding-Window Aggregation in Worst-Case Constant Time</title>
    <feedworld_mtime>1601424000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tangwongsan:Kanat.html">Kanat Tangwongsan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hirzel:Martin.html">Martin Hirzel</a>, Scott Schneider <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.13768">PDF</a><br/><b>Abstract: </b>Sliding-window aggregation is a widely-used approach for extracting insights
from the most recent portion of a data stream. The aggregations of interest can
usually be expressed as binary operators that are associative but not
necessarily commutative nor invertible. Non-invertible operators, however, are
difficult to support efficiently. In a 2017 conference paper, we introduced
DABA, the first algorithm for sliding-window aggregation with worst-case
constant time. Before DABA, if a window had size $n$, the best published
algorithms would require $O(\log n)$ aggregation steps per window
operation---and while for strictly in-order streams, this bound could be
improved to $O(1)$ aggregation steps on average, it was not known how to
achieve an $O(1)$ bound for the worst-case, which is critical for
latency-sensitive applications.
</p>
<p>This article is an extended version of our 2017 paper. Besides describing
DABA in more detail, this article introduces a new variant, DABA Lite, which
achieves the same time bounds in less memory. Whereas DABA requires space for
storing $2n$ partial aggregates, DABA Lite only requires space for $n+2$
partial aggregates. Our experiments on synthetic and real data support the
theoretical findings.
</p></div>
    </summary>
    <updated>2020-09-30T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-09-30T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.13701</id>
    <link href="http://arxiv.org/abs/2009.13701" rel="alternate" type="text/html"/>
    <title>Montage: A General System for Buffered Durably Linearizable Data Structures</title>
    <feedworld_mtime>1601424000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wen:Haosen.html">Haosen Wen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cai:Wentao.html">Wentao Cai</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Du:Mingzhe.html">Mingzhe Du</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jenkins:Louis.html">Louis Jenkins</a>, Benjamin Valpey, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Scott:Michael_L=.html">Michael L. Scott</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.13701">PDF</a><br/><b>Abstract: </b>The recent emergence of fast, dense, nonvolatile main memory suggests that
certain long-lived data might remain in its natural pointer-rich format across
program runs and hardware reboots. Operations on such data must be instrumented
with explicit write-back and fence instructions to ensure consistency in the
wake of a crash. Techniques to minimize the cost of this instrumentation are an
active topic of research.
</p>
<p>We present what we believe to be the first general-purpose approach to
building buffered durably linearizable persistent data structures, and a
system, Montage, to support that approach. Montage is built on top of the
Ralloc nonblocking persistent allocator. It employs a slow-ticking epoch clock,
and ensures that no operation appears to span an epoch boundary. It also
arranges to persist only that data minimally required to reconstruct the
structure after a crash. If a crash occurs in epoch $e$, all work performed in
epochs $e$ and $e-1$ is lost, but work from prior epochs is preserved.
</p>
<p>We describe the implementation of Montage, argue its correctness, and report
unprecedented throughput for persistent queues, sets/mappings, and general
graphs.
</p></div>
    </summary>
    <updated>2020-09-30T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-09-30T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.13689</id>
    <link href="http://arxiv.org/abs/2009.13689" rel="alternate" type="text/html"/>
    <title>Oblivious Sampling Algorithms for Private Data Analysis</title>
    <feedworld_mtime>1601424000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sasy:Sajin.html">Sajin Sasy</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Ohrimenko:Olga.html">Olga Ohrimenko</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.13689">PDF</a><br/><b>Abstract: </b>We study secure and privacy-preserving data analysis based on queries
executed on samples from a dataset. Trusted execution environments (TEEs) can
be used to protect the content of the data during query computation, while
supporting differential-private (DP) queries in TEEs provides record privacy
when query output is revealed. Support for sample-based queries is attractive
due to \emph{privacy amplification} since not all dataset is used to answer a
query but only a small subset. However, extracting data samples with TEEs while
proving strong DP guarantees is not trivial as secrecy of sample indices has to
be preserved. To this end, we design efficient secure variants of common
sampling algorithms. Experimentally we show that accuracy of models trained
with shuffling and sampling is the same for differentially private models for
MNIST and CIFAR-10, while sampling provides stronger privacy guarantees than
shuffling.
</p></div>
    </summary>
    <updated>2020-09-30T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-09-30T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/149</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/149" rel="alternate" type="text/html"/>
    <title>TR20-149 |  Robustly Self-Ordered Graphs: Constructions and Applications to Property Testing | 

	Oded Goldreich, 

	Avi Wigderson</title>
    <summary>A graph $G$ is called {\em self-ordered}\/ (a.k.a asymmetric) if the identity permutation is its only automorphism.
Equivalently, there is a unique isomorphism from $G$ to any graph that is isomorphic to $G$. 
We say that $G=(V,E)$ is {\em robustly self-ordered}\/ if the size of the symmetric difference between $E$ and the edge-set of the graph obtained by permuting $V$ using any permutation $\pi:V\to V$ is proportional to the number of non-fixed-points of $\pi$.

We show that robustly self-ordered bounded-degree graphs exist (in abundance), and that they can be constructed efficiently, in a strong sense.
Specifically, given the index of a vertex in such a graph, it is possible to find all its neighbors in polynomial-time (i.e., in time that is poly-logarithmic in the size of the graph).

We provide two very different constructions, in tools and structure. 
The first, a direct construction, is based on proving a sufficient condition for robust self-ordering, 
which requires that an auxiliary graph, on {\em pairs|}\/ of vertices of the original graph, is expanding. 
In this case the original graph is (not only robustly self-ordered but) also expanding.
The second construction proceeds in three steps: It boosts the mere existence of robustly self-ordered graphs, 
which provides explicit graphs of sublogarithmic size, to an efficient construction of polynomial-size graphs, 
and then, repeating it again, to exponential-size(robustly self-ordered) graphs that are locally constructible.
This construction can yield robustly self-ordered graphs that are either expanders or highly disconnected, having logarithmic size connected components. 

We also consider graphs of unbounded degree, seeking correspondingly unbounded robustness parameters.
We again demonstrate that such graphs (of linear degree) exist (in abundance), and give an explicit construction. 
This turns out to require very different tools, and the definition and constructions of new pseudo-random objects. 
Specifically, we show that the construction of such graphs reduces to the construction of non-malleable two-source extractors 
with very weak parameters but with an additional natural feature. 
Next, we reduce the construction of such non-malleable two-source extractors to the construction of ``relocation-detecting'' codes. Loosely speaking, in such code permuting arbitrarily the coordinates of a random codeword yields a string that is far any other codeword. We conclude by showing how to construct relocation-detecting codes (of various types, including ones with constant rate).  

We demonstrate that robustly self-ordered bounded-degree graphs are useful towards obtaining lower bounds on the query complexity of testing graph properties both in the bounded-degree and the dense graph models.  
Indeed, their robustness offers efficient, local and distance preserving reductions from testing problems on ordered structures (like sequences) to the unordered (effectively unlabeled) graphs. 
One of the results that we obtain, via such a reduction, is a subexponential separation 
between the complexity of testing and tolerant testing of graph properties in the bounded-degree graph model.</summary>
    <updated>2020-09-29T19:33:10Z</updated>
    <published>2020-09-29T19:33:10Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-09-30T07:20:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/09/29/postdoctoral-research-associate-high-performance-parallel-graph-based-machine-learning-at-david-r-cheriton-school-of-computer-science-university-of-waterloo-apply-by-january-1-2021/</id>
    <link href="https://cstheory-jobs.org/2020/09/29/postdoctoral-research-associate-high-performance-parallel-graph-based-machine-learning-at-david-r-cheriton-school-of-computer-science-university-of-waterloo-apply-by-january-1-2021/" rel="alternate" type="text/html"/>
    <title>Postdoctoral Research Associate, High-Performance Parallel Graph-Based Machine Learning at David R. Cheriton School of Computer Science, University of Waterloo (apply by January 1, 2021)</title>
    <summary>We are looking for a postdoctoral research associate to join our research group (opallab.ca) at the Computer Science department at the University of Waterloo. Our goal is to develop parallel and communication efficient algorithms for large-scale graph-based machine learning. Website: https://jobs.siam.org/job/postdoctoral-research-associate/54755436/ Email: kfountou@uwaterloo.ca</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>We are looking for a postdoctoral research associate to join our research group (opallab.ca) at the Computer Science department at the University of Waterloo. Our goal is to develop parallel and communication efficient algorithms for large-scale graph-based machine learning.</p>
<p>Website: <a href="https://jobs.siam.org/job/postdoctoral-research-associate/54755436/">https://jobs.siam.org/job/postdoctoral-research-associate/54755436/</a><br/>
Email: kfountou@uwaterloo.ca</p></div>
    </content>
    <updated>2020-09-29T19:26:33Z</updated>
    <published>2020-09-29T19:26:33Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-09-30T07:20:49Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/148</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/148" rel="alternate" type="text/html"/>
    <title>TR20-148 |  Simple and fast derandomization from very hard functions: Eliminating randomness at almost no cost | 

	Roei Tell, 

	Lijie Chen</title>
    <summary>Extending the classical ``hardness-to-randomness'' line-of-works, Doron et al. (FOCS 2020) recently proved that derandomization with near-quadratic time overhead is possible, under the assumption that there exists a function in $\mathcal{DTIME}[2^n]$ that cannot be computed by randomized SVN circuits of size $2^{(1-\epsilon)\cdot n}$ for a small $\epsilon$.

In this work we extend their inquiry and answer several open questions that arose from their work. Our main result is that *derandomization with almost no time overhead is possible*, under a plausible hypothesis. Specifically, we show that probabilistic algorithms that run in time $T(n)$ can be deterministically simulated in time $n\cdot T(n)^{1+\epsilon}$, under a hypothesis that is formally incomparable to the one of Doron et al., but is arguably more standard: We assume that there exist non-uniformly secure one-way functions, and that for $\delta=\delta(\epsilon)$ and $k=k_T(\epsilon)$ there exists a problem in $\mathcal{DTIME}[2^{k\cdot n}]$ that is hard for algorithms that run in time $2^{(k-\delta)\cdot n}$ and use $2^{(1-\delta)\cdot n}$ bits of advice. We also show that the latter hypothesis (or, more accurately, a relaxation of it that we use) is in fact necessary to obtain the derandomization conclusion if one relies on a PRG construction (as is indeed our approach).

For sub-exponential time functions $T(n)=2^{n^{o(1)}}$ we further improve the derandomization time to $n^{1+\epsilon}\cdot T(n)$, under a mildly stronger hypothesis. We also show that *the multiplicative time overhead of $n$ is essentially optimal*, conditioned on a counting version of the non-deterministic strong exponential-time hypothesis (i.e., on $\# NSETH$). Nevertheless, we show that *in the average-case setting a faster derandomization is possible*: Under hypotheses similar to the ones in our main result, we show that for every $L\in\mathcal{BPTIME}[n^k]$ there exists a deterministic algorithm $A_L$ running in time $n^{\epsilon}\cdot n^{k}$ such that for every distribution $\mathcal{D}$ over $\{0,1\}^n$ samplable in time $n^k$ it holds that $\Pr_{x\sim\mathcal{D}}[A_L(x)=L(x)]\ge1-n^{-\omega(1)}$. 

Lastly, we present an alternative proof for the result of Doron et al. using a *proof paradigm that is both considerably simpler and more general*; in fact, we show how to simplify the analysis of any construction that ``extracts randomness from a pseudoentropic string''. We use this simpler proof to extend their result, deducing a mildly slower derandomization (i.e., with cubic or quadratic overhead) from weaker hardness assumptions (i.e., for SVN circuits that do not use randomness).</summary>
    <updated>2020-09-29T17:09:04Z</updated>
    <published>2020-09-29T17:09:04Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-09-30T07:20:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://mycqstate.wordpress.com/?p=1252</id>
    <link href="https://mycqstate.wordpress.com/2020/09/29/it-happens-to-everyonebut-its-not-fun/" rel="alternate" type="text/html"/>
    <title>It happens to everyone…but it’s not fun</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">A recent post on this blog concerned the posting of our paper MIP*=RE on the arXiv and gave a personal history of the the sequence of works that led to the result. Quite unfortunately (dramatically?) a few weeks after initial … <a href="https://mycqstate.wordpress.com/2020/09/29/it-happens-to-everyonebut-its-not-fun/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><h1/>



<p>A <a href="https://mycqstate.wordpress.com/2020/01/14/a-masters-project/">recent post</a> on this blog concerned the posting of our paper <a href="https://arxiv.org/abs/2001.04383">MIP*=RE</a> on the arXiv and gave a personal history of the the sequence of works that led to the result. Quite unfortunately (dramatically?) a few weeks after initial posting of the paper (and the blog post) John Wright discovered an important error in the proof of a key result in this sequence: my paper <a href="https://doi.org/10.1137/140956622">Three-player entangled XOR games are NP-hard to approximate</a>, published in 2016 in a special issue of the SIAM journal on computing dedicated to selected papers from the FOCS’13 conference. While I did not mention this paper directly in the previous blog post, its main result, a proof of soundness of the Raz-Safra low-degree test against entangled-player strategies, is a key ingredient in the proof of the <a href="https://arxiv.org/abs/1801.03821">quantum low-degree test</a>, itself a key ingredient in the MIP*=RE paper. (Strictly speaking the latter paper relies on an extension of my result to two-player games obtained in a <a href="https://arxiv.org/abs/1710.03062">follow-up</a> with Natarajan. Since that paper re-used the flawed part of my earlier analysis in a black-box manner it is similarly impacted.) So then…?</p>



<h2 id="scientific-aspects">Scientific aspects</h2>



<p>I’ll start with the science. The result MIP*=RE, to the best of our knowledge, remains correct. In order to remove the dependence of the proof on the flawed paper we extended the soundness analysis of Babai et al.’s multilinearity test against entangled provers from my <a href="https://arxiv.org/abs/1207.0550">paper with Ito</a> to the case of multivariate polynomials of low individual degree. We just posted a self-contained analysis of that test on the arXiv <a href="https://arxiv.org/abs/2009.12982">here</a> and updated the MIP*=RE paper to account for the replacement (see v2.). The latter paper is currently under review; on this I will simply say that, as for all mathematical works, it is advised to wait until the outcome of the refereeing process is complete before declaring confidence in the validity of the result. For a more in-depth description of the changes made I refer to the introduction of the <a href="https://arxiv.org/abs/2009.12982">new paper</a>.</p>



<p>Our analysis of the “low individual-degree test” mentioned in the preceding paragraph can be used to recover the main result of my SICOMP’16 paper in a weakened form. Since the proof is different and does not directly fix the error I have decided to withdraw the paper from SICOMP. For more details on the error itself and consequences to other works, such as the quantum low-degree test and the quantum games PCP, I refer to the <a href="http://users.cms.caltech.edu/~vidick/errata.pdf">short note</a> I wrote to accompany the withdrawal of the paper. The one-sentence summary is that essentially all subsequent results expressed in terms of “high” complexity classes such as QMA-EXP, NEEXP, etc., still hold, while “scaled-down” results on the hardness of entangled games can only be recovered by allowing a substantial weakening of parameters. In particular, the <a href="https://arxiv.org/abs/1801.03821">quantum low-degree test</a> holds in its scaled-up version (testing exp(n) EPR pairs using poly(n) resources), but the scaled-down version requires polylog(n) communication to test n EPR pairs, instead of O(log n) as claimed.</p>



<h2 id="personal-aspects">Personal aspects</h2>



<p>In addition to notifying researchers in the area of the bug, my goal in writing this blog post is to help me exorcise the demon of having a large mistake in one of my papers. In doing so I was inspired by Scott Aaronson’s <a href="https://www.scottaaronson.com/blog/?p=2854">blog post</a> on a similar topic. (I’ll admit that even just linking explicitly to his post helps reassure myself, a power which I believe was one of Scott’s aims in writing the post. So, thanks Scott, and allow me to pass it on!) The faulty paper is not based on a minor back-of-the-envelope observation; in fact it is one that I was quite proud of. The mistake in it is not small either; it’s a mistake that I cannot find any excuse for having made. Yet here I am: after having spent the past 6 months trying to find an alternative proof, I now strongly believe that the problem cannot be solved using the kind of techniques that I had imagined could do so. Whether the theorem statement is true or not, I don’t know; but at the moment I am unable to prove it. I have to accept that there is a bug.</p>



<p>As painful as it is I realize that I am writing this post from a relatively comfortable position. Who knows if I would have been able to do the same had we not been able to recover a full proof of MIP*=RE. Moreover, after having banged my head against the problem for 6 months straight (COVID helping, walls were never far) I am now able to see my failure in a more positive light: the story I told in the previous blog post is not yet closed; there is an open challenge for me to solve. It is a very personal challenge; having spent the past 6 months delineating it I have accumulated sufficient grounds on which to believe that it is an interesting one. I feel grateful for this.</p>



<p>Getting there wasn’t easy. So, even though I am writing from a place of comfort, I want to share the pain that the whole adventure has caused me. This simple acknowledgment is especially directed at younger readers: so that when it happens to you, you will remember this post and know that you’re not the only one. That it happens to others as well and that it is possible to face, accept, and move away from such errors. Of course you will try to fix it first. Here are some quick tips. While banging your head on the problem, make sure that your understanding increases every day. To start with, do you really understand why there is a mistake? Of course some step doesn’t go through, but what is the simplest form of the incriminated statement that fails? Can you write it down? Can you formulate and prove a weaker form of it? Probe the issue with examples. Try to isolate it as much as you can: take it outside of the paper and formulate an entirely self-contained version of it, stripped of all the baggage. Place it in as many different contexts that you can think of: do you still believe it, does it stand on its own? Again, make sure that you learn. Even if you’re not able to fix the claim, are you exploring a new technique, discovering a new perspective? If it didn’t work yesterday it probably won’t work today either: make sure that you always find something new to inject. When you can no longer do this, it is time to stop. So make sure to set yourself some near-term (how much to think about this on any given day) and long-term (when to admit defeat) limits. Always remember that problems are much more often solved in the shower or while walking the dog than at the desk. Finally, be ready to move on. Realize that as bad as it may seem to you, there are more important things in life. You can’t reduce yourself to this one problem: you’ll be stronger for accepting what happened than trying to bury it at all costs. If you don’t see this by yourself, try to talk about it. Explain the situation you’re in to your close non-academia friends, to your parents; practice on your pet first if it helps. You will realize, as I eventually did (although it took quite a while) that <em>it is ok</em>.</p>



<h2 id="social-aspects">Social aspects</h2>



<p>After the scientific and the personal aspects, let me end with the sociological. This is a semi-tangent but it is a good opportunity to discuss a topic that we scientists, possibly even more so us working in the “hard sciences” (as the French call “proof-based” disciplines), are insufficiently sensitized to. This is the topic of how science is made, and what is the reality of this “absolute truth” that we claim to discover and establish in our mathematical results.</p>



<p>My paper was posted on arXiv in 2013, it was accepted to the FOCS conference and published in its proceedings the same year, and it appeared in the journal SICOMP in 2016. Both publications were refereed. Since its posting the paper has been cited 47 times (google scholar) and its main result is used in an essential way in at least half a dozen papers (my best guess). 7 years later a big hole has been found in the proof. How did the “truth value of my result evolve in the process? Was it always wrong or was there a time where it had truth, in whatever appropriate sense of the word?</p>



<p>I realize that these questions can be given trivial answers—I know what is an axiom and what is a proof system. Yet I am trying to push myself, and my reader, to look a little deeper. An analogy might help. The situation brought to mind a book by French philosopher of science Bruno Latour, called (in its English translation) <a href="https://www.amazon.com/Laboratory-Life-Construction-Scientific-Facts/dp/069102832X">Laboratory Life: The Construction of Scientific Facts</a>. This is a wonderful book, which goes well beyond the classic misconceptions from Popper or even Kuhn; it should be mandatory reading for every scientist. In one of the early chapters of the book Latour makes a detailed study of how subsequent citations can collectively enshrine an initial claim based entirely on the citer’s conscious or unconscious biases in making use of the citation (i.e. in complete independence from any ground “truth” or “importance” of the cited work). An entertaining example of this can be found in <a href="https://journals.sagepub.com/doi/full/10.1177/0306312714535679">this article</a>, which dissects the claim that “The myth from the 1930s that spinach is a rich source of iron was due to misleading information in the original publication: a malpositioned decimal point gave a 10-fold overestimate of iron content.” The example, pursued in great depth in the article, shows very well how one citation at a time the (spoiler: unjustified) claim is given more and more credibility until it eventually becomes a fact: from initial citations written in a tentative tone “according to Z, it could be that…” to more assertive citations “Z has shown that” by more and more well-known researchers in highly-read journals to pure fact (citation above). I highly recommend the article!</p>



<p>It is easy to dismiss this story as being the result of “sloppy” authors misrepresenting a “soft” claim whose truth value is not well-determined in the first place, being a statement about the world rather than about some hypothetical mathematical universe. Yet I believe that it is worth taking the time to examine with an open mind what exactly, if anything, distinguishes a claim about the iron content of spinach from the main “theorem” of my paper. From its initial posting on the arXiv to its presentation in a conference and its journal publication to the multiple citations it received through its use in subsequent works, and including multiple other considerations such as my own credibility (itself the result of so many other considerations) and the results base “believability”, when was the logical statement itself evaluated? Does it matter? Did the unchallenged existence of the result for 7 years impact the course of science? Or was it a mistake that was bound to be discovered and has no lasting consequences?</p>



<p>These are questions for the reader, that can be (and are probably better) asked in other contexts than the limited one of my result. Indeed there is a much broader point to all this, that I only meant to raise in an indirect manner. It is impossible to disregard the fact that our scientific work is grounded in cultural and societal effects, but we may disagree on the impact that this grounding has. We owe it to ourselves and to our readers (broadly interpreted—from colleagues to funding agencies to the broader public) to refuse to hide behind the thin veil of “hard science”, mathematics or logic, and educate ourselves to what it is that we really are doing.</p></div>
    </content>
    <updated>2020-09-29T15:50:43Z</updated>
    <published>2020-09-29T15:50:43Z</published>
    <category term="meta"/>
    <category term="Quantum"/>
    <category term="Science"/>
    <category term="Uncategorized"/>
    <author>
      <name>Thomas</name>
    </author>
    <source>
      <id>https://mycqstate.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://mycqstate.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://mycqstate.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://mycqstate.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://mycqstate.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>In superposition</subtitle>
      <title>MyCQstate</title>
      <updated>2020-09-30T07:21:09Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.13317</id>
    <link href="http://arxiv.org/abs/2009.13317" rel="alternate" type="text/html"/>
    <title>A note on differentially private clustering with large additive error</title>
    <feedworld_mtime>1601337600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nguyen:Huy_L=.html">Huy L. Nguyen</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.13317">PDF</a><br/><b>Abstract: </b>In this note, we describe a simple approach to obtain a differentially
private algorithm for k-clustering with nearly the same multiplicative factor
as any non-private counterpart at the cost of a large polynomial additive
error. The approach is the combination of a simple geometric observation
independent of privacy consideration and any existing private algorithm with a
constant approximation.
</p></div>
    </summary>
    <updated>2020-09-29T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-09-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.13316</id>
    <link href="http://arxiv.org/abs/2009.13316" rel="alternate" type="text/html"/>
    <title>Explorable Uncertainty in Scheduling with Non-Uniform Testing Times</title>
    <feedworld_mtime>1601337600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Albers:Susanne.html">Susanne Albers</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Eckl:Alexander.html">Alexander Eckl</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.13316">PDF</a><br/><b>Abstract: </b>The problem of scheduling with testing in the framework of explorable
uncertainty models environments where some preliminary action can influence the
duration of a task. In the model, each job has an unknown processing time that
can be revealed by running a test. Alternatively, jobs may be run untested for
the duration of a given upper limit. Recently, D\"urr et al. [5] have studied
the setting where all testing times are of unit size and have given lower and
upper bounds for the objectives of minimizing the sum of completion times and
the makespan on a single machine. In this paper, we extend the problem to
non-uniform testing times and present the first competitive algorithms. The
general setting is motivated for example by online user surveys for market
prediction or querying centralized databases in distributed computing.
Introducing general testing times gives the problem a new flavor and requires
updated methods with new techniques in the analysis. We present constant
competitive ratios for the objective of minimizing the sum of completion times
in the deterministic case, both in the non-preemptive and preemptive setting.
For the preemptive setting, we additionally give a first lower bound. We also
present a randomized algorithm with improved competitive ratio. Furthermore, we
give tight competitive ratios for the objective of minimizing the makespan,
both in the deterministic and the randomized setting.
</p></div>
    </summary>
    <updated>2020-09-29T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-09-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.13257</id>
    <link href="http://arxiv.org/abs/2009.13257" rel="alternate" type="text/html"/>
    <title>Approximation algorithms for connectivity augmentation problems</title>
    <feedworld_mtime>1601337600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nutov:Zeev.html">Zeev Nutov</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.13257">PDF</a><br/><b>Abstract: </b>In Connectivity Augmentation problems we are given a graph $H=(V,E_H)$ and an
edge set $E$ on $V$, and seek a min-size edge set $J \subseteq E$ such that $H
\cup J$ has larger edge/node connectivity than $H$. In the Edge-Connectivity
Augmentation problem we need to increase the edge-connectivity by $1$. In the
Block-Tree Augmentation problem $H$ is connected and $H \cup S$ should be
$2$-connected. In Leaf-to-Leaf Connectivity Augmentation problems every edge in
$E$ connects minimal deficient sets. For this version we give a simple
combinatorial approximation algorithm with ratio $5/3$, improving the previous
$1.91$ approximation that applies for the general case. We also show by a
simple proof that if the Steiner Tree problem admits approximation ratio
$\alpha$ then the general version admits approximation ratio
$1+\ln(4-x)+\epsilon$, where $x$ is the solution to the equation
$1+\ln(4-x)=\alpha+(\alpha-1)x$. For the currently best value of $\alpha=\ln
4+\epsilon$ this gives ratio $1.942$. This is slightly worse than the best
ratio $1.91$, but has the advantage of using Steiner Tree approximation as a
"black box", giving ratio $&lt; 1.9$ if ratio $\alpha \leq 1.35$ can be achieved.
</p></div>
    </summary>
    <updated>2020-09-29T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-09-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.13198</id>
    <link href="http://arxiv.org/abs/2009.13198" rel="alternate" type="text/html"/>
    <title>Discrimination of attractors with noisy nodes in Boolean networks</title>
    <feedworld_mtime>1601337600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cheng:Xiaoqing.html">Xiaoqing Cheng</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Ching:Wai=Ki.html">Wai-Ki Ching</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Guo:Sini.html">Sini Guo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Akutsu:Tatsuya.html">Tatsuya Akutsu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.13198">PDF</a><br/><b>Abstract: </b>Observing the internal state of the whole system using a small number of
sensor nodes is important in analysis of complex networks. Here, we study the
problem of determining the minimum number of sensor nodes to discriminate
attractors under the assumption that each attractor has at most K noisy nodes.
We present exact and approximation algorithms for this minimization problem.
The effectiveness of the algorithms is also demonstrated by computational
experiments using both synthetic data and realistic biological data.
</p></div>
    </summary>
    <updated>2020-09-29T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-09-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.13184</id>
    <link href="http://arxiv.org/abs/2009.13184" rel="alternate" type="text/html"/>
    <title>The canonical directed tree decomposition and its applications to the directed disjoint paths problem</title>
    <feedworld_mtime>1601337600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Giannopoulou:Archontia_C=.html">Archontia C. Giannopoulou</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kawarabayashi:Ken=ichi.html">Ken-ichi Kawarabayashi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kreutzer:Stephan.html">Stephan Kreutzer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kwon:O=joung.html">O-joung Kwon</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.13184">PDF</a><br/><b>Abstract: </b>The canonical tree-decomposition theorem, given by Robertson and Seymour in
their seminal graph minors series, turns out to be one of the most important
tool in structural and algorithmic graph theory. In this paper, we provide the
canonical tree decomposition theorem for digraphs. More precisely, we construct
directed tree-decompositions of digraphs that distinguish all their tangles of
order $k$, for any fixed integer $k$, in polynomial time. As an application of
this canonical tree-decomposition theorem, we provide the following result for
the directed disjoint paths problem:
</p>
<p>For every fixed $k$ there is a polynomial-time algorithm which, on input $G$,
and source and terminal vertices $(s_1, t_1), \dots, (s_k, t_k)$, either
</p>
<p>1. determines that there is no set of pairwise vertex-disjoint paths
connecting each source $s_i$ to its terminal $t_i$, or
</p>
<p>2.finds a half-integral solution, i.e., outputs paths $P_1, \dots, P_k$ such
that $P_i$ links $s_i$ to $t_i$, so that every vertex of the graph is contained
in at most two paths. Given known hardness results for the directed disjoint
paths problem, our result cannot be improved for general digraphs, neither to
fixed-parameter tractability nor to fully vertex-disjoint directed paths. As
far as we are aware, this is the first time to obtain a tractable result for
the $k$-disjoint paths problem for general digraphs. We expect more
applications of our canonical tree-decomposition for directed results.
</p></div>
    </summary>
    <updated>2020-09-29T23:22:25Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-09-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.13090</id>
    <link href="http://arxiv.org/abs/2009.13090" rel="alternate" type="text/html"/>
    <title>A note on weak near unanimity polymorphisms</title>
    <feedworld_mtime>1601337600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rafiey:Arash.html">Arash Rafiey</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.13090">PDF</a><br/><b>Abstract: </b>We show that deciding whether a given relational structure $\mathcal{R}$
admits a weak near unanimity polymorphism is polynomial time solvable.
</p></div>
    </summary>
    <updated>2020-09-29T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-09-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.13071</id>
    <link href="http://arxiv.org/abs/2009.13071" rel="alternate" type="text/html"/>
    <title>$\epsilon$-net Induced Lazy Witness Complexes on Graphs</title>
    <feedworld_mtime>1601337600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Arafat:Naheed_Anjum.html">Naheed Anjum Arafat</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Basu:Debabrota.html">Debabrota Basu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bressan:St=eacute=phane.html">Stéphane Bressan</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.13071">PDF</a><br/><b>Abstract: </b>Computation of persistent homology of simplicial representations such as the
Rips and the C\v{e}ch complexes do not efficiently scale to large point clouds.
It is, therefore, meaningful to devise approximate representations and evaluate
the trade-off between their efficiency and effectiveness. The lazy witness
complex economically defines such a representation using only a few selected
points, called landmarks.
</p>
<p>Topological data analysis traditionally considers a point cloud in a
Euclidean space. In many situations, however, data is available in the form of
a weighted graph. A graph along with the geodesic distance defines a metric
space. This metric space of a graph is amenable to topological data analysis.
</p>
<p>We discuss the computation of persistent homologies on a weighted graph. We
present a lazy witness complex approach leveraging the notion of $\epsilon$-net
that we adapt to weighted graphs and their geodesic distance to select
landmarks. We show that the value of the $\epsilon$ parameter of the
$\epsilon$-net provides control on the trade-off between choice and number of
landmarks and the quality of the approximate simplicial representation.
</p>
<p>We present three algorithms for constructing an $\epsilon$-net of a graph. We
comparatively and empirically evaluate the efficiency and effectiveness of the
choice of landmarks that they induce for the topological data analysis of
different real-world graphs.
</p></div>
    </summary>
    <updated>2020-09-29T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-09-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.12982</id>
    <link href="http://arxiv.org/abs/2009.12982" rel="alternate" type="text/html"/>
    <title>Quantum soundness of the classical low individual degree test</title>
    <feedworld_mtime>1601337600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Ji:Zhengfeng.html">Zhengfeng Ji</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Natarajan:Anand.html">Anand Natarajan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vidick:Thomas.html">Thomas Vidick</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wright:John.html">John Wright</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yuen:Henry.html">Henry Yuen</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.12982">PDF</a><br/><b>Abstract: </b>Low degree tests play an important role in classical complexity theory,
serving as basic ingredients in foundational results such as $\mathsf{MIP} =
\mathsf{NEXP}$ [BFL91] and the PCP theorem [AS98,ALM+98]. Over the last ten
years, versions of these tests which are sound against quantum provers have
found increasing applications to the study of nonlocal games and the complexity
class~$\mathsf{MIP}^*$. The culmination of this line of work is the result
$\mathsf{MIP}^* = \mathsf{RE}$ [JNV+20].
</p>
<p>One of the key ingredients in the first reported proof of $\mathsf{MIP}^* =
\mathsf{RE}$ is a two-prover variant of the low degree test, initially shown to
be sound against multiple quantum provers in [Vid16]. Unfortunately a mistake
was recently discovered in the latter result, invalidating the main result of
[Vid16] as well as its use in subsequent works, including [JNV+20].
</p>
<p>We analyze a variant of the low degree test called the low individual degree
test. Our main result is that the two-player version of this test is sound
against quantum provers. This soundness result is sufficient to re-derive
several bounds on~$\mathsf{MIP}^*$ that relied on [Vid16], including
$\mathsf{MIP}^* = \mathsf{RE}$.
</p></div>
    </summary>
    <updated>2020-09-29T23:20:49Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-09-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.12892</id>
    <link href="http://arxiv.org/abs/2009.12892" rel="alternate" type="text/html"/>
    <title>The Complexity of Connectivity Problems in Forbidden-Transition Graphs and Edge-Colored Graphs</title>
    <feedworld_mtime>1601337600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bellitto:Thomas.html">Thomas Bellitto</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Shaohua.html">Shaohua Li</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Okrasa:Karolina.html">Karolina Okrasa</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pilipczuk:Marcin.html">Marcin Pilipczuk</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sorge:Manuel.html">Manuel Sorge</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.12892">PDF</a><br/><b>Abstract: </b>The notion of forbidden-transition graphs allows for a robust generalization
of walks in graphs. In a forbidden-transition graph, every pair of edges
incident to a common vertex is permitted or forbidden; a walk is compatible if
all pairs of consecutive edges on the walk are permitted. Forbidden-transition
graphs and related models have found applications in a variety of fields, such
as routing in optical telecommunication networks, road networks, and
bio-informatics.
</p>
<p>We initiate the study of fundamental connectivity problems from the point of
view of parameterized complexity, including an in-depth study of tractability
with regards to various graph-width parameters. Among several results, we prove
that finding a simple compatible path between given endpoints in a
forbidden-transition graph is W[1]-hard when parameterized by the
vertex-deletion distance to a linear forest (so it is also hard when
parameterized by pathwidth or treewidth). On the other hand, we show an
algebraic trick that yields tractability when parameterized by treewidth of
finding a properly colored Hamiltonian cycle in an edge-colored graph; properly
colored walks in edge-colored graphs is one of the most studied special cases
of compatible walks in forbidden-transition graphs.
</p></div>
    </summary>
    <updated>2020-09-29T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-09-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.12809</id>
    <link href="http://arxiv.org/abs/2009.12809" rel="alternate" type="text/html"/>
    <title>Rank/Select Queries over Mutable Bitmaps</title>
    <feedworld_mtime>1601337600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pibiri:Giulio_Ermanno.html">Giulio Ermanno Pibiri</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kanda:Shunsuke.html">Shunsuke Kanda</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.12809">PDF</a><br/><b>Abstract: </b>The problem of answering rank/select queries over a bitmap is of utmost
importance for many succinct data structures. When the bitmap does not change,
many solutions exist in the theoretical and practical side. In this work we
consider the case where one is allowed to modify the bitmap via a flip(i)
operation that toggles its i-th bit. By adapting and properly extending some
results concerning prefix-sum data structures, we present a practical solution
to the problem, tailored for modern CPU instruction sets. Compared to the
state-of-the-art, our solution improves runtime with no space degradation.
Moreover, it does not incur in a significant runtime penalty when compared to
the fastest immutable indexes, while providing even lower space overhead.
</p></div>
    </summary>
    <updated>2020-09-29T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-09-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.12685</id>
    <link href="http://arxiv.org/abs/2009.12685" rel="alternate" type="text/html"/>
    <title>The smoothed complexity of Frank-Wolfe methods via conditioning of random matrices and polytopes</title>
    <feedworld_mtime>1601337600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rademacher:Luis.html">Luis Rademacher</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shu:Chang.html">Chang Shu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.12685">PDF</a><br/><b>Abstract: </b>Frank-Wolfe methods are popular for optimization over a polytope. One of the
reasons is because they do not need projection onto the polytope but only
linear optimization over it. To understand its complexity, Lacoste-Julien and
Jaggi introduced a condition number for polytopes and showed linear convergence
for several variations of the method. The actual running time can still be
exponential in the worst case (when the condition number is exponential). We
study the smoothed complexity of the condition number, namely the condition
number of small random perturbations of the input polytope and show that it is
polynomial for any simplex and exponential for general polytopes. Our results
also apply to other condition measures of polytopes that have been proposed for
the analysis of Frank-Wolfe methods: vertex-facet distance (Beck and Shtern)
and facial distance (Pe\~na and Rodr\'iguez).
</p>
<p>Our argument for polytopes is a refinement of an argument that we develop to
study the conditioning of random matrices. The basic argument shows that for
$c&gt;1$ a $d$-by-$n$ random Gaussian matrix with $n \geq cd$ has a $d$-by-$d$
submatrix with minimum singular value that is exponentially small with high
probability. This has consequences on results about the robust uniqueness of
tensor decompositions.
</p></div>
    </summary>
    <updated>2020-09-29T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-09-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.12457</id>
    <link href="http://arxiv.org/abs/2009.12457" rel="alternate" type="text/html"/>
    <title>A Block-Based Triangle Counting Algorithm on Heterogeneous Environments</title>
    <feedworld_mtime>1601337600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Abdurrahman Yaşar, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rajamanickam:Sivasankaran.html">Sivasankaran Rajamanickam</a>, Jonathan Berry, Ümit V. Çatalyürek <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.12457">PDF</a><br/><b>Abstract: </b>Triangle counting is a fundamental building block in graph algorithms. In
this paper, we propose a block-based triangle counting algorithm to reduce data
movement during both sequential and parallel execution. Our block-based
formulation makes the algorithm naturally suitable for heterogeneous
architectures. The problem of partitioning the adjacency matrix of a graph is
well-studied. Our task decomposition goes one step further: it partitions the
set of triangles in the graph. By streaming these small tasks to compute
resources, we can solve problems that do not fit on a device. We demonstrate
the effectiveness of our approach by providing an implementation on a compute
node with multiple sockets, cores and GPUs. The current state-of-the-art in
triangle enumeration processes the Friendster graph in 2.1 seconds, not
including data copy time between CPU and GPU. Using that metric, our approach
is 20 percent faster. When copy times are included, our algorithm takes 3.2
seconds. This is 5.6 times faster than the fastest published CPU-only time.
</p></div>
    </summary>
    <updated>2020-09-29T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-09-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.12442</id>
    <link href="http://arxiv.org/abs/2009.12442" rel="alternate" type="text/html"/>
    <title>Hypergraph $k$-cut for fixed $k$ in deterministic polynomial time</title>
    <feedworld_mtime>1601337600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chandrasekaran:Karthekeyan.html">Karthekeyan Chandrasekaran</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chekuri:Chandra.html">Chandra Chekuri</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.12442">PDF</a><br/><b>Abstract: </b>We consider the Hypergraph-$k$-cut problem. The input consists of a
hypergraph $G=(V,E)$ with non-negative hyperedge-costs $c: E\rightarrow R_+$
and a positive integer $k$. The objective is to find a least-cost subset
$F\subseteq E$ such that the number of connected components in $G-F$ is at
least $k$. An alternative formulation of the objective is to find a partition
of $V$ into $k$ non-empty sets $V_1,V_2,\ldots,V_k$ so as to minimize the cost
of the hyperedges that cross the partition. Graph-$k$-cut, the special case of
Hypergraph-$k$-cut obtained by restricting to graph inputs, has received
considerable attention. Several different approaches lead to a polynomial-time
algorithm for Graph-$k$-cut when $k$ is fixed, starting with the work of
Goldschmidt and Hochbaum (1988). In contrast, it is only recently that a
randomized polynomial time algorithm for Hypergraph-$k$-cut was developed
(Chandrasekaran, Xu, Yu, 2018) via a subtle generalization of Karger's random
contraction approach for graphs. In this work, we develop the first
deterministic polynomial time algorithm for Hypergraph-$k$-cut for all fixed
$k$. We describe two algorithms both of which are based on a divide and conquer
approach. The first algorithm is simpler and runs in $n^{O(k^2)}$ time while
the second one runs in $n^{O(k)}$ time. Our proof relies on new structural
results that allow for efficient recovery of the parts of an optimum
$k$-partition by solving minimum $(S,T)$-terminal cuts. Our techniques give new
insights even for Graph-$k$-cut.
</p></div>
    </summary>
    <updated>2020-09-29T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-09-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.12413</id>
    <link href="http://arxiv.org/abs/2009.12413" rel="alternate" type="text/html"/>
    <title>Covering Tree-Based Phylogenetic Networks</title>
    <feedworld_mtime>1601337600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Nathan Davidov, Amanda Hernandez, Justin Jian, Patrick McKenna, K. A. Medlin, Roadra Mojumder, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Owen:Megan.html">Megan Owen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/q/Quijano:Andrew.html">Andrew Quijano</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rodriguez:Amanda.html">Amanda Rodriguez</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/John:Katherine_St=.html">Katherine St. John</a>, Katherine Thai, Meliza Uraga <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.12413">PDF</a><br/><b>Abstract: </b>Tree-based phylogenetic networks, which may be roughly defined as
leaf-labeled networks built by adding arcs only between the original tree
edges, have elegant properties for modeling evolutionary histories. We answer
an open question of Francis, Semple, and Steel about the complexity of
determining how far a phylogenetic network is from being tree-based, including
non-binary phylogenetic networks. We show that finding a phylogenetic tree
covering the maximum number of nodes in a phylogenetic network can be be
computed in polynomial time via an encoding into a minimum-cost maximum flow
problem.
</p></div>
    </summary>
    <updated>2020-09-29T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-09-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/09/28/postdoc-senior-postdoc-at-maynooth-university-apply-by-october-25-2020/</id>
    <link href="https://cstheory-jobs.org/2020/09/28/postdoc-senior-postdoc-at-maynooth-university-apply-by-october-25-2020/" rel="alternate" type="text/html"/>
    <title>Postdoc / Senior Postdoc at Maynooth University (apply by October 25, 2020)</title>
    <summary>Two 2-year postdoc/senior postdoc/technician positions at the Hamilton Institute, Maynooth University, Ireland. Our group works on both the theory and the engineering of DNA/molecular computers. Several people in our group have backgrounds in CS theory and have learned experimental wet-lab work, taking direct inspiration from the likes of Alan Turing. Website: https://dna.hamilton.ie/join.html Email: dna.hamilton.ie@gmail.com</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Two 2-year postdoc/senior postdoc/technician positions at the Hamilton Institute, Maynooth University, Ireland.</p>
<p>Our group works on both the theory and the engineering of DNA/molecular computers. Several people in our group have backgrounds in CS theory and have learned experimental wet-lab work, taking direct inspiration from the likes of Alan Turing.</p>
<p>Website: <a href="https://dna.hamilton.ie/join.html">https://dna.hamilton.ie/join.html</a><br/>
Email: dna.hamilton.ie@gmail.com</p></div>
    </content>
    <updated>2020-09-28T14:11:12Z</updated>
    <published>2020-09-28T14:11:12Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-09-30T07:20:49Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/09/28/scientific-staff-at-opendp-incubated-by-harvard-university-with-support-from-the-sloan-foundation-apply-by-october-15-2020/</id>
    <link href="https://cstheory-jobs.org/2020/09/28/scientific-staff-at-opendp-incubated-by-harvard-university-with-support-from-the-sloan-foundation-apply-by-october-15-2020/" rel="alternate" type="text/html"/>
    <title>Scientific Staff  at OpenDP (Incubated by Harvard University with support from the Sloan Foundation) (apply by October 15, 2020)</title>
    <summary>OpenDP is hiring scientists to work with Gary King, Salil Vadhan and the OpenDP Community. Candidates should have a graduate-level degree, familiarity with differential privacy, and experience with following: – Implementing software for data science, privacy, and/or security – Applied statistics, and an interest in working to apply OpenDP software to data-sharing problems. (i.e. COVID-19) […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>OpenDP is hiring scientists to work with Gary King, Salil Vadhan and the OpenDP Community. Candidates should have a graduate-level degree, familiarity with differential privacy, and experience with following: – Implementing software for data science, privacy, and/or security<br/>
– Applied statistics, and an interest in working to apply OpenDP software to data-sharing problems. (i.e. COVID-19)</p>
<p>Website: <a href="https://projects.iq.harvard.edu/opendp/blog/opendp-hiring-scientific-staff">https://projects.iq.harvard.edu/opendp/blog/opendp-hiring-scientific-staff</a><br/>
Email: privacytools-info@seas.harvard.edu</p></div>
    </content>
    <updated>2020-09-28T03:47:53Z</updated>
    <published>2020-09-28T03:47:53Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-09-30T07:20:49Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-9181146391897180370</id>
    <link href="https://blog.computationalcomplexity.org/feeds/9181146391897180370/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/09/a-quote-from-testla-which-is-very.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/9181146391897180370" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/9181146391897180370" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/09/a-quote-from-testla-which-is-very.html" rel="alternate" type="text/html"/>
    <title>A Quote from Tesla which is very predictive in one way, and perhaps not in another way</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p> Nikola Tesla, famous inventor, who lived 1856--1943 said the following:</p><p><br/></p><p>When wireless is perfectly applied the whole earth will be converted into</p><p>a huge brain, which in fact it is, all things being particles of a real</p><p>and rhythmic whole. We shall be able to communicate with one another</p><p>instantly, irrespective of distance. Not only this but through television</p><p>and telephony, we shall see and hear one another as perfectly as though</p><p>we were face to face, despite intervening distances of thousands of miles;</p><p>and the instruments through which we shall be able to do this will be</p><p>amazingly simple compared with our present telephone. A man will be able to</p><p>carry one in his vest pocket.</p><p><br/></p><p>The `vest pocket' at the end really impressed me.</p><p><br/></p><p>By `a man will be able to carry one...' I don't know if he mean all people or if he actually </p><p>meant that women would not need such a device. If that is what he meant then,</p><p>while high marks for tech-prediction, low marks for social-prediction. </p><p><br/></p><p>This quote is SO right-on for technology that I offer the following challenge: Find other quotes from year X that were very predictive for year X+Y for a reasonably large Y.</p><p>ADDED LATER: I will give two answers to my own challenge:</p><p>1) On the TV show THE HONEYMOONERS, in 1955, Ralph Cramden predicts 3-Dim TV. I blogged about that <a href="https://blog.computationalcomplexity.org/2010/05/ralph-kramden-your-wait-is-over-3d-tv_05.html#comment-form">here</a></p><p>2) Did the TV show Get Smart foreshadow cell phones. Maxwell Smart's shoe-phone was portable but wearing it on his foot seems odd. It also used dial, not touch tone. Mel Brooks (co-creator of the series) points out that in the Pilot episode Max is enjoying a show and his phone goes off so he has to leave and take the call -- which was very strange then but standard now. So the show did predict one of the problems with cell phones, if not cell phones themselves. </p><p><br/></p><p><br/></p></div>
    </content>
    <updated>2020-09-28T01:44:00Z</updated>
    <published>2020-09-28T01:44:00Z</published>
    <author>
      <name>gasarch</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03004932739846901628</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2020-09-29T18:33:05Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://tcsplus.wordpress.com/?p=473</id>
    <link href="https://tcsplus.wordpress.com/2020/09/27/tcs-talk-wednesday-september-30-alex-wein-nyu/" rel="alternate" type="text/html"/>
    <title>TCS+ talk: Wednesday, September 30 — Alex Wein, NYU</title>
    <summary>The next TCS+ talk will take place this coming Wednesday, September 30th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). Alex Wein from NYU will speak about “Low-Degree Hardness of Random Optimization Problems” (abstract below). You can reserve a spot as an individual or a group to join […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The next TCS+ talk will take place this coming Wednesday, September 30th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). <strong>Alex Wein</strong> from NYU will speak about “<em>Low-Degree Hardness of Random Optimization Problems</em>” (abstract below). </p>



<p>You can reserve a spot as an individual or a group to join us live by signing up on <a href="https://sites.google.com/site/plustcs/livetalk/live-seat-reservation">the online form</a>. Due to security concerns, <em>registration is required</em> to attend the interactive talk. (The link to the YouTube livestream will also be posted <a href="https://sites.google.com/site/plustcs/livetalk">on our  website</a> on the day of the talk, so people who did not sign up will still be able to  watch the talk live.) As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/site/plustcs/suggest">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/site/plustcs/">the website</a>.</p>



<p class="wp-block-quote">Abstract: In high-dimensional statistical problems (including planted clique, sparse PCA, community detection, etc.), the class of “low-degree polynomial algorithms” captures many leading algorithmic paradigms such as spectral methods, approximate message passing, and local algorithms on sparse graphs. As such, lower bounds against low-degree algorithms constitute concrete evidence for average-case hardness of statistical problems. This method has been widely successful at explaining and predicting statistical-to-computational gaps in these settings. <br/>While prior work has understood the power of low-degree algorithms for problems with a “planted” signal, we consider here the setting of “random optimization problems” (with no planted signal), including the problem of finding a large independent set in a random graph, as well as the problem of optimizing the Hamiltonian of mean-field spin glass models. I will define low-degree algorithms in this setting, argue that they capture the best known algorithms, and explain new proof techniques for giving lower bounds against low-degree algorithms in this setting. The proof involves a variant of the so-called “overlap gap property”, which is a structural property of the solution space.<br/><br/>Based on joint work with David Gamarnik and Aukosh Jagannath, available at <a href="https://arxiv.org/abs/2004.12063">arXiv:2004.12063</a>.</p></div>
    </content>
    <updated>2020-09-27T17:15:50Z</updated>
    <published>2020-09-27T17:15:50Z</published>
    <category term="Announcements"/>
    <author>
      <name>plustcs</name>
    </author>
    <source>
      <id>https://tcsplus.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://tcsplus.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://tcsplus.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://tcsplus.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://tcsplus.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A carbon-free dissemination of ideas across the globe.</subtitle>
      <title>TCS+</title>
      <updated>2020-09-30T07:21:16Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=17636</id>
    <link href="https://rjlipton.wordpress.com/2020/09/27/ibm-conference-on-the-informational-lens/" rel="alternate" type="text/html"/>
    <title>IBM Conference on the Informational Lens</title>
    <summary>Some differences from the Computational Lens Chai Wah Wu, Jonathan Lenchner, Charles Bennett, and Yuhai Tu are the moderators for the four days of the First IBM Research Workshop on the Informational Lens. The virtual workshop begins Tuesday morning at 10:45 ET. The conference has free registration and of course is online. Today we preview […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><font color="#0044cc"><br/>
<em>Some differences from the Computational Lens</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<p><a href="https://rjlipton.files.wordpress.com/2020/09/ibmclmods.png"><img alt="" class="alignright wp-image-17638" height="193" src="https://rjlipton.files.wordpress.com/2020/09/ibmclmods.png?w=153&amp;h=193" width="153"/></a></p>
<p>
Chai Wah Wu, Jonathan Lenchner, Charles Bennett, and Yuhai Tu are the moderators for the four days of the First IBM Research Workshop on the Informational Lens. The <a href="https://sites.google.com/view/informational-lens-workshop-1/home">virtual workshop</a> begins Tuesday morning at 10:45 ET. The conference has free registration and of course is online. </p>
<p>
Today we preview the conference and discuss a few of the talks.</p>
<p>
The workshop’s name echoes the moniker “Through the Computational Lens” of <a href="https://simons.berkeley.edu/news/interdisciplinary-collaboration-at-simons">initiatives</a> led by the Simons Institute at Berkeley and used for a 2014 <a href="https://www.ias.edu/ideas/2015/computational-lens">workshop</a> organized by Avi Wigderson at IAS. A <a href="http://theory.cs.berkeley.edu/computational-lens.html">prospectus</a> by the theory group at U.C. Berkeley led off with quantum computing. So will Tuesday’s talks, a full day on quantum by seven leaders we say more about below.</p>
<p>
Then the meeting will branch in some different directions from the computational-lens themes. The preface on the workshop website says:</p>
<blockquote><p><b> </b> <em> Viewing the world through an informational lens, and understanding constraints and tradeoffs such as energy and parallelism versus reliability and speed, will have profound consequences throughout technology and science. This includes not only mathematics and the natural sciences like physics and biology, but also social sciences such as psychology and linguistics. We aim to bring together leading researchers in science and technology from across the globe to discuss ideas and future research directions through the informational lens. </em>
</p></blockquote>
<p/><p>
The other three days have talks that reach into all these areas, a dazzling array. We have made a collage of the twenty-six speakers currently listed on the schedule. Several faces are long familiar but others are novel to us.</p>
<p><a href="https://rjlipton.files.wordpress.com/2020/09/c1.png"><img alt="" class="aligncenter size-medium wp-image-17639" height="225" src="https://rjlipton.files.wordpress.com/2020/09/c1.png?w=300&amp;h=225" width="300"/></a></p>
<p>
</p><p/><h2> Quantum Tuesday </h2><p/>
<p/><p>
The opening morning has Alexander Holevo between Aram Harrow and Gil Kalai. Among many other accomplishments, Holevo is known for a <a href="https://en.wikipedia.org/wiki/Holevo's_theorem">theorem</a> that implies that <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> qubits can yield at most <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> bits of classical information. In particular, any attempt to encode the edges of a general <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>-vertex graph via entanglements between pairs among <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> qubits must be extremely lossy. He will talk about <em>quantum channels</em> and give a structure theorem for quantum Gaussian observables.</p>
<p>
We don’t have information yet on Aram’s talk. But Gil will update us on the state of his skepticism about the feasibility of large-scale quantum computing. This was the subject of the 2012 debate between Aram and Gil that <a href="https://rjlipton.wordpress.com/2012/01/30/perpetual-motion-of-the-21st-century/">spanned</a> <a href="https://rjlipton.wordpress.com/2012/06/20/can-you-hear-the-shape-of-a-quantum-computer/">eight</a> <a href="https://rjlipton.wordpress.com/2012/10/03/quantum-supremacy-or-classical-control/">posts</a> on this blog. Here are Gil’s title and abstract:</p>
<p>
<font color="blue">Computational complexity, mathematical, and statistical aspects of NISQ computers.</font><br/>
<i>Noisy Intermediate-Scale Quantum (NISQ) Computers hold the key for important theoretical and experimental questions regarding quantum computers. In the lecture I will describe some questions about computational complexity, mathematics, and statistics which arose in my study of NISQ systems and are related to: <br/>
a) My general argument “against” quantum computers, <br/>
b) My analysis (with Yosi Rinot and Tomer Shoham) of the Google 2019 “huge quantum advantage” experiment. </i></p>
<p>
IBM have expressed their own skepticism of Google’s claims, which we mentioned in our own <a href="https://rjlipton.wordpress.com/2019/10/27/quantum-supremacy-at-last/">review</a> of the experiment last year. IBM of course also have their own quantum computing initiative.</p>
<p>
<a href="https://rjlipton.files.wordpress.com/2020/09/q.jpeg"><img alt="" class="aligncenter size-medium wp-image-17640" height="169" src="https://rjlipton.files.wordpress.com/2020/09/q.jpeg?w=300&amp;h=169" width="300"/></a></p>
<p>
We may hear about its state from Charlie Bennett, whose talk leads off the afternoon but has yet to be measured, along with the following talk by Isaac Chuang. Then will come Scott Aaronson. If “tomography” in his title sounds to you like a <a href="https://en.wikipedia.org/wiki/CT_scan">CAT scan</a>, you could consider this a “Schrödinger’s Cat” scan. Well, we should let Scott tell it—the 2018 paper he mentions is <a href="https://arxiv.org/abs/1711.01053">this</a>.</p>
<p>
<font color="red">Shadow Tomography of Quantum States: Progress and Prospects. </font><br/>
<i>Given an unknown quantum state <img alt="{\rho}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\rho}"/>, and a known list of two-outcome measurements <img alt="{E_1,...,E_M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BE_1%2C...%2CE_M%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{E_1,...,E_M}"/>, “shadow tomography” is the task of estimating the probability that each <img alt="{E_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BE_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{E_i}"/> accepts <img alt="{\rho}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\rho}"/>, by carefully measuring only a few copies of <img alt="{\rho}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\rho}"/>. In 2018, I gave the first nontrivial protocol for this task. In 2019, Guy Rothblum and I exploited a new connection between gentle measurement of quantum states and the field of differential privacy, to give a protocol that requires fewer copies of <img alt="{\rho}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\rho}"/> in some cases, and has the additional advantage of being online (that is, the measurements are processed one at a time). Huge challenges remain in making shadow tomography practical with near-term devices; extremely recently Huang, Kueng, and Preskill took some promising steps in that direction. I’ll survey these developments and the challenges that remain.</i> </p>
<p>
Then Srinivasan Arunachalam, who also works at IBM T.J. Watson in Westchester, NY, will finish the day with another talk about inferring from samples:</p>
<p>
<font color="blue">Sample-efficient learning of quantum many-body systems.</font><br/>
<i>We study the problem of learning the Hamiltonian of a quantum many-body system given samples from its Gibbs (thermal) state. The classical analog of this problem, known as learning graphical models or Boltzmann machines, is a well-studied question in machine learning and statistics. In this work, we give the first sample-efficient algorithm for the quantum Hamiltonian learning problem. In particular, we prove that polynomially many samples in the number of particles (qudits) are necessary and sufficient for learning the parameters of a spatially local Hamiltonian in <img alt="{\ell_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\ell_2}"/>-norm. Our main contribution is in establishing the strong convexity of the log-partition function of quantum many-body systems, which along with the maximum entropy estimation yields our sample-efficient algorithm. Our work paves the way toward a more rigorous application of machine learning techniques to quantum many-body problems.</i></p>
<p>
</p><p/><h2> B.Y.O.L. </h2><p/>
<p/><p>
The workshop has lunch breaks as usual but they are not lunch breaks. Lunch is served at IBM T.J. Watson, and I (Ken) can vouch from times I have been hosted there by Jon Lenchner that the food is wonderful, but attendees will not be on hand to partake. I have known Jon since we were part of the New York area chess scene in the 1970s. Among Jon’s activities in the past five years have been directing IBM’s research center in Nairobi, Kenya, and helping the Toronto Raptors assemble a championship basketball team via player analytics. The latter is not technically related to my chess analytics, but we have greater shared interests in ideas for lower bounds on uniform complexity classes.</p>
<p>
Instead of physical lunch, the lunch breaks are moderated panel discussions. So you can bring your own lunch while watching and listening via IBM’s WebEx or other portal. Maybe there will be time for remote attendees to ask questions—though not with your mouth full, as our mothers would say. A few years ago, my department began running catered Friday lunch forums under the name “UpBeat,” but those too are now remote and B.Y.O.L.  As for the other thing the “L.” can stand for besides “lunch,” we can mention that the pandemic has rendered onsite restrictions moot.</p>
<p>
There will also be Q &amp; A and panel discussion sessions for 45 minutes after each day’s last talk. </p>
<p>
</p><p/><h2> Some Other Talks </h2><p/>
<p/><p>
We wish we could attend all the talks. We imagine they will be available afterward as recordings, but especially when there is live Q &amp; A it is nice to experience them in the moment as at a physically intimate workshop. Rather than list all the speakers and titles here—you can find them on the abstracts <a href="https://sites.google.com/view/informational-lens-workshop-1/talk-abstracts">page</a>, after all—we will just highlight a few that catch our eye:</p>
<p>
<font color="red">Fun facts about polynomials, and applications to coding theory: Mary Wootters. </font><br/>
<i>Here are some (fun?) facts about polynomials you probably already know. First, given any three points, you can find a parabola through them. Second, if you look at any vertical “slice” of a paraboloid, you get a parabola. These facts, while simple, turn out to be extremely useful in applications! For example, these facts are behind the efficacy of classical Reed-Solomon and Reed-Muller codes, fundamental tools for communication and storage. But this talk is not about those facts — it’s about a few related facts that you might not know. Given less than three points’ worth of information, what can you learn about a parabola going through those points? Are there things other than paraboloids that you can “slice” and always get parabolas? In this talk, I will tell you some (fun!) facts that answer these questions, and discuss applications to error correcting codes.</i></p>
<p>
<font color="blue">Punch Cards and the Difference Engine: William Gibson and Bruce Sterling. </font><br/>
<i>We discuss the <a href="https://en.wikipedia.org/wiki/The_Difference_Engine">power</a> of the card concept. By storing a finite amount of data on a “punch card” we can structure data handling to be straightforward and safe. The machine we plan will be thousands of times slower than even the first vacuum-tube computers were. But our novel use of steam and punch cards does have merits: cards are physical and help solve security and also privacy issues.</i></p>
<p>
<font color="red">Reasoning about Generalization via Conditional Mutual Information: Lydia Zakynthinou. </font><br/>
<i>We provide a framework for studying the generalization properties of machine learning algorithms, which ties together existing approaches, using the unifying language of information theory. We introduce a new notion based on Conditional Mutual Information (CMI) which quantifies how well the input (i.e., the training data) can be recognized given the output (i.e., the trained model) of the learning algorithm. Bounds on CMI can be obtained from several methods, including VC dimension, compression schemes, and differential privacy, and bounded CMI implies various forms of generalization guarantees. In this talk, I will introduce CMI, show how to obtain bounds on CMI from existing methods and generalization bounds from CMI, and discuss the capabilities of our framework. Joint work with Thomas Steinke.</i></p>
<p>
<font color="blue">Rebooting Mathematics: Doron Zeilberger. </font><br/>
<i>Mathematics is what it is today due to the accidental fact that it was developed before the invention of the computer, and, with a few exceptions, continues in the same vein, by inertia. It is time to start all over, remembering that math, is, or at least should be, the math that can be handled by computers, keeping in mind that they are both discrete and finite.</i></p>
<p>
Oh wait, one of these talks is both less novel and more <a href="https://www.amazon.com/Difference-Engine-Novel-William-Gibson/dp/0440423627">novel</a> than the others.  Can a virtual workshop have a virtual virtual talk?  The cards were arguably “the” informational lens for almost 100 years.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
What have been your experiences with top-of-the-line virtual workshops? Our hats are off to the organizers of this one, and we are looking forward to it.</p>
<p/></font></font></div>
    </content>
    <updated>2020-09-27T15:24:46Z</updated>
    <published>2020-09-27T15:24:46Z</published>
    <category term="All Posts"/>
    <category term="History"/>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="People"/>
    <category term="Teaching"/>
    <category term="Aram Harrow"/>
    <category term="Chai Wah Wu"/>
    <category term="Charles Bennett"/>
    <category term="debate"/>
    <category term="Gil Kalai"/>
    <category term="IBM"/>
    <category term="informational lens"/>
    <category term="Jonathan Lenchner"/>
    <category term="Physics"/>
    <category term="quantum"/>
    <category term="workshop"/>
    <category term="Yuhai Tu"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2020-09-30T07:20:47Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://dstheory.wordpress.com/?p=63</id>
    <link href="https://dstheory.wordpress.com/2020/09/26/friday-oct-09-alexandr-andoni-from-columbia-university/" rel="alternate" type="text/html"/>
    <title>Friday, Oct 09 — Alexandr Andoni from Columbia University</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">The next Foundations of Data Science virtual talk will take place on Friday, Oct 09th at 10:00 AM Pacific Time (1:00 pm Eastern Time, 18:00 Central European Time, 17:00 UTC).  Alexandr Andoni from Columbia University will speak about “Approximating Edit Distance in Near-Linear Time”. Abstract: Edit distance is a classic measure of similarity between strings, with<a class="more-link" href="https://dstheory.wordpress.com/2020/09/26/friday-oct-09-alexandr-andoni-from-columbia-university/">Continue reading <span class="screen-reader-text">"Friday, Oct 09 — Alexandr Andoni from Columbia University"</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The next Foundations of Data Science virtual talk will take place on Friday, Oct 09th at 10:00 AM Pacific Time (1:00 pm Eastern Time, 18:00 Central European Time, 17:00 UTC).  <strong>Alexandr Andoni </strong>from Columbia University will speak about “<em><strong>Approximating Edit Distance in Near-Linear Time</strong></em>”.</p>



<p><strong>Abstract</strong>: Edit distance is a classic measure of similarity between strings, with applications ranging from computational biology to coding. Computing edit distance is also a classic dynamic programming problem, with a quadratic run-time solution, often taught in the “Intro to Algorithms” classes. Improving this runtime has been a decades-old challenge, now ruled likely-impossible using tools from the modern area of fine-grained complexity. We show how to approximate the edit distance between two strings in near-linear time, up to a constant factor. Our result completes a research direction set forth in the breakthrough paper of [Chakraborty, Das, Goldenberg, Koucky, Saks; FOCS’18], which showed the first constant-factor approximation algorithm with a (strongly) sub-quadratic running time.</p>



<p>Joint work with Negev Shekel Nosatzki, available at<a href="https://arxiv.org/abs/2005.07678"> https://arxiv.org/abs/2005.07678</a>.</p>



<p><a href="https://sites.google.com/view/dstheory" rel="noreferrer noopener" target="_blank">Please register here to join the virtual talk.</a></p>



<p>The series is supported by the <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1934846&amp;HistoricalAwards=false">NSF HDR TRIPODS Grant 1934846</a>.</p></div>
    </content>
    <updated>2020-09-26T15:46:40Z</updated>
    <published>2020-09-26T15:46:40Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>dstheory</name>
    </author>
    <source>
      <id>https://dstheory.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://dstheory.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://dstheory.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://dstheory.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://dstheory.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Foundation of Data Science – Virtual Talk Series</title>
      <updated>2020-09-30T07:21:20Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/09/25/tenure-track-assistant-professor-at-university-of-vienna-apply-by-october-1-2020/</id>
    <link href="https://cstheory-jobs.org/2020/09/25/tenure-track-assistant-professor-at-university-of-vienna-apply-by-october-1-2020/" rel="alternate" type="text/html"/>
    <title>Tenure-track assistant professor at University of Vienna (apply by October 1, 2020)</title>
    <summary>We are looking for outstanding computer scientists with a research focus on the management of massive data. Examples for research topics of interest are high-performance data mining and machine learning methods in distributed and parallel environments and techniques for the analysis of high-dimensional data, management and analysis of high-throughput data streams. Website: https://informatik.univie.ac.at/en/news-events/article/news/new-tenure-track-professorship-for-the-field-of-management-of-massive-data/ Email: monika.henzinger@univie.ac.at</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>We are looking for outstanding computer scientists with a research focus on the management of massive data. Examples for research topics of interest are high-performance data mining and machine learning methods in distributed and parallel environments and techniques for the analysis of high-dimensional data, management and analysis of high-throughput data streams.</p>
<p>Website: <a href="https://informatik.univie.ac.at/en/news-events/article/news/new-tenure-track-professorship-for-the-field-of-management-of-massive-data/">https://informatik.univie.ac.at/en/news-events/article/news/new-tenure-track-professorship-for-the-field-of-management-of-massive-data/</a><br/>
Email: monika.henzinger@univie.ac.at</p></div>
    </content>
    <updated>2020-09-25T07:23:35Z</updated>
    <published>2020-09-25T07:23:35Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-09-30T07:20:49Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/147</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/147" rel="alternate" type="text/html"/>
    <title>TR20-147 |  Batch Verification for Statistical Zero Knowledge Proofs | 

	Inbar Kaslasi, 

	Guy Rothblum, 

	Ron Rothblum, 

	Adam Sealfon, 

	Prashant Nalini Vasudevan</title>
    <summary>A statistical zero-knowledge proof (SZK) for a problem $\Pi$ enables a computationally unbounded prover to convince a polynomial-time verifier that $x \in \Pi$ without revealing any additional information about $x$ to the verifier, in a strong information-theoretic sense.

Suppose, however, that the prover wishes to convince the verifier that $k$ separate inputs $x_1,\dots,x_k$ all belong to $\Pi$ (without revealing anything else). A naive way of doing so is to simply run the SZK protocol separately for each input. In this work we ask whether one can do better -- that is, is efficient batch verification possible for SZK?

We give a partial positive answer to this question by constructing a batch verification protocol for a natural and important subclass of SZK -- all problems $\Pi$ that have a non-interactive SZK protocol (in the common random string model). More specifically, we show that, for every such problem $\Pi$, there exists an honest-verifier SZK protocol for batch verification of $k$ instances, with communication complexity $poly(n) + k \cdot poly(\log{n},\log{k})$, where $poly$ refers to a fixed polynomial that depends only on $\Pi$ (and not on $k$). This result should be contrasted with the naive solution, which has communication complexity $k \cdot poly(n)$.

Our proof leverages a new NISZK-complete problem, called Approximate Injectivity, that we find to be of independent interest. The goal in this problem is to distinguish circuits that are nearly injective, from those that are non-injective on almost all inputs.</summary>
    <updated>2020-09-24T13:41:26Z</updated>
    <published>2020-09-24T13:41:26Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-09-30T07:20:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/146</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/146" rel="alternate" type="text/html"/>
    <title>TR20-146 |  On the Hardness of Detecting Macroscopic Superpositions | 

	Scott Aaronson, 

	Yosi Atia, 

	Leonard Susskind</title>
    <summary>When is decoherence "effectively irreversible"? Here we examine this central question of quantum foundations using the tools of quantum computational complexity. We prove that, if one had a quantum circuit to determine if a system was in an equal superposition of two orthogonal states (for example, the $|$Alive$\rangle$ and $|$Dead$\rangle$ states of Schrodinger's cat), then with only a slightly larger circuit, one could also $\mathit{swap}$ the two states (e.g., bring a dead cat back to life). In other words, observing interference between the $|$Alive$\rangle$and $|$Dead$\rangle$ states is a "necromancy-hard" problem, technologically infeasible in any world where death is permanent. As for the converse statement (i.e., ability to swap implies ability to detect interference), we show that it holds modulo a single exception, involving unitaries that (for example) map $|$Alive$\rangle$ to $|$Dead$\rangle$ but $|$Dead$\rangle$ to -$|$Alive$\rangle$. We also show that these statements are robust---i.e., even a $\mathit{partial}$ ability to observe interference implies partial swapping ability, and vice versa. Finally, without relying on any unproved complexity conjectures, we show that all of these results are quantitatively tight. Our results have possible implications for the state dependence of observables in quantum gravity, the subject that originally motivated this study.</summary>
    <updated>2020-09-23T22:45:17Z</updated>
    <published>2020-09-23T22:45:17Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-09-30T07:20:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/145</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/145" rel="alternate" type="text/html"/>
    <title>TR20-145 |  An Improved Exponential-Time Approximation Algorithm for Fully-Alternating Games Against Nature | 

	Andrew Drucker</title>
    <summary>"Games against Nature" [Papadimitriou '85] are two-player games of perfect information, in which one player's moves are made randomly (here, uniformly); the final payoff to the non-random player is given by some $[0, 1]$-valued function of the move history.  Estimating the value of such games under optimal play, and computing near-optimal strategies, is an important goal in the study of decision-making under uncertainty, and has seen significant research in AI and allied areas [Hnich, Rossi, Tarim, Prestwich '11], with only experimental evaluation of most algorithms' performance.  The problem's PSPACE-completeness does not rule out nontrivial algorithms.  Improved algorithms with theoretical guarantees are known in various cases where the payoff function $F$ has special structure, and Littman, Majercik, and Pitassi [LMP'01] give a sampling-based improved algorithm for general $F$, for turn-orders which restrict the number of non-random player strategies.

We study the case of general $F$ for which the players strictly alternate with binary moves $(w_1, r_1, w_2, r_2, \ldots, w_{n/2}, r_{n/2})$---for which the approach of [LMP'01] does not improve over brute force.  We give a randomized algorithm to approximate the value of such games under optimal play, and to execute near-optimal strategies. Our algorithm achieves exponential savings over brute-force, making $2^{(1 - \delta) n}$ queries to $F$ for some absolute constant $\delta &gt; 0$, and certifies a lower bound $\hat{v}$ on the game value $v$ with additive expected error bounded as $E[v - \hat{v}] \leq \exp(-\Omega(n))$.  (On the downside, $\delta$ is tiny and the algorithm uses exponential space.)

Our algorithm is recursive, and bootstraps a "base case" algorithm for fixed-size inputs.  The method of recursive composition used, the specific base-case guarantees needed, and the steps to establish these guarantees are interesting and, we feel, likely to find uses beyond the present work.</summary>
    <updated>2020-09-23T21:48:34Z</updated>
    <published>2020-09-23T21:48:34Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-09-30T07:20:35Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-7113260074896603448</id>
    <link href="https://blog.computationalcomplexity.org/feeds/7113260074896603448/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/09/remembering-2000.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7113260074896603448" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7113260074896603448" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/09/remembering-2000.html" rel="alternate" type="text/html"/>
    <title>Remembering 2000</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="http://www.cs.cmu.edu/~FOCS2000/">FOCS 2000</a> took place in Redondo Beach, just south of Los Angeles, November 12-14. Certainly some great results such as the Reingold-Vadhan-Wigderson <a href="https://doi.org/10.1109/SFCS.2000.892006">Zig-Zag Graph Product Expander construction</a> that would lead to Omer Reingold's <a href="https://blog.computationalcomplexity.org/2014/02/favorite-theorems-connecting-in-log.html">Undirected Connectivity in Log Space</a>. Mostly though I remember the discussions about the presidential election held the week before and whether we might find out our next president during the conference. Spoiler alert: <a href="https://en.wikipedia.org/wiki/2000_United_States_presidential_election_recount_in_Florida">We didn't</a>. </p><p>Consider the following viewpoints for a person X</p><p>1. Did X support Bush or Gore?</p><p>2. Did X interpret the rules of the election that Bush won or Gore won?</p><p>These should be independent events. Your interpretation of the rules should not depend on who you supported. But in fact they were nearly perfectly correlated. Whether you were a politician, a newspaper editorial page writer, a supreme court justice, a computer scientist or pretty much everyone else, if you supported Gore, you believed he won the election and vice-versa. Everyone had their logic why they were right and I'm sure my readers who remember that election still believe their logic was correct. </p><p>As this upcoming election gets messy, as it already has, take care with trying to justify your desired endgame by choosing the logic that makes it work. Would you use the same logic if the candidates were reversed? Everyone says "yes" but it's rarely true. Just like Mitch McConnell, you'll just find some excuse why the opposite situation is different. Trust me, my logic is impeccable. </p></div>
    </content>
    <updated>2020-09-23T21:33:00Z</updated>
    <published>2020-09-23T21:33:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2020-09-29T18:33:05Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=20259</id>
    <link href="https://gilkalai.wordpress.com/2020/09/23/to-cheer-you-up-in-difficult-times-12-asaf-ferber-and-david-conlon-found-new-lower-bounds-for-diagonal-ramsey-numbers/" rel="alternate" type="text/html"/>
    <title>To cheer you up in difficult times 12:  Asaf Ferber and David Conlon found new lower bounds for diagonal Ramsey numbers</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Update (Sept. 28): Yuval Wigderson has made a further improvement on the multicolor Ramsey number bound for more than three colors. Lower bounds for multicolor Ramsey numbers The Ramsey number r(t; ℓ) is the smallest natural number n such that … <a href="https://gilkalai.wordpress.com/2020/09/23/to-cheer-you-up-in-difficult-times-12-asaf-ferber-and-david-conlon-found-new-lower-bounds-for-diagonal-ramsey-numbers/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p class="title mathjax"><strong>Update (Sept. 28):</strong> Yuval Wigderson <a href="https://arxiv.org/abs/2009.12020">has made a further improvement on the multicolor Ramsey number bound for more than three colors.</a></p>
<h2><a href="https://arxiv.org/abs/2009.10458">Lower bounds for multicolor Ramsey numbers</a></h2>
<p>The Ramsey number <em>r(t; ℓ)</em> is the smallest natural number <em>n</em> such that every ℓ-coloring of the edges of the complete graph <img alt="K_n" class="latex" src="https://s0.wp.com/latex.php?latex=K_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K_n"/> contains a monochromatic <img alt="K_t" class="latex" src="https://s0.wp.com/latex.php?latex=K_t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K_t"/>. (<em>r(t;2)</em> is often denoted by<em> R(t,t)</em> and <em>r(t;3)</em> by R<em>(t,t,t)</em> etc.) <a href="https://en.wikipedia.org/wiki/Ramsey%27s_theorem">Famously</a>, <em>R(3,3)=6</em>; <em>R(4,4)=18</em>;  and <em>R(3,3,3)=17</em>. Understanding <em>R(t,t)</em> is among the most famous problems in combinatorics. (Understanding if r(3; <em> ℓ</em>) is exponential or superexponential in<em> ℓ</em> is also a very famous problem.)</p>
<p>It is known since the 1940s that <img alt="t/2 +o(1) \le log_2 R(t,t) \le 2t" class="latex" src="https://s0.wp.com/latex.php?latex=t%2F2+%2Bo%281%29+%5Cle+log_2+R%28t%2Ct%29+%5Cle+2t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t/2 +o(1) \le log_2 R(t,t) \le 2t"/>.</p>
<p>Lower bounds for <em>R(t,t)</em> where used by Lefmann in 1987 to give lower bounds on <em>r(t; ℓ)</em> for <em> ℓ</em>&gt;2. Asaf Ferber and David Conlon gave now <span style="color: #ff0000;"><strong>exponential</strong></span> improvement. This is truly remarkable and <a href="https://arxiv.org/abs/2009.10458">the paper is just 4-page long!</a> congratulations Asaf and David!</p>
<p>Expect more cheering news of discrete geometry nature from Oberwolfach. (I take part remotely in the traditional meeting on Discrete and computational geometry, see pictures below).</p>
<p>Update (Sept 24.): <a href="https://anuragbishnoi.wordpress.com/2020/09/23/improved-lower-bounds-for-multicolour-diagonal-ramsey-numbers/">An excellent blog post on Anurag math blog.</a> Anurag describes in details the construction, describes the connections with finite geometries, and improves the construction to get a better result. (See also there many cool posts, e.g., an earlier post with some connections of finite geometries and different Ramsey problems <a href="https://anuragbishnoi.wordpress.com/2020/09/10/heisenberg-groups-irreducible-cubics-and-minimal-ramsey/" rel="bookmark">Heisenberg groups, irreducible cubics and minimal Ramsey</a>.)</p>
<p><a href="https://gilkalai.files.wordpress.com/2020/09/pak.png"><img alt="" class="alignnone size-medium wp-image-20264" height="188" src="https://gilkalai.files.wordpress.com/2020/09/pak.png?w=300&amp;h=188" width="300"/></a> <a href="https://gilkalai.files.wordpress.com/2020/09/ow2.png"><img alt="" class="alignnone size-medium wp-image-20265" height="188" src="https://gilkalai.files.wordpress.com/2020/09/ow2.png?w=300&amp;h=188" width="300"/></a></p></div>
    </content>
    <updated>2020-09-23T11:24:44Z</updated>
    <published>2020-09-23T11:24:44Z</published>
    <category term="Combinatorics"/>
    <category term="Asaf Ferber"/>
    <category term="David Conlon"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2020-09-30T07:20:38Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=17612</id>
    <link href="https://rjlipton.wordpress.com/2020/09/22/puzzle-reviews-by-a-puzzle-writer/" rel="alternate" type="text/html"/>
    <title>Puzzle Reviews by a Puzzle Writer</title>
    <summary>Not puzzling reviews Princeton University Press page Jason Rosenhouse is professor in the Department of Mathematics at James Madison University. His research focuses on algebraic graph theory and analytic number theory involving exponential sums. The former includes a neat paper on expansion properties of a family of graphs associated to block designs, with two undergraduates […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Not puzzling reviews</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2020/09/jason-1.jpeg"><img alt="" class="alignright wp-image-17615" height="160" src="https://rjlipton.files.wordpress.com/2020/09/jason-1.jpeg?w=140&amp;h=160" width="140"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Princeton University Press <a href="https://press.princeton.edu/our-authors/rosenhouse-jason">page</a></font></td>
</tr>
</tbody>
</table>
<p>
Jason Rosenhouse is professor in the Department of Mathematics at James Madison University. His research focuses on algebraic graph theory and analytic number theory involving exponential sums.  The former includes a neat <a href="https://www.researchgate.net/publication/220620901_Expansion_Properties_Of_Levi_Graphs">paper</a> on expansion properties of a family of graphs associated to block designs, with two undergraduates among its authors.  But besides his “real” research, he has written a number of books on puzzles such as <i><a href="https://www.amazon.com/s?k=Jason+Rosenhouse&amp;i=stripbooks&amp;ref=nb_sb_noss_2">The Monty Hall Problem</a>: The Remarkable Story of Math’s Most Contentious Brain Teaser</i>. Soon his book <i><a href="https://www.amazon.co.uk/Games-Your-Mind-History-Puzzles/dp/0691174075">Games for Your Mind</a>: The History and Future of Logic Puzzles</i> is to be published.</p>
<p><a href="https://rjlipton.files.wordpress.com/2020/09/revbook-1.png"><img alt="" class="aligncenter size-thumbnail wp-image-17626" height="150" src="https://rjlipton.files.wordpress.com/2020/09/revbook-1.png?w=103&amp;h=150" width="103"/></a></p>
<p>
Today Ken and I thought we would highlight his recent review of a book on math puzzles.<br/>
<span id="more-17612"/></p>
<p>
I have mixed feelings about puzzles. I like them, and am happy when I can understand their solution. I am even happier when I can solve them. I sometimes feel that I should spend my limited brain cycles on “real” problems. But puzzles are fun. </p>
<p>
Rosenhouse’s <a href="https://www.ams.org/journals/notices/202009/rnoti-p1382.pdf">review</a> is in the recent <em>Notices of the AMS</em> on the book <i><a href="https://bookstore.ams.org/prb-36">Bicycles or Unicycles</a>: A Collection of Intriguing Mathematical Puzzles</i>. This book, the “Bicycle Book,” is authored by Daniel Velleman and Stan Wagon.</p>
<p><a href="https://rjlipton.files.wordpress.com/2020/09/maabook.jpg"><img alt="" class="aligncenter wp-image-17617" height="145" src="https://rjlipton.files.wordpress.com/2020/09/maabook.jpg?w=101&amp;h=145" width="101"/></a></p>
<p>
Their book is a collection of <img alt="{3 \times 5 \times 7}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3+%5Ctimes+5+%5Ctimes+7%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{3 \times 5 \times 7}"/> mathematical puzzles. Rosenhouse likes their book, which means a lot coming from an author of so many puzzle books himself. </p>
<p>
</p><p/><h2> A Cool Problem </h2><p/>
<p/><p>
Rosenhouse presents this problem from the Bicycle Book. </p>
<blockquote><p><b> </b> <em> You are playing solitaire in the first quadrant of the Cartesian plane, the lower corner of which is shown in Figure 1. You begin with a single checker on square a1. On each turn, a legal move consists of removing one checker from the board and then placing two new checkers in the cells immediately above and to the right of the original checker. If either of those two cells is occupied, then the move is illegal, and a different checker must be selected for removal. </em>
</p></blockquote>
<p/><p>
<a href="https://rjlipton.files.wordpress.com/2020/09/solitairepuzzle.png"><img alt="" class="aligncenter size-full wp-image-17618" src="https://rjlipton.files.wordpress.com/2020/09/solitairepuzzle.png?w=600"/></a></p>
<p>
Show that you can never make all of the <img alt="{3 \times 3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3+%5Ctimes+3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{3 \times 3}"/> lower-left squares empty. This is a complexity question. You describe a computation and assert that certain states cannot be reached. The challenge is two-fold: </p>
<ol>
<li>
The computation is nondeterministic. There can be more than one next state. <p/>
</li><li>
The computation can reach infinitely many states. The task is to prove that no reachable state has the lower nine squares empty.
</li></ol>
<p>
</p><p/><h2> A Cool Solution </h2><p/>
<p/><p>
I must admit I read the solution before I tried to solve the puzzle. I did find an alternative solution. It was not as clever as the one from the book. Let’s look at that solution first. </p>
<p>
The idea is to assign <i>magic</i> values to each square on the checkerboard. The value of a state is the sum over all the values of squares with a checker. We need these to hold: </p>
<ol>
<li>
The value of the initial square is <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>. <p/>
</li><li>
The value of a move leaves the total sum over all the checkers the same. <p/>
</li><li>
The value of the squares <b>not</b> in the lower <img alt="{3 \times 3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3+%5Ctimes+3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{3 \times 3}"/> is less than <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>.
</li></ol>
<p>Then there can never be a reachable state that avoids all the lower <img alt="{3 \times 3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3+%5Ctimes+3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{3 \times 3}"/>. How can we do this? Assign the values as shown below. </p>
<p align="center"><img alt="\displaystyle  \begin{array}{ccccl} \vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \\ 1/8 &amp; 1/16 &amp; 1/32 &amp; 1/64 &amp; \cdots\\ 1/4 &amp; 1/8 &amp; 1/16 &amp; 1/32 &amp; \cdots\\ 1/2 &amp; 1/4 &amp; 1/8 &amp; 1/16 &amp; \cdots\\ 1 &amp; 1/2 &amp; 1/4 &amp; 1/8 &amp; \cdots \end{array} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Barray%7D%7Bccccl%7D+%5Cvdots+%26+%5Cvdots+%26+%5Cvdots+%26+%5Cvdots+%26+%5C%5C+1%2F8+%26+1%2F16+%26+1%2F32+%26+1%2F64+%26+%5Ccdots%5C%5C+1%2F4+%26+1%2F8+%26+1%2F16+%26+1%2F32+%26+%5Ccdots%5C%5C+1%2F2+%26+1%2F4+%26+1%2F8+%26+1%2F16+%26+%5Ccdots%5C%5C+1+%26+1%2F2+%26+1%2F4+%26+1%2F8+%26+%5Ccdots+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \begin{array}{ccccl} \vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \\ 1/8 &amp; 1/16 &amp; 1/32 &amp; 1/64 &amp; \cdots\\ 1/4 &amp; 1/8 &amp; 1/16 &amp; 1/32 &amp; \cdots\\ 1/2 &amp; 1/4 &amp; 1/8 &amp; 1/16 &amp; \cdots\\ 1 &amp; 1/2 &amp; 1/4 &amp; 1/8 &amp; \cdots \end{array} "/></p>
<p>
Ken remembers, as a teenager, seeing this puzzle in a collection by the master Martin Gardner, with the same proof. Ken thought of it again when considering problems in physics and combinatorics that involve defining an appropriate potential function as the first step. </p>
<p>
</p><p/><h2> An Uncool Solution </h2><p/>
<p/><p>
Let <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> be the lower-right <img alt="{3 \times 3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3+%5Ctimes+3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{3 \times 3}"/> corner board. Label the positions as usual with <img alt="{(i,j)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28i%2Cj%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(i,j)}"/> where <img alt="{i,j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%2Cj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i,j}"/> both are in <img alt="{\{1,2,3\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B1%2C2%2C3%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{1,2,3\}}"/>.</p>
<p>
Let <img alt="{N(t)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N(t)}"/> be the number of checkers in <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> at time <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t}"/>. Of course <img alt="{N(0)=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%280%29%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N(0)=1}"/> and the checker is at <img alt="{(1,1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%281%2C1%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(1,1)}"/>.</p>
<p>
<a href="https://rjlipton.files.wordpress.com/2020/09/config33v1.jpg"><img alt="" class="aligncenter wp-image-17621" height="107" src="https://rjlipton.files.wordpress.com/2020/09/config33v1.jpg?w=150&amp;h=107" width="150"/></a></p>
<p>
Suppose by way of contradiction that it is possible to make <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> empty. </p>
<p>
Our proof uses that the transition from <img alt="{N(t)&gt;0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%28t%29%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N(t)&gt;0}"/> to <img alt="{N(t+1)=0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%28t%2B1%29%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N(t+1)=0}"/> requires that <img alt="{N(t)=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%28t%29%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N(t)=1}"/>. That is <img alt="{N(t)=2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%28t%29%3D2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N(t)=2}"/> or even <img alt="{3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{3}"/> is impossible. The rule cannot remove two or more checkers from <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> in one move. </p>
<p>
<a href="https://rjlipton.files.wordpress.com/2020/09/config33v2.jpg"><img alt="" class="aligncenter wp-image-17622" height="97" src="https://rjlipton.files.wordpress.com/2020/09/config33v2.jpg?w=150&amp;h=97" width="150"/></a></p>
<p>
Let <img alt="{N(t)=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%28t%29%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N(t)=1}"/> and <img alt="{N(t+1)=0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%28t%2B1%29%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N(t+1)=0}"/>. So where is the checker? A simple case analysis shows it must be at <img alt="{(3,3)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%283%2C3%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(3,3)}"/>. So now we know the last placement. But how did we get to this position? It is easy to see that it had to be previously at <img alt="{(3,2)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%283%2C2%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(3,2)}"/> or <img alt="{(2,3)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%282%2C3%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(2,3)}"/>. By symmetry we can assume was <img alt="{(3,2)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%283%2C2%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(3,2)}"/>. </p>
<p>
<a href="https://rjlipton.files.wordpress.com/2020/09/config33v3.jpg"><img alt="" class="aligncenter wp-image-17623" height="98" src="https://rjlipton.files.wordpress.com/2020/09/config33v3.jpg?w=150&amp;h=98" width="150"/></a></p>
<p>
Our goal to show that we cannot place one checker at <img alt="{(3,2)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%283%2C2%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(3,2)}"/> and no other in <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/>. A little analysis shows that it must be the case that the previous state was one checker at <img alt="{(3,1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%283%2C1%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(3,1)}"/>. But it is impossible to place a checker there and avoid having more checkers. This yields a contradiction. </p>
<p>
<a href="https://rjlipton.files.wordpress.com/2020/09/config33v4.jpg"><img alt="" class="aligncenter wp-image-17624" height="97" src="https://rjlipton.files.wordpress.com/2020/09/config33v4.jpg?w=150&amp;h=97" width="150"/></a></p>
<p/><h2> Another Solution </h2><p/>
<p/><p>
We could use finite state automata theory to supply another solution. The obvious issue is the full game is played on an infinite checkerboard. But we can use a standard trick to reduce the state space to a finite one. Imagine we play the game on just <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/>. When we have a move that creates checkers outside of <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> just throw them away. It is simple to see that no move can place checkers inside <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/>. Thus if we cannot empty <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> in this finite version, then there is no way in the full game. </p>
<p>
Now the state space is bounded by <img alt="{2^{9}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5E%7B9%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2^{9}}"/>: each of the nine squares can have a checker or not. We know the initial state and we know the final state. So we can run a finite state search algorithm and decide the answer.</p>
<p>
The value of this solution is that it could handle more complex rules and larger squares. Well at least those within reason. </p>
<p>
</p><p/><h2> Other Puzzles </h2><p/>
<p/><p>
Rosenhouse covers nine other puzzles in his review. In our meta review of his review we will cover just two more. </p>
<p>
The third puzzle in his review comes from the challenge to prove that each matrix in a certain family <img alt="{\{C_n\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7BC_n%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{C_n\}}"/> has determinant <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>. The particular matrices <img alt="{C_{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_{n}}"/> look like they could have some strange determinant, one that even varies with <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>. The trick is to show that there are other families <img alt="{\{A_n\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7BA_n%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{A_n\}}"/> and <img alt="{\{B_n\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7BB_n%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{B_n\}}"/> of matrices, in which each matrix has determinant <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/> and that 	</p>
<p align="center"><img alt="\displaystyle  C_n = A_n B_n. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++C_n+%3D+A_n+B_n.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  C_n = A_n B_n. "/></p>
<p>Of course this immediately proves that <img alt="{C_{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_{n}}"/> also have determinant <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>. The challenge is kind of a factorization problem. </p>
<p>
Another puzzle is to prove that a number <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> is prime if and only if there is exactly one pair of positive integers <img alt="{m,n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%2Cn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m,n}"/> such that </p>
<p align="center"><img alt="\displaystyle  \frac{1}{m} - \frac{1}{n} = \frac{1}{p}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7B1%7D%7Bm%7D+-+%5Cfrac%7B1%7D%7Bn%7D+%3D+%5Cfrac%7B1%7D%7Bp%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \frac{1}{m} - \frac{1}{n} = \frac{1}{p}. "/></p>
<p>This seems to be surprising in two ways: First who could think of this? Second who could think of this? Okay it should be why is it true? Indeed Rosenhouse says that the proof is complex. </p>
<p>
Rosenhouse adds that most puzzles in this book are less “bite-sized” than the ones typically posed by the master Gardner. This certainly goes for the title puzzle about whether a bicycle can possibly move along a curve—other than a straight line—that was made by a unicycle. It requires a foray into differential equations.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
My “uncool solution” was left somewhat incomplete. Do you see how to complete the analysis?</p>
<p>
[some word fixes]</p></font></font></div>
    </content>
    <updated>2020-09-22T22:01:06Z</updated>
    <published>2020-09-22T22:01:06Z</published>
    <category term="All Posts"/>
    <category term="Ideas"/>
    <category term="Oldies"/>
    <category term="Teaching"/>
    <category term="trick"/>
    <category term="book reviews"/>
    <category term="Daniel Velleman"/>
    <category term="Jason Rosenhouse"/>
    <category term="puzzles"/>
    <category term="Stan Wagon"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2020-09-30T07:20:46Z</updated>
    </source>
  </entry>
</feed>
