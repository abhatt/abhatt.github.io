<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2019-07-22T09:22:32Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-7828284719883166611</id>
    <link href="https://blog.computationalcomplexity.org/feeds/7828284719883166611/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/07/answer-to-both-infinite-hats-problems.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7828284719883166611" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7828284719883166611" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/07/answer-to-both-infinite-hats-problems.html" rel="alternate" type="text/html"/>
    <title>Answer to both Infinite Hats Problems from the last post</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><br/>
(This is a joint post with David Marcus. You'll see why later.)<br/>
<br/>
In a prior  I posed two infinite hat problems. Today I post the solutions. Actually this is a copy of my last post with the solutions added, so it is self contained.<br/>
<br/>
A Hat Problem that you have probably seen:<br/>
<br/>
1) There are an infinite number of people, numbered 1,2,3,...  There are 2 colors of hats. They can all see everyone's hat but their own. <br/>
<br/>
2) The adversary is going to put hats on all the people. They will guess their own hat color<i> at the same time</i>. <br/>
<br/>
3) The people can discuss strategy ahead of time, but must use a deterministic strategy and the adversary knows the strategy.<br/>
<br/>
4) The people want to minimize how many they get wrong. <br/>
<br/>
5) The adversary puts on hats to maximize how many they get wrong.<br/>
<br/>
I ask two questions (the answers are in a document I point to) and one meta-question:<br/>
<br/>
Q1: Is there a solution where they get all but a finite number of the guesses right? (If you have read my prior post on hat puzzles, <a href="https://blog.computationalcomplexity.org/2017/07/two-hat-problems-you-may-or-may-not.html">here</a> then you can do this one.) <br/>
<br/>
Q2: Is there a solution where they get all but at most (say) 18 wrong.<br/>
<br/>
<br/>
Answers to Q1 and Q2 are <a href="https://www.cs.umd.edu/users/gasarch/BLOGPAPERS/infinitehats.pdf">here</a>.<br/>
<br/>
How did I get into this problem? I was looking at hat problems a while back. Then  I began discussing Q1 and Q2 by email  (Does the term <i>discussing</i> have as a default that it is by email?) with David Marcus who had just read the chapter of <a href="https://www.amazon.com/Problems-Point-Exploring-Computer-Science/dp/9813279974">Problems with a Point</a> on hat puzzles. After a few emails back and fourth, he began looking on the web for answers. He found one. There is a website of hat puzzles! It was MY website papers on  Hat Puzzles! It is  <a href="https://www.cs.umd.edu/users/gasarch/TOPICS/hats/hats.html">here</a>. And on it was a relevant paper <a href="https://www.cs.umd.edu/users/gasarch/TOPICS/hats/infinite-hats-and-ac.pdf">here</a>. We did not find any other source of the problem or its solution. <br/>
<br/>
Q3: How well known is problem Q2 and the solution?  I've seen Q1 around but the only source on Q2 that I know of is that paper, and now this blog post. So, please leave a comment telling me if you have seen Q2 and/or the solution someplace else, and if so where.<br/>
<br/>
The responses to my last post indicated that YES the problem was out there, but the proof that you could not get all-but-18 was not well known. <br/>
<br/>
I THINK that all of the proofs that you can't do all-but-18 in the comment of the last post were essentially the same as the solution I pointed to in this blog. I would be interested if there is an alternative proof. <br/></div>
    </content>
    <updated>2019-07-22T03:00:00Z</updated>
    <published>2019-07-22T03:00:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-07-22T09:08:53Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.08579</id>
    <link href="http://arxiv.org/abs/1907.08579" rel="alternate" type="text/html"/>
    <title>On Approximate Range Mode and Range Selection</title>
    <feedworld_mtime>1563753600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/El=Zein:Hicham.html">Hicham El-Zein</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/He:Meng.html">Meng He</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Munro:J=_Ian.html">J. Ian Munro</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nekrich:Yakov.html">Yakov Nekrich</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sandlund:Bryce.html">Bryce Sandlund</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.08579">PDF</a><br/><b>Abstract: </b>For any $\epsilon \in (0,1)$, a $(1+\epsilon)$-approximate range mode query
asks for the position of an element whose frequency in the query range is at
most a factor $(1+\epsilon)$ smaller than the true mode. For this problem, we
design an $O(n/\epsilon)$ bit data structure supporting queries in
$O(\lg(1/\epsilon))$ time. This is an encoding data structure which does not
require access to the input sequence; we prove the space cost is asymptotically
optimal for constant $\epsilon$. Our solution improves the previous best result
of Greve et al. (Cell Probe Lower Bounds and Approximations for Range Mode,
ICALP'10) by reducing the space cost by a factor of $\lg n$ while achieving the
same query time. We also design an $O(n)$-word dynamic data structure that
answers queries in $O(\lg n /\lg\lg n)$ time and supports insertions and
deletions in $O(\lg n)$ time, for any constant $\epsilon \in (0,1)$. This is
the first result on dynamic approximate range mode; it can also be used to
obtain the first static data structure for approximate 3-sided range mode
queries in two dimensions.
</p>
<p>We also consider approximate range selection. For any $\alpha \in (0,1/2)$,
an $\alpha$-approximate range selection query asks for the position of an
element whose rank in the query range is in $[k - \alpha s, k + \alpha s]$,
where $k$ is a rank given by the query and $s$ is the size of the query range.
When $\alpha$ is a constant, we design an $O(n)$-bit encoding data structure
that can answer queries in constant time and prove this space cost is
asymptotically optimal. The previous best result by Krizanc et al. (Range Mode
and Range Median Queries on Lists and Trees, Nordic Journal of Computing, 2005)
uses $O(n\lg n)$ bits, or $O(n)$ words, to achieve constant approximation for
range median only. Thus we not only improve the space cost, but also provide
support for any arbitrary $k$ given at query time.
</p></div>
    </summary>
    <updated>2019-07-22T01:30:27Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.08559</id>
    <link href="http://arxiv.org/abs/1907.08559" rel="alternate" type="text/html"/>
    <title>An Algorithm and Estimates for the Erd\H{o}s-Selfridge Function (work in progress)</title>
    <feedworld_mtime>1563753600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Brianna Sorenson, Jonathan P Sorenson, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Webster:Jonathan.html">Jonathan Webster</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.08559">PDF</a><br/><b>Abstract: </b>Let $p(n)$ denote the smallest prime divisor of the integer $n$. Define the
function $g(k)$ to be the smallest integer $&gt;k+1$ such that
$p(\binom{g(k)}{k})&gt;k$. So we have $g(2)=6$ and $g(3)=g(4)=7$. In this paper we
present the following new results on the Erd\H{o}s-Selfridge function $g(k)$:
We present a new algorithm to compute the value of $g(k)$, and use it to both
verify previous work and compute new values of $g(k)$, with our current limit
being $$ g(272)=57\ 61284\ 34192\ 78614\ 55093\ 37498. $$ We define a new
function $\hat{g}(k)$, and under the assumption of our Uniform Distribution
Heuristic we show that $$ \log g(k) = \log \hat{g}(k) + O(\log k) $$ with high
"probability". We also provide computational evidence to support our claim that
$\hat{g}(k)$ estimates $g(k)$ reasonably well in practice. There are several
open conjectures on the behavior of $g(k)$ which we are able to prove for
$\hat{g}(k)$, namely that $$ \frac{1-\log 2}{2}+o(1) \quad \le \quad \frac{\log
\hat{g}(k)}{k/\log k} \quad \le \quad 2+o(1), $$ and that $$
\limsup_{k\rightarrow\infty} \frac{\hat{g}(k+1)}{\hat{g}(k)}=\infty.$$ Let
$G(x,k)$ count the number of integers $n\le x$ such that $p(\binom{n}{k})&gt;k$.
Unconditionally, we prove that for large $x$, $G(x,k)$ is asymptotic to
$x/\hat{g}(k)$. And finally, we show that the running time of our new algorithm
is at most $g(k) \exp[ -c (k\log\log k) /(\log k)^2 (1+o(1))]$ for a constant
$c&gt;0$.
</p></div>
    </summary>
    <updated>2019-07-22T01:25:38Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.08433</id>
    <link href="http://arxiv.org/abs/1907.08433" rel="alternate" type="text/html"/>
    <title>Some Polycubes Have No Edge-Unzipping</title>
    <feedworld_mtime>1563753600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Joseph O'Rourke <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.08433">PDF</a><br/><b>Abstract: </b>It is unknown whether or not every polycube has an edge-unfolding. A polycube
is an object constructed by gluing cubes face-to-face. An edge-unfolding cuts
edges on the surface and unfolds it to a net, a non-overlapping polygon in the
plane. Here we explore the more restricted edge-unzippings where the cut edges
form a path. We construct a polycube that has no edge-unzipping.
</p></div>
    </summary>
    <updated>2019-07-22T01:35:40Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-07-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.08402</id>
    <link href="http://arxiv.org/abs/1907.08402" rel="alternate" type="text/html"/>
    <title>Favourite distances in 3-space</title>
    <feedworld_mtime>1563753600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Swanepoel:Konrad_J=.html">Konrad J. Swanepoel</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.08402">PDF</a><br/><b>Abstract: </b>Let $S$ be a set of $n$ points in Euclidean $3$-space. Assign to each $x\in
S$ a distance $r(x)&gt;0$, and let $e_r(x,S)$ denote the number of points in $S$
at distance $r(x)$ from $x$. Avis, Erd\H{o}s and Pach (1988) introduced the
extremal quantity $f_3(n)=\max\sum_{x\in S}e_r(x,S)$, where the maximum is
taken over all $n$-point subsets $S$ of 3-space and all assignments $r\colon
S\to(0,\infty)$ of distances. We show that if the pair $(S,r)$ maximises
$f_3(n)$ and $n$ is sufficiently large, then, except for at most $2$ points,
$S$ is contained in a circle $\mathcal{C}$ and the axis of symmetry
$\mathcal{L}$ of $\mathcal{C}$, and $r(x)$ equals the distance from $x$ to $C$
for each $x\in S\cap\mathcal{L}$. This, together with a new construction,
implies that $f_3(n)=n^2/4 + 5n/2 + O(1)$.
</p></div>
    </summary>
    <updated>2019-07-22T01:35:43Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-07-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.08399</id>
    <link href="http://arxiv.org/abs/1907.08399" rel="alternate" type="text/html"/>
    <title>Cluster deletion revisited</title>
    <feedworld_mtime>1563753600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tsur:Dekel.html">Dekel Tsur</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.08399">PDF</a><br/><b>Abstract: </b>In the Cluster Deletion problem the input is a graph $G$ and an integer $k$,
and the goal is to decide whether there is a set of at most $k$ edges whose
removal from $G$ results a graph in which every connected component is a
clique. In this paper we give an algorithm for Cluster Deletion whose running
time is $O^*(1.404^k)$.
</p></div>
    </summary>
    <updated>2019-07-22T01:25:09Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.08362</id>
    <link href="http://arxiv.org/abs/1907.08362" rel="alternate" type="text/html"/>
    <title>Sparse Recovery for Orthogonal Polynomial Transforms</title>
    <feedworld_mtime>1563753600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Anna Gilbert, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gu:Albert.html">Albert Gu</a>, Christopher Re, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rudra:Atri.html">Atri Rudra</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wootters:Mary.html">Mary Wootters</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.08362">PDF</a><br/><b>Abstract: </b>In this paper we consider the following sparse recovery problem. We have
query access to a vector $\vx \in \R^N$ such that $\vhx = \vF \vx$ is
$k$-sparse (or nearly $k$-sparse) for some orthogonal transform $\vF$. The goal
is to output an approximation (in an $\ell_2$ sense) to $\vhx$ in sublinear
time. This problem has been well-studied in the special case that $\vF$ is the
Discrete Fourier Transform (DFT), and a long line of work has resulted in
sparse Fast Fourier Transforms that run in time $O(k \cdot \mathrm{polylog}
N)$. However, for transforms $\vF$ other than the DFT (or closely related
transforms like the Discrete Cosine Transform), the question is much less
settled.
</p>
<p>In this paper we give sublinear-time algorithms---running in time $\poly(k
\log(N))$---for solving the sparse recovery problem for orthogonal transforms
$\vF$ that arise from orthogonal polynomials. More precisely, our algorithm
works for any $\vF$ that is an orthogonal polynomial transform derived from
Jacobi polynomials. The Jacobi polynomials are a large class of classical
orthogonal polynomials (and include Chebyshev and Legendre polynomials as
special cases), and show up extensively in applications like numerical analysis
and signal processing. One caveat of our work is that we require an assumption
on the sparsity structure of the sparse vector, although we note that vectors
with random support have this property with high probability.
</p>
<p>Our approach is to give a very general reduction from the $k$-sparse sparse
recovery problem to the $1$-sparse sparse recovery problem that holds for any
flat orthogonal polynomial transform; then we solve this one-sparse recovery
problem for transforms derived from Jacobi polynomials.
</p></div>
    </summary>
    <updated>2019-07-22T01:23:24Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.08355</id>
    <link href="http://arxiv.org/abs/1907.08355" rel="alternate" type="text/html"/>
    <title>3SUM with Preprocessing: Algorithms, Lower Bounds and Cryptographic Applications</title>
    <feedworld_mtime>1563753600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Golovnev:Alexander.html">Alexander Golovnev</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Guo:Siyao.html">Siyao Guo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Horel:Thibaut.html">Thibaut Horel</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Park:Sunoo.html">Sunoo Park</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vaikuntanathan:Vinod.html">Vinod Vaikuntanathan</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.08355">PDF</a><br/><b>Abstract: </b>Given a set of integers $\{a_1, \ldots, a_N\}$, the 3SUM problem requires
finding $a_i, a_j, a_k \in A$ such that $a_i + a_j = a_k$. A preprocessing
version of 3SUM, called 3SUM-Indexing, considers an initial offline phase where
a computationally unbounded algorithm receives $a_1,\ldots,a_N$ and produces a
data structure with $S$ words of $w$ bits each, followed by an online phase
where one is given the target $b$ and needs to find a pair $(i, j)$ such that
$a_i + a_j = b$ by probing only $T$ memory cells of the data structure. In this
paper, we study the 3SUM-Indexing problem and show the following.
</p>
<p>[New algorithms:] Goldstein et al. conjectured that there is no data
structure for 3SUM-Indexing with $S=N^{2-\varepsilon}$ and
$T=N^{1-\varepsilon}$ for any constant $\varepsilon&gt;0$. Our first contribution
is to disprove this conjecture by showing a suite of algorithms with $S^3 \cdot
T = \tilde{O}(N^6)$; for example, this achieves $S=\tilde{O}(N^{1.9})$ and
$T=\tilde{O}(N^{0.3})$.
</p>
<p>[New lower bounds:] Demaine and Vadhan in 2001 showed that every 1-query
algorithm for 3SUM-Indexing requires space $\tilde{\Omega}(N^2)$. Our second
result generalizes their bound to show that for every space-$S$ algorithm that
makes $T$ non-adaptive queries, $S = \tilde{\Omega}(N^{1+1/T})$. Any asymptotic
improvement to our result will result in a major breakthrough in static data
structure lower bounds.
</p>
<p>[New cryptographic applications:] A natural question in cryptography is
whether we can use a "backdoored" random oracle to build secure cryptography.
We provide a novel formulation of this problem, modeling a random oracle whose
truth table can be arbitrarily preprocessed by an unbounded adversary into an
exponentially large lookup table to which the online adversary has oracle
access. We construct one-way functions in this model assuming the hardness of a
natural average-case variant of 3SUM-Indexing.
</p></div>
    </summary>
    <updated>2019-07-22T01:20:39Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.08306</id>
    <link href="http://arxiv.org/abs/1907.08306" rel="alternate" type="text/html"/>
    <title>A Polynomial Time Algorithm for Log-Concave Maximum Likelihood via Locally Exponential Families</title>
    <feedworld_mtime>1563753600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Axelrod:Brian.html">Brian Axelrod</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Diakonikolas:Ilias.html">Ilias Diakonikolas</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sidiropoulos:Anastasios.html">Anastasios Sidiropoulos</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Stewart:Alistair.html">Alistair Stewart</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Valiant:Gregory.html">Gregory Valiant</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.08306">PDF</a><br/><b>Abstract: </b>We consider the problem of computing the maximum likelihood multivariate
log-concave distribution for a set of points. Specifically, we present an
algorithm which, given $n$ points in $\mathbb{R}^d$ and an accuracy parameter
$\epsilon&gt;0$, runs in time $poly(n,d,1/\epsilon),$ and returns a log-concave
distribution which, with high probability, has the property that the likelihood
of the $n$ points under the returned distribution is at most an additive
$\epsilon$ less than the maximum likelihood that could be achieved via any
log-concave distribution. This is the first computationally efficient
(polynomial time) algorithm for this fundamental and practically important
task. Our algorithm rests on a novel connection with exponential families: the
maximum likelihood log-concave distribution belongs to a class of structured
distributions which, while not an exponential family, "locally" possesses key
properties of exponential families. This connection then allows the problem of
computing the log-concave maximum likelihood distribution to be formulated as a
convex optimization problem, and solved via an approximate first-order method.
Efficiently approximating the (sub) gradients of the objective function of this
optimization problem is quite delicate, and is the main technical challenge in
this work.
</p></div>
    </summary>
    <updated>2019-07-22T01:27:12Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.08304</id>
    <link href="http://arxiv.org/abs/1907.08304" rel="alternate" type="text/html"/>
    <title>A Constant Factor Approximation for Capacitated Min-Max Tree Cover</title>
    <feedworld_mtime>1563753600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Das:Syamantak.html">Syamantak Das</a>, Lavina Jain, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kumar:Nikhil.html">Nikhil Kumar</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.08304">PDF</a><br/><b>Abstract: </b>Given a graph $G=(V,E)$ with non-negative real edge lengths and an integer
parameter $k$, the Min-Max k-Tree Cover problem seeks to find a set of at most
$k$ subtrees of $G$, such that the union of the trees is the vertex set $V$.
The objective is to minimize the maximum length among all the trees. We give
the first constant factor approximation for the hard uniform capacitated
version of this problem, where, an input parameter $\lambda$ upper bounds the
number of vertices that can be covered by any of the trees. Our result extends
to the rooted version of the problem, where we are given a set of $k$ root
vertices, $R$ and each of the covering trees is required to include a distinct
vertex in $R$ as the root. Prior to our work, the only result known was a
$(2k-1)$-approximation algorithm for the special case when the total number of
vertices in the graph is $k\lambda$ [Guttmann-Beck and Hassin, J. of
Algorithms, 1997].
</p>
<p>Our technique circumvents the difficulty of using the minimum spanning tree
of the graph as a lower bound, which is standard for the uncapacitated version
of the problem [Even et al., OR Letters 2004] [Khani et al., Algorithmica
2010}]. Instead, we use Steiner trees that cover $\lambda$ vertices along with
an iterative refinement procedure that ensures that the output trees have low
cost and the vertices are well distributed among the trees
</p></div>
    </summary>
    <updated>2019-07-22T01:26:59Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.08246</id>
    <link href="http://arxiv.org/abs/1907.08246" rel="alternate" type="text/html"/>
    <title>Finding First and Most-Beautiful Queens by Integer Programming</title>
    <feedworld_mtime>1563753600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fischetti:Matteo.html">Matteo Fischetti</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Salvagnin:Domenico.html">Domenico Salvagnin</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.08246">PDF</a><br/><b>Abstract: </b>The n-queens puzzle is a well-known combinatorial problem that requires to
place n queens on an n x n chessboard so that no two queens can attack each
other. Since the 19th century, this problem was studied by many mathematicians
and computer scientists. While finding any solution to the n-queens puzzle is
rather straightforward, it is very challenging to find the lexicographically
first (or smallest) feasible solution. Solutions for this type are known in the
literature for n &lt;= 55, while for some larger chessboards only partial
solutions are known. The present paper was motivated by the question of whether
Integer Linear Programming (ILP) can be used to compute solutions for some open
instances. We describe alternative ILP-based solution approaches, and show that
they are indeed able to compute (sometimes in unexpectedly-short computing
times) many new lexicographically optimal solutions for n ranging from 56 to
115. One of the proposed algorithms is a pure cutting plane method based on a
combinatorial variant of classical Gomory cuts. We also address an intriguing
"lexicographic bottleneck" (or min-max) variant of the problem that requires
finding a most beautiful (in a well defined sense) placement, and report its
solution for n up to 176.
</p></div>
    </summary>
    <updated>2019-07-22T01:25:47Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/095</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/095" rel="alternate" type="text/html"/>
    <title>TR19-095 |  Unambiguous Catalytic Computation | 

	Chetan Gupta, 

	Rahul Jain, 

	Vimal Raj Sharma, 

	Raghunath Tewari</title>
    <summary>The catalytic Turing machine is a model of computation defined by Buhrman, Cleve,
Kouck, Loff, and Speelman (STOC 2014). Compared to the classical space-bounded Turing
machine, this model has an extra space which is filled with arbitrary content in addition
to the clean space. In such a model we study if this additional filled space can be used to
increase the power of computation or not, with the condition that the initial content of this
extra filled space must be restored at the end of the computation.
In this paper, we define the notion of unambiguous catalytic Turing machine and prove
that under a standard derandomization assumption, the class of problems solved by an
unambiguous catalytic Turing machine is same as the class of problems solved by a general
nondeterministic catalytic Turing machine in the logspace setting.</summary>
    <updated>2019-07-21T11:21:02Z</updated>
    <published>2019-07-21T11:21:02Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-07-22T09:20:47Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.08185</id>
    <link href="http://arxiv.org/abs/1907.08185" rel="alternate" type="text/html"/>
    <title>Imperfect Gaps in Gap-ETH and PCPs</title>
    <feedworld_mtime>1563667200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bafna:Mitali.html">Mitali Bafna</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vyas:Nikhil.html">Nikhil Vyas</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.08185">PDF</a><br/><b>Abstract: </b>We study the role of perfect completeness in probabilistically checkable
proof systems (PCPs) and give a new way to transform a PCP with imperfect
completeness to a PCP with perfect completeness when the initial gap is a
constant. In particular, we show that $\text{PCP}_{c,s}[r,q] \subseteq
\text{PCP}_{1,1-\Omega(1)}[r+O(1),q+O(r)]$, for $c-s=\Omega(1)$. This implies
that one can convert imperfect completeness to perfect in linear-sized PCPs for
$NTIME[O(n)]$ with a $O(\log n)$ additive loss in the query complexity $q$. We
show our result by constructing a "robust circuit" using threshold gates. These
results are a gap amplification procedure for PCPs (when completeness is
imperfect), analogous to questions studied in parallel repetition and
pseudorandomness.
</p>
<p>We also investigate the time complexity of approximating perfectly
satisfiable instances of 3SAT versus those with imperfect completeness. We show
that the Gap-ETH conjecture without perfect completeness is equivalent to
Gap-ETH with perfect completeness, i.e. we show that Gap-3SAT, where the gap is
not around 1, has a subexponential algorithm, if and only if, Gap-3SAT with
perfect completeness has subexponential algorithms. We also relate the time
complexities of these two problems in a more fine-grained way, to show that
$T_2(n) \leq T_1(n(\log\log n)^{O(1)})$, where $T_1(n),T_2(n)$ denote the
randomized time-complexity of approximating MAX 3SAT with perfect and imperfect
completeness, respectively.
</p></div>
    </summary>
    <updated>2019-07-21T23:22:51Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-07-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.08142</id>
    <link href="http://arxiv.org/abs/1907.08142" rel="alternate" type="text/html"/>
    <title>Stack sorting with restricted stacks</title>
    <feedworld_mtime>1563667200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cerbai:Giulio.html">Giulio Cerbai</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Claesson:Anders.html">Anders Claesson</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Ferrari:Luca.html">Luca Ferrari</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.08142">PDF</a><br/><b>Abstract: </b>The (classical) problem of characterizing and enumerating permutations that
can be sorted using two stacks connected in series is still largely open. In
the present paper we address a related problem, in which we impose restrictions
both on the procedure and on the stacks. More precisely, we consider a greedy
algorithm where we perform the rightmost legal operation (here "rightmost"
refers to the usual representation of stack sorting problems). Moreover, the
first stack is required to be $\sigma$-avoiding, for some permutation $\sigma$,
meaning that, at each step, the elements maintained in the stack avoid the
pattern $\sigma$ when read from top to bottom. Since the set of permutations
which can be sorted by such a device (which we call $\sigma$-machine) is not
always a class, it would be interesting to understand when it happens. We will
prove that the set of $\sigma$-machines whose associated sortable permutations
are not a class is counted by Catalan numbers. Moreover, we will analyze two
specific $\sigma$-machines in full details (namely when $\sigma=321$ and
$\sigma=123$), providing for each of them a complete characterization and
enumeration of sortable permutations.
</p></div>
    </summary>
    <updated>2019-07-21T23:24:32Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.08121</id>
    <link href="http://arxiv.org/abs/1907.08121" rel="alternate" type="text/html"/>
    <title>On Arrangements of Orthogonal Circles</title>
    <feedworld_mtime>1563667200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chaplick:Steven.html">Steven Chaplick</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/F=ouml=rster:Henry.html">Henry Förster</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kryven:Myroslav.html">Myroslav Kryven</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wolff:Alexander.html">Alexander Wolff</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.08121">PDF</a><br/><b>Abstract: </b>In this paper, we study arrangements of orthogonal circles, that is,
arrangements of circles where every pair of circles must either be disjoint or
intersect at a right angle. Using geometric arguments, we show that such
arrangements have only a linear number of faces. This implies that orthogonal
circle intersection graphs have only a linear number of edges. When we restrict
ourselves to orthogonal unit circles, the resulting class of intersection
graphs is a subclass of penny graphs (that is, contact graphs of unit circles).
We show that, similarly to penny graphs, it is NP-hard to recognize orthogonal
unit circle intersection graphs.
</p></div>
    </summary>
    <updated>2019-07-21T23:28:30Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-07-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.08111</id>
    <link href="http://arxiv.org/abs/1907.08111" rel="alternate" type="text/html"/>
    <title>Makespan Minimization with OR-Precedence Constraints</title>
    <feedworld_mtime>1563667200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Happach:Felix.html">Felix Happach</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.08111">PDF</a><br/><b>Abstract: </b>We consider a variant of the NP-hard problem of assigning jobs to machines to
minimize the completion time of the last job. Usually, precedence constraints
are given by a partial order on the set of jobs, and each job requires all its
predecessors to be completed before it can start. In his seminal paper, Graham
(1966) presented a simple 2-approximation algorithm, and, more than 40 years
later, Svensson (2010) proved that 2 is essentially the best approximation
ratio one can hope for in general. In this paper, we consider a different type
of precedence relation that has not been discussed as extensively and is called
OR-precedence. In order for a job to start, we require that at least one of its
predecessors is completed - in contrast to all its predecessors. Additionally,
we assume that each job has a release date before which it must not start. We
prove that Graham's algorithm has an approximation guarantee of 2 also in this
setting, and present a polynomial-time algorithm that solves the problem to
optimality, if preemptions are allowed. The latter result is in contrast to
classical precedence constraints, for which Ullman (1975) showed that the
preemptive variant is already NP-hard. Our algorithm generalizes a result of
Johannes (2005) who gave a polynomial-time algorithm for unit processing time
jobs subject to OR-precedence constraints, but without release dates. The
performance guarantees presented here match the best-known ones for special
cases where classical precedence constraints and OR-precedence constraints
coincide.
</p></div>
    </summary>
    <updated>2019-07-21T23:24:28Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.08093</id>
    <link href="http://arxiv.org/abs/1907.08093" rel="alternate" type="text/html"/>
    <title>Metric Dimension Parameterized by Treewidth</title>
    <feedworld_mtime>1563667200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bonnet:=Eacute=douard.html">Édouard Bonnet</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Purohit:Nidhi.html">Nidhi Purohit</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.08093">PDF</a><br/><b>Abstract: </b>A resolving set $S$ of a graph $G$ is a subset of its vertices such that no
two vertices of $G$ have the same distance vector to $S$. The Metric Dimension
problem asks for a resolving set of minimum size, and in its decision form, a
resolving set of size at most some specified integer. This problem is
NP-complete, and remains so in very restricted classes of graphs. It is also
W[2]-complete with respect to the size of the solution. Metric Dimension has
proven elusive on graphs of bounded treewidth. On the algorithmic side, a
polytime algorithm is known for trees, and even for outerplanar graphs, but the
general case of treewidth at most two is open. On the complexity side, no
parameterized hardness is known. This has led several papers on the topic to
ask for the parameterized complexity of Metric Dimension with respect to
treewidth. We provide a first answer to the question.
</p>
<p>We show that Metric Dimension parameterized by the treewidth of the input
graph is W[1]-hard. More refinedly we prove that, unless the Exponential Time
Hypothesis fails, there is no algorithm solving Metric Dimension in time
$f(\text{pw})n^{o(\text{pw})}$ on $n$-vertex graphs of constant degree, with
$\text{pw}$ the pathwidth of the input graph, and $f$ any computable function.
This is in stark contrast with an FPT algorithm of Belmonte et al. [SIAM J.
Discrete Math. '17] with respect to the combined parameter $\text{tl}+\Delta$,
where $\text{tl}$ is the tree-length and $\Delta$ the maximum-degree of the
input graph.
</p></div>
    </summary>
    <updated>2019-07-21T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.08024</id>
    <link href="http://arxiv.org/abs/1907.08024" rel="alternate" type="text/html"/>
    <title>Counting single-qubit Clifford equivalent graph states is #P-Complete</title>
    <feedworld_mtime>1563667200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dahlberg:Axel.html">Axel Dahlberg</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Helsen:Jonas.html">Jonas Helsen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wehner:Stephanie.html">Stephanie Wehner</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.08024">PDF</a><br/><b>Abstract: </b>Graph states, which include for example Bell states, GHZ states and cluster
states, form a well-known class of quantum states with applications ranging
from quantum networks to error-correction. Deciding whether two graph states
are equivalent up to single-qubit Clifford operations is known to be decidable
in polynomial time and have been studied both in the context of producing
certain required states in a quantum network but also in relation to stabilizer
codes. The reason for the latter this is that single-qubit Clifford equivalent
graph states exactly corresponds to equivalent stabilizer codes. We here
consider the computational complexity of, given a graph state |G&gt;, counting the
number of graph states, single-qubit Clifford equivalent to |G&gt;. We show that
this problem is #P-Complete. To prove our main result we make use of the notion
of isotropic systems in graph theory. We review the definition of isotropic
systems and point out their strong relation to graph states. We believe that
these isotropic systems can be useful beyond the results presented in this
paper.
</p></div>
    </summary>
    <updated>2019-07-21T23:20:48Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-07-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.08019</id>
    <link href="http://arxiv.org/abs/1907.08019" rel="alternate" type="text/html"/>
    <title>Transforming graph states to Bell-pairs is NP-Complete</title>
    <feedworld_mtime>1563667200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dahlberg:Axel.html">Axel Dahlberg</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Helsen:Jonas.html">Jonas Helsen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wehner:Stephanie.html">Stephanie Wehner</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.08019">PDF</a><br/><b>Abstract: </b>Critical to the construction of large scale quantum networks, i.e. a quantum
internet, is the development of fast algorithms for managing entanglement
present in the network. One fundamental building block for a quantum internet
is the distribution of Bell pairs between distant nodes in the network. Here we
focus on the problem of transforming multipartite entangled states into the
tensor product of bipartite Bell pairs between specific nodes using only a
certain class of local operations and classical communication. In particular we
study the problem of deciding whether a given graph state, and in general a
stabilizer state, can be transformed into a set of Bell pairs on specific
vertices using only single-qubit Clifford operations, single-qubit Pauli
measurements and classical communication. We prove that this problem is
NP-Complete.
</p></div>
    </summary>
    <updated>2019-07-21T23:23:06Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-07-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.07982</id>
    <link href="http://arxiv.org/abs/1907.07982" rel="alternate" type="text/html"/>
    <title>Sensitive Distance and Reachability Oracles for Large Batch Updates</title>
    <feedworld_mtime>1563667200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Brand:Jan_van_den.html">Jan van den Brand</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Saranurak:Thatchaphol.html">Thatchaphol Saranurak</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.07982">PDF</a><br/><b>Abstract: </b>In the sensitive distance oracle problem, there are three phases. We first
preprocess a given directed graph $G$ with $n$ nodes and integer weights from
$[-W,W]$. Second, given a single batch of $f$ edge insertions and deletions, we
update the data structure. Third, given a query pair of nodes $(u,v)$, return
the distance from $u$ to $v$. In the easier problem called sensitive
reachability oracle problem, we only ask if there exists a directed path from
$u$ to $v$.
</p>
<p>Our first result is a sensitive distance oracle with
$\tilde{O}(Wn^{\omega+(3-\omega)\mu})$ preprocessing time,
$\tilde{O}(Wn^{2-\mu}f^{2}+Wnf^{\omega})$ update time, and
$\tilde{O}(Wn^{2-\mu}f+Wnf^{2})$ query time where the parameter $\mu\in[0,1]$
can be chosen. The data-structure requires $O(Wn^{2+\mu} \log n)$ bits of
memory. This is the first algorithm that can handle $f\ge\log n$ updates.
Previous results (e.g. [Demetrescu et al. SICOMP'08; Bernstein and Karger
SODA'08 and FOCS'09; Duan and Pettie SODA'09; Grandoni and Williams FOCS'12])
can handle at most 2 updates. When $3\le f\le\log n$, the only non-trivial
algorithm was by [Weimann and Yuster FOCS'10]. When $W=\tilde{O}(1)$, our
algorithm simultaneously improves their preprocessing time, update time, and
query time. In particular, when $f=\omega(1)$, their update and query time is
$\Omega(n^{2-o(1)})$, while our update and query time are truly subquadratic in
$n$, i.e., ours is faster by a polynomial factor of $n$. To highlight the
technique, ours is the first graph algorithm that exploits the kernel basis
decomposition of polynomial matrices by [Jeannerod and Villard J.Comp'05; Zhou,
Labahn and Storjohann J.Comp'15] developed in the symbolic computation
community.
</p>
<p>[...]
</p></div>
    </summary>
    <updated>2019-07-21T23:25:06Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.07969</id>
    <link href="http://arxiv.org/abs/1907.07969" rel="alternate" type="text/html"/>
    <title>On the $\text{AC}^0[\oplus]$ complexity of Andreev's Problem</title>
    <feedworld_mtime>1563667200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Potukuchi:Aditya.html">Aditya Potukuchi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.07969">PDF</a><br/><b>Abstract: </b>Andreev's Problem states the following: Given an integer $d$ and a subset of
$S \subseteq \mathbb{F}_q \times \mathbb{F}_q$, is there a polynomial $y =
p(x)$ of degree at most $d$ such that for every $a \in \mathbb{F}_q$, $(a,p(a))
\in S$? We show an $\text{AC}^0[\oplus]$ lower bound for this problem.
</p>
<p>This problem appears to be similar to the list recovery problem for degree
$d$-Reed-Solomon codes over $\mathbb{F}_q$ which states the following: Given
subsets $A_1,\ldots,A_q$ of $\mathbb{F}_q$, output all (if any) the
Reed-Solomon codewords contained in $A_1\times \cdots \times A_q$. For our
purpose, we study this problem when $A_1, \ldots, A_q$ are random subsets of a
given size, which may be of independent interest.
</p></div>
    </summary>
    <updated>2019-07-21T23:23:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-07-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.07922</id>
    <link href="http://arxiv.org/abs/1907.07922" rel="alternate" type="text/html"/>
    <title>Approximate counting CSP seen from the other side</title>
    <feedworld_mtime>1563667200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bulatov:Andrei_A=.html">Andrei A. Bulatov</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zivny:Stanislav.html">Stanislav Zivny</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.07922">PDF</a><br/><b>Abstract: </b>In this paper we study the complexity of counting Constraint Satisfaction
Problems (CSPs) of the form #CSP($\mathcal{C}$,-), in which the goal is, given
a relational structure $\mathbf{A}$ from a class $\mathcal{C}$ of structures
and an arbitrary structure $\mathbf{B}$, to find the number of homomorphisms
from $\mathbf{A}$ to $\mathbf{B}$. Flum and Grohe showed that
#CSP($\mathcal{C}$,-) is solvable in polynomial time if $\mathcal{C}$ has
bounded treewidth [FOCS'02]. Building on the work of Grohe [JACM'07] on
decision CSPs, Dalmau and Jonsson then showed that, if $\mathcal{C}$ is a
recursively enumerable class of relational structures of bounded arity, then
assuming FPT $\neq$ #W[1], there are no other cases of #CSP($\mathcal{C}$,-)
solvable exactly in polynomial time (or even fixed-parameter time) [TCS'04].
</p>
<p>We show that, assuming FPT $\neq$ W[1] (under randomised parametrised
reductions) and for $\mathcal{C}$ satisfying certain general conditions,
#CSP($\mathcal{C}$,-) is not solvable even approximately for $\mathcal{C}$ of
unbounded treewidth; that is, there is no fixed parameter tractable (and thus
also not fully polynomial) randomised approximation scheme for
#CSP($\mathcal{C}$,-). In particular, our condition generalises the case when
$\mathcal{C}$ is closed under taking minors.
</p></div>
    </summary>
    <updated>2019-07-21T23:21:09Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-07-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.07910</id>
    <link href="http://arxiv.org/abs/1907.07910" rel="alternate" type="text/html"/>
    <title>On the m-eternal Domination Number of Cactus Graphs</title>
    <feedworld_mtime>1563667200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Václav Blažej, Jan Matyáš Křišťan, Tomáš Valla <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.07910">PDF</a><br/><b>Abstract: </b>Given a graph $G$, guards are placed on vertices of $G$. Then vertices are
subject to an infinite sequence of attacks so that each attack must be defended
by a guard moving from a neighboring vertex. The m-eternal domination number is
the minimum number of guards such that the graph can be defended indefinitely.
In this paper we study the m-eternal domination number of cactus graphs, that
is, connected graphs where each edge lies in at most two cycles, and we
consider three variants of the m-eternal domination number: first variant
allows multiple guards to occupy a single vertex, second variant does not allow
it, and in the third variant additional "eviction" attacks must be defended. We
provide a new upper bound for the m-eternal domination number of cactus graphs,
and for a subclass of cactus graphs called Christmas cactus graphs, where each
vertex lies in at most two cycles, we prove that these three numbers are equal.
Moreover, we present a linear-time algorithm for computing them.
</p></div>
    </summary>
    <updated>2019-07-21T23:23:55Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.07889</id>
    <link href="http://arxiv.org/abs/1907.07889" rel="alternate" type="text/html"/>
    <title>Fast permutation-word multiplication and the simultaneous conjugacy problem</title>
    <feedworld_mtime>1563667200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Brodnik:Andrej.html">Andrej Brodnik</a>, Aleksander Malnič, Rok Požar <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.07889">PDF</a><br/><b>Abstract: </b>Given a finite sequence $a_1, a_2,\ldots, a_d$ of $d$ permutations in the
symmetric group $S_n$, and a permutation word $k_1k_2\cdots k_{m}$ over the
alphabet $\{1,2,\ldots, d\}$, computation of the product $a_{k_1}a_{k_2}\cdots
a_{k_{m}}$ in a straightforward manner takes $O(n m)$ time. However, it appears
that this multiplication is such an elementary operation that, surprisingly
enough, it went on unquestioned. We show that the above product can be computed
in time $O(\min{\{ n m, n m \log d / \log m\}})$ using $O(m + n m^{\epsilon})$
space, where $0 &lt; \epsilon &lt; 1$. Consequently, this computation takes $o(n m)$
time whenever $\log d = o(\log m)$, which is a reasonable assumption in
practice.
</p>
<p>The above result is used to solve the transitive simultaneous conjugacy
problem in $O(n^2 \log d / \log n + dn\log n)$ time and $O(n^{1+ \epsilon} +
dn)$ space, where $0 &lt; \epsilon &lt;1$. This problem asks whether there exists a
permutation $\tau \in S_n$ such that $b_j = \tau^{-1} a_j \tau$ holds for all
$j = 1,2, \ldots, d$, where $a_1, a_2, \ldots, a_d$ and $b_1, b_2, \ldots, b_d$
are given sequences of $d$ permutations in $S_n$, each of which generates a
transitive subgroup of $S_n$. As from mid 70' it has been know that the problem
can be solved in $O(dn^2)$ time. An algorithm with running time $O(dn
\log(dn))$, proposed in late 80', does not work correctly on all input data.
</p></div>
    </summary>
    <updated>2019-07-21T23:25:19Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.07885</id>
    <link href="http://arxiv.org/abs/1907.07885" rel="alternate" type="text/html"/>
    <title>Formal verification of trading in financial markets</title>
    <feedworld_mtime>1563667200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sarswat:Suneel.html">Suneel Sarswat</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Singh:Abhishek_Kr.html">Abhishek Kr Singh</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.07885">PDF</a><br/><b>Abstract: </b>We introduce a formal framework for analyzing trades in financial markets. An
exchange is where multiple buyers and sellers participate to trade. These days,
all big exchanges use computer algorithms that implement double sided auctions
to match buy and sell requests and these algorithms must abide by certain
regulatory guidelines. For example, market regulators enforce that a matching
produced by exchanges should be \emph{fair}, \emph{uniform} and
\emph{individual rational}. To verify these properties of trades, we first
formally define these notions in a theorem prover and then give formal proofs
of relevant results on matchings. Finally, we use this framework to verify
properties of two important classes of double sided auctions. All the
definitions and results presented in this paper are completely formalised in
the Coq proof assistant without adding any additional axioms to it.
</p></div>
    </summary>
    <updated>2019-07-21T23:25:34Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.07833</id>
    <link href="http://arxiv.org/abs/1907.07833" rel="alternate" type="text/html"/>
    <title>Approximating Constraint Satisfaction Problems on High-Dimensional Expanders</title>
    <feedworld_mtime>1563667200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Alev:Vedat_Levi.html">Vedat Levi Alev</a>, Fernando Granha Jeronimo, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tulsiani:Madhur.html">Madhur Tulsiani</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.07833">PDF</a><br/><b>Abstract: </b>We consider the problem of approximately solving constraint satisfaction
problems with arity $k &gt; 2$ ($k$-CSPs) on instances satisfying certain
expansion properties, when viewed as hypergraphs. Random instances of $k$-CSPs,
which are also highly expanding, are well-known to be hard to approximate using
known algorithmic techniques (and are widely believed to be hard to approximate
in polynomial time). However, we show that this is not necessarily the case for
instances where the hypergraph is a high-dimensional expander.
</p>
<p>We consider the spectral definition of high-dimensional expansion used by
Dinur and Kaufman [FOCS 2017] to construct certain primitives related to PCPs.
They measure the expansion in terms of a parameter $\gamma$ which is the
analogue of the second singular value for expanding graphs. Extending the
results by Barak, Raghavendra and Steurer [FOCS 2011] for 2-CSPs, we show that
if an instance of MAX k-CSP over alphabet $[q]$ is a high-dimensional expander
with parameter $\gamma$, then it is possible to approximate the maximum
fraction of satisfiable constraints up to an additive error $\epsilon$ using
$q^{O(k)} \cdot (k/\epsilon)^{O(1)}$ levels of the sum-of-squares SDP
hierarchy, provided $\gamma \leq \epsilon^{O(1)} \cdot (1/(kq))^{O(k)}$.
</p>
<p>Based on our analysis, we also suggest a notion of threshold-rank for
hypergraphs, which can be used to extend the results for approximating 2-CSPs
on low threshold-rank graphs. We show that if an instance of MAX k-CSP has
threshold rank $r$ for a threshold $\tau = (\epsilon/k)^{O(1)} \cdot
(1/q)^{O(k)}$, then it is possible to approximately solve the instance up to
additive error $\epsilon$, using $r \cdot q^{O(k)} \cdot (k/\epsilon)^{O(1)}$
levels of the sum-of-squares hierarchy. As in the case of graphs,
high-dimensional expanders (with sufficiently small $\gamma$) have threshold
rank 1 according to our definition.
</p></div>
    </summary>
    <updated>2019-07-21T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.07796</id>
    <link href="http://arxiv.org/abs/1907.07796" rel="alternate" type="text/html"/>
    <title>An Ongoing Project to Improve the Rectilinear and the Pseudolinear Crossing Constants</title>
    <feedworld_mtime>1563667200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Aichholzer:Oswin.html">Oswin Aichholzer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Duque:Frank.html">Frank Duque</a>, Ruy Fabila-Monroy, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hidalgo=Toscano:Carlos.html">Carlos Hidalgo-Toscano</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Garc=iacute=a=Quintero:Oscar_E=.html">Oscar E. García-Quintero</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.07796">PDF</a><br/><b>Abstract: </b>A drawing of a graph in the plane is {\it pseudolinear} if the edges of the
drawing can be extended to doubly-infinite curves that form an arrangement of
pseudolines, that is, any pair of edges crosses precisely once. A special case
are {\it rectilinear} drawings where the edges of the graph are drawn as
straight line segments. The rectilinear (pseudolinear) crossing number of a
graph is the minimum number of pairs of edges of the graph that cross in any of
its rectilinear (pseudolinear) drawings. In this paper we describe an ongoing
project to continuously obtain better asymptotic upper bounds on the
rectilinear and pseudolinear crossing number of the complete graph $K_n$.
</p></div>
    </summary>
    <updated>2019-07-21T23:30:49Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-07-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.07795</id>
    <link href="http://arxiv.org/abs/1907.07795" rel="alternate" type="text/html"/>
    <title>Efficient computation of the Jacobi symbol</title>
    <feedworld_mtime>1563667200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/M=ouml=ller:Niels.html">Niels Möller</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.07795">PDF</a><br/><b>Abstract: </b>The family of left-to-right GCD algorithms reduces input numbers by
repeatedly subtracting the smaller number, or multiple of the smaller number,
from the larger number. This paper describes how to extend any such algorithm
to compute the Jacobi symbol, using a single table lookup per reduction. For
both quadratic time GCD algorithms (Euclid, Lehmer) and subquadratic algorithms
(Knuth, Sch\"onhage, M\"oller), the additional cost is linear, roughly one
table lookup per quotient in the quotient sequence. This method was used for
the 2010 rewrite of the Jacobi symbol computation in GMP.
</p></div>
    </summary>
    <updated>2019-07-21T23:26:11Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.07783</id>
    <link href="http://arxiv.org/abs/1907.07783" rel="alternate" type="text/html"/>
    <title>Patient-specific Conditional Joint Models of Shape, Image Features and Clinical Indicators</title>
    <feedworld_mtime>1563667200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Egger:Bernhard.html">Bernhard Egger</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schirmer:Markus_D=.html">Markus D. Schirmer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dubost:Florian.html">Florian Dubost</a>, Marco J. Nardin, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rost:Natalia_S=.html">Natalia S. Rost</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Golland:Polina.html">Polina Golland</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.07783">PDF</a><br/><b>Abstract: </b>We propose and demonstrate a joint model of anatomical shapes, image features
and clinical indicators for statistical shape modeling and medical image
analysis. The key idea is to employ a copula model to separate the joint
dependency structure from the marginal distributions of variables of interest.
This separation provides flexibility on the assumptions made during the
modeling process. The proposed method can handle binary, discrete, ordinal and
continuous variables. We demonstrate a simple and efficient way to include
binary, discrete and ordinal variables into the modeling. We build Bayesian
conditional models based on observed partial clinical indicators, features or
shape based on Gaussian processes capturing the dependency structure. We apply
the proposed method on a stroke dataset to jointly model the shape of the
lateral ventricles, the spatial distribution of the white matter hyperintensity
associated with periventricular white matter disease, and clinical indicators.
The proposed method yields interpretable joint models for data exploration and
patient-specific statistical shape models for medical image analysis.
</p></div>
    </summary>
    <updated>2019-07-21T23:26:22Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-07-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=17574</id>
    <link href="https://gilkalai.wordpress.com/2019/07/20/isabella-novik-and-hailun-zheng-neighborly-centrally-symmetric-spheres-exist-in-all-dimensions/" rel="alternate" type="text/html"/>
    <title>Isabella Novik and Hailun Zheng: Neighborly centrally symmetric spheres exist in all dimensions!</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">A twit long summary: The cyclic polytope is wonderful and whenever we construct an analogous object we are happy. Examples: Neighborly cubic polytopes; The amplituhedron; and as of last week, the Novik-Zheng new construction of neighborly centrally symmetric spheres! At … <a href="https://gilkalai.wordpress.com/2019/07/20/isabella-novik-and-hailun-zheng-neighborly-centrally-symmetric-spheres-exist-in-all-dimensions/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><span style="color: #0000ff;">A twit long summary: The cyclic polytope is wonderful and whenever we construct an analogous object we are happy. Examples: Neighborly cubic polytopes; The amplituhedron; and as of last week, the Novik-Zheng new construction of neighborly centrally symmetric spheres!</span></p>
<h2>At last: Neighborly CS spheres!</h2>
<p>The news: Isabella Novik and Hailun Zheng’ paper  <a href="https://arxiv.org/abs/1907.06115">Highly neighborly centrally symmetric spheres</a>, resolves an old standing problem in this field.</p>
<p>Here is the abstract:</p>
<blockquote><p>In 1995, Jockusch constructed an infinite family of centrally symmetric 3-dimensional simplicial spheres that are cs-<em>2</em>-neighborly. Here we generalize his construction and show that for all d ≥ 4 and n ≥ d, there exists a centrally symmetric (d − 1)-dimensional simplicial sphere with <em>2n</em> vertices that is cs-[d/2]-neighborly. This result combined with work of Adin and Stanley completely resolves the upper bound problem for centrally symmetric simplicial spheres.</p></blockquote>
<p>Congratulations to Isabella and Hailun!</p>
<h2>Some background to the Novik and Zheng breakthrough</h2>
<p><strong>Centrally symmetric bodies:</strong> A centrally symmetric (cs) polytope convex body in <img alt="\mathbb R^d" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb R^d"/> satisfies <img alt="x \in P" class="latex" src="https://s0.wp.com/latex.php?latex=x+%5Cin+P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x \in P"/> implies <img alt="-x \in P" class="latex" src="https://s0.wp.com/latex.php?latex=-x+%5Cin+P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="-x \in P"/>. Centrally symmetric bodies are the unit balls of normed spaces.</p>
<p><strong>Centrally symmetric simplicial spheres:</strong> A triangulation <img alt="K" class="latex" src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K"/> of a  <img alt="(d-1)" class="latex" src="https://s0.wp.com/latex.php?latex=%28d-1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(d-1)"/>-dimensional sphere with a set <img alt="V" class="latex" src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="V"/> of vertices is centrally symmetric if there is an involution <img alt="\phi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cphi&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\phi"/> on <img alt="V" class="latex" src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="V"/> that <img alt="\phi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cphi&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\phi"/> maps a face of <img alt="K" class="latex" src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K"/> to a face of <img alt="K" class="latex" src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K"/> and for every vertex <img alt="v" class="latex" src="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="v"/>, <img alt="\phi(v) \ne v" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cphi%28v%29+%5Cne+v&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\phi(v) \ne v"/> and <img alt="\{v , \phi (v)\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7Bv+%2C+%5Cphi+%28v%29%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{v , \phi (v)\}"/> is not an edge of <img alt="K" class="latex" src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K"/>.  The boundary complex of a cs <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/>-polytopes is a cs triangulation of <img alt="S^{d-1}" class="latex" src="https://s0.wp.com/latex.php?latex=S%5E%7Bd-1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S^{d-1}"/>.</p>
<p><strong>Neighborliness.</strong> A simplicial complex <img alt="K" class="latex" src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K"/>  is <img alt="m" class="latex" src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m"/>-neighborly of every set of <img alt="m" class="latex" src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m"/> vertices of <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> form a face.  (The definition was first considered  for simplicial <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/>-polytopes <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/>.) The cyclic <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/>-polytope with <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> vertices is <img alt="[d/2]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Bd%2F2%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="[d/2]"/>-neighborly. (The only (<img alt="[d/2]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Bd%2F2%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="[d/2]"/>+1)-neighborly simplicial <img alt="(d-1)" class="latex" src="https://s0.wp.com/latex.php?latex=%28d-1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(d-1)"/>-sphere is the simplex. There are many other <img alt="[d/2]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Bd%2F2%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="[d/2]"/>-neighborly simplicial $d$-polytopes and <img alt="(d-1)" class="latex" src="https://s0.wp.com/latex.php?latex=%28d-1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(d-1)"/>-spheres.</p>
<p><strong>cs-Neighborliness. </strong>Let <img alt="K" class="latex" src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K"/> be a simplicial complex with an involution <img alt="\phi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cphi&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\phi"/> on its vertices which acts on <img alt="K" class="latex" src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K"/> (maps faces to faces) and has the property that <img alt="\phi(v)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cphi%28v%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\phi(v)"/> is not adjacent to <img alt="v" class="latex" src="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="v"/> (and <img alt="\phi (v) \ne v" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cphi+%28v%29+%5Cne+v&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\phi (v) \ne v"/>). We will call <img alt="v" class="latex" src="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="v"/> and <img alt="\phi (v)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cphi+%28v%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\phi (v)"/> <strong>antipodal</strong>. <img alt="K" class="latex" src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K"/> is cs-<img alt="m" class="latex" src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m"/>-neighborly if every set of <img alt="m" class="latex" src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m"/> vertices that contains no pair of antipodal vertices is a face of <img alt="K" class="latex" src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K"/>. The only cs-<img alt="m" class="latex" src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m"/>-neighborly simplicial sphere is the boundary complex of the cross polytope.</p>
<p><strong>The existence of cs-<img alt="[d/2]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Bd%2F2%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="[d/2]"/>-neighborly spheres. </strong>It was an important open question to understand if cs <img alt="[d/2]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Bd%2F2%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="[d/2]"/>-neighborly simplicial spheres exist. (The only cs-<img alt="([d/2]+1)" class="latex" src="https://s0.wp.com/latex.php?latex=%28%5Bd%2F2%5D%2B1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="([d/2]+1)"/>-neighborly spheres is the boundary complex of the cross polytope.)  The first example (whoch is not a cross polytope) was given by Grunbaum in 1969 in his paper “The importance of being straight(?).” In 1995  Jockusch constructed an infinite family cs-2-neighborly centrally symmetric 3-dimensional simplicial spheres. This problem has now been solved by Novik and Zheng.</p>
<p><strong>Neighborly centrally symmetric polytopes.  </strong>In the 1960s Grünbaum noted the big difference between neighborly centrally symmetric spheres and centrally symmetric polytopes. He proved (This is Theorem 4.1 in his book “Convex polytopes”) that no cs-2-neighborly 4 polytope with 12 vertices exists.  This is an example of the important themes of “streightening” or “linearizing” combimatorial objects and  of extending theorems from the “streight” or “linear” case to more general combinatorial settings.)</p>
<p>This result by Grünbaum was extended in various directions. Let me mention two major results in the field:</p>
<p><strong>Theorem</strong> McMullen and Shephard (1968): A cs <em>d</em>-dimensional polytope with <em>2(d + 2)</em> vertices cannot be more than cs-<em>⌊(d + 1)/3⌋</em>-neighborly.</p>
<p><strong>Theorem</strong> <a href="https://arxiv.org/abs/math/0507280">Linial and Novik (2006):</a> A cs-2-neighborly <em>d</em>-dimensional polytope has at most  <img alt="2^d" class="latex" src="https://s0.wp.com/latex.php?latex=2%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^d"/>;</p>
<p>Novik (2017) <a href="https://arxiv.org/abs/1712.09489">constructed</a>  cs-2-neighborly d polytopes with <img alt="2^{d-1}+1" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7Bd-1%7D%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{d-1}+1"/> vertices. She used a 2017 <a href="https://arxiv.org/abs/1709.03411">breakthrough construction</a> by Gerencsér–Harang of an acute set of size <img alt="2^{d-1}+1" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7Bd-1%7D%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{d-1}+1"/> in <img alt="\mathbb R^d" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb R^d"/>. (A set <em>S</em> is <em>acute</em> if every three points from <em>S </em>determine an acute triangle.)</p>
<p><strong>Face numbers of centrally-symmetric polytopes and spheres. </strong>As the abstract asserts the new construction is related to questions about face numbers of centrally symmetric polytopes, spheres and other cellular objects. In fact, this was the next item in our planned posts on algebraic combinatorics of cellular objects. (The first and only post so far<a href="https://gilkalai.wordpress.com/2018/06/20/beyond-the-g-conjecture-algebraic-combinatorics-of-cellular-spaces-i/"> is here</a>.) Here is a recent survey by Isabella Novik  <a href="https://arxiv.org/abs/1711.09310">A tale on centrally symmetric  polytopes and spheres</a>.</p>
<p><strong>Upper bound theorems.</strong> Neighborly polytopes and spheres are the equality cases of the upper bound theorem (proved by McMullen for polytopes and by Stanley for spheres). A version of the upper bound inequality for centrally symmetric spheres was proved by Adin and Stanley and the new construction shows that the Adin-Stanley inequality is tight. For more on the upper bound theorem and neighborliness see Section 2 of my 2000 survey  <a href="http://www.ma.huji.ac.il/~kalai/VIS.pdf">Combinatorics with geometric flavor. </a> See also the post <a href="https://gilkalai.wordpress.com/2009/04/04/how-the-g-conjecture-came-about/">How the g-conjecture came about</a> and  and the post <a href="https://gilkalai.wordpress.com/2013/09/10/how-the-proof-of-the-upper-bound-theorem-for-spheres-was-found/" rel="bookmark">Richard Stanley: How the Proof of the Upper Bound Theorem (for spheres) was Found.</a></p>
<p> </p>
<p> </p></div>
    </content>
    <updated>2019-07-20T18:33:03Z</updated>
    <published>2019-07-20T18:33:03Z</published>
    <category term="Combinatorics"/>
    <category term="Convexity"/>
    <category term="Hailun Zheng"/>
    <category term="Isabella Novik"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-07-22T09:20:55Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4267</id>
    <link href="https://www.scottaaronson.com/blog/?p=4267" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4267#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4267" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Fake it till you make it (to the moon)</title>
    <summary xml:lang="en-US">While I wait to board a flight at my favorite location on earth—Philadelphia International Airport—I figured I might as well blog something to mark the 50th anniversary of Apollo 11. (Thanks also to Joshua Zelinsky for a Facebook post that inspired this.) I wasn’t alive for Apollo, but I’ve been alive for 3/4 of the […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>While I wait to board a flight at my favorite location on earth—Philadelphia International Airport—I figured I might as well blog something to mark the 50<sup>th</sup> anniversary of Apollo 11.  (Thanks also to Joshua Zelinsky for a Facebook post that inspired this.)</p>



<p>I wasn’t alive for Apollo, but I’ve been alive for 3/4 of the time <em>after</em> it, even though it now seems like ancient history—specifically, like a Roman cathedral being gawked at by a medieval peasant, like an achievement by some vanished, more cohesive civilization that we can’t even replicate today, let alone surpass.</p>



<p>Which brings me to a depressing mystery: why do so many people now deny that humans walked on the moon at all?  Like, why <em>that</em> specifically?  While they’re at it, why don’t they also deny that WWII happened, or that the Beatles existed?</p>



<p>Surprisingly, skepticism of the reality of Apollo seems to have gone all the way back to the landings themselves.  One of my favorite stories growing up was of my mom, as a teenager, working as a waitress at an Israeli restaurant in Philadelphia, on the night of Apollo 11 landing.  My mom asked for a few minutes off to listen to news of the landing on the radio.  The owners wouldn’t grant it—explaining that it was all Hollywood anyway, just some actors in spacesuits on a sound stage, and obviously my mom wasn’t so naïve as to think anyone was <em>actually</em> walking to the moon?</p>



<p>Alas, as we get further and further from the event, with no serious prospect of ever replicating it past the stage of announcing an optimistic timetable (nor, to be honest, any scientific <em>reason</em> to replicate it), as the people involved die off, and as our civilization becomes ever more awash in social-media-fueled paranoid conspiracies, I fear that moon-landing denalism will become more common.</p>



<p>Because here’s the thing: Apollo could happen, but <em>only</em> because of a wildly improbable, once-in-history confluence of social and geopolitical factors.  It was economically insane, taking 100,000 people and 4% of the US federal budget for some photo-ops, a flag-planting, some data and returned moon rocks that had genuine scientific value but could’ve been provided much more cheaply by robots.  It was dismantled immediately afterwards like a used movie set, rather than leading to any greater successes. Indeed, manned spaceflight severely <em>regressed</em> afterwards, surely mocking the expectations of every last science fiction fan and techno-utopian who was alive at that time.</p>



<p>One could summarize the situation by saying that, in certain respects, the Apollo program really <strong>was</strong> “faked.”  It’s just that the way they “faked” it, involved actually landing people on the moon!</p></div>
    </content>
    <updated>2019-07-19T21:40:43Z</updated>
    <published>2019-07-19T21:40:43Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Nerd Interest"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Procrastination"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2019-07-19T23:00:05Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://blogs.princeton.edu/imabandit/?p=1397</id>
    <link href="https://blogs.princeton.edu/imabandit/2019/07/17/guest-post-by-julien-mairal-a-kernel-point-of-view-on-convolutional-neural-networks-part-ii/" rel="alternate" type="text/html"/>
    <title>Guest post by Julien Mairal: A Kernel Point of View on Convolutional Neural Networks, part II</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>This is a continuation of Julien Mairal‘s guest post on CNNs, see part I here. Stability to deformations of convolutional neural networks In their ICML paper Zhang et al. introduce a functional space for CNNs with one layer, by noticing … <a href="https://blogs.princeton.edu/imabandit/2019/07/17/guest-post-by-julien-mairal-a-kernel-point-of-view-on-convolutional-neural-networks-part-ii/">Continue reading <span class="meta-nav">→</span></a></p></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a class="liimagelink" href="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/uploads/sites/122/2019/07/Mairal2.jpg?ssl=1"><img alt="" class="alignnone wp-image-1399" height="324" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/uploads/sites/122/2019/07/Mairal2.jpg?resize=639%2C324&amp;ssl=1" width="639"/></a></p>
<p>This is a continuation of <a class="liinternal" href="https://lear.inrialpes.fr/people/mairal/">Julien Mairal</a>‘s guest post on CNNs, see <a class="liinternal" href="https://blogs.princeton.edu/imabandit/2019/07/10/guest-post-by-julien-mairal-a-kernel-point-of-view-on-convolutional-neural-networks-part-i/">part I here.</a></p>
<p><strong>Stability to deformations of convolutional neural networks</strong></p>
<p>In their <a class="lipdf" href="http://proceedings.mlr.press/v70/zhang17f/zhang17f.pdf">ICML paper</a> Zhang et al. introduce a functional space for CNNs with one layer, by noticing that for some dot-product kernels, smoothed variants of rectified linear unit activation functions (ReLU) live in the corresponding RKHS, see also <a class="lipdf" href="http://proceedings.mlr.press/v48/zhangd16.pdf">this paper</a> and <a class="lipdf" href="https://www.cs.cornell.edu/~sridharan/sicomp.pdf">that one</a>. By following a similar reasoning with multiple layers, it is then possible to show that the functional space described in <a class="liinternal" href="https://blogs.princeton.edu/imabandit/2019/07/10/guest-post-by-julien-mairal-a-kernel-point-of-view-on-convolutional-neural-networks-part-i/">part I</a> <img alt="\{ f_w: x \mapsto \langle w , \Phi_n(x_0) \rangle; w \in L^2(\Omega,\mathcal{H}_n) \}" class="ql-img-inline-formula " height="20" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-3e321e5f0406c9879f25b6b1d69a5fc3_l3.png?resize=298%2C20&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="298"/> contains CNNs with such smoothed ReLU, and that the norm <img alt="\|f_w\|" class="ql-img-inline-formula " height="19" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-62e1a48032624994ba16c4e26421676e_l3.png?resize=34%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="34"/> of such networks can be controlled by the spectral norms of filter matrices. This is consistent with previous measures of complexity for CNNs, see <a class="lipdf" href="https://papers.nips.cc/paper/7204-spectrally-normalized-margin-bounds-for-neural-networks.pdf">this paper</a> by Bartlett et al.</p>
<p>A perhaps more interesting finding is that the abstract representation <img alt="\Phi_n(x)" class="ql-img-inline-formula " height="18" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-3ca9a5351b772e88bebe85e7e4a13632_l3.png?resize=45%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="45"/>, which only depends on the network architecture, may provide near-translation invariance and stability to small image deformations while preserving information—that is, <img alt="x" class="ql-img-inline-formula " height="8" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-1b9fbfb207b6d17d74b33c6d8342a1a4_l3.png?resize=10%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="10"/> can be recovered from <img alt="\Phi_n(x)" class="ql-img-inline-formula " height="18" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-3ca9a5351b772e88bebe85e7e4a13632_l3.png?resize=45%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="45"/>. The original characterization we use was introduced by Mallat in <a class="lipdf" href="https://www.di.ens.fr/~mallat/papiers/ScatCPAM.pdf">his paper</a> on the scattering transform—a multilayer architecture akin to CNNs based on wavelets, and was extended to <img alt="\Phi_n" class="ql-img-inline-formula " height="16" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-273242b8e92b3a9f4dc13c62b2785bd3_l3.png?resize=21%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="21"/> by Alberto Bietti, who should be credited for all the hard work here.</p>
<p>Our goal is to understand under which conditions it is possible to obtain a representation that (i) is near-translation invariant, (ii) is stable to deformations, (iii) preserves signal information. Given a <img alt="C^1" class="ql-img-inline-formula " height="15" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-2e9ea203bbd77c5cd8bee967e2729d8b_l3.png?resize=20%2C15&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="20"/>-diffeomorphism <img alt="\tau: \mathbb{R}^2 \to \mathbb{R}^2" class="ql-img-inline-formula " height="16" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c6f8f1dde2ee4682653c2a6b37d8a42d_l3.png?resize=93%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="93"/> and denoting by <img alt="L_\tau x(u) = x(u-\tau(u))" class="ql-img-inline-formula " height="18" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-835d9f864f712213ee317332b3f3675a_l3.png?resize=167%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="167"/> its action operator (for an image defined on the continuous domain <img alt="\mathbb{R}^2" class="ql-img-inline-formula " height="15" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-d5abe0f29e8cc710ae26f4f0af5a0859_l3.png?resize=20%2C15&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="20"/>), the main stability bound we obtain is the following one, see Theorem 7 in <a class="lipdf" href="https://www.di.ens.fr/~mallat/papiers/ScatCPAM.pdf">Mallat’s paper</a> if <img alt="\|\nabla \tau\|_\infty \leq 1/2" class="ql-img-inline-formula " height="19" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-758b3cac273166048ed1879acf427860_l3.png?resize=104%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="104"/>, for all <img alt="x" class="ql-img-inline-formula " height="8" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-1b9fbfb207b6d17d74b33c6d8342a1a4_l3.png?resize=10%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="10"/>,</p>
<p class="ql-center-displayed-equation" style="line-height: 43px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\[ \| \Phi_n(L_\tau x) - \Phi_n(x)\| \leq \left ( C_1 (1+n) \|\nabla \tau\|_\infty + \frac{C_2}{\sigma_n} \|\tau\|_\infty \right) \|x\|, \]" class="ql-img-displayed-equation " height="43" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-51041d0067a72066938e31b1f00529fa_l3.png?resize=455%2C43&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="455"/></p>
<p>where <img alt="C_1, C_2" class="ql-img-inline-formula " height="16" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-08d1f29fa9c0981e916619b6c6bc7eee_l3.png?resize=48%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="48"/> are universal constants, <img alt="\sigma_n" class="ql-img-inline-formula " height="11" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c0142846a2999e170f7beec7be1523f2_l3.png?resize=18%2C11&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="18"/> is the scale parameter of the pooling operator <img alt="A_n" class="ql-img-inline-formula " height="15" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-e1872c7d7a65e0dc92f8a4a04608b88a_l3.png?resize=21%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="21"/> corresponding to the “amount of pooling” performed up to the last layer, <img alt="\|\tau\|_\infty" class="ql-img-inline-formula " height="19" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c1a5effb150d36de3c7074eaa980c357_l3.png?resize=39%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="39"/> is the maximum pixel displacement and <img alt="\|\nabla \tau\|_\infty" class="ql-img-inline-formula " height="19" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-ab4c5d3fe8fd25af25beb4f58a55c938_l3.png?resize=53%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="53"/> represents the maximum amount of deformation, see <a class="lipdf" href="https://www.di.ens.fr/~mallat/papiers/ScatCPAM.pdf">the paper</a> for the precise definitions of all these quantities. Note that when <img alt="C_2/\sigma_n \to 0" class="ql-img-inline-formula " height="18" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-b732bf857c5f04c7d10dda247f1a5022_l3.png?resize=85%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="85"/>, the representation <img alt="\Phi_n" class="ql-img-inline-formula " height="16" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-273242b8e92b3a9f4dc13c62b2785bd3_l3.png?resize=21%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="21"/> becomes translation invariant: indeed, consider the particular case of <img alt="\tau" class="ql-img-inline-formula " height="8" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-3af6c51247895b176bb502f0ee0857ee_l3.png?resize=10%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="10"/> being a translation, then <img alt="\nabla \tau=0" class="ql-img-inline-formula " height="14" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-aa1278a7149925a4f299de0dbb85cec0_l3.png?resize=57%2C14&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="57"/> and <img alt="\|\Phi_n(L_\tau x) - \Phi_n(x)\| \to 0" class="ql-img-inline-formula " height="19" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-cd1d650abd9970e357384c0653960577_l3.png?resize=186%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="186"/>.</p>
<p>The stability bound and a few additional results tell us a few things about the network architecture: (a) small patches lead to more stable representations (the dependency is hidden in <img alt="C_1" class="ql-img-inline-formula " height="16" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-782c65cbd411fb8862688afc92bc1eea_l3.png?resize=19%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="19"/>); (b) signal preservation for discrete signals requires small subsampling factors (and thus small pooling) between layers. In such a setting, the scale parameter <img alt="\sigma_n" class="ql-img-inline-formula " height="11" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c0142846a2999e170f7beec7be1523f2_l3.png?resize=18%2C11&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="18"/> still grows exponentially with <img alt="n" class="ql-img-inline-formula " height="8" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-a63eb5ff0272d3119fa684be6e7acce8_l3.png?resize=11%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="11"/> and near translation invariance may be achieved with several layers.</p>
<p>Interestingly, we may now come back to the Cauchy-Schwarz inequality from part 1, and note that if <img alt="\Phi_n" class="ql-img-inline-formula " height="16" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-273242b8e92b3a9f4dc13c62b2785bd3_l3.png?resize=21%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="21"/> is stable, the RKHS norm <img alt="\|f\|" class="ql-img-inline-formula " height="19" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-afe70184469e7e3a14405a7193eedf29_l3.png?resize=24%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="24"/> is then a natural quantity that provides stability to deformations to the prediction function <img alt="f" class="ql-img-inline-formula " height="16" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c7d97b919a3b73617cf2fbb375fff3b1_l3.png?resize=10%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="10"/>, in addition to measuring model complexity in a traditional sense.</p>
<p><strong>Feature learning in RKHSs and convolutional kernel networks</strong></p>
<p>The previous paragraph is devoted to the characterization of convolutional architectures such as CNNs but the previous kernel construction can in fact be used to derive more traditional kernel methods. After all, why should one spend efforts defining a kernel between images if not to use it?</p>
<p>This can be achieved by considering finite-dimensional approximations of the previous feature maps. In order to shorten the presentation, we simply describe the main idea based on the Nystrom approximation and refer to <a class="lipdf" href="http://papers.nips.cc/paper/6184-end-to-end-kernel-learning-with-supervised-convolutional-kernel-networks.pdf">the paper</a> for more details. Approximating the infinite-dimensional feature maps <img alt="x_k" class="ql-img-inline-formula " height="11" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-3ad23c5c360c3f33031a5d000d37416f_l3.png?resize=17%2C11&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="17"/> (see the figure at the top of <a class="liinternal" href="https://blogs.princeton.edu/imabandit/2019/07/10/guest-post-by-julien-mairal-a-kernel-point-of-view-on-convolutional-neural-networks-part-i/">part I</a>) can be done by projecting each point in <img alt="\mathcal{H}_k" class="ql-img-inline-formula " height="15" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-bc26f0de4084a72b9e625a080bd5d674_l3.png?resize=22%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="22"/> onto a <img alt="p_k" class="ql-img-inline-formula " height="12" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-5c72bc331dc0008f57d454e7071dc39e_l3.png?resize=17%2C12&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="17"/>-dimensional subspace <img alt="\mathcal{F}_k" class="ql-img-inline-formula " height="16" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-b08b176c0bf0adbd9cbe41b31147e1f7_l3.png?resize=20%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="20"/> leading to a finite-dimensional feature map <img alt="\tilde{x}_k" class="ql-img-inline-formula " height="15" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-5f55b75318f3b8da67917ee0b0e190ce_l3.png?resize=17%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="17"/> akin to CNNs, see the figure at the top of the post.</p>
<p>By parametrizing <img alt="\mathcal{F}_k=\text{span}(\varphi_k(z_1),\varphi_k(z_2),\ldots,\varphi_k(z_{p_k}))" class="ql-img-inline-formula " height="20" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-5dd8802df8efddb9acc5056af47339d7_l3.png?resize=297%2C20&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="297"/> with <img alt="p_k" class="ql-img-inline-formula " height="12" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-5c72bc331dc0008f57d454e7071dc39e_l3.png?resize=17%2C12&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="17"/> anchor points <img alt="Z=[z_1,\ldots,z_{p_k}]" class="ql-img-inline-formula " height="19" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-4614e1cdba47dc6a6db7957fb1d82632_l3.png?resize=123%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="123"/>, and using a dot-product kernel, a patch <img alt="z" class="ql-img-inline-formula " height="8" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-d9d772a59543419785ce66946592259a_l3.png?resize=9%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="9"/> from <img alt="\tilde{x}_{k-1}" class="ql-img-inline-formula " height="16" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-6419748397a324cd2a2ebc3f119b7f80_l3.png?resize=35%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="35"/> is encoded through the mapping function</p>
<p class="ql-center-displayed-equation" style="line-height: 43px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\[ \psi_k(z) = \|z\| \kappa_k( Z^\top Z)^{-1/2} \kappa_k\left( Z^\top \frac{z}{\|z\|} \right), \]" class="ql-img-displayed-equation " height="43" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-cc43da382f024d96cb50e3dc3f051d6f_l3.png?resize=306%2C43&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="306"/></p>
<p>where <img alt="\kappa_k" class="ql-img-inline-formula " height="11" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-684fcf23472c51919624049fb4e0129a_l3.png?resize=17%2C11&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="17"/> is applied pointwise. Then, computing <img alt="\tilde{x}_k" class="ql-img-inline-formula " height="15" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-5f55b75318f3b8da67917ee0b0e190ce_l3.png?resize=17%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="17"/> from <img alt="\tilde{x}_{k-1}" class="ql-img-inline-formula " height="16" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-6419748397a324cd2a2ebc3f119b7f80_l3.png?resize=35%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="35"/> admits a CNN interpretation, where only the normalization and the matrix multiplication by <img alt="\kappa_k( Z^\top Z)^{-1/2}" class="ql-img-inline-formula " height="21" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-a74cffbbd51922298a13f864fbedaa98_l3.png?resize=103%2C21&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="103"/> are not standard operations. It remains now to choose the anchor points:</p>
<ul>
<li><strong>kernel approximation:</strong> a first approach consists of using a variant of the Nystrom method, see <a class="lipdf" href="https://papers.nips.cc/paper/1866-using-the-nystrom-method-to-speed-up-kernel-machines.pdf">this paper</a> and <a class="lipdf" href="http://home.cse.ust.hk/~twinsen/nystrom.pdf">that one</a>. When plugging the corresponding image representation in a linear classifier, the resulting approach behaves as a classical kernel machine. Empirically, we observe that the higher the number of anchor points, the better the kernel approximation, and the higher the accuracy. For instance, a two-layer network with a <img alt="300k" class="ql-img-inline-formula " height="13" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-81a4466abb5fecba81f8a3aa055a1a14_l3.png?resize=36%2C13&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="36"/>-dimensional representations achieves about <img alt="86\%" class="ql-img-inline-formula " height="15" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-0eea28372ada596bc618b4b94fee69ec_l3.png?resize=32%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="32"/> accuracy on CIFAR-10 without data augmentation (see <a class="liinternal" href="https://gitlab.inria.fr/mairal/ckn-cudnn-matlab">here</a>).</li>
<li><strong>back-propagation, feature selection</strong>: learning the anchor points <img alt="Z" class="ql-img-inline-formula " height="12" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-cc9f8fff9fd24060bc054e78f01d5bfb_l3.png?resize=12%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="12"/> can also be done as in a traditional CNN, by optimizing them end-to-end. This allows using deeper lower-dimensional architectures and empirically seems to perform better when enough data is available, e.g., <img alt="92\%" class="ql-img-inline-formula " height="15" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-659ab3cccda2422f955af880d20646cf_l3.png?resize=32%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="32"/> accuracy on CIFAR-10 with simple data augmentation. There, the subspaces <img alt="\mathcal{F}_k" class="ql-img-inline-formula " height="16" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-b08b176c0bf0adbd9cbe41b31147e1f7_l3.png?resize=20%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="20"/> are not learned anymore to provide the best kernel approximation, but the model seems to perform a sort of feature selection in each layer’s RKHS <img alt="\mathcal{H}_k" class="ql-img-inline-formula " height="15" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-bc26f0de4084a72b9e625a080bd5d674_l3.png?resize=22%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="22"/>, which is not well understood yet (This feature selection interpretation is due to my collaborator Laurent Jacob).</li>
</ul>
<p>Note that the first CKN model published <a class="lipdf" href="https://papers.nips.cc/paper/5348-convolutional-kernel-networks.pdf">here</a> was based on a different approximation principle, which was not compatible with end-to-end training. We found this to be less scalable and effective.</p>
<p><strong>Other links between neural networks and kernel methods</strong></p>
<p>Finally, other links between kernels and infinitely-wide neural networks with random weights are classical, but they were not the topic of this blog post (they should be the topic of another one!). In a nutshell, for a large collection of weights distributions and nonlinear functions <img alt="s: \mathbb{R} \to \mathbb{R}" class="ql-img-inline-formula " height="13" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-b4680e3f9e8274687d2d04f0a262ed00_l3.png?resize=76%2C13&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="76"/>, the following quantity admits an analytical form</p>
<p class="ql-center-displayed-equation" style="line-height: 22px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\[ K(x,x') = \E_{w}[ s(w^\top x) s(w^\top x')], \]" class="ql-img-displayed-equation " height="22" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-9144f2d0b847adb69db90629ed805148_l3.png?resize=229%2C22&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="229"/></p>
<p>where the terms <img alt="s(w^\top x)" class="ql-img-inline-formula " height="19" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-da82e444bbc3a5e594b7edbf0b1ba3a0_l3.png?resize=56%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="56"/> may be seen as an infinitely-wide single-layer neural network. The first time such a relation appears is likely to be in <a class="liexternal" href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.446.9306&amp;rep=rep1&amp;type=pdf">the PhD thesis</a> of Radford Neal with a Gaussian process interpretation, and it was revisited later by <a class="lipdf" href="http://proceedings.mlr.press/v2/leroux07a/leroux07a.pdf">Le Roux and Bengio</a> and by <a class="lipdf" href="http://papers.nips.cc/paper/3628-kernel-methods-for-deep-learning.pdf">Cho and Saul</a> with multilayer models.</p>
<p>In particular, when <img alt="s" class="ql-img-inline-formula " height="8" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-3bcfb3f0b6b04be3b598743cd774dd78_l3.png?resize=8%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="8"/> is the rectified linear unit and <img alt="w" class="ql-img-inline-formula " height="8" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-78d46af3f19bae0d88ac0cabd450a296_l3.png?resize=13%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="13"/> follows a Gaussian distribution, it is known that we recover the arc-cosine kernel. We may also note that <a class="lipdf" href="http://papers.nips.cc/paper/3182-random-features-for-large-scale-kernel-machines.pdf">random Fourier features</a> also yield a similar interpretation.</p>
<p>Other important links have also been drawn recently between kernel regression and strongly over-parametrized neural networks, see <a class="lipdf" href="http://papers.nips.cc/paper/8076-neural-tangent-kernel-convergence-and-generalization-in-neural-networks.pdf">this paper</a> and <a class="lipdf" href="https://arxiv.org/pdf/1812.07956.pdf">that one</a>, which is another exciting story.</p></div>
    </content>
    <updated>2019-07-17T16:02:03Z</updated>
    <published>2019-07-17T16:02:03Z</published>
    <category term="Machine learning"/>
    <author>
      <name>Sebastien Bubeck</name>
    </author>
    <source>
      <id>https://blogs.princeton.edu/imabandit</id>
      <link href="https://blogs.princeton.edu/imabandit/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://blogs.princeton.edu/imabandit" rel="alternate" type="text/html"/>
      <subtitle>Random topics in optimization, probability, and statistics. By Sébastien Bubeck</subtitle>
      <title>I’m a bandit</title>
      <updated>2019-07-21T23:35:40Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://minimizingregret.wordpress.com/?p=207</id>
    <link href="https://minimizingregret.wordpress.com/2019/07/17/boosting-for-dynamical-systems/" rel="alternate" type="text/html"/>
    <title>Boosting for Dynamical Systems</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">by Nataly Brukhim, Naman Agarwal and Elad Hazan, based on this paper  In a famous 1906 competition at a local fair in Plymouth, England, participants were asked to guess the weight of an ox. Out of a crowd of hundreds, no one came close to the ox’s actual weight, but the average of all guesses was … <a class="more-link" href="https://minimizingregret.wordpress.com/2019/07/17/boosting-for-dynamical-systems/">Continue reading <span class="screen-reader-text">Boosting for Dynamical Systems</span> <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><em>by Nataly Brukhim, Naman Agarwal and Elad Hazan, based on <a href="https://arxiv.org/abs/1906.08720">this paper</a> </em></p>
<p>In a famous 1906 competition at a local fair in Plymouth, England, participants were asked to guess the weight of an ox. Out of a crowd of hundreds, no one came close to the ox’s actual weight, but the average of all guesses was almost correct. How is it that combining the opinions of laymen can somehow arrive at highly reasoned decisions, despite the weak judgment of individual members? This concept of harnessing wisdom from weak rules of thumb to form a highly accurate prediction rule, is the basis of ensemble methods and <b>boosting</b>. Boosting is a theoretically sound methodology that has transformed machine learning across a variety of applications; in classification and regression tasks, online learning, and many more.</p>
<p>In the case of online learning, examples for training a predictor are not available in advance, but are revealed one at a time. Online boosting combines a set of online prediction rules, or <i>weak learners. </i>At every time step, each weak learner outputs a prediction, suffers some loss and is then updated accordingly. The performance of an online learner is measured using the <i>regret</i> criterion, which compares the accumulated loss over time with that of the best fixed decision in hindsight. A <i>Boosting</i> algorithm can choose which examples are fed to each of the weak learners, as well as the losses they incur. Intuitively, the online booster can encourage some weak learners to become really good in predicting certain common cases, while allowing others to focus on edge cases that are harder to predict. Overall, the <a href="http://proceedings.mlr.press/v37/beygelzimer15.pdf">online</a> <a href="https://arxiv.org/abs/1506.04820">boosting</a> framework can achieve low regret guarantees based on the learners’ individual regret values.</p>
<p>However, online learning can become more challenging when our actions have consequences on the environment. This can be illustrated with the following experiment: imagine learning to balance a long pole on your hand. When you move your hand slightly, the pole tilts. You then move your hand in the opposite direction, and it bounces back and tilts to the other side. One jerk the wrong way might have you struggling for a good few seconds to rebalance. In other words, a <u>sequence of decisions</u> you made earlier determines whether or not the pole is balanced at any given time, rather than the single decision you make at that point.<img alt="" class=" aligncenter" height="129" src="https://minimizingregret.files.wordpress.com/2019/07/image.jpeg?w=136&amp;h=129" title="" width="136"/></p>
<p>More generally, consider cases when our environment has a <b>state, </b>and is in some sense “remembering” our past choices. A stateful framework, able to model a wide range of such phenomena, is a <i>dynamical system</i>. A dynamical system can be thought of as a function that determines, given the current state, what the state of the system will be in the next time step. Think of the physical dynamics that determines our pole’s position based on sequential hand movements. Other intuitive examples are the fluctuations of stock prices in the stock market, or the local weather temperatures; these can all be modeled with dynamical systems.</p>
<p>So how can boosting help us make better predictions for a dynamical system? In <a href="https://arxiv.org/abs/1906.08720">recent work</a> we propose an algorithm, which we refer to as DynaBoost, that achieves this goal. In the paper we provide theoretical regret bounds, as well as an empirical evaluation in a variety of applications, such as online control and time-series prediction.</p>
<p><b>Learning for Online Control</b></p>
<p>Control theory is a field of applied mathematics that deals with the control of various physical processes and engineering systems. The objective is to design an action rule, or <i>controller</i>, for a dynamical system such that steady state values are achieved quickly, and the system maintains stability.</p>
<p>Consider a simple Linear Dynamical System (LDS):</p>
<p style="text-align: center;"><img alt="x_{t+1} = A x_t + B u_t + w_t" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7Bt%2B1%7D+%3D+A+x_t+%2B+B+u_t+%2B+w_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="x_{t+1} = A x_t + B u_t + w_t"/></p>
<p>where <img alt="x_t,u_t" class="latex" src="https://s0.wp.com/latex.php?latex=x_t%2Cu_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="x_t,u_t"/> are the state and control values at time t, respectively. Assume a known transition dynamics specified by the matrices A and B, and an arbitrary disturbance to the system given by <img alt="w_t" class="latex" src="https://s0.wp.com/latex.php?latex=w_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="w_t"/>. The goal of the controller is to minimize a convex cost function <img alt="c_t(x_t,u_t)" class="latex" src="https://s0.wp.com/latex.php?latex=c_t%28x_t%2Cu_t%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="c_t(x_t,u_t)"/>.</p>
<p>A provably optimal controller for the Gaussian noise case (where <img alt="w_t" class="latex" src="https://s0.wp.com/latex.php?latex=w_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="w_t"/> are normally distributed) and when the cost functions are quadratic, is the Linear Quadratic Regulator (LQR). LQR computes a pre-fixed matrix K such that <img alt="u_t^{LQR} = K x_t" class="latex" src="https://s0.wp.com/latex.php?latex=u_t%5E%7BLQR%7D+%3D+K+x_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="u_t^{LQR} = K x_t"/>. In other words, LQR computes a linear controller – which linearly maps the state into a control at every time step.</p>
<p>A <a href="http://proceedings.mlr.press/v97/agarwal19c/agarwal19c.pdf">recent advancement</a> in online control considers <i>arbitrary</i> disturbances, as opposed to normally distributed noise. In this more general setting, there is no closed form for the optimal controller. Instead, it is proposed to use a weighted sum of previously observed noises, i.e., <img alt="u_t^{WL} = K x_t + \sum_{i=1}^H M_i w_{t-i} " class="latex" src="https://s0.wp.com/latex.php?latex=u_t%5E%7BWL%7D+%3D+K+x_t+%2B+%5Csum_%7Bi%3D1%7D%5EH+M_i+w_%7Bt-i%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="u_t^{WL} = K x_t + \sum_{i=1}^H M_i w_{t-i} "/> , where <img alt="M_1,...,M_H" class="latex" src="https://s0.wp.com/latex.php?latex=M_1%2C...%2CM_H&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="M_1,...,M_H"/> are learned parameters, updated in an online fashion. This method is shown to attain vanishing average regret compared to the best fixed linear controller in hindsight, and is applicable for general convex cost functions as opposed to only quadratics.</p>
<p>Crucially, the state-dependent term <img alt="Kx_t" class="latex" src="https://s0.wp.com/latex.php?latex=Kx_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="Kx_t"/> is not learned. Since the learned parameters of the above controller therefore considers only a fixed number of recent disturbances, we can apply existing <a href="http://ocobook.cs.princeton.edu/">online convex optimization</a> techniques developed for <a href="https://papers.nips.cc/paper/6025-online-learning-for-adversaries-with-memory-price-of-past-mistakes">learning with loss functions that have bounded memory</a>.</p>
<p><strong>Boosting for Online Control</strong></p>
<p>Using the insights described above to remove state in online control, we can now use techniques from online boosting. DynaBoost maintains multiple copies of the base-controller above, with each copy corresponding to one stage in boosting. At every time step, the control <img alt="u_t" class="latex" src="https://s0.wp.com/latex.php?latex=u_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="u_t"/> is obtained from a convex combination of the base-controllers’ outputs <img alt="u_t^{WL(1)},...,u_t^{WL(N)}" class="latex" src="https://s0.wp.com/latex.php?latex=u_t%5E%7BWL%281%29%7D%2C...%2Cu_t%5E%7BWL%28N%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="u_t^{WL(1)},...,u_t^{WL(N)}"/>. To update each base-controller’s parameters, DynaBoost feeds each controller with a <i>residual</i> <i>proxy </i>cost function, and seeks to obtain a minimizing point in the direction of the residual loss function’s gradient. Stability ensures that minimizing regret over the proxy costs (which have finite memory) suffices to minimize overall regret. See <a href="https://arxiv.org/abs/1906.08720">our paper</a> for the detailed description of the algorithm and its regret guarantees.</p>
<p><strong>Sanity check experiment</strong></p>
<p>We first conducted experiments for the standard LQR setting with i.i.d. Gaussian noise and known dynamics. We applied our boosting method to the non-optimal controller with learned parameters (Control-WL), and we observe that boosting improves its loss and achieves near-optimal performance (here the optimal controller is given by the fixed LQR solution). We have tested an LDS of different dimensions <img alt="d = 1,10,100" class="latex" src="https://s0.wp.com/latex.php?latex=d+%3D+1%2C10%2C100&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="d = 1,10,100"/>, and averaged results over multiple runs.</p>
<p><img alt="" height="182" src="https://minimizingregret.files.wordpress.com/2019/07/null.png?w=624&amp;h=182" title="" width="624"/></p>
<p><strong>Correlated noise experiment</strong></p>
<p>When the disturbances are not independently drawn, the LQR controller is not guaranteed to perform optimally. We experimented with two LDS settings with correlated disturbances in which (a) the disturbances <img alt="w_t" class="latex" src="https://s0.wp.com/latex.php?latex=w_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="w_t"/> are generated from a Gaussian random-walk, and (b) where they are generated by a sine function applied to the time index. In these cases, boosted controllers perform better compared to the “weak” learned controller, and can also outperform the fixed LQR solution. We have also tested a Recurrent Neural Network, and observed that boosting is effective for RNNs as well.</p>
<p><img alt="" height="266" src="https://minimizingregret.files.wordpress.com/2019/07/null-1.png?w=624&amp;h=266" title="" width="624"/></p>
<p><strong>Inverted Pendulum experiment</strong></p>
<p>A more challenging experiment with a non-linear dynamical system is the Inverted Pendulum experiment. This is very similar to the pole balancing example we discussed above, and is a standard benchmark for control methods. The goal is to balance the inverted pendulum by applying torque that will stabilize it in a vertically upright position, in the presence of noise. In our experiments, we used correlated disturbances from a Gaussian random-walk. We follow the dynamics implemented in <a href="https://gym.openai.com/">OpenAI Gym</a>, and test the performance of different controllers: LQR, a learned controller, and boosting. The video below visualizes this experiment:</p>
<div class="jetpack-video-wrapper"/>
<p>When averaging the loss value over multiple experiment runs, we get the following plot:</p>
<p style="text-align: center;"><img alt="" height="276" src="https://minimizingregret.files.wordpress.com/2019/07/null-2.png?w=369&amp;h=276" title="" width="369"/></p>
<p>It can be seen that the learned controller performs much better than the LQR in the presence of correlated noise, and that boosting can improve its stability and achieve lower average loss.</p>
<p><b>Boosting for Time-Series Prediction</b></p>
<p>Similarly to the control setting, in time-series prediction tasks it is sufficient to use fixed horizons, and online boosting can be efficiently applied here as well. In time-series prediction, the data is often assumed to be generated from an autoregressive moving average (ARMA) model:</p>
<p style="text-align: center;"><img alt="x_{t} = \sum_{i=1}^k \alpha_i x_{t-i} + \sum_{j=1}^q \beta_j w_j + w_t" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7Bt%7D+%3D+%5Csum_%7Bi%3D1%7D%5Ek+%5Calpha_i+x_%7Bt-i%7D+%2B+%5Csum_%7Bj%3D1%7D%5Eq+%5Cbeta_j+w_j+%2B+w_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="x_{t} = \sum_{i=1}^k \alpha_i x_{t-i} + \sum_{j=1}^q \beta_j w_j + w_t"/></p>
<p>In words, each data point <img alt="x_t" class="latex" src="https://s0.wp.com/latex.php?latex=x_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="x_t"/> is given by a weighted sum of previous points, previous noises and a new noise term <img alt="w_t" class="latex" src="https://s0.wp.com/latex.php?latex=w_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="w_t"/>, where <img alt="\alpha,\beta" class="latex" src="https://s0.wp.com/latex.php?latex=%5Calpha%2C%5Cbeta&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\alpha,\beta"/> are the coefficients vectors.</p>
<p>To test our boosting method, We experimented with 4 simulated settings: 1) normally distributed noises, 2) coefficients of the dynamical system slowly change over time, 3) a single, abrupt, change of the coefficients, and, 4) correlated noise: Gaussian random walk.</p>
<p>The weak learners tested here are the ARMA-ONS (online newton step) and ARMA-OGD (online gradient descent) algorithms for time-series prediction (See <a href="http://proceedings.mlr.press/v30/Anava13.pdf">this</a> paper for more details). We applied our boosting method, as well as a fast version of it, which applies to quadratic loss functions (we used squared difference in this case).</p>
<p><i><b>1) Gaussian Noise </b></i> <i><b>2) Changing Coefficients</b></i></p>
<p><img alt="" height="217" src="https://minimizingregret.files.wordpress.com/2019/07/null-3.png?w=289&amp;h=217" title="" width="289"/><img alt="" height="217" src="https://minimizingregret.files.wordpress.com/2019/07/null-4.png?w=289&amp;h=217" title="" width="289"/><img alt="" height="218" src="https://minimizingregret.files.wordpress.com/2019/07/null-5.png?w=292&amp;h=218" title="" width="292"/><img alt="" height="217" src="https://minimizingregret.files.wordpress.com/2019/07/null-6.png?w=290&amp;h=217" title="" width="290"/></p>
<p><i><b>3) Abrupt Change </b></i> <i><b>4) Correlated Noise</b></i></p>
<p>We can see in the plots above that all weak learners’ loss values (red) can be improved by online boosting methods (blue). A similar observation arises when experimenting with real-world data; we experimented with the Air Quality dataset from the <a href="https://archive.ics.uci.edu/ml/index.php">UCI Machine Learning repository</a>, that contains hourly averaged measurements of air quality properties from an Italian city throughout one year, as measured by chemical sensors. We apply similar weak learners to this task, as well as our boosting algorithms. Here we again obtain better averaged losses for boosted methods (blue) compared to the baselines (red).</p>
<p style="text-align: center;"><img alt="" height="373" src="https://minimizingregret.files.wordpress.com/2019/07/null-7.png?w=498&amp;h=373" title="" width="498"/></p></div>
    </content>
    <updated>2019-07-17T14:24:42Z</updated>
    <published>2019-07-17T14:24:42Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Elad Hazan</name>
    </author>
    <source>
      <id>https://minimizingregret.wordpress.com</id>
      <logo>https://minimizingregret.files.wordpress.com/2017/08/cropped-pu1.png?w=32</logo>
      <link href="https://minimizingregret.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://minimizingregret.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://minimizingregret.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://minimizingregret.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Google Princeton AI and Hazan Lab @ Princeton University</subtitle>
      <title>Minimizing Regret</title>
      <updated>2019-07-22T09:22:13Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=17564</id>
    <link href="https://gilkalai.wordpress.com/2019/07/17/dan-romik-on-the-riemann-zeta-function/" rel="alternate" type="text/html"/>
    <title>Dan Romik on the Riemann zeta function</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">This post about the Rieman zeta function, among the most important and mysterious mathematical objects is kindly written by Dan Romik. It is related to his paper Orthogonal polynomial expansions for the Riemann xi function,  that we mentioned in this … <a href="https://gilkalai.wordpress.com/2019/07/17/dan-romik-on-the-riemann-zeta-function/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><em>This post about the Rieman zeta function, among the most important and mysterious mathematical objects is kindly written by Dan Romik. It is related to his paper <a href="https://arxiv.org/abs/1902.06330">Orthogonal polynomial expansions for the Riemann xi function</a>,  that we mentioned in <a href="https://gilkalai.wordpress.com/2019/02/28/dan-romik-studies-the-riemanns-zeta-function-and-other-zeta-news/">this post</a>.</em></p>
<h2>Dan Romik on the Riemann zeta function</h2>
<p>Recently when I was thinking about the Riemann zeta function, I had the double thrill of discovering some new results about it, and then later finding out that my new ideas were closely related to some very classical ideas due to two icons of twentieth-century mathematics, George Pólya and Pál Turán. When you are trying to stand on the shoulders of giants, it’s nice to see other giants right there beside you trying to do the same!</p>
<p>It all goes back to one of the most famous problems in mathematics, the Riemann Hypothesis (RH). Both Pólya and Turán were rather enamored with this problem and published about it extensively; Pólya was said to have been preoccupied with the problem to the very end of his life.(1) And they both recognized that an important first step in trying to prove something about the zeros of the zeta function is having a good representation<br/>
for the Riemann zeta function. After all, there are many different formulas that can be used to define or compute the zeta function. If you don’t choose the right one, you probably won’t get very far with your analysis.</p>
<p>Pólya in one of his famous attacks on the problem considered the representation of the zeta function (or more precisely of the Riemann xi function, which is a symmetrized and better-behaved version of the zeta function; see below) as a Fourier transform—a standard representation due (essentially) to Riemann. I’ll have more to say about that later.</p>
<p>Turán also looked at the Riemann xi function, and instead of working with one of the standard “named” representations such as the Fourier transform or Taylor series, looked around a bit more intentionally for a representation of the function that seemed particularly suited to answering the specific question of whether the zeros all lie on a line. In a 1950 address to the Hungarian Academy of Sciences, he put forward his ideas about what he thought was the correct representation to look at: the infinite series expansion of the xi function in the Hermite polynomials. About eighty years after Turán’s discovery, my own investigations led me to discover [5] that the Hermite polynomials are not the only polynomials in which it’s interesting to expand the Riemann xi function. It turns out that there are at least two other families of polynomials for which the respective expansions are no less (and, in some ways, more) well-behaved. My motto for these polynomial families, which are known to experts in special functions but have until now been somewhat esoteric (though I hope that is about to change), is that they are “the coolest polynomials that you never heard of.”</p>
<p>Let’s look at some of the technical details so that I can explain why these new expansions are interesting, and how they relate to Turán’s work and ultimately back to Pólya’s ideas and one of the particular threads that grew out of them. First, define the Riemann xi function as</p>
<p><img alt="\displaystyle \xi(s) = \frac12 s(s-1) \pi^{-s/2} \Gamma\left(\frac{s}{2}\right) \zeta(s) \qquad (s\in\mathbb{C}), " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cxi%28s%29+%3D+%5Cfrac12+s%28s-1%29+%5Cpi%5E%7B-s%2F2%7D+%5CGamma%5Cleft%28%5Cfrac%7Bs%7D%7B2%7D%5Cright%29+%5Czeta%28s%29+%5Cqquad+%28s%5Cin%5Cmathbb%7BC%7D%29%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \xi(s) = \frac12 s(s-1) \pi^{-s/2} \Gamma\left(\frac{s}{2}\right) \zeta(s) \qquad (s\in\mathbb{C}), "/></p>
<p>where <img alt="{\Gamma(z)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CGamma%28z%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Gamma(z)}"/> is the Euler gamma function and <img alt="{\zeta(s)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Czeta%28s%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\zeta(s)}"/> is the Riemann zeta function. It’s also common to denote<br/>
<img alt="\displaystyle \Xi(t) = \xi\left(\frac12+it\right) \qquad (t\in\mathbb{C}). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5CXi%28t%29+%3D+%5Cxi%5Cleft%28%5Cfrac12%2Bit%5Cright%29+%5Cqquad+%28t%5Cin%5Cmathbb%7BC%7D%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \Xi(t) = \xi\left(\frac12+it\right) \qquad (t\in\mathbb{C}). "/></p>
<p>This is Riemann’s “capital xi” function, which is still usually referred to as Riemann’s xi function. (This seems reasonable: the two functions are the same up to a trivial linear change of variables.) The main point of these definitions is that <img alt="{\Xi(t)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CXi%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Xi(t)}"/> is an entire function of the complex variable <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t}"/>, and that RH can now be reformulated as the statement that the zeros of <img alt="{\Xi(t)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CXi%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Xi(t)}"/> all lie on the real line. Moreover, the famous functional equation satisfied by the Riemann zeta function maps to the statement that <img alt="{\Xi(t)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CXi%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Xi(t)}"/> is an even function.<br/>
Now consider the following four ways of representing the xi function:</p>
<p><img alt="\displaystyle \Xi(t) = \sum_{n=0}^\infty (-1)^n a_{2n} t^{2n},~~~~~(1)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5CXi%28t%29+%3D+%5Csum_%7Bn%3D0%7D%5E%5Cinfty+%28-1%29%5En+a_%7B2n%7D+t%5E%7B2n%7D%2C%7E%7E%7E%7E%7E%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle \Xi(t) = \sum_{n=0}^\infty (-1)^n a_{2n} t^{2n},~~~~~(1)"/></p>
<p><img alt="\displaystyle \Xi(t) = \sum_{n=0}^\infty (-1)^n b_{2n} H_{2n}(t),~~~~~(2)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5CXi%28t%29+%3D+%5Csum_%7Bn%3D0%7D%5E%5Cinfty+%28-1%29%5En+b_%7B2n%7D+H_%7B2n%7D%28t%29%2C%7E%7E%7E%7E%7E%282%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle \Xi(t) = \sum_{n=0}^\infty (-1)^n b_{2n} H_{2n}(t),~~~~~(2)"/></p>
<p><img alt="\displaystyle\Xi(t) = \sum_{n=0}^\infty (-1)^n c_{2n} f_{2n}\left(\frac{t}{2}\right),~~~~~(3)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%5CXi%28t%29+%3D+%5Csum_%7Bn%3D0%7D%5E%5Cinfty+%28-1%29%5En+c_%7B2n%7D+f_%7B2n%7D%5Cleft%28%5Cfrac%7Bt%7D%7B2%7D%5Cright%29%2C%7E%7E%7E%7E%7E%283%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle\Xi(t) = \sum_{n=0}^\infty (-1)^n c_{2n} f_{2n}\left(\frac{t}{2}\right),~~~~~(3)"/></p>
<p><img alt="\displaystyle \Xi(t) = \sum_{n=0}^\infty (-1)^n d_{2n} g_{2n}\left(\frac{t}{2}\right).~~~~~(4)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5CXi%28t%29+%3D+%5Csum_%7Bn%3D0%7D%5E%5Cinfty+%28-1%29%5En+d_%7B2n%7D+g_%7B2n%7D%5Cleft%28%5Cfrac%7Bt%7D%7B2%7D%5Cright%29.%7E%7E%7E%7E%7E%284%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle \Xi(t) = \sum_{n=0}^\infty (-1)^n d_{2n} g_{2n}\left(\frac{t}{2}\right).~~~~~(4)"/></p>
<p>Here, the first representation (1) is simply the Taylor expansion of <img alt="{\Xi(t)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CXi%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Xi(t)}"/>, which contains only even terms since <img alt="{\Xi(t)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CXi%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Xi(t)}"/> is an even function. The numbers <img alt="{a_{2n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba_%7B2n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a_{2n}}"/> are (up to the <img alt="{(-1)^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28-1%29%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(-1)^n}"/> sign factor) the Taylor coefficients. Some attempts have been made to understand them, and one interesting and fairly trivial observation (again going back to facts already known to Riemann) is that they are all positive. Some additional and less trivial things can be said—see for example Section 6.1 of my paper [5], and the recent paper by Griffin, Ono, Rolen and Zagier [2]. But at the end of the day, no one has yet succeeded in using the Taylor expansion to prove anything new about the location of the zeros.</p>
<p>The second representation (2) is the infinite series expansion of <img alt="{\Xi(t)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CXi%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Xi(t)}"/> in the classical sequence of Hermite polynomials, defined by the well-known formula</p>
<p><img alt="\displaystyle H_n(t) = (-1)^n e^{t^2} \frac{d^n}{dt^n} \left( e^{-t^2} \right). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+H_n%28t%29+%3D+%28-1%29%5En+e%5E%7Bt%5E2%7D+%5Cfrac%7Bd%5En%7D%7Bdt%5En%7D+%5Cleft%28+e%5E%7B-t%5E2%7D+%5Cright%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle H_n(t) = (-1)^n e^{t^2} \frac{d^n}{dt^n} \left( e^{-t^2} \right). "/></p>
<p>This is the representation whose use was advocated by Turán. His reasoning was that expanding a function of a complex variable (for example, in the simplest case, a polynomial) in monomials <img alt="{t^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t^n}"/> doesn’t provide useful information to easily decide if the function has only real zeros, because the monomials have, roughly speaking, radial symmetry: their level curves are concentric circles. The Hermite polynomials on the other hand, at least heuristically, have level curves that are closer to being straight lines parallel to the real axis, Turán argued; thus, they are more suited to the geometry of the problem we are trying to solve.</p>
<p>Turán’s case for supporting the Hermite polynomials as the right basis to use is quite detailed—you can read about it in his papers [6,7,8] (and no, he was not able to actually prove anything about the zeros of <img alt="{\Xi(t)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CXi%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Xi(t)}"/>; this is a common theme in most of the attacks on RH to date…). I’ll simply mention that again one interesting and fairly easy observation is that the coefficients <img alt="{b_{2n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb_%7B2n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{b_{2n}}"/> in the expansion (2)—adjusted through the introduction of the sign factor <img alt="{(-1)^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28-1%29%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(-1)^n}"/>—end up being positive numbers. Their asymptotic behavior can also be analyzed: I prove a result about this in my paper (though it’s not particularly pretty).</p>
<p>Now comes the part that to me seems the most exciting, involving the expansions (3) and (4). These are the expansions in the more exotic families of polynomials</p>
<p><img alt="\displaystyle f_n(x)=(-i)^n \sum_{k=0}^n 2^k\binom{n+\frac12}{n-k}\binom{-\frac34+ix}{k}," class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+f_n%28x%29%3D%28-i%29%5En+%5Csum_%7Bk%3D0%7D%5En+2%5Ek%5Cbinom%7Bn%2B%5Cfrac12%7D%7Bn-k%7D%5Cbinom%7B-%5Cfrac34%2Bix%7D%7Bk%7D%2C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle f_n(x)=(-i)^n \sum_{k=0}^n 2^k\binom{n+\frac12}{n-k}\binom{-\frac34+ix}{k},"/></p>
<p><img alt="\displaystyle g_n(x)= (-i)^n \sum_{k=0}^n \frac{(n+k+1)!}{(n-k)!(3/2)_k^2} \binom{-\frac34+ix}{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+g_n%28x%29%3D+%28-i%29%5En+%5Csum_%7Bk%3D0%7D%5En+%5Cfrac%7B%28n%2Bk%2B1%29%21%7D%7B%28n-k%29%21%283%2F2%29_k%5E2%7D+%5Cbinom%7B-%5Cfrac34%2Bix%7D%7Bk%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle g_n(x)= (-i)^n \sum_{k=0}^n \frac{(n+k+1)!}{(n-k)!(3/2)_k^2} \binom{-\frac34+ix}{k}"/></p>
<p>(where <img alt="{(3/2)_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%283%2F2%29_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(3/2)_n}"/> is a <a href="https://en.wikipedia.org/wiki/Falling_and_rising_factorials">Pochhammer symbol</a>), mildly rescaled by replacing <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/>  with <img alt="{t/2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t/2}"/>. In the terminology of the theory of orthogonal polynomials, the family <img alt="{f_n(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_n%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_n(x)}"/> is a special case of a two-parameter family <img alt="{P_n^{(\lambda)}(x;\phi)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP_n%5E%7B%28%5Clambda%29%7D%28x%3B%5Cphi%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{P_n^{(\lambda)}(x;\phi)}"/> known as the Meixner-Pollaczek polynomials, with the parameters taking the particular values <img alt="{\phi=\frac{\pi}{2}, \lambda=\frac{3}{4}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%3D%5Cfrac%7B%5Cpi%7D%7B2%7D%2C+%5Clambda%3D%5Cfrac%7B3%7D%7B4%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\phi=\frac{\pi}{2}, \lambda=\frac{3}{4}}"/>. Similarly, the family <img alt="{g_n(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg_n%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{g_n(x)}"/> is a special case of the four-parameter family <img alt="{p_n(x;a,b,c,d)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_n%28x%3Ba%2Cb%2Cc%2Cd%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p_n(x;a,b,c,d)}"/> known as the continuous Hahn polynomials, with the parameters taking the particular values <img alt="{a=b=c=d=\frac{3}{4}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%3Db%3Dc%3Dd%3D%5Cfrac%7B3%7D%7B4%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a=b=c=d=\frac{3}{4}}"/>. Their main characterizing property is that they are orthogonal sequences of polynomials for two specific weight functions on <img alt="{\mathbb{R}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BR%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathbb{R}}"/>: the <img alt="{f_n(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_n%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_n(x)}"/> are orthogonal with respect to the weight function <img alt="{w_1(x)=\left|\Gamma\left(\frac34+ix\right)\right|^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw_1%28x%29%3D%5Cleft%7C%5CGamma%5Cleft%28%5Cfrac34%2Bix%5Cright%29%5Cright%7C%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{w_1(x)=\left|\Gamma\left(\frac34+ix\right)\right|^2}"/>, and the <img alt="{g_n(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg_n%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{g_n(x)}"/> are orthogonal with respect to <img alt="{w_2(x)=\left|\Gamma\left(\frac34+ix\right)\right|^4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw_2%28x%29%3D%5Cleft%7C%5CGamma%5Cleft%28%5Cfrac34%2Bix%5Cright%29%5Cright%7C%5E4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{w_2(x)=\left|\Gamma\left(\frac34+ix\right)\right|^4}"/>. Again, fairly esoteric. But interesting!</p>
<p>There are several things that make the expansions (3)–(4) well-behaved. First, the coefficients <img alt="{c_{2n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc_%7B2n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c_{2n}}"/>, <img alt="{d_{2n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd_%7B2n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d_{2n}}"/> are again positive. This actually seems pretty relevant for questions like RH: for example, if we consider “toy” versions of (1)–(3) in which the coefficient sequences <img alt="{a_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a_n}"/>, <img alt="{b_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{b_n}"/> and <img alt="{c_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c_n}"/> are replaced by the sequence <img alt="{\alpha^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha^n}"/> for fixed <img alt="{0&lt;\alpha&lt;1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%3C%5Calpha%3C1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0&lt;\alpha&lt;1}"/>, all three expansions sum up to rescaled cosines, which are entire functions that of course have only real zeros. (Without the <img alt="{(-1)^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28-1%29%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(-1)^n}"/> factor, we would get a hyperbolic cosine, which has imaginary zeros.)</p>
<p>Second, one can derive asymptotics for <img alt="{c_{2n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc_%7B2n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c_{2n}}"/> and <img alt="{d_{2n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd_%7B2n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d_{2n}}"/>, and they are quite a bit nicer than the asymptotic formulas for the Taylor and Hermite expansion coefficients. In my paper, I proved that <img alt="\displaystyle c_{2n} \sim A \sqrt{n} e^{-B \sqrt{n}}, \qquad d_{2n} \sim C n^{4/3} e^{-D n^{2/3}} \qquad \textrm{as }n\rightarrow\infty, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+c_%7B2n%7D+%5Csim+A+%5Csqrt%7Bn%7D+e%5E%7B-B+%5Csqrt%7Bn%7D%7D%2C+%5Cqquad+d_%7B2n%7D+%5Csim+C+n%5E%7B4%2F3%7D+e%5E%7B-D+n%5E%7B2%2F3%7D%7D+%5Cqquad+%5Ctextrm%7Bas+%7Dn%5Crightarrow%5Cinfty%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle c_{2n} \sim A \sqrt{n} e^{-B \sqrt{n}}, \qquad d_{2n} \sim C n^{4/3} e^{-D n^{2/3}} \qquad \textrm{as }n\rightarrow\infty, "/> where <img alt="{A,B,C,D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%2CB%2CC%2CD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A,B,C,D}"/> are the constants <img alt="\displaystyle A = 16\sqrt{2}\pi^{3/2}, \qquad B = 4\sqrt{\pi}, \qquad C = \frac{128 \times 2^{1/3} \pi^{2/3} e^{-2\pi /3}}{\sqrt{3}}, \qquad D = 3 (4\pi)^{1/3}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+A+%3D+16%5Csqrt%7B2%7D%5Cpi%5E%7B3%2F2%7D%2C+%5Cqquad+B+%3D+4%5Csqrt%7B%5Cpi%7D%2C+%5Cqquad+C+%3D+%5Cfrac%7B128+%5Ctimes+2%5E%7B1%2F3%7D+%5Cpi%5E%7B2%2F3%7D+e%5E%7B-2%5Cpi+%2F3%7D%7D%7B%5Csqrt%7B3%7D%7D%2C+%5Cqquad+D+%3D+3+%284%5Cpi%29%5E%7B1%2F3%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle A = 16\sqrt{2}\pi^{3/2}, \qquad B = 4\sqrt{\pi}, \qquad C = \frac{128 \times 2^{1/3} \pi^{2/3} e^{-2\pi /3}}{\sqrt{3}}, \qquad D = 3 (4\pi)^{1/3}. "/></p>
<p>Third, the expansions have some conceptual meaning: (3) turns out to be equivalent to the expansion of the elementary function <img alt="{\frac{d^2}{du^2} (u \coth(\pi u))}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7Bd%5E2%7D%7Bdu%5E2%7D+%28u+%5Ccoth%28%5Cpi+u%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\frac{d^2}{du^2} (u \coth(\pi u))}"/>, <img alt="{u&gt;0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u&gt;0}"/>, in an orthogonal basis of functions related to the Laguerre polynomials <img alt="{L_n^{1/2}(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_n%5E%7B1%2F2%7D%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_n^{1/2}(x)}"/>. And analogously, (4) arises out of the expansion of a certain auxiliary function <img alt="{\tilde{\nu}(u)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctilde%7B%5Cnu%7D%28u%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\tilde{\nu}(u)}"/> (I won’t define it here) in yet another classical family of orthogonal polynomials, the Chebyshev polynomials of the second kind.</p>
<p>Fourth (and fifth, sixth, …): the expansions are just… nice, in the sense that they arise in a way that seems natural when one asks certain questions, that they have excellent convergence properties, and that the coefficients <img alt="{c_{2n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc_%7B2n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c_{2n}}"/> and <img alt="{d_{2n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd_%7B2n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d_{2n}}"/> have several elegant formulas, each revealing something interesting about them. Read the paper to understand more.</p>
<p>I said I will get back to Pólya’s work on RH. This post is already quite long so I will say only a little bit about this. One of Pólya’s major discoveries was that there are operations on entire functions that (under certain mild assumptions) preserve the property of the function having only real zeros. Specifically this is the case for the operation of multiplying the Fourier transform of the function by the factor <img alt="{e^{\lambda u^2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Be%5E%7B%5Clambda+u%5E2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{e^{\lambda u^2}}"/> for <img alt="{\lambda&gt;0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\lambda&gt;0}"/>  (where <img alt="{u}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u}"/> is the frequency variable). This opens the way to defining a family of deformations <img alt="{\Xi_\lambda(t)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CXi_%5Clambda%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Xi_\lambda(t)}"/> of the Riemann xi function arising out of this operation, and trying to generalize RH by asking for which values of <img alt="{\lambda}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\lambda}"/> it is the case that <img alt="{\Xi_\lambda(t)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CXi_%5Clambda%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Xi_\lambda(t)}"/> has only real zeros. Since Pólya’s work, and important later extensions of it by De Bruijn and Newman, this has become a very active topic of research, nowadays referred to under the name of the De Bruijn-Newman constant.<br/>
See the recent survey of Newman and Wu [3], a 2018 paper by Rodgers and Tao [4] proving a major conjecture of Newman, and the recent paper [9] by the <a href="https://terrytao.wordpress.com/2018/12/28/polymath-15-eleventh-thread-writing-up-the-results-and-exploring-negative-t/">Polymath15 project</a> (mentioned by Gil in his <a href="https://gilkalai.wordpress.com/2019/02/28/dan-romik-studies-the-riemanns-zeta-function-and-other-zeta-news/">earlier post</a>), for the latest on this subject.</p>
<p>The connection I found between this topic and the idea of expanding the Riemann xi function in families of orthogonal polynomials is the following: expansions such as (2)–(4) suggest yet another natural way of “deforming” the Riemann xi function by adding a parameter <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/>: simply multiply the <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>th term in the expansion by <img alt="{\alpha^{2n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%5E%7B2n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha^{2n}}"/> (the linear operator that does this is called the Poisson kernel, and generalizes the standard Poisson kernel from complex analysis and the theory of harmonic functions). It turns out—and is actually easy to prove, and really isn’t terribly surprising in the grand scheme of things—that in the case of the Hermite expansion (2), this family of deformations is the same, up to some trivial reparametrization, as the family of deformations <img alt="{\Xi_\lambda(t)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CXi_%5Clambda%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Xi_\lambda(t)}"/> that was studied in connection with the work of Pólya, De Bruijn, Newman and their successors. A nice connection between two threads of research that were not previously recognized as being related to each other, I think. Furthermore, this suggests that the Poisson kernel and associated deformations may yet have an important role to play in the context of the new expansions in the orthogonal polynomial families <img alt="{f_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_n}"/> and <img alt="{g_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{g_n}"/>, where we get genuinely new families of deformations of the Riemann xi function. I explore this idea in my paper and it leads to some interesting things.</p>
<p>So let’s summarize. The key questions you are no doubt wondering about are: where does any of this lead? And do these new ideas say anything really useful or especially relevant for the Riemann hypothesis? The answer is that I don’t know (and I’m wondering about the same things). That being said, these orthogonal polynomial expansions seem quite interesting in their own right. The Riemann zeta function is a mysterious object, and there are <a href="https://en.wikipedia.org/wiki/Lindel%C3%B6f_hypothesis">other things</a> we wish to understand about it beside where its zeros are, so it’s always good to have additional points of view from which to approach it. Moreover, even on the question of the zeros there are reasons to be cautiously optimistic that this approach may have something useful to offer; see Chapter 7 of my paper for a brief discussion of why that is the case.</p>
<h2/>
<h2>References</h2>
<p>[1] D. Albers and G. L. Alexanderson, editors. Mathematical People: Profiles and Interviews. A K Peters, 2008.</p>
<p>[2] M. Griffin, K. Ono, L. Rolen and D. Zagier. Jensen polynomials for the Riemann zeta function and other sequences. Preprint (2019), <a href="https://arxiv.org/abs/1902.07321">arXiv:1902.07321</a>.</p>
<p>[3] C. M. Newman. Constants of de Bruijn-Newman type in analytic number theory and statistical physics. To appear in Bull. Amer. Math. Soc.</p>
<p>[4] B. Rodgers and T. Tao. The De Bruijn-Newman constant is nonnegative. Preprint (2018), <a href="https://arxiv.org/abs/1801.05914">arXiv:1801.05914</a>.</p>
<p>[5] D. Romik. <a href="https://arxiv.org/abs/1902.06330">Orthogonal polynomial expansions for the Riemann xi function</a>. Preprint (2019), <a href="https://arxiv.org/abs/1902.06330">arXiv:1902.06330</a>.</p>
<p>[6] P. Turán. Sur l’algèbre fonctionelle. Pages 279–290 in: Comptes Rendus du Premier Congrès des Mathématiciens Hongrois, 27 Août–2 Septembre 1950. Akadémiai Kiadó, 1952. Reprinted in Collected Papers of Paul Turán, Ed. P. Erdos, Vol. 1, pp. 677–688. Akadémiai Kiadó, 1990. An English translation of the paper by Dan Romik <a href="http://math.ucdavis.edu/~romik/data/uploads/misc/turan1952-english.pdf">On functional algebra</a>.</p>
<p>[7] P. Turán. Hermite-expansion and strips for zeros of polynomials. Arch. Math. 5 (1954), 148–152. Reprinted in Collected Papers of Paul Turán, Ed. P. Erdos, Vol. 1, pp. 738–742. Akadémiai Kiadó, 1990.</p>
<p>[8]  P. Turán. To the analytical theory of algebraic equations. Bulgar. Akad. Nauk. Otd. Mat. Fiz. Nauk. Izv. Mat. Inst. 3 (1959), 123–137. Reprinted in Collected Papers of Paul Turán, Ed. P. Erdos, Vol. 2, pp. 1080–1090. Akadémiai Kiadó, 1990.</p>
<p>[9] D.H.J. Polymath. Effective approximation of heat flow evolution of the Riemann ξ function, and a new upper bound for the de Bruijn-Newman constant. Preprint (2019), <a href="https://arxiv.org/abs/1904.12438">arXiv:1904.12438</a>.</p>
<h2>Notes:</h2>
<p>(1) Alexanderson writes in [1, p. 259]: “A week or so before he died, Pólya asked me to look on his desk at home for some papers on which he said he had written down some interesting ideas he had for proving RH. Of course I could find no such notes, but until the day he died he was thinking about that famous problem.”</p>
<p> </p>
<p>(2) Turán’s Hungarian Academy of Sciences talk was published in a rather obscure French-language paper [6] that seems to have been largely forgotten. It’s an interesting read nonetheless, and to make it more accessible to anyone who may be interested, I recently translated it to English.</p>
<p> </p>
<p>(3) Turán mentions in [8] that he discovered the results on the Hermite expansion in 1938–39, but they were not published until much later. Clearly this was not a convenient time in history for publishing such discoveries; Turán, a Hungarian Jew, spent much of World War II interned in labor camps in Hungary.</p></div>
    </content>
    <updated>2019-07-17T06:22:33Z</updated>
    <published>2019-07-17T06:22:33Z</published>
    <category term="Combinatorics"/>
    <category term="Guest blogger"/>
    <category term="Number theory"/>
    <category term="Dan Romik"/>
    <category term="George Polya"/>
    <category term="Paul Turan"/>
    <category term="Riemann Hypothesis"/>
    <category term="Riemann zeta function"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-07-22T09:20:54Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16114</id>
    <link href="https://rjlipton.wordpress.com/2019/07/16/summer-reading-in-theory/" rel="alternate" type="text/html"/>
    <title>Summer Reading in Theory</title>
    <summary>Some formative books in mathematics and computing theory LSE source: “Calculus on Clay?” Norman Biggs is the author of the wonderful book Algebraic Graph Theory. Both Ken and I read it long ago, and both of us have it out now because of its relevance to Hao Huang’s beautiful short proof of the Boolean Sensitivity […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Some formative books in mathematics and computing theory</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2019/07/biggs-norman-150x150.jpg"><img alt="" class="alignright size-full wp-image-16115" src="https://rjlipton.files.wordpress.com/2019/07/biggs-norman-150x150.jpg?w=600"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">LSE <a href="https://blogs.lse.ac.uk/maths/2016/04/15/norman-biggs-calculus-on-clay/">source</a>: <i>“Calculus on Clay?”</i></font></td>
</tr>
</tbody>
</table>
<p>
Norman Biggs is the author of the wonderful <a href="https://www.cambridge.org/core/books/algebraic-graph-theory/6C70471342F19680068C35EF174075DC">book</a> <em>Algebraic Graph Theory</em>. Both Ken and I read it long ago, and both of us have it out now because of its relevance to Hao Huang’s beautiful short <a href="http://www.mathcs.emory.edu/~hhuan30/papers/sensitivity_1.pdf">proof</a> of the Boolean Sensitivity Conjecture. </p>
<p>
Today we wish to ask, <i>What are your top five favorite books on mathematics and theory for summer reading?</i></p>
<p>
There’s an <a href="https://en.wikipedia.org/wiki/Aporia">aporia</a> in that question. A working definition of aporia is: “a self-contradiction that isn’t.” The point is that books for summer reading should be new, so how would you already know which are your favorites? Well, we are thinking of books that are so rich you can always find new things in them—and that also played formative roles earlier in our careers.</p>
<p>
Ken knew Biggs during his first year at Oxford when Biggs was visiting there from London. He took part in a weekly sitting-room seminar organized by Peter Neumann. Biggs’s book was a central reference for Ken’s undergraduate senior thesis at Princeton, and both he and Ken presented material based on it. </p>
<p>
</p><p/><h2> Best Five Books—Dick </h2><p/>
<p/><p>
Here are my votes for all-time best books in mathematics and in computer science theory.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <a href="https://www.cambridge.org/core/books/algebraic-graph-theory/6C70471342F19680068C35EF174075DC"><i>Algebraic Graph Theory</i></a>, by Norman Biggs. A wonderful book. First appeared in 1974.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <a href="https://www.amazon.com/Introduction-Probability-Theory-Applications-Vol/dp/0471257087/ref=sr_1_1?keywords=William+Feller&amp;qid=1563190401&amp;s=books&amp;sr=1-1"><i> An Introduction to Probability Theory and Its Applications, Vol. 1</i></a>, by William Feller. This is the book I used to learn probability theory.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <a href="https://www.amazon.com/gp/product/0199219869/ref=as_li_tl?ie=UTF8&amp;tag=mathblog05-20&amp;camp=1789&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=0199219869&amp;linkId=a71963a143733e948f50588526d624c0"><i> An Introduction to the Theory of Numbers</i></a>, by Godfrey Hardy and Edward Wright. Now updated by Andrew Wiles, Roger Heath-Brown, and Joseph Silverman. </p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <a href="https://www.amazon.com/Elements-Number-Theory-Dover-Mathematics/dp/0486781658/ref=sr_1_1?keywords=Vinogradov&amp;qid=1563190340&amp;s=books&amp;sr=1-1"><i>Elements of Number Theory</i></a>, by Ivan Vinogradov. Another small book that is loaded with ideas. </p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <a href="https://www.abebooks.com/Paul-Erds-Art-Counting-Erdos-Joel/13380002114/bd"><i>The Art of Counting</i></a>, by Paul Erdős and Joel Spencer. This book changed my life. Today the book is of course <a href="https://www.amazon.com/dp/0470170204/?tag=stackoverfl08-20"><i>The Probabilistic Method</i></a>, by Noga Alon and Joel Spencer. </p>
<p>
</p><p/><h2> Best Five Books—Ken </h2><p/>
<p/><p>
Ken reaches back to his teen years but it’s still the same span of years as my list. Here he tells it:</p>
<p>
<img alt="{\bullet}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet}"/> All books by Martin Gardner—in particular, the books of collections of his “Mathematical Games” columns in <em>Scientific American</em>. Here is an <a href="https://blogs.scientificamerican.com/guest-blog/the-top-10-martin-gardner-scientific-american-articles/">overview</a>.</p>
<p>
<img alt="{\bullet}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet}"/> <a href="https://www.lybrary.com/scarne-on-dice-p-655.html"><i>Scarne on Dice</i></a> and <a href="https://www.lybrary.com/scarne-on-cards-p-759.html"><i> Scarne on Cards</i></a>. Originally it was neither of these books—nor John Scarne’s <em>Complete Guide to Gambling</em>—but a different book on in which both Scarne and Gardner figured prominently. Alas I, Ken, cannot trace it. That’s what I used to learn probability theory.</p>
<p>
<img alt="{\bullet}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet}"/> <a href="https://www.amazon.com/Spectra-Graphs-Application-Applied-Mathematics/dp/0121951502"><i>Spectra of Graphs</i></a>, by Dragoš Cvetković, Michael Doob, and Horst Sachs. I could put Biggs’s book here, but this is the one that got me on to the whole subject just before my senior year at Princeton. It was fresh out in 1980—I recall the tactile sensation of the dark green spanking new cover in the Fine Hall Library’s copy. A great book with pictures and algebra. </p>
<p>
<img alt="{\bullet}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet}"/> <a href="https://www.amazon.com/Ideals-Varieties-Algorithms-Computational-Undergraduate/dp/0387356509"><i> Ideals, Varieties, and Algorithms</i></a>, by David Cox, John Little, and Donal O’Shea. Fast forward to 1997. Having realized that techniques from algebraic geometry could surmount the “Natural Proofs” <a href="https://rjlipton.wordpress.com/2009/03/25/whos-afraid-of-natural-proofs/">barrier</a> (see also <a href="https://en.wikipedia.org/wiki/Geometric_complexity_theory">GCT</a>), I went whole-hog after it. See “Manic Monomials” in this <a href="https://rjlipton.wordpress.com/2012/07/04/july-fourth-sale-of-ideas/">post</a> for one thing that tripped it up. The book remains incredibly stimulating. It has a <a href="https://www.amazon.com/Using-Algebraic-Geometry-Graduate-Mathematics/dp/0387984879/">sequel</a>, <em>Using Algebraic Geometry</em>.</p>
<p>
<img alt="{\bullet}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet}"/> <a href="https://en.wikipedia.org/wiki/Quantum_Computation_and_Quantum_Information"><i>Quantum Computation and Quantum Information</i></a> by Michael Nielsen and Isaac Chuang. As with Hardy and Wright, it has its own Wikipedia page. Dick and I can say this is nominating a competitor, but Chaung &amp; Nielsen is really in a class by itself for the sheer richness and writing style. One odd mark of its influence: In 2006 when I reacted to the sensational and frightening accusations of cheating at the world championship <a href="https://en.wikipedia.org/wiki/World_Chess_Championship_2006">match</a>, my first thought was to apply distributional distance measures of the kind used in its later chapters. Among such measures is (quantum) <a href="https://en.wikipedia.org/wiki/Fidelity_of_quantum_states">fidelity</a>, and although I focused more on Jensen-Shannon divergence before deciding on simpler stuff, my chess research <a href="https://cse.buffalo.edu/~regan/chess/fidelity/">website</a> retains “fidelity” in its name as part of a multi-way reference to <a href="https://en.wikipedia.org/wiki/FIDE">FIDE</a>, faith, and playing in good faith.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
What books most influenced you? What are your votes for the best books that might influence others?	 </p></font></font></div>
    </content>
    <updated>2019-07-17T04:26:38Z</updated>
    <published>2019-07-17T04:26:38Z</published>
    <category term="All Posts"/>
    <category term="History"/>
    <category term="Ideas"/>
    <category term="Oldies"/>
    <category term="Teaching"/>
    <category term="algebraic"/>
    <category term="books"/>
    <category term="Hao Huang"/>
    <category term="Norman Biggs"/>
    <category term="probabilistic"/>
    <category term="spectral graph theory"/>
    <category term="summer reading"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-07-22T09:21:02Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-6069637759837834972</id>
    <link href="https://blog.computationalcomplexity.org/feeds/6069637759837834972/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/07/guest-post-by-samir-khuller-on.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/6069637759837834972" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/6069637759837834972" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/07/guest-post-by-samir-khuller-on.html" rel="alternate" type="text/html"/>
    <title>Guest post by Samir Khuller on attending The TCS Women 2019 meeting</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><br/>
(I will post the solution to the problem in the last blog later in the week---probably Thursday. Meanwhile, enjoy these thoughts from Samir Khuller on the TCS Women 2019 meeting.)<br/>
<br/>
Guest Post by Samir Khuller:<br/>
<br/>
Am I even allowed here?” was the first thought that crossed my mind when I entered the room. It was packed with women (over 95%), however a few minutes later, several men had trickled in. I was at the TCS Women spotlight workshop on the day before STOC. Kudos to Barna Saha, Sofya Raskhodnikova, and Virginia Vassilevska Williams for putting this grand (and long needed) event together, which serves as a role model and showcases some of the recent work by rising stars. In addition to the Sun afternoon workshop, the event was followed by both an all women panel and a poster session (which I sadly did not attend).<br/>
<br/>
<br/>
The rising stars talks were given by Naama Ben-David (CMU), Andrea Lincoln (MIT), Debarati Das (Charles University) and Oxana Poburinnaya (Boston U). After a short break the inspirational talk was by Ronitt Rubinfeld from MIT.  Ronitt’s talk was on the topic of Program Checking, but she made it inspirational by putting us in her shoes as a young graduate student, three decades back, trying to make a dent in research by working on something that her advisor Manuel Blum, and his senior graduate student Sampath Kannan had been working on, and I must say she made a pretty big dent in the process! She also related those ideas to other pieces of work done since in a really elegant manner and how these pieces of work lead to work on property testing.<br/>
<br/>
<br/>
I am delighted to say that NSF supported the workshop along with companies such as Amazon, Akamai, Google and Microsoft. SIGACT plans to be a major sponsor next year.<br/>
<br/>
<br/>
The Full program for the workshop is at the following URL<a href="https://sigact.org/tcswomen/tcs-women-2019/">here.</a><br/>
<br/></div>
    </content>
    <updated>2019-07-16T23:38:00Z</updated>
    <published>2019-07-16T23:38:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-07-22T09:08:53Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/094</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/094" rel="alternate" type="text/html"/>
    <title>TR19-094 |  Rainbow coloring hardness via low sensitivity polymorphisms | 

	Venkatesan Guruswami, 

	Sai Sandeep</title>
    <summary>A $k$-uniform hypergraph is said to be $r$-rainbow colorable if there is an $r$-coloring of its vertices such that every hyperedge intersects all $r$ color classes. Given as input such a hypergraph, finding a $r$-rainbow coloring of it is NP-hard for all $k \ge 3$ and $r \ge 2$. Therefore, one settles for finding a rainbow coloring with fewer colors (which is an easier task).  When $r=k$ (the maximum possible value), i.e., the hypergraph is $k$-partite, one can efficiently $2$-rainbow color the hypergraph, i.e., $2$-color its vertices so that there are no monochromatic edges. In this work we consider the next smaller value of $r=k-1$, and prove that in this case it is NP-hard to rainbow color the hypergraph with $q :=  \lceil \frac{k-2}{2} \rceil$ colors. In particular, for $k \le 6$, it is NP-hard to $2$-color $(k-1)$-rainbow colorable $k$-uniform hypergraphs.

Our proof follows the algebraic approach to promise constraint satisfaction problems. It proceeds by characterizing the polymorphisms associated with the approximate rainbow coloring problem, which are rainbow colorings of some product hypergraphs on vertex set $[r]^n$. We prove that any such polymorphism $f: [r]^n \to [q]$ must be $C$-fixing, i.e., there is a small subset $S$ of $C$ coordinates and a setting $a \in [q]^S$ such that fixing $x_{|S} = a$ determines the value of $f(x)$. The key step in our proof is bounding the sensitivity of certain rainbow colorings, thereby arguing that they must be juntas. Armed with the $C$-fixing characterization, our NP-hardness is obtained via a reduction from smooth Label Cover.</summary>
    <updated>2019-07-16T01:19:56Z</updated>
    <published>2019-07-16T01:19:56Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-07-22T09:20:47Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/093</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/093" rel="alternate" type="text/html"/>
    <title>TR19-093 |  Improved 3LIN Hardness via Linear Label Cover | 

	Euiwoong Lee, 

	Subhash Khot, 

	Prahladh Harsha, 

	Devanathan Thiruvenkatachari</title>
    <summary>We prove that for every constant $c$ and $\epsilon = (\log n)^{-c}$, there is no polynomial time algorithm that when given an instance of 3LIN with $n$ variables where an $(1 - \epsilon)$-fraction of the clauses are satisfiable, finds an assignment that satisfies at least $(\frac{1}{2} + \epsilon)$-fraction of clauses unless $\mathbf{NP} \subseteq \mathbf{BPP}$. The previous best hardness using a polynomial time reduction achieves $\epsilon = (\log \log n)^{-c}$, which is obtained by the Label Cover hardness of Moshkovitz and Raz [J. ACM, 57(5), 2010] followed by the reduction from Label Cover to 3LIN of Hastad [J. ACM, 48(4):798--859, 2001].

Our main idea is to prove a hardness result for Label Cover similar to Moshkovitz and Raz where each projection has a linear structure. This linear structure of Label Cover allows us to use Hadamard codes instead of long codes, making the reduction more efficient. For the hardness of Linear Label Cover, we follow the work of Dinur and Harsha [SIAM J. Comput., 42(6):2452--2486, 2013] that simplified the construction of Moshkovitz and Raz, and observe that running their reduction from a hardness of the problem LIN (of unbounded arity) instead of the more standard problem of solving quadratic equations ensures the linearity of the resultant Label Cover.</summary>
    <updated>2019-07-16T01:10:59Z</updated>
    <published>2019-07-16T01:10:59Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-07-22T09:20:47Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/07/15/linkage</id>
    <link href="https://11011110.github.io/blog/2019/07/15/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>Turkey has charged over 700 academics with terrorism for signing a peace petition (). Among the most severely penalized is Tuna Altınel, a mathematician in France who was arrested visiting family in Turkey, and who has now been imprisoned for over 50 days (via).</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><ul>
  <li>
    <p><a href="https://www.insidehighered.com/news/2019/07/01/about-700-academics-have-been-criminally-charged-turkey-their-signatures-petition">Turkey has charged over 700 academics with terrorism for signing a peace petition</a> (<a href="https://mathstodon.xyz/@11011110/102367088461002886"/>). Among the most severely penalized is <a href="https://en.wikipedia.org/wiki/Tuna_Alt%C4%B1nel">Tuna Altınel</a>, a mathematician in France who was arrested visiting family in Turkey, and who <a href="http://math.univ-lyon1.fr/SoutienTunaAltinel/?lang=en">has now been imprisoned for over 50 days</a> (<a href="https://cameroncounts.wordpress.com/2019/05/31/tuna-altnel/">via</a>).</p>
  </li>
  <li>
    <p><a href="http://web.cs.elte.hu/~lovasz/bookxx/geomgraphbook/geombook2019.01.11.pdf">László Lovász’s book “Graphs and Geometry”, on geometric representations of graphs</a> (<a href="https://mathstodon.xyz/@11011110/102374639115017977"/>, <a href="https://news.ycombinator.com/item?id=20317825">via</a>). <a href="https://bookstore.ams.org/coll-65">The print version</a> should appear in a month or so from the AMS.</p>
  </li>
  <li>
    <p><a href="https://www.insidehighered.com/quicktakes/2019/06/28/huge-budget-cut-university-alaska">University of Alaska budget gutted by 40%</a> (<a href="https://mathstodon.xyz/@11011110/102381510293748063"/>, <a href="https://www.metafilter.com/181768/We-dont-need-no-stinkin-edumaction">see also</a>). The total amount cut over the past five years (including this new biggest cut) is <a href="https://www.chronicle.com/article/Unprecedented-in-Our/246596">more like 63%, from $522M to $192M</a>. And <a href="https://www.npr.org/2019/07/03/738569508/university-of-alaska-readies-for-budget-slash-we-may-likely-never-recover">the likely response is to close one of its three main campuses and all 13 smaller community campuses</a>. Ironically, the cause is right-wing insistence on a universal basic income of $3000/person from fuel extraction revenues.</p>
  </li>
  <li>
    <p><a href="https://aperiodical.com/category/the-big-internet-math-off/">The annual Big Internet Math-off — view and vote on your favorites!</a> (<a href="https://mathstodon.xyz/@11011110/102385386477969762"/>). 
The first few matches include <a href="https://aperiodical.com/2019/07/the-big-internet-math-off-2019-group-1-alex-corner-vs-lucy-rycroft-smith/">commutativity of log-exponentiation vs weather infovis</a>, the <a href="https://aperiodical.com/2019/07/the-big-internet-math-off-2019-group-2-marianne-rachel-vs-vincent-pantaloni/">geometry of the Sydney Opera House vs straight lines on a donut</a>, <a href="https://aperiodical.com/2019/07/the-big-internet-math-off-2019-group-3-vicky-neale-vs-jim-propp/">multiplication tables and muffins</a> and <a href="https://aperiodical.com/2019/07/the-big-internet-math-off-2019-group-4-colin-beveridge-vs-kyle-d-evans/">a video on shapes in La Sagrada Familia (shot on location?!) vs an introduction to fractals</a>. More daily for roughly a month.</p>
  </li>
  <li>
    <p><a href="https://www.scmp.com/magazines/post-magazine/long-reads/article/3016267/chinese-scientists-guilty-researching-while">Chinese scientists guilty of “researching while Asian” in Trump’s America</a> (<a href="https://mathstodon.xyz/@11011110/102390640744960409"/>, <a href="https://news.ycombinator.com/item?id=20319936">via</a>, <a href="https://www.bloomberg.com/news/features/2019-06-13/the-u-s-is-purging-chinese-americans-from-top-cancer-research">see also</a>). The story focuses on star cancer researcher <a href="https://en.wikipedia.org/wiki/Xifeng_Wu">Xifeng Wu</a>, forced to resign from the University of Texas, apparently because she fostered collaboration with Chinese cancer research institutions at the behest of her higher administration.</p>
  </li>
  <li>
    <p><a href="https://mathstodon.xyz/@ccppurcell/102133405425258779">Chris Purcell thinks about graphs with degree sequence </a>. They have to have at least one cycle of each parity.</p>
  </li>
  <li>
    <p><a href="https://petapixel.com/2019/07/05/goodbye-aberration-physicist-solves-2000-year-old-optical-problem/">A formula for designing lenses with no spherical aberration</a> (<a href="https://mathstodon.xyz/@11011110/102401888807980335"/>, <a href="https://news.ycombinator.com/item?id=20369960">via</a>). This seems to have little practical value as there was already a numerical solution, and I don’t think it handles chromatic aberration, but it’s interesting that there is an analytic formula for these shapes.</p>
  </li>
  <li>
    <p>Last week I traveled to Milan for the <a href="https://sgp2019.di.unimi.it/">Symposium on Geometry Processing</a> (<a href="https://mathstodon.xyz/@11011110/102407039766140849"/>). They also have an <a href="https://twitter.com/geometryprocess">official twitter stream</a>, mostly consisting of event photos. The sightseeing highlight of my trip was seeing pages of <a href="https://www.ambrosiana.it/en/discover/codex-atlanticus/">Da Vinci’s Codex Atlanticus at the Ambrosian Library</a>.</p>
  </li>
  <li>
    <p><a href="https://boingboing.net/2019/07/08/check-out-this-cool-synthesize.html">Evoboxx</a> (<a href="https://mathstodon.xyz/@11011110/102412280507996705"/>), a retro-styled portable device that does only two things: run Conway’s Game of Life and generate sounds from it. Not very practical in these days of cell phones but then maybe that’s what makes it a fun project.</p>
  </li>
  <li>
    <p><a href="http://jdh.hamkins.org/modal-model-theory/">Modal model theory</a> (<a href="https://mathstodon.xyz/@11011110/102418646790775178"/>). For graphs, this extends first order logic (where the only quantification is over vertices and the only predicate is adjacency) with operators  and .  is true when all supergraphs model  and  is true when at least one supergraph models . This can express nontrivial graph properties like -colorability, and comes in two variants depending on whether you can quantify outside the operators.</p>
  </li>
  <li>
    <p><a href="https://www.instagram.com/p/ByH-R4Ql-NA/">Very quick video tutorial on how to make the Miura-ori fold</a>, by Polly Verity (<a href="https://mathstodon.xyz/@11011110/102429787082169299"/>, <a href="https://www.thisiscolossal.com/2019/07/new-polly-verity/">via</a>).</p>
  </li>
  <li>
    <p><a href="http://jtra.cz/stuff/essays/math-self-reference-smooth/index.html">Trávník’s smooth self-referential formula</a> (<a href="https://mathstodon.xyz/@11011110/102435762025301458"/>, <a href="https://twitter.com/johncarlosbaez/status/1141376710551601152">via</a>). It is actually a linked set of formulas, described in a typeset image, that when plotted as described in the image produces the image itself. It follows the same ideas as earlier self-referential formulas like <a href="https://en.wikipedia.org/wiki/Tupper%27s_self-referential_formula">Tupper’s self-referential formula</a> but unlike them describes a smooth vector image based on splines instead of a pixelated bitmap.</p>
  </li>
  <li>
    <p><a href="http://muurformules.nl/">Leiden wall formulas</a> (<a href="https://mathstodon.xyz/@11011110/102444110227078604"/>). The last time I was in Leiden they were decorating the exterior walls of all their buildings with poems of many different languages. Now they’ve moved on to the language of mathematics.</p>
  </li>
  <li>
    <p><a href="https://www.youtube.com/watch?v=eYfpSAxGakI">Numberphile video on Dehn invariants</a> (15-minutes; <a href="https://mathstodon.xyz/@11011110/102448538574760818"/>). The Dehn invariant is a value derived from a polyhedron that doesn’t change if you cut up the polyhedron into smaller polyhedral pieces and rearrange them into a different polyhedron. It’s 0 for the cube and nonzero for other Platonic solids, proving that they can’t be cut and rearranged into a cube. See <a href="https://en.wikipedia.org/wiki/Dehn_invariant">the Wikipedia article</a> for more technical details.</p>
  </li>
</ul></div>
    </content>
    <updated>2019-07-15T21:57:00Z</updated>
    <published>2019-07-15T21:57:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-07-16T04:58:02Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=16778</id>
    <link href="https://gilkalai.wordpress.com/2019/07/15/itai-benjamini-and-jeremie-brieussel-noise-sensitivity-meets-group-theory/" rel="alternate" type="text/html"/>
    <title>Itai Benjamini and Jeremie Brieussel: Noise Sensitivity Meets Group Theory</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">The final  version of my ICM 2018 paper Three puzzles on mathematics computation and games is available for some time. (This proceeding’s version unlike the arXived version has a full list of references.)  In this post I would like to … <a href="https://gilkalai.wordpress.com/2019/07/15/itai-benjamini-and-jeremie-brieussel-noise-sensitivity-meets-group-theory/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The final  version of my ICM 2018 paper <a href="https://gilkalai.files.wordpress.com/2019/07/main-pf.pdf">Three puzzles on mathematics computation and games</a> is available for some time. (This proceeding’s version unlike the arXived version has a full list of references.)  In this post I would like to advertise one problem that I mentioned in the paper. You can read more about it in the paper  by Itai Benjamini and  Jeremie Brieussel  <a href="https://arxiv.org/abs/1901.03617">Noise sensitivity of random walks on groups</a> and learn about it also from the videotaped lecture by Jeremie. BTW, the name of my ICM paper is a tribute to Avi Wigdeson’s great book <strong><a href="https://www.math.ias.edu/files/Website03-25-19.pdf#page=1" target="&#x201D;_blank&#x201D;">Mathematics and Computation</a> </strong>(see <a href="https://gilkalai.wordpress.com/2017/10/27/must-read-book-by-avi-wigderson/">this post</a>). Click on the title for an  almost final draft of Avi’s book (March, 25, 2019) soon to be published by Princeton University Press<strong>. </strong>(We are negotiating with Avi on showing here first how the cover of his book will look like.)</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/07/friends-of-noise.png"><img alt="" class="alignnone size-full wp-image-17590" height="381" src="https://gilkalai.files.wordpress.com/2019/07/friends-of-noise.png?w=640&amp;h=381" width="640"/></a></p>
<p><a href="http://friendsofnoise.org/about/">source</a></p>
<h2>The problem of Benjamini and Brieussel and their conjecture</h2>
<p> </p>
<p/>
<p>Consider an <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>-step simple random walk (SRW) <img alt="X_n" class="latex" src="https://s0.wp.com/latex.php?latex=X_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X_n"/> on a Cayley graph of a finitely generated infinite group <img alt="\Gamma" class="latex" src="https://s0.wp.com/latex.php?latex=%5CGamma&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Gamma"/>. Refresh independently each step with probability <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon"/>, to get <img alt="Y_n" class="latex" src="https://s0.wp.com/latex.php?latex=Y_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y_n"/> from <img alt="X_n" class="latex" src="https://s0.wp.com/latex.php?latex=X_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X_n"/>. Are there groups for which at time <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> the positions <img alt="X_n" class="latex" src="https://s0.wp.com/latex.php?latex=X_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X_n"/> and <img alt="Y_n" class="latex" src="https://s0.wp.com/latex.php?latex=Y_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y_n"/> are asymptotically independent? That is, does the <img alt="l_1" class="latex" src="https://s0.wp.com/latex.php?latex=l_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="l_1"/> (total variation) distance between the chain <img alt="(X_n, Y_n)" class="latex" src="https://s0.wp.com/latex.php?latex=%28X_n%2C+Y_n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(X_n, Y_n)"/> and two independent copies <img alt="(X'_n, X''_n)" class="latex" src="https://s0.wp.com/latex.php?latex=%28X%27_n%2C+X%27%27_n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(X'_n, X''_n)"/> go to 0, as <img alt="n \to \infty" class="latex" src="https://s0.wp.com/latex.php?latex=n+%5Cto+%5Cinfty&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n \to \infty"/>?</p>
<p>Note that on the line <img alt="\mathbb Z" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+Z&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb Z"/>, they are uniformally correlated, and therefore also on any group with a nontrivial homomorphism to <img alt="\mathbb R" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb R"/>, or on any group that has a finite index subgroup with a nontrivial homomorphism to <img alt="\mathbb R" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb R"/>. On the free group and for any non-Liouville group, <img alt="X_n" class="latex" src="https://s0.wp.com/latex.php?latex=X_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X_n"/> and <img alt="Y_n" class="latex" src="https://s0.wp.com/latex.php?latex=Y_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y_n"/> are correlated as well, but for a different reason: both <img alt="X_n" class="latex" src="https://s0.wp.com/latex.php?latex=X_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X_n"/> and <img alt="Y_n" class="latex" src="https://s0.wp.com/latex.php?latex=Y_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y_n"/> have a nontrivial correlation with <img alt="X_1" class="latex" src="https://s0.wp.com/latex.php?latex=X_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X_1"/>.</p>
<p>Itai Benjamini and Jeremie Brieussel conjecture that these are the only ways not to be noise sensitive. That is, if a Cayley graph is Liouville and the group does not have a finite index subgroup with a homomorphism to the reals, then the Cayley graph is noise sensitive for the simple random walk. In particular, the Grigorchuk group is noise sensitive for the simple random walk!</p>
<h3>A paragraph of philosophical nature from Benjamini and Brieussel’s paper.</h3>
<p>“Physically, an <em>ℓ</em><img alt="^1" class="latex" src="https://s0.wp.com/latex.php?latex=%5E1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="^1"/>-noise sensitive process can somewhat not be observed, since the observation <img alt="Y^\rho_n" class="latex" src="https://s0.wp.com/latex.php?latex=Y%5E%5Crho_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y^\rho_n"/> does not provide any significant information on the actual output <img alt="X_n" class="latex" src="https://s0.wp.com/latex.php?latex=X_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X_n"/>. Speculatively, this could account for the rarity of Liouville groups in natural science. Indeed besides virtually nilpotent ones, all known Liouville groups are genuinely mathematical objects .”</p>
<h3>Polytope integrality gap: An update</h3>
<p>An update on polytope integrality gap:  In my ICM paper and also in <a href="https://gilkalai.wordpress.com/2018/01/21/hardness-of-approximating-vertex-cover-polytope-integrality-gap-the-alswede-kachaterian-theorem-and-more/">this post</a>  I asked the beautiful problem that I learned from Anna Karlin if for vertex cover for every graph G and every vector of weights, there is an efficient algorithm achieving the “polytope integrality gap”.  Anna Karlin kindly informed me that <a href="https://www2.isye.gatech.edu/~msingh94/publications.html">Mohit Singh</a> got in touch with her after seeing the conjecture on my blog and pointed out that the hope for approximating the polytope integrality gap for vertex cover is unlikely to be possible because of its relationship to fractional chromatic number. Mohit noted that fractional chromatic number is hard to approximate even when it is constant assuming UGC. I still think that  the notion of polytope integrality gap for vertex cover as well as for more general problems is important and worth further study.</p>
<p> </p>
<p> </p></div>
    </content>
    <updated>2019-07-15T08:13:08Z</updated>
    <published>2019-07-15T08:13:08Z</published>
    <category term="Algebra"/>
    <category term="Combinatorics"/>
    <category term="Probability"/>
    <category term="Itai Benjamini"/>
    <category term="Jeremie Brieussel"/>
    <category term="Noise-sensitivity"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-07-22T09:20:53Z</updated>
    </source>
  </entry>
</feed>
