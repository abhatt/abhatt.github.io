<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2019-01-10T04:22:53Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1901.02871</id>
    <link href="http://arxiv.org/abs/1901.02871" rel="alternate" type="text/html"/>
    <title>The Lingering of Gradients: How to Reuse Gradients over Time</title>
    <feedworld_mtime>1547078400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Allen=Zhu:Zeyuan.html">Zeyuan Allen-Zhu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Simchi=Levi:David.html">David Simchi-Levi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Xinshang.html">Xinshang Wang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1901.02871">PDF</a><br/><b>Abstract: </b>Classically, the time complexity of a first-order method is estimated by its
number of gradient computations. In this paper, we study a more refined
complexity by taking into account the "lingering" of gradients: once a gradient
is computed at $x_k$, the additional time to compute gradients at
$x_{k+1},x_{k+2},\dots$ may be reduced.
</p>
<p>We show how this improves the running time of gradient descent and SVRG. For
instance, if the "additional time" scales linearly with respect to the traveled
distance, then the "convergence rate" of gradient descent can be improved from
$1/T$ to $\exp(-T^{1/3})$. On the empirical side, we solve a hypothetical
revenue management problem on the Yahoo! Front Page Today Module application
with 4.6m users to $10^{-6}$ error (or $10^{-12}$ dual error) using 6 passes of
the dataset.
</p></div>
    </summary>
    <updated>2019-01-10T02:33:14Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-01-10T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1901.02857</id>
    <link href="http://arxiv.org/abs/1901.02857" rel="alternate" type="text/html"/>
    <title>Fragile Complexity of Comparison-Based Algorithms</title>
    <feedworld_mtime>1547078400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Afshani:Peyman.html">Peyman Afshani</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fagerberg:Rolf.html">Rolf Fagerberg</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hammer:David.html">David Hammer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jacob:Riko.html">Riko Jacob</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kostitsyna:Irina.html">Irina Kostitsyna</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Meyer:Ulrich.html">Ulrich Meyer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Penschuck:Manuel.html">Manuel Penschuck</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sitchinava:Nodari.html">Nodari Sitchinava</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1901.02857">PDF</a><br/><b>Abstract: </b>We initiate a study of algorithms with a focus on the computational
complexity of individual elements, and introduce the fragile complexity of
comparison-based algorithms as the maximal number of comparisons any individual
element takes part in. We give a number of upper and lower bounds on the
fragile complexity for fundamental problems, including Minimum, Selection,
Sorting and Heap Construction. The results include both deterministic and
randomized upper and lower bounds, and demonstrate a separation between the two
settings for a number of problems. The depth of a comparator network is a
straight-forward upper bound on the worst case fragile complexity of the
corresponding fragile algorithm. We prove that fragile complexity is a
different and strictly easier property than the depth of comparator networks,
in the sense that for some problems a fragile complexity equal to the best
network depth can be achieved with less total work and that with randomization,
even a lower fragile complexity is possible.
</p></div>
    </summary>
    <updated>2019-01-10T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-01-10T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1901.02823</id>
    <link href="http://arxiv.org/abs/1901.02823" rel="alternate" type="text/html"/>
    <title>An Elastic Energy Minimization Framework for Mean Contour Calculation</title>
    <feedworld_mtime>1547078400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Jozsef Molnar, Michael Barbier, Winnok H. De Vos, Peter Horvath <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1901.02823">PDF</a><br/><b>Abstract: </b>In this paper we propose a contour mean calculation and interpolation method
designed for averaging manual delineations of objects performed by experts and
interpolate 3D layer stack images. The proposed method retains all visible
information of the input contour set: the relative positions, orientations and
size, but allows invisible quantities - parameterization and the centroid - to
be changed. The chosen representation space - the position vector rescaled by
square root velocity - is a real valued vector space on which the imposed L2
metric is used to define the distance function. With respect to this
representation the re-parameterization group acts by isometries and the
distance has well defined meaning: the sum of the central second moments of the
coordinate functions. To identify the optimal re-parameterization system and
proper centroid we use double energy minimization realized in a variational
framework.
</p></div>
    </summary>
    <updated>2019-01-10T02:36:06Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-01-10T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1901.02778</id>
    <link href="http://arxiv.org/abs/1901.02778" rel="alternate" type="text/html"/>
    <title>On NP-completeness of the cell formation problem</title>
    <feedworld_mtime>1547078400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Mikhail V. Batsyn, Ekaterina K. Batsyna, Ilya S. Bychkov <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1901.02778">PDF</a><br/><b>Abstract: </b>In the current paper we provide a proof of NP-completeness for the CFP
problem with the fractional grouping efficacy objective. For this purpose we
first consider the CFP with the linear objective minimizing the total number of
exceptions and voids. Following the ideas of Pinheiro et al. (2016) we show
that it is equivalent to the Bicluster Graph Editing Problem (BGEP), which is
known to be NP-complete (Amit, 2004). Then we suggest a reduction of the CFP
problem with the linear objective function to the CFP with the grouping
efficacy objective.
</p></div>
    </summary>
    <updated>2019-01-10T02:25:59Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-01-10T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1901.02771</id>
    <link href="http://arxiv.org/abs/1901.02771" rel="alternate" type="text/html"/>
    <title>Sweep Algorithms for the Capacitated Vehicle Routing Problem with Structured Time Window</title>
    <feedworld_mtime>1547078400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Christoph Hertrich, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hungerl=auml=nder:Philipp.html">Philipp Hungerländer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Truden:Christian.html">Christian Truden</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1901.02771">PDF</a><br/><b>Abstract: </b>The capacitated Vehicle Routing Problem with structured Time Windows
(cVRPsTW) is concerned with finding optimal tours for vehicles with given
capacity constraints to deliver goods to customers within assigned time
windows. In our problem variant these time windows have a special structure,
namely they are non-overlapping and each time window holds several customers.
This is a reasonable assumption for Attended Home Delivery services. Sweep
algorithms are known as simple, yet effective heuristics for the classical
capacitated Vehicle Routing Problem. We propose variants of the sweep algorithm
that are not only able to deal with time windows, but also exploit the
additional structure of the time windows in a cVRPsTW. Afterwards we suggest
local improvement heuristics to decrease our objective function even further. A
carefully constructed benchmark set that resembles real-world data is used to
prove the efficacy of our algorithms in a computational study.
</p></div>
    </summary>
    <updated>2019-01-10T02:35:27Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-01-10T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1901.02560</id>
    <link href="http://arxiv.org/abs/1901.02560" rel="alternate" type="text/html"/>
    <title>Coercion-Resistant Voting in Linear Time via Fully Homomorphic Encryption: Towards a Quantum-Safe Scheme</title>
    <feedworld_mtime>1547078400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/R=oslash=nne:Peter_B=.html">Peter B. Rønne</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Atashpendar:Arash.html">Arash Atashpendar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gj=oslash=steen:Kristian.html">Kristian Gjøsteen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Ryan:Peter_Y=_A=.html">Peter Y. A. Ryan</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1901.02560">PDF</a><br/><b>Abstract: </b>We present an approach for performing the tallying work in the
coercion-resistant JCJ voting protocol, introduced by Juels, Catalano, and
Jakobsson, in linear time using fully homomorphic encryption (FHE). The
suggested enhancement also paves the path towards making JCJ quantum-resistant,
while leaving the underlying structure of JCJ intact. The exhaustive,
comparison-based approach of JCJ using plaintext equivalence tests leads to a
quadratic blow-up in the number of votes, which makes the tallying process
rather impractical in realistic settings with a large number of voters. We show
how the removal of invalid votes can be done in linear time via a solution
based on recent advances in various FHE primitives such as hashing,
zero-knowledge proofs of correct decryption, verifiable shuffles and threshold
FHE. We conclude by touching upon some of the advantages and challenges of such
an approach, followed by a discussion of further security and post-quantum
considerations.
</p></div>
    </summary>
    <updated>2019-01-10T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-01-10T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1901.02536</id>
    <link href="http://arxiv.org/abs/1901.02536" rel="alternate" type="text/html"/>
    <title>Fast generalized DFTs for all finite groups</title>
    <feedworld_mtime>1547078400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/u/Umans:Chris.html">Chris Umans</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1901.02536">PDF</a><br/><b>Abstract: </b>For any finite group $G$, we give an arithmetic algorithm to compute
generalized Discrete Fourier Transforms (DFTs) with respect to $G$, using
$O(|G|^{\omega/2 + \epsilon})$ operations, for any $\epsilon &gt; 0$. Here,
$\omega$ is the exponent of matrix multiplication.
</p></div>
    </summary>
    <updated>2019-01-10T02:32:52Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-01-10T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1901.02510</id>
    <link href="http://arxiv.org/abs/1901.02510" rel="alternate" type="text/html"/>
    <title>New approach for a stable multi-criteria ridesharing system</title>
    <feedworld_mtime>1547078400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Sawsen Ben Nasr <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1901.02510">PDF</a><br/><b>Abstract: </b>The witnessed boom in mobility results in many problems such as urbanization,
costly construction of many highways and air pollution. In an attempt to
address these problems, in this master, we are interested in the implementation
of a ridesharing system. Ridesharing is recognized as a highly effective means
of transport to solve energy consumption, environmental pollution and traffic
congestion issues. Indeed, ridesharing can reduce the number of vehicles on the
roads to avoid traffic jams and thus it contributes to a reduction in
greenhouse gas emissions. Its main thrust resides in sharing transport
expenses, meeting different people and making traveling more enjoyable. In this
respect, we introduce in this dissertation an effective ridesharing system,
called the Stable Multi-Criteria Rideshare Matching (SMRM) system, that (i)
considers users' personal preferences when sharing a private space with others
and (ii) enables a stable matching between driver and passenger sets. The
performed experiments show that the introduced system outperforms its
competitors in terms of stability quality and cost.
</p>
<p>Keywords: Smart cities, Social sustainability, Ridesharing , Social
preferences , TOPSIS , Stable marriage .
</p></div>
    </summary>
    <updated>2019-01-10T02:33:12Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-01-10T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1901.02508</id>
    <link href="http://arxiv.org/abs/1901.02508" rel="alternate" type="text/html"/>
    <title>An Application of Manifold Learning in Global Shape Descriptors</title>
    <feedworld_mtime>1547078400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bashiri:Fereshteh_S=.html">Fereshteh S. Bashiri</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rostami:Reihaneh.html">Reihaneh Rostami</a>, Peggy Peissig, Roshan M. D'Souza, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yu:Zeyun.html">Zeyun Yu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1901.02508">PDF</a><br/><b>Abstract: </b>With the rapid expansion of applied 3D computational vision, shape
descriptors have become increasingly important for a wide variety of
applications and objects from molecules to planets. Appropriate shape
descriptors are critical for accurate (and efficient) shape retrieval and 3D
model classification. Several spectral-based shape descriptors have been
introduced by solving various physical equations over a 3D surface model. In
this paper, for the first time, we incorporate a specific group of techniques
in statistics and machine learning, known as manifold learning, to develop a
global shape descriptor in the computer graphics domain. The proposed
descriptor utilizes the Laplacian Eigenmap technique in which the Laplacian
eigenvalue problem is discretized using an exponential weighting scheme. As a
result, our descriptor eliminates the limitations tied to the existing spectral
descriptors, namely dependency on triangular mesh representation and high
intra-class quality of 3D models. We also present a straightforward
normalization method to obtain a scale-invariant descriptor. The extensive
experiments performed in this study show that the present contribution provides
a highly discriminative and robust shape descriptor under the presence of a
high level of noise, random scale variations, and low sampling rate, in
addition to the known isometric-invariance property of the Laplace-Beltrami
operator. The proposed method significantly outperforms state-of-the-art
algorithms on several non-rigid shape retrieval benchmarks.
</p></div>
    </summary>
    <updated>2019-01-10T02:35:41Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-01-10T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1901.02491</id>
    <link href="http://arxiv.org/abs/1901.02491" rel="alternate" type="text/html"/>
    <title>Faster parameterized algorithm for pumpkin vertex deletion set</title>
    <feedworld_mtime>1547078400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tsur:Dekel.html">Dekel Tsur</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1901.02491">PDF</a><br/><b>Abstract: </b>A directed graph $G$ is called a pumpkin if $G$ is a union of induced paths
with a common start vertex $s$ and a common end vertex $t$, and the internal
vertices of every two paths are disjoint. We give an algorithm that given a
directed graph $G$ and an integer $k$, decides whether a pumpkin can be
obtained from $G$ by deleting at most $k$ vertices. The algorithm runs in
$O^*(2^k)$ time.
</p></div>
    </summary>
    <updated>2019-01-10T02:34:05Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-01-10T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1901.01861</id>
    <link href="http://arxiv.org/abs/1901.01861" rel="alternate" type="text/html"/>
    <title>On the Parameterized Complexity of $k$-Edge Colouring</title>
    <feedworld_mtime>1547078400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Galby:Esther.html">Esther Galby</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lima:Paloma_T=.html">Paloma T. Lima</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Paulusma:Dani=euml=l.html">Daniël Paulusma</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Ries:Bernard.html">Bernard Ries</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1901.01861">PDF</a><br/><b>Abstract: </b>For every fixed integer $k \geq 1$, we prove that $k$-Edge Colouring is
fixed-parameter-tractable when parameterized by the number of vertices of
maximum degree.
</p></div>
    </summary>
    <updated>2019-01-10T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-01-10T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1802.05859</id>
    <link href="http://arxiv.org/abs/1802.05859" rel="alternate" type="text/html"/>
    <title>A Parameterized Strongly Polynomial Algorithm for Block Structured Integer Programs</title>
    <feedworld_mtime>1547078400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kouteck=yacute=:Martin.html">Martin Koutecký</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Levin:Asaf.html">Asaf Levin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Onn:Shmuel.html">Shmuel Onn</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1802.05859">PDF</a><br/><b>Abstract: </b>The theory of $n$-fold integer programming has been recently emerging as an
important tool in parameterized complexity. The input to an $n$-fold integer
program (IP) consists of parameter $A$, dimension $n$, and numerical data of
binary encoding length $L$. It was known for some time that such programs can
be solved in polynomial time using $O(n^{g(A)}L)$ arithmetic operations where
$g$ is an exponential function of the parameter. In 2013 it was shown that it
can be solved in fixed-parameter tractable (FPT) time using $O(f(A)n^3L)$
arithmetic operations for a single-exponential function $f$. This, and a faster
algorithm for a special case of combinatorial $n$-fold IP, have led to several
very recent breakthroughs in the parameterized complexity of scheduling,
stringology, and computational social choice. In 2015 it was shown that it can
be solved in strongly polynomial time using $O(n^{g(A)})$ arithmetic
operations.
</p>
<p>Here we establish a result which subsumes all three of the above results by
showing that $n$-fold IP can be solved in strongly polynomial FPT time using
$O(f(A)n^3)$ arithmetic operations. In fact, our results are much more general,
briefly outlined as follows.
</p>
<p>- There is a strongly polynomial algorithm for ILP whenever a so-called
Graver-best oracle is realizable for it.
</p>
<p>- Graver-best oracles for the large classes of multi-stage stochastic and
tree-fold ILPs can be realized in FPT time. Together with the previous oracle
algorithm, this newly shows two large classes of ILP to be strongly polynomial;
in contrast, only few classes of ILP were previously known to be strongly
polynomial.
</p>
<p>- We show that ILP is FPT parameterized by the largest coefficient
$\|A\|_\infty$ and the primal or dual treedepth of $A$, and that this
parameterization cannot be relaxed, signifying substantial progress in
understanding the parameterized complexity of ILP.
</p></div>
    </summary>
    <updated>2019-01-10T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-01-10T01:30:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-8890204.post-4590649641895956020</id>
    <link href="http://mybiasedcoin.blogspot.com/feeds/4590649641895956020/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=8890204&amp;postID=4590649641895956020" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/8890204/posts/default/4590649641895956020" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/8890204/posts/default/4590649641895956020" rel="self" type="application/atom+xml"/>
    <link href="http://mybiasedcoin.blogspot.com/2019/01/analco-sosa-soda-post.html" rel="alternate" type="text/html"/>
    <title>ANALCO, SOSA, SODA post</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">I spent the last few days at SODA-ANALCO-ALENEX-SOSA in San Diego.  (Nice location choice, I'd say!)  Here's some news.<br/><br/>This will be the last ANALCO (Analytic Algorithms and Combinatorics).  Apparently submissions have been decreasing, so they've decided it will halt and the work on these topics will go into SODA and other conferences.  I'm not sure how to think of it -- I think we as a community have far too many conferences/workshops generally, but I think the SODA model of having ANALCO and ALENEX (and now SOSA, I imagine) folded in cleanly into the main conference is an excellent model.  I also like the ANALCO topics.  But I can understand the time may have come to do something else.  Thanks to everyone who worked to organize ANALCO and keep it going these many years.<br/><br/>It looks like SOSA (Symposium on Simplicity in Algorithms) will be taking its place in the SODA lineup.  I co-chaired the symposium with Jeremy Fineman this year, the second for the symposium.  I was surprised by the high quality of the submissions, and was then further surprised by the strong turnout at SODA.  The room was quite full for the Tuesday afternoon sessions, and there were easily 75+ people at several of the talks.  I do think there's a need for SOSA -- no other workshop/conference hits the theme of simplicity in our area, and it's a really nice fit with the rest of SODA.  I'm hoping it will last, and in particular that they'll continue to have a good number of high quality submissions, but that depends on all of you.  Ideally, there will be a positive feedback loop here -- now that there's a good home for this type of work (besides notes on the arxiv), people will be more inclined to write up and submit things to SOSA.  For Tuesday's talks, I'll call out Josh Alman's great presentation on "An Illuminating Algorithm for the Light Bulb Problem" as my favorite for the day.<br/><br/>With ANALCO exiting, though, I think there's more room for additional satellite events at SODA, so hopefully some people will get creative.<br/><br/>If I had thought about it I should have live-blogged the business meeting.  I'd say as highlights, first, Sandy Irani presented the report of the ad hoc committee to combat harassment and discrimination in the theory of computing community.   (See <a href="https://www.ics.uci.edu/~irani/safetoc.html">here</a> for the report.)  There was an overwhelming vote to adopt their recommendations going forward.  It's good to see progress in addressing these community concerns.  Second, Shuchi Chawla will be the next PC chair, and she brought forward a plan to have SODA PC members be allowed to submit papers (with a higher bar) that was voted on favorably as well.<br/><br/>I suppose the last note is that Jon Kleinberg's invited talk was the conference highlight you expect a Jon Kleinberg talk to be, with interesting results and models related to fairness and implicit bias.<br/><br/>Thanks to SIAM and all the organizers for their hard work.</div>
    </content>
    <updated>2019-01-09T22:25:00Z</updated>
    <published>2019-01-09T22:25:00Z</published>
    <author>
      <name>Michael Mitzenmacher</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/02161161032642563814</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-8890204</id>
      <category term="conferences"/>
      <category term="research"/>
      <category term="society"/>
      <category term="algorithms"/>
      <category term="administration"/>
      <category term="teaching"/>
      <category term="Harvard"/>
      <category term="papers"/>
      <category term="graduate students"/>
      <category term="funding"/>
      <category term="talks"/>
      <category term="blogs"/>
      <category term="codes"/>
      <category term="jobs"/>
      <category term="reviews"/>
      <category term="personal"/>
      <category term="travel"/>
      <category term="undergraduate students"/>
      <category term="books"/>
      <category term="open problems"/>
      <category term="PCs"/>
      <category term="consulting"/>
      <category term="randomness"/>
      <category term="CCC"/>
      <category term="blog book project"/>
      <category term="research labs"/>
      <category term="ISIT"/>
      <category term="tenure"/>
      <category term="comments"/>
      <category term="recommendations"/>
      <category term="outreach"/>
      <category term="students"/>
      <author>
        <name>Michael Mitzenmacher</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06738274256402616703</uri>
      </author>
      <link href="http://mybiasedcoin.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/8890204/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://mybiasedcoin.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/8890204/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">My take on computer science -- <br/> 
algorithms, networking, information theory -- <br/> 
and related items.</div>
      </subtitle>
      <title>My Biased Coin</title>
      <updated>2019-01-09T22:25:51Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://cstheory.stackexchange.com/q/42183</id>
    <link href="https://cstheory.stackexchange.com/questions/42183/new-subset-sum-approach-tc-results" rel="alternate" type="text/html"/>
    <title>new subset sum approach TC/results</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I have been working on a new approach for a subset sum exact solver, and the current state provides an algorithm operating on <span class="math-container">$O{n/2 \choose n/4}$</span>, demonstrating as well the hardest target value is not <span class="math-container">$\approx \frac{sum(S)}{2}$</span> but <span class="math-container">$\approx\frac{sum(S)}{4}$</span> for dense instances (<span class="math-container">$d \approx 1$</span>) in all cases.</p>

<p>I asked several people about their opinion and I got mixed feedback, some people though it was worth it to keep pushing the approach before publishing (to try to obtain an improved result, given this is likely possible, then publish), while other people encouraged me to publish right away given the TC improvement over the <span class="math-container">$O(2^{\frac{n}{2}})$</span> approach and the new characterization for the hardest target values not demonstrated before in the available literature, then continue working looking to improve these results.</p>

<p>What are your suggestions/opinions? </p></div>
    </summary>
    <updated>2019-01-09T21:51:34Z</updated>
    <published>2019-01-09T21:51:34Z</published>
    <category scheme="https://cstheory.stackexchange.com/tags" term="np-complete"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="subset-sum"/>
    <author>
      <name>John Seppard</name>
      <uri>https://cstheory.stackexchange.com/users/47335</uri>
    </author>
    <source>
      <id>https://cstheory.stackexchange.com/feeds/</id>
      <link href="https://cstheory.stackexchange.com/feeds/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory.stackexchange.com/questions" rel="alternate" type="text/html"/>
      <link href="http://www.creativecommons.org/licenses/by-sa/3.0/rdf" rel="license"/>
      <subtitle>most recent 30 from cstheory.stackexchange.com</subtitle>
      <title>Recent Questions - Theoretical Computer Science Stack Exchange</title>
      <updated>2019-01-10T04:21:27Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2019/01/09/mixed-integer-nonlinear-optimization-meets-data-science/</id>
    <link href="https://cstheory-events.org/2019/01/09/mixed-integer-nonlinear-optimization-meets-data-science/" rel="alternate" type="text/html"/>
    <title>Mixed-Integer Nonlinear Optimization meets Data Science</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">June 25, 2018 – June 28, 2019 Ischia, Italy http://www.iasi.cnr.it/minoa/big-data-school/ CNR-IASI, as part of the MINOA project, announces the school for PhD students and post-docs on the theme Mixed Integer Non linear Optimization meets Data Science. The school will cover the following topics: Deep learning for AI Clustering for Big Data Machine Learning for Combinatorial … <a class="more-link" href="https://cstheory-events.org/2019/01/09/mixed-integer-nonlinear-optimization-meets-data-science/">Continue reading <span class="screen-reader-text">Mixed-Integer Nonlinear Optimization meets Data Science</span></a></div>
    </summary>
    <updated>2019-01-09T20:51:39Z</updated>
    <published>2019-01-09T20:51:39Z</published>
    <category term="school"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2019-01-10T04:22:25Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://adamsheffer.wordpress.com/?p=5374</id>
    <link href="https://adamsheffer.wordpress.com/2019/01/09/the-baruch-distinguished-mathematics-lecture-series/" rel="alternate" type="text/html"/>
    <title>The Baruch Distinguished Mathematics Lecture Series</title>
    <summary>I am happy to announce the beginning of the Baruch Distinguished Mathematics Lecture Series. In this series we will bring established mathematicians to give talks to a general mathematical audience. Our first Distinguished Lecture, by Bjorn Poonen, will be “Undecidability in Number Theory”. Click here for the full details. The talk is open to everyone, […]</summary>
    <updated>2019-01-09T20:43:09Z</updated>
    <published>2019-01-09T20:43:09Z</published>
    <category term="Math events"/>
    <author>
      <name>Adam Sheffer</name>
    </author>
    <source>
      <id>https://adamsheffer.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://adamsheffer.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://adamsheffer.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://adamsheffer.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://adamsheffer.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Discrete geometry and other typos</subtitle>
      <title>Some Plane Truths</title>
      <updated>2019-01-10T04:22:14Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://blogs.princeton.edu/imabandit/?p=1350</id>
    <link href="https://blogs.princeton.edu/imabandit/2019/01/09/nemirovskis-acceleration/" rel="alternate" type="text/html"/>
    <title>Nemirovski’s acceleration</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I will describe here the very first (to my knowledge) acceleration algorithm for smooth convex optimization, which is due to Arkadi Nemirovski (dating back to the end of the 70’s). The algorithm relies on a -dimensional plane-search subroutine (which, in … <a href="https://blogs.princeton.edu/imabandit/2019/01/09/nemirovskis-acceleration/">Continue reading <span class="meta-nav">→</span></a></p></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I will describe here the very first (to my knowledge) acceleration algorithm for smooth convex optimization, which is due to <a class="liinternal" href="https://en.wikipedia.org/wiki/Arkadi_Nemirovski" rel="nofollow">Arkadi Nemirovski</a> (dating back to the end of the 70’s). The algorithm relies on a <img alt="2" class="ql-img-inline-formula " height="12" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-bc2da46d9824359f6ac8d33c5fb882dd_l3.png?resize=8%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="8"/>-dimensional plane-search subroutine (which, in theory, can be implemented in <img alt="\log(1/\epsilon)" class="ql-img-inline-formula " height="19" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-38bfa3c1131fbae41cb358b8b685dc56_l3.png?resize=61%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="61"/> calls to a first-order oracle). He later improved it to only require a <img alt="1" class="ql-img-inline-formula " height="13" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-21b5b4cbe9a10b6d847eeb4265b99898_l3.png?resize=7%2C13&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="7"/>-dimensional line-search in 1981, but of course the breakthrough that everyone knows about came a year after with the famous 1982 paper by <a class="liinternal" href="https://en.wikipedia.org/wiki/Yurii_Nesterov" rel="nofollow">Nesterov</a> that gets rid of this extraneous logarithmic term altogether (and in addition is based on the <a class="liinternal" href="https://blogs.princeton.edu/imabandit/2018/11/21/a-short-proof-for-nesterovs-momentum/">deep insight</a> of modifying Polyak’s momentum).</p>
<p>Let <img alt="f" class="ql-img-inline-formula " height="16" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c7d97b919a3b73617cf2fbb375fff3b1_l3.png?resize=10%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="10"/> be a <img alt="1" class="ql-img-inline-formula " height="13" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-21b5b4cbe9a10b6d847eeb4265b99898_l3.png?resize=7%2C13&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="7"/>-smooth function. Denote <img alt="x^{+} = x - \nabla f(x)" class="ql-img-inline-formula " height="19" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-d69559ebcb4e4ecdf7454cab91bf526b_l3.png?resize=125%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="125"/>. Fix a sequence <img alt="(\lambda_t)_{t \in \N}" class="ql-img-inline-formula " height="18" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-ba9ca1ebe088d1befda0acb3c4644727_l3.png?resize=43%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="43"/>, to be optimized later. We consider the “conjugate” point <img alt="\sum_{s =1}^t \lambda_s \nabla f(x_s)" class="ql-img-inline-formula " height="23" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-d22daf1993fbb2397de0b21ab0ea87ee_l3.png?resize=119%2C23&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="119"/>. The algorithm simply returns the optimal combination of the conjugate point and the gradient descent point, that is:</p>
<p class="ql-center-displayed-equation" style="line-height: 54px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\[ x_{t+1} = \argmin_{x \in P_t} f(x) \, \text{where} \, P_t = \mathrm{span}\left(x_t^+, \sum_{s =1}^t \lambda_s \nabla f(x_s)\right) \,. \]" class="ql-img-displayed-equation " height="54" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-360399a70097a55997eaeacb3ec02615_l3.png?resize=424%2C54&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="424"/></p>
<p>Let us denote <img alt="g_s = \nabla f(x_s)" class="ql-img-inline-formula " height="18" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-e614d7a76c02a9a308f9898af91df8ff_l3.png?resize=95%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="95"/> and <img alt="\delta_s = f(x_s) - f(x^*)" class="ql-img-inline-formula " height="18" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-629dcf91ea83c14ea854c74de1069acd_l3.png?resize=143%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="143"/> for shorthand. The key point is that <img alt="g_{t+1} \in P_t^{\perp}" class="ql-img-inline-formula " height="20" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-9d21b904e2ccc5df54959aa117a37b98_l3.png?resize=77%2C20&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="77"/>, and in particular <img alt="\|\sum_{s \leq t} \lambda_s g_s\|^2 = \sum_{s \leq t} \lambda_s^2 \|g_s\|^2" class="ql-img-inline-formula " height="22" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-4e57279bc2d0342e42087a51af61fb76_l3.png?resize=231%2C22&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="231"/>. Now recognize that <img alt="\|g_s\|^2" class="ql-img-inline-formula " height="20" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-b728147d95760e42ef7cdbb706a8cfd1_l3.png?resize=38%2C20&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="38"/> is a lower bound on the improvement <img alt="\delta_s - \delta_{s+1}" class="ql-img-inline-formula " height="17" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-0808cda8024eb11ab7ce37176832a9fe_l3.png?resize=68%2C17&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="68"/> (here we use that <img alt="x_{s+1}" class="ql-img-inline-formula " height="13" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-b0878f455a78407f8618e726e941aea6_l3.png?resize=33%2C13&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="33"/> is better than <img alt="x_s^+" class="ql-img-inline-formula " height="19" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-5acc4c663fcf2f647eb177ebb24bc154_l3.png?resize=20%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="20"/>). Thus we get:</p>
<p class="ql-center-displayed-equation" style="line-height: 40px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\[ \|\sum_{s \leq t} \lambda_s g_s\|^2 \leq \sum_{s \leq t} \lambda_s^2 (\delta_s - \delta_{s+1}) \leq \sum_{s \leq t} \delta_s (\lambda_s^2 - \lambda_{s-1}^2) \,. \]" class="ql-img-displayed-equation " height="40" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-a12bda17f9c1f0f0e13ef03c9a1c9d2c_l3.png?resize=404%2C40&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="404"/></p>
<p>In other words if the sequence <img alt="\lambda" class="ql-img-inline-formula " height="12" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-ab48baf331239642a00255b86324280a_l3.png?resize=10%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="10"/> is chosen such that <img alt="\lambda_s = \lambda_s^2 - \lambda_{s-1}^2" class="ql-img-inline-formula " height="21" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-2f241a8315da6dd3f7735135d1d2b7ae_l3.png?resize=114%2C21&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="114"/> then we get</p>
<p class="ql-center-displayed-equation" style="line-height: 40px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\[ \|\sum_{s \leq t} \lambda_s g_s\|^2 \leq \sum_{s \leq t} \lambda_s \delta_s \,. \]" class="ql-img-displayed-equation " height="40" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-8e959561f27eec9096b81bd7148a4a75_l3.png?resize=180%2C40&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="180"/></p>
<p>This is good because roughly the reverse inequality also holds true by convexity (and the fact that <img alt="x_s \in P_s" class="ql-img-inline-formula " height="15" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-212cae06b1b9b8b6af498b589bb15865_l3.png?resize=56%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="56"/> so <img alt="g_s \cdot x_s = 0" class="ql-img-inline-formula " height="16" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-cf91835fdc91be361d1c7e89f867c5db_l3.png?resize=78%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="78"/>):</p>
<p class="ql-center-displayed-equation" style="line-height: 40px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\[ \sum_{s \leq t} \lambda_s \delta_s \leq \sum_{s \leq t} \lambda_s g_s \cdot (x_s - x^*) \leq \|x^*\| \cdot \| \sum_{s \leq t} \lambda_s g_s\| \,. \]" class="ql-img-displayed-equation " height="40" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-9d1ee450c97dfc04bca3a123fb68daa8_l3.png?resize=391%2C40&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="391"/></p>
<p>So finally we get <img alt="\sum_{s \leq t} \lambda_s \delta_s \leq \|x^*\|^2" class="ql-img-inline-formula " height="22" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-d58dea2404181d7f1751fcf8e68ad024_l3.png?resize=143%2C22&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="143"/>, and it just remains to realize that <img alt="\lambda_s" class="ql-img-inline-formula " height="15" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-f100f89f751713a1814b3938a510009b_l3.png?resize=16%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="16"/> is of order <img alt="s" class="ql-img-inline-formula " height="8" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-3bcfb3f0b6b04be3b598743cd774dd78_l3.png?resize=8%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="8"/> so that <img alt="\delta_t \leq \|x^*\|^2 / t^2" class="ql-img-inline-formula " height="20" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-3ff4a3e78d1ced5a05f33eb077194504_l3.png?resize=103%2C20&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="103"/>.</p></div>
    </content>
    <updated>2019-01-09T18:51:19Z</updated>
    <published>2019-01-09T18:51:19Z</published>
    <category term="Optimization"/>
    <author>
      <name>Sebastien Bubeck</name>
    </author>
    <source>
      <id>https://blogs.princeton.edu/imabandit</id>
      <link href="https://blogs.princeton.edu/imabandit/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://blogs.princeton.edu/imabandit" rel="alternate" type="text/html"/>
      <subtitle>Random topics in optimization, probability, and statistics. By Sébastien Bubeck</subtitle>
      <title>I’m a bandit</title>
      <updated>2019-01-09T23:25:28Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://cstheory.stackexchange.com/q/42180</id>
    <link href="https://cstheory.stackexchange.com/questions/42180/coordinate-descent-in-integer-programing-when-does-it-work" rel="alternate" type="text/html"/>
    <title>Coordinate descent in integer programing: when does it work?</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Denote <span class="math-container">$N_i=\{0,1,\dots,\bar{n}_i\}$</span> and define <span class="math-container">$N=N_1\times \dots \times N_I$</span>. I want to minimize a function <span class="math-container">$f:N\rightarrow \mathbb{R}$</span>. It is very easy to minimize <span class="math-container">$f$</span> coordinate by coordinate so one natural algorithm is to iterate on a mapping <span class="math-container">$T$</span> for which the <span class="math-container">$i$</span>th element is defined as
<span class="math-container">$$(Tn)_i=\arg\min_{\tilde{n}_i\in N_i} f\left( \left\{ n_1,\dots,\tilde{n}_i,\dots,n_I\right\}\right)$$</span>
until we have convergence. This is essentially a <a href="https://en.wikipedia.org/wiki/Coordinate_descent" rel="nofollow noreferrer">coordinate descent</a> algorithm but in a discrete space.</p>

<p>My question is: under what conditions does this approach yield the true global minimum of <span class="math-container">$f$</span>? For instance, is <span class="math-container">$f$</span> strictly convex a sufficient condition for this procedure to work? Also, if anybody has a reference on the topic that would be highly appreciated.</p></div>
    </summary>
    <updated>2019-01-09T18:38:14Z</updated>
    <published>2019-01-09T18:38:14Z</published>
    <category scheme="https://cstheory.stackexchange.com/tags" term="ds.algorithms"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="reference-request"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="optimization"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="integer-programming"/>
    <author>
      <name>user_lambda</name>
      <uri>https://cstheory.stackexchange.com/users/51700</uri>
    </author>
    <source>
      <id>https://cstheory.stackexchange.com/feeds/</id>
      <link href="https://cstheory.stackexchange.com/feeds/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory.stackexchange.com/questions" rel="alternate" type="text/html"/>
      <link href="http://www.creativecommons.org/licenses/by-sa/3.0/rdf" rel="license"/>
      <subtitle>most recent 30 from cstheory.stackexchange.com</subtitle>
      <title>Recent Questions - Theoretical Computer Science Stack Exchange</title>
      <updated>2019-01-10T04:21:27Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://emanueleviola.wordpress.com/?p=606</id>
    <link href="https://emanueleviola.wordpress.com/2019/01/09/my-last-3-5-years/" rel="alternate" type="text/html"/>
    <title>My last 3.5 years</title>
    <summary>I haven’t breathed (freely) since 3.5 years ago.  Precisely since the day before I left my Cambridge flat, when the Pods guy told me he couldn’t park. I had to vacate within 24 hours, had no place to put all the stuff I had never used since moving there in 2008, and also happened to […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p style="text-align: justify;">I haven’t breathed (freely) since 3.5 years ago.  Precisely since the day before I left my Cambridge flat, when the Pods guy told me he couldn’t park. I had to vacate within 24 hours, had no place to put all the stuff I had never used since moving there in 2008, and also happened to have a 3-hour CPR course planned long ago, starting in minutes.  I took that life-saving course on the edge of the seat, each 5-minute break dashing out to call movers who might have had an unlikely last minute cancellation in the busiest day of the year (August 31).</p>
<p style="text-align: justify;">Oh the times I wished that the fireproof storage where the things eventually went burned down to the ground.  Instead I was going to have to move my never used belongings a million times up and down stairs.</p>
<p style="text-align: justify;">Anyway, after Cambridge I went to the <a href="https://emanueleviola.wordpress.com/2015/11/16/from-the-simons-institute/">Simons institute</a>. Even with all the help from the staff, finding housing was atrocious, and I had to change it during the semester. I didn’t have a place to come back, and from Berkeley I eventually found a short-term rental in Needham, MA.  The idea was to buy a house in that short term.  This proved <a href="https://emanueleviola.wordpress.com/2015/12/15/how-to-buy-a-house/">impossible</a>.  So we had to find another rental.  In the process, I was discriminated against three times.  One time the landlord rejected in writing my application claiming that they did not want to rent to families. The other two times the landlord simply rejected my application, and then lowered the price. I thought these moves made them dumb, but maybe they are actually much smarter than me, because after toying with the idea I did not, in fact, sue.</p>
<p style="text-align: justify;">Eventually we found another longer-term rental.  From there, with more excruciating difficulties I <a href="https://emanueleviola.wordpress.com/2017/12/19/how-to-buy-a-house-ii/">wrote about earlier</a>, I bought a house, which however required 1 year of renovations (not exactly cosmetic — more about this later).  These were completed just in time to store my useless stuff there: I left for another semester at the Simons institute.</p>
<p style="text-align: justify;">My second visit to the institute was also great.  In fact I enjoyed it even more than the semester on fine-grained: I was there for the program on lower bounds, which are exactly the problems I went into computer science to study. I had the best time, and lots of research exchanges.</p>
<p style="text-align: justify;">But again, the housing situation in Berkeley was desperate.  Twice I lost a house for 1 hour. Meaning, the landlord called to make the deal, I couldn’t pick up the phone, and when I called back 1 hour later the place was gone.  I still think it would be better if the institute bought a block of houses, and also provided computers.  Even better if they make it easier to print, rather than having to stand in a corner or go through a complicated set up.</p>
<p style="text-align: justify;">Another interesting pattern is that during my first visit there was a heat wave and the AC broke, and it was hot.  This time there was a rather serious wildfire, causing very unhealthy conditions in the bay area, and at times they couldn’t run the heating systems to avoid sucking in the smoke, and it was cold.</p>
<p style="text-align: justify;">Berkeley isn’t Princeton, but it’s hard for me not to compare the logistics of my visits to Simons and the IAS in Princeton.  In the latter I was put in a house steps from the Institute, with minimal effort and at a fraction of the price.  In my office there was already a working computer, connected to a printer.</p>
<p>Here’s the meaning of cloud computing, remote desktop, telnet, etc in 2019, here’s the progress, the sustainability, the sharing economy: everybody brings their own laptop.</p>
<p style="text-align: justify;">Back from Simons, I can’t help but be surprised that I still have an office.  In fact this happens every time I go up the stairs, turn the corner and see my name on the tag, and it says “Professor”. Really? Under <em>my name</em>? I have a startle each time.  I know this feeling is irrational, but is there.  Coming back from California, the feeling is intense.</p>
<p style="text-align: justify;">Back to business, I am now teaching algorithms.  I am running an online section, for which I am making videos on my <a href="https://www.youtube.com/channel/UChbOQ1Q8Fv44LbrQMvTPoEQ">youtube channel</a>. It’s the future.</p></div>
    </content>
    <updated>2019-01-09T16:36:12Z</updated>
    <published>2019-01-09T16:36:12Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Emanuele</name>
    </author>
    <source>
      <id>https://emanueleviola.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://emanueleviola.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://emanueleviola.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://emanueleviola.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://emanueleviola.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>By Emanuele Viola</subtitle>
      <title>Thoughts</title>
      <updated>2019-01-10T04:22:01Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://cstheory.stackexchange.com/q/42178</id>
    <link href="https://cstheory.stackexchange.com/questions/42178/approximate-multi-covering-with-randomized-rounding" rel="alternate" type="text/html"/>
    <title>Approximate Multi Covering with Randomized Rounding</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>In the set multicover problem we are given a set <span class="math-container">$N$</span> of <span class="math-container">$n$</span> elements and a set <span class="math-container">$S$</span> of <span class="math-container">$m$</span> subsets of <span class="math-container">$N$</span>. Additionally, each element has a coverage requirement (the number of times it has to be covered) and each set has a weight. The question is to cover <span class="math-container">$N$</span> with the minimum weight subsets from <span class="math-container">$S$</span>. I'm aware of the approximation algorithm for this problem using (Rajagopalan &amp; Vazirani) .</p>

<p>But I am interested in finding an algorithm for this problem that uses the randomized rounding and study its approximation factor.</p>

<p>Thanks in advance!</p></div>
    </summary>
    <updated>2019-01-09T16:01:30Z</updated>
    <published>2019-01-09T16:01:30Z</published>
    <category scheme="https://cstheory.stackexchange.com/tags" term="approximation-algorithms"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="randomized-algorithms"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="set-cover"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="covering-problems"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="iterated-rounding"/>
    <author>
      <name>user2404626</name>
      <uri>https://cstheory.stackexchange.com/users/51697</uri>
    </author>
    <source>
      <id>https://cstheory.stackexchange.com/feeds/</id>
      <link href="https://cstheory.stackexchange.com/feeds/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory.stackexchange.com/questions" rel="alternate" type="text/html"/>
      <link href="http://www.creativecommons.org/licenses/by-sa/3.0/rdf" rel="license"/>
      <subtitle>most recent 30 from cstheory.stackexchange.com</subtitle>
      <title>Recent Questions - Theoretical Computer Science Stack Exchange</title>
      <updated>2019-01-10T04:21:27Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://cstheory.stackexchange.com/q/42177</id>
    <link href="https://cstheory.stackexchange.com/questions/42177/maximum-minimum-satisfiability" rel="alternate" type="text/html"/>
    <title>Maximum-minimum satisfiability</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>In <a href="https://en.wikipedia.org/wiki/Maximum_satisfiability_problem" rel="nofollow noreferrer">MAX-SAT</a>, given a formula, we want to maximize the number of satisfied clauses: given a formula <span class="math-container">$\phi = c_1 \cap \cdots \cap c_n$</span>, where each <span class="math-container">$c_i$</span> is a disjunction, we want to find the largest <span class="math-container">$k\in\{1,\ldots,n\}$</span> such that, for some assignment, some <span class="math-container">$k$</span> clauses <span class="math-container">$c_{i1},\ldots,c_{ik}$</span> are true.</p>

<p>In <strong>MAX-MIN-SAT</strong>, given two different formulas, we want to maximize the minimum number of satisfied clauses in both.
I.e., given <span class="math-container">$\phi_a = a_1 \cap \cdots \cap a_n$</span> and <span class="math-container">$\phi_b = b_1 \cap \cdots \cap b_n$</span>,  where each <span class="math-container">$a_i$</span> and each <span class="math-container">$b_i$</span> is a disjunction, find the largest <span class="math-container">$k$</span> such that, for some assignment, some <span class="math-container">$k$</span> clauses <span class="math-container">$a_{i1},\ldots,a_{ik}$</span> and some <span class="math-container">$k$</span> clauses <span class="math-container">$b_{j1},\ldots,b_{jk}$</span> are true.</p>

<p>To illustrate the difference between the problems, suppose we have two assignments: one assignment satisfies 10 clauses in <span class="math-container">$\phi_a$</span> and 1 clause in <span class="math-container">$\phi_b$</span>, while another assignment satisfies 5 clauses in <span class="math-container">$\phi_a$</span> and 4 clauses in <span class="math-container">$\phi_b$</span>. Then, MAX-SAT (on <span class="math-container">$\phi_a \cap \phi_b$</span>) would prefer the first assignment since it satisfies <span class="math-container">$11&gt;9$</span> clauses overall, while MAX-MIN-SAT would prefer the second assignment since it satisfies at least <span class="math-container">$4&gt;1$</span> clauses in both formulas.</p>

<p>This problem is obviously NP-hard, so I am looking for reasonable approximations.</p>

<p>As a first approximation, suppose each formula is a conjunction of <span class="math-container">$n$</span> clauses, and each clause is a disjunction of <span class="math-container">$l$</span> variables. Suppose we set each variable randomly. Then, each clause is unsatisfied with probability <span class="math-container">$2^{-l}$</span>. So the expected number of unsatisfied clauses in each formula is <span class="math-container">$2^{-l}n$</span>. So the expected number of unsatisfied clauses in both formulas is <span class="math-container">$2^{1-l}n$</span>. So there exists an assignment in which the total number of unsatisfied clauses is at most <span class="math-container">$2^{1-l}n$</span>. In that assignment, in each formula, at least  <span class="math-container">$(1-2^{1-l})n$</span> clauses are satisfied. 
So we have a constant-factor <span class="math-container">$(1-2^{1-l})$</span> approximation to MAX MIN SAT. </p>

<p>Is there a better approximation? </p>

<p><sub><a href="https://cs.stackexchange.com/q/100375/1342">Posted some weeks ago in cs.SE,</a> with no replies</sub></p></div>
    </summary>
    <updated>2019-01-09T15:31:20Z</updated>
    <published>2019-01-09T15:31:20Z</published>
    <category scheme="https://cstheory.stackexchange.com/tags" term="approximation-algorithms"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="optimization"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="sat"/>
    <author>
      <name>Erel Segal-Halevi</name>
      <uri>https://cstheory.stackexchange.com/users/9453</uri>
    </author>
    <source>
      <id>https://cstheory.stackexchange.com/feeds/</id>
      <link href="https://cstheory.stackexchange.com/feeds/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory.stackexchange.com/questions" rel="alternate" type="text/html"/>
      <link href="http://www.creativecommons.org/licenses/by-sa/3.0/rdf" rel="license"/>
      <subtitle>most recent 30 from cstheory.stackexchange.com</subtitle>
      <title>Recent Questions - Theoretical Computer Science Stack Exchange</title>
      <updated>2019-01-10T04:21:27Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-2727898493587029341</id>
    <link href="https://blog.computationalcomplexity.org/feeds/2727898493587029341/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/01/search-versus-decision.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/2727898493587029341" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/2727898493587029341" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/01/search-versus-decision.html" rel="alternate" type="text/html"/>
    <title>Search versus Decision</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Shockingly I've never done a post on search versus decision, one of the more interesting dualities in complexity. In short: Decision: Is there a needle in the haystack? Search: Find the needle.<br/>
<br/>
In Satisfiability, or any other NP-complete problem, the two problems are essentially equivalent. If you can decided SAT you can find a solution (good homework problem) or even the best solution. Often people mix up the two, where people say finding the shortest Traveling Salesman Tour is NP-complete, <a href="https://blog.computationalcomplexity.org/2014/01/is-traveling-salesman-np-complete.html">usually</a> without getting into too much trouble.<br/>
<br/>
Decision is always at least as easy as search: If you have a solution you know there is one. What about the other direction? We can't actually prove search is hard without separating P and NP, but we have our conjectures.<br/>
<br/>
Sometimes both are easy. We can easily find the maximum weighted matching.<br/>
<br/>
Sometimes decision is easy and search is supposedly hard: Composite Numbers. The search version is factoring.<br/>
<br/>
Sometimes decision is trivial (i.e. they always exist) and search is still hard. Nash Equilibria. <a href="https://blog.computationalcomplexity.org/2006/05/dispersing-ramsey-graphs.html">Ramsey Graphs</a>.<br/>
<br/>
Often we ask whether search reduces to decision? If you have some oracle (magic black box) that answered decision questions, can you solve the search problem efficiently? SAT has this property, as does Matching (for trivial reasons). Nash Equilibrium and Composite Numbers likely don't.<br/>
<br/>
Graph Isomorphism does, i.e., given an oracle for graph isomorphism you can find the isomorphism (another good homework problem).<br/>
<br/>
There's also an interesting non-adaptive version. Given a SAT formula can you find an assignment with questions to a SAT oracle that all have to be asked at the same time?<br/>
<br/>
Here we get a probable yes. If the formula has one solution you can find it by asking for each bit of the solution. <a href="https://blog.computationalcomplexity.org/2006/09/favorite-theorems-unique-witnesses.html">Randomly you can reduce SAT to several formulas</a>, one of which is likely to have a single assignment that is also an assignment of the original formula. With standard hardness assumptions <a href="https://blog.computationalcomplexity.org/2006/07/full-derandomization.html">you can eliminate the randomness</a>.<br/>
<br/>
Is the same true for graph isomorphism? I think that's still open.</div>
    </content>
    <updated>2019-01-09T13:10:00Z</updated>
    <published>2019-01-09T13:10:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>https://plus.google.com/101693130490639305932</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>https://plus.google.com/101693130490639305932</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-01-09T22:38:21Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1901.02441</id>
    <link href="http://arxiv.org/abs/1901.02441" rel="alternate" type="text/html"/>
    <title>Lower bounds for maximal matchings and maximal independent sets</title>
    <feedworld_mtime>1546992000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Balliu:Alkida.html">Alkida Balliu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Brandt:Sebastian.html">Sebastian Brandt</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hirvonen:Juho.html">Juho Hirvonen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Olivetti:Dennis.html">Dennis Olivetti</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rabie:Mika=euml=l.html">Mikaël Rabie</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Suomela:Jukka.html">Jukka Suomela</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1901.02441">PDF</a><br/><b>Abstract: </b>There are distributed graph algorithms for finding maximal matchings and
maximal independent sets in $O(\Delta + \log^* n)$ communication rounds; here
$n$ is the number of nodes and $\Delta$ is the maximum degree. The lower bound
by Linial (1992) shows that the dependency on $n$ is optimal: these problems
cannot be solved in $o(\log^* n)$ rounds even if $\Delta = 2$.
</p>
<p>However, the dependency on $\Delta$ is a long-standing open question, and
there is currently an exponential gap between the upper and lower bounds.
</p>
<p>We prove that the upper bounds are tight. We show that maximal matchings and
maximal independent sets cannot be found in $o(\Delta + \log \log n / \log \log
\log n)$ rounds. Our lower bound holds for deterministic and randomized
distributed algorithms in the LOCAL model of distributed computing.
</p></div>
    </summary>
    <updated>2019-01-09T23:20:50Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-01-09T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1901.02393</id>
    <link href="http://arxiv.org/abs/1901.02393" rel="alternate" type="text/html"/>
    <title>Fair Algorithms for Clustering</title>
    <feedworld_mtime>1546992000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bera:Suman_K=.html">Suman K. Bera</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chakrabarty:Deeparnab.html">Deeparnab Chakrabarty</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Negahbani:Maryam.html">Maryam Negahbani</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1901.02393">PDF</a><br/><b>Abstract: </b>We study clustering problems under the lens of {\em algorithmic fairness}
inspired by the disparate impact doctrine. Given a collection of points
containing many {\em protected groups}, the goal is to find good clustering
solutions where each cluster {\em fairly represents} each group. We allow the
user to specify the parameters that define fair representation, and this
flexibility makes our model significantly more general than the recent models
of Chierichetti et al. (NIPS 2017) and R\"osner and Schmidt (ICALP 2018). Our
main result is a simple algorithm that, for any $\ell_p$-norm including the
$k$-center, $k$-median, and $k$-means objectives, transforms any clustering
solution to a fair one with only a slight loss in quality.
</p></div>
    </summary>
    <updated>2019-01-09T23:22:48Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-01-09T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1901.02209</id>
    <link href="http://arxiv.org/abs/1901.02209" rel="alternate" type="text/html"/>
    <title>Subset Feedback Vertex Set in Chordal and Split Graphs</title>
    <feedworld_mtime>1546992000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Philip:Geevarghese.html">Geevarghese Philip</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rajan:Varun.html">Varun Rajan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Saurabh:Saket.html">Saket Saurabh</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tale:Prafullkumar.html">Prafullkumar Tale</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1901.02209">PDF</a><br/><b>Abstract: </b>In the \textsc{Subset Feedback Vertex Set (Subset-FVS)} problem the input is
a graph $G$, a subset \(T\) of vertices of \(G\) called the `terminal'
vertices, and an integer $k$. The task is to determine whether there exists a
subset of vertices of cardinality at most $k$ which together intersect all
cycles which pass through the terminals. \textsc{Subset-FVS} generalizes
several well studied problems including \textsc{Feedback Vertex Set} and
\textsc{Multiway Cut}. This problem is known to be \NP-Complete even in split
graphs. Cygan et al. proved that \textsc{Subset-FVS} is fixed parameter
tractable (\FPT) in general graphs when parameterized by $k$ [SIAM J. Discrete
Math (2013)]. In split graphs a simple observation reduces the problem to an
equivalent instance of the $3$-\textsc{Hitting Set} problem with same solution
size. This directly implies, for \textsc{Subset-FVS} \emph{restricted to split
graphs}, (i) an \FPT algorithm which solves the problem in $\OhStar(2.076^k)$
time \footnote{The \(\OhStar()\) notation hides polynomial factors.}% for
\textsc{Subset-FVS} in Chordal % Graphs [Wahlstr\"om, Ph.D. Thesis], and (ii) a
kernel of size $\mathcal{O}(k^3)$. We improve both these results for
\textsc{Subset-FVS} on split graphs; we derive (i) a kernel of size
$\mathcal{O}(k^2)$ which is the best possible unless $\NP \subseteq \coNP/{\sf
poly}$, and (ii) an algorithm which solves the problem in time
$\mathcal{O}^*(2^k)$. Our algorithm, in fact, solves \textsc{Subset-FVS} on the
more general class of \emph{chordal graphs}, also in $\mathcal{O}^*(2^k)$ time.
</p></div>
    </summary>
    <updated>2019-01-09T23:22:25Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-01-09T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1901.02166</id>
    <link href="http://arxiv.org/abs/1901.02166" rel="alternate" type="text/html"/>
    <title>K-Core Minimization: A Game Theoretic Approach</title>
    <feedworld_mtime>1546992000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Medya:Sourav.html">Sourav Medya</a>, Tiyani Ma, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Silva:Arlei.html">Arlei Silva</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Singh:Ambuj.html">Ambuj Singh</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1901.02166">PDF</a><br/><b>Abstract: </b>$K$-cores are maximal induced subgraphs where all vertices have degree at
least $k$. These dense patterns have applications in community detection,
network visualization and protein function prediction. However, $k$-cores can
be quite unstable to network modifications, which motivates the question: How
resilient is the k-core structure of a network, such as the Web or Facebook, to
edge deletions? We investigate this question from an algorithmic perspective.
More specifically, we study the problem of computing a small set of edges for
which the removal minimizes the $k$-core structure of a network.
</p>
<p>This paper provides a comprehensive characterization of the hardness of the
$k$-core minimization problem (KCM), including innaproximability and
fixed-parameter intractability. Motivated by such a challenge in terms of
algorithm design, we propose a novel algorithm inspired by Shapley value---a
cooperative game-theoretic concept--- that is able to leverage the strong
interdependencies in the effects of edge removals in the search space. As
computing Shapley values is also NP-hard, we efficiently approximate them using
a randomized algorithm with probabilistic guarantees. Our experiments, using
several real datasets, show that the proposed algorithm outperforms competing
solutions in terms of $k$-core minimization while being able to handle large
graphs. Moreover, we illustrate how KCM can be applied in the analysis of the
$k$-core resilience of networks.
</p></div>
    </summary>
    <updated>2019-01-09T23:22:08Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-01-09T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1901.02070</id>
    <link href="http://arxiv.org/abs/1901.02070" rel="alternate" type="text/html"/>
    <title>Convolutional Neural Networks on non-uniform geometrical signals using Euclidean spectral transformation</title>
    <feedworld_mtime>1546992000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Chiyu "Max" Jiang, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Dequan.html">Dequan Wang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Huang:Jingwei.html">Jingwei Huang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Marcus:Philip.html">Philip Marcus</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nie=szlig=ner:Matthias.html">Matthias Nießner</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1901.02070">PDF</a><br/><b>Abstract: </b>Convolutional Neural Networks (CNN) have been successful in processing data
signals that are uniformly sampled in the spatial domain (e.g., images).
However, most data signals do not natively exist on a grid, and in the process
of being sampled onto a uniform physical grid suffer significant aliasing error
and information loss. Moreover, signals can exist in different topological
structures as, for example, points, lines, surfaces and volumes. It has been
challenging to analyze signals with mixed topologies (for example, point cloud
with surface mesh). To this end, we develop mathematical formulations for
Non-Uniform Fourier Transforms (NUFT) to directly, and optimally, sample
nonuniform data signals of different topologies defined on a simplex mesh into
the spectral domain with no spatial sampling error. The spectral transform is
performed in the Euclidean space, which removes the translation ambiguity from
works on the graph spectrum. Our representation has four distinct advantages:
(1) the process causes no spatial sampling error during the initial sampling,
(2) the generality of this approach provides a unified framework for using CNNs
to analyze signals of mixed topologies, (3) it allows us to leverage
state-of-the-art backbone CNN architectures for effective learning without
having to design a particular architecture for a particular data structure in
an ad-hoc fashion, and (4) the representation allows weighted meshes where each
element has a different weight (i.e., texture) indicating local properties. We
achieve results on par with the state-of-the-art for the 3D shape retrieval
task, and a new state-of-the-art for the point cloud to surface reconstruction
task.
</p></div>
    </summary>
    <updated>2019-01-09T23:23:25Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-01-09T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/01/08/postdoc-at-saint-louis-university-apply-by-january-21-2019/</id>
    <link href="https://cstheory-jobs.org/2019/01/08/postdoc-at-saint-louis-university-apply-by-january-21-2019/" rel="alternate" type="text/html"/>
    <title>Postdoc at Saint Louis University (apply by January 21, 2019)</title>
    <summary>I have a openings for 2 postdocs, both starting in 2019: One is flexible in focus, fitting under the broad categories of computational topology/geometry and algorithms. The other is for a shape simplification project, jointly supervised by Dr. David Letscher, focusing on designing and implementing algorithms that use persistent homology as well as other tools […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I have a openings for 2 postdocs, both starting in 2019: One is flexible in focus, fitting under the broad categories of computational topology/geometry and algorithms. The other is for a shape simplification project, jointly supervised by Dr. David Letscher, focusing on designing and implementing algorithms that use persistent homology as well as other tools from computational topology.</p>
<p>Website: <a href="http://cs.slu.edu/~chambers/">http://cs.slu.edu/~chambers/</a><br/>
Email: erin.chambers@slu.edu</p></div>
    </content>
    <updated>2019-01-08T18:05:57Z</updated>
    <published>2019-01-08T18:05:57Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-01-10T04:20:58Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://cstheory.stackexchange.com/q/42176</id>
    <link href="https://cstheory.stackexchange.com/questions/42176/minimal-dfa-corresponding-to-complement-of-a-language" rel="alternate" type="text/html"/>
    <title>minimal DFA corresponding to complement of a language [on hold]</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>is it necessary that number of states in minimal DFA for a language corresponding to L' is equal to the number of states in minimal DFA of the language corresponding to L. </p>

<p>here L' is the complement of the language L.</p>

<p>for example,
number of states in the minimal DFA for the language</p>

<p>L={set of all string containing 01 and 011 as the substring over the alphabet {0,1}}</p>

<p>is 4. </p>

<p>if i'm making the DFA for the complement of this language, i'm getting 3. 
but is it true that it should be 4?</p>

<p>please help!! which one is correct-- 3 or 4?</p></div>
    </summary>
    <updated>2019-01-08T14:41:22Z</updated>
    <published>2019-01-08T14:41:22Z</published>
    <category scheme="https://cstheory.stackexchange.com/tags" term="automata-theory"/>
    <author>
      <name>aambazinga</name>
      <uri>https://cstheory.stackexchange.com/users/51682</uri>
    </author>
    <source>
      <id>https://cstheory.stackexchange.com/feeds/</id>
      <link href="https://cstheory.stackexchange.com/feeds/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory.stackexchange.com/questions" rel="alternate" type="text/html"/>
      <link href="http://www.creativecommons.org/licenses/by-sa/3.0/rdf" rel="license"/>
      <subtitle>most recent 30 from cstheory.stackexchange.com</subtitle>
      <title>Recent Questions - Theoretical Computer Science Stack Exchange</title>
      <updated>2019-01-10T04:21:27Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://cstheory.stackexchange.com/q/42171</id>
    <link href="https://cstheory.stackexchange.com/questions/42171/minimum-relevant-variables-in-linear-system-additive-approximation" rel="alternate" type="text/html"/>
    <title>Minimum relevant variables in linear system - additive approximation</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>In the problem <a href="https://en.wikipedia.org/wiki/Minimum_relevant_variables_in_linear_system" rel="nofollow noreferrer">Minimum Relevant Variables in Linear System</a> (Min-RVLS), the input is a linear system, e.g.:</p>

<p><span class="math-container">$$ A x = b $$</span></p>

<p>and the goal is to find a solution <span class="math-container">$x$</span> with as few nonzero variables as possible. </p>

<p>The problem is known to be NP-hard and hard to approximate to within a constant multiplicative factor (see the wikipedia page for details). </p>

<p>My question is: is anything known about <em>additive</em> approximations? In particular: what is the complexity of finding a solution that has at most <span class="math-container">$\text{OPT}+d$</span> nonzero variables, where <span class="math-container">$\text{OPT}$</span> is the smallest number of nonzero variables in a solution, and <span class="math-container">$d$</span> is some constant?</p></div>
    </summary>
    <updated>2019-01-07T16:08:53Z</updated>
    <published>2019-01-07T16:08:53Z</published>
    <category scheme="https://cstheory.stackexchange.com/tags" term="approximation-algorithms"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="optimization"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="linear-programming"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="approximation-hardness"/>
    <author>
      <name>Erel Segal-Halevi</name>
      <uri>https://cstheory.stackexchange.com/users/9453</uri>
    </author>
    <source>
      <id>https://cstheory.stackexchange.com/feeds/</id>
      <link href="https://cstheory.stackexchange.com/feeds/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory.stackexchange.com/questions" rel="alternate" type="text/html"/>
      <link href="http://www.creativecommons.org/licenses/by-sa/3.0/rdf" rel="license"/>
      <subtitle>most recent 30 from cstheory.stackexchange.com</subtitle>
      <title>Recent Questions - Theoretical Computer Science Stack Exchange</title>
      <updated>2019-01-10T04:21:27Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://cstheory.stackexchange.com/q/42169</id>
    <link href="https://cstheory.stackexchange.com/questions/42169/optimal-algorithm-to-compare-lines-of-different-files-without-repetition" rel="alternate" type="text/html"/>
    <title>Optimal algorithm to compare lines of different files without repetition [on hold]</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I have 1600 ASCII files with 1000 lines in each file. Each line has only one entry and is a floating point number e.g. 1.67923.
Let's denote the line1 of file1 with <code>L(1,1)</code>, line2 of file1 with <code>L(1,2)</code> and so forth to ...<code>L(1,1000)</code>. Similarly, line1 of file2 will be <code>L(2,1)</code> and the last line of file1600 will thus be <code>L(1600,1000)</code>.
My task is to come up with a memory efficient algorithm to compare all lines between each file and the lines within each file. Since, I have 1600 files and 1000 lines in each file, it will take approx. <code>10^12</code> calculations. These first comparisons will look like this:</p>

<pre><code>1. {L(1,1)-L(1,2)}, {L(1,1)-L(1,3)},....,{L(1,1)-L(1,1000)}
2. {L(1,1)-L(2,1)}, {L(1,1)-L(2,2)},....,{L(1,1)-L(2,1000)}
3. {L(1,1)-L(3,1)}, {L(1,1)-L(3,2)},....,{L(1,1)-L(3,1000)}
.
.
. 
</code></pre>

<p>Please note that I don't want repetitions i.e <code>{L(1,1)-L(2,1)} = {L(2,1)-L(1,1)}</code>.
I need to code this problem in Fortran but any help on a general scheme as to how the problem needs to be approached will be useful.
Thank you in advance!  </p></div>
    </summary>
    <updated>2019-01-07T15:12:49Z</updated>
    <published>2019-01-07T15:12:49Z</published>
    <category scheme="https://cstheory.stackexchange.com/tags" term="ds.algorithms"/>
    <author>
      <name>Abedin Y. Abedin</name>
      <uri>https://cstheory.stackexchange.com/users/51670</uri>
    </author>
    <source>
      <id>https://cstheory.stackexchange.com/feeds/</id>
      <link href="https://cstheory.stackexchange.com/feeds/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory.stackexchange.com/questions" rel="alternate" type="text/html"/>
      <link href="http://www.creativecommons.org/licenses/by-sa/3.0/rdf" rel="license"/>
      <subtitle>most recent 30 from cstheory.stackexchange.com</subtitle>
      <title>Recent Questions - Theoretical Computer Science Stack Exchange</title>
      <updated>2019-01-10T04:21:27Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://thmatters.wordpress.com/?p=1259</id>
    <link href="https://thmatters.wordpress.com/2019/01/07/catcs-mailing-list-and-sign-up-link/" rel="alternate" type="text/html"/>
    <title>CATCS mailing list and sign-up link</title>
    <summary>CATCS is starting up a new mailing list to send out annual newsletters. Messages will be sent out 1-2 times every year describing recent projects undertaken by the committee, funding opportunities, links to useful resources, etc. Anyone interested in hearing about our activities is welcome to sign up at this link. You do not have […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>CATCS is starting up a new mailing list to send out annual newsletters. Messages will be sent out 1-2 times every year describing recent projects undertaken by the committee, funding opportunities, links to useful resources, etc. Anyone interested in hearing about our activities is welcome to sign up at <a href="https://groups.google.com/forum/#!forum/catcs-news">this link</a>. You do not have to be a member of SIGACT to sign up.<span style="color: #000000; font-family: Arial, sans-serif;"><br/>
</span></p>
<div/></div>
    </content>
    <updated>2019-01-07T08:42:09Z</updated>
    <published>2019-01-07T08:42:09Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shuchic</name>
    </author>
    <source>
      <id>https://thmatters.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://thmatters.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://thmatters.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://thmatters.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://thmatters.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theory Matters</title>
      <updated>2019-01-10T04:21:27Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://cstheory.stackexchange.com/q/42167</id>
    <link href="https://cstheory.stackexchange.com/questions/42167/decomposition-for-a-certain-class-of-graphs" rel="alternate" type="text/html"/>
    <title>Decomposition for a certain class of graphs</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Suppose a graph, <span class="math-container">$G = (V,E)$</span> is characterized as a lattice/network of cliques as in the picture below. Does there exist some decomposition principle (i.e. on the right) for <span class="math-container">$G$</span>, that yields some special structure that may be used to explain efficiencies experienced with what are supposed to be combinatorial hard problems?</p>

<p><a href="https://i.stack.imgur.com/FTbx8.png" rel="nofollow noreferrer"><img alt="enter image description here" src="https://i.stack.imgur.com/FTbx8.png"/></a></p></div>
    </summary>
    <updated>2019-01-07T06:19:24Z</updated>
    <published>2019-01-07T06:19:24Z</published>
    <category scheme="https://cstheory.stackexchange.com/tags" term="graph-theory"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="graph-algorithms"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="co.combinatorics"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="treewidth"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="integer-lattice"/>
    <author>
      <name>Student</name>
      <uri>https://cstheory.stackexchange.com/users/51578</uri>
    </author>
    <source>
      <id>https://cstheory.stackexchange.com/feeds/</id>
      <link href="https://cstheory.stackexchange.com/feeds/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory.stackexchange.com/questions" rel="alternate" type="text/html"/>
      <link href="http://www.creativecommons.org/licenses/by-sa/3.0/rdf" rel="license"/>
      <subtitle>most recent 30 from cstheory.stackexchange.com</subtitle>
      <title>Recent Questions - Theoretical Computer Science Stack Exchange</title>
      <updated>2019-01-10T04:21:27Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://cstheory.stackexchange.com/q/42166</id>
    <link href="https://cstheory.stackexchange.com/questions/42166/algorithm-for-k-best-non-perfect-bipartite-matchings" rel="alternate" type="text/html"/>
    <title>Algorithm for K-best NON perfect bipartite matchings</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I was reading this great article: <a href="https://core.ac.uk/download/pdf/82129717.pdf" rel="nofollow noreferrer">https://core.ac.uk/download/pdf/82129717.pdf</a></p>

<p>It solves a generalization of the maximum sum assignment problem by finding the k best assignments and not only the best.
However, it only looks at perfect matchings. I'm am especially interested in bipartite matchings.</p>

<p>In particular, for the bipartite graphs, the Theorem 1 p. 161 uses the fact that the matchings are considered perfect.</p>

<p>How can I solve the k-best assignment problem for general bipartite graphs?</p></div>
    </summary>
    <updated>2019-01-06T23:47:08Z</updated>
    <published>2019-01-06T23:47:08Z</published>
    <category scheme="https://cstheory.stackexchange.com/tags" term="graph-algorithms"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="matching"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="bipartite-graphs"/>
    <author>
      <name>Labo</name>
      <uri>https://cstheory.stackexchange.com/users/43172</uri>
    </author>
    <source>
      <id>https://cstheory.stackexchange.com/feeds/</id>
      <link href="https://cstheory.stackexchange.com/feeds/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory.stackexchange.com/questions" rel="alternate" type="text/html"/>
      <link href="http://www.creativecommons.org/licenses/by-sa/3.0/rdf" rel="license"/>
      <subtitle>most recent 30 from cstheory.stackexchange.com</subtitle>
      <title>Recent Questions - Theoretical Computer Science Stack Exchange</title>
      <updated>2019-01-10T04:21:27Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-4355005625360509962</id>
    <link href="https://blog.computationalcomplexity.org/feeds/4355005625360509962/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/01/when-is-kilogram-not-kilogram.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/4355005625360509962" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/4355005625360509962" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/01/when-is-kilogram-not-kilogram.html" rel="alternate" type="text/html"/>
    <title>When is a kilogram not a kilogram?</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">A long long time ago the standards for meter's, kilograms, etc was an actual physical object.<br/>
<br/>
Those days are long gone of course. For example, the meter is defined is the length of the path traveled by light in 1/299,792,458 th of a second. Why such an odd number (can fractions be odd?)? Because they retrofitted it to what that the meter is.  Rather than go to France and compare my stick to the one under a glass case I can just measure the speed of light. Oh. That sounds hard!<br/>
<br/>
It matters a bit since the weight of what was the standard kilogram did increase over time, though of course not by much. When did the measurements for stuff STOP being based on physical objects and was all done based on constants of the universe?<br/>
<br/>
The answer surprised me:<br/>
<br/>
On Nov 16, 2018 (yes, you read that light) they decided that by May 20, 2019, the Kilogram will be defined in terms of Plank's constant. I have not been able to find out how they will use Plank, maybe they don't know yet (they do and its known -- see the first comment) .With that, there are no more standards based on physical objects. Read about it <a href="https://www.wired.com/story/new-kilogram-definition-based-on-planck-constant/">here</a>.<br/>
<br/>
Why did it take so long? I honestly don't know and I am tossing that question out to my readers. You can leave serious or funny answers, and best if I can't tell which is which!<br/>
<br/>
<br/>
<br/>
<br/></div>
    </content>
    <updated>2019-01-06T21:35:00Z</updated>
    <published>2019-01-06T21:35:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>https://plus.google.com/101693130490639305932</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-01-09T22:38:21Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=15562</id>
    <link href="https://rjlipton.wordpress.com/2019/01/06/predictions-for-2019/" rel="alternate" type="text/html"/>
    <title>Predictions For 2019</title>
    <summary>The problem of predicting ‘when’ not just ‘what’ Cropped from Toronto Star source Isaac Asimov was a prolific writer of science fiction and nonfiction. Thirty-five years ago, on the eve of the year 1984, he noted that 35 years had passed since the publication of George Orwell’s 1984. He wrote an exclusive feature for the […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>The problem of predicting ‘when’ not just ‘what’</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2019/01/asimovtorontostar.jpg"><img alt="" class="alignright wp-image-15564" height="167" src="https://rjlipton.files.wordpress.com/2019/01/asimovtorontostar.jpg?w=180&amp;h=167" width="180"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Cropped from Toronto Star <a href="https://www.thestar.com/news/world/2018/12/27/35-years-ago-isaac-asimov-was-asked-by-the-star-to-predict-the-world-of-2019-here-is-what-he-wrote.html">source</a></font></td>
</tr>
</tbody>
</table>
<p>
Isaac Asimov was a prolific writer of science fiction and nonfiction. Thirty-five years ago, on the eve of the year 1984, he noted that 35 years had passed since the publication of George Orwell’s <em>1984</em>. He wrote an exclusive <a href="https://www.thestar.com/news/world/2018/12/27/35-years-ago-isaac-asimov-was-asked-by-the-star-to-predict-the-world-of-2019-here-is-what-he-wrote.html">feature</a> for the Toronto Star newspaper predicting what the world would be like 35 years hence, that is, in 2019.</p>
<p>
Today we give our take on his predictions and make our own for the rest of 2019.</p>
<p>
Asimov’s essay began by presupposing the absence of nuclear holocaust without predicting it. It then focused on two subjects: computerization and use of outer space. On the spectrum of evaluations subtended by this laudatory BBC <a href="https://www.bbc.com/news/technology-46736024">piece</a> and this critical <a href="https://www.thestar.com/news/world/2018/12/27/isaac-asimov-you-were-no-nostradamus.html">column</a> in the Toronto Star itself, we’re closer to the latter. On space he predicted we’d be mining the Moon by now; instead nothing more landed on the Moon until the Chinese <a href="https://en.wikipedia.org/wiki/Chang'e_3">Chang’e 3</a> mission in 2013 and <a href="https://en.wikipedia.org/wiki/Chang'e_4">Chang’e 4</a> happening now. His 35-year span should be lengthened to over a century.</p>
<p>
On computerization and robotics he was mostly right except again for the timespan: he said the transition would be “about over” by 2019 whereas it may be entering its period of greatest flux only now. However, for the end of 1983 we think the “whats” of his predictions were easy. Personal computers had already been around for almost a decade. Computer systems for business were plentiful. The Internet was already a proclaimed goal and the text-based <a href="https://en.wikipedia.org/wiki/Usenet">Usenet</a> was already operating. Asimov’s essay seems to miss how the combination of these three would soon move points of control outward to end-users. </p>
<p>
We still think what he wrote about space and robots will happen. This shows the problem of predictions is not just ‘what’ but ‘when.’ For another instance of being wrong on ‘when’ too soon, Ken told a Harvard Law graduate who visited him in Oxford in 1984 that what we now call <a href="https://en.wikipedia.org/wiki/Deepfake">deepfake</a> videos were imminent. We’ll make the rest of this post more about ‘when’ than ‘what.’</p>
<p>
</p><p/><h2> Predictions in Past Years </h2><p/>
<p/><p>
Here are some predictions that we have made before. Seems we did not make any new predictions last year—oh well—but see <a href="https://rjlipton.wordpress.com/2018/01/02/predictions-we-didnt-make/">this</a>.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <em>No circuit lower bound of <img alt="{1000n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1000n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1000n}"/> or better will be proved for SAT.</em> Well that’s a freebie.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <em>A computer scientist will win a Nobel Prize.</em> No—indeed, less close than other years.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <em>At least five claims that <img alt="{\mathsf{P}=\mathsf{NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D%3D%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{P}=\mathsf{NP}}"/> and five that <img alt="{\mathsf{P} \neq \mathsf{NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D+%5Cneq+%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{P} \neq \mathsf{NP}}"/> will be made.</em> </p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> A “provably” secure crypto-system will be broken. For this one we don’t have to check any claims. We just pocket the ‘yes’ answer. Really, could you ever prove the opposite? How about the <a href="https://cacm.acm.org/magazines/2019/1/233523-imperfect-forward-secrecy/abstract">attack</a> on Diffie-Hellman in the current CACM?</p>
<p>
<img alt="{\bullet}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet}"/> <em>An Earth-sized planet will be detected orbiting within the habitable zone of its single star.</em> The “when” for this one came in 2017 already. We are retiring it.</p>
<p>
<img alt="{\bullet}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet}"/> <em>A Clay problem will be solved, or at least notable progress made.</em> Again we sense that the answer on progress is “no.” This includes saying that nothing substantial seems to have emerged from Sir Michael Atiyah’s <a href="https://aperiodical.com/2018/09/atiyah-riemann-hypothesis-proof-final-thoughts/">claim</a> of proving the Riemann Hypothesis. However, we note <a href="https://gilkalai.wordpress.com/2018/12/25/amazing-karim-adiprasito-proved-the-g-conjecture-for-spheres/">via</a> Gil Kalai’s blog that a longstanding problem called the <img alt="{g}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{g}"/>-conjecture for spheres has been <a href="https://arxiv.org/abs/1812.10454">solved</a> by Karim Adiprasito.</p>
<p>
</p><p/><h2> Predictions This Year </h2><p/>
<p/><p>
We will add some new predictions—it seems unfair to keep repeating sure winners. </p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <em>Deep learning methods will be found able to solve integer factoring.</em> This will place current cryptography is trouble.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <em>Deep learning methods will be found to help prove that factoring is hard.</em></p>
<p>
These may not be as contradictory as they seem. There is a long-known <a href="http://www.cs.sfu.ca/~kabanets/papers/natural-learning-short.pdf">connection</a> between certain learning algorithms and the <a href="https://en.wikipedia.org/wiki/Natural_proof">natural</a> <a href="https://rjlipton.wordpress.com/2009/03/25/whos-afraid-of-natural-proofs/">proofs</a> of Alexander Razborov and Stephen Rudich. The hardness predicate at the core of a natural proof is a classifier to distinguish (succinct) hard Boolean functions from easy ones. There is a duality between upper and lower bounds that in particular leads to the unconditional result that the discrete log problem, which is related to factoring and equally amenable to Peter Shor’s famous polynomial-time quantum algorithm, does not have natural proofs of hardness—because their existence would make discrete log relatively easy. </p>
<p>
Talking about quantum, we predict:</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <em>Quantum supremacy will be proved—finally.</em> But be careful: there is a problem with this whole direction. See the next section.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <em>An algorithm originating in a theoretical model will be enshrined in law.</em> </p>
<p>
There are several near-term opportunities for this. The Supreme Court yesterday agreed to <a href="https://www.cnn.com/2019/01/04/politics/supreme-court-gerrymandering-cases/index.html">hear</a> two cases on partisan gerrymandering, at least one of which promises to codify an algorithmic criterion for excessive vote dilution. Maine adopted a automatic-runoff voting system whose dependence on computer implementation gave grounds for an unsuccessful <a href="https://www.americanthinker.com/blog/2018/11/maine_gop_rep_sues_to_stop_counting_ranked_choice_ballots.html">lawsuit</a>. Algorithmic fairness is a burgeoning area which we <a href="https://rjlipton.wordpress.com/2017/11/20/a-magic-madison-visit/">discussed</a> a year-plus ago. <a href="https://www.sciencemag.org/news/2019/01/can-set-equations-keep-us-census-data-private">Use</a> of differential privacy by the U.S. Census could involve legislation. We distinguish legal provisions from the myriad problematic uses of algorithmic models in public and private <em>policy</em> ranging from credit evaluations to parole decisions to college admissions and much else.</p>
<p>
<img alt="{\bullet}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet}"/> <em>The lines between heuristically solvable and really hard problems will become clearer.</em> We have <a href="https://rjlipton.wordpress.com/2016/07/10/the-world-turned-upside-down/">previously</a> <a href="https://rjlipton.wordpress.com/2014/02/28/practically-pnp/">opined</a> that the great success of SAT solvers in particular renders the <img alt="{\mathsf{P=NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%3DNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{P=NP}}"/> question moot for many purposes. Well, now we say the opposite: SAT solvers will hit a wall.</p>
<p>
</p><p/><h2> Quantum Supremacy and Advantage </h2><p/>
<p/><p>
Ken recently attended a workshop in central New York that aimed to bring together researchers in many fields working on quantum devices. Materials for the workshop led off with the question of building quantum computers and highlighted Gil Kalai’s skeptical position in particular. An <a href="https://rjlipton.wordpress.com/2012/01/30/perpetual-motion-of-the-21st-century/">eight</a>–<a href="https://rjlipton.wordpress.com/2012/02/15/nature-does-not-conspire/">part</a> <a href="https://rjlipton.wordpress.com/2012/06/20/can-you-hear-the-shape-of-a-quantum-computer/">debate</a> between him and Aram Harrow which we hosted in 2012 <a href="https://rjlipton.wordpress.com/2012/03/05/the-quantum-super-pac/">involved</a> also John Preskill and <a href="https://rjlipton.wordpress.com/2012/10/03/quantum-supremacy-or-classical-control/">ended</a> with a discussion of quantum <a href="https://en.wikipedia.org/wiki/Quantum_supremacy">supremacy</a>, a term advanced that year by Preskill. The workshop preferred the term quantum <em>advantage</em>. We interpret these terms as having the following distinction:</p>
<ul>
<li>
(a) Quantum <em>supremacy</em> means that a quantum device can perform general-purpose computations that no classical program or device can emulate in comparably feasible time. <p/>
</li><li>
(b) Quantum <em>advantage</em> means that some particular practical task can be achieved by available quantum devices at lower costs than near-term available classical devices.
</li></ul>
<p>
As theoreticians we tend to think about (a) but many businesses and public-sector organizations would be ecstatic to have (b) in important applications. </p>
<p>
A new angle on (a) was shown by the new construction by Ran Raz and Avishay Tal of an oracle <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/> such that <img alt="{\mathsf{BQP}^A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BBQP%7D%5EA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{BQP}^A}"/> is not in <img alt="{\mathsf{PH}^A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BPH%7D%5EA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{PH}^A}"/>. This was <a href="https://blog.computationalcomplexity.org/2018/12/complexity-year-in-review-2018.html">hailed</a> as the “result of the year” by Lance Fortnow (his second and our first is this <a href="https://eccc.weizmann.ac.il/report/2018/006/">progress</a> on the Unique Games Conjecture), and Scott Aaronson furnished a great <a href="https://www.scottaaronson.com/blog/?p=3827">discussion</a> of its genesis and further ramifications in complexity theory. <a href="https://www.quantamagazine.org/finally-a-problem-that-only-quantum-computers-will-ever-be-able-to-solve-20180621/">Several</a> <a href="https://cacm.acm.org/magazines/2019/1/233514-quantum-leap/fulltext">popular</a> <a href="https://www.thehindu.com/sci-tech/science/quantum-computers-have-an-edge-over-classical-ones-says-the-oracle/article24420375.ece">articles</a> tried to pump this as non-oracle evidence for (a). But there is the over-arching problem:</p>
<blockquote><p><b> </b> <em> We know <img alt="{\mathsf{P \subseteq BPP \subseteq BQP \subseteq PP \subseteq P^{\#P} \subseteq PSPACE}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%5Csubseteq+BPP+%5Csubseteq+BQP+%5Csubseteq+PP+%5Csubseteq+P%5E%7B%5C%23P%7D+%5Csubseteq+PSPACE%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\mathsf{P \subseteq BPP \subseteq BQP \subseteq PP \subseteq P^{\#P} \subseteq PSPACE}}"/> but we don’t know <img alt="{\mathsf{P \neq PSPACE}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%5Cneq+PSPACE%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\mathsf{P \neq PSPACE}}"/>. </em>
</p></blockquote>
<p/><p>
So how are we ever going to be able to <em>prove</em> any form of supremacy? Even if we replace ‘polynomial time’ as our definition of ‘feasible’ by something more concrete, how can we prove that successful classical heuristics <em>do not exist</em>? On a certain practical problem of general import, Ewin Tang, a teenager in Texas advised by Scott, <a href="https://arxiv.org/abs/1807.04271">designed</a> an improved classical algorithm for low-rank matrix completion that <a href="https://www.quantamagazine.org/teenager-finds-classical-alternative-to-quantum-recommendation-algorithm-20180731/">eliminated</a> a previous quantum exponential advantage in the time dependence on the rank parameter. It is not just a case of <em>whether</em> we can prove supremacy, but judging <em>when</em> general quantum computers will be built to realize it.</p>
<p>
Whereas, the <em>when</em> involved in (b) is <em>now</em>. If a quantum device can do something useful now that classical methods are not delivering now, then it does not matter if the latter could be improved at greater hardware and development cost to work a year from now. This has been the gung-ho tenor of many responses to the recently-<a href="https://www.fedscoop.com/trump-signs-national-quantum-initiative-law/">signed</a> National Quantum Initiative Act. We do, however, still need to find and build said devices…</p>
<p>
As for the status of (a), we don’t know any better thought for January than the Janus-like title of this <a href="https://arxiv.org/abs/1807.10749">paper</a> by Igor Markov, Aneeqa Fatima, Sergei Isakov, and Sergio Boixo: </p>
<blockquote><p><b> </b> <em> “Quantum Supremacy Is Both Closer and Farther than It Appears.” </em>
</p></blockquote>
<p>
</p><p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
What are your predictions for 2019? What are the most important matters we’ve left unsaid?</p>
<p>
[added some words to end of intro]</p></font></font></div>
    </content>
    <updated>2019-01-06T19:03:39Z</updated>
    <published>2019-01-06T19:03:39Z</published>
    <category term="All Posts"/>
    <category term="History"/>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="Oldies"/>
    <category term="2018"/>
    <category term="2019"/>
    <category term="Isaac Asimov"/>
    <category term="New Year's"/>
    <category term="predictions"/>
    <category term="quantum advantage"/>
    <category term="quantum supremacy"/>
    <category term="year-in-review"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-01-10T04:20:54Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://cstheory.stackexchange.com/q/42163</id>
    <link href="https://cstheory.stackexchange.com/questions/42163/immutable-space-model" rel="alternate" type="text/html"/>
    <title>Immutable Space Model</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I have heard it said that time is more precious than space because we can reuse space but not time.  What if we treat space with this much reverence?</p>

<h3>What is generally known about models of computation in which space is immutable?</h3>

<p>I would expect such models to initialize each memory cell to some "blank" state and then only allow the writing of some "non-blank" value to each cell at most once.</p>

<p>The study of <a href="https://en.wikipedia.org/wiki/Persistent_data_structure" rel="noreferrer">persistent data structures</a> seems to me like a possible way to answer this question.</p>

<p>I thought of this question while studying functional programming, which highly values immutability.</p></div>
    </summary>
    <updated>2019-01-06T15:37:04Z</updated>
    <published>2019-01-06T15:37:04Z</published>
    <category scheme="https://cstheory.stackexchange.com/tags" term="reference-request"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="ds.data-structures"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="functional-programming"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="space-complexity"/>
    <author>
      <name>Tyson Williams</name>
      <uri>https://cstheory.stackexchange.com/users/3964</uri>
    </author>
    <source>
      <id>https://cstheory.stackexchange.com/feeds/</id>
      <link href="https://cstheory.stackexchange.com/feeds/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory.stackexchange.com/questions" rel="alternate" type="text/html"/>
      <link href="http://www.creativecommons.org/licenses/by-sa/3.0/rdf" rel="license"/>
      <subtitle>most recent 30 from cstheory.stackexchange.com</subtitle>
      <title>Recent Questions - Theoretical Computer Science Stack Exchange</title>
      <updated>2019-01-10T04:21:27Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://cstheory.stackexchange.com/q/42161</id>
    <link href="https://cstheory.stackexchange.com/questions/42161/is-this-partition-problem-strongly-np-complete" rel="alternate" type="text/html"/>
    <title>Is this partition problem strongly NP-complete?</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Some computational problems have variants that appear to be harder. For instance, Graph Automorphism (GA) problem has quasi-polynomial time algorithm ( by Babai's Graph Isomorphism result) while the fixed-point free GA problem is NP-complete. </p>

<p><a href="https://en.wikipedia.org/wiki/Partition_problem" rel="nofollow noreferrer">Partition problem</a> is weakly NP-complete problem since it has pseudo-polynomial time algorithm. I am interested in variants that are strongly NP-complete.</p>

<p>Here is a variant of partition problem:</p>

<p>Restricted partition problem</p>

<p><strong>Input</strong>: Set <span class="math-container">$S$</span> of <span class="math-container">$2N$</span> integers, and a collection <span class="math-container">$P$</span> of pairs from <span class="math-container">$S$</span>, <span class="math-container">$0 \lt |P| \lt N$</span> </p>

<p><strong>Query</strong>: Is there a partition of <span class="math-container">$S$</span> into two equal cardinality parts <span class="math-container">$A$</span> and <span class="math-container">$S-A$</span> such that both parts have the same sum and no pair in <span class="math-container">$P$</span> has both elements in one side of the partition?</p>

<blockquote>
  <p>Is this variant of partition problem NP-complete in the strong sense? </p>
</blockquote>

<p>This was posted first on <a href="https://mathoverflow.net/questions/306039/is-this-partition-problem-strongly-np-complete">Math overflow</a> (I believe the posted answer is incorrect since the proposed dynamic programming algorithm does not take into consideration the cardinality of <span class="math-container">$P$</span>).</p></div>
    </summary>
    <updated>2019-01-06T12:45:42Z</updated>
    <published>2019-01-06T12:45:42Z</published>
    <category scheme="https://cstheory.stackexchange.com/tags" term="cc.complexity-theory"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="partition-problem"/>
    <author>
      <name>Mohammad Al-Turkistany</name>
      <uri>https://cstheory.stackexchange.com/users/495</uri>
    </author>
    <source>
      <id>https://cstheory.stackexchange.com/feeds/</id>
      <link href="https://cstheory.stackexchange.com/feeds/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory.stackexchange.com/questions" rel="alternate" type="text/html"/>
      <link href="http://www.creativecommons.org/licenses/by-sa/3.0/rdf" rel="license"/>
      <subtitle>most recent 30 from cstheory.stackexchange.com</subtitle>
      <title>Recent Questions - Theoretical Computer Science Stack Exchange</title>
      <updated>2019-01-10T04:21:27Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://cstheory.stackexchange.com/q/42160</id>
    <link href="https://cstheory.stackexchange.com/questions/42160/maximize-edges-minus-vertices-in-a-weighted-graph" rel="alternate" type="text/html"/>
    <title>maximize edges minus vertices in a weighted graph</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>for a given weighted vertices and edges graph, we want to find the maximum subgraph. the maximum subgraph is made of some vertices and some edges of the given graph which sum of the edges minus sum of the vertices is maximum. what is the algorithm for this problem? or any help with the code please.</p></div>
    </summary>
    <updated>2019-01-06T11:00:18Z</updated>
    <published>2019-01-06T11:00:18Z</published>
    <category scheme="https://cstheory.stackexchange.com/tags" term="graph-theory"/>
    <author>
      <name>andrew</name>
      <uri>https://cstheory.stackexchange.com/users/51663</uri>
    </author>
    <source>
      <id>https://cstheory.stackexchange.com/feeds/</id>
      <link href="https://cstheory.stackexchange.com/feeds/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory.stackexchange.com/questions" rel="alternate" type="text/html"/>
      <link href="http://www.creativecommons.org/licenses/by-sa/3.0/rdf" rel="license"/>
      <subtitle>most recent 30 from cstheory.stackexchange.com</subtitle>
      <title>Recent Questions - Theoretical Computer Science Stack Exchange</title>
      <updated>2019-01-10T04:21:27Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/003</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/003" rel="alternate" type="text/html"/>
    <title>TR19-003 |  Near-Optimal Lower Bounds on the Threshold Degree and Sign-Rank of AC^0 | 

	Alexander A. Sherstov, 

	Pei Wu</title>
    <summary>The threshold degree of a Boolean function $f\colon\{0,1\}^n\to\{0,1\}$ is the minimum degree of a real polynomial $p$ that represents $f$ in sign: $\mathrm{sgn}\; p(x)=(-1)^{f(x)}.$ A related notion is sign-rank, defined for a Boolean matrix $F=[F_{ij}]$ as the minimum rank of a real matrix $M$ with $\mathrm{sgn}\; M_{ij}=(-1)^{F_{ij}}$.  Determining the maximum threshold degree and sign-rank achievable by constant-depth circuits ($\text{AC}^{0}$) is a well-known and extensively studied open problem, with complexity-theoretic and algorithmic applications.

We give an essentially optimal solution to this problem. For any $\epsilon&gt;0,$ we construct an $\text{AC}^{0}$ circuit in $n$ variables that has threshold degree $\Omega(n^{1-\epsilon})$ and sign-rank $\exp(\Omega(n^{1-\epsilon})),$ improving on the previous best lower bounds of $\Omega(\sqrt{n})$ and $\exp(\tilde{\Omega}(\sqrt{n}))$, respectively. Our results subsume all previous lower bounds on the threshold degree and sign-rank of $\text{AC}^{0}$ circuits of any given depth, with a strict improvement starting at depth $4$. As a corollary, we also obtain near-optimal bounds on the discrepancy, threshold weight, and threshold density of $\text{AC}^{0}$, strictly subsuming previous work on these quantities.  Our work gives some of the strongest lower bounds to date on the communication complexity of $\text{AC}^{0}$.</summary>
    <updated>2019-01-06T08:28:49Z</updated>
    <published>2019-01-06T08:28:49Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-01-10T04:20:40Z</updated>
    </source>
  </entry>
</feed>
