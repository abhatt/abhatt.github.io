<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2019-03-12T20:21:57Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/040</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/040" rel="alternate" type="text/html"/>
    <title>TR19-040 |  The Complexity of Finding {$S$}-factors in Regular Graphs | 

	Sanjana Kolisetty, 

	Linh Le, 

	Ilya Volkovich, 

	Mihalis Yannakakis</title>
    <summary>A graph $G$ has an \emph{$S$-factor} if there exists a spanning subgraph $F$ of $G$ such that for all $v \in V: \deg_F(v) \in S$.
The simplest example of such factor is a $1$-factor, which corresponds to a perfect matching in a graph. In this paper we study the computational complexity of finding $S$-factors in regular graphs.
Our techniques combine some classical as well as recent tools from graph theory.</summary>
    <updated>2019-03-12T17:07:28Z</updated>
    <published>2019-03-12T17:07:28Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-03-12T20:20:42Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/039</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/039" rel="alternate" type="text/html"/>
    <title>TR19-039 |  Planarity, Exclusivity, and Unambiguity | 

	Eric Allender, 

	Archit Chauhan, 

	Samir Datta, 

	Anish Mukherjee</title>
    <summary>We provide new upper bounds on the complexity of the s-t-connectivity problem in planar graphs, thereby providing additional evidence that this problem is not complete for NL. This also yields a new upper bound on the complexity of computing edit distance. Building on these techniques, we provide new upper bounds on the complexity of several other computational problems on planar graphs. All of these problems are shown to be solvable in logarithmic time on a concurrent-read exclusive-write (CREW) PRAM. The new upper bounds are provided by making use of a known characterization of CREW algorithms in terms of "unambiguous" AC$^1$ circuits. This seems to be the first occasion where this characterization has been used in order to provide new upper bounds on natural problems.</summary>
    <updated>2019-03-12T04:11:48Z</updated>
    <published>2019-03-12T04:11:48Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-03-12T20:20:42Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1903.04351</id>
    <link href="http://arxiv.org/abs/1903.04351" rel="alternate" type="text/html"/>
    <title>Coresets for Ordered Weighted Clustering</title>
    <feedworld_mtime>1552348800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Braverman:Vladimir.html">Vladimir Braverman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jiang:Shaofeng_H==C=.html">Shaofeng H.-C. Jiang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Krauthgamer:Robert.html">Robert Krauthgamer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wu:Xuan.html">Xuan Wu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1903.04351">PDF</a><br/><b>Abstract: </b>We design coresets for Ordered k-Median, a generalization of classical
clustering problems such as k-Median and k-Center, that offers a more flexible
data analysis, like easily combining multiple objectives (e.g., to increase
fairness or for Pareto optimization). Its objective function is defined via the
Ordered Weighted Averaging (OWA) paradigm of Yager (1988), where data points
are weighted according to a predefined weight vector, but in order of their
contribution to the objective (distance from the centers).
</p>
<p>A powerful data-reduction technique, called a coreset, is to summarize a
point set $X$ in $\mathbb{R}^d$ into a small (weighted) point set $X'$, such
that for every set of $k$ potential centers, the objective value of the coreset
$X'$ approximates that of $X$ within factor $1\pm \epsilon$. When there are
multiple objectives (weights), the above standard coreset might have limited
usefulness, whereas in a \emph{simultaneous} coreset, which was introduced
recently by Bachem and Lucic and Lattanzi (2018), the above approximation holds
for all weights (in addition to all centers). Our main result is a construction
of a simultaneous coreset of size $O_{\epsilon, d}(k^2 \log^2 |X|)$ for Ordered
k-Median.
</p>
<p>To validate the efficacy of our coreset construction we ran experiments on a
real geographical data set. We find that our algorithm produces a small
coreset, which translates to a massive speedup of clustering computations,
while maintaining high accuracy for a range of weights.
</p></div>
    </summary>
    <updated>2019-03-12T01:31:50Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-03-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1903.04325</id>
    <link href="http://arxiv.org/abs/1903.04325" rel="alternate" type="text/html"/>
    <title>The relationship between word complexity and computational complexity in subshifts</title>
    <feedworld_mtime>1552348800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pavlov:Ronnie.html">Ronnie Pavlov</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vanier:Pascal.html">Pascal Vanier</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1903.04325">PDF</a><br/><b>Abstract: </b>We prove several results about the relationship between the word complexity
function of a subshift and the set of Turing degrees of points of the subshift,
which we call the Turing spectrum. Among other results, we show that a Turing
spectrum can be realized via a subshift of linear complexity if and only if it
consists of the union of a finite set and a finite number of cones, that a
Turing spectrum can be realized via a subshift of exponential complexity (i.e.
positive entropy) if and only if it contains a cone, and that every Turing
spectrum which either contains degree 0 or is a union of cones is realizable by
subshifts with a wide range of 'intermediate' complexity growth rates between
linear and exponential.
</p></div>
    </summary>
    <updated>2019-03-12T01:20:31Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-03-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1903.04194</id>
    <link href="http://arxiv.org/abs/1903.04194" rel="alternate" type="text/html"/>
    <title>Fitting Tractable Convex Sets to Support Function Evaluations</title>
    <feedworld_mtime>1552348800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Soh:Yong_Sheng.html">Yong Sheng Soh</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chandrasekaran:Venkat.html">Venkat Chandrasekaran</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1903.04194">PDF</a><br/><b>Abstract: </b>The geometric problem of estimating an unknown compact convex set from
evaluations of its support function arises in a range of scientific and
engineering applications. Traditional approaches typically rely on estimators
that minimize the error over all possible compact convex sets; in particular,
these methods do not allow for the incorporation of prior structural
information about the underlying set and the resulting estimates become
increasingly more complicated to describe as the number of measurements
available grows. We address both of these shortcomings by describing a
framework for estimating tractably specified convex sets from support function
evaluations. Building on the literature in convex optimization, our approach is
based on estimators that minimize the error over structured families of convex
sets that are specified as linear images of concisely described sets -- such as
the simplex or the free spectrahedron -- in a higher-dimensional space that is
not much larger than the ambient space. Convex sets parametrized in this manner
are significant from a computational perspective as one can optimize linear
functionals over such sets efficiently; they serve a different purpose in the
inferential context of the present paper, namely, that of incorporating
regularization in the reconstruction while still offering considerable
expressive power. We provide a geometric characterization of the asymptotic
behavior of our estimators, and our analysis relies on the property that
certain sets which admit semialgebraic descriptions are Vapnik-Chervonenkis
(VC) classes. Our numerical experiments highlight the utility of our framework
over previous approaches in settings in which the measurements available are
noisy or small in number as well as those in which the underlying set to be
reconstructed is non-polyhedral.
</p></div>
    </summary>
    <updated>2019-03-12T01:42:17Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-03-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1903.04097</id>
    <link href="http://arxiv.org/abs/1903.04097" rel="alternate" type="text/html"/>
    <title>Bus Manufacturing Workshop Scheduling Method with Routing Buffer</title>
    <feedworld_mtime>1552348800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Han:Zhonghua.html">Zhonghua Han</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Jingyuan.html">Jingyuan Zhang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dong:Xiaoting.html">Xiaoting Dong</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/q/Qi:Yuanwei.html">Yuanwei Qi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1903.04097">PDF</a><br/><b>Abstract: </b>Aiming at solving the problem that the moving route is complicated and the
scheduling is difficult in the routing buffer of the bus in the manufacturing
workshop, a routing buffer mathematical programming model for bus manufacturing
workshop is proposed. We design a moving approach for minimizing the total
setup cost for moving in routing buffer. The framework and the solution ofthe
optimization problem of such a bus manufacturing workshop scheduling with
routing buffer arepresented. The evaluation results show that, comparing with
the irregularly guided moving method, the proposed method can better guide the
bus movement in routing buffer by reducing the total setup time of all buses
processed at the next stage, and obtaining a better scheduling optimization
solution with minimize maximum total completion time.
</p></div>
    </summary>
    <updated>2019-03-12T01:31:05Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-03-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1903.04054</id>
    <link href="http://arxiv.org/abs/1903.04054" rel="alternate" type="text/html"/>
    <title>Asymptotically faster algorithm for counting self-avoiding walks and self-avoiding polygons</title>
    <feedworld_mtime>1552348800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zbarsky:Samuel.html">Samuel Zbarsky</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1903.04054">PDF</a><br/><b>Abstract: </b>We give an algorithm for counting self-avoiding walks or self-avoiding
polygons that runs in time $\exp(C\sqrt{n\log n})$ on 2-dimensional lattices
and time $\exp(C_dn^{(d-1)/d}\log n)$ on $d$-dimensional lattices for $d&gt;2$.
</p></div>
    </summary>
    <updated>2019-03-12T01:33:08Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-03-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1903.04039</id>
    <link href="http://arxiv.org/abs/1903.04039" rel="alternate" type="text/html"/>
    <title>Knowledge compilation languages as proof systems</title>
    <feedworld_mtime>1552348800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Capelli:Florent.html">Florent Capelli</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1903.04039">PDF</a><br/><b>Abstract: </b>In this paper, we study proof systems in the sense of Cook-Reckhow for
problems that are higher in the polynomial hierarchy than coNP, in particular,
#SAT and maxSAT. We start by explaining how the notion of Cook-Reckhow proof
systems can be apply to these problems and show how one can twist existing
languages in knowledge compilation such as decision DNNF so that they can be
seen as proof systems for problems such as #SAT and maxSAT.
</p></div>
    </summary>
    <updated>2019-03-12T01:29:59Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-03-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1903.04015</id>
    <link href="http://arxiv.org/abs/1903.04015" rel="alternate" type="text/html"/>
    <title>NormalNet: Learning based Guided Normal Filtering for Mesh Denoising</title>
    <feedworld_mtime>1552348800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhao:Wenbo.html">Wenbo Zhao</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liu:Xianming.html">Xianming Liu</a>, Yongsen Zhao, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fan:Xiaopeng.html">Xiaopeng Fan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhao:Debin.html">Debin Zhao</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1903.04015">PDF</a><br/><b>Abstract: </b>Mesh denoising is a critical technology in geometry processing, which aims to
recover high-fidelity 3D mesh models of objects from noise-corrupted versions.
In this work, we propose a deep learning based face normal filtering scheme for
mesh denoising, called \textit{NormalNet}. Different from natural images, for
mesh, it is difficult to collect enough examples to build a robust end-to-end
training scheme for deep networks. To remedy this problem, we propose an
iterative framework to generate enough face-normal pairs, based on which a
convolutional neural networks (CNNs) based scheme is designed for guidance
normal learning. Moreover, to facilitate the 3D convolution operation in CNNs,
for each face in mesh, we propose a voxelization strategy to transform
irregular local mesh structure into regular 4D-array form. Finally, guided
normal filtering is performed to obtain filtered face normals, according to
which denoised positions of vertices are derived. Compared to the
state-of-the-art works, the proposed scheme can generate accurate guidance
normals and remove noise effectively while preserving original features and
avoiding pseudo-features.
</p></div>
    </summary>
    <updated>2019-03-12T01:36:27Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-03-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1903.03944</id>
    <link href="http://arxiv.org/abs/1903.03944" rel="alternate" type="text/html"/>
    <title>Near Optimal Online Algorithms and Fast Approximation Algorithms for Resource Allocation Problems</title>
    <feedworld_mtime>1552348800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Devanur:Nikhil_R=.html">Nikhil R. Devanur</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jain:Kamal.html">Kamal Jain</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sivan:Balasubramanian.html">Balasubramanian Sivan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wilkens:Christopher_A=.html">Christopher A. Wilkens</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1903.03944">PDF</a><br/><b>Abstract: </b>We present prior robust algorithms for a large class of resource allocation
problems where requests arrive one-by-one (online), drawn independently from an
unknown distribution at every step. We design a single algorithm that, for
every possible underlying distribution, obtains a $1-\epsilon$ fraction of the
profit obtained by an algorithm that knows the entire request sequence ahead of
time. The factor $\epsilon$ approaches $0$ when no single request
consumes/contributes a significant fraction of the global
consumption/contribution by all requests together. We show that the tradeoff we
obtain here that determines how fast $\epsilon$ approaches $0$, is near
optimal: we give a nearly matching lower bound showing that the tradeoff cannot
be improved much beyond what we obtain.
</p>
<p>Going beyond the model of a static underlying distribution, we introduce the
adversarial stochastic input model, where an adversary, possibly in an adaptive
manner, controls the distributions from which the requests are drawn at each
step. Placing no restriction on the adversary, we design an algorithm that
obtains a $1-\epsilon$ fraction of the optimal profit obtainable w.r.t. the
worst distribution in the adversarial sequence.
</p>
<p>In the offline setting we give a fast algorithm to solve very large LPs with
both packing and covering constraints. We give algorithms to approximately
solve (within a factor of $1+\epsilon$) the mixed packing-covering problem with
$O(\frac{\gamma m \log (n/\delta)}{\epsilon^2})$ oracle calls where the
constraint matrix of this LP has dimension $n\times m$, the success probability
of the algorithm is $1-\delta$, and $\gamma$ quantifies how significant a
single request is when compared to the sum total of all requests.
</p>
<p>We discuss implications of our results to several special cases including
online combinatorial auctions, network routing and the adwords problem.
</p></div>
    </summary>
    <updated>2019-03-12T01:33:13Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-03-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1903.03697</id>
    <link href="http://arxiv.org/abs/1903.03697" rel="alternate" type="text/html"/>
    <title>Scalable and Congestion-aware Routing for Autonomous Mobility-on-Demand via Frank-Wolfe Optimization</title>
    <feedworld_mtime>1552348800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Solovey:Kiril.html">Kiril Solovey</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Salazar:Mauro.html">Mauro Salazar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pavone:Marco.html">Marco Pavone</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1903.03697">PDF</a><br/><b>Abstract: </b>We consider the problem of vehicle routing for Autonomous Mobility-on-Demand
(AMoD) systems, wherein a fleet of self-driving vehicles provides on-demand
mobility in a given environment. Specifically, the task it to compute routes
for the vehicles (both customer-carrying and empty travelling) so that travel
demand is fulfilled and operational cost is minimized. The routing process must
account for congestion effects affecting travel times, as modeled via a
volume-delay function (VDF). Route planning with VDF constraints is notoriously
challenging, as such constraints compound the combinatorial complexity of the
routing optimization process. Thus, current solutions for AMoD routing resort
to relaxations of the congestion constraints, thereby trading optimality with
computational efficiency. In this paper, we present the first
computationally-efficient approach for AMoD routing where VDF constraints are
explicitly accounted for. We demonstrate that our approach is faster by at
least one order of magnitude with respect to the state of the art, while
providing higher quality solutions. From a methodological standpoint, the key
technical insight is to establish a mathematical reduction of the AMoD routing
problem to the classical traffic assignment problem (a related vehicle-routing
problem where empty traveling vehicles are not present). Such a reduction
allows us to extend powerful algorithmic tools for traffic assignment, which
combine the classic Frank-Wolfe algorithm with modern techniques for
pathfinding, to the AMoD routing problem. We provide strong theoretical
guarantees for our approach in terms of near-optimality of the returned
solution.
</p></div>
    </summary>
    <updated>2019-03-12T01:30:06Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-03-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1903.03693</id>
    <link href="http://arxiv.org/abs/1903.03693" rel="alternate" type="text/html"/>
    <title>Active Learning a Convex Body in Low Dimensions</title>
    <feedworld_mtime>1552348800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Har=Peled:Sariel.html">Sariel Har-Peled</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jones:Mitchell.html">Mitchell Jones</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rahul:Saladi.html">Saladi Rahul</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1903.03693">PDF</a><br/><b>Abstract: </b>Consider a set $P \subseteq \mathbb{R}^d$ of $n$ points, and a convex body
$C$ provided via a separation oracle. The task at hand is to decide for each
point of $P$ if it is in $C$. We show that one can solve this problem in two
and three dimensions using $O( \mathrm{index}(P) \log n)$ queries, where
$\mathrm{index}(P)$ is the largest subset of points of $P$ in convex position.
Furthermore, we show that in two dimensions one can solve this problem using
$O( \mathrm{price}(P,C) \log^2 n )$ oracle queries, where $\mathrm{price}(P,
C)$ is the minimal number of queries that any algorithm for this specific
instance requires.
</p></div>
    </summary>
    <updated>2019-03-12T01:34:25Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-03-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1903.03636</id>
    <link href="http://arxiv.org/abs/1903.03636" rel="alternate" type="text/html"/>
    <title>How fast can we reach a target vertex in stochastic temporal graphs?</title>
    <feedworld_mtime>1552348800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Akrida:Eleni_C=.html">Eleni C. Akrida</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mertzios:George_B=.html">George B. Mertzios</a>, Sotiris Nikoletseas, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Raptopoulos:Christoforos.html">Christoforos Raptopoulos</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Spirakis:Paul_G=.html">Paul G. Spirakis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zamaraev:Viktor.html">Viktor Zamaraev</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1903.03636">PDF</a><br/><b>Abstract: </b>Temporal graphs are used to abstractly model real-life networks that are
inherently dynamic in nature. Given a static underlying graph $G=(V,E)$, a
temporal graph on $G$ is a sequence of snapshots $G_t$, one for each time step
$t\geq 1$. In this paper we study stochastic temporal graphs, i.e. stochastic
processes $\mathcal{G}$ whose random variables are the snapshots of a temporal
graph on $G$. A natural feature observed in various real-life scenarios is a
memory effect in the appearance probabilities of particular edges; i.e. the
probability an edge $e\in E$ appears at time step $t$ depends on its appearance
(or absence) at the previous $k$ steps. In this paper we study the hierarchy of
models memory-$k$, addressing this memory effect in an edge-centric network
evolution: every edge of $G$ has its own independent probability distribution
for its appearance over time. Clearly, for every $k\geq 1$, memory-$(k-1)$ is a
special case of memory-$k$. We make a clear distinction between the values
$k=0$ ("no memory") and $k\geq 1$ ("some memory"), as in some cases these
models exhibit a fundamentally different computational behavior, as our results
indicate. For every $k\geq 0$ we investigate the complexity of two naturally
related, but fundamentally different, temporal path (journey) problems: MINIMUM
ARRIVAL and BEST POLICY. In the first problem we are looking for the expected
arrival time of a foremost journey between two designated vertices $s,y$. In
the second one we are looking for the arrival time of the best policy for
actually choosing a particular $s$-$y$ journey. We present a detailed
investigation of the computational landscape of both problems for the different
values of memory $k$. Among other results we prove that, surprisingly, MINIMUM
ARRIVAL is strictly harder than BEST POLICY; in fact, for $k=0$, MINIMUM
ARRIVAL is #P-hard while BEST POLICY is solvable in $O(n^2)$ time.
</p></div>
    </summary>
    <updated>2019-03-12T01:20:41Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-03-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1903.02958</id>
    <link href="http://arxiv.org/abs/1903.02958" rel="alternate" type="text/html"/>
    <title>Reparameterizing Distributions on Lie Groups</title>
    <feedworld_mtime>1552348800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Falorsi:Luca.html">Luca Falorsi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Haan:Pim_de.html">Pim de Haan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Davidson:Tim_R=.html">Tim R. Davidson</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Forr=eacute=:Patrick.html">Patrick Forré</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1903.02958">PDF</a><br/><b>Abstract: </b>Reparameterizable densities are an important way to learn probability
distributions in a deep learning setting. For many distributions it is possible
to create low-variance gradient estimators by utilizing a `reparameterization
trick'. Due to the absence of a general reparameterization trick, much research
has recently been devoted to extend the number of reparameterizable
distributional families. Unfortunately, this research has primarily focused on
distributions defined in Euclidean space, ruling out the usage of one of the
most influential class of spaces with non-trivial topologies: Lie groups. In
this work we define a general framework to create reparameterizable densities
on arbitrary Lie groups, and provide a detailed practitioners guide to further
the ease of usage. We demonstrate how to create complex and multimodal
distributions on the well known oriented group of 3D rotations,
$\operatorname{SO}(3)$, using normalizing flows. Our experiments on applying
such distributions in a Bayesian setting for pose estimation on objects with
discrete and continuous symmetries, showcase their necessity in achieving
realistic uncertainty estimates.
</p></div>
    </summary>
    <updated>2019-03-12T01:42:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-03-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>http://corner.mimuw.edu.pl/?p=1067</id>
    <link href="http://corner.mimuw.edu.pl/?p=1067" rel="alternate" type="text/html"/>
    <title>HALG 2019 (Highlights of Algorithms) - Final Call for Short Contributed Presentations</title>
    <summary>I think we have an exciting program that awaits us during HALG 2019: http://highlightsofalgorithms.org/speakers. Please remember that the call for short contributed talks ends this week - on 15th of March. </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I think we have an exciting program that awaits us during HALG 2019: http://highlightsofalgorithms.org/speakers. Please remember that the call for short contributed talks ends this week - on 15th of March. </p></div>
    </content>
    <updated>2019-03-11T21:17:51Z</updated>
    <published>2019-03-11T21:17:51Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>sank</name>
    </author>
    <source>
      <id>http://corner.mimuw.edu.pl</id>
      <link href="http://corner.mimuw.edu.pl/?feed=rss2" rel="self" type="application/atom+xml"/>
      <link href="http://corner.mimuw.edu.pl" rel="alternate" type="text/html"/>
      <subtitle>University of Warsaw</subtitle>
      <title>Banach's Algorithmic Corner</title>
      <updated>2019-03-11T23:48:43Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/03/11/postdoc-at-technion-israel-institute-of-technology-apply-by-april-30-2019/</id>
    <link href="https://cstheory-jobs.org/2019/03/11/postdoc-at-technion-israel-institute-of-technology-apply-by-april-30-2019/" rel="alternate" type="text/html"/>
    <title>Postdoc at Technion Israel Institute of Technology (apply by April 30, 2019)</title>
    <summary>For an exciting project funded by the European Commission for Research (ERC), I currently have several openings for post-docs working in the intersection of theoretical computer science and learning theory. Website: https://nailon.net.technion.ac.il/openings/ Email: nailon@cs.technion.ac.il</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>For an exciting project funded by the European Commission for Research (ERC), I currently have several openings for post-docs working in the intersection of theoretical computer science and learning theory.</p>
<p>Website: <a href="https://nailon.net.technion.ac.il/openings/">https://nailon.net.technion.ac.il/openings/</a><br/>
Email: nailon@cs.technion.ac.il</p></div>
    </content>
    <updated>2019-03-11T15:10:35Z</updated>
    <published>2019-03-11T15:10:35Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-03-12T20:20:51Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://adamsheffer.wordpress.com/?p=5378</id>
    <link href="https://adamsheffer.wordpress.com/2019/03/11/incidences-open-problem-part-1/" rel="alternate" type="text/html"/>
    <title>Incidences: Open Problems (part 1)</title>
    <summary>The past decade brought us several breakthroughs in the study of geometric incidences. Most importantly, Guth and Katz introduced polynomial partitioning, and this has become the main technique for studying incidences. The recent breakthroughs sometimes leads to a wrong impression about the state of this field. Actually, most of the main incidence problems are still […]</summary>
    <updated>2019-03-11T01:06:19Z</updated>
    <published>2019-03-11T01:06:19Z</published>
    <category term="Incidences"/>
    <author>
      <name>Adam Sheffer</name>
    </author>
    <source>
      <id>https://adamsheffer.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://adamsheffer.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://adamsheffer.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://adamsheffer.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://adamsheffer.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Discrete geometry and other typos</subtitle>
      <title>Some Plane Truths</title>
      <updated>2019-03-12T20:21:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1903.03605</id>
    <link href="http://arxiv.org/abs/1903.03605" rel="alternate" type="text/html"/>
    <title>Understanding Sparse JL for Feature Hashing</title>
    <feedworld_mtime>1552262400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jagadeesan:Meena.html">Meena Jagadeesan</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1903.03605">PDF</a><br/><b>Abstract: </b>Feature hashing and more general projection schemes are commonly used in
machine learning to reduce the dimensionality of feature vectors. The goal is
to efficiently project a high-dimensional feature vector living in
$\mathbb{R}^n$ into a lower-dimensional space $\mathbb{R}^m$, while
approximately preserving Euclidean norm. These schemes can be constructed using
sparse random projections, for example using a sparse Johnson-Lindenstrauss
(JL) transform. In practice, feature vectors often have a low
$\ell_\infty$-to-$\ell_2$ norm ratio, and for this restricted set of vectors,
many sparse JL-based schemes can achieve the norm-preserving objective with
smaller dimension $m$ than is necessary for the scheme on the full space
$\mathbb{R}^n$. A line of work introduced by Weinberger et. al (ICML '09)
analyzes the sparse JL transform with one nonzero entry per column, which is a
standard feature hashing scheme. Recently, Freksen, Kamma, and Larsen (NIPS
'18) closed this line of work by proving an essentially tight tradeoff between
$\ell_\infty$-to-$\ell_2$ norm ratio, distortion, failure probability, and
dimension $m$ for this feature hashing scheme.
</p>
<p>We study more general projection schemes that are constructed using sparse JL
transforms permitted to have more than one (but still a small fraction of)
nonzero entries per column. Our main result is an essentially tight tradeoff
between $\ell_\infty$-to-$\ell_2$ norm ratio, distortion, failure probability,
and dimension $m$ for a general sparsity $s$, that generalizes the result of
Freksen et. al. We also connect our result to the sparse JL literature by
showing that it implies lower bounds on dimension-sparsity tradeoffs that
essentially match upper bounds by Cohen (SODA '16). Moreover, our proof
introduces a new perspective on bounding moments of certain random variables,
that could be useful in other settings in theoretical computer science.
</p></div>
    </summary>
    <updated>2019-03-11T23:46:03Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-03-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1903.03560</id>
    <link href="http://arxiv.org/abs/1903.03560" rel="alternate" type="text/html"/>
    <title>Belga B-trees</title>
    <feedworld_mtime>1552262400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Demaine:Erik_D=.html">Erik D. Demaine</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Iacono:John.html">John Iacono</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Koumoutsos:Grigorios.html">Grigorios Koumoutsos</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Langerman:Stefan.html">Stefan Langerman</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1903.03560">PDF</a><br/><b>Abstract: </b>We revisit self-adjusting external memory tree data structures, which combine
the optimal (and practical) worst-case I/O performances of B-trees, while
adapting to the online distribution of queries. Our approach is analogous to
undergoing efforts in the BST model, where Tango Trees (Demaine et al. 2007)
were shown to be $O(\log\log N)$-competitive with the runtime of the best
offline binary search tree on every sequence of searches. Here we formalize the
B-Tree model as a natural generalization of the BST model. We prove lower
bounds for the B-Tree model, and introduce a B-Tree model data structure, the
Belga B-tree, that executes any sequence of searches within a $O(\log \log N)$
factor of the best offline B-tree model algorithm, provided $B=\log^{O(1)}N$.
We also show how to transform any static BST into a static B-tree which is
faster by a $\Theta(\log B)$ factor; the transformation is randomized and we
show that randomization is necessary to obtain any significant speedup.
</p></div>
    </summary>
    <updated>2019-03-11T23:30:41Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-03-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1903.03520</id>
    <link href="http://arxiv.org/abs/1903.03520" rel="alternate" type="text/html"/>
    <title>The One-Way Communication Complexity of Dynamic Time Warping Distance</title>
    <feedworld_mtime>1552262400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Braverman:Vladimir.html">Vladimir Braverman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Charikar:Moses.html">Moses Charikar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kuszmaul:William.html">William Kuszmaul</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Woodruff:David_P=.html">David P. Woodruff</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yang:Lin_F=.html">Lin F. Yang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1903.03520">PDF</a><br/><b>Abstract: </b>We resolve the randomized one-way communication complexity of Dynamic Time
Warping (DTW) distance. We show that there is an efficient one-way
communication protocol using $\widetilde{O}(n/\alpha)$ bits for the problem of
computing an $\alpha$-approximation for DTW between strings $x$ and $y$ of
length $n$, and we prove a lower bound of $\Omega(n / \alpha)$ bits for the
same problem. Our communication protocol works for strings over an arbitrary
metric of polynomial size and aspect ratio, and we optimize the logarithmic
factors depending on properties of the underlying metric, such as when the
points are low-dimensional integer vectors equipped with various metrics or
have bounded doubling dimension. We also consider linear sketches of DTW,
showing that such sketches must have size $\Omega(n)$.
</p></div>
    </summary>
    <updated>2019-03-11T23:20:33Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-03-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1903.03487</id>
    <link href="http://arxiv.org/abs/1903.03487" rel="alternate" type="text/html"/>
    <title>Set CRDT com M\'ultiplas Pol\'iticas de Resolu\c{c}\~ao de Conflitos</title>
    <feedworld_mtime>1552262400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>André Rijo, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Ferreira:Carla.html">Carla Ferreira</a>, Nuno Preguiça <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1903.03487">PDF</a><br/><b>Abstract: </b>Um CRDT \'e um tipo de dados que pode ser replicado e modificado
concorrentemente sem coordena\c{c}\~ao, garantindo-se a converg\^encia das
r\'eplicas atrav\'es da resolu\c{c}\~ao autom\'atica de conflitos. Cada CRDT
implementa uma pol\'itica espec\'ifica para resolver conflitos. Por exemplo, um
conjunto CRDT add-wins d\'a prioridade ao "add" aquando da execu\c{c}\~ao
concorrente de um "add" e "rem" do mesmo elemento. Em algumas aplica\c{c}\~oes
pode ser necess\'ario usar diferentes pol\'iticas para diferentes
execu\c{c}\~oes de uma opera\c{c}\~ao -- por exemplo, uma aplica\c{c}\~ao que
utilize um conjunto CRDT add-wins pode querer que alguns "removes" ganhem sobre
"adds" concorrentes. Neste artigo \'e apresentado e avaliado o desenho dum
conjunto CRDT que implementa as sem\^anticas referidas.
</p>
<p>---
</p>
<p>Conflict-Free Replicated Data Types (CRDTs) allow objects to be replicated
and concurrently modified without coordination. CRDTs solve conflicts
automatically and provide eventual consistency. Typically each CRDT uses a
specific policy for solving conflicts. For example, in an add-wins set CRDT,
when an element is concurrently add and removed in different replicas, priority
is given to add, i.e., the element stays in the set. Unfortunately, this may be
inadequate for some applications - it may be desired to overrule the default
policy for some operation executions. For example, an application using an
add-wins set may want some removes to win over concurrent adds. This paper
present the design of a set CRDT that implements such semantics.
</p></div>
    </summary>
    <updated>2019-03-11T23:30:32Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-03-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1903.03479</id>
    <link href="http://arxiv.org/abs/1903.03479" rel="alternate" type="text/html"/>
    <title>NEARBY Platform for Automatic Asteroids Detection and EURONEAR Surveys</title>
    <feedworld_mtime>1552262400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gorgan:Dorian.html">Dorian Gorgan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vaduvescu:Ovidiu.html">Ovidiu Vaduvescu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Stefanut:Teodor.html">Teodor Stefanut</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bacu:Victor.html">Victor Bacu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sabou:Adrian.html">Adrian Sabou</a>, Denisa Copandean Balazs, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nandra:Constantin.html">Constantin Nandra</a>, Costin Boldea, Afrodita Boldea, Marian Predatu, Viktoria Pinter, Adrian Stanica <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1903.03479">PDF</a><br/><b>Abstract: </b>The survey of the nearby space and continuous monitoring of the Near Earth
Objects (NEOs) and especially Near Earth Asteroids (NEAs) are essential for the
future of our planet and should represent a priority for our solar system
research and nearby space exploration. More computing power and sophisticated
digital tracking algorithms are needed to cope with the larger astronomy
imaging cameras dedicated for survey telescopes. The paper presents the NEARBY
platform that aims to experiment new algorithms for automatic image reduction,
detection and validation of moving objects in astronomical surveys,
specifically NEAs. The NEARBY platform has been developed and experimented
through a collaborative research work between the Technical University of
Cluj-Napoca (UTCN) and the University of Craiova, Romania, using observing
infrastructure of the Instituto de Astrofisica de Canarias (IAC) and Isaac
Newton Group (ING), La Palma, Spain. The NEARBY platform has been developed and
deployed on the UTCN's cloud infrastructure and the acquired images are
processed remotely by the astronomers who transfer it from ING through the web
interface of the NEARBY platform. The paper analyzes and highlights the main
aspects of the NEARBY platform development, and the results and conclusions on
the EURONEAR surveys.
</p></div>
    </summary>
    <updated>2019-03-11T23:45:06Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-03-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1903.03404</id>
    <link href="http://arxiv.org/abs/1903.03404" rel="alternate" type="text/html"/>
    <title>Accelerating Generalized Linear Models with MLWeaving: A One-Size-Fits-All System for Any-precision Learning</title>
    <feedworld_mtime>1552262400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Zeke.html">Zeke Wang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kara:Kaan.html">Kaan Kara</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Hantian.html">Hantian Zhang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Alonso:Gustavo.html">Gustavo Alonso</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mutlu:Onur.html">Onur Mutlu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Ce.html">Ce Zhang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1903.03404">PDF</a><br/><b>Abstract: </b>Learning from the data stored in a database is an important function
increasingly available in relational engines. Methods using lower precision
input data are of special interest given their overall higher efficiency but,
in databases, these methods have a hidden cost: the quantization of the real
value into a smaller number is an expensive step. To address the issue, in this
paper we present MLWeaving, a data structure and hardware acceleration
technique intended to speed up learning of generalized linear models in
databases. ML-Weaving provides a compact, in-memory representation enabling the
retrieval of data at any level of precision. MLWeaving also takes advantage of
the increasing availability of FPGA-based accelerators to provide a highly
efficient implementation of stochastic gradient descent. The solution adopted
in MLWeaving is more efficient than existing designs in terms of space (since
it can process any resolution on the same design) and resources (via the use of
bit-serial multipliers). MLWeaving also enables the runtime tuning of
precision, instead of a fixed precision level during the training. We
illustrate this using a simple, dynamic precision schedule. Experimental
results show MLWeaving achieves up to16 performance improvement over
low-precision CPU implementations of first-order methods.
</p></div>
    </summary>
    <updated>2019-03-11T23:24:01Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-03-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1903.03211</id>
    <link href="http://arxiv.org/abs/1903.03211" rel="alternate" type="text/html"/>
    <title>The VC Dimension of Metric Balls under Fr\'echet and Hausdorff Distances</title>
    <feedworld_mtime>1552262400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Driemel:Anne.html">Anne Driemel</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Phillips:Jeff_M=.html">Jeff M. Phillips</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Psarros:Ioannis.html">Ioannis Psarros</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1903.03211">PDF</a><br/><b>Abstract: </b>The Vapnik-Chervonenkis dimension provides a notion of complexity for systems
of sets. If the VC dimension is small, then knowing this can drastically
simplify fundamental computational tasks such as classification, range
counting, and density estimation through the use of sampling bounds. We analyze
set systems where the ground set $X$ is a set of polygonal curves in
$\mathbb{R}^d$ and the sets $\mathcal{R}$ are metric balls defined by curve
similarity metrics, such as the Fr\'echet distance and the Hausdorff distance,
as well as their discrete counterparts. We derive upper and lower bounds on the
VC dimension that imply useful sampling bounds in the setting that the number
of curves is large, but the complexity of the individual curves is small. Our
upper bounds are either near-quadratic or near-linear in the complexity of the
curves that define the ranges and they are logarithmic in the complexity of the
curves that define the ground set.
</p></div>
    </summary>
    <updated>2019-03-11T23:47:05Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-03-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1903.03147</id>
    <link href="http://arxiv.org/abs/1903.03147" rel="alternate" type="text/html"/>
    <title>External memory priority queues with decrease-key and applications to graph algorithms</title>
    <feedworld_mtime>1552262400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Iacono:John.html">John Iacono</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jacob:Riko.html">Riko Jacob</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tsakalidis:Konstantinos.html">Konstantinos Tsakalidis</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1903.03147">PDF</a><br/><b>Abstract: </b>We present priority queues in the external memory model with block size $B$
and main memory size $M$ that support on $N$ elements, operation Update (a
combination of operations Insert and Decrease-Key) in
$O\left({\frac{1}{B}\log_{\frac{M}{B}} \frac{N}{B}}\right)$ amortized I/Os,
operation Extract-Min in $O\left({\frac{M^{\varepsilon}}{B}\log_{\frac{M}{B}}
\frac{N}{B}}\right)$ amortized I/Os and operation Delete in
$O\left({\frac{M^{\varepsilon}}{B}\log^2_{\frac{M}{B}} \frac{N}{B}}\right)$
amortized I/Os, for any real $\varepsilon \in \left(0,1\right)$, using
$O\left({\frac{N}{B}\log_{\frac{M}{B}} \frac{N}{B}}\right)$ blocks. Previous
I/O-efficient priority queues either support these operations in
$O\left({\frac{1}{B}\log_2 \frac{N}{B}}\right)$ amortized I/Os [Kumar and
Schwabe, SPDP '96], or support only operations Insert, Delete and Extract-Min
in optimal $O\left({\frac{1}{B}\log_{\frac{M}{B}} \frac{N}{B}}\right)$
amortized I/Os, however without supporting Decrease-Key [Fadel et al., TCS
'99].
</p>
<p>We also present buffered repository trees that support on a multi-set of $N$
elements, operations Insert and Extract (on $K$ extracted elements) in
$O\left({\frac{1}{B}\log_{\frac{M}{B}} \frac{N}{B}}\right)$ and
$O\left({\log_{\frac{M}{B}} \frac{N}{B} + K/B}\right)$ amortized I/Os,
respectively, using $O\left({\frac{N}{B}}\right)$ blocks. This improves upon
the previous I/O-bounds that achieve a base-$2$ logarithm instead [Buchsbaum et
al., SODA '00].
</p>
<p>Our results imply improved $O\left({\frac{E}{B}\log_{\frac{M}{B}}
\frac{E}{B}}\right)$ I/Os for single-source shortest paths, depth-first search
and breadth-first search algorithms on massive directed graphs with an
edge-to-node ratio $\frac{E}{V}=\Omega({M^{\varepsilon}})$, which is equal to
the I/O-optimal bound for sorting $E$ values in external memory.
</p></div>
    </summary>
    <updated>2019-03-11T23:46:07Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-03-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-5113460714750651988</id>
    <link href="https://blog.computationalcomplexity.org/feeds/5113460714750651988/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/03/richard-karp-his-influence-and-how-to.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/5113460714750651988" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/5113460714750651988" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/03/richard-karp-his-influence-and-how-to.html" rel="alternate" type="text/html"/>
    <title>Richard Karp: His influence and how to honor him</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">When I first saw the definition of NP-Complete I first thought<i> if there are NP-complete problems I suspect they are contrived. </i>When I saw the proof that  SAT is NP-complete I thought <i>okay, so there is one natural problem  NP-complete by a trick of encoding, but I suspect there aren't any more.</i>  I then read Karp's article that had 22 NP-complete problems. I thought <i>okay, there are 22, but I suspect there are no more. </i>No I didn't think that. But the point is that Cook and Karp together birthed modern complexity theory by introduction NP-completeness and showing that there are MANY natural problems that are NP-complete.<br/>
<br/>
How many people has Richard Karp inspired? I don't know but I suspect it's a  cardinal between countable and the reals so it may depend on your model of set theory. Later in this post I will present Samir Khuller's story of how Richard Karp inspired him.<br/>
<br/>
How to honor him?  The Simons inst. is currently welcoming contributions to the Richard M Karp Fund, which honors the scientific contributions of Founding Director Dick Karp. The fund will provide vital support for the mission and activities of the Simons institute. They have a deadline of Pi-Day. You can go <a href="https://simons.berkeley.edu/support/donate">here</a> to contribute and/or <a href="https://www.cs.umd.edu/users/gasarch/BLOGPAPERS/goldwasserkarp.txt">here</a> for a letter from Shafi Goldwasser, Prabhakar Raghavan, and Umesh Vazirani about the fund.<br/>
<br/>
OKAY, Samir's story:<br/>
<br/>
<div>
<b>Mentoring and Influence via a Train Journey...</b></div>
<div>
<br/></div>
<div>
Almost to the day, 33 years ago I was running from my dorm room to catch an unreliable bus to the train station as I headed home for a mid-semester break.  On the way,I  stopped by the mailroom, and not knowing where to put the CACM that had just arrived,  stuffed it into the side of my bag and in the process, dropping my   notebook in the process. On the train, when I looked for my  notebook to go over  some material I realized it was missing! All I had was a CACM and a very long train ride. Skimming through the journal, I found Karp’s Turing Award article “Combinatorics, Complexity, and Randomness“. I  started reading this article, and was riveted! It was one of those life changing moments for me, when my immediate future became clear - I wanted to study Theoretical Computer Science and specifically the complexity of combinatorial problems. Without ever having met Dick Karp, he changed my life forever.</div>
<div>
<br/></div>
<div>
I met Dick long after he influenced me via his Turing Award Lecture and it was a real privilege to have had the opportunity to interview him via a fireside chat at Simons. See <a href="https://www.youtube.com/watch?v=g1DT_UeJwps">here</a>.</div>
<div>
<br/></div>
<div>
I am delighted about the fund Bill mentions above as the money that goes to it will help inspire others as Karp inspired me.</div>
<div>
<br/></div>
<div>
<br/></div>
<div>
<br/></div>
<br/>
<br/></div>
    </content>
    <updated>2019-03-10T21:26:00Z</updated>
    <published>2019-03-10T21:26:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>https://plus.google.com/101693130490639305932</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-03-12T16:11:12Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/03/10/postdoc-at-ist-austria-vienna-apply-by-april-15-2019/</id>
    <link href="https://cstheory-jobs.org/2019/03/10/postdoc-at-ist-austria-vienna-apply-by-april-15-2019/" rel="alternate" type="text/html"/>
    <title>Postdoc at IST Austria (Vienna) (apply by April 15, 2019)</title>
    <summary>The Distributed Algorithms Group at IST Austria (near Vienna) is looking for strong postdoc candidates in CS Theory, with a focus on (distributed) optimization. The starting date is (roughly) in Fall 2019. Website: http://people.csail.mit.edu/alistarh/ Email: d.alistarh@gmail.com</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Distributed Algorithms Group at IST Austria (near Vienna) is looking for strong postdoc candidates in CS Theory, with a focus on (distributed) optimization. The starting date is (roughly) in Fall 2019.</p>
<p>Website: <a href="http://people.csail.mit.edu/alistarh/">http://people.csail.mit.edu/alistarh/</a><br/>
Email: d.alistarh@gmail.com</p></div>
    </content>
    <updated>2019-03-10T20:48:31Z</updated>
    <published>2019-03-10T20:48:31Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-03-12T20:20:51Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=15674</id>
    <link href="https://rjlipton.wordpress.com/2019/03/10/problems-with-a-point/" rel="alternate" type="text/html"/>
    <title>Problems With a Point</title>
    <summary>Bill and Clyde’s new book Bill Gasarch and Clyde Kruskal are colleagues in Computer Science at the University of Maryland. They have just seen the publication of their book Problems With a Point. Today Dick and I congratulate them on the book and give a brief overview of it. The tandem of Bill and Clyde […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Bill and Clyde’s new book</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<p><a href="https://rjlipton.wordpress.com/2019/03/10/problems-with-a-point/gasarchkruskal/" rel="attachment wp-att-15675"><img alt="" class="alignright wp-image-15675" height="114" src="https://rjlipton.files.wordpress.com/2019/03/gasarchkruskal.png?w=200&amp;h=114" width="200"/></a></p>
<p/><p>
Bill Gasarch and Clyde Kruskal are colleagues in Computer Science at the University of Maryland. They have just seen the publication of their <a href="https://www.worldscientific.com/worldscibooks/10.1142/11261">book</a> <em>Problems With a Point</em>.</p>
<p>
Today Dick and I congratulate them on the book and give a brief overview of it.</p>
<p>
The tandem of Bill and Clyde were <a href="https://rjlipton.wordpress.com/2011/12/06/theorems-are-forever-a-great-one-from-1492/">featured</a> before on this blog in connection with a <a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.138.6154">series</a> of <a href="http://www.cs.umd.edu/~gasarch/BLOGPAPERS/3apsurvey.pdf">papers</a> with James Glenn on sets of numbers that have no arithmetical progressions of length 3. </p>
<p>
Can a “series” have only two members? We could add a third <a href="https://link.springer.com/chapter/10.1007/11821069_13">paper</a> to the series, but it is by Glenn and Bill with Richard Beigel rather than Clyde and is on the different topic of multi-party communication complexity. But Clyde gets into the act since it is the topic of Chapter 19 of the book. That chapter analyzes a game form of problems that go back to a 1983 <a href="http://www.cs.umd.edu/~gasarch/BLOGPAPERS/multiparty-vdw.pdf">paper</a> by Dick with Ashok Chandra and Merrick Furst. Does this mean Dick should get some royalties? Note that this last link is to Bill’s website. And ‘vdw’ in this link seems to refer to van der Waerden’s <a href="https://en.wikipedia.org/wiki/Van_der_Waerden's_theorem">theorem</a>, which is a pillar of both Ramsey theory and number theory, which in turn receive much attention in the book.</p>
<p>
My last paragraph flits through divergent questions but they are representative of things that we working mathematical computing theorists think about every day—and of various kinds of content in the book. Of course, Bill partners on Lance Fortnow’s prominent <a href="https://blog.computationalcomplexity.org/">blog</a> and so has shared all kinds of these musings. The book, which incorporates numerous posts by Bill but is not a “blog book” <em>per-se</em>, furnishes contexts for them. Let’s look at the book.</p>
<p>
</p><p/><h2> The Book </h2><p/>
<p/><p>
The book has three main parts, titled:</p>
<ul>
<li>
Stories With a Point. <p/>
</li><li>
Problems With a Point. <p/>
</li><li>
Theorems With a Point.
</li></ul>
<p>
All the chapters except three are prefaced with a section titled “Point”—or “The Point” or “Points”—after one sentence on prior knowledge needed, which often reads, “None.”</p>
<p>
The first part begins with a chapter titled, “When Terms From Math are Used By Civilians,” one of several with social discussion. The second is about how human aspects of sports upset statistical regularities one might expect to see. For example, many more baseball hitters have had season batting averages of .300 than .299 or .301, evidently because .300 is a “goal number” everyone strives to meet. There are numerous things in the book I didn’t know. </p>
<p>
The next chapter largely reproduces this record-long <a href="https://blog.computationalcomplexity.org/2011/07/disproofing-myth-that-many-early.html">post</a> on the blog but adds much extra commentary. Then there are chapters on what makes a mathematical function worth defining, on how mathematical objects are named, on Bill’s visit to a “Gathering for [Martin] Gardner” <a href="http://www.gathering4gardner.org/">conference</a>, on coloring the plane, two on imagined applications of Ramsey Theory to medieval history, and one on the methodological and social impact of having theorems that represent barriers to ways of trying to prove other theorems. </p>
<p>
</p><p/><h2> Chapter Ten </h2><p/>
<p/><p>
This last chapter of Part I <a href="https://blog.computationalcomplexity.org/2010/04/lets-prove-something-instead-of-proving.html">draws</a> on <a href="https://blog.computationalcomplexity.org/2010/04/but-seriously-now-folks-what-do-you.html">several</a> of Bill’s <a href="https://blog.computationalcomplexity.org/2017/03/other-fields-of-math-dont-prove-barrier.html">posts</a>. It goes most to the heart of what we all in computational complexity grapple with daily and benefits from having more context: As we just mused in this blog’s 10-year anniversary <a href="https://rjlipton.wordpress.com/2019/02/18/have-ten-years-brought-us-closer/">post</a>, the major questions in complexity are not only as open as when we started, but as open as when the field started 50-plus years ago. There has barely been any discernible direct progress, and this is not only a concern for entering students but a retardant on everyone—about which we’ve given <a href="https://rjlipton.wordpress.com/2014/09/18/lets-mention-foundations/">exhortation</a>.</p>
<p>
There are instead <a href="https://rjlipton.wordpress.com/2012/11/29/barriers-to-pnp-proofs/">barrier</a> theorems saying <em>why</em> the main questions will not be resolvable by the very techniques that were used to build the field. Of three broad categories of barriers, “oracle results” de-fang all the methods typically taught in intro graduate complexity courses. Those methods meter computations at inputs and outputs but not how they “progress” inside toward a solution. Oracle languages supply blasts of external information that either make progress trivially quick or allow conditioning the terms of the complexity-class relation under analysis to information in the oracle that is tailored to obfuscate. Oracles of the former kind usually collapse complexity classes together, such as <img alt="{A =}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA+%3D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A =}"/> any polynomial-space complete language making <img alt="{\mathsf{P}^A = \mathsf{NP}^A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D%5EA+%3D+%5Cmathsf%7BNP%7D%5EA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{P}^A = \mathsf{NP}^A}"/>, whereas oracles <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B}"/> of the latter kind drive them apart (so <img alt="{\mathsf{P}^B \neq \mathsf{NP}^B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D%5EB+%5Cneq+%5Cmathsf%7BNP%7D%5EB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{P}^B \neq \mathsf{NP}^B}"/>) but often for reasons that frustrate as much as enlighten. When contemplating a new complexity class relation it is incumbent to frame a “relativized” version of it and see if some oracles can make it true and others false. Such oracle constructions were initially easy to come by—“fast food” for research—but their ultimate besideness-of-the-point is reflected in this early <a href="https://rjlipton.wordpress.com/2009/05/21/i-hate-oracle-results/">post</a> by Dick.</p>
<p>
Next after oracles is the “Natural Proofs” <a href="https://en.wikipedia.org/wiki/Natural_proof">barrier</a>, which basically cuts against all the techniques taught in advanced graduate complexity courses unless they can somehow be weirdly narrow or intensely complex in their conceptual framing. The attitude on those is captured by the title of another early <a href="https://rjlipton.wordpress.com/2009/03/25/whos-afraid-of-natural-proofs/">post</a> by Dick titled, “Who’s Afraid of Natural Proofs?” The third barrier is <a href="https://www.scottaaronson.com/papers/algstoc.pdf">algebrization</a>, which cuts <a href="https://en.wikipedia.org/wiki/P_versus_NP_problem#Results_about_difficulty_of_proof">against</a> efforts to escape from oracles. </p>
<p>
Amid all this environment of obstruction, what of consequence can we prove? Well, the chapter on this has by far the highest concentration of Bill’s trademark all-capital letters and exclamation points. The initial “Point” section is titled, “Rant.” (The chapter also includes a page on the attempts to prove Euclid’s parallel postulate, which might be called the original “problem with a point.”)</p>
<p>
</p><p/><h2> Part II </h2><p/>
<p/><p>
Much of Part II involves the kind of problems that were used or considered for high-school mathematics competitions. By definition those are not research problems but they often point toward frontiers by representing accessible cases of them. The appealing ones blend equal parts research relevance, amusement value, and reward of technical command. Often they require mathematical “street smarts” and a repertoire of useful tricks and proof patterns. Practicing researchers will find this aspect of the book most valuable. The problems are mainly on the number-theory side of recreational mathematics, plus geometric and coloring problems. Egyptian fractions, prime-factor puzzles, sums over digits, summation formulas, and of course Ramsey theory all make their appearance. Here is one problem I mention partly to correct a small content error, where the correction seems to make the problem more interesting. Say that <img alt="{C(n,m)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%28n%2Cm%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C(n,m)}"/> holds if there are integers <img alt="{n_1,\dots,n_m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn_1%2C%5Cdots%2Cn_m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n_1,\dots,n_m}"/> such that </p>
<p align="center"><img alt="\displaystyle  n_1 + \cdots + n_m = n \qquad\text{and}\qquad \frac{1}{n_1} + \cdots + \frac{1}{n_m} = 1. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++n_1+%2B+%5Ccdots+%2B+n_m+%3D+n+%5Cqquad%5Ctext%7Band%7D%5Cqquad+%5Cfrac%7B1%7D%7Bn_1%7D+%2B+%5Ccdots+%2B+%5Cfrac%7B1%7D%7Bn_m%7D+%3D+1.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  n_1 + \cdots + n_m = n \qquad\text{and}\qquad \frac{1}{n_1} + \cdots + \frac{1}{n_m} = 1. "/></p>
<p>A general principle discovered by Joseph Sylvester gives cases such as <img alt="{C(1861,5)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%281861%2C5%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C(1861,5)}"/> being witnessed by </p>
<p align="center"><img alt="\displaystyle  1861 = 2 + 3 + 7 + 43 + 1806 \qquad\text{and}\qquad 1 = \frac{1}{2} + \frac{1}{3} + \frac{1}{7} + \frac{1}{43} + \frac{1}{1806}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++1861+%3D+2+%2B+3+%2B+7+%2B+43+%2B+1806+%5Cqquad%5Ctext%7Band%7D%5Cqquad+1+%3D+%5Cfrac%7B1%7D%7B2%7D+%2B+%5Cfrac%7B1%7D%7B3%7D+%2B+%5Cfrac%7B1%7D%7B7%7D+%2B+%5Cfrac%7B1%7D%7B43%7D+%2B+%5Cfrac%7B1%7D%7B1806%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  1861 = 2 + 3 + 7 + 43 + 1806 \qquad\text{and}\qquad 1 = \frac{1}{2} + \frac{1}{3} + \frac{1}{7} + \frac{1}{43} + \frac{1}{1806}. "/></p>
<p>How can it and related ideas be extended to other cases? The particular problem is given <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> to find <img alt="{m_n =}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm_n+%3D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m_n =}"/> the least <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m}"/> such that <img alt="{C(n,m)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%28n%2Cm%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C(n,m)}"/> holds—and to find a witnessing sum. The error is an assertion that <img alt="{m_n \leq n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm_n+%5Cleq+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m_n \leq n}"/> “by writing <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> as a sum of <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>‘s,” but then the reciprocals add up to <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> not <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>. So is there any bound on <img alt="{m_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m_n}"/>? That is rather fun to think about. </p>
<p>
This problem’s chapter is made from a short <a href="https://blog.computationalcomplexity.org/2011/12/is-this-problem-too-hard-for-hs-math.html">post</a> with an enormous comments section.  There is also a chapter on the boundary between a fair problem and a “trick question” that much extends an April Fool’s post on the blog.</p>
<p>
</p><p/><h2> Part III </h2><p/>
<p/><p>
Part III continues the nature of the problem content with emphasis on the worths of proofs of theorems. One illustration involving perfect numbers and sums of cubes notes that the proof loses value because it also applies to certain non-perfect numbers. Two things <em>en-passant</em>: First, Lemma 21.1 in this chapter needs qualification that <img alt="{a,b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%2Cb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a,b}"/> are relatively prime and <img alt="{x+1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x+1}"/> is prime. Second, this prompts me to note <a href="https://gilkalai.wordpress.com/2019/03/09/">via</a> Gil Kalai the discovery by Tim Browning that the number 33 is a sum of three cubes: </p>
<p><br/></p>
<p align="center"><img alt="\displaystyle  33 = 8,\!866,\!128,\!975,\!287,\!528^3 + (-8,\!778,\!405,\!442,\!862,\!239)^3 + (-2,\!736,\!111,\!468,\!807,\!040)^3. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++33+%3D+8%2C%5C%21866%2C%5C%21128%2C%5C%21975%2C%5C%21287%2C%5C%21528%5E3+%2B+%28-8%2C%5C%21778%2C%5C%21405%2C%5C%21442%2C%5C%21862%2C%5C%21239%29%5E3+%2B+%28-2%2C%5C%21736%2C%5C%21111%2C%5C%21468%2C%5C%21807%2C%5C%21040%29%5E3.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  33 = 8,\!866,\!128,\!975,\!287,\!528^3 + (-8,\!778,\!405,\!442,\!862,\!239)^3 + (-2,\!736,\!111,\!468,\!807,\!040)^3. "/></p>
<p/><p><br/>
Gil points to a Quora <a href="https://affinemess.quora.com/HOLY-CRAP-33-IS-THE-SUM-OF-THREE-CUBES">post</a> by Alon Amit. There is only the bare equation on Browning’s <a href="http://pub.ist.ac.at/~tbrownin/">homepage</a>, and nothing about his methods or how much he used computer search is known. The theme of proofs by computer runs through several chapters of Bill and Clyde’s book. It is also <a href="https://www.scottaaronson.com/blog/?p=4133">current</a> on Scott Aaronson’s blog—we would be remiss if we did not mention Scott in this post—and more widely.</p>
<p>
The penultimate chapter covers the beautiful theory of rectangle-free colorings of grids. We mentioned Bill’s involvement with this Ramsey-style problem in a <a href="https://rjlipton.wordpress.com/2012/02/12/how-deep-is-your-coloring/">post</a> on what happened to be this blog’s third anniversary. We connected it to Kolmogorov complexity, which together with uncomputability is the subject of the last chapter. This and other chapters I’ve mentioned exemplify how the research ambit connects traditional mathematics with the terms and concerns of computing theory. How to work in this ambit may be the greatest value of the book for students. In all I found the book light, lighthearted, and enlightening.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
The big open problem with the book is how it might help gear us up to tackle the big open problems.</p>
<p>
[sourced chapter near end of Part II to blog]</p></font></font></div>
    </content>
    <updated>2019-03-10T19:43:13Z</updated>
    <published>2019-03-10T19:43:13Z</published>
    <category term="All Posts"/>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="People"/>
    <category term="primes"/>
    <category term="Proofs"/>
    <category term="Teaching"/>
    <category term="trick"/>
    <category term="Bill Gasarch"/>
    <category term="book"/>
    <category term="Clyde Kruskal"/>
    <category term="Problems"/>
    <category term="review"/>
    <category term="teaching"/>
    <author>
      <name>KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-03-12T20:20:49Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/038</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/038" rel="alternate" type="text/html"/>
    <title>TR19-038 |  Statistical Difference Beyond the Polarizing Regime | 

	Itay Berman, 

	Akshay Degwekar, 

	Ron D. Rothblum, 

	Prashant Nalini Vasudevan</title>
    <summary>The polarization lemma for statistical distance ($\mathrm{SD}$), due to Sahai and Vadhan (JACM, 2003), is an efficient transformation taking as input a pair of circuits $(C_0,C_1)$ and an integer $k$ and outputting a new pair of circuits $(D_0,D_1)$ such that if $\mathrm{SD}(C_0,C_1)\geq\alpha$ then $\mathrm{SD}(D_0,D_1) \geq 1-2^{-k}$ and if $\mathrm{SD}(C_0,C_1) \leq \beta$ then $\mathrm{SD}(D_0,D_1) \leq 2^{-k}$. The polarization lemma is known to hold for any constant values $\beta &lt; \alpha^2$, but extending the lemma to the regime in which $\alpha^2 \leq \beta &lt; \alpha$ has remained elusive. The focus of this work is in studying the latter regime of parameters. Our main results are:

1. Polarization lemmas for different notions of distance, such as Triangular Discrimination ($\mathrm{TD}$) and Jensen-Shannon Divergence ($\mathrm{JS}$), which enable polarization for some problems where the statistical distance satisfies $\alpha^2 &lt; \beta &lt; \alpha$. We also derive a polarization lemma for statistical distance with any inverse-polynomially small gap between $\alpha^2$ and $\beta$ (rather than a constant).

2. The average-case hardness of the statistical difference problem (i.e., determining whether the statistical distance between two given circuits is at least $\alpha$ or at most $\beta$), for any values of $\beta &lt; \alpha$, implies the existence of one-way functions. Such a result was previously only known for $\beta &lt; \alpha^2$.

3. A (direct) constant-round interactive proof for estimating the statistical distance between any two distributions (up to any inverse polynomial error) given circuits that generate them.</summary>
    <updated>2019-03-10T08:50:14Z</updated>
    <published>2019-03-10T08:50:14Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-03-12T20:20:42Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://theorydish.blog/?p=1494</id>
    <link href="https://theorydish.blog/2019/03/08/stoc-2019-workshop-and-tutorial-proposals/" rel="alternate" type="text/html"/>
    <title>STOC 2019 workshop and tutorial proposals</title>
    <summary>I want to draw your attention to the call for workshop and tutorial proposals for STOC 2019:http://acm-stoc.org/stoc2019/callforworkshops.html Important Dates Submission deadline:March 24, 2019Notification:April 5, 2019Workshop Day:Sunday June 23, 2019 STOC 2019 will hold a Workshop and Tutorial Day on Sunday June 23. We invite groups of interested researchers to submit workshop or tutorial proposals. The STOC 2019 Workshop and Tutorial Day provides an informal forum for researchers to discuss important research questions, directions, and challenges of the field. We also encourage workshops that focus on connections between theoretical computer science and other areas, topics that are not well represented at STOC, new directions, and open problems. The program may also include tutorials, each consisting of a few survey talks on a particular area. Format: We have room for three workshops/tutorials running in parallel for the course of the day with a break for lunch. In addition, workshops or tutorials may be full-day (6 hrs) or half-day (3 hrs). Proposal Submission Workshop and tutorial proposals should, ideally, fit one page. Please include a list of names and email addresses of the organizers, a brief description of the topic and the goals of the workshop or tutorial, the proposed workshop format (invited [...]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I want to draw your attention to the call for workshop and tutorial proposals for STOC 2019:<br/><a href="http://acm-stoc.org/stoc2019/callforworkshops.html">http://acm-stoc.org/stoc2019/callforworkshops.html</a></p>



<h4>Important Dates</h4>



<table class="wp-block-table"><tbody><tr><td>Submission deadline:</td><td><strong>March 24, 2019</strong></td></tr><tr><td>Notification:</td><td>April 5, 2019</td></tr><tr><td>Workshop Day:</td><td><strong>Sunday June 23, 2019</strong></td></tr></tbody></table>



<p><strong>STOC 2019 will hold a Workshop and Tutorial Day on Sunday June 23. We invite groups of interested researchers to submit workshop or tutorial proposals.</strong></p>



<p>The STOC 2019 Workshop and Tutorial Day provides an informal forum for researchers to discuss important research questions, directions, and challenges of the field. We also encourage workshops that focus on connections between theoretical computer science and other areas, topics that are not well represented at STOC, new directions, and open problems. The program may also include tutorials, each consisting of a few survey talks on a particular area.</p>



<p><strong>Format</strong>: We have room for three workshops/tutorials running in parallel for the course of the day with a break for lunch. In addition, workshops or tutorials may be full-day (6 hrs) or half-day (3 hrs). </p>



<h4>Proposal Submission</h4>



<p>Workshop and tutorial proposals should, ideally, fit one page. Please include a list of names and email addresses of the organizers, a brief description of the topic and the goals of the workshop or tutorial, the proposed workshop format (invited talks, contributed talks, contributed posters, panel, etc.), and proposed or tentatively confirmed speakers if known. Please also indicate the preferred length of time (3 hrs or 6 hrs) for your workshop/tutorial. If your proposal is accepted and you wish to solicit contributed talks (which we strongly encourage), we can link to your call-for-contributions from the STOC 2019 page. Feel free to contact the Chair of the Workshop and Tutorials Committee directly or at the email address below if you have any questions.</p>



<h4>Submission Deadline</h4>



<p>Proposals should be submitted by <strong>March 24, 2019</strong> via email to <a href="mailto:stoc2019events@gmail.com">stoc2019events@gmail.com</a>. Proposers will be notified by April 5, 2019 whether their proposals have been accepted.</p>



<p><strong>Workshop and Tutorials Committee:</strong> Moses Charikar (Chair)</p>



<p><br/></p>



<p/></div>
    </content>
    <updated>2019-03-08T16:25:56Z</updated>
    <published>2019-03-08T16:25:56Z</published>
    <category term="Uncategorized"/>
    <category term="STOC2019"/>
    <author>
      <name>Moses Charikar</name>
    </author>
    <source>
      <id>https://theorydish.blog</id>
      <logo>https://theorydish.files.wordpress.com/2017/03/cropped-nightdish1.jpg?w=32</logo>
      <link href="https://theorydish.blog/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://theorydish.blog" rel="alternate" type="text/html"/>
      <link href="https://theorydish.blog/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://theorydish.blog/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Stanford's CS Theory Research Blog</subtitle>
      <title>Theory Dish</title>
      <updated>2019-03-12T20:21:42Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-5011417931001574576</id>
    <link href="https://blog.computationalcomplexity.org/feeds/5011417931001574576/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/03/qed.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/5011417931001574576" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/5011417931001574576" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/03/qed.html" rel="alternate" type="text/html"/>
    <title>QED</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Via <a href="https://www.scottaaronson.com/blog/?p=4133">Scott</a>, John Horgan wrote a <a href="https://blogs.scientificamerican.com/cross-check/the-horgan-surface-and-the-death-of-proof/">blog post</a> following on his 1993 Scientific American article <a href="https://blogs.scientificamerican.com/cross-check/the-horgan-surface-and-the-death-of-proof/">The Death of Proof</a>. The article talked about computer-generated proofs, experimental mathematics and even mentioned some of our work on <a href="https://doi.org/10.1145/103418.103428">transparent proofs</a> (basically time-efficient probabilistically checkable proofs). I got (sarcastically I think) accused of killing mathematics after that article but of course we had traditional proofs about probabilistically check proofs. Andrew Wiles got a sidebar titled "A Splendid Anachronism?" for merely solving the most famous open problem in all of mathematics. Somehow traditional mathematical proofs survived the article.<div>
<br/></div>
<div>
Meanwhile in CACM, Moshe Vardi writes <a href="https://cacm.acm.org/magazines/2019/3/234913-lost-in-math/fulltext">Lost in Math?</a> </div>
<blockquote class="tr_bq">
TCS is surely blessed with mathematical beauty. As a graduate student a long time ago, it was mathematical beauty that attracted me to TCS, and continued to lead my research for many years. I find computational complexity theory (or complexity theory, for short), with its theorems (for example, the time-hierarchy and space-hierarchy theorems) and its open questions (for example, P vs NP), to be hauntingly beautiful. Beauty, yes; but what about truth?</blockquote>
Here here on the beauty of complexity. So what about truth? I cover much of this in my <a href="https://cacm.acm.org/magazines/2009/9/38904-the-status-of-the-p-versus-np-problem/fulltext">P v NP survey</a>. In short the P v NP captures the most critical aspects of what is efficiently computable but it is not the endpoint. Nevertheless P v NP captures both truth and beauty and that's why the problem has so captivated and guided me throughout my research career.</div>
    </content>
    <updated>2019-03-08T15:05:00Z</updated>
    <published>2019-03-08T15:05:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>https://plus.google.com/101693130490639305932</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>https://plus.google.com/101693130490639305932</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-03-12T16:11:12Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://emanueleviola.wordpress.com/?p=622</id>
    <link href="https://emanueleviola.wordpress.com/2019/03/07/a-dream-come-true-sort-of-e-ink-monitors/" rel="alternate" type="text/html"/>
    <title>A dream come true, sort of: E-ink monitors</title>
    <summary>Spending your life staring at a (traditional) computer screen may not be ideal for your eyes (and more); so since an early age I have been dreaming of a “purely mechanical” monitor that you could stare at more or less indefinitely, like at parchment. This dream is not becoming reality, sort of.  The Dasung E-ink […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p style="text-align: justify;">Spending your life staring at a (traditional) computer screen may not be ideal for your eyes (and more); so since an early age I have been dreaming of a “purely mechanical” monitor that you could stare at more or less indefinitely, like at parchment.</p>
<p style="text-align: justify;">This dream is not becoming reality, sort of.  The <a href="https://www.amazon.com/Dasung-Ink-Paperlike-13-3-Monitor/dp/B07GWGFW1B/ref=asc_df_B07GWGFW1B/?tag=hyprod-20&amp;linkCode=df0&amp;hvadid=309743296044&amp;hvpos=1o1&amp;hvnetw=g&amp;hvrand=4273202700836301476&amp;hvpone=&amp;hvptwo=&amp;hvqmt=&amp;hvdev=c&amp;hvdvcmdl=&amp;hvlocint=&amp;hvlocphy=9002067&amp;hvtargid=pla-571127059636&amp;psc=1">Dasung E-ink monitor </a>has no backlight and instead reportedly uses electric flows to move ink droplets.</p>
<p style="text-align: justify;">After some consideration, spending yet more hours reading reviews online and watching youtube videos about it sealed the deal.  I shelled out $1300 and bought the thing.</p>
<p style="text-align: justify;">I have had it for a few days now and I am sort of happy. I went from using a giant 30-inch monitor far away (my theory for avoiding eye strain) to using a ~13-inch monitor at pretty much the same distance as reading a book. I had to avoid sunlight, now I seek it (see the picture).</p>
<p style="text-align: justify;"><img alt="20190307_094550" class="alignnone size-full wp-image-624" src="https://emanueleviola.files.wordpress.com/2019/03/20190307_094550.jpg?w=640"/></p>
<p style="text-align: justify;">The monitor makes your computer look like Windows 3.1 on a monochrome screen from the 80’s. The refresh is slow, and there is a ghosting effect, meaning there are shadows of previous images — which you can clear out. Also, it’s 4:3 instead of 16:9, which is a pain because it means I have to change resolution when I am forced to use my other monitor (for example if I have to check colors — the screen is gray-scale, did I mention that?). It makes browsing the internet quite painful, which is a nice side effect.</p>
<p style="text-align: justify;">Contrary to advice, I am using it as my primary monitor. I am sort of happy with it and don’t regret buying it. I have started writing and reading papers with it and it’s working well enough.</p>
<p style="text-align: justify;">I think as soon as the technology improves the market for these things will be huge.  Already having a 17″ monitor in 16:9 ratio, ideally touch-screen, even if gray scale, would be a dream come true.</p></div>
    </content>
    <updated>2019-03-07T14:54:57Z</updated>
    <published>2019-03-07T14:54:57Z</published>
    <category term="Uncategorized"/>
    <category term="health"/>
    <category term="review"/>
    <category term="tech"/>
    <author>
      <name>Emanuele</name>
    </author>
    <source>
      <id>https://emanueleviola.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://emanueleviola.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://emanueleviola.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://emanueleviola.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://emanueleviola.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>By Emanuele Viola</subtitle>
      <title>Thoughts</title>
      <updated>2019-03-12T20:21:24Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4133</id>
    <link href="https://www.scottaaronson.com/blog/?p=4133" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4133#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4133" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Death of proof greatly exaggerated</title>
    <summary xml:lang="en-US">In 1993, the science writer John Horgan—who’s best known for his book The End of Science, and (of course) for interviewing me in 2016—wrote a now-(in)famous cover article for Scientific American entitled “The Death of Proof.” Mashing together a large number of (what I’d consider) basically separate trends and ideas, Horgan argued that math was […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>In 1993, the science writer <a href="https://en.wikipedia.org/wiki/John_Horgan_(journalist)">John Horgan</a>—who’s best known for his book <em><a href="https://www.amazon.com/End-Science-Knowledge-Twilight-Scientific/dp/0465065929">The End of Science</a></em>, and (of course) for <a href="https://blogs.scientificamerican.com/cross-check/scott-aaronson-answers-every-ridiculously-big-question-i-throw-at-him/">interviewing me in 2016</a>—wrote a now-(in)famous cover article for <em>Scientific American</em> entitled <a href="https://pdfs.semanticscholar.org/4e56/c6fea76922082400dfc6e13a3a169ae7b9a6.pdf">“The Death of Proof.”</a>  Mashing together a large number of (what I’d consider) basically separate trends and ideas, Horgan argued that math was undergoing a fundamental change, with traditional deductive proofs being replaced by a combination of non-rigorous numerical simulations, machine-generated proofs, probabilistic and probabilistically-checkable proofs, and proofs using graphics and video.  Horgan also suggested that Andrew Wiles’s then-brand-new <a href="https://en.wikipedia.org/wiki/Wiles%27s_proof_of_Fermat%27s_Last_Theorem">proof</a> of Fermat’s Last Theorem—which might have looked, at first glance, like a spectacular counterexample to the “death of proof” thesis—could be the “last gasp of a dying culture” and a “splendid anachronism.”  Apparently, “The Death of Proof” garnered one of the largest volumes of angry mail in <em>Scientific American</em>‘s history, with mathematician after mathematician arguing that Horgan had strung together half-digested quotes and vignettes to manufacture a non-story.</p>



<p>Now Horgan—who you could variously describe as a wonderful sport, or a ham, or a sucker for punishment—has written a <a href="https://blogs.scientificamerican.com/cross-check/the-horgan-surface-and-the-death-of-proof/">26-year retrospective</a> on his “death of proof” article.  The prompt for this was Horgan’s recent discovery that, back in the 90s, David Hoffman and Hermann Karcher, two mathematicians annoyed by the “death of proof” article, had named a nonexistent mathematical object after its author.  The so-called <em><a href="https://minimalsurfaces.blog/home/repository/non-existent-surfaces/the-horgan-surface/">Horgan surface</a></em> is a minimal surface that numerical computations strongly suggested should exist, but that can be rigorously proven not to exist after all.  “The term was intended as an insult, but I’m honored anyway,” Horgan writes.</p>



<p>As a followup to his blog post, Horgan then decided to solicit commentary from various people he knew, including yours truly, about “how proofs are faring in an era of increasing computerization.”  He wrote, “I’d love to get a paragraph or two from you.”  Alas, I didn’t have the time to do as requested, but only to write <i>eight</i> paragraphs.  So Horgan suggested that I make the result into a post on my own blog, which he’d then link to.  Without further ado, then:</p>



<hr/>



<p>John, I like you so I hate to say it, but the last quarter century has not been kind to your thesis about “the death of proof”!  Those mathematicians sending you the irate letters had a point: there’s been no fundamental change to mathematics that deserves such a dramatic title.  Proof-based math remains quite healthy, with (e.g.) a solution to the <a href="https://en.wikipedia.org/wiki/Poincar%C3%A9_conjecture">Poincaré conjecture</a> since your article came out, as well as to the <a href="https://arxiv.org/abs/1509.05363">Erdős discrepancy problem</a>, the <a href="https://en.wikipedia.org/wiki/Kadison%E2%80%93Singer_problem">Kadison-Singer conjecture</a>, <a href="https://en.wikipedia.org/wiki/Catalan%27s_conjecture">Catalan’s conjecture</a>, <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.308.998&amp;rep=rep1&amp;type=pdf">bounded gaps in primes</a>, <a href="https://en.wikipedia.org/wiki/AKS_primality_test">testing primality in deterministic polynomial time</a>, etc. — just to pick a few examples from the tiny subset of areas that I know anything about.</p>



<p>There are evolutionary changes to mathematical practice, as there always have been.  Since 2009, the website <a href="https://mathoverflow.net/">MathOverflow</a> has let mathematicians query the global hive-mind about an obscure reference or a recalcitrant step in a proof, and get near-instant answers.  Meanwhile <a href="https://polymathprojects.org/">“polymath” projects</a> have, with moderate success, tried to harness blogs and other social media to make advances on long-standing open math problems using massive collaborations.</p>



<p>While humans remain in the driver’s seat, there are persistent efforts to increase the role of computers, with some notable successes.  These include Thomas Hales’s 1998 computer-assisted proof of the <a href="https://en.wikipedia.org/wiki/Kepler_conjecture">Kepler Conjecture</a> (about the densest possible way to pack oranges) — now fully machine-verified from start to finish, after <del>the </del><em><del>Annals of Mathematics</del></em><del> refused to publish a mixture of traditional mathematics and computer code</del> (seems this is not exactly what happened; see the comment section for more).  It also includes William McCune’s 1996 solution to the <a href="https://en.wikipedia.org/wiki/Robbins_algebra">Robbins Conjecture</a> in algebra (the computer-generated <a href="https://www.cs.unm.edu/~mccune/papers/robbins/eqp-theorem.proof.txt">proof</a> was only half a page, but involved substitutions so strange that for 60 years no human had found them); and at the “opposite extreme,” the 2016 solution to the <a href="https://en.wikipedia.org/wiki/Boolean_Pythagorean_triples_problem">Pythagorean triples problem</a> by Marijn Heule and collaborators, which weighed in at 200 terabytes (at that time, “the longest proof in the history of mathematics”).</p>



<p>It’s conceivable that someday, computers will replace humans at all aspects of mathematical research — but it’s also conceivable that, by the time they can do that, they’ll be able to replace humans at music and science journalism and everything else!</p>



<p><a href="http://www.scottaaronson.com/talks/proofs.ppt">New notions of proof</a> — including probabilistic, interactive, zero-knowledge, and even quantum proofs — have seen further development by theoretical computer scientists since 1993.  So far, though, these new types of proof remain either entirely theoretical (as with <a href="https://arxiv.org/abs/1610.01664">quantum proofs</a>), or else they’re used for cryptographic protocols but not for mathematical research.  (For example, zero-knowledge proofs now play a major role in certain cryptocurrencies, such as <a href="https://en.wikipedia.org/wiki/Zcash">Zcash</a>.)</p>



<p>In many areas of math (including my own, theoretical computer science), proofs have continued to get longer and harder for any one person to absorb.  This has led some to advocate a split approach, wherein human mathematicians would talk to each other only about the handwavy intuitions and high-level concepts, while the tedious verification of details would be left to computers.  So far, though, the huge investment of time needed to write proofs in machine-checkable format — for almost no return in new insight — has prevented this approach’s wide adoption.</p>



<p>Yes, there are non-rigorous approaches to math, which continue to be widely used in physics and engineering and other fields, as they always have been.  But none of these approaches have displaced proof as the gold standard whenever it’s available.  If I had to speculate about why, I’d say: if you use non-rigorous approaches, then even if it’s clear to you under what conditions your results can be trusted, it’s probably much less clear to others.  Also, even if only one segment of a research community cares about rigor, whatever earlier work that segment builds on will need to be rigorous as well — thereby exerting constant pressure in that direction.  Thus, the more collaborative a given research area becomes, the more important is rigor.</p>



<p>For my money, the elucidation of the foundations of mathematics a century ago, by Cantor, Frege, Peano, Hilbert, Russell, Zermelo, Gödel, Turing, and others, still stands as one of the greatest triumphs of human thought, up there with evolution or quantum mechanics or anything else.  It’s true that the ideal set by these luminaries remains mostly aspirational.  When mathematicians say that a theorem has been “proved,” they still mean, as they always have, something more like: “we’ve reached a social consensus that all the ideas are now in place for a strictly formal proof that could be verified by a machine … with the only task remaining being massive rote coding work that none of us has any intention of ever doing!”  It’s also true that mathematicians, being human, are subject to the full panoply of foibles you might expect: claiming to have proved things they haven’t, squabbling over who proved what, accusing others of lack of rigor while hypocritically taking liberties themselves.  But just like love and honesty remain fine ideals no matter how often they’re flouted, so too does mathematical rigor.</p>



<p><strong><font color="red">Update:</font></strong> <a href="https://blogs.scientificamerican.com/cross-check/okay-maybe-proofs-arent-dying-after-all/">Here’s Horgan’s new post</a> (entitled “Okay, Maybe Proofs Aren’t Dying After All”), which also includes a contribution from Peter Woit.<br/></p></div>
    </content>
    <updated>2019-03-07T10:11:41Z</updated>
    <published>2019-03-07T10:11:41Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Nerd Interest"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2019-03-07T19:54:51Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/037</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/037" rel="alternate" type="text/html"/>
    <title>TR19-037 |  Closure of VP under taking factors: a short and simple proof | 

	Mrinal Kumar, 

	Chi-Ning  Chou, 

	Noam Solomon</title>
    <summary>In this note, we give a short, simple and almost completely self contained proof of a classical result of Kaltofen [Kal86, Kal87, Kal89] which shows that if an n variate degree $d$ polynomial f can be computed by an arithmetic circuit of size s, then each of its factors can be computed by an arithmetic circuit of size at most poly(s, n, d). 

However, unlike Kaltofen's argument, our proof  does not  directly give an efficient algorithm for computing the circuits for the factors of f.</summary>
    <updated>2019-03-06T05:52:21Z</updated>
    <published>2019-03-06T05:52:21Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-03-12T20:20:42Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/03/06/postdoc-at-center-for-quantum-technologies-nus-singapore-apply-by-april-30-2019/</id>
    <link href="https://cstheory-jobs.org/2019/03/06/postdoc-at-center-for-quantum-technologies-nus-singapore-apply-by-april-30-2019/" rel="alternate" type="text/html"/>
    <title>postdoc at Center for Quantum Technologies, NUS, Singapore (apply by April 30, 2019)</title>
    <summary>We have a postdoctoral position in post-quantum cryptography broadly defined. In particular, anyone interested in algorithmic and/or complexity-theoretic aspects of problems relevant in lattice-based, code-based, multivariate cryptography is welcome to apply. The position comes with an internationally competitive salary and sufficient support for travel. Website: http://cs.quantumlah.org/index.php Email: divesh.aggarwal@gmail.com</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>We have a postdoctoral position in post-quantum cryptography broadly defined. In particular, anyone interested in algorithmic and/or complexity-theoretic aspects of problems relevant in lattice-based, code-based, multivariate cryptography is welcome to apply.</p>
<p>The position comes with an internationally competitive salary and sufficient support for travel.</p>
<p>Website: <a href="http://cs.quantumlah.org/index.php">http://cs.quantumlah.org/index.php</a><br/>
Email: divesh.aggarwal@gmail.com</p></div>
    </content>
    <updated>2019-03-06T00:50:53Z</updated>
    <published>2019-03-06T00:50:53Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-03-12T20:20:51Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2019/03/04/symposium-on-50-years-of-complexity-theory-a-celebration-of-the-work-of-stephen-cook/</id>
    <link href="https://cstheory-events.org/2019/03/05/symposium-on-50-years-of-complexity-theory-a-celebration-of-the-work-of-stephen-cook/" rel="alternate" type="text/html"/>
    <title>Symposium on 50 Years of Complexity Theory: A Celebration of the Work of Stephen Cook</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">May 6-9, 2019 The Fields Institute, Toronto, Ontario, Canada http://www.fields.utoronto.ca/activities/18-19/NP50 This symposium celebrates 50 years of NP-Completeness and the outstanding achievements of Stephen Cook and his remarkable influence on the field of computing. The symposium begins Monday evening May 6, with a reception and a public lecture by Christos Papadimitriou. The scientific program continues Tuesday … <a class="more-link" href="https://cstheory-events.org/2019/03/05/symposium-on-50-years-of-complexity-theory-a-celebration-of-the-work-of-stephen-cook/">Continue reading <span class="screen-reader-text">Symposium on 50 Years of Complexity Theory: A Celebration of the Work of Stephen Cook</span></a></div>
    </summary>
    <updated>2019-03-05T19:05:21Z</updated>
    <published>2019-03-05T19:05:21Z</published>
    <category term="other"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2019-03-12T20:21:40Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-27705661.post-2300296093606210929</id>
    <link href="http://processalgebra.blogspot.com/feeds/2300296093606210929/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=27705661&amp;postID=2300296093606210929" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/2300296093606210929" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/2300296093606210929" rel="self" type="application/atom+xml"/>
    <link href="http://processalgebra.blogspot.com/2019/03/sirocco-2019-second-call-for-papers.html" rel="alternate" type="text/html"/>
    <title>SIROCCO 2019 - Second Call for Papers</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><i>Michele Flammini, PC co-chair of <a href="http://cs.gssi.it/sirocco2019" target="_blank">this year's SIROCCO conference</a>, asked me to post the second CFP for that event. Submit your paper and win a trip to the Abruzzo region this summer! (In case you need them, here are <a href="https://edition.cnn.com/travel/article/italy-abruzzo-best-things-to-do/index.html" target="_blank">ten reasons why you should</a>. In my biased opinion, there are many more.)</i><br/><br/><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">SIROCCO 2019 - Second Call for Papers</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;"> </span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;"> </span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">26th International Colloquium on Structural Information and Communication Complexity (SIROCCO 2019)</span></div><div><u><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;"><a href="http://cs.gssi.it/sirocco2019" style="color: purple;" target="_blank">http://cs.gssi.it/sirocco2019</a></span></u><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;"/></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">July 1-4, 2019, L’Aquila, Italy</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;"> </span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">OVERVIEW. SIROCCO is devoted to the study of the interplay between structural knowledge, communication, and computing in decentralized systems of multiple communicating entities. Special emphasis is given to innovative approaches leading to better understanding of the relationship between computing and communication. SIROCCO has a tradition of interesting and productive scientific meetings in a relaxed and pleasant atmosphere, attracting leading researchers in a variety of fields in which communication and knowledge play a significant role. This year, SIROCCO will be held in L’Aquila, a beautiful historical city in the mountain side, 100km away from Rome.</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;"> </span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">SCOPE. Original papers are solicited from all areas of study of local structural knowledge, global communication, and computational complexities. Among the typical areas are distributed computing, communication networks, game theory, parallel computing, social networks, mobile computing (including autonomous robots), peer to peer systems, communication complexity, fault tolerant graphs, and probability in networks. Keeping up with the tradition of SIROCCO, new areas are always welcome.</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;"> </span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">SUBMISSIONS. Papers are to be submitted electronically through EasyChair at the following link: <a href="https://easychair.org/conferences/?conf=sirocco2019" style="color: purple;" target="_blank">https://easychair.org/conferences/?conf=sirocco2019</a>.</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;"> </span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Authors are invited to submit their work in one of the two acceptable formats: regular papers and brief announcements. First, abstracts should be registered and later the full papers are due. A regular submission must report on original research and must contain results that have not previously appeared, and have not been concurrently submitted to a journal or a conference with published proceedings. It must be no longer than 12 single-column pages on letter-size paper using at least 11-point font, including tables and references. Up to 4 additional pages of figures may be included with the submission. Additional details may be included in a clearly marked appendix, which will be read at the discretion of the program committee. Full Proofs omitted for lack of space should appear in an appendix.</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">A submission for a brief announcement must be no longer than 3 single-column pages on letter-size paper using at least 11-point font. The title of a submission for a brief announcement must begin with “Brief announcement:”. Such submissions may describe work in progress or work presented elsewhere. A submission that is not selected for regular presentation may be invited for a brief announcement.</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;"> </span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">PUBLICATION. Regular papers and brief announcements will be included in the conference proceedings that will be published by Springer. Regular papers receive up to 15 pages, brief announcements receive up to 2 LNCS-style pages.</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;"> </span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">BEST STUDENT PAPER AWARD. A prize will be given to the best student regular paper. A paper is eligible if at least one author is a full-time student at the time of submission, and the contribution of the student is significant. This must be noted on the cover page. The program committee may decline to give the award or may split it.</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;"> </span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">INVITED SPEAKERS</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Susanne Albers, TU München, Germany</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Pierre Fraigniaud, CNRS and University Paris Diderot, France</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Stefano Leonardi, Sapienza University of Rome, Italy</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Merav Parter, Weizmann Institute of Science, Israel</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;"> </span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">SIROCCO 2019 will also feature a talk by Paola Flocchini, University of Ottawa, Canada – Recipient of the 2019 Prize for Innovation in Distributed Computing</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;"> </span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">KEY DATES (all in 2019)</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Abstract registration: April 1</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Full paper submission: April 7</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">SIROCCO notification: May 17</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Proceedings version: TBD</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Early registration: June 1</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;"> </span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">PROGRAM COMMITTEE</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Dan Alistarh, IST Austria, Austria</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">James Aspnes, Yale University, USA</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Alkida Balliu, Aalto University, Finland</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Vittorio Bilò, University of Salento, Italy</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Lelia Blin, Sorbonne University, France</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Ioannis Caragiannis, University of Patras, Greece</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Keren Censor-Hillel, Technion, Israel (co-chair)</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Michele Flammini, GSSI &amp; University of L’Aquila, Italy (co-chair)</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Luisa Gargano, University of Salerno, Italy</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Chryssis Georgiou, University of Cyprus, Cyprus</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Magnús Halldórsson, Reykjavik University, Iceland</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Tomasz Jurdzinski, University of Wroclaw, Poland</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Fabian Kuhn, University of Freiburg, Germany</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Toshimitsu Masuzawa, Osaka University, Japan</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Alessia Milani, University of Bordeaux, France</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Ivan Rapaport, Universidad de Chile, Chile</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Dror Rawitz, Bar-Ilan University, Israel</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Mordechai Shalom, Tel-Hai College, Israel</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Jennifer Welch, Texas A&amp;M University, USA</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Prudence W.H. Wong, University of Liverpool, UK</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Yukiko Yamauchi, Kyushu University, Japan</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">        </span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">ORGANIZING COMMITTEE</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Guido Proietti, University of L'Aquila, Italy (chair)</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Gianlorenzo D’Angelo, GSSI, Italy</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Mattia D’Emidio, University of L'Aquila, Italy</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Michele Flammini, GSSI &amp; University of L'Aquila, Italy</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Luciano Gualà, University of Rome Tor Vergata, Italy</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Ludovico Iovino, GSSI, Italy</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Cosimo Vinci, University of L'Aquila, Italy</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;"> </span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">STEERING COMMITTEE</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Shantanu Das, Aix-Marseille University, France</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Rastislav Kralovic, Comenius University, Slovakia</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Zvi Lotker, Ben Gurion University, Israel</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Boaz Patt-Shamir, Tel Aviv University, Israel</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Andrzej Pelc, University of Québec, Canada</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Nicola Santoro, Carleton University, Canada</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Sebastien Tixeuil, University Paris 6, France</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Jukka Suomela, Aalto University, Finland</span></div></div>
    </content>
    <updated>2019-03-05T18:03:00Z</updated>
    <published>2019-03-05T18:03:00Z</published>
    <author>
      <name>Luca Aceto</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/01092671728833265127</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-27705661</id>
      <author>
        <name>Luca Aceto</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/01092671728833265127</uri>
      </author>
      <link href="http://processalgebra.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://processalgebra.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Papers I find interesting---mostly, but not solely, in Process Algebra---, and some fun stuff in Mathematics and Computer Science at large and on general issues related to research, teaching and academic life.</subtitle>
      <title>Process Algebra Diary</title>
      <updated>2019-03-05T18:03:24Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/036</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/036" rel="alternate" type="text/html"/>
    <title>TR19-036 |  On the complexity of computing a random Boolean function over the reals | 

	Pavel Hrubes</title>
    <summary>We say that a first-order formula $A(x_1,\dots,x_n)$ over $\mathbb{R}$ defines a Boolean function $f:\{0,1\}^n\rightarrow\{0,1\}$, if for every $x_1,\dots,x_n\in\{0,1\}$, $A(x_1,\dots,x_n)$ is true iff $f(x_1,\dots,x_n)=1$. We show that:

(i) every $f$ can be defined by a formula of size $O(n)$, 
(ii) if $A$ is required to have at most $k\geq 1$ quantifier alternations, there exists an $f$ which requires  a formula of size $2^{\Omega(n/k)}$. 
 
The latter result implies several previously known as well as some new lower bounds in computational complexity. We note that (i) holds over any field of characteristic zero, and (ii) holds for any real closed or algebraically closed field.</summary>
    <updated>2019-03-05T14:26:34Z</updated>
    <published>2019-03-05T14:26:34Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-03-12T20:20:42Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/035</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/035" rel="alternate" type="text/html"/>
    <title>TR19-035 |  PIT for depth-4 circuits and Sylvester-Gallai theorem for polynomials | 

	Alexey Milovanov</title>
    <summary>This text is a development of  a preprint of Ankit Gupta. 

We present an approach for devising a deterministic polynomial time whitekbox identity testing (PIT) algorithm for depth-$4$ circuits with bounded top fanin.
This approach is similar to Kayal-Saraf approach for depth-$3$ circuits. Kayal and Saraf  based their algorithm on Sylvester-Gallai-type theorem about linear polynomials. We show how it is possible to generalize this approach to depth-$4$ circuits. However we failed to implement this plan completely. We succeeded to construct a polynomial time deterministic algorithm for depth-$4$ circuits with bounded top fanin and its correctness requires a hypothesis. Also we present a  polynomial-time (unconditional) algorithm for some subclass of   depth-$4$ circuits with bounded top fanin.</summary>
    <updated>2019-03-05T14:25:03Z</updated>
    <published>2019-03-05T14:25:03Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-03-12T20:20:42Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/034</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/034" rel="alternate" type="text/html"/>
    <title>TR19-034 |  On $\epsilon$-sensitive monotone computations | 

	Pavel Hrubes</title>
    <summary>We show that strong-enough lower bounds on monotone arithmetic circuits or the non-negative rank of a matrix imply unconditional lower bounds in arithmetic or Boolean circuit complexity. First, we show that if a polynomial $f\in {\mathbb {R}}[x_1,\dots, x_n]$ of degree $d$ has an arithmetic circuit of size $s$ then $(x_1+\dots+x_n+1)^d+\epsilon f$ has a monotone arithmetic circuit of size $O(sd^2+n\log n)$, for some $\epsilon&gt;0$.  Second, if $f:\{0,1\}^n\rightarrow \{0,1\}$ is a Boolean function,  we associate with $f$ an explicit exponential-size matrix $M(f)$ such that the Boolean circuit size of $f$ is at least $\Omega(\min_{\epsilon &gt;0}(\hbox{rk}_+(M(f)-\epsilon J))- 2n)$, where $J$ is the all-ones matrix and $\hbox{rk}_+$ denotes the non-negative rank of a matrix. In fact, the quantity $\min_{\epsilon &gt;0}(\hbox{rk}_+(M(f)-\epsilon J))$ characterizes how hard is it to distinguish rejecting and accepting inputs of $f$ by means of a linear program. 
Finally, we introduce a proof system resembling the Boolean monotone calculus and show that similar $\epsilon$-sensitive lower bounds on monotone arithmetic circuits imply lower bounds on proof-size in the system.</summary>
    <updated>2019-03-05T13:06:08Z</updated>
    <published>2019-03-05T13:06:08Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-03-12T20:20:42Z</updated>
    </source>
  </entry>
</feed>
