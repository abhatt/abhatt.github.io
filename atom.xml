<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2020-02-21T00:21:48Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.08202</id>
    <link href="http://arxiv.org/abs/2002.08202" rel="alternate" type="text/html"/>
    <title>Span Recovery for Deep Neural Networks with Applications to Input Obfuscation</title>
    <feedworld_mtime>1582243200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jayaram:Rajesh.html">Rajesh Jayaram</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Woodruff:David_P=.html">David P. Woodruff</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Qiuyi.html">Qiuyi Zhang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.08202">PDF</a><br/><b>Abstract: </b>The tremendous success of deep neural networks has motivated the need to
better understand the fundamental properties of these networks, but many of the
theoretical results proposed have only been for shallow networks. In this
paper, we study an important primitive for understanding the meaningful input
space of a deep network: span recovery. For $k&lt;n$, let $\mathbf{A} \in
\mathbb{R}^{k \times n}$ be the innermost weight matrix of an arbitrary feed
forward neural network $M:\mathbb{R}^n \to \mathbb{R}$, so $M(x)$ can be
written as $M(x) = \sigma(\mathbf{A} x)$, for some network $\sigma:\mathbb{R}^k
\to \mathbb{R}$. The goal is then to recover the row span of $\mathbf{A}$ given
only oracle access to the value of $M(x)$. We show that if $M$ is a
multi-layered network with ReLU activation functions, then partial recovery is
possible: namely, we can provably recover $k/2$ linearly independent vectors in
the row span of $\mathbf{A}$ using poly$(n)$ non-adaptive queries to $M(x)$.
Furthermore, if $M$ has differentiable activation functions, we demonstrate
that full span recovery is possible even when the output is first passed
through a sign or $0/1$ thresholding function; in this case our algorithm is
adaptive. Empirically, we confirm that full span recovery is not always
possible, but only for unrealistically thin layers. For reasonably wide
networks, we obtain full span recovery on both random networks and networks
trained on MNIST data. Furthermore, we demonstrate the utility of span recovery
as an attack by inducing neural networks to misclassify data obfuscated by
controlled random noise as sensical inputs.
</p></div>
    </summary>
    <updated>2020-02-20T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-02-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.08198</id>
    <link href="http://arxiv.org/abs/2002.08198" rel="alternate" type="text/html"/>
    <title>The Tree Stabbing Number is not Monotone</title>
    <feedworld_mtime>1582243200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mulzer:Wolfgang.html">Wolfgang Mulzer</a>, Johannes Obenaus <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.08198">PDF</a><br/><b>Abstract: </b>Let $P \subseteq \mathbb{R}^2$ be a set of points and $T$ be a spanning tree
of $P$. The \emph{stabbing number} of $T$ is the maximum number of
intersections any line in the plane determines with the edges of $T$. The
\emph{tree stabbing number} of $P$ is the minimum stabbing number of any
spanning tree of $P$. We prove that the tree stabbing number is not a monotone
parameter, i.e., there exist point sets $P \subsetneq P'$ such that
\treestab{$P$} $&gt;$ \treestab{$P'$}, answering a question by Eppstein \cite[Open
Problem~17.5]{eppstein_2018}.
</p></div>
    </summary>
    <updated>2020-02-21T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-02-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.08114</id>
    <link href="http://arxiv.org/abs/2002.08114" rel="alternate" type="text/html"/>
    <title>BB_Evac: Fast Location-Sensitive Behavior-Based Building Evacuation</title>
    <feedworld_mtime>1582243200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mazumdar:Subhra.html">Subhra Mazumdar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pal:Arindam.html">Arindam Pal</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Parisi:Francesco.html">Francesco Parisi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Subrahmanian:V=_S=.html">V. S. Subrahmanian</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.08114">PDF</a><br/><b>Abstract: </b>Past work on evacuation planning assumes that evacuees will follow
instructions -- however, there is ample evidence that this is not the case.
While some people will follow instructions, others will follow their own
desires. In this paper, we present a formal definition of a behavior-based
evacuation problem (BBEP) in which a human behavior model is taken into account
when planning an evacuation. We show that a specific form of constraints can be
used to express such behaviors. We show that BBEPs can be solved exactly via an
integer program called BB_IP, and inexactly by a much faster algorithm that we
call BB_Evac. We conducted a detailed experimental evaluation of both
algorithms applied to buildings (though in principle the algorithms can be
applied to any graphs) and show that the latter is an order of magnitude faster
than BB_IP while producing results that are almost as good on one real-world
building graph and as well as on several synthetically generated graphs.
</p></div>
    </summary>
    <updated>2020-02-20T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-02-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.07988</id>
    <link href="http://arxiv.org/abs/2002.07988" rel="alternate" type="text/html"/>
    <title>Globally optimal point set registration by joint symmetry plane fitting</title>
    <feedworld_mtime>1582243200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hu:Lan.html">Lan Hu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shi:Haomin.html">Haomin Shi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kneip:Laurent.html">Laurent Kneip</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.07988">PDF</a><br/><b>Abstract: </b>The present work proposes a solution to the challenging problem of
registering two partial point sets of the same object with very limited
overlap. We leverage the fact that most objects found in man-made environments
contain a plane of symmetry. By reflecting the points of each set with respect
to the plane of symmetry, we can largely increase the overlap between the sets
and therefore boost the registration process. However, prior knowledge about
the plane of symmetry is generally unavailable or at least very hard to find,
especially with limited partial views, and finding this plane could strongly
benefit from a prior alignment of the partial point sets. We solve this
chicken-and-egg problem by jointly optimizing the relative pose and symmetry
plane parameters, and notably do so under global optimality by employing the
branch-and-bound (BnB) paradigm. Our results demonstrate a great improvement
over the current state-of-the-art in globally optimal point set registration
for common objects. We furthermore show an interesting application of our
method to dense 3D reconstruction of scenes with repetitive objects.
</p></div>
    </summary>
    <updated>2020-02-21T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-02-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.07955</id>
    <link href="http://arxiv.org/abs/2002.07955" rel="alternate" type="text/html"/>
    <title>Improved (Provable) Algorithms for the Shortest Vector Problem via Bounded Distance Decoding</title>
    <feedworld_mtime>1582243200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Aggarwal:Divesh.html">Divesh Aggarwal</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Yanlin.html">Yanlin Chen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kumar:Rajendra.html">Rajendra Kumar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shen:Yixin.html">Yixin Shen</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.07955">PDF</a><br/><b>Abstract: </b>The most important computational problem on lattices is the Shortest Vector
Problem ($SVP$). In this paper we present new algorithms that improve the
state-of-the-art for provable classical/quantum algorithms for $SVP$. We
present the following results.
</p>
<p>$\bullet$ A new algorithm for $SVP$ that provides a smooth tradeoff between
time complexity and memory requirement. For any positive integer $q&gt;1$, our
algorithm takes $q^{\Theta(n)}$ time and requires $q^{\Theta(n/q)}$ memory. In
fact, we give a similar time-memory tradeoff for Discrete Gaussian sampling
above the smoothing parameter.
</p>
<p>$\bullet$ A quantum algorithm that runs in time $2^{0.9532n+o(n)}$ and
requires $2^{0.5n+o(n)}$ classical memory and $poly(n)$ qubits. This improves
over the previously fastest classical (which is also the fastest quantum)
algorithm due to [ADRS15] that has a time and space complexity $2^{n+o(n)}$.
</p>
<p>$\bullet$ A classical algorithm for $SVP$ that runs in time $2^{1.73n+o(n)}$
time and $2^{0.5n+o(n)}$ space and improves over an algorithm from [CCL18] that
has the same space complexity.
</p></div>
    </summary>
    <updated>2020-02-21T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-02-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.07945</id>
    <link href="http://arxiv.org/abs/2002.07945" rel="alternate" type="text/html"/>
    <title>On the Planar Two-Center Problem and Circular Hulls</title>
    <feedworld_mtime>1582243200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Haitao.html">Haitao Wang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.07945">PDF</a><br/><b>Abstract: </b>Given a set $S$ of $n$ points in the Euclidean plane, the two-center problem
is to find two congruent disks of smallest radius whose union covers all points
of $S$. Previously, Eppstein [SODA'97] gave a randomized algorithm of
$O(n\log^2n)$ expected time and Chan [CGTA'99] presented a deterministic
algorithm of $O(n\log^2 n\log^2\log n)$ time. In this paper, we propose an
$O(n\log^2 n)$ time deterministic algorithm, which improves Chan's
deterministic algorithm and matches the randomized bound of Eppstein. If $S$ is
in convex position, then we solve the problem in $O(n\log n\log\log n)$
deterministic time. Our results rely on new techniques for dynamically
maintaining circular hulls under point insertions and deletions, which are of
independent interest.
</p></div>
    </summary>
    <updated>2020-02-21T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-02-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.07912</id>
    <link href="http://arxiv.org/abs/2002.07912" rel="alternate" type="text/html"/>
    <title>Simplex based Steiner tree instances yield large integrality gaps for the bidirected cut relaxation</title>
    <feedworld_mtime>1582243200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Robert Vicari <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.07912">PDF</a><br/><b>Abstract: </b>The bidirected cut relaxation is the characteristic representative of the
bidirected relaxations ($\mathrm{\mathcal{BCR}}$) which are a well-known class
of equivalent LP-relaxations for the NP-hard Steiner Tree Problem in Graphs
(STP). Although no general approximation algorithm based on
$\mathrm{\mathcal{BCR}}$ with an approximation ratio better than $2$ for STP is
known, it is mostly preferred in integer programming as an implementation of
STP, since there exists a formulation of compact size, which turns out to be
very effective in practice.
</p>
<p>It is known that the integrality gap of $\mathrm{\mathcal{BCR}}$ is at most
$2$, and a long standing open question is whether the integrality gap is less
than $2$ or not. The best lower bound so far is $\frac{36}{31} \approx 1.161$
proven by Byrka et al. [BGRS13]. Based on the work of Chakrabarty et al.
[CDV11] about embedding STP instances into simplices by considering appropriate
dual formulations, we improve on this result by constructing a new class of
instances and showing that their integrality gaps tend at least to $\frac{6}{5}
= 1.2$.
</p>
<p>More precisely, we consider the class of equivalent LP-relaxations
$\mathrm{\mathcal{BCR}}^{+}$, that can be obtained by strengthening
$\mathrm{\mathcal{BCR}}$ by already known straightforward Steiner vertex degree
constraints, and show that the worst case ratio regarding the optimum value
between $\mathrm{\mathcal{BCR}}$ and $\mathrm{\mathcal{BCR}}^{+}$ is at least
$\frac{6}{5}$. Since $\mathrm{\mathcal{BCR}}^{+}$ is a lower bound for the
hypergraphic relaxations ($\mathrm{\mathcal{HYP}}$), another well-known class
of equivalent LP-relaxations on which the current best $(\ln(4) +
\varepsilon)$-approximation algorithm for STP by Byrka et al. [BGRS13] is
based, this worst case ratio also holds for $\mathrm{\mathcal{BCR}}$ and
$\mathrm{\mathcal{HYP}}$.
</p></div>
    </summary>
    <updated>2020-02-21T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-02-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.07840</id>
    <link href="http://arxiv.org/abs/2002.07840" rel="alternate" type="text/html"/>
    <title>Sparse Hop Spanners for Unit Disk Graphs</title>
    <feedworld_mtime>1582243200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dumitrescu:Adrian.html">Adrian Dumitrescu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Ghosh:Anirban.html">Anirban Ghosh</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/T=oacute=th:Csaba_D=.html">Csaba D. Tóth</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.07840">PDF</a><br/><b>Abstract: </b>A unit disk graph $G$ on a given set of points $P$ in the plane is a
geometric graph where an edge exists between two points $p,q \in P$ if and only
if $|pq| \leq 1$. A subgraph $G'$ of $G$ is a $k$-hop spanner if and only if
for every edge $pq\in G$, the topological shortest path between $p,q$ in $G'$
has at most $k$ edges. We obtain the following results for unit disk graphs.
</p>
<p>(i) Every $n$-vertex unit disk graph has a $5$-hop spanner with at most
$5.5n$ edges. We analyze the family of spanners constructed by Biniaz (WADS
2019) and improve the upper bound on the number of edges from $9n$ to $5.5n$.
</p>
<p>(ii) Using a new construction, we show that every $n$-vertex unit disk graph
has a $3$-hop spanner with at most $11n$ edges.
</p>
<p>(iii) Every $n$-vertex unit disk graph has a $2$-hop spanner with
$O(n^{3/2})$ edges. This is the first construction of a $2$-hop spanner with a
subquadratic number of edges.
</p>
<p>(iv) For every sufficiently large $n$, there exists a set $P$ of $n$ points
such that every plane hop spanner on $P$ has hop stretch factor at least $4$.
Previously, no lower bound greater than $2$ was known.
</p>
<p>(v) For every point set on a circle, there exists a plane $4$-hop spanner. As
such, this provides a tight bound for points on a circle.
</p>
<p>(vi) The maximum degree of $k$-hop spanners cannot be bounded above by a
function of $k$.
</p></div>
    </summary>
    <updated>2020-02-21T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-02-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16702</id>
    <link href="https://rjlipton.wordpress.com/2020/02/20/pnp-a-story/" rel="alternate" type="text/html"/>
    <title>P=NP: A Story</title>
    <summary>The P=NP story without symbols. [ The Movie ] Dr. Strangelove is the classic 1964 movie about the potential for nuclear war between the US and the Soviet Union during the cold war. The film was directed by Stanley Kubrick and stars Peter Sellers, George Scott, Sterling Hayden, and Slim Pickens. Today we try to […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>The P=NP story without symbols.</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2020/02/20/pnp-a-story/unknown-135/" rel="attachment wp-att-16705"><img alt="" class="alignright size-full wp-image-16705" src="https://rjlipton.files.wordpress.com/2020/02/unknown-2.jpeg?w=600"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">[ The Movie ]</font></td>
</tr>
</tbody>
</table>
<p>
<em>Dr. Strangelove</em> is the classic 1964 movie about the potential for nuclear war between the US and the Soviet Union during the cold war. The film was directed by Stanley Kubrick and stars Peter Sellers, George Scott, Sterling Hayden, and Slim Pickens. </p>
<p>
Today we try to explain the P=NP problem in an “analog” fashion.</p>
<p>
In <a href="https://en.wikipedia.org/wiki/Dr._Strangelove">Dr. Strangelove</a>, US President Merkin Muffley wishes to recall a group of US bombers that are incorrectly about to drop nuclear weapons on Russia. He hopes to stop war. Here is the conversation between General Turgidson played by Scott and Muffley played by Sellers, in which Turgidson informs that the recall message will not be received…</p>
<blockquote><p>
<tt><br/>
<b>Turgidson:</b> 	…unless the message is preceded by the correct three-letter prefix. </tt></p><tt>
<p><b>Muffley:</b> 	Then do you mean to tell me, General Turgidson, that you will be unable to 	recall the aircraft? </p>
<p><b>Turgidson:</b> 	That’s about the size of it. However, we are plowing through every possible 	three letter combination of the code. But since there are seventeen thousand 	permutations it’s going to take us about two and a half days to transmit them all. </p>
<p><b>Muffley:</b> 	How soon did you say the planes would penetrate Russian radar cover? </p>
</tt><p><tt><b>Turgidson:</b> 	About eighteen minutes from now, sir.<br/>
</tt>
</p></blockquote>
<p>
This is the problem that P=NP addresses. How do you find a solution to a problem that has many potential solutions? In this case there are over thousands of possible combinations. Since each requires sending a message to an electronic unit that sits on a plane, thousands of miles away, and since messages cannot be sent too often, it will take much too long to find the secret message. </p>
<p>
The central P=NP question is: Can we do better than trying all possibilities? The answer is yes—at least in the case of the movie, the secret combination is indeed found. More on that in a moment.</p>
<p>
</p><p/><h2> Opening Mechanical Locks </h2><p/>
<p/><p>
In <em>Dr. Strangelove</em> the issue is finding the three letter code for a certain device that sits on the bombers. The protocol is: Send a three letter code to the bombers. If the code is correct, then the bombers will be recalled, and all is saved. If the code is wrong, then nothing happens. </p>
<p>
Instead of this, consider the same type of problem for finding the combination to a mechanical lock. That is a lock that is often at a gym, for example, to protect your belongings. Recall you spin the lock’s dial three times to the right, stop on the first number, then turn one time to the left, stop on the second number, and finally go to the right to stop at the third number. Then you pull the lock open.</p>
<p>
This works provided you know the combination. In general there are 64,000 such combinations. So unless you know the numbers, you are in trouble. Trying all possible combinations is not possible for mortals. But there is hope. It is possible to find the combination without knowing it. This is possible provided: <i>You have the combination lock in your hands</i>. </p>
<p>
If you only can send a possible combination to someone else to try, you are out of luck. Unfortunately in Dr. Strangelove the device on the bomber is not in your hands. So as the General says, we are trying all the possible combinations one at a time. But if the device is local you can do better.</p>
<p>
</p><p/><h3> Breaking The Locks </h3><p/>
<p/><p>
There are many <a href="https://www.wikihow.com/Open-Combination-Locks-Without-a-Code">sites</a> on the web that explain how to do much better. Here is one way to find the first number for a lock:</p>
<ol>
<li>
Pull up gently on the shackle and hold it in place. Turn the dial clockwise listening carefully until you hear the lock click. <p/>
</li><li>
Start with a good deal of pressure and gently let up as you spin it around, until you meet resistance in only one place. It should catch in only one place, making a click. <p/>
</li><li>
Add 5 to that number and write it down.
</li></ol>
<p>
This is the first number in the combination. There are similar methods to get the remaining two numbers. But already you have reduced the choices for the combination from 64,000 by a factor of 40. The rest of the how-to-do rules help you get the remaining two numbers. </p>
<p/><p/>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.wordpress.com/2020/02/20/pnp-a-story/lock6/" rel="attachment wp-att-16707"><img alt="" class="aligncenter size-full wp-image-16707" src="https://rjlipton.files.wordpress.com/2020/02/lock6.jpg?w=600"/></a>
</td>
</tr>
<tr>

</tr>
</tbody></table>
<p>
Note this attack relies on physical properties of the lock. A lock is made from springs and gears and rods, and is not perfect. As you turn the dial the mechanical parts rub and make noises. These noises reveal information, that is useful to you. Information that can reveal the combination of the lock.</p>
<p>
</p><p/><h2> Opening Digital Locks </h2><p/>
<p/><p>
The point is that there is a way to open a lock without knowing the combination. Here the trick is that you can try and use the lock and play with it in a way that it reveals information about its secret combination. This is what the P=NP question asks: </p>
<blockquote><p><b> </b> <em> <i>Are there ways to manipulate a digital lock and get it to reveal information?</i> </em>
</p></blockquote>
<p/><p>
Put another way: <i>Do digital locks make noise?</i> </p>
<p>
Essentially P=NP is true if digital locks all are imperfect, like mechanical locks. That is, if digital locks all make noise. It is widely believed that is <b>false</b>. The belief is that P<img alt="{\neq}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cneq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\neq}"/> NP which means that there are essentially perfect digital locks. That is some digital locks make no noise. </p>
<p>
</p><p/><h2> P<img alt="{\neq}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cneq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\neq}"/> NP </h2><p/>
<p/><p>
Why is it believed that digital locks can be perfect? Well the answer is simple. To date certain types of digital locks have not been broken. That is no one yet knows how to make them click and reveal information. This is of course a dangerous position for several reasons.</p>
<ol>
<li>
The failure to break a lock does not mean that someone cleverer cannot break it. <p/>
</li><li>
There are reasons that if some people knew how to break certain digital locks that they would <i>not</i> tell anyone. They might prefer to keep their ability secret to make money or cause harm. <p/>
</li><li>
Finally, it seems dangerous to guess that anything can be done without noise.
</li></ol>
<p>
The latter point is that making systems work perfectly is usually impossible. Mechanical systems must have friction of some kind, and it seems possible that digital systems will also. We will see.</p>
<p>
</p><p/><h2> Smart Search </h2><p/>
<p/><p>
Colonel Ripper, played by Hayden, is the one that launched the bombers against Russia. The recall code is found and the bombers are recalled. An officer named Mandrake, played by Sellers too, notices some doodles on a pad by the crazy Ripper. It is covered with an interlocking pattern of the words Peace On Earth, and Purity Of Essence. Ripper is obsessed with these ideas—do not ask why.</p>
<blockquote><p>
<tt><br/>
<b>Mandrake:</b> Peace on Earth. Peace on Earth. Peace on Earth: <b>P O E</b>.<br/>
Purity of essence. <b>O P E</b>. (whispers) <b>O P E</b>.<br/>
</tt>
</p></blockquote>
<p>
This is the key. This information is sent to the Pentagon and soon the bombers are recalled. The search space is cut down from thousands to 6 possible orders. Success. Well if you’ve seen the movie, you know it was not exactly success, but that failure has nothing to do with our attempt to explain the P=NP question.</p>
<p>
This second idea is different from whether locks make noise. It is whether every lock has a giveaway by dint of the process by which we obtained that particular lock to begin with. Note that the lock is not the definition of the problem itself, like SAT or graph 3-coloring, but rather a particular instance of the problem. We have discussed how instances of factoring that tend to be generated by algorithms have collective giveaways in an earlier <a href="https://rjlipton.wordpress.com/2012/03/01/do-gaps-between-primes-affect-rsa-keys/">post</a>—which quotes another part of <em>Dr. Strangelove</em>.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
I love the movie <em>Dr. Strangelove</em>, and love any excuse to talk about it. So please forgive me this story about P=NP. I hope that trying to understand the P=NP question without complex notation may help us better understand it. What do you all think?</p>
<p/></font></font></div>
    </content>
    <updated>2020-02-20T16:12:04Z</updated>
    <published>2020-02-20T16:12:04Z</published>
    <category term="Ideas"/>
    <category term="P=NP"/>
    <category term="combination lock"/>
    <category term="digital locks"/>
    <category term="locks"/>
    <category term="noise"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2020-02-21T00:20:44Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://tcsplus.wordpress.com/?p=389</id>
    <link href="https://tcsplus.wordpress.com/2020/02/20/tcs-talk-wednesday-february-26-henry-yuen-university-of-toronto/" rel="alternate" type="text/html"/>
    <title>TCS+ talk: Wednesday, February 26 — Henry Yuen, University of Toronto</title>
    <summary>The next TCS+ talk will take place this coming Wednesday, February 26th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 18:00 UTC). Henry Yuen from University of Toronto will speak about “MIP* = RE” (abstract below). Please make sure you reserve a spot for your group to join us live […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The next TCS+ talk will take place this coming Wednesday, February 26th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 18:00 UTC). <strong>Henry Yuen</strong> from University of Toronto will speak about “<em>MIP* = RE</em>” (abstract below).</p>
<p>Please make sure you reserve a spot for your group to join us live by signing up on <a href="https://sites.google.com/site/plustcs/livetalk/live-seat-reservation">the online form</a>. As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/site/plustcs/suggest">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/site/plustcs/">the website</a>.</p>
<blockquote><p>Abstract: MIP* denotes the class of problems that admit interactive proofs with quantum entangled provers. It has been an outstanding question to characterize the complexity of MIP*. Most notably, there was no known computable upper bound on this class.<br/>
We show that MIP* is equal to the class RE, the set of recursively enumerable languages. In particular, this shows that MIP* contains uncomputable problems. Through a series of known connections, this also yields a negative answer to Connes’ Embedding Problem from the theory of operator algebras. In this talk, I will explain the connection between Connes’ Embedding Problem, quantum information theory, and complexity theory. I will then give an overview of our approach, which involves reducing the Halting Problem to the problem of approximating the entangled value of nonlocal games.<br/>
Joint work with Zhengfeng Ji, Anand Natarajan, Thomas Vidick, and John Wright.</p></blockquote></div>
    </content>
    <updated>2020-02-20T08:30:51Z</updated>
    <published>2020-02-20T08:30:51Z</published>
    <category term="Announcements"/>
    <author>
      <name>plustcs</name>
    </author>
    <source>
      <id>https://tcsplus.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://tcsplus.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://tcsplus.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://tcsplus.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://tcsplus.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A carbon-free dissemination of ideas across the globe.</subtitle>
      <title>TCS+</title>
      <updated>2020-02-21T00:21:27Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.08311</id>
    <link href="http://arxiv.org/abs/2002.08311" rel="alternate" type="text/html"/>
    <title>U-Bubble Model for Mixed Unit Interval Graphs and its Applications: The MaxCut Problem Revisited</title>
    <feedworld_mtime>1582156800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kratochv=iacute=l:Jan.html">Jan Kratochvíl</a>, Tomáš Masařík, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Novotn=aacute=:Jana.html">Jana Novotná</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.08311">PDF</a><br/><b>Abstract: </b>Interval graphs, intersection graphs of segments on a real line (intervals),
play a key role in the study of algorithms and special structural properties.
Unit interval graphs, their proper subclass, where each interval has a unit
length, has also been extensively studied. We study mixed unit interval graphs;
a generalization of unit interval graphs where each interval has still a unit
length, but intervals of more than one type (open, closed, semi-closed) are
allowed. This small modification captures a much richer class of graphs. In
particular, mixed unit interval graphs are not claw-free, compared to unit
interval graphs.
</p>
<p>Heggernes, Meister, and Papadopoulos defined a representation of unit
interval graphs called the bubble model which turned out to be useful in
algorithm design. We extend this model to the class of mixed unit interval
graphs. The original bubble model was used by Boyaci, Ekim, and Shalom for
proving the polynomiality of the MaxCut problem on unit interval graphs.
However, we found a significant mistake in the proof which seems to be hardly
repairable. Moreover, we demonstrate the advantages of such a model by
providing a subexponential-time algorithm solving the MaxCut problem on mixed
unit interval graphs using our extended version of the bubble model. In
addition, it gives us a polynomial-time algorithm for specific mixed unit
interval graphs; that improves a state-of-the-art result even for unit interval
graphs. We further provide a better algorithmic upper-bound on the clique-width
of mixed unit interval graphs. Clique-width is one of the most general
structural graph parameters, where a large group of natural problems is still
solvable in the tracktable time when an efficient representation is given.
Unfortunately, the exact computation of the clique-width representation is
NP-hard. Therefore, good upper-bounds on clique-width are highly appreciated.
</p></div>
    </summary>
    <updated>2020-02-20T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-02-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.08299</id>
    <link href="http://arxiv.org/abs/2002.08299" rel="alternate" type="text/html"/>
    <title>Parallel Algorithms for Small Subgraph Counting</title>
    <feedworld_mtime>1582156800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Biswas:Amartya_Shankha.html">Amartya Shankha Biswas</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Eden:Talya.html">Talya Eden</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liu:Quanquan_C=.html">Quanquan C. Liu</a>, Slobodan Mitrović, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rubinfeld:Ronitt.html">Ronitt Rubinfeld</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.08299">PDF</a><br/><b>Abstract: </b>Subgraph counting is a fundamental problem in analyzing massive graphs, often
studied in the context of social and complex networks. There is a rich
literature on designing efficient, accurate, and scalable algorithms for this
problem. In this work, we tackle this challenge and design several new
algorithms for subgraph counting in the Massively Parallel Computation (MPC)
model:
</p>
<p>Given a graph $G$ over $n$ vertices, $m$ edges and $T$ triangles, our first
main result is an algorithm that, with high probability, outputs a
$(1+\varepsilon)$-approximation to $T$, with optimal round and space complexity
provided any $S \geq \max{(\sqrt m, n^2/m)}$ space per machine, assuming
$T=\Omega(\sqrt{m/n})$.
</p>
<p>Our second main result is an $\tilde{O}_{\delta}(\log \log n)$-rounds
algorithm for exactly counting the number of triangles, parametrized by the
arboricity $\alpha$ of the input graph. The space per machine is
$O(n^{\delta})$ for any constant $\delta$, and the total space is $O(m\alpha)$,
which matches the time complexity of (combinatorial) triangle counting in the
sequential model. We also prove that this result can be extended to exactly
counting $k$-cliques for any constant $k$, with the same round complexity and
total space $O(m\alpha^{k-2})$. Alternatively, allowing $O(\alpha^2)$ space per
machine, the total space requirement reduces to $O(n\alpha^2)$.
</p>
<p>Finally, we prove that a recent result of Bera, Pashanasangi and Seshadhri
(ITCS 2020) for exactly counting all subgraphs of size at most $5$, can be
implemented in the MPC model in $\tilde{O}_{\delta}(\sqrt{\log n})$ rounds,
$O(n^{\delta})$ space per machine and $O(m\alpha^3)$ total space. Therefore,
this result also exhibits the phenomenon that a time bound in the sequential
model translates to a space bound in the MPC model.
</p></div>
    </summary>
    <updated>2020-02-20T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-02-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.08240</id>
    <link href="http://arxiv.org/abs/2002.08240" rel="alternate" type="text/html"/>
    <title>Quantum statistical query learning</title>
    <feedworld_mtime>1582156800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Arunachalam:Srinivasan.html">Srinivasan Arunachalam</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Grilo:Alex_B=.html">Alex B. Grilo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yuen:Henry.html">Henry Yuen</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.08240">PDF</a><br/><b>Abstract: </b>We propose a learning model called the quantum statistical learning QSQ
model, which extends the SQ learning model introduced by Kearns to the quantum
setting. Our model can be also seen as a restriction of the quantum PAC
learning model: here, the learner does not have direct access to quantum
examples, but can only obtain estimates of measurement statistics on them.
Theoretically, this model provides a simple yet expressive setting to explore
the power of quantum examples in machine learning. From a practical
perspective, since simpler operations are required, learning algorithms in the
QSQ model are more feasible for implementation on near-term quantum devices. We
prove a number of results about the QSQ learning model. We first show that
parity functions, (log n)-juntas and polynomial-sized DNF formulas are
efficiently learnable in the QSQ model, in contrast to the classical setting
where these problems are provably hard. This implies that many of the
advantages of quantum PAC learning can be realized even in the more restricted
quantum SQ learning model. It is well-known that weak statistical query
dimension, denoted by WSQDIM(C), characterizes the complexity of learning a
concept class C in the classical SQ model. We show that log(WSQDIM(C)) is a
lower bound on the complexity of QSQ learning, and furthermore it is tight for
certain concept classes C. Additionally, we show that this quantity provides
strong lower bounds for the small-bias quantum communication model under
product distributions. Finally, we introduce the notion of private quantum PAC
learning, in which a quantum PAC learner is required to be differentially
private. We show that learnability in the QSQ model implies learnability in the
quantum private PAC model. Additionally, we show that in the private PAC
learning setting, the classical and quantum sample complexities are equal, up
to constant factors.
</p></div>
    </summary>
    <updated>2020-02-20T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-02-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.08231</id>
    <link href="http://arxiv.org/abs/2002.08231" rel="alternate" type="text/html"/>
    <title>A note on the explicit constructions of tree codes over polylogarithmic-sized alphabet</title>
    <feedworld_mtime>1582156800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bhandari:Siddharth.html">Siddharth Bhandari</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Harsha:Prahladh.html">Prahladh Harsha</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.08231">PDF</a><br/><b>Abstract: </b>Recently, Cohen, Haeupler and Schulman gave an explicit construction of
binary tree codes over polylogarithmic-sized output alphabet based on
Pudl\'{a}k's construction of maximum-distance-separable (MDS) tree codes using
totally-non-singular triangular matrices. In this short note, we give a unified
and simpler presentation of Pudl\'{a}k and Cohen-Haeupler-Schulman's
constructions.
</p></div>
    </summary>
    <updated>2020-02-20T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-02-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.08226</id>
    <link href="http://arxiv.org/abs/2002.08226" rel="alternate" type="text/html"/>
    <title>Subexponential parameterized algorithms and kernelization on almost chordal graphs</title>
    <feedworld_mtime>1582156800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fomin:Fedor_V=.html">Fedor V. Fomin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Golovach:Petr_A=.html">Petr A. Golovach</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.08226">PDF</a><br/><b>Abstract: </b>We study the algorithmic properties of the graph class Chordal-ke, that is,
graphs that can be turned into a chordal graph by adding at most k edges or,
equivalently, the class of graphs of fill-in at most k. We discover that a
number of fundamental intractable optimization problems being parameterized by
k admit subexponential algorithms on graphs from Chordal-ke. We identify a
large class of optimization problems on Chordal-ke that admit algorithms with
the typical running time 2^{O(\sqrt{k}\log k)}\cdot n^{O(1)}. Examples of the
problems from this class are finding an independent set of maximum weight,
finding a feedback vertex set or an odd cycle transversal of minimum weight, or
the problem of finding a maximum induced planar subgraph. On the other hand, we
show that for some fundamental optimization problems, like finding an optimal
graph coloring or finding a maximum clique, are FPT on Chordal-ke when
parameterized by k but do not admit subexponential in k algorithms unless ETH
fails. Besides subexponential time algorithms, the class of Chordal-ke graphs
appears to be appealing from the perspective of kernelization (with parameter
k). While it is possible to show that most of the weighted variants of
optimization problems do not admit polynomial in k kernels on Chordal-ke
graphs, this does not exclude the existence of Turing kernelization and
kernelization for unweighted graphs. In particular, we construct a polynomial
Turing kernel for Weighted Clique on Chordal-ke graphs. For (unweighted)
Independent Set we design polynomial kernels on two interesting subclasses of
Chordal-ke, namely, Interval-ke and Split-ke graphs.
</p></div>
    </summary>
    <updated>2020-02-20T23:31:17Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-02-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.08225</id>
    <link href="http://arxiv.org/abs/2002.08225" rel="alternate" type="text/html"/>
    <title>Efficient Construction of Behavior Graphs for Uncertain Event Data</title>
    <feedworld_mtime>1582156800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pegoraro:Marco.html">Marco Pegoraro</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/u/Uysal:Merih_Seran.html">Merih Seran Uysal</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Aalst:Wil_M=_P=_van_der.html">Wil M. P. van der Aalst</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.08225">PDF</a><br/><b>Abstract: </b>The discipline of process mining deals with analyzing execution data of
operational processes, extracting models from event data, checking the
conformance between event data and normative models, and enhancing all aspects
of processes. Recently, new techniques have been developed to analyze event
data containing uncertainty; these techniques strongly rely on representing
uncertain event data through graph-based models capturing uncertainty. In this
paper we present a novel approach to efficiently compute a graph representation
of the behavior contained in an uncertain process trace. We present our new
algorithm, analyze its time complexity, and report experimental results showing
order-of-magnitude performance improvements for behavior graph construction.
</p></div>
    </summary>
    <updated>2020-02-20T23:40:02Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-02-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.08216</id>
    <link href="http://arxiv.org/abs/2002.08216" rel="alternate" type="text/html"/>
    <title>Truly Tight-in-$\Delta$ Bounds for Bipartite Maximal Matching and Variants</title>
    <feedworld_mtime>1582156800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Brandt:Sebastian.html">Sebastian Brandt</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Olivetti:Dennis.html">Dennis Olivetti</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.08216">PDF</a><br/><b>Abstract: </b>In a recent breakthrough result, Balliu et al. [FOCS'19] proved a
deterministic $\Omega(\min(\Delta,\log n /\log \log n))$-round and a randomized
$\Omega(\min(\Delta,\log \log n/\log \log \log n))$-round lower bound for the
complexity of the bipartite maximal matching problem on $n$-node graphs in the
LOCAL model of distributed computing.
</p>
<p>Both lower bounds are asymptotically tight as a function of the maximum
degree $\Delta$.
</p>
<p>We provide truly tight bounds in $\Delta$ for the complexity of bipartite
maximal matching and many natural variants, up to and including the additive
constant.
</p>
<p>As a by-product, our results yield a considerably simplified version of the
proof by Balliu et al.
</p>
<p>We show that our results can be obtained via bounded automatic round
elimination, a version of the recent automatic round elimination technique by
Brandt [PODC'19] that is particularly suited for automatization from a
practical perspective.
</p>
<p>In this context, our work can be seen as another step towards the
automatization of lower bounds in the LOCAL model.
</p></div>
    </summary>
    <updated>2020-02-20T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-02-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.08199</id>
    <link href="http://arxiv.org/abs/2002.08199" rel="alternate" type="text/html"/>
    <title>The set of hyperbolic equilibria and of invertible zeros on the unit ball is computable</title>
    <feedworld_mtime>1582156800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gra=ccedil=a:Daniel_S=.html">Daniel S. Graça</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhong:Ning.html">Ning Zhong</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.08199">PDF</a><br/><b>Abstract: </b>In this note, we construct an algorithm that, on input of a description of a
structurally stable planar dynamical flow defined on the unit disk, outputs the
exact number of the (hyperbolic) equilibrium points as well the locations of
all equilibriums with arbitrary precision. By arbitrary accuracy it is meant
that the accuracy is included in the input of the algorithm. As a consequence,
we obtain a root-finding algorithm that computes the set of all zeros of a
continuously differentiable function $f$ defined on the unit ball of
$\mathbb{R}^{d}$ with arbitrary accuracy, provided that the Jacobian of $f$ is
invertible at each zero of $f$; moreover, the computation is uniform in $f$.
</p></div>
    </summary>
    <updated>2020-02-20T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-02-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.08086</id>
    <link href="http://arxiv.org/abs/2002.08086" rel="alternate" type="text/html"/>
    <title>The complexity of knapsack problems in wreath products</title>
    <feedworld_mtime>1582156800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Figelius:Michael.html">Michael Figelius</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Ganardi:Moses.html">Moses Ganardi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lohrey:Markus.html">Markus Lohrey</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zetzsche:Georg.html">Georg Zetzsche</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.08086">PDF</a><br/><b>Abstract: </b>We prove new complexity results for computational problems in certain wreath
products of groups and (as an application) for free solvable group. For a
finitely generated group we study the so-called power word problem (does a
given expression $u_1^{k_1} \ldots u_d^{k_d}$, where $u_1, \ldots, u_d$ are
words over the group generators and $k_1, \ldots, k_d$ are binary encoded
integers, evaluate to the group identity?) and knapsack problem (does a given
equation $u_1^{x_1} \ldots u_d^{x_d} = v$, where $u_1, \ldots, u_d,v$ are words
over the group generators and $x_1,\ldots,x_d$ are variables, has a solution in
the natural numbers). We prove that the power word problem for wreath products
of the form $G \wr \mathbb{Z}$ with $G$ nilpotent and iterated wreath products
of free abelian groups belongs to $\mathsf{TC}^0$. As an application of the
latter, the power word problem for free solvable groups is in $\mathsf{TC}^0$.
On the other hand we show that for wreath products $G \wr \mathbb{Z}$, where
$G$ is a so called uniformly strongly efficiently non-solvable group (which
form a large subclass of non-solvable groups), the power word problem is
$\mathsf{coNP}$-hard. For the knapsack problem we show
$\mathsf{NP}$-completeness for iterated wreath products of free abelian groups
and hence free solvable groups. Moreover, the knapsack problem for every wreath
product $G \wr \mathbb{Z}$, where $G$ is uniformly efficiently non-solvable, is
$\Sigma^2_p$-hard.
</p></div>
    </summary>
    <updated>2020-02-20T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-02-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.08061</id>
    <link href="http://arxiv.org/abs/2002.08061" rel="alternate" type="text/html"/>
    <title>Translating Between Wavelet Tree and Wavelet Matrix Construction</title>
    <feedworld_mtime>1582156800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dinklage:Patrick.html">Patrick Dinklage</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.08061">PDF</a><br/><b>Abstract: </b>The wavelet tree (Grossi et al. [SODA, 2003]) and wavelet matrix (Claude et
al. [Inf. Syst., 2015]) are compact data structures with many applications such
as text indexing or computational geometry. By continuing the recent research
of Fischer et al. [ALENEX, 2018], we explore the similarities and differences
of these heavily related data structures with focus on their construction. We
develop a data structure to modify construction algorithms for either the
wavelet tree or matrix to construct instead the other. This modification is
efficient, in that it does not worsen the asymptotic time and space
requirements of any known wavelet tree or wavelet matrix construction
algorithm.
</p></div>
    </summary>
    <updated>2020-02-20T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-02-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.08004</id>
    <link href="http://arxiv.org/abs/2002.08004" rel="alternate" type="text/html"/>
    <title>Fast and linear-time string matching algorithms based on the distances of $q$-gram occurrences</title>
    <feedworld_mtime>1582156800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kobayashi:Satoshi.html">Satoshi Kobayashi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hendrian:Diptarama.html">Diptarama Hendrian</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yoshinaka:Ryo.html">Ryo Yoshinaka</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shinohara:Ayumi.html">Ayumi Shinohara</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.08004">PDF</a><br/><b>Abstract: </b>Given a text $T$ of length $n$ and a pattern $P$ of length $m$, the string
matching problem is a task to find all occurrences of $P$ in $T$. In this
study, we propose an algorithm that solves this problem in $O((n + m)q)$ time
considering the distance between two adjacent occurrences of the same $q$-gram
contained in $P$. We also propose a theoretical improvement of it which runs in
$O(n + m)$ time, though it is not necessarily faster in practice. We compare
the execution times of our and existing algorithms on various kinds of real and
artificial datasets such as an English text, a genome sequence and a Fibonacci
string. The experimental results show that our algorithm is as fast as the
state-of-the-art algorithms in many cases, particularly when a pattern
frequently appears in a text.
</p></div>
    </summary>
    <updated>2020-02-20T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-02-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.07892</id>
    <link href="http://arxiv.org/abs/2002.07892" rel="alternate" type="text/html"/>
    <title>Fair Clustering with Multiple Colors</title>
    <feedworld_mtime>1582156800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/B=ouml=hm:Matteo.html">Matteo Böhm</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fazzone:Adriano.html">Adriano Fazzone</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Leonardi:Stefano.html">Stefano Leonardi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schwiegelshohn:Chris.html">Chris Schwiegelshohn</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.07892">PDF</a><br/><b>Abstract: </b>A fair clustering instance is given a data set $A$ in which every point is
assigned some color. Colors correspond to various protected attributes such as
sex, ethnicity, or age. A fair clustering is an instance where membership of
points in a cluster is uncorrelated with the coloring of the points.
</p>
<p>Of particular interest is the case where all colors are equally represented.
If we have exactly two colors, Chierrichetti, Kumar, Lattanzi and Vassilvitskii
(NIPS 2017) showed that various $k$-clustering objectives admit a constant
factor approximation. Since then, a number of follow up work has attempted to
extend this result to a multi-color case, though so far, the only known results
either result in no-constant factor approximation, apply only to special
clustering objectives such as $k$-center, yield bicrititeria approximations, or
require $k$ to be constant.
</p>
<p>In this paper, we present a simple reduction from unconstrained
$k$-clustering to fair $k$-clustering for a large range of clustering
objectives including $k$-median, $k$-means, and $k$-center. The reduction loses
only a constant factor in the approximation guarantee, marking the first true
constant factor approximation for many of these problems.
</p></div>
    </summary>
    <updated>2020-02-20T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-02-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2020/02/19/snowflake-spanners</id>
    <link href="https://11011110.github.io/blog/2020/02/19/snowflake-spanners.html" rel="alternate" type="text/html"/>
    <title>Snowflake spanners</title>
    <summary>My previous post gave an example of a largish random point set where the greedy geometric spanner for distance ratio 2 had no crossings, while the spanner for the lower distance ratio had many (linearly many) crossings. And you might think from that example that there is some threshold for which distance ratios above the threshold always have planar greedy spanners, or even that the threshold is at or below 2. But it’s not true.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="https://11011110.github.io/blog/2020/02/17/spanners-have-sparse.html">My previous post</a> gave an example of a largish random point set where the <a href="https://en.wikipedia.org/wiki/Greedy_geometric_spanner">greedy geometric spanner</a> for distance ratio 2 had no crossings, while the spanner for the lower distance ratio had many (linearly many) crossings. And you might think from that example that there is some threshold for which distance ratios above the threshold always have planar greedy spanners, or even that the threshold is at or below 2. But it’s not true.</p>

<p>To see why not, we have to turn to an idea from an earlier paper of mine, “<a href="https://arxiv.org/abs/cs.CG/9907031">Beta-skeletons have unbounded dilation</a>” (<em>CGTA</em> 2002). In it, I used a flattened variant of the <a href="https://en.wikipedia.org/wiki/Koch_snowflake">Koch snowflake fractal</a> to find bad examples for a different kind of spanner, and the same thing works here too. The intuitive idea is that these fractals form curves that, locally, look nice to a spanner algorithm (just connect consecutive pairs of points along the curve). But they pack a lot of length into a small area, forcing the spanner algorithm to eventually add some shortcuts to the curve. If we can control where it adds the shortcuts, maybe we can make pairs of shortcuts cross.</p>

<p>In fact the Koch snowflake itself almost works, but it has some closest pairs that are non-consecutive along the curve, allowing the greedy spanner algorithm to choose those pairs instead of the consecutive curve points that we want it to choose. If we flatten the snowflake just a little bit, that complication goes away. If we choose the distance ratio of the spanner large enough, we can make it so that the greedy spanner algorithm doesn’t add any shortcuts until it reaches pairs of points that are opposite each other on the curve. And if we make it just barely large enough for that to be true, it will be forced to add those shortcuts once it does reach that distance in the sorted ordering of the distances. For instance, here’s a point set and its non-planar greedy spanner generated in this way with spanning ratio 4:</p>

<p style="text-align: center;"><img alt="Greedy spanner of snowflake-like curve with distance ratio 4" src="https://11011110.github.io/blog/assets/2020/snowflake.svg"/></p>

<p>This pretty picture, with the three crossing shortcuts between opposite pairs of points, doesn’t quite generalize to arbitrary-order snowflake-like curves, unfortunately. It will always be possible to find a distance ratio  such that the greedy algorithm adds one of these three shortcuts, as the first shortcut it needs to add. But then once it has added it, that shortcut can make the other two opposite pairs of points closer to each other in the spanner than they were, so that the greedy algorithm doesn’t need to add them. We might only get one of these three crossing edges, instead of all three. (In fact, for the point set shown here, this is exactly what happens for spanning ratio 4.5.)</p>

<p>Instead, let’s look for a slightly lower distance ratio , for which the first shortcuts added by the greedy spanner algorithm cut off two lobes of the snowflake instead of three. For the same points as above,  works:</p>

<p style="text-align: center;"><img alt="Greedy spanner of snowflake-like curve with distance ratio 3.5" src="https://11011110.github.io/blog/assets/2020/snowflake2.svg"/></p>

<p>These two-lobe shortcuts are shorter than the three-lobe shortcuts, so they’re considered earlier by the greedy algorithm. There are two crossing equilateral triangles of two-lobe shortcuts (forming a Star of David pattern) and the greedy algorithm has to include two edges from each equilateral triangle. This is because, for each of these potential shortcuts, the greedy spanner won’t include a better path between its endpoints until it has either that shortcut itself or the two other shortcuts of the same triangle. No matter which two shortcuts we choose from each of the two equilateral triangles, we get either two crossings or, as here, three crossings.</p>

<p>For any order of flattened Koch snowflake, there’s a distance ratio  producing a greedy spanner that looks like this picture, with two or three crossings. And by choosing a snowflake of high-enough order, we can make  become arbitrarily large. Or, to put it another way, the greedy spanner algorithm can generate crossings for arbitrarily large distance ratios.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/103689972863017904">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2020-02-19T23:01:00Z</updated>
    <published>2020-02-19T23:01:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2020-02-20T07:24:46Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/019</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/019" rel="alternate" type="text/html"/>
    <title>TR20-019 |  A note on the explicit constructions of tree codes over polylogarithmic-sized alphabet | 

	Siddharth Bhandari, 

	Prahladh Harsha</title>
    <summary>Recently, Cohen, Haeupler and Schulman gave an explicit construction of binary tree codes over polylogarithmic-sized output alphabet based on Pudl\'{a}k's construction of maximum-distance-separable (MDS)  tree codes using totally-non-singular triangular matrices. In this short note, we give a unified and simpler presentation of Pudl\'{a}k and Cohen-Haeupler-Schulman's constructions.</summary>
    <updated>2020-02-19T15:04:50Z</updated>
    <published>2020-02-19T15:04:50Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-02-21T00:20:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/02/19/associate-professor-professor-of-computer-science-at-university-of-oxford-apply-by-april-24-2020/</id>
    <link href="https://cstheory-jobs.org/2020/02/19/associate-professor-professor-of-computer-science-at-university-of-oxford-apply-by-april-24-2020/" rel="alternate" type="text/html"/>
    <title>Associate Professor/Professor of Computer Science at University of Oxford (apply by April 24, 2020)</title>
    <summary>The Department of Computer Science and St Catherine’s College are recruiting an Associate Professor of Computer Science in the Department of Computer Science, to start before 31 July 2020 if possible and by no later than 1 October 2020. The successful candidate will also be appointed as Fellow and Tutor in Computer Science at St […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Department of Computer Science and St Catherine’s College are recruiting an Associate Professor of Computer Science in the Department of Computer Science, to start before 31 July 2020 if possible and by no later than 1 October 2020. The successful candidate will also be appointed as Fellow and Tutor in Computer Science at St Catherine’s College. (see link for details)</p>
<p>Website: <a href="http://www.cs.ox.ac.uk/news/1782-full.html">http://www.cs.ox.ac.uk/news/1782-full.html</a><br/>
Email: agalanis@cs.ox.ac.uk</p></div>
    </content>
    <updated>2020-02-19T13:29:42Z</updated>
    <published>2020-02-19T13:29:42Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-02-21T00:21:02Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://emanueleviola.wordpress.com/?p=717</id>
    <link href="https://emanueleviola.wordpress.com/2020/02/18/working-remotely-will-be-the-most-significant-transformation-since-agriculture/" rel="alternate" type="text/html"/>
    <title>Working remotely will be the most significant transformation since agriculture</title>
    <summary>Its impact on civilization will be exactly opposite. Rather than concentrating population, it will disperse it. Commuting and the traffic crisis will disappear. So will the housing crisis. You will have a large lot of land with a robot-ready house built new with safe, eco-friendly material and free of hazardous substance. You will live away […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Its impact on civilization will be exactly opposite.  Rather than concentrating population, it will disperse it.  Commuting and the traffic crisis will disappear.  So will the housing crisis.  You will have a large lot of land with a robot-ready house built new with safe, eco-friendly material and free of hazardous substance.  You will live away from volcanoes, fault lines, tornadoes, wild fires and other hazards. You’ll be able to move to a location with ideal climate, which for historical reasons are now under-populated.  This will dramatically reduce housing costs, especially heating, and solve  or greatly mitigate the pollution problem. Huge amounts of space will be cleared up and given back to nature, or used for housing.</p>



<p>Doctors will visit patients remotely.  This will enable patients to be followed up more regularly and consistently throughout their lives regardless of where they are.  Doctors will have more time to give meaningful advice rather than having the patient wait 1 year for the appointment and then spend 1 hour to get to the doctor for a 10-minute visit of which 8 are spent looking at the screen and filling reports. Robo-tools will take measurements and send them to the doctor.  If a complicated procedure is required, the expert will connect with the patient and the doctor remotely first, and then the patient will schedule a trip for the procedure.</p>



<p>You’ll take gym classes remotely via a remote gym. The instructor will give you personalized advice and follow your progress anywhere, anytime. Demanding facilities like swimming pools will be next to your house.</p>



<p>Courts of law, and the entire judicial system will be taken off-line.</p>



<p>People will vote from home, elections will be more frequent and granular.  Constituents choosing not to vote will (maybe) have to specifically abstain.  This will finally realize the democratic ideal where the government represents the will of the people.</p>



<p>Constituents will be able to participate to discussions, instead of having to travel 1 hour for a 5-minute in-person discussion.  The level of engagement will be measured by the level of engagement as opposed to travel distance.</p>



<p>Wireless won’t be used on a large scale, since its noxious effects will be undeniable. Instead we will have network cables densely spread out over the earth — one of the few duties of the government will be to maintain these cables for the free, democratic, public use.</p>



<p>Banking will be done remotely, and physical money will disappear.</p>



<p>We will have immersive work-stations with wall-to-wall, solar-powered e-ink screens, holographic images, and audio indistinguishable from reality.  You will be able to attend meetings while exercising, like walking or biking on a machine or outside.  This will boost your health, lowering health care costs for all.</p>



<p>People with special needs will have the same opportunities and duties as everyone else and will be fully integrated.</p>



<p>All learning will be done remotely.  The instructor will be able to provide better, more personalized teaching, and connect with each student face-to-face.  Testing will be done remotely, each student monitored via cameras.  Critical examinations will be administered in special-purpose facilities which are next to your house (similar in spirit to say the way GRE is administered, but much more large scale and flexible, including for example synchronized examination).</p>



<p>You will have farms next to your house, growing organic food that you can eat fresh. Epidemics will be much rarer and more easily controlled, as population will be less concentrated and will travel less.</p>



<p>Fantasy? Actually, many of these things are already happening!</p>



<p/></div>
    </content>
    <updated>2020-02-18T20:38:26Z</updated>
    <published>2020-02-18T20:38:26Z</published>
    <category term="Uncategorized"/>
    <category term="Utopia"/>
    <author>
      <name>Manu</name>
    </author>
    <source>
      <id>https://emanueleviola.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://emanueleviola.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://emanueleviola.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://emanueleviola.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://emanueleviola.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>by Manu</subtitle>
      <title>Thoughts</title>
      <updated>2020-02-21T00:21:20Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/018</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/018" rel="alternate" type="text/html"/>
    <title>TR20-018 |  Algorithms and Lower Bounds for de Morgan Formulas of Low-Communication Leaf Gates | 

	Valentine Kabanets, 

	Sajin Koroth, 

	Zhenjian Lu, 

	Dimitrios Myrisiotis, 

	Igor Oliveira</title>
    <summary>The class $FORMULA[s] \circ \mathcal{G}$ consists of Boolean functions computable by size-$s$ de Morgan formulas whose leaves are any Boolean functions from a class $\mathcal{G}$. We give lower bounds and (SAT, Learning, and PRG) algorithms for $FORMULA[n^{1.99}]\circ \mathcal{G}$, for classes $\mathcal{G}$ of functions with low communication complexity. Let $R^{(k)}(\mathcal{G})$ be the maximum $k$-party number-on-forehead randomized communication complexity of a function in $\mathcal{G}$. Among other results, we show:


(1) The Generalized Inner Product function $GIP^k_n$ cannot be computed in  $FORMULA[s]\circ \mathcal{G}$ on more than $1/2+\varepsilon$ fraction of inputs for
    	    $$
    	        s = o \! \left ( \frac{n^2}{ \left(k \cdot 4^k \cdot {R}^{(k)}(\mathcal{G}) \cdot \log (n/\varepsilon) \cdot \log (1/\varepsilon) \right)^{2}} \right).
    	    $$
    	    This significantly extends the lower bounds against bipartite formulas obtained by [Tal17]. As a corollary, we get an average-case lower bound for $GIP^k_n$ against $FORMULA[n^{1.99}]\circ PTF^{k-1}$, i.e., sub-quadratic-size de Morgan formulas with degree-$(k-1)$ PTF (polynomial threshold function) gates at the bottom. Previously, only sub-linear lower bounds were known [Nis94, Vio15] for circuits with PTF gates.
   	 

(2) There is a PRG of seed length $n/2 + O\left( \sqrt{s} \cdot R^{(2)}(\mathcal{G}) \cdot\log(s/\varepsilon) \cdot \log (1/\varepsilon) \right)$ that $\varepsilon$-fools $FORMULA[s] \circ \mathcal{G}$. For the special case of $FORMULA[s] \circ LTF$, i.e., size-$s$ formulas with LTF (linear threshold function) gates at the bottom, we get the better seed length $O\left(n^{1/2}\cdot s^{1/4}\cdot \log(n)\cdot \log(n/\varepsilon)\right)$. In particular, this  provides the first non-trivial PRG (with seed length $o(n)$) for intersections of $n$ half-spaces in the regime where $\varepsilon \leq 1/n$, complementing a recent result of [OST19].


(3) There exists a randomized $2^{n-t}$-time $\#$SAT algorithm for $FORMULA[s] \circ \mathcal{G}$, where
            $$
                t = \Omega\left(\frac{n}{\sqrt{s} \cdot \log^2(s)\cdot R^{(2)}(\mathcal{G})}\right)^{1/2}.
            $$ 
            In particular, this implies a nontrivial #SAT algorithm for $FORMULA[n^{1.99}]\circ LTF$.


(4) The Minimum Circuit Size Problem is not in $FORMULA[n^{1.99}] \circ XOR$; thereby making progress on hardness magnification, in connection with results from [OPS19, CJW19]. On the algorithmic side, we show that the concept class $FORMULA[n^{1.99}] \circ XOR$ can be PAC-learned in time $2^{O(n/\log n)}$.</summary>
    <updated>2020-02-18T18:28:25Z</updated>
    <published>2020-02-18T18:28:25Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-02-21T00:20:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/017</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/017" rel="alternate" type="text/html"/>
    <title>TR20-017 |  Multiparty Karchmer-Wigderson Games and Threshold Circuits | 

	Alexander Kozachinskiy, 

	Vladimir Podolskii</title>
    <summary>We suggest a generalization of Karchmer-Wigderson communication games to the multiparty setting. Our generalization turns out to be tightly connected to circuits consisting of threshold gates. This allows us to obtain new explicit constructions of such circuits for several functions. In particular, we provide an explicit (polynomial-time computable) log-depth monotone formula for Majority function, consisting only of 3-bit majority gates and variables. This resolves  a conjecture of Cohen et al. (CRYPTO 2013).</summary>
    <updated>2020-02-18T18:24:22Z</updated>
    <published>2020-02-18T18:24:22Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-02-21T00:20:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/016</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/016" rel="alternate" type="text/html"/>
    <title>TR20-016 |  Hitting Sets Give Two-Sided Derandomization of Small Space | 

	Kuan Cheng, 

	William Hoza</title>
    <summary>A hitting set is a "one-sided" variant of a pseudorandom generator (PRG), naturally suited to derandomizing algorithms that have one-sided error. We study the problem of using a given hitting set to derandomize algorithms that have two-sided error, focusing on space-bounded algorithms. For our first result, we show that if there is a log-space hitting set for polynomial-width read-once branching programs (ROBPs), then not only does $\mathbf{L} = \mathbf{RL}$, but $\mathbf{L} = \mathbf{BPL}$ as well. This answers a question raised by Hoza and Zuckerman (FOCS 2018).

Next, we consider constant-width ROBPs. We show that if there are log-space hitting sets for constant-width ROBPs, then given black-box access to a constant-width ROBP $f$, it is possible to deterministically estimate $\mathbb{E}[f]$ to within $\pm \varepsilon$ in space $O(\log(n/\varepsilon))$. Unconditionally, we give a deterministic algorithm for this problem with space complexity $O(\log^2 n + \log(1/\varepsilon))$, slightly improving over previous work.

Finally, we investigate the limits of this line of work. Perhaps the strongest reduction along these lines one could hope for would say that for every explicit hitting set, there is an explicit PRG with similar parameters. In the setting of constant-width ROBPs over a large alphabet, we prove that establishing such a strong reduction is at least as difficult as constructing a good PRG outright. Quantitatively, we prove that if the strong reduction holds, then for every constant $\alpha &gt; 0$, there is an explicit PRG for constant-width ROBPs with seed length $O(\log^{1 + \alpha} n)$. Along the way, unconditionally, we construct an improved hitting set for ROBPs over a large alphabet.</summary>
    <updated>2020-02-18T17:48:26Z</updated>
    <published>2020-02-18T17:48:26Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-02-21T00:20:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/015</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/015" rel="alternate" type="text/html"/>
    <title>TR20-015 |  New lower bounds for probabilistic degree and AC0 with parity gates | 

	Emanuele Viola</title>
    <summary>We prove new lower bounds for computing some functions $f:\{0,1\}^{n}\to\{0,1\}$ in $E^{NP}$ by polynomials modulo $2$, constant-depth circuits with parity gates ($AC^{0}[\oplus]$), and related classes. Results include:

(1) $\Omega(n/\log^{2}n)$ lower bounds probabilistic degree. This is optimal up to a factor $O(\log^{2}n)$. The previous best lower bound was $\Omega(\sqrt{n})$ proved in the 80's by Razborov and Smolensky.

(2) $\exp(\Omega(n/\log^{2}n)^{1/(h-1)})$ lower bounds on the size of depth-$h$ $AC^{0}[\oplus]$ circuits, for any $h$. This almost matches the $\exp(\Omega(n^{1/(h-1)}))$ lower bounds for $AC^{0}$ by Hastad. The previous best lower bound was $\exp(\Omega(n^{1/(h+1)}))$ by Rajgopal, Santhanam, and Srinivasan who recently improved Razborov and Smolensky's $\exp(\Omega(n^{1/(2h-2)}))$ bound.

(3) $(1/2-(\log^{O(h)}s)/n)$ average-case hardness for size-$s$ depth-$h$ $AC^{0}[\oplus]$ circuits under the uniform distribution, for say polynomial or quasi-polynomial $s$, and any fixed $h$. The previous best was $(1/2-(\log^{O(h)}s)/\sqrt{n})$.

(4) any majority of $t$ $AC^{0}[\oplus]$ circuits, $MAJ_{^{t}}\circ AC^{0}[\oplus]$, of size $s$ and depth $h$, has $t\ge n^{2}/\log^{O(h)}(s)$, for any $s,h$. The previous best was $t\ge n/\log^{O(h)}(s)$.

(5) any $AC^{0}[\oplus]\circ LTF_{t}\circ AC^{0}[\oplus]\circ LTF$ circuit, where $LTF$ are threshold functions, has $t\ge n/\log^{O(h)}(s)$, for any $s,h$. The previous best was $t\ge\sqrt{n}/\log^{O(h)}(s)$ recently proved by Alman and Chen.

The mentioned previous best lower bounds in (1), (3), and (4) held for the Majority function. Each of the new lower bounds in this paper is false for Majority. For (2) and (5) the previous best held for $E^{NP}$.
The proofs build on Williams' "guess-and-SAT" method. For (1) we show how to use a PCP by Ben-Sasson and Viola towards probabilistic-degree lower bounds. Results (2), (4), and (5) are then more or less automatic, as is (3) under a non-uniform distribution. To strengthen (3) to hold under the uniform distribution we use a different argument which combines the recent work by Alman and Chen with hardness amplification.

A concurrent work by Chen and Ren obtains a result stronger than (3).</summary>
    <updated>2020-02-18T17:11:55Z</updated>
    <published>2020-02-18T17:11:55Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-02-21T00:20:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/014</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/014" rel="alternate" type="text/html"/>
    <title>TR20-014 |  Palette-Alternating Tree Codes | 

	Gil Cohen, 

	Shahar Samocha</title>
    <summary>A tree code is an edge-coloring of the complete infinite binary tree such that every two nodes of equal depth have a fraction--bounded away from $0$--of mismatched colors between the corresponding paths to their least common ancestor. Tree codes were introduced in a seminal work by Schulman (STOC 1993) and serve as a key ingredient in almost all deterministic interactive coding schemes. The number of colors effects the coding scheme's rate.

It is shown that $4$ is precisely the least number of colors for which tree codes exist. Thus, tree-code-based coding schemes cannot achieve rate larger than $1/2$. To overcome this barrier, a relaxed notion called palette-alternating tree codes is introduced, in which the number of colors can depend on the layer. We prove the existence of such constructs in which most layers use  $2$ colors--the bare minimum. The distance-rate tradeoff we obtain matches the Gilbert-Varshamov bound.

Based on palette-alternating tree codes, we devise a deterministic interactive coding scheme against adversarial errors that approaches capacity. To analyze our protocol, we prove a structural result on the location of failed communication-rounds induced by the error pattern enforced by the adversary. Our coding scheme is efficient given an explicit palette-alternating tree codes and serves as an alternative to the scheme obtained by Gelles et al. (SODA 2016)</summary>
    <updated>2020-02-18T15:46:07Z</updated>
    <published>2020-02-18T15:46:07Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-02-21T00:20:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/013</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/013" rel="alternate" type="text/html"/>
    <title>TR20-013 |  Linear-time Erasure List-decoding of Expander Codes | 

	Noga Ron-Zewi, 

	Mary Wootters, 

	Gilles Z\&amp;#39;{e}mor</title>
    <summary>We give a linear-time erasure list-decoding algorithm for expander codes. More precisely, let $r &gt; 0$ be any integer.  Given an inner code $\cC_0$ of length $d$, and a $d$-regular bipartite expander graph $G$ with $n$ vertices on each side, we give an algorithm to list-decode the expander code $\cC = \cC(G, \cC_0)$ of length $nd$ from approximately $\delta \delta_r nd$ erasures in time $n \cdot \poly(d2^r / \delta)$, where $\delta$ and $\delta_r$ are the relative distance and the $r$'th generalized relative distance of $\cC_0$, respectively. To the best of our knowledge, this is the first linear-time algorithm that can list-decode expander codes from erasures beyond their (designed) distance of approximately $\delta^2 nd$.


To obtain our results, we show that an approach similar to that of (Hemenway and Wootters, \emph {Information and Computation}, 2018) can be used to obtain such an erasure-list-decoding algorithm with an exponentially worse dependence of the running time on $r$ and $\delta$; then  we show how to improve the dependence of the running time on these parameters.</summary>
    <updated>2020-02-18T15:44:18Z</updated>
    <published>2020-02-18T15:44:18Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-02-21T00:20:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4616</id>
    <link href="https://www.scottaaronson.com/blog/?p=4616" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4616#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4616" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">My video interview with Lex Fridman at MIT about philosophy and quantum computing</title>
    <summary xml:lang="en-US">Here it is (about 90 minutes; I recommend the 1.5x speed) I had buried this as an addendum to my previous post on the quantum supremacy lecture tour, but then decided that a steely-eyed assessment of what’s likely to have more or less interest for this blog’s readers probably militated in favor of a separate […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="https://www.youtube.com/watch?v=uX5t8EivCaM">Here it is</a> (about 90 minutes; I recommend the 1.5x speed)</p>



<p>I had buried this as an addendum to my previous post on the quantum supremacy lecture tour, but then decided that a steely-eyed assessment of what’s likely to have more or less interest for this blog’s readers probably militated in favor of a separate post.</p>



<p>Thanks so much to Lex for arranging the interview and for his questions!</p></div>
    </content>
    <updated>2020-02-18T05:36:06Z</updated>
    <published>2020-02-18T05:36:06Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Adventures in Meatspace"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Announcements"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Metaphysical Spouting"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Quantum"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2020-02-20T17:56:04Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>http://corner.mimuw.edu.pl/?p=1104</id>
    <link href="http://corner.mimuw.edu.pl/?p=1104" rel="alternate" type="text/html"/>
    <title>Postdoc position in theoretical computer science</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">We announce POSTDOC POSITIONS  at the Institute of Informatics, University of Warsaw, Poland. The positions are supported by the ERC Consolidator Grant TUgbOAT: “Towards Unification of Algorithmic Tools” led by Piotr Sankowski. The TUgbOAT’ focus is on basic algorithmic problems. … <a href="http://corner.mimuw.edu.pl/?p=1104">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>We announce</p>



<p><strong>POSTDOC POSITIONS </strong></p>



<p>at the Institute of Informatics, University of Warsaw, Poland. The positions are supported by the ERC Consolidator Grant TUgbOAT: “Towards Unification of Algorithmic Tools” led by Piotr Sankowski.</p>



<p>The TUgbOAT’ focus is on basic algorithmic problems. Example topics include:</p>



<p> * algorithms for finding matchings in graphs;</p>



<p> * online algorithms in various settings;</p>



<p> * studying and algorithmically exploiting properties of data.</p>



<p>The theoretical computer science group in Warsaw is strong and growing. Apart from the algorithms group members specializing in parameterized, approximation and graph algorithms (Łukasz Kowalik, Marcin Mucha, Marcin Pilipczuk, Michał Pilipczuk, Piotr Sankowski), we have also a leading research group in logic and automata (Mikołaj Bojańczyk, Bartosz Klin, Sławomir Lasota).</p>



<p>We are looking for outstanding <strong>candidates with a Ph.D.</strong> (or soon to obtain a Ph.D.) in Computer Science or Mathematics who have already proven their high scientific potential in the area of algorithms or graph theory through publications in proceedings of highly ranked international conferences and/or journals. Background in the specific areas of projects in question will be an advantage.</p>



<p>The gross annual salary is around <strong>100,000 PLN</strong>. For comparison, this translates to around twice the average salary in Poland. The position comes with <strong>generous travel support</strong> and <strong>no teaching duties</strong>. The application deadline is <strong>15th March 2020</strong>. The default length of the contract is one year. The starting date is flexible.</p>



<p>To apply, send a CV to Piotr Sankowski &lt;sank@mimuw.edu.pl&gt;.</p>



<p>Questions and informal inquiries are welcome.</p></div>
    </content>
    <updated>2020-02-17T22:07:25Z</updated>
    <published>2020-02-17T22:07:25Z</published>
    <category term="post"/>
    <author>
      <name>Renata Czarniecka</name>
    </author>
    <source>
      <id>http://corner.mimuw.edu.pl</id>
      <link href="http://corner.mimuw.edu.pl/?feed=rss2" rel="self" type="application/atom+xml"/>
      <link href="http://corner.mimuw.edu.pl" rel="alternate" type="text/html"/>
      <subtitle>University of Warsaw</subtitle>
      <title>Banach's Algorithmic Corner</title>
      <updated>2020-02-21T00:17:42Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4608</id>
    <link href="https://www.scottaaronson.com/blog/?p=4608" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4608#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4608" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">My “Quantum Supremacy: Skeptics Were Wrong” 2020 World Speaking Tour</title>
    <summary xml:lang="en-US">(At a few people’s request, I’ve changed the title so that it no longer refers to a specific person. I try always to be accurate, amusing, and appropriate, but sometimes I only hit 1 or 2 of the 3.) As part of my speaking tour, in the last month I’ve already given talks at the […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>(At a few people’s request, I’ve changed the title so that it no longer refers to a specific person.  I try always to be accurate, amusing, and appropriate, but sometimes I only hit 1 or 2 of the 3.)</p>



<p>As part of my speaking tour, in the last month I’ve already given talks at the following fine places:</p>



<p>World Economic Forum at Davos<br/>University of Waterloo<br/>Perimeter Institute<br/>UC Berkeley<br/>Harvard<br/>MIT<br/>Princeton<br/>University of Houston</p>



<p>And I’ll be giving talks at the following places over the next couple of months:</p>



<p>Louisiana State University<br/>Pittsburgh Quantum Institute<br/>Fermilab<br/>Yale</p>



<p>For anyone who’s interested, I’ll add links and dates to this post later (if you want that to happen any faster, feel free to hunt them down for me!).</p>



<p>In the meantime, there are also interviews!  See, for example, <a href="https://www.texasstandard.org/stories/why-quantum-computing-gets-special-attention-in-the-trump-administrations-budget-proposal/">this 5-minute one on Texas Standard</a> (an NPR affiliate), where I’m asked about the current state of quantum computing in the US, in light of the Trump administration’s recent proposal to give a big boost to quantum computing and AI research, even while slashing and burning basic science more broadly.  I made some critical comments—for example, about the need to support the whole basic research ecosystem (I pointed out that “quantum computing can’t thrive in isolation”), and also about the urgent need to make it feasible for the best researchers from around the world to get US visas and green cards.  Unfortunately, those parts seem to have been edited out, in favor of my explanations of basic points about quantum computing.</p>



<p><strong>More Updates:</strong></p>



<p>There was a discussion on Twitter of the ethics of the “Quantum Bullshit Detector” Twitter feed—which dishes out vigilante justice,  like some dark and troubled comic-book hero, by rendering anonymous, unexplained, unaccountable, very often correct albeit not infallible verdicts of “Bullshit” or “Not Bullshit” on claimed quantum information advances.  As part of that discussion, <a href="https://twitter.com/cjsavoie/status/1229495571016278017">Christopher Savoie wrote</a>:</p>



<blockquote class="wp-block-quote"><p>[Criticizing] is what we do in science.  [But not calling] “bullshit” anonymously and without any accountability.  Look at Scott Aaronson’s blog.  He takes strong positions.  But as Scott.  I respect that.</p></blockquote>



<p>What do people think: should “He takes strong positions.  But as Scott.” be added onto the <em>Shtetl-Optimized</em> header bar?</p>



<p>In other news, I was amused by the following headline, for a <em>Vice</em> story about the MIP*=RE breakthrough: <a href="https://www.vice.com/en_us/article/xgqg9a/mathematicians-are-studying-planet-sized-quantum-computers-with-god-like-powers">Mathematicians Are Studying Planet-Sized Supercomputers With God-Like Powers</a>.  (If I’m going to quibble about accuracy: only planet-sized???)</p></div>
    </content>
    <updated>2020-02-17T20:41:10Z</updated>
    <published>2020-02-17T20:41:10Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Adventures in Meatspace"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Announcements"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Quantum"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2020-02-20T17:56:04Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2020/02/17/spanners-have-sparse</id>
    <link href="https://11011110.github.io/blog/2020/02/17/spanners-have-sparse.html" rel="alternate" type="text/html"/>
    <title>Spanners have sparse crossings</title>
    <summary>In a 2017 SIGSPATIAL paper with Sid Gupta, Sid and I modeled non-planar road networks as graph drawings whose edges intersect sparsely, and showed that this implies that these graphs have small separators, allowing algorithms designed for planar graphs (such as linear-time shortest paths) to be extended to them. My latest preprint, with UCI student Hadi Khodabandeh, uses similar ideas of sparse edge intersections to show that greedy geometric spanners also have small separators. The paper is “On the edge crossings of the greedy spanner” (arXiv:2002.05854).</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>In a <a href="https://arxiv.org/abs/1709.06113">2017 SIGSPATIAL paper</a> with Sid Gupta, Sid and I <a href="https://11011110.github.io/blog/2017/09/19/graphs-with-sparse.html">modeled non-planar road networks as graph drawings whose edges intersect sparsely, and showed that this implies that these graphs have small separators</a>, allowing algorithms designed for planar graphs (such as linear-time shortest paths) to be extended to them. My latest preprint, with UCI student Hadi Khodabandeh, uses similar ideas of sparse edge intersections to show that <a href="https://en.wikipedia.org/wiki/Greedy_geometric_spanner">greedy geometric spanners</a> also have small separators. The paper is <a href="https://arxiv.org/abs/2002.05854">“On the edge crossings of the greedy spanner” (arXiv:2002.05854)</a>.</p>

<p>Here, a spanner is a graph whose vertices are a given finite set of points in the plane, with the property that shortest paths in the graph (with distance measured geometrically along each edge) are a good approximation to shortest paths in the plane, the straight line segments between two given points. The graph is not allowed to have extra vertices, and we don’t care about distances between points that are not in the given set. These things have all sorts of applications, for instance in approximation algorithms (you can approximate a geometric problem involving distances by solving a graph problem on the spanner). Of course, a <a href="https://en.wikipedia.org/wiki/Complete_graph">complete graph</a> is a spanner in this sense, but it has a lot of edges. We’d like spanners that are sparser, and still accurately approximate all the distances.</p>

<p>You can get a constant-factor approximation with some planar graphs (like the Delaunay triangulation), and planar graphs are sparse and have <a href="https://en.wikipedia.org/wiki/Planar_separator_theorem">good separators</a>, among other properties. But the example of four points in a square shows that to get a distance ratio better than  we need to allow edges to cross each other. A standard way of doing this is to use a greedy algorithm: just consider all pairs of points, in order by distance, and add an edge when the graph you’ve built so far doesn’t include a short-enough path between them. For any target distance ratio, this turns out to give spanners that are sparse (a linear rather than quadratic number of edges, and more strongly having bounded degree at each vertex) and low weight (within a constant factor of the minimum spanning tree). Versions of these spanners can be constructed in near-linear time, and work in Euclidean spaces of any bounded dimension.</p>

<p>Here, for instance, is a greedy spanner of 100 random points with distance ratio 2 (big enough that, in this example, there are no crossings):</p>

<p style="text-align: center;"><img alt="Greedy spanner with distance ratio 2" src="https://11011110.github.io/blog/assets/2020/greedy2.svg"/></p>

<p>And here is a much more accurate greedy spanner on the same points, one with distance ratio 1.1:</p>

<p style="text-align: center;"><img alt="Greedy spanner with distance ratio 1.1" src="https://11011110.github.io/blog/assets/2020/greedy1.1.svg"/></p>

<p>What we show is that for greedy spanners in the plane, each spanner edge is crossed by a bounded number of longer or equal-length edges. An edge can be crossed by an unbounded number of shorter edges, but our result implies that the <a href="https://en.wikipedia.org/wiki/Intersection_graph">intersection graph</a> of the edges is itself a sparse graph. (In any subgraph of the intersection graph, the longest edge has bounded degree, so the graph as a whole has bounded <a href="https://en.wikipedia.org/wiki/Degeneracy_(graph_theory)">degeneracy</a>.) And that, in combination with the results of the SIGSPATIAL paper, implies that these graphs also have small separators: any -vertex subgraph of a greedy spanner can be split into two smaller graphs of at most  vertices each by the removal of  vertices.</p>

<p>Unlike many of the other known results on greedy spanners, this works only in the plane. It doesn’t make sense to talk about crossings in higher-dimensional greedy spanners, because for points in general position there won’t be any crossings, even in the complete graph. So we don’t know whether higher-dimensional greedy spanners have sublinear separators or not; it would be of interest to find out.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/103677400632411777">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2020-02-17T18:01:00Z</updated>
    <published>2020-02-17T18:01:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2020-02-20T07:24:46Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-25562705.post-3683250814233232375</id>
    <link href="http://aaronsadventures.blogspot.com/feeds/3683250814233232375/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=25562705&amp;postID=3683250814233232375" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/25562705/posts/default/3683250814233232375" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/25562705/posts/default/3683250814233232375" rel="self" type="application/atom+xml"/>
    <link href="http://aaronsadventures.blogspot.com/2020/02/fair-prediction-with-endogenous-behavior.html" rel="alternate" type="text/html"/>
    <title>Fair Prediction with Endogenous Behavior</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><h2 style="text-align: center;">Can Game Theory Help Us Choose Among Fairness Constraints?</h2><br/><div style="text-align: center;"><i>This blog post is about a <a href="https://www.cis.upenn.edu/~aaroth/Papers/endogenous.pdf">new paper</a>, joint with Christopher Jung, Sampath Kannan, Changhwa Lee, Mallesh M. Pai, and Rakesh Vohra.</i></div><br/><br/>A lot of the recent boom in interest in fairness in machine learning can be traced back to the 2016 Propublica article <a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing">Machine Bias</a>. To summarize what you will already know if you have interacted with the algorithmic fairness literature at all --- Propublica discovered that the COMPAS recidivism prediction instrument (used to inform bail and parole decisions by predicting whether individuals would go on to commit violent crimes if released)  made errors of different sorts on different populations. The false positive rate (i.e. the rate at which it incorrectly labeled people "high risk") was much higher on the African American population than on the white population, and the false negative rate (i.e. the rate at which it incorrectly labeled people as "low risk") was much higher on the white population. Because being falsely labeled high risk is harmful (it decreases the chance you are released), this was widely and reasonably viewed as unfair.<br/><br/>But the story wasn't so simple. Northpointe, the company that produced COMPAS (They have since changed their name) <a href="https://go.volarisgroup.com/rs/430-MBX-989/images/ProPublica_Commentary_Final_070616.pdf">responded </a>by pointing out that their instrument satisfied predictive parity across the two populations --- i.e. that the <i>positive predictive value </i>of their instrument was roughly the same for both white and African American populations. This means that their predictions conveyed the same meaning across the two populations: the people that COMPAS predicted were high risk had roughly the same chance of recidivating, on average, whether or not they were black or white. This is also desirable, because if we use an instrument that produces predictions whose meanings differ according to an individual's demographic group, then we are explicitly incentivizing judges to make decisions based on race, after they are shown the prediction of the instrument. Of course, we now know that simultaneously equalizing false positive rates, false negative rates, and positive predictive values across populations is <a href="https://arxiv.org/abs/1610.07524">generically impossible</a> --- i.e. it is impossible except under very special conditions, such as when the underlying crime rate is exactly the same in both populations. This <a href="http://aaronsadventures.blogspot.com/2019/02/impossibility-results-in-fairness-as.html">follows from thinking about Bayes Rule</a>.<br/><br/>Another sensible notion of fairness suggests that "similarly risky people should be treated similarly". This harkens back to notions of <a href="https://arxiv.org/abs/1104.3913">individual fairness</a>, and suggests that we should do something like the following: we should gather as much information about an individual as we possibly can, and condition on all of it to find a (hopefully correct) posterior belief that they will go on to commit a crime. Then, we should make incarceration decisions by subjecting everyone to the same threshold on these posterior beliefs --- any individual who crosses some uniform threshold should be incarcerated; anyone who doesn't cross the threshold should not be. This is the approach that <a href="https://arxiv.org/abs/1808.00023">Corbett-Davies and Goel </a>advocate for, and it seems to have a lot going for it. In addition to uniform thresholds feeling fair, its also easy to see that doing this is the Bayes-optimal decision rule to optimize any societal cost function that differently weights the cost of false positives and false negatives. But applying a uniform threshold on posterior distributions unfortunately will generally result in a decision rule that neither equalizes false positive and false negative rates, nor positive predictive value. Similarly, satisfying these other notions of fairness will generally result in a decision rule that is sub-optimal in terms of its predictive performance.<br/><br/>Unfortunately, this leaves us with little guidance --- should we aim to equalize false positive and negative rates (sometime called <i><a href="https://arxiv.org/abs/1610.02413">equalized odds</a></i> in this literature)? Should we aim to equalize positive predictive value? Or should we aim for using uniform thresholds on posterior beliefs? Should we aim for something else entirely? More importantly, by what means should we aim to make these decisions?<br/><br/><h2>A Game Theoretic Model</h2><div>One way we can attempt to choose among different fairness "solution concepts" is to try and think about the larger societal effects that imposing a fairness constraint on a classifier will have. This is tricky, of course --- if we don't commit to some model of the world, then different fairness constraints can have either <a href="https://arxiv.org/abs/1803.04383">good or bad long term effects</a>, which still doesn't give us much guidance. Of course making modeling assumptions has its own risks: inevitably the model won't match reality, and we should worry that the results that we derive in our stylized model will not tell us anything useful about the real world. Nevertheless, it is worth trying to proceed: all models are wrong, but some are useful. Our goal will be to come up with a clean, simple model, in which results are robust to modelling choices, and the necessary assumptions are clearly identified. Hopefully the result is some nugget of insight that applies outside of the model. This is what we try to do in our <a href="https://www.cis.upenn.edu/~aaroth/Papers/endogenous.pdf">new paper</a> with Chris Jung, Sampath Kannan, Changhwa Lee, Mallesh Pai, and Rakesh Vohra. We'll use the language of criminal justice here, but the model is simple enough that you could apply it to a number of other settings of interest in which we need to design binary classification rules. </div><div><br/></div><div>In our model, individuals make rational choices about whether or not to commit crimes: that is, individuals have some "outside option" (their opportunity for legal employment, for example), some expected monetary benefit of crime, and some dis-utility for being incarcerated. In deciding whether or not to commit a crime, an individual will weigh their expected benefit of committing a crime, compared to taking their outside option ---- and this calculation will involve their risk of being incarcerated if they commit a crime, and also if they do not (since inevitably any policy will both occasionally free the guilty as well as incarcerate the innocent). Different people might make different decisions because their benefits and costs of crime may differ --- for example, some people will have better opportunities for legal employment than others. And in our model, the only way two different populations differ is in their distributions of these benefits and costs. Each person draws, i.i.d. from a distribution corresponding to their group, a type which encodes this outside option value and cost for incarceration. So in our model, populations differ e.g. only in their access to legal employment opportunities, and this is what will underlie any difference in criminal base rates.  </div><div><br/></div><div>As a function of whether each person commits a crime or not, a "noisy signal" is generated. In general, think of higher signals as corresponding to increased evidence of guilt, and so if someone commits a crime, they will tend to draw higher signals than those who don't commit crimes --- but the signals are noisy, so there is no way to perfectly identify the guilty. </div><div><br/></div><div>Incarceration decisions are made as a function of these noisy signals: society has a choice as to what incarceration rule to choose, and can potentially choose a different rule for different groups. Once an incarceration rule is chosen, this determines each person's incentive to commit crime, which in turn fixes a base rate of crime in each population. In general, base rates will be different across different groups (because outside option distributions differ), so the impossibility of e.g. equalizing false positive rates, false negative rates, and positive predictive value across groups will hold in our setting. Since crime rates in our setting are a function of the incarceration rule we choose, there is a natural objective to consider: finding the policy that <i>minimizes crime</i>. </div><div><br/></div><div>Lets think about how we might implement different fairness notions in this setting. First, how should we think about posterior probabilities that an individual will commit a crime? Before we see an individual's noisy signal, but after we see his group membership, we can form our <i>prior </i>belief that he has committed a crime --- this is just the base crime rate in his population. After we observe his noisy signal, we can use Bayes rule to calculate a posterior probability that he has committed a crime. So we could apply the "uniform posterior threshold" approach to fairness and use an incarceration rule that would incarcerate an individual exactly when their posterior probability of having committed a crime exceeded some uniform threshold. But note that because crime rates (and hence prior probabilities of crime) will generically differ between populations (because outside option distributions differ), setting the -same- threshold on posterior probability of crime for both groups corresponds to setting <i>different</i> thresholds on the raw noisy signals. This makes sense --- a Bayesian doesn't need as strong evidence to convince her that someone from a high crime group has committed a crime, as she would need to be convinced that someone from a low crime group has committed a crime, because she started off with a higher prior belief about the person from the high crime group. This (as we already know) results in a classification rule that has different false positive rates and false negative rates across groups. </div><div><br/></div><div>On the other hand, if we want to equalize false positive and false negative rates across groups, we need an incarceration rule that sets the same threshold on raw noisy signals, independently of group. This will of course correspond to setting different thresholds on the posterior probability of crime (i.e. thresholding calibrated risk scores differently for different groups). And this will always be sub-optimal from the point of view of predicting crime --- the Bayes optimal predictor uniformly thresholds posterior probabilities. </div><div><br/></div><h2>Which Notions of Fairness Lead to Desirable Outcomes?</h2><div><br/></div><div>But only one of these solutions is consistent with our social goal of minimizing crime. And its not the Bayes optimal predictor. The crime-minimizing solution is the one that sets <i>different</i> thresholds on posterior probabilities (i.e. uniform thresholds on signals) so as to equalize false positive rates and false negative rates. In other words, to minimize crime, society should explicitly commit to <i>not</i> conditioning on group membership, even when group membership is statistically informative for the goal of predicting crime. </div><div><br/></div><div>Why? Its because although using demographic information is statistically informative for the goal of predicting crime when base rates differ, it is not something that is under the control of individuals --- they can control their own choices, but not what group they were born into. And making decisions about individuals using information that is not under their control has the effect of distorting their dis-incentive to commit crime --- it ends up providing less of a dis-incentive to individuals from the higher crime group (since they are more likely to be wrongly incarcerated even if they don't commit a crime). And because in our model people are rational actors, minimizing crime is all about managing incentives. </div><div><br/></div><div>This is our baseline model, and in <a href="https://www.cis.upenn.edu/~aaroth/Papers/endogenous.pdf">the paper</a> we introduce a number of extensions, generalizations, and elaborations on the model in order to stress-test it. The conclusions continue to hold in more elaborate and general settings, but at a high level, the key assumptions that are needed to reach them are that:</div><div><div><ol><li>The underlying base rates are rationally responsive to the decision rule used by society.</li><li>Signals are observed at the same rates across populations, and</li><li>The signals are conditionally independent of an individual’s group, conditioned on the individual’s decision about whether or not to commit crime.</li></ol></div><div>Here, conditions (2) and (3) are unlikely to hold precisely in most situations,  but we show that they can be relaxed in various ways while still preserving the core conclusion.</div><div><br/></div><div>But more generally, if we are in a setting in which we believe that individual decisions are rationally made in response to the deployed classifier, and yet the deployed classifier does not equalize false  positive and negative rates, then this is an indication that <i>either </i>the deployed classifier is sub-optimal (for the purpose of minimizing crime rates), or that one of conditions (2) and (3) fails to hold.  Since in fairness relevant settings, the failure of conditions (2) and (3) is itself undesirable, this can be a diagnostic to highlight discriminatory conditions earlier in the pipeline than the final incarceration rule.  In particular, if conditions (2) or (3) fail to hold, then imposing technical fairness constraints on a deployed classifier may be premature, and instead attention should be focused on structural differences in the observations that are being fed into the deployed classifier.</div></div></div>
    </content>
    <updated>2020-02-17T16:08:00Z</updated>
    <published>2020-02-17T16:08:00Z</published>
    <author>
      <name>Aaron</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/09952936358739421126</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-25562705</id>
      <category term="game theory"/>
      <category term="news"/>
      <author>
        <name>Aaron</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/09952936358739421126</uri>
      </author>
      <link href="http://aaronsadventures.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/25562705/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://aaronsadventures.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/25562705/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <title>Adventures in Computation</title>
      <updated>2020-02-20T09:13:45Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=19341</id>
    <link href="https://gilkalai.wordpress.com/2020/02/17/hoi-neguyen-and-melanie-wood-remarkable-formulas-for-the-probability-that-projections-of-lattices-are-surjective/" rel="alternate" type="text/html"/>
    <title>Hoi Neguyen and Melanie Wood: Remarkable Formulas for the Probability that Projections of Lattices are Surjective</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Following a lecture by Hoi Neguyen at Oberwolfach, I would like to tell you a little about the paper: Random integral matrices: universality of surjectivity and the cokernel by Hoi Neguyen and Melanie Wood. Two background questions: Hoi started with … <a href="https://gilkalai.wordpress.com/2020/02/17/hoi-neguyen-and-melanie-wood-remarkable-formulas-for-the-probability-that-projections-of-lattices-are-surjective/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Following a lecture by <a href="https://math.osu.edu/people/nguyen.1261">Hoi Neguyen</a> at Oberwolfach, I would like to tell you a little about the paper: <a href="https://arxiv.org/abs/1806.00596">Random integral matrices: universality of surjectivity and the cokernel</a> by Hoi Neguyen and <a href="https://math.berkeley.edu/~mmwood/">Melanie Wood</a>.</p>
<h2>Two background questions:</h2>
<p>Hoi started with two background questions –</p>
<p>Background Question 1: Consider an <img alt="n \times n" class="latex" src="https://s0.wp.com/latex.php?latex=n+%5Ctimes+n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n \times n"/> 0-1 matrix where the entries are taken at random. What is the probability that the matrix is singular (over the rationals)?</p>
<p>Hoi mentioned the <a href="https://gilkalai.wordpress.com/2019/02/02/konstantin-tikhomrov-the-probability-that-a-bernoulli-matrix-is-singular/">recent result of Konstantin Tikhomirov,</a> and moved to talk about matrices over the integers.</p>
<p>Background Question 2: Now, think about the lattice spanned by the rows of the matrix. How likely it is that this is the full <img alt="\mathbb Z^n" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+Z%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb Z^n"/>? (In other words that the determinant is +1 or -1.)</p>
<p>Probably, I thought, the answer is less than exponentially small.</p>
<h2>The main question</h2>
<p>Hoi moved quickly to the main question</p>
<p><strong>Main question:</strong> Now think about the rows of a random 0-1 <img alt="(n+1) \times n" class="latex" src="https://s0.wp.com/latex.php?latex=%28n%2B1%29+%5Ctimes+n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(n+1) \times n"/> matrix. How likely it is that this is the full <img alt="\mathbb Z^n" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+Z%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb Z^n"/>?</p>
<p>Hmm, I was not sure how quickly the answer should tend to zero. But I learnt quickly that the answer does not tend to zero at all!</p>
<h3><span style="color: #ff0000;">A remarkable heuristic formula: the probability for a random integral matrix from (n+1)-dimensions to n-dimenssions to be surjective is </span></h3>
<h3 style="text-align: center;"><span style="color: #ff0000;"><strong><span style="color: #ff0000;">one over <em> (ζ(2)ζ(3)ζ(4)ζ(5)…) </em></span></strong></span></h3>
<p>What would justify this formula? Hoi described the following heuristic argument.</p>
<ol>
<li>To be surjective you need to be surjective modulo p for every prime number p.</li>
<li> Take some p. The probability to be surjective modulo p when the entries are uniformly random (independently) numbers modulo p is <img alt="\prod_{j=2}^{n+1}(1-p^{-j})" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cprod_%7Bj%3D2%7D%5E%7Bn%2B1%7D%281-p%5E%7B-j%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\prod_{j=2}^{n+1}(1-p^{-j})"/>.</li>
<li>This probability continues to work if you consider 0-1 entries.</li>
<li>You can assume that all these probabilities for different primes are statistically independent.</li>
<li>When you multiply all these probabilities you get</li>
</ol>
<p style="text-align: center;"><img alt="\zeta(2)^{-1}\zeta(3)^{-1}\zeta(5)^{-1}\zeta(7)^{-1}\cdots" class="latex" src="https://s0.wp.com/latex.php?latex=%5Czeta%282%29%5E%7B-1%7D%5Czeta%283%29%5E%7B-1%7D%5Czeta%285%29%5E%7B-1%7D%5Czeta%287%29%5E%7B-1%7D%5Ccdots&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\zeta(2)^{-1}\zeta(3)^{-1}\zeta(5)^{-1}\zeta(7)^{-1}\cdots"/></p>
<p>When Hoi reached this formula in his Oberfolfach lecture my immediate thought was this: This is a remarkable formula; maybe it is even true although it looks very hard to justify the two crucial steps  in the heuristics. Why you can assume that 0-1 matrices behave like random matrices with uniform entries and why we have statistical independence that allows us to multiply probabilities just like in high school probability class? And maybe it is not true.</p>
<p>(This heuristics is known as the Cohen Lenstra heuristics and it was made for understanding the structure of class groups of quadratic fields.)</p>
<p>And then came the next slide of the presentation.</p>
<p><a href="https://gilkalai.files.wordpress.com/2020/02/w2j-1.png"><img alt="" class="alignnone size-full wp-image-19345" height="335" src="https://gilkalai.files.wordpress.com/2020/02/w2j-1.png?w=640&amp;h=335" width="640"/></a></p>
<p> </p>
<h3>Hoi Neguyen and Melanie Wood actually proved this formula!</h3>
<p>This is  a special case of a considerably more general formula. Look at<a href="https://arxiv.org/abs/1806.00596"> the paper for more details</a> and for the proofs.</p>
<p>It looks to me that the proof is tour de force and it uses various difficult and delicious techniques and earlier results. Various new and old Littlewood-Oﬀord type results which are independently interesting are used.</p>
<p>And here is a related paper by Hoi and Melanie:<a href="https://arxiv.org/abs/1806.10068"> Cokernels of adjacency matrices of random r-regular graphs</a>.</p>
<p> </p>
<h3>Little more</h3>
<p>As mentioned in the Neguyen-Wood paper, Shaked Koplewitz  <a href="https://arxiv.org/pdf/1611.06441.pdf"> roposed and proved</a> some cases the Cohen-Lenstra heuristic for integral n by n+k matrices. (See Skaed’s comment below.)</p>
<p>SHAKED KOPLEWITZ</p>
<p>As for background problem 2, the paper mentioned that the fact that the probability tends to 0 follows from Corollary 3.4 from a paper by Melanie Wood: <a href="https://arxiv.org/abs/1504.04391">Random integral matrices and the Cohen Lenstra Heuristics.</a>  (Maybe there are different avenues for showing that there is a vanishing probability for every specific value of the determinant as well.) I don’t know if it is known that the probability that the determinant is 1 is exponentially small. (You can guess it is like square root of n! or something like that.) Also I don’t know if the ratio between the probabilities that the determinant is 3 and that it is 7 respects the Cohen Lenstra heuristics. Do we expect it at all? You can regard the determinant as a strange random walk so what is the reason that stopping at 3 will be different than stopping at 7?  It is also not known and this is raised as a question in the paper if the probability that the determinant is a perfect square respects the Cohen-Lenstra heuristics (and this seems reasonable).</p>
<p>There are similar nice questions for simplicial complexes. See the paper <a href="https://arxiv.org/abs/1710.05683">Cohen–Lenstra heuristics for torsion in homology of random complexes</a>, by Matthew Kahle, Frank Lutz, Andrew Newman, and Kyle Parsons.</p>
<p>So if you consider the torsion of the 7 dimensional homology of a random 14 dimensional manifolds. Then (unless there are theorems to the contrary) it is natural to guess that the torsion will obey a Cohen-Lenstra heuristic of some kind.  This also applies to rationally acyclic complexes (hypertrees) and various other gadgets.</p>
<p> </p></div>
    </content>
    <updated>2020-02-17T15:29:58Z</updated>
    <published>2020-02-17T15:29:58Z</published>
    <category term="Algebra"/>
    <category term="Combinatorics"/>
    <category term="Number theory"/>
    <category term="Probability"/>
    <category term="Hoi Neguyen"/>
    <category term="Melanie Wood"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2020-02-21T00:20:39Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16691</id>
    <link href="https://rjlipton.wordpress.com/2020/02/16/a-beetle-math-puzzle/" rel="alternate" type="text/html"/>
    <title>A Beetle Math Puzzle</title>
    <summary>Lessons from a puzzle about prime numbers [ Wikipedia ] Doron Zeilberger is a famous combinatorial mathematician based at Rutgers. He is noted for actively using computers in research. His computers even get co-authorship credit under the name “Shalosh B. Ekhad,” which is Hebrew for 3B1—a computer that came from building 3, corridor B, room […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Lessons from a puzzle about prime numbers</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2020/02/16/a-beetle-math-puzzle/unknown-134/" rel="attachment wp-att-16694"><img alt="" class="alignright size-full wp-image-16694" src="https://rjlipton.files.wordpress.com/2020/02/unknown-1.jpeg?w=600"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">[ Wikipedia ]</font></td>
</tr>
</tbody>
</table>
<p>
Doron Zeilberger is a famous combinatorial mathematician based at Rutgers. He is noted for actively using computers in research. His computers even get co-authorship credit under the name “Shalosh B. Ekhad,” which is Hebrew for 3B1—a computer that came from building 3, corridor B, room 1 of AT&amp;T Bell Labs.</p>
<p>
Today I thought we would talk about a recent joint <a href="https://arxiv.org/abs/1801.05097">paper</a> of Zeilberger on Covering Systems.</p>
<p>
This paper has one co-author who is human, Anthony Zaleski, also of Rutgers. It starts with a puzzle about beetles on a circular track. The puzzle does not need a computer to solve—though a computerized visualization would make it more enjoyable. It makes several interesting points, points that are distinctly human, and I hope you might enjoy it. </p>
<p>
</p><p/><h2> The Puzzle </h2><p/>
<p/><p>
They ascribe the <a href="https://www.pourlascience.fr/sd/mathematiques/cinq-enigmes-mathematiques-pour-la-rentree-9796.php">puzzle</a> to Jean-Paul Delahaye, who modified Peter Winkler’s writeup of a folk puzzle that Winkler stated about ants. </p>
<blockquote><p><b> </b> <em> One places nine beetles on a circular track, where the nine arc distances, measured in meters, between two consecutive beetles are the first nine prime numbers, <img alt="{2,3,5,7,11,13,17,19,23}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%2C3%2C5%2C7%2C11%2C13%2C17%2C19%2C23%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{2,3,5,7,11,13,17,19,23}"/>. The order is arbitrary, and each number appears exactly once as a distance.</em></p><em>
</em><p><em>
At the starting time, each beetle decides randomly whether she would go, traveling at a speed of 1 meter per minute, clockwise or counter-clockwise. When two beetles bump into each other, they immediately do a “U-turn”, i.e. reverse direction. We assume that the size of the beetles is negligible. At the end of <img alt="{50}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B50%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{50}"/> minutes, after many collisions, one notices the distances between the new positions of the beetles. </em>
</p></blockquote>
<p/><p>
Note that there are two levels of probability: the initial order of the vector of distances and the initial direction of each beetle. Yet after <img alt="{50}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B50%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{50}"/> minutes there is a high probability of the distances being exactly the same: the first nine prime numbers. Is this a miracle? What is the probability?</p>
<p>
</p><p/><h2> The Lessons </h2><p/>
<p/><p>
The point is we have deliberately stated the puzzle to make it harder. The way we stated it is misleading and the following lessons are hints to help solve the puzzle.</p>
<ul>
<li>
That the arc lengths are prime numbers is unimportant. The puzzle works whether or not the distances between the beetles are prime numbers. <p/>
</li><li>
The probability is <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/> that the beetles are at the given positions. There is no chance that they will not arrive at the antipode points. None.
</li></ul>
<p>
</p><p/><h2> The Solution </h2><p/>
<p/><p>
The first observation is that the circular track’s length is 	</p>
<p align="center"><img alt="\displaystyle  2+3+5+7+11+13+17+19+23=100. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++2%2B3%2B5%2B7%2B11%2B13%2B17%2B19%2B23%3D100.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  2+3+5+7+11+13+17+19+23=100. "/></p>
<p><a href="https://rjlipton.wordpress.com/2020/02/16/a-beetle-math-puzzle/antipode/" rel="attachment wp-att-16698"><img alt="" class="aligncenter size-full wp-image-16698" src="https://rjlipton.files.wordpress.com/2020/02/antipode.png?w=600"/></a></p>
<p>The second is that the probability is <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/> that the distances are the same after <img alt="{50}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B50%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{50}"/> minutes. Imagine that each beetle carries a flag. Instead of reversing direction when they collide, let the beetles exchange their flags and continue moving as before. Now the flags always are moving in the same direction at the same speed. This means that after <img alt="{50}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B50%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{50}"/> minutes the flags are at the antipode position. But the beetles are located at the same places as flags, and so the distances are the same as before. Note, the beetles are each located at the position of some unique flag, but which flag can change many times.</p>
<p>
The only constraint is that the distance traveled in <img alt="{50}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B50%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{50}"/> minutes divides the length of the circular track. The fact that the distances are primes is never used.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Zaleski and Zeilberger say:</p>
<blockquote><p><b> </b> <em> We point out that very often primes are red herrings. This is definitely the case for covering system, and who knows, perhaps also for the Riemann Hypothesis. </em>
</p></blockquote>
<p/><p>
I assume this is a bit tongue in cheek, but their point is valid. Do we miss solutions to problems when we use information that is not really important? How do we decide which information is key and which is redundant? This why I like this puzzle. </p>
<p/></font></font></div>
    </content>
    <updated>2020-02-16T18:35:51Z</updated>
    <published>2020-02-16T18:35:51Z</published>
    <category term="Ideas"/>
    <category term="People"/>
    <category term="Proofs"/>
    <category term="Results"/>
    <category term="beetle"/>
    <category term="primes"/>
    <category term="puzzle"/>
    <category term="solution"/>
    <category term="trick"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2020-02-21T00:20:44Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-1276607874189152226</id>
    <link href="https://blog.computationalcomplexity.org/feeds/1276607874189152226/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/02/pre-publish-and-perish.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/1276607874189152226" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/1276607874189152226" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/02/pre-publish-and-perish.html" rel="alternate" type="text/html"/>
    <title>Pre-(Publish and Perish)</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><i>Guest post by Evangelos Georgiadis</i><br/>
<div>
<br/></div>
Quite a few posts have recently focused on papers,publications and venues;
"optimal" venues for papers under different objective functions,e.g.
minimizing carbon footprint while maximizing community building, networking
as well as information sharing, see <a href="https://cacm.acm.org/magazines/2020/1/241717-publish-and-perish/fulltext">Moshe Vardi</a>.<br/>
<br/>
Here we would like to take a closer look at one of the key assumptions 
-- the paper.
In order to generate a paper, one needs to come up with a result, something
novel, fresh or interesting to say.
The question that has baffled this author is what represents a conducive
or perhaps even optimal setting for generating papers.
Since papers come in different flavors ranging from "<a href="https://blog.computationalcomplexity.org/2009/11/innovation.html">solid technical papers to risky innovative ones</a>" the 
settings
may vary; but ultimately, what would be interesting to investigate (or
for that matter crowdsource) is whether there is a common denominator
in terms of setting or environment, a necessary but not sufficient 
condition (so to speak).
<br/>
<br/>
Here are some accounts of others which may be helpful as reference points.
<br/>
<br/>
Knuth's papers entitled "<a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.455.1434&amp;rep=rep1&amp;type=pdf">Semantics of context free grammar</a>" along with
"The analysis of algorithms" represent two instances that suggest research
institutes might not provide an optimal environment for idea generation.
<br/>
<br/>
As Knuth points out in "<a href="https://www-cs-faculty.stanford.edu/~knuth/cl.html">Selected Papers on Computer Languages</a>" (Chapter 18, p. 431):<br/>
<blockquote class="tr_bq">
Perhaps new ideas emerge most often from hectic, disorganized 
activity,
      when a great many sources of stimulation are present at once -- 
when numerous
     deadlines need to be met, and when other miscellaneous activities 
like child-rearing
     are also mixed into the agenda.</blockquote>
Knuth goes on to say, that it was challenging to do creative work in 
office and that finding
a few hideaways provided some form of solution -- aka sitting under 
'that' oak tree
near Lake Lagunita.
That said, the inspirational setting for getting into the zone for the 
aforementioned two papers
were provided by (Californian) beaches. Hold that observation. Is this 
not something we
have come across somewhere else ?
Fields medalist Stephen Smale in  "<a href="http://math.berkeley.edu/~smale/biblio/chaos.ps">Chaos: Finding a Horseshoe on the Beaches of Rio</a>" suggests that some of his best work happened at his "beach office". 
Whether beaches do provide
for a good setting remains to be shown; perhaps for very innovative 
ideas, oceanic freedom is necessary.
That said, the author recalls (hopefully accurately enough) an account 
by the young  James H Simons,
who attended a conference in Japan in the early days.
Instead of choosing a spacious accommodation (which he was able to 
afford), he restricted himself to the typically confined room type --
not only confined by space, but also pressured by time, young Simons was 
able to generate an interesting result for that conference.
(This probably demonstrates that technical results don't necessarily 
require 'oceanic freedom'.)<br/>
<br/>
Some meaningful probabilistic advice comes from  the fat-tails department,
in "The Black Swan" by Nassim Taleb (on page 209) :
"Go to parties! If you're a scientist, you will chance upon a remark 
that might spark a new research. "
<br/>
<br/>
Murray Gell-Mann provides an interesting collective account in his 
Google Tech Talk entitled "On Getting Creative Ideas."
He <a href="https://youtu.be/3fSB6ut-cT0?t=118">recollects</a> a workshop he attended in 1969 in Aspen that focused on 
the experience
of getting creative ideas, not just among mathematicians and theoretical 
physicists but also poets and
artists. This account seems to 
neglect the actual setting that might
nurture creative thought process, but provides interesting references to 
people such as
  Hermann von Helmholtz, who happened to have thought about this topic 
and partitioned the process
in terms of "saturation, incubation and illumination".
<br/>
<br/>
For those interested in an account that focuses on the Eureka moments of 
exclusively
mathematicians/theoretical physicists see Jacques Hadamard's book "<a href="https://www.amazon.com/Mathematicians-Mind-Jacques-Hadamard/dp/0691029318">The Mathematician's Mind</a>". 
Hadamard
iterated on Helmholtz's 3 stage process and it's worth taking a look at 
what he came up.
<br/>
<br/>
At last, what are good venues or workshops for generating papers ? Or 
let's rephrase that a bit,
what type of atmosphere at venues fosters creativity -- what food for 
thought to provide
participants and how to distribute that food for thought over a given day ?
Ryan R Williams proposed (as practiced by 34th Bellairs Winter Workshop 
on Computational Geometry)
  "... easy problems, informal atmosphere focusing exclusively
       on thinking about problems in a cycle of down-time where
       one meets in two intense sessions and have free time otherwise."
(This type of setting seems to resonate with the 3 stages of 
"saturation, incubation and illumination".)
<br/>
<br/>
That said, most workshops including the Simons workshops don't seem to 
follow such a recipe.
They are more geared towards the follow-up step, namely, communicating 
what people have found,
rather than collaborating with them to tackle open problems.
Perhaps some re-evaluation might be required in how workshops are run.</div>
    </content>
    <updated>2020-02-16T16:02:00Z</updated>
    <published>2020-02-16T16:02:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2020-02-20T09:14:29Z</updated>
    </source>
  </entry>
</feed>
