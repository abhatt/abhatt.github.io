<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2019-07-16T18:22:14Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/094</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/094" rel="alternate" type="text/html"/>
    <title>TR19-094 |  Rainbow coloring hardness via low sensitivity polymorphisms | 

	Venkatesan Guruswami, 

	Sai Sandeep</title>
    <summary>A $k$-uniform hypergraph is said to be $r$-rainbow colorable if there is an $r$-coloring of its vertices such that every hyperedge intersects all $r$ color classes. Given as input such a hypergraph, finding a $r$-rainbow coloring of it is NP-hard for all $k \ge 3$ and $r \ge 2$. Therefore, one settles for finding a rainbow coloring with fewer colors (which is an easier task).  When $r=k$ (the maximum possible value), i.e., the hypergraph is $k$-partite, one can efficiently $2$-rainbow color the hypergraph, i.e., $2$-color its vertices so that there are no monochromatic edges. In this work we consider the next smaller value of $r=k-1$, and prove that in this case it is NP-hard to rainbow color the hypergraph with $q :=  \lceil \frac{k-2}{2} \rceil$ colors. In particular, for $k \le 6$, it is NP-hard to $2$-color $(k-1)$-rainbow colorable $k$-uniform hypergraphs.

Our proof follows the algebraic approach to promise constraint satisfaction problems. It proceeds by characterizing the polymorphisms associated with the approximate rainbow coloring problem, which are rainbow colorings of some product hypergraphs on vertex set $[r]^n$. We prove that any such polymorphism $f: [r]^n \to [q]$ must be $C$-fixing, i.e., there is a small subset $S$ of $C$ coordinates and a setting $a \in [q]^S$ such that fixing $x_{|S} = a$ determines the value of $f(x)$. The key step in our proof is bounding the sensitivity of certain rainbow colorings, thereby arguing that they must be juntas. Armed with the $C$-fixing characterization, our NP-hardness is obtained via a reduction from smooth Label Cover.</summary>
    <updated>2019-07-16T01:19:56Z</updated>
    <published>2019-07-16T01:19:56Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-07-16T18:20:44Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/093</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/093" rel="alternate" type="text/html"/>
    <title>TR19-093 |  Improved 3LIN Hardness via Linear Label Cover | 

	Euiwoong Lee, 

	Subhash Khot, 

	Prahladh Harsha, 

	Devanathan Thiruvenkatachari</title>
    <summary>We prove that for every constant $c$ and $\epsilon = (\log n)^{-c}$, there is no polynomial time algorithm that when given an instance of 3LIN with $n$ variables where an $(1 - \epsilon)$-fraction of the clauses are satisfiable, finds an assignment that satisfies at least $(\frac{1}{2} + \epsilon)$-fraction of clauses unless $\mathbf{NP} \subseteq \mathbf{BPP}$. The previous best hardness using a polynomial time reduction achieves $\epsilon = (\log \log n)^{-c}$, which is obtained by the Label Cover hardness of Moshkovitz and Raz [J. ACM, 57(5), 2010] followed by the reduction from Label Cover to 3LIN of Hastad [J. ACM, 48(4):798--859, 2001].

Our main idea is to prove a hardness result for Label Cover similar to Moshkovitz and Raz where each projection has a linear structure. This linear structure of Label Cover allows us to use Hadamard codes instead of long codes, making the reduction more efficient. For the hardness of Linear Label Cover, we follow the work of Dinur and Harsha [SIAM J. Comput., 42(6):2452--2486, 2013] that simplified the construction of Moshkovitz and Raz, and observe that running their reduction from a hardness of the problem LIN (of unbounded arity) instead of the more standard problem of solving quadratic equations ensures the linearity of the resultant Label Cover.</summary>
    <updated>2019-07-16T01:10:59Z</updated>
    <published>2019-07-16T01:10:59Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-07-16T18:20:44Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.06601</id>
    <link href="http://arxiv.org/abs/1907.06601" rel="alternate" type="text/html"/>
    <title>On circles enclosing many points</title>
    <feedworld_mtime>1563235200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Claverol:Merc=egrave=.html">Mercè Claverol</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Huemer:Clemens.html">Clemens Huemer</a>, Alejandra Martínez-Moraian <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.06601">PDF</a><br/><b>Abstract: </b>We prove that every set of $n$ red and $n$ blue points in the plane contains
a red and a blue point such that every circle through them encloses at least
$n(1-\frac{1}{\sqrt{2}}) -o(n)$ points of the set. This is a two-colored
version of a problem posed by Neumann-Lara and Urrutia. We also show that every
set $S$ of $n$ points contains two points such that either (i) every circle
passing through them encloses at least $\lfloor{\frac{n-2}{3}}\rfloor$ points
of $S$, or (ii) every circle passing through them encloses at most
$\lfloor{\frac{2n-5}{3}}\rfloor$ points of $S$. The proofs make use of
properties of higher order Voronoi diagrams, in the spirit of the work of
Edelsbrunner, Hasan, Seidel and Shen on this topic. Closely related, we also
study the number of collinear edges in higher order Voronoi diagrams and
present several constructions.
</p></div>
    </summary>
    <updated>2019-07-16T02:13:56Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-07-16T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.06576</id>
    <link href="http://arxiv.org/abs/1907.06576" rel="alternate" type="text/html"/>
    <title>Improved Budgeted Connected Domination and Budgeted Edge-Vertex Domination</title>
    <feedworld_mtime>1563235200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lamprou:Ioannis.html">Ioannis Lamprou</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sigalas:Ioannis.html">Ioannis Sigalas</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zissimopoulos:Vassilis.html">Vassilis Zissimopoulos</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.06576">PDF</a><br/><b>Abstract: </b>We consider the \emph{budgeted} version of the classical \emph{connected
dominating set} problem (BCDS). Given a graph $G$ and an integer budget $k$, we
seek to find a connected subset of at most $k$ vertices which maximizes the
number of dominated vertices in $G$. We answer an open question in [Khuller,
Purohit, and Sarpatwar,\ \emph{SODA 2014}] and thus we improve over the
previous $(1-1/e)/13$ approximation. Our algorithm provides a $(1-1/e)/7$
approximation guarantee by employing an improved method for enforcing
connectivity and performing tree decompositions.
</p>
<p>We also consider the \emph{edge-vertex domination} variant, where an edge
dominates its endpoints and all vertices neighboring them. In \emph{budgeted
edge-vertex domination} (BEVD), we are given a graph $G$, and a budget $k$, and
we seek to find a, not necessarily connected, subset of edges such that the
number of dominated vertices in $G$ is maximized. We prove there exists a
$(1-1/e)$-approximation algorithm. Also, for any $\epsilon &gt; 0$, we present a
$(1-1/e+\epsilon)$-inapproximability result by a gap-preserving reduction from
the \emph{maximum coverage} problem. We notice that, in the connected case,
BEVD becomes equivalent to BCDS. Moreover, we examine the ``dual''
\emph{partial edge-vertex domination} (PEVD) problem, where a graph $G$ and a
quota $n'$ are given. The goal is to select a minimum-size set of edges to
dominate at least $n'$ vertices in $G$. In this case, we present a
$H(n')$-approximation algorithm by a reduction to the \emph{partial cover}
problem.
</p></div>
    </summary>
    <updated>2019-07-16T02:08:02Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-16T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.06565</id>
    <link href="http://arxiv.org/abs/1907.06565" rel="alternate" type="text/html"/>
    <title>Recovery Guarantees for Compressible Signals with Adversarial Noise</title>
    <feedworld_mtime>1563235200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dhaliwal:Jasjeet.html">Jasjeet Dhaliwal</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hambrook:Kyle.html">Kyle Hambrook</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.06565">PDF</a><br/><b>Abstract: </b>We provide recovery guarantees for compressible signals that have been
corrupted with noise and extend the framework introduced in [1] to defend
neural networks against $\ell_0$-norm and $\ell_2$-norm attacks. Concretely,
for a signal that is approximately sparse in some transform domain and has been
perturbed with noise, we provide guarantees for accurately recovering the
signal in the transform domain. We can then use the recovered signal to
reconstruct the signal in its original domain while largely removing the noise.
Our results are general as they can be directly applied to most unitary
transforms used in practice and hold for both $\ell_0$-norm bounded noise and
$\ell_2$-norm bounded noise. In the case of $\ell_0$-norm bounded noise, we
prove recovery guarantees for Iterative Hard Thresholding (IHT) and Basis
Pursuit (BP). For the case of $\ell_2$-norm bounded noise, we provide recovery
guarantees for BP. These guarantees theoretically bolster the defense framework
introduced in [1] for defending neural networks against adversarial inputs.
Finally, we experimentally demonstrate this defense framework using both IHT
and BP against the One Pixel Attack [21], Carlini-Wagner $\ell_0$ and $\ell_2$
attacks [3], Jacobian Saliency Based attack [18], and the DeepFool attack [17]
on CIFAR-10 [12], MNIST [13], and Fashion-MNIST [27] datasets. This expands
beyond the experimental demonstrations of [1].
</p></div>
    </summary>
    <updated>2019-07-16T01:46:08Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-16T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.06529</id>
    <link href="http://arxiv.org/abs/1907.06529" rel="alternate" type="text/html"/>
    <title>Inapproximability within W[1]: the case of Steiner Orientation</title>
    <feedworld_mtime>1563235200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wlodarczyk:Michal.html">Michal Wlodarczyk</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.06529">PDF</a><br/><b>Abstract: </b>In the $k$-Steiner Orientation problem we are given a mixed graph, that is,
with both directed and undirected edges, and a set of $k$ terminal pairs. The
goal is to find an orientation of the undirected edges that maximizes the
number of terminal pairs for which there is a path from the source to the sink.
The problem is known to be W[1]-hard when parameterized by $k$ and hard to
approximate up to some constant for FPT algorithms assuming Gap-ETH. On the
other hand, no approximation better than $O(k)$ is known.
</p>
<p>We show that $k$-Steiner Orientation admits no sublogarithmic approximation
algorithm, even with a parameterized running time, assuming W[1] $\ne$ FPT. To
obtain this result, we reduce the problem to itself via a hashing-based gap
amplification technique, which turns out useful even outside of the FPT
paradigm. Precisely, we rule out any approximation ratio of the form $(\log
k)^{o(1)}$ for parameterized algorithms and $(\log n)^{o(1)}$ for purely
polynomial running time, under the same assumption. This constitutes a novel
inapproximability result for polynomial time algorithms obtained via tools from
the FPT theory. Moreover, we prove $k$-Steiner Orientation to be W[1]-complete,
what provides an example of a natural approximation task that is complete in a
parameterized complexity class.
</p>
<p>Finally, we apply our technique to the maximization version of Directed
Multicut and obtain a simple proof that the problem admits no FPT approximation
with ratio $O(k^{\frac 1 2 - \epsilon})$ (assuming W[1] $\ne$ FPT) and no
polynomial-time approximation with ratio $O(m^{\frac 1 2 - \epsilon})$
(assuming NP $\not\subseteq$ co-RP).
</p></div>
    </summary>
    <updated>2019-07-16T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-16T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.06441</id>
    <link href="http://arxiv.org/abs/1907.06441" rel="alternate" type="text/html"/>
    <title>Noise-Stable Rigid Graphs for Euclidean Embedding</title>
    <feedworld_mtime>1563235200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Zishuo Zhao, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hu:Shi=Min.html">Shi-Min Hu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.06441">PDF</a><br/><b>Abstract: </b>We proposed a new criterion \textit{noise-stability}, which revised the
classical rigidity theory, for evaluation of MDS algorithms which can
truthfully represent the fidelity of global structure reconstruction; then we
proved the noise-stability of the cMDS algorithm in generic conditions, which
provides a rigorous theoretical guarantee for the precision and theoretical
bounds for Euclidean embedding and its application in fields including wireless
sensor network localization and satellite positioning.
</p>
<p>Furthermore, we looked into previous work about minimum-cost globally rigid
spanning subgraph, and proposed an algorithm to construct a minimum-cost
noise-stable spanning graph in the Euclidean space, which enabled reliable
localization on sparse graphs of noisy distance constraints with linear numbers
of edges and sublinear costs in total edge lengths. Additionally, this
algorithm enabled us to reconstruct point clouds from pairwise distances at a
minimum of $O(n)$ time complexity, down from $O(n^3)$ for cMDS.
</p></div>
    </summary>
    <updated>2019-07-16T02:14:15Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-07-16T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.06334</id>
    <link href="http://arxiv.org/abs/1907.06334" rel="alternate" type="text/html"/>
    <title>Seedless Graph Matching via Tail of Degree Distribution for Correlated Erdos-Renyi Graphs</title>
    <feedworld_mtime>1563235200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Mahdi Bozorg, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Salehkaleybar:Saber.html">Saber Salehkaleybar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hashemi:Matin.html">Matin Hashemi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.06334">PDF</a><br/><b>Abstract: </b>The graph matching problem refers to recovering the node-to-node
correspondence between two correlated graphs. A previous work theoretically
showed that recovering is feasible in sparse Erdos-Renyi graphs if and only if
the probability of having an edge between a pair of nodes in one of the graphs
and also between the corresponding nodes in the other graph is in the order of
$\Omega(\log(n)/n)$, where n is the number of nodes. In this paper, we propose
a graph matching algorithm which obtains correct matching with high probability
in Erdos-Renyi graphs for the region of $\Theta(\log(n)/n)$ without using a
seed set of pre-matched node pairs as an input. The algorithm assigns
structurally innovative features to high-degree nodes based on the tail of
empirical degree distribution of their neighbor nodes. Then, it matches the
high-degree nodes according to these features, and finally obtains a matching
for the remaining nodes. We evaluate the performance of proposed algorithm in
the regions of $\Theta(\log(n)/n)$ and $\Theta(\log^{2}(n)/n)$. Experiments
show that it outperforms previous works in both regions.
</p></div>
    </summary>
    <updated>2019-07-16T01:41:41Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-16T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.06310</id>
    <link href="http://arxiv.org/abs/1907.06310" rel="alternate" type="text/html"/>
    <title>New Paths from Splay to Dynamic Optimality</title>
    <feedworld_mtime>1563235200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Levy:Caleb_C=.html">Caleb C. Levy</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tarjan:Robert_E=.html">Robert E. Tarjan</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.06310">PDF</a><br/><b>Abstract: </b>Consider the task of performing a sequence of searches in a binary search
tree. After each search, an algorithm is allowed to arbitrarily restructure the
tree, at a cost proportional to the amount of restructuring performed. The cost
of an execution is the sum of the time spent searching and the time spent
optimizing those searches with restructuring operations. This notion was
introduced by Sleator and Tarjan in (JACM, 1985), along with an algorithm and a
conjecture. The algorithm, Splay, is an elegant procedure for performing
adjustments while moving searched items to the top of the tree. The conjecture,
called "dynamic optimality," is that the cost of splaying is always within a
constant factor of the optimal algorithm for performing searches. The
conjecture stands to this day. In this work, we attempt to lay the foundations
for a proof of the dynamic optimality conjecture.
</p></div>
    </summary>
    <updated>2019-07-16T01:41:59Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-16T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.06309</id>
    <link href="http://arxiv.org/abs/1907.06309" rel="alternate" type="text/html"/>
    <title>Splaying Preorders and Postorders</title>
    <feedworld_mtime>1563235200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Levy:Caleb_C=.html">Caleb C. Levy</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tarjan:Robert_E=.html">Robert E. Tarjan</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.06309">PDF</a><br/><b>Abstract: </b>Let $T$ be a binary search tree. We prove two results about the behavior of
the Splay algorithm (Sleator and Tarjan 1985). Our first result is that
inserting keys into an empty binary search tree via splaying in the order of
either $T$'s preorder or $T$'s postorder takes linear time. Our proof uses the
fact that preorders and postorders are pattern-avoiding: i.e. they contain no
subsequences that are order-isomorphic to $(2,3,1)$ and $(3,1,2)$,
respectively. Pattern-avoidance implies certain constraints on the manner in
which items are inserted. We exploit this structure with a simple potential
function that counts inserted nodes lying on access paths to uninserted nodes.
Our methods can likely be extended to permutations that avoid more general
patterns. Second, if $T'$ is any other binary search tree with the same keys as
$T$ and $T$ is weight-balanced (Nievergelt and Reingold 1973), then splaying
$T$'s preorder sequence or $T$'s postorder sequence starting from $T'$ takes
linear time. To prove this, we demonstrate that preorders and postorders of
balanced search trees do not contain many large "jumps" in symmetric order, and
exploit this fact by using the dynamic finger theorem (Cole et al. 2000). Both
of our results provide further evidence in favor of the elusive "dynamic
optimality conjecture."
</p></div>
    </summary>
    <updated>2019-07-16T01:46:17Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-16T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.06257</id>
    <link href="http://arxiv.org/abs/1907.06257" rel="alternate" type="text/html"/>
    <title>More Supervision, Less Computation: Statistical-Computational Tradeoffs in Weakly Supervised Learning</title>
    <feedworld_mtime>1563235200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yi:Xinyang.html">Xinyang Yi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Zhaoran.html">Zhaoran Wang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yang:Zhuoran.html">Zhuoran Yang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Caramanis:Constantine.html">Constantine Caramanis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liu:Han.html">Han Liu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.06257">PDF</a><br/><b>Abstract: </b>We consider the weakly supervised binary classification problem where the
labels are randomly flipped with probability $1- {\alpha}$. Although there
exist numerous algorithms for this problem, it remains theoretically unexplored
how the statistical accuracies and computational efficiency of these algorithms
depend on the degree of supervision, which is quantified by ${\alpha}$. In this
paper, we characterize the effect of ${\alpha}$ by establishing the
information-theoretic and computational boundaries, namely, the minimax-optimal
statistical accuracy that can be achieved by all algorithms, and
polynomial-time algorithms under an oracle computational model. For small
${\alpha}$, our result shows a gap between these two boundaries, which
represents the computational price of achieving the information-theoretic
boundary due to the lack of supervision. Interestingly, we also show that this
gap narrows as ${\alpha}$ increases. In other words, having more supervision,
i.e., more correct labels, not only improves the optimal statistical accuracy
as expected, but also enhances the computational efficiency for achieving such
accuracy.
</p></div>
    </summary>
    <updated>2019-07-16T01:38:38Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-07-16T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.06173</id>
    <link href="http://arxiv.org/abs/1907.06173" rel="alternate" type="text/html"/>
    <title>The FAST Algorithm for Submodular Maximization</title>
    <feedworld_mtime>1563235200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Breuer:Adam.html">Adam Breuer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Balkanski:Eric.html">Eric Balkanski</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Singer:Yaron.html">Yaron Singer</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.06173">PDF</a><br/><b>Abstract: </b>In this paper we describe a new algorithm called Fast Adaptive Sequencing
Technique (FAST) for maximizing a monotone submodular function under a
cardinality constraint $k$ whose approximation ratio is arbitrarily close to
$1-1/e$, is $O(\log(n) \log^2(\log k))$ adaptive, and uses a total of $O(n
\log\log(k))$ queries. Recent algorithms have comparable guarantees in terms of
asymptotic worst case analysis, but their actual number of rounds and query
complexity depend on very large constants and polynomials in terms of precision
and confidence, making them impractical for large data sets. Our main
contribution is a design that is extremely efficient both in terms of its
non-asymptotic worst case query complexity and number of rounds, and in terms
of its practical runtime. We show that this algorithm outperforms any algorithm
for submodular maximization we are aware of, including hyper-optimized parallel
versions of state-of-the-art serial algorithms, by running experiments on large
data sets. These experiments show FAST is orders of magnitude faster than the
state-of-the-art.
</p></div>
    </summary>
    <updated>2019-07-16T01:45:21Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-16T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.06172</id>
    <link href="http://arxiv.org/abs/1907.06172" rel="alternate" type="text/html"/>
    <title>On Happy Colorings, Cuts, and Structural Parameterizations</title>
    <feedworld_mtime>1563235200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bliznets:Ivan.html">Ivan Bliznets</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sagunov:Danil.html">Danil Sagunov</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.06172">PDF</a><br/><b>Abstract: </b>We study the Maximum Happy Vertices and Maximum Happy Edges problems. The
former problem is a variant of clusterization, where some vertices have already
been assigned to clusters. The second problem gives a natural generalization of
Multiway Uncut, which is the complement of the classical Multiway Cut problem.
Due to their fundamental role in theory and practice, clusterization and cut
problems has always attracted a lot of attention. We establish a new connection
between these two classes of problems by providing a reduction between Maximum
Happy Vertices and Node Multiway Cut. Moreover, we study structural and
distance to triviality parameterizations of Maximum Happy Vertices and Maximum
Happy Edges. Obtained results in these directions answer questions explicitly
asked in four works: Agrawal '17, Aravind et al. '16, Choudhari and Reddy '18,
Misra and Reddy '17.
</p></div>
    </summary>
    <updated>2019-07-16T01:45:11Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-16T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.06156</id>
    <link href="http://arxiv.org/abs/1907.06156" rel="alternate" type="text/html"/>
    <title>Zeros of ferromagnetic 2-spin systems</title>
    <feedworld_mtime>1563235200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Guo:Heng.html">Heng Guo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liu:Jingcheng.html">Jingcheng Liu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lu:Pinyan.html">Pinyan Lu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.06156">PDF</a><br/><b>Abstract: </b>We study zeros of the partition functions of ferromagnetic 2-state spin
systems in terms of the external field, and obtain new zero-free regions of
these systems via a refinement of Asano's and Ruelle's contraction method. The
strength of our results is that they do not depend on the maximum degree of the
underlying graph. Via Barvinok's method, we also obtain new efficient and
deterministic approximate counting algorithms. In certain regimes, our
algorithm outperforms all other methods such as Markov chain Monte Carlo and
correlation decay.
</p></div>
    </summary>
    <updated>2019-07-16T01:40:46Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-16T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.06033</id>
    <link href="http://arxiv.org/abs/1907.06033" rel="alternate" type="text/html"/>
    <title>Perfect sampling from spatial mixing</title>
    <feedworld_mtime>1563235200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Feng:Weiming.html">Weiming Feng</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Guo:Heng.html">Heng Guo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yin:Yitong.html">Yitong Yin</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.06033">PDF</a><br/><b>Abstract: </b>We show that strong spatial mixing with a rate faster than the growth of
neighborhood implies the existence of efficient perfect samplers for spin
systems. Our new resampling based algorithm bypasses a major barrier of
previous work along this line, namely that our algorithm works for general spin
systems and does not require additional structures of the problem. In addition,
our framework naturally incorporates spatial mixing properties to obtain linear
expected running time. Using this new technique, we give the currently best
perfect sampling algorithms for colorings in bounded degree graphs and in
graphs with sub-exponential neighborhood growth.
</p></div>
    </summary>
    <updated>2019-07-16T01:45:47Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-16T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.06012</id>
    <link href="http://arxiv.org/abs/1907.06012" rel="alternate" type="text/html"/>
    <title>Efficient methods to determine the reversibility of general 1D linear cellular automata in polynomial complexity</title>
    <feedworld_mtime>1563235200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Du:Xinyu.html">Xinyu Du</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Chao.html">Chao Wang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Tianze.html">Tianze Wang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gao:Zeyu.html">Zeyu Gao</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.06012">PDF</a><br/><b>Abstract: </b>In this paper, we study reversibility of one-dimensional(1D) linear cellular
automata(LCA) under null boundary condition, whose core problems have been
divided into two main parts: calculating the period of reversibility and
verifying the reversibility in a period. With existing methods, the time and
space complexity of these two parts are still too expensive to be employed. So
the process soon becomes totally incalculable with a slightly big size, which
greatly limits its application. In this paper, we set out to solve these two
problems using two efficient algorithms, which make it possible to solve
reversible LCA of very large size. Furthermore, we provide an interesting
perspective to conversely generate 1D LCA from a given period of reversibility.
Due to our methods' efficiency, we can calculate the reversible LCA with large
size, which has much potential to enhance security in cryptography system.
</p></div>
    </summary>
    <updated>2019-07-16T01:20:45Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-07-16T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.06009</id>
    <link href="http://arxiv.org/abs/1907.06009" rel="alternate" type="text/html"/>
    <title>On linear regression in three-dimensional Euclidean space</title>
    <feedworld_mtime>1563235200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>O. V. Ageev, R. A. Sharipov <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.06009">PDF</a><br/><b>Abstract: </b>The three-dimensional linear regression problem is a problem of finding a
spacial straight line best fitting a group of points in three-dimensional
Euclidean space. This problem is considered in the present paper and a solution
to it is given in a coordinate-free form.
</p></div>
    </summary>
    <updated>2019-07-16T02:16:04Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-07-16T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.06001</id>
    <link href="http://arxiv.org/abs/1907.06001" rel="alternate" type="text/html"/>
    <title>The Two-Sided Game of Googol and Sample-Based Prophet Inequalities</title>
    <feedworld_mtime>1563235200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Correa:Jos=eacute=.html">José Correa</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cristi:Andr=eacute=s.html">Andrés Cristi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Epstein:Boris.html">Boris Epstein</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Soto:Jos=eacute=_A=.html">José A. Soto</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.06001">PDF</a><br/><b>Abstract: </b>The secretary problem or the game of Googol are classic models for online
selection problems that have received significant attention in the last five
decades. We consider a variant of the problem and explore its connections to
data-driven online selection. Specifically, we are given $n$ cards with
arbitrary non-negative numbers written on both sides. The cards are randomly
placed on $n$ consecutive positions on a table, and for each card, the visible
side is also selected at random. The player sees the visible side of all cards
and wants to select the card with the maximum hidden value. To this end, the
player flips the first card, sees its hidden value and decides whether to pick
it or drop it and continue with the next card.
</p>
<p>We study algorithms for two natural objectives. In the first one, as in the
secretary problem, the player wants to maximize the probability of selecting
the maximum hidden value. We show that this can be done with probability at
least $0.45292$. In the second one, similar to the prophet inequality, the
player maximizes the expectation of the selected hidden value. We show a
guarantee of at least $0.63518$ with respect to the expected maximum hidden
value.
</p>
<p>Our algorithms result from combining three basic strategies. One is to stop
whenever we see a value larger than the initial $n$ visible numbers. The second
one is to stop the first time the last flipped card's value is the largest of
the currently $n$ visible numbers in the table. And the third one is similar to
the latter but it additionally requires that the last flipped value is larger
than the value on the other side of its card.
</p>
<p>We apply our results to the prophet secretary problem with unknown
distributions, but with access to a single sample from each distribution. Our
guarantee improves upon $1-1/e$ for this problem, which is the currently best
known guarantee and only works for the i.i.d. case.
</p></div>
    </summary>
    <updated>2019-07-16T02:07:36Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-16T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.05981</id>
    <link href="http://arxiv.org/abs/1907.05981" rel="alternate" type="text/html"/>
    <title>Coloring invariants of knots and links are often intractable</title>
    <feedworld_mtime>1563235200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kuperberg:Greg.html">Greg Kuperberg</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Samperton:Eric.html">Eric Samperton</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.05981">PDF</a><br/><b>Abstract: </b>Let $G$ be a nonabelian, simple group with a nontrivial conjugacy class $C
\subseteq G$. Let $K$ be a diagram of an oriented knot in $S^3$, thought of as
computational input. We show that for each such $G$ and $C$, the problem of
counting homomorphisms $\pi_1(S^3\setminus K) \to G$ that send meridians of $K$
to $C$ is almost parsimoniously $\mathsf{\#P}$-complete. This work is a sequel
to a previous result by the authors that counting homomorphisms from
fundamental groups of integer homology 3-spheres to $G$ is almost
parsimoniously $\mathsf{\#P}$-complete. Where we previously used mapping class
groups actions on closed, unmarked surfaces, we now use braid group actions.
</p></div>
    </summary>
    <updated>2019-07-16T01:20:33Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-07-16T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.05964</id>
    <link href="http://arxiv.org/abs/1907.05964" rel="alternate" type="text/html"/>
    <title>Efficient average-case population recovery in the presence of insertions and deletions</title>
    <feedworld_mtime>1563235200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Ban:Frank.html">Frank Ban</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Xi.html">Xi Chen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Servedio:Rocco_A=.html">Rocco A. Servedio</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sinha:Sandip.html">Sandip Sinha</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.05964">PDF</a><br/><b>Abstract: </b>Several recent works have considered the \emph{trace reconstruction problem},
in which an unknown source string $x\in\{0,1\}^n$ is transmitted through a
probabilistic channel which may randomly delete coordinates or insert random
bits, resulting in a \emph{trace} of $x$. The goal is to reconstruct the
original string~$x$ from independent traces of $x$. While the best algorithms
known for worst-case strings use $\exp(O(n^{1/3}))$ traces
\cite{DOS17,NazarovPeres17}, highly efficient algorithms are known
\cite{PZ17,HPP18} for the \emph{average-case} version, in which $x$ is
uniformly random. We consider a generalization of this average-case trace
reconstruction problem, which we call \emph{average-case population recovery in
the presence of insertions and deletions}. In this problem, there is an unknown
distribution $\cal{D}$ over $s$ unknown source strings $x^1,\dots,x^s \in
\{0,1\}^n$, and each sample is independently generated by drawing some $x^i$
from $\cal{D}$ and returning an independent trace of $x^i$.
</p>
<p>Building on \cite{PZ17} and \cite{HPP18}, we give an efficient algorithm for
this problem. For any support size $s \leq \smash{\exp(\Theta(n^{1/3}))}$, for
a $1-o(1)$ fraction of all $s$-element support sets $\{x^1,\dots,x^s\} \subset
\{0,1\}^n$, for every distribution $\cal{D}$ supported on $\{x^1,\dots,x^s\}$,
our algorithm efficiently recovers ${\cal D}$ up to total variation distance
$\epsilon$ with high probability, given access to independent traces of
independent draws from $\cal{D}$. The algorithm runs in time
poly$(n,s,1/\epsilon)$ and its sample complexity is
poly$(s,1/\epsilon,\exp(\log^{1/3}n)).$ This polynomial dependence on the
support size $s$ is in sharp contrast with the \emph{worst-case} version (when
$x^1,\dots,x^s$ may be any strings in $\{0,1\}^n$), in which the sample
complexity of the most efficient known algorithm \cite{BCFSS19} is doubly
exponential in $s$.
</p></div>
    </summary>
    <updated>2019-07-16T01:49:33Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-16T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.05944</id>
    <link href="http://arxiv.org/abs/1907.05944" rel="alternate" type="text/html"/>
    <title>Online-Learning for min-max discrete problems</title>
    <feedworld_mtime>1563235200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bampis:Evripidis.html">Evripidis Bampis</a>, Dimitris Christou, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Escoffier:Bruno.html">Bruno Escoffier</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Thang:Nguyen_Kim.html">Nguyen Kim Thang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.05944">PDF</a><br/><b>Abstract: </b>We study various discrete nonlinear combinatorial optimization problems in an
online learning framework. In the first part, we address the question of
whether there are negative results showing that getting a vanishing (or even
vanishing approximate) regret is computational hard. We provide a general
reduction showing that many (min-max) polynomial time solvable problems not
only do not have a vanishing regret, but also no vanishing approximation
$\alpha$-regret, for some $\alpha$ (unless $NP=BPP$). Then, we focus on a
particular min-max problem, the min-max version of the vertex cover problem
which is solvable in polynomial time in the offline case. The previous
reduction proves that there is no $(2-\epsilon)$-regret online algorithm,
unless Unique Game is in $BPP$; we prove a matching upper bound providing an
online algorithm based on the online gradient descent method. Then, we turn our
attention to online learning algorithms that are based on an offline
optimization oracle that, given a set of instances of the problem, is able to
compute the optimum static solution. We show that for different nonlinear
discrete optimization problems, it is strongly $NP$-hard to solve the offline
optimization oracle, even for problems that can be solved in polynomial time in
the static case (e.g. min-max vertex cover, min-max perfect matching, etc.). On
the positive side, we present an online algorithm with vanishing regret that is
based on the follow the perturbed leader algorithm for a generalized knapsack
problem.
</p></div>
    </summary>
    <updated>2019-07-16T02:08:19Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-16T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.05940</id>
    <link href="http://arxiv.org/abs/1907.05940" rel="alternate" type="text/html"/>
    <title>Planar Disjoint Paths in Linear Time</title>
    <feedworld_mtime>1563235200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Golovach:Petr_A=.html">Petr A. Golovach</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kolliopoulos:Stavros_G=.html">Stavros G. Kolliopoulos</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Stamoulis:Giannos.html">Giannos Stamoulis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Thilikos:Dimitrios_M=.html">Dimitrios M. Thilikos</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.05940">PDF</a><br/><b>Abstract: </b>The Disjoint Paths problem asks whether a fixed number of pairs of terminals
in a graph $G$ can be linked by pairwise disjoint paths. In the context of this
problem, Robertson and Seymour introduced the celebrated irrelevant vertex
technique that has since become standard in graph algorithms. The technique
consists of detecting a vertex that is irrelevant in the sense that its removal
creates an equivalent instance of the problem. That way, one may solve the
problem in $O(n^2)$ steps, as the detection of an irrelevant vertex takes
$O(n)$ time and at most $n$ vertices may need to be removed. In this paper we
study the Planar Disjoint Paths problem where the input graph is planar. We
introduce an extension of the irrelevant vertex technique where all the
irrelevant vertices are removed simultaneously so that an instance of the
Planar Disjoint Paths problem can be transformed in a linear number of steps to
an equivalent one that has bounded treewidth. As a consequence, the Planar
Disjoint Paths problem can be solved in linear time for every fixed number of
terminals.
</p></div>
    </summary>
    <updated>2019-07-16T02:09:34Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-16T01:30:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/07/15/linkage</id>
    <link href="https://11011110.github.io/blog/2019/07/15/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>Turkey has charged over 700 academics with terrorism for signing a peace petition (). Among the most severely penalized is Tuna Altınel, a mathematician in France who was arrested visiting family in Turkey, and who has now been imprisoned for over 50 days (via).</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><ul>
  <li>
    <p><a href="https://www.insidehighered.com/news/2019/07/01/about-700-academics-have-been-criminally-charged-turkey-their-signatures-petition">Turkey has charged over 700 academics with terrorism for signing a peace petition</a> (<a href="https://mathstodon.xyz/@11011110/102367088461002886"/>). Among the most severely penalized is <a href="https://en.wikipedia.org/wiki/Tuna_Alt%C4%B1nel">Tuna Altınel</a>, a mathematician in France who was arrested visiting family in Turkey, and who <a href="http://math.univ-lyon1.fr/SoutienTunaAltinel/?lang=en">has now been imprisoned for over 50 days</a> (<a href="https://cameroncounts.wordpress.com/2019/05/31/tuna-altnel/">via</a>).</p>
  </li>
  <li>
    <p><a href="http://web.cs.elte.hu/~lovasz/bookxx/geomgraphbook/geombook2019.01.11.pdf">László Lovász’s book “Graphs and Geometry”, on geometric representations of graphs</a> (<a href="https://mathstodon.xyz/@11011110/102374639115017977"/>, <a href="https://news.ycombinator.com/item?id=20317825">via</a>). <a href="https://bookstore.ams.org/coll-65">The print version</a> should appear in a month or so from the AMS.</p>
  </li>
  <li>
    <p><a href="https://www.insidehighered.com/quicktakes/2019/06/28/huge-budget-cut-university-alaska">University of Alaska budget gutted by 40%</a> (<a href="https://mathstodon.xyz/@11011110/102381510293748063"/>, <a href="https://www.metafilter.com/181768/We-dont-need-no-stinkin-edumaction">see also</a>). The total amount cut over the past five years (including this new biggest cut) is <a href="https://www.chronicle.com/article/Unprecedented-in-Our/246596">more like 63%, from $522M to $192M</a>. And <a href="https://www.npr.org/2019/07/03/738569508/university-of-alaska-readies-for-budget-slash-we-may-likely-never-recover">the likely response is to close one of its three main campuses and all 13 smaller community campuses</a>. Ironically, the cause is right-wing insistence on a universal basic income of $3000/person from fuel extraction revenues.</p>
  </li>
  <li>
    <p><a href="https://aperiodical.com/category/the-big-internet-math-off/">The annual Big Internet Math-off — view and vote on your favorites!</a> (<a href="https://mathstodon.xyz/@11011110/102385386477969762"/>). 
The first few matches include <a href="https://aperiodical.com/2019/07/the-big-internet-math-off-2019-group-1-alex-corner-vs-lucy-rycroft-smith/">commutativity of log-exponentiation vs weather infovis</a>, the <a href="https://aperiodical.com/2019/07/the-big-internet-math-off-2019-group-2-marianne-rachel-vs-vincent-pantaloni/">geometry of the Sydney Opera House vs straight lines on a donut</a>, <a href="https://aperiodical.com/2019/07/the-big-internet-math-off-2019-group-3-vicky-neale-vs-jim-propp/">multiplication tables and muffins</a> and <a href="https://aperiodical.com/2019/07/the-big-internet-math-off-2019-group-4-colin-beveridge-vs-kyle-d-evans/">a video on shapes in La Sagrada Familia (shot on location?!) vs an introduction to fractals</a>. More daily for roughly a month.</p>
  </li>
  <li>
    <p><a href="https://www.scmp.com/magazines/post-magazine/long-reads/article/3016267/chinese-scientists-guilty-researching-while">Chinese scientists guilty of “researching while Asian” in Trump’s America</a> (<a href="https://mathstodon.xyz/@11011110/102390640744960409"/>, <a href="https://news.ycombinator.com/item?id=20319936">via</a>, <a href="https://www.bloomberg.com/news/features/2019-06-13/the-u-s-is-purging-chinese-americans-from-top-cancer-research">see also</a>). The story focuses on star cancer researcher <a href="https://en.wikipedia.org/wiki/Xifeng_Wu">Xifeng Wu</a>, forced to resign from the University of Texas, apparently because she fostered collaboration with Chinese cancer research institutions at the behest of her higher administration.</p>
  </li>
  <li>
    <p><a href="https://mathstodon.xyz/@ccppurcell/102133405425258779">Chris Purcell thinks about graphs with degree sequence </a>. They have to have at least one cycle of each parity.</p>
  </li>
  <li>
    <p><a href="https://petapixel.com/2019/07/05/goodbye-aberration-physicist-solves-2000-year-old-optical-problem/">A formula for designing lenses with no spherical aberration</a> (<a href="https://mathstodon.xyz/@11011110/102401888807980335"/>, <a href="https://news.ycombinator.com/item?id=20369960">via</a>). This seems to have little practical value as there was already a numerical solution, and I don’t think it handles chromatic aberration, but it’s interesting that there is an analytic formula for these shapes.</p>
  </li>
  <li>
    <p>Last week I traveled to Milan for the <a href="https://sgp2019.di.unimi.it/">Symposium on Geometry Processing</a> (<a href="https://mathstodon.xyz/@11011110/102407039766140849"/>). They also have an <a href="https://twitter.com/geometryprocess">official twitter stream</a>, mostly consisting of event photos. The sightseeing highlight of my trip was seeing pages of <a href="https://www.ambrosiana.it/en/discover/codex-atlanticus/">Da Vinci’s Codex Atlanticus at the Ambrosian Library</a>.</p>
  </li>
  <li>
    <p><a href="https://boingboing.net/2019/07/08/check-out-this-cool-synthesize.html">Evoboxx</a> (<a href="https://mathstodon.xyz/@11011110/102412280507996705"/>), a retro-styled portable device that does only two things: run Conway’s Game of Life and generate sounds from it. Not very practical in these days of cell phones but then maybe that’s what makes it a fun project.</p>
  </li>
  <li>
    <p><a href="http://jdh.hamkins.org/modal-model-theory/">Modal model theory</a> (<a href="https://mathstodon.xyz/@11011110/102418646790775178"/>). For graphs, this extends first order logic (where the only quantification is over vertices and the only predicate is adjacency) with operators  and .  is true when all supergraphs model  and  is true when at least one supergraph models . This can express nontrivial graph properties like -colorability, and comes in two variants depending on whether you can quantify outside the operators.</p>
  </li>
  <li>
    <p><a href="https://www.instagram.com/p/ByH-R4Ql-NA/">Very quick video tutorial on how to make the Miura-ori fold</a>, by Polly Verity (<a href="https://mathstodon.xyz/@11011110/102429787082169299"/>, <a href="https://www.thisiscolossal.com/2019/07/new-polly-verity/">via</a>).</p>
  </li>
  <li>
    <p><a href="http://jtra.cz/stuff/essays/math-self-reference-smooth/index.html">Trávník’s smooth self-referential formula</a> (<a href="https://mathstodon.xyz/@11011110/102435762025301458"/>, <a href="https://twitter.com/johncarlosbaez/status/1141376710551601152">via</a>). It is actually a linked set of formulas, described in a typeset image, that when plotted as described in the image produces the image itself. It follows the same ideas as earlier self-referential formulas like <a href="https://en.wikipedia.org/wiki/Tupper%27s_self-referential_formula">Tupper’s self-referential formula</a> but unlike them describes a smooth vector image based on splines instead of a pixelated bitmap.</p>
  </li>
  <li>
    <p><a href="http://muurformules.nl/">Leiden wall formulas</a> (<a href="https://mathstodon.xyz/@11011110/102444110227078604"/>). The last time I was in Leiden they were decorating the exterior walls of all their buildings with poems of many different languages. Now they’ve moved on to the language of mathematics.</p>
  </li>
  <li>
    <p><a href="https://www.youtube.com/watch?v=eYfpSAxGakI">Numberphile video on Dehn invariants</a> (15-minutes; <a href="https://mathstodon.xyz/@11011110/102448538574760818"/>). The Dehn invariant is a value derived from a polyhedron that doesn’t change if you cut up the polyhedron into smaller polyhedral pieces and rearrange them into a different polyhedron. It’s 0 for the cube and nonzero for other Platonic solids, proving that they can’t be cut and rearranged into a cube. See <a href="https://en.wikipedia.org/wiki/Dehn_invariant">the Wikipedia article</a> for more technical details.</p>
  </li>
</ul></div>
    </content>
    <updated>2019-07-15T21:57:00Z</updated>
    <published>2019-07-15T21:57:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-07-16T04:58:02Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=16778</id>
    <link href="https://gilkalai.wordpress.com/2019/07/15/itai-benjamini-and-jeremie-brieussel-noise-sensitivity-meets-group-theory/" rel="alternate" type="text/html"/>
    <title>Itai Benjamini and Jeremie Brieussel: Noise Sensitivity Meets Group Theory</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">The final  version of my ICM 2018 paper Three puzzles on mathematics computation and games is available for some time. (This proceeding’s version unlike the arXived version has a full list of references.)  In this post I would like to … <a href="https://gilkalai.wordpress.com/2019/07/15/itai-benjamini-and-jeremie-brieussel-noise-sensitivity-meets-group-theory/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The final  version of my ICM 2018 paper <a href="https://gilkalai.files.wordpress.com/2019/07/main-pf.pdf">Three puzzles on mathematics computation and games</a> is available for some time. (This proceeding’s version unlike the arXived version has a full list of references.)  In this post I would like to advertise one problem that I mentioned in the paper. You can read more about it in the paper  by Itai Benjamini and  Jeremie Brieussel  <a href="https://arxiv.org/abs/1901.03617">Noise sensitivity of random walks on groups</a> and learn about it also from the videotaped lecture by Jeremie. BTW, the name of my ICM paper is a tribute to Avi Wigdeson’s great book <strong><a href="https://www.math.ias.edu/files/Website03-25-19.pdf#page=1" target="&#x201D;_blank&#x201D;">Mathematics and Computation</a> </strong>(see <a href="https://gilkalai.wordpress.com/2017/10/27/must-read-book-by-avi-wigderson/">this post</a>). Click on the title for an  almost final draft of Avi’s book (March, 25, 2019) soon to be published by Princeton University Press<strong>. </strong>(We are negotiating with Avi on showing here first how the cover of his book will look like.)</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/07/friends-of-noise.png"><img alt="" class="alignnone size-full wp-image-17590" height="381" src="https://gilkalai.files.wordpress.com/2019/07/friends-of-noise.png?w=640&amp;h=381" width="640"/></a></p>
<p><a href="http://friendsofnoise.org/about/">source</a></p>
<h2>The problem of Benjamini and Brieussel and their conjecture</h2>
<p> </p>
<p/>
<p>Consider an <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>-step simple random walk (SRW) <img alt="X_n" class="latex" src="https://s0.wp.com/latex.php?latex=X_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X_n"/> on a Cayley graph of a finitely generated infinite group <img alt="\Gamma" class="latex" src="https://s0.wp.com/latex.php?latex=%5CGamma&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Gamma"/>. Refresh independently each step with probability <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon"/>, to get <img alt="Y_n" class="latex" src="https://s0.wp.com/latex.php?latex=Y_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y_n"/> from <img alt="X_n" class="latex" src="https://s0.wp.com/latex.php?latex=X_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X_n"/>. Are there groups for which at time <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> the positions <img alt="X_n" class="latex" src="https://s0.wp.com/latex.php?latex=X_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X_n"/> and <img alt="Y_n" class="latex" src="https://s0.wp.com/latex.php?latex=Y_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y_n"/> are asymptotically independent? That is, does the <img alt="l_1" class="latex" src="https://s0.wp.com/latex.php?latex=l_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="l_1"/> (total variation) distance between the chain <img alt="(X_n, Y_n)" class="latex" src="https://s0.wp.com/latex.php?latex=%28X_n%2C+Y_n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(X_n, Y_n)"/> and two independent copies <img alt="(X'_n, X''_n)" class="latex" src="https://s0.wp.com/latex.php?latex=%28X%27_n%2C+X%27%27_n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(X'_n, X''_n)"/> go to 0, as <img alt="n \to \infty" class="latex" src="https://s0.wp.com/latex.php?latex=n+%5Cto+%5Cinfty&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n \to \infty"/>?</p>
<p>Note that on the line <img alt="\mathbb Z" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+Z&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb Z"/>, they are uniformally correlated, and therefore also on any group with a nontrivial homomorphism to <img alt="\mathbb R" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb R"/>, or on any group that has a finite index subgroup with a nontrivial homomorphism to <img alt="\mathbb R" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb R"/>. On the free group and for any non-Liouville group, <img alt="X_n" class="latex" src="https://s0.wp.com/latex.php?latex=X_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X_n"/> and <img alt="Y_n" class="latex" src="https://s0.wp.com/latex.php?latex=Y_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y_n"/> are correlated as well, but for a different reason: both <img alt="X_n" class="latex" src="https://s0.wp.com/latex.php?latex=X_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X_n"/> and <img alt="Y_n" class="latex" src="https://s0.wp.com/latex.php?latex=Y_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y_n"/> have a nontrivial correlation with <img alt="X_1" class="latex" src="https://s0.wp.com/latex.php?latex=X_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X_1"/>.</p>
<p>Itai Benjamini and Jeremie Brieussel conjecture that these are the only ways not to be noise sensitive. That is, if a Cayley graph is Liouville and the group does not have a finite index subgroup with a homomorphism to the reals, then the Cayley graph is noise sensitive for the simple random walk. In particular, the Grigorchuk group is noise sensitive for the simple random walk!</p>
<h3>A paragraph of philosophical nature from Benjamini and Brieussel’s paper.</h3>
<p>“Physically, an <em>ℓ</em><img alt="^1" class="latex" src="https://s0.wp.com/latex.php?latex=%5E1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="^1"/>-noise sensitive process can somewhat not be observed, since the observation <img alt="Y^\rho_n" class="latex" src="https://s0.wp.com/latex.php?latex=Y%5E%5Crho_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y^\rho_n"/> does not provide any significant information on the actual output <img alt="X_n" class="latex" src="https://s0.wp.com/latex.php?latex=X_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X_n"/>. Speculatively, this could account for the rarity of Liouville groups in natural science. Indeed besides virtually nilpotent ones, all known Liouville groups are genuinely mathematical objects .”</p>
<h3>Polytope integrality gap: An update</h3>
<p>An update on polytope integrality gap:  In my ICM paper and also in <a href="https://gilkalai.wordpress.com/2018/01/21/hardness-of-approximating-vertex-cover-polytope-integrality-gap-the-alswede-kachaterian-theorem-and-more/">this post</a>  I asked the beautiful problem that I learned from Anna Karlin if for vertex cover for every graph G and every vector of weights, there is an efficient algorithm achieving the “polytope integrality gap”.  Anna Karlin kindly informed me that <a href="https://www2.isye.gatech.edu/~msingh94/publications.html">Mohit Singh</a> got in touch with her after seeing the conjecture on my blog and pointed out that the hope for approximating the polytope integrality gap for vertex cover is unlikely to be possible because of its relationship to fractional chromatic number. Mohit noted that fractional chromatic number is hard to approximate even when it is constant assuming UGC. I still think that  the notion of polytope integrality gap for vertex cover as well as for more general problems is important and worth further study.</p>
<p> </p>
<p> </p></div>
    </content>
    <updated>2019-07-15T08:13:08Z</updated>
    <published>2019-07-15T08:13:08Z</published>
    <category term="Algebra"/>
    <category term="Combinatorics"/>
    <category term="Probability"/>
    <category term="Itai Benjamini"/>
    <category term="Jeremie Brieussel"/>
    <category term="Noise-sensitivity"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-07-16T18:20:48Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-4254868758435665114</id>
    <link href="https://blog.computationalcomplexity.org/feeds/4254868758435665114/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/07/two-infinite-hat-problem-and-question.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/4254868758435665114" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/4254868758435665114" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/07/two-infinite-hat-problem-and-question.html" rel="alternate" type="text/html"/>
    <title>Two infinite hat problem and a question about what is ``well known''</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><br/>
This is a joint post with David Marcus. You will see how he is involved in my next post.<br/>
<br/>
Two infinite hat problems based on one scenario. I am also curious if they are well known.<br/>
<br/>
1) There are an infinite number of people, numbered 1,2,3,...  There are 2 colors of hats. They can all see everyone's hat but their own. <br/>
<br/>
2) The adversary is going to put hats on all the people. They will guess their own hat color<i> at the same time</i>. <br/>
<br/>
3) The people can discuss strategy ahead of time, but must use a deterministic strategy and the adversary knows the strategy.<br/>
<br/>
4) The people want to minimize how many they get wrong. <br/>
<br/>
5) The adversary puts on hats to maximize how many they get wrong.<br/>
<br/>
I ask two questions  and one meta-question:<br/>
<br/>
Q1: Is there a solution where they get all but a finite number of the guesses right? (I have blogged about a variant of this one a while back.)<br/>
<br/>
Q2: Is there a solution where they get all but at most (say) 18 wrong. (My students would say <i>the answer has to be YES or he</i> <i>wouldn't ask it</i>. They don't realize that I work on upper AND lower bounds!)<br/>
<br/>
Q3: How well known is problem Q1 and the solution?  Q2 and the solution? I've seen Q1 and its solution around (not sure where), but the only source on Q2 that I know of is CAN'T TELL YOU IN THIS POST, WILL IN THE NEXT POST. So, please leave a comment telling me if you have seen Q1 or Q2 and solutions. And if so then where.<br/>
<br/>
Feel free to leave any comments you want; however, I warn readers who want to solve it themselves to not look at the comments, or at my next post.<br/></div>
    </content>
    <updated>2019-07-15T03:12:00Z</updated>
    <published>2019-07-15T03:12:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-07-16T13:06:10Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.05870</id>
    <link href="http://arxiv.org/abs/1907.05870" rel="alternate" type="text/html"/>
    <title>On a Generalization of the Marriage Problem</title>
    <feedworld_mtime>1563148800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lenchner:Jonathan.html">Jonathan Lenchner</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.05870">PDF</a><br/><b>Abstract: </b>We present a generalization of the marriage problem underlying Hall's famous
Marriage Theorem to what we call the Symmetric Marriage Problem, a problem that
can be thought of as a special case of Maximal Weighted Bipartite Matching. We
show that there is a solution to the Symmetric Marriage Problem if and only if
a variation on Hall's Condition holds on each of the bipartitions. We prove
both finite and infinite versions of this result and provide applications.
</p></div>
    </summary>
    <updated>2019-07-15T23:38:38Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.05816</id>
    <link href="http://arxiv.org/abs/1907.05816" rel="alternate" type="text/html"/>
    <title>Towards Optimal Moment Estimation in Streaming and Distributed Models</title>
    <feedworld_mtime>1563148800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jayaram:Rajesh.html">Rajesh Jayaram</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Woodruff:David_P=.html">David P. Woodruff</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.05816">PDF</a><br/><b>Abstract: </b>One of the oldest problems in the data stream model is to approximate the
$p$-th moment $\|\mathcal{X}\|_p^p = \sum_{i=1}^n |\mathcal{X}_i|^p$ of an
underlying vector $\mathcal{X} \in \mathbb{R}^n$, which is presented as a
sequence of poly$(n)$ updates to its coordinates. Of particular interest is
when $p \in (0,2]$. Although a tight space bound of $\Theta(\epsilon^{-2} \log
n)$ bits is known for this problem when both positive and negative updates are
allowed, surprisingly there is still a gap in the space complexity when all
updates are positive. Specifically, the upper bound is $O(\epsilon^{-2} \log
n)$ bits, while the lower bound is only $\Omega(\epsilon^{-2} + \log n)$ bits.
Recently, an upper bound of $\tilde{O}(\epsilon^{-2} + \log n)$ bits was
obtained assuming that the updates arrive in a random order.
</p>
<p>We show that for $p \in (0, 1]$, the random order assumption is not needed.
Namely, we give an upper bound for worst-case streams of
$\tilde{O}(\epsilon^{-2} + \log n)$ bits for estimating $\|\mathcal{X}\|_p^p$.
Our techniques also give new upper bounds for estimating the empirical entropy
in a stream. On the other hand, we show that for $p \in (1,2]$, in the natural
coordinator and blackboard communication topologies, there is an
$\tilde{O}(\epsilon^{-2})$ bit max-communication upper bound based on a
randomized rounding scheme. Our protocols also give rise to protocols for heavy
hitters and approximate matrix product. We generalize our results to arbitrary
communication topologies $G$, obtaining an $\tilde{O}(\epsilon^{2} \log d)$
max-communication upper bound, where $d$ is the diameter of $G$. Interestingly,
our upper bound rules out natural communication complexity-based approaches for
proving an $\Omega(\epsilon^{-2} \log n)$ bit lower bound for $p \in (1,2]$ for
streaming algorithms. In particular, any such lower bound must come from a
topology with large diameter.
</p></div>
    </summary>
    <updated>2019-07-15T23:32:32Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.05725</id>
    <link href="http://arxiv.org/abs/1907.05725" rel="alternate" type="text/html"/>
    <title>Space Efficient Approximation to Maximum Matching Size from Uniform Edge Samples</title>
    <feedworld_mtime>1563148800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kapralov:Michael.html">Michael Kapralov</a>, Slobodan Mitrović, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Norouzi=Fard:Ashkan.html">Ashkan Norouzi-Fard</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tardos:Jakab.html">Jakab Tardos</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.05725">PDF</a><br/><b>Abstract: </b>Given a source of iid samples of edges of an input graph $G$ with $n$
vertices and $m$ edges, how many samples does one need to compute a constant
factor approximation to the maximum matching size in $G$? Moreover, is it
possible to obtain such an estimate in a small amount of space? We show that,
on the one hand, this problem cannot be solved using a nontrivially sublinear
(in $m$) number of samples: $m^{1-o(1)}$ samples are needed. On the other hand,
a surprisingly space efficient algorithm for processing the samples exists:
$O(\log^2 n)$ bits of space suffice to compute an estimate.
</p>
<p>Our main technical tool is a new peeling type algorithm for matching that we
simulate using a recursive sampling process that crucially ensures that local
neighborhood information from `dense' regions of the graph is provided at
appropriately higher sampling rates. We show that a delicate balance between
exploration depth and sampling rate allows our simulation to not lose precision
over a logarithmic number of levels of recursion and achieve a constant factor
approximation. The previous best result on matching size estimation from random
samples was a $\log^{O(1)} n$ approximation [Kapralov et al'14].
</p>
<p>Our algorithm also yields a constant factor approximate local computation
algorithm (LCA) for matching with $O(d\log n)$ exploration starting from any
vertex. Previous approaches were based on local simulations of randomized
greedy, which take $O(d)$ time {\em in expectation over the starting vertex or
edge} (Yoshida et al'09, Onak et al'12), and could not achieve a better than
$d^2$ runtime. Interestingly, we also show that unlike our algorithm, the local
simulation of randomized greedy that is the basis of the most efficient prior
results does take $\wt{\Omega}(d^2)\gg O(d\log n)$ time for a worst case edge
even for $d=\exp(\Theta(\sqrt{\log n}))$.
</p></div>
    </summary>
    <updated>2019-07-15T23:34:53Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.05568</id>
    <link href="http://arxiv.org/abs/1907.05568" rel="alternate" type="text/html"/>
    <title>A Quantum-inspired Classical Algorithm for Separable Non-negative Matrix Factorization</title>
    <feedworld_mtime>1563148800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Zhihuai Chen, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Yinan.html">Yinan Li</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sun:Xiaoming.html">Xiaoming Sun</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yuan:Pei.html">Pei Yuan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Jialin.html">Jialin Zhang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.05568">PDF</a><br/><b>Abstract: </b>Non-negative Matrix Factorization (NMF) asks to decompose a (entry-wise)
non-negative matrix into the product of two smaller-sized nonnegative matrices,
which has been shown intractable in general. In order to overcome this issue,
the separability assumption is introduced which assumes all data points are in
a conical hull. This assumption makes NMF tractable and is widely used in text
analysis and image processing, but still impractical for huge-scale datasets.
In this paper, inspired by recent development on dequantizing techniques, we
propose a new classical algorithm for separable NMF problem. Our new algorithm
runs in polynomial time in the rank and logarithmic in the size of input
matrices, which achieves an exponential speedup in the low-rank setting.
</p></div>
    </summary>
    <updated>2019-07-15T23:35:15Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.05548</id>
    <link href="http://arxiv.org/abs/1907.05548" rel="alternate" type="text/html"/>
    <title>The Projection Games Conjecture and the Hardness of Approximation of SSAT and related problems</title>
    <feedworld_mtime>1563148800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mukhopadhyay:Priyanka.html">Priyanka Mukhopadhyay</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.05548">PDF</a><br/><b>Abstract: </b>The Super-SAT or SSAT problem was introduced by Dinur, Kindler, Raz and
Safra[2002,2003] to prove the NP-hardness of approximation of two popular
lattice problems - Shortest Vector Problem (SVP) and Closest Vector Problem
(CVP). They conjectured that SSAT is NP-hard to approximate to within factor
$n^c$ for some constant $c&gt;0$, where $n$ is the size of the SSAT instance. In
this paper we prove this conjecture assuming the Projection Games Conjecture
(PGC), given by Moshkovitz[2012]. This implies hardness of approximation of SVP
and CVP within polynomial factors, assuming the Projection Games Conjecture.
</p>
<p>We also reduce SSAT to the Nearest Codeword Problem (NCP) and Learning
Halfspace Problem (LHP), as considered by Arora, Babai, Stern and
Sweedyk[1997]. This proves that both these problems are NP-hard to approximate
within factor $N^{c'/\log\log n}$ for some constant $c'&gt;0$ where $N$ is the
size of the instances of the respective problems. Assuming the Projection Games
Conjecture these problems are proved to be NP-hard to approximate within
polynomial factors.
</p></div>
    </summary>
    <updated>2019-07-15T23:20:28Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-07-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.05515</id>
    <link href="http://arxiv.org/abs/1907.05515" rel="alternate" type="text/html"/>
    <title>Spherical Discrepancy Minimization and Algorithmic Lower Bounds for Covering the Sphere</title>
    <feedworld_mtime>1563148800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jones:Chris.html">Chris Jones</a>, Matt McPartlon <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.05515">PDF</a><br/><b>Abstract: </b>Inspired by the boolean discrepancy problem, we study the following
optimization problem which we term \textsc{Spherical Discrepancy}: given $m$
unit vectors $v_1, \dots, v_m$, find another unit vector $x$ that minimizes
$\max_i \langle x, v_i\rangle$. We show that \textsc{Spherical Discrepancy} is
APX-hard and develop a multiplicative weights-based algorithm that achieves
nearly optimal worst-case error bounds. We use our algorithm to give the first
non-trivial lower bounds for the problem of covering a hypersphere by
hyperspherical caps of uniform volume at least $2^{-o(\sqrt{n})}$, and to give
a lower bound for covering a Gaussian random variable by equal-sized
halfspaces. Up to a log factor, our lower bounds match known upper bounds in
this regime. Finally, we show how to modify our algorithm to solve a natural
version of the Koml{\'o}s problem for the spherical setting.
</p></div>
    </summary>
    <updated>2019-07-15T23:20:37Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-07-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.05473</id>
    <link href="http://arxiv.org/abs/1907.05473" rel="alternate" type="text/html"/>
    <title>Geometry of Scheduling on Multiple Machines</title>
    <feedworld_mtime>1563148800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bansal:Nikhil.html">Nikhil Bansal</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Batra:Jatin.html">Jatin Batra</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.05473">PDF</a><br/><b>Abstract: </b>We consider the following general scheduling problem: there are $m$ identical
machines and $n$ jobs all released at time $0$. Each job $j$ has a processing
time $p_j$, and an arbitrary non-decreasing function $f_j$ that specifies the
cost incurred for $j$, for each possible completion time. The goal is to find a
preemptive migratory schedule of minimum cost. This models several natural
objectives such as weighted norm of completion time, weighted tardiness and
much more.
</p>
<p>We give the first $O(1)$ approximation algorithm for this problem, improving
upon the $O(\log \log nP)$ bound due to Moseley (2019). To do this, we first
view the job-cover inequalities of Moseley geometrically, to reduce the problem
to that of covering demands on a line by rectangular and triangular capacity
profiles. Due to the non-uniform capacities of triangles, directly using
quasi-uniform sampling loses a $O(\log \log P)$ factor, so a second idea is to
adapt it to our setting to only lose an $O(1)$ factor. Our ideas for covering
points with non-uniform capacity profiles (which have not been studied before)
may be of independent interest.
</p></div>
    </summary>
    <updated>2019-07-15T23:37:12Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.05457</id>
    <link href="http://arxiv.org/abs/1907.05457" rel="alternate" type="text/html"/>
    <title>Schatten Norms in Matrix Streams: Hello Sparsity, Goodbye Dimension</title>
    <feedworld_mtime>1563148800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Braverman:Vladimir.html">Vladimir Braverman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Krauthgamer:Robert.html">Robert Krauthgamer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Krishnan:Aditya.html">Aditya Krishnan</a>, Roi Sinoff <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.05457">PDF</a><br/><b>Abstract: </b>The spectrum of a matrix contains important structural information about the
underlying data, and hence there is considerable interest in computing various
functions of the matrix spectrum. A fundamental example for such functions is
the $l_p$-norm of the spectrum, called the Schatten $p$-norm of the matrix.
Large matrices representing real-world data are often \emph{sparse} (most
entries are zeros) or \emph{doubly sparse}, i.e., sparse in both rows and
columns. These large matrices are usually accessed as a \emph{stream} of
updates, typically organized in \emph{row-order}. In this setting, where space
(memory) is the limiting resource, computing spectral functions is an expensive
task and known algorithms require space that is polynomial in the dimension of
the matrix, even for sparse matrices. Thus, it is highly desirable to design
algorithms requiring significantly smaller space.
</p>
<p>We answer this challenge by providing the first algorithm that uses space
\emph{independent of the matrix dimension} to compute the Schatten $p$-norm of
a doubly-sparse matrix presented in row order. Instead, our algorithm uses
space polynomial in the sparsity parameter $k$ and makes $O(p)$ passes over the
data stream. We further prove that multiple passes are unavoidable in this
setting and show several extensions of our primary technique, including
stronger upper bounds for special matrix families, algorithms for the more
difficult turnstile model, and a trade-off between space requirements and
number of passes.
</p></div>
    </summary>
    <updated>2019-07-15T23:23:25Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.05445</id>
    <link href="http://arxiv.org/abs/1907.05445" rel="alternate" type="text/html"/>
    <title>Eccentricity function in distance-hereditary graphs</title>
    <feedworld_mtime>1563148800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dragan:Feodor_F=.html">Feodor F. Dragan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Guarnera:Heather_M=.html">Heather M. Guarnera</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.05445">PDF</a><br/><b>Abstract: </b>A graph $G = (V,E)$ is distance hereditary if every induced path of $G$ is a
shortest path. In this paper, we show that the eccentricity function $e(v) =
\max\{d(v, u) : u \in V \}$ in any distance-hereditary graph $G$ is almost
unimodal, that is, every vertex $v$ with $e(v) &gt; rad(G) + 1$ has a neighbor
with smaller eccentricity. Here, $rad(G) = \min\{e(v) : v \in V \}$ is the
radius of graph $G$. Moreover, we use this result to characterize the centers
of distance-hereditary graphs and provide a linear time algorithm to find a
large subset of central vertices, and in some cases, all central vertices. We
introduce two new algorithmic techniques to approximate all eccentricities in
distance-hereditary graphs, including a linear time additive 1-approximation.
</p></div>
    </summary>
    <updated>2019-07-15T23:36:30Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.05087</id>
    <link href="http://arxiv.org/abs/1907.05087" rel="alternate" type="text/html"/>
    <title>Optimal Space-Depth Trade-Off of CNOT Circuits in Quantum Logic Synthesis</title>
    <feedworld_mtime>1563148800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jiang:Jiaqing.html">Jiaqing Jiang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sun:Xiaoming.html">Xiaoming Sun</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Teng:Shang=Hua.html">Shang-Hua Teng</a>, Bujiao Wu, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wu:Kewen.html">Kewen Wu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Jialin.html">Jialin Zhang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.05087">PDF</a><br/><b>Abstract: </b>Due to the decoherence of the state-of-the-art physical implementations of
quantum computers, it is essential to parallelize the quantum circuits to
reduce their depth. Two decades ago, Moore et al. demonstrated that additional
qubits (or ancillae) could be used to design "shallow" parallel circuits for
quantum operators. They proved that any $n$-qubit CNOT circuit could be
parallelized to $O(\log n)$ depth, with $O(n^2)$ ancillae. However, the
near-term quantum technologies can only support limited amount of qubits,
making space-depth trade-off a fundamental research subject for quantum-circuit
synthesis.
</p>
<p>In this work, we establish an asymptotically optimal space-depth trade-off
for the design of CNOT circuits. We prove that for any $m\geq0$, any $n$-qubit
CNOT circuit can be parallelized to $O\left(\max \left\{\log n,
\frac{n^{2}}{(n+m)\log (n+m)}\right\} \right)$ depth, with $O(m)$ ancillae. We
show that this bound is tight by a counting argument, and further show that
even with arbitrary two-qubit quantum gates to approximate CNOT circuits, the
depth lower bound still meets our construction, illustrating the robustness of
our result. Our work improves upon two previous results, one by Moore et al.
for $O(\log n)$-depth quantum synthesis, and one by Patel et al. for $m = 0$:
for the former, we reduce the need of ancillae by a factor of $\log^2 n$ by
showing that $m=O(n^2/\log^2 n)$ additional qubits suffice to build $O(\log
n)$-depth, $O(n^2/\log n)$ size --- which is asymptotically optimal --- CNOT
circuits; for the later, we reduce the depth by a factor of $n$ to the
asymptotically optimal bound $O(n/\log n)$. Our results can be directly
extended to stabilizer circuits using an earlier result by Aaronson et al. In
addition, we provide relevant hardness evidences for synthesis optimization of
CNOT circuits in term of both size and depth.
</p></div>
    </summary>
    <updated>2019-07-15T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.05083</id>
    <link href="http://arxiv.org/abs/1907.05083" rel="alternate" type="text/html"/>
    <title>Cake Cutting on Graphs: A Discrete and Bounded Proportional Protocol</title>
    <feedworld_mtime>1563148800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bei:Xiaohui.html">Xiaohui Bei</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sun:Xiaoming.html">Xiaoming Sun</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wu:Hao.html">Hao Wu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Jialin.html">Jialin Zhang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Zhijie.html">Zhijie Zhang</a>, Wei Zi <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.05083">PDF</a><br/><b>Abstract: </b>The classical cake cutting problem studies how to find fair allocations of a
heterogeneous and divisible resource among multiple agents. Two of the most
commonly studied fairness concepts in cake cutting are proportionality and
envy-freeness. It is well known that a proportional allocation among $n$ agents
can be found efficiently via simple protocols [16]. For envy-freeness, in a
recent breakthrough, Aziz and Mackenzie [5] proposed a discrete and bounded
envy-free protocol for any number of players. However, the protocol suffers
from high multiple-exponential query complexity and it remains open to find
simpler and more efficient envy-free protocols.
</p>
<p>In this paper we consider a variation of the cake cutting problem by assuming
an underlying graph over the agents whose edges describe their acquaintance
relationships, and agents evaluate their shares relatively to those of their
neighbors. An allocation is called locally proportional if each agent thinks
she receives at least the average value over her neighbors. Local
proportionality generalizes proportionality and is in an interesting middle
ground between proportionality and envy-freeness: its existence is guaranteed
by that of an envy-free allocation, but no simple protocol is known to produce
such a locally proportional allocation for general graphs. Previous works
showed locally proportional protocols for special classes of graphs, and it is
listed in both [1] and [8] as an open question to design simple locally
proportional protocols for more general classes of graphs. In this paper we
completely resolved this open question by presenting a discrete and bounded
locally proportional protocol for any given graphs. Our protocol has a query
complexity of only single exponential, which is significantly smaller than the
six towers of $n$ query complexity of the envy-free protocol given in [5].
</p></div>
    </summary>
    <updated>2019-07-15T23:24:37Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4253</id>
    <link href="https://www.scottaaronson.com/blog/?p=4253" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4253#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4253" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">On two blog posts of Jerry Coyne</title>
    <summary xml:lang="en-US">A few months ago, I got to know Jerry Coyne, the recently-retired biologist at the University of Chicago who writes the blog “Why Evolution Is True.” The interaction started when Jerry put up a bemused post about my thoughts on predictability and free will, and if I pointed out that if he wanted to engage […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>A few months ago, I got to know <a href="https://en.wikipedia.org/wiki/Jerry_Coyne">Jerry Coyne</a>, the recently-retired biologist at the University of Chicago who writes the blog <a href="https://whyevolutionistrue.wordpress.com/">“Why Evolution Is True.”</a>  The interaction started when Jerry put up a <a href="https://whyevolutionistrue.wordpress.com/2019/01/15/a-computer-scientist-finds-the-question-of-free-will-uninteresting-for-bad-reasons/">bemused post about my thoughts on predictability and free will</a>, and if I pointed out that if he wanted to engage me on those topics, there was <a href="https://www.scottaaronson.com/papers/giqtm3.pdf">more to go on</a> than an 8-minute YouTube video.  I told Coyne that it would be a shame to get off on the wrong foot with him, since perusal of his blog made it obvious that whatever he and I disputed, it was dwarfed by our areas of agreement.  He and I exchanged more emails and had lunch in Chicago.</p>



<p>By way of explaining how he hadn’t read <a href="https://www.scottaaronson.com/papers/giqtm3.pdf">“The Ghost in the Quantum Turing Machine,”</a> Coyne emphasized the difference in my and his turnaround times: while these days I update my blog only a couple times per month, Coyne often updates multiple times per <em>day</em>.  Indeed the sheer volume of material he posts, on subjects from biology to culture wars to <a href="https://whyevolutionistrue.wordpress.com/2019/02/27/the-chicago-hot-dog-museum-and-our-wonderful-hot-dogs/">Chicago hot dogs</a>, would take months to absorb.</p>



<p>Today, though, I want to comment on just two posts of Jerry’s.</p>



<p>The <a href="https://whyevolutionistrue.wordpress.com/2019/05/17/computer-scientist-david-gelertner-drinks-the-academic-kool-aid-buys-into-intelligent-design/">first post</a>, from back in May, concerns <a href="https://en.wikipedia.org/wiki/David_Gelernter">David Gelernter</a>, the computer science professor at Yale who was infamously injured in a 1993 attack by the Unabomber, and who’s now mainly known as a right-wing commentator.  I don’t know Gelernter, though I did once attend a small interdisciplinary workshop in the south of France that Gelernter also attended, wherein I gave a talk about quantum computing and computational complexity in which Gelernter showed no interest.  Anyway, Gelernter, in an <a href="https://www.claremont.org/crb/article/giving-up-darwin/">essay in May for the <em>Claremont Review of Books</em></a>, argued that recent work has definitively disproved Darwinism as a mechanism for generating new species, and until something better comes along, Intelligent Design is the best available alternative.</p>



<p>Curiously, I think that Gelernter’s argument falls flat not for detailed reasons of biology, but mostly just because it indulges in <em>bad math and computer science</em>—in fact, in precisely the sorts of arguments that I was trying to answer in <a href="https://www.scottaaronson.com/blog/?p=1487">my segment on Morgan Freeman’s </a><em><a href="https://www.scottaaronson.com/blog/?p=1487">Through the Wormhole</a></em> (see also Section 3.2 of <a href="https://www.scottaaronson.com/papers/philos.pdf">Why Philosophers Should Care About Computational Complexity</a>).  Gelernter says that</p>



<ol><li>a random change to an amino acid sequence will pretty much always make it worse,</li><li>the probability of finding a useful new such sequence by picking one at random is at most ~1 in 10<sup>77</sup>, and</li><li>there have only been maybe ~10<sup>40</sup> organisms in earth’s history.</li></ol>



<p>Since 10<sup>77</sup> &gt;&gt; 10<sup>40</sup>, Darwinism is thereby refuted—not in principle, but as an explanation for life on earth.  QED. </p>



<p>The most glaring hole in the above argument, it seems to me, is that it simply ignores <em>intermediate</em> possible numbers of mutations.  How hard would it be to change, not 1 or 100, but 5 amino acids in a given protein to get a usefully different one—as might happen, for example, with local optimization methods like simulated annealing run at nonzero temperature?  And how many chances were there for <em>that</em> kind of mutation in the earth’s history?</p>



<p>Gelernter can’t personally see how a path could cut through the exponentially large solution space in a polynomial amount of time, so he asserts that it’s impossible.  Many of the would-be P≠NP provers who email me every week do the same.  But this particular kind of “argument from incredulity” has an abysmal track record: it would’ve applied equally well, for example, to problems like maximum matching that turned out to have efficient algorithms.  This is why, in CS, we demand better evidence of hardness—like completeness results or black-box lower bounds—neither of which seem however to apply to the case at hand.  Surely Gelernter understands all this, but had he not, he could’ve learned it from my lecture at the workshop in France!</p>



<p>Alas, online debate, as it’s wont to do, focused less on Gelernter’s actual arguments and the problems with them, than on the tiresome questions of “standing” and “status.”  In particular: does Gelernter’s authority, as a noted computer science professor, somehow lend new weight to Intelligent Design?  Or conversely: does the very fact that a computer scientist endorsed ID prove that computer science itself isn’t a real science at all, and that its practitioners should never be taken seriously in any statements about the real world?</p>



<p>It’s hard to say which of these two questions makes me want to bury my face deeper into my hands.  <a href="https://en.wikipedia.org/wiki/Serge_Lang">Serge Lang</a>, the famous mathematician and textbook author, spent much of his later life fervently denying the connection between HIV and AIDS.  <a href="https://en.wikipedia.org/wiki/Lynn_Margulis">Lynn Margulis</a>, the discoverer of the origin of mitochondria (and Carl Sagan’s first wife), died a 9/11 truther.  What broader lesson should we draw from any of this?  And anyway, what percentage of computer scientists actually do doubt evolution, and how does it compare to the percentage in other academic fields and other professions?  Isn’t the question of how divorced we computer scientists are from the real world an … ahem … <strong>empirical</strong> matter, one hard to answer on the basis of armchair certainties and anecdotes?</p>



<p>Speaking of empiricism, if you check Gelernter’s <a href="https://dblp.uni-trier.de/pers/hd/g/Gelernter:David">publication list on DBLP</a> and his <a href="https://scholar.google.ca/scholar?hl=en&amp;as_sdt=0%2C5&amp;q=david+gelernter&amp;btnG=&amp;oq=david+geler">Google Scholar page</a>, you’ll find that he did influential work in programming languages, parallel computing, and other areas from 1981 through 1997, and then in the past 22 years published a grand total of … <strong>two</strong> papers in computer science.  One with four coauthors, the other a review/perspective piece about his earlier work.  So it seems fair to say that, some time after receiving tenure in a CS department, Gelernter pivoted (to put it mildly) away from CS and toward conservative punditry.  His recent offerings, in case you’re curious, include the book <a href="https://www.amazon.com/America-Lite-Imperial-Academia-Dismantled-Obamacrats/dp/1594036063/ref=sr_1_1?keywords=david+gelernter&amp;qid=1563047627&amp;s=gateway&amp;sr=8-1">America-Lite: How Imperial Academia Dismantled Our Culture (and Ushered In the Obamacrats)</a>.</p>



<p>Some will claim that this case underscores what’s wrong with the tenure system itself, while others will reply that it’s precisely what tenure was designed for, even if in this instance you happen to disagree with what Gelernter uses his tenured freedom to say.  The point I wanted to make is different, though.  It’s that the question “what kind of a field is computer science, anyway, that a guy can do high-level CS research on Monday, and then on Tuesday reject Darwinism and unironically use the word ‘Obamacrat’?”—well, even if I accepted the immense weight this question places on one atypical example (which I don’t), and even if I dismissed the power of compartmentalization (which I again don’t), the question <em>still</em> wouldn’t arise in Gelernter’s case, since getting from “Monday” to “Tuesday” seems to have taken him 15+ years.</p>



<p>Anyway, the second post of Coyne’s that I wanted to talk about is <a href="https://whyevolutionistrue.wordpress.com/2019/07/12/tarring-steve-pinker-and-others-with-jeffrey-epstein/">from just yesterday</a>, and is about Jeffrey Epstein—the financier, science philanthropist, and confessed sex offender, whose appalling crimes you’ll have read all about this week if you weren’t on a long sea voyage without Internet or something.</p>



<p>For the benefit of my many fair-minded friends on Twitter, I should clarify that I’ve never met Jeffrey Epstein, let alone accepted any private flights to his sex island or whatever.  I doubt he has any clue who I am either—even if he did once claim to be <a href="https://web.archive.org/web/20101112131000/http://www.jeffreyepsteinscience.com/2010/10/the-value-of-quantum-computing-to-jeffrey-epstein/">“intrigued”</a> by quantum information.</p>



<p>I do know a few of the scientists who Epstein once hung out with, including Seth Lloyd and Steven Pinker.  Pinker, in particular, is now facing vociferous attacks on Twitter, similar in magnitude perhaps to what I faced in the comment-171 affair, for having been photographed next to Epstein at a 2014 luncheon that was hosted by Lawrence Krauss (a physicist who later faced sexual harassment allegations of his own).  By the evidentiary standards of social media, this photo suffices to convict Pinker as basically a child molester himself, and is <em>also</em> a devastating refutation of any data that Pinker might have adduced in his books about the Enlightenment’s contributions to human flourishing.</p>



<p>From my standpoint, what’s surprising is not that Pinker is up against this, but that it <em>took this long</em> to happen, given that Pinker’s pro-Enlightenment, anti-blank-slate views have had the effect of painting a giant red target on his back.  Despite the near-inevitability, though, you can’t blame Pinker for wanting to defend himself, as I did when it was my turn for the struggle session.</p>



<p>Thus, in response to an emailed inquiry by Jerry Coyne, Pinker shared some detailed reflections about Epstein; Pinker then gave Coyne permission to post those reflections on his blog (though they were originally meant for Coyne only).  Like everything Pinker writes, they’re <a href="https://whyevolutionistrue.wordpress.com/2019/07/12/tarring-steve-pinker-and-others-with-jeffrey-epstein/">worth reading in full</a>.  Here’s the opening paragraph:</p>



<blockquote class="wp-block-quote"><p>The annoying irony is that I could never stand the guy [Epstein], never took research funding from him, and always tried to keep my distance. Friends and colleagues described him to me as a quantitative genius and a scientific sophisticate, and they invited me to salons and coffee klatches at which he held court. But I found him to be a kibitzer and a dilettante — he would abruptly change the subject ADD style, dismiss an observation with an adolescent wisecrack, and privilege his own intuitions over systematic data.</p></blockquote>



<p>Pinker goes on to discuss his record of celebrating, and extensively documenting, the forces of modernity that led to dramatic reductions in violence against women and that have the power to continue doing so.  On Twitter, Pinker had <a href="https://twitter.com/sapinker/status/1149154274787627010">already written</a>: “Needless to say I condemn Epstein’s crimes in the strongest terms.”</p>



<p>I probably should’ve predicted that Pinker would then be attacked again—this time, for having prefaced his condemnation with the phrase “needless to say.”  The argument, as best I can follow, runs like this: given all the isms of which woke Twitter has already convicted Pinker—scientism, neoliberalism, biological determinism, etc.—how could Pinker’s being against Epstein’s crimes (which we recently learned probably include the <a href="https://www.cnn.com/videos/us/2019/07/10/jeffrey-epstein-accuser-speaks-out-today-show-nbc-intv-sot-newday-vpx.cnn">rape</a>, and not only statutorily, of a 15-year-old) <em>possibly</em> be assumed as a given?</p>



<p>For the record, just as Epstein’s friends and enablers weren’t confined to one party or ideology, so the public condemnation of Epstein strikes me as a matter that is (or should be) beyond ideology, with all reasonable dispute now confined to the space between “very bad” and “extremely bad,” between “lock away for years” and “lock away for life.”</p>



<p>While I didn’t need Pinker to tell me <em>that</em>, one reason I personally appreciated his comments is that they helped to answer a question that had bugged me, and that none of the mountains of other condemnations of Epstein had given me a clear sense about.  Namely: supposing, hypothetically, that I’d met Epstein around 2002 or so—without, of course, knowing about his crimes—would I have been as taken with him as many other academics seem to have been?  (Would <em>you</em> have been?  How sure are you?)</p>



<p>Over the last decade, I’ve had the opportunity to meet some titans and semi-titans of finance and business, to discuss quantum computing and other nerdy topics.  For a few (by no means all) of these titans, my overriding impression was <em>precisely</em> their unwillingness to concentrate on any one point for more than about 20 seconds—as though they wanted the crust of a deep intellectual exchange without the meat filling.  My experience with them fit Pinker’s description of Epstein to a T (though I hasten to add that, as far as I know, none of these others ran teenage sex rings).</p>



<p>Anyway, given all the anger at Pinker for having intersected with Epstein, it’s ironic that I could easily imagine Pinker’s comments rattling Epstein the most of anyone’s, if Epstein hears of them from his prison cell.  It’s like: Epstein must have developed a skin like a rhinoceros’s by this point about being called a child abuser, a creep, and a thousand similar (and similarly deserved) epithets.  But “a kibitzer and a dilettante” who merely lured famous intellectuals into his living room, with wads of cash not entirely unlike the ones used to lure teenage girls to his massage table?  Ouch!</p>



<p>OK, but what about Alan Dershowitz—the man who apparently used to be Epstein’s close friend, who still is Pinker’s friend, and who played a crucial role in securing Epstein’s 2008 plea bargain, the one now condemned as a travesty of justice?  I’m not sure how I feel about Dershowitz.  It’s like: I understand that our system requires attorneys willing to mount a vociferous defense even for clients who they privately know or believe to be guilty—and even to get those clients off on technicalities or bargaining whenever they can.  I’m also incredibly grateful that I chose CS rather than law school, because I don’t think I could last an hour advocating causes that I knew to be unjust.  Just like my fellow CS professor, the intelligent design advocate David Gelernter, I have the privilege and the burden of speaking only for myself.</p></div>
    </content>
    <updated>2019-07-13T23:33:12Z</updated>
    <published>2019-07-13T23:33:12Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Nerd Interest"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Obviously I'm Not Defending Aaronson"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2019-07-14T19:20:16Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/07/13/connectivity-finiteness-modal</id>
    <link href="https://11011110.github.io/blog/2019/07/13/connectivity-finiteness-modal.html" rel="alternate" type="text/html"/>
    <title>Connectivity and finiteness in modal graph logic</title>
    <summary>I read with interest Joel David Hamkins’ recent blog post on modal model theory. This week, on a long plane flight home from Italy, I was inspired to play with the modal logic of graphs, in which one describes properties of graphs by simpler properties of their (induced) supergraphs. My interest is less in what this says about set theory and model theory, and more in how expressive this language is: which graph properties can it describe? Joel showed in his post how to describe -colorability in this theory, but I thought it would be of interest to start with something simpler than an -complete problem. And what could be simpler for graphs than testing whether a graph is connected or finite?</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I read with interest Joel David Hamkins’ recent blog post on <a href="http://jdh.hamkins.org/modal-model-theory/">modal model theory</a>.
This week, on a long plane flight home from Italy, I was inspired to play with the modal logic of graphs, in which one describes properties of graphs by simpler properties of their (induced) supergraphs. My interest is less in what this says about set theory and model theory, and more in how expressive this language is: which graph properties can it describe? Joel showed in his post how to describe -colorability in this theory, but I thought it would be of interest to start with something simpler than an -complete problem. And what could be simpler for graphs than testing whether a graph is connected or finite?</p>

<h1 id="the-basics-of-modal-graph-logic">The basics of modal graph logic</h1>

<p><a href="https://en.wikipedia.org/wiki/Modal_logic">Modal logic</a> is a logic of “possible worlds” with two operators on formulas,  (it is possible for  to be true, in at least one possible world) and  (it is necessary for  to be true, in all possible worlds).
Modal graph logic applies this idea to the first-order <a href="https://en.wikipedia.org/wiki/Logic_of_graphs">logic of graphs</a>, in which one can quantify over variables that represent graph vertices and use a binary predicate  representing adjacency of pairs of vertices. I’ll assume here that all graphs are simple and undirected (i.e.,  is irreflexive and commutative). A given graph  models a given first-order formula  (written as ) if the formula becomes true when you evaluate it in the obvious way for the given graph. In the modal logic of graphs, the possible worlds are graphs containing  as an induced subgraph. So  means that it is possible for  to be modeled by one of these larger graphs and  means that it is necessary for  to be modeled by all of these larger graphs. If we apply a modal operator to a formula  that is itself modal, the possible worlds of the modal operators within  are supergraphs of these larger graphs, in the same way (in modal logic terminology, we are assuming S4 accessibility of possible worlds).</p>

<p>In some ways this is enormously powerful: the class of all graphs containing  is so big that it’s not even a set, and it can encode arbitrarily complicated structures. In other ways this is more highly constrained than other graph logics like monadic second-order logic (in which one can describe and quantify sets of vertices or edges, but not more complicated structures like sequences of vertices or strategy trees over games defined on the graph). The issue is that in a possible world, one can’t tell the vertices that were part of the base graph apart from the ones that were added later, except possibly for a finite set of vertices named in variables outside the modal operator. So while the possible worlds that model a given formula can be very large and complicated, it can be difficult to anchor these castles in the air to the base graph that you started with.</p>

<p>Joel’s description of how to express -colorability suggests a path around this difficulty: Suppose we want to test a hereditary property  of graphs (one that extends from any graph to its induced subgraphs) such as colorability. Then we should look for a family of self-verifyingly- graphs: a family of graphs with property  such that membership in the family can be tested by a first-order formula  and such that every graph with property  is an induced subgraph of a larger graph in this family. If we can find such a family and first-order formula , then  will describe property  itself. For instance, for colorability, the self-verifyingly--colorable graphs are graphs in which each color class has a universal vertex, every vertex is adjacent to all but one of the universal vertices, and no two adjacent vertices are both non-adjacent to the same universal vertex.</p>

<p>Similar ideas can also work when the property is not hereditary (for instance, a graph has chromatic number 3 when it is 3-colorable but not 2-colorable) or when checking membership in the family of self-verifying graphs itself involves modal logic (as we’ll see for testing finiteness).</p>

<h1 id="connectivity">Connectivity</h1>

<p>Connectivity is not hereditary: every connected graph is part of a larger disconnected graph and vice versa. But the property that some particular pair of vertices  is separated is hereditary: if  is separated from , the two vertices remain separated in any induced subgraph that contains them both. And while it’s not possible to verify this directly in a first order formula, for all graphs, it is possible in a special family of disconnected graphs, the ones containing a <em>transitive vertex</em>, one whose neighborhood forms a connected component of the graph. We can define a formula</p>



<p>which characterizes these transitive vertices. (Here I am using  to mean syntactic equivalence of formulas or definition of the name of a formula, rather than its meaning in Joel’s post, equivalence of models.) Then we can test whether  is separated from  by the formula</p>



<p>(Here, the instance of “transitive” on the right hand side is not a unary predicate, even though it looks like one; it should be expanded by the definition of the “transitive” formula to produce the resulting “separated” formula. Think of it as being like a C preprocessor macro.)
If  is indeed separated from , there is a possible world modeling the formula, in which we add an extra vertex  to the starting graph, adjacent to everything in the connected component of . And in any possible world modeling the formula,  is separated from , and this must remain true in every induced subgraph of this possible world, including the base graph. Finally, a graph is connected if and only if it has no separated pair:</p>



<p>In MSO logic, one of the standard tools is the <em>method of syntactic interpretations</em>. This allows you to modify your base graph  to form a different graph  (for any of certain standard types of modification) and test whether the resulting graph models a given formula . To do this, you instead modify the formula (in certain purely mechanical ways derived from how you were modifying ) and test whether your original graph models the modified formula . The same thing works in first-order logic and in modal logic, and allows such modifications as adding or removing an edge between given vertices, removing any given vertex, restricting to a logically-specified induced subgraph, or adding a new vertex with a logically-specified adjacency relation. I’ll write  for the modified formula that simulates formula  on the modified graph . We can use this idea to extend connectedness to other properties; for instance, a graph is a forest if it has no cycle, and this is true if every edge removal disconnects it:</p>



<h1 id="finiteness">Finiteness</h1>

<p>Following the earlier outline,
I’d like to find a simple family of finite graphs for which their finiteness is
so obvious that it can be tested by a simple logical formula, and then embed
every finite graph into one of these simple finite graphs.</p>

<p>The first natural choice of such a family is the family of paths.
We can define a path to be a connected graph with exactly two degree-one vertices in which all remaining vertices have degree two. Checking the degrees is first order, but I’ll spare you the messy details of the formula. All such graphs are finite, because a graph is connected if and only if every two vertices are a finite distance apart, and when the endpoints of a path are a finite distance apart there can be only finitely many other degree-two vertices between them. Any other vertices outside of this finite set must belong to a different component.</p>

<p>Not every finite graph can be embedded into a path. However, every finite graph has a perfect matching to the vertices of a path. To check the existence of an induced perfect matching between two sets of vertices in a graph, it’s helpful to have an extra vertex  that is not part of the matching, but that distinguishes one side of the matching (the neighbors of ) from the other side:</p>



<p>Here,  is shorthand for the <a href="https://en.wikipedia.org/wiki/Uniqueness_quantification">existence of exactly one thing</a>. With this test for an induced perfect matching in hand, we can check for a perfect matching to a finite path by</p>



<p>where  denotes the open neighborhood of , the graph induced by the vertices adjacent to .</p>

<p>I don’t think it’s possible to test finiteness in the same way in MSO.
We can define paths in MSO, and force them to have a perfect induced matching to the remaining vertices. But the recipe above breaks down at the point where it embeds the given graph into a supergraph, not generally possible in MSO. More generally I don’t think it’s possible in MSO to distinguish the family of finite complete graphs from their limit, the countable complete graph.</p>

<h1 id="additional-properties">Additional properties</h1>

<p>The same technology of paths and matchings can also be used to formulate not-very-natural properties of finite graphs that are definitely not expressible in MSO. For instance, we can check whether a graph  is the disjoint union of two equal-length paths, by first checking that it is a forest with four degree-one vertices and the rest degree-two, and then checking that both paths can be simultaneously perfectly matched to a third path of remaining vertices (with an additional vertex used to distinguish the sides of the matching as above). When this structure exists, the whole graph forms a polyhedron in the form of a  grid with the sides of the grid connected to the distinguishing vertex, and this polyhedral structure can be used to prove that we cannot trick the formula by adding new paths connecting the original path endpoints. In contrast, MSO cannot express equality of path lengths, because (per <a href="https://en.wikipedia.org/wiki/Courcelle%27s_theorem">Courcelle’s theorem</a>) it can only express properties of path-like graphs that can be expressed as regular languages (over bounded-width path-decompositions of the graph), and equality of length is context-free but not regular for path-decompositions that concatenate the two paths separately.</p>

<p>It’s also possible to express that the <a href="https://en.wikipedia.org/wiki/Degeneracy_(graph_theory)">degeneracy of a graph</a> is at most some constant  in modal logic. As special cases, the graphs of degeneracy zero are the independent sets (first-order expressible) and the graphs of degeneracy one are the forests, which we’ve already seen how to express. Otherwise, we can represent sequences of vertices by <em>ladders</em>, paths of degree-three vertices matched to independent sets of degree-two vertices, with the represented sequence being the other endpoints of these degree-two vertices. Adding a ladder to a graph of degeneracy at least two doesn’t change its degeneracy, and we can express the existence of a degeneracy ordering of a finite graph (a sequence of the vertices such that all vertices have at most  neighbors that are later in the sequence) by the addition of a ladder with a designated starting vertex that touches all non-ladder vertices.
Each non-ladder vertex  should have at most  neighbors with the property that, within the ladder, the ladder vertex nearest  separates the top of the ladder from the ladder vertices nearest these neighbors.</p>

<p>We can <a href="https://11011110.github.io/blog/2019/01/17/orientations-infinite-graphs.html">extend the concept of degeneracy from finite to infinite graphs</a>
by requiring that every finite subgraph have degeneracy at most .
With this definition, we can identify a finite subgraph as the neighbors of a ladder, and then use the formula for finite-graph degeneracy on these neighbors.
This leads to a modal logic expression for infinite graph degeneracy in which the overall structure of the formula is that it is necessary that, whenever a vertex  forms the start of a ladder, it should be possible for there to exist another ladder defining a degeneracy ordering for ’s ladder and its neighbors.</p>

<p>I suspect, although I haven’t worked out all the details, that planarity testing is also expressible in modal logic. Here’s the outline of an idea for proving this. First, we can check that the graph is finite, to avoid complications of which infinite graphs should be considered to be planar or what a drawing of an infinite planar graph might look like. Next, a graph is planar if and only if it is an induced subgraph of a maximal planar graph, one in which all edges belong to exactly two <a href="https://en.wikipedia.org/wiki/Peripheral_cycle">peripheral triangles</a>. A graph with this two-peripheral-triangle property is planar if and only if one can partition its edges into two subsets, one of which forms a spanning tree for the graph and the other of which forms a spanning tree for the dual graph of the peripheral cycles. (The two-peripheral-triangle property defines a surface embedding which, if non-planar, would have some leftover edges that are neither part of a spanning tree nor a complementary dual spanning tree; see my paper “<a href="https://www.ics.uci.edu/~eppstein/pubs/p-dyngen.html">Dynamic generators of topologically embedded graphs</a>”.) And it should be possible to describe this partition in a planarity-preserving way by decorating the edges on one side of the partition by additional small planar graphs (maybe even just attaching a triangle to each decorated edge). So all we need to check is that it’s possible for the given graph to be part of a larger graph
that looks like a maximal planar graph with some decorated edges (ignoring the decorations, each edge belongs to two peripheral triangles) and that the decorations describe a spanning tree and a dual spanning tree. We already know how to describe spanning trees and dual spanning trees should also be possible using similar logic.</p>

<p>One natural and simple property that I don’t see how to express in modal logic is regularity. One can ask: do each two vertices have the same degree? And equality of sets of vertices can be checked by the existence of perfect matchings, as in the two-equal-paths example. But how do we know, in a possible world, which neighbors of two given vertices are original and which are added? For the same reason, the property of having a perfect matching seems difficult to express in modal logic, even though it is easy in MSO. Again, it seems difficult to impose any extra structure on a supergraph without losing too much information about which parts of the graph are original.</p>

<h1 id="standard-and-nonstandard-models">Standard and nonstandard models</h1>

<p>I have been (deliberately) naive here about what kind of set theory I am using to define my graphs, what “all induced supergraphs” means (do I consider graphs only over some set of candidate vertices, or the proper class of all graphs in some set theory), and whether there is always a “correct” value of  that our models of modal graph logic should produce for a given graph and formula. If these naive assumptions are not valid, the description of what these formulas express may be inaccurate.</p>

<p>In particular, the claim that a graph is connected if and only if every two vertices are a finite distance apart uses concepts of distance that go beyond the first-order theory of graphs. In non-standard models of set theory, or in standard models of set theory but with non-standard collections of possible worlds that are not really the collection of all induced supergraphs of a given graph, that claim may fail to be true. In such cases, the finiteness formula may determine that an infinite graph (one that models the first-order logical formulas stating that there exist at least  distinct vertices, for every finite integer ) is finite. It’s not a bug in the formula, just an indication that you need to be careful about your models. Or in computer science terms, <a href="https://en.wikipedia.org/wiki/Garbage_in,_garbage_out">GIGO</a>.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/102438063877916451">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2019-07-13T21:57:00Z</updated>
    <published>2019-07-13T21:57:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-07-16T04:58:02Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16085</id>
    <link href="https://rjlipton.wordpress.com/2019/07/12/tools-and-sensitivity/" rel="alternate" type="text/html"/>
    <title>Tools and Sensitivity</title>
    <summary>Cutting right through a 30-year-old conjecture Cropped from Emory homepage Hao Huang is a mathematician and computer scientist at Emory University. Last week he released a paper of only six pages that solves the Boolean Sensitivity Conjecture, which goes back at least to a 1992 paper by Noam Nisan and Mario Szegedy. Today we discuss […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Cutting right through a 30-year-old conjecture</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2019/07/12/tools-and-sensitivity/haohuangcropped/" rel="attachment wp-att-16086"><img alt="" class="alignright wp-image-16086" height="212" src="https://rjlipton.files.wordpress.com/2019/07/haohuangcropped.jpg?w=148&amp;h=212" width="148"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Cropped from Emory <a href="http://www.mathcs.emory.edu/~hhuan30/">homepage</a></font></td>
</tr>
</tbody>
</table>
<p>
Hao Huang is a mathematician and computer scientist at Emory University. Last week he released a <a href="http://www.mathcs.emory.edu/~hhuan30/papers/sensitivity_1.pdf">paper</a> of only six pages that solves the Boolean Sensitivity Conjecture, which goes back at least to a 1992 <a href="https://www.researchgate.net/publication/2508255_On_the_Degree_of_Boolean_Functions_as_Real_Polynomials">paper</a> by Noam Nisan and Mario Szegedy.</p>
<p>
Today we discuss his brilliant proof and what it means for sensitivity of the <em>tools</em> one employs.</p>
<p>
Several of our blogging friends have <a href="https://www.scottaaronson.com/blog/?p=4229">covered</a> this <a href="https://gilkalai.wordpress.com/2019/07/02/amazing-hao-huang-proved-the-sensitivity-conjecture/">news</a> in <a href="https://blog.computationalcomplexity.org/2019/07/local-kid-makes-history.html">posts</a> <a href="https://windowsontheory.org/2019/07/02/sensitivity-conjecture-proved/">already</a>, and Ryan O’Donnell even summarized the proof in one <a href="https://twitter.com/BooleanAnalysis/status/1145837576487612416">tweet</a>. Scott Aaronson’s thread includes a <a href="https://www.scottaaronson.com/blog/?p=4229#comment-1813116">comment</a> by Huang on how he came by his proof. </p>
<p>
We will try to draw implications for the related matter of how <em>you</em> might come by proofs of <em>other</em> conjectures. We have previously <a href="https://rjlipton.wordpress.com/2016/04/09/missing-mate-in-ten/">discussed</a> the possibility of overlooking short solutions to major problems. Here we will discuss how to <em>find</em> them.</p>
<p>
</p><p/><h2> A Graph Puzzle </h2><p/>
<p/><p>
To get a flavor of what Huang proved, consider the graph of an ordinary <a href="https://commons.wikimedia.org/wiki/File:Cube_graph.png">cube</a>:</p>
<p/><p><br/>
<a href="https://rjlipton.wordpress.com/2019/07/12/tools-and-sensitivity/cube_graph/" rel="attachment wp-att-16087"><img alt="" class="aligncenter wp-image-16087" height="181" src="https://rjlipton.files.wordpress.com/2019/07/cube_graph.png?w=192&amp;h=181" width="192"/></a></p>
<p/><p><br/>
The question is, <em>can you color 5 vertices red so that no red node has 3 red neighbors?</em> Your first impulse might be to color 4 nodes red according to parity so that none has a red neighbor, per below left:</p>
<p/><p><br/>
<a href="https://rjlipton.wordpress.com/2019/07/12/tools-and-sensitivity/cube_graph_tries/" rel="attachment wp-att-16088"><img alt="" class="aligncenter wp-image-16088" height="175" src="https://rjlipton.files.wordpress.com/2019/07/cube_graph_tries.png?w=450&amp;h=175" width="450"/></a></p>
<p/><p><br/>
But then any 5th node will have 3 red neighbors. Another “greedy” idea is to pack a subgraph of the allowed degree 2 into half the cube, as at right. Any 5th node will again create a degree-3 vertex in the subgraph induced by the red nodes.</p>
<p>
The answer is that actually one can pack 6 nodes that induce a simple cycle:</p>
<p/><p><br/>
<a href="https://rjlipton.wordpress.com/2019/07/12/tools-and-sensitivity/cube_graph_solved/" rel="attachment wp-att-16089"><img alt="" class="aligncenter wp-image-16089" height="181" src="https://rjlipton.files.wordpress.com/2019/07/cube_graph_solved.png?w=192&amp;h=181" width="192"/></a></p>
<p/><p><br/>
Now let’s up the dimension by one—that is, take <img alt="{n = 4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn+%3D+4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n = 4}"/> and <img alt="{N = 2^n = 16}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN+%3D+2%5En+%3D+16%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N = 2^n = 16}"/>. How many nodes can we color red and keep the induced degree 2? </p>
<p/><p><br/>
<a href="https://rjlipton.wordpress.com/2019/07/12/tools-and-sensitivity/hypercube_graph/" rel="attachment wp-att-16091"><img alt="" class="aligncenter wp-image-16091" height="230" src="https://rjlipton.files.wordpress.com/2019/07/hypercube_graph-1.png?w=300&amp;h=230" width="300"/></a></p>
<p/><p><br/>
Again the parity trick gives us degree 0 with 8 nodes, but then we can’t add a 9th. We can greedily try to pack the outer cube with our 6-node solution, but then—perhaps surprisingly—we can add only 2 more red nodes from the inner cube. So we can only do 5 from the outer cube. We can get 9 overall by:</p>
<p><a href="https://rjlipton.wordpress.com/2019/07/12/tools-and-sensitivity/hypercube_graph_try10/" rel="attachment wp-att-16092"><img alt="" class="aligncenter wp-image-16092" height="230" src="https://rjlipton.files.wordpress.com/2019/07/hypercube_graph_try10.png?w=300&amp;h=230" width="300"/></a></p>
<p/><p><br/>
The fact that one red node is isolated seems to give room to improve, but there is no way to make 10. </p>
<p>
</p><p/><h2> The Theorem </h2><p/>
<p/><p>
The calculations have left an interesting jump from degree 0 with eight red nodes and degree 2 with nine. How about degree 1? Can we do that with 9 nodes? We can pack four disjoint edges but then there is nowhere to stick an isolated node. </p>
<p>
So for 9 nodes, which is <img alt="{\frac{N}{2} + 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7BN%7D%7B2%7D+%2B+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\frac{N}{2} + 1}"/>, the best we can do is degree 2, which is <img alt="{\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\sqrt{n}}"/>. This is what Huang proved:</p>
<blockquote><p><b>Theorem 1</b> <em><a name="graphs"/> Every subgraph induced by <img alt="{\frac{N}{2} + 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7BN%7D%7B2%7D+%2B+1%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\frac{N}{2} + 1}"/> nodes of the <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n}"/>-dimensional hypercube graph has a node of degree at least <img alt="{\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7Bn%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\sqrt{n}}"/>. </em>
</p></blockquote>
<p/><p>
This is completely tight. When <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> is a perfect square there is a way to achieve <img alt="{\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\sqrt{n}}"/> as the maximum degree (shown <a href="https://pdfs.semanticscholar.org/3917/3e0cb4e028c94328f1355bf02febea132127.pdf">here</a>). Otherwise the least integer above <img alt="{\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\sqrt{n}}"/> is best. Thus every subgraph of the <img alt="{5}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B5%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{5}"/>-cube induced by 17 nodes has a node with three neighbors, but you can go as high as 257 nodes in the <img alt="{9}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B9%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{9}"/>-cube while keeping the maximum degree to 3.</p>
<p>
We will mention the relation to Boolean sensitivity only briefly. The nodes of the <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>-cube correspond to truth assignments in <img alt="{\{0,1\}^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B0%2C1%5C%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{0,1\}^n}"/>. Since every red node <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> has <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> neighbors in the cube but at most <img alt="{\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\sqrt{n}}"/> red neighbors, the color function is highly sensitive to bitflips. But every flip also changes the parity of <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/>. Hence the <em>exclusive-or</em> of the color function with the parity function has <em>low</em> sensitivity. </p>
<p>
But not too low: Huang proved it is at least <img alt="{\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\sqrt{n}}"/>. That was enough to prove the conjecture. I’ve cut two sections on Boolean sensitivity from this post’s <a href="https://cse.buffalo.edu/~regan/cse705/wsensitivity.pdf">original draft</a>—let’s just say the connection to the <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>-cube and graph degree was known since this 1992 <a href="https://www.sciencedirect.com/science/article/pii/0097316592900608">paper</a>. Here we’ll focus on what it took to prove this theorem.</p>
<p>
</p><p/><h2> The Proof </h2><p/>
<p/><p>
From my undergrad days I’ve kept an interest in spectral graph theory. One of the basic facts is that the degree <img alt="{d(G)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d(G)}"/> of a graph <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> is always at least as great as the largest eigenvalue <img alt="{\lambda}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\lambda}"/> of its adjacency matrix <img alt="{A_G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_G%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_G}"/>. For a <img alt="{d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d}"/>-regular graph they are equal. Huang’s first trick is to note that the classic proof of this also allows <img alt="{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-1}"/> values on edges:</p>
<blockquote><p><b>Lemma 2</b> <em> Let <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{A}"/> be a symmetric matrix obtained from <img alt="{A_G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_G%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{A_G}"/> by multiplying some entries by <img alt="{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{-1}"/> and <img alt="{\lambda}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\lambda}"/> any of its eigenvalues. Then <img alt="{d(G) \geq |\lambda|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%28G%29+%5Cgeq+%7C%5Clambda%7C%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{d(G) \geq |\lambda|}"/>. </em>
</p></blockquote>
<p/><p>
<em>Proof:</em>  Choose an eigenvector <img alt="{v}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bv%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{v}"/> such that <img alt="{Av = \lambda v}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BAv+%3D+%5Clambda+v%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Av = \lambda v}"/> and take an index <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/> that maximizes <img alt="{|v_i|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7Cv_i%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|v_i|}"/>. Then </p>
<p align="center"><img alt="\displaystyle  |\lambda v_i| = |(A v)_i| = |\sum_j A_{i,j} v_j| \leq |\sum_j A_{i,j}| \cdot |v_i| \leq \sum_{(i,j) \in E(G)} |A_{i,j}|\cdot |v_i| \leq d(G)|v_i|. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7C%5Clambda+v_i%7C+%3D+%7C%28A+v%29_i%7C+%3D+%7C%5Csum_j+A_%7Bi%2Cj%7D+v_j%7C+%5Cleq+%7C%5Csum_j+A_%7Bi%2Cj%7D%7C+%5Ccdot+%7Cv_i%7C+%5Cleq+%5Csum_%7B%28i%2Cj%29+%5Cin+E%28G%29%7D+%7CA_%7Bi%2Cj%7D%7C%5Ccdot+%7Cv_i%7C+%5Cleq+d%28G%29%7Cv_i%7C.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  |\lambda v_i| = |(A v)_i| = |\sum_j A_{i,j} v_j| \leq |\sum_j A_{i,j}| \cdot |v_i| \leq \sum_{(i,j) \in E(G)} |A_{i,j}|\cdot |v_i| \leq d(G)|v_i|. "/></p>
<p>Dividing out <img alt="{|v_i|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7Cv_i%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|v_i|}"/> gives the lemma. <img alt="\Box" class="latex" src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Box"/></p>
<p/><p><br/>
So now what we want to do is find conditions that force <img alt="{\lambda = \sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda+%3D+%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\lambda = \sqrt{n}}"/> when <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> is a <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m}"/>-vertex subgraph of the <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>-cube with <img alt="{m \geq \frac{N}{2} + 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm+%5Cgeq+%5Cfrac%7BN%7D%7B2%7D+%2B+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m \geq \frac{N}{2} + 1}"/>, where <img alt="{N = 2^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN+%3D+2%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N = 2^n}"/>. The trick that Huang realized is that he could do this by making <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/> sit inside a matrix <img alt="{A_N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_N}"/> with at least <img alt="{\frac{N}{2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7BN%7D%7B2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\frac{N}{2}}"/> eigenvalues of <img alt="{+\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%2B%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{+\sqrt{n}}"/>. </p>
<p>
To see how, form <img alt="{A_{N-1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_%7BN-1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_{N-1}}"/> by knocking out the last row and column of <img alt="{A_N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_N}"/>. Since <img alt="{A_N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_N}"/> and <img alt="{A_{N-1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_%7BN-1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_{N-1}}"/> are both real and symmetric, their eigenvalues are real, so we can order them <img alt="{\lambda_1,\dots,\lambda_N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda_1%2C%5Cdots%2C%5Clambda_N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\lambda_1,\dots,\lambda_N}"/> and <img alt="{\mu_1,\dots,\mu_{N-1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmu_1%2C%5Cdots%2C%5Cmu_%7BN-1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mu_1,\dots,\mu_{N-1}}"/> in nonincreasing order. The basic fact is that they always <em>interlace</em>: </p>
<p align="center"><img alt="\displaystyle  \lambda_1 \geq \mu_1 \geq \lambda_2 \geq \mu_2 \geq \lambda_3 \geq \cdots \geq \mu_{N-1} \geq \lambda_N. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clambda_1+%5Cgeq+%5Cmu_1+%5Cgeq+%5Clambda_2+%5Cgeq+%5Cmu_2+%5Cgeq+%5Clambda_3+%5Cgeq+%5Ccdots+%5Cgeq+%5Cmu_%7BN-1%7D+%5Cgeq+%5Clambda_N.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \lambda_1 \geq \mu_1 \geq \lambda_2 \geq \mu_2 \geq \lambda_3 \geq \cdots \geq \mu_{N-1} \geq \lambda_N. "/></p>
<p>See <a href="https://arxiv.org/pdf/math/0502408.pdf">this</a> for a one-page proof. The neat point is that you can repeat this: if you get <img alt="{A''}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%27%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A''}"/> by knocking out another row and corresponding column, and <img alt="{[\nu_i]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5B%5Cnu_i%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{[\nu_i]}"/> are its eigenvalues in order, then </p>
<p align="center"><img alt="\displaystyle  \mu_1 \geq \nu_1 \geq \mu_2 \geq \nu_2 \geq \mu_3 \cdots. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmu_1+%5Cgeq+%5Cnu_1+%5Cgeq+%5Cmu_2+%5Cgeq+%5Cnu_2+%5Cgeq+%5Cmu_3+%5Ccdots.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \mu_1 \geq \nu_1 \geq \mu_2 \geq \nu_2 \geq \mu_3 \cdots. "/></p>
<p>It follows that <img alt="{\lambda_1 \geq \nu_1 \geq \lambda_3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda_1+%5Cgeq+%5Cnu_1+%5Cgeq+%5Clambda_3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\lambda_1 \geq \nu_1 \geq \lambda_3}"/>. If you do this again, you get a matrix whose leading eigenvalue is still at least as big as <img alt="{\lambda_4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda_4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\lambda_4}"/>. Do it <img alt="{\frac{N}{2} - 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7BN%7D%7B2%7D+-+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\frac{N}{2} - 1}"/> times inside <img alt="{A_N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_N}"/>, and you’re still above <img alt="{\lambda_{N/2}(A_N)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda_%7BN%2F2%7D%28A_N%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\lambda_{N/2}(A_N)}"/>, which we just said we will arrange to be <img alt="{+\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%2B%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{+\sqrt{n}}"/>. Thus if we knock out the <img alt="{\frac{N}{2} - 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7BN%7D%7B2%7D+-+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\frac{N}{2} - 1}"/> white nodes, we will get the graph on the red nodes with adjacency matrix <img alt="{A_m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_m}"/> and conclude: </p>
<p align="center"><img alt="\displaystyle  \lambda_1(A_N) \geq \lambda_1(A_m) \geq \lambda_{N/2}(A_N) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clambda_1%28A_N%29+%5Cgeq+%5Clambda_1%28A_m%29+%5Cgeq+%5Clambda_%7BN%2F2%7D%28A_N%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \lambda_1(A_N) \geq \lambda_1(A_m) \geq \lambda_{N/2}(A_N) "/></p>
<p>Plugging into the lemma gives: </p>
<p align="center"><img alt="\displaystyle  d(G) \geq \lambda_1(A_m) \geq \lambda_{N/2}(A_N) = \sqrt{n}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++d%28G%29+%5Cgeq+%5Clambda_1%28A_m%29+%5Cgeq+%5Clambda_%7BN%2F2%7D%28A_N%29+%3D+%5Csqrt%7Bn%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  d(G) \geq \lambda_1(A_m) \geq \lambda_{N/2}(A_N) = \sqrt{n}. "/></p>
<p>(In fact, as also <a href="https://www.scottaaronson.com/blog/?p=4229#comment-1813084">noted</a> on Scott’s blog, this case of interlacing can be inferred from simpler reasoning—but our point is that the interlacing theorem was in Huang’s bag of tricks.) </p>
<p>
</p><p/><h2> Building the Matrix </h2><p/>
<p/><p>
Finally, how do we lay hands on <img alt="{A_N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_N}"/>? We want a matrix of trace zero such that <img alt="{A_N^2 = nI}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_N%5E2+%3D+nI%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_N^2 = nI}"/>. Then all its eigenvalues are <img alt="{+\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%2B%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{+\sqrt{n}}"/> and <img alt="{-\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-\sqrt{n}}"/>.  They come in equal numbers because they sum to the trace which is zero. So we will have <img alt="{N/2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N/2}"/> eigenvalues of <img alt="{+\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%2B%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{+\sqrt{n}}"/>, as needed. And we would want <img alt="{A_N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_N}"/> to be the matrix of the <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>-cube but that doesn’t work: each <img alt="{i,j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%2Cj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i,j}"/> entry of its square counts all paths of length 2 from node <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/> to node <img alt="{j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{j}"/> and that number can be nonzero.</p>
<p>
This is where the trick of putting <img alt="{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-1}"/> on edges comes in, and we can explain it in a way familiar from quantum. We arrange that every 4-cycle of the <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>-cube has exactly one edge with <img alt="{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-1}"/>. Then the pairs of paths from one corner to the opposite corner will always <em>cancel</em>, leaving <img alt="{A^2_{i,j} = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%5E2_%7Bi%2Cj%7D+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A^2_{i,j} = 0}"/> whenever <img alt="{i \neq j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi+%5Cneq+j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i \neq j}"/>. And <img alt="{A^2_{i,j} = n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%5E2_%7Bi%2Cj%7D+%3D+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A^2_{i,j} = n}"/> because there are <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> ways to go out and come back along the same edge, always contributing <img alt="{1\cdot 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%5Ccdot+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1\cdot 1}"/> or <img alt="{(-1)\cdot(-1) = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28-1%29%5Ccdot%28-1%29+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(-1)\cdot(-1) = 1}"/> either way. Huang defines the needed labeling explicitly by the recursion: </p>
<p align="center"><img alt="\displaystyle  A_2 = \begin{bmatrix} 0 &amp; 1 \\ 1 &amp; 0 \end{bmatrix},\quad\text{and for } N &gt; 2,\quad A_N = \begin{bmatrix} A_{N/2} &amp; I \\ I &amp; -A_{N/2} \end{bmatrix}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++A_2+%3D+%5Cbegin%7Bbmatrix%7D+0+%26+1+%5C%5C+1+%26+0+%5Cend%7Bbmatrix%7D%2C%5Cquad%5Ctext%7Band+for+%7D+N+%3E+2%2C%5Cquad+A_N+%3D+%5Cbegin%7Bbmatrix%7D+A_%7BN%2F2%7D+%26+I+%5C%5C+I+%26+-A_%7BN%2F2%7D+%5Cend%7Bbmatrix%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  A_2 = \begin{bmatrix} 0 &amp; 1 \\ 1 &amp; 0 \end{bmatrix},\quad\text{and for } N &gt; 2,\quad A_N = \begin{bmatrix} A_{N/2} &amp; I \\ I &amp; -A_{N/2} \end{bmatrix}. "/></p>
<p>This puts a <img alt="{-}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-}"/> sign on exactly one-fourth of the entries in the needed way. OK, we changed Huang’s subscripts for consistency with “<img alt="{A_N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_N}"/>” above and also to note that the basis could be <img alt="{A_1 = [0]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_1+%3D+%5B0%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_1 = [0]}"/>.  Anyway, he verifies <img alt="{A_N^2 = nI}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_N%5E2+%3D+nI%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_N^2 = nI}"/> directly by simple algebra and induction.  That’s it—that’s the proof.</p>
<p>
Why was it hard to spot? Dick and I believe it was the <img alt="{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-1}"/> trick. In the 1980s, I thought about ways to convert undirected graphs into directed ones by putting arrows on the edges, but not <img alt="{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-1}"/> signs. The chance of thinking of it maybe rises with knowing quantum ideas such as interference and amplification. Now we can see, OK, <img alt="{A_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_2}"/> is the quantum NOT gate and the recursion treats signs in similar fashion to the recursion defining Hadamard matrices.  The matrix <img alt="{\frac{1}{\sqrt{n}}A_N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B1%7D%7B%5Csqrt%7Bn%7D%7DA_N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\frac{1}{\sqrt{n}}A_N}"/> is unitary, so it defines a quantum operator. This all goes to our main point about having tools at one’s command—the more tools, the better. </p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Huang’s theorem still leaves a gap between a quadratic lower bound and his 4th-power upper bound (my longer <a href="https://cse.buffalo.edu/~regan/cse705/wsensitivity.pdf">draft</a> lays this out).  Can this gap be closed?  In discussing this, Huang notes that his spectral methods need not be confined to sub-matrices of the <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>-cube, and our thoughts of involving quantum are similar. Can quantum tools improve the results even further?</p>
<p/></font></font></div>
    </content>
    <updated>2019-07-12T10:51:42Z</updated>
    <published>2019-07-12T10:51:42Z</published>
    <category term="algorithms"/>
    <category term="All Posts"/>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="Open Problems"/>
    <category term="People"/>
    <category term="Proofs"/>
    <category term="Results"/>
    <category term="Teaching"/>
    <category term="trick"/>
    <category term="Boolean functions"/>
    <category term="Boolean sensitivity conjecture"/>
    <category term="complexity"/>
    <category term="concrete complexity"/>
    <category term="eigenvalues"/>
    <category term="Hao Huang"/>
    <category term="linear algebra"/>
    <category term="matrices"/>
    <category term="quantum"/>
    <category term="spectral methods"/>
    <category term="tricks"/>
    <author>
      <name>KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-07-16T18:20:54Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-1705625191398821823</id>
    <link href="https://blog.computationalcomplexity.org/feeds/1705625191398821823/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/07/degree-and-sensitivity.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/1705625191398821823" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/1705625191398821823" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/07/degree-and-sensitivity.html" rel="alternate" type="text/html"/>
    <title>Degree and Sensitivity</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Hao Huang's <a href="https://arxiv.org/abs/1907.00847">proof of the sensitivity conjecture</a> that I <a href="https://blog.computationalcomplexity.org/2019/07/local-kid-makes-history.html">posted on last week</a> relied on a 1992 <a href="https://doi.org/10.1016/0097-3165(92)90060-8">result of Gotsman and Linial</a>. Let's talk about that result.<br/>
<br/>
Consider the set S={-1,1}<sup>n</sup>. The hypercube of dimension n is the graph with vertex set S and an edge between x = (x<sub>1</sub>,…,x<sub>n</sub>) and y = (y<sub>1</sub>,…,y<sub>n</sub>) in S if there is exactly one i such that x<sub>i</sub> ≠ y<sub>i</sub>. Every vertex has degree n.<br/>
<br/>
We say a vertex x is odd if x has an odd number of -1 coordinates, even otherwise. Every edge joins an odd and even vertex.<br/>
<br/>
Let f be a function mapping S to {-1,1}. The sensitivity of f on x is the number of i such that f(x<sub>1</sub>,…,x<sub>i</sub>,…,x<sub>n</sub>) ≠ f(x<sub>1</sub>,…,-x<sub>i</sub>,…,x<sub>n</sub>). The sensitivity of f is the maximum over all x in S of the sensitivity of f on x.<br/>
<br/>
Let g be the same function as f except that we flip the value on all odd vertices. Notice now that the sensitivity of f on x is the number of i such that g(x<sub>1</sub>,…,x<sub>i</sub>,…,x<sub>n</sub>) = g(x<sub>1</sub>,…,-x<sub>i</sub>,…,x<sub>n</sub>).<br/>
<br/>
Let G be the induced subgraph of vertices of x such that g(x)=-1 and H be induced subgraph on the set of x such that g(x)=1. The sensitivity of f is the maximum number of neighbors of any vertex in G or H.<br/>
<br/>
Consider f as a multilinear polynomial over the reals. The sensitivity conjecture states there is some α&gt;0 such that if f has degree n then f has sensitivity at least n<sup>α</sup>.<br/>
<br/>
Note g(x<sub>1</sub>,…,x<sub>n</sub>)=f(x<sub>1</sub>,…,x<sub>n</sub>)x<sub>1</sub>⋯x<sub>n</sub>. If f has a degree n term, the variables in that term cancel out on S (since x<sub>i</sub><sup>2</sup>=1) and the constant of the degree n term of f becomes the constant term of g. The constant term is just the expected value, so f has full degree iff g is unbalanced.<br/>
<br/>
GL Assumption: Suppose you have a partition of the hypercube into sets A and B with |A| ≠ |B|, and let G and H be the induced subgraphs of A and B. Then there is some constant α&gt;0 such that there is a node of A or B with at least n<sup>α</sup> neighbors.<br/>
<br/>
The above argument, due to Gotsman and Linial, shows that the GL assumption is equivalent to the sensitivity conjecture.<br/>
<br/>
Huang proved that given any subset A of the vertices of a hypercube with |A|&gt;2<sup>n</sup>/2 the induced subgraph has a node of degree at least n<sup>1/2</sup>. Since either A or B in the GL assumption has size greater than 2<sup>n</sup>/2, Huang's result gives the sensitivity conjecture.</div>
    </content>
    <updated>2019-07-11T17:54:00Z</updated>
    <published>2019-07-11T17:54:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-07-16T13:06:10Z</updated>
    </source>
  </entry>
</feed>
