<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2019-09-18T11:22:16Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.07919</id>
    <link href="http://arxiv.org/abs/1909.07919" rel="alternate" type="text/html"/>
    <title>Combinatorial Algorithms for Edge-Disjoint $T$-Paths and Integer Free Multiflow</title>
    <feedworld_mtime>1568764800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Iwata:Satoru.html">Satoru Iwata</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yokoi:Yu.html">Yu Yokoi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.07919">PDF</a><br/><b>Abstract: </b>Let $G=(V,E)$ be a multigraph with a set $T\subseteq V$ of terminals. A path
in $G$ is called a $T$-path if its ends are distinct vertices in $T$ and no
internal vertices belong to $T$. In 1978, Mader showed a characterization of
the maximum number of edge-disjoint $T$-paths. The original proof was not
constructive, and hence it did not suggest an efficient algorithm.
</p>
<p>In this paper, we provide a combinatorial, deterministic algorithm for
finding the maximum number of edge-disjoint $T$-paths. The algorithm adopts an
augmenting path approach. More specifically, we introduce a novel concept of
augmenting walks in auxiliary labeled graphs to capture a possible augmentation
of the number of edge-disjoint $T$-paths. To design a search procedure for an
augmenting walk, we introduce blossoms analogously to the matching algorithm of
Edmonds (1965), while it is neither a special case nor a generalization of the
present problem. When the search procedure terminates without finding an
augmenting walk, the algorithm provides a certificate for the optimality of the
current edge-disjoint $T$-paths. Thus the correctness argument of the algorithm
serves as an alternative direct proof of Mader's theorem on edge-disjoint
$T$-paths. The algorithm runs in $O(|V|\cdot |E|^2)$ time, which is much faster
than the best known deterministic algorithm based on a reduction to the linear
matroid parity problem.
</p>
<p>We also present a strongly polynomial algorithm for solving the integer free
multiflow problem, which asks for a nonnegative integer combination of
$T$-paths maximizing the sum of the coefficients subject to capacity
constraints on the edges.
</p></div>
    </summary>
    <updated>2019-09-18T01:28:05Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.07854</id>
    <link href="http://arxiv.org/abs/1909.07854" rel="alternate" type="text/html"/>
    <title>Dynamic coloring for Bipartite and General Graphs</title>
    <feedworld_mtime>1568764800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kashyop:Manas_Jyoti.html">Manas Jyoti Kashyop</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Narayanaswamy:N=_S=.html">N. S. Narayanaswamy</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nasre:Meghana.html">Meghana Nasre</a>, Sai Mohith Potluri <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.07854">PDF</a><br/><b>Abstract: </b>We consider the dynamic coloring problem on bipartite and general graphs in
the incremental as well as fully-dynamic settings. In this work, we are
interested in the following parameters : the update time and query time, the
number of colors used, and the number of vertex recolorings per update. Our
results reveal the following trade-off for a bipartite graph with $n$ vertices:
</p>
<p>In the fully dynamic setting, if we restrict the number of colors to $2$ then
the maximum of update and query time is at least $\log n$. In the incremental
setting, using $2$ colors we achieve the maximum of update and query time to be
$O(\alpha(n))$, where $\alpha(n)$ is the inverse Ackermann function.
</p>
<p>We show that by allowing more than two colors we can reduce the query time to
$O(1)$ without changing the update time. Our incremental algorithm uses $1+2
\log{n}$ colors.
</p>
<p>To the best of our knowledge, there are no known theoretical guarantees for
dynamic coloring specific to bipartite graphs. For general graphs we provide a
deterministic fully-dynamic algorithm with constant number of recolorings per
update.
</p>
<p>We use $\Delta+1$ colors and achieve $O(\sqrt{m})$ worst case update time
with at most one recoloring per update. Here $\Delta$ is the maximum degree of
a vertex and $m$ denotes the maximum number of edges throughout the update
sequence.
</p>
<p>For graphs of arboricity bounded by $\gamma$ we maintain a $\Delta+1$
coloring with at most one recoloring per update, an amortized update time of
$O(\gamma + \log{n})$, and an $O(1)$ query time.
</p></div>
    </summary>
    <updated>2019-09-18T01:23:39Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.07816</id>
    <link href="http://arxiv.org/abs/1909.07816" rel="alternate" type="text/html"/>
    <title>The Computational Complexity of Fire Emblem Series and similar Tactical Role-Playing Games</title>
    <feedworld_mtime>1568764800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gao:Jiawei.html">Jiawei Gao</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.07816">PDF</a><br/><b>Abstract: </b>Fire Emblem (FE) is a popular turn-based tactical role-playing game (TRPG)
series on the Nintendo gaming consoles. This paper studies the computational
complexity of FE, and proves that: 1. General FE is PSPACE-complete. 2.
Poly-round FE is NP-complete, even when the map is cycle-free. Poly-round FE is
to decide whether the player can win the game in a certain number of rounds
that is polynomial to the map size. A map is called cycle-free if its
corresponding planar graph is cycle-free. These hardness results also hold for
other similar TRPG series, such as Final Fantasy Tactics, Tactics Ogre and
Disgaea.
</p></div>
    </summary>
    <updated>2019-09-18T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.07780</id>
    <link href="http://arxiv.org/abs/1909.07780" rel="alternate" type="text/html"/>
    <title>Preprocessing and Cutting Planes with Conflict Graphs</title>
    <feedworld_mtime>1568764800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Brito:Samuel_S=.html">Samuel S. Brito</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Santos:Haroldo_G=.html">Haroldo G. Santos</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.07780">PDF</a><br/><b>Abstract: </b>This paper addresses the implementation of conflict graph-based routines into
the COIN-OR Branch-and-Cut (CBC) solver, including: $(i)$ a conflict graph
infrastructure with an improved version of a state-of-the-art conflict
detection algorithm to quickly build conflict graphs; this version detects
additional conflicts and has the same worst-case complexity of the original
algorithm; $(ii)$ a preprocessing routine based on a clique-strengthening
scheme that can both reduce the number of nonzeros in the constraint matrix and
also produce stronger formulations; $(iii)$ a clique cut separator capable of
obtaining dual bounds at the root node that are $26\%$ stronger than the ones
provided by the equivalent cut generator of a state-of-the-art commercial
solver, $467\%$ stronger than those attained by the clique cut separator of the
GLPK solver and $500\%$ stronger than the dual bounds obtained by the clique
separation routine of the COIN-OR Cut Generation Library; $(iv)$ an odd-cycle
cut separator with a lifting module to produce valid odd-wheel inequalities.
This new version of CBC obtained an average gap closed that is $26\%$ better
than the previous one and solved $27\%$ more instances.
</p></div>
    </summary>
    <updated>2019-09-18T01:21:22Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.07703</id>
    <link href="http://arxiv.org/abs/1909.07703" rel="alternate" type="text/html"/>
    <title>Multi-robot persistent surveillance with connectivity constraints</title>
    <feedworld_mtime>1568764800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Scherer:J=uuml=rgen.html">Jürgen Scherer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rinner:Bernhard.html">Bernhard Rinner</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.07703">PDF</a><br/><b>Abstract: </b>Mobile robots, especially unmanned aerial vehicles (UAVs), are of increasing
interest for surveillance and disaster response scenarios. We consider the
problem of multi-robot persistent surveillance with connectivity constraints
where robots have to visit sensing locations periodically and maintain a
multi-hop connection to a base station. We formally define several problem
instances closely related to multi-robot persistent surveillance with
connectivity constraints, i.e., connectivity-constrained multi-robot persistent
surveillance (CMPS), connectivity-constrained multi-robot reachability (CMR),
and connectivity-constrained multi-robot reachability with relay dropping
(CMRD), and show that they are all NP-hard on general graph. We introduce three
heuristics with different planning horizons for convex grid graphs and combine
these with a tree traversal approach which can be applied to a partitioning of
non-convex grid graphs (CMPS with tree traversal, CMPSTT). In simulation
studies we show that a short horizon greedy approach, which requires parameters
to be optimized beforehand, can outperform a full horizon approach, which
requires a tour through all sensing locations, if the number of robots is
larger than the minimum number of robots required to reach all sensing
locations. The minimum number required is the number of robots necessary for
building a chain to the farthest sensing location from the base station.
Furthermore, we show that partitioning the area and applying the tree traversal
approach can achieve a performance similar to the unpartitioned case up to a
certain number of robots but requires less optimization time.
</p></div>
    </summary>
    <updated>2019-09-18T01:26:56Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.07647</id>
    <link href="http://arxiv.org/abs/1909.07647" rel="alternate" type="text/html"/>
    <title>A heuristic use of dynamic programming to upperbound treewidth</title>
    <feedworld_mtime>1568764800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tamaki:Hisao.html">Hisao Tamaki</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.07647">PDF</a><br/><b>Abstract: </b>For a graph $G$, let $\Omega(G)$ denote the set of all potential maximal
cliques of $G$. For each subset $\Omega$ of $\Omega(G)$, let $\tw(G, \Omega)$
denote the smallest $k$ such that there is a tree-decomposition of $G$ of width
$k$ whose bags all belong to $\Omega$. Bouchitt\'{e} and Todinca observed in
2001 that $\tw(G, \Omega(G))$ is exactly the treewidth of $G$ and developed a
dynamic programming algorithm to compute it. Indeed, their algorithm can
readily be applied to an arbitrary non-empty subset $\Omega$ of $\Omega(G)$ and
computes $\tw(G, \Omega)$, or reports that it is undefined, in time
$|\Omega||V(G)|^{O(1)}$. This efficient tool for computing $\tw(G, \Omega)$
allows us to conceive of an iterative improvement procedure for treewidth upper
bounds which maintains, as the current solution, a set of potential maximal
cliques rather than a tree-decomposition.
</p>
<p>We design and implement an algorithm along this approach. Experiments show
that our algorithm vastly outperforms previously implemented heuristic
algorithms for treewidth.
</p></div>
    </summary>
    <updated>2019-09-18T01:24:22Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.07633</id>
    <link href="http://arxiv.org/abs/1909.07633" rel="alternate" type="text/html"/>
    <title>Communication-Efficient Weighted Sampling and Quantile Summary for GBDT</title>
    <feedworld_mtime>1568764800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Huang:Ziyue.html">Ziyue Huang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yi:Ke.html">Ke Yi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.07633">PDF</a><br/><b>Abstract: </b>Gradient boosting decision tree (GBDT) is a powerful and widely-used machine
learning model, which has achieved state-of-the-art performance in many
academic areas and production environment. However, communication overhead is
the main bottleneck in distributed training which can handle the massive data
nowadays. In this paper, we propose two novel communication-efficient methods
over distributed dataset to mitigate this problem, a weighted sampling approach
by which we can estimate the information gain over a small subset efficiently,
and distributed protocols for weighted quantile problem used in approximate
tree learning.
</p></div>
    </summary>
    <updated>2019-09-18T01:26:47Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.07557</id>
    <link href="http://arxiv.org/abs/1909.07557" rel="alternate" type="text/html"/>
    <title>Object Reachability via Swaps under Strict and Weak Preferences</title>
    <feedworld_mtime>1568764800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Huang:Sen.html">Sen Huang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/x/Xiao:Mingyu.html">Mingyu Xiao</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.07557">PDF</a><br/><b>Abstract: </b>The \textsc{Housing Market} problem is a widely studied resource allocation
problem. In this problem, each agent can only receive a single object and has
preferences over all objects. Starting from an initial endowment, we want to
reach a certain assignment via a sequence of rational trades. We first consider
whether an object is reachable for a given agent under a social network, where
a trade between two agents is allowed if they are neighbors in the network and
no participant has a deficit from the trade. Assume that the preferences of the
agents are strict (no tie among objects is allowed). This problem is
polynomially solvable in a star-network and NP-complete in a tree-network. It
is left as a challenging open problem whether the problem is polynomially
solvable when the network is a path. We answer this open problem positively by
giving a polynomial-time algorithm. Then we show that when the preferences of
the agents are weak (ties among objects are allowed), the problem becomes
NP-hard even when the network is a path. In addition, we consider the
computational complexity of finding different optimal assignments for the
problem under the network being a path or a star.
</p></div>
    </summary>
    <updated>2019-09-18T01:26:22Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.07538</id>
    <link href="http://arxiv.org/abs/1909.07538" rel="alternate" type="text/html"/>
    <title>Generalized Dictionary Matching under Substring Consistent Equivalence Relations</title>
    <feedworld_mtime>1568764800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hendrian:Diptarama.html">Diptarama Hendrian</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.07538">PDF</a><br/><b>Abstract: </b>Given a set of patterns called a dictionary and a text, the dictionary
matching problem is a task to find all occurrence positions of all patterns in
the text. The dictionary matching problem can be solved efficiently by using
the Aho-Corasick algorithm. Recently, Matsuoka et al. [TCS, 2016] proposed a
generalization of pattern matching problem under substring consistent
equivalence relations and presented a generalization of the Knuth-Morris-Pratt
algorithm to solve this problem. An equivalence relation $\approx$ is a
substring consistent equivalence relation (SCER) if for two strings $X,Y$, $X
\approx Y$ implies $|X| = |Y|$ and $X[i:j] \approx Y[i:j]$ for all $1 \le i \le
j \le |X|$. In this paper, we propose a generalization of the dictionary
matching problem and present a generalization of the Aho-Corasick algorithm for
the dictionary matching under SCER. We present an algorithm that constructs
SCER automata and an algorithm that performs dictionary matching under SCER by
using the automata. Moreover, we show the time and space complexity of our
algorithms with respect to the size of input strings.
</p></div>
    </summary>
    <updated>2019-09-18T01:25:28Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.07515</id>
    <link href="http://arxiv.org/abs/1909.07515" rel="alternate" type="text/html"/>
    <title>Multiplicative Rank-1 Approximation using Length-Squared Sampling</title>
    <feedworld_mtime>1568764800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jaiswal:Ragesh.html">Ragesh Jaiswal</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kumar:Amit.html">Amit Kumar</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.07515">PDF</a><br/><b>Abstract: </b>We show that the span of $\Omega(\frac{1}{\varepsilon^4})$ rows of any matrix
$A \subset \mathbb{R}^{n \times d}$ sampled according to the length-squared
distribution contains a rank-$1$ matrix $\tilde{A}$ such that $||A -
\tilde{A}||_F^2 \leq (1 + \varepsilon) \cdot ||A - \pi_1(A)||_F^2$, where
$\pi_1(A)$ denotes the best rank-$1$ approximation of $A$ under the Frobenius
norm. Length-squared sampling has previously been used in the context of
rank-$k$ approximation. However, the approximation obtained was additive in
nature. We obtain a multiplicative approximation albeit only for rank-$1$
approximation.
</p></div>
    </summary>
    <updated>2019-09-18T01:25:36Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.07511</id>
    <link href="http://arxiv.org/abs/1909.07511" rel="alternate" type="text/html"/>
    <title>Streaming PTAS for Constrained k-Means</title>
    <feedworld_mtime>1568764800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Goyal:Dishant.html">Dishant Goyal</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jaiswal:Ragesh.html">Ragesh Jaiswal</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kumar:Amit.html">Amit Kumar</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.07511">PDF</a><br/><b>Abstract: </b>We generalise the results of Bhattacharya et al. (Journal of Computing
Systems, 62(1):93-115, 2018) for the list-$k$-means problem defined as -- for a
(unknown) partition $X_1, ..., X_k$ of the dataset $X \subseteq \mathbb{R}^d$,
find a list of $k$-center sets (each element in the list is a set of $k$
centers) such that at least one of $k$-center sets $\{c_1, ..., c_k\}$ in the
list gives an $(1+\varepsilon)$-approximation with respect to the cost function
$\min_{\textrm{permutation } \pi} \left[ \sum_{i=1}^{k} \sum_{x \in X_i} ||x -
c_{\pi(i)}||^2 \right]$. The list-$k$-means problem is important for the
constrained $k$-means problem since algorithms for the former can be converted
to PTAS for various versions of the latter. Following are the consequences of
our generalisations:
</p>
<p>- Streaming algorithm: Our $D^2$-sampling based algorithm running in a single
iteration allows us to design a 2-pass, logspace streaming algorithm for the
list-$k$-means problem. This can be converted to a 4-pass, logspace streaming
PTAS for various constrained versions of the $k$-means problem. To the best of
our knowledge, these are the first constant pass, logspace streaming PTASs for
constrained versions of the $k$-means problem.
</p>
<p>- Faster PTAS under stability: Our generalisation is also useful in $k$-means
clustering scenarios where finding good centers becomes easy once good centers
for a few "bad" clusters have been chosen. One such scenario is clustering
under stability where the number of such bad clusters is a constant. Using the
above idea, we significantly improve the running time of the known algorithm
from $O(dn^3) (k \log{n})^{poly(\frac{1}{\beta}, \frac{1}{\varepsilon})}$ to $O
\left(dn^3 k^{\tilde{O}_{\beta \varepsilon}(\frac{1}{\beta \varepsilon})}
\right)$.
</p></div>
    </summary>
    <updated>2019-09-18T01:24:38Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.07498</id>
    <link href="http://arxiv.org/abs/1909.07498" rel="alternate" type="text/html"/>
    <title>Vanishing-Error Approximate Degree and QMA Complexity</title>
    <feedworld_mtime>1568764800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sherstov:Alexander_A=.html">Alexander A. Sherstov</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Thaler:Justin.html">Justin Thaler</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.07498">PDF</a><br/><b>Abstract: </b>The $\epsilon$-approximate degree of a function $f\colon X \to \{0, 1\}$ is
the least degree of a multivariate real polynomial $p$ such that $|p(x)-f(x)|
\leq \epsilon$ for all $x \in X$. We determine the $\epsilon$-approximate
degree of the element distinctness function, the surjectivity function, and the
permutation testing problem, showing they are $\Theta(n^{2/3}
\log^{1/3}(1/\epsilon))$, $\tilde\Theta(n^{3/4} \log^{1/4}(1/\epsilon))$, and
$\Theta(n^{1/3} \log^{2/3}(1/\epsilon))$, respectively. Previously, these
bounds were known only for constant $\epsilon.$
</p>
<p>We also derive a connection between vanishing-error approximate degree and
quantum Merlin--Arthur (QMA) query complexity. We use this connection to show
that the QMA complexity of permutation testing is $\Omega(n^{1/4})$. This
improves on the previous best lower bound of $\Omega(n^{1/6})$ due to Aaronson
(Quantum Information &amp; Computation, 2012), and comes somewhat close to matching
a known upper bound of $O(n^{1/3})$.
</p></div>
    </summary>
    <updated>2019-09-18T01:20:35Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-09-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.07446</id>
    <link href="http://arxiv.org/abs/1909.07446" rel="alternate" type="text/html"/>
    <title>Three-in-a-Tree in Near Linear Time</title>
    <feedworld_mtime>1568764800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Kai-Yuan Lai, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lu:Hsueh=I.html">Hsueh-I Lu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Thorup:Mikkel.html">Mikkel Thorup</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.07446">PDF</a><br/><b>Abstract: </b>The three-in-a-tree problem is to determine if a simple undirected graph
contains an induced subgraph which is a tree connecting three given vertices.
Based on a beautiful characterization that is proved in more than twenty pages,
Chudnovsky and Seymour [Com-binatorica 2010] gave the previously only known
polynomial-time algorithm, running in $O(mn^2)$ time, to solve the
three-in-a-tree problem on an $n$-vertex $m$-edge graph. Their three-in-a-tree
algorithm has become a critical subroutine in several state-of-the-art graph
recognition and detection algorithms.
</p>
<p>In this paper we solve the three-in-a-tree problem in $\tilde{O}(m)$ time,
leading to improved algorithms for recognizing perfect graphs and detecting
thetas, pyramids, beetles, and odd and even holes. Our result is based on a new
and more constructive characterization than that of Chudnovsky and Seymour. Our
new characterization is stronger than the original, and our proof implies a new
simpler proof for the original characterization. The improved characterization
gains the first factor $n$ in speed. The remaining improvement is based on
dynamic graph algorithms.
</p></div>
    </summary>
    <updated>2019-09-18T01:21:34Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.07420</id>
    <link href="http://arxiv.org/abs/1909.07420" rel="alternate" type="text/html"/>
    <title>Regular Partitions and Their Use in Structural Pattern Recognition</title>
    <feedworld_mtime>1568764800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fiorucci:Marco.html">Marco Fiorucci</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.07420">PDF</a><br/><b>Abstract: </b>Recent years are characterized by an unprecedented quantity of available
network data which are produced at an astonishing rate by an heterogeneous
variety of interconnected sensors and devices. This high-throughput generation
calls for the development of new effective methods to store, retrieve,
understand and process massive network data. In this thesis, we tackle this
challenge by introducing a framework to summarize large graphs based on
Szemer\'edi's Regularity Remma (RL), which roughly states that any sufficiently
large graph can almost entirely be partitioned into a bounded number of
random-like bipartite graphs. The partition resulting from the RL gives rise to
a summary, which inherits many of the essential structural properties of the
original graph. We first extend an heuristic version of the RL to improve its
efficiency and its robustness. We use the proposed algorithm to address
graph-based clustering and image segmentation tasks. In the second part of the
thesis, we introduce a new heuristic algorithm which is characterized by an
improvement of the summary quality both in terms of reconstruction error and of
noise filtering. We use the proposed heuristic to address the graph search
problem defined under a similarity measure. Finally, we study the linkage among
the regularity lemma, the stochastic block model and the minimum description
length. This study provide us a principled way to develop a graph decomposition
algorithm based on stochastic block model which is fitted using likelihood
maximization.
</p></div>
    </summary>
    <updated>2019-09-18T01:26:42Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.07413</id>
    <link href="http://arxiv.org/abs/1909.07413" rel="alternate" type="text/html"/>
    <title>On Decoding Cohen-Haeupler-Schulman Tree Codes</title>
    <feedworld_mtime>1568764800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Narayanan:Anand_Kumar.html">Anand Kumar Narayanan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Weidner:Matthew.html">Matthew Weidner</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.07413">PDF</a><br/><b>Abstract: </b>Tree codes, introduced by Schulman, are combinatorial structures essential to
coding for interactive communication. An infinite family of tree codes with
both rate and distance bounded by positive constants is called asymptotically
good. Rate being constant is equivalent to the alphabet size being constant.
Schulman proved that there are asymptotically good tree code families using the
Lovasz local lemma, yet their explicit construction remains an outstanding open
problem. In a major breakthrough, Cohen, Haeupler and Schulman constructed
explicit tree code families with constant distance, but over an alphabet
polylogarithmic in the length. Our main result is a randomized polynomial time
decoding algorithm for these codes making novel use of the polynomial method.
The number of errors corrected scales roughly as the block length to the
three-fourths power, falling short of the constant fraction error correction
guaranteed by the constant distance. We further present number theoretic
variants of Cohen-Haeupler-Schulman codes, all correcting a constant fraction
of errors with polylogarithmic alphabet size. Towards efficiently correcting
close to a constant fraction of errors, we propose a speculative convex
optimization approach inspired by compressed sensing.
</p></div>
    </summary>
    <updated>2019-09-18T01:20:25Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-09-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1901.09527</id>
    <link href="http://arxiv.org/abs/1901.09527" rel="alternate" type="text/html"/>
    <title>Envy-free Matchings in Bipartite Graphs and their Applications to Fair Division</title>
    <feedworld_mtime>1568764800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Aigner=Horev:Elad.html">Elad Aigner-Horev</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Segal=Halevi:Erel.html">Erel Segal-Halevi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1901.09527">PDF</a><br/><b>Abstract: </b>A matching in a bipartite graph $G:=(X + Y,E)$ is said to be envy-free if no
unmatched vertex in $X$ is adjacent to a mathced vertex in $Y$. Every perfect
matching is envy-free, but envy-free matchings may exist even when perfect
matchings do not.
</p>
<p>We provide a polynomial-time algorithm for finding an envy-free matching of
maximum cardinality. For edge-weighted bipartite graphs, we provide a
polynomial-time algorithm for finding a maximum-cardinality envy-free matching
of minimum weight.
</p>
<p>We show how envy-free matchings can be used in various fair division problems
with either continuous resources (``cakes'') or discrete ones. In particular,
we show a symmetric algorithm for proportional cake-cutting, and an algorithm
for $1$-out-of-$(2n-2)$ maximin-share allocation of discrete objects among $n$
agents.
</p></div>
    </summary>
    <updated>2019-09-18T01:24:09Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/125</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/125" rel="alternate" type="text/html"/>
    <title>TR19-125 |  Hardness Amplification of Optimization Problems 	 | 

	Elazar Goldenberg, 

	Karthik  C. S.</title>
    <summary>In this paper, we prove a general hardness amplification scheme for optimization problems based on the technique of direct products.
  
We say that an optimization problem $\Pi$ is direct product feasible if it is possible to efficiently aggregate any $k$ instances of $\Pi$ and form one large instance of $\Pi$ such that given an optimal feasible solution to the larger instance, we can efficiently find optimal feasible solutions to all the $k$ smaller instances. Given a direct product feasible optimization problem $\Pi$, our hardness amplification theorem may be informally stated as follows:
  
If there is a distribution $\mathcal{D}$ over instances of $\Pi$ of size $n$ such that every randomized algorithm running in time $t(n)$ fails to solve $\Pi$ on $\frac{1}{\alpha(n)}$ fraction of inputs sampled from $\mathcal{D}$, then, assuming some relationships on $\alpha(n)$ and $t(n)$, there is a distribution $\mathcal{D}'$ over instances of $\Pi$ of size $O(n\cdot \alpha(n))$ such that every randomized algorithm running in time $\frac{t(n)}{poly(\alpha(n))}$ fails to solve $\Pi$ on $\frac{99}{100}$ fraction of inputs sampled from $\mathcal{D}'$.
  
As a consequence of the above theorem, we show hardness amplification of problems in various classes such as NP-hard problems like Max-Clique, Knapsack, and Max-SAT, problems in P such as Longest Common Subsequence, Edit Distance, Matrix Multiplication, and even problems in TFNP such as Factoring and computing Nash equilibrium.</summary>
    <updated>2019-09-17T23:59:55Z</updated>
    <published>2019-09-17T23:59:55Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-09-18T11:20:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/124</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/124" rel="alternate" type="text/html"/>
    <title>TR19-124 |  Testing Odd Direct Sums Using High Dimensional Expanders | 

	Roy Gotlib, 

	Tali Kaufman</title>
    <summary>In this work, using methods from high dimensional expansion, we show that the property of $k$-direct-sum is testable for odd values of $k$ . Previous work of Kaufman and Lubotzky could inherently deal only with the case that $k$ is even, using a reduction to linearity testing.
Interestingly, our work is the first to combine the topological notion of high dimensional expansion (called co-systolic expansion) with the combinatorial/spectral notion of high dimensional expansion (called colorful expansion) to obtain the result.

The classical $k$-direct-sum problem applies to the complete complex; Namely it considers a function defined over all $k$-subsets of some $n$ sized universe. Our result here applies to any collection of $k$-subsets of an $n$-universe, assuming this collection of subsets forms a high dimensional expander.</summary>
    <updated>2019-09-17T00:04:22Z</updated>
    <published>2019-09-17T00:04:22Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-09-18T11:20:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/123</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/123" rel="alternate" type="text/html"/>
    <title>TR19-123 |  On the Hardness of Robust Classification | 

	Pascale Gourdeau, 

	Varun Kanade, 

	Marta Kwiatkowska, 

	James Worrell</title>
    <summary>It is becoming increasingly important to understand the vulnerability of machine learning models to adversarial attacks. In this paper we study the feasibility of robust learning from the perspective of computational learning theory, considering both sample and computational complexity. In particular, our definition of robust learnability requires polynomial sample complexity. We start with two negative results. We show that no non-trivial concept class can be robustly learned in the distribution-free setting against an adversary who can perturb just a single input bit. We show moreover that the class of monotone conjunctions cannot be robustly learned under the uniform distribution against an adversary who can perturb $\omega(\log n)$ input bits. However if the adversary is restricted to perturbing $O(\log n)$ bits, then the class of monotone conjunctions can be robustly learned with respect to a general class of distributions (that includes the uniform distribution). Finally, we provide a simple proof of the computational hardness of robust learning on the boolean hypercube. Unlike previous results of this nature, our result does not rely on another computational model (e.g. the statistical query model) nor on any hardness assumption other than the existence of a hard learning problem in the PAC framework.</summary>
    <updated>2019-09-17T00:00:40Z</updated>
    <published>2019-09-17T00:00:40Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-09-18T11:20:36Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.07347</id>
    <link href="http://arxiv.org/abs/1909.07347" rel="alternate" type="text/html"/>
    <title>Extending simple drawings with one edge is hard</title>
    <feedworld_mtime>1568678400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Arroyo:Alan.html">Alan Arroyo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Klute:Fabian.html">Fabian Klute</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Parada:Irene.html">Irene Parada</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Seidel:Raimund.html">Raimund Seidel</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vogtenhuber:Birgit.html">Birgit Vogtenhuber</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wiedera:Tilo.html">Tilo Wiedera</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.07347">PDF</a><br/><b>Abstract: </b>A simple drawing $D(G)$ of a graph $G = (V,E)$ is a drawing in which two
edges have at most one point in common that is either an endpoint or a proper
crossing. An edge $e$ from the complement of $ G $ can be inserted into $D(G)$
if there exists a simple drawing of $G' = (V, E\cup \{e\})$ containing $D(G)$
as a subdrawing. We show that it is NP-complete to decide whether a given edge
can be inserted into a simple drawing, by this solving an open question by
Arroyo, Derka, and Parada.
</p></div>
    </summary>
    <updated>2019-09-17T23:56:01Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-09-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.07326</id>
    <link href="http://arxiv.org/abs/1909.07326" rel="alternate" type="text/html"/>
    <title>Multitype Integer Monoid Optimization and Applications</title>
    <feedworld_mtime>1568678400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Dušan Knop, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kouteck=yacute=:Martin.html">Martin Koutecký</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Levin:Asaf.html">Asaf Levin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mnich:Matthias.html">Matthias Mnich</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Onn:Shmuel.html">Shmuel Onn</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.07326">PDF</a><br/><b>Abstract: </b>Configuration integer programs (IP) have been key in the design of algorithms
for NP-hard high-multiplicity problems since the pioneering work of Gilmore and
Gomory [Oper. Res., 1961]. Configuration IPs have a variable for each possible
configuration, which describes a placement of items into a location, and whose
value corresponds to the number of locations with that placement. In high
multiplicity problems items come in types, and are represented succinctly by a
vector of multiplicities; solving the configuration IP then amounts to deciding
whether the input vector of multiplicities of items of each type can be
decomposed into a given number of configurations.
</p>
<p>We make this implicit notion explicit by observing that the set of all input
vectors decomposable into configurations forms a monoid, and solving the
configuration IP is the Monoid Decomposition problem. Motivated by
applications, we enrich this problem in two ways. First, sometimes each
configuration additionally has an objective value, yielding an optimization
problem of finding a "best" decomposition under the given objective. Second,
there are often different types of configurations for different types of
locations. The resulting problem is to optimize over decompositions of the
input multiplicity vector into configurations of several types, and we call it
Multitype Integer Monoid Optimization, or MIMO.
</p>
<p>We develop fast exact algorithms for various MIMO with few or many location
types and with various objectives. Our algorithms build on a novel proximity
theorem connecting the solutions of a certain configuration IP to those of its
continuous relaxation. We then cast several fundamental scheduling and bin
packing problems as MIMOs, and thereby obtain new or substantially faster
algorithms for them.
</p>
<p>We complement our positive algorithmic results by hardness results.
</p></div>
    </summary>
    <updated>2019-09-17T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.07313</id>
    <link href="http://arxiv.org/abs/1909.07313" rel="alternate" type="text/html"/>
    <title>Solving Strong-Substitutes Product-Mix Auctions</title>
    <feedworld_mtime>1568678400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Elizabeth Baldwin, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Goldberg:Paul_W=.html">Paul W. Goldberg</a>, Paul Klemperer, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lock:Edwin.html">Edwin Lock</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.07313">PDF</a><br/><b>Abstract: </b>This paper develops algorithms to solve strong-substitutes product-mix
auctions. That is, it finds competitive equilibrium prices and quantities for
agents who use this auction's bidding language to truthfully express their
strong-substitutes preferences over an arbitrary number of goods, each of which
is available in multiple discrete units. (Strong substitutes preferences are
also known, in other literatures, as $M^\natural$-concave, matroidal and
well-layered maps, and valuated matroids). Our use of the bidding language, and
the information it provides, contrasts with existing algorithms that rely on
access to a valuation or demand oracle to find equilibrium.
</p>
<p>We compute market-clearing prices using algorithms that apply existing
submodular minimisation methods. Allocating the supply among the bidders at
these prices then requires solving a novel constrained matching problem. Our
algorithm iteratively simplifies the allocation problem, perturbing bids and
prices in a way that resolves tie-breaking choices created by bids that can be
accepted on more than one good. We provide practical running time bounds on
both price-finding and allocation, and illustrate experimentally that our
allocation mechanism is practical.
</p></div>
    </summary>
    <updated>2019-09-17T23:25:50Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.07251</id>
    <link href="http://arxiv.org/abs/1909.07251" rel="alternate" type="text/html"/>
    <title>Note on distributed certification of minimum spanning trees</title>
    <feedworld_mtime>1568678400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Feuilloley:Laurent.html">Laurent Feuilloley</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.07251">PDF</a><br/><b>Abstract: </b>A distributed proof (also known as local certification, or proof-labeling
scheme) is a mechanism to certify that the solution to a graph problem is
correct. It takes the form of an assignment of labels to the nodes, that can be
checked locally. There exists such a proof for the minimum spanning tree
problem, using $O(\log n \log W)$ bit labels (where $n$ is the number of nodes
in the graph, and $W$ is the largest weight of an edge). This is due to Korman
and Kutten who describe it in concise and formal manner in [Korman and Kutten
07]. In this note, we propose a more intuitive description of the result, as
well as a gentle introduction to the problem.
</p></div>
    </summary>
    <updated>2019-09-17T23:37:26Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.07141</id>
    <link href="http://arxiv.org/abs/1909.07141" rel="alternate" type="text/html"/>
    <title>Disproportionate division</title>
    <feedworld_mtime>1568678400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Logan Crew, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Narayanan:Bhargav.html">Bhargav Narayanan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Spirkl:Sophie.html">Sophie Spirkl</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.07141">PDF</a><br/><b>Abstract: </b>We study the disproportionate version of the classical cake-cutting problem:
how efficiently can we divide a cake, here $[0,1]$, among $n$ agents with
different demands $\alpha_1, \alpha_2, \dots, \alpha_n$ summing to $1$? When
all the agents have equal demands of $\alpha_1 = \alpha_2 = \dots = \alpha_n =
1/n$, it is well-known that there exists a fair division with $n-1$ cuts, and
this is optimal. For arbitrary demands on the other hand, folklore arguments
from algebraic topology show that $O(n\log n)$ cuts suffice, and this has been
the state of the art for decades. Here, we improve the state of affairs in two
ways: we prove that disproportionate division may always be achieved with
$3n-4$ cuts, and give an effective combinatorial procedure to construct such a
division. We also offer a topological conjecture that implies that $2n-2$ cuts
suffice in general, which would be optimal.
</p></div>
    </summary>
    <updated>2019-09-17T23:45:52Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-09-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.07093</id>
    <link href="http://arxiv.org/abs/1909.07093" rel="alternate" type="text/html"/>
    <title>How to Morph a Tree on a Small Grid</title>
    <feedworld_mtime>1568678400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Barrera=Cruz:Fidel.html">Fidel Barrera-Cruz</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Borrazzo:Manuel.html">Manuel Borrazzo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lozzo:Giordano_Da.html">Giordano Da Lozzo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Battista:Giuseppe_Di.html">Giuseppe Di Battista</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Frati:Fabrizio.html">Fabrizio Frati</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Patrignani:Maurizio.html">Maurizio Patrignani</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Roselli:Vincenzo.html">Vincenzo Roselli</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.07093">PDF</a><br/><b>Abstract: </b>In this paper we study planar morphs between straight-line planar grid
drawings of trees. A morph consists of a sequence of morphing steps, where in a
morphing step vertices move along straight-line trajectories at constant speed.
We show how to construct planar morphs that simultaneously achieve a reduced
number of morphing steps and a polynomially-bounded resolution. We assume that
both the initial and final drawings lie on the grid and we ensure that each
morphing step produces a grid drawing; further, we consider both upward
drawings of rooted trees and drawings of arbitrary trees.
</p></div>
    </summary>
    <updated>2019-09-17T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-09-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.07059</id>
    <link href="http://arxiv.org/abs/1909.07059" rel="alternate" type="text/html"/>
    <title>Improved Strong Spatial Mixing for Colorings on Trees</title>
    <feedworld_mtime>1568678400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Efthymiou:Charilaos.html">Charilaos Efthymiou</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Galanis:Andreas.html">Andreas Galanis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hayes:Thomas_P=.html">Thomas P. Hayes</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Stefankovic:Daniel.html">Daniel Stefankovic</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vigoda:Eric.html">Eric Vigoda</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.07059">PDF</a><br/><b>Abstract: </b>Strong spatial mixing (SSM) is a form of correlation decay that has played an
essential role in the design of approximate counting algorithms for spin
systems. A notable example is the algorithm of Weitz (2006) for the hard-core
model on weighted independent sets. We study SSM for the $q$-colorings problem
on the infinite $(d+1)$-regular tree. Weak spatial mixing (WSM) captures
whether the influence of the leaves on the root vanishes as the height of the
tree grows. Jonasson (2002) established WSM when $q&gt;d+1$. In contrast, in SSM,
we first fix a coloring on a subset of internal vertices, and we again ask if
the influence of the leaves on the root is vanishing. It was known that SSM
holds on the $(d+1)$-regular tree when $q&gt;\alpha d$ where $\alpha\approx
1.763...$ is a constant that has arisen in a variety of results concerning
random colorings. Here we improve on this bound by showing SSM for $q&gt;1.59d$.
Our proof establishes an $L^2$ contraction for the BP operator. For the
contraction we bound the norm of the BP Jacobian by exploiting combinatorial
properties of the coloring of the tree.
</p></div>
    </summary>
    <updated>2019-09-17T23:36:06Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.07013</id>
    <link href="http://arxiv.org/abs/1909.07013" rel="alternate" type="text/html"/>
    <title>Proceedings of the 27th International Symposium on Graph Drawing and Network Visualization (GD 2019)</title>
    <feedworld_mtime>1568678400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Archambault:Daniel.html">Daniel Archambault</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/T=oacute=th:Csaba_D=.html">Csaba D. Tóth</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.07013">PDF</a><br/><b>Abstract: </b>This is the arXiv index for the electronic proceedings of GD 2019, which
contains the peer-reviewed and revised accepted papers with an optional
appendix. Proceedings (without appendices) are also to be published by Springer
in the Lecture Notes in Computer Science series.
</p></div>
    </summary>
    <updated>2019-09-17T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-09-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.06988</id>
    <link href="http://arxiv.org/abs/1909.06988" rel="alternate" type="text/html"/>
    <title>Explicit near-Ramanujan graphs of every degree</title>
    <feedworld_mtime>1568678400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mohanty:Sidhanth.html">Sidhanth Mohanty</a>, Ryan O'Donnell, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Paredes:Pedro.html">Pedro Paredes</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.06988">PDF</a><br/><b>Abstract: </b>For every constant $d \geq 3$ and $\epsilon &gt; 0$, we give a deterministic
$\mathrm{poly}(n)$-time algorithm that outputs a $d$-regular graph on
$\Theta(n)$ vertices that is $\epsilon$-near-Ramanujan; i.e., its eigenvalues
are bounded in magnitude by $2\sqrt{d-1} + \epsilon$ (excluding the single
trivial eigenvalue of~$d$).
</p></div>
    </summary>
    <updated>2019-09-17T23:23:41Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.06811</id>
    <link href="http://arxiv.org/abs/1909.06811" rel="alternate" type="text/html"/>
    <title>Noisy Beeping Networks</title>
    <feedworld_mtime>1568678400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Yagel Ashkenazi, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gelles:Ran.html">Ran Gelles</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Leshem:Amir.html">Amir Leshem</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.06811">PDF</a><br/><b>Abstract: </b>We introduce noisy beeping networks, where nodes have limited communication
capabilities, namely, they can only emit energy or sense the channel for
energy. Furthermore, imperfections may cause devices to malfunction with some
fixed probability when sensing the channel, which amounts to deducing a noisy
received transmission. Such noisy networks have implications for
ultra-lightweight sensor networks and biological systems.
</p>
<p>We show how to compute tasks in a noise-resilient manner over noisy beeping
networks of arbitrary structure. In particular, we transform any algorithm that
assumes a noiseless beeping network (of size $n$) into a noise-resilient
version while incurring a multiplicative overhead of only $O(\log n)$ in its
round complexity, with high probability. We show that our coding is optimal for
some tasks, such as node-coloring of a clique.
</p>
<p>We further show how to simulate a large family of algorithms designed for
distributed networks in the CONGEST($B$) model over a noisy beeping network.
The simulation succeeds with high probability and incurs an asymptotic
multiplicative overhead of $O(B\cdot \Delta \cdot \min(n,\Delta^2))$ in the
round complexity, where $\Delta$ is the maximal degree of the network. The
overhead is tight for certain graphs, e.g., a clique. Further, this simulation
implies a constant overhead coding for constant-degree networks.
</p></div>
    </summary>
    <updated>2019-09-17T23:26:38Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.06794</id>
    <link href="http://arxiv.org/abs/1909.06794" rel="alternate" type="text/html"/>
    <title>Run-Length Encoding in a Finite Universe</title>
    <feedworld_mtime>1568678400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Larsson:N=_Jesper.html">N. Jesper Larsson</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.06794">PDF</a><br/><b>Abstract: </b>Text compression schemes and compact data structures usually combine
sophisticated probability models with basic coding methods whose average
codeword length closely match the entropy of known distributions. In the
frequent case where basic coding represents run-lengths of outcomes that have
probability $p$, i.e.\@ the geometric distribution $\Pr(i)=p^i(1-p)$, a
\emph{Golomb code} is an optimal instantaneous code, which has the additional
advantage that codewords can be computed using only an integer parameter
calculated from $p$, without need for a large or sophisticated data structure.
Golomb coding does not, however, gracefully handle the case where run-lengths
are bounded by a known integer~$n$. In this case, codewords allocated for the
case $i&gt;n$ are wasted. While negligible for large $n$, this makes Golomb coding
unattractive in situations where $n$ is recurrently small, e.g., when
representing many short lists of integers drawn from limited ranges, or when
the range of $n$ is narrowed down by a recursive algorithm. We address the
problem of choosing a code for this case, considering efficiency from both
information-theoretic and computational perspectives, and arrive at a simple
code that allows computing a codeword using only $O(1)$ simple computer
operations and $O(1)$ machine words. We demonstrate experimentally that the
resulting representation length is very close (equal in a majority of tested
cases) to the optimal Huffman code, to the extent that the expected difference
is practically negligible. We describe efficient branch-free implementation of
encoding and decoding.
</p></div>
    </summary>
    <updated>2019-09-17T23:41:01Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.06747</id>
    <link href="http://arxiv.org/abs/1909.06747" rel="alternate" type="text/html"/>
    <title>Algorithms for Manipulating Sequential Allocation</title>
    <feedworld_mtime>1568678400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/x/Xiao:Mingyu.html">Mingyu Xiao</a>, Jiaxing Ling <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.06747">PDF</a><br/><b>Abstract: </b>Sequential allocation is a simple and widely studied mechanism to allocate
indivisible items in turns to agents according to a pre-specified picking
sequence of agents. At each turn, the current agent in the picking sequence
picks its most preferred item among all items having not been allocated yet.
This problem is well-known to be not strategyproof, i.e., an agent may get more
utility by reporting an untruthful preference ranking of items. It arises the
problem: how to find the best response of an agent?
</p>
<p>It is known that this problem is polynomially solvable for only two agents
and NP-complete for arbitrary number of agents.
</p>
<p>The computational complexity of this problem with three agents was left as an
open problem. In this paper, we give a novel algorithm that solves the problem
in polynomial time for each fixed number of agents. We also show that an agent
can always get at least half of its optimal utility by simply using its
truthful preference as the response.
</p></div>
    </summary>
    <updated>2019-09-17T23:29:39Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.06653</id>
    <link href="http://arxiv.org/abs/1909.06653" rel="alternate" type="text/html"/>
    <title>A Tree Structure For Dynamic Facility Location</title>
    <feedworld_mtime>1568678400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Goranci:Gramoz.html">Gramoz Goranci</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Henzinger:Monika.html">Monika Henzinger</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Leniowski:Dariusz.html">Dariusz Leniowski</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.06653">PDF</a><br/><b>Abstract: </b>We study the metric facility location problem with client insertions and
deletions. This setting differs from the classic dynamic facility location
problem, where the set of clients remains the same, but the metric space can
change over time. We show a deterministic algorithm that maintains a constant
factor approximation to the optimal solution in worst-case time $\tilde
O(2^{O(\kappa^2)})$ per client insertion or deletion in metric spaces while
answering queries about the cost in $O(1)$ time, where $\kappa$ denotes the
doubling dimension of the metric. For metric spaces with bounded doubling
dimension, the update time is polylogarithmic in the parameters of the problem.
</p></div>
    </summary>
    <updated>2019-09-17T23:23:52Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.06535</id>
    <link href="http://arxiv.org/abs/1909.06535" rel="alternate" type="text/html"/>
    <title>Private and Atomic Exchange of Assets over Zero Knowledge Based Payment Ledger</title>
    <feedworld_mtime>1568678400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gao:Zhimin.html">Zhimin Gao</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/x/Xu:Lei.html">Lei Xu</a>, Keshav Kasichainula, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Lin.html">Lin Chen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Carbunar:Bogdan.html">Bogdan Carbunar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shi:Weidong.html">Weidong Shi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.06535">PDF</a><br/><b>Abstract: </b>Bitcoin brings a new type of digital currency that does not rely on a central
system to maintain transactions. By benefiting from the concept of
decentralized ledger, users who do not know or trust each other can still
conduct transactions in a peer-to-peer manner. Inspired by Bitcoin, other
cryptocurrencies were invented in recent years such as Ethereum, Dash, Zcash,
Monero, Grin, etc. Some of these focus on enhancing privacy for instance crypto
note or systems that apply the similar concept of encrypted notes used for
transactions to enhance privacy (e.g., Zcash, Monero). However, there are few
mechanisms to support the exchange of privacy-enhanced notes or assets on the
chain, and at the same time preserving the privacy of the exchange operations.
Existing approaches for fair exchanges of assets with privacy mostly rely on
off-chain/side-chain, escrow or centralized services. Thus, we propose a
solution that supports oblivious and privacy-protected fair exchange of crypto
notes or privacy enhanced crypto assets. The technology is demonstrated by
extending zero-knowledge based crypto notes. To address "privacy" and
"multi-currency", we build a new zero-knowledge proving system and extend note
format with new property to represent various types of tokenized assets or
cryptocurrencies. By extending the payment protocol, exchange operations are
realized through privacy enhanced transactions (e.g., shielded transactions).
Based on the possible scenarios during the exchange operation, we add new
constraints and conditions to the zero-knowledge proving system used for
validating transactions publicly.
</p></div>
    </summary>
    <updated>2019-09-17T23:41:06Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.06524</id>
    <link href="http://arxiv.org/abs/1909.06524" rel="alternate" type="text/html"/>
    <title>A Generalized Randomized Rank-Revealing Factorization</title>
    <feedworld_mtime>1568678400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Ballard:Grey.html">Grey Ballard</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Demmel:James.html">James Demmel</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dumitriu:Ioana.html">Ioana Dumitriu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rusciano:Alexander.html">Alexander Rusciano</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.06524">PDF</a><br/><b>Abstract: </b>We introduce a Generalized Randomized QR-decomposition that may be applied to
arbitrary products of matrices and their inverses, without needing to
explicitly compute the products or inverses. This factorization is a critical
part of a communication-optimal spectral divide-and-conquer algorithm for the
nonsymmetric eigenvalue problem. In this paper, we establish that this
randomized QR-factorization satisfies the strong rank-revealing properties. We
also formally prove its stability, making it suitable in applications. Finally,
we present numerical experiments which demonstrate that our theoretical bounds
capture the empirical behavior of the factorization.
</p></div>
    </summary>
    <updated>2019-09-17T23:27:47Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.06485</id>
    <link href="http://arxiv.org/abs/1909.06485" rel="alternate" type="text/html"/>
    <title>Multi-Perspective, Simultaneous Embedding</title>
    <feedworld_mtime>1568678400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Md Iqbal Hossain, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Huroyan:Vahan.html">Vahan Huroyan</a>, Stephen Kobourov, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Navarrete:Raymundo.html">Raymundo Navarrete</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.06485">PDF</a><br/><b>Abstract: </b>We describe a method for simultaneous visualization of multiple pairwise
distances in 3 dimensional (3D) space. Given the distance matrices that
correspond to 2 dimensional projections of a 3 dimensional object (dataset) the
goal is to recover the 3 dimensional object (dataset). We propose an approach
that uses 3D to place the points, along with projections (planes) that preserve
each of the given distance matrices. Our multi-perspective, simultaneous
embedding (MPSE) method is based on non-linear dimensionality reduction that
generalizes multidimensional scaling. We consider two versions of the problem:
in the first one we are given the input distance matrices and the projections
(e.g., if we have 3 different projections we can use the three orthogonal
directions of the unit cube). In the second version of the problem we also
compute the best projections as part of the optimization. We experimentally
evaluate MPSE using synthetic datasets that illustrate the quality of the
resulting solutions. Finally, we provide a functional prototype which
implements both settings.
</p></div>
    </summary>
    <updated>2019-09-17T23:39:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.06463</id>
    <link href="http://arxiv.org/abs/1909.06463" rel="alternate" type="text/html"/>
    <title>Optimization on the Surface of the (Hyper)-Sphere</title>
    <feedworld_mtime>1568678400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Raman:Parameswaran.html">Parameswaran Raman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yang:Jiasen.html">Jiasen Yang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.06463">PDF</a><br/><b>Abstract: </b>Thomson problem is a classical problem in physics to study how $n$ number of
charged particles distribute themselves on the surface of a sphere of $k$
dimensions. When $k=2$, i.e. a 2-sphere (a circle), the particles appear at
equally spaced points. Such a configuration can be computed analytically.
However, for higher dimensions such as $k \ge 3$, i.e. the case of 3-sphere
(standard sphere), there is not much that is understood analytically. Finding
global minimum of the problem under these settings is particularly tough since
the optimization problem becomes increasingly computationally intensive with
larger values of $k$ and $n$. In this work, we explore a wide variety of
numerical optimization methods to solve the Thomson problem. In our empirical
study, we find stochastic gradient based methods (SGD) to be a compelling
choice for this problem as it scales well with the number of points.
</p></div>
    </summary>
    <updated>2019-09-17T23:57:17Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-09-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.06457</id>
    <link href="http://arxiv.org/abs/1909.06457" rel="alternate" type="text/html"/>
    <title>Linear Size Planar Manhattan Network for Convex Point Sets</title>
    <feedworld_mtime>1568678400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jana:Satyabrata.html">Satyabrata Jana</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Maheshwari:Anil.html">Anil Maheshwari</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Roy:Sasanka.html">Sasanka Roy</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.06457">PDF</a><br/><b>Abstract: </b>Let $G = (V, E)$ be an edge-weighted geometric graph such that every edge is
horizontal or vertical. The weight of an edge $uv \in E$ is its length. Let $
W_G (u,v)$ denote the length of a shortest path between a pair of vertices $u$
and $v$ in $G$. The graph $G$ is said to be a Manhattan network for a given
point set $ P $ in the plane if $P \subseteq V$ and $\forall p,q \in P$, $ W_G
(p,q)=|pq|_1$. In addition to $ P$, graph $G$ may also include a set $T$ of
Steiner points in its vertex set $V$. In the Manhattan network problem, the
objective is to construct a Manhattan network of small size for a set of $ n $
points. This problem was first considered by Gudmundsson et
al.\cite{gudmundsson2007small}. They give a construction of a Manhattan network
of size $\Theta(n \log n)$ for general point set in the plane. We say a
Manhattan network is planar if it can be embedded in the plane without any edge
crossings. In this paper, we construct a linear size planar Manhattan network
for convex point set in linear time using $\mathcal{ O}(n)$ Steiner points. We
also show that, even for convex point set, the construction in Gudmundsson et
al. \cite{gudmundsson2007small} needs $\Omega (n \log n)$ Steiner points and
the network may not be planar.
</p></div>
    </summary>
    <updated>2019-09-17T23:52:08Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-09-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.06444</id>
    <link href="http://arxiv.org/abs/1909.06444" rel="alternate" type="text/html"/>
    <title>Local Decode and Update for Big Data Compression</title>
    <feedworld_mtime>1568678400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vatedka:Shashank.html">Shashank Vatedka</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tchamkerten:Aslan.html">Aslan Tchamkerten</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.06444">PDF</a><br/><b>Abstract: </b>This paper investigates data compression that simultaneously allows local
decoding and local update. The main result is a universal compression scheme
for memoryless sources with the following features. The rate can be made
arbitrarily close to the entropy of the underlying source, contiguous fragments
of the source can be recovered or updated by probing or modifying a number of
codeword bits that is on average linear in the size of the fragment, and the
overall encoding and decoding complexity is quasilinear in the blocklength of
the source. In particular, the local decoding or update of a single message
symbol can be performed by probing or modifying a constant number of codeword
bits. This latter part improves over previous best known results for which
local decodability or update efficiency grows logarithmically with blocklength.
</p></div>
    </summary>
    <updated>2019-09-17T23:35:50Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.06437</id>
    <link href="http://arxiv.org/abs/1909.06437" rel="alternate" type="text/html"/>
    <title>The Computational Complexity of Finding Temporal Paths under Waiting Time Constraints</title>
    <feedworld_mtime>1568678400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Casteigts:Arnaud.html">Arnaud Casteigts</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Himmel:Anne=Sophie.html">Anne-Sophie Himmel</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Molter:Hendrik.html">Hendrik Molter</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zschoche:Philipp.html">Philipp Zschoche</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.06437">PDF</a><br/><b>Abstract: </b>Computing a (shortest) path between two vertices in a graph is one of the
most fundamental primitive in graph algorithmics. In recent years, the study of
paths in temporal graphs, that is, graphs where the vertex set remains static
but the edge set may change over time, gained more and more attention. In a
nutshell, temporal paths have to respect time, that is, they may only move
forward in time. More formally, the time edges used by a temporal path either
need to have increasing or non-decreasing time stamps. In is well known that
computing temporal paths is polynomial-time solvable. We study a natural
variant, where temporal paths may only dwell a certain given amount of time
steps in any vertex, which we call restless temporal paths. This small
modification creates a significant change in the computational complexity of
the task of finding temporal paths. We show that finding restless temporal
paths is NP-complete and give a thorough analysis of the (parameterized)
computational complexity of this problem. In particular, we show that problem
remains computationally hard on temporal graphs with three layers and is
W[1]-hard when parameterized by the feedback vertex number of the underlying
graph. On the positive side, we give an efficient (FPT) algorithm to find short
restless temporal paths that has an asymptotically optimal running time
assuming the Exponential Time Hypothesis.
</p></div>
    </summary>
    <updated>2019-09-17T23:20:33Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-09-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.06435</id>
    <link href="http://arxiv.org/abs/1909.06435" rel="alternate" type="text/html"/>
    <title>A Random Network Model for the Analysis of Blockchain Designs with Communication Delay</title>
    <feedworld_mtime>1568678400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pinz=oacute=n:Carlos.html">Carlos Pinzón</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rocha:Camilo.html">Camilo Rocha</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Finke:Jorge.html">Jorge Finke</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.06435">PDF</a><br/><b>Abstract: </b>This paper proposes a random network model for blockchains, a distributed
hierarchical data structure of blocks that has found several applications in
various industries. The model is parametric on two probability distribution
functions governing block production and communication delay, which are key to
capture the complexity of the mechanism used to synchronize the many
distributed local copies of a blockchain. The proposed model is equipped with
simulation algorithms for both bounded and unbounded number of distributed
copies of the blockchain. They are used to study fast blockchain systems, i.e.,
blockchains in which the average time of block production can match the average
time of message broadcasting used for blockchain synchronization. In
particular, the model and the algorithms are useful to understand efficiency
criteria associated with fast blockchains for identifying, e.g., when
increasing the block production will have negative impact on the stability of
the distributed data structure given the network's broadcast delay.
</p></div>
    </summary>
    <updated>2019-09-17T23:38:43Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-17T01:30:00Z</updated>
    </source>
  </entry>
</feed>
