<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2020-06-19T00:22:01Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4859</id>
    <link href="https://www.scottaaronson.com/blog/?p=4859" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4859#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4859" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Justice has no faction</title>
    <summary xml:lang="en-US">(1) To start with some rare good news: I was delighted that the US Supreme Court, in a 5-4 holding led by Chief Justice Roberts (!), struck down the Trump administration’s plan to end DACA (Deferred Action for Childhood Arrivals). Dismantling DACA would’ve been a first step toward deporting 700,000 overwhelmingly blameless and peaceful people from, in […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><div class="wp-block-group"><div class="wp-block-group__inner-container"/></div>



<p>(1) To start with some rare good news: I was delighted that the US Supreme Court, in a 5-4 <a href="https://www.supremecourt.gov/opinions/19pdf/18-587_5ifl.pdf">holding</a> led by Chief Justice Roberts (!), struck down the Trump administration’s plan to end DACA (Deferred Action for Childhood Arrivals). Dismantling DACA would’ve been a first step toward deporting 700,000 overwhelmingly blameless and peaceful people from, in many cases, the only homes they remember, for no particular reason other than to slake the resentment of Trump’s base. Better still was the majority’s argument: that when, by law, a federal agency has to supply a <em>reason</em> for a policy change (in this case, ending DACA), its reason can’t just be blatantly invented <em>post facto</em>.</p>



<p>To connect to my <a href="https://www.scottaaronson.com/blog/?p=4845">last post</a>: I hope this gives some evidence that, if Trump refuses to accept an electoral loss in November, and if it ends up in the Supreme Court as Bush v. Gore did, then Roberts might once again break from the Court’s other four rightists, in favor of the continued survival of the Republic.</p>



<p>(2) Along with Steven Pinker, Scott Alexander, Sam Altman, Jonathan Haidt, Robert Solovay, and others who might be known to this blog’s readership, I decided after reflection to sign a <a href="https://sites.google.com/view/petition-letter-stephen-hsu/home?authuser=0">petition</a> in support of Steve Hsu, a theoretical physicist turned genomics researcher, and the Senior Vice President for Research and Innovation at Michigan State University.</p>



<figure class="wp-block-image"><img alt="Information Processing: Hail to the Chief" src="https://1.bp.blogspot.com/-dVAprDWO_YI/UzGkunExlkI/AAAAAAAAEq4/MuApiqQsX_I/s1600/photo+(4).JPG"/>Hsu is the one on the right.</figure>



<p>Hsu now faces possible firing, because of a social media campaign apparently started by an MSU grad student and SneerClub poster named Kevin Bird.  What are the <a href="https://twitter.com/GradEmpUnion/status/1270829003130261504">charges</a>?  Hsu appeared in 2017 on an alt-right podcast (albeit, one that Noam Chomsky has also appeared on).  On Hsu’s own podcast, he <a href="https://manifoldlearning.com/episode-010-transcript/">interviewed Ron Unz</a>, who despite Jewish birth has become a <a href="https://www.unz.com/runz/american-pravda-holocaust-denial/">nutcase Holocaust denier</a>—yet somehow that topic never came up on the podcast.  Hsu said that, as a scientist, he doesn’t know whether group differences in average IQ have a genetic component, but our commitment to anti-racism should never hinge on questions of biology (a view also espoused by Peter Singer, perhaps the leading liberal moral philosopher of our time).  Hsu has championed genomics research that, in addition to medical uses, <em>might someday</em> help enable embryo screening for traits like IQ.  Finally, Hsu supports the continued use of standardized tests in university admissions (yes, that’s one of the listed charges).</p>



<p>Crucially, <strong>it doesn’t matter</strong> for present purposes if you disagree with many of Hsu’s views. The question is more like: <em>is agreement with Steven Pinker, Jonathan Haidt, and other mild-mannered, Obama-supporting thinkers featured in your local airport bookstore now a firing offense in academia?  And will those who affirm that it is, claim in the next breath to be oppressed, marginalized, the Rebel Alliance?</em></p>



<p>To be fair to the cancelers, I think they have two reasonable arguments in their favor.</p>



<p>The first that they’re “merely” asking for Hsu to step down as vice president, not for him to lose his tenured professorship in physics.  Only <em>professors</em>, say the activists, enjoy academic freedom; <em>administrators</em> need to uphold the values and public image of their university, as Larry Summers learned fifteen years ago.  (And besides, we might add, what intellectual iconoclast in their right mind would ever <em>become</em> a university VP, or want to stay one??)  I’d actually be fine with this if I had any confidence that it was going to end here.  But I don’t.  Given the now-enshrined standards—e.g., that professors hold positions of power, and that the powerful can oppress the powerless, or even do violence to them, just by expressing or entertaining thoughts outside an ever-shrinking range—why should Hsu trust any assurances that he’ll be left alone, if he <em>does</em> go back to being a physics professor?  If the SneerClubbers can cancel him, then how long until they cancel Pinker, or Haidt, or me?  (I <em>hope</em> the SneerClubbers enthusiastically embrace those ideas!  If they do, then no one ever again gets to call me paranoid about Red Guards behind every bush.)</p>



<p>The second reasonable argument is that, as far as I can tell, Hsu really did grant undeserved legitimacy to a Holocaust denier, via a friendly interview about other topics on his podcast.  I think it would help if, without ceding a word that he doesn’t believe, Hsu were now to denounce racism, Holocaust denial, and specifically Ron Unz’s flirtation with Holocaust denial in the strongest possible terms, and explain why he didn’t bring the topic up with his guest (e.g., did he not know Unz’s views?).</p></div>
    </content>
    <updated>2020-06-18T21:35:08Z</updated>
    <published>2020-06-18T21:35:08Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Obviously I'm Not Defending Aaronson"/>
    <category scheme="https://www.scottaaronson.com/blog" term="The Fate of Humanity"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2020-06-18T22:06:37Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-27705661.post-785371757594389601</id>
    <link href="http://processalgebra.blogspot.com/feeds/785371757594389601/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=27705661&amp;postID=785371757594389601" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/785371757594389601" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/785371757594389601" rel="self" type="application/atom+xml"/>
    <link href="http://processalgebra.blogspot.com/2020/06/an-interview-with-hans-huttel-concur.html" rel="alternate" type="text/html"/>
    <title>An interview with Hans Hüttel, CONCUR Test-of-Time Award recipient</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><br/><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US">This post is devoted to the fourth, and last, interview with the <a href="https://concur2020.forsyte.at/test-of-time/index.html">colleagues</a> who were selected for the first edition of the CONCUR  Test-of-Time Award. (See <a href="https://processalgebra.blogspot.com/2020/04/an-interview-with-davide-sangiorgi.html">here</a> for the interview with <a href="http://www.cs.unibo.it/~sangio/">Davide Sangiorgi</a>,  <a href="https://processalgebra.blogspot.com/2020/04/an-interview-with-nancy-lynch-and.html">here</a> for the interview with <a href="https://people.csail.mit.edu/lynch/">Nancy Lynch</a> and <a href="http://profs.sci.univr.it/~segala/">Roberto Segala</a>, and here for the interview with </span></span></span></span></span></span><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US"><a href="http://theory.stanford.edu/~rvg/">Rob van Glabbeek</a></span></span></span></span></span></span>.) In keeping with my previous interviews, I asked  <a href="http://people.cs.aau.dk/~hans/index-eng.html">Hans  Hüttel</a> (Aalborg University, Denmak) a few questions via email and you can find his answers below. </span></span></span></span></span></span><br/><br/><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US">Hans receives the award for his paper</span></span></span></span></span></span><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US"> "Bisimulation Equivalence is Decidable for all Context-Free Processes", which he wrote  with S</span></span></span><span><span style="font-size: x-small;"><span lang="da-DK">ø</span></span></span><span><span style="font-size: x-small;"><span lang="en-US">ren Christensen and Colin Stirling. </span></span></span></span></span></span></span></span></span></span></span></span><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US">S</span></span></span><span><span style="font-size: x-small;"><span lang="da-DK">ø</span></span></span><span><span style="font-size: x-small;"><span lang="en-US">ren moved to industry after finishing his PhD. Colin is now retired.  </span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><br/><br/><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US">Luca: You receive one of the two CONCUR ToT Awards for the period 1990-1993 for the paper</span></span></span><span><span style="font-size: x-small;">  </span></span><span><span style="font-size: x-small;"><span lang="en-US">"Bisimulation Equivalence is Decidable for all Context-Free Processes" you published with S</span></span></span><span><span style="font-size: x-small;"><span lang="da-DK">ø</span></span></span><span><span style="font-size: x-small;"><span lang="en-US">ren Christensen and Colin Stirling at CONCUR 1992. Could you tell us briefly what the context for that work was and how it came about? </span></span></span></span></span></span></div><div align="justify" style="border: none; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="da-DK">Hans: I was working on my PhD which was on the topic of decidability of behavioural equivalences for process calculi that allow processes to have infinite state spaces. Baeten, Bergstra and Klop had proved that strong bisimilarity is in fact decidable for the BPA calculus even though the class of trace languages for BPA is exactly the class of context-free languages. The result only held for normed BPA processes, that is, processes that could always terminate. Colin was my supervisor in Edinburgh, and he suggested that I try to find a simpler proof of that result (much can be said about the original proof, but simple it was not!). This turned out to be really interesting; I met Didier Caucal from IRISA who had found a nice, much shorter proof that relied on finite characterizations and I was able to use his notion of self-bisimilarity to prove that a tableau system for bisimilarity was sound and complete wrt. bisimilary. Jan Friso Groote, who was a PhD student at the CWI at the time, and myself proved that all other known equivalences are undecidable for normed BPA (and therefore </span></span></span><span><span style="font-size: x-small;"><span lang="da-DK"><i>a fortiori</i></span></span></span><span><span style="font-size: x-small;"><span lang="da-DK">also for full, unnormed BPA). But one problem that Colin and I was never able to solve was if the decidability result also held for the full BPA calculus.</span></span></span></span></span></span></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="da-DK">Søren arrived in Edinburgh in 1990 and we shared a flat there, in St Leonards Bank just across from Holyrood Park. We hung out with the same people in the LFCS, many of whom were clever Italians such as Davide Sangiorgi and clever quasi-Italians such as Marcelo Fiore. It is no surprise that Søren and I often discussed our work or that he, given that Colin was also his supervisor, moved on to study decidability problems as well, the only difference being that Søren was mostly interested in the BPP calculus that has parallel composition instead of sequential composition.</span></span></span></span></span></span></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="da-DK">When I left Edinburgh at the end of August of 1991, Colin and I had managed to make some progress on the decidability problem for unnormed BPA. We realised that a finite characterization of the maximal bisimulation </span></span></span><span><span style="font-size: x-small;"><span lang="da-DK"><i>á la</i></span></span></span><span><span style="font-size: x-small;"><span lang="da-DK">Caucal was the way head but the actual characterization escaped us. When I returned for my viva in December, Søren had found an important lemma on finite characterizations and everything fell into place. The decidability result relied on proving that bisimilarity is semi-decidable using the finite characterization; non-bisimilarity was already known to be semi-decidable. </span></span></span></span></span></span></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US">Luca: Both S</span></span></span><span><span style="font-size: x-small;"><span lang="da-DK">ø</span></span></span><span><span style="font-size: x-small;"><span lang="en-US">ren Christensen and you wrote the award-winning paper as PhD students in Edinburgh. Could you tell us about the research environment in Edinburgh at that time, and the influence it had on you then and in the rest of your career? </span></span></span></span></span></span></div><div align="justify" style="border: none; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="da-DK">Hans: The LFCS in Edinburgh was a great place to be at the time. Robin Milner was still around and busy working on the pi-calculus together with Davide Sangiorgi, who was his student at the time. Watching them at the blackboard was interesting, even though the rest of us often could not follow their discussions! Gordon Plotkin was there (and still is, fortunately). Rod Burstall was still active, and so was Mike Fourman. Plus many, many others. There was always someone to talk to, and it was perfectly legitimate to have an interest in basic research. Unlike the other professors, Colin had no background in maths – he was originally a philosopher! – and maybe that was why he was trying to avoid heavy mathematical lingo, trying to be simple and precise in his writing at the same time. I learned a lot from him, also in that respect.</span></span></span></span></span></span></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="da-DK">After Søren returned to Denmark, he left academia and got a job in the private sector. He still lives near Aarhus. Sadly we lost touch with each other, in all likelihood because our lives turned out so different. We got back in touch recently, when we were told about the reward and we look forward to finally meeting each other again. Colin retired recently, and I really hope to see him again, when I am able to travel to Scotland again some day.</span></span></span></span></span></span></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: medium none; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US">Luca: How much of your later work has built on your award-winning papers? What follow-up results of yours are you most proud of and why?</span></span></span></span></span></span></div><div align="justify" style="border: none; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="da-DK">Hans: I worked on decidability issues for another few years after that but there was no-one to talk to in Aalborg, or rather, there was no-one there that shared my interest in the area at the time. What is more, the open problems that remained were major challenges. Some were only solved much later (such as the decidability of bisimilarity for pushdown automata, a result due to Sénizergues, the proof later greatly simplified by Colin) or remain open (such as the decidability of weak bisimilarity for BPA). Eventually I drifted down the slippery slope and became interested in other, related topics, and focused somewhat more directly on program properties. The follow-up result that most directly relates to my paper with Søren and Colin is the result from 1994 that bisimilarity is also the only equivalence that is decidable for BPP. This is a result that I am also quite proud of. It grew out of discussions with Javier Esparza and Yoram Hirshfeld, when I was back in Edinburgh for a while in 1993. Ironically, there was a subtle flaw in the proof that Naoki Kobayashi discovered many years later. Naoki and one of his student found out how to repair the proof, and the three of us co-authored the journal version that came out many years later. The reason why Naoki became interested in BPP was that he was trying to use the calculus as a behavioural type system for a pi-calculus. As it happened, this was also the route that I had taken.</span></span></span></span></span></span></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="da-DK">Those of my later results that I am most proud of have to do with this area: My work on type systems for psi-calculus (CONCUR 2011 and later) and a session type system for bounded name use in the pi-calculus (Acta Informatica 2019). The latter paper also has a CONCUR connection; it grew out of attending a talk by Roland Meyer at CONCUR 2013 and wondering why they were not trying to characterize notions of name-boundedness in the pi-calculus by means of a type system. It turned out that Meyer et al. were not familiar with type systems at all. It took me an awful long time to work out a type-based characterization (using session types), as you can probably tell.</span></span></span></span></span></span></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="da-DK">As you can tell, I have not worked on bisimulation for quite some time. Not that there is anything wrong with bisimulation, of course, but if one wants results that are applicable for automated reasoning about program behaviour, decidability is important. One can then either choose to go for a less expressive model of computation (which is what researchers in the model checking community do) or keep the model of computation and go for sound, but incomplete characterizations of program properties (which is what researchers interested in type systems and related static analysis methods do). I ended up in the latter camp.</span></span></span></span></span></span></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US">Luca: To your mind, what are the most interesting or unexpected uses in the literature of the notions and techniques you developed in "Bisimulation Equivalence is Decidable for all Context-Free Processes"? </span></span></span></span></span></span></div><div align="justify" style="border: none; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="da-DK">Hans: BPA, BPP and similar process calculi can be used as the basis of behavioural type systems, and I am thrilled that my old research interests and my current research interests are so directly related. </span></span></span></span></span></span></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="da-DK">In 2018 I discovered that Vasco Vasconcelos and Peter Thiemann had devised a session type system for a functional programming language in which session types were not regular expressions (which is essentially what they are in the original work by Honda, Kubo and Vasconcelos) but BPA processes. Vasco and Peter knew that type equivalence should be decidable but they were not so familiar with our results from the early 1990s. At POPL 2019 I attended a talk by Andreia Mordido, one of Vasco’s collaborators, and she mentioned our paper from CONCUR 1992! Later that day, I ended up talking to Andreia and Vasco about my work on BPA from all those years ago.</span></span></span></span></span></span></div><div align="justify" style="border: none; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US">Luca: The last forty years have seen a huge amount of work on process algebra and process calculi. However, the emphasis on that field of research within concurrency theory seems to have diminished over the last few years, even in Europe. What advice would you give to a young researcher interested in working on process calculi today? </span></span></span></span></span></span></div><div align="justify" style="border: none; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="da-DK">Hans: That they should still work on process calculi! There remains a lot of interesting work to be done. One reason why research topics drift in and out of focus is simply that researchers lose interest; it is hardly ever the case that a topic runs out of interesting research questions. Another reason is rather grim: Basic research is nowhere near as well-respected as it used to be. If you look at the funding schemes that we have today, only the very successful few can get funding for basic research; I am not among them and it does get frustrating quite often. Most topics these days deal with applied research. There is nothing wrong with applied research per se; some of what I do is on that side of things, but there has to be more to research than that. </span></span></span></span></span></span></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: medium none; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US">Luca: What are the research topics that currently excite you the most?</span></span></span></span></span></span></div><div align="justify" style="border: none; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="da-DK">Hans: I have slowly become more and more interested in programming language theory, and some of my current collaborators have taken a similar route, beginning in concurrency theory, drifting into the world of behavioural type systems and finally wanting to apply all of their skills to actual programming languages. Right now Mario Bravetti, Adrian Francalanza, António Ravara and myself are involved in working on a behavioural type system related to the Mungo tool for a subset of Java. I am fortunately enough to have had three exceptionally clever and productive MSc students involved as well, and this has been extremely helpful. Mungo is in many ways the work of Simon Gay and Ornela Dardha at Glasgow University, and they, too, began their careers working on process calculi.</span></span></span></span></span></span></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: medium none; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US">Luca: You have a keen interest in teaching at university level. Is there anything you think we should do better in conveying the beauty and usefulness of theoretical computer science in general, and concurrency theory in particular, to our students today? Do you have any thoughts you'd like to share with us on how to combine digital resources and in-person meetings in the teaching of subjects in the theory of computing?</span></span></span></span></span></span></div><div align="justify" style="border: none; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="da-DK">Hans: Personally I think there is a tendency to present any academic topic – and in particular topics in the mathematical science, broadly speaking – in such a way that the definitions and theorems appear as if they fell from the heavens, fully formed. As any researcher will know, that is certainly </span></span></span><span><span style="font-size: x-small;"><span lang="da-DK"><i>not </i></span></span></span><span><span style="font-size: x-small;"><span lang="da-DK">how they came about. In this way, we focus a lot on what Imre Lakatos and Karl Popper called the </span></span></span><span><span style="font-size: x-small;"><span lang="da-DK"><i>context of justification. </i></span></span></span><span><span style="font-size: x-small;"><span lang="da-DK">A well-honed presentation of a theory may appear to be beautiful, but in my opinion the actual beauty is the one that one experiences when one has finally understood the theory and understands why the definitions and theorem turned out the way they did – that is, one must understand the </span></span></span><span><span style="font-size: x-small;"><span lang="da-DK"><i>context of discovery.</i></span></span></span><span><span style="font-size: x-small;"><span lang="da-DK">I think problem-based learning (which is something that we talk about a lot at Aalborg University and at Roskilde University) is the key here, because it puts the focus on student-centered active learning.</span></span></span></span></span></span></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="da-DK">I have lectured a lot over the years but since 2013 I have drifted away from traditional lectures towards flipped teaching in which I use pre-recorded podcasts (of my own making) that students can watch whenever they want; I then use the plenary sessions for activities that focus on active learning. I by far prefer having a dialogue with students that focuses on the problems that they encounter to the monologue style of a lecture. All my teaching activities are now flipped and I am happy to say that some of my colleagues are now thinking along similar lines. It is always good to have someone to talk to. </span></span></span></span></span></span><br/><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="da-DK"> </span></span></span></span></span></span></div></div>
    </content>
    <updated>2020-06-18T21:29:00Z</updated>
    <published>2020-06-18T21:29:00Z</published>
    <author>
      <name>Luca Aceto</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/01092671728833265127</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-27705661</id>
      <author>
        <name>Luca Aceto</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/01092671728833265127</uri>
      </author>
      <link href="http://processalgebra.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://processalgebra.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Papers I find interesting---mostly, but not solely, in Process Algebra---, and some fun stuff in Mathematics and Computer Science at large and on general issues related to research, teaching and academic life.</subtitle>
      <title>Process Algebra Diary</title>
      <updated>2020-06-18T21:29:22Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-5834988441622500007</id>
    <link href="https://blog.computationalcomplexity.org/feeds/5834988441622500007/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/06/on-chain-letters-and-pandemics.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/5834988441622500007" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/5834988441622500007" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/06/on-chain-letters-and-pandemics.html" rel="alternate" type="text/html"/>
    <title>On Chain Letters and Pandemics</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div><i>Guest post by Varsha Dani.</i></div><div><br/></div><div>My 11-year-old child received a letter in the mail. "Send a book to the first person named," it said, "then move everyone's name up the list, add your own name and send copies of the letter to six friends. In a few weeks you will receive 36 books from all over the world!". Wow. When I first encountered chain letters in the mid eighties, it was postcards, but even then it hadn't taken me in. Since then I hadn't seen one of these in a long time, but I guess with a lot of people suddenly at home for extended periods, people crave both entertainment and a connection to others. </div><div><br/></div><div>What's wrong with chain letters? Well quite apart from the fact that they are illegal, even a child can comprehend that the number of books (or postcards or other gifts) received must equal the number sent, and that for every participant who does get a rich reward, there will be many who get nothing. </div><div><br/></div><div>But there is another kind of chain communication going around. It is an email, asking the recipient to send a poem or meditation to somebody, and later they will receive many communications of the same sort. How endearing. Poetry. Sweetness and Light. No get-rich-quick pyramid schemes here. What's wrong with that? </div><div><br/></div><div>Of course, it depends on what one means by "wrong". Maybe you like exchanging poetry with strangers. Maybe you don't find it onerous or wish that your spam filter would weed it out. But let's leave aside those issues and look at the math alone. You send the email to two friends, each of whom forwards it to two of their friends and so on. So the number of people the email reaches ostensibly doubles every step. Exponential growth. But in fact that is not what the graph of human connections looks like. Instead, what happens is that the sets of friends overlap, so that after a while the growth stops being exponential and tapers down. </div><div><br/></div><div>Where else have we seen something like that? Oh, right. The pandemic. The virus jumps from infected people to the people they meet, and from them to the people they meet and so on. Initially, that's exponential growth fof new cases, but after a while  it tapers off, forms a peak and then starts to decrease. Why? Because eventually there is overlap in the sets of people that each infected person is "trying" (unintentionally) to infect, and a newly infected person who got the virus from one or many previously infected people is still just one newly infected person.  </div><div><br/></div><div>So the chain letter spreads just like a virus. Indeed if one were to, somewhat fancifully, think of the chain letter as an independent entity whose goal is to self-replicate, then it looks even more like a virus, and, like a virus, it can only achieve its self-replication goal through the help of a host. But here's a way in which it is not like a virus. Once one has got the virus and recovered, one (hopefully) does not get it again. Not so the chain letter, of which one may get many copies over time! So maybe you will get some gifts or poetry, but you will likely also get more requests for them!</div><div><br/></div><div>So what's wrong with the poetry chain email? It depends on your perspective.  To those of you who are wistfully waiting for that Poem from a Stranger, I dedicate the following to you.</div><div><br/></div><hr/><div><br/></div><div><i>An open letter to my 2<sup>n</sup> dearest friends:</i></div><div><br/></div><div>A letter came for me today</div><div>It promised wondrous ends</div><div>If only I would forward it </div><div>To just two other friends.</div><div><br/></div><div>If they in turn should send it on</div><div>to two more that they know,</div><div>the goodwill that we're sending out</div><div>would grow and grow and grow.</div><div><br/></div><div>Is this as pleasant as it seems?</div><div>Alas, dear friends, it's not.</div><div>This exponential growth can lead</div><div>To quite a sticky spot.</div><div><br/></div><div>Friends of friends of friends of mine</div><div>May very well be linked</div><div>The further that the letters go.</div><div>These folks are not distinct!</div><div><br/></div><div>Ensuring there's no overlap</div><div>Is a logistic* pain.</div><div>As you will see, when you receive</div><div>That letter yet again. </div><div><br/></div><div>So while you're stuck at home this year</div><div>And pacing in your room.</div><div>Pick up the phone and make a call</div><div>Or see your friends on Zoom.</div><div><br/></div><div>Your real thoughts would make me smile.</div><div>Chain letters are a con.</div><div>Do everyone a favor and</div><div>Don't send that letter on!</div><div><br/></div><div>--------------</div><div>* Pun intended. <a href="https://en.wikipedia.org/wiki/Logistic_function#In_medicine:_modeling_of_a_pandemic">https://en.wikipedia.org/wiki/Logistic_function#In_medicine:_modeling_of_a_pandemic</a></div><div><br/></div><div><br/></div></div>
    </content>
    <updated>2020-06-18T13:57:00Z</updated>
    <published>2020-06-18T13:57:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2020-06-18T16:42:45Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://gradientscience.org/background/</id>
    <link href="https://gradientscience.org/background/" rel="alternate" type="text/html"/>
    <title>Noise or Signal&amp;#58; The Role of Backgrounds in Image Classification</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a class="bbutton" href="http://arxiv.org/abs/2006.09994" style="float: left;">
<i class="fas fa-file-pdf"/>
    Read the paper
</a>
<a class="bbutton" href="https://github.com/MadryLab/backgrounds_challenge" style="float: right;">
<i class="fab fa-github"/>
   Download the datasets
</a></p>

<p><em>We discuss our recent <a href="https://arxiv.org/abs/2006.09994">paper</a> 
on identifying the role of backgrounds in image classification. Along with our
results, we’re releasing our code and datasets <a href="https://github.com/MadryLab/backgrounds_challenge">as a benchmark</a>.</em></p>

<p>As we discussed in our <a href="https://gradientscience.org/benchmarks">last post</a>, quantitative
benchmarks are key drivers of progress across many computer vision tasks. 
On tasks like image classification, state of the art is often determined by models’
accuracies on standard datasets, such as CIFAR-10 and ImageNet. 
Still, model accuracy isn’t all that matters, as evidenced by investigations into
robustness (e.g., <a href="https://gradientscience.org/intro_adversarial">[1]</a>), 
reliability (e.g., <a href="https://arxiv.org/abs/1903.12261">[2]</a>), 
and out-of-distribution performance (e.g., <a href="https://arxiv.org/abs/1706.02690">[3]</a>). 
These properties are governed not only by models’ predictions on test data, but
also by the specific set of correlations models use, and by how these
correlations are combined to make predictions. 
For example, previous work has shown that model predictions can behave
unexpectedly due to reliance on correlations that we humans 
don’t rely on (e.g. <a href="https://arxiv.org/abs/1711.11561">[4]</a>,
<a href="https://arxiv.org/abs/1807.04200">[5]</a>,
<a href="https://arxiv.org/abs/1905.02175">[6]</a>, 
<a href="https://arxiv.org/abs/1811.00401">[7]</a>); or due to overusing even
human-recognizable correlations such as texture (e.g., 
<a href="https://arxiv.org/abs/1811.12231">[8]</a>,
<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6306249/">[9]</a>) or color 
(e.g., <a href="https://journals.sagepub.com/doi/10.1068/p3376">[10]</a>). 
So it follows that if we want to understand these more complex properties of
machine learning models, we must first be able to characterize the correlations
that these models leverage.</p>

<p>Needless to say, a full characterization of the features and signals exploited
by deep neural networks is far beyond the scope of any single paper. In our
<a href="https://arxiv.org/abs/2006.09994">latest paper</a>, 
we thus take a deep dive into one specific kind of signal: <em>image backgrounds</em>.</p>

<p>Backgrounds are an established source of correlation between images and
their labels in object detection: ML models may use backgrounds in
classification (cf.
<a href="https://hal.archives-ouvertes.fr/hal-00171412/file/ZhangMarszalekLazebnikSchmid-IJCV07-ClassificationStudy.pdf">[11]</a>,
<a href="https://arxiv.org/abs/1602.04938">[12]</a>, 
<a href="https://arxiv.org/abs/1611.06596">[13]</a>,
<a href="https://arxiv.org/abs/1911.08731">[14]</a>), and even human
vision can make use of image context (cf.
<a href="http://people.csail.mit.edu/torralba/IJCVobj.pdf">[15]</a> and references). 
We thus want to understand better how current
state-of-the-art image classifiers rely on image backgrounds. 
Specifically, we investigate the extent of this reliance, its implications, and how models’ use of
backgrounds has evolved over time.</p>

<h2 id="a-new-dataset-or-seven">A new dataset (or seven)</h2>

<p>Our main tool for understanding how models use background signals is a set of
synthetic datasets that we refer to as ImageNet-9 (IN9). These datasets aim
to disentangle images’ foreground and background signals and thus enable us
to study their relative effects.</p>

<p>To generate ImageNet-9, we start by organizing a subset of ImageNet into nine
coarse-grained classes based on common ancestry in the <a href="https://wordnet.princeton.edu">WordNet hierarchy</a>: the
resulting “super-classes” are dog, bird, vehicle, reptile, carnivore, insect, 
instrument, primate, and fish. We call the 9-class dataset of unmodified images
Original.
We then use a combination of the bounding boxes
provided by ImageNet and the computer vision library <a href="https://opencv.org">OpenCV</a> to separate the
foreground and background in each imagewe deleted any images where this
process was unsuccessful (e.g., if there is no bounding box provided by ImageNet, or the bounding box takes up the entirety of the image).</p>

<p>Once we’ve separated the foreground and background signals, we introduce
 <em>seven</em> new datasets, falling into three categories:</p>

<ul>
  <li>Background-only datasets
    <ul>
      <li><strong>Only-BG-B</strong>: Black out the bounding boxes given by ImageNet annotations,
leaving only the background.</li>
      <li><strong>Only-BG-T</strong>: Take Only-BG-B and replace the blacked-out region with a
tiled version of the rest of the image (the background).</li>
      <li><strong>No-FG</strong>: Use OpenCV to extract the exact shape of the foreground, and
replace it with black.</li>
    </ul>
  </li>
  <li>Foreground-only datasets
    <ul>
      <li><strong>Only-FG</strong>: The exact complement of No-FG—rather than removing
the foreground, remove everything else.</li>
    </ul>
  </li>
  <li>Mixed datasets
    <ul>
      <li><strong>Mixed-Rand</strong>: For each image, overlay the foreground (extracted using
OpenCV) onto the background from a different random image (again,
extracted using OpenCV).</li>
      <li><strong>Mixed-Next</strong>: Assign each class a number from 1 to 9. For each image of
class $y$, add the background from a random image of class $y+1$ (or $1$, if
$y=9$).</li>
      <li><strong>Mixed-Same</strong>: For each image, add the background from a random image of
the same class.</li>
    </ul>
  </li>
</ul>

<div class="widget" style="display: flex;">
    <div class="choices_one" id="left_in9">
	<span class="widgetheading">Choose an Image</span>
    </div>
    <div class="selected_one" id="in9_selected"/>
</div>
<div style="clear: both;"/>
<div class="footnote">
        8 versions of the same image, with each version capturing a different
        combination of foreground and background signals.
</div>

<h2 id="putting-imagenet-9-to-work">Putting ImageNet-9 to work</h2>

<p>It turns out that these proposed ImageNet-9 datasets allow us to ask (and
answer) a variety of questions about the role of background signals in image
classification.</p>

<h3 id="1-is-background-signal-enough-for-classification">1. Is background signal enough for classification?</h3>

<p>Before we look at the behaviour of standard ML models, we first double-check
that background signals are exploitable in the first place—i.e., that models
can learn reasonably accurate classifiers for natural images while being trained
on backgrounds alone. 
We are not the first ones to consider this question (e.g.,
<a href="https://arxiv.org/abs/1611.06596">[13]</a>) but it serves as a useful sanity 
check and gives us a baseline to compare the rest of our experiments to.</p>

<p>We train models on the Only-BG-T, Only-BG-B, and No-FG datasets; the models
generalize reasonably well to both their corresponding test sets <em>and</em> the Original
test set (each model gets around 40-50% accuracy: a random classifier would get
11%). Thus, image backgroundsInterestingly, the No-FG model doesn't do
significantly better than the others, despite having access to the shape of the
foregrounds in the training set. <em>do</em> contain signal that
models can use to classify images.</p>

<p><img alt="The results of training models on background-only datasets and testing on the original." src="https://gradientscience.org/images/background/bg_only_train.png" style="width: 70%;"/></p>

<h3 id="2-do-models-actually-use-background-signals">2. Do models actually use background signals?</h3>

<p>So, backgrounds are indeed a useable signal for deep learning classifiers.
That’s not necessarily bad, or even different to humans: if you see an
occluded picture with an underwater background, you’d (hopefully) say that the
pictured object is more likely to be a fish than a dog.
On the other hand, humans are still able to call a dog a dog when it’s
underwater, i.e., a misleading/irrelevant background usually does not preclude us from
making the correct predictions. Is the same true for models?</p>

<p>To answer this question, we study model accuracies on the Mixed-Rand dataset,
where image backgrounds are randomized and thus provide no information 
about the correct label. 
Specifically, we compare model performance on Mixed-Rand and Mixed-Same: the
latter maintains the foreground-background correlation (since the background is
from the correct class), while controlling for artifactsSee
Appendix D of our paper for more details! from image
splicing process.</p>

<p>We denote the accuracy gap between Mixed-Same and Mixed-Rand as the BG-Gap,
i.e., the drop in model accuracy due to changing the class signal from the
background. The table below summarizes our observations: the BG-Gap is
13-22% and 6-14% for models trained on IN-9 and ImageNet, respectively,
suggesting that backgrounds often mislead state-of-the-art models even
when the correct foreground is present. (As we discuss in Appendix B of <a href="https://arxiv.org/abs/2006.09994">our
paper</a>, ImageNet-trained models do seem to be
more robust in this sense, but the reason for this robustness is hard to pin down.)</p>

<p><img alt="Evaluating pretrained models on Imagenet, Mixed-Rand, and Mixed-Same to compute the BG-Gap." src="https://gradientscience.org/images/background/table.png" style="width: 100%;"/></p>

<h3 id="3-ok-but-how-bad-can-it-get">3. Ok, but how bad can it get?</h3>

<p>The BG-Gap introduced in the previous experiment measures, in some sense,
models’ average robustness to misleading backgrounds. What does the worst case
look like? To diagnose just how large of an issue background over-reliance
can be, we search for the worst extracted background corresponding for each
extracted foreground. It turns out that a ResNet-50 model can be fooled on
87.5% of foregrounds by overlaying them on a corresponding “adversarial background.”</p>

<p>In fact, there also turn out to exist backgrounds that consistently affect the
prediction of the classifier <em>regardless</em> of what foreground is overlaid onto
them. The backgrounds below (extracted from insect images) fool our model into
predicting “insect” on up to 52\% of non-insect foregrounds:
<img alt="Adversarial Backgrounds" src="https://gradientscience.org/images/background/insect_result.png" style="width: 100%;"/></p>
<div class="footnote">
        The 5 most fooling backgrounds from the insect class, as well as the percent of non-insect foregrounds that they individually fool.
</div>

<p>Further, we can make the classifier predict “insect” on over 2/3 of the
foregrounds in the ImageNet-9 dataset, just by combining the foregrounds with
different insect backgrounds.</p>

<h3 id="4-what-is-the-effect-of-the-training-dataset">4. What is the effect of the training dataset?</h3>

<p>So far, all of the models that we’ve looked at have been trained on natural
data, i.e., either on the Original dataset from IN9, or on ImageNet itself.
We now want to test whether the previously-observed dependence on backgrounds
can be reduced (or removed altogether) by appropriately altering the training data.</p>

<p>To this end, we train models on Mixed-Rand, where background signals have been
decorrelated from class labels. 
We find these models perform only slightly better than
random on datasets with no foregrounds (e.g., a ResNet-50 trained on Mixed-Rand
achieves 15% accuracy on Only-BG-T and Only-BG-B).
They also perform better in the presence of misleading backgrounds:
training on Mixed-Rand improves accuracy on Mixed-Rand by 17%, and improves
accuracy on Mixed-NextRecall that Mixed-Next
images have foregrounds from class $y$ mixed with backgrounds from class $y+1$,
labeled as class $y$. by 22%. The model trained on
Mixed-Rand also has very little variation in accuracy across all five test sets
that contain the correct foreground (providing more evidence for its invariance
to other factors).</p>

<p><img alt="Training on Mixed-Rand and evaluating on other datasets" src="https://gradientscience.org/images/background/mixed_rand_results.png" style="width: 100%;"/></p>

<p>Qualitatively, the Mixed-Rand model also appears to place more relative
importance on foreground pixels than its original counterpart, as demonstrated
by the saliency maps below:</p>

<p><img alt="Saliency maps for models trained on original versus on Mixed-Rand" src="https://gradientscience.org/images/background/saliency_other.png" style="width: 100%;"/></p>

<h3 id="5-are-we-really-making-progress">5. Are we really making progress?</h3>

<p>We’ve now shown that models can exploit backgrounds, do exploit backgrounds, and
may actually do so to a fault. Considering that the development of these models
is driven by standard computer vision benchmarks, our results beg the question: to
what extent have improvements on ImageNet come with (or resulted from)
improvements in leveraging background correlations? And relatedly, how has
model robustness
to misleading background signals evolved over time?</p>

<p>As a first step towards answering these questions, we study the progress made by
ImageNet models on our proposed synthetic datasets. Below, we plot accuracy on
these datasets against ImageNet accuracy for a variety of different
network architectures:</p>

<p><img alt="ImageNet accuracy plotted against accuracy on synthetic datasets" src="https://gradientscience.org/images/background/in_vs_bg.png" style="width: 100%;"/></p>

<p>The plot indicates that accuracy increases on ImageNet generally correspond to
accuracy increases on all of the synthetic datasets that we consider. 
This includes the datasets that only contain background signals (Only-BG-T
in the graph above), which means that models <em>do</em> improve at extracting correlations
from image backgrounds. The fact that better models are also better at
classifying background-only images suggests that the use of background
signals might be inherent to the current training paradigm, and may
not disappearThough again, this might not be a bad
thing! on its own (i.e., without explicit regularization
or training).</p>

<p>Still, models’ <em>relative</em> improvement in accuracy across dataset variants is
promising—accuracy on background-only datasets is improving slower than
accuracy on datasets where the background is misleading, such as Mixed-Rand or
Mixed-Next. Another promising sign is that the
performance gap between the Mixed-Rand and Mixed-Same dataset (which we
previously referred to as the BG-Gap) trends towards closing, indicating that
models are not only better at using foreground features, but also more
robust to misleading background features.</p>

<p>Overall, our analysis reveals that better models in terms of ImageNet accuracy
are (a) increasingly capable of exploiting background correlations, but at the
same time (b) becoming more robust to changes in background, suggesting that
over-reliance on background features may not be necessary to maximize the
benchmark accuracy.</p>

<h3 id="conclusions">Conclusions</h3>

<p>In this post, we saw how computer vision models tend to over-rely on image
backgrounds in image classification. On one hand, our findings provide more
evidence that our models are not fully aligned with the human vision system. On the
other hand, we have shown that advances in computer vision models, such as new
architectures and training methods, have led to models that tend to use the
foreground more effectively and are more robust to misleading backgrounds.
We hope that the datasets and findings in this work provide a way to monitor
progress towards reliable, human-aligned machine learning.</p>

<p>For more detailed information about the <a href="https://github.com/MadryLab/backgrounds_challenge">datasets</a> we created, full
experimental results, and additional analysis, see <a href="https://gradientscience.org/background.pdf">our paper</a>!</p></div>
    </summary>
    <updated>2020-06-18T00:00:00Z</updated>
    <published>2020-06-18T00:00:00Z</published>
    <source>
      <id>https://gradientscience.org/</id>
      <author>
        <name>Gradient Science</name>
      </author>
      <link href="https://gradientscience.org/" rel="alternate" type="text/html"/>
      <link href="https://gradientscience.org/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Research highlights and perspectives on machine learning and optimization from MadryLab.</subtitle>
      <title>gradient science</title>
      <updated>2020-06-18T23:31:13Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.10012</id>
    <link href="http://arxiv.org/abs/2006.10012" rel="alternate" type="text/html"/>
    <title>Robust Persistence Diagrams using Reproducing Kernels</title>
    <feedworld_mtime>1592438400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Siddharth Vishwanath, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fukumizu:Kenji.html">Kenji Fukumizu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kuriki:Satoshi.html">Satoshi Kuriki</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sriperumbudur:Bharath.html">Bharath Sriperumbudur</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.10012">PDF</a><br/><b>Abstract: </b>Persistent homology has become an important tool for extracting geometric and
topological features from data, whose multi-scale features are summarized in a
persistence diagram. From a statistical perspective, however, persistence
diagrams are very sensitive to perturbations in the input space. In this work,
we develop a framework for constructing robust persistence diagrams from
superlevel filtrations of robust density estimators constructed using
reproducing kernels. Using an analogue of the influence function on the space
of persistence diagrams, we establish the proposed framework to be less
sensitive to outliers. The robust persistence diagrams are shown to be
consistent estimators in bottleneck distance, with the convergence rate
controlled by the smoothness of the kernel. This, in turn, allows us to
construct uniform confidence bands in the space of persistence diagrams.
Finally, we demonstrate the superiority of the proposed approach on benchmark
datasets.
</p></div>
    </summary>
    <updated>2020-06-18T23:29:54Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-06-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.09969</id>
    <link href="http://arxiv.org/abs/2006.09969" rel="alternate" type="text/html"/>
    <title>Playing Unique Games on Certified Small-Set Expanders</title>
    <feedworld_mtime>1592438400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bafna:Mitali.html">Mitali Bafna</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Barak:Boaz.html">Boaz Barak</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kothari:Pravesh.html">Pravesh Kothari</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schramm:Tselil.html">Tselil Schramm</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Steurer:David.html">David Steurer</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.09969">PDF</a><br/><b>Abstract: </b>We give an algorithm for solving unique games (UG) instances whose
constraints correspond to edges of graphs with a sum-of-squares (SoS)
small-set-expansion certificate. As corollaries, we obtain the first
polynomial-time algorithms for solving UG on the noisy hypercube and the short
code graphs. The prior best algorithm for such instances was the eigenvalue
enumeration algorithm of Arora, Barak, and Steurer (2010) which requires
quasi-polynomial time for the noisy hypercube and nearly-exponential time for
the short code graph. All of our results achieve an approximation of
$1-\epsilon$ vs $\delta$ for UG instances, where $\delta &gt; 0$ depends on the
expansion parameters of the graph but is independent of the alphabet size.
</p>
<p>Specifically, say that a regular graph $G=(V,E)$ is a $(\mu,\eta)$ small-set
expander (SSE) if for every subset $S \subseteq V$ with $|S| \leq \mu |V|$, the
edge-expansion of $S$ is at least $\eta$. We say that $G$ is a $d$-certified
$(\mu,\eta)$-SSE if there is a degree-d SoS certificate for this fact (based on
2 to 4 hypercontractivity). We prove that there is a $|V|^{f(d,\mu,\eta)}$ time
algorithm $A$ (based on the SoS hierarchy) such that for every $\eta&gt;0$ and
$d$-certified $(\mu, \eta)$-SSE $G$, if $I$ is a $1-\eta^2/100$ satisfiable
affine UG instance over $G$ then $A(I)$ is an assignment satisfying at least
some positive fraction $\delta = \delta(\mu,\eta)$ of $I$'s constraints. As a
corollary, we get a polynomial-time algorithm $A$ such that if $I$ is a
$1-\epsilon$ satisfiable instance over the $\alpha$-noisy hypercube or short
code graph, then $A(I)$ outputs an assignment satisfying an
$\exp(-O(\sqrt{\epsilon}/\alpha))$ fraction of the constraints. Our techniques
can be extended even to graphs that are not SSE, and in particular we obtain a
new efficient algorithm for solving UG instances over the Johnson graph.
</p></div>
    </summary>
    <updated>2020-06-18T23:20:27Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-06-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.09956</id>
    <link href="http://arxiv.org/abs/2006.09956" rel="alternate" type="text/html"/>
    <title>Bad Projections of the PSD Cone</title>
    <feedworld_mtime>1592438400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jiang:Yuhan.html">Yuhan Jiang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sturmfels:Bernd.html">Bernd Sturmfels</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.09956">PDF</a><br/><b>Abstract: </b>The image of the cone of positive semidefinite matrices under a linear map is
a convex cone. Pataki characterized the set of linear maps for which that image
is not closed. The Zariski closure of this set is a hypersurface in the
Grassmannian. Its components are the coisotropic hypersurfaces of symmetric
determinantal varieties. We develop the convex algebraic geometry of such bad
projections, with focus on explicit computations.
</p></div>
    </summary>
    <updated>2020-06-18T23:29:09Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-06-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.09912</id>
    <link href="http://arxiv.org/abs/2006.09912" rel="alternate" type="text/html"/>
    <title>Bute: A Bottom-Up Exact Solver for Treedepth (Submitted to PACE 2020 under username peaty)</title>
    <feedworld_mtime>1592438400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Trimble:James.html">James Trimble</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.09912">PDF</a><br/><b>Abstract: </b>This note introduces the exact solver Bute for the exact treedepth problem,
along with two variants of the solver. Each of these solvers computes an
elimination tree in a bottom-up fashion by finding sets of vertices that induce
subgraphs of small treedepth, then combining sets of vertices together with a
root vertex to produce larger sets. The algorithms make use of a trie data
structure to reduce the effort required to determine acceptable combinations of
subtrees. Bute-Plus and Bute-Plus-Plus add a heuristic presolve step, which can
quickly find a treedepth decomposition of optimal depth for many instances.
</p></div>
    </summary>
    <updated>2020-06-18T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.09877</id>
    <link href="http://arxiv.org/abs/2006.09877" rel="alternate" type="text/html"/>
    <title>Twin-width II: small classes</title>
    <feedworld_mtime>1592438400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bonnet:=Eacute=douard.html">Édouard Bonnet</a>, Colin Geniet, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kim:Eun_Jung.html">Eun Jung Kim</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Thomass=eacute=:St=eacute=phan.html">Stéphan Thomassé</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Watrigant:R=eacute=mi.html">Rémi Watrigant</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.09877">PDF</a><br/><b>Abstract: </b>The twin-width of a graph $G$ is the minimum integer $d$ such that $G$ has a
$d$-contraction sequence, that is, a sequence of $|V(G)|-1$ iterated vertex
identifications for which the overall maximum number of red edges incident to a
single vertex is at most $d$, where a red edge appears between two sets of
identified vertices if they are not homogeneous in $G$. We show that if a graph
admits a $d$-contraction sequence, then it also has a linear-arity tree of
$f(d)$-contractions, for some function $f$. First this permits to show that
every bounded twin-width class is small, i.e., has at most $n!c^n$ graphs
labeled by $[n]$, for some constant $c$. This unifies and extends the same
result for bounded treewidth graphs [Beineke and Pippert, JCT '69], proper
subclasses of permutations graphs [Marcus and Tardos, JCTA '04], and proper
minor-free classes [Norine et al., JCTB '06]. The second consequence is an
$O(\log n)$-adjacency labeling scheme for bounded twin-width graphs, confirming
several cases of the implicit graph conjecture. We then explore the "small
conjecture" that, conversely, every small hereditary class has bounded
twin-width. Inspired by sorting networks of logarithmic depth, we show that
$\log_{\Theta(\log \log d)}n$-subdivisions of $K_n$ (a small class when $d$ is
constant) have twin-width at most $d$. We obtain a rather sharp converse with a
surprisingly direct proof: the $\log_{d+1}n$-subdivision of $K_n$ has
twin-width at least $d$. Secondly graphs with bounded stack or queue number
(also small classes) have bounded twin-width. Thirdly we show that cubic
expanders obtained by iterated random 2-lifts from $K_4$~[Bilu and Linial,
Combinatorica '06] have bounded twin-width, too. We suggest a promising
connection between the small conjecture and group theory. Finally we define a
robust notion of sparse twin-width and discuss how it compares with other
sparse classes.
</p></div>
    </summary>
    <updated>2020-06-18T23:22:50Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.09872</id>
    <link href="http://arxiv.org/abs/2006.09872" rel="alternate" type="text/html"/>
    <title>Scheduling a Proportionate Flow Shop of Batching Machines</title>
    <feedworld_mtime>1592438400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hertrich:Christoph.html">Christoph Hertrich</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wei=szlig=:Christian.html">Christian Weiß</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Ackermann:Heiner.html">Heiner Ackermann</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Heydrich:Sandy.html">Sandy Heydrich</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Krumke:Sven_O=.html">Sven O. Krumke</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.09872">PDF</a><br/><b>Abstract: </b>In this paper we study a proportionate flow shop of batching machines with
release dates and a fixed number $m \geq 2$ of machines. The scheduling problem
has so far barely received any attention in the literature, but recently its
importance has increased significantly, due to applications in the industrial
scaling of modern bio-medicine production processes. We show that for any fixed
number of machines, the makespan and the sum of completion times can be
minimized in polynomial time. Furthermore, we show that the obtained algorithm
can also be used to minimize the weighted total completion time, maximum
lateness, total tardiness and (weighted) number of late jobs in polynomial time
if all release dates are $0$. Previously, polynomial time algorithms have only
been known for two machines.
</p></div>
    </summary>
    <updated>2020-06-18T23:23:53Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.09735</id>
    <link href="http://arxiv.org/abs/2006.09735" rel="alternate" type="text/html"/>
    <title>Efficient Statistics for Sparse Graphical Models from Truncated Samples</title>
    <feedworld_mtime>1592438400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bhattacharyya:Arnab.html">Arnab Bhattacharyya</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Desai:Rathin.html">Rathin Desai</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nagarajan:Sai_Ganesh.html">Sai Ganesh Nagarajan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Panageas:Ioannis.html">Ioannis Panageas</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.09735">PDF</a><br/><b>Abstract: </b>In this paper, we study high-dimensional estimation from truncated samples.
We focus on two fundamental and classical problems: (i) inference of sparse
Gaussian graphical models and (ii) support recovery of sparse linear models.
</p>
<p>(i) For Gaussian graphical models, suppose $d$-dimensional samples ${\bf x}$
are generated from a Gaussian $N(\mu,\Sigma)$ and observed only if they belong
to a subset $S \subseteq \mathbb{R}^d$. We show that ${\mu}$ and ${\Sigma}$ can
be estimated with error $\epsilon$ in the Frobenius norm, using
$\tilde{O}\left(\frac{\textrm{nz}({\Sigma}^{-1})}{\epsilon^2}\right)$ samples
from a truncated $\mathcal{N}({\mu},{\Sigma})$ and having access to a
membership oracle for $S$. The set $S$ is assumed to have non-trivial measure
under the unknown distribution but is otherwise arbitrary.
</p>
<p>(ii) For sparse linear regression, suppose samples $({\bf x},y)$ are
generated where $y = {\bf x}^\top{{\Omega}^*} + \mathcal{N}(0,1)$ and $({\bf
x}, y)$ is seen only if $y$ belongs to a truncation set $S \subseteq
\mathbb{R}$. We consider the case that ${\Omega}^*$ is sparse with a support
set of size $k$. Our main result is to establish precise conditions on the
problem dimension $d$, the support size $k$, the number of observations $n$,
and properties of the samples and the truncation that are sufficient to recover
the support of ${\Omega}^*$. Specifically, we show that under some mild
assumptions, only $O(k^2 \log d)$ samples are needed to estimate ${\Omega}^*$
in the $\ell_\infty$-norm up to a bounded error.
</p>
<p>For both problems, our estimator minimizes the sum of the finite population
negative log-likelihood function and an $\ell_1$-regularization term.
</p></div>
    </summary>
    <updated>2020-06-18T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.09665</id>
    <link href="http://arxiv.org/abs/2006.09665" rel="alternate" type="text/html"/>
    <title>Caching with Time Windows and Delays</title>
    <feedworld_mtime>1592438400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gupta:Anupam.html">Anupam Gupta</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kumar:Amit.html">Amit Kumar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Panigrahi:Debmalya.html">Debmalya Panigrahi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.09665">PDF</a><br/><b>Abstract: </b>We consider two generalizations of the classical weighted paging problem that
incorporate the notion of delayed service of page requests. The first is the
(weighted) Paging with Time Windows (PageTW) problem, which is like the
classical weighted paging problem except that each page request only needs to
be served before a given deadline. This problem arises in many practical
applications of online caching, such as the "deadline" I/O scheduler in the
Linux kernel and video-on-demand streaming. The second, and more general,
problem is the (weighted) Paging with Delay (PageD) problem, where the delay in
serving a page request results in a penalty being assessed to the objective.
This problem generalizes the caching problem to allow delayed service, a line
of work that has recently gained traction in online algorithms (e.g., Emek et
al. STOC '16, Azar et al. STOC '17, Azar and Touitou FOCS '19).
</p>
<p>We give $O(\log k\log n)$-competitive algorithms for both the PageTW and
PageD problems on $n$ pages with a cache of size $k$. This significantly
improves on the previous best bounds of $O(k)$ for both problems (Azar et al.
STOC '17). We also consider the offline PageTW and PageD problems, for which we
give $O(1)$ approximation algorithms and prove APX-hardness. These are the
first results for the offline problems; even NP-hardness was not known before
our work. At the heart of our algorithms is a novel "hitting-set" LP relaxation
of the PageTW problem that overcomes the $\Omega(k)$ integrality gap of the
natural LP for the problem. To the best of our knowledge, this is the first
example of an LP-based algorithm for an online algorithm with delays/deadlines.
</p></div>
    </summary>
    <updated>2020-06-18T23:25:50Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.09509</id>
    <link href="http://arxiv.org/abs/2006.09509" rel="alternate" type="text/html"/>
    <title>Online Algorithms for Weighted Paging with Predictions</title>
    <feedworld_mtime>1592438400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jiang:Zhihao.html">Zhihao Jiang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Panigrahi:Debmalya.html">Debmalya Panigrahi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sun:Kevin.html">Kevin Sun</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.09509">PDF</a><br/><b>Abstract: </b>In this paper, we initiate the study of the weighted paging problem with
predictions. This continues the recent line of work in online algorithms with
predictions, particularly that of Lykouris and Vassilvitski (ICML 2018) and
Rohatgi (SODA 2020) on unweighted paging with predictions. We show that unlike
unweighted paging, neither a fixed lookahead nor knowledge of the next request
for every page is sufficient information for an algorithm to overcome existing
lower bounds in weighted paging. However, a combination of the two, which we
call the strong per request prediction (SPRP) model, suffices to give a
2-competitive algorithm. We also explore the question of gracefully degrading
algorithms with increasing prediction error, and give both upper and lower
bounds for a set of natural measures of prediction error.
</p></div>
    </summary>
    <updated>2020-06-18T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-8890204.post-6952358197668395658</id>
    <link href="http://mybiasedcoin.blogspot.com/feeds/6952358197668395658/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=8890204&amp;postID=6952358197668395658" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/8890204/posts/default/6952358197668395658" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/8890204/posts/default/6952358197668395658" rel="self" type="application/atom+xml"/>
    <link href="http://mybiasedcoin.blogspot.com/2020/06/algorithms-with-predictions-survey-and.html" rel="alternate" type="text/html"/>
    <title>Algorithms with Predictions:  Survey and Workshop</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">There's a whole new, interesting theory trend  -- Algorithms with Predictions.  The idea, spurred by advances in machine learning, is that you assume you have predictor that tells you something about your input.  For example, in caching, you might have a prediction of when the item you are currently accessing will be next accessed.  Of course, machine learning predictions aren't perfect.  Still, you'd like to use this prediction to improve your caching algorithm, but from the theory side, we'd like provable statements.  For example, you could say, if my prediction is THIS good (e.g., the error is bounded under some metric), then my caching performance will correspondingly be at least THIS good (e.g., performance bounded in some way).<br/><br/>If you haven't seen the burgeoning spread of this line of work and are interested, you're in luck.  First, Sergei Vassilvitskii and I have written a <a href="https://arxiv.org/abs/2006.09123">brief survey that's now on the arxiv</a>.  We had written it for a collection Tim Roughgarden is organizing on Beyond Worst-Case Analysis (that we thought we be out by now, and should be out from the publisher soon-ish), but we've gone ahead and put a version on the arxiv to make it available.  The area is moving fast, so there are already many new results --  we hope to update the "survey" with new material as the area grows.<br/><br/>Second, one of the <a href="https://www.mit.edu/~vakilian/stoc-workshop.html">STOC'20 Workshops will be on Algorithms with Predictions</a>.  It will be on Friday from 1-4pm, with speakers Tim Roughgarden, Edith Cohen,  Ravi Kumar, and me.  I'll be talking about some of my recent work  (in submission) on queues with predictions, and partitioned learned Bloom filters.  (Arxiv papers are <a href="https://arxiv.org/abs/1902.00732">here</a>, <a href="https://arxiv.org/abs/1905.12155">here</a>, and <a href="https://arxiv.org/abs/2006.03176">here</a>, but maybe you want to see the talk first.)  I'll also do a blog post on partitioned learned Bloom filters in the near future.</div>
    </content>
    <updated>2020-06-17T17:52:00Z</updated>
    <published>2020-06-17T17:52:00Z</published>
    <author>
      <name>Michael Mitzenmacher</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/02161161032642563814</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-8890204</id>
      <category term="conferences"/>
      <category term="research"/>
      <category term="society"/>
      <category term="algorithms"/>
      <category term="administration"/>
      <category term="teaching"/>
      <category term="Harvard"/>
      <category term="papers"/>
      <category term="graduate students"/>
      <category term="funding"/>
      <category term="talks"/>
      <category term="blogs"/>
      <category term="codes"/>
      <category term="jobs"/>
      <category term="reviews"/>
      <category term="personal"/>
      <category term="travel"/>
      <category term="undergraduate students"/>
      <category term="books"/>
      <category term="open problems"/>
      <category term="PCs"/>
      <category term="consulting"/>
      <category term="randomness"/>
      <category term="CCC"/>
      <category term="blog book project"/>
      <category term="research labs"/>
      <category term="ISIT"/>
      <category term="tenure"/>
      <category term="comments"/>
      <category term="recommendations"/>
      <category term="outreach"/>
      <category term="students"/>
      <author>
        <name>Michael Mitzenmacher</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06738274256402616703</uri>
      </author>
      <link href="http://mybiasedcoin.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/8890204/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://mybiasedcoin.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/8890204/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">My take on computer science -- <br/> 
algorithms, networking, information theory -- <br/> 
and related items.</div>
      </subtitle>
      <title>My Biased Coin</title>
      <updated>2020-06-17T17:53:04Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-27705661.post-2271116647104476479</id>
    <link href="http://processalgebra.blogspot.com/feeds/2271116647104476479/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=27705661&amp;postID=2271116647104476479" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/2271116647104476479" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/2271116647104476479" rel="self" type="application/atom+xml"/>
    <link href="http://processalgebra.blogspot.com/2020/06/logic-mentoring-workshop-2020.html" rel="alternate" type="text/html"/>
    <title>Logic Mentoring Workshop 2020</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div class="_5pbx userContent _3576" id="js_k"><a href="https://www2.csc.liv.ac.uk/~lehtinen/">Karoliina Lehtinen</a> asked me to encourage young researchers of all ages to attend this year's edition of the Logic Mentoring Workshop. (See <a href="https://lmw.mpi-sws.org/">here</a> for information.) The <a href="https://lmw.mpi-sws.org/speakers.html">set of speakers</a> is top class, registration is  free and I am sure that attending the event would be beneficial  to  many. Spread the news!<br/><br/>FWIW, I gave a talk at the <a href="https://lics.siglog.org/lics17/lmw.html">2017 edition</a> of the event and thoroughly enjoyed it. Even though the event is targeted at students, from senior undergraduates to graduates, I feel that I always learn something new from attending this kind of workshops/talks. </div></div>
    </content>
    <updated>2020-06-17T16:10:00Z</updated>
    <published>2020-06-17T16:10:00Z</published>
    <author>
      <name>Luca Aceto</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/01092671728833265127</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-27705661</id>
      <author>
        <name>Luca Aceto</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/01092671728833265127</uri>
      </author>
      <link href="http://processalgebra.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://processalgebra.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Papers I find interesting---mostly, but not solely, in Process Algebra---, and some fun stuff in Mathematics and Computer Science at large and on general issues related to research, teaching and academic life.</subtitle>
      <title>Process Algebra Diary</title>
      <updated>2020-06-18T21:29:22Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=17204</id>
    <link href="https://rjlipton.wordpress.com/2020/06/16/pnp/" rel="alternate" type="text/html"/>
    <title>P&lt;NP</title>
    <summary>Some thoughts on P versus NP Norbert Blum is a computer science theorist at the University of Bonn, Germany. He has made important contributions to theory over his career. Another claim to fame is he was a student of Kurt Mehlhorn, indeed the third of Mehlhorn’s eighty-eight listed students. Today I wish to discuss a […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Some thoughts on P versus NP</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/?attachment_id=17188" rel="attachment wp-att-17188"><img alt="" class="alignright size-full wp-image-17188" src="https://rjlipton.files.wordpress.com/2020/06/unknown.jpeg?w=600"/></a>
</td>
</tr>
<tr>
</tr>
</tbody>
</table>
<p>
Norbert Blum is a computer science theorist at the University of Bonn, Germany. He has made important contributions to theory over his career. Another claim to fame is he was a student of Kurt Mehlhorn, indeed the <a href="https://www.genealogy.math.ndsu.nodak.edu/id.php?id=35475&amp;fChrono=1">third</a> of Mehlhorn’s eighty-eight listed students.</p>
<p>
Today I wish to discuss a new paper by Blum.</p>
<p>
No, it does not solve the P versus NP problem. The title of his paper is: <i>On the Approximation Method and the P versus NP Problem</i>. Its is available <a href="https://arxiv.org/pdf/1708.03486.pdf">here</a>.</p>
<p>
Blum. like most complexity theorists, believes that P is weaker than NP. This is usually stated as P<img alt="{\neq}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cneq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\neq}"/>NP. The staff at GLL have the idea that we should state this as 	</p>
<p align="center"><img alt="\displaystyle  P &lt; NP. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++P+%3C+NP.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  P &lt; NP. "/></p>
<p>This is clearer, more to the point, and logically what P<img alt="{\neq}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cneq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\neq}"/>NP actually says. We will soon have T-shirts, mugs, and other stuff available in our web store at https:donotgotothisaddressplease.com. </p>
<p/><p/>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.wordpress.com/2020/06/16/pnp/mug2-2/" rel="attachment wp-att-17207"><img alt="" class="aligncenter size-medium wp-image-17207" height="257" src="https://rjlipton.files.wordpress.com/2020/06/mug2-1.png?w=300&amp;h=257" width="300"/></a>
</td>
</tr>
<tr>

</tr>
</tbody></table>
<p>
</p><p/><h2> Three Years Ago </h2><p/>
<p/><p>
In 2017 Blum released a <a href="https://arxiv.org/abs/1708.03486">paper</a> that tried to prove P<img alt="{&lt;}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%3C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{&lt;}"/>NP. It caused a sensation—it was discussed on the complexity blogs such as <a href="https://lucatrevisan.wordpress.com/2017/08/15/on-norbert-blums-claimed-proof-that-p-does-not-equal-np/">In theory</a> and <a href="https://www.scottaaronson.com/blog/?p=3409">Shtetl-Optimized</a>. And also at <a href="https://rjlipton.wordpress.com/2017/08/17/on-the-edge-of-eclipses-and-pnp/">GLL</a>. Blum’s paper got thousands of Twitter mentions. Unfortunately he had to retract it, since it is wrong: He said: </p>
<blockquote><p><b> </b> <em> The proof is wrong. I shall elaborate precisely what the mistake is. For doing this, I need some time. I shall put the explanation on my homepage </em>
</p></blockquote>
<p>Look at <a href="https://johncarlosbaez.wordpress.com/2017/08/15/norbert-blum-on-p-versus-np/">here</a> for more comments that were made after his paper was released. </p>
<p>
He did, months later in 2017, post a two-page retraction<br/>
<a href="http://theory.cs.uni-bonn.de/blum/PvsNP/mistake.pdf">here</a>. His original paper’s abstract: </p>
<blockquote><p><b> </b> <em> Berg and Ulfberg and Amano and Maruoka have used CNF-DNF-approximators to prove exponential lower bounds for the monotone network complexity of the clique function and of Andreev’s function. We show that these approximators can be used to prove the same lower bound for their non-monotone network complexity. This implies P not equal NP. </em>
</p></blockquote>
<p>This approach is what we will discuss.</p>
<p>
</p><p/><h2> Today </h2><p/>
<p/><p>
Blum’s new paper does not claim to prove P<img alt="{&lt;}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%3C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{&lt;}"/>NP, but gives his thoughts on P<img alt="{&lt;}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%3C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{&lt;}"/>NP. I think he has earned our attention. It must have been difficult to go from thinking you have solved <i>the problem</i> to retracting your paper. I have thought, privately, that I had solved some neat problems. Only later to discover that I was wrong. I cannot imagine how tough it was to do this in public. </p>
<p>
</p><p/><h2> The Idea </h2><p/>
<p/><p>
Blum’s work on proving lower bounds began with his dissertation under Mehlhorn, which included a 1985 <a href="https://www.sciencedirect.com/science/article/pii/0304397585900301">paper</a> on monotone network complexity for convolutions. Earlier in 1984 Blum <a href="https://reader.elsevier.com/reader/sd/pii/0304397583900294? which was improved token=1F67F05B416D89618750BC409200E17D536C46207555E1A9FD524B2592630E400FC2C597EA81F7190D2A747A4B82F28B">proved</a> a lower bound of order <img alt="{3n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{3n}"/>. This stood for thirty years until in 2015 Magnus Find, Alexander Golovnev, Edward Hirsch, and Alexander Kulikov <a href="https://tsapps.nist.gov/publication/get_pdf.cfm?pub_id=919494">improved</a> it to order <img alt="{3.011n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3.011n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{3.011n}"/>. A long way from super-polynomial lower bounds. See also a <a href="https://simons.berkeley.edu/sites/default/files/docs/3815/20151001gateelimination.pdf">talk</a> about this work. </p>
<p>
Blum’s new paper discusses an old approach to prove boolean circuit lower bounds. The methods he used in 1984 and those improved in 2015 do not seem to be on track to prove even non-linear circuit lower bounds. </p>
<p>
Let’s look at his comments at a high level. See his paper for details. </p>
<p>
Suppose that one has a boolean function <img alt="{f(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(x)}"/> that is monotone: recall this means that if <img alt="{f(x)=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(x)=1}"/>, then changing some input <img alt="{x_{k}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_%7Bk%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x_{k}}"/> from <img alt="{0 \rightarrow 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0+%5Crightarrow+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0 \rightarrow 1}"/> does not change the value of <img alt="{f(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(x)}"/>. Then it is always possible to compute <img alt="{f(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(x)}"/> without using any negations: only and/or operations are needed. Sometimes one can prove that the number of such operations is super-linear, sometimes even super-polynomial. Even bounds in this restricted model can be deep.</p>
<p>
The idea that has tempted Blum and many other complexity theorists is: Can we extend the proofs for lower bounds without negations to ones with negations? One problem is there is a function <img alt="{f(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(x)}"/> so that the following are true: </p>
<ol>
<li>
The function is monotone; <p/>
</li><li>
The function can be computed in polynomial time; <p/>
</li><li>
Any monotone circuit for computing the function requires exponential size
</li></ol>
<p>This is the famous <a href="https://en.wikipedia.org/wiki/Tardos_function">Tardos function</a> due to Éva Tardos. The existence of this function sunk Blum’s original paper. And it makes life hard for this general program—this is an instance of what our previous <a href="https://rjlipton.wordpress.com/2020/06/13/proof-checking-not-line-by-line/">post</a> meant by a proof attempt running up against a fundamental law. Negations can help tremendously in computing a function. </p>
<p>
</p><p/><h2> Blum’s Paper </h2><p/>
<p/><p>
In his new <a href="https://arxiv.org/pdf/1708.03486.pdf">paper</a> he surveys boolean complexity ideas—especially those linked to monotone complexity. He begins by trying to argue that the largeness feature of the <a href="https://rjlipton.wordpress.com/2009/03/25/whos-afraid-of-natural-proofs/">natural proofs</a> barrier, which applies to combinatorial properties defined via sub-additive circuit complexity measures, does not constrain approximation complexity measures of the kind he envisions. He then proceeds to define <em>CNF-DNF approximators</em> and further what he calls <em>sunflower approximators</em>. He does enough development to highlight a missing piece of information about monomial representations of <em>non-</em>approximated pieces of the Boolean function one is trying to prove hard. He concludes that without this information, his methods cannot even prove super-<em>linear</em> size lower bounds on general circuits.</p>
<p>
He ends with this assessment: </p>
<blockquote><p><b> </b> <em> How to proceed the work with respect to the P versus NP problem? Currently, I am convinced that we are far away to prove a super-polynomial lower bound for the non-monotone complexity of any explicit Boolean function. On the other hand, the strongest barrier towards proving P<img alt="{&lt;}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%3C%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{&lt;}"/>NP could be that it holds P = NP. To ensure that the whole time spent for working on the P versus NP problem is not used to prove an impossible theorem, I would switch to the try to develop a polynomial algorithm for the solution of an NP-complete problem. </em>
</p></blockquote>
<p/><p>
Note, we have changed his P<img alt="{\neq}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cneq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\neq}"/>NP to P<img alt="{&lt;}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%3C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{&lt;}"/>NP. Ken and I agree with him on trying to work both on P<img alt="{&lt;}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%3C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{&lt;}"/>NP and P=NP. However, see our comments below. </p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
I applaud Blum for thinking about P<img alt="{&lt;}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%3C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{&lt;}"/>NP. We need people to be fearless if it is ever going to be solved. However, I personally believe that his approach may be wrong:</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> I am not as sure as he is that P<img alt="{&lt;}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%3C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{&lt;}"/>NP. I do think that P=NP is possible, especially if algorithms are allowed to be <a href="https://en.wikipedia.org/wiki/Galactic_algorithm">galactic</a>. Recall these are algorithms that run in polynomial time, but in polynomials of astronomical degree.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> Also I am not sure if the boolean approach to P<img alt="{&lt;}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%3C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{&lt;}"/>NP is the right one. Suppose there is a <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> so that SAT has boolean circuits of size <img alt="{n^{C}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%5E%7BC%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n^{C}}"/> where 	</p>
<p align="center"><img alt="\displaystyle  C = 2^{2^{2^{10000}}}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++C+%3D+2%5E%7B2%5E%7B2%5E%7B10000%7D%7D%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  C = 2^{2^{2^{10000}}}. "/></p>
<p>It still could be the case that P<img alt="{&lt;}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%3C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{&lt;}"/>NP, since there may be no uniform algorithm for SAT.</p>
<p>
Restating the last point: I believe we should try to prove what is needed, and not any more. The approach to P<img alt="{&lt;}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%3C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{&lt;}"/>NP based on boolean circuit complexity is trying to prove too much. A proof that SAT has super-polynomial circuits does imply more than P<img alt="{&lt;}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%3C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{&lt;}"/>NP. A proof that SAT cannot be solved in time <img alt="o(n\log n)" class="latex" src="https://s0.wp.com/latex.php?latex=o%28n%5Clog+n%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="o(n\log n)"/> on a multitape Turing machine would imply much less than P &lt; NP, yet still be a breakthrough</p>
<p>
Be cheap, prove the least possible. </p>
<p/></font></font></div>
    </content>
    <updated>2020-06-16T20:40:41Z</updated>
    <published>2020-06-16T20:40:41Z</published>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2020-06-19T00:20:38Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/092</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/092" rel="alternate" type="text/html"/>
    <title>TR20-092 |  Computing Igusa&amp;#39;s local zeta function of univariates in deterministic polynomial-time | 

	Ashish Dwivedi, 

	Nitin Saxena</title>
    <summary>Igusa's local zeta function $Z_{f,p}(s)$ is the generating function that counts the number of integral roots, $N_{k}(f)$, of $f(\mathbf x) \bmod p^k$, for all $k$. It is a famous result, in analytic number theory, that $Z_{f,p}$ is a rational function in $\mathbb{Q}(p^s)$. We give an elementary proof of this fact for a univariate polynomial $f$. Our proof is constructive as it gives a closed-form expression for the number of roots $N_{k}(f)$. 

Our proof, when combined with the recent root-counting algorithm of (Dwivedi, Mittal, Saxena, CCC, 2019), yields the first deterministic poly($|f|, \log p$) time algorithm to compute $Z_{f,p}(s)$. Previously, an algorithm was known only in the case when $f$ completely splits over $\mathbb{Q_p}$; it required the rational roots to use the concept of generating function of a tree (Zuniga-Galindo, J.Int.Seq., 2003).</summary>
    <updated>2020-06-16T08:32:14Z</updated>
    <published>2020-06-16T08:32:14Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-06-19T00:20:25Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/06/15/postdoc-positions-in-tcs-at-university-of-copenhagen-apply-by-july-6-2020/</id>
    <link href="https://cstheory-jobs.org/2020/06/15/postdoc-positions-in-tcs-at-university-of-copenhagen-apply-by-july-6-2020/" rel="alternate" type="text/html"/>
    <title>Postdoc positions in TCS at University of Copenhagen (apply by July 6, 2020)</title>
    <summary>The CS department at the University of Copenhagen invites applications for postdoc positions in TCS. The application deadline is July 6, 2020. See https://employment.ku.dk/faculty/?show=151975 for the full announcement with more information and instructions for how to apply. Informal enquiries are welcome and may be sent to mthorup@di.ku.dk or jn@di.ku.dk. Website: https://employment.ku.dk/faculty/?show=151975 Email: jn@di.ku.dk</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The CS department at the University of Copenhagen invites applications for postdoc positions in TCS. The application deadline is July 6, 2020. See <a href="https://employment.ku.dk/faculty/?show=151975">https://employment.ku.dk/faculty/?show=151975</a> for the full announcement with more information and instructions for how to apply. Informal enquiries are welcome and may be sent to mthorup@di.ku.dk or jn@di.ku.dk.</p>
<p>Website: <a href="https://employment.ku.dk/faculty/?show=151975">https://employment.ku.dk/faculty/?show=151975</a><br/>
Email: jn@di.ku.dk</p></div>
    </content>
    <updated>2020-06-15T21:51:22Z</updated>
    <published>2020-06-15T21:51:22Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-06-19T00:20:42Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2020/06/15/linkage</id>
    <link href="https://11011110.github.io/blog/2020/06/15/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>Graduata data structures online (), finally done and graded. Warning: dry voice-over-slides videos, and some mistakes, because I didn’t have time to put together anything more sophisticated or edit more carefully.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><ul>
  <li>
    <p><a href="https://www.ics.uci.edu/~eppstein/261/">Graduata data structures online</a> (<a href="https://mathstodon.xyz/@11011110/104266993520726615"/>), finally done and graded. Warning: dry voice-over-slides videos, and some mistakes, because I didn’t have time to put together anything more sophisticated or edit more carefully.</p>
  </li>
  <li>
    <p><a href="https://boingboing.net/2020/06/02/list-100-times-law-enforceme.html">Freedom of the press under attack: 100+ times law enforcement violently assaulted journalists in US at George Floyd protests</a> (<a href="https://mathstodon.xyz/@11011110/104276714124643888"/>). Of course this is only a small piece of an enormous pattern of awfulness by the current administration, law enforcement, and the prison-industrial complex, but it’s a piece that I think is important to document.</p>
  </li>
  <li>
    <p><a href="https://blog.archive.org/2020/06/01/four-commercial-publishers-filed-a-complaint-about-the-internet-archives-lending-of-digitized-books/">Four book publishing corporations claim that what libraries always have done (lending out copies of books they have purchased as physical objects) is illegal, because computer, and are suing the Internet Archive over it</a> (<a href="https://mathstodon.xyz/@11011110/104283895750093044"/>, <a href="https://www.theverge.com/2020/6/1/21277036/internet-archive-publishers-lawsuit-open-library-ebook-lending">via</a>, <a href="https://torrentfreak.com/publishers-sue-the-internet-archive-over-its-open-library-declare-it-a-pirate-site-200601/">via2</a>). One of them, Wiley, is also a major publisher of academic works. Perhaps that should give some of us pause in which journals we send our papers to and referee for.</p>
  </li>
  <li>
    <p><a href="https://observablehq.com/@otaviocv/moire-patterns-from-random-dots">Moiré patterns from random dots</a> (<a href="https://mathstodon.xyz/@11011110/104290097720006041"/>). Overlaying the same random dot pattern on a translated and rotated copy of itself shows concentric dots around the center of rotation, illustrating <a href="https://en.wikipedia.org/wiki/Chasles%27_theorem_(kinematics)">Chasles’ theorem</a> that every rigid transformation of the plane is a translation or rotation. The effect seems to have first been observed by Leon Glass in “<a href="https://doi.org/10.1038/223578a0">Moiré patterns from random dots</a>” (<em>Nature</em>, 1969).</p>
  </li>
  <li>
    <p><a href="https://doi.org/10.1007/978-3-030-48966-3_3">“The Micro-world of Cographs”, Alecu, Lozin, and de Werra, <em>IWOCA</em> 2020</a> (<a href="https://mathstodon.xyz/@11011110/104295850760016598"/>). <a href="https://en.wikipedia.org/wiki/Cograph">Cographs</a> have a simple structure, but there’s still an interesting hierarchy of subclasses of graphs within them restricting different parameters of graph complexity to be bounded. A typical result: Every cograph with large h-index must contain a large complete graph, balanced bipartite graph, or forest of many high-degree stars.</p>
  </li>
  <li>
    <p><a href="https://www.theguardian.com/technology/2020/jun/01/cutting-edge-japanese-paper-art-inspires-a-non-slip-shoe">Japanese scientists use kirigami to design a shoe sole with pop-up non-slip spikes</a>.</p>
  </li>
  <li>
    <p><a href="https://mamot.fr/@starifi/104246098809527372">Ombre et lumière</a>. Artwork in which random-looking blocks on a wall create a recognizable shadow in side-light.</p>
  </li>
  <li>
    <p><a href="https://mathoverflow.net/a/362569/440">Brian Hopkins answers his own 9-year-old question on the history of  Fibonacci numbers and compositions</a> (<a href="https://mathstodon.xyz/@11011110/104312192948087479"/>). The ancient Indians knew that compositions (ordered partitions of integers) into ’s and ’s are counted by Fibonacci numbers. For instance, there five ways of forming  as an ordered sum of ’s and ’s:     . Cayley knew that the compositions with all parts bigger than  have Fibonacci counts. But who first knew that compositions with all parts odd are also counted by Fibonacci? Hopkins suggests: de Morgan, 1846.</p>
  </li>
  <li>
    <p>Despite new US covid cases being more or less the same level (or worse) as the start of the lockdown in March, <a href="https://www.chronicle.com/article/Faculty-Want-a-Say-in-Whether/248951">some universities are telling their students that it’s safe to return to normal and at the same time telling their faculty that unless they’re close to retirement age and have additional medical conditions, they must teach face to face</a> (<a href="https://mathstodon.xyz/@11011110/104318055800990449"/>).</p>
  </li>
  <li>
    <p><a href="https://drericsilverman.wordpress.com/games/">A nice page of recent writings about abstract strategy games, mostly connection games</a> (<a href="https://mathstodon.xyz/@jsiehler/104241019767261031"/>).</p>
  </li>
  <li>
    <p><a href="https://news.mit.edu/2020/guided-by-open-access-principles-mit-ends-elsevier-negotiations-0611">MIT gives up on trying to get an equitable subscription deal from Elsevier, ends negotiations</a> (<a href="https://mathstodon.xyz/@11011110/104326335350221116"/>, <a href="https://news.ycombinator.com/item?id=23489068">via</a>).</p>
  </li>
  <li>
    <p><em><a href="https://drops.dagstuhl.de/opus/portals/lipics/index.php?semnr=16150">The Proceedings of the 17th Scandinavian Symposium and Workshops on Algorithm Theory (SWAT 2020)</a></em> (<a href="https://mathstodon.xyz/@11011110/104334978432657954"/>), newly published open-access through LIPIcs. Sadly, the conference will be online rather than in the Faroe Islands as originally planned. <em><a href="https://drops.dagstuhl.de/opus/portals/lipics/index.php?semnr=16149">The Proceedings of the 36th International Symposium on Computational Geometry (SoCG 2020)</a></em> is also now out.</p>
  </li>
  <li>
    <p><a href="https://www.win.tue.nl/~kbuchin/proj/ruler/art/">Illuminate</a> (<a href="https://mathstodon.xyz/@11011110/104340239573347579"/>). An online puzzle based on the art gallery theorem, part of the media exposition of this year’s Symposium on Computational Geometry. See also the <a href="https://doi.org/10.4230/LIPIcs.SoCG.2020.80">theoretical writeup</a>.</p>
  </li>
  <li>
    <p><a href="https://link.springer.com/book/10.1007/978-1-84800-070-4">Skiena’s <em>Algorithm Design Manual</em></a> (<a href="https://mathstodon.xyz/@11011110/104349420443124730"/>, <a href="https://news.ycombinator.com/item?id=23529759">via</a>, <a href="https://news.ycombinator.com/item?id=23055340">via2</a>, <a href="https://www.metafilter.com/187489/Free-Textbooks">see also</a>), one of 500 Springer textbooks still available for free download from the publisher.</p>
  </li>
</ul></div>
    </content>
    <updated>2020-06-15T17:54:00Z</updated>
    <published>2020-06-15T17:54:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2020-06-16T00:55:22Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-3523309889572389823</id>
    <link href="https://blog.computationalcomplexity.org/feeds/3523309889572389823/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/06/presentations-of-diffie-helman-leave.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/3523309889572389823" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/3523309889572389823" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/06/presentations-of-diffie-helman-leave.html" rel="alternate" type="text/html"/>
    <title>Presentations of Diffie-Helman leave out how to find g</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">When I first taught Diffie Helman I read the following<br/>
1) Alice and Bob agree on p a prime and g a generator<br/>
2) Alice picks a, sends g^a to Bob, Bob picks b, sends g^b to Alice<br/>
3) Alice computes (g^b)^a and Bob computes (g^a)^b so they both have g^{ab}<br/>
<br/>
I knew how to find a prime- pick a number of length n (perhaps make sure the last digit is not even) and test for primality, if not then try again, you'll get one soon enough. I did not know how to find g. I had thought you<i> first </i>find p, and<i> then</i> given p you find g. I then figured out that you make actually pick  p to be a  <i>safe prime</i>, so q=(p-1)/2 is a prime, and then just pick random g and test them via computing  g^2  and g^q: if neither is 1 then g is a generator. You will find a generator soon enough.<br/>
<br/>
That was all fine. But how come my source didn't <i>say </i>how to find g.?You need to know that to run the algorithm. That was years ago. Then I wondered how common it is for an explanation to not say how to find g. So I Googled ``Diffie-Helman'' I only record those that had some technical content to them, and were not about other DH such as Elliptic Curves.<br/>
<br/>
0) <a href="http://www.cs.jhu.edu/~rubin/courses/sp03/papers/diffie.hellman.pdf">The Original DH paper</a> Page 34:<i> alpha is a fixed primitive element of GF(alpha)</i>. No mention of how to find either the prime q or the prim root alpha.<br/>
<br/>
1) <a href="https://en.wikipedia.org/wiki/Diffie%E2%80%93Hellman_key_exchange">Wikiepdia</a>: ... <i>protocol uses the mult group of integers mod p, where p is a prime and g is a prim</i> <i>root mod p</i>. NO mention of how they find p or g.<br/>
<br/>
2) <a href="https://mathworld.wolfram.com/Diffie-HellmanProtocol.html">Wolfram's MathWorld</a>:<i> They agree on two prime numbers g and p, where p is large and g is a prim root mod p. In practice it is good to choose p such that (p-1)/2 is also prime. </i>They mention (p-1)/2 but not for the reason I give. (There are algorithms for Discrete Log that do well if (p-1)/2 has many factors.)<br/>
<br/>
3) <a href="https://www.comparitech.com/blog/information-security/diffie-hellman-key-exchange/">Comparatech</a>: <i>Alice and Bob start out by deciding two numbers p and g.</i> No mention of how to find p or g.<br/>
<br/>
4) <a href="https://searchsecurity.techtarget.com/definition/Diffie-Hellman-key-exchange">Searchsecurity</a> Won't bother quoting, but more of the same, no mention of how to find p or g.<br/>
<br/>
5) <a href="https://doubleoctopus.com/security-wiki/encryption-and-cryptography/diffie-hellman-algorithm/">The Secret Security Wiki</a> <i>Alice and Bob agree on p and g</i>.<br/>
<br/>
6) <a href="https://www.sciencedirect.com/topics/computer-science/diffie-hellman">Science Direct</a> More of the same.<br/>
<br/>
7) <a href="https://www.math.ucla.edu/~baker/40/handouts/rev_DH/node1.html">Notes from a UCLA Crypto Course</a> YEAH! They say how to find g.<br/>
<br/>
8) <a href="https://brilliant.org/wiki/diffie-hellman-protocol/">Brilliant (yes that really is the name of this site)</a> Brilliant? Not brilliant enough to realize you need to say how to find p and g.<br/>
<br/>
9) <a href="https://wiki.openssl.org/index.php/Diffie_Hellman">OpenSSL</a> Hard to tell. Their intuitive explanation leaves it out, but they have details below and code that might have it.<br/>
<br/>
<br/>
I looked at a few more but it was the same story.<br/>
<br/>
This is NOT a RANT or even a complaint, but its a question:<br/>
<br/>
<b>Why do so few expositions of DH mention how to find p,g? You really need to do that if you really want to DO DH.</b><br/>
<b><br/></b>
Speculation<br/>
<br/>
1) Some of the above are for the laymen and hence can not get into that. But some are not.<br/>
<br/>
2) Some of them are for advanced audiences who would know how to do it. Even so, how to find the generator really needs to be mentioned.<br/>
<br/>
3) Goldilocks: Some papers are for the layman who would not notice the gap, and some papers are for the expert who can fill in the gap themselves, so no paper in between. I do not believe that.<br/>
<br/>
4) The oddest of the above is that the original paper did not say how to find g.<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/></div>
    </content>
    <updated>2020-06-15T15:17:00Z</updated>
    <published>2020-06-15T15:17:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2020-06-18T16:42:45Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2020/06/14/infinite-threshold-graphs</id>
    <link href="https://11011110.github.io/blog/2020/06/14/infinite-threshold-graphs.html" rel="alternate" type="text/html"/>
    <title>Infinite threshold graphs, four different ways</title>
    <summary>One of the difficulties of extending results from finite graphs to infinite ones is that it is not always obvious how to extend the definitions. A single class of finite graphs may correspond, in the infinite graph world, to several different natural classes of infinite graphs. One of the ways this can happen is through orderings: if a class of graphs has a natural ordering on its vertices (say, through a construction in which graphs in this class are built up by adding one vertex at a time) then we might get several classes of infinite graphs with different ways of restricting or not restricting this vertex ordering.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>One of the difficulties of extending results from finite graphs to infinite ones is that it is not always obvious how to extend the definitions. A single class of finite graphs may correspond, in the infinite graph world, to several different natural classes of infinite graphs. One of the ways this can happen is through orderings: if a class of graphs has a natural ordering on its vertices (say, through a construction in which graphs in this class are built up by adding one vertex at a time) then we might get several classes of infinite graphs with different ways of restricting or not restricting this vertex ordering.</p>

<p style="text-align: center;"><img alt="Threshold graph" src="https://11011110.github.io/blog/assets/2020/threshold.svg"/></p>

<p>As an example of this phenomenon, consider the <a href="https://en.wikipedia.org/wiki/Threshold_graph">threshold graphs</a>, one of the simplest classes of finite graphs. An example is shown above. These can be defined in multiple equivalent ways:</p>

<ul>
  <li>
    <p>The finite threshold graphs are the graphs that can be built up by repeatedly adding either a universal vertex or an isolated vertex to a smaller graph. In the example, the vertices have been added in left-to-right order, with isolated vertices depicted in yellow and universal vertices in blue. This can be formalized in a way that extends to infinite graphs by saying that they are the graphs in which every nonempty induced subgraph contains either a universal vertex or an isolated vertex. Let’s call these graphs the “inductive threshold graphs”.</p>
  </li>
  <li>
    <p>We can also construct graphs in the reverse ordering, by repeatedly adding a vertex whose neighbors form a clique and whose non-neighbors form an independent set. More concisely, the vertex is both simplicial and cosimplicial. The example above can be constructed in this way by adding the vertices in right-to-left order, with the blue neighbors of each added vertex forming a clique and the yellow neighbors forming an independent set. This can be formalized in a way that extends to infinite graphs by requiring that every induced subgraph has a vertex that is simplicial and cosimplicial. Let’s call a graph with this property a “coinductive threshold graph”.</p>
  </li>
  <li>
    <p>The finite threshold graphs are the -free finite graphs, meaning that no four vertices form an induced subgraph that is a path, cycle, or perfect matching.</p>
  </li>
  <li>
    <p>The finite threshold graphs get their name from the following property: they are the graphs that we can generate by assigning weights in the interval  to the vertices and connecting two vertices by an edge whenever their sum of weights is at least one. Let’s call a graph with this property a “real threshold graph”.</p>
  </li>
</ul>

<p>All four of these properties are <a href="https://en.wikipedia.org/wiki/Hereditary_property">hereditary</a>: if a graph has the property, so do all its induced subgraphs. Because the three forbidden subgraphs , , and  have no universal or isolated vertex, have no simplicial and cosimplicial vertex, and have no valid weight assignment, the inductive threshold graphs, coinductive threshold graphs, and real threshold graphs are all subclasses of the -free graphs.</p>

<p>If a graph is -free, we can define a relation  on its vertices by saying that  if there is no vertex  with  forming an induced path or complement of a path. It follows from the nonexistence of the forbidden subgraphs that this is a total preorder, that every vertex  is universal or isolated among the vertices , and that every vertex  is simplicial and cosimplicial among the vertices . In the example above, two vertices are in the same equivalence class of the ordering if they are in a contiguous block of vertices with the same color, and otherwise their ordering according to  is the same as their left-to-right ordering. Because every finite total preorder has a minimal and a maximal element, every finite -free graph is an inductive threshold graph and a coinductive threshold graph.</p>

<p>However, these properties differ for infinite graphs. In an infinite inductive threshold graph, the total preorder must obey the <a href="https://en.wikipedia.org/wiki/Ascending_chain_condition">ascending chain condition</a> that there be no strictly-increasing infinite sequence of vertices, for the subgraph induced by the vertices of such a sequence would have no isolated or universal vertex. Conversely, if the order does obey the ascending chain condition, one could find an isolated or universal vertex in any subgraph by starting from an arbitrary vertex and repeatedly moving upwards in the order until getting stuck. So the inductive threshold graphs are exactly the ones whose order obeys the ascending chain condition. Similarly, the coinductive threshold graphs are exactly the ones whose order obeys the descending chain condition. But it is easy to construct orders that violate one or both of these conditions. A graph can only be a real threshold graph if the total order on the equivalence classes of its preorder can be embedded into , and again this is not true of all total orders.</p>

<p>One consequence of this difference between classes of infinite graphs is the construction of natural statements in the first-order <a href="https://en.wikipedia.org/wiki/Logic_of_graphs">logic of graphs</a> that are true for all finite graphs but untrue for some infinite graphs. For instance, the statements that a -free graph has an isolated or universal vertex, and that a -free graph has a simplicial and cosimplicial vertex, are both true of all finite graphs, but untrue of some infinite graphs.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/104345188939710302">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2020-06-14T15:50:00Z</updated>
    <published>2020-06-14T15:50:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2020-06-16T00:55:22Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/091</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/091" rel="alternate" type="text/html"/>
    <title>TR20-091 |  Randomized polynomial-time equivalence between determinant and trace-IMM equivalence tests | 

	Janaky Murthy, 

	vineet nair, 

	Chandan Saha</title>
    <summary>Equivalence testing for a polynomial family $\{g_m\}_{m \in \mathbb{N}}$ over a field F is the following problem: Given black-box access to an $n$-variate polynomial $f(\mathbb{x})$, where $n$ is the number of variables in $g_m$ for some $m \in \mathbb{N}$, check if there exists an $A \in \text{GL}(n,\text{F})$ such that $f(\mathbb{x}) = g_m(A\mathbb{x})$. If yes, then output such an $A$. The complexity of equivalence testing has been studied for a number of important polynomial families, including the determinant (Det) and the family of iterated matrix multiplication polynomials. Two popular variants of the iterated matrix multiplication polynomial are: IMM$_{w,d}$ (the $(1,1)$ entry of the product of $d$ many $w\times w$  symbolic matrices) and Tr-IMM$_{w,d}$ (the trace of the product of $d$ many $w\times w$ symbolic matrices). The families - Det, IMM and Tr-IMM - are VBP-complete under $p$-projections, and so, in this sense, they have the same complexity. But, do they have the same equivalence testing complexity? We show that the answer is 'yes' for Det and Tr-IMM (modulo the use of randomness). 

The above result may appear a bit surprising as the complexity of equivalence testing for IMM and that for Det are quite different over rationals: a randomized polynomial-time equivalence testing for IMM over rationals is known [Kayal,Nair,Saha,Tavenas 2019], whereas [Garg,Gupta,Kayal,Saha 2019] showed that equivalence testing for Det over rationals is integer factoring hard (under randomized reductions and assuming GRH). To our knowledge, the complexity of equivalence testing for Tr-IMM was not known before this work. We show that, despite the syntactic similarity between IMM and Tr-IMM, equivalence testing for Tr-IMM and that for Det are randomized polynomial-time Turing reducible to each other over any field of characteristic zero or sufficiently large. The result is obtained by connecting the two problems via another well-studied problem in computer algebra, namely the full matrix algebra isomorphism problem (FMAI). In particular, we prove the following: 

1.Testing equivalence of polynomials to Tr-IMM$_{w,d}$, for $d\geq 3$ and $w\geq 2$, is randomized polynomial-time Turing reducible to testing equivalence of polynomials to Det$_w$, the determinant of the $w \times w$ matrix of formal variables. (Here, $d$ need not be a constant.)

2. FMAI is randomized polynomial-time Turing reducible to equivalence testing (in fact, to tensor isomorphism testing) for the family of matrix multiplication tensors $\{$Tr-IMM$_{w,3}\}_{w \in \mathbb{N}}$.

These results, in conjunction with the randomized poly-time reduction (shown in [GGKS19]) from determinant equivalence testing to FMAI, imply that the four problems - FMAI, equivalence testing for Tr-IMM and for Det, and the $3$-tensor isomorphism problem for the family of matrix multiplication tensors - are randomized poly-time equivalent under Turing reductions.</summary>
    <updated>2020-06-14T13:41:43Z</updated>
    <published>2020-06-14T13:41:43Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-06-19T00:20:25Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=17191</id>
    <link href="https://rjlipton.wordpress.com/2020/06/13/proof-checking-not-line-by-line/" rel="alternate" type="text/html"/>
    <title>Proof Checking: Not Line by Line</title>
    <summary>Proofs and perpetual motion machines Leonardo da Vinci is, of course, famous for his paintings and drawings, but was also interested in inventions, and in various parts of science including mathematics and engineering. It is hard to imagine that he died over 500 years ago, given his continued impact on our world. He invented practical […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Proofs and perpetual motion machines</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<p><a href="https://rjlipton.files.wordpress.com/2020/06/picture.png"><img alt="" class="alignright  wp-image-17193" height="150" src="https://rjlipton.files.wordpress.com/2020/06/picture.png?w=200&amp;h=150" width="200"/></a></p>
<p>
Leonardo da Vinci is, of course, famous for his paintings and drawings, but was also interested in inventions, and in various parts of science including mathematics and engineering. It is hard to imagine that he died over 500 years ago, given his continued impact on our world. He invented practical and impractical <a href="https://en.wikipedia.org/wiki/Leonardo_da_Vinci">inventions</a>: musical instruments, a mechanical knight, hydraulic pumps, reversible crank mechanisms, finned mortar shells, and a steam cannon.</p>
<p>
Today I wish to discuss proofs and perpetual motion machines.</p>
<p>
You might ask: <i>What do proofs and perpetual motion machines have in common?</i> Proofs refer to math proofs that claim to solve open problems like P <img alt="{\neq}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cneq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\neq}"/> NP. Ken and I get such claims all time. I take a look at them, not because I think they are likely to be correct. Rather because I am interested in understanding how people think. </p>
<p>
I started to work on discussing such proofs when I realized that such “proofs” are related to claims about perpetual motion machines. Let’s see how.</p>
<p>
</p><p/><h2> Perpetual Motion Machines </h2><p/>
<p/><p>
A perpetual motion <a href="https://en.wikipedia.org/wiki/Perpetual_motion">machine</a> is a machine that operates indefinitely without an energy source. This kind of machine is impossible, as da Vinci knew already:</p>
<blockquote><p><b> </b> <em> Oh ye seekers after perpetual motion, how many vain chimeras have you pursued? Go and take your place with the alchemists. <br/>
—da Vinci, 1494 </em>
</p></blockquote>
<p/><p>
I like this statement about applying for US patents on such machines: </p>
<blockquote><p><b> </b> <em> Proposals for such inoperable machines have become so common that the United States Patent and Trademark Office (USPTO) has made an official policy of refusing to grant patents for perpetual motion machines without a working model. </em>
</p></blockquote>
<p/><p>
Here is a classic attempt at perpetual motion: The motion goes on “forever” since the right side floats up and the left side falls down. </p>
<p><a href="https://rjlipton.files.wordpress.com/2020/06/float.png"><img alt="" class="aligncenter size-full wp-image-17194" src="https://rjlipton.files.wordpress.com/2020/06/float.png?w=600"/></a></p>
<p>
The analogy of proofs and to perpetual motion machines is: The debunking such a machine is not done by looking carefully at each gear and lever to see why the machine fails to work. Rather is done like this: </p>
<blockquote><p><b> </b> <em> Your machine violates the fundamental laws of thermodynamics and is thus impossible. </em>
</p></blockquote>
<p>Candidate machines are not studied to find the exact flaw in their design. The force of fundamental laws allows a sweeping, simple, and powerful argument against them. There are similar ideas in checking a proof. Let’s take a look at them.</p>
<p>
</p><p/><h2> Proofs </h2><p/>
<p/><p>
Claims are made about proofs of open problems all the time. Often these are made for solutions to famous open problems, like P<img alt="{\neq}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cneq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\neq}"/>NP or the Riemann Hypothesis (RH).</p>
<p>
Math proofs are used to try to get to the <i>truth</i>. As we said <a href="https://rjlipton.wordpress.com/2019/04/24/why-check-a-proof/">before</a> proofs are only as good as the assumptions made and the rules invoked. The beauty of the proof concept is that arguments can be checked, even long and complex ones. If the assumptions and the rules are correct, then no matter how strange the conclusion is, it must be true.</p>
<p>
For <a href="https://math.stackexchange.com/questions/2949/which-one-result-in-mathematics-has-surprised-you-the-most">example</a>:</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> The Riemann rearrangement <a href="https://en.wikipedia.org/wiki/Ri emann_series_theorem#Statement_of_the_theorem">theorem</a>. A sum 	</p>
<p align="center"><img alt="\displaystyle  a_{1} + a_{2} + a_{3} + \dots " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++a_%7B1%7D+%2B+a_%7B2%7D+%2B+a_%7B3%7D+%2B+%5Cdots+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  a_{1} + a_{2} + a_{3} + \dots "/></p>
<p>that is conditionally convergent can be reordered to yield any number. Thus there is series 	</p>
<p align="center"><img alt="\displaystyle  b_{1} + b_{2} + b_{3} + \dots " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++b_%7B1%7D+%2B+b_%7B2%7D+%2B+b_%7B3%7D+%2B+%5Cdots+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  b_{1} + b_{2} + b_{3} + \dots "/></p>
<p>that sums conditionally to your favorite number <img alt="{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M}"/> and yet the <img alt="{b_{1},b_{2},\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb_%7B1%7D%2Cb_%7B2%7D%2C%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{b_{1},b_{2},\dots}"/> is just a arrangement of the <img alt="{a_{1},a_{2},\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba_%7B1%7D%2Ca_%7B2%7D%2C%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a_{1},a_{2},\dots}"/>. This says that addition is not commutative for infinite series.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> Cover the largest triangle by two <a href="https://www2.stetson.edu/~efriedma/squcotri/">unit squares</a>: what is the best? The following shows that it is unexpected: </p>
<p/><p/>
<p><a href="https://rjlipton.files.wordpress.com/2020/06/cover.png"><img alt="" class="aligncenter size-full wp-image-17195" src="https://rjlipton.files.wordpress.com/2020/06/cover.png?w=600"/></a></p>
<p/><p><br/>
The point of a proof is that it is a series of small steps. If each step is correct, then the whole is correct. But in practice proofs are often checked in other ways.</p>
<p>
</p><p/><h2> Checking Proofs </h2><p/>
<p/><p>
The starting point for my thoughts—joined here with Ken’s—are these two issues:</p>
<ol>
<li>
A proof that <em>only</em> has many small steps but no global picture is hard to motivate. <p/>
</li><li>
A proof with complex logic at the high level is hard to understand.
</li></ol>
<p>
Note that a deep, hard theorem can still have straightforward logic. A famous <a href="https://en.wikipedia.org/wiki/Riemann_hypothesis#Littlewood's_theorem">theorem</a> of Littlewood has for its proof the structure:</p>
<ul>
<li>
Case the RH is false: Then <img alt="{\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\dots}"/> <p/>
</li><li>
Case the RH is true: Then <img alt="{\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\dots}"/>
</li></ul>
<p>
The RH-false case takes under a page. The benefit with this logic is that one gets to assume RH for the rest. The strategy for the famous proof by Andrew Wiles of Fermat’s Last Theorem (FLT)—incorporating the all-important fix by Richard Taylor—has this structure:</p>
<ul>
<li>
If <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X}"/> then <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y}"/>. <p/>
</li><li>
If not-<img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X}"/> then <img alt="{Z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BZ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Z}"/>. <p/>
</li><li>
<img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y}"/> implies FLT. <p/>
</li><li>
<img alt="{Z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BZ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Z}"/> implies FLT.
</li></ul>
<p>
Wiles had done the last step long before but had put aside since he didn’t know how to get <img alt="{Z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BZ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Z}"/>. The key was framing <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X}"/> so that it enabled bridged the gap in his originally-announced proof while its negation enabled the older proof.</p>
<p>
Thus what we should seek are proofs with simple logic at the high level that breaks into cases or into sequential sub-goals so that the proof is a chain or relatively few of those goals. </p>
<p>
</p><p/><h2> Shapes and Barriers </h2><p/>
<p/><p>
This makes Ken and I think again about an old <a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.73.7682">paper</a> by Juris Hartmanis with his students Richard Chang, Desh Ranjan, and Pankaj Rohatgi in the May 1990 <em>Bulletin of the EATCS</em> titled, “On IP=PSPACE and Theorems With Narrow Proofs.” Ken’s <a href="https://rjlipton.wordpress.com/2015/05/17/the-shapes-of-computations/">post</a> on it included this nice diagram of what the paper calls “shapes of proofs”:</p>
<p><a href="https://rjlipton.files.wordpress.com/2020/06/proofshapes.png"><img alt="" class="aligncenter  wp-image-17197" height="252" src="https://rjlipton.files.wordpress.com/2020/06/proofshapes.png?w=400&amp;h=252" width="400"/></a></p>
<p/><p><br/>
Ken’s thought now is that this taxonomy needs to be augmented with a proof shape corresponding to certain classes believed to be properly below polynomial time—classes within the <a href="https://en.wikipedia.org/wiki/NC_(complexity)">NC</a> hierarchy. Those proofs branch at the top into manageable-size subcases, and/or have a limited number of sequential stages, where each stage may be wide but is shallow in its chains of dependencies. Call this shape a “macro-tree.”</p>
<p>
The difference between the macro-tree shape and the sequential shapes pictured above is neatly captured by Ashley Ahlin on a <a href="http://www.math.wichita.edu/~pparker/classes/thms.htm">page</a> about “Reading Theorems”:</p>
<blockquote><p><b> </b> <em> Note that, in some ways, the easiest way to read a proof is to check that each step follows from the previous ones. This is a bit like following a game of chess by checking to see that each move was legal, or like running a spell-checker on an essay. It’s important, and necessary, but it’s not really the point. … The problem with this is that you are unlikely to remember anything about how to prove the theorem, if you’ve only read in this manner. Once you’re read a theorem and its proof, you can go back and ask some questions to help synthesize your understanding. </em>
</p></blockquote>
<p/><p>
The other high-level structure that a proof needs to make evident—before seeing it is reasonable to expend the effort to check it—is shaped by <em>barriers</em>. We have <a href="https://rjlipton.wordpress.com/2012/11/29/barriers-to-pnp-proofs/">touched</a> on <a href="https://rjlipton.wordpress.com/2013/03/13/no-go-theorems/">this</a> topic <a href="https://rjlipton.wordpress.com/2009/03/25/whos-afraid-of-natural-proofs/">several</a> <a href="https://rjlipton.wordpress.com/2019/04/18/a-reason-why-circuit-lower-bounds-are-hard/">times</a> but maybe have not stated it full on for P versus NP. A recent <a href="http://theory.stanford.edu/~liyang/teaching/projects/formal-barriers-to-proving-P-ne-NP.pdf">essay</a> for a course led by Li-Yang Tan at Stanford does so in just a few pages. A proof should state up front how it works around barriers, and this alone makes its strategy easier to follow.</p>
<p>
The idea of barriers extends outside P versus NP, of course. Peter Scholze seems to be invoking it in a <a href="https://www.math.columbia.edu/~woit/wordpress/?p=11709&amp;cpage=1#comment-235940">comment</a> two months ago in a <a href="https://www.math.columbia.edu/~woit/wordpress/?p=11709">post</a> by Peter Woit in April on the status of Shinichi Mochizuki’s claimed proof of the ABC conjecture:</p>
<blockquote><p><b> </b> <em> I may have not expressed this clearly enough in my manuscript with Stix, but there is just no way that anything like what Mochizuki does can work. … The reason it cannot work is a[nother] theorem of Mochizuki himself. … If the above claims [which are negated by the theorem] would have been true, I would see how Mochizuki’s strategy might have a nonzero chance of succeeding. … </em>
</p></blockquote>
<p/><p>
Thus what Ken and I conclude is that in order for a proof to be checkable <em>chunk by chunk</em>—not line by line—it needs to have:</p>
<ol>
<li>
A top-level decomposition into a relatively small number of components and stages—like legs in a sailing race—and <p/>
</li><li>
A demonstration of how the stages navigate around known barriers.
</li></ol>
<p>
Lack of a clear plan in the first already says the proof attempt cannot avoid being snagged on a barrier, as surely as natural laws prevent building a perpetual-motion machine.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Does this help in ascertaining what shape a proof that resolves the P versus NP problem must have?</p>
<p/></font></font></div>
    </content>
    <updated>2020-06-14T01:33:31Z</updated>
    <published>2020-06-14T01:33:31Z</published>
    <category term="All Posts"/>
    <category term="History"/>
    <category term="Ideas"/>
    <category term="P=NP"/>
    <category term="Proofs"/>
    <category term="Teaching"/>
    <category term="barriers"/>
    <category term="Leonardo da Vinci"/>
    <category term="perpetual motion"/>
    <category term="proof checking"/>
    <category term="shapes of proofs"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2020-06-19T00:20:38Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://agtb.wordpress.com/?p=3504</id>
    <link href="https://agtb.wordpress.com/2020/06/14/submitting-papers-to-jet/" rel="alternate" type="text/html"/>
    <title>Suggestions for computer scientists submitting papers to JET</title>
    <summary>Guest post by Tilman Borgers (JET Lead Editor), Marciano Siniscalchi (JET Editor), and Jason Hartline (JET Associate Editor): The Journal of Economic Theory (JET) would like to encourage submissions from computer scientists. JET is a leading journal of the economic theory community, and has a broader readership among economists and covers a broader range of […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><i>Guest post by <a href="http://www-personal.umich.edu/~tborgers/">Tilman Borgers</a> (JET Lead Editor), <a href="https://faculty.wcas.northwestern.edu/~msi661/">Marciano Siniscalchi</a> (JET Editor), and <a href="https://sites.northwestern.edu/hartline/">Jason Hartline</a> (JET Associate Editor):</i></p>
<p>The <a href="https://www.journals.elsevier.com/journal-of-economic-theory">Journal of Economic Theory (JET)</a> would like to encourage submissions from computer scientists. JET is a leading journal of the economic theory community, and has a broader readership among economists and covers a broader range of topics than other theory journals. JET is also the first field journal of the economic theory community, having been founded more than 50 years ago. Many publications in JET in those 50 years have changed not just the direction of economic theory, but also the direction of economics overall.</p>
<p>The convergence of research interests of computer scientists and economic theorists has been a remarkable development, and JET would like to do more to help facilitate the exchange of ideas across fields. Therefore, we compile here some suggestions for computer scientists who are interested in submitting their work to JET.</p>
<p>The basic standard for a publication in JET is that the paper should be original, make a substantial contribution, and be of interest to a broad group of readers, and this group should include economic theorists. Of course, editors make subjective, and fallible, judgments when assessing whether a paper meets these criteria. Typically, the substantive contribution is a contribution to economic theory, i.e. to our understanding of models of markets, strategic games, mechanisms, etc. Papers may be computer-science centric in its contributions, but then these contributions should be on a topic of interest to economists. For example, new algorithmic results related to game theory or mechanism design may be of interest to JET, if it is the editors’ judgment that these algorithms will be of interest to economists. On the other hand, results on more applied computational problems, such as faster algorithms for winner determination in auctions, or for clearing prediction markets, may be out of scope for JET.</p>
<p>In terms of style, successful JET submissions include an introduction that is accessible to a broad theory audience, and that explains the motivation for the work, overviews the main results, and explains some key intuitions. The introduction, or a separate literature review section, should precisely situate the work relative to the most closely related research. The main body of the paper should explain the model rigorously, and state the results precisely. Proofs which are not very long, and which provide insight, are typically included in the main body of the paper, whereas other proofs are moved to an appendix. It is often useful to paraphrase results in words after stating them formally, and to give explanations of intuitions as well as explanations of proof structures. We encourage authors to make their work as simple as is possible without losing the main message.</p>
<p>There is no length limit per se, but published papers have rarely more than 40 pages, including appendix and references, in print. We value conciseness, and focus on a main theme throughout the paper. Minor results can be left out. On the other hand, we do provide authors with the space needed to be precise and clear.</p>
<p>One general recommendation for computer science authors in preparing manuscripts for economics journals is to have an economist colleague look over the paper before submitting.  This is a good way to identify inaccurate assumptions about readers’ knowledge, or omitted relationships to the prior literature in economics.  Such advice can also help better motivate the results of the paper from an economic perspective.</p>
<p>To be publishable, if an earlier version of a paper was published as an extended abstract in conference proceedings, then the journal version must make additional contributions beyond the conference version.  This additional contribution may include important conceptual aspects of economic interest that were omitted from the original extended abstract, proofs that were omitted from the extended abstract, and additional results that did not appear in the extended abstract. Authors should explain the differences between the conference version and the journal version in a cover letter. Papers that have previously appeared as one or two page abstracts in a conference volume do not need to distinguish themselves.  Mentioning these appearances in a cover letter would useful, however.</p></div>
    </content>
    <updated>2020-06-14T00:53:10Z</updated>
    <published>2020-06-14T00:53:10Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Jason Hartline</name>
    </author>
    <source>
      <id>https://agtb.wordpress.com</id>
      <logo>https://secure.gravatar.com/blavatar/52ef314e11e379febf97d1a97547f4cd?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fbuttonw-com.png</logo>
      <link href="https://agtb.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://agtb.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://agtb.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://agtb.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Computation, Economics, and Game Theory</subtitle>
      <title>Turing's Invisible Hand</title>
      <updated>2020-06-19T00:20:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://grigory.github.io/blog/theory-jobs-2020</id>
    <link href="http://grigory.github.io/blog/theory-jobs-2020/" rel="alternate" type="text/html"/>
    <title xml:lang="en">Theory Jobs 2020</title>
    <content type="xhtml" xml:lang="en"><div xmlns="http://www.w3.org/1999/xhtml"><p>It’s been an unusually challenging year for both sides of the TCS job market with some unexpected obstacles and delays. Apologies for putting up the spreadsheet later than usual and congrats to both sides in each converged process!</p>

<p><a href="https://docs.google.com/spreadsheets/d/1kzq4xVyU1k5CUTrV0yjIgzqlcv8agZqN_jiVlbYJb9g/edit?usp=sharing">Here is a link</a> to a crowdsourced spreadsheet created to collect information about theory jobs this year. 
I put in a biased pseudorandom seed, please help populate and share!
Rules for the spreadsheet have been copied from previous years (with one substantial suggestion regarding senior hires based on one of my friends’ recommendation, see below) and all edits to the document are anonymized. Please, post a comment if you have any suggestions about the rules.</p>
<ul>
 <li>Separate sheets for faculty, industry and postdocs/visitors. </li>
 <li>People should be connected to theoretical computer science, broadly defined.</li>
 <li>Only add jobs that you are absolutely sure have been offered and accepted. This is not the place for speculation and rumors. <b>New:</b> Please, be particularly careful when adding senior hires (people who already have an academic or industrial job) -- end dates of their current positions might be still in the future. </li>
 <li>You are welcome to add yourself, or people your department has hired. </li>
</ul>


  <p><a href="http://grigory.github.io/blog/theory-jobs-2020/">Theory Jobs 2020</a> was originally published by Grigory Yaroslavtsev at <a href="http://grigory.github.io/blog">The Big Data Theory</a> on June 14, 2020.</p></div>
    </content>
    <updated>2020-06-14T00:00:00Z</updated>
    <published>2020-06-14T00:00:00Z</published>
    <author>
      <name>Grigory Yaroslavtsev</name>
      <email>grigory@grigory.us</email>
      <uri>http://grigory.github.io/blog</uri>
    </author>
    <source>
      <id>http://grigory.github.io/blog/</id>
      <author>
        <name>Grigory Yaroslavtsev</name>
        <email>grigory@grigory.us</email>
        <uri>http://grigory.github.io/blog/</uri>
      </author>
      <link href="http://grigory.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="http://grigory.github.io/blog" rel="alternate" type="text/html"/>
      <title xml:lang="en">The Big Data Theory</title>
      <updated>2020-06-15T04:23:19Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/06/12/phd-positions-at-international-max-planck-research-school-on-trustworthy-computing-apply-by-june-30-2020/</id>
    <link href="https://cstheory-jobs.org/2020/06/12/phd-positions-at-international-max-planck-research-school-on-trustworthy-computing-apply-by-june-30-2020/" rel="alternate" type="text/html"/>
    <title>PhD Positions at International Max Planck Research School on Trustworthy Computing (apply by June 30, 2020)</title>
    <summary>The International Max Planck Research School on Trustworthy Computing is a graduate program jointly run by the Max Planck Institutes for Informatics and Software Systems, Saarland University, and TU Kaiserslautern. It offers a fully funded PhD program that leads to a doctoral degree from one of the participating universities and is open to students with […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The International Max Planck Research School on Trustworthy Computing is a graduate program jointly run by the Max Planck Institutes for Informatics and Software Systems, Saarland University, and TU Kaiserslautern. It offers a fully funded PhD program that leads to a doctoral degree from one of the participating universities and is open to students with a degree in computer science or equivalent.</p>
<p>Website: <a href="https://www.imprs-trust.mpg.de">https://www.imprs-trust.mpg.de</a><br/>
Email: imprs@mpi-klsb.mpg.de</p></div>
    </content>
    <updated>2020-06-12T19:45:16Z</updated>
    <published>2020-06-12T19:45:16Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-06-19T00:20:42Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2020/06/12/logic-mentoring-workshop-2020/</id>
    <link href="https://cstheory-events.org/2020/06/12/logic-mentoring-workshop-2020/" rel="alternate" type="text/html"/>
    <title>Logic Mentoring Workshop 2020</title>
    <summary>July 6, 2020 Online http://lmw.mpi-sws.org/index.html The Logic Mentoring Workshop (LMW) will introduce young researchers to the technical and practical aspects of a career in logic research. It is targeted at students, from senior undergraduates to graduates, and will include talks and a panel session from leaders in the subject.</summary>
    <updated>2020-06-12T18:31:23Z</updated>
    <published>2020-06-12T18:31:23Z</published>
    <category term="workshop"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2020-06-19T00:21:21Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://agtb.wordpress.com/?p=3496</id>
    <link href="https://agtb.wordpress.com/2020/06/12/virtual-ec-2020/" rel="alternate" type="text/html"/>
    <title>Virtual EC 2020</title>
    <summary>EC 2020 will be held virtually with events from June 15 to July 22 (details of virtual format).  Participation by members of related fields is strongly encouraged.   Since 1999 the ACM Special Interest Group on Economics and Computation (SIGecom) has sponsored the leading scientific conference on advances in theory, empirics, and applications at the interface […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>EC 2020 will be held virtually with events from June 15 to July 22 (<a href="http://ec20.sigecom.org/participation/covid/">details of virtual format</a>).  Participation by members of related fields is strongly encouraged.  </p>



<p>Since 1999 the ACM Special Interest Group on Economics and Computation (<a href="http://sigecom.org/">SIGecom</a>) has sponsored the leading scientific conference on advances in theory, empirics, and applications at the interface of economics and computation. The 21st ACM Conference on Economics and Computation (<a href="http://ec20.sigecom.org/">Virtual EC 2020</a>) will feature invited speakers, a highlight of papers from other conferences and journals, a technical program of submitted paper presentations and posters, workshops, and tutorials.  </p>



<p>Registration is mandatory (<a href="http://ec20.sigecom.org/participation/registration/">register here</a>) but complimentary with SIGecom membership of $10 ($5 for students).  Details on joining EC events will be emailed to registered participants.</p>



<p>An overview of the schedule:</p>



<p><strong>June 15 – 19:</strong> <a href="http://ec20.sigecom.org/program/mentoring-workshop">Mentoring Workshop</a> and <a href="http://ec20.sigecom.org/program/workshops-tutorials/">Live Tutorial Pre-recording Sessions</a>.<br/>
<strong>June 22 – July 3:</strong> <a href="http://ec20.sigecom.org/program/pre-recording/">Live EC Paper Pre-recording Plenary Sessions</a>.<br/>
<strong>July 13:</strong> <a href="http://ec20.sigecom.org/program/workshops-tutorials/">Tutorial Watch Parties</a>, Business Meeting, and <a href="http://ec20.sigecom.org/call-for-contributions-acm/posters/">Poster Session</a><br/>
<strong>July 14 – 16:</strong> <a href="http://ec20.sigecom.org/program/main/">EC Conference</a> (Paper Watch Parties, Paper Poster Sessions, and Plenaries).<br/>
<strong>July 17 – 22:</strong> <a href="http://ec20.sigecom.org/program/workshops-tutorials/">Workshops</a>.</p>



<p>Areas of interest include, but are not limited to:</p>



<p><strong>Design of economic mechanisms:</strong> algorithmic mechanism design; market design; matching; auctions; revenue maximization; pricing; fair division; computational social choice; privacy and ethics.</p>



<p><strong>Game theory:</strong> equilibrium computation; price of anarchy; learning in games.</p>



<p><strong>Information elicitation and generation:</strong> prediction markets; recommender, reputation and trust systems; social learning; data markets.</p>



<p><strong>Behavioral models:</strong> behavioral game theory and bounded rationality; decision theory; computational social science; agent-based modeling.</p>



<p><strong>Online systems:</strong> online advertising; electronic commerce; economics of cloud computing; social networks; crowdsourcing; ridesharing and transportation; labor markets; cryptocurrencies; industrial organization.</p>



<p><strong>Methodological developments:</strong> machine learning; econometrics; data mining.</p></div>
    </content>
    <updated>2020-06-12T16:09:54Z</updated>
    <published>2020-06-12T16:09:54Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Jason Hartline</name>
    </author>
    <source>
      <id>https://agtb.wordpress.com</id>
      <logo>https://secure.gravatar.com/blavatar/52ef314e11e379febf97d1a97547f4cd?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fbuttonw-com.png</logo>
      <link href="https://agtb.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://agtb.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://agtb.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://agtb.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Computation, Economics, and Game Theory</subtitle>
      <title>Turing's Invisible Hand</title>
      <updated>2020-06-19T00:20:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://emanueleviola.wordpress.com/?p=771</id>
    <link href="https://emanueleviola.wordpress.com/2020/06/12/cifellows2020-in-theoretical-computer-science-and-computational-complexity-theory/" rel="alternate" type="text/html"/>
    <title>CIFellows2020 in Theoretical Computer Science and Computational Complexity Theory</title>
    <summary>This post is to advertise the CIFellow program 2020, and my availability. People who are looking for a postdoctoral position in theoretical computer science please consider getting in touch with me. The deadline for the application is in 5 days, and if possible complete part of it by today.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>This post is to advertise the <a href="https://cifellows2020.org/">CIFellow program 2020</a>, and my availability.  People who are looking for a postdoctoral position in theoretical computer science please consider getting in touch with me.  The deadline for the application is in 5 days, and if possible complete part of it by today.</p></div>
    </content>
    <updated>2020-06-12T12:44:04Z</updated>
    <published>2020-06-12T12:44:04Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Manu</name>
    </author>
    <source>
      <id>https://emanueleviola.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://emanueleviola.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://emanueleviola.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://emanueleviola.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://emanueleviola.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>by Manu</subtitle>
      <title>Thoughts</title>
      <updated>2020-06-19T00:21:02Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://decentralizedthoughts.github.io/2020-06-12-optimal-optimistic-responsiveness/</id>
    <link href="https://decentralizedthoughts.github.io/2020-06-12-optimal-optimistic-responsiveness/" rel="alternate" type="text/html"/>
    <title>On the Optimality of Optimistic Responsiveness</title>
    <summary>Synchronous consensus protocols tolerating Byzantine failures depend on the maximum network delay $\Delta$ for their safety and progress. The delay, $\Delta$ is usually much larger than actual network delay $\delta$ since $\Delta$ is a pessimistic value. While synchronous protocols tolerating more than one-third will have executions with at least a...</summary>
    <updated>2020-06-12T08:10:00Z</updated>
    <published>2020-06-12T08:10:00Z</published>
    <source>
      <id>https://decentralizedthoughts.github.io</id>
      <author>
        <name>Decentralized Thoughts</name>
      </author>
      <link href="https://decentralizedthoughts.github.io" rel="alternate" type="text/html"/>
      <link href="https://decentralizedthoughts.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Decentralized thoughts about decentralization</subtitle>
      <title>Decentralized Thoughts</title>
      <updated>2020-06-18T23:32:20Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4845</id>
    <link href="https://www.scottaaronson.com/blog/?p=4845" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4845#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4845" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Book Review: “Will He Go?”</title>
    <summary xml:lang="en-US">Will He Go?, by legal scholar Lawrence Douglas, is, at 120 pages, a slim volume focused on a single question: what happens if the 2020 US election delivers a narrow or disputed result favoring Biden, and Trump refuses to concede? This question will, of course, either be answered or rendered irrelevant in half a year. […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="https://www.amazon.com/Will-He-Go-Election-Meltdown/dp/1538751887">Will He Go?</a>, by legal scholar Lawrence Douglas, is, at 120 pages, a slim volume focused on a single question: <em>what happens if the 2020 US election delivers a narrow or disputed result favoring Biden, and Trump refuses to concede?</em>  This question will, of course, either be answered or rendered irrelevant in half a year.  And yet, in my estimation, there’s at least a 15% probability that <em>Will He Go?</em> will enter the ranks of the most important and prescient books ever written.  You should read it right now (or at least read <a href="https://www.vox.com/policy-and-politics/2020/6/3/21257133/trump-2020-election-meltdown-lawrence-douglas">this Vox interview</a>), if you want to think through the contours of a civilizational Singularity that seems at least as plausible to me as the AI Singularity, but whose fixed date of November 3, 2020 we’re now hurtling toward.</p>



<p>In one of the defining memes of the past few years, a sign in a bookstore reads “Dear customers: post-apocalyptic fiction has been moved to the Current Affairs section.”  I was reminded of that as Douglas dryly lays out his horror scenario: imagine, hypothetically, that a President of the United States gets elected on a platform of racism and lies, with welcomed assistance from a foreign adversary.  Suppose that his every outrage only endears him further to his millions of followers.  Suppose that, as this president’s deepest (and perhaps only) principle, he never backs down, never apologizes, never acknowledges any inconvenient fact, and never accepts the legitimacy of any contest that he loses—and <em>this is perfectly rational for him, </em>as he’s been richly rewarded for this strategy his entire life.  Suppose that, during the final presidential debate, he pointedly refuses to promise to respect the election outcome if he loses—a first in American history.  And suppose that, after eking out a narrow win in the Electoral College, he then turns around and <em>disputes the election anyway</em> (!)—claiming, ludicrously, that he would’ve won the popular vote too, if not for millions of fraudulent voters.  Suppose that, for their own sordid reasons, Republican majorities in the Senate and Supreme Court enable this president’s chaotic rule, block his impeachment, and acquiesce to his daily cruelties and lies.</p>



<p>Then what happens in the <em>next</em> election?</p>



<p>Taking the existing catastrophe as given, Douglas asks: is America’s Constitutional machinery up to a challenge that it’s never yet faced, of a president who accepts democracy itself as legitimate only when he wins?  Douglas concludes that it isn’t—and this is the book’s terrifying and non-obvious part.  There are no checks or balances in the Constitution that will magically ensure a smooth transition of power.  On the contrary, the design flaws of our antiquated system make a meltdown <em>more</em> likely.</p>



<p>OK, but then why hasn’t America’s Reactor of Democracy exploded yet (or at least, not since the Civil War)?  Douglas spends a lot of time on historical parallels, including the Tilden-Hayes election of 1876 and the Bush-Gore election of 2000.  In each case, he finds, collapse was averted not because of mythical safeguards in our rickety, Rube-Goldberg system, but <em>only</em> because the relevant people (e.g., Samuel Tilden, Al Gore) stood down, having internalized the norm that the national good required them to.  But that’s precisely what Trump has telegraphed that he’ll never do.</p>



<p>The class of scenario that most worries Douglas runs as follows: just like last time, the election comes down to a few swing states, such as Pennsylvania, Wisconsin, and Michigan.  Crucially, right now all three of those states have Democratic governors and Republican-controlled legislatures … and <em>there’s no clear law about which of the two (the governor or the legislature) gets to certify election results and send them to Congress!</em>  So suppose Trump has a slight edge on election night, Fox News calls the race for him, but then an avalanche of absentee or provisional ballots shift things in Biden’s favor over the following week.  Can you imagine Trump or his supporters accepting the latter?</p>



<p>Or suppose that, on election day, Russian hackers cut off electricity or voter registration databases in Philadelphia or Detroit, via computer systems that <em>we know they already broke into and that remain exposed (!)</em>.  Hundreds of thousands are unable to vote; the Democratic governor orders a revote; the Republican legislature tries to preempt that by sending the original tally to Congress.</p>



<p>The final authority over election results rests with Congress.  The trouble is, the Senate is currently under Republican control and the House under Democratic control—and once again, <em>the Constitution and federal law provide no clear guidance on how to resolve a deadlock between the two on presidential succession (!!)</em>.  So what if Michigan or Pennsylvania or Wisconsin sends two separate sets of election results, and (predictably) the House accepts one and the Senate accepts the other?  And what if there’s no resolution by noon EST on January 20, 2021?  Then by law, the Speaker of the House, currently Nancy Pelosi, becomes acting president.  Can you imagine Trump willingly vacating the Oval Office if that comes to pass?</p>



<p>Douglas seems to have finished writing <em>Will He Go?</em> just as the coronavirus shut down the planet; he includes some comments about how that will massively exacerbate the above problems.  Election officials expect a historic number of absentee ballots, from people—disproportionately urban—who will (reasonably) consider it unsafe to wait in line for hours in a room packed with hundreds of strangers.  Alas, Trump has already told his followers that voting by mail is a scam to be fiercely opposed, never mind that he uses it himself.  Worse yet, the laws governing mail-in ballots—the signature, the postmark, the deadline for receipt—are byzantine, open to interpretation, and wildly different from county to county.  So again: imagine if mail-in ballots overturn what looked like a Trump win on election night.  The 2000 Florida recount battle was tea and cookies by comparison.</p>



<p>Douglas doesn’t mention, because it happened too recently, the nationwide Black Lives Matter protests (and in rarer cases, vandalism and looting) set off by the horrific murder of George Floyd, and the often shockingly militarized response.  But assuming the protests continue through the fall, they’ll of course give the Trumpists even more pretexts to meddle with the election, in the name of imposing “order.”</p>



<p>This is not a sound statistical methodology, but if I imagine a <em>gong</em> every time the US inches perceptibly closer to collapse—<em>gong</em> when Trump got elected, <em>gong</em> when covid made landfall and the states were abandoned to fight each other over medical supplies, <em>gong</em> when George Floyd was murdered and staid, conformist liberals suddenly became anarchists demanding the complete abolition of all police—well, the <em>gong</em>s seem to be getting more frequent!  Almost as if they were building toward a <em>gong</em>ularity that was, I dunno, sometime around November!</p>



<p>Douglas never mentions the prospect of a second Civil War until literally the book’s last sentence, but it’s the undercurrent of everything he writes—particularly given Trump’s frequent glorifications of violence, and his heavily armed base.  Having spent his career studying American jurisprudence, Douglas is willing to guide our imaginations all the way to the precipice but not over it.  Part of me still finds the possibility of going over unthinkable—although wasn’t the <em>first</em> Civil War similarly unthinkable until shortly before it happened?</p>



<p>If there <em>is</em> to be a Chernobyl-like meltdown of the Founding Fathers’ machine, at least it would retrospectively make sense of a lot that’s confused me in the past few years.  As I’m far from the only one to notice, “my” side, the left, has seemed less and less interested in debate and discussion, and more and more eager to denounce, ban, shame, and no-platform.  As just one example, out of hundreds that would serve, last week a 28-year-old analyst named David Shor was <a href="https://nymag.com/intelligencer/2020/06/case-for-liberalism-tom-cotton-new-york-times-james-bennet.html">fired from his job</a> for <em>politely tweeting about an <a href="http://omarwasow.com/APSR_protests3_1.pdf">academic paper</a> offering evidence that peaceful protests are effective at winning public support for progressive, antiracist causes, while violence is ineffective</em>.  Hopefully <em>I</em> won’t now be fired for mentioning this!</p>



<p>Of course every cause has its extremists, but the puzzle is that I <em>know</em> plenty of people who will eagerly join whatever is the shaming or firing campaign du jour.  And many of those people strike me as friendly, insightful, honest, balanced, wise—at least when the topic is apolitical, as (alas) less and less seems to be these days.</p>



<p>Thought experiment: two protesters meet on a street, carrying huge signs that say “BLACK LIVES MATTER” and “ALL LIVES MATTER” respectively.  Can you imagine the following conversation ensuing: “Ah, my good fellow, it looks like you and I are allies, sharing deeply compatible moral messages with the world … one of us merely focused more on a special case, and the other on its generalization!  Shall we sit in the park to discuss our joint strategy?”</p>



<p>I guess it takes an Aspbergery STEM nerd even to <em>ask</em> why that never happens.  To spell it out: both sides are deploying English words, not for what they explicitly assert, but as markers of tribal affiliation, of <em>which side they’re on</em>.</p>



<p>It’s much the same with “Believe Women.”  “Believe <em>all</em> women, <em>always</em>?” asks our hapless STEM nerd.  “Women are goddesses who never lie?  Feminism is no longer the radical notion that women are people?”  “No, you sexist asshat,” replies the normie.  “It means listen to women, empathize with women, believe women, be on their side, be on <em>our</em> side.  What about that is so f-ing hard to understand?”</p>



<p>Or consider the slogans now conquering the world: “abolish the police” and “defund the police.”  “You mean <em>fundamentally reform</em> the police, right?” asks the STEM nerd.  “Eliminate qualified immunity, bust the unions that protect abusive cops, get rid of military gear, provide de-escalation training, stop treating homelessness and drug abuse as law enforcement problems, and all those other no-brainers?  But not, like, literally end all law enforcement, leave the 911 calls unanswered as machete-wielding rapists run free, and let gangsters and warlords fill the vacuum?”</p>



<p>“No, abolish the police means <em>abolish the police</em>,” reply the activists sternly.  “You refuse to listen.  You’re not our ally.”</p>



<p>Imagine a ragtag guerilla army encamped in the jungle, surrounded by a brutal occupying force and facing impossible odds, constantly on the alert for turncoats and spies and fair-weather friends in its midst.  Would it surprise you if these guerillas had a macabre initiation ritual for new recruits: say, slicing off the tips of recruits’ fingers?</p>



<p>Now suppose you reckoned that truth and justice were at least 3/4 on the guerillas’ side, and so decided to join them.  At your initiation, would you ask the guerillas if they’d analyzed whether finger-slicing <em>actually</em> leads to greater effectiveness in battle?  Or, as you swore the oath of eternal allegiance to the cause, with one hand on your heart and the other on your Kalashnikov, would you add: “… <em>assuming</em> that we continue to represent Enlightenment values like science, free speech, and intellectual charity”?</p>



<p>When the Nazis invaded the Soviet Union in 1941, it suddenly became reasonable to take the side of the bloodthirsty Stalin.  And it would’ve been <em>praiseworthy</em> for a Russian to say: “I now pledge my life to fighting for the Soviet government—even if, likely as not, that government will thank me afterward by sending me to the gulag for an invented crime.”</p>



<p>Five years ago, thousands of woke activists shamed me for writing about my teenage experiences on this blog, a few even calling for an end to my career.  Especially if those activists emerge victorious from a turbulent 2020—<em>as I hope they will</em>—I expect that they’ll come for me again.  (Well, if they get around to it.  I’m nowhere near the top of their list.)</p>



<p>And yet, if Lawrence Douglas’s scenario comes to pass—if, for example, the 2020 election leaves Trump barricaded in the White House with his loyalists, while a duly elected government waits in limbo—then I pledge to render whatever assistance I can, and even risk my life if needed, for the same side that the woke activists will be on.</p>



<p>I’d rather not, though.  As Douglas points out, the more overwhelming we can make Trump’s electoral defeat, the less chance that it ever comes to this.</p></div>
    </content>
    <updated>2020-06-11T21:41:10Z</updated>
    <published>2020-06-11T21:41:10Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="The Fate of Humanity"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2020-06-18T22:06:37Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/06/10/postdoc-at-technion-apply-by-september-30-2020/</id>
    <link href="https://cstheory-jobs.org/2020/06/10/postdoc-at-technion-apply-by-september-30-2020/" rel="alternate" type="text/html"/>
    <title>Postdoc at Technion (apply by September 30, 2020)</title>
    <summary>Postdoctoral positions in distributed computing are available in the research group of Keren Censor-Hillel at the Technion. Candidates with a strong publication record in closely related areas are welcome to apply (deadline is flexible). To apply, send to Mrs. Hila Mizrahi: (1) a CV, (2) a 1-2 page research statement, (3) the contact details of […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Postdoctoral positions in distributed computing are available in the research group of Keren Censor-Hillel at the Technion. Candidates with a strong publication record in closely related areas are welcome to apply (deadline is flexible). To apply, send to Mrs. Hila Mizrahi: (1) a CV, (2) a 1-2 page research statement, (3) the contact details of 3 references, and (4) an expected graduation date.</p>
<p>Website: <a href="https://ckeren.net.technion.ac.il/">https://ckeren.net.technion.ac.il/</a><br/>
Email: hilamiz@cs.technion.ac.il</p></div>
    </content>
    <updated>2020-06-10T12:22:37Z</updated>
    <published>2020-06-10T12:22:37Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-06-19T00:20:42Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/090</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/090" rel="alternate" type="text/html"/>
    <title>TR20-090 |  Tight Quantum Time-Space Tradeoffs for Function Inversion | 

	Kai-Min Chung, 

	Siyao  Guo, 

	Qipeng Liu, 

	Luowen Qian</title>
    <summary>In function inversion, we are given a function $f: [N] \mapsto [N]$, and want to prepare some advice of size $S$, such that we can efficiently invert any image in time $T$. This is a well studied problem with profound connections to cryptography, data structures, communication complexity, and circuit lower bounds. Investigation of this problem in the quantum setting was initiated by Nayebi, Aaronson, Belovs, and Trevisan (2015), who proved a lower bound of $ST^2 = \tilde\Omega(N)$ for random permutations against classical advice, leaving open an intriguing possibility that Grover's search can be sped up to time $\tilde O(\sqrt{N/S})$. Recent works by Hhan, Xagawa, and Yamakawa (2019), and Chung, Liao, and Qian (2019) extended the argument for random functions and quantum advice, but the lower bound remains $ST^2 = \tilde\Omega(N)$. 

In this work, we prove that even with quantum advice, $ST + T^2 = \tilde\Omega(N)$ is required for an algorithm to invert random functions. This demonstrates that Grover's search is optimal for $S = \tilde O(\sqrt{N})$, ruling out any substantial speed-up for Grover's search even with quantum advice. Further improvements to our bounds would imply a breakthrough in circuit lower bounds, as shown by Corrigan-Gibbs and Kogan (2019).

To prove this result, we develop a general framework for establishing quantum time-space lower bounds. We further demonstrate the power of our framework by proving the following results. 

* Yao's box problem: We prove a tight quantum time-space lower bound for classical advice. For quantum advice, we prove a first time-space lower bound using shadow tomography. These results resolve two open problems posted by Nayebi, Aaronson, Belovs, and Trevisan (2015). 

* Salted cryptography: We show that “salting generically provably defeats preprocessing,” a result shown by Coretti, Dodis, Guo, and Steinberger (2018), also holds in the quantum setting. In particular, we prove quantum time-space lower bounds for a wide class of salted cryptographic primitives in the quantum random oracle model. This yields a first quantum time-space lower bound for salted collision-finding, which in turn implies that ${PWPP}^{O} \not\subseteq {FBQP}^{O}{/qpoly}$ relative to a random oracle $O$.</summary>
    <updated>2020-06-10T06:43:41Z</updated>
    <published>2020-06-10T06:43:41Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-06-19T00:20:25Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/089</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/089" rel="alternate" type="text/html"/>
    <title>TR20-089 |  Lower Bounds on  the Time/Memory Tradeoff of Function Inversion | 

	Dror Chawin, 

	Iftach Haitner, 

	Noam Mazor</title>
    <summary>We study time/memory tradeoffs of function inversion: an algorithm, i.e., an inverter, equipped with an $s$-bit advice for a randomly chosen function $f\colon [n] \mapsto [n]$ and using $q$ oracle queries to $f$, tries to invert a randomly chosen output $y$ of $f$ (i.e., to find $x$ such that $f(x)=y$). Much progress was done regarding adaptive function inversion - the inverter is allowed to make adaptive oracle queries. Hellman [IEEE transactions on Information Theory '80] presented an adaptive inverter that inverts with high probability a random $f$. Fiat and Naor [SICOMP '00] proved that for any $s,q$ with $s^2 q = n^2$ (ignoring low-order terms), an $s$-advice, $q$-query variant of Hellman's algorithm inverts a constant fraction of the image points of any function. Yao [STOC '90] proved a lower bound of $sq\ge n$ for  this problem. Closing the gap between the above lower and upper bounds is a long-standing open question.

Very little is known for the non-adaptive variant of the question - the inverter chooses its queries in advance. The only known upper bounds, i.e., inverters, are the trivial ones (with $s+q= n$), and the only lower bound is the above bound of Yao. In a recent work, Corrigan-Gibbs and Kogan [TCC '19] partially justified the difficulty of finding lower bounds on non-adaptive inverters, showing that a lower bound on the time/memory tradeoff of non-adaptive inverters implies a lower bound on low-depth Boolean circuits. Bounds that for a strong enough choice of parameters, are notoriously hard to prove.

We make progress on the above intriguing question, both for the adaptive and the non-adaptive case, proving the following lower bounds on restricted families of inverters:

	- Linear-advice (adaptive inverter): If the advice string is a linear function of $f$ (e.g., $A\times f$, viewing $f$ as  a vector in $[n]^n$), then $s+q \in \Omega(n)$.
	
	- Affine non-adaptive decoders: If the non-adaptive inverter has an affine decoder - it outputs a linear function, determined by the advice string and the element to invert, of the query answers - then $s \in \Omega(n)$ (regardless of $q$).
	
	- Affine non-adaptive decision trees: If the non-adaptive inversion algorithm is a $d$-depth affine decision tree - it outputs the evaluation of a decision tree whose nodes compute a linear function of the answers to the queries - and $q \le cn$ for some universal $c&gt;0$, then $s\in \Omega(n/d \log n)$.</summary>
    <updated>2020-06-09T13:19:02Z</updated>
    <published>2020-06-09T13:19:02Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-06-19T00:20:25Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/088</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/088" rel="alternate" type="text/html"/>
    <title>TR20-088 |  Eliminating Intermediate Measurements in Space-Bounded Quantum Computation | 

	Bill Fefferman, 

	Zachary Remscrim</title>
    <summary>A foundational result in the theory of quantum computation known as the ``principle of safe storage'' shows that it is always possible to take a quantum circuit and produce an equivalent circuit that makes all measurements at the end of the computation.  While this procedure is time efficient, meaning that it does not introduce a large overhead in the number of gates, it uses extra ancillary qubits and so is not generally space efficient.  It is quite natural to ask whether it is possible to defer measurements to the end of a quantum computation without increasing the number of ancillary qubits.
		
		We give an affirmative answer to this question by exhibiting a procedure to eliminate all intermediate measurements that is simultaneously space-efficient and time-efficient. A key component of our approach, which may be of independent interest, involves showing that the well-conditioned versions of many standard linear-algebraic problems may be solved by a quantum computer in less space than seems possible by a classical computer.</summary>
    <updated>2020-06-08T21:24:06Z</updated>
    <published>2020-06-08T21:24:06Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-06-19T00:20:25Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/087</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/087" rel="alternate" type="text/html"/>
    <title>TR20-087 |  Quantum Logspace Algorithm for Powering Matrices with Bounded Norm | 

	Uma Girish, 

	Ran Raz, 

	Wei Zhan</title>
    <summary>We give a quantum logspace algorithm for powering contraction matrices, that is, matrices with spectral norm at most 1. The algorithm gets as an input an arbitrary $n\times n$ contraction matrix $A$, and a parameter $T \leq poly(n)$ and outputs the entries of $A^T$, up to (arbitrary) polynomially small additive error. The algorithm applies only unitary operators, without intermediate measurements. We show various implications and applications of this result:

First, we use this algorithm to show that the class of quantum logspace algorithms with only quantum memory and with intermediate measurements is equivalent to the class of quantum logspace algorithms with only quantum memory without intermediate measurements. This shows that the deferred-measurement principle, a fundamental principle of quantum computing, applies also for quantum logspace algorithms (without classical memory). More generally, we give a quantum algorithm with space $O(S + \log T)$ that takes as an input the description of a quantum algorithm with quantum space $S$ and time $T$, with intermediate measurements (without classical memory), and simulates it unitarily with polynomially small error, without intermediate measurements.

Since unitary transformations are reversible (while measurements are irreversible) an interesting aspect of this result is that it shows that any quantum logspace algorithm (without classical memory) can be simulated by a reversible quantum logspace algorithm. This proves a quantum analogue of the result of Lange, McKenzie and Tapp that deterministic logspace is equal to reversible logspace.

Finally, we use our results to show non-trivial classical simulations of quantum logspace learning algorithms.</summary>
    <updated>2020-06-08T18:51:13Z</updated>
    <published>2020-06-08T18:51:13Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-06-19T00:20:25Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-9046421052819875987</id>
    <link href="https://blog.computationalcomplexity.org/feeds/9046421052819875987/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/06/the-committee-for-adv-of-tcs-workshop.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/9046421052819875987" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/9046421052819875987" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/06/the-committee-for-adv-of-tcs-workshop.html" rel="alternate" type="text/html"/>
    <title>The Committee for the Adv. of TCS- workshop coming up SOON!</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><span id="docs-internal-guid-06a8f4c9-7fff-916b-0154-0d4b08969907"/><br/>
<div dir="ltr" style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;">
<span id="docs-internal-guid-06a8f4c9-7fff-916b-0154-0d4b08969907"><span>(Posted by request from Jelani Nelson.)</span></span></div>
<span id="docs-internal-guid-06a8f4c9-7fff-916b-0154-0d4b08969907"><br/><div dir="ltr" style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;">
<span>The Committee for the Advancement of Theoretical Computer Science (CATCS)</span></div>
<div dir="ltr" style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;">
<span>is organizing a Visioning workshop.  The primary objective of the workshop</span></div>
<div dir="ltr" style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;">
<span>is for TCS participants to brainstorm directions and talking points for TCS</span></div>
<div dir="ltr" style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;">
<span>program managers at funding agencies to advocate for theory funding.</span></div>
<br/><div dir="ltr" style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;">
<span>There was some question of whether or not it would run this summer, but</span></div>
<div dir="ltr" style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;">
<span>YES, it is going to run.</span></div>
<br/><div dir="ltr" style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;">
<span>If you are interested then reply (at the link below) by June 15.</span></div>
<div dir="ltr" style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;">
<span>This is SOON so click that link SOON.</span></div>
<br/><div dir="ltr" style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;">
<span>The time commitment is 4-5 hours during the week of July 20-July 24 for</span></div>
<div dir="ltr" style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;">
<span>most participants, or roughly 10 hours for those who are willing to</span></div>
<div dir="ltr" style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;">
<span>volunteer to be group leaders.</span></div>
<br/><div dir="ltr" style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;">
<span>The link to sign up is:</span></div>
<br/><div dir="ltr" style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;">
<span><a href="https://thmatters.wordpress.com/2020/06/05/tcs-visioning-workshop-call-for-participation/">https://thmatters.wordpress.com/2020/06/05/tcs-visioning-workshop-call-for-participation/</a></span></div>
<div dir="ltr" style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;">
<br/></div>
<div dir="ltr" style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;">
<br/></div>
</span></div>
    </content>
    <updated>2020-06-08T15:03:00Z</updated>
    <published>2020-06-08T15:03:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2020-06-18T16:42:45Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://lucatrevisan.wordpress.com/?p=4392</id>
    <link href="https://lucatrevisan.wordpress.com/2020/06/08/visioning-workshop-call-for-participation/" rel="alternate" type="text/html"/>
    <title>“Visioning” workshop call for participation</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">In 2008, the Committee for the Advancement of Theoretical Computer Science convened a workshop to brainstorm directions and talking points for TCS program managers at funding agencies to advocate for theory funding. The event was quite productive and successful. A … <a href="https://lucatrevisan.wordpress.com/2020/06/08/visioning-workshop-call-for-participation/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>In 2008, the <a href="https://thmatters.wordpress.com/catcs/">Committee for the Advancement of Theoretical Computer Science</a> convened a workshop to brainstorm directions and talking points for TCS<br/>
program managers at funding agencies to advocate for theory funding. The event was quite productive and successful. </p>
<p>A second such workshop is going to be held, online, in the third week of July. Applications to participate are due on June 15, a week from today. Organizers expect that participants will have to devote about four hours of their time to the workshop, and those who volunteer to be team leads will have a time commitment of about ten hours.</p>
<p>More information <a href="https://thmatters.wordpress.com/2020/06/05/tcs-visioning-workshop-call-for-participation/">at this link</a></p></div>
    </content>
    <updated>2020-06-08T09:38:07Z</updated>
    <published>2020-06-08T09:38:07Z</published>
    <category term="theory"/>
    <author>
      <name>luca</name>
    </author>
    <source>
      <id>https://lucatrevisan.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://lucatrevisan.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://lucatrevisan.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://lucatrevisan.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://lucatrevisan.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>"Marge, I agree with you - in theory. In theory, communism works. In theory." -- Homer Simpson</subtitle>
      <title>in   theory</title>
      <updated>2020-06-19T00:20:11Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>http://ptreview.sublinear.info/?p=1343</id>
    <link href="https://ptreview.sublinear.info/?p=1343" rel="alternate" type="text/html"/>
    <title>Welcome Akash Kumar!</title>
    <summary>Let’s welcome our latest editor, Akash Kumar. Akash will be taking the place of Gautam Kamath, who has decided to pass the torch on. Let’s also thank Gautam for all the help with PTReview.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Let’s welcome our latest editor, Akash Kumar. Akash will be taking the place of Gautam Kamath, who has decided to pass the torch on. Let’s also thank Gautam for all the help with PTReview.</p></div>
    </content>
    <updated>2020-06-08T03:29:36Z</updated>
    <published>2020-06-08T03:29:36Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Seshadhri</name>
    </author>
    <source>
      <id>https://ptreview.sublinear.info</id>
      <link href="https://ptreview.sublinear.info/?feed=rss2" rel="self" type="application/atom+xml"/>
      <link href="https://ptreview.sublinear.info" rel="alternate" type="text/html"/>
      <subtitle>The latest in property testing and sublinear time algorithms</subtitle>
      <title>Property Testing Review</title>
      <updated>2020-06-18T23:32:10Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>http://ptreview.sublinear.info/?p=1315</id>
    <link href="https://ptreview.sublinear.info/?p=1315" rel="alternate" type="text/html"/>
    <title>News for May 2020</title>
    <summary>Last month saw activity across a diverse collection of topics in sublinear algorithms. In particular, we had the following five six papers. (Sorry, I missed one) One-Sided Error Testing of Monomials and Affine Subspaces by Oded Goldreich and Dana Ron (ECCC). This work focuses on one-sided testing of two kinds of problems (and their variants): […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Last month saw activity across a diverse collection of topics in sublinear algorithms. In particular, we had the following <s>five</s> six papers. <em>(Sorry, I missed one)</em> </p>



<p><strong>One-Sided Error Testing of Monomials and Affine Subspaces</strong> by Oded Goldreich and Dana Ron (<a href="https://eccc.weizmann.ac.il/report/2020/068/">ECCC</a>). This work focuses on one-sided testing of two kinds of problems (and their variants): <br/><span class="has-inline-color has-blue-color">1.</span> Testing Monomials: Suppose you are given a function \(f \colon \{0,1\}^n \to \{0,1\}\). Is \(f = \wedge_{i \in I} x_i\) (that is, is \(f\) a monotone monomial). <br/><span class="has-inline-color has-blue-color">2.</span> Testing Affine Subspaces: Consider the task of testing whether a \(f \colon \mathcal{F}^n \to \{0,1\}\) is the indicator of an \((n-k)\)-dimensional affine space for some \(k\) (where \(\mathcal{F}\) is a finite field).<br/></p>



<p>The paper shows that the general problem — the one in which the arity of the monomial (resp the co-dimension of the subspace) is not specified has one-sided query complexity \(\widetilde{O}(1/\varepsilon)\). The same holds for testing whether the arity of the monomial is at most \(k\) (resp the co-dimension of the subspace is at most \(k\)). Finally, the exact problem which seeks to test whether the arity of the monomial is exactly \(k\) (resp the co-dimension of the space is exactly \(k\)) has query complexity \(\Omega(\log n)\). For two sided testers however, size oblivious testers are known for this problem. Thus, like the authors remark, two-sided error is inherent in the case of the exact version of the problem.</p>



<p/>



<p><strong>Sampling Arbitrary Subgraphs Exactly Uniformly in Sublinear Time</strong> by Hendrik Fichtenberger, Mingze Gao, Pan Peng (<a href="https://arxiv.org/abs/2005.01861v2">arXiv</a>). Readers of PT Review are no strangers to the problem of counting cliques in sublinear time (with a certain query model). Building on tools from [1], in [2], Eden-Ron-Seshadhri gave the first algorithms for counting number of copies \(K_r\) in a graph \(G\) to within a \((1 \pm \varepsilon)\) multiplicative factor. En route to this result, they also gave a procedure to sample cliques incident to some special set \(S \subseteq V(G)\). The query model in [2] allowed the following queries: a u.a.r vertex query, degree query, \(i^{th}\) neighbor query and a pair query which answers whether a pair \((u,v)\) forms an edge. The work under consideration shows a result which I personally find remarkable: given the additional ability to get a u.a.r edge sample, we can do the following. For any graph \(H\) we can obtain a uniformly random subgraph isomorphic to \(H\) in \(G\). Let that sink in: this work shows that you can sample \(H\) <em>exactly uniformly</em> from the graph \(G\).  </p>



<p><strong>Finding Planted Cliques in Sublinear Time</strong> by Jay Mardia, Hilal Asi, Kabir Aladin Chandrasekher (<a href="https://arxiv.org/abs/2004.12002">arXiv</a>). Planted Clique is a time honored problem in average case complexity. This classic problem asks the following: You are given a \(G \sim \mathcal{G}(n, 1/2)\). Suppose I select a subset of \(k\) vertices in this graph and put a clique on the subgraph they induce. In principle it is possible to recover the clique I planted if \(k &gt; (2 + \varepsilon) \log n\). But it seems you get polynomial time algorithms only when \(k \geq \Omega(\sqrt n)\) even after you throw SDPs at the problem. Moreover, so far, the algorithms which recover the planted \(k\)-clique were known to take \(\widetilde{O}(n^2)\) time. This work shows that you actually get algorithms which take time \(\widetilde{O}(n^{3/2})\) if \(k \geq \Omega(\sqrt{n \log n})\). The key idea is to first obtain a “core” part of the clique of size \(O(\log n)\) in time \(\widetilde{O}(n^2/k)\). This is followed up with a clique completion routine where you mark all vertices connected to the entire core as being potentially in the clique. The paper also shows a conditional lower bound result which shows that given query access to adjacency matrix of the graph, a natural family of non-adaptive algorithms cannot recover a planted \(k\) clique in time \(o\left(\frac{n}{k}\right)^3\) (for \(k \geq \widetilde{\Omega}(\sqrt n))\).</p>



<p><strong>A robust multi-dimensional sparse Fourier transform in the continuous setting</strong> by Yaonan Jin, Daogao Liu and Zhao Song (<a href="https://arxiv.org/abs/2005.06156">arXiv</a>).  Suppose you are given an unknown signal whose Fourier Spectrum is k-sparse (that is, there are at most k dominant Fourier Coefficients and all the others are zero or close to zero). Significant research effort has been devoted to learn these signals leading to works which study this problem for multi-dimensional discrete setting and in the one-dimensional continuous case. The \(d\)-dimensional continuous case \((d = \Theta(1))\) was largely unexplored. This work makes progress on this frontier by making some natural assumptions on the unknown signal. In particular, the paper assumes that the frequencies — which are vectors \(f_i’s \in R^d\) — are well separated and satisfy \(\|f_i – f_j\|_2 \leq \eta\) and that all \({f_i}_{i \in [k]} \subseteq [-F, F]^d\) sit inside a bounded box.<br/>The authors assume sample access to the signal in the sense that at any desired timestep \(\tau\), the algorithm can sample the signal’s value. With this setup, the authors show that all the dominant frequencies can be recovered with a \(O_d(k \cdot \log(F/\eta))\) samples by considering a relatively small time horizon.</p>



<p><strong>Extrapolating the profile of a finite population</strong> by Soham Jana, Yury Polyanskiy, Yihong Wu (<a href="https://arxiv.org/abs/2005.10561">arXiv</a>). Consider the following setup. You are given a universe \(k\) balls. Ball come in up to \(k\) different colors. Say you \(\theta_j\) balls in color \(j\) for each \(j \in [k]\). One of the fundamental problems in statistics considers taking samples \(m\) balls from the universe and attempts estimating “population profile” (that is, the number of balls in each color). Historically, it is known that unless an overwhelming majority of the universe has been seen, one cannot estimate the empirical distribution of colors. This paper shows that in the sublinear regime, with \(m \geq \omega(k/\log k)\), it is possible to consistently estimate the population profile in total variation. And once you have a handle on the empirical distribution of the population, you can go ahead and learn lots of interesting label invariant properties of your universe (things like entropy, number of distinct elements etc). </p>



<p/>



<p><em>(Edit added later)</em></p>



<p><strong>Testing Positive Semi-Definiteness via Random Submatrices</strong> by Ainesh Bakshi, Nadiia Chepurko, Rajesh Jayaram (<a href="https://arxiv.org/abs/2005.06441">arXiv</a>). Suppose I give you a PSD matrix \(A \in R^{n \times n}\). You know that all of its principle submatrices are also PSD. What if \(A\) was \(\varepsilon\)-far from the PSD cone (in a sense I will define soon)? What can you say about the eigenvalues of principle submatrices of \(A\) now? In this paper, the authors tackle precisely this question. The paper defines a matrix \(A\) to be \(\varepsilon\)-far in \(\ell_2^2\) distance from the PSD Cone if you have that \(\min_{B \geq 0: B \in R^{n \times n}}\|A – B\|_F^2 \geq \varepsilon n^2\). You are allowed to randomly sample a bunch of principle submatrices (of order roughly \(O(1/\varepsilon)\) by \(O(1/\varepsilon)\) and check if they are PSD. Armed with this setup, the paper gives a non-adaptive one sided tester for this problem which makes \(\widetilde{O}(1/\varepsilon^4)\) queries. The paper also supplements this result with a lower bound of \(\widetilde{\Omega}(1/\varepsilon^2)\) queries.</p>



<p>If I missed something, please let me know. This is my first post on PT Review and I might have botched up a few things.</p>



<p><strong>References</strong></p>



<p>[1] Talya Eden, Amit Levi, Dana Ron and C. Seshadhri. Approximately Counting Triangles in Sublinear Time. <em>56th Annual Symposium on Foundations of Computer Science, 2015</em></p>



<p>[2] Talya Eden, Dana Ron and C. Seshadhri. On approximating the number of k-cliques in sublinear time. Proceedings of the <em>50th Annual ACM SIGACT Symposium on Theory of Computing 2018</em>.</p></div>
    </content>
    <updated>2020-06-07T22:22:58Z</updated>
    <published>2020-06-07T22:22:58Z</published>
    <category term="Monthly digest"/>
    <author>
      <name>akumar</name>
    </author>
    <source>
      <id>https://ptreview.sublinear.info</id>
      <link href="https://ptreview.sublinear.info/?feed=rss2" rel="self" type="application/atom+xml"/>
      <link href="https://ptreview.sublinear.info" rel="alternate" type="text/html"/>
      <subtitle>The latest in property testing and sublinear time algorithms</subtitle>
      <title>Property Testing Review</title>
      <updated>2020-06-18T23:32:10Z</updated>
    </source>
  </entry>
</feed>
