<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2022-02-08T13:38:57Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.02305</id>
    <link href="http://arxiv.org/abs/2202.02305" rel="alternate" type="text/html"/>
    <title>Faster exact solution of sparse MaxCut and QUBO problems</title>
    <feedworld_mtime>1644192000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rehfeldt:Daniel.html">Daniel Rehfeldt</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Koch:Thorsten.html">Thorsten Koch</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shinano:Yuji.html">Yuji Shinano</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.02305">PDF</a><br/><b>Abstract: </b>The maximum-cut problem is one of the fundamental problems in combinatorial
optimization. With the advent of quantum computers, both the maximum-cut and
the equivalent quadratic unconstrained binary optimization problem have
experienced much interest in recent years.
</p>
<p>This article aims to advance the state of the art in the exact solution of
both problems -- by using mathematical programming techniques on digital
computers. The main focus lies on sparse problem instances, although also dense
ones can be solved. We enhance several algorithmic components such as reduction
techniques and cutting-plane separation algorithms, and combine them in an
exact branch-and-cut solver. Furthermore, we provide a parallel implementation.
The new solver is shown to significantly outperform existing state-of-the-art
software for sparse MaxCut and QUBO instances. Furthermore, we improve the best
known bounds for several instances from the 7th DIMACS Challenge and the QPLIB,
and solve some of them (for the first time) to optimality.
</p></div>
    </summary>
    <updated>2022-02-07T22:38:43Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-02-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.02217</id>
    <link href="http://arxiv.org/abs/2202.02217" rel="alternate" type="text/html"/>
    <title>Flow Time Scheduling and Prefix Beck-Fiala</title>
    <feedworld_mtime>1644192000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bansal:Nikhil.html">Nikhil Bansal</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rohwedder:Lars.html">Lars Rohwedder</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Svensson:Ola.html">Ola Svensson</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.02217">PDF</a><br/><b>Abstract: </b>We relate discrepancy theory with the classic scheduling problems of
minimizing max flow time and total flow time on unrelated machines.
Specifically, we give a general reduction that allows us to transfer
discrepancy bounds in the prefix Beck-Fiala (bounded $\ell_1$-norm) setting to
bounds on the flow time of an optimal schedule.
</p>
<p>Combining our reduction with a deep result proved by Banaszczyk via convex
geometry, give guarantees of $O(\sqrt{\log n})$ and $O(\sqrt{\log n} \log P)$
for max flow time and total flow time, respectively, improving upon the
previous best guarantees of $O(\log n)$ and $O(\log n \log P)$. Apart from the
improved guarantees, the reduction motivates seemingly easy versions of prefix
discrepancy questions: any constant bound on prefix Beck-Fiala where vectors
have sparsity two (sparsity one being trivial) would already yield tight
guarantees for both max flow time and total flow time. While known techniques
solve this case when the entries take values in $\{-1,0,1\}$, we show that they
are unlikely to transfer to the more general $2$-sparse case of bounded
$\ell_1$-norm.
</p></div>
    </summary>
    <updated>2022-02-07T22:39:23Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-02-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.02188</id>
    <link href="http://arxiv.org/abs/2202.02188" rel="alternate" type="text/html"/>
    <title>Koopman von Neumann mechanics and the Koopman representation: A perspective on solving nonlinear dynamical systems with quantum computers</title>
    <feedworld_mtime>1644192000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lin:Yen_Ting.html">Yen Ting Lin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lowrie:Robert_B=.html">Robert B. Lowrie</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Aslangil:Denis.html">Denis Aslangil</a>, Yiğit Subaşı, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sornborger:Andrew_T=.html">Andrew T. Sornborger</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.02188">PDF</a><br/><b>Abstract: </b>A number of recent studies have proposed that linear representations are
appropriate for solving nonlinear dynamical systems with quantum computers,
which fundamentally act linearly on a wave function in a Hilbert space. Linear
representations, such as the Koopman representation and Koopman von Neumann
mechanics, have regained attention from the dynamical-systems research
community. Here, we aim to present a unified theoretical framework, currently
missing in the literature, with which one can compare and relate existing
methods, their conceptual basis, and their representations. We also aim to show
that, despite the fact that quantum simulation of nonlinear classical systems
may be possible with such linear representations, a necessary projection into a
feasible finite-dimensional space will in practice eventually induce numerical
artifacts which can be hard to eliminate or even control. As a result a
practical, reliable and accurate way to use quantum computation for solving
general nonlinear dynamical systems is still an open problem.
</p></div>
    </summary>
    <updated>2022-02-07T22:44:56Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-02-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.02174</id>
    <link href="http://arxiv.org/abs/2202.02174" rel="alternate" type="text/html"/>
    <title>Lossy Planarization: A Constant-Factor Approximate Kernelization for Planar Vertex Deletion</title>
    <feedworld_mtime>1644192000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jansen:Bart_M=_P=.html">Bart M. P. Jansen</a>, Michał Włodarczyk <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.02174">PDF</a><br/><b>Abstract: </b>In the F-minor-free deletion problem we want to find a minimum vertex set in
a given graph that intersects all minor models of graphs from the family F. The
Vertex planarization problem is a special case of F-minor-free deletion for the
family F = {K_5, K_{3,3}}. Whenever the family F contains at least one planar
graph, then F-minor-free deletion is known to admit a constant-factor
approximation algorithm and a polynomial kernelization [Fomin, Lokshtanov,
Misra, and Saurabh, FOCS'12]. The Vertex planarization problem is arguably the
simplest setting for which F does not contain a planar graph and the existence
of a constant-factor approximation or a polynomial kernelization remains a
major open problem.
</p>
<p>In this work we show that Vertex planarization admits an algorithm which is a
combination of both approaches. Namely, we present a polynomial A-approximate
kernelization, for some constant A &gt; 1, based on the framework of lossy
kernelization [Lokshtanov, Panolan, Ramanujan, and Saurabh, STOC'17]. Simply
speaking, when given a graph G and integer k, we show how to compute a graph G'
on poly(k) vertices so that any B-approximate solution to G' can be lifted to
an (A*B)-approximate solution to G, as long as A*B*OPT(G) &lt;= k. In order to
achieve this, we develop a framework for sparsification of planar graphs which
approximately preserves all separators and near-separators between subsets of
the given terminal set.
</p>
<p>Our result yields an improvement over the state-of-art approximation
algorithms for Vertex planarization. The problem admits a polynomial-time
O(n^eps)-approximation algorithm, for any eps &gt; 0, and a quasi-polynomial-time
(log n)^O(1) approximation algorithm, both randomized [Kawarabayashi and
Sidiropoulos, FOCS'17]. By pipelining these algorithms with our approximate
kernelization, we improve the approximation factors to respectively O(OPT^eps)
and (log OPT)^O(1).
</p></div>
    </summary>
    <updated>2022-02-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-02-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.02046</id>
    <link href="http://arxiv.org/abs/2202.02046" rel="alternate" type="text/html"/>
    <title>A Framework for Loop and Path Puzzle Satisfiability NP-Hardness Results</title>
    <feedworld_mtime>1644192000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tang:Hadyn.html">Hadyn Tang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.02046">PDF</a><br/><b>Abstract: </b>Building on the results published in arxiv:<a href="http://export.arxiv.org/abs/2004.12849">2004.12849</a> we present a general
framework for demonstrating the NP-hardness of satisfying many genres of loop
and path puzzles using a 'T-metacell' gadget. We then use this to prove the
NP-completeness of a variety of such genres, and discuss some of the
limitations of this gadget.
</p></div>
    </summary>
    <updated>2022-02-07T22:37:47Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2022-02-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.02010</id>
    <link href="http://arxiv.org/abs/2202.02010" rel="alternate" type="text/html"/>
    <title>Globally Minimal Defensive Alliances: A Parameterized Perspective</title>
    <feedworld_mtime>1644192000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gaikwad:Ajinkya.html">Ajinkya Gaikwad</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Maity:Soumen.html">Soumen Maity</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.02010">PDF</a><br/><b>Abstract: </b>A defensive alliance in an undirected graph $G=(V,E)$ is a non-empty set of
vertices $S$ satisfying the condition that every vertex $v\in S$ has at least
as many neighbours (including itself) in $S$ as it has in $V\setminus S$. We
consider the notion of global minimality in this paper. We are interested in
globally minimal defensive alliance of maximum size. This problem is known to
be NP-hard but its parameterized complexity remains open until now. We enhance
our understanding of the problem from the viewpoint of parameterized complexity
by showing that the Globally Minimal Defensive Alliance problem is FPT
parameterized by the neighbourhood diversity of the input graph. The result for
neighborhood diversity implies that the problem is FPT parameterized by vertex
cover number also. We prove that the problem parameterized by the vertex cover
number of the input graph does not admit a polynomial compression unless coNP
$\subseteq$ NP/poly. We show that the problem is W[1]-hard parameterized by a
wide range of fairly restrictive structural parameters such as the feedback
vertex set number, pathwidth, treewidth and treedepth. We also proved that,
given a vertex $r \in V(G)$, deciding if $G$ has a globally minimal defensive
alliance of any size containing vertex $r$ is NP-complete.
</p></div>
    </summary>
    <updated>2022-02-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-02-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.01908</id>
    <link href="http://arxiv.org/abs/2202.01908" rel="alternate" type="text/html"/>
    <title>Sampling with Riemannian Hamiltonian Monte Carlo in a Constrained Space</title>
    <feedworld_mtime>1644192000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kook:Yunbum.html">Yunbum Kook</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lee:Yin_Tat.html">Yin Tat Lee</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shen:Ruoqi.html">Ruoqi Shen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vempala:Santosh_S=.html">Santosh S. Vempala</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.01908">PDF</a><br/><b>Abstract: </b>We demonstrate for the first time that ill-conditioned, non-smooth,
constrained distributions in very high dimension, upwards of 100,000, can be
sampled efficiently $\textit{in practice}$. Our algorithm incorporates
constraints into the Riemannian version of Hamiltonian Monte Carlo and
maintains sparsity. This allows us to achieve a mixing rate independent of
smoothness and condition numbers.
</p>
<p>On benchmark data sets in systems biology and linear programming, our
algorithm outperforms existing packages by orders of magnitude. In particular,
we achieve a 1,000-fold speed-up for sampling from the largest published human
metabolic network (RECON3D). Our package has been incorporated into the COBRA
toolbox.
</p></div>
    </summary>
    <updated>2022-02-07T22:41:58Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-02-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.01780</id>
    <link href="http://arxiv.org/abs/2202.01780" rel="alternate" type="text/html"/>
    <title>Even Simpler Deterministic Matrix Sketching</title>
    <feedworld_mtime>1644192000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liberty:Edo.html">Edo Liberty</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.01780">PDF</a><br/><b>Abstract: </b>This paper provides a one-line proof of Frequent Directions (FD) for
sketching streams of matrices. The simpler proof arises from sketching the
covariance of the stream of matrices rather than the stream itself.
</p></div>
    </summary>
    <updated>2022-02-07T22:39:12Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-02-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-6817129401606575319</id>
    <link href="http://blog.computationalcomplexity.org/feeds/6817129401606575319/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/02/pspace-is-contained-in-zero-knowledge.html#comment-form" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/6817129401606575319" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/6817129401606575319" rel="self" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/02/pspace-is-contained-in-zero-knowledge.html" rel="alternate" type="text/html"/>
    <title>PSPACE is contained in Zero Knowledge!! How come nobody seems to care?</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>(This post was inspired by Lance's post on Zero Knowledge, <a href="https://blog.computationalcomplexity.org/2022/02/the-beginnings-of-zero-knowledge.html">here</a>, which was inspired by a video he has in the post which was inspired by... (I think this ordering is well founded.))</p><p> ZK= Zero Knowledge.</p><p>When it was shown that NP \subseteq ZK this was a big deal. This was by Goldreich-Micali-Wigderson  (see <a href="https://dl.acm.org/doi/10.1145/116825.116852">her</a>e (FOCS-1986, JACM-1991). In the JACM paper they have the following passage:</p><div><blockquote>Our result that all languages in NP have zero-knowledge proof systems, has been extended to IP, assuming the same assumptions. (The result was first proved by Impagliazzo and Yung, but since their paper [53] contains only a claim of the result, the interested reader is directed to [11] where a (different proof) appears.) In other words, whatever can be efficiently proven can be efficiently proven in a zero-knowledge manner. This may be viewed as the best result possible, since only languages having interactive proof systems can have zero-knowledge interactive proof systems.<br/><br/>11. BEN-OR, M., GOLDREICH, O., GOLDWASSER, S., HASTAD, J., KILLIAN, J., MICALI, S,,  AND ROGAWAY, P. Everything provable is provable in zero-knowledge. In Proceedings of Advances in Cryptology— Crypto88. Lecture Notes in Computer Science, vol. 403. Springer-Verlag, New York, 1990, pp. 37-56.<br/><br/>53.IMPAGLIAZZO. R., AND YUNG, M. Direct minimum-knowledge computations. In C. Pomerance, ed., Proceedings of Advances in Cryptology— Crypto87. Lecture Notes in Computer Science, vol. 293. Springer-Verlag, New York, 1987, pp. 40-51.</blockquote>Later the papers of Lund-Fortnow-Karloff-Nisan and Shamir showed IP=PSPACE. Hence<br/><br/><div style="text-align: center;">PSPACE \subseteq ZK</div><p>When I realized this I thought OH, that's interesting! I then looked around the web and could not find any mention of it. I asked Lance and some people in crypto and yeah, they all knew it was true, but nobody seemed to care.</p><p>Why the apathy? Speculation:</p><p>1) ZK is a notion people actually want to use in real crypto (and there has been some progress on that lately). The prover for ZK in PSPACE has to be way to powerful to be practical. I don't really like this explanation since we are talking about theorists. Even in crypto, which has more of a connection to the real works then, say, Ramsey Theory, there are still plenty of non-useful results. </p><p>2) IP=PSPACE was the big news and  had interesting proof with nice ideas. Nothing crypto-ish about it. So the corollary that PSPACE \subseteq ZK is an afterthought. </p><p>3) SAT in ZK was big news. IP in ZK is nice, but uses mostly the same ideas.</p><p>4) I am WRONG- it is a celebrated result and I somehow missed the celebration.</p><p>5) The proof that ZK is in PSPACE USES two interesting results, but adds NOTHING to the mix. In short, the proof is to easy.</p><p>Any other ideas?</p></div></div>
    </content>
    <updated>2022-02-06T20:19:00Z</updated>
    <published>2022-02-06T20:19:00Z</published>
    <author>
      <name>gasarch</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03004932739846901628</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="http://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2022-02-07T23:18:36Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://scottaaronson.blog/?p=6288</id>
    <link href="https://scottaaronson.blog/?p=6288" rel="alternate" type="text/html"/>
    <link href="https://scottaaronson.blog/?p=6288#comments" rel="replies" type="text/html"/>
    <link href="https://scottaaronson.blog/?feed=atom&amp;p=6288" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">AlphaCode as a dog speaking mediocre English</title>
    <summary xml:lang="en-US">Tonight, I took the time actually to read DeepMind’s AlphaCode paper, and to work through the example contest problems provided, and understand how I would’ve solved those problems, and how AlphaCode solved them. It is absolutely astounding. Consider, for example, the “n singers” challenge (pages 59-60). To solve this well, you first need to parse […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>Tonight, I took the time actually to read DeepMind’s <a href="https://storage.googleapis.com/deepmind-media/AlphaCode/competition_level_code_generation_with_alphacode.pdf">AlphaCode paper</a>, and to work through the example contest problems provided, and understand how I would’ve solved those problems, and how AlphaCode solved them.</p>



<p>It is absolutely astounding.</p>



<p>Consider, for example, the “n singers” challenge (pages 59-60). To solve this well, you first need to parse a somewhat convoluted English description, discarding the irrelevant fluff about singers, in order to figure out that you’re being asked to find a positive integer solution (if it exists) to a linear system whose matrix looks like<br/>1 2 3 4<br/>4 1 2 3<br/>3 4 1 2<br/>2 3 4 1.<br/>Next you need to find a trick for solving such a system without Gaussian elimination or the like (I’ll leave that as an exercise…). Finally, you need to generate code that implements that trick, correctly handling the wraparound at the edges of the matrix, and breaking and returning “NO” for any of multiple possible reasons why a positive integer solution won’t exist.   Oh, and also correctly parse the input.</p>



<p>Yes, I realize that AlphaCode generates a million candidate programs for each challenge, then discards the vast majority by checking that they don’t work on the example data provided, then <em>still</em> has to use clever tricks to choose from among the thousands of candidates remaining. I realize that it was trained on tens of thousands of contest problems and millions of solutions to those problems. I realize that it “only” solves about a third of the contest problems, making it similar to a mediocre human programmer on these problems. I realize that it works only in the artificial domain of programming contests, where a complete English problem specification and example inputs and outputs are always provided.</p>



<p>Forget all that. Judged against where AI was 20-25 years ago, when I was a student, a dog is now holding meaningful conversations in English. And people are complaining that the dog isn’t a very eloquent orator, that it often makes grammatical errors and has to start again, that it took heroic effort to train it, and that it’s unclear how much the dog really understands.</p>



<p>It’s not obvious how you go from solving programming contest problems to conquering the human race or whatever, but I feel pretty confident that we’ve now entered a world where “programming” will look different.</p>



<p><strong>Update:</strong> A colleague of mine points out that one million, the number of candidate programs that AlphaCode needs to generate, could be seen as roughly exponential in the number of lines of the generated programs.  If so, this suggests a perspective according to which DeepMind has created almost the exact equivalent, in AI code generation, of a non-fault-tolerant quantum computer that’s nevertheless competitive on some task (as in the quantum supremacy experiments). I.e., it clearly does something highly nontrivial, but the “signal” is still decreasing exponentially with the number of instructions, necessitating an exponential number of repetitions to extract the signal and imposing a limit on the size of the programs you can scale to.</p></div>
    </content>
    <updated>2022-02-06T09:12:13Z</updated>
    <published>2022-02-06T09:12:13Z</published>
    <category scheme="https://scottaaronson.blog" term="Nerd Interest"/>
    <category scheme="https://scottaaronson.blog" term="The Fate of Humanity"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://scottaaronson.blog/?feed=atom</id>
      <icon>https://scottaaronson.blog/wp-content/uploads/2021/10/cropped-Jacket-32x32.gif</icon>
      <link href="https://scottaaronson.blog" rel="alternate" type="text/html"/>
      <link href="https://scottaaronson.blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2022-02-07T01:34:21Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/013</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/013" rel="alternate" type="text/html"/>
    <title>TR22-013 |  On properties that are non-trivial to test | 

	Nader Bshouty, 

	Oded Goldreich</title>
    <summary>In this note we show that all sets that are neither finite nor too dense are non-trivial to test in the sense that, for every $\epsilon&gt;0$, distinguishing between strings in the set and strings that are $\epsilon$-far from the set requires $\Omega(1/\epsilon)$ queries. 
Specifically, we show that if, for infinitely many $n$'s, the set contains at least one $n$-bit long string and at most $2^{n-\Omega(n)}$ many $n$-bit strings, then it is non-trivial to test.</summary>
    <updated>2022-02-05T16:37:06Z</updated>
    <published>2022-02-05T16:37:06Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-02-08T13:37:23Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2022/02/05/assistant-professor-at-linkoping-university-at-department-of-computer-and-information-science-apply-by-march-1-2022/</id>
    <link href="https://cstheory-jobs.org/2022/02/05/assistant-professor-at-linkoping-university-at-department-of-computer-and-information-science-apply-by-march-1-2022/" rel="alternate" type="text/html"/>
    <title>Assistant professor at Linköping University at Department of Computer and Information Science (apply by March 1 , 2022)</title>
    <summary>Linköping University announces an assistant professor position in computer science that focuses on the borderland between theoretical computer science, mathematics, and artificial intelligence. Website: https://liu.se/en/work-at-liu/vacancies?rmpage=job&amp;rmjob=18113&amp;rmlang=UK Email: peter.jonsson@liu.se</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Linköping University announces an assistant professor position in computer science<br/>
that focuses on the borderland between theoretical computer science, mathematics, and artificial intelligence.</p>
<p>Website: <a href="https://liu.se/en/work-at-liu/vacancies?rmpage=job&amp;rmjob=18113&amp;rmlang=UK">https://liu.se/en/work-at-liu/vacancies?rmpage=job&amp;rmjob=18113&amp;rmlang=UK</a><br/>
Email: peter.jonsson@liu.se</p></div>
    </content>
    <updated>2022-02-05T15:39:01Z</updated>
    <published>2022-02-05T15:39:01Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2022-02-08T13:37:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://scottaaronson.blog/?p=6256</id>
    <link href="https://scottaaronson.blog/?p=6256" rel="alternate" type="text/html"/>
    <link href="https://scottaaronson.blog/?p=6256#comments" rel="replies" type="text/html"/>
    <link href="https://scottaaronson.blog/?feed=atom&amp;p=6256" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Scott Aaronson Speculation Grant WINNERS!</title>
    <summary xml:lang="en-US">Two weeks ago, I announced on this blog that, thanks to the remarkable generosity of Jaan Tallinn, and the Speculation Grants program of the Survival and Flourishing Fund that Jaan founded, I had $200,000 to give away to charitable organizations of my choice. So, inspired by what Scott Alexander had done, I invited the readers […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>Two weeks ago, I <a href="https://scottaaronson.blog/?p=6232">announced</a> on this blog that, thanks to the remarkable generosity of Jaan Tallinn, and the Speculation Grants program of the <a href="https://survivalandflourishing.fund/">Survival and Flourishing Fund</a> that Jaan founded, I had $200,000 to give away to charitable organizations of my choice.  So, inspired by what Scott Alexander had <a href="https://astralcodexten.substack.com/p/acx-grants-results">done</a>, I invited the readers of <em>Shtetl-Optimized</em> to pitch their charities, mentioning only some general areas of interest to me (e.g., advanced math education at the precollege level, climate change mitigation, pandemic preparedness, endangered species conservation, and any good causes that would enrage the people who attack me on Twitter).</p>



<p>I’m grateful to have gotten more than twenty well-thought-out pitches; you can read a subset of them in the <a href="https://scottaaronson.blog/?p=6232#comments">comment thread</a>.  Now, having studied them all, I’ve decided—as I hadn’t at the start—to use my entire allotment to make as strong a statement as I can about a single cause: namely, <strong>subject-matter passion and excellence in precollege STEM education</strong>.</p>



<p>I’ll be directing funds to some shockingly cash-starved math camps, math circles, coding outreach programs, magnet schools, and enrichment programs, in Maine and Oregon and England and Ghana and Ethiopia and Jamaica.  The programs I’ve chosen target a variety of ability levels, not merely the “mathematical elite.”  Several explicitly focus on minority and other underserved populations.  But they share a goal of raising every student they work with as high as possible, rather than pushing the students down to fit some standardized curriculum.</p>



<p>Language like that ought to be meaningless boilerplate, but alas, it no longer is.  We live in a time when the state of California, in a misguided pursuit of “modernization” and “equity,” is <a href="https://sites.google.com/view/k12mathmatters/home">poised</a> to eliminate 8th-grade algebra, make it nearly impossible for high-school seniors to take AP Calculus, and shunt as many students as possible from serious mathematical engagement into a “data science pathway” that in practice might teach little more than how to fill in spreadsheets.  (This watering-down effort now <em>itself</em> looks liable to be watered down—but only because of a furious pushback from parents and STEM professionals, pushback in which I’m proud that this blog <a href="https://scottaaronson.blog/?p=6146">played a small role</a>.)  We live in a time when elite universities are racing to eliminate the SAT—thus, for all their highminded rhetoric, effectively slamming the door on thousands of nerdy kids from poor or immigrant backgrounds who know how to think, but not how to shine in a college admissions popularity pageant.  We live in a time when America’s legendary STEM magnet high schools, from Thomas Jefferson in Virginia to Bronx Science to Lowell in San Francisco, rather than being celebrated as the national treasures that they are, or better yet replicated, are bitterly attacked as “elitist” (even while competitive sports and music programs are not similarly attacked)—and are now being forcibly “demagnetized” by bureaucrats, made all but indistinguishable from other high schools, over the desperate pleas of their students, parents, and alumni.</p>



<p>And—alright, fine, on a global scale, arresting climate change is surely a higher-priority issue than protecting the intellectual horizons of a few teenage STEM nerds.  The survival of liberal democracy is a higher-priority issue.  Pandemic preparedness, poverty, malnutrition are higher-priority issues.  Some of my friends strongly believe that <em>the danger of AI becoming super-powerful and taking over the world</em> is the highest-priority issue … and truthfully, with this week’s announcements of <a href="https://deepmind.com/blog/article/Competitive-programming-with-AlphaCode">AlphaCode</a> and <a href="https://openai.com/blog/formal-math/">OpenAI’s theorem prover</a>, which achieve human-competitive performance in elite programming and math competitions respectively, I can’t confidently declare that they’re wrong.</p>



<p>On the other hand, when you think about the astronomical returns on every penny that was invested in setting a teenage Ramanujan or Einstein or Turing or Sofya Kovalevskaya or Norman Borlaug or Mario Molina onto their trajectories in life … and the comically tiny budgets of the world-leading programs that aim to nurture the <em>next</em> Ramanujans, to the point where $10,000 often seems like a windfall to those programs … well, you might come to the conclusion that the “protecting nerds” thing actually isn’t <em>that</em> far down the global priority list!  Like, it probably cracks the top ten.</p>



<p>And there’s more to it than that.  There’s a reason beyond parochialism, it dawned on me, why individual charities tend to specialize in wildlife conservation in Ecuador or deworming in Swaziland or some other little domain, rather than simply casting around for the highest-priority cause on earth.  <em>Expertise matters</em>—since one wants to make, not only good judgments about which stuff to support, but good judgments that most others can’t or haven’t made.  In my case, it would seem sensible to leverage the fact that I’m Scott Aaronson.  I’ve spent much of my career in math/CS education and outreach—mostly, of course, at the university level, but <em>by god</em> did I personally experience the good and the bad in nearly every form of precollege STEM education!  I’m pretty confident in my ability to distinguish the two, and for whatever I don’t know, I have close friends in the area who I trust.</p>



<p>There’s also a practical issue: in order for me to fund something, the recipient has to fill out a somewhat time-consuming application to SFF.  If I’d added, say, another $20,000 drop into the bucket of global health or sustainability or whatever, there’s no guarantee that the intended recipients of my largesse would even notice, or care enough to go through the application process if they did.  With STEM education, by contrast, holy crap!  I’ve got an inbox full of <em>Shtetl-Optimized</em> readers explaining how their little math program is an intellectual oasis that’s changed the lives of hundreds of middle-schoolers in their region, and how $20,000 would mean the difference between their program continuing or not.  <em>That’s</em> someone who I trust to fill out the form.</p>



<p>Without further ado, then, here are the first-ever Scott Aaronson Speculation Grants:</p>



<ul><li>$57,000 for <a href="https://www.mathcamp.org/">Canada/USA Mathcamp</a>, which changed my life when I attended it as a 15-year-old in 1996, and which I returned to as a lecturer in 2008.  The funds will be used for COVID testing to allow Mathcamp to resume in-person this summer, and perhaps scholarships and off-season events as well.</li><li>$30,000 for <a href="https://www.addiscoder.com/">AddisCoder</a>, which has had spectacular success teaching computer science to high-school students in Ethiopia, placing some of its alumni at elite universities in the US, to help them expand to a new “JamCoders” program in Jamaica.  These programs were founded by UC Berkeley’s amazing <a href="https://en.wikipedia.org/wiki/Jelani_Nelson">Jelani Nelson</a>, also with involvement from friend and <em>Shtetl-Optimized</em> semi-regular <a href="https://en.wikipedia.org/wiki/Boaz_Barak">Boaz Barak</a>.</li><li>$30,000 for the <a href="https://www.mssm.org/">Maine School of Science and Mathematics</a>, which seems to offer a curriculum comparable to those of Thomas Jefferson, Bronx Science, or the nation’s other elite magnet high schools, but (1) on a shoestring budget and (2) in rural Maine.  I hadn’t even heard of MSSM before Alex Altair, an alum and <em>Shtetl-Optimized</em> reader, told me about it, but now I couldn’t be prouder to support it.</li><li>$30,000 for the <a href="https://pages.uoregon.edu/nemirovm/emc.html">Eugene Math Circle</a>, which provides a math enrichment lifeline to kids in Oregon, and whose funding was just cut.  This donation will keep the program alive for another year.</li><li>$13,000 for the <a href="https://summerscience.org/">Summer Science Program</a>, which this summer will offer research experiences to high-school juniors in astrophysics, biochemistry, and genomics.</li><li>$10,000 for the <a href="https://misemaths.wordpress.com/">MISE Foundation</a>, which provides math enrichment for the top middle- and high-school students in Ghana.</li><li>$10,000 for <a href="https://www.numberchampions.org.uk/">Number Champions</a>, which provides one-on-one coaching to kids in the UK who struggle with math.</li><li>$10,000 for <a href="https://www.beammath.org/">Bridge to Enter Advanced Mathematics (BEAM)</a>, which runs math summer programs in New York, Los Angeles, and elsewhere for underserved populations.</li><li>$10,000 for <a href="https://powderhouse.org/">Powderhouse</a>, an innovative lab school being founded in Somerville, MA.</li></ul>



<p>While working on this, it crossed my mind that, on my deathbed, I might be at least as happy about having directed funds to efforts like these as about any of my research or teaching.</p>



<p>To the applicants who weren’t chosen: I’m sorry, as many of you had wonderful projects too!  As I said in the earlier post, you remain warmly invited to apply to SFF, and to make your pitch to the other Speculators and/or the main SFF committee.</p>



<p>Needless to say, anyone who feels inspired should add to my (or rather, SFF’s) modest contributions to these STEM programs.  My sense is that, while $200k can go eye-poppingly far in this area, it still hasn’t come <em>close</em> to exhausting even the lowest-hanging fruit.</p>



<p>Also needless to say, the opinions in this post are my own and are not necessarily shared by SFF or by the organizations I’m supporting.  The latter are welcome to disagree with me as long as they keep up their great work!</p>



<p>Huge thanks again to Jaan, to SFF, to my SFF contact Andrew Critch, to everyone (whether chosen or not) who participated in this contest, and to everyone who’s putting in work to broaden kids’ intellectual horizons or otherwise make the world a little less horrible.</p></div>
    </content>
    <updated>2022-02-04T17:26:02Z</updated>
    <published>2022-02-04T17:26:02Z</published>
    <category scheme="https://scottaaronson.blog" term="Announcements"/>
    <category scheme="https://scottaaronson.blog" term="Nerd Interest"/>
    <category scheme="https://scottaaronson.blog" term="The Fate of Humanity"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://scottaaronson.blog/?feed=atom</id>
      <icon>https://scottaaronson.blog/wp-content/uploads/2021/10/cropped-Jacket-32x32.gif</icon>
      <link href="https://scottaaronson.blog" rel="alternate" type="text/html"/>
      <link href="https://scottaaronson.blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2022-02-07T01:34:21Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2022/02/04/postdoc-at-lip-ens-lyon-apply-by-march-1-2022/</id>
    <link href="https://cstheory-jobs.org/2022/02/04/postdoc-at-lip-ens-lyon-apply-by-march-1-2022/" rel="alternate" type="text/html"/>
    <title>postdoc at LIP, ENS Lyon (apply by March 1, 2022)</title>
    <summary>A postdoctoral position in Computer Science is available at LIP, ENS Lyon. Details on the website. Website: http://perso.ens-lyon.fr/edouard.bonnet/postdocOffer.html Email: edouard.bonnet@ens-lyon.fr</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>A postdoctoral position in Computer Science is available at LIP, ENS Lyon. Details on the website.</p>
<p>Website: <a href="http://perso.ens-lyon.fr/edouard.bonnet/postdocOffer.html">http://perso.ens-lyon.fr/edouard.bonnet/postdocOffer.html</a><br/>
Email: edouard.bonnet@ens-lyon.fr</p></div>
    </content>
    <updated>2022-02-04T16:59:38Z</updated>
    <published>2022-02-04T16:59:38Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2022-02-08T13:37:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2022/02/04/phd-privacy-by-design-computing-for-iot-data-at-graduate-school-of-technical-sciences-aarhus-university-denmark-apply-by-march-15-2022/</id>
    <link href="https://cstheory-jobs.org/2022/02/04/phd-privacy-by-design-computing-for-iot-data-at-graduate-school-of-technical-sciences-aarhus-university-denmark-apply-by-march-15-2022/" rel="alternate" type="text/html"/>
    <title>Phd – Privacy-by-design Computing for IoT data at Graduate School of Technical Sciences, Aarhus University, Denmark (apply by March 15, 2022)</title>
    <summary>Applications are invited for a PhD fellowship/scholarship at Graduate School of Technical Sciences, Aarhus University, Denmark, within the Electrical and Computer Engineering programme. The position is available from 1 May 2022 or later. Website: https://phd.tech.au.dk/for-applicants/apply-here/saeropslag/privacy-by-design-computing-for-iot-data/ Email: daniel.lucani@ece.au.dk</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Applications are invited for a PhD fellowship/scholarship at Graduate School of Technical Sciences, Aarhus University, Denmark, within the Electrical and Computer Engineering programme. The position is available from 1 May 2022 or later.</p>
<p>Website: <a href="https://phd.tech.au.dk/for-applicants/apply-here/saeropslag/privacy-by-design-computing-for-iot-data/">https://phd.tech.au.dk/for-applicants/apply-here/saeropslag/privacy-by-design-computing-for-iot-data/</a><br/>
Email: daniel.lucani@ece.au.dk</p></div>
    </content>
    <updated>2022-02-04T09:17:46Z</updated>
    <published>2022-02-04T09:17:46Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2022-02-08T13:37:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://rjlipton.wpcomstaging.com/?p=19620</id>
    <link href="https://rjlipton.wpcomstaging.com/2022/02/03/next-big-thing/" rel="alternate" type="text/html"/>
    <title>Next Big Thing?</title>
    <summary>Big ideas we tend to like are the ones that seem impossible or crazy—Bill Maris UW History page Margaret O’Mara is a historian at the University of Washington. She specializes in the history of Silicon Valley. Of course we are most interested in the future of Silicon Valley. Today—between history and the future—we channel her […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Big ideas we tend to like are the ones that seem impossible or crazy—Bill Maris</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2022/02/03/next-big-thing/mo/" rel="attachment wp-att-19622"><img alt="" class="alignright wp-image-19622" height="175" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/02/mo.png?resize=140%2C175&amp;ssl=1" width="140"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">UW History <a href="https://history.washington.edu/people/margaret-omara">page</a></font></td>
</tr>
</tbody>
</table>
<p>
Margaret O’Mara is a <a href="https://www.margaretomara.com/">historian</a> at the University of Washington. She specializes in the history of Silicon Valley. Of course we are most interested in the future of Silicon Valley. </p>
<p>
Today—between history and the future—we channel her insights to ask what next-big-things may intersect our fields.</p>
<p>
An <a href="https://www.nytimes.com/2022/01/24/technology/silicon-valley-next-big-thing.html">article</a> last week in the New York Times quotes her on recent developments:</p>
<ol>
<li>
“The age of mobile and cloud computing has created so many new business opportunities,” O’Mara said. “But now there are trickier problems.” <p/>
</li><li>
“Imagine the economic impact of the pandemic had there not been the infrastructure— the hardware and the software— that allowed so many white-collar workers to work from home and so many other parts of the economy to be conducted in a digitally mediated way”, she added.
</li></ol>
<p>
But what’s next?</p>
<p>
</p><p/><h2> The Next Big Idea? </h2><p/>
<p/><p>
The NYT article talks about the future of Silicon Valley as seen by O’Mara and other experts. The main issue is: what are the next big ideas that will come out of Silicon Valley? Big ideas are defined by ones that will change the future and generate billions if not trillions in dollars. Some possible ones are:</p>
<ol>
<li>
Self-driving cars; <p/>
</li><li>
Advanced artificial intelligence; <p/>
</li><li>
Brain implants—to control devices with only thoughts; <p/>
</li><li>
Quantum computing; <p/>
</li><li>
<img alt="{\dots ?}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots+%3F%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>
</li></ol>
<p>
The article quotes Jake Taylor, the chief science officer at the quantum start-up <a href="https://www.riverlane.com">Riverlane</a>, as saying that “building a quantum computer might may be the most difficult task ever undertaken, [one that] defies the physics of everyday life.” </p>
<p/><h2> Next Big Theory Ideas? </h2><p/>
<p/><p>
I am quite interested in hearing what role complexity theory might play in creating the next big thing. If the area is quantum based then perhaps theory could play a major role. It helped start the explosion in interest in quantum computing. The famous results of Peter Shor on <a href="https://en.wikipedia.org/wiki/Shor%27s_algorithm">factoring</a> could no doubt play a major role. But the paradox is that theory does not seem to be central to thoughts on what the next big idea will be? Even if the idea is quantum based. </p>
<p>
What goal, result, breakthrough will make theory play a major role in the next <b>big idea</b>? </p>
<p>
One answer is to search the Internet. We find that Kurt Mehlhorn has had a course on the main ideas of theory. Perhaps we could imagine a direction for the next big idea based on one of these <a href="http://resources.mpi-inf.mpg.de/departments/d1/teaching/ss14/gitcs/syllabus.pdf">ideas</a> from his course:</p>
<ol>
<li>
Time vs. Space, P vs. NP, and More. <p/>
</li><li>
Interactive System, Zero Knowledge Proofs, the PCP Theorem. <p/>
</li><li>
Expander Graphs. <p/>
</li><li>
Learning Theory. <p/>
</li><li>
Streaming Algorithms. <p/>
</li><li>
Public-Key Cryptography. <p/>
</li><li>
Linear Programming. <p/>
</li><li>
Randomness in Computation. <p/>
</li><li>
Introduction to Approximation Algorithms. <p/>
</li><li>
Algorithms for Big Data. <p/>
</li><li>
Algebraic Techniques in Algorithm Design
</li></ol>
<p>
Here are the opening <a href="https://www.anilada.com/courses/15251f18/www/slides/lec1.pdf">slides</a> from a related course at CMU by Anil Ada and Bernhard Haeupler.</p>
<p>
</p><p/><h2> The Next is <img alt="{\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>? </h2><p/>
<p/><p>
Another idea is to search for other groups that have more directly looked at possible next ideas. For example: in 2014, a team of technical leaders from the IEEE Computer Society joined forces to write a technical report, entitled <a href="https://www.computer.org/publications/tech-news/trends/2022-report">IEEE CS 2022</a>, surveying 23 technologies that could potentially change the landscape of computer science and industry by the year 2022. By the way, 23 is special: <i>The famous Hilbert Problems are 23 in number.</i> See <a href="https://en.wikipedia.org/wiki/Hilbert%27s_problems">here</a>.</p>
<p>
Here are some of the top few that we might consider. Note we left out some that seem less special for computer science.  That leaves 14 problems.  OK, 14 is the number of Steve Smale’s problems that are fully or partly unresolved according to <a href="https://en.wikipedia.org/wiki/Smale%27s_problems">this</a>.</p>
<ol>
<li>
Security Cross-Cutting Issues The growth of large data repositories and emergence of data analytics have combined with intrusions by bad actors, governments, and corporations to open a Pandora’s box of issues. How can we balance security and privacy in this environment? <p/>
</li><li>
Sustainability Can electronic cars, LED lighting, new types of batteries and chips, and increasing use of renewables combat rising energy use and an explosion in the uptake of computing? <p/>
</li><li>
Device and Nanotechnology It is clear that MEMS devices, nanoparticles, and their use in applications are here to stay. Nanotechnology has already been useful in manufacturing sunscreen, tires, and medical devices that can be swallowed. <p/>
</li><li>
3D Integrated Circuits The transition from printed circuit boards to 3D-ICs is already underway in the mobile arena, and will eventually spread across the entire spectrum of IT products. <p/>
</li><li>
Photonics Silicon photonics will be a fundamental technology to address the bandwidth, latency, and energy challenges in the fabric of high-end systems. <p/>
</li><li>
Networking and Interconnectivity Developments at all levels of the network stack will continue to drive research and the Internet economy. <p/>
</li><li>
Software-Defined Networks OpenFlow and SDN will make networks more secure, transparent, flexible, and functional. <p/>
</li><li>
High-Performance Computing While some governments are focused on reaching exascale, some researchers are intent on moving HPC to the cloud. <p/>
</li><li>
The Internet of Things From clothes that monitor our movements to smart homes and cities, the Internet of Things knows no bounds, except for our concerns about ensuring privacy amid such convenience. <p/>
</li><li>
Natural User Interfaces The long-held dreams of computers that can interface with us through touch, gesture, and speech are finally coming true, with more radical interfaces on the horizon. <p/>
</li><li>
3D Printing 3D printing promises a revolution in fabrication, with many opportunities to produce designs that would have been prohibitively expensive. <p/>
</li><li>
Big Data and Analytics The growing availability of data and demand for its insights holds great potential to improve many data-driven decisions. <p/>
</li><li>
Machine Learning and Intelligent Systems Machine learning plays an increasingly important role in our lives, whether it’s ranking search results, recommending products, or building better models of the environment. <p/>
</li><li>
Computer Vision and Pattern Recognition Unlocking information in pictures and videos has had a major impact on consumers and more significant advances are in the pipeline.
</li></ol>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Any thoughts? Can theory play a main role in the future? </p>
<p/></font></font></div>
    </content>
    <updated>2022-02-04T04:47:33Z</updated>
    <published>2022-02-04T04:47:33Z</published>
    <category term="All Posts"/>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="ideas"/>
    <category term="Margaret O'Mara"/>
    <category term="Next Big Thing"/>
    <category term="predictions"/>
    <category term="Theory"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wpcomstaging.com</id>
      <logo>https://s0.wp.com/i/webclip.png</logo>
      <link href="https://rjlipton.wpcomstaging.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wpcomstaging.com" rel="alternate" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel's Lost Letter and P=NP</title>
      <updated>2022-02-08T13:37:32Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-1841700560229331052</id>
    <link href="http://blog.computationalcomplexity.org/feeds/1841700560229331052/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/02/the-beginnings-of-zero-knowledge.html#comment-form" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/1841700560229331052" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/1841700560229331052" rel="self" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/02/the-beginnings-of-zero-knowledge.html" rel="alternate" type="text/html"/>
    <title>The Beginnings of Zero-Knowledge</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Wired runs this <a href="https://www.youtube.com/playlist?list=PLibNZv5Zd0dyCoQ6f4pdXUFnpAIlKgm3N">video series</a> where topic expert explain concepts to five levels of difficulty, typically a child, teen, undergrad, grad student and expert. UCLA professor Amit Sahai <a href="https://www.youtube.com/watch?v=fOGdb1CTu5c">took this on</a> for zero-knowledge. </p><p>I'd recommend the whole thing but I'd like to focus on the last segment with USC Professor Shanghua Teng (<a href="https://youtu.be/fOGdb1CTu5c?t=1025">starts at 17:05</a>). Amit nicely summed up the importance of the paper.</p><blockquote><p>What was such a beautiful insight is that the idea of zero-knowledge being something that you can already predict. If you can already predict the answer, then you must not be gaining any knowledge by that interaction. This insight of being able to predict the future accurately, and that being an evidence of a lack of new knowledge.</p></blockquote><p>Like Shanghua I was also assigned the seminal zero-knowledge paper by Goldwasser-Micali-Rackoff from my advisor. In many ways the <a href="https://dl.acm.org/doi/10.1145/22145.22178">original STOC paper</a> was rough. The definitions were buggy, the examples uninspiring. Supposedly the paper didn't even get accepted into a conference in its first try. And yet as you read the paper you realize the potential, the beauty of not one but two new models that would go on to change both cryptography and complexity forever.</p><p>In the fall of 1985 when I started graduate school I took a cryptography class from Manuel Blum. Much of that class was spent on protocols that would convince you that, for example, a number was the product of three primes. By the spring of 1986, Goldreich, Micali and Wigderson distributed <a href="https://dl.acm.org/doi/abs/10.1145/116825.116852">their paper</a> showing, among other things, all NP problems has zero-knowledge proofs, making many of the protocols discussed in Blum's course a few months earlier trivial corollaries.</p><p>But it wasn't just zero-knowledge. Goldwasser, Micali and Rackoff (and independently <a href="https://doi.org/10.1016/0022-0000(88)90028-1">Babai and Moran</a>) developed the notion of interactive proof, a proof system with statistical confidence, a model that would lead to probabilistically checkable proofs and helping us understand the limits of approximation.</p><p>I owe most of my early research to the models developed in the GMR paper and glad that Amit has found a way to share these ideas so well.</p></div>
    </content>
    <updated>2022-02-02T21:46:00Z</updated>
    <published>2022-02-02T21:46:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="http://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2022-02-07T23:18:36Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://lucatrevisan.wordpress.com/?p=4607</id>
    <link href="https://lucatrevisan.wordpress.com/2022/02/02/%e6%81%ad%e5%96%9c%e5%8f%91%e8%b4%a2-13/" rel="alternate" type="text/html"/>
    <title>恭喜发财!</title>
    <summary>新年快乐！</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><figure class="wp-block-image size-full"><a href="https://lucatrevisan.files.wordpress.com/2010/02/calvin-and-hobbes.jpg"><img alt="" class="wp-image-1680" src="https://lucatrevisan.files.wordpress.com/2010/02/calvin-and-hobbes.jpg"/></a></figure>



<p>新年快乐！</p></div>
    </content>
    <updated>2022-02-02T20:15:12Z</updated>
    <published>2022-02-02T20:15:12Z</published>
    <category term="&#x65B0;&#x5E74;"/>
    <author>
      <name>luca</name>
    </author>
    <source>
      <id>https://lucatrevisan.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://lucatrevisan.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://lucatrevisan.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://lucatrevisan.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://lucatrevisan.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>"Marge, I agree with you - in theory. In theory, communism works. In theory." -- Homer Simpson</subtitle>
      <title>in   theory</title>
      <updated>2022-02-08T13:37:07Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2022/02/02/tenure-track-faculty-at-university-of-haifa-at-oranim-campus-apply-by-february-28-2022/</id>
    <link href="https://cstheory-jobs.org/2022/02/02/tenure-track-faculty-at-university-of-haifa-at-oranim-campus-apply-by-february-28-2022/" rel="alternate" type="text/html"/>
    <title>Tenure-Track Faculty at University of Haifa at Oranim Campus (apply by February 28, 2022)</title>
    <summary>The Department of Mathematics-Physics-Computer Science of the University of Haifa at Oranim College invites applications for a tenure-track faculty position in all areas of Computer Science, to begin October 1st 2022. More details on our website. Applications will be considered until the position is filled. Website: https://mathphys.haifa.ac.il/en/announcements/ Email: ackerman@math.haifa.ac.il</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Department of Mathematics-Physics-Computer Science of the University of Haifa at Oranim College invites applications for a tenure-track faculty position in all areas of Computer Science, to begin October 1st 2022. More details on our website.<br/>
Applications will be considered until the position is filled.</p>
<p>Website: <a href="https://mathphys.haifa.ac.il/en/announcements/">https://mathphys.haifa.ac.il/en/announcements/</a><br/>
Email: ackerman@math.haifa.ac.il</p></div>
    </content>
    <updated>2022-02-02T14:47:55Z</updated>
    <published>2022-02-02T14:47:55Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2022-02-08T13:37:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2022/02/02/postdoc-at-university-of-bergen-apply-by-february-11-2022/</id>
    <link href="https://cstheory-jobs.org/2022/02/02/postdoc-at-university-of-bergen-apply-by-february-11-2022/" rel="alternate" type="text/html"/>
    <title>Postdoc at University of Bergen (apply by February 11, 2022)</title>
    <summary>Two postdoctoral positions in Algorithmic foundations of data science (in a very broad sense), funded by ERC Consolidator grant of Saket Saurabh. Competitive salary, solid travel funds, and friendly research environment. Website: https://www.jobbnorge.no/en/available-jobs/job/218932/researcher-in-informatics-algorithmic-foundations-of-data-science Email: fedor.fomin@uib.no</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Two postdoctoral positions in Algorithmic foundations of data science (in a very broad sense), funded by ERC Consolidator grant of Saket Saurabh. Competitive salary, solid travel funds, and friendly research environment.</p>
<p>Website: <a href="https://www.jobbnorge.no/en/available-jobs/job/218932/researcher-in-informatics-algorithmic-foundations-of-data-science">https://www.jobbnorge.no/en/available-jobs/job/218932/researcher-in-informatics-algorithmic-foundations-of-data-science</a><br/>
Email: fedor.fomin@uib.no</p></div>
    </content>
    <updated>2022-02-02T12:06:04Z</updated>
    <published>2022-02-02T12:06:04Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2022-02-08T13:37:35Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://gradientscience.org/datamodels-1/</id>
    <link href="https://gradientscience.org/datamodels-1/" rel="alternate" type="text/html"/>
    <title>Predicting Predictions with Datamodels</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a class="bbutton" href="https://arxiv.org/abs/2202.00622" style="float: left; width: 45%;">
<i class="fas fa-file-pdf"/>
    Paper
</a>
<a class="bbutton" href="https://github.com/MadryLab/datamodels-data" style="float: left; width: 45%;">
<i class="fab fa-github"/>
   Data
</a>
<br/>
<em>What drives machine learning (ML) models’ predictions?</em></p>

<p>This question is rarely an easy one to answer. On one hand, we know that predictions are a product of <em>training data</em> and <em>learning algorithms</em>. On the other hand, it is often hard to characterize exactly how these two elements interact.</p>

<p>In our <a href="https://arxiv.org/abs/2202.00622">latest work</a>, we introduce <em>datamodels</em>—a step towards acquiring a more fine-grained understanding of how learning algorithms use training data to make predictions. This post introduces the datamodeling framework, describes its simplest, <em>linear</em> instantiation, and illustrates its success in modeling data-to-prediction mapping for deep neural networks. Our future posts will tour through some of the applications of the datamodeling framework that we are most excited about.</p>

<h2 id="what-is-a-datamodel">What is a datamodel?</h2>

<p>In the standard machine learning setup, we have both a learning algorithm (say, stochastic gradient descent applied to a deep neural network) and a training set to learn from (say, the CIFAR-10 training set).</p>

<p>Now, suppose that we want to evaluate model behavior on a specific input \(x\). For example, \(x\) might be one of the following input-label pairs from the <a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-10</a> test set:</p>



<div class="row">
     <div class="img_holder">
         <img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/horse7.png"/>
         <span>"horse"</span>
     </div>
     <div class="img_holder">
         <img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/dog7.png"/>
         <span>"dog"</span>
     </div>
     <div class="img_holder">
         <img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/ship5.png"/>
         <span>"boat"</span>
     </div>
     <div class="img_holder">
         <img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/truck5.png"/>
         <span>"firetruck"</span>
     </div>
 </div>

<p>A natural question that might arise in this context is: <em>for such an example \(x\), how does the learning algorithm use the training data to arrive at its prediction?</em> Answering this question is difficult—think of the underlying complexity stemming from training  a deep neural network using thousands of stochastic gradient descent (SGD) steps.</p>

<p>Our <em>datamodeling</em> framework is motivated exactly by this challenge. Specifically, the goal of datamodeling is to bypass that complexity of model training entirely, and instead find a <em>simple</em> function that <em>directly</em> maps training data to predictions. So, roughly speaking, a <em>datamodel</em> for a specific example of interest \(x\) is a function \(g(S’)\) that takes as input any subset \(S’\) of the original training \(S\), and as output predicts the outcome of training a model on \(S’\) and then evaluating on \(x\).</p>
<div class="footnote">
Note that “evaluating” is left intentionally vague here as we expect the specific form to be task dependent: one might be interested in, for instance, the predicted label (e.g., in classification tasks), squared error (e.g., in regression tasks), or log-likelihood (e.g., in language modeling tasks).
</div>

<p>For the visual learners out there, datamodels have the following interface:</p>

<p><img src="https://gradientscience.org/images/datamodels/flow.png" style="width: 75%;"/></p>

<p>The hope is to find datamodels that are <em>simple</em> enough to analyze directly, yet <em>accurate</em> enough to faithfully capture model behavior. We then can use such datamodels to gain insight into how the algorithm and data combine <em>through</em> the lens of the training dynamics (but without having to analyze that dynamics directly).</p>

<p>At first glance, this of task of <em>predicting</em> the output of a learning algorithm trained on different subsets of the original training set does not appear any easier than <em>analyzing</em> the learning algorithm on that original training set—in fact, it might seem even harder. At the very least, one would expect that any function approximating such a learning algorithm would need to be rather complicated. It turns out, however, that a (very) simple instantiation of datamodels—as linear functions—is already expressive enough to accurately capture the intended mapping, even for real-world deep neural networks!</p>

<h2 id="linear-datamodels-for-deep-classifiers">Linear datamodels for deep classifiers</h2>

<p>How exactly do we formulate <em>linear datamodels</em>? We represent each subset \(S’\) of the training set as an <em>indicator vector</em> \(\mathbf{1}_{S’}\), and then have our datamodel \(g_\theta\) map such indicator vectors to scalars. Specifically, we parameterize linear datamodels as:</p>

\[g_\theta(S’) = \mathbf{1}_{S’}^\top \theta + \theta_0,\]

<p>where \(\theta\) are our model’s parameters.</p>

<div class="footnote">
An <a href="https://en.wikipedia.org/wiki/Indicator_vector">indicator vector</a>
is a binary vector of dimension equal to the size of the training set, whose
\(i\)-th index is equal to \(1\) if and only if the \(i\)-th training example is present in \(S’\). 
</div>

<h2 id="estimating-linear-datamodels">Estimating linear datamodels</h2>

<p>Now, how do we actually select parameters \(\theta\) for such a linear datamodel? Recall that our goal is to find a \(\theta\) such that our linear datamodel satisfies:</p>

<center>
$$
g_\theta(S’) \approx \mbox{the output on \(x\) of a model trained on \(S’\).}
$$
</center>

<p>Our idea is to frame this task as a <em>supervised learning problem</em> in which we infer \(g_\theta\) from “input-label pairs.” Here, each of these pairs consists of a specific training subset \(S’\) (“input”) and the corresponding model output on \(x\) (“label”). Indeed, obtaining such pairs is rather easy—for a given choice of \(S’\), we retrieve corresponding outputs by just executing the learning algorithm on \(S’\) and evaluating on \(x\).</p>

<p>From this perspective, estimating \(g_\theta\) for a given \(x\) becomes a two-step process:</p>

<ul>
  <li><strong>Collecting our datamodel train set</strong>:  Sample a training subset \(S_i\), train
 a model on \(S_i\), and, finally, add the corresponding “input-label pair”
 \((S_i, \text{trained model output on }x)\) to our datamodel training set. 
 Rinse and repeat (until that training set becomes sufficiently large).</li>
  <li><strong>Datamodel training</strong>: Solve for \(\theta\) by regressing from our “training subsets” \(S_i\) to their corresponding model outputs on \(x\).</li>
</ul>

<p>Now: how many such input-label pairs do we need to be able to solve the corresponding (very high-dimensional) regression problem? (Note that the dimension here is 50k, the size of the training set!) The answer is: a lot. Specifically, to fit CIFAR-10 datamodels we trained a few <em>hundred thousand</em> CIFAR-10 models. (Moreover, looking across all our paper’s experiments, we train more than 4 million such models in total.) To make this task feasible, we designed (and released!) a <a href="https://ffcv.io/">fast fast model training library</a>—you might find this library helpful for your training tasks, however big or small. With our library, we were able to bring CIFAR training down to <em>seconds</em> on a single (A100) GPU, meaning that training hundreds of thousands of models takes (only) a few days (on a single machine).</p>

<div class="footnote">
Use our <i>data release</i>! Both pre-computed datamodels and the predictions of 4 million trained CIFAR models are available for download at <a href="https://github.com/MadryLab/datamodels-data">https://github.com/MadryLab/datamodels-data</a>.
</div>

<h2 id="evaluating-datamodels">Evaluating datamodels</h2>

<p>Now, after all this setup, the key question is: how accurately do such linear datamodels predict model behavior? Following our supervised learning perspective, the gold standard is to evaluate via a held-out test set: a set of (held-out) input-label (or rather, in our case, subset-model output) pairs.</p>

<p>Specifically, we make a <em>datamodel “test set”</em> using the same sampling process employed to generate the datamodel train set. We then compare <em>datamodel-predicted</em> outputs for these (previously unseen) collected subsets to the <em>true outputs</em> (i.e., the output of training a model on the subset and evaluating on the relevant example). It turns out that datamodels predictions predict the result of model training rather well!</p>

<p>
    <img src="https://gradientscience.org/images/datamodels/blog_xy.svg" style="width: 50%;"/>
</p>

<div class="footnote">
    The plotted points range across both choice of training set and target example \(x\). The magnified clusters of the same color each correspond to the same \(x\) for different sampled training sets \(S’\). The output here that we measure is correct-label margin, i.e., the difference between the logit for the correct class and the largest incorrect logit.
</div>

<p>The predicted and actual margins here—even conditioned on a specific \(x\)—correspond nearly one-to-one, despite that our predicted margins come from a linear model, and the actual margins stem from thousands of SGD steps on a ResNet-9!</p>

<h2 id="how-can-we-use-datamodels">How can we use datamodels?</h2>

<p>We’ve already seen that a simple linear model can predict the output of end-to-end model training (for a single target example) relatively well. We found this phenomenon surprising on its own, and hope that studying it further might yield theoretical or empirical insights into the generalization of deep networks (and when applied to new settings, other classes of machine learning models).</p>

<p>That said, in a series of follow up posts we’ll also highlight some of the other direct datamodel applications:</p>

<ul>
  <li>In Part 2, we’ll take a deeper dive into datamodels’ ability to predict outcomes of model training, and find that this ability extends beyond just the subsets sampled from the distribution they were fitted to. We’ll then use this capability to identify <em>brittle predictions</em>, test examples for which model predictions can be flipped by removing just a small number of examples from the training set.</li>
  <li>In Part 3, we’ll discuss how to use datamodels to identify training examples that are similar to any given test example, and will then employ this capability to find (non-trivial) train-test leakage in both CIFAR-10 and FMoW datasets. (FMoW is the other dataset that we investigate in our paper.)</li>
  <li>In Part 4, we’ll explore leveraging linear datamodels as <em>feature representation</em>. Specifically, we find that datamodels yield a natural way to embed every example into a well-behaved representation space. We use the corresponding embeddings to perform clustering and identify <em>model-driven</em> data subpopulations.</li>
</ul>

<p>All of these applications are fully detailed in <a href="https://arxiv.org/abs/2202.00622">our paper</a>, along with more experiments, a more formal introduction to datamodels, and an extensive discussion of the related and future work in this area. Also, check out our <a href="https://github.com/MadryLab/datamodels-data">data release</a> with both pre-computed datamodels and predictions corresponding to million CIFAR-10 models. Stay tuned for more!</p></div>
    </summary>
    <updated>2022-02-02T00:00:00Z</updated>
    <published>2022-02-02T00:00:00Z</published>
    <source>
      <id>https://gradientscience.org/</id>
      <author>
        <name>Gradient Science</name>
      </author>
      <link href="https://gradientscience.org/" rel="alternate" type="text/html"/>
      <link href="https://gradientscience.org/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Research highlights and perspectives on machine learning and optimization from MadryLab.</subtitle>
      <title>gradient science</title>
      <updated>2022-02-07T22:46:46Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/012</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/012" rel="alternate" type="text/html"/>
    <title>TR22-012 |  On List Decoding Transitive Codes From Random Errors | 

	Anup Rao, 

	Oscar Sprumont</title>
    <summary>We study the error resilience of transitive linear codes over $F_2$. We give tight bounds on the weight distribution of every such code $C$, and we show how these bounds can be used to infer bounds on the error rates that $C$ can tolerate on the binary symmetric channel. Using this connection, we show that every transitive code can be list-decoded from random errors. As an application, our results imply list-decoding bounds for Reed-Muller codes even when the rate exceeds the channel capacity.</summary>
    <updated>2022-02-01T22:26:33Z</updated>
    <published>2022-02-01T22:26:33Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-02-08T13:37:23Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2022/02/01/postdoc-at-boston-college-apply-by-february-21-2022/</id>
    <link href="https://cstheory-jobs.org/2022/02/01/postdoc-at-boston-college-apply-by-february-21-2022/" rel="alternate" type="text/html"/>
    <title>Postdoc at Boston College (apply by February 21, 2022)</title>
    <summary>The Computer Science department at Boston College invites applications for a postdoctoral position in the area of graph algorithms (broadly defined, e.g. distributed graph algorithms, local algorithms, dynamic graph algorithms, streaming algorithms, MPC algorithms, and etc) under the supervision of Hsin-Hao Su. Website: https://sites.google.com/site/distributedhsinhao/postdoc-position-on-distributed-graph-algorithms Email: suhx@bc.edu</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Computer Science department at Boston College invites applications for a postdoctoral position in the area of graph algorithms (broadly defined, e.g. distributed graph algorithms, local algorithms, dynamic graph algorithms, streaming algorithms, MPC algorithms, and etc) under the supervision of Hsin-Hao Su.</p>
<p>Website: <a href="https://sites.google.com/site/distributedhsinhao/postdoc-position-on-distributed-graph-algorithms">https://sites.google.com/site/distributedhsinhao/postdoc-position-on-distributed-graph-algorithms</a><br/>
Email: suhx@bc.edu</p></div>
    </content>
    <updated>2022-02-01T19:10:53Z</updated>
    <published>2022-02-01T19:10:53Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2022-02-08T13:37:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://nisheethvishnoi.wordpress.com/?p=131</id>
    <link href="https://nisheethvishnoi.wordpress.com/2022/01/31/focs-2021-is-virtually-here/" rel="alternate" type="text/html"/>
    <title>FOCS 2021 is (Virtually) Here!</title>
    <summary>The 62nd Annual IEEE Foundations of Computer Science (FOCS) will be held (virtually) February 7-10, 2022 — this coming Monday! Thanks to the effort of the progam committee, the FOCS 2021 program consists of 118 amazing papers in three parallel sessions. All talks will be live and of the usual length of 20 minutes. The […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The <a href="https://focs2021.cs.colorado.edu/">62nd Annual IEEE Foundations of Computer Science (FOCS)</a> will be held (virtually) February 7-10,  2022 — this coming Monday!</p>



<p>Thanks to the effort of the <a href="https://focs2021.cs.colorado.edu/cfp/">progam committee</a>, the <a href="https://focs2021.cs.colorado.edu/program/">FOCS 2021 program</a> consists of 118 amazing papers in three parallel sessions. All talks will be <strong>live </strong>and of the usual length of 20 minutes. The program has also set aside ample time for breaks to enable the participants to socialize and connect on gather and slack. </p>



<p>FOCS 2021 also has <strong>three exciting workshops</strong> as a part of the main program:<br/><br/>1) <a href="https://sites.google.com/view/focs2021ml/home">Recent directions in Machine Learning</a>: co-organized by <a href="https://www.cs.columbia.edu/~djhsu/">Daniel Hsu</a>, <a href="https://people.csail.mit.edu/madry/">Aleksander Madry</a>, and <a href="http://users.eecs.northwestern.edu/~aravindv/">Aravindan Vijayaraghavan</a>, and and featuring <a href="http://tensorlab.cms.caltech.edu/users/anima/">Anima Anandkumar</a>, <a href="https://causalai.net/">Elias Bareinboim</a>, <a href="http://people.cs.uchicago.edu/~risi/">Risi Kondor</a>, <a href="https://profiles.stanford.edu/chris-manning">Christopher Manning</a>, <a href="https://www.andrew.cmu.edu/user/aristesk/">Andrej Risteski</a>, <a href="http://www.columbia.edu/~cgr2130/">Cynthia Rush</a>, <a href="https://jsteinhardt.stat.berkeley.edu/">Jacob Steinhardt</a>.<br/><br/>2) <a href="https://derezende.github.io/focs21proofcomplexity/index.html">Reflections on Propositional Proofs in Algorithms and Complexity</a>: co-organized by <a href="https://www.cs.toronto.edu/~toni/" rel="noreferrer noopener" target="_blank">Toni Pitassi</a>, <a href="https://derezende.github.io/">Susanna de Rezende</a>, and <a href="https://www.cs.mcgill.ca/~robere/" rel="noreferrer noopener" target="_blank">Robert Robere</a>, and featuring <a href="https://www.math.ucsd.edu/~sbuss/" rel="noreferrer noopener" target="_blank">Sam Buss</a>, <a href="https://home.cs.colorado.edu/~jgrochow/index.html" rel="noreferrer noopener" target="_blank">Joshua Grochow</a>, <a href="https://www.cs.cmu.edu/~praveshk/" rel="noreferrer noopener" target="_blank">Pravesh K. Kothari</a>, <a href="https://www2.karlin.mff.cuni.cz/~krajicek/" rel="noreferrer noopener" target="_blank">Jan Krajíček</a>, <a href="https://www.cs.toronto.edu/~toni/" rel="noreferrer noopener" target="_blank">Toni Pitassi</a>, <a href="https://derezende.github.io/">Susanna de Rezende</a>, <a href="https://www.cs.mcgill.ca/~robere/" rel="noreferrer noopener" target="_blank">Robert Robere</a>, <a href="https://www.cs.ox.ac.uk/people/rahul.santhanam/" rel="noreferrer noopener" target="_blank">Rahul Santhanam</a>, <a href="https://users.math.cas.cz/~thapen/" rel="noreferrer noopener" target="_blank">Neil Thapen</a>.<br/><br/>3) <a href="https://focs2021.cs.colorado.edu/workshop-on-cryptography/">Workshop on Cryptography</a>: co-organized by <a href="https://crypto.stanford.edu/~dabo/">Dan Boneh</a> and <a href="http://web.cs.ucla.edu/~sahai/">Amit Sahai</a>, and featuring <a href="https://cs.idc.ac.il/~elette/">Elette Boyle</a>, <a href="https://sites.google.com/view/aayushjain/home">Aayush Jain</a>, <a href="https://www.cs.technion.ac.il/~yuvali/">Yuval Ishai</a>, <a href="https://homes.cs.washington.edu/~rachel/">Rachel Lin</a>, <a href="https://c.rypto.systems/">Wilson Nguyen</a>, <a href="https://www.cs.cornell.edu/~rafael/">Rafael Pass</a>, <a href="https://simons.berkeley.edu/people/hoeteck-wee">Hoeteck Wee</a>.</p>



<p><a href="https://focs2021.cs.colorado.edu/registration/">Registration </a>is still open and available at a reduced rate of $100-150 for participants. </p>



<p>Thanks to generous support from the National Science Foundation, there will be a total of $15,000 in <a href="https://focs2021.cs.colorado.edu/nsf-awards-for-focs-2021/">support for FOCS 2021</a> for eligible students and postdoctoral fellows towards registration fee. </p>



<p>Looking forward to seeing many of you next week!</p>



<p/>



<p><strong>Update: Junior/Senior Lunches by <a href="https://ccanonne.github.io/">Clement Cannone</a> and <a href="http://www.gautamkamath.com/">Gautam Kamath</a>:<br/></strong></p>



<p>Back by popular demand! As part of FOCS 2021, and in view of the success of similar events in the past, a “junior/senior lunch” will take place on Tuesday February 8, 1:30PM-2:30pm ET. Importantly, this is <strong>not</strong> limited to FOCS attendees! As in previous years, this virtual lunch will be the occasion for senior researchers in the field, broadly construed, to have an informal chat with students, postdocs, and junior faculty, answer their questions, discuss their research, and generally have a nice conversation.</p>



<p>To participate as either a senior or junior researcher, please write your name in <a href="https://docs.google.com/spreadsheets/d/1nrL8I0l2OF1kbMFTKlaBdK1L2LXkOMjR1PKBjEUSA4E/edit?usp=sharing">this spreadsheet</a>. Further instructions will be sent to people who sign up.  If you are on the “senior” side of the lunch, you will be responsible for contacting the corresponding juniors, and provide a Zoom link.</p>



<p/>



<p><br/></p></div>
    </content>
    <updated>2022-01-31T21:33:22Z</updated>
    <published>2022-01-31T21:33:22Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>nisheethvishnoi</name>
    </author>
    <source>
      <id>https://nisheethvishnoi.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://nisheethvishnoi.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://nisheethvishnoi.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://nisheethvishnoi.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://nisheethvishnoi.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Algorithms, Nature, and Society</title>
      <updated>2022-02-08T13:38:40Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2022/01/31/linkage</id>
    <link href="https://11011110.github.io/blog/2022/01/31/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>A happy 75th birthday to Dick Lipton and 1000th post on his blog with Ken Regan, Gödel’s Lost Letter and \(\mathsf{P}=\mathsf{NP}\) (\(\mathbb{M}\)).</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><ul>
  <li>
    <p><a href="https://rjlipton.wpcomstaging.com/2022/01/14/happy-1000th-post-and-75th-birthday-dick/">A happy 75th birthday to Dick Lipton and 1000th post on his blog with Ken Regan, <em>Gödel’s Lost Letter and \(\mathsf{P}=\mathsf{NP}\)</em></a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107634279991786612">\(\mathbb{M}\)</a>).</span></p>
  </li>
  <li>
    <p>A quick round-up of three recent Wikipedia Good Articles <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107640833016660096">\(\mathbb{M}\)</a>):</span></p>

    <ul>
      <li>
        <p><a href="https://en.wikipedia.org/wiki/Factorial">Factorial</a> – you know, <span style="white-space: nowrap;">\(n!\).</span></p>
      </li>
      <li>
        <p><a href="https://en.wikipedia.org/wiki/Jessen%27s_icosahedron">Jessen’s icosahedron</a> – polyhedron with all-right dihedrals despite not having axis-parallel sides; the shape of the “Skwish” tensegrity.</p>
      </li>
      <li>
        <p><a href="https://en.wikipedia.org/wiki/Erd%C5%91s%E2%80%93Straus_conjecture">Erdős–Straus conjecture</a> – the question of whether \(\tfrac4n=\tfrac1x+\tfrac1y+\tfrac1z\) has positive integer solutions for <span style="white-space: nowrap;">all \(n\gt 1\).</span></p>
      </li>
    </ul>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2201.06475">Infinite Hex is a draw</a>, Joel David Hamkins and Davide Leonessi <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107646776817088370">\(\mathbb{M}\)</a>,</span> <a href="http://jdh.hamkins.org/infinite-hex-is-a-draw/">via</a>). The paper uses a winning condition for the infinite game that seems pretty technical: you need a bidirectional infinite path of your pieces, whose two ends eventually stay inside all translations of  two opposite quadrants (NE-SW or NW-SE depending on the player). They give a simple mirroring strategy for drawing, and explain why other winning conditions aren’t as nice.</p>
  </li>
  <li>
    <p><a href="https://fractalkitty.com/2022/01/19/string-art-presentation/">String art from Fractal Kitty</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@fractalkitty/107649797432442304">\(\mathbb{M}\)</a>).</span></p>
  </li>
  <li>
    <p><a href="https://cs.stanford.edu/~knuth/fasc12a+.pdf">The Art of Computer Programming, Volume 4, Pre-Fascicle 12A: Components and Traversal</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107659396275070620">\(\mathbb{M}\)</a>).</span> It’s labeled as “ridiculously preliminary”, but includes interesting material on <a href="https://en.wikipedia.org/wiki/Weak_component">weak components of directed graphs</a>. Strong components are the finest partially ordered vertex sets under reachability; analogously, weak components are the finest total order. Every vertex can reach all vertices in later sets, and none in earlier ones.</p>
  </li>
  <li>
    <p><a href="https://mirtitles.org/2022/01/16/some-applications-of-mechanics-to-mathematics-popular-lectures-in-mathematics-vol-3-uspenskii/"><em>Some Applications Of Mechanics To Mathematics</em> by V. A. Uspenskii</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@jarban/107634117912496403">\(\mathbb{M}\)</a>).</span> Usually it goes the other way around. One of the Mir free book series, translated from Russian into English.</p>
  </li>
  <li>
    <p><a href="https://somethingorotherwhatever.com/jiggraph/">JIGGRAPH</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@christianp/107671629340668489">\(\mathbb{M}\)</a>).</span> A game of holding hands or, if you prefer something more abstract, fitting vertices with known local geometries together into a graph.</p>
  </li>
  <li>
    <p><a href="https://history-of-mathematics.org/">History of Mathematics Project</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107676446199538323">\(\mathbb{M}\)</a>,</span> <a href="https://www.sciencenews.org/article/history-math-online-exhibit-journey">via</a>, <a href="https://www.metafilter.com/194098/Math-History">via2</a>), an online exhibit for MOMATH. I’m not convinced of the soundness of a project whose timeline of prime numbers starts with Eratosthenes instead of Euclid, skips from Greeks to enlightenment Europe completely bypassing Ibn al-Haytham (using an ordinal time scale to hide the gap), and doesn’t mention the prime number theorem, but still this looks interesting or at least entertaining.</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2107.13460">Asymptotics of the number of \(n\)-queens placements</a>, Michael Simkin <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107681952236743192">\(\mathbb{M}\)</a>,</span> <a href="https://news.harvard.edu/gazette/story/2022/01/harvard-mathematician-answers-150-year-old-chess-problem/">via</a>, <a href="https://news.ycombinator.com/item?id=30068680">via2</a>). “The chief innovation is the introduction of limit objects for \(n\)-queens configurations, which we call queenons.”</p>
  </li>
  <li>
    <p><a href="https://theconversation.com/more-women-in-a-stem-field-leads-people-to-label-it-as-a-soft-science-according-to-new-research-173724">More women in a STEM field leads people to label it as a “soft science”</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107687670599777394">\(\mathbb{M}\)</a>).</span> Alysson Light provides a general-audience explanation of <a href="https://doi.org/10.1016/j.jesp.2021.104234">her research with Tessa Benson-Greenwald and Amanda Diekman in <em>J. Experimental Social Psych.</em></a>.</p>
  </li>
  <li>
    <p>Today’s observation on overlooked history of mathematics <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107693041325431974">\(\mathbb{M}\)</a>):</span> The <a href="https://en.wikipedia.org/wiki/Binary_tiling">binary tiling of the hyperbolic plane</a>, generally attributed to a 1974 paper by Károly Böröczky, was already used by M. C. Escher in a 1957 print, <em><a href="https://www.escherinhetpaleis.nl/escher-today/woodblocks-and-the-regular-division-of-the-plane/?lang=en">Regular Division of the Plane VI</a></em>.</p>
  </li>
  <li>
    <p>If the pigeonhole principle is the idea that more than \(n\) items distributed into  containers lead to a container with more than one item <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107706939046931942">\(\mathbb{M}\)</a>),</span> what is the name for the principle that fewer than \(n\) items distributed into  containers lead to an empty container?</p>
  </li>
  <li>
    <p><a href="https://3quarksdaily.com/3quarksdaily/2022/01/do-androids-dream-of-mathematics.html">Do androids dream of mathematics</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107710557994842340">\(\mathbb{M}\)</a>)?</span> A popular-audience essay by algebraic combinatorist Jonathan Kujawa on data vs insight in mathematics, and the use of computers in sifting through piles of data on mathematical objects and their invariants in order to focus on potential relations between them.</p>
  </li>
  <li>
    <p>I upgraded from MacOS 11 to 12.2 recently <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107718968183366763">\(\mathbb{M}\)</a>).</span> Today was our first day of in-person classes. I could not get my laptop working with the lecture hall display. Fortunately I was broadcasting the lecture over Zoom and everyone in the classroom had a laptop so we did it that way. But <a href="https://www.youtube.com/watch?v=C6FyXNfGY0k">this video</a> looks like it describes the problem, and a fix (in System Preferences : Battery : Battery, uncheck “Automatic graphics switching”) — I’m hopeful this will work and I can lecture from the big screen next time.</p>
  </li>
</ul></div>
    </content>
    <updated>2022-01-31T17:14:00Z</updated>
    <published>2022-01-31T17:14:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2022-02-05T20:49:19Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-6013534385390898908</id>
    <link href="http://blog.computationalcomplexity.org/feeds/6013534385390898908/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/01/regan-lipton-celebrates-my-1000th-blog.html#comment-form" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/6013534385390898908" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/6013534385390898908" rel="self" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/01/regan-lipton-celebrates-my-1000th-blog.html" rel="alternate" type="text/html"/>
    <title>Regan Lipton celebrates my 1000th blog post and random thoughts this inspires</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Ken Regan emailed me recently asking if our software could tell how many blogs I had done (not how many Lance+Bill had done). We didn't know how to do that but he managed it anyway. Apparently he was more interested in this question than either Lance or I was. </p><p>But the answer was interesting: My1000th post of Complexityblog was about Betty White dying at just the wrong time to be in those <i>those we say goodbye to</i> articles that appear CLOSE to the end of the year. (I don't know why, but I think the fact that my 1000th post was on Betty White is just awesome!) The post is <a href="https://blog.computationalcomplexity.org/2022/01/did-betty-white-die-in-2021why-do.html">here</a>. He was asking this because he thought (correctly) that I was around 1000 and wanted to do a tribute blog to me (actually it was done by Lipton and Regan- more on that later). And indeed they did do the post, its <a href="https://rjlipton.wpcomstaging.com/2022/01/29/bill-gasarch-also-1000/">here</a>.</p><p>RANDOM THOUGHT ONE</p><p>While preparing it Ken asked me about my papers.  This brings up the more general question: When looking at your old work what do you think? Common reactions are</p><p>1) Gee, I was smarter then. That was very clever. OH, now I remember, my co-author did it. </p><p>2) Gee, I was dumber then. I could do that argument so much better now. </p><p>3) Why did I care about Muffins so much to write a book about it? (Replace <i>Muffins</i> with <i>whatever you</i> <i>worked on</i> and <i>book</i> with the<i> venue it appeared in</i>.) </p><p>Item 3 is probably the most common: As a graduate student one works on things without really have a vision of the field (though the advisor can mitigate this) so what you work on may seem odd later on. And ones tastes can change as well. </p><p>RANDOM THOUGHT TWO</p><p>Ken and Dick write actual posts together. I find that amazing! By contrast, the extent of Lance and my interactions about the blog are: </p><p>a) Someone died. Which of us should do the blog obit? or get a guest blogger.?(Whenever Lance phones me on the telephone I answer <i>who died</i> and usually someone did.) </p><p>b) Which of us does the April Fools Day post this year (we usually alternate, or <a href="https://blog.computationalcomplexity.org/2014/04/i-am-bill-gasarch.html">do we</a>)?</p><p>c) I plan on doing 2 posts close together- a question and an answer, so when do you NOT plan on blogging so I can do that.</p><p>d) Someone proved X. Which of us should blog? Or should we get a guest blogger?</p><p>e) Establish a general rule for the year like <i>Bill will post Sunday's, Lance Thursdays.</i></p><p>f) I ask Lance for technical help on the blog. How do you get rid of the white background when I cut and paste?</p><p>g) Sometimes one of us wants commentary on a blog we are working no- but that is rare. Though I asked Lance for this post and he added a few things to this list.</p><p>h) Sometimes I look at one of his posts before it goes out and offer commentary, or vice versa. Also rare.</p><p>i) Lance writes the end of year posts, but always with my input. We jointly choose the theorem of the year.</p><p>j) The very <a href="https://blog.computationalcomplexity.org/2015/03/leonard-nimoy-1931-2015_2.html">rare</a> <a href="https://blog.computationalcomplexity.org/2017/08/the-crystal-blogaversity.html">joint</a> <a href="https://blog.computationalcomplexity.org/2008/02/wseas-greek-tragedy.html">posts</a>.</p><p>k) If we happen to be in the same place at the same time, like Dagsthul, we'll do a <a href="https://blog.computationalcomplexity.org/search?q=typecast">typecast</a> capturing our conversations. In the past we've also had <a href="https://lance.fortnow.com/blogpodcasts/podcast.xml">podcasts</a> and <a href="https://www.youtube.com/user/fortnow">vidcasts</a> together.</p><p><br/></p><p><br/></p></div>
    </content>
    <updated>2022-01-30T19:50:00Z</updated>
    <published>2022-01-30T19:50:00Z</published>
    <author>
      <name>gasarch</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03004932739846901628</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="http://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2022-02-07T23:18:36Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2022/01/30/fast-iterated-exchange</id>
    <link href="https://11011110.github.io/blog/2022/01/30/fast-iterated-exchange.html" rel="alternate" type="text/html"/>
    <title>Fast iterated exchange transformations via normal curves</title>
    <summary>Soon after I posted my preprint “The Complexity of Iterated Reversible Computation” (arXiv:2112.11607) last month (see previous post “Raytracing diamonds”), Mark Bell emailed me to observe that one of the problems I mentioned in it, iterated integer interval exchange transformations, could be solved in polynomial time by reinterpreting it as a problem on normal curves in triangulated surfaces and plugging in known results from computational topology. Here is a more detailed expansion of that observation.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Soon after I posted my preprint <a href="https://arxiv.org/abs/2112.11607">“The Complexity of Iterated Reversible Computation” (arXiv:2112.11607)</a> last month (see <a href="https://11011110.github.io/blog/2021/12/23/raytracing-diamonds.html">previous post “Raytracing diamonds”</a>), Mark Bell emailed me to observe that one of the problems I mentioned in it, iterated integer interval exchange transformations, could be solved in polynomial time by reinterpreting it as a problem on normal curves in triangulated surfaces and plugging in known results from computational topology. Here is a more detailed expansion of that observation.</p>

<p>First, some terminology, with a picture to help make sense of it:</p>

<p style="text-align: center;"><img alt="Integer interval exchange transformation represented as a normal curve on a triangulated surface" src="https://11011110.github.io/blog/assets/2022/normal-interval-exchange.svg"/></p>

<dl>
  <dt>Interval exchange transformation</dt>
  <dd>An <a href="https://en.wikipedia.org/wiki/Interval_exchange_transformation">interval exchange transformation</a> is a transformation of an interval, obtained by dividing it up into subintervals, permuting the subintervals, and concatenating them back together in the permuted order to obtain the starting interval. They have been widely studied in the theory of dynamical systems. The picture above is derived from an interval exchange transformation on four subintervals \(a\), \(b\), \(c\), and \(d\) (top edge of the rectangle), permuted into the new order \(b\), \(d\), \(c\), \(a\) (bottom edge of the rectangle).</dd>
  <dt>Integer interval exchange transformation</dt>
  <dd>In order to obtain a transformation on a discrete set rather than a continuous interval, we restrict our attention to intervals of the number line, interval exchange transformations that map integers to integers on the number line, and the action of those transformations on the integers. More specifically, we can consider the \(N\) integers from \(0\) to \(N-1\), for some \(N\). The one in the picture has \(N=15\), with the integer positions on the number line shown as vertical blue line segments.</dd>
  <dd>
    <p>An integer interval exchange transformation can be specified by listing the largest integer in each interval, in permuted order: here, this permuted list is \(5, 14, 6, 3\). If there are \(k\) intervals, this specification has bit-length \(O(k\log N)\) and so to achieve polynomial time we will want a time bound that is polynomial in \(k\) and \(\log N\).</p>
  </dd>
  <dt>Iterated interval exchange transformation</dt>
  <dd>Given a number \(n\), a starting value \(x\), and a specified integer interval exchange transformation \(f\), repeatedly apply \(f\), \(n\) times. What is the value \(f^{(n)}(x)\) that results? For instance, the transformation shown takes \(0\to 11\to 6\to 8\to\cdots\), so \(f^3(0)=8\).</dd>
  <dt>Surface</dt>
  <dd>The surfaces I have in mind are compact two-dimensional <a href="https://en.wikipedia.org/wiki/Orientability">oriented manifolds</a> without boundary: topologically like a plane at every point, but globally having a different topology. They can be classified as the sphere, torus, two-handled torus, etc., but we won’t need this classification. The rectangle in the figure can be interpreted as a surface if we glue the pairs of labeled edges together. The left and right sides of the rectangle, when glued together, make a cylinder. The top and bottom edges of the rectangle are glued according to the labeling shown, rather than just wrapping directly from top to bottom.</dd>
  <dt>Triangulated surface</dt>
  <dd>Subdivide the surface into triangles, meeting edge-to-edge, as in the figure. For topological purposes the geometry of the surface is unimportant: all you need to know is the triangles and how they meet edge-to-edge.</dd>
  <dt>Normal curve</dt>
  <dd>A normal curve, on a triangulated surface, is a curve that does not cross itself, does not pass through any triangle vertices, and when entering a triangle on one edge always leaves on a different edge. After gluing the rectangle to form a surface, the blue lines link up to form a normal curve.</dd>
  <dt>Normal arc</dt>
  <dd>A normal curve can have more than one connected component; when it does, a single component is called an arc. The blue normal curve turns out to be an arc: it has only one component.</dd>
  <dt>Normal coordinates</dt>
  <dd>The normal coordinates of a normal curve describe the curve by specifying, for each edge of a topological triangulation, how many times the normal curve crosses each edge. The normal coordinates on the labeled horizontal edges are \(N_a=4\), \(N_b=2\), \(N_c=1\), and \(N_d=8\). The normal coordinates on the vertical edges are all zero; the other edges interior to the rectangle have nonzero normal coordinates, which are just the numbers of times each edge is crossed by the blue curve.</dd>
  <dd>
    <p>Not all assignments of numbers to triangulation edges work. For a triangle with edges \(x\), \(y\), and \(z\), the normal coordinates \(N_x\), \(N_y\), and \(N_z\) must obey the <a href="https://en.wikipedia.org/wiki/Triangle_inequality">triangle inequality</a>. You can read off how the curve crosses the triangle from these numbers: it has \((N_x+N_y-N_z)/2\) segments that cross from edge \(x\) to edge \(y\), etc. The triangle inequality ensures that these numbers of segments are all non-negative; additionally, each triangle must have an even sum of coordinates, to make these numbers of segments be integers. A curve topologically equivalent to the given curve can be obtained by placing the given number of tick-marks on each edge and connecting them by non-crossing segments according to this formula.</p>
  </dd>
  <dt>Edge coordinates</dt>
  <dd>The edge coordinate of a point where a normal curve crosses an edge is just its position along the crossings on that edge.</dd>
  <dt>Arc coordinates</dt>
  <dd>The arc coordinate of a point where a normal curve crosses an edge is its position among all of the crossings along the normal curve, in the order they are reached by that curve, after choosing an arbitrary starting point to have coordinate zero.</dd>
</dl>

<p>With all of this as setup, and with the algorithms on normal curves from a paper by Jeff Erickson and Amir Nayyeri, <a href="https://doi.org/10.1007/s00454-013-9515-z">“Tracing Compressed Curves in Triangulated Surfaces”, <em>DCG</em> 2013</a>, the rest is easy:</p>

<ul>
  <li>
    <p>Given an interval exchange transformation, construct a surface in the form depicted: a triangulated rectangle, divided into some number \(s\) of horizontal stripes, with the input intervals to the transformation subdividing the top of the rectangle and the outputs subdividing the bottom. Triangulate it as shown in the figure, so that each vertical line through the rectangle crosses exactly one diagonal per slice, and so that the central horizontal line across the rectangle forms an unsubdivided edge. Each step up or down from this central line allows the number of horizontal subdivisions to double, so it suffices to let \(s=2\lceil\log_2 k\rceil\), producing a triangulation with \(O(k)\) triangles. Glue the left and right sides of the rectangle together, and glue top and bottom according to the labeling from the transformation.</p>
  </li>
  <li>
    <p>Compute the normal coordinates of the normal curve formed by the vertical integer lines in the rectangle. The normal coordinate of any edge is how far apart horizontally its endpoints are within the rectangle.</p>
  </li>
  <li>
    <p>Given the number \(x\) whose iterates we want to compute, let \(p_x\) be the point of the central horizontal line, \(x\) steps from the left. Each iteration of the exchange transformation can be obtained by advancing \(2s\) units upward along the curve, starting from \(p_x\), and wrapping around halfway through from the top of the rectangle to the bottom.</p>
  </li>
  <li>
    <p>Find the normal arc containing \(p_x\) and its normal coordinates (Erickson and Nayyeri, Theorem 6.2). Its length \(X\) (measured as a number of crossings) is just the sum of these normal coordinates.</p>
  </li>
  <li>
    <p>Convert the known edge coordinate of \(p_x\) to an arc coordinate (Erickson and Nayyeri, Theorem 6.3), add \(2ns\) (modulo \(X\)) to this arc coordinate, convert the resulting arc coordinate back into an edge coordinate in its arc (Erickson and Nayyeri, Theorem 6.4), and then back into an edge coordinate in the whole curve. This edge coordinate is the number we want to compute, \(f^{(n)}(x)\).</p>
  </li>
</ul>

<p>The topological subroutines used by this algorithm all take time quadratic in the size of the triangulation and logarithic in the number of crossings of the normal curve, so for the triangulation and normal curve constructed above this time bound is \(O(k^2\log N)\).</p>

<p>(<a href="https://mathstodon.xyz/@11011110/107714613861230488">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2022-01-30T17:34:00Z</updated>
    <published>2022-01-30T17:34:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2022-02-05T20:49:19Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/011</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/011" rel="alternate" type="text/html"/>
    <title>TR22-011 |  Public-Key Encryption from Continuous LWE | 

	Andrej Bogdanov, 

	Miguel Cueto Noval, 

	Charlotte Hoffmann, 

	Alon Rosen</title>
    <summary>The continuous learning with errors (CLWE) problem was recently introduced by Bruna
et al. (STOC 2021). They showed that its hardness implies infeasibility of learning Gaussian
mixture models, while its tractability implies efficient Discrete Gaussian Sampling and thus
asymptotic improvements in worst-case lattice algorithms. No reduction between CLWE and
LWE is currently known, in either direction.
We propose four public-key encryption schemes based on the hardness of CLWE, with varying
tradeoffs between decryption and security errors, and different discretization techniques. Some
of our schemes are based on hCLWE, a homogeneous variant, which is no easier than CLWE.
Our schemes yield a polynomial-time algorithm for solving hCLWE, and hence also CLWE,
using a Statistical Zero-Knowledge oracle.</summary>
    <updated>2022-01-30T04:10:37Z</updated>
    <published>2022-01-30T04:10:37Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-02-08T13:37:23Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://rjlipton.wpcomstaging.com/?p=19594</id>
    <link href="https://rjlipton.wpcomstaging.com/2022/01/29/bill-gasarch-also-1000/" rel="alternate" type="text/html"/>
    <title>Bill Gasarch Also 1,000</title>
    <summary>Another theory of computing blogging milestone 2016 Gathering For Gardner lecture William Gasarch turned 1,000 earlier this month. Or in October, depending on how you count. That is, he has made 1,000 posts on a theory blog all by himself. Bill is a professor at the University of Maryland Department of Computer Science and is […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><font color="#0044cc"><br/>
<em>Another theory of computing blogging milestone</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<p/>
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2022/01/29/bill-gasarch-also-1000/billgsnip/" rel="attachment wp-att-19596"><img alt="" class="alignright wp-image-19596" height="200" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/01/BillGsnip.jpg?resize=162%2C200&amp;ssl=1" width="162"/>
</a></td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">2016 Gathering For Gardner <a href="https://rjlipton.wpcomstaging.com/feed/www.youtube.com/watch?v=TXJ6fYF9em8">lecture</a></font></td>
</tr>
</tbody>
</table>
<p>
William Gasarch turned 1,000 earlier this month. Or in October, depending on how you count. That is, he has made 1,000 posts on a theory blog all by himself. Bill is a professor at the University of Maryland Department of Computer Science and is one of the leaders in computational complexity theory, computability theory, computational learning theory, and Ramsey theory. </p>
<p>
Today we congratulate Bill on this milestone and convey some of his other work and activities.<br/>
<span id="more-19594"/></p>
<p>
Bill joined as Lance Fortnow’s official partner on the <i>Computational Complexity</i> <a href="https://blog.computationalcomplexity.org">blog</a> in March 2007. His 1,000th from that point was his Jan. 2 <a href="https://blog.computationalcomplexity.org/2022/01/did-betty-white-die-in-2021why-do.html">post</a> about Betty White and boundaries of time. If we count seven posts from two earlier guest-blogger stints when Lance was on vacation, then his 1,000th <i>Computational Complexity</i> post was <a href="https://blog.computationalcomplexity.org/2021/10/squaring-circle-is-mentioned-in-gilbert.html">this</a> last October 24th about some appearances of mathematics in Gilbert and Sullivan operettas.</p>
<p>
As noted <a href="https://www.meersworld.net/2019/02/how-to-filter-blogger-posts-by-authors.html">here</a>, the <em>Blogger</em> platform does not break down post counts by author, only by label, so I (Ken) resorted to grabbing all the text and counting all the “Posted by” lines. By the same count, Lance has 1,850 posts, and there are blocks by other guest posters. </p>
<p>
Other metrics might be interesting: Shall we count equations? theorems? open problems? proofs given in full? conjectures? How about a raw count of numbers used in the posts, apart from words? Anyway, Bill has done a lot more in the public eye than the blog.</p>
<p>
</p><p/><h2> Book Reviews </h2><p/>
<p/><p>
Bill was the book review editor for ACM SIGACT NEWS from 1997 to 2015 before turning the job over to Fred Green, a professor of computer science at Clark University. See Bill’s reviews <a href="https://www.cs.umd.edu/users/gasarch/bookrev/bookrev.html">here</a>. The reviews are wonderful and there are lots of them. He should be thanked many times for the terrific work he did there.</p>
<p>
I (Dick) am happy to say that Bill reviewed three of my books: </p>
<ol>
<li>
People, Problems, and Proofs, by Richard Lipton and Ken Regan. <p/>
</li><li>
The P=NP Question and Gödel’s Lost Letter, by Richard Lipton. <p/>
</li><li>
Ideas that Created the Future: Classic Papers of Computer Science, the <a href="https://www.yumpu.com/en/document/view/65334324/pdf-ideas-that-created-the-future-classic-papers-of-computer-science-full">book</a> edited by Harry Lewis.
</li></ol>
<p>
The last one includes one of my strangest papers: “Social Processes and Proofs of Theorems and Programs,” with Rich DeMillo and Alan Perlis in 1977. Rich and I cherish it because it included Perlis as a co-author. He was special to many of us—especially those from <a href="https://www.cmu.edu">CMU</a>. We always will miss him. </p>
<p>
</p><p/><h2> New Book and Numbers </h2><p/>
<p/><p>
Let’s look at Bill’s <a href="https://www.cs.umd.edu/users/gasarch/">personal</a> page. He highlights his wonderful newest <a href="https://www.amazon.com/Mathematical-Muffin-Morsels-Problem-Mathematics/dp/9811215170">book</a> <i>Mathematical Muffin Morsels: Nobody Wants a Small Piece</i>. It is joint with Erik Metz, Jacob Prinz, and Daniel Smolyak, who were undergraduate students in Bill’s group, and features contributions by numerous others.</p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2022/01/29/bill-gasarch-also-1000/book-7/" rel="attachment wp-att-19598"><img alt="" class="aligncenter size-full wp-image-19598" height="283" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/01/book.png?resize=178%2C283&amp;ssl=1" width="178"/></a></p>
<p>
A summary: </p>
<blockquote><p><b> </b> <em> Suppose you have five muffins that you want to divide and give to Alice, Bob, and Carol. You want each of them to get <img alt="{5/3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B5%2F3%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/>. You could cut each muffin into <img alt="{1/3-1/3-1/3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%2F3-1%2F3-1%2F3%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/> and give each student five <img alt="{1/3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%2F3%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/>-sized pieces. But Alice objects! She has large hands! She wants everyone to have pieces larger than <img alt="{1/3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%2F3%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/>.</em></p><em>
<p>
Is there a way to divide five muffins for three students so that everyone gets <img alt="{5/3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B5%2F3%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/>, and all pieces are larger than <img alt="{1/3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%2F3%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/>? Spoiler alert: Yes! In fact, there is a division where the smallest piece is <img alt="{5/12}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B5%2F12%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/>. Is there a better division? Spoiler alert: No.</p>
</em><p><em>
This problem takes us through much mathematics of interest, for example, combinatorics and optimization theory. However, the math is elementary enough for an advanced high school student. </em>
</p></blockquote>
<p/><p>
What supplements the math is the use of accessibly simple computer programs to do numerical experiments. Some can be found on Bill’s <a href="https://www.cs.umd.edu/~gasarch/MUFFINS/muffins.html">Muffin Website</a>. Among news after our June 2018 <a href="https://rjlipton.wpcomstaging.com/2018/06/21/muffins-and-integers/">post</a> on the muffin problem, Richard Chatwin <a href="https://arxiv.org/pdf/1907.08726.pdf">proved</a> that the value <img alt="{f(s,m) =}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28s%2Cm%29+%3D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> the largest size of the smallest piece—when <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> muffins are divided equally among <img alt="{s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> people—depends only on the ratio <img alt="{m/s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%2Fs%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. The value <img alt="{f(61,27)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%2861%2C27%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> left wide open in the post has been proved to equal <img alt="{41/90}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B41%2F90%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and other bounds have been closed.</p>
<p>
All these sources have tables of what we might—to channel the title of Bill’s other <a href="https://rjlipton.wpcomstaging.com/2019/03/10/problems-with-a-point/">recent</a> <a href="https://www.worldscientific.com/worldscibooks/10.1142/11261">book</a> with Clyde Kruskal—call <em>Numbers With a Point</em>. The point is the insight they give about asymptotic growth and likelihood of conjectures. We note in particular a 2020 <a href="https://www.cs.umd.edu/~gasarch/MUFFINS/MuffinsAnalysis/MuffinsAnalysis.pdf">paper</a> by Smolyak on “The Muffin Problem – Data Analysis of Exceptions” to patterns in the values <img alt="{f(s,m)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28s%2Cm%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. </p>
<p>
</p><p/><h2> More Numbers </h2><p/>
<p/><p>
Bill gave a <a href="https://www.cs.umd.edu/~gasarch/COURSES/858/S20/notes/liptonbday.pdf">talk</a> in our January 17 workshop on “Seeking an Easier Proof of a Weaker Result in Multiparty Communication Complexity.” The topic is a classic setting in which <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> people each have an <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>-bit number on their foreheads, so that all can see everyone else’s number but not their own. The problem is to compute some function or predicate <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> of the numbers, such as their whether their sum exceeds or equals a given value <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, while minimizing the total number <img alt="{d_{f,k}(n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd_%7Bf%2Ck%7D%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> of bits communicated. </p>
<p>
Ashok Chandra, Merrick Furst, and I (Dick) raised these problems in a 1983 <a href="http://www.cs.umd.edu/~gasarch/TOPICS/ramsey/mpp.pdf">paper</a>, which Bill preserves on his site for papers related to Ramsey theory. The trivial way of having one person reveal another’s hidden number giving bound <img alt="{d_{f,k}(n) \leq n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd_%7Bf%2Ck%7D%28n%29+%5Cleq+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> (plus one or more bits needed for that person to speak the result of <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> to all parties). The basic surprising fact is that, as a function of <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and for the above and other natural predicates <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, one can do asymptotically much better than <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>.</p>
<p>
Bill talked about his own <a href="https://www.cs.umd.edu/~gasarch/papers/multicomm.pdf">paper</a> with Richard Beigel and James Glenn on the exact-<img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> case. It appeared at the MFCS 2006 conference. This paper is really neat because it shows the problem has depth and difficulty and ramifications beyond what I imagined back then. It gives connections to groups and regular expressions, besides refining our original application to branching programs. See also the <a href="https://www.cs.umd.edu/~gasarch/BLOGBOOK/foreheadserious.pdf">update</a> that went with Bill’s talk.</p>
<p>
Even the case of <img alt="{k=3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%3D3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> people is highly nontrivial. The paper gives a chart tracking the constant in the <img alt="{O}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> for the result giving <img alt="{d_{f,k}(n) = O(\sqrt{n})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd_%7Bf%2Ck%7D%28n%29+%3D+O%28%5Csqrt%7Bn%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> with <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> of order <img alt="{2^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. The constant on the closest-known bounding formula seems to stay in the vicinity of <img alt="{\pi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> (the chart gives its reciprocal), going from <img alt="{47/15 = 3.13...}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B47%2F15+%3D+3.13...%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> to <img alt="{48/15 = 3.2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B48%2F15+%3D+3.2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> in the last lines. Is that a coincidence? It relates to the density of sets of integers with no arithmetic progression of length 3, for which see this StackExchange <a href="https://math.stackexchange.com/questions/1250622/largest-subset-with-no-arithmetic-progression">item</a> from last year, and this older <a href="http://www.cs.umd.edu/~gasarch/BLOGPAPERS/3apsurvey.pdf">survey</a> by Bill with Glenn and Kruskal.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Bill is one of the top writers on theory. We owe him some props. Thank you, Bill.</p>
<p/></font></font></div>
    </content>
    <updated>2022-01-29T23:04:04Z</updated>
    <published>2022-01-29T23:04:04Z</published>
    <category term="All Posts"/>
    <category term="News"/>
    <category term="People"/>
    <category term="Teaching"/>
    <category term="1000th post"/>
    <category term="Bill Gasarch"/>
    <category term="blog milestone"/>
    <category term="book reviews"/>
    <category term="muffin puzzle"/>
    <category term="multiparty protocols"/>
    <category term="numbers"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wpcomstaging.com</id>
      <logo>https://s0.wp.com/i/webclip.png</logo>
      <link href="https://rjlipton.wpcomstaging.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wpcomstaging.com" rel="alternate" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel's Lost Letter and P=NP</title>
      <updated>2022-02-08T13:37:32Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2022/01/27/open-algorithmic-problems</id>
    <link href="https://11011110.github.io/blog/2022/01/27/open-algorithmic-problems.html" rel="alternate" type="text/html"/>
    <title>Open algorithmic problems from a talk by Alon</title>
    <summary>The UCI mathematics department had a departmental colloquium today given by Noga Alon, titled “The Polynomial Method and its Algorithmic Aspects”. One part of his talk that I found very interesting was a collection of easy-to-state combinatorial problems where the existence of a solution can be proved, but there is no known efficient (polynomial time) algorithm for finding the solution:</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The UCI mathematics department had a departmental colloquium today given by Noga Alon, titled “The Polynomial Method and its Algorithmic Aspects”. One part of his talk that I found very interesting was a collection of easy-to-state combinatorial problems where the existence of a solution can be proved, but there is no known efficient (polynomial time) algorithm for finding the solution:</p>

<ul>
  <li>
    <p>Let \(p\) be a prime number, and suppose that we are given two inputs: a sequence \(A=a_1,a_2,\dots a_k\) of elements of \(\mathbb{Z}_p\), of length \(k\lt p\), not necessarily distinct from each other, and a set \(B\), also consisting of \(k\) elements of \(\mathbb{Z}_p\), distinct but not ordered. Can we pair them up by assigning an ordering \(b_1,b_2,\dots\) to the elements of \(B\) so that all of the sums \(a_i+b_i\) are distinct? For instance, if all of the \(A\)’s are equal, then any ordering of the \(B\)’s will work.</p>
  </li>
  <li>
    <p>Let \(G\) be a bipartite graph that has a perfect matching. Assign “non-degrees” to the vertices on one side of the bipartition, numbers that should not be the degree of the vertex. Can we delete some subset of the vertices on the other side, so that in the remaining graph each vertex’s degree is different from its non-degree? For instance, if the non-degrees are all zero, then \(G\) itself will work (it has nonzero degree because it has a perfect matching). If the non-degrees are all non-zero, then we can delete all of the vertices on the other side of the bipartition.</p>
  </li>
  <li>
    <p>Let \(G\) be a planar graph with degree three at every vertex, and suppose also that each edge of \(G\) has a list of three colors available to it. Can we assign colors from these lists to the edges so that each vertex touches edges of three different colors?</p>
  </li>
  <li>
    <p>Let \(C_1\) and \(C_2\) be proper colorings of a large \(d\)-dimensional grid, using \(q\ge d+2\) colors, and let \(S_1\) and \(S_2\) be subsets of the vertices of the grid that are far apart from each other (I am not sure how far this needs to be but it seems to be \(d\pm O(1)\) or maybe \(q\pm O(1)\)). Can we find a proper coloring of the whole grid that blends between the two colorings, agreeing with each \(C_i\) on \(S_i\)? This one comes from a new paper by Alon, Raimundo Briceño, Nishant Chandgotia, Alexander Magazinov, and Yinon Spinka, <a href="https://doi.org/10.1017/S0963548320000395">“Mixing properties of colourings of the \(\mathbb{Z}^d\) lattice”, <em>Combinatorics, Probability and Computing</em> 2021</a>. Fewer colors will not always work.</p>
  </li>
</ul>

<p>In all of these cases, the answer to the existence problem is yes, but we don’t know of an efficient algorithm for finding the structure that is supposed to exist. Instead, Alon proves the existence non-constructively, through a combinatorial <a href="https://en.wikipedia.org/wiki/Hilbert%27s_Nullstellensatz">Nullstellensatz</a> encoding the principle that low-degree polynomials don’t have many roots. For one-variable polynomials of degree \(d\), for instance, there cannot be more than \(d\) values at which the polynomial is zero. But the degree really has to be \(d\), and not merely at most \(d\), because the degree-zero constant-zero polynomial is zero everywhere.</p>

<p>The analogous principle Alon uses for higher numbers of variables is the following: Let \(p\) be a polynomial of degree \(d\) in the variables \(x_1,x_2,\dots x_n\), over some field, and let \(t_i\) be the exponents of a nonzero monomial \(\prod_i x_i^{t_i}\) of degree \(d\) in \(p\). Additionally, let \(S_i\) be (not necessarily distinct) sets of \(t_i+1\) elements. Then we can choose an element \(s_i\) in each \(S_i\) such that \(p(s_1,s_2,\dots)\) is non-zero. Alon surveys this principle and its applications in his paper <a href="https://doi.org/10.1017/S0963548398003411">“Combinatorial Nullstellensatz”, <em>Combinatorics, Probability and Computing</em> 1999</a>.</p>

<p>The hard parts about using this method to prove existence in combinatorial problems such as the ones above are finding the right polynomial and proving that it has a nonzero coefficient at the right monomial. The problem on reordering with distinct pairwise sums, for instance, comes from Alon’s paper <a href="https://doi.org/10.1007/BF02773567">“Additive Latin transversals”, <em>Israel J. Math.</em> 2000</a> and uses the polynomial</p>

\[\prod_{i\lt j}(x_i-x_j)(a_i+x_i-a_j-x_j)\]

<p>where each \(S_i=B\), the first terms in the product can only be nonzero if each \(x_i\) is chosen to be a distinct member of \(B\), and the second terms in the product can only be nonzero if the pairwise sums are different from each other. The coefficient of the monomial \(\prod x_i^{k-1}\) turns out to be (up to sign) exactly \(k!\), which is nonzero modulo \(p\) by the assumptions that \(p\) is prime and \(k\lt p\). The nonzero coefficients for the other two problems are not so easy to compute: they are the <a href="https://en.wikipedia.org/wiki/Permanent_(mathematics)">permanent</a> (number of perfect matchings) and the number of 3-edge-colorings of the given graphs. For the case of 3-edge-colorings, the fact that this number is nonzero is one of the equivalent forms of the 4-color theorem.</p>

<p>The general problem of constructing a nonzero solution to an instance of the combinatorial Nullstellensatz whose polynomial is described by an arithmetic circuit is (according to Alon) as hard as inverting arbitrary one-way permutations, a standard cryptographic primitive. This suggests that a polynomial-time construction algorithm does not exist; if it did exist, it would break a lot of modern cryptography. On the other hand, proving that it does not exist would also prove \(\mathsf{P}\ne\mathsf{NP}\). Despite this relation to standard hard problems, there’s no strong reason for believing that any of the combinatorial problems outlined above is as hard as the general case, so maybe they might still have an efficient algorithm. If so, it would probably translate into an existence proof that is substantially different than the ones we already have for these problems.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/107698894668333119">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2022-01-27T23:08:00Z</updated>
    <published>2022-01-27T23:08:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2022-02-05T20:49:19Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://differentialprivacy.org/synth-data-1/</id>
    <link href="https://differentialprivacy.org/synth-data-1/" rel="alternate" type="text/html"/>
    <title>A simple recipe for private synthetic data generation</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>In the <a href="https://differentialprivacy.org/synth-data-0/">last blog post</a>, we covered the potential pitfalls of synthetic data without formal privacy guarantees, and motivated the need for differentially private synthetic data mechanisms.  In this blog post, we will describe the <strong>select-measure-generate</strong> paradigm, which is a simple and effective template for designing synthetic data mechanisms.  The three steps underlying the select-measure-generate paradigm are illustrated and explained below.</p>

<p><img alt="" src="https://differentialprivacy.org/images/select-measure-reconstruct.png"/></p>

<ol>
  <li><strong>Select</strong> a collection of queries to measure — typically low-dimensional marginals.</li>
  <li><strong>Measure</strong> the selected queries privately using a noise-addition mechanism.</li>
  <li><strong>Generate</strong> synthetic data that best explains the noisy measurements.<sup id="fnref:0"><a class="footnote" href="https://differentialprivacy.org/feed.xml#fn:0" rel="footnote">1</a></sup></li>
</ol>

<p>Mechanisms in this class differ primarily in their methodology for selecting queries and their algorithm for generating synthetic data from noisy measurements.  The focus of this blog post is the final <strong>Generate</strong> step.  Specifically, we will explore different ways in which one can model data distributions for the purpose of generating synthetic data, outlining the qualitative pros and cons of each method. We will then introduce the <strong><a href="https://github.com/ryan112358/private-pgm" target="_blank">Marginal-Based Inference (MBI)</a></strong> repository that provides methods that, given some set of noisy measurements, enables users to generate synthetic data in a generic and scalable way.</p>

<p>Separating the Generate subroutine from the existing synthetic data generation mechanisms greatly simplifies the design space of new differentially private mechanisms.  It allows the mechanism designer to focus on <em>selecting the queries</em> to maximize utility of the synthetic data, rather than <em>how to generate synthetic data</em> that explain the noisy measurements well.  Both are challenging technical problems that require different techniques to solve, and MBI provides principled solutions to the latter problem, while exposing an interface that can be readily adopted by mechanism designers.</p>

<h1 id="the-generate-subproblem-a-unifying-view">The Generate Subproblem: A Unifying View</h1>

<p>In this section we will introduce the main optimization problem that underlies several methods for the Generate subproblem, and provide a high-level overview of how each method attempts to solve this optimization problem. Let \( y = \mathcal{M}(D) \) be the noisy measurements obtained from running a privacy mechanism on a discrete dataset \( D \).  Our goal is to post-process these noise measurements to obtain synthetic data that explains them well.  In particular, we wish to minimize over the space of all <em>datasets</em> for one that maximizes the likelihood of the observations \( y \).<sup id="fnref:1"><a class="footnote" href="https://differentialprivacy.org/feed.xml#fn:1" rel="footnote">2</a></sup></p>

<p>\[ \hat{D} \in \text{arg} \max_{D \in \mathcal{D}} \log \mathbb{P}[\mathcal{M}(D) = y] \]</p>

<p>This is a high-dimensional discrete optimization problem, and is generally intractable to solve in practice, even in low-dimensional settings.  It is common to consider the relaxed problem that instead optimizes over the set of <em>probability distributions</em> \( \mathcal{S} \):</p>

<p>\[ \hat{P} \in \text{arg} \max_{P \in \mathcal{S}} \log \mathbb{P}[\mathcal{M}(P) = y] \label{eq1} \tag{1} \]</p>

<p>More generally, we can consider any objective function that measures how well \( P \) explains \( y \).  The log-likelihood is a natural choice, although other choices are also possible and used in practice.  In the special-but-common case where the mechanism is an instance of the Gaussian mechanism, we have \( \mathcal{M}(D) = f(D) + \mathcal{N}(0, \sigma^2)^k \) and \( \log \mathbb{P}[\mathcal{M}(P) = y] \propto - || f(P) - y ||_2^2 \).  If \( f \) is a linear function of \( P \), then Problem \ref{eq1} is simply a quadratic program.  In the subsequent subsections, we will describe different approaches to solve or approximately solve Problem \ref{eq1}.</p>

<blockquote>
  <p><strong>Remark 1</strong>: The distribution learned from solving Problem \ref{eq1} will resemble the true data with respect to the statistics measured by \( \mathcal{M} \).  It may or may not accurately preserve other statistics — that is data dependent.</p>
</blockquote>

<blockquote>
  <p><strong>Remark 2</strong>: The most common statistics to measure are <strong>low-dimensional marginals</strong>.  A marginal for a subset of attributes counts the number of records in the dataset that match each setting of possible values. They are appealing statistics to measure because:</p>
  <ul>
    <li>They capture low-dimensional structure common in real world data distributions.</li>
    <li>Each cell in a marginal is a count, a statistic that is fairly robust to noise.</li>
    <li>One individual can only contribute to a single cell of a marginal, so all cells have low sensitivity and can be measured simultaneously with low privacy cost.</li>
  </ul>
</blockquote>

<h3 id="direct">Direct</h3>

<p>We can attempt to solve Problem \ref{eq1} directly by utilizing any algorithm for convex optimization over the probability simplex, such as multiplicative weights.  This method works well in low-dimensional regimes, although quickly becomes intractable for higher-dimensional domains, where it is generally intractable to even enumerate all the entries of a single distribution \( P \), let alone optimize over the space of all distributions.</p>

<p>Until recently, variants of the direct method were the only general-purpose solutions available for this problem, and as a result, many mechanisms struggled to scale to high-dimensional domains.  Recently, several methods have been proposed that attempt to overcome the curse of dimensionality inherent in the direct approach, which scale by imposing additional assumptions on the mechanism \( \mathcal{M} \) and/or by relaxing the optimization problem.  A common theme is to restrict attention to a subset of joint distributions which have tractable representations.     The sections below describe these more scalable methods, including the different (implicit) assumptions each method makes, as well as the consequences of those assumptions.</p>

<h3 id="probabilistic-graphical-models-pgm">Probabilistic Graphical Models (PGM)</h3>

<p>The first method we describe is <a href="https://arxiv.org/abs/1901.09136" target="\_blank">PGM</a>, which was a key component of the first-place solution in the 2018 NIST Differential Privacy <a href="https://www.nist.gov/ctl/pscr/open-innovation-prize-challenges/past-prize-challenges/2018-differential-privacy-synthetic" target="\_blank">Synthetic Data Competition</a> and in both the first and second-place solutions in the follow-up <a href="https://www.nist.gov/ctl/pscr/open-innovation-prize-challenges/current-and-upcoming-prize-challenges/2020-differential" target="\_blank">Temporal Map Competition</a>.</p>

<p>PGM scales by restricting attention to distributions that can be represented as a graphical model \( P_{\theta} \).  The key observation of PGM is that when \( \mathcal{M} \) only depends on \( P \) through its low-dimensional marginals, then one of the optimizers of Problem \ref{eq1} is a graphical model with parameters \( \theta \).  In this case, Problem \ref{eq1} is under-determined and typically has infinitely many solutions.  It turns out that the solution found by PGM has maximum entropy among all solutions to the problem — a very natural way to break ties among equally good solutions. Remarkably, these facts are true for any dataset — they do not require the underlying data to be generated from a graphical model with the same structure <a href="https://arxiv.org/abs/2108.04978" target="\_blank">[MMS21]</a>.</p>

<p>The parameter vector \( \theta \) is often much smaller than \( P \), and we can efficiently optimize it, bypassing the curse of dimensionality in this special case.  The size of \( \theta \) and in turn the complexity of PGM depends on the mechanism \( \mathcal{M} \), and in the worst case is the same as the Direct method.<sup id="fnref:6"><a class="footnote" href="https://differentialprivacy.org/feed.xml#fn:6" rel="footnote">3</a></sup>  However, in many common cases of practical interest, the complexity of PGM is exponentially better than that of Direct, in which case we can efficiently solve the optimization problem above, finding \( \theta \) and thus a tractable representation of \( \hat{P} \).  The complexity ultimately depends on the size of the junction tree derived from the mechanism \( \mathcal{M} \), and understanding this relationship requires some expertise in graphical models.  However, if we utilize this understanding to design \( \mathcal{M} \), we can avoid this worst-case behavior, as <a href="https://arxiv.org/abs/2108.04978" target="\_blank">MST</a> and <a href="http://vldb.org/pvldb/vol14/p2190-cai.pdf" target="\_blank">PrivMRF</a> do.</p>

<h3 id="relaxed-tabular">Relaxed Tabular</h3>

<p>An alternative approach was proposed in the recent <a href="https://arxiv.org/abs/2103.06641" target="\_blank">RAP</a> paper.  The key idea is to restrict attention to “pseudo-distributions” that can be represented in a relaxed tabular format.  The format is similar to the one-hot encoding of a discrete dataset, although the entries need not be \( 0 \) or \( 1 \), which enables gradient-based optimization to be performed on the cells in this table.  The number of rows is a tunable knob that can be set to trade off expressive capacity with computational efficiency.  With a sufficiently large knob size, the true minimizer of the original problem can be expressed in this way, but there is no guarantee that gradient-based optimization will converge to it because this representation introduces non-convexity.  Moreover, the search space of this method includes “spurious” distributions, so even the global optimum of relaxed problem would not necessarily solve the original problem.<sup id="fnref:9"><a class="footnote" href="https://differentialprivacy.org/feed.xml#fn:9" rel="footnote">4</a></sup>  Despite these drawbacks, this method appears to work well in practice.</p>

<h3 id="generative-networks">Generative Networks</h3>

<p>Among the iterative methods introduced by <a href="https://arxiv.org/abs/2106.07153" target="\_blank">[LVW21]</a> is GEM (Generative networks with the exponential mechanism), an approach inspired by generative adversarial networks. They propose representing any dataset as mixture of product distributions over attributes in the data domain. They implicitly encode such distributions using a generative neural network with a softmax layer. In concrete terms, given some Gaussian noise \( \mathbf{z} \sim \mathcal{N}(0, I) \), their <strong>Generate</strong> step outputs \( f_\theta(\mathbf{z}) \) where \( f \) is some feedforward neural network parametrized by \( \theta \). \( f_\theta(\mathbf{z}) \) represents a collection of marginal distributions for each individual attribute in the domain, which can be used to directly answer any k-way marginal query. Alternatively, one can sample directly from \( f_\theta(\mathbf{z}) \) if the goal is generate synthetic tabular data.</p>

<p>Note that the size of \( \mathbf{z} \) can be arbitrarily large, meaning that this generative network approach can theoretically be scaled up to capture any distribution \( P \). Moreover, <a href="https://arxiv.org/abs/2106.07153">[LVW21]</a> show that one can achieve strong performance in practical settings even when \( \mathbf{z} \) is small, making such generative network approaches to scale in terms of both computation and memory. Howevever, as is commonly found in deep learning methods, this optimization problem is nonconvex.</p>

<h3 id="local-consistency">Local Consistency</h3>

<p>Finally, <a href="https://arxiv.org/abs/2106.07153" target="\_blank">GUM</a> and <a href="https://arxiv.org/abs/2109.06153" target="\_blank">APPGM</a> do not search over any space of distributions, but instead impose <em>local consistency</em> constraints on the noisy measurements.  These methods relax Problem \ref{eq1} to optimize over the space of pseudo-marginals, rather than distributions.  The pseudo-marginals are required to be internally consistent, but there is no guarantee that there is a distribution which realizes those pseudo-marginals.  As a result, the solution found by these methods need not be feasible in Problem \ref{eq1}.  Nevertheless, we can attempt to generate synthetic data using heuristics to translate these locally consistent pseudo-marginals into synthetic tabular data.  This approach was used by team DPSyn in both NIST competitions.</p>

<h3 id="summary">Summary</h3>

<p>A qualitative comparison between the discussed methods is given in the table below.<sup id="fnref:7"><a class="footnote" href="https://differentialprivacy.org/feed.xml#fn:7" rel="footnote">5</a></sup></p>

<blockquote>
  <p><strong>Remark 3</strong>: Among the alternatives discussed here, only Direct and PGM can be expected to solve Problem \ref{eq1}.    The alternatives fail to solve Problem \ref{eq1} in general, either from non-convexity, or from introducing spurious distributions to the search space.  This distinguishing feature of PGM comes at a cost: the complexity can be much higher than the alternatives, and in the worst-case, will not be feasible to run.  In such cases, one of the approximations must be used instead.</p>
</blockquote>

<table>
  <tbody>
    <tr>
      <td> </td>
      <td><strong>Direct</strong></td>
      <td><strong>PGM</strong></td>
      <td><strong>Relaxed Tabular</strong></td>
      <td><strong>Generative Networks</strong></td>
      <td><strong>Local Consistency</strong></td>
    </tr>
    <tr>
      <td>Search space includes optimum</td>
      <td><span style="color: green;">Yes</span></td>
      <td><span style="color: green;">Yes</span></td>
      <td><span style="color: green;">Yes</span></td>
      <td><span style="color: green;">Yes</span></td>
      <td><span style="color: green;">Yes</span></td>
    </tr>
    <tr>
      <td>Search space excludes spurious distributions</td>
      <td><span style="color: green;">Yes</span></td>
      <td><span style="color: green;">Yes</span></td>
      <td><span style="color: red;">No</span></td>
      <td><span style="color: green;">Yes</span></td>
      <td><span style="color: red;">No</span></td>
    </tr>
    <tr>
      <td>Convexity preserving</td>
      <td><span style="color: green;">Yes</span></td>
      <td><span style="color: green;">Yes</span></td>
      <td><span style="color: red;">No</span></td>
      <td><span style="color: red;">No</span></td>
      <td><span style="color: green;">Yes</span></td>
    </tr>
    <tr>
      <td>Solves Problem \ref{eq1}</td>
      <td><span style="color: green;">Yes</span></td>
      <td><span style="color: green;">Yes</span></td>
      <td><span style="color: red;">No</span></td>
      <td><span style="color: red;">No</span></td>
      <td><span style="color: red;">No</span></td>
    </tr>
    <tr>
      <td>Factors influencing scalability</td>
      <td><span style="color: red;">Size of Entire Domain</span></td>
      <td><span style="color: orange;">Size of Junction Tree</span></td>
      <td><span style="color: green;">Size of Largest Marginal</span></td>
      <td><span style="color: green;">Size of Largest Marginal</span></td>
      <td><span style="color: green;">Size of Largest Marginal</span></td>
    </tr>
  </tbody>
</table>

<h1 id="generating-synthetic-data-with-mbi">Generating Synthetic Data with MBI</h1>

<p>Now that we have introduced the techniques underlying the Generate step, we will show how to utilize the implementations in the MBI repository to develop end-to-end mechanisms for differentially private synthetic data.</p>

<h2 id="preparing-noisy-measurements">Preparing Noisy Measurements</h2>

<p>The input to any method for Generate is a collection of noisy measurements.  We show below how to prepare these measurements in a format compatible with the methods for Generate implemented in the MBI repository.  The measurements are represented as a list, where each element of the list is a noisy marginal (represented as a numpy array), along with relevant metadata including the attributes in the marginal and the amount of noise used to answer it.  In the code snippet below, the selected marginals are hard-coded, but in general this list can be modified to tailor the synthetic data towards a different set of marginals.</p>

<figure class="highlight"><pre><code class="language-python"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">sparse</span>
<span class="kn">from</span> <span class="nn">mbi</span> <span class="kn">import</span> <span class="n">Dataset</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">Dataset</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="s">'adult.csv'</span><span class="p">,</span> <span class="s">'adult-domain.json'</span><span class="p">)</span>

<span class="c1"># SELECT the marginals we'd like to measure
</span><span class="n">marginals</span> <span class="o">=</span> <span class="p">[(</span><span class="s">'marital-status'</span><span class="p">,</span> <span class="s">'sex'</span><span class="p">),</span>
             <span class="p">(</span><span class="s">'education-num'</span><span class="p">,</span> <span class="s">'race'</span><span class="p">),</span>
             <span class="p">(</span><span class="s">'sex'</span><span class="p">,</span> <span class="s">'hours-per-week'</span><span class="p">),</span>
             <span class="p">(</span><span class="s">'workclass'</span><span class="p">,),</span>
             <span class="p">(</span><span class="s">'marital-status'</span><span class="p">,</span> <span class="s">'occupation'</span><span class="p">,</span> <span class="s">'income&gt;50K'</span><span class="p">)]</span>

<span class="c1"># MEASURE the marginals and log the noisy answers
</span><span class="n">sigma</span> <span class="o">=</span> <span class="mi">50</span> 
<span class="n">measurements</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">M</span> <span class="ow">in</span> <span class="n">marginals</span><span class="p">:</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">project</span><span class="p">(</span><span class="n">M</span><span class="p">).</span><span class="n">datavector</span><span class="p">()</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">I</span> <span class="o">=</span> <span class="n">sparse</span><span class="p">.</span><span class="n">eye</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">size</span><span class="p">)</span>
    <span class="n">measurements</span><span class="p">.</span><span class="n">append</span><span class="p">(</span> <span class="p">(</span><span class="n">I</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span> <span class="p">)</span></code></pre></figure>

<p>The above code snippet is a 5-fold composition of Gaussian mechanisms with \( \sigma = 50 \), and hence the entire mechanism is \( \frac{5}{2 \sigma^2} = \frac{1}{1000} \)-zCDP.</p>

<h2 id="generating-synthetic-data-from-measurements">Generating Synthetic Data from Measurements</h2>

<p>Given measurements represented in the format above, we can readily generate synthetic data using one of several methods.  For example, the code snippet below generates synthetic data that approximately matches the noisy measurements:</p>

<figure class="highlight"><pre><code class="language-python"><span class="kn">from</span> <span class="nn">mbi</span> <span class="kn">import</span> <span class="n">FactoredInference</span> <span class="c1"># PGM
</span><span class="kn">from</span> <span class="nn">mbi</span> <span class="kn">import</span> <span class="n">MixtureInference</span>  <span class="c1"># Relaxed Tabular + Softmax
</span><span class="kn">from</span> <span class="nn">mbi</span> <span class="kn">import</span> <span class="n">LocalInference</span>    <span class="c1"># Local Consistency
</span><span class="kn">from</span> <span class="nn">mbi</span> <span class="kn">import</span> <span class="n">PublicInference</span>   <span class="c1"># Not Discussed
</span>
<span class="c1"># GENERATE synthetic data using PGM 
</span><span class="n">engine</span> <span class="o">=</span> <span class="n">FactoredInference</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">domain</span><span class="p">,</span> <span class="n">iters</span><span class="o">=</span><span class="mi">2500</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">engine</span><span class="p">.</span><span class="n">estimate</span><span class="p">(</span><span class="n">measurements</span><span class="p">)</span>
<span class="n">synth</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">synthetic_data</span><span class="p">()</span></code></pre></figure>

<p>To generate synthetic data, we have to simply instantiate one of the inference engines imported.  In the code snippet above, we use the FactoredInference engine, which corresponds to the PGM method.  The other inference engines share the same interface, and can be used instead if desired.</p>

<blockquote>
  <p><strong>Remark 4</strong>: By utilizing the inference engines implemented in MBI, end-to-end synthetic data mechanisms can be written with remarkably little code.  This simple example required less than 25 lines of code, and <a href="https://github.com/ryan112358/private-pgm/tree/master/mechanisms" target="\_blank">more complex mechanisms</a> can usually be written in a single file with less than 200 lines of code.  As a result, future research can focus on the measurement selection subproblem, and new ideas can more rapidly be evaluated and iterated on.</p>
</blockquote>

<p>We evaluated the quality of the synthetic data generated by measuring the error of the measured marginals.  Interestingly, the synthetic data has lower error than the noisy marginals, with reductions in error up to 30% for the larger marginals, and around 3% for the smaller ones.</p>

<p><img alt="" src="https://differentialprivacy.org/images/smr1.png"/></p>

<blockquote>
  <p><strong>Remark 5:</strong> It is not surprising that the synthetic data enjoys lower error than the noisy marginals.  Problem \ref{eq1} can be seen as a <em>projection problem</em>, and there is substantial theoretical <a href="https://arxiv.org/abs/1212.0297" target="\_blank">[NTZ12]</a> and empirical [<a href="https://dl.acm.org/doi/abs/10.1145/2783258.2783366" target="\_blank">LWK15</a>, <a href="https://systems.cs.columbia.edu/private-systems-class/papers/Abowd2019Census.pdf" target="\_blank">AAGK+19</a>] evidence that solving this problem reduces error.  Intuitively, the benefit arises due to the inconsistencies in the noisy observations that are resolved through the optimization procedure.</p>
</blockquote>

<p>We can also use the synthetic data to estimate marginals we didn’t measure with the Gaussian mechanism.  These estimates may or may not be accurate, it depends on the data and the marginal being estimated.  For example, the error on the (sex, income&gt;50K) marginal is around 0.02, while the error on the (education-num, occupation) marginal is about 0.5.</p>

<p><img alt="" src="https://differentialprivacy.org/images/smr2.png"/></p>
<blockquote>
  <p><strong>Remark 6:</strong> The fact that the synthetic data is not accurate for some marginals is not a limitation of the method used for Generate, but rather an artifact of what marginals were selected.  Thus, it is clear that selecting the right marginals to measure plays a crucial role in the quality of the synthetic data. This is an important open problem that will be the topic of a future blog post.</p>
</blockquote>

<h1 id="coming-up-next">Coming up Next</h1>

<p>In this blog post, we focused on the <strong>Generate</strong> step of the select-measure-generate paradigm.  For the next blog post in this series, we will focus on state-of-the-art approaches to the <strong>Select</strong> sub-problem.  If you have any comments, questions, or remarks, please feel free to share them in the comments section below.  If you would like to try generating synthetic data with MBI, check out this <a href="https://colab.research.google.com/drive/1c8gT5m_GWfQoa_mx8eXh4sPD48Y0z3ML?usp=sharing">jupyter notebook</a> on Google Colab!</p>

<hr/>
<div class="footnotes">
  <ol>
    <li id="fn:0">
      <p>The Generate step is a post-processing of already privatized noisy marginals, and therefore the privacy analysis only needs to reason about the first two steps. <a class="reversefootnote" href="https://differentialprivacy.org/feed.xml#fnref:0">↩</a></p>
    </li>
    <li id="fn:1">
      <p>Here we assume that \( \mathcal{M} \) is a mechanism with a discrete output space.  In practice, this is always the case because any mechanism implemented on a finite computer must have a discrete output space.  For continuous output spaces, interpret the objective function as a log density rather than a log probability. <a class="reversefootnote" href="https://differentialprivacy.org/feed.xml#fnref:1">↩</a></p>
    </li>
    <li id="fn:6">
      <p>For example, this worst-case behavior is realized if <strong>all</strong> 2-way marginals are measured.  While this can be seen as a limitation of PGM, <a href="http://people.seas.harvard.edu/~salil/research/synthetic-Feb2010.pdf">it is known</a> that generating synthetic data that preserves all 2-way marginals is computationally hard in the worst-case. <a class="reversefootnote" href="https://differentialprivacy.org/feed.xml#fnref:6">↩</a></p>
    </li>
    <li id="fn:9">
      <p>This idea was refined into <a href="https://arxiv.org/abs/2106.07153" target="\_blank">RAP<sup>softmax</sup></a> in follow-up-work, which overcomes the latter issue, but does not resolve the non-convexity issue. <a class="reversefootnote" href="https://differentialprivacy.org/feed.xml#fnref:9">↩</a></p>
    </li>
    <li id="fn:7">
      <p>These approximations were all developed concurrently, and systematic empirical comparisons between them (and PGM) have not been done to date.  Some experimental comparisons can be found in <a href="https://arxiv.org/abs/2106.07153" target="\_blank">[LVW21]</a> and <a href="https://arxiv.org/abs/2109.06153">[MPSM21]</a>. <a class="reversefootnote" href="https://differentialprivacy.org/feed.xml#fnref:7">↩</a></p>
    </li>
  </ol>
</div></div>
    </summary>
    <updated>2022-01-27T17:00:00Z</updated>
    <published>2022-01-27T17:00:00Z</published>
    <author>
      <name>Terrance Liu</name>
    </author>
    <source>
      <id>https://differentialprivacy.org</id>
      <link href="https://differentialprivacy.org" rel="alternate" type="text/html"/>
      <link href="https://differentialprivacy.org/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Website for the differential privacy research community</subtitle>
      <title>Differential Privacy</title>
      <updated>2022-02-07T22:48:55Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2022/01/27/research-fellow-postdoc-at-national-university-of-singapore-apply-by-july-31-2022/</id>
    <link href="https://cstheory-jobs.org/2022/01/27/research-fellow-postdoc-at-national-university-of-singapore-apply-by-july-31-2022/" rel="alternate" type="text/html"/>
    <title>Research Fellow (Postdoc) at National University of Singapore (apply by July 31, 2022)</title>
    <summary>I (Prashant Nalini Vasudevan) have a postdoctoral position available at the Department of Computer Science at NUS. I am looking for someone who works on the foundations of cryptography, information-theoretic cryptography, and/or related areas of theoretical computer science. See the website below for details, and feel free to email me if you have questions. Website: […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I (Prashant Nalini Vasudevan) have a postdoctoral position available at the Department of Computer Science at NUS. I am looking for someone who works on the foundations of cryptography, information-theoretic cryptography, and/or related areas of theoretical computer science. See the website below for details, and feel free to email me if you have questions.</p>
<p>Website: <a href="https://careers.nus.edu.sg/NUS/job/Kent-Ridge-Research-Fellow%2C-Theory-of-Cryptography-Kent/7003544/">https://careers.nus.edu.sg/NUS/job/Kent-Ridge-Research-Fellow%2C-Theory-of-Cryptography-Kent/7003544/</a><br/>
Email: prashant@comp.nus.edu.sg</p></div>
    </content>
    <updated>2022-01-27T09:35:49Z</updated>
    <published>2022-01-27T09:35:49Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2022-02-08T13:37:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://thmatters.wordpress.com/?p=1348</id>
    <link href="https://thmatters.wordpress.com/2022/01/26/theory-fest22-call-for-workshop-proposals/" rel="alternate" type="text/html"/>
    <title>STOC’22: Call for Workshop Proposals</title>
    <summary>The Theory Fest workshops committee is soliciting proposals for workshops. Workshops will be held during the STOC conference week, June 20-24, 2022. The (updated) deadline for submitting proposals is Feb 15, 2022. Details on how to submit a proposal can be found at http://acm-stoc.org/stoc2022/callforworkshops.html.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Theory Fest workshops committee is soliciting proposals for workshops. Workshops will be held during the STOC conference week, June 20-24, 2022. The (updated) deadline for submitting proposals is <strong>Feb 15, 2022</strong>. Details on how to submit a proposal can be found at <a href="http://acm-stoc.org/stoc2022/callforworkshops.html" rel="nofollow">http://acm-stoc.org/stoc2022/callforworkshops.html</a>.</p></div>
    </content>
    <updated>2022-01-26T23:43:17Z</updated>
    <published>2022-01-26T23:43:17Z</published>
    <category term="Deadlines"/>
    <author>
      <name>shuchic</name>
    </author>
    <source>
      <id>https://thmatters.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://thmatters.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://thmatters.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://thmatters.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://thmatters.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theory Matters</title>
      <updated>2022-02-08T13:37:44Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-8274979502456032700</id>
    <link href="http://blog.computationalcomplexity.org/feeds/8274979502456032700/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/01/a-failure-to-communicate.html#comment-form" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/8274979502456032700" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/8274979502456032700" rel="self" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/01/a-failure-to-communicate.html" rel="alternate" type="text/html"/>
    <title>A Failure to Communicate</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The screenwriter Aaron Sorkin wrote an <a href="https://ew.com/movies/aaron-sorkin-column-biopics-being-the-ricardos/">article</a> on prioritizing "Truth over Accuracy". He tells stories from his movies The Social Network and Being the Ricardos, of where he moves away from accuracy to get to the truth of a situation.</p><blockquote><p>My friend and teacher, the late William Goldman, said of his Academy Award-winning screenplay for All the President's Men, "If I'm telling the true story of the fall of the President of the United States, the last thing I'm going to do is make anything up." I understand what he meant in context, but the fact is, as soon as he wrote "FADE IN," he'd committed to making things up. People don't speak in dialogue, and their lives don't play out in a series of scenes that form a narrative. Dramatists do that. They prioritize truth over accuracy. Paintings over photographs.</p></blockquote><p>As scientists we focus on accuracy, as we should in our scientific publications. However being fully accurate can distract from the "truth", the underlying message you want to say, particularly in the title, abstract and introduction of our papers </p><p>Even more so when we promote our research to the public. A science writer once <a href="https://blog.computationalcomplexity.org/2004/04/view-of-science-writer.html">lamented to me</a> that scientists would focus too much on the full accuracy of the science and the names behind it, even though neither serves the reader well.</p><p>Reminds me of the recent Netflix movie <a href="https://www.netflix.com/title/81252357">Don't Look Up</a> satirizes scientists trying to communicate an end-of-the-world event to an untrusting society. I wish it was a better movie but still worth watching just to see Leo DiCaprio and Jennifer Lawrence play scientists frustrated with their ability to communicate a true existential crisis to the government and the general public. </p><p>So how should we as scientists try to frame our messaging to get people onboard, particularly when we say things they don't want to hear? Most importantly, how do scientists regain trust in a world where trust is in short supply. Perhaps we should paint more and photograph less.</p></div>
    </content>
    <updated>2022-01-26T17:49:00Z</updated>
    <published>2022-01-26T17:49:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="http://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2022-02-07T23:18:36Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://rjlipton.wpcomstaging.com/?p=19580</id>
    <link href="https://rjlipton.wpcomstaging.com/2022/01/26/a-list-of-most-theory-blogs/" rel="alternate" type="text/html"/>
    <title>A List of Most Theory Blogs</title>
    <summary>The list doesn’t destroy culture; it creates it. Wherever you look in cultural history, you will find lists—Umberto Eco Luca Trevisan, Stefan Schmid, James Lee, Scott Aaronson, Michael Mitzenmacher, Omer Reingold, Lance Fortnow, David Eppstein are some of the top bloggers in theory. That is not “in theory” but “in the area of theory”. This […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<i>The list doesn’t destroy culture; it creates it. Wherever you look in cultural history, you will find lists—Umberto Eco</i></p>
<p>
Luca Trevisan, Stefan Schmid, James Lee, Scott Aaronson, Michael Mitzenmacher, Omer Reingold, Lance Fortnow, David Eppstein are some of the top bloggers in theory. That is not “in theory” but “in the area of theory”. </p>
<p>
<a href="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/01/all.png?ssl=1"><img alt="" class="aligncenter size-full wp-image-19583" height="424" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/01/all.png?resize=600%2C424&amp;ssl=1" width="600"/></a></p>
<p>
This led us to spend some time while watching NFL football to put together a list of theory blogs for computer science. We insist that they are reasonably current. Our rule is: They must have some posts in 2021.</p>
<p>
 <span id="more-19580"/></p>
<p><b> Our List </b></p>
<p/><p>
The next is the list:</p>
<ol>
<li> <a href="https://11011110.github.io/blog/">11011110</a>
</li><li> <a href="http://aaronsadventures.blogspot.com">Adventures in Computation</a>
</li><li> <a href="https://liorpachter.wordpress.com">Bits of DNA</a>
</li><li> <a href="https://blog.simons.berkeley.edu">Calvin Cafe: The Simons Institute</a>
</li><li> <a href="https://gilkalai.wordpress.com">Combinatorics and more</a>
</li><li> <a href="https://blog.computationalcomplexity.org">Computational Complexity</a>
</li><li> <a href="https://scholar.harvard.edu/stavins/blog-posts-economic-view-environment">Constructive Economics</a> <a href="https://math.williams.edu/morgan/">Frank Morgan</a>
</li><li> <a href="https://rjlipton.wpcomstaging.com">Godel’s Lost Letter and P=NP</a>
</li><li> <a href="https://ai.googleblog.com">Google Research</a>
</li><li> <a href="https://gowers.wordpress.com">Gowers</a>
</li><li> <a href="https://igorpak.wordpress.com">Igor Pak’s</a>
</li><li> <a href="https://lucatrevisan.wordpress.com">in theory</a>
</li><li> <a href="http://jdh.hamkins.org">Joel David Hamkins</a>
</li><li> <a href="https://www.benkdpearce.com/blog/tag/PhD">kd-PhD</a>
</li><li> <a href="https://jeremykun.com">Math <img alt="{\cap}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ccap%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> Programming</a>
</li><li> <a href="https://mathprofessorquotes.com">Math Professor Quotes</a>
</li><li> <a href="http://math.andrej.com">Mathematics and Computation</a>
</li><li> <a href="https://micromath.wordpress.com">Mathematics under the Microscope</a>
</li><li> <a href="https://www.math.columbia.edu/~woit/wordpress/?p=7479">Mathematics without Apologies, by Michael Harris</a>
</li><li> <a href="http://mybiasedcoin.blogspot.com">My Biased Coin</a>
</li><li> <a href="https://www.wisdom.weizmann.ac.il/~oded/my-choice.html">My Choices (Oded Goldreich)</a>
</li><li> <a href="https://www.offconvex.org">Off the convex path</a>
</li><li> <a href="https://cameroncounts.wordpress.com">Peter Cameron</a>
</li><li> <a href="http://processalgebra.blogspot.com">Process Algebra Diary</a>
</li><li> <a href="https://daveagp.wordpress.com/category/math/">QED and NOM</a>
</li><li> <a href="https://www.scottaaronson.com/blog/">Shtetl-Optimized</a>
</li><li> <a href="https://adamsheffer.wordpress.com">Some Plane Truths</a>
</li><li> <a href="https://blog.tanyakhovanova.com">Tanya Khovanova’s Math</a>
</li><li> <a href="http://grigory.us/blog/">The Big Data Theory</a>
</li><li> <a href="http://blog.geomblog.org">The Geomblog</a>
</li><li> <a href="https://polymathprojects.org">The polymath blog</a>
</li><li> <a href="http://dmatheorynet.blogspot.com">Theory Announcements</a>
</li><li> <a href="https://thmatters.wordpress.com/tcs-blogs/">Theory Matters</a>
</li><li> <a href="https://tjoresearchnotes.wordpress.com">Tobias Osborne’s research notes</a>
</li><li> <a href="https://agtb.wordpress.com">Turing’s Invisible Hand</a>
</li><li> <a href="https://terrytao.wordpress.com">What’s new</a>
</li><li> <a href="https://windowsontheory.org">Windows On Theory</a>
</li><li> <a href="https://xorshammer.com">XOR’s Hammer</a>
</li></ol>
<p>
</p><p><b> Open Problems </b></p>
<p>We would like to get some feedback. First any typos in the above? Second any we should have included? Third, any we should have left out—they do not satisfy our 2021 rule?</p>
<p/></div>
    </content>
    <updated>2022-01-26T13:17:40Z</updated>
    <published>2022-01-26T13:17:40Z</published>
    <category term="History"/>
    <category term="Ideas"/>
    <category term="People"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wpcomstaging.com</id>
      <logo>https://s0.wp.com/i/webclip.png</logo>
      <link href="https://rjlipton.wpcomstaging.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wpcomstaging.com" rel="alternate" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel's Lost Letter and P=NP</title>
      <updated>2022-02-08T13:37:32Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://scottaaronson.blog/?p=6244</id>
    <link href="https://scottaaronson.blog/?p=6244" rel="alternate" type="text/html"/>
    <link href="https://scottaaronson.blog/?p=6244#comments" rel="replies" type="text/html"/>
    <link href="https://scottaaronson.blog/?feed=atom&amp;p=6244" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Why Quantum Mechanics?</title>
    <summary xml:lang="en-US">In the past few months, I’ve twice injured the same ankle while playing with my kids. This, perhaps combined with covid, led me to several indisputable realizations: I am mortal. Despite my self-conception as a nerdy little kid awaiting the serious people’s approval, I am now firmly middle-aged. By my age, Einstein had completed general […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>In the past few months, I’ve twice injured the same ankle while playing with my kids.  This, perhaps combined with covid, led me to several indisputable realizations:</p>



<ol><li>I am mortal.</li><li>Despite my self-conception as a nerdy little kid awaiting the serious people’s approval, I am now firmly middle-aged.  By my age, Einstein had completed general relativity, Turing had founded CS, won WWII, <em>and</em> proposed the Turing Test, and Galois, Ramanujan, and Ramsey had been dead for years.</li><li>Thus, whatever I wanted to accomplish in my intellectual life, I should probably get started on it <em>now</em>.</li></ol>



<p>Hence today’s post.  I’m feeling a strong compulsion to write an essay, or possibly even a book, surveying and critically evaluating a century of ideas about the following question:</p>



<p><strong>Q: Why should the universe have been quantum-mechanical?</strong></p>



<p>If you want, you can divide Q into two subquestions:</p>



<p><strong>Q1: Why didn’t God just make the universe classical and be done with it?  What would’ve been wrong with <em>that</em> choice?</strong></p>



<p><strong>Q2: Assuming classical physics wasn’t good enough for whatever reason, why this specific alternative?  Why the complex-valued amplitudes?  Why unitary transformations?  Why the Born rule?  Why the tensor product?</strong></p>



<p>Despite its greater specificity, Q2 is ironically the question that I feel we have a better handle on.  I could spend half a semester teaching theorems that admittedly don’t <em>answer</em> Q2, as satisfyingly as Einstein answered the question “why the Lorentz transformations?,” but that at least render this particular set of mathematical choices (the 2-norm, the Born Rule, complex numbers, etc.) orders-of-magnitude less surprising than one might’ve thought they were <em>a priori</em>.  Q1 therefore stands, to me at least, as the more mysterious of the two questions.</p>



<p>So, I want to write something about the space of credible answers to Q, and especially Q1, that humans can currently conceive.  I want to do this for my own sake as much as for others’.  I want to do it because I regard Q as one of the biggest questions ever asked, for which it seems plausible to me that there’s simply an <em>answer</em> that most experts would accept as valid once they saw it, but for which no such answer is known.  And also because, besides having spent 25 years working in quantum information, I have the following qualifications for the job:</p>



<ul><li><span style="color: initial;">I don’t dismiss either Q1 </span><em style="color: initial;">or</em><span style="color: initial;"> Q2 as silly; and</span></li><li>crucially, I don’t think I already know the answers, and merely need better arguments to justify them.  I’m genuinely uncertain and confused.</li></ul>



<p><strong>The purpose of this post is to invite you to share your own answers to Q in the comments section.</strong>  Before I embark on my survey project, I’d better know if there are promising ideas that I’ve missed, and this blog seems like as good a place as any to crowdsource the job.</p>



<p>Any answer is welcome, no matter how wild or speculative, <em>so long as it honestly grapples with the actual nature of QM</em>.  To illustrate, nothing along the lines of “the universe is quantum because it needs to be holistic, interconnected, full of surprises, etc. etc.” will cut it, since such answers leave utterly unexplained why the world wasn’t simply endowed with those properties directly, rather than specifically via <em>generalizing the rules of probability to allow interference and noncommuting observables</em>.</p>



<p>Relatedly, whatever “design goal” you propose for the laws of physics, if the goal is satisfied by QM, but satisfied <em>even better</em> by theories that provide <em>even more</em> power than QM does—for instance, superluminal signalling, or violations of <a href="https://en.wikipedia.org/wiki/Tsirelson%27s_bound">Tsirelson’s bound</a>, or the efficient solution of NP-complete problems—then your explanation is out.  This is a remarkably strong constraint.</p>



<p>Oh, needless to say, don’t try my patience with anything about the uncertainty principle being due to floating-point errors or rendering bugs, or anything else that relies on a travesty of QM lifted from a popular article or meme! <img alt="&#x1F642;" class="wp-smiley" src="https://s.w.org/images/core/emoji/13.1.0/72x72/1f642.png" style="height: 1em;"/></p>



<p>OK, maybe four more comments to enable a more productive discussion, before I shut up and turn things over to you:</p>



<ol><li>I’m aware, of course, of the radical uncertainty about what form an answer to Q should even take.  Am I asking you to psychoanalyze the will of God in creating the universe?  Or, what perhaps amounts to the same thing, am I asking for the design objectives of the giant computer simulation that we’re living in?  (As in, “I’m 100% fine with living inside a Matrix … I just want to understand why it’s a <em>unitary</em> matrix!”)  Am I instead asking for an anthropic explanation, showing why <em>of course</em> QM would be needed if you wanted life or consciousness like ours?  Am I “merely” asking for simpler or more intuitive physical principles from which QM is to be derived as a consequence?  Am I asking why QM is the “most elegant choice” in some space of mathematical options … even to the point where, with hindsight, a 19th-century mathematician or physicist could’ve been convinced that <em>of course</em> this must be part of Nature’s plan?  Am I asking for something else entirely?  <strong>You get to decide</strong>!<strong>  Should you take up my challenge, this is both your privilege and your terrifying burden.</strong><br/></li><li>I’m aware, of course, of the dizzying array of central physical phenomena that rely on QM for their ultimate explanation.  These phenomena range from the stability of matter itself, which depends on the Pauli exclusion principle; to the nuclear fusion that powers the sun, which depends on a quantum tunneling effect; to the discrete energy levels of electrons (and hence, the combinatorial nature of chemistry), which relies on electrons being waves of probability amplitude that can only circle nuclei an integer number of times if their crests are to meet their troughs.  Important as they are, though, I don’t regard any of these phenomena as satisfying answers to Q in themselves.  The reason is simply that, in each case, it would seem like child’s-play to contrive some classical mechanism to produce the same effect, were that the goal.  QM just seems far too grand to have been the answer to <em>these</em> questions!  An exponentially larger state space for all of reality, <em>plus</em> the end of Newtonian determinism, just to overcome the technical problem that accelerating charges radiate energy in classical electrodynamics, thereby rendering atoms unstable?  It reminds me of the <em>Simpsons</em> episode where Homer <a href="https://www.youtube.com/watch?v=GZ6cCaEy5eo">uses a teleportation machine</a> to get a beer from the fridge without needing to get up off the couch.<br/></li><li>I’m aware of <a href="https://en.wikipedia.org/wiki/Gleason%27s_theorem">Gleason’s theorem</a>, and of the <a href="https://arxiv.org/abs/quant-ph/0401062">specialness</a> of the 1-norm and 2-norm in linear algebra, and of the <a href="https://scottaaronson.blog/?p=4021">arguments for complex amplitudes</a> as opposed to reals or quaternions, and of the beautiful work of <a href="https://arxiv.org/abs/quant-ph/0101012">Lucien Hardy</a> and of <a href="https://arxiv.org/abs/1506.00398">Chiribella et al.</a> and others on axiomatic derivations of quantum theory.  As some of you might remember, I even discussed much of this material in <em><a href="https://www.amazon.com/Quantum-Computing-since-Democritus-Aaronson/dp/0521199565">Quantum Computing Since Democritus</a></em>!  There’s a <em>huge</em> amount to say about these fascinating justifications for the rules of QM, and I hope to say some of it in my planned survey!  For now, I’ll simply remark that every axiomatic reconstruction of QM that I’ve seen, impressive though it was, has relied on one or more axioms that struck me as <em>weird</em>, in the sense that I’d have little trouble dismissing the axioms as totally implausible and unmotivated if I hadn’t already known (from QM, of course) that they were true.  The axiomatic reconstructions <em>do</em> help me somewhat with Q2, but little if at all with Q1.<br/></li><li>To keep the discussion focused, in this post I’d like to exclude answers along the lines of “but what if QM is merely an approximation to something else?,” to say nothing of “a century of evidence for QM was all just a massive illusion!  LOCAL HIDDEN VARIABLES FOR THE WIN!!!”  We can have those debates another day—God knows that, here on <em>Shtetl-Optimized</em>, we <a href="https://scottaaronson.blog/?p=6215">have</a> and we will.  Here I’m asking instead: imagine that, as fantastical as it sounds, QM were not only exactly true, but (along with relativity, thermodynamics, evolution, and the tastiness of chocolate) one of the profoundest truths our sorry species had ever discovered.  Why should I have <em>expected</em> that truth all along?  What possible reasons to expect it have I missed?</li></ol>



<p/></div>
    </content>
    <updated>2022-01-25T07:00:45Z</updated>
    <published>2022-01-25T07:00:45Z</published>
    <category scheme="https://scottaaronson.blog" term="Embarrassing Myself"/>
    <category scheme="https://scottaaronson.blog" term="Metaphysical Spouting"/>
    <category scheme="https://scottaaronson.blog" term="Quantum"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://scottaaronson.blog/?feed=atom</id>
      <icon>https://scottaaronson.blog/wp-content/uploads/2021/10/cropped-Jacket-32x32.gif</icon>
      <link href="https://scottaaronson.blog" rel="alternate" type="text/html"/>
      <link href="https://scottaaronson.blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2022-02-07T01:34:21Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2022/01/25/chair-of-the-department-of-computer-science-at-university-of-victoria-apply-by-march-8-2022/</id>
    <link href="https://cstheory-jobs.org/2022/01/25/chair-of-the-department-of-computer-science-at-university-of-victoria-apply-by-march-8-2022/" rel="alternate" type="text/html"/>
    <title>Chair of the Department of Computer Science at University of Victoria (apply by March 8, 2022)</title>
    <summary>We invite applications for the position of Chair of the Department of Computer Science as a tenured Associate Professor or tenured Professor effective on or before September 1, 2022. Candidates should have a Ph.D. in the field of Computer Science. Website: https://academicjobsonline.org/ajo/jobs/21010 Email: csc-chair-search@uvic.ca</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>We invite applications for the position of Chair of the Department of Computer Science as a tenured Associate Professor or tenured Professor effective on or before September 1, 2022. Candidates should have a Ph.D. in the field of Computer Science.</p>
<p>Website: <a href="https://academicjobsonline.org/ajo/jobs/21010">https://academicjobsonline.org/ajo/jobs/21010</a><br/>
Email: csc-chair-search@uvic.ca</p></div>
    </content>
    <updated>2022-01-25T06:16:35Z</updated>
    <published>2022-01-25T06:16:35Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2022-02-08T13:37:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2022/01/25/stoc-2022-workshops-call-for-proposals/</id>
    <link href="https://cstheory-events.org/2022/01/25/stoc-2022-workshops-call-for-proposals/" rel="alternate" type="text/html"/>
    <title>STOC 2022 Workshops: Call for Proposals</title>
    <summary>June 20-24, 2022 Rome, Italy http://acm-stoc.org/stoc2022/callforworkshops.html Submission deadline: January 15, 2022 STOC/TheoryFest 2022 will hold workshops during the conference week, June 20–24, 2022. We invite groups of interested researchers to submit workshop proposals. The due date for proposals is February 15, 2022. Submission instructions can be found on the STOC’22 website.</summary>
    <updated>2022-01-25T00:03:12Z</updated>
    <published>2022-01-25T00:03:12Z</published>
    <category term="conference"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2022-02-08T13:38:21Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://rjlipton.wpcomstaging.com/?p=19570</id>
    <link href="https://rjlipton.wpcomstaging.com/2022/01/24/cheating-in-chess/" rel="alternate" type="text/html"/>
    <title>Cheating In Chess</title>
    <summary>Colonel Stok: Do you play chess? Harry Palmer: Yes, but I prefer a game with a better chance of cheating.—Funeral in Berlin Ken Regan is well known to us all, and is the co-author of this blog. He is in the Department of Computer Science and Engineering, University at Buffalo (SUNY)–as part of the theory […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<i>Colonel Stok: Do you play chess? <br/>
 Harry Palmer: Yes, but I prefer a game with a better chance of cheating.—<a href="https://www.google.com/search?q=Funeral+in+Berlin1966&amp;source=hp&amp;ei=9IHtYdaRB6ChptQPha-1wAE&amp;iflsig=ALs-wAMAAAAAYe2QBI_BvUjvZLRDMJfKiHAGuQzsBNNU&amp;ved=0ahUKEwjW27yhpcj1AhWgkIkEHYVXDRgQ4dUDCAw&amp;uact=5&amp;oq=Funeral+in+Berlin1966&amp;gs_lcp=Cgdnd3Mtd2l6EAMyBAguEA0yBggAEA0QHjIGCAAQDRAeMgYIABANEB4yBggAEA0QHjIGCAAQDRAeMgYIABANEB4yBggAEA0QHjIGCAAQDRAeMgYIABANEB5QAFgAYOIDaABwAHgAgAFUiAFUkgEBMZgBAKABAqABAQ&amp;sclient=gws-wiz">Funeral in Berlin</a></i></p>
<p>
Ken Regan is well known to us all, and is the co-author of this blog. He is in the Department of Computer Science and Engineering, University at Buffalo (SUNY)–as part of the theory group. He is also an International Master from the World Chess Federation (FIDE).<br/>
<a href="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/01/kr.png?ssl=1"><img alt="" class="aligncenter size-full wp-image-19573" height="643" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/01/kr.png?resize=600%2C643&amp;ssl=1" width="600"/></a></p>
<p>
<span id="more-19570"/></p>
<p>
</p><p><b> Ken’s Trip </b></p>
<p/><p>
Ken has used his ability in theory with his expertise in chess to study how to detect cheating in chess. Unfortunately people do currently cheat in chess, and so detecting them is an important problem for FIDE. Ken has just spent some time in Bologna, Italy at the International Chess Federation Fair Play Commission’s meeting. The group’s goal is:  There is an increasing demand for fair play experts during chess events, and we want to provide the organizers with professionals who know how to collect evidence, apply law, use the state-of-the-art detection tools. And do it in the way that players are protected and public perception of how important the fair play is improved. </p>
<p>
Ken is on the way back from Italy and soon will explain in detail what is the latest about cheating in chess.</p>
<p>
</p><p><b> Cheating In The Past </b></p>
<p/><p>
In the past cheating at chess started with machines like the famous <a href="https://en.wikipedia.org/wiki/Mechanical_Turk">Turk</a> of 1770. This was a machine that claimed to play chess without human help. Even just playing legal moves would have been impressive, but the Turk played strong chess.</p>
<p>
<a href="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/01/turk.jpg?ssl=1"><img alt="" class="aligncenter size-full wp-image-19574" height="462" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/01/turk.jpg?resize=600%2C462&amp;ssl=1" width="600"/></a></p>
<p>
The secret to the Turk is it used a hidden human chess player to make its moves. The player was hidden inside the machine. The audience was allowed to examine the machine by opening and looking at parts of the machine. The audience member could only examine one part of the Turk at a time. The trick was that the player could move from one part of the Turk to another. At each time some parts of the Turk would be visible, but some part stayed invisible. This meant the player could move from one part to another of the Turk. This fooled the audience and made it seem “magical” that the mechanical system could play chess.</p>
<p>
<a href="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/01/show.png?ssl=1"><img alt="" class="aligncenter size-full wp-image-19577" height="168" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/01/show.png?resize=300%2C168&amp;ssl=1" width="300"/></a></p>
<p>
</p><p><b> Cheating Now and in the Future </b></p>
<p/><p>
Cheating at chess became interesting again when computer programs started to play strong chess—<a href="https://en.wikipedia.org/wiki/Cheating_in_chess">cheating</a>. The fundamental insight was that once programs could play master level chess, players could cheat and play at this level. The idea was simple: A player would not look at the board and select the next move. They would instead ask the program what move should they do. They would then use that move.</p>
<p>
Of course a serious issue was how could the player ask a program to make the next move? If the game they were playing was offline, then the player should be able to use their laptop to remotely run the program. If the game was played in some public place, then the player might have to work harder to run the program. But a player could perhaps still do this without being detected. </p>
<p>
 Technology has been used by chess cheaters in several ways. The most common way is to use a chess program while playing chess remotely, such as on the Internet or in correspondence chess. Rather than play the game directly, the cheater simply inputs the moves so far into the program and follows its suggestions, essentially letting the program play for them. Electronic communication with an accomplice during face-to-face competitive chess is a similar type of cheating; the accomplice can either be using a computer program or else simply be a much better player than their associate.  </p>
<p>
</p><p><b> Open Problems </b></p>
<p/><p>
The main open problem is still: How well can cheating be detected? The basic idea is simple: Suppose that the player named Carol plays a game in some tournament. We wish to determine whether Carol played her own moves or whether she used moves of some program. How can we do this? There are several issues that make this hard. </p>
<ol>
<li> Carol may stay on “book” at the beginning. How do we factor this in?
</li><li> Carol may have used a program that is secret. Does this effect the detection?
</li><li> Carol may follow a program for all moves or for some of the moves. Does this make the detection more difficult?
</li><li> Carol may already be a strong player. Suppose she uses the program to play at a stronger level. Is this even more difficult to detect?
</li></ol>
<p>
Ken will update us on the latest views of these and other issues. </p>
<p/></div>
    </content>
    <updated>2022-01-24T17:44:23Z</updated>
    <published>2022-01-24T17:44:23Z</published>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wpcomstaging.com</id>
      <logo>https://s0.wp.com/i/webclip.png</logo>
      <link href="https://rjlipton.wpcomstaging.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wpcomstaging.com" rel="alternate" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel's Lost Letter and P=NP</title>
      <updated>2022-02-08T13:37:32Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-9122075582706163619</id>
    <link href="http://blog.computationalcomplexity.org/feeds/9122075582706163619/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/01/personal-reflections-on-dick-lipton-in.html#comment-form" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/9122075582706163619" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/9122075582706163619" rel="self" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/01/personal-reflections-on-dick-lipton-in.html" rel="alternate" type="text/html"/>
    <title>Personal Reflections on Dick Lipton in honor of his 1000th blog/75th bday.</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p> Is it an irony that Lipton's 1000th post and 75th bday are close together? No. Its a coincidence. People use irony/paradox/coincidence interchangeably. Hearing people make that mistake makes me literally want to strangle them. </p><p>The community celebrated this milestone by having  talks on zoom in Lipton's honor. The  blog post by Ken Regan that announced the event and has a list of speakers is <a href="https://rjlipton.wpcomstaging.com/2022/01/14/happy-1000th-post-and-75th-birthday-dick/">here</a>. The talks were recorded so they should be available soon. YEAH KEN for organizing the event! We may one day be celebrating his 2000th blog post/Xth bday. </p><p>I will celebrate this milestone by writing on how Lipton and his work have inspired and enlightened me. </p><p><br/></p><p>1) My talk at the Lipton zoom-day-of-talks was on the Chandra-Furst-Lipton (1983)  paper (see <a href="http://www.cs.umd.edu/~gasarch/BLOGPAPERS/CFG-multiparty.pdf">here</a>) that sparked my interest in Ramsey Theory, lead to a paper I wrote that improved their upper and lower bounds, and lead to an educational open problem that I posted on this blog, that was answered. There is still more to do.  An expanded version of the slide talk I gave on the zoom-day is <a href="https://www.cs.umd.edu/~gasarch/BLOGPAPERS/liptonbdaytalk.pdf">here</a>. (Their paper also got me interested in Communication complexity.) </p><p>2) I read the De Millo-Lipton-Perlis (1979) paper (see <a href="https://www.cs.umd.edu/~gasarch/BLOGPAPERS/social.pdf">here</a>) my first year in graduate school and found it very enlightening. NOT about program verification, which I did not know much about, but about how mathematics really works.  As an ugrad I was very much into THEOREM-PROOF-THEOREM-PROOF as the basis for truth. This is wrongheaded for two reasons (1) I did not see the value of intuition, and (2) I did not realize that the PROOF is not the END of the story, but the BEGINNING of a process of checking it- many people over time have to check a result. DLP woke me up to point (2) and (to a lesser extend) point (1). A scary thought: most results in math, once published, are never looked at again. So their could be errors in the math literature. However, the important results DO get looked at quite carefully. Even so, I worry that an important result will depend on one that has not been looked at much...Anyway, a link to a  blog post about a symposium about DLP is <a href="https://blog.computationalcomplexity.org/2021/06/i-went-to-debate-about-program-verif.html">here</a>.</p><p>3) The Karp-Lipton theorem is: <i> if SAT has poly sized circuits than PH collapses</i> (see <a href="https://dl.acm.org/doi/10.1145/800141.804678">here</a>), It connects uniform and non-uniform complexity.  This impressed me but also made me thing about IF-THEN statements. In this case something we don't think is true implies something else we don't think is true. So--- do we know something? Yes! The result has been used to get results like </p><p>                                                   If GI is NPC then PH collapses.</p><p>This is evidence that GI is not NPC. </p><p>4) Lipton originally blogged by himself and a blog book came out of that. I reviewed it in <a href="https://www.cs.umd.edu/~gasarch/bookrev/41-4.pdf">this</a> column. Later it became the  Lipton-Regan blog, which also gave rise to a book, which I reviewed   <a href="https://blog.computationalcomplexity.org/2014/05/review-of-people-problems-and-proofs-by.html#comment-form">here</a>.  Both of these books inspired my blog book. This is a shout-out to BOTH Lipton AND Regan.</p><p>5) Lipton either thinks P=NP or pretends to since he wants people to NOT all think the same thing. Perhaps someone will prove P NE NP while trying to prove P=NP. Like in <i>The Hitchhiker's Guide to the</i> <i>Galaxy </i>where they say that to fly, you throw yourself on the ground and miss. I took Lipton's advice in another context: While trying to prove that there IS a protocol for 11 muffins, 5 students where everyone gets 11/5 and the smallest piece is 11/25, I wrote down what such a protocol  would have to satisfy (I was sincerely trying to find such a protocol) and ended up proving that you could not do better than 13/30 (for which I already had a protocol). Reminds me of a quote attributed to Erdos: when trying to prove X, spend half your time trying to prove X and half trying to prove NOT(X).</p><p>6) Lipton had a blog post (probably also a paper someplace) about using Ramsey Theory as the basis for a proof system (see <a href="https://rjlipton.wpcomstaging.com/2009/06/13/a-proof-system-based-on-ramsey-theory/">here</a>).  That inspired me to propose a potential randomized n^{log n) algorithm for the CLIQUE-GAP problem (see <a href="https://blog.computationalcomplexity.org/2011/07/slightly-diff-take-on-liptons-use-or.html">here</a>). The comments showed why the idea could not work-- no surprise as my idea would have lead to NP contained in RTIME(n^{log n}). Still, it was fun to think about and I learned things in the effort. </p><p><br/></p><p><br/></p><p><br/></p><p><br/></p></div>
    </content>
    <updated>2022-01-23T20:28:00Z</updated>
    <published>2022-01-23T20:28:00Z</published>
    <author>
      <name>gasarch</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03004932739846901628</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="http://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2022-02-07T23:18:36Z</updated>
    </source>
  </entry>
</feed>
