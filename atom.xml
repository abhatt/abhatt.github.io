<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2020-10-13T14:22:00Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-6616178737091923837</id>
    <link href="https://blog.computationalcomplexity.org/feeds/6616178737091923837/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/10/hugh-woodin-kurt-godel-dwayne-rock.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/6616178737091923837" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/6616178737091923837" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/10/hugh-woodin-kurt-godel-dwayne-rock.html" rel="alternate" type="text/html"/>
    <title>Hugh Woodin, Kurt Godel, Dwayne `The Rock' Johnson, Robert De Niro, David Frum, Tom Selleck: Do I care what they think? Should I?</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p> MATH:</p><p>My last <a href="https://blog.computationalcomplexity.org/2020/10/revisiting-continuum-hypothesis.html">post</a> on CH mentioned that Hugh Woodin used to think NOT(CH) but now thinks CH. In both cases his reasons have some math content to them. Also, note that Hugh Woodin seems to believe that CH somehow HAS an answer. Kurt Godel also thought CH HAS an answer. It has been said that he could have announced  his result that CH is consistent but saying  L is THE model, and the problem is now solved. </p><p>Should we care what Hugh Woodin and Kurt Godel think about CH?</p><p>YES- they have both studied the issue A LOT. If you think CH should have an answer, then surely you would care what they think. </p><p>NO-  CH has no answer so there opinions are no better than mine. If you think CH does not have an answer then you might think this; however, I think you should still be at least INTERESTED in what people who have thought about the problem A LOT have to say, even if you will disagree with them.</p><p>But with MATH there are people who clearly know more than you on topics you care about, so it is worth hearing what they have to say. </p><p>POLITICS:</p><p>Recently Dwayne THE ROCK Johnson (by Wikipedia: actor, producer, businessman, and former professional wrestler) ENDORSED Joe Biden. Should we care about his opinion? Maybe, if wrestling fans and former pro wrestler tend to be Republicans, so this may indicate a shift. I do not know if this is the case. </p><p>Robert De Niro was in favor of impeaching Donald Trump. He also said that Trump was like a Gangster. He would know because he was in the movie GOODFELLOWS and later THE IRISHMAN (about Jimmy Hoffa). To be fair I do not think he said that is how he would know. Even so, I don't think I care what he thinks, unless he has some specialized knowledge I do not know about. </p><p>David Frum is a republican who had a break with the party NOT over Donald Trump, but over Obamacare- which you may recall was originally a CONSERVATIVE response to Hillarycare by the Heritage Foundation.  He has a good article on this <a href="https://www.theatlantic.com/politics/archive/2017/03/the-republican-waterloo/520833/">here</a>. Because he is an intelligent  republican in favor of Obamacare (or some version of it) he is worth listening to.</p><p>In POLITICS its trickier- who is worth listening to and why. For all I know, THE ROCK has made a detailed study of the Republican and Democratic platforms (actually this cannot be true since the Republicans did not have a platform this time). </p><p>COMMERCIALS:</p><p>Tom Selleck (Actor-Magnum PI a while back, Blue Bloods now)  does commercials for reverse mortgages. A while back I asked a group of people WHY he is doing them. Here were some answers and reactions</p><p>a) He needs the money. Not likely, he seems to have done well and does not seem to have the kind of bad habits (e.g., drugs) that need money. Maybe he has expensive tastes (my only expensive tastes is in fine European Kit Kat bars--- which actually are not that expensive). </p><p>b) He likes doing commercials. Maybe.</p><p>c) He believes in the product. At this, everyone cracked up in laughter.</p><p>This raises a more general point: Why does ANYONE believe ANY commercial since we KNOW the actor is being PAID to say it. I ask non rhetorically as always. </p></div>
    </content>
    <updated>2020-10-12T17:49:00Z</updated>
    <published>2020-10-12T17:49:00Z</published>
    <author>
      <name>gasarch</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03004932739846901628</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2020-10-13T14:11:32Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=5005</id>
    <link href="https://www.scottaaronson.com/blog/?p=5005" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=5005#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=5005" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">My second podcast with Lex Fridman</title>
    <summary xml:lang="en-US">Here it is—enjoy! We recorded it a month ago—outdoors (for obvious covid reasons), on a covered balcony in Austin, as it drizzled all around us. Topics included: Whether the universe is a simulation Eugene Goostman, GPT-3, the Turing Test, and consciousness Why I disagree with Integrated Information Theory Why I disagree with Penrose’s ideas about […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="https://www.youtube.com/watch?v=nAMjv0NAESM&amp;list=PLrAXtmErZgOdP_8GztsuKi9nrraNbKKp4">Here it is—enjoy!</a></p>



<p>We recorded it a month ago—outdoors (for obvious covid reasons), on a covered balcony in Austin, as it drizzled all around us.  Topics included:</p>



<ul><li>Whether the universe is a simulation</li><li>Eugene Goostman, GPT-3, the Turing Test, and consciousness</li><li>Why I disagree with Integrated Information Theory</li><li>Why I disagree with Penrose’s ideas about physics and the mind</li><li>Intro to complexity theory, including P, NP, PSPACE, BQP, and SZK</li><li>The US’s catastrophic failure on covid</li><li>The importance of the election</li><li>My objections to cancel culture</li><li>The role of love in my life (!)</li></ul>



<p>Thanks so much to Lex for his characteristically probing questions, apologies as always for my verbal tics, and here’s our <a href="https://lexfridman.com/scott-aaronson-2/">first podcast</a> for those who missed that one.</p></div>
    </content>
    <updated>2020-10-12T14:38:07Z</updated>
    <published>2020-10-12T14:38:07Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Complexity"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Metaphysical Spouting"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Quantum"/>
    <category scheme="https://www.scottaaronson.com/blog" term="The Fate of Humanity"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2020-10-13T03:03:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2010.04662</id>
    <link href="http://arxiv.org/abs/2010.04662" rel="alternate" type="text/html"/>
    <title>Deterministic computation of the characteristic polynomial in the time of matrix multiplication</title>
    <feedworld_mtime>1602460800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Neiger:Vincent.html">Vincent Neiger</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pernet:Cl=eacute=ment.html">Clément Pernet</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2010.04662">PDF</a><br/><b>Abstract: </b>This paper describes an algorithm which computes the characteristic
polynomial of a matrix over a field within the same asymptotic complexity, up
to constant factors, as the multiplication of two square matrices. Previously,
to our knowledge, this was only achieved by resorting to genericity assumptions
or randomization techniques, while the best known complexity bound with a
general deterministic algorithm was obtained by Keller-Gehrig in 1985 and
involves logarithmic factors. Our algorithm computes more generally the
determinant of a univariate polynomial matrix in reduced form, and relies on
new subroutines for transforming shifted reduced matrices into shifted weak
Popov matrices, and shifted weak Popov matrices into shifted Popov matrices.
</p></div>
    </summary>
    <updated>2020-10-12T23:24:16Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-10-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2010.04643</id>
    <link href="http://arxiv.org/abs/2010.04643" rel="alternate" type="text/html"/>
    <title>Equitable Scheduling on a Single Machine</title>
    <feedworld_mtime>1602460800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Heeger:Klaus.html">Klaus Heeger</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hermelin:Danny.html">Danny Hermelin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mertzios:George_B=.html">George B. Mertzios</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Molter:Hendrik.html">Hendrik Molter</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Niedermeier:Rolf.html">Rolf Niedermeier</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shabtay:Dvir.html">Dvir Shabtay</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2010.04643">PDF</a><br/><b>Abstract: </b>We introduce a natural but seemingly yet unstudied generalization of the
problem of scheduling jobs on a single machine so as to minimize the number of
tardy jobs. Our generalization lies in simultaneously considering several
instances of the problem at once. In particular, we have $n$ clients over a
period of $m$ days, where each client has a single job with its own processing
time and deadline per day. Our goal is to provide a schedule for each of the
$m$ days, so that each client is guaranteed to have their job meet its deadline
in at least $k \le m$ days. This corresponds to an equitable schedule where
each client is guaranteed a minimal level of service throughout the period of
$m$ days. We provide a thorough analysis of the computational complexity of
three main variants of this problem, identifying both efficient algorithms and
worst-case intractability results.
</p></div>
    </summary>
    <updated>2020-10-12T23:27:15Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-10-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2010.04638</id>
    <link href="http://arxiv.org/abs/2010.04638" rel="alternate" type="text/html"/>
    <title>Baseline and Triangulation Geometry in a Standard Plenoptic Camera</title>
    <feedworld_mtime>1602460800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hahne:Christopher.html">Christopher Hahne</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Aggoun:Amar.html">Amar Aggoun</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Velisavljevic:Vladan.html">Vladan Velisavljevic</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fiebig:Susanne.html">Susanne Fiebig</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pesch:Matthias.html">Matthias Pesch</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2010.04638">PDF</a><br/><b>Abstract: </b>In this paper, we demonstrate light field triangulation to determine depth
distances and baselines in a plenoptic camera. Advances in micro lenses and
image sensors have enabled plenoptic cameras to capture a scene from different
viewpoints with sufficient spatial resolution. While object distances can be
inferred from disparities in a stereo viewpoint pair using triangulation, this
concept remains ambiguous when applied in the case of plenoptic cameras. We
present a geometrical light field model allowing the triangulation to be
applied to a plenoptic camera in order to predict object distances or specify
baselines as desired. It is shown that distance estimates from our novel method
match those of real objects placed in front of the camera. Additional benchmark
tests with an optical design software further validate the model's accuracy
with deviations of less than +-0.33 % for several main lens types and focus
settings. A variety of applications in the automotive and robotics field can
benefit from this estimation model.
</p></div>
    </summary>
    <updated>2020-10-12T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-10-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2010.04623</id>
    <link href="http://arxiv.org/abs/2010.04623" rel="alternate" type="text/html"/>
    <title>Symmetric Promise Constraint Satisfaction Problems: Beyond the Boolean Case</title>
    <feedworld_mtime>1602460800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Barto:Libor.html">Libor Barto</a>, Diego Battistelli, Kevin M. Berg <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2010.04623">PDF</a><br/><b>Abstract: </b>The Promise Constraint Satisfaction Problem (PCSP) is a recently introduced
vast generalization of the Constraint Satisfaction Problem (CSP). We
investigate the computational complexity of a class of PCSPs beyond the most
studied cases - approximation variants of satisfiability and graph coloring
problems. We give an almost complete classification for the class of PCSPs of
the form: given a 3-uniform hypergraph that has an admissible 2-coloring, find
an admissible 3-coloring, where admissibility is given by a ternary symmetric
relation. The only PCSP of this sort whose complexity is left open in this work
is a natural hypergraph coloring problem, where admissibility is given by the
relation "if two colors are equal, then the remaining one is higher."
</p></div>
    </summary>
    <updated>2020-10-12T23:20:45Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-10-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2010.04618</id>
    <link href="http://arxiv.org/abs/2010.04618" rel="alternate" type="text/html"/>
    <title>Finitely Tractable Promise Constraint Satisfaction Problems</title>
    <feedworld_mtime>1602460800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Kristina Asimi, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Barto:Libor.html">Libor Barto</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2010.04618">PDF</a><br/><b>Abstract: </b>The Promise Constraint Satisfaction Problem (PCSP) is a generalization of the
Constraint Satisfaction Problem (CSP) that includes approximation variants of
satisfiability and graph coloring problems. Barto [LICS '19] has shown that a
specific PCSP, the problem to find a valid Not-All-Equal solution to a
1-in-3-SAT instance, is not finitely tractable in that it can be solved by a
trivial reduction to a tractable CSP, but such a CSP is necessarily over an
infinite domain (unless P=NP). We initiate a systematic study of this
phenomenon by giving a general necessary condition for finite tractability and
characterizing finite tractability within a class of templates - the "basic"
tractable cases in the dichotomy theorem for symmetric Boolean PCSPs allowing
negations by Brakensiek and Guruswami [SODA'18].
</p></div>
    </summary>
    <updated>2020-10-12T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-10-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2010.04527</id>
    <link href="http://arxiv.org/abs/2010.04527" rel="alternate" type="text/html"/>
    <title>Constant-time connectivity tests</title>
    <feedworld_mtime>1602460800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Krause:Philipp_Klaus.html">Philipp Klaus Krause</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2010.04527">PDF</a><br/><b>Abstract: </b>We present implementations of constant-time algorithms for connectivity tests
and related problems. Some are implementations of slightly improved variants of
previously known algorithms; for other problems we present new algorithms that
have substantially better runtime than previously known algorithms (estimates
of the distance to and tolerant testers for connectivity, 2-edge-connectivity,
3-edge-connectivity, eulerianity).
</p></div>
    </summary>
    <updated>2020-10-12T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-10-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2010.04412</id>
    <link href="http://arxiv.org/abs/2010.04412" rel="alternate" type="text/html"/>
    <title>Streaming Submodular Maximization with Fairness Constraints</title>
    <feedworld_mtime>1602460800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Yanhao.html">Yanhao Wang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fabbri:Francesco.html">Francesco Fabbri</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mathioudakis:Michael.html">Michael Mathioudakis</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2010.04412">PDF</a><br/><b>Abstract: </b>We study the problem of extracting a small subset of representative items
from a large data stream. Following the convention in many data mining and
machine learning applications such as data summarization, recommender systems,
and social network analysis, the problem is formulated as maximizing a monotone
submodular function subject to a cardinality constraint -- i.e., the size of
the selected subset is restricted to be smaller than or equal to an input
integer $k$. In this paper, we consider the problem with additional
\emph{fairness constraints}, which takes into account the group membership of
data items and limits the number of items selected from each group to a given
number. We propose efficient algorithms for this fairness-aware variant of the
streaming submodular maximization problem. In particular, we first provide a
$(\frac{1}{2}-\varepsilon)$-approximation algorithm that requires
$O(\frac{1}{\varepsilon} \cdot \log \frac{k}{\varepsilon})$ passes over the
stream for any constant $ \varepsilon&gt;0 $. In addition, we design a single-pass
streaming algorithm that has the same $(\frac{1}{2}-\varepsilon)$ approximation
ratio when unlimited buffer size and post-processing time is permitted.
</p></div>
    </summary>
    <updated>2020-10-12T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-10-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2010.04400</id>
    <link href="http://arxiv.org/abs/2010.04400" rel="alternate" type="text/html"/>
    <title>Stand Up Indulgent Rendezvous</title>
    <feedworld_mtime>1602460800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bramas:Quentin.html">Quentin Bramas</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lamani:Anissa.html">Anissa Lamani</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tixeuil:S=eacute=bastien.html">Sébastien Tixeuil</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2010.04400">PDF</a><br/><b>Abstract: </b>We consider two mobile oblivious robots that evolve in a continuous Euclidean
space. We require the two robots to solve the rendezvous problem (meeting in
finite time at the same location, not known beforehand) despite the possibility
that one of those robots crashes unpredictably. The rendezvous is stand up
indulgent in the sense that when a crash occurs, the correct robot must still
meet the crashed robot on its last position. We characterize the system
assumptions that enable problem solvability, and present a series of algorithms
that solve the problem for the possible cases.
</p></div>
    </summary>
    <updated>2020-10-12T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-10-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2010.04333</id>
    <link href="http://arxiv.org/abs/2010.04333" rel="alternate" type="text/html"/>
    <title>Succinct Navigational Oracles for Families of Intersection Graphs on a Circle</title>
    <feedworld_mtime>1602460800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Acan:H=uuml=seyin.html">Hüseyin Acan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chakraborty:Sankardeep.html">Sankardeep Chakraborty</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jo:Seungbum.html">Seungbum Jo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nakashima:Kei.html">Kei Nakashima</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sadakane:Kunihiko.html">Kunihiko Sadakane</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Satti:Srinivasa_Rao.html">Srinivasa Rao Satti</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2010.04333">PDF</a><br/><b>Abstract: </b>We consider the problem of designing succinct navigational oracles, i.e.,
succinct data structures supporting basic navigational queries such as degree,
adjacency, and neighborhood efficiently for intersection graphs on a circle,
which include graph classes such as {\it circle graphs}, {\it
$k$-polygon-circle graphs}, {\it circle-trapezoid graphs}, {\it trapezoid
graphs}. The degree query reports the number of incident edges to a given
vertex, the adjacency query asks if there is an edge between two given
vertices, and the neighborhood query enumerates all the neighbors of a given
vertex. We first prove a general lower bound for these intersection graph
classes and then present a uniform approach that lets us obtain matching lower
and upper bounds for representing each of these graph classes. More
specifically, our lower bound proofs use a unified technique to produce tight
bounds for all these classes, and this is followed by our data structures which
are also obtained from a unified representation method to achieve succinctness
for each class. In addition, we prove a lower bound of space for representing
{\it trapezoid} graphs and give a succinct navigational oracle for this class
of graphs.
</p></div>
    </summary>
    <updated>2020-10-12T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-10-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2010.04281</id>
    <link href="http://arxiv.org/abs/2010.04281" rel="alternate" type="text/html"/>
    <title>Sensitivity Analysis of Submodular Function Maximization</title>
    <feedworld_mtime>1602460800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/McMeel:Conor.html">Conor McMeel</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yoshida:Yuichi.html">Yuichi Yoshida</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2010.04281">PDF</a><br/><b>Abstract: </b>We study the recently introduced idea of worst-case sensitivity for monotone
submodular maximization with cardinality constraint $k$, which captures the
degree to which the output argument changes on deletion of an element in the
input. We find that for large classes of algorithms that non-trivial
sensitivity of $o(k)$ is not possible, even with bounded curvature, and that
these results also hold in the distributed framework. However, we also show
that in the regime $k = \Omega(n)$ that we can obtain $O(1)$ sensitivity for
sufficiently low curvature.
</p></div>
    </summary>
    <updated>2020-10-12T23:24:45Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-10-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=17669</id>
    <link href="https://rjlipton.wordpress.com/2020/10/11/are-black-holes-necessary/" rel="alternate" type="text/html"/>
    <title>Are Black Holes Necessary?</title>
    <summary>Our congratulations on the 2020 Nobel Prize in Physics Composite crop of src1, src2 Roger Penrose, Reinhard Genzel, and Andrea Ghez have won the 2020 Nobel Prize in Physics. The prize is divided half to Penrose for theoretical work and half to Genzel and Ghez for finding a convincing and appreciably large practical example. Today […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc">
<em>Our congratulations on the 2020 Nobel Prize in Physics</em>
<font color="#000000">


</font></font></p><table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2020/10/penrosegenzelghez.jpg"><img alt="" class="alignright wp-image-17675" height="115" src="https://rjlipton.files.wordpress.com/2020/10/penrosegenzelghez.jpg?w=300" width="320"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Composite crop of <a href="https://www.bbc.com/news/science-environment-54439150">src1</a>, <a href="https://theconversation.com/nobel-prize-how-penrose-genzel-and-ghez-helped-put-black-holes-at-the-centre-of-modern-astrophysics-147613">src2</a></font></td>
</tr>
</tbody>
</table><font color="#0044cc"><font color="#000000">



<p>
Roger Penrose, Reinhard Genzel, and Andrea Ghez have won the 2020 Nobel Prize in Physics. The prize is divided half to Penrose for theoretical work and half to Genzel and Ghez for finding a convincing and appreciably large practical example.

</p><p>
Today we congratulate the winners and give further musings on the nature of knowledge and the role of theory.

</p><p>
The physics Nobel has always had the rule that it cannot be for a theory alone, no matter how beautiful and how many mathematical discoveries follow from its development. Stephen Hawking’s theory of black-hole <a href="https://en.wikipedia.org/wiki/Hawking_radiation">radiation</a> is almost universally accepted, despite its association with <a href="https://en.wikipedia.org/wiki/Black_hole_information_paradox">paradox</a>, yet it was said that only an empirical confirmation such as mini-black holes being discovered to explode in an accelerator core would have brought it a Nobel. The official citation to Sir Roger says that his prize is:

</p><p>

</p><blockquote><b> </b> <em> “for the discovery that black hole formation is a robust prediction of the general theory of relativity.” </em>
</blockquote>




<p>
What is a “robust” prediction? The word strikes us as having overtones of <em>necessity</em>. Necessary knowledge is the kind we deal with in mathematics. The citation to Genzel and Ghez stays on empirical grounds:

</p><p>

</p><blockquote><b> </b> <em> “for the discovery of a supermassive compact object at the centre of our galaxy.” </em>
</blockquote>


<p>



</p><p>
The “object” <em>must</em> be a black hole—given relativity and its observed gravitational effects, it cannot be otherwise. Among many possible witnesses for the reality of black holes—one being the evident origin of the gravitational waves whose <a href="https://rjlipton.wordpress.com/2016/02/16/waves-hazards-and-guesses/">detection</a> brought the 2017 Nobel—the centers of galaxies are hefty examples. The combination of these citations opens several threads we’d like to discuss.

</p><p>



</p><p>

</p><h2> The Proof Horizon of a Black Hole </h2>


<p>



</p><p>
Dick and I are old enough to remember when black holes had the status of conjecture. One of my childhood astronomy books stated that the <a href="https://en.wikipedia.org/wiki/Cygnus_X-1">Cygnus X-1</a> X-ray source was the best known candidate for a black hole. In 1974, Hawking bet Kip Thorne that it was not a black hole. The bet lasted until 1990, when Hawking conceded. He wrote the following in his famous <a href="https://en.wikipedia.org/wiki/A_Brief_History_of_Time">book</a>, <em>A Brief History of Time</em>:

</p><p>

</p><blockquote><b> </b> <em> This was a form of insurance policy for me. I have done a lot of work on black holes, and it would all be wasted if it turned out that black holes do not exist. But in that case, I would have the consolation of winning my bet. … When we made the bet in 1975, we were 80% certain that Cygnus X-1 was a black hole. By now [1988], I would say that we are about 95% certain, but the bet has yet to be settled. </em>
</blockquote>


<p>



</p><p>
In the 1980s, I was a student and then postdoc in Penrose’s department, so I was imbued with the ambience of black holes and never had a thought about doubting their existence. I even once spent an hour with John Wheeler, who coined the term “black hole,” when Penrose delegated me to accompany Wheeler to Oxford’s train station for his return to London. But it seems from the record that the progression to regarding black holes as proven entities was as gradual as many argue the act of crossing a large black hole’s event horizon to be. Although the existence of a central black hole from data emanating from Sagittarius had been proposed at least as far back as 1971, the work by Ghez and then Genzel cited for their prize began in 1995. The official <a href="https://www.nobelprize.org/prizes/physics/2002/press-release/">announcement</a> for Riccardo Giacconi’s share of the 2002 physics Nobel stated:

</p><p>

</p><blockquote><b> </b> <em> “He also detected sources of X-rays that most astronomers now consider to contain black holes.” </em>
</blockquote>


<p>



</p><p>
This speaks lingering doubt at least about <em>where</em> black holes might be judged to exist, if not their existence at all.

</p><p>
However their time of confirmation might be pinpointed, it is the past five years that have given by far the greatest flood of evidence, including the first visual <a href="https://www.jpl.nasa.gov/edu/news/2019/4/19/how-scientists-captured-the-first-image-of-a-black-hole/">image</a> of a black hole last year. The fact of their presence in our universe is undeniable. But <em>necessity</em> is a separate matter, and with Penrose this goes back to 1964.

</p><p>



</p><p>

</p><h2> Relativity and Necessity </h2>


<p>



</p><p>
We have <a href="https://rjlipton.wordpress.com/2011/10/31/an-interview-with-kurt-gdel/">mentioned</a> Kurt Gödel’s solution to the equations of general relativity (GR) in which time travel is possible. This does not mean that time travel must be possible, or that it is possible in our universe. A “solution” to GR is more like a <em>model</em> in logic: it may satisfy a theory’s axioms but have other properties that are contingent (unless the theory is <em>categorical</em>, meaning that all of its models are isomorphic). Gödel’s model has a negative value for Einstein’s <a href="https://en.wikipedia.org/wiki/Cosmological_constant">cosmological constant</a>; the 2011 physics Nobel went to the discovery that in our universe the constant has a tiny <a href="https://rjlipton.wordpress.com/2011/10/12/empirical-humility/">positive</a> value. GR also allows solutions in which some particles (called <em>tachyons</em>) travel faster than light.

</p><p>
That GR has solutions allowing black holes had been known from its infancy in work by Karl Schwarzschild and Johannes Droste. There are also solutions without black holes; a universe with no mass is legal in GR in <a href="https://en.wikipedia.org/wiki/Vacuum_solution_(general_relativity)">many ways</a> besides the case of special relativity. Penrose took the opposite tack, of giving minimal conditions under which black holes are <em>necessary</em>. Following this <a href="https://theconversation.com/nobel-prize-how-penrose-genzel-and-ghez-helped-put-black-holes-at-the-centre-of-modern-astrophysics-147613">article</a>, we list them informally as follows:

</p><p>


</p><ol> 
<li>
Sufficiently large concentrations of mass exerting gravity exist. 
</li><li>
Gravity always attracts, never repels. 
</li><li>
No physical effect can travel faster than light. 
</li><li>
Gravity determines how light bends and moves. 
</li><li>
The space-time manifold is metrically complete. 
</li></ol>



<p>
Penrose showed that any system obeying these properties and evolving in accordance with GR must develop black holes. He showed this without any symmetry assumptions on the system. Thus he derived black holes as a prediction with the force of a theorem derived from minimal axioms.

</p><p>
His 1965 <a href="http://quantum-gravitation.de/media/2d2cde3ec9c38fffffff80d0fffffff1.pdf">paper</a> actually used a proof by contradiction. He derived five properties needed in order for the system to avoid forming a singularity. Then he showed they are mutually inconsistent—a proof by contradiction. Here is the crux of his paper:

</p><p>




</p><p>
</p><table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2020/10/penrosediagram1965.jpg"><img alt="" class="aligncenter wp-image-17673" height="442" src="https://rjlipton.files.wordpress.com/2020/10/penrosediagram1965.jpg?w=600" width="600"/></a>
<p>
</p></td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">[ Snip from <a href="http://quantum-gravitation.de/media/2d2cde3ec9c38fffffff80d0fffffff1.pdf">paper</a> ]</font>
</td>
</tr>
</tbody></table>



<p>
In the diagram, time flows up. The point in a nutshell—a very tight nutshell—is that once a surface flows inside the cylinder at the Schwarzschild radius then light and any other motion from it can go only inward toward a singularity. The analysis is possible without the kind of symmetry assumption that had been used to tame the algebraic complexity of the equations of GR. The metric completeness mandates a singularity apart from any symmetries; a periodic equilibrium is ruled out by analysis of Cauchy surfaces.

</p><p>



</p><p>

</p><h2> Necessary For Us? </h2>


<p>



</p><p>
Like Richard Feynman’s famous diagrams for quantum field theory, Penrose developed his diagrams as tools for shortcutting the vicissitudes of GR. We could devote entire other posts to his famous <a href="https://en.wikipedia.org/wiki/Penrose_tiling">tiles</a> and <a href="https://en.wikipedia.org/wiki/Penrose_triangle">triangle</a> and other combinatorial inventions. His tools enable quantifying black-hole formation from observations in our universe.

</p><p>
The question of <em>necessity</em>, however, pertains to other possible universes. Let us take for granted that GR and quantum theory are facets of a physical theory that governs the entire cosmos—the long-sought “theory of everything”—and let us also admit the contention of inflationary theorists that multiple universes are a necessary consequence of any inflation theory. The question remains, <em>are black holes necessary in those universes?</em>

</p><p>
It is possible that those universes might not satisfy axiom 1 above, or might have enough complexity for existence of black holes but not large-scale formation of them. The question then becomes whether black holes must exist in any universe rich enough for sentient life forms such as ourselves to develop. This is a branch of the <a href="https://en.wikipedia.org/wiki/Anthropic_principle">anthropic principle</a>.

</p><p>
Lee Smolin <a href="https://en.wikipedia.org/wiki/Cosmological_natural_selection">proposed</a> a mechanism via which black holes engender new universes and so propagate the complexity needed for their large-scale formation. Since complexity also attends the development of sentient life forms, this would place our human existence in the wake of consequence, as opposed to the direction of logic when reasoning by the anthropic principle.

</p><p>



</p><p>

</p><h2> A Little More About Science </h2>


<p>



</p><p>
The 2020 Nobel Prize in Chemistry was awarded this week to Jennifer Doudna and Emmanuelle Charpentier for their lead roles in developing the <a href="https://en.wikipedia.org/wiki/CRISPR">CRISPR</a> gene-editing technology, specifically around the protein <a href="https://en.wikipedia.org/wiki/Cas9">Cas9</a>. 

</p><p>
We argue that two more different types of results cannot be found: 

</p><p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\bullet }"/> Penrose shows that black holes and general relativity are connected, which is a math result. We still cannot create black holes in a lab to experiment with—or maybe we could but should be very afraid of going anywhere near doing so. It was not clear that there could ever be a real application of this result.

</p><p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\bullet }"/> Charpentier and Doudna discover that an existing genetic mechanism could be used to edit genetic material. Clearly this can and was experimented on in labs. Also clear that there are applications of this result. Actually it is now a standard tool used in countless labs. There even are patent battles over the method.

</p><p>
We like the fact that Nobels are given for such diverse type of research. It is not just that one is for astrophysics and one for chemistry. It is that Nobels can be given for very different types of research. We think this is important.

</p><p>
But wait. These results do have something in common, something that sets them apart from any research we can do in complexity theory. Both operate like this:

</p><p>

</p><blockquote><b> </b> <em> 	Observe something important from nature. Something that is there independent of us. Then in Penrose’s case explain why it is true. Then in Charpentier and Doudna’s case, use it to solve some important problems. </em>
</blockquote>


<p>



</p><p>
We wonder if anything like this could be done in our research world—say in complexity theory?

</p><p>



</p><p>

</p><h2> Open Problems </h2>


<p>



</p><p>
Besides our congratulations to all those mentioned in this post, Ken expresses special thanks to Sir Roger among other Oxford Mathematical Institute fellows for the kindness recorded <a href="https://rjlipton.wordpress.com/2011/03/09/tex-is-great-what-is-tex/#comment-11172">here</a>.

</p>

<p>
[changed note about massless universe]</p></font></font>



<p/></div>
    </content>
    <updated>2020-10-11T19:19:58Z</updated>
    <published>2020-10-11T19:19:58Z</published>
    <category term="All Posts"/>
    <category term="History"/>
    <category term="News"/>
    <category term="Proofs"/>
    <category term="Andrea Ghez"/>
    <category term="black hole"/>
    <category term="Chemistry"/>
    <category term="Emmanuelle Charpentier"/>
    <category term="Jennifer Doudna"/>
    <category term="John Wheeler"/>
    <category term="knowledge"/>
    <category term="Lee Smolin"/>
    <category term="necessity"/>
    <category term="Nobel Prize"/>
    <category term="Physics"/>
    <category term="progress in knowledge"/>
    <category term="Reinhard Genzel"/>
    <category term="relativity"/>
    <category term="Riccardo Giacconi"/>
    <category term="Roger Penrose"/>
    <category term="science"/>
    <category term="scientific proof"/>
    <category term="Stephen Hawking"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2020-10-13T14:20:49Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/154</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/154" rel="alternate" type="text/html"/>
    <title>TR20-154 |  A Structural Theorem for Local Algorithms with Applications to Coding, Testing, and Privacy | 

	Marcel Dall&amp;#39;Agnol, 

	Tom Gur, 

	Oded Lachish</title>
    <summary>We prove a general structural theorem for a wide family of local algorithms, which includes property testers, local decoders, and PCPs of proximity. Namely, we show that the structure of every algorithm that makes $q$ adaptive queries and satisfies a natural robustness condition admits a sample-based algorithm with $n^{1- 1/O(q^2 \log^2 q)}$ sample complexity, following the definition of Goldreich and Ron (TOCT 2016). We prove that this transformation is nearly optimal. Our theorem also admits a scheme for constructing privacy-preserving local algorithms. 

Using the unified view that our structural theorem provides, we obtain results regarding various types of local algorithms, including the following.


- We strengthen the state-of-the-art lower bound for relaxed locally decodable codes, obtaining an exponential improvement on the dependency in query complexity; this resolves an open problem raised by Gur and Lachish (SODA 2020).
- We show that any (constant-query) testable property admits a sample-based tester with sublinear sample complexity; this resolves a problem left open in a work of Fischer, Lachish, and Vasudev (FOCS 2015) by extending their main result to adaptive testers.
- We prove that the known separation between proofs of proximity and testers is essentially maximal; this resolves a problem left open by Gur and Rothblum (ECCC 2013, Computational Complexity 2018) regarding sublinear-time delegation of computation.

Our techniques strongly rely on relaxed sunflower lemmas and the Hajnal–Szemerédi theorem.</summary>
    <updated>2020-10-10T11:21:31Z</updated>
    <published>2020-10-10T11:21:31Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-10-13T14:20:37Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/153</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/153" rel="alternate" type="text/html"/>
    <title>TR20-153 |  Total Functions in the Polynomial Hierarchy | 

	Robert Kleinberg, 

	Daniel Mitropolsky, 

	Christos Papadimitriou</title>
    <summary>We identify several genres of search problems beyond NP for which existence of solutions is guaranteed.  One class that seems especially rich in such problems is PEPP (for "polynomial empty pigeonhole principle"), which includes problems related to existence theorems proved through the union bound, such as finding a bit string that is far from all codewords, finding an explicit rigid matrix, as well as a problem we call Complexity, capturing Complexity Theory's quest.  When the union bound is generous, in that solutions constitute at least a polynomial fraction of the domain, we have a family of seemingly weaker classes $\alpha$-PEPP, which are inside FP}$^{\text{NP}}|$poly.  Higher in the hierarchy, we identify the constructive version of the Sauer-Shelah lemma and the appropriate generalization of PPP that contains it.  The resulting total function hierarchy turns out to be more stable than the polynomial hierarchy: it is known that, under oracles, total functions within FNP may be easy, but total functions a level higher may still be harder than FP$^{\text{NP}}$.</summary>
    <updated>2020-10-08T22:31:10Z</updated>
    <published>2020-10-08T22:31:10Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-10-13T14:20:38Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/152</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/152" rel="alternate" type="text/html"/>
    <title>TR20-152 |  Variants of the Determinant polynomial and VP-completeness | 

	Prasad Chaugule, 

	Nutan Limaye, 

	Shourya Pandey</title>
    <summary>The determinant is a canonical VBP-complete polynomial in the algebraic complexity setting. In this work, we introduce two variants of the determinant polynomial which we call $StackDet_n(X)$ and $CountDet_n(X)$ and show that they are VP and VNP complete respectively under $p$-projections. The definitions of the polynomials are inspired by a combinatorial characterisation of the determinant developed by Mahajan and Vinay (SODA 1997). We extend the combinatorial object in their work, namely clow sequences, by introducing additional edge labels on the edges of the underlying graph. The idea of using edge labels is inspired by the work of Mengel (MFCS 2013).</summary>
    <updated>2020-10-08T22:27:25Z</updated>
    <published>2020-10-08T22:27:25Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-10-13T14:20:38Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://francisbach.com/?p=1380</id>
    <link href="https://francisbach.com/hermite-polynomials/" rel="alternate" type="text/html"/>
    <title>Polynomial magic III : Hermite polynomials</title>
    <summary>After two blog posts earlier this year on Chebyshev and Jacobi polynomials, I am coming back to orthogonal polynomials, with Hermite polynomials. This time, in terms of applications to machine learning, no acceleration, but some interesting closed-form expansions in positive-definite kernel methods. Definition and first properties There are many equivalent ways to define Hermite polynomials....</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p class="justify-text">After two blog posts earlier this year on <a href="https://francisbach.com/chebyshev-polynomials/">Chebyshev</a> and <a href="https://francisbach.com/jacobi-polynomials/">Jacobi</a> polynomials, I am coming back to orthogonal polynomials, with Hermite polynomials. </p>



<p class="justify-text">This time, in terms of applications to machine learning, no acceleration, but some interesting closed-form expansions in positive-definite kernel methods. </p>



<h2>Definition and first properties</h2>



<p class="justify-text">There are many equivalent ways to define Hermite polynomials. A natural one is through the so-called <a href="https://en.wikipedia.org/wiki/Rodrigues%27_formula">Rodrigues’ formula</a>: $$H_k(x) = (-1)^k e^{x^2} \frac{d^k}{d x^k}\big[ e^{-x^2} \big],$$ from which we can deduce \(H_0(x) = 1\), \(H_1(x) =\   – e^{x^2} \big[ -2x e^{-x^2} \big] = 2x\), \(H_2(x) = e^{x^2} \big[ (-2x)^2e^{-x^2} -2 e^{-x^2}  \big] =  4x^2 – 2\), etc.</p>



<p class="justify-text">Other simple properties which are consequences of the definition (and can be shown by recursion) are that \(H_k\) is a polynomial of degree \(k\), with the same parity as \(k\), and with a leading coefficient equal to \(2^k\).</p>



<p class="justify-text"><strong>Orthogonality for Gaussian distribution.</strong> Using integration by parts, one can show (see end of the post) that for \(k \neq \ell\), we have $$\int_{-\infty}^{+\infty}  \!\!\!H_k(x) H_\ell(x) e^{-x^2} dx =0, $$ and that for \(k=\ell\), we have $$\int_{-\infty}^{+\infty} \!\!\! H_k(x)^2 e^{-x^2}dx = \sqrt{\pi} 2^k k!.$$ </p>



<p class="justify-text">In other words, the Hermite polynomials are orthogonal for the Gaussian distribution with mean \(0\) and variance \(\frac{1}{2}\). Yet in other words, defining the <em>Hermite functions</em> as \( \displaystyle \psi_k(x) = (\sqrt{\pi} 2^k k!)^{-1/2} H_k(x) e^{-x^2/2}\), we obtain an orthonormal basis of \(L_2(dx)\). As illustrated below, the Hermite functions, as the index \(k\) increases, have an increasing “support” (the support is always the entire real line, but most of the mass is concentrated in centered balls of increasing sizes, essentially at \(\sqrt{k}\)) and, like cosines and sines, an increasingly oscillatory behavior.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-full is-resized"><img alt="" class="wp-image-4579" height="305" src="https://francisbach.com/wp-content/uploads/2020/08/hermite.gif" width="349"/>Plot of Hermite functions \(\psi_k(x) = (\sqrt{\pi} 2^k k!)^{-1/2} H_k(x) e^{-x^2/2}\), from \(k=0\) to \(k=20\).</figure></div>



<p class="justify-text">Among such orthonormal bases, the Hermite functions happen to be diagonalizing the Fourier tranform operator.  In other words, the Fourier transform of \(\psi_k\) (for the definition making it an isometry of \(L_2(dx)\)) is equal to $$ \mathcal{F}(\psi_k)(\omega)  =  \frac{1}{\sqrt{2\pi}} \int_{-\infty}^{+\infty} \psi_k(x) e^{- i \omega x} dx = (-i)^k \psi_k(\omega).$$ (note that the eigenvalues are all of unit modulus as we have an isometry). See a proof at the end of the post. I am not aware of any applications of this property in machine learning or statistics (but there are probably some).</p>



<p class="justify-text"><strong>Recurrence.</strong> In order to compute Hermite polynomials, the following recurrence relation is the most useful $$ H_{k+1}(x) = 2x H_k(x) \ – 2k H_{k-1}(x). \tag{1}$$  Such recursions are always available for orthogonal polynomials (see [4]), but it takes here a particularly simple form (see a proof at the end of the post).</p>



<p class="justify-text"><strong>Generating function.</strong> The following property is central in many proofs of properties of Hermite polynomials: for all \(t \in \mathbb{R}\), we have $$\sum_{k=0}^\infty \frac{t^k}{k!} H_k(x) =e^{ 2xt \ – \ t^2}, \tag{2}$$ with a proof at the end of the post based on the residue theorem.</p>



<h2>Further (less standard) properties</h2>



<p class="justify-text">For the later developments, we need other properties which are less standard (there are many other interesting properties, which are not useful for this post, see <a href="https://en.wikipedia.org/wiki/Hermite_polynomials">here</a>).</p>



<p class="justify-text"><strong>Mehler formula. </strong>For \(|\rho| &lt; 1\), it states: $$ \exp \Big( – \frac{\rho}{1- \rho^2} (x-y)^2\Big) = \sqrt{1-\rho^2} \sum_{k=0}^\infty \frac{\rho^k}{2^k k!} H_k(x) H_k(y) \exp \Big( – \frac{\rho}{1+\rho} (x^2 + y^2) \Big).$$ The proof is significantly more involved; see [<a href="https://academic.oup.com/jlms/article-pdf/s1-8/3/194/2363185/s1-8-3-194.pdf">1</a>] for details (with a great last sentence: “Prof. Hardy tells me that he has not seen his proof in print, though the inevitability of the successive steps makes him think that it is unlikely to be new”). Note that we will in fact obtain a new proof from the relationship with kernel methods (see below).</p>



<p class="justify-text"><strong>Expectation for Gaussian distributions. </strong>We will need this property for \(|\rho|&lt;1\) (see proof at the end of the post), which corresponds to the expectation of \(H_k(x)\) for \(x\) distributed as a non-centered Gaussian distribution: $$\int_{-\infty}^\infty H_k(x) \exp\Big( – \frac{(x-\rho y)^2}{1-\rho^2} \Big)dx= \sqrt{\pi} \rho^k \sqrt{1-\rho^2} H_k (y). \tag{3}$$</p>



<p class="justify-text">Given the relationship with the Gaussian distribution, it is no surprise that Hermite polynomials pop up whenever Gaussians are used, as distributions or kernels. Before looking into it, let’s first give a brief review of kernel methods.</p>



<h2>From positive-definite kernel to Hilbert spaces</h2>



<p class="justify-text">Given a prediction problem with inputs in a set \(\mathcal{X}\), a traditional way of parameterizing real-valued functions on \(\mathcal{X}\) is to use <em>positive-definite kernels</em>.</p>



<p class="justify-text">A positive-definite kernel is a function \(K: \mathcal{X} \times \mathcal{X} \to \mathbb{R}\) such that for all sets \(\{x_1,\dots,x_n\}\) of \(n\) elements of \(\mathcal{X}\), the “kernel matrix” in \(\mathbb{R}^{n \times n}\) composed of pairwise evaluations is symmetric positive semi-definite. This property happens to be equivalent to the existence of a Hilbert feature space \(\mathcal{H}\) and a feature map \(\varphi: \mathcal{X} \to \mathcal{H}\) such that $$K(x,x’) = \langle \varphi(x), \varphi(x’) \rangle_{\mathcal{H}},$$ with an elegant constructive proof [<a href="https://www.ams.org/journals/tran/1950-068-03/S0002-9947-1950-0051437-7/S0002-9947-1950-0051437-7.pdf">15</a>].</p>



<p class="justify-text">This allows to define the space of linear functions on the features, that is, functions of the form $$f(x) = \langle f, \varphi(x) \rangle_{\mathcal{H}},$$ for \(f \in \mathcal{H}\). </p>



<p class="justify-text">This space is often called the <a class="" href="https://en.wikipedia.org/wiki/Reproducing_kernel_Hilbert_space">reproducing kernel Hilbert space</a> (RKHS) associated to the kernel \(K\) (we can prove that it is indeed uniquely defined). In such a space, we can also define the squared norm of the function \(f\), namely \(\| f\|_{\mathcal{H}}^2\), which can be seen as a specific regularization term in kernel methods.</p>



<p class="justify-text">The space satisfies the so-called reproducing property (hence its name): \(f(x) = \langle f, K(\cdot,x) \rangle_{\mathcal{H}}\). In other words, the feature \(\varphi(x)\) is the kernel function evaluated at \(x\), that is,  \(\varphi(x) = K(\cdot,x)\). These spaces have been a source of many developments in statistics [5] and machine learning [6, 7].</p>



<p class="justify-text"><strong>Orthonormal basis.</strong> A difficulty in working with infinite-dimensional Hilbert spaces of functions is that it is sometimes hard to understand what functions are actually considered. One simple way to enhance understanding of the regularization property is to have an orthonormal basis (in very much the same way as the Fourier basis), as we can then identify \(\mathcal{H}\) to the space of squared-integrable sequences.</p>



<p class="justify-text">For kernel-based Hilbert spaces, if we have an orthonormal basis \((g_k)_{k \geqslant 0}\) of the Hilbert space \(\mathcal{H}\), then, by decomposing \(\varphi(x)\) in the basis, we have $$\varphi(x) = \sum_{k =0}^\infty \langle \varphi(x), g_k \rangle_\mathcal{H} g_k,$$ we get $$K(x,y) = \langle \varphi(y), \varphi(x) \rangle = \sum_{k =0}^\infty \langle \varphi(x), g_k \rangle_\mathcal{H} \langle  \varphi(y), g_k \rangle_\mathcal{H} =\sum_{k=0}^\infty g_k(x) g_k(y), \tag{4}$$ that is, we have an expansion of the kernel as an infinite sum (note here, that we ignore summability issues).</p>



<p class="justify-text">Among orthonormal bases, some are more interesting than others. The ones composed of eigenfunctions for particular operators are really more interesting, in particular for the covariance operator that we now present, and their use in statistical learning theory.</p>



<h2>Analyzing ridge regression through covariance operators</h2>



<p class="justify-text">The most classical problem where regularization by RKHS norms occurs is <em>ridge regression</em>, where, given some observations \((x_1,y_1),\dots,(x_n,y_n) \in \mathcal{X} \times \mathbb{R}\), one minimizes with respect to \(f \in \mathcal{H}\): $$ \frac{1}{n} \sum_{i=1}^n \big( y_i \ – \langle f, \varphi(x_i) \rangle_{\mathcal{H}} \big)^2 +  \lambda \| f\|_{\mathcal{H}}^2.$$</p>



<p class="justify-text">In finite dimensions, the convergence properties are characterized by the (non-centered) covariance matrix \(\Sigma = \mathbb{E} \big[ \varphi(x) \otimes \varphi(x) \big]\), where the expectation is taken with respect to the underlying distribution of the observations \(x_1,\dots,x_n\) (which are assumed independently and identically distributed for simplicity). If \(\mathcal{H} = \mathbb{R}^d\), then \(\Sigma\) is a \(d \times d\) matrix. </p>



<p class="justify-text">For infinite-dimensional \(\mathcal{H}\), the same expression \(\Sigma = \mathbb{E} \big[ \varphi(x) \otimes \varphi(x) \big]\) defines a linear <em>operator</em> from \(\mathcal{H}\) to  \(\mathcal{H}\), so that for \(f,g \in \mathcal{H}\), we have $$\langle f, \Sigma g \rangle_{\mathcal{H}} = \mathbb{E} \big[ \langle f, \varphi(x)\rangle_{\mathcal{H}}\langle g, \varphi(x)\rangle_{\mathcal{H}}\big] = \mathbb{E} \big[ f(x) g(x) \big].$$</p>



<p class="justify-text">The generalization property of ridge regression has been thoroughly studied (see, e.g., [8, 9]), and if there exists \(f_\ast \in \mathcal{H}\) such that \(y_i = \langle f_\ast, \varphi(x_i) \rangle + \varepsilon_i\) for a noise \(\varepsilon_i\) which is independent of \(x_i\), with zero mean and variance equal to \(\sigma^2\), then the expected error on unseen data is asymptotically upper-bounded by $$\sigma^2 + \lambda \| f_\ast\|_{\mathcal{H}}^2 + \frac{\sigma^2}{n} {\rm tr} \big[ \Sigma ( \Sigma + \lambda I)^{-1} \big].$$ The first term \(\sigma^2\) is the best possible expected performance, the term \(\lambda \| f_\ast\|_{\mathcal{H}}^2\) is usually referred to as the <em>bias</em> term and characterizes the bias introduced by regularizing towards zero, while the third term \(\frac{\sigma^2}{n} {\rm tr} \big[ \Sigma ( \Sigma + \lambda I)^{-1} \big]\) is the <em>variance</em> term, which characterizes the loss in performance due to the observation of only \(n\) observations.</p>



<p class="justify-text">The quantity \({\rm df}(\lambda) = {\rm tr} \big[ \Sigma ( \Sigma + \lambda I)^{-1} \big]\) is often referred to as the degrees of freedom [10]. When \(\lambda\) tends to infinity, then \({\rm df}(\lambda)\) tends to zero; when \(\lambda\) tends to zero, then \({\rm df}(\lambda)\) tends to the number of non-zero eigenvalues of \(\Sigma\). Thus, in finite dimension, this typically leads to the underlying dimension. Given the usual variance term in \(\sigma^2 \frac{d}{n}\) for ordinary least-squares with \(d\)-dimensional features, \({\rm df}(\lambda)\) is often seen as an implicit number of parameters for kernel ridge regression.</p>



<p class="justify-text">In infinite dimensions, under mild assumptions, there are infinitely many eigenvalues for \(\Sigma\), which form a decreasing sequence \((\lambda_i)_{i \geqslant 0}\) that tends to zero (and is summable, with a sum equal to the trace of \(\Sigma\)). The rate of such a decay is key to understanding the generalization capabilities of kernel methods. With the following classical types of decays:</p>



<ul class="justify-text"><li><em>Polynomial decays</em>: If \(\lambda_i \leqslant \frac{C}{(i+1)^{\alpha}}\) for \(\alpha &gt; 1\), then one can upper bound the sum by an integral as $$ {\rm tr} \big[ \Sigma ( \Sigma + \lambda I)^{-1} \big] = \sum_{i=0}^\infty \frac{\lambda_i}{\lambda_i + \lambda} \leqslant \sum_{i=1}^\infty \frac{1}{1  + \lambda i^\alpha / C} \leqslant \int_0^\infty \frac{1}{1+\lambda t^\alpha / C} dt.$$ With the change of variable \(u = \lambda t^\alpha / C\), we get that \({\rm df}(\lambda) = O(\lambda^{-\alpha})\). We can then balance bias and variance with \(\lambda \sim n^{-\alpha/(\alpha+1)}\) and an excess risk proportional to \(n^{-\alpha/(\alpha+1)}\). This type of decay is typical of <a href="https://en.wikipedia.org/wiki/Sobolev_space">Sobolev spaces</a>.</li><li><em>Exponential decays</em>: If \(\lambda_i \leqslant {C}e^{-\alpha i}\), for some \(\alpha &gt;0\), we have $$ {\rm tr} \big[ \Sigma ( \Sigma + \lambda I)^{-1} \big]  \leqslant \sum_{i=0}^\infty \frac{{C}e^{-\alpha i}}{  \lambda + {C}e^{-\alpha i}} \leqslant \int_{0}^\infty \frac{{C}e^{-\alpha t}}{ \lambda + {C}e^{-\alpha t}}dt.$$ With the change of variable \(u = e^{-\alpha t}\), we get an upper bound $$\int_{0}^1 \frac{C}{\alpha}\frac{1}{ \lambda + {C}u}du = \frac{1}{\alpha}\big[ \log(\lambda + C) \ – \log (\lambda) \big] = \frac{1}{\alpha} \log \big( 1+\frac{C}{\lambda} \big).$$ We can then balance bias and variance with \(\lambda \sim 1/n \) and an excess risk proportional to \((\log n) / n \), which is very close to the usual parametric (finite-dimensional) rate in \(O(1/n)\). We will see an example of this phenomenon for the Gaussian kernel.</li></ul>



<p class="justify-text">In order to analyze the generalization capabilities, we consider a measure \(d \mu\) on \(\mathcal{X}\), and the following (non-centered) <em>covariance operator</em> defined above as $$\mathbb{E} \big[ \varphi(x) \otimes \varphi(x) \big],$$ which is now an self-adjoint operator from \(\mathcal{H}\) to \(\mathcal{H}\) with a finite trace. The traditional empirical estimator \(\hat\Sigma = \frac{1}{n} \sum_{i=1}^n \varphi(x_i) \otimes \varphi(x_i)\), whose eigenvalues are the same as the eigenvalues of \(1/n\) times the \(n \times n\) kernel matrix of pairwise kernel evaluations (see simulation below).</p>



<p class="justify-text"><strong>Characterizing eigenfunctions.</strong> If \((g_k)\) is the eigenbasis associated to the eigenfunctions of \(\Sigma\), then it has to be an orthogonal family that span the entire space \(\mathcal{H}\) and such that \(\Sigma g_k = \lambda_k g_k\). Applying it to \(\varphi(y) = K(\cdot,y)\), we get $$ \langle K(\cdot,y), \Sigma g_k \rangle_{\mathcal{H}} = \mathbb{E} \big[ K(x,y) g_k(x) \big] = \lambda_k \langle g_k, \varphi(y)\rangle_\mathcal{H} =  \lambda_k g_k(y),$$ which implies that the functions also have to be eigenfunctions of the self-adjoint so-called <em>integral operator</em> \(T\) defined on \(L_2(d\mu)\) as \(T f(y) = \int_{\mathcal{X}} K(x,y) f(y) d\mu(y)\). Below, we will check this property. Note that this other notion of integral operator (defined on \(L_2(d\mu)\) and not in \(\mathcal{H}\)), which has the same eigenvalues and eigenfunctions, is important to deal with mis-specified models (see [9]). Note that the eigenfunctions \(g_k\) are orthogonal for both dot-products in \(L_2(d\mu)\) and \(\mathcal{H}\), but that the normalization to unit norm differs. If \(\| g_k \|_{L_2(d\mu)}=1\) for all \(k \geqslant 0\), then we have \( \| g_k \|^2_\mathcal{H}=  \lambda_k^{-1} \langle g_k, \Sigma g_k \rangle_\mathcal{H} = \lambda_k^{-1}\mathbb{E} [ g_k(x)^2] =\lambda_k^{-1}\) , and thus, \(\| \lambda_k^{1/2} g_k \|_{\mathcal{H}}=1\), and we have the kernel expansion from an orthonormal basis of \(\mathcal{H}\): $$K(x,y) = \sum_{k=0}^\infty\lambda_k g_k(x) g_k(y),$$ which will lead to a new proof for Mehler formula.</p>



<h2>Orthonormal basis for the Gaussian kernel</h2>



<p class="justify-text">Hermite polynomials naturally lead to orthonormal basis of some reproducing kernel Hilbert spaces (RKHS). For simplicity, I will focus on one-dimensional problems, but this extends to higher dimension. </p>



<p class="justify-text"><strong>Translation-invariant kernels.</strong> We consider a function \(q: \mathbb{R} \to \mathbb{R}\) which is integrable, with <a href="https://en.wikipedia.org/wiki/Fourier_transform">Fourier transform</a> (note the different normalization than before) which is defined for all \(\omega \in \mathbb{R}\) because of the integrability: $$\hat{q}(\omega) = \int_{\mathbb{R}} q(x) e^{-i \omega x} dx.$$ We consider the kernel $$K(x,y) = q(x-y).$$ It can be check that as soon as  \(\hat{q}(\omega) \in \mathbb{R}_+\)  for all \(\omega \in \mathbb{R}\), then the kernel \(K\) is positive-definite.</p>



<p class="justify-text">For a translation-invariant kernel, we can write using the inverse Fourier transform formula: $$K(x,y) = q(x-y) = \frac{1}{2\pi} \int_{\mathbb{R}} \hat{q}(\omega) e^{i \omega ( x- y)} d \omega = \int_{\mathbb{R}} \varphi_\omega(x)^* \varphi_\omega(y) d \omega,$$ with \(\varphi_\omega(x) = \sqrt{\hat{q}(\omega) / (2\pi) } e^{i\omega x}\). Intuitively, for a function \(f: \mathbb{R} \to \mathbb{R}\), with \(\displaystyle f(x) = \frac{1}{2\pi} \int_{\mathbb{R}} \hat{f}(\omega)e^{i\omega x} d\omega = \int_{\mathbb{R}} \frac{\hat{f}(\omega)  }{\sqrt{2 \pi \hat{q}(\omega)}}\varphi_\omega(x) d\omega\), which is a “dot-product” between the family \((\varphi_\omega(x))_\omega\) and \(\Big( \frac{\hat{f}(\omega)  }{\sqrt{2 \pi \hat{q}(\omega)}} \Big)_\omega\), the squared norm \(\| f\|_{\mathcal{H}}^2\) is equal to the corresponding “squared norm” of \(\Big( \frac{\hat{f}(\omega)  }{\sqrt{2 \pi \hat{q}(\omega)}}\Big)_\omega\), and we thus have $$ \| f\|_{\mathcal{H}}^2 = \int_{\mathbb{R}} \Big| \frac{\hat{f}(\omega)  }{\sqrt{2 \pi \hat{q}(\omega)}} \Big|^2 d\omega =  \frac{1}{2\pi} \int_{\mathbb{R}} \frac{ | \hat{f}(\omega) |^2}{\hat{q}(\omega)} d\omega,$$ where \(\hat{f}\) is the Fourier transform of \(f\). While the derivation above is not rigorous, the last expression is.</p>



<p class="justify-text">In this section, I will focus on the Gaussian kernel defined as \(K(x,y) = q(x-y) =  \exp \big( – \alpha ( x- y )^2 \big)\), for which \(\displaystyle \hat{q}(\omega)= \sqrt{\frac{\pi}{\alpha}} \exp\big( – \frac{\omega^2}{4 \alpha} \big)\).</p>



<p class="justify-text">Given that \(\displaystyle \frac{1}{\hat{q}(\omega)} = \sqrt{\frac{\alpha}{\pi}} \exp\big(  \frac{\omega^2}{4 \alpha} \big)= \sqrt{\frac{\alpha}{\pi}} \sum_{k=0}^\infty  \frac{\omega^{2k}}{(4 \alpha)^k k!} \), the penalty \(\|f\|_\mathcal{H}^2\) is a linear combination of squared \(L_2\)-norm of \(\omega^k \hat{f}(\omega)\), which is the squared \(L_2\)-norm of the \(k\)-th derivative of \(f\). Thus, functions in the RKHS are infinitely differentiable, and thus very smooth (this implies that to have the fast rate \((\log n) / n \) above, the optimal regression function has to be very smooth).</p>



<p class="justify-text"><strong>Orthonormal basis of the RKHS</strong>. As seen in Eq. (4), an expansion in an infinite sum is necessary to obtain an orthonormal basis. We have: $$K(x,y) = e^{-\alpha x^2} e^{-\alpha y^2} e^{2 \alpha x y} = e^{-\alpha x^2} e^{-\alpha y^2} \sum_{k=0}^\infty \frac{ (2\alpha)^k}{k!} x^k y^k.$$ Because of Eq. (4), with \(g_k(x) = \sqrt{ \frac{(2\alpha)^k}{k!}} x^k \exp \big( – \alpha x^2 \big)\), we have a good candidate for an orthonornal basis. Let us check that this is the case. Note that the expansion above alone cannot be used as a proof that \((g_k)\) is an orthonormal basis of \(\mathcal{H}\).</p>



<p class="justify-text">Given the function \(f_k(x) = x^k \exp \big( – \alpha x^2 \big)\), we can compute its Fourier transform as $$ \hat{f}_k(\omega) = i^{-k} ( 4 \alpha)^{-k/2} \sqrt{\frac{\pi}{\alpha}} H_k \Big( \frac{\omega}{\sqrt{4 \alpha}} \Big) \exp\big( – \frac{\omega^2}{4 \alpha} \big) .$$ Indeed, we have, from Rodrigues’ formula, $$H_k \Big( \frac{\omega}{\sqrt{4 \alpha}} \Big) \exp\big( – \frac{\omega^2}{4 \alpha} \big) =(-1)^k (4 \alpha)^{k/2} \frac{d^k}{d \omega^k}\big[ \exp\big( – \frac{\omega^2}{4 \alpha} \big) \big],$$ and thus its inverse Fourier transform is equal to \((ix)^k\) times the one of \((-1)^k (4 \alpha)^{k/2} \exp\big( – \frac{\omega^2}{4 \alpha} \big)\), which is thus equal to \((-i)^k (4 \alpha)^{k/2} \sqrt{ \alpha / \pi }e^{-\alpha x^2} \), which leads to the Fourier transform formula above.</p>



<p class="justify-text">We can now compute the RKHS dot products, to show how to obtain the orthonormal basis described in [11]. This leads to $$ \langle f_k, f_\ell \rangle = \frac{1}{2\pi} \sqrt{\frac{\pi}{\alpha}} ( 4 \alpha)^{-k/2}( 4 \alpha)^{-\ell/2}  \int_{\mathbb{R}} H_k \Big( \frac{\omega}{\sqrt{4 \alpha}} \Big) H_\ell \Big( \frac{\omega}{\sqrt{4 \alpha}} \Big) \exp\big( – \frac{\omega^2}{4 \alpha} \big)  d\omega,$$ which leads to, with a change of variable $$ \langle f_k, f_\ell \rangle = \frac{1}{2\pi} \sqrt{\frac{\pi}{\alpha}} ( 4 \alpha)^{-k/2}( 4 \alpha)^{-\ell/2} \sqrt{4 \alpha} \int_{\mathbb{R}} H_k (u) H_\ell (u)  \exp(-u^2) du,$$ which is equal to zero if \(k \neq \ell\), and equal to \(\frac{1}{2\pi} \sqrt{\frac{\pi}{\alpha}} ( 4 \alpha)^{-k} \sqrt{4 \alpha} \sqrt{\pi} 2^k k!   = ( 2 \alpha)^{-k} k!\) if \(k = \ell\). Thus the sequence \((f_k)\) is an orthogonal basis of the RKHS, and the sequence \((g_k)\) defined as \(g_k(x) = \sqrt{ \frac{(2\alpha)^k}{k!}} f_k(x)\) is an orthonormal basis of the RKHS, from which, using the expansion as in Eq. (4), we recover the expansion: $$K(x,y) = \sum_{k=0}^\infty g_k(x) g_k(y) = e^{-\alpha x^2} e^{-\alpha y^2} \sum_{k=0}^\infty \frac{ (2\alpha)^k}{k!} x^k y^k.$$</p>



<p class="justify-text">This expansion can be used to approximate the Gaussian kernel by finite-dimensional explicit feature spaces, by just keeping the first basis elements (see an application to optimal transport in [<a href="https://arxiv.org/pdf/1810.10046">12</a>], with an improved behavior using an adaptive low-rank approximation through the Nyström method in [<a href="https://papers.nips.cc/paper/8693-massively-scalable-sinkhorn-distances-via-the-nystrom-method.pdf">13</a>]).</p>



<h2>Eigenfunctions for the Gaussian kernels</h2>



<p class="justify-text">In order to obtain explicit formulas for the eigenvalues of the covariance operator, we need more than a mere orthonormal basis, namely an eigenbasis.</p>



<p class="justify-text">An orthogonal basis will now be constructed with arguably better properties as it is also an orthonormal basis for both the RKHS and \(L_2(d\mu)\) for a Gaussian measure, that diagonalizes the integral operator associated to this probability measure, as well as the covariance operator.</p>



<p class="justify-text">As seen above, we simply need an orthogonal family \((f_k)_{k \geqslant 0}\), such that given a distribution \(d\mu\),  \((f_k)_{k \geqslant 0}\) is a family in \(L_2(d\mu)\) such that $$\int_{\mathbb{R}} f_k(x) K(x,y) d\mu(x) = \lambda_k f_k(y), \tag{5}$$ for eigenvalues \((\lambda_k)\). In the next paragraph, we will do exactly this for the Gaussian kernel \(K(x,y) = e^{-\alpha (x-y)^2}\) for \(\alpha = \frac{\rho}{1- \rho^2}\) for some \(\rho \in (0,1)\); this particular parameterization in \(\rho\) is to make the formulas below not (too) complicated.</p>



<p class="justify-text">With \(f_k(x) = \frac{1}{\sqrt{N_k}} H_k(x) \exp \Big( – \frac{\rho}{1+\rho} x^2 \Big)\), where \(N_k = {2^k k!} \sqrt{ \frac{1-\rho}{1+\rho}}\), then \((f_k)_{k \geqslant 0}\) is an <em>orthonormal</em> basis for \(L_2(d\mu)\) for \(d\mu\) the Gaussian distribution with mean zero and variance \(\frac{1}{2} \frac{1+\rho}{1-\rho}\) (this is a direct consequence of the orthogonality property of Hermite polynomials).</p>



<p class="justify-text">Moreover, the moment of the Hermite polynomial in Eq. (3) exactly leads to Eq. (5) for the chosen kernel and \(\lambda_k = (1-\rho) \rho^k\). Since the eigenvalues sum to one, and the trace of \(\Sigma\) is equal to one (as a consequence of \(K(x,x)=1\)), the family \((f_k)\) has to be a basis of \(\mathcal{H}\).</p>



<p>From properties of the eigenbasis, since \((f_k)\) is an orthonormal eigenbasis of \(L_2(d\mu)\) and the eigenvalues are \(\lambda_k = (1-\rho)\rho^k\),  we get: $$ K(x,y) = \exp \Big( – \frac{\rho}{1- \rho^2} (x-y)^2\Big) = \sum_{k=0}^\infty (1-\rho)\rho^k f_k(x) f_k(y),$$ which is exactly the Mehler formula, and thus we obtain an alternative proof.</p>



<p class="justify-text">We then get an explicit basis and the exponential decay of eigenvalues, which was first outlined by [2]. See an application to the estimation of the Poincaré constant in [<a href="https://hal.archives-ouvertes.fr/hal-02327453v1/document">14</a>] (probably a topic for another post in a few months).</p>



<p class="justify-text"><strong>Experiments.</strong> In order to showcase the exact eigenvalues of the expectation \(\Sigma\) (for the correct combination of Gaussian kernel and Gaussian distribution), we compare the eigenvalues with the ones of the empirical covariance operator \(\hat\Sigma\), for various values of the number of observations. We see that as \(n\) increases, the empirical eigenvalues match the exact ones for higher \(k\).</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-full is-resized"><img alt="" class="wp-image-4889" height="307" src="https://francisbach.com/wp-content/uploads/2020/10/gaussian_kernel-1.gif" width="363"/>Eigenvalues of the covariance operator \(\Sigma\) (“expectation”) compared to the ones of the empirical covariance operator \(\hat\Sigma\), averaged over 20 replications (“empirical”), for several values of \(n\).</figure></div>



<h2>Conclusion</h2>



<p class="justify-text">In this post, I only presented applications of Hermite polynomials to the Gaussian kernel, but these polynomials appear in many other areas of applied mathematics, for other types of kernels within machine learning such as dot-product kernels [3], in random matrix theory (see <a href="https://terrytao.wordpress.com/2011/02/20/topics-in-random-matrix-theory/">here</a>), in statistics for <a href="https://en.wikipedia.org/wiki/Edgeworth_series">Edgeworth expansions</a>, and of course for <a href="https://en.wikipedia.org/wiki/Gauss%E2%80%93Hermite_quadrature">Gauss-Hermite quadrature</a>.</p>



<p class="justify-text"><strong>Acknowledgements</strong>. I would like to thank Loucas Pillaud-Vivien and Alessandro Rudi for proofreading this blog post and making good clarifying suggestions.</p>



<h2>References</h2>



<p class="justify-text">[1] George Neville Watson. <a href="https://academic.oup.com/jlms/article-pdf/s1-8/3/194/2363185/s1-8-3-194.pdf">Notes on Generating Functions of Polynomials: (2) Hermite Polynomials</a>. <em>Journal of the London Mathematical Soc</em>iety, 8, 194-199, 1933.<br/>[2] Huaiyu Zhu, Christopher K. I. Williams, Richard Rohwer, and Michal Morciniec. <a href="https://publications.aston.ac.uk/id/eprint/38366/1/NCRG_97_011.pdf">Gaussian regression and optimal finite dimensional linear models</a>. In <em>Neural Networks and Machine Learning</em>. Springer-Verlag, 1998.<br/>[3] A. Daniely, R. Frostig, and Y. Singer. <a href="https://papers.nips.cc/paper/6427-toward-deeper-understanding-of-neural-networks-the-power-of-initialization-and-a-dual-view-on-expressivity.pdf">Toward deeper understanding of neural networks: The power of initialization and a dual view on expressivity</a>. In Advances In Neural Information Processing Systems, 2016.<br/>[4] Gabor Szegö. <em>Orthogonal polynomials</em>. American Mathematical Society, 1939.<br/>[5] Grace Wahba. <a href="https://epubs.siam.org/doi/book/10.1137/1.9781611970128">Spline models for observational data</a>. Society for Industrial and Applied Mathematics, 1990.<br/>[6] Bernhard Schölkopf, Alexander J. Smola. <a href="https://mitpress.mit.edu/books/learning-kernels">Learning with kernels: support vector machines, regularization, optimization, and beyond</a>. MIT Press, 2002.<br/>[7] John Shawe-Taylor, Nello Cristianini. <em>Kernel methods for pattern analysis</em>. Cambridge University Press, 2004.<br/>[8] Andrea Caponnetto, Ernesto De Vito. <a href="https://link.springer.com/content/pdf/10.1007/s10208-006-0196-8.pdf">Optimal rates for the regularized least-squares algorithm</a>. Foundations of Computational Mathematics 7.3: 331-368, 2007.<br/>[9] Jerome Friedman, Trevor Hastie, and Robert Tibshirani. <a href="http://web.stanford.edu/~hastie/Papers/ESLII.pdf">The elements of statistical learning</a>. Vol. 1. No. 10. Springer series in statistics, 2001.<br/>[10] Trevor Hastie and Robert Tibshirani. <em>Generalized Additive Models</em>. Chapman &amp; Hall, 1990.<br/>[11] Ingo Steinwart, Don Hush, and Clint Scovel. <a href="http://[PDF] ieee.org">An explicit description of the reproducing kernel Hilbert spaces of Gaussian RBF kernels</a>. <em>IEEE Transactions on Information Theory</em>, 52.10:4635-4643, 2006.<br/>[12] Jason Altschuler, Francis Bach, Alessandro Rudi, Jonathan Niles-Weed. <a href="https://arxiv.org/pdf/1810.10046">Approximating the quadratic transportation metric in near-linear time</a>. Technical report arXiv:1810.10046, 2018.<br/>[13] Jason Altschuler, Francis Bach, Alessandro Rudi, Jonathan Niles-Weed. <a href="https://papers.nips.cc/paper/8693-massively-scalable-sinkhorn-distances-via-the-nystrom-method.pdf">Massively scalable Sinkhorn distances via the Nyström method</a>. <em>Advances in Neural Information Processing Systems (NeurIPS)</em>, 2019.<br/>[14] Loucas Pillaud-Vivien, Francis Bach, Tony Lelièvre, Alessandro Rudi, Gabriel Stoltz. <a href="https://hal.archives-ouvertes.fr/hal-02327453v1/document">Statistical Estimation of the Poincaré constant and Application to Sampling Multimodal Distributions</a>. <em>Proceedings of the International Conference on Artificial Intelligence and Statistics (AISTATS),</em> 2020.<br/>[15] Nachman Aronszajn. <a href="https://www.ams.org/journals/tran/1950-068-03/S0002-9947-1950-0051437-7/S0002-9947-1950-0051437-7.pdf">Theory of Reproducing Kernels</a>. <em>Transactions of the American Mathematical Society</em>, 68(3): 337–404, 1950.</p>



<h2>Proof of properties of Hermite polynomials</h2>



<p class="justify-text">In this small appendix, I give “simple” proofs (that sometimes require knowledge of <a href="https://en.wikipedia.org/wiki/Complex_analysis">complex analysis</a>) to the properties presented above.</p>



<p class="justify-text"><strong>Generating function.</strong> We have, using <a href="https://en.wikipedia.org/wiki/Residue_theorem">residue theory</a>, $$H_k(x)=(-1)^k e^{x^2} \frac{d^k}{d x^k}\big[ e^{-x^2} \big] = (-1)^k \frac{k!}{2i\pi} e^{x^2} \oint_\gamma \frac{e^{-z^2}}{(z-x)^{k+1}}dz, $$ where \(\gamma\) is a contour in the complex plane around \(x\). This leads to, for any \(t\) (here, we ignore on purpose the summability issues, for more details, see [4, Section 5.5]): $$ \sum_{k=0}^\infty \frac{t^k}{k!} H_k(x) =  \frac{1}{2i\pi} e^{x^2} \oint_\gamma \frac{e^{-z^2}}{z-x} \sum_{k=0}^\infty \frac{t^k} {(x-z)^{k}}dz, $$ which can be simplified using the sum of the geometric series, leading to $$\frac{1}{2i\pi} e^{x^2} \oint_\gamma \frac{e^{-z^2}}{z-x} \frac{z-x}{z-x- t} dz =  \frac{1}{2i\pi} e^{x^2} \oint_\gamma \frac{e^{-z^2}} {z-x- t} dz.$$ Using the first-order residue at \(x+t\). This is thus equal to \(e^{x^2-(t+x)^2} = e^{-t^2 + 2tx}\), which is exactly the generating function statement from Eq. (2).</p>



<p class="justify-text"><strong>Orthogonality for Gaussian distribution.</strong> We can prove through integration by parts, but there is a nicer proof through the generating function. Indeed, with $$ a_{k \ell} = \int_{-\infty}^{+\infty} e^{-x^2} H_k(x) H_\ell(x) dx, $$ for \(k, \ell \geqslant 0\), we get $$\sum_{k,\ell = 0}^\infty a_{k \ell} \frac{t^k u^\ell}{k! \ell!} = \int_{-\infty}^{+\infty}e^{-x^2}\Big(  \sum_{k,\ell = 0}^\infty a_{k \ell} \frac{t^k u^\ell}{k! \ell!}  H_k(x) H_\ell(x) \Big) dx.$$ Using the generating function, this leads to $$\sum_{k,\ell = 0}^\infty a_{k \ell} \frac{t^k u^\ell}{k! \ell!} =  \int_{-\infty}^{+\infty} e^{-x^2 + 2xu-u^2 + 2xt – t^2} dx= e^{2uv} \int_{-\infty}^{+\infty} e^{-(x-u-v)^2}dx, $$ which can be computed explicitly using normalization constants of the Gaussian distribution, as \( \sqrt{\pi} e^{2uv} = \sqrt{\pi} \sum_{k=0}^\infty \frac{ (2  u v)^k}{k!},\) leading to all desired orthogonality relationships using the uniqueness of all coefficients for factors \(t^k u^\ell\).</p>



<p class="justify-text"><strong>Recurrence relationship.</strong> Taking the derivative of the generating function with respect to \(t\), one gets \( \displaystyle (2x-2t) e^{2tx-t^2} = \sum_{k=0}^\infty \frac{t^{k-1}}{(k-1)!} H_k(x),\) which is equal to (using again the generating function) \(\displaystyle \sum_{k=0}^\infty \frac{t^{k}}{k!} 2x H_k(x) \ – \sum_{n=0}^\infty \frac{t^{k+1}}{k!} 2 H_k(x).\) By equating the coefficients for all powers of \(t\), this leads to the desired recursion in Eq. (1).</p>



<p class="justify-text"><strong>Fourier transform.</strong> Again using the generating function, written $$ e^{-x^2/2 + 2xt – t^2} = \sum_{k=0}^\infty \frac{t^k}{k!} e^{-x^2/2} H_k(x), $$ we can take Fourier transforms and use the fact that the Fourier transform of \(e^{-x^2/2}\) is itself (for the chosen normalization), and then equate coefficients for all powers of \(t\) to conclude (see more details <a href="https://en.wikipedia.org/wiki/Hermite_polynomials#Hermite_functions_as_eigenfunctions_of_the_Fourier_transform">here</a>).</p>



<p class="justify-text"><strong>Expectation for Gaussian distributions.</strong> We finish the appendix by proving Eq. (3). We consider computing for any \(t\), $$\sum_{k=0}^\infty \rho^k \frac{t^k}{k!} H_k (y) = e^{2\rho t y – \rho^2 t^2},$$ using the generating function from Eq. (2). We then compute $$A=\int_{-\infty}^\infty \exp\Big( – \frac{(x-\rho y)^2}{1-\rho^2} \Big) \sum_{k=0}^\infty \frac{t^k}{k!} H_k(x) dx = \int_{-\infty}^\infty \exp\Big( – \frac{(x-\rho y)^2}{1-\rho^2} \Big) \exp( 2tx – t^2) dx.$$ We then use \( \frac{(x-\rho y)^2}{1-\rho^2} – 2tx + t^2 = \frac{x^2}{1-\rho^2}  – \frac{2x[ t(1-\rho^2) + \rho y]}{1-\rho^2}  + t^2 + \frac{\rho^2 y^2}{1-\rho^2}\), leading to $$A = \sqrt{\pi} \sqrt{1-\rho^2} \exp\Big( -t^2 – \frac{\rho^2 y^2}{1-\rho^2} +(1-\rho^2) \big( t + \frac{\rho y}{1-\rho^2} \big)^2 \Big) = \sqrt{\pi} \sqrt{1-\rho^2} e^{2\rho t y – \rho^2 t^2}.$$ By equating powers of \(t\), this leads to Eq. (3).</p></div>
    </content>
    <updated>2020-10-08T19:33:36Z</updated>
    <published>2020-10-08T19:33:36Z</published>
    <category term="Tools"/>
    <author>
      <name>Francis Bach</name>
    </author>
    <source>
      <id>https://francisbach.com</id>
      <link href="https://francisbach.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://francisbach.com" rel="alternate" type="text/html"/>
      <subtitle>Francis Bach</subtitle>
      <title>Machine Learning Research Blog</title>
      <updated>2020-10-13T14:21:57Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/151</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/151" rel="alternate" type="text/html"/>
    <title>TR20-151 |  Pseudobinomiality of the Sticky Random Walk | 

	Venkatesan Guruswami, 

	Vinayak Kumar</title>
    <summary>Random walks on expanders are a central and versatile tool in pseudorandomness.  If an arbitrary half of the vertices of an expander graph are marked, known Chernoff bounds for expander walks imply that the number $M$ of marked vertices visited in a long $n$-step random walk strongly concentrates around the expected $n/2$ value. Surprisingly, it was recently shown that the parity of $M$ also has exponentially small bias.

Is there a common unification of these results? What other statistics about $M$ resemble the binomial distribution (the Hamming weight of a random $n$-bit string)? To gain insight into such questions, we analyze a simpler model called the sticky random walk. This model is a natural stepping stone towards understanding expander random walks, and we also show that it is a necessary step. The sticky random walk starts with a random bit and then each subsequent bit independently equals the previous bit with probability $(1+\lambda)/2$. Here $\lambda$ is the proxy for the expander's (second largest) eigenvalue.
    
Using Krawtchouk expansion of functions, we derive several probabilistic results about the sticky random walk. We show an asymptotically tight $\Theta(\lambda)$ bound on the total variation distance between the (Hamming weight of the) sticky walk and the binomial distribution. We prove that the correlation between the majority and parity bit of the sticky walk is bounded by $O(n^{-1/4})$. This lends hope to unifying Chernoff bounds and parity concentration, as well as establishing other interesting statistical properties, of expander random walks.</summary>
    <updated>2020-10-08T14:03:25Z</updated>
    <published>2020-10-08T14:03:25Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-10-13T14:20:38Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/150</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/150" rel="alternate" type="text/html"/>
    <title>TR20-150 |  Almost-Everywhere Circuit Lower Bounds from Non-Trivial Derandomization | 

	Lijie Chen, 

	Xin Lyu, 

	Ryan Williams</title>
    <summary>In certain complexity-theoretic settings, it is notoriously difficult to prove complexity separations which hold almost everywhere, i.e., for all but finitely many input lengths. For example, a classical open question is whether $\mathrm{NEXP} \subset \mathrm{i.o.-}\mathrm{NP}$; that is, it is open whether nondeterministic exponential time computations can be simulated on infinitely many input lengths by $\mathrm{NP}$ algorithms. This difficulty also applies to Williams' algorithmic method for circuit lower bounds [Williams, J. ACM 2014]. In particular, although [Murray and Williams, STOC 2018] proved $\mathrm{NTIME}[2^{\mathrm{polylog}(n)}] \not\subset \mathrm{ACC}^0$, it has remained an open problem to show that $\mathrm{E}^{\mathrm{NP}}$ ($2^{O(n)}$ time with an $\mathrm{NP}$ oracle) is not contained in $\mathrm{i.o.-}\mathrm{ACC}^0$. 
	
In this paper, we show how many infinitely-often circuit lower bounds proved by the algorithmic method can be adapted to establish almost-everywhere lower bounds. 

- We show there is a function $f \in \mathrm{E}^{\mathrm{NP}}$ such that for all sufficiently large input lengths $n$ and $\varepsilon \leq o(1)$, $f$ cannot be $(1/2+2^{-n^{\varepsilon}})$-approximated by $2^{n^\varepsilon}$-size $\mathrm{ACC}^0$ circuits on inputs of length $n$, improving lower bounds in [Chen and Ren, STOC 2020] and [Viola, ECCC 2020]. 

- We construct rigid matrices in $\mathrm{P}^{\mathrm{NP}}$ for all but finitely many inputs, rather than infinitely often as in [Alman and Chen, FOCS 2019] and [Bhangale et al., FOCS 2020]. 

- We show there are functions in $\mathrm{E}^{\mathrm{NP}}$ requiring constant-error probabilistic degree at least $\Omega(n/\log^2 n)$ for all large enough $n$, improving an infinitely-often separation of [Viola, ECCC 2020].
	
Our key to proving almost-everywhere worst-case lower bounds is a new ``constructive'' proof of an NTIME hierarchy theorem proved by [Fortnow and Santhanam, CCC 2016], where we show for every ``weak'' nondeterminstic algorithm (with smaller running-time and short witness), a ``refuter algorithm'' exists that can construct ``bad'' inputs for the hard language. We use this refuter algorithm to construct an almost-everywhere hard function. To extend our lower bounds to the average case, we prove a new XOR Lemma based on approximate linear sums, and combine it with the PCP-of-proximity applications developed in [Chen and Williams, CCC 2019] and [Chen and Ren, STOC 2020]. As a byproduct of our new XOR Lemma, we obtain a nondeterministic pseudorandom generator for poly-size $\mathrm{ACC}^0$ circuits with seed length $\mathrm{polylog}(n)$, which resolves an open question in [Chen and Ren, STOC 2020].</summary>
    <updated>2020-10-08T13:53:53Z</updated>
    <published>2020-10-08T13:53:53Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-10-13T14:20:38Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-7346788885933681031</id>
    <link href="https://blog.computationalcomplexity.org/feeds/7346788885933681031/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/10/revisiting-continuum-hypothesis.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7346788885933681031" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7346788885933681031" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/10/revisiting-continuum-hypothesis.html" rel="alternate" type="text/html"/>
    <title>Revisiting the Continuum Hypothesis</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I have been thinking about CH lately for two reasons</p><p>1) I reread the article</p><p>Hilbert's First Problem: The Continuum Hypothesis by Donald Martin from <b>Proceedings of Symposia </b> i<b>n Pure Mathematics: Mathematical developments arising from Hilbert Problems</b>. 1976. (For a book review of the symposia and, <b>The Honor Class</b>, also about Hilbert's problems, see <a href="https://www.cs.umd.edu/users/gasarch/bookrev/44-4.pdf">here</a>.)</p><p>The article takes the point of view that CH CAN have an answer. He discusses large cardinals (why assuming they exist is plausible, but alas, that assumption does not seem to resolve CH) and Projective Det.  (why assuming it is true is plausible, but alas, that assumption does not seem to resolve CH).</p><p>(A set A \subseteq {0,1}^omega is DETERMINED if either Alice or Bob has a winning strategy in the following non-fun game: they alternate picking bits a_1, b_1, a_2, b_2, ... with Alice going first. If a_1 b_1 a_2 b_2... IS IN A then Alice wins, IF NOT then Bob wins. Martin showed that all Borel sets are determined. Proj Det is the statement that all projections of Borel sets are determined. AD is the axiom that ALL sets A are determined. It contradicts AC.)</p><p>But what really inspired this post is the last paragraph:</p><p><i>Throughout the latter part of my discussion, I have been assuming a naive and uncritical attitude towards CH. While this <b>is</b> in fact my attitude, I by no means wish to dismiss the opposite viewpoint.  Those that argue that the concept of set is not sufficiently clear to fix the truth-value of CH have a position that is at present difficult to assail. As long as no new axiom is found which decides CH, their case will continue to grow stronger, and our assertions that the meaning of CH is clear will sound more and more empty.</i></p><p>2) Scott Aaronson mentioned in a blog post (see <a href="https://www.scottaaronson.com/blog/?p=4962">here</a>) that  he has read and understood the proof that CH is independent of set theory.</p><p>SO, this seemed like a good time to revisit thoughts on CH.</p><p> I took a very short poll, just two people, about CH: Stephen Fenner (in a perfect world he would be a set theorists) and Scott Aaronson (having JUST read the proof that CH is ind.  he has thought about it recently).</p><p>Here are some thoughts of theirs and mine</p><p>1) All three of us are Platonists with regard to the Naturals (I was surprised to find recently that there are people who are not!) but not with regard to the reals.  So we would be OKAY with having CH have no answer.</p><p>2) All three of us  agree that it would be nice if SOME axiom was both</p><p>a) Intuitively appealing or aesthetically appealing ,  and</p><p>b) resolved CH.</p><p>I always thought that (a) would be the hard part-- or at least getting everyone (not sure who we are talking about) to AGREE on a new axiom. But even getting an axiom to resolve CH seems hard.  Large cardinals don't seem to do it, and various forms of Determinacy don't seem to do it.</p><p>Scott reminded me of Freiling's Axiom of Symmetry (see <a href="https://en.wikipedia.org/wiki/Freiling%27s_axiom_of_symmetry">here</a>) which IS intuitive and DOES resolve CH (its false) though there are problems with it--- a minor variant   of it contradicts AC (I am QUITE FINE with that since AC implies Banach-Tarski which Darling says shows `Math is broken'.)</p><p>Stephen recalled some of Hugh Woodin's opinions of CH, but Hugh seems to have changed his mind from NOT(CH): 2^{aleph_0} = aleph_2, to CH:  2^{aleph_0} = aleph_1.(See <a href="https://www.jstor.org/stable/24569622?seq=1#metadata_info_tab_contents">here</a>.)</p><p>3) All three of would be okay with V=L, though note that this would put many set theorists out of work. All the math that applies to the real world would still be intact.  I wonder if in an alternative history the reaction to Russell's paradox would be a formulation of set theory where V=L. We would KNOW that CH is true, KNOW that AC is true. We would know a lot about L but less about forcing.</p><p>4) Which Geometry is true: Euclidian, Riemannian, others? This is now regarded as a silly question: Right Tool, Right Job! If you build a bridge use Euclid. If you are doing astronomy use Riemann. Might Set Theory go the same way? It would be AWESOME if Scott Aaronson found some quantum thing where assuming 2^{aleph_0} = aleph_2 was the right way to model it.</p><p>5) If I was more plugged into the set theory community I might do a poll of set theorists, about CH. Actually, someone sort-of already has. Penelope Maddy has two excellent and readable articles where she studies what set theorists believe and why.</p><p><b>Believing The Axioms I</b>: <a href="http://www.cs.umd.edu/~gasarch/BLOGPAPERS/belaxioms1.pdf">here</a></p><p><b>Believing The Axioms II</b>: <a href="http://www.cs.umd.edu/~gasarch/BLOGPAPERS/belaxioms2.pdf">here</a></p><p>Those articles were written in 1988. I wonder if they need an update.</p><p><br/></p><p><br/></p><p><br/></p><p><br/></p><p><br/></p><p><br/></p><p><br/></p><p><br/></p><p><br/></p><p><br/></p><p><br/></p><p><br/></p></div>
    </content>
    <updated>2020-10-08T13:52:00Z</updated>
    <published>2020-10-08T13:52:00Z</published>
    <author>
      <name>gasarch</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03004932739846901628</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2020-10-13T14:11:32Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>http://ptreview.sublinear.info/?p=1420</id>
    <link href="https://ptreview.sublinear.info/?p=1420" rel="alternate" type="text/html"/>
    <title>News for September 2020</title>
    <summary>Apologies dear readers for the late posting. The beginning of the school year is always frenzied, and the pandemic has only added to that frenzy. We have an exciting September, with four papers on graph property testing, one two papers on distribution testing, and one paper that connects both topics. (Ed: we normally scan through […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Apologies dear readers for the late posting. The beginning of the school year is always frenzied, and the pandemic has only added to that frenzy. We have an exciting September, with four papers on graph property testing, <s>one</s> two papers on distribution testing, and one paper that connects both topics.</p>



<p><em>(Ed: we normally scan through ECCC and arXiv, but are happy to post about papers that appear elsewhere. Thanks to the reader who pointed out a relevant COLT 2020 paper.)</em></p>



<p><strong>Estimation of Graph Isomorphism Distance in the Query World</strong> by Sourav Chakraborty, Arijit Ghosh, Gopinath Mishra, and Sayantan Sen (<a href="https://eccc.weizmann.ac.il/report/2020/135/">ECCC</a>). Graph isomorphism is about as fundamental as it gets, and this papers studies approximating the graph isomorphism distance for dense graphs. There is a known graph \(G_k\) (with \(n\) vertices). The algorithm is given query access to an input graph \(G_u\) and needs to approximate the number of edge inserts/deletes required to make the graphs isomorphic. This is the tolerant testing version; the property testing version is known to be doable in \(\widetilde{O}(\sqrt{n})\) queries (<a href="https://epubs.siam.org/doi/abs/10.1137/070680795?journalCode=smjcat">Matsliah-Fischer</a>). The main insight of this paper is to relate the tolerant testing complexity to a distribution testing problem. Consider distributions over the \(\{0,1\}^n\) defined by multisets of \(n\) hypercube points. Our aim is to estimate the earthmover distance between a known distribution and an unknown distribution. Interestingly, the query model is different: one can sample the underlying multisets <em>without</em> replacement. It turns out that the optimal complexity of this problem is (upto polylog factors) is the same as the optimal complexity of tolerant testing of graph isomorphism. A direct corollary is that the isomorphism distance can be approximated upto additive \(\epsilon n^2\) using \(\widetilde{O}(n)\) samples. This equivalence also gives an alternate proof for lower bounds for property testing graph isomorphism.</p>



<p><strong>Robustly Self-Ordered Graphs: Constructions and Applications to Property Testing </strong>by Oded Goldreich and Avi Wigderson (<a href="https://eccc.weizmann.ac.il/report/2020/149/">ECCC</a>). Let’s start from the application. The aim is to prove the following property testing lower bounds for the bounded-degree graph setting: an exponential separation between tolerant and vanilla testing, and finding an efficiently decidable property (in polynomial time) that cannot be property tested in sublinear time. For binary strings, results of this form are known. Can these be “ported” to the bounded-degree graph world? Can we construct graphs such that adjacency queries reduce to bit queries in strings? Naturally, one can simply represent the adjacency list as a string and treat graph queries as bit queries. But the problem is that of isomorphisms: different bit strings could represent the same graph and therefore, the different bit strings must have the same status with respect to the underlying property. The key insight in this paper is to introduce <em>robustly self-ordered graph</em>s, as a tool to port bit string property testing lower bounds to bounded-degree graphs. Such graphs essentially have a unique (identity) automorphism, even after a few edge insert/deletes. The actual definition is more technical, but that is the essence. The main result is an explicit construction of such graphs, from which the lower bound can be ported directly through a convenient lemma.</p>



<p><strong>Modifying a Graph’s Degree Sequence and the Testablity of Degree Sequence Properties </strong>by Lior Gishboliner (<a href="https://arxiv.org/pdf/2009.12697.pdf">arXiv</a>). A sequence of numbers \(D = (d_1, d_2, \ldots, d_n)\) is graphic if there exists an undirected graph on \(n\) vertices whose degrees are precisely the numbers of the sequence. Graphical sequences have been characterized by classic results of <a href="https://en.wikipedia.org/wiki/Erd%C5%91s%E2%80%93Gallai_theorem">Erdös-Gállai</a> and <a href="https://en.wikipedia.org/wiki/Havel%E2%80%93Hakimi_algorithm">Havel-Hakimi</a>. This paper first proves the following theorem. Suppose a graphic sequence \(D’\) has \(l_1\)-distance at most \(\delta\) from the degree sequence \(D\) of a graph \(G\). Then, there exists a graph \(G’\) with degree sequence \(D’\) such that the (dense graph) distance between \(G\) and \(G’\) is \(O(\sqrt{\delta})\). This theorem is used to prove an interesting property testing result. Let \(\mathcal{D}\) be a subset of graphic sequences that are closed under permutation. Let \(\mathcal{G}\) be the set of graphs that have a degree sequence in \(\mathcal{D}\). Then \(\mathcal{G}\) can be tested in \(poly(1/\epsilon)\) queries.</p>



<p><strong>Sampling an Edge Uniformly in Sublinear Time</strong> by Jakub Têtek (<a href="https://arxiv.org/pdf/2009.11178.pdf">arXiv</a>). In the general model for sublinear algorithms on graphs, an important choice is whether one allows uniform random edge queries. A natural question is whether such queries can simulated efficiently, using only random vertex, degree, and neighbor queries. This problem appears somewhat implicitly in previous sublinear subgraph counting algorithms, and <a href="http://drops.dagstuhl.de/opus/volltexte/2019/10628/pdf/LIPIcs-ICALP-2019-52.pdf">Eden-Ron-Rosenbaum</a> study it explicitly. They prove that one can sample from an \(\epsilon\)-approximate uniform distribution (over edges) using \(O(n/\sqrt{\epsilon m})\) samples. The problem of sampling from exactly the uniform distribution is left open. Until this paper. The main result shows that by modifying the Eden-Ron-Rosenbaum algorithm parameters, one can generate edge samples from an \(\epsilon\)-approximate uniform distribution using \(O((n/\sqrt{m})\log \epsilon^{-1})\) samples. The exact uniform distribution is achieved by setting \(\epsilon = 1/n\), to get a sample complexity of \(O((n\log n)/\sqrt{m})\).</p>



<p><strong>Faster Property Testers in a Variation of the Bounded Degree Model </strong>by Isolde Adler and Polly Fahey (<a href="https://arxiv.org/pdf/2009.07770.pdf">arXiv</a>). The setting of bounded-degree graph property testing naturally extends to bounded-degree relational databases, which can be thought of as “directed” hypergraphs. This is an interesting new direction of research, that combines property testing with database theory (see <a href="https://core.ac.uk/download/pdf/157699299.pdf">Adler-Harwath</a> and <a href="https://dl.acm.org/doi/10.1145/3294052.3319679">Chen-Yoshida</a>). One of the main contributions of this work is to consider another notion of distance: edge and vertex inserts/deletes. This is a natural extension, and we can now compare distances between graphs/databases with different numbers of vertices. The main result is that, under this notion of distance, a large class of properties can be tested in constant running time on databases with bounded degree and treewidth. Specifically, any property expressible in Counting Monadic Second-Order Logic (CMSO) can be tested in constant time. Previous results by Alder-Harwath showed that such properties can be tested (under the standard distance notion) in constant queries, but polylogarithmic time. </p>



<p><strong>Optimal Testing of Discrete Distributions with High Probability</strong> by Ilias Diakonikolas, Themis Gouleakis, Daniel M. Kane, John Peebles, and Eric Price (<a href="https://arxiv.org/abs/2009.06540">arXiv</a>, <a href="https://eccc.weizmann.ac.il/report/2020/140/">ECCC</a>). The focus of this paper is distribution testing in the “high probability” regime, where we wish the error of the tester to be \(&lt; \delta\). Typically, most results just get an error of at most \(1/3\), from which standard probabilistic boosting would tack on an extra \(O(\log 1/\delta)\) factor. In standard TCS settings, one doesn’t focus on optimizing this dependence, but in statistics, there is significant focus on the optimal sample complexity. And indeed, for practical applications, it is crucial to have sharp bounds on the right number of samples required for hypothesis testing. The paper also argues that getting the optimal sample complexity requires new algorithms, even for uniformity testing. There are optimal results given for closeness and independence testing. The optimal sample complexity only pays a multiplicative factor of \(\log^{1/3} (1/\delta)\) or \(\log^{1/2}(1/\delta)\) over the optimal bound for constant error (with other additive terms depending on \(\log(1/\delta)\)).</p>



<p><strong>Bessel Smoothing and Multi-Distribution Property Estimation</strong> by Yi Hao and Ping Li (<a href="http://proceedings.mlr.press/v125/hao20a.html">COLT 2020</a>). Let us consider some standard (tolerant) distribution testing questions, phrases as approximation algorithms. Given sample access to two distributions \(p\) and \(q\) over \([n]\), we may wish to estimate the \(l_1\)-distance, \(l_2\)-distance, relative entropy, etc. between these distributions. One can phrases this problem abstractly as estimating \(\sum_{i \in [n]} f(p_i, q_i)\), where \(f\) is some explicit function. This papers shows that for any 1-Lipschitz function \(f\) that satisfies some “regularity” property, the sum \(\sum_{i \in [n]} f(p_i, q_i)\) can be \(\epsilon\)-approximated with \(O(\epsilon^{-3}n/\sqrt{\log n})\) samples (apologies to the authors to replacing their \(k\) with the more familiar \(n\) for our readers). Thus, we can get sublinear sampling complexity for a very general class of estimation problems. Moreover, this was actually the simplest setting consider in the paper. One can deal with such functions of \(d\) distributions, not just two distributions. One of the corollaries of the theorems is a sublinear tolerant tester for the property of being a mixture of distributions.</p></div>
    </content>
    <updated>2020-10-07T23:20:27Z</updated>
    <published>2020-10-07T23:20:27Z</published>
    <category term="Monthly digest"/>
    <author>
      <name>Seshadhri</name>
    </author>
    <source>
      <id>https://ptreview.sublinear.info</id>
      <link href="https://ptreview.sublinear.info/?feed=rss2" rel="self" type="application/atom+xml"/>
      <link href="https://ptreview.sublinear.info" rel="alternate" type="text/html"/>
      <subtitle>The latest in property testing and sublinear time algorithms</subtitle>
      <title>Property Testing Review</title>
      <updated>2020-10-12T23:50:08Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://tcsplus.wordpress.com/?p=488</id>
    <link href="https://tcsplus.wordpress.com/2020/10/07/tcs-talk-wednesday-october-14-jayadev-acharya-cornell-university/" rel="alternate" type="text/html"/>
    <title>TCS+ talk: Wednesday, October 14 — Jayadev Acharya, Cornell University</title>
    <summary>The next TCS+ talk will take place this coming Wednesday, October 14th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). Jayadev Acharya from Cornell University will speak about “Distributed Statistical Inference under Local Information Constraints ” (abstract below). You can reserve a spot as an individual or a […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The next TCS+ talk will take place this coming Wednesday, October 14th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). <strong>Jayadev Acharya</strong> from Cornell University will speak about  “<em>Distributed Statistical Inference under Local Information Constraints</em> ” (abstract below).</p>



<p>You can reserve a spot as an individual or a group to join us live by signing up on <a href="https://sites.google.com/site/plustcs/livetalk/live-seat-reservation">the online form</a>. Due to security concerns, <em>registration is required</em> to attend the interactive talk. (The link to the YouTube livestream will also be posted <a href="https://sites.google.com/site/plustcs/livetalk">on our  website</a> on the day of the talk, so people who did not sign up will still be able to  watch the talk live.) As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/site/plustcs/suggest">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/site/plustcs/">the website</a>.</p>



<blockquote class="wp-block-quote"><p>Abstract: We consider statistical inference tasks in a distributed setting where access to data samples is subjected to strict “local constraints,” through a unified framework that captures communication limitations and (local) privacy constraints as special cases. We study estimation (learning) and goodness-of-fit (testing) for both discrete and high-dimensional distributions. Our goal is to understand how the sample complexity increases under the information constraints.<br/><br/>In this talk we will provide an overview of this field and a sample of some of our results. We will discuss the role of (public) randomness  and interactivity in information-constrained inference, and make a case for thinking about randomness and interactivity as resources.<br/><br/>The work is part of a long-term ongoing collaboration with Clément Canonne (IBM Research) and Himanshu Tyagi (IISc), and includes works done with Cody Freitag (Cornell), Yanjun Han (Stanford), Yuhan Liu (Cornell), and Ziteng Sun (Cornell). </p></blockquote></div>
    </content>
    <updated>2020-10-07T20:11:36Z</updated>
    <published>2020-10-07T20:11:36Z</published>
    <category term="Announcements"/>
    <author>
      <name>plustcs</name>
    </author>
    <source>
      <id>https://tcsplus.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://tcsplus.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://tcsplus.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://tcsplus.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://tcsplus.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A carbon-free dissemination of ideas across the globe.</subtitle>
      <title>TCS+</title>
      <updated>2020-10-13T14:21:48Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://differentialprivacy.org/neurips2020/</id>
    <link href="https://differentialprivacy.org/neurips2020/" rel="alternate" type="text/html"/>
    <title>Conference Digest - NeurIPS 2020</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="https://neurips.cc/Conferences/2020">NeurIPS 2020</a> is the biggest conference on machine learning, with tons of content on differential privacy in many different forms.
We were able to find two workshops, a competition, and 31 papers. 
This was just going off the preliminary <a href="https://nips.cc/Conferences/2020/AcceptedPapersInitial">accepted papers list</a>, so it’s possible that we might have missed some papers on differential privacy – please let us know!
We will update this post later, once all the conference material (papers and videos) are publicly available.</p>

<h2 id="workshops">Workshops</h2>

<ul>
  <li>
    <p><a href="https://ppml-workshop.github.io/">Privacy Preserving Machine Learning - PriML and PPML Joint Edition</a></p>
  </li>
  <li>
    <p><a href="http://icfl.cc/SpicyFL/2020">International Workshop on Scalability, Privacy, and Security in Federated Learning (SpicyFL 2020)</a></p>
  </li>
</ul>

<h2 id="competitions">Competitions</h2>

<ul>
  <li><a href="https://www.vanderschaar-lab.com/privacy-challenge/">Hide-and-Seek Privacy Challenge: Synthetic Data Generation vs. Patient Re-identification with Clinical Time-series Data</a></li>
</ul>

<h2 id="papers">Papers</h2>

<ul>
  <li>
    <p><a href="https://arxiv.org/abs/2007.05665">A Computational Separation between Private Learning and Online Learning</a><br/>
<a href="https://cs-people.bu.edu/mbun/">Mark Bun</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2004.05975">Adversarially Robust Streaming Algorithms via Differential Privacy</a><br/>
<a href="http://u.cs.biu.ac.il/~avinatan/">Avinatan Hasidim</a>, <a href="http://www.cs.tau.ac.il/~haimk/">Haim Kaplan</a>, <a href="https://www.tau.ac.il/~mansour/">Yishay Mansour</a>, <a href="https://research.google/people/YossiMatias/">Yossi Matias</a>, <a href="https://www.uri.co.il/">Uri Stemmer</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2006.07709">Auditing Differentially Private Machine Learning: How Private is Private SGD?</a><br/>
<a href="https://www.ccis.northeastern.edu/home/jagielski/">Matthew Jagielski</a>, <a href="https://www.ccs.neu.edu/home/jullman/">Jonathan Ullman</a>, <a href="https://www.ccs.neu.edu/home/alina/">Alina Oprea</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2007.11707">Breaking the Communication-Privacy-Accuracy Trilemma</a><br/>
<a href="https://web.stanford.edu/~wnchen/index.html">Wei-Ning Chen</a>, <a href="https://kairouzp.github.io/">Peter Kairouz</a>, <a href="https://web.stanford.edu/~aozgur/">Ayfer Ozgur</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2006.06618">CoinPress: Practical Private Mean and Covariance Estimation</a><br/>
<a href="https://sravb.github.io/">Sourav Biswas</a>, <a href="https://yihedong.me/">Yihe Dong</a>, <a href="http://www.gautamkamath.com/">Gautam Kamath</a>, <a href="https://www.ccs.neu.edu/home/jullman/">Jonathan Ullman</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2008.08007">Differentially Private Clustering: Tight Approximation Ratios</a><br/>
<a href="https://sites.google.com/view/badihghazi/home">Badih Ghazi</a>, <a href="https://sites.google.com/site/ravik53/">Ravi Kumar</a>, <a href="https://pasin30055.github.io/">Pasin Manurangsi</a></p>
  </li>
  <li>
    <p><a href="http://web.mit.edu/dubeya/www/files/dp_linucb_20.pdf">Differentially-Private Federated Contextual Bandits</a><br/>
<a href="http://web.mit.edu/dubeya/www/">Abhimanyu Dubey</a>, <a href="https://www.media.mit.edu/people/sandy/overview/">Alex Pentland</a></p>
  </li>
  <li>
    <p>Faster Differentially Private Samplers via Rényi Divergence Analysis of Discretized Langevin MCMC<br/>
<a href="https://people.eecs.berkeley.edu/~arunganesh/">Arun Ganesh</a>, <a href="http://kunaltalwar.org/">Kunal Talwar</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2006.08265">GS-WGAN: A Gradient-Sanitized Approach for Learning Differentially Private Generators</a><br/>
<a href="https://cispa.de/en/people/dingfan.chen">Dingfan Chen</a>, <a href="https://tribhuvanesh.github.io/">Tribhuvanesh Orekondy</a>, <a href="https://cispa.saarland/group/fritz/">Mario Fritz</a></p>
  </li>
  <li>
    <p>Improving Sparse Vector Technique with Renyi Differential Privacy<br/>
<a href="https://jeremy43.github.io/">Yuqing Zhu</a>, <a href="https://sites.cs.ucsb.edu/~yuxiangw/">Yu-Xiang Wang</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2005.10630">Instance-optimality in differential privacy via approximate inverse sensitivity mechanisms</a><br/>
<a href="http://web.stanford.edu/~asi/">Hilal Asi</a>, <a href="https://web.stanford.edu/~jduchi/">John Duchi</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2007.13660">Learning discrete distributions: user vs item-level privacy</a><br/>
<a href="https://www.ece.cornell.edu/research/grad-students/yuhan-liu">Yuhan Liu</a>, <a href="http://theertha.info/">Ananda Theertha Suresh</a>, <a href="http://felixyu.org/">Felix Xinnan Yu</a>, <a href="https://research.google/people/author11555/">Sanjiv Kumar</a>, <a href="https://research.google/people/author125/">Michael D Riley</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2008.00331">Learning from Mixtures of Private and Public Populations</a><br/>
<a href="https://sites.google.com/view/rbassily">Raef Bassily</a>, <a href="http://www.cs.technion.ac.il/~shaymrn/">Shay Moran</a>, <a href="http://web.cse.ohio-state.edu/~nandi.10/">Anupama Nandi</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2006.00701">Locally Differentially Private (Contextual) Bandits Learning</a><br/>
<a href="https://scholar.google.com/citations?user=Bw-WdyUAAAAJ">Kai Zheng</a>, <a href="https://tianle.website/">Tianle Cai</a>, <a href="https://www.weiranhuang.com/">Weiran Huang</a>, <a href="http://www.ee.columbia.edu/~zgli/">Zhenguo Li</a>, <a href="http://www.liweiwang-pku.com/">Liwei Wang</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2005.12601">Locally private non-asymptotic testing of discrete distributions is faster using interactive mechanisms</a><br/>
<a href="https://warwick.ac.uk/fac/sci/statistics/staff/academic-research/berrett/">Thomas Berrett</a>, <a href="http://cbutucea.perso.math.cnrs.fr/">Cristina Butucea</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2006.01980">On the Equivalence between Online and Private Learnability beyond Binary Classification</a><br/>
<a href="https://scholar.google.com/citations?user=ajqlbHUAAAAJ">Young Hun Jung</a>, <a href="https://scholar.google.com/citations?user=5xt0ba0AAAAJ&amp;hl=en">Baekjin Kim</a>, <a href="https://ambujtewari.github.io/">Ambuj Tewari</a></p>
  </li>
  <li>
    <p>Optimal Private Median Estimation under Minimal Distributional Assumptions<br/>
<a href="https://tzamos.com/">Christos Tzamos</a>, <a href="http://www.cs.columbia.edu/~emvlatakis/">Emmanouil-Vasileios Vlatakis-Gkaragkounis</a>, <a href="http://www.mit.edu/~izadik/">Ilias Zadik</a></p>
  </li>
  <li>
    <p>Permute-and-Flip: A new mechanism for differentially-private selection<br/>
<a href="https://people.cs.umass.edu/~rmckenna/">Ryan McKenna</a>, <a href="https://people.cs.umass.edu/~sheldon/">Daniel Sheldon</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2007.06605">Privacy Amplification via Random Check-Ins</a><br/>
<a href="https://borjaballe.github.io/">Borja Balle</a>, <a href="https://kairouzp.github.io/">Peter Kairouz</a>, <a href="https://scholar.google.com/citations?user=iKPWydkAAAAJ">Brendan McMahan</a>, <a href="https://scholar.google.com/citations?user=iKPWydkAAAAJ">Om Thakkar</a>, <a href="https://athakurta.squarespace.com/">Abhradeep Thakurta</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1905.11947">Private Identity Testing for High-Dimensional Distributions</a><br/>
<a href="http://www.cs.columbia.edu/~ccanonne/">Clement Canonne</a>, <a href="http://www.gautamkamath.com/">Gautam Kamath</a>, <a href="https://audramarymcmillan.wixsite.com/mysite">Audra McMillan</a>, <a href="https://www.ccs.neu.edu/home/jullman/">Jonathan Ullman</a>, <a href="https://www.ccs.neu.edu/home/lydiazak/">Lydia Zakynthinou</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2004.07839">Private Learning of Halfspaces: Simplifying the Construction and Reducing the Sample Complexity</a><br/>
<a href="http://www.cs.tau.ac.il/~haimk/">Haim Kaplan</a>, <a href="https://www.tau.ac.il/~mansour/">Yishay Mansour</a>, <a href="https://www.uri.co.il/">Uri Stemmer</a>, <a href="https://dblp.org/pid/146/9658.html">Eliad Tsfadia</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2006.10129">Smoothed Analysis of Online and Differentially Private Learning</a><br/>
<a href="https://www.cs.cornell.edu/~nika/">Nika Haghtalab</a>, <a href="http://timroughgarden.org/">Tim Roughgarden</a>, <a href="https://ashettyv.github.io/">Abhishek Shetty</a></p>
  </li>
  <li>
    <p>Smoothly Bounding User Contributions in Differential Privacy<br/>
<a href="https://www.epasto.org/">Alessandro Epasto</a>, <a href="https://research.google/people/MohammadMahdian/">Mohammad Mahdian</a>, <a href="https://sites.google.com/view/jieming-mao">Jieming Mao</a>, <a href="https://people.csail.mit.edu/mirrokni/Welcome.html">Vahab Mirrokni</a>, <a href="https://www.linkedin.com/in/lijie-ren-57162633/">Lijie Ren</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2006.06914">Stability of Stochastic Gradient Descent on Nonsmooth Convex Losses</a><br/>
<a href="https://sites.google.com/view/rbassily">Raef Bassily</a>, <a href="http://vtaly.net/">Vitaly Feldman</a>, <a href="https://sites.google.com/view/cguzman/">Cristobal Guzman</a>, <a href="http://kunaltalwar.org/">Kunal Talwar</a></p>
  </li>
  <li>
    <p>Synthetic Data Generators – Sequential and Private<br/>
<a href="https://research.google/people/OlivierBousquet/">Olivier Bousquet</a>, <a href="https://www.tau.ac.il/~rlivni/">Roi Livni</a>, <a href="http://www.cs.technion.ac.il/~shaymrn/">Shay Moran</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2004.00010">The Discrete Gaussian for Differential Privacy</a><br/>
<a href="http://www.cs.columbia.edu/~ccanonne/">Clement Canonne</a>, <a href="http://www.gautamkamath.com/">Gautam Kamath</a>, <a href="http://www.thomas-steinke.net/">Thomas Steinke</a></p>
  </li>
  <li>
    <p>The Flajolet-Martin Sketch Itself Preserves Differential Privacy: Private Counting with Minimal Space<br/>
<a href="https://cs-people.bu.edu/ads22/">Adam Smith</a>, <a href="https://shs037.github.io/">Shuang Song</a>, <a href="https://athakurta.squarespace.com/">Abhradeep Thakurta</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2006.08598">Towards practical differentially private causal graph discovery</a><br/>
<a href="https://wanglun1996.github.io/">Lun Wang</a>, Qi Pang, <a href="https://people.eecs.berkeley.edu/~dawnsong/">Dawn Song</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2006.15429">Understanding Gradient Clipping in Private SGD: A Geometric Perspective</a><br/>
<a href="https://scholar.google.com/citations?user=M0ki5ZgAAAAJ">Xiangyi Chen</a>, <a href="https://zstevenwu.com/">Steven Wu</a>, <a href="https://people.ece.umn.edu/~mhong/mingyi.html">Mingyi Hong</a></p>
  </li>
</ul></div>
    </summary>
    <updated>2020-10-07T16:30:00Z</updated>
    <published>2020-10-07T16:30:00Z</published>
    <author>
      <name>Gautam Kamath</name>
    </author>
    <source>
      <id>https://differentialprivacy.org</id>
      <link href="https://differentialprivacy.org" rel="alternate" type="text/html"/>
      <link href="https://differentialprivacy.org/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Website for the differential privacy research community</subtitle>
      <title>Differential Privacy</title>
      <updated>2020-10-12T23:50:43Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://dstheory.wordpress.com/?p=63</id>
    <link href="https://dstheory.wordpress.com/2020/10/07/friday-oct-09-alexandr-andoni-from-columbia-university/" rel="alternate" type="text/html"/>
    <title>Friday, Oct 09 — Alexandr Andoni from Columbia University</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">The next Foundations of Data Science virtual talk will take place on Friday, Oct 09th at 10:00 AM Pacific Time (1:00 pm Eastern Time, 18:00 Central European Time, 17:00 UTC).  Alexandr Andoni from Columbia University will speak about “Approximating Edit Distance in Near-Linear Time”. Abstract: Edit distance is a classic measure of similarity between strings, with<a class="more-link" href="https://dstheory.wordpress.com/2020/10/07/friday-oct-09-alexandr-andoni-from-columbia-university/">Continue reading <span class="screen-reader-text">"Friday, Oct 09 — Alexandr Andoni from Columbia University"</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The next Foundations of Data Science virtual talk will take place on Friday, Oct 09th at 10:00 AM Pacific Time (1:00 pm Eastern Time, 18:00 Central European Time, 17:00 UTC).  <strong>Alexandr Andoni </strong>from Columbia University will speak about “<em><strong>Approximating Edit Distance in Near-Linear Time</strong></em>”.</p>



<p><strong>Abstract</strong>: Edit distance is a classic measure of similarity between strings, with applications ranging from computational biology to coding. Computing edit distance is also a classic dynamic programming problem, with a quadratic run-time solution, often taught in the “Intro to Algorithms” classes. Improving this runtime has been a decades-old challenge, now ruled likely-impossible using tools from the modern area of fine-grained complexity. We show how to approximate the edit distance between two strings in near-linear time, up to a constant factor. Our result completes a research direction set forth in the breakthrough paper of [Chakraborty, Das, Goldenberg, Koucky, Saks; FOCS’18], which showed the first constant-factor approximation algorithm with a (strongly) sub-quadratic running time.</p>



<p>Joint work with Negev Shekel Nosatzki, available at<a href="https://arxiv.org/abs/2005.07678"> https://arxiv.org/abs/2005.07678</a>.</p>



<p><a href="https://sites.google.com/view/dstheory" rel="noreferrer noopener" target="_blank">Please register here to join the virtual talk.</a></p>



<p>The series is supported by the <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1934846&amp;HistoricalAwards=false">NSF HDR TRIPODS Grant 1934846</a>.</p></div>
    </content>
    <updated>2020-10-07T15:44:56Z</updated>
    <published>2020-10-07T15:44:56Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>dstheory</name>
    </author>
    <source>
      <id>https://dstheory.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://dstheory.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://dstheory.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://dstheory.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://dstheory.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Foundation of Data Science – Virtual Talk Series</title>
      <updated>2020-10-13T14:21:54Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=17368</id>
    <link href="https://rjlipton.wordpress.com/2020/10/06/knowledge-is-good/" rel="alternate" type="text/html"/>
    <title>Knowledge is Good</title>
    <summary>Science is good too Emil Faber is the pretend founder of the pretend Faber College. The 1978 movie Animal House starts with a close-up of Faber’s statue, which has the inscription, Knowledge Is Good. Today, Ken and I thought we might talk about knowledge, science, mathematics, proofs, and more. The phrase on Faber’s pedestal is […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Science is good too</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<p><a href="https://rjlipton.files.wordpress.com/2020/08/seal.png"><img alt="" class="alignright size-thumbnail wp-image-17660" height="150" src="https://rjlipton.files.wordpress.com/2020/08/seal.png?w=150" width="150"/></a></p>
<p>
Emil Faber is the pretend founder of the pretend Faber College. The 1978 movie <a href="https://en.wikipedia.org/wiki/Animal_House">Animal House</a> starts with a close-up of Faber’s statue, which has the inscription, <b>Knowledge Is Good</b>.</p>
<p>
Today, Ken and I thought we might talk about knowledge, science, mathematics, proofs, and more.<br/>
<span id="more-17368"/></p>
<p>
The phrase on Faber’s pedestal is meant to be a joke, as is the subtitle we added saying the same about science. But there is some truth to both of them. From the cause of climate change to the best response to the current pandemic to sports predictions there is much interest in science. Science is good, indeed.</p>
<p><a href="https://rjlipton.files.wordpress.com/2020/08/faberpedestal.jpg"><img alt="" class="aligncenter size-thumbnail wp-image-17661" height="228" src="https://rjlipton.files.wordpress.com/2020/08/faberpedestal.jpg?w=300" width="300"/></a></p>
<p>
</p><p/><h2> Science </h2><p/>
<p/><p>
What is science and what are methods of creating knowledge via science? There is a whole world on the philosophy of <a href="https://en.wikipedia.org/wiki/Science">science</a>. The central questions are: What is science? What methods are used to create new science? Is science good?—just kidding. </p>
<p>
We are not experts on the philosophy of science. But there seem to be three main ways to create scientific knowledge.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\bullet }"/> <i>Experiments:</i> This is the classic one. Think about the testing of a candidate vaccine to stop the pandemic. </p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\bullet }"/> <i>Computational Experiments:</i> This is relatively new. Think computer simulations of how climate change is effected by the methods of creating energy—for example. wind vs. coal. </p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\bullet }"/> <i>Mathematical Proofs:</i> This is the one we focus on here at GLL. Think proofs that some algorithm works or that there is no algorithm that can work unless… </p>
<p>
</p><p/><h2> Mathematical Proofs </h2><p/>
<p/><p>
We are interested in creating knowledge via proving new theorems. This is how we try to create knowledge. Our science is based not on experiments and not on simulations but mostly on the theorem-proof method. Well not exactly. We do use experiments and simulations. For example, the field of quantum algorithms uses both of these.</p>
<p>
However, math proofs are the basis of complexity theory. This means that we need to create proofs and then check that they are correct. The difficulty of checking a proof is based on who created them: </p>
<ul>
<li>
You did—checking your own work. <p/>
</li><li>
Someone else did—refereeing for a journal. <p/>
</li><li>
Someone in your class did—grading exams. <p/>
</li><li>
Some graduate student did—mentoring. <p/>
</li><li>
Someone on the web who claims a major result like <img alt="{\mathsf{P &lt; NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%3C+NP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\mathsf{P &lt; NP}}"/> did—debugging. <p/>
</li><li>
And so on.
</li></ul>
<p>
</p><p/><h2> My Favorite Checking Method </h2><p/>
<p/><p>
My favorite tool for checking is this trick: Suppose that we have a proof <img alt="{P}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{P}"/> that demonstrates <img alt="{A \implies X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA+%5Cimplies+X%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{A \implies X}"/> is true. Sometimes it is possible to show that there is a proof <img alt="{Q}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BQ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{Q}"/> that proves <img alt="{A \implies Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA+%5Cimplies+Y%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{A \implies Y}"/> where: </p>
<ol>
<li>
The proof <img alt="{Q}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BQ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{Q}"/> is based on changing the claimed proof <img alt="{P}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{P}"/>. <p/>
</li><li>
The proof <img alt="{Q}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BQ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{Q}"/> demonstrates <img alt="{A \implies Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA+%5Cimplies+Y%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{A \implies Y}"/>, and; <p/>
</li><li>
The statement <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{Y}"/> does not follow from <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{A}"/>.
</li></ol>
<p>
One way this commonly arises is when <img alt="{P}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{P}"/> as a proof did not use all of the assumptions in <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{A}"/>. Thus <img alt="{P}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{P}"/> really proves more that <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{X}"/> and it proves <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{Y}"/>. But we note that <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{Y}"/> is not a consequence of <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{A}"/>.</p>
<p>
For example, consider the Riemann hypothesis. Suppose that we claim that we have a proof that 	</p>
<p align="center"><img alt="\displaystyle  \sum_{n=1}^{\infty} \frac{1}{n^{s}} \neq 0 " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_%7Bn%3D1%7D%5E%7B%5Cinfty%7D+%5Cfrac%7B1%7D%7Bn%5E%7Bs%7D%7D+%5Cneq+0+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="\displaystyle  \sum_{n=1}^{\infty} \frac{1}{n^{s}} \neq 0 "/></p>
<p>follows from the usual axioms of math plus <img alt="{\Re(s) &gt; 1/2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CRe%28s%29+%3E+1%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\Re(s) &gt; 1/2}"/>. Sounds great. But suppose this is based on an argument that assumes that 	</p>
<p align="center"><img alt="\displaystyle  \sum_{n=1}^{\infty} \frac{1}{n^{s}} = 0 " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_%7Bn%3D1%7D%5E%7B%5Cinfty%7D+%5Cfrac%7B1%7D%7Bn%5E%7Bs%7D%7D+%3D+0+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="\displaystyle  \sum_{n=1}^{\infty} \frac{1}{n^{s}} = 0 "/></p>
<p>and manipulates the summation, eventually yielding a contradiction, without using the condition <img alt="{\Re(s) &gt; 1/2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CRe%28s%29+%3E+1%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\Re(s) &gt; 1/2}"/>. This is a problem, since there are <img alt="{s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{s}"/> with <img alt="{\Re(s) = 1/2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CRe%28s%29+%3D+1%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\Re(s) = 1/2}"/> so that the sum is zero. This is an example of the above method of checking. </p>
<p>
</p><p/><h2> A New Checking Method </h2><p/>
<p/><p>
From time to time claims are made of resolutions to famous conjectures. Think <img alt="{\mathsf{P = NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%3D+NP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\mathsf{P = NP}}"/>. These claims have all been wrong to date. So most researchers are reluctant to take time to check any new claims. Why would you take the effort to try and find the bug that is likely there? </p>
<p>
I wonder if there could be a method that is based on competition. For concreteness, suppose Alice and Bob are two researchers who both claim a resolution to the <img alt="{\mathsf{P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\mathsf{P}}"/> versus <img alt="{\mathsf{NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\mathsf{NP}}"/> problem. Alice has a lower bound argument that <img alt="{\mathsf{P &lt; NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%3C+NP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\mathsf{P &lt; NP}}"/> and Bob has an upper bound that <img alt="{\mathsf{P = NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%3D+NP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\mathsf{P = NP}}"/>. Could we have them play a “game”? </p>
<blockquote><p><b> </b> <em> Give their papers to each other. Have them try to find a flaw in each other’s paper. </em>
</p></blockquote>
<p/><p>
They are highly motivated. Could we argue that if they cannot find any flaw then we would be slightly more motivated to look at the papers? </p>
<p>
This might work even if they both claim <img alt="{\mathsf{P = NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%3D+NP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\mathsf{P = NP}}"/>. Ken and I, personally, have had more claims of <img alt="{\mathsf{P = NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%3D+NP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\mathsf{P = NP}}"/> brought to our attention. Even in this case they would be highly motivated: the awards, the prizes, the praise will go to the one who is correct. </p>
<p>
</p><p/><h2> Possible Extensions </h2><p/>
<p/><p>
One difference in our situation from classic empirical science is the nature of gaps in knowledge. For example, one of the big current controversies in physics is over the existence of <a href="https://en.wikipedia.org/wiki/Dark_matter">dark matter</a>. The Wikipedia article we just linked seems to date mostly to years around 2012 when dark matter was more widely accepted than <a href="https://medium.com/futuresin/doubting-dark-matter-f3e400c7dcd7">strikes</a> us <a href="https://www.scientificamerican.com/article/is-dark-matter-real/">today</a> (see also <a href="http://backreaction.blogspot.com/2019/10/dark-matter-nightmare-what-if-we-just.html">this</a> and <a href="http://backreaction.blogspot.com/2020/03/are-dark-energy-and-dark-matter.html">this</a>). There are cases where two competing theories are incompatible yet the available data do not suffice to find a fault in either. </p>
<p>
Whereas, with claimed proofs of incompatible statements, such as <img alt="{\mathsf{P &lt; NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%3C+NP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\mathsf{P &lt; NP}}"/> and <img alt="{\mathsf{P = NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%3D+NP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\mathsf{P = NP}}"/>, at least one must have a demonstrable error. The statements themselves may have barriers all the way up to undecidability, but that does not matter to judging the proffered proofs.</p>
<p>
The method may be more applicable in life sciences where the gap is gathering sufficient field or lab observations. For a topical example, consider claims about the risk or safety of human gatherings amid the pandemic. One extreme is represented by the extraordinary <a href="http://ftp.iza.org/dp13670.pdf">claim</a>, which is <a href="https://www.wired.com/story/how-much-do-crowds-contribute-to-covid-its-complicated/">evidently</a> quite <a href="https://bgr.com/2020/09/14/sturgis-bike-rally-paper-impact-on-covid-19-coronavirus-cases/">excessive</a>, that the Sturgis motorcycle rally in August led to over 250,000 Covid-19 cases. The other extreme would be analyses used to justify gatherings with minimal precautions. The extremes cannot coexist. The means to arbitrate between them are available in principle but require costly social effort for contact tracing and testing as well as resolving mathematical issues between epidemiological models.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
What do you think of our new checking method? Should it be more widely employed for evaluating claims and hypotheses?</p>
<p/></font></font></div>
    </content>
    <updated>2020-10-07T04:54:16Z</updated>
    <published>2020-10-07T04:54:16Z</published>
    <category term="All Posts"/>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="Open Problems"/>
    <category term="P=NP"/>
    <category term="Proofs"/>
    <category term="Results"/>
    <category term="Animal House"/>
    <category term="claims"/>
    <category term="Emil Faber"/>
    <category term="Logic"/>
    <category term="science"/>
    <category term="science and society"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2020-10-13T14:20:48Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://minimizingregret.wordpress.com/?p=389</id>
    <link href="https://minimizingregret.wordpress.com/2020/10/06/blackwell-approachability-meets-online-convex-optimization/" rel="alternate" type="text/html"/>
    <title>Blackwell approachability meets Online Convex Optimization</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">David Blackwell was still roaming the corridors of UC Berkeley’s stat department during my postdoc years, circa 2009. Jake Abernethy, Sasha Rakhlin, Peter Bartlett and myself were discussing his results, and his seminal contributions to prediction theory were already well known. At that time, still the early days of online convex optimization, we were contemplating … <a class="more-link" href="https://minimizingregret.wordpress.com/2020/10/06/blackwell-approachability-meets-online-convex-optimization/">Continue reading <span class="screen-reader-text">Blackwell approachability meets Online Convex Optimization</span> <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>David Blackwell was still roaming the corridors of UC Berkeley’s stat department during my postdoc years, circa 2009. Jake Abernethy, Sasha Rakhlin, Peter Bartlett and myself were discussing his results, and his seminal contributions to prediction theory were already well known.</p>



<figure class="wp-block-image size-large is-resized"><img alt="" class="wp-image-395" height="183" src="https://minimizingregret.files.wordpress.com/2020/10/download.jpeg?w=275" width="275"/>David Blackwell</figure>



<figure class="wp-block-image size-large is-resized"><img alt="" class="wp-image-397" height="200" src="https://minimizingregret.files.wordpress.com/2020/10/16-figure11-1-1.png?w=662" width="204"/>James Hannan</figure>



<p>At that time, still the early days of online convex optimization, we were contemplating everything from adaptive gradient methods to bandit convex optimization. Blackwell’s famed approachability theorem was looming in the background, considered to be one of the strongest theorems in the ML-theorists toolkit. </p>



<p>I’ve recently added a new draft chapter to to V2.0 of <a href="http://ocobook.cs.princeton.edu">Introduction to Online Convex Optimization</a>, about the connection between OCO and Blackwell approachability: they are algorithmically equivalent! More precisely, an efficient algorithm for approachability gives rise to an efficient algorithm for OCO with sublinear regret, and vice versa. </p>



<p>Details are in the chapter draft, and  I recommend this music for reading it: (the song is called “together we won despite everything”, dedicated to music and science)</p>



<figure class="wp-block-embed is-type-rich is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"><div class="wp-block-embed__wrapper">
<div class="jetpack-video-wrapper"/>
</div></figure>



<p>.</p>



<p/></div>
    </content>
    <updated>2020-10-06T00:11:46Z</updated>
    <published>2020-10-06T00:11:46Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Elad Hazan</name>
    </author>
    <source>
      <id>https://minimizingregret.wordpress.com</id>
      <logo>https://minimizingregret.files.wordpress.com/2017/08/cropped-pu1.png?w=32</logo>
      <link href="https://minimizingregret.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://minimizingregret.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://minimizingregret.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://minimizingregret.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Google Princeton AI and Hazan Lab @ Princeton University</subtitle>
      <title>Minimizing Regret</title>
      <updated>2020-10-13T14:21:37Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://theorydish.blog/?p=1794</id>
    <link href="https://theorydish.blog/2020/10/05/forc-2021-is-on-its-way/" rel="alternate" type="text/html"/>
    <title>FORC 2021 Is on Its Way</title>
    <summary>After a powerful launch at 2021, the second meeting of The Symposium on Foundations of Responsible Computing (FORC) is on its way. The call for papers for FORC 2021 is out, with a wonderful PC, headed by Katrina Ligett. Please consider sending your strong submissions down our way.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>After <a href="https://theorydish.blog/2020/03/30/forc-2020-going-strong-going-virtual/">a powerful launch</a> at 2021, the second meeting of  <a href="https://responsiblecomputing.org/">The Symposium on Foundations of Responsible Computing (FORC)</a> is on its way. The <a href="https://responsiblecomputing.org/forc-2021-call-for-papers/">call for papers</a> for FORC 2021 is out, with a wonderful PC, headed by <a href="https://www.cs.huji.ac.il/~katrina/">Katrina Ligett</a>. Please consider sending your strong submissions down our way.</p></div>
    </content>
    <updated>2020-10-05T15:00:47Z</updated>
    <published>2020-10-05T15:00:47Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Omer Reingold</name>
    </author>
    <source>
      <id>https://theorydish.blog</id>
      <logo>https://theorydish.files.wordpress.com/2017/03/cropped-nightdish1.jpg?w=32</logo>
      <link href="https://theorydish.blog/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://theorydish.blog" rel="alternate" type="text/html"/>
      <link href="https://theorydish.blog/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://theorydish.blog/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Stanford's CS Theory Research Blog</subtitle>
      <title>Theory Dish</title>
      <updated>2020-10-13T14:21:58Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-2360146425812493374</id>
    <link href="https://blog.computationalcomplexity.org/feeds/2360146425812493374/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/10/mip-re-redux.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/2360146425812493374" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/2360146425812493374" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/10/mip-re-redux.html" rel="alternate" type="text/html"/>
    <title>MIP* = RE Redux</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Everything pre-covid seems at least five years ago to me, so it's hard to believe that <a href="https://arxiv.org/abs/2001.04383">MIP* = RE</a> is a 2020 result. To remind you, consider the model where we have two powerful provers put in separate rooms where they can't communicate (think suspects of a crime put in separate interrogation rooms). An computationally efficient verifier can ask them questions based on random coins. Thirty years ago, Laszlo Babai, Carsten Lund and myself <a href="https://doi.org/10.1007/BF01200056">showed</a> that every language in nondeterministic exponential time has proofs in this model.<div><br/></div><div>Now suppose the provers have entangled quantum bits. This question has a long history that culminates in the <a href="https://arxiv.org/abs/2001.04383">MIP* = RE paper</a> earlier this year by Zhengfeng Ji, Anand Natarajan, Thomas Vidick, John Wright, Henry Yuen showing that every proof of any length can be proven in this model. Incredible!</div><div><br/></div><div>But wait, why is there a new version 2 dated last week? Turns out the MIP* = RE paper relied on a 2016 paper by Vidick which was later discovered to have a bug. No worries, as the authors of the MIP* = RE paper got around this issue by a <a href="https://arxiv.org/abs/2009.12982">quantum analysis</a> of a low-degree test from that old Babai-Fortnow-Lund paper.</div><div><br/></div><div>Vidick's <a href="https://mycqstate.wordpress.com/2020/09/29/it-happens-to-everyonebut-its-not-fun/">blog post</a> explains it all, including the angst of a major result falling apart temporarily. He has <a href="https://blog.computationalcomplexity.org/2017/01/babai-strikes-back.html">good</a> <a href="http://nautil.us/issue/24/error/how-maths-most-famous-proof-nearly-broke">company</a>. Glad it all worked out. </div></div>
    </content>
    <updated>2020-10-05T12:50:00Z</updated>
    <published>2020-10-05T12:50:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2020-10-13T14:11:32Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4979</id>
    <link href="https://www.scottaaronson.com/blog/?p=4979" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4979#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4979" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">On the destruction of America’s best high school</title>
    <summary xml:lang="en-US">[C]hildren with special abilities and skills need to be nourished and encouraged. They are a national treasure. Challenging programs for the “gifted” are sometimes decried as “elitism.” Why aren’t intensive practice sessions for varsity football, baseball, and basketball players and interschool competition deemed elitism? After all, only the most gifted athletes participate. There is a […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><blockquote class="wp-block-quote"><p>[C]hildren with special abilities and skills need to be nourished and encouraged.  They are a national treasure.  Challenging programs for the “gifted” are sometimes decried as “elitism.”  Why aren’t intensive practice sessions for varsity football, baseball, and basketball players and interschool competition deemed elitism?  After all, only the most gifted athletes participate.  There is a self-defeating double standard at work here, nationwide.<br/>—Carl Sagan, <a href="https://www.amazon.com/Demon-Haunted-World-Science-Candle-Dark/dp/0345409469"><em>The Demon-Haunted World</em></a> (1996)</p></blockquote>



<p>I’d like you to feel about the <a href="https://quillette.com/2020/09/23/rallying-to-protect-admissions-standards-at-americas-best-public-high-school/">impending destruction</a> of Virginia’s <a href="https://en.wikipedia.org/wiki/Thomas_Jefferson_High_School_for_Science_and_Technology">Thomas Jefferson High School for Science and Technology</a>, the same way you might’ve felt when the Taliban threatened to blow up the <a href="https://en.wikipedia.org/wiki/Buddhas_of_Bamyan">Bamyan Buddhas</a>, and then days later actually did blow them up.  Or the way you felt when human negligence caused wildfires that incinerated half the koalas in Australia, or turned the San Francisco skyline into an orange hellscape.  For that matter, the same way most of us felt the day Trump was elected.  I’d like you to feel in the bottom of your stomach the <em>avoidability</em>, and yet the finality, of the loss.</p>



<p>For thousands of kids in the DC area, especially first- or second-generation immigrants, TJHS represented a lifeline.  Score high enough on an entrance exam—something hard but<em> totally within your control</em>—and you could attend a school where, instead of the other kids either tormenting or ignoring you, they might teach you Lisp or the surreal number system.  Where you could learn humility instead of humiliation.</p>



<p>When I visited TJHS back in 2012 to give a quantum computing talk, I toured the campus, chatted with students, fielded their questions, and thought: so <em>this</em> is the teenagerhood—the ironically <em>normal</em> teenagerhood—that I was denied by living someplace else.  I found myself wishing that a hundred more TJHS’s, large and small, would sprout up across the country.  I felt like if I could further that goal then, though the universe return to rubble, my life would’ve had a purpose.</p>



<p>Instead, of course, our sorry country is destroying the few such schools that exist.  <a href="https://www.nytimes.com/2019/06/24/nyregion/specialized-schools-nyc-deblasio.html">Stuyvesant and Bronx Science</a> in New York, and the Liberal Arts and Science Academy here in Austin, are also under mortal threat right now.  The numerous parents who moved, who arranged their lives, specifically so that these schools might later be available for “high-risk” kids were suckered.</p>



<p>Assuming you haven’t just emerged from 30 years in a Tibetan cave, you presumably know why this is happening.  As the <em>Washington Post</em>‘s Jay Matthews <a href="https://www.washingtonpost.com/local/education/americas-top-sat-school-makes-another-disputed-attempt-at-diversity/2020/10/03/1bef3db2-0261-11eb-897d-3a6201d6643f_story.html?utm_campaign=wp_post_most&amp;utm_medium=email&amp;utm_source=newsletter&amp;wpisrc=nl_most&amp;carta-url=https%3A%2F%2Fs2.washingtonpost.com%2Fcar-ln-tr%2F2bf01fe%2F5f78a5d19d2fda0efb3d8031%2F5974cf76ade4e21a8497eeb1%2F42%2F62%2F2b179e7390f19bdba6f66f626ab37646">explains</a>, the Fairfax County School Board is “embarrassed” to have a school that, despite all its outreach attempts, remains only 5% Black and Latino—even though, crucially, the school <em>also</em> happens to be only 19% White (it’s now ~75% Asian).</p>



<p>You might ask: so then why doesn’t TJHS just institute affirmative action, like almost every university does?  It seems there’s an extremely interesting answer: <a href="https://www.washingtonian.com/2017/04/26/is-the-no-1-high-school-in-america-thomas-jefferson-fairfax-discrimination/">they did in the 1990s</a>, and Black and Hispanic enrollment surged.  But then the verdicts of court cases, brought by right-wing groups, made the school district fear that they’d be open to lawsuits if they continued with affirmative action, so they dropped it.  Now the boomerang has returned, and the School Board has decided on a more drastic remedy: namely, to eliminate the TJHS entrance exam entirely, and replace it by a lottery for anyone whose GPA exceeds 3.5.</p>



<p>The trouble is, TJHS without an entrance exam is no longer TJHS.  More likely than not, such a place would simply converge to become another of the thousands of schools across the US where success is based on sports, networking, and popularity.  And if by some miracle it avoided that fate, <em>still</em> it would no longer be available to most of the kids who‘d most need it.</p>



<p>So yes, the district is <strong>embarrassed</strong>—note that the<em> Washington Post</em> writer explains it as if that’s the most obvious, natural reaction in the world—to host a school that’s regularly ranked #1 in the US, with the highest average SATs and a distinguished list of alumni.  To avoid this embarrassment, the solution is (in effect) to burn the school to the ground.</p>



<p>In a world-historic irony, the main effect of this “solution” will be to <strong>drastically limit the number of Asian students, while drastically <em>increasing</em> (!!!) the number of White students</strong>.  The proportion of Black and Hispanic students is projected to increase a bit but remain small.  Let me say that one more time: in practice, TJHS’s move from a standardized test to a lottery will be<strong> overwhelmingly pro-White, anti-Asian, and anti-immigrant</strong>; only as a much smaller effect will it be pro-underrepresented-minority.</p>



<p>In spite of covid and everything else going on, hundreds of students and parents have been <a href="https://quillette.com/2020/09/23/rallying-to-protect-admissions-standards-at-americas-best-public-high-school/">protesting in front of TJHS</a> to try to prevent the school’s tragic and pointless destruction.  But it sounds like TJHS’s fate might be sealed.  The school board tolerated excellence for 35 more years than it wanted to; now its patience is at an end.</p>



<p>Some will say: sure, the end of TJHS is unfortunate, Scott, but why do you let this stuff <em>weigh</em> on you so heavily?  This is merely another instance of friendly fire, of good people fighting the just war against racism, and in <em>one</em> case hitting a target that, yeah, OK, probably should’ve been spared.  On reflection, though, I can accept that only insofar as I accept that it was “friendly fire” when Bolsheviks targeted the kulaks, or (much more comically, less importantly, and less successfully) when Arthur Chu, Amanda Marcotte, and a thousand other woke-ists targeted me.  With friendly fire like that, who needs enemy fire?</p>



<p>If you care about the gifted Black and Hispanic kids of Fairfax County, then like me, you should demand a change in the law to allow the reinstatement of affirmative action for them.  You should acknowledge that the issue lies there and not with TJHS itself.</p>



<p>I don’t see how you reach the point of understanding all the facts and still wanting to dismantle TJHS, over the desperate pleas of the students and parents, without a decent helping of <em>resentment</em> toward the kind of student who flourishes there—without a wish to see those uppity,  “fresh off the boat” Chinese and Indian grinds get dragged down to where they belong.  And if you tell me that such magnet programs need to end even though you yourself once benefitted from them—well, isn’t that more contemptible still?  Aren’t you knowingly burning a bridge you crossed so that a younger generation can’t follow you, basically reassuring the popular crowd that if they’ll only accept <em>you</em>, then there won’t be a hundred more greasy nerds in your tow?  And if, on some level, you already know these things about yourself, then the only purpose of this post has been to remind you of them.</p>



<hr class="wp-block-separator"/>



<p>As for the news that dominates the wires and inevitably preempts what I’ve written: <strong>I wish for his successful recovery, followed by his losing the election and spending the rest of his life in New York State prison</strong>.  (And I look forward to seeing how woke Twitter summarizes the preceding statement—e.g., “Aaronson, his mask finally off, conveys well-wishes to Donald Trump”…)</p>



<hr class="wp-block-separator"/>



<p>See <a href="https://news.ycombinator.com/item?id=24682119">further discussion of this post</a> on Hacker News.</p></div>
    </content>
    <updated>2020-10-04T18:59:18Z</updated>
    <published>2020-10-04T18:59:18Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Nerd Interest"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Obviously I'm Not Defending Aaronson"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Rage Against Doofosity"/>
    <category scheme="https://www.scottaaronson.com/blog" term="The Fate of Humanity"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2020-10-13T03:03:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://differentialprivacy.org/open-problem-avoid-union/</id>
    <link href="https://differentialprivacy.org/open-problem-avoid-union/" rel="alternate" type="text/html"/>
    <title>Open Problem - Avoiding the Union Bound for Multiple Queries</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><strong>Background:</strong> Perhaps the best-studied problem in differential privacy is answering multiple counting queries.
The standard approach is to add independent, appropriately-calibrated (Laplace or Gaussian) noise to each query result and apply a composition theorem.
To bound the maximum error over the query answers, one takes a union bound over the independent noise samples.
However, this is <em>not</em> optimal.
The problem is to identify the optimal method (up to constant factors).</p>

<p><strong>Problem 1:</strong> Is there a randomized algorithm \(M : \{0,1\}^{n \times k} \rightarrow \mathbb{R}^k\) that is differentially private<sup id="fnref:1"><a class="footnote" href="https://differentialprivacy.org/feed.xml#fn:1">1</a></sup> and satisfies
\[
\forall x \in \{0, 1\}^{n \times k} \quad \mathbb{E}\left[ \left\|M(x) - \sum_{i=1}^n x_i \right\|_\infty \right] \leq c \sqrt{k}
\]
for some constant \( c &gt; 0\) depending only on the privacy parameters?<sup id="fnref:2"><a class="footnote" href="https://differentialprivacy.org/feed.xml#fn:2">2</a></sup></p>

<p>Adding independent Gaussian noise to each coordinate/query yields \(c \sqrt{k \log k}\) in place of \(c \sqrt{k}\) above. 
Steinke and Ullman [<a href="https://arxiv.org/abs/1501.06095">SU17</a>] showed that the union bound can <em>almost</em> be avoided and obtained \(c \sqrt{k \log \log k}\) using correlated noise.
The algorithm is nonetheless based on independent Gaussian noise, with the added step of using the exponential mechanism to identify high-error answers and correct them.</p>

<p>Note that a \(\Omega(\sqrt{k})\) lower bound is known [<a href="https://arxiv.org/abs/1311.3158">BUV18</a>, <a href="https://arxiv.org/abs/1501.06095">SU17</a>]. By [<a href="http://www.cs.utah.edu/~bhaskara/files/privacy.pdf">BDKT12</a>] it suffices to consider mechanisms \(M\) that add <em>instance-independent noise</em>. That is, \(M(x) = \sum_{i=1}^n x_i + Z\) where \(Z\) is some fixed noise distribution over \(\mathbb{R}^k\) that is independent of \(x\).</p>

<p><strong>Reward:</strong> For a positive solution, an all-you-can-eat sushi dinner at a sushi restaurant of your choice.
If the solution is an efficiently-sampleable distribution with a closed-form density, alcohol will be included.
For a negative solution, alcohol only.<sup id="fnref:3"><a class="footnote" href="https://differentialprivacy.org/feed.xml#fn:3">3</a></sup></p>

<p><strong>Other related work:</strong> [<a href="https://privacytools.seas.harvard.edu/files/privacytools/files/robust.pdf">DSSUV15</a>, <a href="https://privacytools.seas.harvard.edu/files/privacytools/files/complexityprivacy_1.pdf">Vad17</a>, <a href="https://arxiv.org/abs/1801.09236">AS18</a>]. 
A very recent work by Ganesh and Zhao [<a href="https://people.eecs.berkeley.edu/~arunganesh/papers/generalizedgaussians.pdf">GZ20</a>] improves the best upper bound from \(c\sqrt{k \log \log k}\) to \(c\sqrt{k \log \log \log k}\).</p>

<p><em>Submitted by <a href="http://www.thomas-steinke.net/">Thomas Steinke</a> and <a href="https://www.ccs.neu.edu/home/jullman/">Jonathan Ullman</a> on April 9, 2019.</em></p>

<hr/>

<div class="footnotes">
  <ol>
    <li id="fn:1">
      <p>Specifically, \(M\) is either 1-zCDP [<a href="https://arxiv.org/abs/1605.02065">BS16</a>] with \(c\) an absolute constant or, for every \(\delta &gt; 0\), there is an \(M_\delta\) that is \((1, \delta)\)-DP with \(c = c(\delta) = c’ \cdot \sqrt{\log (1/\delta)}\) for an absolute constant \(c’\). <a class="reversefootnote" href="https://differentialprivacy.org/feed.xml#fnref:1">↩</a></p>
    </li>
    <li id="fn:2">
      <p>Here \(x_i \in \{0, 1\}^k \subset \mathbb{R}^k\) denotes the data vector of individual \(i\) and \(x = (x_1, x_2, \dots, x_n) \in \{0,1\}^{n \times k}\). For simplicity, we only consider expected error; high-probability error bounds are an immediate consequence. <a class="reversefootnote" href="https://differentialprivacy.org/feed.xml#fnref:2">↩</a></p>
    </li>
    <li id="fn:3">
      <p>Restaurant need not necessarily be all-you-can-eat. Maximum redeemable value US$500. <a class="reversefootnote" href="https://differentialprivacy.org/feed.xml#fnref:3">↩</a></p>
    </li>
  </ol>
</div></div>
    </summary>
    <updated>2020-10-03T23:00:00Z</updated>
    <published>2020-10-03T23:00:00Z</published>
    <author>
      <name>Gautam Kamath</name>
    </author>
    <source>
      <id>https://differentialprivacy.org</id>
      <link href="https://differentialprivacy.org" rel="alternate" type="text/html"/>
      <link href="https://differentialprivacy.org/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Website for the differential privacy research community</subtitle>
      <title>Differential Privacy</title>
      <updated>2020-10-12T23:50:43Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/10/02/positions-in-differential-privacy-open-source-software-project-at-opendp-apply-by-october-23-2020/</id>
    <link href="https://cstheory-jobs.org/2020/10/02/positions-in-differential-privacy-open-source-software-project-at-opendp-apply-by-october-23-2020/" rel="alternate" type="text/html"/>
    <title>Positions in Differential Privacy Open-Source Software Project  at OpenDP (apply by October 23, 2020)</title>
    <summary>The new open-source software project OpenDP is hiring 1-2 scientists to work on the theory and practice of differential privacy. Website: https://projects.iq.harvard.edu/opendp/blog/opendp-hiring-scientific-staff Email: privacytools-info@seas.harvard.edu</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The new open-source software project OpenDP is hiring 1-2 scientists to work on the theory and practice of differential privacy.</p>
<p>Website: <a href="https://projects.iq.harvard.edu/opendp/blog/opendp-hiring-scientific-staff">https://projects.iq.harvard.edu/opendp/blog/opendp-hiring-scientific-staff</a><br/>
Email: privacytools-info@seas.harvard.edu</p></div>
    </content>
    <updated>2020-10-02T21:58:51Z</updated>
    <published>2020-10-02T21:58:51Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-10-13T14:21:11Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=20278</id>
    <link href="https://gilkalai.wordpress.com/2020/10/02/cheerful-test-your-intuition-45-survey-about-sisters-and-brothers/" rel="alternate" type="text/html"/>
    <title>Cheerful Test Your Intuition (#45):  Survey About Sisters and Brothers</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">You survey many many school children and ask each one: Do you have more brothers than sisters? or more sisters than brothers? or the same number? Then you separate the boys’s answers from the girls’s answers Which of the following … <a href="https://gilkalai.wordpress.com/2020/10/02/cheerful-test-your-intuition-45-survey-about-sisters-and-brothers/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>You survey many many school children and ask each one:</p>



<p>Do you have more brothers than sisters? or more sisters than brothers? or the same number?</p>



<p>Then you separate the boys’s answers from the girls’s answers</p>



<p>Which of the following is true?</p>



<ol><li>The answers from boys will be tilted toward having MORE sisters and LESS brothers</li><li>The answers from boys will be tilted toward having MORE brothers and LESS sisters</li><li>There will be no (statistically significant) difference.      </li></ol>



<p><strong>The reason for answer 1 is</strong>: Since the ratio of boys/girls is 50/50, and you don’t count yourself in the answer, boys will tend to have more sisters and girls will tend to have more brothers</p>



<p><strong>The reason for answer 2 </strong>is: Some families are uneven and have more boys. In these families you will see more boys having more brothers than sisters and less girls having more brothers than sisters. Some families are uneven and have more girls. In these families you will see more girls having more sisters than brothers and less boys having more sisters than brothers. </p>



<p>I thank <a href="https://securityintelligence.com/author/oded-margalit/">Oded</a> Margalit for this question given to me as a birthday gift.<br/><br/></p>



<p/>



<p/>



<p/>


<div class="align crowdsignal-poll-wrapper wp-block-crowdsignal-forms-poll"/></div>
    </content>
    <updated>2020-10-02T12:48:04Z</updated>
    <published>2020-10-02T12:48:04Z</published>
    <category term="Combinatorics"/>
    <category term="Probability"/>
    <category term="Riddles"/>
    <category term="Statistics"/>
    <category term="Test your intuition"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2020-10-13T14:20:41Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/10/02/postdocs-at-irif-cnrs-u-de-paris-paris-france-apply-by-november-2-2020/</id>
    <link href="https://cstheory-jobs.org/2020/10/02/postdocs-at-irif-cnrs-u-de-paris-paris-france-apply-by-november-2-2020/" rel="alternate" type="text/html"/>
    <title>postdocs at IRIF (CNRS &amp; U. de Paris), Paris, France (apply by November 2, 2020)</title>
    <summary>IRIF (Institute for Research in Foundations of Computer Science, CNRS &amp; U. de Paris) is seeking excellent candidates for postdoctoral positions in all areas of the Foundations of Computer Science. Candidates must hold a Ph.D. in Computer Science or a related area before the starting date of the position. Knowledge of French is not required, […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>IRIF (Institute for Research in Foundations of Computer Science, CNRS &amp; U. de Paris) is seeking excellent candidates for postdoctoral positions in all areas of the Foundations of Computer Science.</p>
<p>Candidates must hold a Ph.D. in Computer Science or a related area before the starting date of the position. Knowledge of French is not required, and applications can be sent in French or English.</p>
<p>Website: <a href="https://www.irif.fr/postes/postdoc">https://www.irif.fr/postes/postdoc</a><br/>
Email: adiro@irif.fr</p></div>
    </content>
    <updated>2020-10-02T07:25:05Z</updated>
    <published>2020-10-02T07:25:05Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-10-13T14:21:11Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/10/01/tenure-track-faculty-and-teaching-faculty-at-university-of-michigan-ann-arbor-apply-by-april-30-2021/</id>
    <link href="https://cstheory-jobs.org/2020/10/01/tenure-track-faculty-and-teaching-faculty-at-university-of-michigan-ann-arbor-apply-by-april-30-2021/" rel="alternate" type="text/html"/>
    <title>Tenure Track Faculty, and Teaching Faculty at University of Michigan, Ann Arbor (apply by April 30, 2021)</title>
    <summary>Computer Science and Engineering (CSE) at the University of Michigan invites applications for multiple tenure-track and teaching faculty (lecturer) positions. We seek exceptional candidates in all areas of CSE, with special emphasis on candidates at the early stages; we also have a targeted search for an endowed professorship in CS theory (the Fischer Chair). Positions […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Computer Science and Engineering (CSE) at the University of Michigan invites applications for multiple tenure-track and teaching faculty (lecturer) positions. We seek exceptional candidates in all areas of CSE, with special emphasis on candidates at the early stages; we also have a targeted search for an endowed professorship in CS theory (the Fischer Chair). Positions remain open until filled.</p>
<p>Website: <a href="https://cse.engin.umich.edu/about/faculty-hiring/">https://cse.engin.umich.edu/about/faculty-hiring/</a><br/>
Email: <a href="mailto:cpeikert@umich.edu" rel="noopener" target="_blank">cpeikert@umich.edu</a></p></div>
    </content>
    <updated>2020-10-01T21:06:09Z</updated>
    <published>2020-10-01T21:06:09Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-10-13T14:21:11Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://tcsplus.wordpress.com/?p=479</id>
    <link href="https://tcsplus.wordpress.com/2020/09/30/479/" rel="alternate" type="text/html"/>
    <title>TCS+ talk: Wednesday, October 7 — Susanna F. de Rezende, Mathematical Institute of the Czech Academy of Sciences</title>
    <summary>The next TCS+ talk will take place this coming Wednesday, October 7th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). Susanna F. de Rezende from Mathematical Institute of the Czech Academy of Sciences will speak about “Lifting with Simple Gadgets and Applications to Circuit and Proof Complexity” (abstract […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The next TCS+ talk will take place this coming Wednesday, October 7th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). <strong>Susanna F. de Rezende</strong> from Mathematical Institute of the Czech Academy of Sciences will speak about “<em>Lifting with Simple Gadgets and Applications to Circuit and Proof Complexity</em>” (abstract below). </p>



<p>You can reserve a spot as an individual or a group to join us live by signing up on <a href="https://sites.google.com/site/plustcs/livetalk/live-seat-reservation">the online form</a>. Due to security concerns, <em>registration is required</em> to attend the interactive talk. (The link to the YouTube livestream will also be posted <a href="https://sites.google.com/site/plustcs/livetalk">on our  website</a> on the day of the talk, so people who did not sign up will still be able to  watch the talk live.) As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/site/plustcs/suggest">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/site/plustcs/">the website</a>.</p>



<p class="wp-block-quote">Abstract: Lifting theorems in complexity theory are a method of transferring lower bounds in a weak computational model into lower bounds for a more powerful computational model, via function composition. There has been an explosion of lifting theorems in the last ten years, essentially reducing communication lower bounds to query complexity lower bounds. These theorems only hold for composition with very specific “gadgets” such as indexing and inner product. <br/><br/> In this talk, we will present a generalization of the theorem lifting Nullstellensatz degree to monotone span program size by Pitassi and Robere (2018) so that it works for any gadget with high enough rank, in particular, for useful gadgets such as equality and greater-than. We will then explain how to apply our generalized theorem to solve three open problems: <br/>– We present the first result that demonstrates a separation in proof power for cutting planes with unbounded versus polynomially bounded coefficients. Specifically, we exhibit CNF formulas that can be refuted in quadratic length and constant line space in cutting planes with unbounded coefficients, but for which there are no refutations in subexponential length and subpolynomial line space if coefficients are restricted to be of polynomial magnitude.<br/>– We give the strongest separation to-date between monotone Boolean formulas and monotone Boolean circuits. Namely, we show that the classical GEN problem, which has polynomial-size monotone Boolean circuits, requires monotone Boolean formulas of size <img alt="2^{\Omega(n / \textrm{polylog} n)}" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7B%5COmega%28n+%2F+%5Ctextrm%7Bpolylog%7D+n%29%7D&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002" title="2^{\Omega(n / \textrm{polylog} n)}"/>.<br/>– We give the first explicit separation between monotone Boolean formulas and monotone real formulas. Namely, we give an explicit family of functions that can be computed with monotone real formulas of nearly linear size but require monotone Boolean formulas of exponential size. Previously only a non-explicit separation was known.<br/><br/>This talk is based on joint work with Or Meir, Jakob Nordström, Toniann Pitassi, Robert Robere, and Marc Vinyals, available at <a href="https://arxiv.org/abs/2001.02144" rel="nofollow">https://arxiv.org/abs/2001.02144</a> </p></div>
    </content>
    <updated>2020-09-30T23:43:35Z</updated>
    <published>2020-09-30T23:43:35Z</published>
    <category term="Announcements"/>
    <author>
      <name>plustcs</name>
    </author>
    <source>
      <id>https://tcsplus.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://tcsplus.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://tcsplus.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://tcsplus.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://tcsplus.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A carbon-free dissemination of ideas across the globe.</subtitle>
      <title>TCS+</title>
      <updated>2020-10-13T14:21:48Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2020/09/30/linkage</id>
    <link href="https://11011110.github.io/blog/2020/09/30/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>A new algorithm for graph crossings, hiding in plain sight (\(\mathbb{M}\)). Dynamic graph planarity testing, in Quanta. The original papers are arXiv:1910.09005, in SODA 2020 and arXiv:1911.03449, in STOC 2020, by Jacob Holm and Eva Rotenberg.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><ul>
  <li>
    <p><a href="https://www.quantamagazine.org/a-new-algorithm-for-graph-crossings-hiding-in-plain-sight-20200915/">A new algorithm for graph crossings, hiding in plain sight</a> (<a href="https://mathstodon.xyz/@11011110/104876209471911167">\(\mathbb{M}\)</a>). Dynamic graph planarity testing, in <em>Quanta</em>. The original papers are <a href="https://arxiv.org/abs/1910.09005">arXiv:1910.09005, in SODA 2020</a> and <a href="https://arxiv.org/abs/1911.03449">arXiv:1911.03449, in STOC 2020</a>, by Jacob Holm and Eva Rotenberg.</p>
  </li>
  <li>
    <p><a href="https://drops.dagstuhl.de/opus/portals/lipics/index.php?semnr=16159">Fun with Algorithms proceedings, now online</a> (<a href="https://mathstodon.xyz/@11011110/104884749945714543">\(\mathbb{M}\)</a>). So if you want to read about robot bamboo trimmers, phase transitions in the mine density of minesweeper, applications of the Blaschke–Lebesgue inequality to the game of battleship, multiplication of base-Fibonacci numbers, or trains that can jump gaps in their tracks, you know where to go. The conference itself has been rescheduled to next May. Maybe by then we can actually get a trip to an Italian resort island out of it.</p>
  </li>
  <li>
    <p><a href="https://fractalkitty.com/2020/07/02/week-37-cantor-set-kirigami/">Cantor set kirigami</a> (<a href="https://mathstodon.xyz/@11011110/104889995571500186">\(\mathbb{M}\)</a>). One of many many mathy-craft blog posts at Fractal Kitty, which I found via <a href="https://blogs.ams.org/blogonmathblogs/2020/08/24/fractal-kitty-blog-a-tour/">the AMS math blog tour</a>.</p>
  </li>
  <li>
    <p>Probability theorist <a href="https://en.wikipedia.org/wiki/Nina_Holden">Nina Holden</a>, quantum complexity theorist <a href="https://en.wikipedia.org/wiki/Urmila_Mahadev">Urmila Mahadev</a>, and knot theorist <a href="https://en.wikipedia.org/wiki/Lisa_Piccirillo">Lisa Piccirillo</a> win the <a href="https://breakthroughprize.org/News/60">2021 Maryam Mirzakhani New Frontiers Prizes</a> (<a href="https://mathstodon.xyz/@11011110/104894368463336926">\(\mathbb{M}\)</a>). For more on them their work, see <a href="https://johncarlosbaez.wordpress.com/2020/09/19/the-brownian-map/">Baez on the Brownian map</a>, <a href="https://www.quantamagazine.org/graduate-student-solves-quantum-verification-problem-20181008/"><em>Quanta</em> on quantum verification</a>, and <a href="https://www.quantamagazine.org/graduate-student-solves-decades-old-conway-knot-problem-20200519/"><em>Quanta</em> on Conway’s knot problem</a>.</p>
  </li>
  <li>
    <p><a href="https://www.youtube.com/channel/UCIyDqfi_cbkp-RU20aBF-MQ/videos">Richard Borcherd’s YouTube channel</a> (<a href="https://mathstodon.xyz/@jsiehler/104870496696544903">\(\mathbb{M}\)</a>), “a trove of mathematical lectures at various levels”.</p>
  </li>
  <li>
    <p><em><a href="https://archive.org/details/gri_33125012889602">Perspectiva corporum regularium</a></em> (1568), by Wenzel Jamnitzer (<a href="https://mathstodon.xyz/@11011110/104907440380152299">\(\mathbb{M}\)</a>, <a href="https://en.wikipedia.org/wiki/Perspectiva_corporum_regularium">see also</a>). I don’t know how readable the brief medieval German text connecting the regular polyhedra to Plato’s theory of the four elements is, but the pictures of elaborated variations of the regular polyhedra can be understood in any language.</p>
  </li>
  <li>
    <p>Two new Wikipedia articles inspired by papers at Graph Drawing 2020 (<a href="https://mathstodon.xyz/@11011110/104911250878365185">\(\mathbb{M}\)</a>):</p>

    <ul>
      <li>
        <p><a href="https://en.wikipedia.org/wiki/Geodetic_graph">Geodetic graph</a>, a graph in which all shortest paths are unique, inspired by “<a href="https://arxiv.org/abs/2008.07637">Drawing shortest paths in geodetic graphs</a>”</p>
      </li>
      <li>
        <p><a href="https://en.wikipedia.org/wiki/Kirchberger%27s_theorem">Kirchberger’s theorem</a>, that if every  points in a red-blue point set are linearly separable then all of them are, inspired by “<a href="https://arxiv.org/abs/2005.12568">Topological drawings meet classical theorems from convex geometry</a>”</p>
      </li>
    </ul>
  </li>
  <li>
    <p><a href="https://www.europeanwomeninmaths.org/ewm-open-letter-on-the-covid-19-pandemic/">European Women in Mathematics have written an open letter advocating proactive support of temporary employees, applicants, women, and parents in academia</a> (<a href="https://mathstodon.xyz/@11011110/104918402781146229">\(\mathbb{M}\)</a>, <a href="https://twitter.com/hollykrieger/status/1308375574285606913">via</a>), to forestall disproportionate losses in diversity in the wake of the covid pandemic. It’s addressed to European authorities but most of the same concerns apply more globally.</p>
  </li>
  <li>
    <p><a href="https://wikimediafoundation.org/news/2020/09/24/china-blocks-wikimedia-foundations-accreditation/">China blocks Wikimedia Foundation from being an observer to the World Intellectual Property Organization</a> (<a href="https://mathstodon.xyz/@11011110/104926568710157787">\(\mathbb{M}\)</a>, <a href="https://news.ycombinator.com/item?id=24588913">via</a>), apparently because it has a chapter in Taiwan.</p>
  </li>
  <li>
    <p><a href="https://www.iqoqi-vienna.at/blog/article/dishonesty-in-academia-the-deafening-silence-of-the-royal-society-open-science-journal-on-an-accept/">Royal Society Open Science journal publishes crank quantum paper despite negative referee reports, and has not responded to two-year-old open letter from two of the referees and several other quantum heavy hitters requesting its retraction</a> (<a href="https://mathstodon.xyz/@11011110/104927678937136375">\(\mathbb{M}\)</a>, <a href="https://news.ycombinator.com/item?id=24593465">via</a>).</p>
  </li>
  <li>
    <p>Michael Wehar posted a nice algorithms / fine grained complexity question on the CS theory stack exchange: <a href="https://cstheory.stackexchange.com/q/47588/95">how quickly can we test whether a 2d matrix has a square of four non-zero entries</a> (<a href="https://mathstodon.xyz/@11011110/104934034382351929">\(\mathbb{M}\)</a>)? The obvious method, looping over nonzeros and testing the squares each might be part of, is cubic when there are many nonzeros. And there can be many nonzeros without forcing a square to exist. Is there a standard hardness assumption under which strongly subcubic is impossible?</p>
  </li>
  <li>
    <p><a href="https://cacm.acm.org/magazines/2020/10/247584-bouncing-balls-and-quantum-computing/fulltext">The connection between the unexpected appearance of \(\pi\) in counting the bounces of billiard balls of different sizes and Grover’s algorithm for quantum search</a> (<a href="https://mathstodon.xyz/@11011110/104941135715864349">\(\mathbb{M}\)</a>): hidden constraints that keep things on a unit circle. Based on <a href="https://arxiv.org/abs/1912.02207">a preprint by Adam Brown</a>.</p>
  </li>
  <li>
    <p><a href="https://rjlipton.wordpress.com/2020/09/22/puzzle-reviews-by-a-puzzle-writer/">Puzzle reviews by a puzzle writer</a> (<a href="https://mathstodon.xyz/@11011110/104949202213901273">\(\mathbb{M}\)</a>). Lipton and Regan look at a few puzzles from the book <em>Bicycles or Unicycles: A Collection of Intriguing Mathematical Puzzles</em>, by Velleman and Wagon, concentrating on one that places a pebble at the origin of the positive quadrant and asks to clear a \(3\times 3\) square by moves that replace a pebble by one above and one to its left. The puzzle writer is Jason Rosenhouse, who <a href="https://www.ams.org/journals/notices/202009/rnoti-p1382.pdf">reviewed <em>Bicycles or Unicycles</em> in the <em>Notices</em></a>.</p>
  </li>
  <li>
    <p><a href="https://www.ams.org/journals/notices/202009/rnoti-p1397.pdf">Otto Neugebauer, famous as a historian of mathematics, also championed internationalism and diversity during Nazi times</a> (<a href="https://mathstodon.xyz/@11011110/104952629031738190">\(\mathbb{M}\)</a>, <a href="https://blogs.ams.org/beyondreviews/2020/09/28/otto-neugebauer-redux/">via</a>).</p>
  </li>
  <li>
    <p><a href="https://www.nature.com/articles/d41586-020-02746-y"><em>Nature</em> covers the stories of five international students and postdocs whose plans to join US academia were disrupted by Trumpist visa restrictions</a> (<a href="https://mathstodon.xyz/@11011110/104955593693842251">\(\mathbb{M}\)</a>, <a href="https://news.ycombinator.com/item?id=24634486">via</a>).</p>
  </li>
</ul></div>
    </content>
    <updated>2020-09-30T17:15:00Z</updated>
    <published>2020-09-30T17:15:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2020-10-01T00:18:03Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/09/30/postdoc-graduate-student-at-ben-gurion-university-at-ben-gurion-university-apply-by-december-30-2020/</id>
    <link href="https://cstheory-jobs.org/2020/09/30/postdoc-graduate-student-at-ben-gurion-university-at-ben-gurion-university-apply-by-december-30-2020/" rel="alternate" type="text/html"/>
    <title>POSTDOC, GRADUATE STUDENT AT BEN-GURION UNIVERSITY at Ben Gurion University (apply by December 30, 2020)</title>
    <summary>Excellent students with a strong background in Theoretical Computer Science and Mathematics, interested to conduct research in Error-Correcting Codes, Information Theory, or Arithmetic Circuits, are welcome to apply to postdoctoral and graduate student positions. The position is funded by the ERC, and it includes a generous salary, as well as funding for equipment and travel. […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Excellent students with a strong background in Theoretical Computer Science and Mathematics, interested to conduct research in Error-Correcting Codes, Information Theory, or Arithmetic Circuits, are welcome to apply to postdoctoral and graduate student positions. The position is funded by the ERC, and it includes a generous salary, as well as funding for equipment and travel.</p>
<p>Website: <a href="https://www.cs.bgu.ac.il/~klim/Links/Call">https://www.cs.bgu.ac.il/~klim/Links/Call</a><br/>
Email: klimefrem@gmail.com</p></div>
    </content>
    <updated>2020-09-30T10:15:57Z</updated>
    <published>2020-09-30T10:15:57Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-10-13T14:21:11Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/149</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/149" rel="alternate" type="text/html"/>
    <title>TR20-149 |  Robustly Self-Ordered Graphs: Constructions and Applications to Property Testing | 

	Oded Goldreich, 

	Avi Wigderson</title>
    <summary>A graph $G$ is called {\em self-ordered}\/ (a.k.a asymmetric) if the identity permutation is its only automorphism.
Equivalently, there is a unique isomorphism from $G$ to any graph that is isomorphic to $G$. 
We say that $G=(V,E)$ is {\em robustly self-ordered}\/ if the size of the symmetric difference between $E$ and the edge-set of the graph obtained by permuting $V$ using any permutation $\pi:V\to V$ is proportional to the number of non-fixed-points of $\pi$.

We show that robustly self-ordered bounded-degree graphs exist (in abundance), and that they can be constructed efficiently, in a strong sense.
Specifically, given the index of a vertex in such a graph, it is possible to find all its neighbors in polynomial-time (i.e., in time that is poly-logarithmic in the size of the graph).

We provide two very different constructions, in tools and structure. 
The first, a direct construction, is based on proving a sufficient condition for robust self-ordering, 
which requires that an auxiliary graph, on {\em pairs|}\/ of vertices of the original graph, is expanding. 
In this case the original graph is (not only robustly self-ordered but) also expanding.
The second construction proceeds in three steps: It boosts the mere existence of robustly self-ordered graphs, 
which provides explicit graphs of sublogarithmic size, to an efficient construction of polynomial-size graphs, 
and then, repeating it again, to exponential-size(robustly self-ordered) graphs that are locally constructible.
This construction can yield robustly self-ordered graphs that are either expanders or highly disconnected, having logarithmic size connected components. 

We also consider graphs of unbounded degree, seeking correspondingly unbounded robustness parameters.
We again demonstrate that such graphs (of linear degree) exist (in abundance), and give an explicit construction. 
This turns out to require very different tools, and the definition and constructions of new pseudo-random objects. 
Specifically, we show that the construction of such graphs reduces to the construction of non-malleable two-source extractors 
with very weak parameters but with an additional natural feature. 
Next, we reduce the construction of such non-malleable two-source extractors to the construction of ``relocation-detecting'' codes. Loosely speaking, in such code permuting arbitrarily the coordinates of a random codeword yields a string that is far any other codeword. We conclude by showing how to construct relocation-detecting codes (of various types, including ones with constant rate).  

We demonstrate that robustly self-ordered bounded-degree graphs are useful towards obtaining lower bounds on the query complexity of testing graph properties both in the bounded-degree and the dense graph models.  
Indeed, their robustness offers efficient, local and distance preserving reductions from testing problems on ordered structures (like sequences) to the unordered (effectively unlabeled) graphs. 
One of the results that we obtain, via such a reduction, is a subexponential separation 
between the complexity of testing and tolerant testing of graph properties in the bounded-degree graph model.</summary>
    <updated>2020-09-29T19:33:10Z</updated>
    <published>2020-09-29T19:33:10Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-10-13T14:20:37Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/09/29/postdoctoral-research-associate-high-performance-parallel-graph-based-machine-learning-at-david-r-cheriton-school-of-computer-science-university-of-waterloo-apply-by-january-1-2021/</id>
    <link href="https://cstheory-jobs.org/2020/09/29/postdoctoral-research-associate-high-performance-parallel-graph-based-machine-learning-at-david-r-cheriton-school-of-computer-science-university-of-waterloo-apply-by-january-1-2021/" rel="alternate" type="text/html"/>
    <title>Postdoctoral Research Associate, High-Performance Parallel Graph-Based Machine Learning at David R. Cheriton School of Computer Science, University of Waterloo (apply by January 1, 2021)</title>
    <summary>We are looking for a postdoctoral research associate to join our research group (opallab.ca) at the Computer Science department at the University of Waterloo. Our goal is to develop parallel and communication efficient algorithms for large-scale graph-based machine learning. Website: https://jobs.siam.org/job/postdoctoral-research-associate/54755436/ Email: kfountou@uwaterloo.ca</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>We are looking for a postdoctoral research associate to join our research group (opallab.ca) at the Computer Science department at the University of Waterloo. Our goal is to develop parallel and communication efficient algorithms for large-scale graph-based machine learning.</p>
<p>Website: <a href="https://jobs.siam.org/job/postdoctoral-research-associate/54755436/">https://jobs.siam.org/job/postdoctoral-research-associate/54755436/</a><br/>
Email: kfountou@uwaterloo.ca</p></div>
    </content>
    <updated>2020-09-29T19:26:33Z</updated>
    <published>2020-09-29T19:26:33Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-10-13T14:21:11Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/148</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/148" rel="alternate" type="text/html"/>
    <title>TR20-148 |  Simple and fast derandomization from very hard functions: Eliminating randomness at almost no cost | 

	Roei Tell, 

	Lijie Chen</title>
    <summary>Extending the classical ``hardness-to-randomness'' line-of-works, Doron et al. (FOCS 2020) recently proved that derandomization with near-quadratic time overhead is possible, under the assumption that there exists a function in $\mathcal{DTIME}[2^n]$ that cannot be computed by randomized SVN circuits of size $2^{(1-\epsilon)\cdot n}$ for a small $\epsilon$.

In this work we extend their inquiry and answer several open questions that arose from their work. Our main result is that *derandomization with almost no time overhead is possible*, under a plausible hypothesis. Specifically, we show that probabilistic algorithms that run in time $T(n)$ can be deterministically simulated in time $n\cdot T(n)^{1+\epsilon}$, under a hypothesis that is formally incomparable to the one of Doron et al., but is arguably more standard: We assume that there exist non-uniformly secure one-way functions, and that for $\delta=\delta(\epsilon)$ and $k=k_T(\epsilon)$ there exists a problem in $\mathcal{DTIME}[2^{k\cdot n}]$ that is hard for algorithms that run in time $2^{(k-\delta)\cdot n}$ and use $2^{(1-\delta)\cdot n}$ bits of advice. We also show that the latter hypothesis (or, more accurately, a relaxation of it that we use) is in fact necessary to obtain the derandomization conclusion if one relies on a PRG construction (as is indeed our approach).

For sub-exponential time functions $T(n)=2^{n^{o(1)}}$ we further improve the derandomization time to $n^{1+\epsilon}\cdot T(n)$, under a mildly stronger hypothesis. We also show that *the multiplicative time overhead of $n$ is essentially optimal*, conditioned on a counting version of the non-deterministic strong exponential-time hypothesis (i.e., on $\# NSETH$). Nevertheless, we show that *in the average-case setting a faster derandomization is possible*: Under hypotheses similar to the ones in our main result, we show that for every $L\in\mathcal{BPTIME}[n^k]$ there exists a deterministic algorithm $A_L$ running in time $n^{\epsilon}\cdot n^{k}$ such that for every distribution $\mathcal{D}$ over $\{0,1\}^n$ samplable in time $n^k$ it holds that $\Pr_{x\sim\mathcal{D}}[A_L(x)=L(x)]\ge1-n^{-\omega(1)}$. 

Lastly, we present an alternative proof for the result of Doron et al. using a *proof paradigm that is both considerably simpler and more general*; in fact, we show how to simplify the analysis of any construction that ``extracts randomness from a pseudoentropic string''. We use this simpler proof to extend their result, deducing a mildly slower derandomization (i.e., with cubic or quadratic overhead) from weaker hardness assumptions (i.e., for SVN circuits that do not use randomness).</summary>
    <updated>2020-09-29T17:09:04Z</updated>
    <published>2020-09-29T17:09:04Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-10-13T14:20:37Z</updated>
    </source>
  </entry>
</feed>
