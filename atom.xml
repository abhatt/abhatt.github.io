<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2021-11-24T14:39:02Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/169</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/169" rel="alternate" type="text/html"/>
    <title>TR21-169 |  Hypercontractivity on High Dimensional Expanders: a Local-to-Global Approach for Higher Moments | 

	Max Hopkins, 

	Mitali Bafna, 

	Tali Kaufman, 

	Shachar Lovett</title>
    <summary>Hypercontractivity is one of the most powerful tools in Boolean function analysis. Originally studied over the discrete hypercube, recent years have seen increasing interest in extensions to settings like the $p$-biased cube, slice, or Grassmannian, where variants of hypercontractivity have found a number of breakthrough applications including the resolution of Khot’s 2-2 Games Conjecture (Khot, Minzer, Safra FOCS 2018). In this work, we develop a new theory of hypercontractivity on high dimensional expanders (HDX), an important class of expanding complexes that has recently seen similarly impressive applications in both coding theory and approximate sampling. Our results lead to a new understanding of the structure of Boolean functions on HDX, including a tight analog of the KKL Theorem and a new characterization of non-expanding sets. 

Unlike previous settings satisfying hypercontractivity, HDX can be asymmetric, sparse, and very far from products, which makes the application of traditional proof techniques challenging. We handle these barriers with the introduction of two new tools of independent interest: a new explicit combinatorial Fourier basis for HDX that behaves well under restriction, and a new local-to-global method for analyzing higher moments. Interestingly, unlike analogous second moment methods that apply equally across all types of expanding complexes, our tools rely inherently on simplicial structure. This suggests a new distinction among high dimensional expanders based upon their behavior beyond the second moment.</summary>
    <updated>2021-11-24T08:19:32Z</updated>
    <published>2021-11-24T08:19:32Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-11-24T14:37:23Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/168</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/168" rel="alternate" type="text/html"/>
    <title>TR21-168 |  Hypercontractivity on High Dimensional Expanders | 

	Tom Gur, 

	Noam Lifshitz, 

	Siqi Liu</title>
    <summary>We prove hypercontractive inequalities on high dimensional expanders. As in the settings of the p-biased hypercube, the symmetric group, and the Grassmann scheme, our inequalities are effective for global functions, which are functions that are not significantly affected by a restriction of a small set of coordinates. As applications, we obtain Fourier concentration, small-set expansion, and Kruskal-Katona theorems for high dimensional expanders. Our techniques rely on a new approximate Efron-Stein decomposition for high dimensional link expanders.</summary>
    <updated>2021-11-24T08:10:52Z</updated>
    <published>2021-11-24T08:10:52Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-11-24T14:37:23Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.12040</id>
    <link href="http://arxiv.org/abs/2111.12040" rel="alternate" type="text/html"/>
    <title>Generating Tree Structures for Hyperbolic Tessellations</title>
    <feedworld_mtime>1637712000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Dorota Celińska-Kopczyńska, Eryk Kopczyński <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.12040">PDF</a><br/><b>Abstract: </b>We show an efficient algorithm for generating geodesic regular tree
structures for periodic hyperbolic and Euclidean tessellations and
experimentally verify its performance on tessellations.
</p></div>
    </summary>
    <updated>2021-11-24T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2021-11-24T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.10984</id>
    <link href="http://arxiv.org/abs/2111.10984" rel="alternate" type="text/html"/>
    <title>Topological Regularization for Dense Prediction</title>
    <feedworld_mtime>1637712000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fu:Deqing.html">Deqing Fu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nelson:Bradley_J=.html">Bradley J. Nelson</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.10984">PDF</a><br/><b>Abstract: </b>Dense prediction tasks such as depth perception and semantic segmentation are
important applications in computer vision that have a concrete topological
description in terms of partitioning an image into connected components or
estimating a function with a small number of local extrema corresponding to
objects in the image. We develop a form of topological regularization based on
persistent homology that can be used in dense prediction tasks with these
topological descriptions. Experimental results show that the output topology
can also appear in the internal activations of trained neural networks which
allows for a novel use of topological regularization to the internal states of
neural networks during training, reducing the computational cost of the
regularization. We demonstrate that this topological regularization of internal
activations leads to improved convergence and test benchmarks on several
problems and architectures.
</p></div>
    </summary>
    <updated>2021-11-24T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2021-11-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.10912</id>
    <link href="http://arxiv.org/abs/2111.10912" rel="alternate" type="text/html"/>
    <title>Johnson Coverage Hypothesis: Inapproximability of k-means and k-median in L_p metrics</title>
    <feedworld_mtime>1637712000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cohen=Addad:Vincent.html">Vincent Cohen-Addad</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/S=:Karthik_C=.html">Karthik C. S.</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lee:Euiwoong.html">Euiwoong Lee</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.10912">PDF</a><br/><b>Abstract: </b>K-median and k-means are the two most popular objectives for clustering
algorithms. Despite intensive effort, a good understanding of the
approximability of these objectives, particularly in $\ell_p$-metrics, remains
a major open problem. In this paper, we significantly improve upon the hardness
of approximation factors known in literature for these objectives in
$\ell_p$-metrics.
</p>
<p>We introduce a new hypothesis called the Johnson Coverage Hypothesis (JCH),
which roughly asserts that the well-studied max k-coverage problem on set
systems is hard to approximate to a factor greater than 1-1/e, even when the
membership graph of the set system is a subgraph of the Johnson graph. We then
show that together with generalizations of the embedding techniques introduced
by Cohen-Addad and Karthik (FOCS '19), JCH implies hardness of approximation
results for k-median and k-means in $\ell_p$-metrics for factors which are
close to the ones obtained for general metrics. In particular, assuming JCH we
show that it is hard to approximate the k-means objective:
</p>
<p>$\bullet$ Discrete case: To a factor of 3.94 in the $\ell_1$-metric and to a
factor of 1.73 in the $\ell_2$-metric; this improves upon the previous factor
of 1.56 and 1.17 respectively, obtained under UGC.
</p>
<p>$\bullet$ Continuous case: To a factor of 2.10 in the $\ell_1$-metric and to
a factor of 1.36 in the $\ell_2$-metric; this improves upon the previous factor
of 1.07 in the $\ell_2$-metric obtained under UGC.
</p>
<p>We also obtain similar improvements under JCH for the k-median objective.
Additionally, we prove a weak version of JCH using the work of Dinur et al.
(SICOMP '05) on Hypergraph Vertex Cover, and recover all the results stated
above of Cohen-Addad and Karthik (FOCS '19) to (nearly) the same
inapproximability factors but now under the standard NP$\neq$P assumption
(instead of UGC).
</p></div>
    </summary>
    <updated>2021-11-24T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2021-11-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.10690</id>
    <link href="http://arxiv.org/abs/2111.10690" rel="alternate" type="text/html"/>
    <title>Network Graph Generation through Adaptive Clustering and Infection Dynamics: A Step Towards Global Connectivity</title>
    <feedworld_mtime>1637712000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rahman:Aniq_Ur.html">Aniq Ur Rahman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fourati:Fares.html">Fares Fourati</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Ngo:Khac=Hoang.html">Khac-Hoang Ngo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jindal:Anish.html">Anish Jindal</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Alouini:Mohamed=Slim.html">Mohamed-Slim Alouini</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.10690">PDF</a><br/><b>Abstract: </b>More than 40% of the world's population is not connected to the internet,
majorly due to the lack of adequate infrastructure. Our work aims to bridge
this digital divide by proposing solutions for network deployment in remote
areas. Specifically, a number of access points (APs) are deployed as an
interface between the users and backhaul nodes (BNs). The main challenges
include designing the number and location of the APs, and connecting them to
the BNs. In order to address these challenges, we first propose a metric called
connectivity ratio to assess the quality of the deployment. Next, we propose an
agile search algorithm to determine the number of APs that maximizes this
metric and perform clustering to find the optimal locations of the APs.
Furthermore, we propose a novel algorithm inspired by infection dynamics to
connect all the deployed APs to the existing BNs economically. To support the
existing terrestrial BNs, we investigate the deployment of non-terrestrial BNs,
which further improves the network performance in terms of average hop count,
traffic distribution, and backhaul length. Finally, we use real datasets from a
remote village to test our solution.
</p></div>
    </summary>
    <updated>2021-11-24T00:37:20Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2021-11-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/167</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/167" rel="alternate" type="text/html"/>
    <title>TR21-167 |  Post-Quantum Zero Knowledge, Revisited (or: How to Do Quantum Rewinding Undetectably) | 

	Alex Lombardi, 

	Fermi Ma, 

	Nicholas Spooner</title>
    <summary>A major difficulty in quantum rewinding is the fact that measurement is destructive: extracting information from a quantum state irreversibly changes it. This is especially problematic in the context of zero-knowledge simulation, where preserving the adversary's state is essential.
    
    In this work, we develop new techniques for quantum rewinding in the context of extraction and zero-knowledge simulation:
    
1. We show how to extract information from a quantum adversary by rewinding it without disturbing its internal state. We use this technique to prove that important interactive protocols, such as the Goldreich-Micali-Wigderson protocol for graph non-isomorphism and the Feige-Shamir protocol for NP, are zero-knowledge against quantum adversaries. 

2. We prove that the Goldreich-Kahan protocol for NP is post-quantum zero knowledge using a simulator that can be seen as a natural quantum extension of the classical simulator. 

Our results achieve (constant-round) black-box zero-knowledge with negligible simulation error, appearing to contradict a recent impossibility result due to Chia-Chung-Liu-Yamakawa (FOCS 2021). This brings us to our final contribution:

3. We introduce coherent-runtime expected quantum polynomial time, a computational model that (a) captures all of our zero-knowledge simulators, (b) cannot break any polynomial hardness assumptions, and (c) is not subject to the CCLY impossibility. In light of our positive results and the CCLY negative results, we propose coherent-runtime simulation to be the right quantum analogue of classical expected polynomial-time simulation.</summary>
    <updated>2021-11-23T11:09:07Z</updated>
    <published>2021-11-23T11:09:07Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-11-24T14:37:23Z</updated>
    </source>
  </entry>

  <entry>
    <id>http://benjamin-recht.github.io/2021/11/23/mask-rct-revisited/</id>
    <link href="http://benjamin-recht.github.io/2021/11/23/mask-rct-revisited/" rel="alternate" type="text/html"/>
    <title>Revisiting the Bangladesh Mask RCT.</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>In an earlier post, <a href="https://www.argmin.net/2021/09/13/effect-size/">I raised a few issues</a> with a <a href="https://www.poverty-action.org/sites/default/files/publications/Mask_Second_Stage_Paper_20211108.pdf.pdf">large-scale RCT run in Bangladesh aimed at estimating the effectiveness of masks on reducing the spread of the coronavirus</a>. In particular, I was a bit dismayed that the authors did not post the raw number of seropositive cases in their study, preventing me from computing standard statistical analyses of their results. I also objected to the number of statistical regressions run to pull signals out of a very complex intervention.</p>

<p>Recently, the authors were kind enough to release their <a href="https://gitlab.com/emily-crawford/bd-mask-rct">code and data</a>. I send nothing but kudos to them in this regard. Releasing code and data can help disambiguate questions that are not always answerable from papers alone. In fact, I was immediately able to answer my question by querying their data. In this post, I will walk through a simple analysis to estimate the efficacy of their proposed intervention.</p>

<p>In the Bangladesh Mask RCT, there were $n_C=$163,861 individuals from 300 villages in the control group. There were $n_T=$178,322 individuals from 300 villages in the intervention group. The main end point of the study was whether their intervention reduced the number of individuals who both reported covid-like symptoms and tested seropositive at some point during the trial. The number of such individuals appears nowhere in their paper, and one has to compute this from the data they kindly provided: There were $i_C=$1,106 symptomatic individuals confirmed seropositive in the control group and $i_T=$1,086 such individuals in the treatment group. The difference between the two groups was small: only <em>20 cases</em> out of over 340,000 individuals over a span of 8 weeks.</p>

<p>I have a hard time going from these numbers to the assured conclusions that “masks work” that was <a href="https://www.theatlantic.com/ideas/archive/2021/09/masks-were-working-all-along/619989/">promulgated</a> <a href="https://www.nature.com/articles/d41586-021-02457-y">by</a> <a href="https://www.nbcnews.com/science/science-news/largest-study-masks-yet-details-importance-fighting-covid-19-rcna1858">the</a> <a href="https://www.washingtonpost.com/world/2021/09/01/masks-study-covid-bangladesh/">media</a> or <a href="https://www.nytimes.com/2021/09/26/opinion/do-masks-work-for-covid-prevention.html">the authors</a> after this preprint appeared. This study was not blinded, as it’s impossible to blind a study on masks. The intervention was highly complex and included a mask promotion campaign and education about other mitigation measures including social distancing. Moreover, individuals were only added to the study if they consented to allow the researchers to visit and survey their household. There was a large differential between the control and treatment groups here, with 95% consenting in the treatment group but only 92% consenting in control. <em>This differential alone could wash away the difference in observed cases.</em> Finally, symptomatic seropositivity is a crude measure of covid as the individuals could have been infected before the trial began.</p>

<p>Given the numerous caveats and confounders, the study still only found a tiny effect size. My takeaway is that a complex intervention including an educational program, free masks, encouraged mask wearing, and surveillance in a poor country with low population immunity and no vaccination showed at best modest reduction in infection. I think this summary is fair to the study authors. And this is valuable information to have! It reaffirms my priors that non-pharmaceutical interventions are challenging to implement and have only modest benefits in the presence of a highly contagious respiratory infection. But your mileage may vary.</p>

<p>As I mentioned, of course, this was not the message that the majority of the media took away from this study. Instead we were told that this trial finally confirmed that masks worked. I think one of the key confusing points was <a href="http://www.argmin.net/2021/08/13/relative-risk/">using “efficacy” instead of relative risk</a> as a measure of intervention power.</p>

<p>One of the dark tricks of biostatistics is moving away from absolute case counts to  measures of risk such as relative risk reduction, efficacy, or the odds ratio. All of these measures are relative, and they tend to exaggerate effects. The relative risk reduction is the ratio of the rate of infection in the treatment group to the rate of infection in the control group</p>

\[{\small
    RR = \frac{i_T/n_T}{i_C/n_C}\,.
}\]

<p>A small $RR$ corresponds to a large reduction in risk. For the mask study, $RR=$0.9. That’s not a lot of risk reduction: in this study, community masking improved an individual’s risk of infection by a factor of only 1.1x. As a convenient comparator, the $RR$ in the MRNA vaccine trials was 0.05. In this case, vaccines reduce the risk of infection by a factor of 20x.</p>

<p>The academic vaccine community unfortunately uses “efficacy” or “effectiveness” to describe relative risk reduction. <a href="http://www.argmin.net/xxx">Efficacy is a confusing, commonly misinterpreted metric</a>. Efficacy in a trial is one minus the relative risk reduction:</p>

\[{\small
EFF = 1-RR\,,
}\]

<p>reported as a percentage. So if the $RR=$0.9, then $EFF=$10%.</p>

<p>The important thing to realize about efficacy is that the range from 0% to 20% is barely better than nothing. Here, even a 20% efficacy corresponds to a reduction of risk by a factor of 1.25x. 1.25x is not literally nothing, but it’s also not enough to halt a highly contagious respiratory infection. For what it’s worth, a vaccine with 20% efficacy would not be approved. Another major flaw of using efficacy as a metric is that it is highly nonlinear. The difference between 10% and 20% efficacy is very small whereas the difference between 85% and 95% is huge, corresponding to a 7-fold and 20-fold risk reduction respectively. Efficacy is a nonlinear metric, but these percentages are bandied around as if they are linear effects, and this adds confusion to the public dialogue.</p>

<p class="center"><img alt="The relationship between effectiveness and risk reduction is highly nonlinear" src="http://www.argmin.net/assets/eff_v_rr.png" width="65%"/></p>

<p>To further dive into the absurdity of efficacy, let’s examine the claim that “cloth masks” worked less well than “surgical masks.” This is too strong an observation to be gleaned from the data. The preprint provides two stratified calculations to estimate the efficacy of types of masks. In the first case, the authors analyzed villages randomized to only be given surgical masks and their matched control villages. In this case there were 190 pairs of villages consisting of $n_C=$103,247 individuals in the control group and $n_T=$113,082 individuals in the treatment group. They observed $i_C=$774 symptomatic and seropositive individuals in the control group and $i_T=$756 symptomatic and seropositive individuals in the treatment group. <em>This is a difference of 18 individuals.</em> The corresponding efficacy is 11%, still woefully low.</p>

<p>We can do a similar analysis for the villages only given cloth masks. There were 96 pairs of villages consisting of $n_C=$53,691 individuals in the control group and $n_T=$57,415 individuals in the treatment group. They observed $i_C=$332 symptomatic and seropositive individuals in the control group and $i_T=$330 symptomatic and seropositive individuals in the treatment group. <em>This is a difference of only 2 individuals.</em> Certainly, no one would put much faith in an intervention where we see a difference of 2 cases in a study with over one hundred thousand people. However, to further demonstrate the absurdity of the notion of efficacy, the observed efficacy for cloth masks in this study is 7%. I think in many people’s minds, the difference between 7% and 11% is small. And 7% should be considered “no effect” as should 11%. As a final absurd comparison, the study data shows cloth masks are more efficacious than purple surgical masks where the estimated efficacy is 0% ($n_C=$27,918, $n_T=$29,541, $i_C=$177, $i_T=$187)! Certainly, comparing a bunch of such small effects is not telling us much.</p>

<p>Anyone who spends too much time around statisticians will note that I never once tried to compute a p-value for any of these results. As I’ve belabored, obsession with statistical significance distracts us from discussing effect sizes. We should be able to just look at the effect size and conclude the study did not find a significant impact of masks on coronavirus spread. We don’t need a p-value to tell us 10% efficacy is not helpful in this context. But it’s also important to note that you can’t just run a standard binomial test on this data because it is cluster-randomized and the subjects are anything but independent. In the next blog, just for the sake of academic navel gazing, I’ll discuss the lack of statistical significance of this study and show why cluster randomized trials are inherently more challenging to interpret than standard RCTs.</p></div>
    </summary>
    <updated>2021-11-23T00:00:00Z</updated>
    <published>2021-11-23T00:00:00Z</published>
    <source>
      <id>http://benjamin-recht.github.io/</id>
      <author>
        <name>Ben Recht</name>
      </author>
      <link href="http://benjamin-recht.github.io/" rel="alternate" type="text/html"/>
      <link href="http://benjamin-recht.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Musings on systems, information, learning, and optimization.</subtitle>
      <title>arg min blog</title>
      <updated>2021-11-24T14:38:38Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.11072</id>
    <link href="http://arxiv.org/abs/2111.11072" rel="alternate" type="text/html"/>
    <title>Algorithmizing the Multiplicity Schwartz-Zippel Lemma</title>
    <feedworld_mtime>1637625600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>S. Bhandari, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Harsha:P=.html">P. Harsha</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kumar:M=.html">M. Kumar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shankar:A=.html">A. Shankar</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.11072">PDF</a><br/><b>Abstract: </b>The multiplicity Schwartz-Zippel lemma asserts that over a field, a
low-degree polynomial cannot vanish with high multiplicity very often on a
sufficiently large product set. Since its discovery in a work of Dvir,
Kopparty, Saraf and Sudan [SIAM J. Comput., 2013], the lemma has found numerous
applications in both math and computer science; in particular, in the
definition and properties of multiplicity codes by Kopparty, Saraf and Yekhanin
[J. ACM, 2014].
</p>
<p>In this work, we show how to algorithmize the multiplicity Schwartz-Zippel
lemma for arbitrary product sets over any field. In other words, we give an
efficient algorithm for unique decoding of multivariate multiplicity codes from
half their minimum distance on arbitrary product sets over all fields.
Previously, such an algorithm was known either when the underlying product set
had a nice algebraic structure: for instance, was a subfield (by Kopparty [ToC,
2015]) or when the underlying field had large (or zero) characteristic, the
multiplicity parameter was sufficiently large and the multiplicity code had
distance bounded away from $1$ (Bhandari, Harsha, Kumar and Sudan [STOC 2021]).
In particular, even unique decoding of bivariate multiplicity codes with
multiplicity two from half their minimum distance was not known over arbitrary
product sets over any field.
</p>
<p>Our algorithm builds upon a result of Kim and Kopparty [ToC, 2017] who gave
an algorithmic version of the Schwartz-Zippel lemma (without multiplicities) or
equivalently, an efficient algorithm for unique decoding of Reed-Muller codes
over arbitrary product sets. We introduce a refined notion of distance based on
the multiplicity Schwartz-Zippel lemma and design a unique decoding algorithm
for this distance measure. On the way, we give an alternate proof of Forney's
classical generalized minimum distance decoder that might be of independent
interest.
</p></div>
    </summary>
    <updated>2021-11-23T22:40:16Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2021-11-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.10980</id>
    <link href="http://arxiv.org/abs/2111.10980" rel="alternate" type="text/html"/>
    <title>Theoretically and Practically Efficient Parallel Nucleus Decomposition</title>
    <feedworld_mtime>1637625600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shi:Jessica.html">Jessica Shi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dhulipala:Laxman.html">Laxman Dhulipala</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shun:Julian.html">Julian Shun</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.10980">PDF</a><br/><b>Abstract: </b>This paper studies the nucleus decomposition problem, which has been shown to
be useful in finding dense substructures in graphs. We present a novel parallel
algorithm that is efficient both in theory and in practice. Our algorithm
achieves a work complexity matching the best sequential algorithm while also
having low depth (parallel running time), which significantly improves upon the
only existing parallel nucleus decomposition algorithm (Sariyuce et al., PVLDB
2018). The key to the theoretical efficiency of our algorithm is a new lemma
that bounds the amount of work done when peeling cliques from the graph,
combined with the use of a theoretically-efficient parallel algorithms for
clique listing and bucketing. We introduce several new practical optimizations,
including a new multi-level hash table structure to store information on
cliques space-efficiently and a technique for traversing this structure
cache-efficiently. On a 30-core machine with two-way hyper-threading on
real-world graphs, we achieve up to a 55x speedup over the state-of-the-art
parallel nucleus decomposition algorithm by Sariyuce et al., and up to a 40x
self-relative parallel speedup. We are able to efficiently compute larger
nucleus decompositions than prior work on several million-scale graphs for the
first time.
</p></div>
    </summary>
    <updated>2021-11-23T22:49:31Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-11-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.10939</id>
    <link href="http://arxiv.org/abs/2111.10939" rel="alternate" type="text/html"/>
    <title>A Dynamic Programming Algorithm to Compute Joint Distribution of Order Statistics on Graphs</title>
    <feedworld_mtime>1637625600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Galgana:Rigel.html">Rigel Galgana</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Greenwald:Amy.html">Amy Greenwald</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Oyakawa:Takehiro.html">Takehiro Oyakawa</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.10939">PDF</a><br/><b>Abstract: </b>Order statistics play a fundamental role in statistical procedures such as
risk estimation, outlier detection, and multiple hypothesis testing as well as
in the analyses of mechanism design, queues, load balancing, and various other
logistical processes involving ranks. In some of these cases, it may be
desirable to compute the \textit{exact} values from the joint distribution of
$d$ order statistics. While this problem is already computationally difficult
even in the case of $n$ independent random variables, the random variables
often have no such independence guarantees. Existing methods obtain the
cumulative distribution indirectly by first computing and then aggregating over
the marginal distributions. In this paper, we provide a more direct, efficient
algorithm to compute cumulative joint order statistic distributions of
dependent random variables that improves an existing dynamic programming
solution via dimensionality reduction techniques. Our solution guarantees a
$O(\frac{d^{d-1}}{n})$ and $O(d^{d})$ factor of improvement in both time and
space complexity respectively over previous methods.
</p></div>
    </summary>
    <updated>2021-11-23T22:53:35Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-11-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.10908</id>
    <link href="http://arxiv.org/abs/2111.10908" rel="alternate" type="text/html"/>
    <title>Multiscale entropic regularization for MTS on general metric spaces</title>
    <feedworld_mtime>1637625600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Ebrahimnejad:Farzam.html">Farzam Ebrahimnejad</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lee:James_R=.html">James R. Lee</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.10908">PDF</a><br/><b>Abstract: </b>We present an $O((\log n)^2)$-competitive algorithm for metrical task systems
(MTS) on any $n$-point metric space that is also $1$-competitive for service
costs. This matches the competitive ratio achieved by Bubeck, Cohen, Lee, and
Lee (2019) and the refined competitive ratios obtained by Coester and Lee
(2019). Those algorithms work by first randomly embedding the metric space into
an ultrametric and then solving MTS there. In contrast, our algorithm is cast
as regularized gradient descent where the regularizer is a multiscale metric
entropy defined directly on the metric space. This answers an open question of
Bubeck (Highlights of Algorithms, 2019).
</p></div>
    </summary>
    <updated>2021-11-23T22:45:17Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-11-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.10885</id>
    <link href="http://arxiv.org/abs/2111.10885" rel="alternate" type="text/html"/>
    <title>On Fairness and Stability in Two-Sided Matchings</title>
    <feedworld_mtime>1637625600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Gili Karni, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rothblum:Guy_N=.html">Guy N. Rothblum</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yona:Gal.html">Gal Yona</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.10885">PDF</a><br/><b>Abstract: </b>There are growing concerns that algorithms, which increasingly make or
influence important decisions pertaining to individuals, might produce outcomes
that discriminate against protected groups. We study such fairness concerns in
the context of a two-sided market, where there are two sets of agents, and each
agent has preferences over the other set. The goal is producing a matching
between the sets. This setting has been the focus of a rich body of work. The
seminal work of Gale and Shapley formulated a stability desideratum, and showed
that a stable matching always exists and can be found efficiently. We study
this question through the lens of metric-based fairness notions (Dwork et al.,
Kim et al.). We formulate appropriate definitions of fairness and stability in
the presence of a similarity metric, and ask: does a fair and stable matching
always exist? Can such a matching be found in polynomial time? Our
contributions are as follows: (1) Composition failures for classical
algorithms: We show that composing the Gale-Shapley algorithm with fair
hospital preferences can produce blatantly unfair outcomes. (2) New algorithms
for finding fair and stable matchings: Our main technical contributions are
efficient new algorithms for finding fair and stable matchings when: (i) the
hospitals' preferences are fair, and (ii) the fairness metric satisfies a
strong "proto-metric" condition: the distance between every two doctors is
either zero or one. In particular, these algorithms also show that, in this
setting, fairness and stability are compatible. (3) Barriers for finding fair
and stable matchings in the general case: We show that if the hospital
preferences can be unfair, or if the metric fails to satisfy the proto-metric
condition, then no algorithm in a natural class can find a fair and stable
matching. The natural class includes the classical Gale-Shapley algorithms and
our new algorithms.
</p></div>
    </summary>
    <updated>2021-11-23T22:55:10Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-11-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.10830</id>
    <link href="http://arxiv.org/abs/2111.10830" rel="alternate" type="text/html"/>
    <title>Simple circuit simulations of classical and quantum Turing machines</title>
    <feedworld_mtime>1637625600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gurevich:Yuri.html">Yuri Gurevich</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Blass:Andreas.html">Andreas Blass</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.10830">PDF</a><br/><b>Abstract: </b>We construct reversible Boolean circuits efficiently simulating reversible
Turing machines. Both the circuits and the simulation proof are rather simple.
Then we give a fairly straightforward generalization of the circuits and the
simulation proof to the quantum case.
</p></div>
    </summary>
    <updated>2021-11-23T22:37:25Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2021-11-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.10822</id>
    <link href="http://arxiv.org/abs/2111.10822" rel="alternate" type="text/html"/>
    <title>New Clocks, Optimal Line Formation and Efficient Replication Population Protocols (Making Population Protocols Alive)</title>
    <feedworld_mtime>1637625600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gasieniec:Leszek.html">Leszek Gasieniec</a>, Paul Spirakis, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Stachowiak:Grzegorz.html">Grzegorz Stachowiak</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.10822">PDF</a><br/><b>Abstract: </b>We consider the model of population protocols permitting presence of
dynamically changing edges connecting agents. Our main contribution is a new
constant space phase clock allowing to count parallel time $O(n\log n)$ whp in
the adopted model. This clock admits confirmation of slow leader election and
in turn construction of a line (and a ring) comprising every agent in the
optimal parallel time $\Theta(n\log n)$ and constant space. This improves on
the currently best known upper bound $O(n^2).$
</p>
<p>We also discuss a variant of the new clock in which utilisation of edges is
replaced by interaction of agents with a unique leader. This variant provides a
universal (for models with and without edges) synchronisation mechanism and is
adopted in some of our efficient line replication protocols.
</p></div>
    </summary>
    <updated>2021-11-23T22:47:44Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-11-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.10818</id>
    <link href="http://arxiv.org/abs/2111.10818" rel="alternate" type="text/html"/>
    <title>New Binary-Addition Tree Algorithm for the All-Multiterminal Binary-State Network Reliability Problem</title>
    <feedworld_mtime>1637625600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yeh:Wei=Chang.html">Wei-Chang Yeh</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.10818">PDF</a><br/><b>Abstract: </b>Various real-life applications, for example, Internet of Things, wireless
sensor networks, smart grids, transportation networks, communication networks,
social networks, and computer grid systems, are always modeled as network
structures. The binary-state network composed of binary-state (e.g.,
functioning or failed) components (arcs and/or nodes) is one of the most
popular network structures. The two-terminal network reliability is a success
probability that the network is still functioning and can be calculated by
verifying the connectivity between two specific nodes, and is an effective and
popular technique for evaluating the performance of all types of networks. To
obtain complete information for a making better decisions, a multi-terminal
network reliability extends the two specific nodes to a specific node subset in
which all nodes are connected. In this study, a new algorithm called the
all-multiterminal BAT is proposed by revising the binary-addition-tree
algorithm (BAT) and the layered-search algorithm (LSA) to calculate all
multi-terminal reliabilities. The efficiency and effectiveness of the proposed
all-multiterminal BAT are analyzed from the perspective of time complexity and
explained via numerical experiments to solve the all-multiterminal network
reliability problems.
</p></div>
    </summary>
    <updated>2021-11-23T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-11-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.10699</id>
    <link href="http://arxiv.org/abs/2111.10699" rel="alternate" type="text/html"/>
    <title>Faster Deterministic Approximation Algorithms for Correlation Clustering and Cluster Deletion</title>
    <feedworld_mtime>1637625600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Veldt:Nate.html">Nate Veldt</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.10699">PDF</a><br/><b>Abstract: </b>Correlation clustering is a framework for partitioning datasets based on
pairwise similarity and dissimilarity scores, and has been used for diverse
applications in bioinformatics, social network analysis, and computer vision.
Although many approximation algorithms have been designed for this problem, the
best theoretical results rely on obtaining lower bounds via expensive linear
programming relaxations. In this paper we prove new relationships between
correlation clustering problems and edge labeling problems related to the
principle of strong triadic closure. We use these connections to develop new
approximation algorithms for correlation clustering that have deterministic
constant factor approximation guarantees and avoid the canonical linear
programming relaxation. Our approach also extends to a variant of correlation
clustering called cluster deletion, that strictly prohibits placing negative
edges inside clusters. Our results include 4-approximation algorithms for
cluster deletion and correlation clustering, based on simplified linear
programs with far fewer constraints than the canonical relaxations. More
importantly, we develop faster techniques that are purely combinatorial, based
on computing maximal matchings in certain auxiliary graphs and hypergraphs.
This leads to a combinatorial 6-approximation for complete unweighted
correlation clustering, which is the best deterministic result for any method
that does not rely on linear programming. We also present the first
combinatorial constant factor approximation for cluster deletion.
</p></div>
    </summary>
    <updated>2021-11-23T22:54:11Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-11-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.10626</id>
    <link href="http://arxiv.org/abs/2111.10626" rel="alternate" type="text/html"/>
    <title>Learning algorithms versus automatability of Frege systems</title>
    <feedworld_mtime>1637625600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pich:J=aacute=n.html">Ján Pich</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Santhanam:Rahul.html">Rahul Santhanam</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.10626">PDF</a><br/><b>Abstract: </b>We connect learning algorithms and algorithms automating proof search in
propositional proof systems: for every sufficiently strong, well-behaved
propositional proof system $P$, we prove that the following statements are
equivalent,
</p>
<p>1. Provable learning: $P$ proves efficiently that p-size circuits are
learnable by subexponential-size circuits over the uniform distribution with
membership queries.
</p>
<p>2. Provable automatability: $P$ proves efficiently that $P$ is automatable by
non-uniform circuits on propositional formulas expressing p-size circuit lower
bounds.
</p>
<p>Here, $P$ is sufficiently strong and well-behaved if I.-III. holds: I. $P$
p-simulates Je\v{r}\'abek's system $WF$ (which strengthens the Extended Frege
system $EF$ by a surjective weak pigeonhole principle); II. $P$ satisfies some
basic properties of standard proof systems which p-simulate $WF$; III. $P$
proves efficiently for some Boolean function $h$ that $h$ is hard on average
for circuits of subexponential size. For example, if III. holds for $P=WF$,
then Items 1 and 2 are equivalent for $P=WF$.
</p>
<p>If there is a function $h\in NE\cap coNE$ which is hard on average for
circuits of size $2^{n/4}$, for each sufficiently big $n$, then there is an
explicit propositional proof system $P$ satisfying properties I.-III., i.e. the
equivalence of Items 1 and 2 holds for $P$.
</p></div>
    </summary>
    <updated>2021-11-23T22:42:09Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2021-11-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.10607</id>
    <link href="http://arxiv.org/abs/2111.10607" rel="alternate" type="text/html"/>
    <title>Oblivious Online Contention Resolution Schemes</title>
    <feedworld_mtime>1637625600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fu:Hu.html">Hu Fu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lu:Pinyan.html">Pinyan Lu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tang:Zhihao_Gavin.html">Zhihao Gavin Tang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Turkieltaub:Abner.html">Abner Turkieltaub</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wu:Hongxun.html">Hongxun Wu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wu:Jinzhao.html">Jinzhao Wu</a>, Qianfan Zhang <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.10607">PDF</a><br/><b>Abstract: </b>Contention resolution schemes (CRSs) are powerful tools for obtaining "ex
post feasible" solutions from candidates that are drawn from "ex ante feasible"
distributions. Online contention resolution schemes (OCRSs), the online
version, have found myriad applications in Bayesian and stochastic problems,
such as prophet inequalities and stochastic probing.
</p>
<p>When the ex ante distribution is unknown, it was unknown whether good
CRSs/OCRSs exist with no sample (in which case the scheme is oblivious) or few
samples from the distribution. In this work, we give a simple
$\frac{1}{e}$-selectable oblivious single item OCRS by mixing two simple
schemes evenly, and show, via a Ramsey theory argument, that it is optimal. On
the negative side, we show that no CRS or OCRS with $O(1)$ samples can be
$\Omega(1)$-balanced/selectable (i.e., preserve every active candidate with a
constant probability) for graphic or transversal matroids.
</p></div>
    </summary>
    <updated>2021-11-23T22:45:43Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-11-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.10577</id>
    <link href="http://arxiv.org/abs/2111.10577" rel="alternate" type="text/html"/>
    <title>Distributed CONGEST Approximation of Weighted Vertex Covers and Matchings</title>
    <feedworld_mtime>1637625600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Faour:Salwa.html">Salwa Faour</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fuchs:Marc.html">Marc Fuchs</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kuhn:Fabian.html">Fabian Kuhn</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.10577">PDF</a><br/><b>Abstract: </b>We provide CONGEST model algorithms for approximating minimum weighted vertex
cover and the maximum weighted matching. For bipartite graphs, we show that a
$(1+\varepsilon)$-approximate weighted vertex cover can be computed
deterministically in polylogarithmic time. This generalizes a corresponding
result for the unweighted vertex cover problem shown in [Faour, Kuhn; OPODIS
'20]. Moreover, we show that in general weighted graph families that are closed
under taking subgraphs and in which we can compute an independent set of weight
at least a $\lambda$-fraction of the total weight, one can compute a
$(2-2\lambda +\varepsilon)$-approximate weighted vertex cover in
polylogarithmic time in the CONGEST model. Our result in particular implies
that in graphs of arboricity $a$, one can compute a
$(2-1/a+\varepsilon)$-approximate weighted vertex cover.
</p>
<p>For maximum weighted matchings, we show that a $(1-\varepsilon)$-approximate
solution can be computed deterministically in polylogarithmic CONGEST rounds
(for constant $\varepsilon$). We also provide a more efficient randomized
algorithm. Our algorithm generalizes results of [Lotker, Patt-Shamir, Pettie;
SPAA '08] and [Bar-Yehuda, Hillel, Ghaffari, Schwartzman; PODC '17] for the
unweighted case.
</p>
<p>Finally, we show that even in the LOCAL model and in bipartite graphs of
degree $\leq 3$, if $\varepsilon&lt;\varepsilon_0$ for some constant
$\varepsilon_0&gt;0$, then computing a $(1+\varepsilon)$-approximation for the
unweighted minimum vertex cover problem requires $\Omega\big(\frac{\log
n}{\varepsilon}\big)$ rounds. This generalizes aresult of [G\"o\"os, Suomela;
DISC '12], who showed that computing a $(1+\varepsilon_0)$-approximation in
such graphs requires $\Omega(\log n)$ rounds.
</p></div>
    </summary>
    <updated>2021-11-23T22:50:11Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-11-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.10538</id>
    <link href="http://arxiv.org/abs/2111.10538" rel="alternate" type="text/html"/>
    <title>Approximation Algorithms for LCS and LIS with Truly Improved Running Times</title>
    <feedworld_mtime>1637625600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rubinstein:Aviad.html">Aviad Rubinstein</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Seddighin:Saeed.html">Saeed Seddighin</a>, Zhao Song, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sun:Xiaorui.html">Xiaorui Sun</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.10538">PDF</a><br/><b>Abstract: </b>Longest common subsequence ($\mathsf{LCS}$) is a classic and central problem
in combinatorial optimization. While $\mathsf{LCS}$ admits a quadratic time
solution, recent evidence suggests that solving the problem may be impossible
in truly subquadratic time. A special case of $\mathsf{LCS}$ wherein each
character appears at most once in every string is equivalent to the longest
increasing subsequence problem ($\mathsf{LIS}$) which can be solved in
quasilinear time. In this work, we present novel algorithms for approximating
$\mathsf{LCS}$ in truly subquadratic time and $\mathsf{LIS}$ in truly sublinear
time. Our approximation factors depend on the ratio of the optimal solution
size over the input size. We denote this ratio by $\lambda$ and obtain the
following results for $\mathsf{LCS}$ and $\mathsf{LIS}$ without any prior
knowledge of $\lambda$.
</p>
<p>$\bullet$ A truly subquadratic time algorithm for $\mathsf{LCS}$ with
approximation factor $\Omega(\lambda^3)$.
</p>
<p>$\bullet$A truly sublinear time algorithm for $\mathsf{LIS}$ with
approximation factor $\Omega(\lambda^3)$.
</p>
<p>Triangle inequality was recently used by [Boroujeni, Ehsani, Ghodsi,
HajiAghayi and Seddighin SODA 2018] and [Charkraborty, Das, Goldenberg, Koucky
and Saks FOCS 2018] to present new approximation algorithms for edit distance.
Our techniques for $\mathsf{LCS}$ extend the notion of triangle inequality to
non-metric settings.
</p></div>
    </summary>
    <updated>2021-11-23T22:51:39Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-11-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.10436</id>
    <link href="http://arxiv.org/abs/2111.10436" rel="alternate" type="text/html"/>
    <title>A counter-example to the probabilistic universal graph conjecture via randomized communication complexity</title>
    <feedworld_mtime>1637625600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hambardzumyan:Lianna.html">Lianna Hambardzumyan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hatami:Hamed.html">Hamed Hatami</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hatami:Pooya.html">Pooya Hatami</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.10436">PDF</a><br/><b>Abstract: </b>We refute the Probabilistic Universal Graph Conjecture of Harms, Wild, and
Zamaraev, which states that a hereditary graph property admits a constant-size
probabilistic universal graph if and only if it is stable and has at most
factorial speed.
</p>
<p>Our counter-example follows from the existence of a sequence of $n \times n$
Boolean matrices $M_n$, such that their public-coin randomized communication
complexity tends to infinity, while the randomized communication complexity of
every $n^{1/4}\times n^{1/4}$ submatrix of $M_n$ is bounded by a universal
constant.
</p></div>
    </summary>
    <updated>2021-11-23T22:41:37Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2021-11-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.10409</id>
    <link href="http://arxiv.org/abs/2111.10409" rel="alternate" type="text/html"/>
    <title>The Acrobatics of BQP</title>
    <feedworld_mtime>1637625600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Aaronson:Scott.html">Scott Aaronson</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Ingram:DeVon.html">DeVon Ingram</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kretschmer:William.html">William Kretschmer</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.10409">PDF</a><br/><b>Abstract: </b>We show that, in the black-box setting, the behavior of quantum
polynomial-time ($\mathsf{BQP}$) can be remarkably decoupled from that of
classical complexity classes like $\mathsf{NP}$. Specifically:
</p>
<p>-There exists an oracle relative to which
$\mathsf{NP^{BQP}}\not\subset\mathsf{BQP^{PH}}$, resolving a 2005 problem of
Fortnow. As a corollary, there exists an oracle relative to which
$\mathsf{P}=\mathsf{NP}$ but $\mathsf{BQP}\neq\mathsf{QCMA}$.
</p>
<p>-Conversely, there exists an oracle relative to which
$\mathsf{BQP^{NP}}\not\subset\mathsf{PH^{BQP}}$.
</p>
<p>-Relative to a random oracle, $\mathsf{PP}=\mathsf{PostBQP}$ is not contained
in the "$\mathsf{QMA}$ hierarchy"
$\mathsf{QMA}^{\mathsf{QMA}^{\mathsf{QMA}^{\cdots}}}$, and more generally
$\mathsf{PP}\not\subset
(\mathsf{MIP}^*)^{(\mathsf{MIP}^*)^{(\mathsf{MIP}^*)^{\cdots}}}$ (!), despite
the fact that $\mathsf{MIP}^*=\mathsf{RE}$ in the unrelativized world. This
result shows that there is no black-box quantum analogue of Stockmeyer's
approximate counting algorithm.
</p>
<p>-Relative to a random oracle,
$\mathsf{\Sigma}_{k+1}^\mathsf{P}\not\subset\mathsf{BQP}^{\mathsf{\Sigma}_{k}^\mathsf{P}}$
for every $k$.
</p>
<p>-There exists an oracle relative to which $\mathsf{BQP}=\mathsf{P^{\# P}}$
and yet $\mathsf{PH}$ is infinite.
</p>
<p>-There exists an oracle relative to which
$\mathsf{P}=\mathsf{NP}\neq\mathsf{BQP}=\mathsf{P^{\# P}}$.
</p>
<p>To achieve these results, we build on the 2018 achievement by Raz and Tal of
an oracle relative to which $\mathsf{BQP}\not \subset \mathsf{PH}$, and
associated results about the Forrelation problem. We also introduce new tools
that might be of independent interest. These include a "quantum-aware" version
of the random restriction method, a concentration theorem for the block
sensitivity of $\mathsf{AC^0}$ circuits, and a (provable) analogue of the
Aaronson-Ambainis Conjecture for sparse oracles.
</p></div>
    </summary>
    <updated>2021-11-23T22:42:47Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2021-11-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-4583902398250806221</id>
    <link href="http://blog.computationalcomplexity.org/feeds/4583902398250806221/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2021/11/finding-element-with-nonadaptive.html#comment-form" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/4583902398250806221" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/4583902398250806221" rel="self" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2021/11/finding-element-with-nonadaptive.html" rel="alternate" type="text/html"/>
    <title>Finding an element with nonadaptive questions</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Suppose you have a non-empty subset S of {1,...N} and want to find an element of S. You can ask arbitrary questions of the form "Does S contain an element in A?" for some A a subset of {1,...N}. How many questions do you need?</p><p>Of course you can use binary search, using questions of the form "is there number greater than <i>m</i> in S?". This takes log N questions and it's easy to show that's tight.</p><p>What if you have to ask all the questions ahead of time before you get any of the answers? Now binary search won't work. If |S|=1 you can ask "is there a number in S whose <i>i</i>th bit is one?" That also takes log N questions.</p><p>For arbitrary S the situation is trickier. With randomness you still don't need too many questions. <a href="https://doi.org/10.1007/BF02579206">Mulmuley, Vazirani and Vazirani</a>'s isolating lemma works as follows: For each i &lt;= log N, pick a random weight w<sub>i</sub> between 1 and 2 log N. For each element m in S, let the weight of m be the sum of the weights of the bits of m that are 1. With probability at least 1/2 there will be an m with an unique minimum weight. There's a <a href="https://blog.computationalcomplexity.org/2015/07/new-proof-of-isolation-lemma.html">cool proof</a> of an isolating lemma by Noam Ta-Shma.</p><p>Once you have this lemma, you can ask questions of the form "Given a list of w<sub>i</sub>'s and a value v, is there an m in S of weight v whose jth bit is 1?" Choosing w<sub>i</sub> and v at random you have a 1/O(log N) chance of a single m whose weight is v, and trying all j will give you a witness. </p><p>Randomness is required. The X-search problem described by <a href="https://doi.org/10.1016/0022-0000(88)90027-X">Karp, Upfal and Wigderson</a> shows that any deterministic procedure requires essentially N queries. </p><p>This all came up because Bill had some colleagues looking a similar problems testing machines for errors. </p><p>I've been interested in the related question of finding satisfying assignments using non-adaptive NP queries. The results are similar to the above. In particular, you can randomly find a satisfying assignment with high probability using a polynomial number of non-adaptive NP queries. It follows from the techniques above, and even earlier papers, but I haven't been able to track down a reference for the first paper to do so.</p></div>
    </content>
    <updated>2021-11-22T20:39:00Z</updated>
    <published>2021-11-22T20:39:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="http://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2021-11-24T10:13:54Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://emanueleviola.wordpress.com/?p=964</id>
    <link href="https://emanueleviola.wordpress.com/2021/11/22/phd-in-complexity-theory-with-me/" rel="alternate" type="text/html"/>
    <title>PhD in complexity theory with me</title>
    <summary>This is around the time when people start applying for PhD programs, at least judging from my inbox. If you are applying, consider that we have an amazing theory group , are highly ranked, have tons of resources, and I am looking for students.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>This is around the time when people start applying for PhD programs, at least judging from my inbox.  If you are applying, consider that we have an <a href="https://www2.ccs.neu.edu/theory/">amazing theory group </a>, are <a href="http://csrankings.org/#/index?all&amp;us">highly ranked</a>, have <a href="https://philanthropynewsdigest.org/news/northeastern-receives-50-million-for-college-of-computer-sciences">tons </a>of <a href="https://mainestartupsinsider.com/roux-institute-receives-another-100m-gift-to-support-its-high-tech-education-initiative-in-portland/">resources</a>, and I am looking for students.</p></div>
    </content>
    <updated>2021-11-22T19:31:33Z</updated>
    <published>2021-11-22T19:31:33Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Manu</name>
    </author>
    <source>
      <id>https://emanueleviola.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://emanueleviola.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://emanueleviola.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://emanueleviola.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://emanueleviola.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>by Manu</subtitle>
      <title>Thoughts</title>
      <updated>2021-11-24T14:37:56Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/11/22/assistant-professors-theory-positions-at-uestc-chengdu-china-apply-by-february-28-2022/</id>
    <link href="https://cstheory-jobs.org/2021/11/22/assistant-professors-theory-positions-at-uestc-chengdu-china-apply-by-february-28-2022/" rel="alternate" type="text/html"/>
    <title>Assistant Professors, theory positions at UESTC, Chengdu, China (apply by February 28, 2022)</title>
    <summary>The theory group at the cs school invites applications for Assistant Professor positions. The school is a top school in China and competitive at the world stage. We thrive to become among the best theoretical computer science groups in China. By joining us, you work with experienced, young, exciting, curiosity driven researchers and talented students. […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The theory group at the cs school invites applications for Assistant Professor positions. The school is a top school in China and competitive at the world stage. We thrive to become among the best theoretical computer science groups in China. By joining us, you work with experienced, young, exciting, curiosity driven researchers and talented students. Life is exciting &amp; remuneration is generous.</p>
<p>Website: <a href="https://tcs.uestc.edu.cn/">https://tcs.uestc.edu.cn/</a><br/>
Email: bmk@uestc.edu.cn</p></div>
    </content>
    <updated>2021-11-22T12:07:31Z</updated>
    <published>2021-11-22T12:07:31Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-11-24T14:37:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/11/21/research-fellow-at-university-of-oxford-apply-by-november-29-2021/</id>
    <link href="https://cstheory-jobs.org/2021/11/21/research-fellow-at-university-of-oxford-apply-by-november-29-2021/" rel="alternate" type="text/html"/>
    <title>Research Fellow at University of Oxford (apply by November 29, 2021)</title>
    <summary>The Department of Computer Science is pleased to invite applications for the Glasstone Fellowship in Computer Science—a three-year postdoctoral fellowship supported by the Glasstone Bequest. Candidates should be completing or have recently (i.e. normally within the past 3 years) completed a doctorate in Computer Science or a closely related discipline. Website: https://www.cs.ox.ac.uk/news/1984-full.html Email: james.worrell@cs.ox.ac.uk</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Department of Computer Science is pleased to invite applications for the Glasstone Fellowship in Computer Science—a three-year<br/>
postdoctoral fellowship supported by the Glasstone Bequest. Candidates should be completing or have recently (i.e. normally within the past 3 years) completed a doctorate in<br/>
Computer Science or a closely related discipline.</p>
<p>Website: <a href="https://www.cs.ox.ac.uk/news/1984-full.html">https://www.cs.ox.ac.uk/news/1984-full.html</a><br/>
Email: james.worrell@cs.ox.ac.uk</p></div>
    </content>
    <updated>2021-11-21T18:32:47Z</updated>
    <published>2021-11-21T18:32:47Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-11-24T14:37:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/166</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/166" rel="alternate" type="text/html"/>
    <title>TR21-166 |  Average-case Hardness of NP and PH from Worst-case Fine-grained Assumptions | 

	Lijie Chen, 

	Shuichi Hirahara, 

	Neekon Vafa</title>
    <summary>What is a minimal worst-case complexity assumption that implies non-trivial average-case hardness of NP or PH? This question is well motivated by the theory of fine-grained average-case complexity and fine-grained cryptography. In this paper, we show that several standard worst-case complexity assumptions are sufficient to imply non-trivial average-case hardness of NP or PH:
    
    1. NTIME[$n$] cannot be solved in quasi-linear time on average if UP is not in DTIME[$2^{\widetilde{O}\left(\sqrt{n}\right)}$].
    
    2. $\Sigma_2$TIME[$n$] cannot be solved in quasi-linear time on average if $\Sigma_k$SAT cannot be solved in time $2^{\widetilde{O}\left(\sqrt{n}\right)}$ for some constant $k$. Previously, it was not known if even average-case hardness of $\Sigma_3$SAT implies the average-case hardness of $\Sigma_2$TIME[$n$].
    
    3. Under the Exponential-Time Hypothesis (ETH), there is no average-case $n^{1+\varepsilon}$-time algorithm for NTIME[$n$] whose running time can be estimated in time $n^{1+\varepsilon}$ for some constant $\varepsilon &gt; 0$.
    
    Our results are given by generalizing the non-black-box worst-case-to-average-case connections presented by Hirahara (STOC 2021) to the settings of fine-grained complexity. To do so, we construct quite efficient complexity-theoretic pseudorandom generators under the assumption that the nondeterministic linear time is easy on average, which may be of independent interest.</summary>
    <updated>2021-11-21T01:35:02Z</updated>
    <published>2021-11-21T01:35:02Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-11-24T14:37:23Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/165</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/165" rel="alternate" type="text/html"/>
    <title>TR21-165 |  Improved Merlin-Arthur Protocols for Central Problems in Fine-Grained Complexity | 

	Shyan Akmal, 

	Lijie Chen, 

	Ce Jin, 

	Malvika Raj, 

	Ryan Williams</title>
    <summary>In a Merlin-Arthur proof system, the proof verifier (Arthur) accepts valid proofs (from Merlin) with probability $1$, and rejects invalid proofs with probability arbitrarily close to $1$. The running time of such a system is defined to be the length of Merlin's proof plus the running time of Arthur.  We provide new Merlin-Arthur proof systems for some key problems in fine-grained complexity. In several cases our proof systems have optimal running time. Our main results include:

$\bullet$ Certifying that a list of $n$ integers has no 3-SUM solution can be done in Merlin-Arthur time $\tilde{O}(n)$. Previously, Carmosino et al. [ITCS 2016] showed that the problem has a nondeterministic algorithm running in $\tilde{O}(n^{1.5})$  time (that is, there is a proof system with proofs of length $\tilde{O}(n^{1.5})$ and a deterministic verifier running in $\tilde{O}(n^{1.5})$ time).

$\bullet$ Counting the number of $k$-cliques with total edge weight equal to zero in an $n$-node graph can be done in Merlin-Arthur time $\tilde O(n^{\lceil k/2\rceil })$ (where $k\ge 3$). For odd $k$, this bound can be further improved for sparse graphs: for example, counting the number of zero-weight triangles in an $m$-edge graph can be done in Merlin-Arthur time $\tilde O(m)$. Previous Merlin-Arthur protocols by Williams [CCC'16] and Bj\"orklund and Kaski [PODC'16] could only count $k$-cliques in unweighted graphs, and had worse running times for small $k$.

$\bullet$ Computing the All-Pairs Shortest Distances matrix for an $n$-node graph can be done in Merlin-Arthur time $\tilde{O}(n^2)$. Note this is optimal, as the matrix can have $\Omega(n^2)$ nonzero entries in general. Previously, Carmosino et al. [ITCS 2016] showed that this problem has an $\tilde{O}(n^{2.94})$ nondeterministic time algorithm.

$\bullet$ Certifying that an $n$-variable $k$-CNF is unsatisfiable can be done in Merlin-Arthur time $2^{n/2 - n/O(k)}$. We also observe an algebrization barrier for the previous $2^{n/2}\cdot \mathrm{poly}(n)$-time Merlin-Arthur protocol of R. Williams [CCC'16] for $\#$SAT: in particular, his protocol algebrizes, and we observe there is no algebrizing protocol for $k$-UNSAT running in $2^{n/2}/n^{\omega(1)}$ time. Therefore we have to exploit non-algebrizing properties to obtain our new protocol.


$\bullet$ Certifying a Quantified Boolean Formula is true can be done in Merlin-Arthur time $2^{4n/5}\cdot \mathrm{poly}(n)$. Previously, the only nontrivial result known along these lines was an Arthur-Merlin-Arthur protocol (where Merlin's proof depends on some of Arthur's coins) running in $2^{2n/3}\cdot\mathrm{poly}(n)$ time. 

Due to the centrality of these problems in fine-grained complexity, our results have consequences for many other problems of interest. For example, our work implies that certifying there is no Subset Sum solution to $n$ integers can be done in Merlin-Arthur time $2^{n/3}\cdot\mathrm{poly}(n)$, improving on the previous best protocol by Nederlof [IPL 2017] which took $2^{0.49991n}\cdot\mathrm{poly}(n)$ time.</summary>
    <updated>2021-11-21T00:21:01Z</updated>
    <published>2021-11-21T00:21:01Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-11-24T14:37:23Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/11/20/assistant-associate-professors-at-aalto-university-apply-by-january-12-2022/</id>
    <link href="https://cstheory-jobs.org/2021/11/20/assistant-associate-professors-at-aalto-university-apply-by-january-12-2022/" rel="alternate" type="text/html"/>
    <title>Assistant &amp; Associate Professors at Aalto University (apply by January 12, 2022)</title>
    <summary>We invite applications for tenure-track positions at the Assistant Professor level, and tenured positions at the Associate Professor level. We are a diverse community welcoming applications in ALL AREAS of Computer Science. Our CS Theory group (https://research.cs.aalto.fi/theory/) has e.g. received the best paper awards in FOCS 2019 and ICALP 2017, as well as ERC starting […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>We invite applications for tenure-track positions at the Assistant Professor level, and tenured positions at the Associate Professor level. We are a diverse community welcoming applications in ALL AREAS of Computer Science. Our CS Theory group (<a href="https://research.cs.aalto.fi/theory/">https://research.cs.aalto.fi/theory/</a>) has e.g. received the best paper awards in FOCS 2019 and ICALP 2017, as well as ERC starting grants in 2014 and 2017.</p>
<p>Website: <a href="https://bit.ly/aalto-csprof">https://bit.ly/aalto-csprof</a><br/>
Email: laura.kuusisto-noponen@aalto.fi</p></div>
    </content>
    <updated>2021-11-20T19:20:40Z</updated>
    <published>2021-11-20T19:20:40Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-11-24T14:37:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/11/19/simons-berkeley-fellowships-for-fall-2022-and-spring-2023-at-simons-institute-for-the-theory-of-computing-apply-by-december-15-2021/</id>
    <link href="https://cstheory-jobs.org/2021/11/19/simons-berkeley-fellowships-for-fall-2022-and-spring-2023-at-simons-institute-for-the-theory-of-computing-apply-by-december-15-2021/" rel="alternate" type="text/html"/>
    <title>Simons-Berkeley Fellowships for Fall 2022 and Spring 2023 at Simons Institute for the Theory of Computing (apply by December 15, 2021)</title>
    <summary>The Simons Institute for the Theory of Computing invites applications for Simons-Berkeley Research Fellowships for the Fall 2022 and Spring 2023 semesters. The Institute will host programs on “Data-Driven Decision Processes” and “Graph Limits and Processes on Networks: From Epidemics to Misinformation” in Fall 2022 and “Meta-Complexity in Spring 2023. Website: https://simons.berkeley.edu/simons-berkeley-research-fellowship-call-applications Email: simonsvisitorservices@berkeley.edu</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Simons Institute for the Theory of Computing invites applications for Simons-Berkeley Research Fellowships for the Fall 2022 and Spring 2023 semesters. The Institute will host programs on “Data-Driven Decision Processes” and “Graph Limits and Processes on Networks: From Epidemics to Misinformation” in Fall 2022 and “Meta-Complexity in Spring 2023.</p>
<p>Website: <a href="https://simons.berkeley.edu/simons-berkeley-research-fellowship-call-applications">https://simons.berkeley.edu/simons-berkeley-research-fellowship-call-applications</a><br/>
Email: simonsvisitorservices@berkeley.edu</p></div>
    </content>
    <updated>2021-11-19T22:07:32Z</updated>
    <published>2021-11-19T22:07:32Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-11-24T14:37:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://scottaaronson.blog/?p=6129</id>
    <link href="https://scottaaronson.blog/?p=6129" rel="alternate" type="text/html"/>
    <link href="https://scottaaronson.blog/?p=6129#comments" rel="replies" type="text/html"/>
    <link href="https://scottaaronson.blog/?feed=atom&amp;p=6129" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">The Acrobatics of BQP</title>
    <summary xml:lang="en-US">Just in case anyone is depressed this afternoon and needs something to cheer them up, students William Kretschmer, DeVon Ingram, and I have finally put out a new paper: The Acrobatics of BQP Abstract: We show that, in the black-box setting, the behavior of quantum polynomial-time (BQP) can be remarkably decoupled from that of classical […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>Just in case anyone is depressed this afternoon and needs something to cheer them up, students <a href="https://www.cs.utexas.edu/~kretsch/">William Kretschmer</a>, <a href="https://www.quantitativebiology.northwestern.edu/2021/02/23/three-students-awarded-prizes-in-the-great-math-challenge-in-biology-contest/">DeVon Ingram</a>, and I have finally put out a new paper:</p>



<blockquote class="wp-block-quote"><p><strong><a href="https://eccc.weizmann.ac.il/report/2021/164/">The Acrobatics of BQP</a></strong></p><p><strong>Abstract:</strong> We show that, in the black-box setting, the behavior of quantum polynomial-time (BQP) can be remarkably decoupled from that of classical complexity classes like NP.  Specifically:</p><p>– There exists an oracle relative to which NP<sup>BQP</sup>⊄BQP<sup>PH</sup>, resolving a 2005 problem of Fortnow. Interpreted another way, we show that AC<sup>0</sup> circuits cannot perform useful homomorphic encryption on instances of the Forrelation problem. As a corollary, there exists an oracle relative to which P=NP but BQP≠QCMA.</p><p>– Conversely, there exists an oracle relative to which BQP<sup>NP</sup>⊄PH<sup>BQP</sup>.</p><p>– Relative to a random oracle, PP=PostBQP is not contained in the “QMA hierarchy” QMA<sup>QMA^QMA^…</sup>, and more generally PP⊄(MIP*)<sup>(MIP*)^(MIP*)^…</sup> (!), despite the fact that MIP*=RE in the unrelativized world. This result shows that there is no black-box quantum analogue of Stockmeyer’s approximate counting algorithm.</p><p>– Relative to a random oracle, Σ<sub>k+1</sub>⊄BQP<sup>Σ_k</sup> for every k.</p><p>– There exists an oracle relative to which BQP=P<sup>#P</sup> and yet PH is infinite. (By contrast, if NP⊆BPP, then PH collapses relative to all oracles.)</p><p>– There exists an oracle relative to which P=NP≠BQP=P<sup>#P</sup>.</p><p>To achieve these results, we build on the 2018 achievement by Raz and Tal of an oracle relative to which BQP⊄PH, and associated results about the Forrelation problem. We also introduce new tools that might be of independent interest. These include a “quantum-aware” version of the random restriction method, a concentration theorem for the block sensitivity of AC<sup>0</sup> circuits, and a (provable) analogue of the Aaronson-Ambainis Conjecture for sparse oracles.</p></blockquote>



<p>Incidentally, particularly when I’ve worked on a project with students, I’m often tremendously excited and want to shout about it from the rooftops for the students’ sake … but then I also don’t want to use this blog to privilege my own papers “unfairly.”  Can anyone suggest a principle that I should follow going forward?</p></div>
    </content>
    <updated>2021-11-19T21:48:06Z</updated>
    <published>2021-11-19T21:48:06Z</published>
    <category scheme="https://scottaaronson.blog" term="Complexity"/>
    <category scheme="https://scottaaronson.blog" term="Quantum"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://scottaaronson.blog/?feed=atom</id>
      <icon>https://scottaaronson.blog/wp-content/uploads/2021/10/cropped-Jacket-32x32.gif</icon>
      <link href="https://scottaaronson.blog" rel="alternate" type="text/html"/>
      <link href="https://scottaaronson.blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2021-11-19T21:48:06Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/11/19/postdoc-at-georgia-institute-of-technology-apply-by-december-15-2021/</id>
    <link href="https://cstheory-jobs.org/2021/11/19/postdoc-at-georgia-institute-of-technology-apply-by-december-15-2021/" rel="alternate" type="text/html"/>
    <title>PostDoc at Georgia Institute of Technology (apply by December 15, 2021)</title>
    <summary>Algorithms and Randomness Center (ARC) at Georgia Tech is seeking postdoctoral fellows starting Fall 2022. ARC has faculty associated with many departments including CS, Math, ISyE. The selected candidate may work on any aspect of algorithms, optimization, broadly interpreted. Qualified applicants must possess a PhD in CS, Math, OR or a related field. Apply by […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Algorithms and Randomness Center (ARC) at Georgia Tech is seeking postdoctoral fellows starting Fall 2022. ARC has faculty associated with many departments including CS, Math, ISyE. The selected candidate may work on any aspect of algorithms, optimization, broadly interpreted. Qualified applicants must possess a PhD in CS, Math, OR or a related field. Apply by December 15, 2021.</p>
<p>Website: <a href="http://arc.gatech.edu/node/384">http://arc.gatech.edu/node/384</a><br/>
Email: ftonge3@cc.gatech.edu</p></div>
    </content>
    <updated>2021-11-19T20:01:19Z</updated>
    <published>2021-11-19T20:01:19Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-11-24T14:37:36Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://toc4fairness.org/?p=1968</id>
    <link href="https://toc4fairness.org/our-2022-postdoc-program-is-up/" rel="alternate" type="text/html"/>
    <title>Our 2022 Postdoc Program is up</title>
    <summary>We are excited to announce our new postdoc program. We are seeking strong candidates from a diverse set of academic backgrounds and personal experiences who want to work with one ...</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>We are excited to announce <a href="https://toc4fairness.org/postdoc-opportunities/">our new postdoc program</a>. We are seeking strong candidates from a diverse set of academic backgrounds and personal experiences who want to work with one or more of the PIs on algorithmic fairness and responsible computing more broadly. We expect to be extending multiple offers.  </p></div>
    </content>
    <updated>2021-11-19T13:45:11Z</updated>
    <published>2021-11-19T13:45:11Z</published>
    <category term="Blog"/>
    <author>
      <name>Omer Reingold</name>
    </author>
    <source>
      <id>https://toc4fairness.org</id>
      <logo>https://i1.wp.com/toc4fairness.org/wp-content/uploads/2020/10/cropped-favicon.png?fit=32%2C32&amp;ssl=1</logo>
      <link href="https://toc4fairness.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://toc4fairness.org" rel="alternate" type="text/html"/>
      <subtitle>a simons collaboration project</subtitle>
      <title>TOC for Fairness</title>
      <updated>2021-11-24T14:39:01Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/164</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/164" rel="alternate" type="text/html"/>
    <title>TR21-164 |  The Acrobatics of BQP | 

	Scott Aaronson, 

	DeVon Ingram, 

	William Kretschmer</title>
    <summary>We show that, in the black-box setting, the behavior of quantum polynomial-time (${BQP}$) can be remarkably decoupled from that of classical complexity classes like ${NP}$. Specifically:

-There exists an oracle relative to which ${NP}^{{BQP}}\not \subset {BQP}^{{PH}}$, resolving a 2005 problem of Fortnow. Interpreted another way, we show that ${AC^0}$ circuits cannot perform useful homomorphic encryption on instances of the Forrelation problem. As a corollary, there exists an oracle relative to which ${P} = {NP}$ but ${BQP} \neq {QCMA}$.
-Conversely, there exists an oracle relative to which ${BQP}^{{NP}}\not \subset {PH}^{{BQP}}$.
-Relative to a random oracle, ${PP} = {PostBQP}$ is not contained in the "${QMA}$ hierarchy" ${QMA}^{{QMA}^{{QMA}^{\cdots}}}$, and more generally ${PP} \not\subset ({MIP}^*)^{({MIP}^*)^{({MIP}^*)^{\cdots}}}$ (!), despite the fact that ${MIP}^{\ast}={RE}$ in the unrelativized world. This result shows that there is no black-box quantum analogue of Stockmeyer's approximate counting algorithm.
-Relative to a random oracle, ${\Sigma}_{k+1}^{P} \not\subset {BQP}^{{\Sigma}_{k}^{P}}$ for every $k$.
-There exists an oracle relative to which ${BQP} = {P^{\# P}}$ and yet ${PH}$ is infinite. (By contrast, if ${NP}\subseteq{BPP}$, then ${PH}$ collapses relative to all oracles.)
-There exists an oracle relative to which ${P}={NP} \neq {BQP}={P}^{{\#P}}$.

To achieve these results, we build on the 2018 achievement by Raz and Tal of an oracle relative to which ${BQP}\not \subset {PH}$, and associated results about the Forrelation problem. We also introduce new tools that might be of independent interest. These include a "quantum-aware" version of the random restriction method, a concentration theorem for the block sensitivity of ${AC^0}$ circuits, and a (provable) analogue of the Aaronson-Ambainis Conjecture for sparse oracles.</summary>
    <updated>2021-11-19T13:02:40Z</updated>
    <published>2021-11-19T13:02:40Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-11-24T14:37:23Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/163</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/163" rel="alternate" type="text/html"/>
    <title>TR21-163 |  Algorithmizing the Multiplicity Schwartz-Zippel Lemma | 

	Siddharth Bhandari, 

	Prahladh Harsha, 

	Mrinal Kumar, 

	A. Shankar</title>
    <summary>The multiplicity Schwartz-Zippel lemma asserts that over a field, a low-degree polynomial cannot vanish with high multiplicity very often on a sufficiently large product set. Since its discovery in a work of Dvir, Kopparty, Saraf and Sudan [DKSS13], the lemma has found nu- merous applications in both math and computer science; in particular, in the definition and properties of multiplicity codes by Kopparty, Saraf and Yekhanin [KSY14].

In this work, we show how to algorithmize the multiplicity Schwartz-Zippel lemma for ar- bitrary product sets over any field. In other words, we give an efficient algorithm for unique decoding of multivariate multiplicity codes from half their minimum distance on arbitrary product sets over all fields. Previously, such an algorithm was known either when the un- derlying product set had a nice algebraic structure (for instance, was a subfield) [Kop15] or when the underlying field had large (or zero) characteristic, the multiplicity parameter was sufficiently large and the multiplicity code had distance bounded away from 1 [BHKS21]. In particular, even unique decoding of bivariate multiplicity codes with multiplicity two from half their minimum distance was not known over arbitrary product sets over any field.

Our algorithm builds upon a result of Kim &amp; Kopparty [KK17] who gave an algorithmic version of the Schwartz-Zippel lemma (without multiplicities) or equivalently, an efficient al- gorithm for unique decoding of Reed-Muller codes over arbitrary product sets. We introduce a refined notion of distance based on the multiplicity Schwartz-Zippel lemma and design a unique decoding algorithm for this distance measure. On the way, we give an alternate proof of Forney’s classical generalized minimum distance decoder that might be of independent interest.</summary>
    <updated>2021-11-18T23:12:39Z</updated>
    <published>2021-11-18T23:12:39Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-11-24T14:37:22Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/11/18/postdocs-at-universite-de-lyon-ens-lyon-apply-by-january-4-2022/</id>
    <link href="https://cstheory-jobs.org/2021/11/18/postdocs-at-universite-de-lyon-ens-lyon-apply-by-january-4-2022/" rel="alternate" type="text/html"/>
    <title>Postdocs at Université de Lyon / ENS Lyon (apply by January 4, 2022)</title>
    <summary>Two postdoctoral positions in mathematics, computer science and their interactions are open for the period 2022-2024. Website: https://milyon.universite-lyon.fr/postdoctoral-positions-2022-2024-130160.kjsp?RH=1571748911317 Email: [guillaume.hanrot,nicolas.trotignon]@ens-lyon.fr</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Two postdoctoral positions in mathematics, computer science and their interactions are open for the period 2022-2024.</p>
<p>Website: <a href="https://milyon.universite-lyon.fr/postdoctoral-positions-2022-2024-130160.kjsp?RH=1571748911317">https://milyon.universite-lyon.fr/postdoctoral-positions-2022-2024-130160.kjsp?RH=1571748911317</a><br/>
Email: [guillaume.hanrot,nicolas.trotignon]@ens-lyon.fr</p></div>
    </content>
    <updated>2021-11-18T11:27:50Z</updated>
    <published>2021-11-18T11:27:50Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-11-24T14:37:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/162</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/162" rel="alternate" type="text/html"/>
    <title>TR21-162 |  Fast, Algebraic Multivariate Multipoint Evaluation in Small Characteristic and Applications | 

	Vishwas Bhargava, 

	Sumanta Ghosh, 

	Mrinal Kumar, 

	Chandra Kanta Mohapatra</title>
    <summary>Multipoint evaluation is the computational task of evaluating a polynomial given as a list of coefficients at a given set of inputs. Besides being a natural and fundamental question in computer algebra on its own, fast algorithms for this problem is also closely related to fast algorithms for other natural algebraic questions like polynomial factorization and modular composition. And while \emph{nearly linear time} algorithms have been known for the univariate instance of multipoint evaluation  for close to five decades due to a work of Borodin and Moenck \cite{BM74}, fast algorithms for the multivariate version have been much harder to come by. In a significant improvement to the state of art for this problem, Umans \cite{Umans08} and Kedlaya \&amp; Umans \cite{Kedlaya11} gave nearly linear time algorithms for this problem over field of small characteristic and over all finite fields respectively, provided that the number of variables $n$ is at most $d^{o(1)}$ where the degree of the input polynomial in every variable is less than $d$. They also stated the question of designing fast algorithms for the large variable case (i.e. $n \notin d^{o(1)}$) as an open problem. 

In this work, we show that there is a deterministic algorithm for multivariate multipoint evaluation over a field $\F_{q}$ of characteristic $p$ which evaluates an $n$-variate polynomial of degree less than $d$ in each variable on $N$ inputs in time $$\left((N + d^n)^{1 + o(1)}\poly(\log q, d, p, n)\right) \, ,$$ provided that $p$ is at most $d^{o(1)}$, and $q$ is at most $(\exp(\exp(\exp(\cdots (\exp(d)))))$, where the height of this tower of exponentials is fixed. When the number of variables is large (e.g. $n \notin d^{o(1)}$), this is the first {nearly linear} time algorithm for this problem over any (large enough) field.

Our algorithm is based on elementary algebraic ideas and this algebraic structure naturally leads to the following two independently interesting applications.

\begin{itemize}
\item We  show that there is an \emph{algebraic} data structure for univariate polynomial evaluation with nearly linear space complexity and sublinear time complexity over finite fields of small characteristic and quasipolynomially bounded size. This  provides a counterexample to a conjecture of Milterson \cite{M95} who conjectured that over small finite fields, any algebraic data structure for polynomial evaluation using  polynomial space must have linear query complexity. 

 \item We also show that over finite fields of small characteristic and quasipolynomially bounded size,  Vandermonde matrices are not rigid enough to  yield size-depth tradeoffs for linear circuits via the current quantitative bounds in Valiant's program \cite{Valiant1977}. More precisely, for every fixed prime $p$, we show that for every constant $\epsilon &gt; 0$, and large enough $n$, the rank of any $n \times n$ Vandermonde matrix $V$ over the field $\F_{p^a}$ can be reduced to $
   \left(n/\exp(\Omega(\poly(\epsilon)\sqrt{\log n}))\right) $ by changing at most $n^{\Theta(\epsilon)}$ entries in every row of $V$, provided $a \leq \poly(\log n)$. Prior to this work, similar upper bounds on rigidity were known only for special Vandermonde matrices. For instance, the Discrete Fourier Transform matrices and Vandermonde matrices with generators in a geometric progression \cite{DL20}. 
   
\end{itemize}</summary>
    <updated>2021-11-17T21:05:46Z</updated>
    <published>2021-11-17T21:05:46Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-11-24T14:37:22Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-1208458514334119738</id>
    <link href="http://blog.computationalcomplexity.org/feeds/1208458514334119738/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2021/11/cs-slow-to-change.html#comment-form" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/1208458514334119738" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/1208458514334119738" rel="self" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2021/11/cs-slow-to-change.html" rel="alternate" type="text/html"/>
    <title>CS Slow to Change?</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Back in March of 2019 <a href="https://blog.computationalcomplexity.org/2019/03/scooped.html">I wrote</a></p><blockquote><p>I was also going to post about Yann LeCun's Facebook rant about stodgy CS departments but then Yann goes ahead and wins a Turing award with Geoffrey Hinton and Yoshua Bengio for their work on machine learning. I knew Yann from when we worked together at NEC Research in the early 2000's and let's just congratulate him and the others and let them bask in glory for truly transforming how we think of computing today. I'll get back to his post soon enough.</p></blockquote><p>So not that soon. Yann's <a href="https://www.facebook.com/story.php?story_fbid=10152719972317143&amp;id=722677142">post</a> was from 2015 where he went after "stodgy" CS departments naming Yale, Harvard, Princeton and Chicago.</p><blockquote><p>CS is a quickly evolving field.  Because of excess conservatism, these departments have repeatedly missed important trends in CS and related field, such as Data Science. They seem to view CS as meaning strictly theory, crypto, systems and programming  languages, what some have called "core CS", paying lip service to graphics, vision, machine learning, AI, HCI, robotics, etc. But these areas are the ones that have been expanding the fastest in the last decades, particularly machine learning and computer vision in the last decade....It is quite common, and somewhat natural, that newer areas (eg ML) be looked down upon by members of older, more established areas (eg Theory and Systems). After all, scientists are professional skeptics. But in a fast evolving disciplines like CS and now Data Science, an excessive aversion to risk and change is a recipe for failure.</p></blockquote><p>We've seen some changes since. Yale's Statistics Department is now <a href="https://statistics.yale.edu/">Statistics and Data Science</a>. The University of Chicago has a new Data Science <a href="https://news.uchicago.edu/story/new-college-data-science-major-foundations-insight-impact">undergrad major</a> and <a href="https://cdac.uchicago.edu/insights/introducing-the-uchicago-data-science-institute/">institute</a>.</p><p>I wonder if that's the future. CS doesn't really change that much, at least not quickly. Data science, and perhaps cybersecurity, evolve as separate fields which only have limited intersection with traditional CS. The CS degree itself just focuses on those interested in how the machines work and the theory behind them. We're busy trying to figure this out at Illinois Tech as are most other schools. And what about augmented/virtual reality and the metaverse, quantum computing, fintech, social networks, human and social factors and so on? How do you choose which bets to make? </p><p>Most of all, universities, traditionally slowly moving machines, need to far more agile even in fields outside computing since the digital transformation is affecting everything. How do you plan degrees when the computing landscape when students graduate is different from when they start? </p></div>
    </content>
    <updated>2021-11-17T18:44:00Z</updated>
    <published>2021-11-17T18:44:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="http://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2021-11-24T10:13:54Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://scottaaronson.blog/?p=6111</id>
    <link href="https://scottaaronson.blog/?p=6111" rel="alternate" type="text/html"/>
    <link href="https://scottaaronson.blog/?p=6111#comments" rel="replies" type="text/html"/>
    <link href="https://scottaaronson.blog/?feed=atom&amp;p=6111" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Scott Aaronson, when reached for comment, said…</title>
    <summary xml:lang="en-US">About IBM’s new 127-qubit superconducting chip: As I told New Scientist, I look forward to seeing the actual details! As far as I could see, the marketing materials that IBM released yesterday take a lot of words to say absolutely nothing about what, to experts, is the single most important piece of information: namely, what […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p><strong>About IBM’s new <a href="https://research.ibm.com/blog/127-qubit-quantum-processor-eagle">127-qubit superconducting chip</a>:</strong> As I <a href="https://www.newscientist.com/article/2297583-ibm-creates-largest-ever-superconducting-quantum-computer/">told <em>New Scientist</em></a>, I look forward to seeing the actual details!  As far as I could see, the marketing materials that IBM released yesterday take a lot of words to say absolutely nothing about what, to experts, is the single most important piece of information: namely, <em>what are the gate fidelities?</em>  How deep of a quantum circuit can they apply?  How have they benchmarked the chip?  Right now, all I have to go on is a <a href="https://quantum-computing.ibm.com/services?services=systems&amp;order=qubits%20DESC&amp;view=table&amp;system=ibm_washington">stats page</a> for the new chip, <s>which reports its average CNOT error as 0.9388—in other words, close to 1, or terrible! (But see also a <a href="https://twitter.com/decodoku/status/1460622008916627456?s=21">tweet by James Wootton</a>, which explains that such numbers are often highly misleading when a new chip is first rolled out.)  Does anyone here have more information?</s>  <strong><span class="has-inline-color has-vivid-red-color">Update (11/17):</span></strong> As of this morning, the average CNOT error has been updated to 2%.  Thanks to multiple commenters for letting me know!</p>



<p><strong>About the <a href="https://arxiv.org/abs/2110.14502">new simulation</a> of Google’s 53-qubit Sycamore chip in 5 minutes on a Sunway supercomputer (see also <a href="https://arxiv.org/abs/2111.01066">here</a>):</strong> This is an exciting step forward on the classical validation of quantum supremacy experiments, and—ironically, what currently amounts to almost the same thing—on the classical <em>spoofing</em> of those experiments.  Congratulations to the team in China that achieved this!  But there are two crucial things to understand.  First, “5 minutes” refers to the time needed to calculate a <em>single</em> amplitude (or perhaps, several correlated amplitudes) using tensor network contraction.  It doesn’t refer to the time needed to generate millions of <em>independent</em> noisy samples, which is what Google’s Sycamore chip does in 3 minutes.  For the latter task, more like a week still seems to be needed on the supercomputer.  (I’m grateful to Chu Guo, a coauthor of the new work who spoke in UT Austin’s weekly quantum Zoom meeting, for clarifying this point.)  Second, the Sunway supercomputer has parallel processing power equivalent to approximately ten million of your laptop.  Thus, even if we agreed that Google no longer had quantum supremacy as measured by time, it would still have quantum supremacy as measured by carbon footprint!  (And this despite the fact that the quantum computer itself requires a noisy, closet-sized dilution fridge.)  Even so, for me the new work underscores the point that quantum supremacy is not yet a done deal.  Over the next few years, I hope that Google and USTC, as well as any new entrants to this race (IBM? IonQ? Harvard? Rigetti?), will push forward with more qubits and, even more importantly, better gate fidelities leading to higher Linear Cross-Entropy scores.  Meanwhile, we theorists should try to do our part by inventing new and better protocols with which to demonstrate near-term quantum supremacy—<em>especially</em> protocols for which the classical verification is easier.</p>



<p><strong>About the new anti-woke <a href="https://bariweiss.substack.com/p/we-cant-wait-for-universities-to">University of Austin</a> (UATX):</strong> In general, I’m extremely happy for people to experiment with new and different institutions, and of course I’m happy for more intellectual activity in my adopted city of Austin.  And, as <em>Shtetl-Optimized</em> readers will know, I’m probably more sympathetic than most to the reality of the problem that UATX is trying to solve—living, as we do, in an era when one academic after another has been cancelled for ideas that a mere decade ago would’ve been considered unexceptional, moderate, center-left.  Having said all that, I wish I could feel more optimistic about UATX’s prospects.  I found its <a href="https://www.uaustin.org/">website</a> heavy on free-speech rhetoric but frustratingly light on what the new university is actually going to <em>do</em>: what courses it will offer, who will teach them, where the campus will be, etc. etc.  Arguably this is all excusable for a university still in ramp-up mode, but had I been in their shoes, I might have held off on the public launch until I had at least some sample content to offer.  Certainly, the fact that Steven Pinker has <a href="https://www.uaustin.org/news/uatx-statement-about-robert-zimmer-and-steven-pinker">quit UATX’s advisory board</a> is a discouraging sign.  If UATX asks me to get involved—to lecture there, to give them advice about their CS program, etc.—I’ll consider it as I would any other request.  So far, though, they haven’t.</p>



<p><strong>About the Association for Mathematical Research:</strong> Last month, some colleagues invited me to join a brand-new society called the <a href="https://amathr.org/">Association for Mathematical Research</a>.  Many of the other founders (Joel Hass, Abigail Thompson, Colin Adams, Richard Borcherds, Jeff Cheeger, Pavel Etingof, Tom Hales, Jeff Lagarias, Mark Lackenby, Cliff Taubes, …) were brilliant mathematicians who I admired, they seemed like they could use a bit of theoretical computer science representation, there was no time commitment, maybe they’d eventually do something good, so I figured why not?  Alas, to say that AMR has proved unpopular on Twitter would be an understatement: it’s received the same contemptuous reception that UATX has.  The argument seems to be: starting a new mathematical society, even an avowedly diverse and apolitical one, is really just an implicit claim that the existing societies, like the <a href="https://www.maa.org/">Mathematical Association of America (MAA)</a>  and the <a href="https://www.ams.org/home/page">American Mathematical Society (AMS)</a>, have been co-opted by woke true-believers.  But that’s paranoid and insane!  I mean, it’s not as if an <a href="https://blogs.ams.org/inclusionexclusion/">AMS blog</a> has called for the <a href="https://blogs.ams.org/inclusionexclusion/2017/05/11/get-out-the-way/#more-772">mass resignation</a> of white male mathematicians to make room for the marginalized, or the boycott of Israeli universities, or the abolition of the criminal justice system <font size="-3"><em>(what to do about Kyle Rittenhouse though?)</em></font>.  Still, even though claims of that sort of co-option are obviously far-out, rabid fantasies, yeah, I did decide to give a new organization the benefit of the doubt.  AMR might well fail or languish in obscurity, just like UATX might.  On the other hand, the barriers to making a positive difference for the intellectual world, the world I love, the world under constant threat from the self-certain ideologues of every side, do strike me as orders of magnitude smaller for a new professional society than they do for a new university.</p></div>
    </content>
    <updated>2021-11-16T23:06:35Z</updated>
    <published>2021-11-16T23:06:35Z</published>
    <category scheme="https://scottaaronson.blog" term="Announcements"/>
    <category scheme="https://scottaaronson.blog" term="Complexity"/>
    <category scheme="https://scottaaronson.blog" term="Obviously I'm Not Defending Aaronson"/>
    <category scheme="https://scottaaronson.blog" term="Quantum"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://scottaaronson.blog/?feed=atom</id>
      <icon>https://scottaaronson.blog/wp-content/uploads/2021/10/cropped-Jacket-32x32.gif</icon>
      <link href="https://scottaaronson.blog" rel="alternate" type="text/html"/>
      <link href="https://scottaaronson.blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2021-11-19T21:48:06Z</updated>
    </source>
  </entry>
</feed>
