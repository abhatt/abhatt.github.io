<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2019-04-23T21:21:18Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=17325</id>
    <link href="https://gilkalai.wordpress.com/2019/04/23/an-invitation-to-a-conference-visions-in-mathematics-towards-2000/" rel="alternate" type="text/html"/>
    <title>An Invitation to a Conference: Visions in Mathematics towards 2000</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Let me invite you to a conference. The conference took place in 1999 but only recently the 57 videos of the lectures and the discussion sessions are publicly available. (I thank Vitali Milman for telling me about it.) One novel … <a href="https://gilkalai.wordpress.com/2019/04/23/an-invitation-to-a-conference-visions-in-mathematics-towards-2000/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Let me invite you to a conference. The conference took place in 1999 but only recently <a href="https://www.youtube.com/playlist?list=PLP0YToNcfAwLBd8yibTtjv3aHfcbT4GBA">the 57 videos of the lectures and the discussion sessions are publicly available.</a> (I thank Vitali Milman for telling me about it.) One novel idea of Vitali Milman was to hold discussion sessions and they were quite interesting. (But, I am biased, I like discussions.) I will invite you to one of the heated discussions in the next post. There were very many nice talks and very many nice visions. And it is fun to watch the videos and judge the ideas in the perspective of time.</p>
<p>The proceedings appeared as GAFA special volumes, but alas the articles are not electronically available even to GAFA’s subscribers. Let me encourage both Birkhauser and the contributors to make them more available. My talk was: <a href="https://youtu.be/Wjg1_QwjUos">An invitation to Tverberg’s theorem</a>, and my own contribution to the Proceedings <a href="http://www.ma.huji.ac.il/~kalai/VIS.pdf">Combinatorics with a Geometric Flavor </a>is probably the widest scope survey article I ever wrote.  At the end of each section I added a brief philosophical thought about mathematics and those are collected in the post “<a href="https://gilkalai.wordpress.com/2008/10/12/about-mathematics/">about mathematics</a>“.</p>
<p>Two more things: The conference (and few others organized by Vitali) was  in Tel Aviv with a few days at the dead see and this worked very nicely.  Vitali also organized in the mid 90s another very successful geometry conference unofficially celebrating Gromov’s 50th birthday with, among others, a very nice lecture by Gregory Perelman. If videos will become available I will be delighted to invite you to that conference as well.</p>
<p/>
<p><span style="color: #ff0000;">Avi Wigderson’s lecture</span></p>
<p><span style="color: #ff0000;">Are so called “natural questions” good for mathematics. Specifically is Kepler’s questions about the densest packing of unit balls in 3-space interesting? Watch a discussion of Misha Gromov, Noga Alon, Laci Lovasz and others. (next post)</span></p>
<h2/>
<h2><a href="https://gilkalai.files.wordpress.com/2019/04/vis99-p1.png"><img alt="" class="alignnone size-full wp-image-17362" height="363" src="https://gilkalai.files.wordpress.com/2019/04/vis99-p1.png?w=640&amp;h=363" width="640"/></a></h2>
<p><span style="color: #ff0000;">We were all so much younger!  (And in that old millennium,  we were also all men <img alt="&#x1F642;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f642.png" style="height: 1em;"/> )</span></p>
<p><a href="https://gilkalai.files.wordpress.com/2019/04/misha5.png"><img alt="" class="alignnone size-full wp-image-17366" height="614" src="https://gilkalai.files.wordpress.com/2019/04/misha5.png?w=640&amp;h=614" width="640"/></a></p>
<p><span style="color: #ff0000;">Misha Gromov argues passionately that natural problems are bad problems (see next post)</span></p>
<p>Pictures of most participants ad two slides are below</p>
<p><span id="more-17325"/><br/>
<a href="https://gilkalai.files.wordpress.com/2019/04/vim1.png"><img alt="VIM1.png" class="alignnone size-full wp-image-17372" src="https://gilkalai.files.wordpress.com/2019/04/vim1.png?w=640" style="font-size: 12px;"/></a><br/>
<img alt="VIM2.png" class="alignnone size-full wp-image-17373" src="https://gilkalai.files.wordpress.com/2019/04/vim2.png?w=640"/><img alt="VIM3.png" class="alignnone size-full wp-image-17374" src="https://gilkalai.files.wordpress.com/2019/04/vim3.png?w=640"/><img alt="VIM5.png" class="alignnone size-full wp-image-17376" src="https://gilkalai.files.wordpress.com/2019/04/vim5.png?w=640"/><img alt="VIM6.png" class="alignnone size-full wp-image-17377" src="https://gilkalai.files.wordpress.com/2019/04/vim6.png?w=640"/><img alt="VIM7.png" class="alignnone size-full wp-image-17378" src="https://gilkalai.files.wordpress.com/2019/04/vim7.png?w=640"/><a href="https://gilkalai.files.wordpress.com/2019/04/vim4.png"><img alt="VIM4.png" class="alignnone size-full wp-image-17375" src="https://gilkalai.files.wordpress.com/2019/04/vim4.png?w=640"/></a></p></div>
    </content>
    <updated>2019-04-23T15:40:47Z</updated>
    <published>2019-04-23T15:40:47Z</published>
    <category term="Combinatorics"/>
    <category term="Conferences"/>
    <category term="What is Mathematics"/>
    <category term="Vitali Milman"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-04-23T21:20:30Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-8139226761048070665</id>
    <link href="https://blog.computationalcomplexity.org/feeds/8139226761048070665/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/04/quiz-show-scandalsadmissions.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/8139226761048070665" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/8139226761048070665" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/04/quiz-show-scandalsadmissions.html" rel="alternate" type="text/html"/>
    <title>Quiz Show Scandals/Admissions Scandal/Stormy Daniels/Beer names:being  a lawyer would drive me nuts!!!!!!</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">0) Charles van Doren (see <a href="https://en.wikipedia.org/wiki/Charles_Van_Doren">here</a>) passed away recently. For those who don't know he he was (prob most of you) he was one of the contestants involved in RIGGED quiz shows in the 1950's.  While there was a Grand Jury Hearing about Quiz Shows being rigged, nobody went to jail since TV was new and it was not clear if rigging quiz shows was illegal. Laws were then passed to make them it illegal.<br/>
<br/>
So why are today's so-called reality shows legal? I ask non-rhetorically.<br/>
<br/>
(The person he beat in a rigged game show- Herb Stempel (see <a href="https://en.wikipedia.org/wiki/Herb_Stempel">here</a>) is still alive.)<br/>
<br/>
1) The college admissions scandal. I won't restate the details and how awful it is since you can get that elsewhere and I doubt I can add much to it.  One thing I've heard in the discussions about it is a question that is often posted rhetorically but I want to pose for real:<br/>
<br/>
There are people whose parents give X dollars to a school and they get admitted even though they are not qualified. Why is that legal?<br/>
<br/>
I ask that question without an ax to grind and without anger. Why is out-right bribery of this sort legal?<br/>
<br/>
Possibilities:<br/>
<br/>
a) Its transparent. So being honest about bribery makes it okay?<br/>
<br/>
b) My question said `even though they are not qualified' - what if they explicitly or implicitly said `having parents give money to our school is one of our qualifications'<br/>
<br/>
c) The money they give is used to fund scholarships for students who can't afford to go. This is an argument for why its not immoral, not why its not illegal.<br/>
<br/>
But here is my question: Really, what is the legal issue here? It still seems like bribery.<br/>
<br/>
2) Big Oil gives money to congressman Smith, who then votes against a carbon tax. This seems like outright bribery<br/>
<br/>
Caveat:<br/>
<br/>
a) If Congressman Smith is normally a anti-regulation then he could say correctly that he was given the money because they agree with his general philosophy, so it's  not bribery.<br/>
<br/>
b) If Congressman smith is normally pro-environment and has no problem with voting for taxes then perhaps it is bribery.<br/>
<br/>
3) John Edwards a while back and Donald Trump now are claiming (not quite) that the money used to pay off their mistress to be quiet is NOT a campaign contribution, but was to keep the affair from his wife. (I don't think Donald Trump has admitted the affair so its harder to know what his defense is). But lets take a less controversial example of `what is a campaign contribution'<br/>
<br/>
I throw a party for my wife's 50th birthday and I invite Beto O'Rourke and many voters and some Dem party big-wigs to the party. The party costs me $50,000.  While I claim it's for my wife's bday it really is for Beto to make connections to voters and others. So is that a campaign contribution?<br/>
<br/>
4) The creators of HUGE ASS BEER are suing GIANT ASS BEER for trademark infringement. I am not making this up- see <a href="https://thetakeout.com/huge-giant-ass-beer-lawsuit-new-orleans-1832989913">here</a><br/>
<br/>
---------------------------------------------------------<br/>
<br/>
All of these cases involve ill defined questions (e.g., `what is a bribe'). And the people arguing either side are not unbiased. The cases also illustrate why I prefer mathematics: nice clean questions that (for the most part) have answers. We may have our biases as to which way they go, but if it went the other way we would not sue in a court of law.</div>
    </content>
    <updated>2019-04-23T03:24:00Z</updated>
    <published>2019-04-23T03:24:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-04-23T14:16:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://lucatrevisan.wordpress.com/?p=4233</id>
    <link href="https://lucatrevisan.wordpress.com/2019/04/22/the-more-things-change-the-more-they-stay-the-same/" rel="alternate" type="text/html"/>
    <title>The more things change the more they stay the same</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">From a 1981 (!!) New York Times Article titled “Changing San Francisco is foreseen as a haven for wealthy and childless”: A major reason for the exodus of the middle class from San Francisco, demographers say, is the high cost … <a href="https://lucatrevisan.wordpress.com/2019/04/22/the-more-things-change-the-more-they-stay-the-same/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>From a 1981 (!!) <a href="https://www.nytimes.com/1981/06/09/us/changing-san-francisco-is-foreseen-as-a-haven-for-wealthy-and-childless.html">New York Times Article</a> titled “Changing San Francisco is foreseen as a haven for wealthy and childless”:</p>
<blockquote><p>
A major reason for the exodus of the middle class from San Francisco, demographers say, is the high cost of housing, the highest in the mainland United States. Last month, the median cost of a dwelling in the San Francisco Standard Metropolitan Statistical Area was $129,000, according to the Federal Home Loan Bank Board in Washington, D.C. The comparable figure for New York, Newark and Jersey City was $90,400, and for Los Angeles, the second most expensive city, $118,400.</p>
<p>”This city dwarfs anything I’ve ever seen in terms of housing prices,” said Mr. Witte. Among factors contributing to high housing cost, according to Mr. Witte and others, is its relative scarcity, since the number of housing units has not grown significantly in a decade; the influx of Asians, whose first priority is usually to buy a home; the high incidence of adults with good incomes and no children, particularly homosexuals who pool their incomes to buy homes, and the desirability of San Francisco as a place to live.
</p></blockquote>
<p>$129,000 in 1981 dollars is $360,748 in 2019 dollars.</p></div>
    </content>
    <updated>2019-04-23T01:52:32Z</updated>
    <published>2019-04-23T01:52:32Z</published>
    <category term="history"/>
    <category term="San Francisco"/>
    <author>
      <name>luca</name>
    </author>
    <source>
      <id>https://lucatrevisan.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://lucatrevisan.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://lucatrevisan.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://lucatrevisan.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://lucatrevisan.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>"Marge, I agree with you - in theory. In theory, communism works. In theory." -- Homer Simpson</subtitle>
      <title>in   theory</title>
      <updated>2019-04-23T21:20:09Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.09958</id>
    <link href="http://arxiv.org/abs/1904.09958" rel="alternate" type="text/html"/>
    <title>Almost Optimal Testers for Concise Representations</title>
    <feedworld_mtime>1555977600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bshouty:Nader_H=.html">Nader H. Bshouty</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.09958">PDF</a><br/><b>Abstract: </b>We give improved and almost optimal testers for several classes of Boolean
functions on $n$ inputs that have concise representation in the uniform and
distribution-free model. Classes, such as $k$-junta, $k$-linear functions,
$s$-term DNF, $s$-term monotone DNF, $r$-DNF, decision list, $r$-decision list,
size-$s$ decision tree, size-$s$ Boolean formula, size-$s$ branching programs,
$s$-sparse polynomials over the binary field and function with Fourier degree
at most $d$. The method can be extended to several other classes of functions
over any domain that can be approximated by functions that have a small number
of relevant variables.
</p></div>
    </summary>
    <updated>2019-04-23T01:29:44Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.09854</id>
    <link href="http://arxiv.org/abs/1904.09854" rel="alternate" type="text/html"/>
    <title>A Triangle Algorithm for Semidefinite Version of Convex Hull Membership Problem</title>
    <feedworld_mtime>1555977600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kalantari:Bahman.html">Bahman Kalantari</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.09854">PDF</a><br/><b>Abstract: </b>Given a subset $\mathbf{S}=\{A_1, \dots, A_m\}$ of $\mathbb{S}^n$, the set of
$n \times n$ real symmetric matrices, we define its {\it spectrahull} as the
set $SH(\mathbf{S}) = \{p(X) \equiv (Tr(A_1 X), \dots, Tr(A_m X))^T : X \in
\mathbf{\Delta}_n\}$, where ${\bf \Delta}_n$ is the {\it spectraplex}, $\{ X
\in \mathbb{S}^n : Tr(X)=1, X \succeq 0 \}$. We let {\it spectrahull
membership} (SHM) to be the problem of testing if a given $b \in \mathbb{R}^m$
lies in $SH(\mathbf{S})$. On the one hand when $A_i$'s are diagonal matrices,
SHM reduces to the {\it convex hull membership} (CHM), a fundamental problem in
LP. On the other hand, a bounded SDP feasibility is reducible to SHM. By
building on the {\it Triangle Algorithm} (TA) \cite{kalchar,kalsep}, developed
for CHM and its generalization, we design a TA for SHM, where given
$\varepsilon$, in $O(1/\varepsilon^2)$ iterations it either computes a
hyperplane separating $b$ from $SH(\mathbf{S})$, or $X_\varepsilon \in
\mathbf{\Delta}_n$ such that $\Vert p(X_\varepsilon) - b \Vert \leq \varepsilon
R$, $R$ maximum error over $\mathbf{\Delta}_n$. Under certain conditions
iteration complexity improves to $O(1/\varepsilon)$ or even $O(\ln
1/\varepsilon)$. The worst-case complexity of each iteration is $O(mn^2)$, plus
testing the existence of a pivot, shown to be equivalent to estimating the
least eigenvalue of a symmetric matrix. This together with a semidefinite
version of Carath\'eodory theorem allow implementing TA as if solving a CHM,
resorting to the {\it power method} only as needed, thereby improving the
complexity of iterations. The proposed Triangle Algorithm for SHM is simple,
practical and applicable to general SDP feasibility and optimization. Also, it
extends to a spectral analogue of SVM for separation of two spectrahulls.
</p></div>
    </summary>
    <updated>2019-04-23T01:24:17Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-04-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.09841</id>
    <link href="http://arxiv.org/abs/1904.09841" rel="alternate" type="text/html"/>
    <title>Low-Rank Approximation from Communication Complexity</title>
    <feedworld_mtime>1555977600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Musco:Cameron.html">Cameron Musco</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Musco:Christopher.html">Christopher Musco</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Woodruff:David_P=.html">David P. Woodruff</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.09841">PDF</a><br/><b>Abstract: </b>In low-rank approximation with missing entries, given $A\in
\mathbb{R}^{n\times n}$ and binary $W \in \{0,1\}^{n\times n}$, the goal is to
find a rank-$k$ matrix $L$ for which: $$cost(L)=\sum_{i=1}^{n}
\sum_{j=1}^{n}W_{i,j}\cdot (A_{i,j} - L_{i,j})^2\le OPT+\epsilon \|A\|_F^2,$$
where $OPT=\min_{rank-k\ \hat{L}}cost(\hat L)$. This problem is also known as
matrix completion and, depending on the choice of $W$, captures low-rank plus
diagonal decomposition, robust PCA, low-rank recovery from monotone missing
data, and a number of other important problems. Many of these problems are
NP-hard, and while algorithms with provable guarantees are known in some cases,
they either 1) run in time $n^{\Omega(k^2/\epsilon)}$, or 2) make strong
assumptions, e.g., that $A$ is incoherent or that $W$ is random.
</p>
<p>In this work, we consider $bicriteria\ algorithms$, which output $L$ with
rank $k' &gt; k$. We prove that a common heuristic, which simply sets $A$ to $0$
where $W$ is $0$, and then computes a standard low-rank approximation, achieves
the above approximation bound with rank $k'$ depending on the $communication\
complexity$ of $W$. Namely, interpreting $W$ as the communication matrix of a
Boolean function $f(x,y)$ with $x,y\in \{0,1\}^{\log n}$, it suffices to set
$k'=O(k\cdot 2^{R^{1-sided}_{\epsilon}(f)})$, where $R^{1-sided}_{\epsilon}(f)$
is the randomized communication complexity of $f$ with $1$-sided error
probability $\epsilon$. For many problems, this yields bicriteria algorithms
with $k'=k\cdot poly((\log n)/\epsilon)$.
</p>
<p>We prove a similar bound using the randomized communication complexity with
$2$-sided error. Further, we show that different models of communication yield
algorithms for natural variants of the problem. E.g., multi-player
communication complexity connects to tensor decomposition and non-deterministic
communication complexity to Boolean low-rank factorization.
</p></div>
    </summary>
    <updated>2019-04-23T01:26:13Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.09828</id>
    <link href="http://arxiv.org/abs/1904.09828" rel="alternate" type="text/html"/>
    <title>Magic: The Gathering is Turing Complete</title>
    <feedworld_mtime>1555977600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Alex Churchill, Stella Biderman, Austin Herrick <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.09828">PDF</a><br/><b>Abstract: </b>$\textit{Magic: The Gathering}$ is a popular and famously complicated trading
card game about magical combat. In this paper we show that optimal play in
real-world $\textit{Magic}$ is at least as hard as the Halting Problem, solving
a problem that has been open for a decade. To do this, we present a methodology
for embedding an arbitrary Turing machine into a game of $\textit{Magic}$ such
that the first player is guaranteed to win the game if and only if the Turing
machine halts. Our result applies to how real $\textit{Magic}$ is played, can
be achieved using standard-size tournament-legal decks, and does not rely on
stochasticity or hidden information. Our result is also highly unusual in that
all moves of both players are forced in the construction. This shows that even
recognising who will win a game in which neither player has a non-trivial
decision to make for the rest of the game is undecidable. We conclude with a
discussion of the implications for a unified computational theory of games and
remarks about the playability of such a board in a tournament setting.
</p></div>
    </summary>
    <updated>2019-04-23T01:20:26Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-04-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.09710</id>
    <link href="http://arxiv.org/abs/1904.09710" rel="alternate" type="text/html"/>
    <title>Robust Clustering Oracle and Local Reconstructor of Cluster Structure of Graphs</title>
    <feedworld_mtime>1555977600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Peng:Pan.html">Pan Peng</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.09710">PDF</a><br/><b>Abstract: </b>Due to the massive size of modern network data, local algorithms that run in
sublinear time for analyzing the cluster structure of the graph are receiving
growing interest. Two typical examples are local graph clustering algorithms
that find a cluster from a seed node with running time proportional to the size
of the output set, and clusterability testing algorithms that decide if a graph
can be partitioned into a few clusters in the framework of property testing.
</p>
<p>In this work, we develop sublinear time algorithms for analyzing the cluster
structure of graphs with noisy partial information. By using conductance based
definitions for measuring the quality of clusters and the cluster structure, we
formalize a definition of noisy clusterable graphs with bounded maximum degree.
The algorithm is given query access to the adjacency list to such a graph. We
then formalize the notion of robust clustering oracle for a noisy clusterable
graph, and give an algorithm that builds such an oracle in sublinear time,
which can be further used to support typical queries (e.g., IsOutlier($s$),
SameCluster($s,t$)) regarding the cluster structure of the graph in sublinear
time. All the answers are consistent with a partition of $G$ in which all but a
small fraction of vertices belong to some good cluster. We also give a local
reconstructor for a noisy clusterable graph that provides query access to a
reconstructed graph that is guaranteed to be clusterable in sublinear time. All
the query answers are consistent with a clusterable graph which is guaranteed
to be close to the original graph.
</p></div>
    </summary>
    <updated>2019-04-23T01:29:16Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.09690</id>
    <link href="http://arxiv.org/abs/1904.09690" rel="alternate" type="text/html"/>
    <title>Dynamic Time Warping in Strongly Subquadratic Time: Algorithms for the Low-Distance Regime and Approximate Evaluation</title>
    <feedworld_mtime>1555977600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kuszmaul:William.html">William Kuszmaul</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.09690">PDF</a><br/><b>Abstract: </b>Dynamic time warping distance (DTW) is a widely used distance measure between
time series. The best known algorithms for computing DTW run in near quadratic
time, and conditional lower bounds prohibit the existence of significantly
faster algorithms. The lower bounds do not prevent a faster algorithm for the
special case in which the DTW is small, however. For an arbitrary metric space
$\Sigma$ with distances normalized so that the smallest non-zero distance is
one, we present an algorithm which computes $\operatorname{dtw}(x, y)$ for two
strings $x$ and $y$ over $\Sigma$ in time $O(n \cdot \operatorname{dtw}(x,
y))$. We also present an approximation algorithm which computes
$\operatorname{dtw}(x, y)$ within a factor of $O(n^\epsilon)$ in time
$\tilde{O}(n^{2 - \epsilon})$ for $0 &lt; \epsilon &lt; 1$. The algorithm allows for
the strings $x$ and $y$ to be taken over an arbitrary well-separated tree
metric with logarithmic depth and at most exponential aspect ratio. Extending
our techniques further, we also obtain the first approximation algorithm for
edit distance to work with characters taken from an arbitrary metric space,
providing an $n^\epsilon$-approximation in time $\tilde{O}(n^{2 - \epsilon})$,
with high probability. Additionally, we present a simple reduction from
computing edit distance to computing DTW. Applying our reduction to a
conditional lower bound of Bringmann and K\"unnemann pertaining to edit
distance over $\{0, 1\}$, we obtain a conditional lower bound for computing DTW
over a three letter alphabet (with distances of zero and one). This improves on
a previous result of Abboud, Backurs, and Williams. With a similar approach, we
prove a reduction from computing edit distance to computing longest LCS length.
This means that one can recover conditional lower bounds for LCS directly from
those for edit distance, which was not previously thought to be the case.
</p></div>
    </summary>
    <updated>2019-04-23T01:26:08Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.09667</id>
    <link href="http://arxiv.org/abs/1904.09667" rel="alternate" type="text/html"/>
    <title>Scheduling to Approximate Minimization Objectives on Identical Machines</title>
    <feedworld_mtime>1555977600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Moseley:Benjamin.html">Benjamin Moseley</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.09667">PDF</a><br/><b>Abstract: </b>This paper considers scheduling on identical machines. The scheduling
objective considered in this paper generalizes most scheduling minimization
problems. In the problem, there are $n$ jobs and each job $j$ is associated
with a monotonically increasing function $g_j$. The goal is to design a
schedule that minimizes $\sum_{j \in [n]} g_{j}(C_j)$ where $C_j$ is the
completion time of job $j$ in the schedule. An $O(1)$-approximation is known
for the single machine case. On multiple machines, this paper shows that if the
scheduler is required to be either non-migratory or non-preemptive then any
algorithm has an unbounded approximation ratio. Using preemption and migration,
this paper gives a $O(\log \log nP)$-approximation on multiple machines, the
first result on multiple machines. These results imply the first non-trivial
positive results for several special cases of the problem considered, such as
throughput minimization and tardiness.
</p>
<p>Natural linear programs known for the problem have a poor integrality gap.
The results are obtained by strengthening a natural linear program for the
problem with a set of covering inequalities we call job cover inequalities.
This linear program is rounded to an integral solution by building on
quasi-uniform sampling and rounding techniques.
</p></div>
    </summary>
    <updated>2019-04-23T01:30:54Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.09618</id>
    <link href="http://arxiv.org/abs/1904.09618" rel="alternate" type="text/html"/>
    <title>Trace Reconstruction: Generalized and Parameterized</title>
    <feedworld_mtime>1555977600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Krishnamurthy:Akshay.html">Akshay Krishnamurthy</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mazumdar:Arya.html">Arya Mazumdar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/McGregor:Andrew.html">Andrew McGregor</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pal:Soumyabrata.html">Soumyabrata Pal</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.09618">PDF</a><br/><b>Abstract: </b>In the beautifully simple-to-state problem of trace reconstruction, the goal
is to reconstruct an unknown binary string $x$ given random "traces" of $x$
where each trace is generated by deleting each coordinate of $x$ independently
with probability $p&lt;1$. The problem is well studied both when the unknown
string is arbitrary and when it is chosen uniformly at random. For both
settings, there is still an exponential gap between upper and lower sample
complexity bounds and our understanding of the problem is still surprisingly
limited. In this paper, we consider natural parameterizations and
generalizations of this problem in an effort to attain a deeper and more
comprehensive understanding.
</p>
<p>We prove that $\exp(O(n^{1/4} \sqrt{\log n}))$ traces suffice for
reconstructing arbitrary matrices. In the matrix version of the problem, each
row and column of an unknown $\sqrt{n}\times \sqrt{n}$ matrix is deleted
independently with probability $p$. Our results contrasts with the best known
results for sequence reconstruction where the best known upper bound is
$\exp(O(n^{1/3}))$. An optimal result for random matrix reconstruction: we show
that $\Theta(\log n)$ traces are necessary and sufficient. This is in contrast
to the problem for random sequences where there is a super-logarithmic lower
bound and the best known upper bound is $\exp({O}(\log^{1/3} n))$. We show that
$\exp(O(k^{1/3}\log^{2/3} n))$ traces suffice to reconstruct $k$-sparse
strings, providing an improvement over the best known sequence reconstruction
results when $k = o(n/\log^2 n)$. We show that $\textrm{poly}(n)$ traces
suffice if $x$ is $k$-sparse and we additionally have a "separation" promise,
specifically that the indices of 1's in $x$ all differ by $\Omega(k \log n)$.
</p></div>
    </summary>
    <updated>2019-04-23T01:25:22Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.09562</id>
    <link href="http://arxiv.org/abs/1904.09562" rel="alternate" type="text/html"/>
    <title>An Improved FPTAS for 0-1 Knapsack</title>
    <feedworld_mtime>1555977600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jin:Ce.html">Ce Jin</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.09562">PDF</a><br/><b>Abstract: </b>The 0-1 knapsack problem is an important NP-hard problem that admits fully
polynomial-time approximation schemes (FPTASs). Previously the fastest FPTAS by
Chan (2018) with approximation factor $1+\varepsilon$ runs in $\tilde O(n +
(1/\varepsilon)^{12/5})$ time, where $\tilde O$ hides polylogarithmic factors.
In this paper we present an improved algorithm in $\tilde
O(n+(1/\varepsilon)^{9/4})$ time, with only a $(1/\varepsilon)^{1/4}$ gap from
the quadratic conditional lower bound based on $(\min,+)$-convolution. Our
improvement comes from a multi-level extension of Chan's number-theoretic
construction, and a greedy lemma that reduces unnecessary computation spent on
cheap items.
</p></div>
    </summary>
    <updated>2019-04-23T01:29:23Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.09561</id>
    <link href="http://arxiv.org/abs/1904.09561" rel="alternate" type="text/html"/>
    <title>Proceedings Twelfth Workshop on Developments in Computational Models and Ninth Workshop on Intersection Types and Related Systems</title>
    <feedworld_mtime>1555977600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pagani:Michele.html">Michele Pagani</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Alves:Sandra.html">Sandra Alves</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.09561">PDF</a><br/><b>Abstract: </b>This volume contains a final and revised selection of papers presented at
Twelfth Workshop on Developments in Computational Models (DCM 2018) and the
Ninth Workshop on Intersection Types and Related Systems (ITRS 2018), held on
July 8, 2018 in Oxford, in affiliation with FLOC 2018.
</p></div>
    </summary>
    <updated>2019-04-23T01:24:04Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-04-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.09526</id>
    <link href="http://arxiv.org/abs/1904.09526" rel="alternate" type="text/html"/>
    <title>Constructive Polynomial Partitioning for Algebraic Curves in $\mathbb{R}^3$ with Applications</title>
    <feedworld_mtime>1555977600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Aronov:Boris.html">Boris Aronov</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Ezra:Esther.html">Esther Ezra</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zahl:Joshua.html">Joshua Zahl</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.09526">PDF</a><br/><b>Abstract: </b>In 2015, Guth proved that for any set of $k$-dimensional varieties in
$\mathbb{R}^d$ and for any positive integer $D$, there exists a polynomial of
degree at most $D$ whose zero-set divides $\mathbb{R}^d$ into open connected
"cells," so that only a small fraction of the given varieties intersect each
cell. Guth's result generalized an earlier result of Guth and Katz for points.
</p>
<p>Guth's proof relies on a variant of the Borsuk-Ulam theorem, and for $k&gt;0$,
it is unknown how to obtain an explicit representation of such a partitioning
polynomial and how to construct it efficiently. In particular, it is unknown
how to effectively construct such a polynomial for curves (or even lines) in
$\mathbb{R}^3$.
</p>
<p>We present an efficient algorithmic construction for this setting. Given a
set of $n$ input curves and a positive integer $D$, we efficiently construct a
decomposition of space into $O(D^3\log^3{D})$ open cells, each of which meets
$O(n/D^2)$ curves from the input. The construction time is $O(n^2)$. For the
case of lines in $3$-space we present an improved implementation, whose running
time is $O(n^{4/3} \operatorname{polylog} n)$. The constant of proportionality
in both time bounds depends on $D$ and the maximum degree of the polynomials
defining the input curves.
</p>
<p>As an application, we revisit the problem of eliminating depth cycles among
non-vertical lines in $3$-space, recently studied by Aronov and Sharir (2018),
and show an algorithm that cuts $n$ such lines into $O(n^{3/2+\varepsilon})$
pieces that are depth-cycle free, for any $\varepsilon &gt; 0$. The algorithm runs
in $O(n^{3/2+\varepsilon})$ time, which is a considerable improvement over
previously known algorithms.
</p></div>
    </summary>
    <updated>2019-04-23T01:31:53Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-04-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.09470</id>
    <link href="http://arxiv.org/abs/1904.09470" rel="alternate" type="text/html"/>
    <title>Cluster Deletion on Interval Graphs and Split Related Graphs</title>
    <feedworld_mtime>1555977600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Konstantinidis:Athanasios_L=.html">Athanasios L. Konstantinidis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Papadopoulos:Charis.html">Charis Papadopoulos</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.09470">PDF</a><br/><b>Abstract: </b>In the {\sc Cluster Deletion} problem the goal is to remove the minimum
number of edges of a given graph, such that every connected component of the
resulting graph constitutes a clique. It is known that the decision version of
{\sc Cluster Deletion} is NP-complete on ($P_5$-free) chordal graphs, whereas
{\sc Cluster Deletion} is solved in polynomial time on split graphs. However,
the existence of a polynomial-time algorithm of {\sc Cluster Deletion} on
interval graphs, a proper subclass of chordal graphs, remained a well-known
open problem. Our main contribution is that we settle this problem in the
affirmative, by providing a polynomial-time algorithm for {\sc Cluster
Deletion} on interval graphs. Moreover, despite the simple formulation of the
algorithm on split graphs, we show that {\sc Cluster Deletion} remains
NP-complete on a natural and slight generalization of split graphs that
constitutes a proper subclass of $P_5$-free chordal graphs. To complement our
results, we provide two polynomial-time algorithms for {\sc Cluster Deletion}
on subclasses of such generalizations of split graphs.
</p></div>
    </summary>
    <updated>2019-04-23T01:29:27Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.09438</id>
    <link href="http://arxiv.org/abs/1904.09438" rel="alternate" type="text/html"/>
    <title>Decomposing a Graph into Unigraphs</title>
    <feedworld_mtime>1555977600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Horiyama:Takashi.html">Takashi Horiyama</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kawahara:Jun.html">Jun Kawahara</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Minato:Shin=ichi.html">Shin-ichi Minato</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nakahata:Yu.html">Yu Nakahata</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.09438">PDF</a><br/><b>Abstract: </b>Unigraphs are graphs uniquely determined by their own degree sequence up to
isomorphism. There are many subclasses of unigraphs such as threshold graphs,
split matrogenic graphs, matroidal graphs, and matrogenic graphs. Unigraphs and
these subclasses are well studied in the literature. Nevertheless, there are
few results on superclasses of unigraphs. In this paper, we introduce two types
of generalizations of unigraphs: $k$-unigraphs and $k$-strong unigraphs. We say
that a graph $G$ is a $k$-unigraph if $G$ can be partitioned into $k$
unigraphs. $G$ is a $k$-strong unigraph if not only each subgraph is a unigraph
but also the whole graph can be uniquely determined up to isomorphism, by using
the degree sequences of all the subgraphs in the partition. We describe a
relation between $k$-strong unigraphs and the subgraph isomorphism problem. We
show some properties of $k$-(strong) unigraphs and algorithmic results on
calculating the minimum $k$ such that a graph $G$ is a $k$-(strong) unigraph.
This paper will open many other research topics.
</p></div>
    </summary>
    <updated>2019-04-23T01:28:27Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.09433</id>
    <link href="http://arxiv.org/abs/1904.09433" rel="alternate" type="text/html"/>
    <title>Can Machine Learning Model with Static Features be Fooled: an Adversarial Machine Learning Approach</title>
    <feedworld_mtime>1555977600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Rahim Taheri, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Javidan:Reza.html">Reza Javidan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shojafar:Mohammad.html">Mohammad Shojafar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/P:Vinod.html">Vinod P</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Conti:Mauro.html">Mauro Conti</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.09433">PDF</a><br/><b>Abstract: </b>The widespread adoption of smartphones dramatically increases the risk of
attacks and the spread of mobile malware, especially on the Android platform.
Machine learning based solutions have been already used as a tool to supersede
signature based anti-malware systems. However, malware authors leverage
attributes from malicious and legitimate samples to estimate statistical
difference in-order to create adversarial examples. Hence, to evaluate the
vulnerability of machine learning algorithms in malware detection, we propose
five different attack scenarios to perturb malicious applications (apps). By
doing this, the classification algorithm inappropriately fits discriminant
function on the set of data points, eventually yielding a higher
misclassification rate. Further, to distinguish the adversarial examples from
benign samples, we propose two defense mechanisms to counter attacks. To
validate our attacks and solutions, we test our model on three different
benchmark datasets. We also test our methods using various classifier
algorithms and compare them with the state-of-the-art data poisoning method
using the Jacobian matrix. Promising results show that generated adversarial
samples can evade detection with a very high probability. Additionally, evasive
variants generated by our attacks models when used to harden the developed
anti-malware system improves the detection rate.
</p></div>
    </summary>
    <updated>2019-04-23T01:20:45Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-04-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.09378</id>
    <link href="http://arxiv.org/abs/1904.09378" rel="alternate" type="text/html"/>
    <title>A General Neural Network Architecture for Persistence Diagrams and Graph Classification</title>
    <feedworld_mtime>1555977600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Carri=egrave=re:Mathieu.html">Mathieu Carrière</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chazal:Fr=eacute=d=eacute=ric.html">Frédéric Chazal</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Ike:Yuichi.html">Yuichi Ike</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lacombe:Th=eacute=o.html">Théo Lacombe</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Royer:Martin.html">Martin Royer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/u/Umeda:Yuhei.html">Yuhei Umeda</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.09378">PDF</a><br/><b>Abstract: </b>Graph classification is a difficult problem that has drawn a lot of attention
from the machine learning community over the past few years. This is mainly due
to the fact that, contrarily to Euclidean vectors, the inherent complexity of
graph structures can be quite hard to encode and handle for traditional
classifiers. Even though kernels have been proposed in the literature, the
increase in the dataset sizes has greatly limited the use of kernel methods
since computation and storage of kernel matrices has become impracticable. In
this article, we propose to use extended persistence diagrams to efficiently
encode graph structure. More precisely, we show that using the so-called heat
kernel signatures for the computation of these extended persistence diagrams
allows one to quickly and efficiently summarize the graph structure. Then, we
build on the recent development of neural networks for point clouds to define
an architecture for (extended) persistence diagrams which is modular and
easy-to-use. Finally, we demonstrate the usefulness of our approach by
validating our architecture on several graph datasets, on which the obtained
results are comparable to the state-of-the-art for graph classification.
</p></div>
    </summary>
    <updated>2019-04-23T01:31:15Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-04-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.09354</id>
    <link href="http://arxiv.org/abs/1904.09354" rel="alternate" type="text/html"/>
    <title>Submodular Maximization Beyond Non-negativity: Guarantees, Fast Algorithms, and Applications</title>
    <feedworld_mtime>1555977600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Harshaw:Christopher.html">Christopher Harshaw</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Feldman:Moran.html">Moran Feldman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Ward:Justin.html">Justin Ward</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Karbasi:Amin.html">Amin Karbasi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.09354">PDF</a><br/><b>Abstract: </b>It is generally believed that submodular functions -- and the more general
class of $\gamma$-weakly submodular functions -- may only be optimized under
the non-negativity assumption $f(S) \geq 0$. In this paper, we show that once
the function is expressed as the difference $f = g - c$, where $g$ is monotone,
non-negative, and $\gamma$-weakly submodular and $c$ is non-negative modular,
then strong approximation guarantees may be obtained. We present an algorithm
for maximizing $g - c$ under a $k$-cardinality constraint which produces a
random feasible set $S$ such that $\mathbb{E} \left[ g(S) - c(S) \right] \geq
(1 - e^{-\gamma} - \epsilon) g(OPT) - c(OPT)$, whose running time is $O
(\frac{n}{\epsilon} \log^2 \frac{1}{\epsilon})$, i.e., independent of $k$. We
extend these results to the unconstrained setting by describing an algorithm
with the same approximation guarantees and faster $O(\frac{n}{\epsilon}
\log\frac{1}{\epsilon})$ runtime. The main techniques underlying our algorithms
are two-fold: the use of a surrogate objective which varies the relative
importance between $g$ and $c$ throughout the algorithm, and a geometric sweep
over possible $\gamma$ values. Our algorithmic guarantees are complemented by a
hardness result showing that no polynomial-time algorithm which accesses $g$
through a value oracle can do better. We empirically demonstrate the success of
our algorithms by applying them to experimental design on the Boston Housing
dataset and directed vertex cover on the Email EU dataset.
</p></div>
    </summary>
    <updated>2019-04-23T01:24:29Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://lucatrevisan.wordpress.com/?p=4230</id>
    <link href="https://lucatrevisan.wordpress.com/2019/04/22/online-optimization-post-0-definitions/" rel="alternate" type="text/html"/>
    <title>Online Optimization Post 0: Definitions</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Online convex optimization deals with the following setup: we want to design an algorithm that, at each discrete time step , comes up with a solution , where is a certain convex set of feasible solution. After the algorithm has … <a href="https://lucatrevisan.wordpress.com/2019/04/22/online-optimization-post-0-definitions/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
 Online convex optimization deals with the following setup: we want to design an algorithm that, at each discrete time step <img alt="{t=1,2,\ldots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%3D1%2C2%2C%5Cldots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t=1,2,\ldots}"/>, comes up with a solution <img alt="{x_t \in K}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_t+%5Cin+K%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x_t \in K}"/>, where <img alt="{K}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BK%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{K}"/> is a certain convex set of feasible solution. After the algorithm has selected its solution <img alt="{x_t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x_t}"/>, a convex cost function <img alt="{f_t : K \rightarrow {\mathbb R}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_t+%3A+K+%5Crightarrow+%7B%5Cmathbb+R%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_t : K \rightarrow {\mathbb R}}"/>, coming from a known restricted set of admissible cost functions <img alt="{{\cal F}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Ccal+F%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{\cal F}}"/>, is revealed, and the algorithm pays the loss <img alt="{f_t (x_t)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_t+%28x_t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_t (x_t)}"/>. </p>
<p>
Again, the algorithm has to come up with a solution <em>without knowing what cost functions it is supposed to be optimizing</em>. Furthermore, we will think of the sequence of cost functions <img alt="{f_1,f_2, \ldots,f_t,\ldots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_1%2Cf_2%2C+%5Cldots%2Cf_t%2C%5Cldots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_1,f_2, \ldots,f_t,\ldots}"/> not as being fixed in advanced and unknown to the algorithm, but as being dynamically generated by an adversary, after seeing the solutions provided by the algorithm. (This resilience to adaptive adversaries will be important in most of the applications.)</p>
<p>
The <em>offline optimum</em> after <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> steps is the total cost that the best possible fixed solution would have incurred when evaluated against the cost functions seen by the algorithm, that is, it is a solution to </p>
<p align="center"><img alt="\displaystyle  \min_{x\in K} \ \ \sum_{t=1}^T f_t (x) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmin_%7Bx%5Cin+K%7D+%5C+%5C+%5Csum_%7Bt%3D1%7D%5ET+f_t+%28x%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \min_{x\in K} \ \ \sum_{t=1}^T f_t (x) "/></p>
<p>
The <em>regret</em> after <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> steps is the difference between the loss suffered by the algorithm and the offline optimum, that is, </p>
<p/><p align="center"><img alt="\displaystyle  {\rm Regret}_T = \sum_{t=1}^T f_t (x_t) - \min_{x\in K} \ \ \sum_{t=1}^T f_t (x) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7B%5Crm+Regret%7D_T+%3D+%5Csum_%7Bt%3D1%7D%5ET+f_t+%28x_t%29+-+%5Cmin_%7Bx%5Cin+K%7D+%5C+%5C+%5Csum_%7Bt%3D1%7D%5ET+f_t+%28x%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  {\rm Regret}_T = \sum_{t=1}^T f_t (x_t) - \min_{x\in K} \ \ \sum_{t=1}^T f_t (x) "/></p>
<p>
The remarkable results that we will review give algorithms that achieve regret</p>
<p/><p align="center"><img alt="\displaystyle  {\rm Regret}_T \leq O_{K, {\cal F}} (\sqrt T) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7B%5Crm+Regret%7D_T+%5Cleq+O_%7BK%2C+%7B%5Ccal+F%7D%7D+%28%5Csqrt+T%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  {\rm Regret}_T \leq O_{K, {\cal F}} (\sqrt T) "/></p>
<p> that is, for fixed <img alt="{K}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BK%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{K}"/> and <img alt="{{\cal F}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Ccal+F%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{\cal F}}"/>, the regret-per-time-step goes to zero with the number of steps, as <img alt="{O\left( \frac 1 {\sqrt T} \right)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%5Cleft%28+%5Cfrac+1+%7B%5Csqrt+T%7D+%5Cright%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{O\left( \frac 1 {\sqrt T} \right)}"/>. It is intuitive that our bounds will have to depend on how big is the “diameter” of <img alt="{K}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BK%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{K}"/> and how large is the “magnitude” and “smoothness” of the functions <img alt="{f\in {\cal F}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%5Cin+%7B%5Ccal+F%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f\in {\cal F}}"/>, but depending on how we choose to formalize these quantities we will be led to define different algorithms. </p>
<p/></div>
    </content>
    <updated>2019-04-22T21:35:44Z</updated>
    <published>2019-04-22T21:35:44Z</published>
    <category term="theory"/>
    <category term="online optimization"/>
    <author>
      <name>luca</name>
    </author>
    <source>
      <id>https://lucatrevisan.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://lucatrevisan.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://lucatrevisan.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://lucatrevisan.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://lucatrevisan.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>"Marge, I agree with you - in theory. In theory, communism works. In theory." -- Homer Simpson</subtitle>
      <title>in   theory</title>
      <updated>2019-04-23T21:20:09Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=15778</id>
    <link href="https://rjlipton.wordpress.com/2019/04/21/pnp-proofs/" rel="alternate" type="text/html"/>
    <title>P=NP Proofs</title>
    <summary>Advice to claimers The Claimers The Claimers are a gang on the hit AMC television series The Walking Dead. They are the main antagonists in the second half of the zombie-apocalypse show’s Season 4. According to Wikipedia’s description, they “live by the philosophy of ‘claiming’.” Today Ken and I discuss issues about ‘claiming’ and give […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Advice to claimers</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2019/04/21/pnp-proofs/claimers3/" rel="attachment wp-att-15790"><img alt="" class="alignright size-medium wp-image-15790" height="191" src="https://rjlipton.files.wordpress.com/2019/04/claimers3.png?w=300&amp;h=191" width="300"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2"><a href="https://the-walking-dead-tvseries.fandom.com/wiki/The_Claimers">The Claimers</a></font></td>
</tr>
</tbody>
</table>
<p>
The Claimers are a gang on the hit AMC television <a href="https://en.wikipedia.org/wiki/The_Walking_Dead_(TV_series)">series</a> <em>The Walking Dead</em>. They are the main antagonists in the second half of the zombie-apocalypse show’s Season 4. According to Wikipedia’s <a href="https://en.wikipedia.org/wiki/The_Walking_Dead_(season_4)#The_Claimers">description</a>, they “live by the philosophy of ‘claiming’.”</p>
<p>
Today Ken and I discuss issues about ‘claiming’ and give advice on how to present your claims—or not.</p>
<p>
Yes, this post is about our own “claimers” in complexity theory. It is especially about those who claim to have a solution to P=NP. We will not give any names today. You know who you are.</p>
<p>
The TV Claimers meet a grisly end. We will not say any more about it. We want to be nice. But we would like to not keep seeing the same level of zombie claims raised again and again.</p>
<p>
<b>Please: Do not stop reading.</b> Yes we know that it is likely that no claimer really has such a proof. However, our suggestions apply to all of us when we have a non-trivial result. Especially a result that has been open, even if the result is not a major open problem. So please keep reading today.</p>
<p>
</p><p/><h2> So You Can Prove P=NP </h2><p/>
<p/><p>
This is a list of ideas for anyone who claims to have solved P=NP or some similar hard open problem in mathematics. There are already lots of suggestions online about what you should do, so this is just a list of additional thoughts. We hope they are helpful.</p>
<p>
</p><p/><h3> You are being pretty arrogant </h3><p/>
<p/><p>
In order to succeed in mathematics research one has to be a bit arrogant. It is quite difficult to prove new things without some swagger. However, proving or resolving P=NP requires a very non-humble attitude. I think many claimers have not thought how arrogant they are being. The P=NP problem is a huge open problem. Thousands and thousands of researchers have spent years thinking about it. Why do you, the claimer, think you see the light and we remain in the dark?</p>
<p>
It might be useful for the claimers to ponder: <i>Why did I succeed where all others have failed?</i> It might be useful to be a bit humble and at least think what did they see that we all missed? If they can say something like:</p>
<blockquote><p><b> </b> <em> The reason I succeeded in finding an algorithm for P=NP is that I noticed that <img alt="{\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\dots}"/> No one else seems to see that this insight is very powerful. It is very useful since it implies <img alt="{\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\dots}"/> </em>
</p></blockquote>
<p>
</p><p/><h3> Working alone </h3><p/>
<p/><p>
I think the vast majority of claimers of P=NP or other big results have almost always worked alone. This is okay, but the average number of authors these days of a theory paper is pretty large. So any paper that is sole authored, perhaps, leads the community think it is unusual—and is wrong. Another point is that being part of a team may help control the arrogance. It can also be invaluable in detecting errors. </p>
<p>
</p><p/><h3> Show them the money </h3><p/>
<p/><p>
There is an advantage in “proving” P=NP over other major problems. There is the Clay prize of a million dollars. I wonder if claimers could use the prize money in some interesting way. How about saying: If you read the my proof and repair it or make it more readable and it is correct, then you get something. A certain dollar amount. Or a percentage of the prize. Or—you get the idea.</p>
<p>
</p><p/><h3> The role of code </h3><p/>
<p/><p>
Many claimers have also supplied working code for their algorithm. That is they also supply a program that claims to solve some NP-complete problem. I have several thoughts about this. In some cases it seems that it could be possible to have code that works for small size problems, but not in the general case. This seems to be possible for the claims by some that they can solve the Traveling Salesman Problem, for example. Their algorithm could be correct for small instances.</p>
<p>
Mathematics is filled with surprises like: This effect works for all values of <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X}"/> less than some bound. If the claimers give a program, our expectation based on experience is that it may work for small cases but will probably fail in general. </p>
<p>
The last point is that working code could actually be valuable. If the code can be used to solve SAT problems how about using your program to enter a SAT contest and win it. A win, or even a good showing, would help tremendously in convincing people to read the paper. Or use the code to break some known cryptosystem. That would also convince people that they need to read your paper.</p>
<p>
</p><p/><h2> Writing Your Paper </h2><p/>
<p/><p>
Okay we all dream about solving a major open problem. Or even a minor one. Here we give an outline of how to write up such a paper. </p>
<p/><h3> How to write up the proof </h3><p/>
<p>
I would suggest that you not have any statements about why P=NP is an important problem. None. No history of the problem. No literature survey is needed. None. You goal is to get an expert to read and believe the proof. They will just skip over the above. Also please no statements of how your algorithm that solves P=NP is going to change the world. Just give us the proof.</p>
<p>
</p><p/><h3> How to get them to read the proof </h3><p/>
<p/><p>
This is really hard. Hard. I have read a number of claimers’ papers. I try to be helpful. However, many of us do not have the time to look at such papers. Years ago, before Fermat’s Last Theorem was solved, a famous mathematician once made up a post-card that looked like this:</p>
<p>
<a href="https://rjlipton.wordpress.com/2019/04/21/pnp-proofs/postcard/" rel="attachment wp-att-15784"><img alt="" class="aligncenter size-medium wp-image-15784" height="221" src="https://rjlipton.files.wordpress.com/2019/04/postcard.png?w=300&amp;h=221" width="300"/></a></p>
<p>
I think that we all have a mental version of this card. There are definitely ways to help induce someone to read a paper and its proof. Look at some recent top theory papers. Even the authors of these papers, often well known authors, work hard to motivate potential readers. The authors often do several things:</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <em>They often sketch the proof.</em> By leaving out details they may help get a reader interested. </p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <em>They often explain the new trick—or tricks.</em> The goal here is to explain some new insight that is used in the proof. We are very self-oriented: If I see that your new trick could be useful in my research that is a huge motivator for me to understand the proof. People are very excited about a strong result, but they are even more excited about a new trick. Explain what is new in your proof. If there is nothing new, no new trick or method, then hmmmm<img alt="{\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\dots}"/></p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <em>They often first prove a weaker result.</em> That is, they show that their method can already make progress. If you could prove that the zeta function has all its nontrivial zeros on the critical line, that would be apocalyptic—the famous Riemann Hypothesis, of course. But if you could merely prove that there is no zero in some new region, then that would still be <em>wonderful</em>. And also probably more believable. If you could prove that there is no zero <img alt="{z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bz%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{z}"/> with its real part <img alt="{0.99999}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0.99999%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0.99999}"/> that would be huge. If the proof of this is simpler, then use it to get readers excited about your full result. </p>
<p>
An observation related to the last point is: </p>
<blockquote><p><b> </b> <em> <i>Why do all claims of progress on P=NP give a polynomial time bound?</i> </em>
</p></blockquote>
<p>How about just getting a better bound of say <img alt="{2^{n/10}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5E%7Bn%2F10%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2^{n/10}}"/> for the Traveling Salesman Problem? Or a better bound for factoring? Or a better bound for your favorite problem?</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p>I hope these points help. One last pointer is to double-check dependencies. If your proof relies on a result by someone else, make sure the result really gives what you need. Terms may be defined differently from what you expect, or you may really need a feature of the proof rather than the mere statement. A mis-attributed result can become “undead.”</p></font></font></div>
    </content>
    <updated>2019-04-22T03:25:39Z</updated>
    <published>2019-04-22T03:25:39Z</published>
    <category term="Open Problems"/>
    <category term="P=NP"/>
    <category term="People"/>
    <category term="Proofs"/>
    <category term="claimed proofs"/>
    <category term="claims"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-04-23T21:20:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.09284</id>
    <link href="http://arxiv.org/abs/1904.09284" rel="alternate" type="text/html"/>
    <title>Stochastic Online Metric Matching</title>
    <feedworld_mtime>1555891200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gupta:Anupam.html">Anupam Gupta</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Guruganesh:Guru.html">Guru Guruganesh</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Peng:Binghui.html">Binghui Peng</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wajc:David.html">David Wajc</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.09284">PDF</a><br/><b>Abstract: </b>We study the minimum-cost metric perfect matching problem under online i.i.d
arrivals. We are given a fixed metric with a server at each of the points, and
then requests arrive online, each drawn independently from a known probability
distribution over the points. Each request has to be matched to a free server,
with cost equal to the distance. The goal is to minimize the expected total
cost of the matching.
</p>
<p>Such stochastic arrival models have been widely studied for the maximization
variants of the online matching problem; however, the only known result for the
minimization problem is a tight $O(\log n)$-competitiveness for the
random-order arrival model. This is in contrast with the adversarial model,
where an optimal competitive ratio of $O(\log n)$ has long been conjectured and
remains a tantalizing open question.
</p>
<p>In this paper, we show improved results in the i.i.d arrival model. We show
how the i.i.d model can be used to give substantially better algorithms: our
main result is an $O((\log \log \log n)^2)$-competitive algorithm in this
model. Along the way we give a $9$-competitive algorithm for the line and tree
metrics. Both results imply a strict separation between the i.i.d model and the
adversarial and random order models, both for general metrics and these
much-studied metrics.
</p></div>
    </summary>
    <updated>2019-04-22T23:22:10Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.09266</id>
    <link href="http://arxiv.org/abs/1904.09266" rel="alternate" type="text/html"/>
    <title>Secure and secret cooperation of robotic swarms by using Merkle trees</title>
    <feedworld_mtime>1555891200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Ferrer:Eduardo_Castell=oacute=.html">Eduardo Castelló Ferrer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hardjono:Thomas.html">Thomas Hardjono</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pentland:Alex.html">Alex Pentland</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.09266">PDF</a><br/><b>Abstract: </b>Swarm robotics systems are envisioned to become an important component of
both academic research and real-world applications. However, in order to reach
widespread adoption, new models that ensure the secure cooperation of these
systems need to be developed. This work proposes a novel model to encapsulate
cooperative robotic missions in Merkle trees, one of the fundamental components
of blockchain technology. With the proposed model, swarm operators can provide
the "blueprint" of the swarm's mission without disclosing raw data about the
mission itself. In other words, data verification can be separated from data
itself. We propose a system where swarm robots have to "prove" their integrity
to their peers by exchanging cryptographic proofs. This work analyzes and tests
the proposed approach for two different robotic missions: foraging (where
robots modify the environment) and maze formation (where robots become part of
the environment). In both missions, robots were able to cooperate and carry out
sequential operations in the correct order without having explicit knowledge
about the mission's high-level goals or objectives. The performance,
communication costs, and information diversity requirements for the proposed
approach are analyzed. Finally, conclusions are drawn and future work
directions are suggested.
</p></div>
    </summary>
    <updated>2019-04-22T23:24:19Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.09265</id>
    <link href="http://arxiv.org/abs/1904.09265" rel="alternate" type="text/html"/>
    <title>SSRGD: Simple Stochastic Recursive Gradient Descent for Escaping Saddle Points</title>
    <feedworld_mtime>1555891200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Zhize.html">Zhize Li</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.09265">PDF</a><br/><b>Abstract: </b>We analyze stochastic gradient algorithms for optimizing nonconvex problems.
In particular, our goal is to find local minima (second-order stationary
points) instead of just finding first-order stationary points which may be some
bad unstable saddle points. We show that a simple perturbed version of
stochastic recursive gradient descent algorithm (called SSRGD) can find an
$(\epsilon,\delta)$-second-order stationary point with
$\widetilde{O}(\sqrt{n}/\epsilon^2 + \sqrt{n}/\delta^4 + n/\delta^3)$
stochastic gradient complexity for nonconvex finite-sum problems. As a
by-product, SSRGD finds an $\epsilon$-first-order stationary point with
$O(n+\sqrt{n}/\epsilon^2)$ stochastic gradients. These results are almost
optimal since Fang et al. [2018] provided a lower bound
$\Omega(\sqrt{n}/\epsilon^2)$ for finding even just an $\epsilon$-first-order
stationary point. We emphasize that SSRGD algorithm for finding second-order
stationary points is as simple as for finding first-order stationary points
just by adding a uniform perturbation sometimes, while all other algorithms for
finding second-order stationary points with similar gradient complexity need to
combine with a negative-curvature search subroutine (e.g., Neon2 [Allen-Zhu and
Li, 2018]). Moreover, the simple SSRGD algorithm gets a simpler analysis.
Besides, we also extend our results from nonconvex finite-sum problems to
nonconvex online (expectation) problems, and prove the corresponding
convergence results.
</p></div>
    </summary>
    <updated>2019-04-22T23:30:26Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.09246</id>
    <link href="http://arxiv.org/abs/1904.09246" rel="alternate" type="text/html"/>
    <title>On the fixed-parameter tractability of the maximum 2-edge-colorable subgraph problem</title>
    <feedworld_mtime>1555891200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Aloisio:Alessandro.html">Alessandro Aloisio</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mkrtchyan:Vahan.html">Vahan Mkrtchyan</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.09246">PDF</a><br/><b>Abstract: </b>A $k$-edge-coloring of a graph is an assignment of colors $\{1,...,k\}$ to
edges of the graph such that adjacent edges receive different colors. In the
maximum $k$-edge-colorable subgraph problem we are given a graph and an integer
$k$, the goal is to find a $k$-edge-colorable subgraph with maximum number of
edges together with its $k$-edge-coloring. In this paper, we consider the
maximum 2-edge-colorable subgraph problem and present some results that deal
with the fixed-parameter tractability of this problem.
</p></div>
    </summary>
    <updated>2019-04-22T23:20:44Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-04-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.09228</id>
    <link href="http://arxiv.org/abs/1904.09228" rel="alternate" type="text/html"/>
    <title>Uncertainty about Uncertainty: Near-Optimal Adaptive Algorithms for Estimating Binary Mixtures of Unknown Coins</title>
    <feedworld_mtime>1555891200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lee:Jasper_C=_H=.html">Jasper C. H. Lee</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Valiant:Paul.html">Paul Valiant</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.09228">PDF</a><br/><b>Abstract: </b>Given a mixture between two populations of coins, "positive" coins that have
(unknown and potentially different) probabilities of heads
$\geq\frac{1}{2}+\Delta$ and negative coins with probabilities
$\leq\frac{1}{2}-\Delta$, we consider the task of estimating the fraction
$\rho$ of coins of each type to within additive error $\epsilon$. We introduce
new techniques to show a fully-adaptive lower bound of
$\Omega(\frac{\rho}{\epsilon^2\Delta^2})$ samples (for constant probability of
success). We achieve almost-matching algorithmic performance of
$O(\frac{\rho}{\epsilon^2\Delta^2}(1+\rho\log\frac{1}{\epsilon}))$ samples,
which matches the lower bound except in the regime where
$\rho=\omega(\frac{1}{\log 1/\epsilon})$. The fine-grained adaptive flavor of
both our algorithm and lower bound contrasts with much previous work in
distributional testing and learning.
</p></div>
    </summary>
    <updated>2019-04-22T23:30:14Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.09222</id>
    <link href="http://arxiv.org/abs/1904.09222" rel="alternate" type="text/html"/>
    <title>Tight Bounds for Online Edge Coloring</title>
    <feedworld_mtime>1555891200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cohen:Ilan_Reuven.html">Ilan Reuven Cohen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Peng:Binghui.html">Binghui Peng</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wajc:David.html">David Wajc</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.09222">PDF</a><br/><b>Abstract: </b>Vizing's celebrated theorem asserts that any graph of maximum degree $\Delta$
admits an edge coloring using at most $\Delta+1$ colors. In contrast, Bar-Noy,
Naor and Motwani showed over a quarter century that the trivial greedy
algorithm, which uses $2\Delta-1$ colors, is optimal among online algorithms.
Their lower bound has a caveat, however: it only applies to low-degree graphs,
with $\Delta=O(\log n)$, and they conjectured the existence of online
algorithms using $\Delta(1+o(1))$ colors for $\Delta=\omega(\log n)$. Progress
towards resolving this conjecture was only made under stochastic arrivals
(Aggarwal et al., FOCS'03 and Bahmani et al., SODA'10).
</p>
<p>We resolve the above conjecture for \emph{adversarial} vertex arrivals in
bipartite graphs, for which we present a $(1+o(1))\Delta$-edge-coloring
algorithm for $\Delta=\omega(\log n)$ known a priori. Surprisingly, if $\Delta$
is not known ahead of time, we show that no $\big(\frac{e}{e-1} - \Omega(1)
\big) \Delta$-edge-coloring algorithm exists. We then provide an optimal,
$\big(\frac{e}{e-1}+o(1)\big)\Delta$-edge-coloring algorithm for unknown
$\Delta=\omega(\log n)$. Key to our results, and of possible independent
interest, is a novel fractional relaxation for edge coloring, for which we
present optimal fractional online algorithms and a near-lossless online
rounding scheme, yielding our optimal randomized algorithms.
</p></div>
    </summary>
    <updated>2019-04-22T23:21:56Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.09216</id>
    <link href="http://arxiv.org/abs/1904.09216" rel="alternate" type="text/html"/>
    <title>Beyond Submodular Maximization</title>
    <feedworld_mtime>1555891200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Ghadiri:Mehrdad.html">Mehrdad Ghadiri</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Santiago:Richard.html">Richard Santiago</a>, Bruce Shepherd <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.09216">PDF</a><br/><b>Abstract: </b>While there are well-developed tools for maximizing a submodular function
subject to a matroid constraint, there is much less work on the corresponding
supermodular maximization problems. We develop new techniques for attacking
these problems inspired by the continuous greedy method applied to the
multi-linear extension of a submodular function. We first adapt the continuous
greedy algorithm to work for general twice-continuously differentiable
functions. The performance of the adapted algorithm depends on a new smoothness
parameter. If $F:[0,1]^n\rightarrow\mathbb{R}_{\geq 0}$ is one-sided
$\sigma$-smooth, then the approximation factor only depends on $\sigma$. We
apply the new algorithm to a broad class of quadratic supermodular functions
arising in diversity maximization. The case $\sigma=2$ captures metric
diversity maximization. We also develop new methods (inspired by swap rounding
and approximate integer decomposition) for rounding quadratics over a matroid
polytope. Together with the adapted continuous greedy this leads to a
$O(\sigma^{3/2})$-approximation. This is the best asymptotic approximation
known for this class of diversity maximization and the evidence suggests that
it may be tight.
</p>
<p>We then consider general (non-quadratic) functions. We give a broad
parameterized family of monotone functions which include submodular functions
and the just-discussed supermodular family of discrete quadratics. Such set
functions are called \emph{$\gamma$-meta-submodular}. We develop local search
algorithms with approximation factors that depend only on $\gamma$. We show
that the $\gamma$-meta-submodular families include well-known function classes
including meta-submodular functions ($\gamma=0$), proportionally submodular
($\gamma=1$), and diversity functions based on negative-type distances or
Jensen-Shannon divergence (both $\gamma=2$) and (semi-)metric diversity
functions.
</p></div>
    </summary>
    <updated>2019-04-22T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-04-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.09142</id>
    <link href="http://arxiv.org/abs/1904.09142" rel="alternate" type="text/html"/>
    <title>An Efficient Algorithm for the Fast Delivery Problem</title>
    <feedworld_mtime>1555891200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Carvalho:Iago_A=.html">Iago A. Carvalho</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Erlebach:Thomas.html">Thomas Erlebach</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Papadopoulos:Kleitos.html">Kleitos Papadopoulos</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.09142">PDF</a><br/><b>Abstract: </b>We study a problem where k autonomous mobile agents are initially located on
distinct nodes of a weighted graph (with n nodes and m edges). Each autonomous
mobile agent has a predefined velocity and is only allowed to move along the
edges of the graph. We are interested in delivering a package, initially
positioned in a source node s, to a destination node y. The delivery is
achieved by the collective effort of the autonomous mobile agents, which can
carry and exchange the package among them. The objective is to compute a
delivery schedule that minimizes the delivery time of the package. In this
paper, we propose an O(kn log(kn) + k m) time algorithm for this problem. This
improves the previous state-of-the-art O(k^2 m + k n^2 + APSP) time algorithm
for this problem, where APSP stands for the running-time of an algorithm for
the All-Pairs Shortest Paths problem.
</p></div>
    </summary>
    <updated>2019-04-22T23:30:31Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.08954</id>
    <link href="http://arxiv.org/abs/1904.08954" rel="alternate" type="text/html"/>
    <title>A Conditional Lower Bound on Graph Connectivity in MapReduce</title>
    <feedworld_mtime>1555891200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Im:Sungjin.html">Sungjin Im</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Moseley:Benjamin.html">Benjamin Moseley</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.08954">PDF</a><br/><b>Abstract: </b>MapReduce (and its open source implementation Hadoop) has become the de facto
platform for processing large data sets. MapReduce offers a streamlined
computational framework by interleaving sequential and parallel computation
while hiding underlying system issues from the programmer. Due to the
popularity of MapReduce, there have been attempts in the theoretical computer
science community to understand the power and limitations of the MapReduce
framework. In the most widely studied MapReduce models each machine has memory
sub-linear in the input size to the problem, hence cannot see the entire input.
This restriction places many limitations on algorithms that can be developed
for the model; however, the current understanding of these restrictions is
still limited.
</p>
<p>In this paper, our goal is to work towards understanding problems which do
not admit efficient algorithms in the MapReduce model. We study the basic
question of determining if a graph is connected or not. We concentrate on
instances of this problem where an algorithm is to determine if a graph
consists of a single cycle or two disconnected cycles. In this problem, locally
every part of the graph is similar and the goal is to determine the global
structure of the graph. We consider a natural class of algorithms that can
store/process/transfer the information only in the form of paths and show that
no randomized algorithm cannot answer the decision question in a
sub-logarithmic number of rounds. Currently, there are no absolute super
constant lower bounds on the number of rounds known for any problem in
MapReduce. We introduce some of the first lower bounds for a natural graph
problem, albeit for a restricted class of algorithms. We believe our result
makes progress towards understanding the limitations of MapReduce.
</p></div>
    </summary>
    <updated>2019-04-22T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.08934</id>
    <link href="http://arxiv.org/abs/1904.08934" rel="alternate" type="text/html"/>
    <title>Convex Graph Invariant Relaxations For Graph Edit Distance</title>
    <feedworld_mtime>1555891200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Candogan:Utkan_Onur.html">Utkan Onur Candogan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chandrasekaran:Venkat.html">Venkat Chandrasekaran</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.08934">PDF</a><br/><b>Abstract: </b>The edit distance between two graphs is a widely used measure of similarity
that evaluates the smallest number of vertex and edge deletions/insertions
required to transform one graph to another. It is NP-hard to compute in
general, and a large number of heuristics have been proposed for approximating
this quantity. With few exceptions, these methods generally provide upper
bounds on the edit distance between two graphs. In this paper, we propose a new
family of computationally tractable convex relaxations for obtaining lower
bounds on graph edit distance. These relaxations can be tailored to the
structural properties of the particular graphs via convex graph invariants.
Specific examples that we highlight in this paper include constraints on the
graph spectrum as well as (tractable approximations of) the stability number
and the maximum-cut values of graphs. We prove under suitable conditions that
our relaxations are tight (i.e., exactly compute the graph edit distance) when
one of the graphs consists of few eigenvalues. We also validate the utility of
our framework on synthetic problems as well as real applications involving
molecular structure comparison problems in chemistry.
</p></div>
    </summary>
    <updated>2019-04-22T23:31:45Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.08845</id>
    <link href="http://arxiv.org/abs/1904.08845" rel="alternate" type="text/html"/>
    <title>Planar Point Sets Determine Many Pairwise Crossing Segments</title>
    <feedworld_mtime>1555891200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pach:J=aacute=nos.html">János Pach</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rubin:Natan.html">Natan Rubin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tardos:G=aacute=bor.html">Gábor Tardos</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.08845">PDF</a><br/><b>Abstract: </b>We show that any set of $n$ points in general position in the plane
determines $n^{1-o(1)}$ pairwise crossing segments. The best previously known
lower bound, $\Omega\left(\sqrt n\right)$, was proved more than 25 years ago by
Aronov, Erd\H os, Goddard, Kleitman, Klugerman, Pach, and Schulman. Our proof
is fully constructive, and extends to dense geometric graphs.
</p></div>
    </summary>
    <updated>2019-04-22T23:32:34Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-04-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/062</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/062" rel="alternate" type="text/html"/>
    <title>TR19-062 |  Quantum Lower Bounds for Approximate Counting via Laurent Polynomials | 

	Scott Aaronson, 

	Robin Kothari, 

	William Kretschmer, 

	Justin Thaler</title>
    <summary>This paper proves new limitations on the power of quantum computers to solve approximate counting---that is, multiplicatively estimating the size of a nonempty set $S\subseteq [N]$.

Given only a membership oracle for $S$, it is well known that approximate counting takes $\Theta(\sqrt{N/|S|})$ quantum queries. But what if a quantum algorithm is also given "QSamples"---i.e., copies of the state $|S\rangle = \sum_{i\in S}|i\rangle$---or even the ability to apply reflections about $|S\rangle$? Our first main result is that, even then, the algorithm needs either $\Theta(\sqrt{N/|S|})$ queries or else $\Theta(\min\{|S|^{1/3},\sqrt{N/|S|}\})$ reflections or samples. We also give matching upper bounds.

We prove the lower bound using a novel generalization of the polynomial method of Beals et al. to Laurent polynomials, which can have negative exponents. We lower-bound Laurent polynomial degree using two methods: a new "explosion argument" and a new formulation of the dual polynomials method.

Our second main result rules out the possibility of a black-box Quantum Merlin-Arthur (or QMA) protocol for proving that a set is large. We show that, even if Arthur can make $T$ quantum queries to the set $S$, and also receives an $m$-qubit quantum witness from Merlin in support of $S$ being large, we have $Tm=\Omega(\min\{|S|,\sqrt{N/|S|}\})$. This resolves the open problem of giving an oracle separation between SBP and QMA.

Note that QMA is "stronger" than the queries+QSamples model in that Merlin's witness can be anything, rather than just the specific state $|S\rangle$, but also "weaker" in that Merlin's witness cannot be trusted. Intriguingly, Laurent polynomials also play a crucial role in our QMA lower bound, but in a completely different manner than in the queries+QSamples lower bound. This suggests that the "Laurent polynomial method" might be broadly useful in complexity theory.</summary>
    <updated>2019-04-21T13:57:29Z</updated>
    <published>2019-04-21T13:57:29Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-04-23T21:20:28Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/061</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/061" rel="alternate" type="text/html"/>
    <title>TR19-061 |  A Quantum Query Complexity Trichotomy for Regular Languages | 

	Daniel Grier, 

	Luke Schaeffer, 

	Scott Aaronson</title>
    <summary>We present a trichotomy theorem for the quantum query complexity of regular languages. Every regular language has quantum query complexity $\Theta(1)$, $\tilde{\Theta}(\sqrt n)$, or $\Theta(n)$. The extreme uniformity of regular languages prevents them from taking any other asymptotic complexity. This is in contrast to even the context-free languages, which we show can have query complexity $\Theta(n^c)$ for all computable $c \in [1/2,1]$. Our result implies an equivalent trichotomy for the approximate degree of regular languages, and a dichotomy---either $\Theta(1)$ or $\Theta(n)$---for sensitivity, block sensitivity, certificate complexity, deterministic query complexity, and randomized query complexity.

The heart of the classification theorem is an explicit quantum algorithm which decides membership in any star-free language in $\tilde{O}(\sqrt n)$ time. This well-studied family of the regular languages admits many interesting characterizations, for instance, as those languages expressible as sentences in first-order logic over the natural numbers with the less-than relation. Therefore, not only do the star-free languages capture functions such as OR, they can also express functions such as ``there exist a pair of 2's such that everything between them is a 0."  

Thus, we view the algorithm for star-free languages as a nontrivial generalization of Grover's algorithm which extends the quantum quadratic speedup to a much wider range of string-processing algorithms than was previously known.  We show a variety of applications---new quantum algorithms for dynamic constant-depth Boolean formulas, balanced parentheses nested constantly many levels deep, binary addition, a restricted word break problem, and path-discovery in narrow grids---all obtained as immediate consequences of our classification theorem.</summary>
    <updated>2019-04-21T13:56:47Z</updated>
    <published>2019-04-21T13:56:47Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-04-23T21:20:28Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=17317</id>
    <link href="https://gilkalai.wordpress.com/2019/04/21/the-random-matrix-and-more/" rel="alternate" type="text/html"/>
    <title>The (Random) Matrix and more</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Three pictures, and a few related links. Van Vu Spoiler: In one of the most intense scenes, the protagonist, with his bare hands and against all odds, took care of the mighty Wigner semi-circle law in two different ways. (From … <a href="https://gilkalai.wordpress.com/2019/04/21/the-random-matrix-and-more/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Three pictures, and a few related links.</p>
<h3>Van Vu</h3>
<p><a href="https://gilkalai.files.wordpress.com/2019/04/thematrixvv.jpg"><img alt="" class="alignnone size-full wp-image-17318" height="989" src="https://gilkalai.files.wordpress.com/2019/04/thematrixvv.jpg?w=640&amp;h=989" width="640"/></a></p>
<p><span style="color: #ff0000;">Spoiler: In one of the most intense scenes, the protagonist, with his bare hands and against all odds, took care of the mighty Wigner semi-circle law in two different ways. (From VV’s FB)</span></p>
<p><a href="https://math.virginia.edu/ims/lectures/van-vu/">More information on Van Vu’s series of lectures</a>. <a href="http://campuspress.yale.edu/vanvu/">Van Vu’s home page</a>; Related posts: <a href="https://www.scottaaronson.com/blog/?p=3482">did physicists really just prove that the universe is not a computer simulation—that we can’t be living in the Matrix?</a> (Shtetl-Optimized); A <a href="https://terrytao.wordpress.com/2012/02/02/random-matrices-the-universality-phenomenon-for-wigner-ensembles/">related 2012 post</a> on What’s New;</p>
<p>Two more pictures the first also from FB<span id="more-17317"/></p>
<h3>Saharon Shelah</h3>
<p><a href="https://gilkalai.files.wordpress.com/2019/04/saharon75.jpg"><img alt="" class="alignnone size-full wp-image-17320" height="498" src="https://gilkalai.files.wordpress.com/2019/04/saharon75.jpg?w=640&amp;h=498" width="640"/></a></p>
<p>Shaharon Shelah ICM 1974 (Vancouver) (Mohammad Golshani over FB)</p>
<p>See my post <a href="https://gilkalai.wordpress.com/2012/01/18/a-theorem-about-infinite-cardinals-everybody-should-know/" rel="bookmark">A theorem about infinite cardinals everybody should know</a>; Gowers’s post <a href="https://gowers.wordpress.com/2017/09/19/two-infinities-that-are-surprisingly-equal/">Two infinities that are surprisingly equal </a>about a recent breakthrough result by <a href="https://en.wikipedia.org/wiki/Maryanthe_Malliaris">Maryanthe Malliaris</a> and <a href="https://en.wikipedia.org/wiki/Saharon_Shelah">Saharon Shelah</a>; and <a href="https://arxiv.org/abs/1806.04917">a recent 4-page solution to a conjecture of Spencer</a> on finitary Hindman numbers by <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Mohsenipour%2C+S">Shahram Mohsenipour</a> and Shelah.  More information on the last paper: (1) It is an Iranian-Israeli collaboration (2) Spencer asked Shelah the question during the workshop: Combinatorics: Challenges and Applications, celebrating Noga Alon’s <a href="https://gilkalai.wordpress.com/2015/08/10/nogafest-nogaformulas-and-amazing-cash-prizes/">60th birthday</a>, Tel Aviv University, January 17-21, 2016. (3) This is paper 1146 in Shelah’s (main) <a href="http://shelah.logic.at/">list of publications</a>. Shelah’s 1974 lecture was called “Why There Are Many Nonisomorphic Models for Unsuperstable Theories.”</p>
<h3>Sándor Szalai,  Catherine Rényi, Alfréd Rényi András Hajnal and Paul Erdős</h3>
<p><a href="https://gilkalai.files.wordpress.com/2019/04/matrahazaszalairenyihajnalerdos1958.jpg"><img alt="" class="alignnone size-full wp-image-17314" height="434" src="https://gilkalai.files.wordpress.com/2019/04/matrahazaszalairenyihajnalerdos1958.jpg?w=640&amp;h=434" width="640"/></a></p>
<p>From left: Sándor Szalai,  Catherine Rényi, Alfréd Rényi, András Hajnal and Paul Erdős (Matrahaza ) The picture is from Janos Pach’s Lancaster lecture, who also discussed how Szalai came up with Ramsey’s theorem. (See also Noga Alon and Michel Krivelevich’s chapter <a href="http://www.cs.tau.ac.il/~nogaa/PDFS/epc7.pdf" rel="noopener" target="_blank" title="opens in a new window">Extremal and Probabilistic Combinatorics, In: Princeton Companion to Mathematics, W. T. Gowers, Ed., Princeton University Press 2008, pp. 562-575.</a>)</p>
<p>In the course of an examination of friendship between children some fifty years ago, the Hungarian sociologist Sandor Szalai observed that among any group of about twenty children he checked he could always find four children any two of whom were friends, or else four children no two of whom were friends. Despite the temptation to try to draw sociological conclusions, Szalai realized that this might well be a mathematical phenomenon rather than sociological one.  He got interested in the problem, discussed it with  Erdős, Rényi , and Turán and in a short time he came up with a number of interesting constructions. In fact, he obtained record lower bound estimates for several Ramsey numbers.</p>
<p>(Janos’ further remarks: “Sandor (Alexander) Szalai was a well known Hungarian sociologist and a famously bright and witty man. I am not sure whether he was the first to notice and study the the laws of clique- and anti-clique formation among groups of schoolchildren, but I suspect that he was not. The sociology of small groups used to be a popular alternative to more “dangerous” Marxist theories of classes in the 50-ies and 60-ies. My guess would be that Szalai discussed these issues and was fascinated by this subject some time around 1960. It is fair to say that he independently<em> conjectured</em> Ramsey’s theorem.”)</p></div>
    </content>
    <updated>2019-04-21T06:33:41Z</updated>
    <published>2019-04-21T06:33:41Z</published>
    <category term="Combinatorics"/>
    <category term="People"/>
    <category term="What is Mathematics"/>
    <category term="Alfr&#xE9;d R&#xE9;nyi"/>
    <category term="Andr&#xE1;s Hajnal"/>
    <category term="Catherine R&#xE9;nyi"/>
    <category term="Paul Erdos"/>
    <category term="Saharon Shelah"/>
    <category term="S&#xE1;ndor Szalai"/>
    <category term="Van Vu"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-04-23T21:20:30Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4172</id>
    <link href="https://www.scottaaronson.com/blog/?p=4172" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4172#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4172" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Not yet retired from research</title>
    <summary xml:lang="en-US">Last night, two papers appeared on the quantum physics arXiv that my coauthors and I have been working on for more than a year, and that I’m pretty happy about. The first paper, with Guy Rothblum, is Gentle Measurement of Quantum States and Differential Privacy (85 pages, to appear in STOC’2019). This is Guy’s first […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>Last night, two papers appeared on the quantum physics arXiv that my coauthors and I have been working on for more than a year, and that I’m pretty happy about.</p>



<p>The first paper, with Guy Rothblum, is <a href="https://arxiv.org/abs/1904.08747">Gentle Measurement of Quantum States and Differential Privacy</a> (85 pages, to appear in STOC’2019).  This is Guy’s first paper that has anything to do with quantum, and also my first paper that has anything to do with privacy.  (What do I care about privacy?  I just share everything on this blog…)  The paper has its origin when I gave a talk at the Weizmann Institute about “shadow tomography” (a task where you have to measure quantum states very carefully to avoid destroying them), and Guy was in the audience, and he got all excited that the techniques sounded just like what they use to ensure privacy in data-mining, and I figured it was just some wacky coincidence and brushed him off, but he persisted, and it turned out that he was 100% right, and our two fields were often studying the same problems from different angles and we could prove it.  Anyway, here’s the abstract:</p>



<blockquote>In <i>differential privacy (DP)</i>, we want to query a database about n users, in a way that “leaks at most ε about any individual user,” even conditioned on any outcome of the query.  Meanwhile, in <i>gentle measurement</i>, we want to measure n quantum states, in a way that “damages the states by at most α,” even conditioned on any outcome of the measurement.  In both cases, we can achieve the goal by techniques like deliberately adding noise to the outcome before returning it.  This paper proves a new and general connection between the two subjects.  Specifically, we show that on products of n quantum states, any measurement that is α-gentle for small α is also O(α)-DP, and any product measurement that is ε-DP is also O(ε√n)-gentle.
<p>Illustrating the power of this connection, we apply it to the recently studied problem of <i>shadow tomography</i>.  Given an unknown d-dimensional quantum state ρ, as well as known two-outcome measurements E<sub>1</sub>,…,E<sub>m</sub>, shadow tomography asks us to estimate Pr[E<sub>i</sub> accepts ρ], for <i>every</i> i∈[m], by measuring few copies of ρ.  Using our connection theorem, together with a quantum analog of the so-called <i>private multiplicative weights</i> algorithm of Hardt and Rothblum, we give a protocol to solve this problem using O((log m)<sup>2</sup>(log d)<sup>2</sup>) copies of ρ, compared to Aaronson’s previous bound of ~O((log m)<sup>4</sup>(log d)).  Our protocol has the advantages of being <i>online</i> (that is, the E<sub>i</sub>‘s are processed one at a time), gentle, and conceptually simple.
</p><p>Other applications of our connection include new <i>lower</i> bounds for shadow tomography from lower bounds on DP, and a result on the safe use of estimation algorithms as subroutines inside larger quantum algorithms.</p></blockquote>



<p>The second paper, with Robin Kothari, UT Austin PhD student William Kretschmer, and Justin Thaler, is <a href="https://arxiv.org/abs/1904.08914">Quantum Lower Bounds for Approximate Counting via Laurent Polynomials</a>.  Here’s the abstract:</p>



<blockquote>Given only a membership oracle for S, it is well-known that approximate counting takes Θ(√(N/|S|)) quantum queries.  But what if a quantum algorithm is also given “QSamples”—i.e., copies of the state |S〉=Σ<sub>i∈S</sub>|i〉—or even the ability to apply reflections about |S〉?  Our first main result is that, even then, the algorithm needs either Θ(√(N/|S|)) queries or else Θ(min{|S|<sup>1/3</sup>,√(N/|S|)}) reflections or samples.  We also give matching upper bounds.

<p>We prove the lower bound using a novel generalization of the polynomial method of Beals et al. to <i>Laurent polynomials</i>, which can have negative exponents.  We lower-bound Laurent polynomial degree using two methods: a new “explosion argument” that pits the positive- and negative-degree parts of the polynomial against each other, and a new formulation of the dual polynomials method.

</p><p>Our second main result rules out the possibility of a black-box Quantum Merlin-Arthur (or QMA) protocol for proving that a set is large. More precisely, we show that, even if Arthur can make T quantum queries to the set S⊆[N], and also receives an m-qubit quantum
witness from Merlin in support of S being large, we have Tm=Ω(min{|S|,√(N/|S|)}).  This resolves the open problem of giving an oracle separation between SBP, the complexity class that captures
approximate counting, and QMA.

</p><p>Note that QMA is “stronger” than the queries+QSamples model in that Merlin’s witness can be anything, rather than just the specific state |S〉, but also “weaker” in that Merlin’s witness cannot be trusted.  Intriguingly, Laurent polynomials <i>also</i> play a crucial role in our QMA lower bound, but in a completely different
manner than in the queries+QSamples lower bound.  This suggests that the “Laurent polynomial method” might be broadly useful in complexity theory.</p></blockquote>



<p>I need to get ready for our family’s Seder now, but after that, I’m happy to answer any questions about either of these papers in the comments.</p>



<p>Meantime, the biggest breakthrough in quantum complexity theory of the past month isn’t either of the above: it’s the <a href="https://arxiv.org/abs/1904.05870">paper by Anand Natarajan and John Wright</a> showing that MIP*, or multi-prover interactive proof systems with entangled provers, contains NEEXP, or nondeterministic <strong>doubly</strong>-exponential time (!!).  I’ll try to blog about this later, but if you can’t wait, check out <a href="https://mycqstate.wordpress.com/2019/04/14/randomness-and-interaction-entanglement-ups-the-game/">this excellent post by Thomas Vidick</a>.</p></div>
    </content>
    <updated>2019-04-19T21:16:21Z</updated>
    <published>2019-04-19T21:16:21Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Complexity"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Quantum"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2019-04-19T21:17:59Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=15768</id>
    <link href="https://rjlipton.wordpress.com/2019/04/18/a-reason-why-circuit-lower-bounds-are-hard/" rel="alternate" type="text/html"/>
    <title>A Reason Why Circuit Lower Bounds Are Hard</title>
    <summary>And a possible approach to avoid this obstacle Valentine Kabanets is a famous complexity theorist from Simon Fraser University. He has been at the forefront of lower bounds for over two decades. Today we draw attention to this work and raise an idea about trying to unravel what makes circuit lower bounds hard. He is […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>And a possible approach to avoid this obstacle</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<p><a href="https://rjlipton.files.wordpress.com/2019/04/kabanetssfu.jpg"><img alt="" class="alignright wp-image-15769" height="200" src="https://rjlipton.files.wordpress.com/2019/04/kabanetssfu.jpg?w=129&amp;h=200" width="129"/></a></p>
<p>
Valentine Kabanets is a famous complexity theorist from Simon Fraser University. He has been at the forefront of lower bounds for over two decades. </p>
<p>
Today we draw attention to this work and raise an idea about trying to unravel what makes circuit lower bounds hard.<span id="more-15768"/></p>
<p>
He is the common author on <a href="https://eccc.weizmann.ac.il/report/2019/022/">two</a> new <a href="https://eccc.weizmann.ac.il/report/2019/018/">papers</a> on the Minimum Circuit Size Problem (MCSP), which belongs to <img alt="{\mathsf{NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{NP}}"/> but is not known to be complete or in <img alt="{\mathsf{P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{P}}"/>. We <a href="https://rjlipton.wordpress.com/2015/03/05/news-on-intermediate-problems/">posted</a> on MCSP four years ago and mentioned his 1999 <a href="http://eccc.hpi-web.de/report/1999/045">paper</a> with Jin-Yi Cai, which gives evidence for MCSP truly being neither complete nor in <img alt="{\mathsf{P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{P}}"/>. This “intermediate” status and the problem’s simplicity have raised hopes that direct attacks might succeed. The new papers prove direct lower bounds against some restricted circuit/formula models, including constant-depth circuits with mod-<img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> gates for <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> prime. But they stop short of mod-<img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m}"/> for <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m}"/> composite and other barrier cases.</p>
<p>
He has a nifty research <a href="https://www.cs.sfu.ca/~kabanets/research.html">statement</a> on his home page. It shows how derandomization, pseudorandomness, circuit complexity, and crypto combine into his two current projects. In a clickable tab for the third heading, he puts the meta-issue in pithy terms:</p>
<blockquote><p><b> </b> <em> <i>Why is proving circuit lower bounds so difficult?</i> </em>
</p></blockquote>
<p/><p>
His first answer tab speaks a connection we have also often emphasized here:</p>
<blockquote><p><b> </b> <em> Traditionally, designing efficient algorithms is the subject of the theory of algorithms, while lower bounds are sought in complexity theory. It turns out, however, that there is a deep connection between the two directions: better algorithms (for a certain class of problems) also yield strong lower bounds (for related problems), and vice versa: strong lower bounds translate into more efficient algorithms. </em>
</p></blockquote>
<p/><p>
Of course we agree, and we love connections shown in the new papers to problems such as distinguishing a very slightly biased coin from a true one. But we will try to supplement the algorithmic view of circuit lower bounds with a direct look at the underlying logic.</p>
<p>
</p><p/><h2> Logical Structure of Lower Bounds </h2><p/>
<p/><p>
Okay we all know that circuit lower bounds are hard. For all Kabanets’ success and beautiful work—he like the rest of the complexity field—are unable to prove what we believe is true. They cannot in the full circuit model prove anything close to what is believed to be true for at least a half a century: There are explicit Boolean functions that cannot be computed by any linear size circuit.</p>
<p>
We feel that the logical structure of lower bounds statements gives insight into their difficulty. Perhaps this is almost a tautology. Of course the logical structure of any mathematical statement helps us understand its inherent difficulty. But we believe more: That this structure can reveal quite a bit about lower bounds. Let’s take a look at lower bounds and see if this belief holds up.</p>
<p>
In particular let’s compare the two main approaches to proving lower bounds: non-uniform and uniform. Our claim is that they have different logical structure, and that this difference explains why there is such a gap between the two. While lower bounds—non-uniform or uniform—are hard, uniform ones are at least possible now. Non-uniform lower bounds are really very difficult.</p>
<p>
Here is one example. To prove an explicit size lower bound for Boolean circuits—we’ll be content with just a linear one—we must give a particular family of Boolean functions <img alt="{f_{n}(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_%7Bn%7D%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_{n}(x)}"/> (each of <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> inputs) so that:</p>
<ol>
<li>
Given <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> and <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> we can evaluate <img alt="{f_{n}(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_%7Bn%7D%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_{n}(x)}"/> in polynomial time; <p/>
</li><li>
There is no Boolean circuit of size <img alt="{\alpha n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha n}"/> that correctly computes <img alt="{f_{n}(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_%7Bn%7D%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_{n}(x)}"/> on all <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> of length <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>.
</li></ol>
<p>
Here <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> is a constant and <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> is assumed to be large enough. The terrific <a href="http://www.wisdom.weizmann.ac.il/~ranraz/publications/P5nlb.pdf">paper</a> of Kazuo Iwama, Oded Lachish, Hiroki Morizumi, and Ran Raz gives explicit Boolean functions whose size for circuits with the usual <em>not</em> and binary <em>and</em> and <em>or</em> operators exceeds <img alt="{5n-o(n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B5n-o%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{5n-o(n)}"/>. </p>
<p>
</p><p/><h2> An Approach </h2><p/>
<p/><p>
Let’s look at the above example more carefully. Suppose that in place of a single Boolean function on <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> inputs we have a list of them: </p>
<p align="center"><img alt="\displaystyle  f_{n,1}(x),\dots,f_{n,m}(x). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++f_%7Bn%2C1%7D%28x%29%2C%5Cdots%2Cf_%7Bn%2Cm%7D%28x%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  f_{n,1}(x),\dots,f_{n,m}(x). "/></p>
<p>Can we prove the following? </p>
<p align="center"><img alt="\displaystyle  \exists n_{0}\ \forall n &gt; n_{0} \ \exists f_{n,k} \ \forall C \in \mathsf{SIZE}(\alpha n) \ \neg\mathsf{compute}(C,f_{n,k}). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cexists+n_%7B0%7D%5C+%5Cforall+n+%3E+n_%7B0%7D+%5C+%5Cexists+f_%7Bn%2Ck%7D+%5C+%5Cforall+C+%5Cin+%5Cmathsf%7BSIZE%7D%28%5Calpha+n%29+%5C+%5Cneg%5Cmathsf%7Bcompute%7D%28C%2Cf_%7Bn%2Ck%7D%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \exists n_{0}\ \forall n &gt; n_{0} \ \exists f_{n,k} \ \forall C \in \mathsf{SIZE}(\alpha n) \ \neg\mathsf{compute}(C,f_{n,k}). "/></p>
<p>The first thing to note is the effect of letting the number <img alt="{\bf m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbf+m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bf m}"/> of functions vary:</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> If <img alt="{\bf m = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbf+m+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bf m = 1}"/>, this just becomes our original explicit circuit lower bound problem. </p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> If <img alt="{\bf m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbf+m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bf m}"/> is a huge value, however, this becomes the exponential lower bound shown by Claude Shannon—a known quantity. </p>
<p>
In our terms, the latter takes <img alt="{\bf m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbf+m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bf m}"/> equal to <img alt="{2^{2^{n}}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5E%7B2%5E%7Bn%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2^{2^{n}}}"/>, so that given <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> our function list is just the list of all Boolean functions. If all we care about is an <img alt="{\alpha n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha n}"/> lower bound, then the high end of the range can be something like <img alt="{m = 2^{2\alpha n\log(n)} = n^{2\alpha n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm+%3D+2%5E%7B2%5Calpha+n%5Clog%28n%29%7D+%3D+n%5E%7B2%5Calpha+n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m = 2^{2\alpha n\log(n)} = n^{2\alpha n}}"/>. So at the high end we have a simple counting argument for the proof but have traded away explicitness. The question will be about the tradeoffs for <img alt="{\bf m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbf+m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bf m}"/> in-between the extremes.</p>
<p>
</p><p/><h2> An Analogy </h2><p/>
<p/><p>
The above idea that we can model the lower bound methods by controlling the length of the list of the functions is the key to our approach. Perhaps it may help to note an analogy to other famous hard problems of constructing explicit objects. In particular, let’s look at constructing transcendental numbers. Recall these are real numbers that are not algebraic: they are not roots of polynomials with integer coefficients. They include <img alt="{\pi = 3.14159\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi+%3D+3.14159%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\pi = 3.14159\dots}"/> and <img alt="{e = 2.71828\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Be+%3D+2.71828%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{e = 2.71828\dots}"/></p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> The <a href="https://en.wikipedia.org/wiki/Liouville_number">Liouville</a> numbers of Joseph Liouville. 	</p>
<p align="center"><img alt="\displaystyle  x = \sum_{k=1}^\infty \frac{a_k}{b^{k!}}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++x+%3D+%5Csum_%7Bk%3D1%7D%5E%5Cinfty+%5Cfrac%7Ba_k%7D%7Bb%5E%7Bk%21%7D%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  x = \sum_{k=1}^\infty \frac{a_k}{b^{k!}}. "/></p>
<p>These are explicit numbers that were proved by him in 1844 to be transcendental. In terms of our model <img alt="{\bf m=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbf+m%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bf m=1}"/>.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> The great <img alt="{\pi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\pi}"/> and <img alt="{e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Be%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{e}"/> puzzle. This is the observation that of <img alt="{\pi + e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi+%2B+e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\pi + e}"/> or <img alt="{\pi - e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi+-+e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\pi - e}"/>, at least one is a transcendental number. In our terms this gives <img alt="{\bf m=2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbf+m%3D2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bf m=2}"/>.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> The famous theorem of Georg Cantor—read as proving the existence of transcendental numbers since algebraic ones are countable.</p>
<p>
Here the high end of the range is as extreme as can be. Cantor’s `list’ of numbers is uncountable—in our model, <img alt="{\bf m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbf+m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bf m}"/> is the cardinality of the real numbers. Note, the fact that his <img alt="{\bf m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbf+m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bf m}"/> is huge, really huge, may explain why some at the time were unimpressed by this result. They wanted the ‘list’ to be small, actually they wanted <img alt="{\bf m=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbf+m%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bf m=1}"/>. See <a href="https://www.jstor.org/stable/2975129?seq=1#page_scan_tab_contents">this</a> for a discussion of the history of these ideas.</p>
<p>
<img alt="{\bullet}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet}"/> The theorem by Waim Zudilin, in a 2001 <a href="https://iopscience.iop.org/article/10.1070/RM2001v056n04ABEH000427/meta">paper</a>, that at least one of the numbers <img alt="{\zeta(5), \zeta(7), \zeta(9), \zeta(11)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Czeta%285%29%2C+%5Czeta%287%29%2C+%5Czeta%289%29%2C+%5Czeta%2811%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\zeta(5), \zeta(7), \zeta(9), \zeta(11)}"/> must be irrational. It is for “irrational” not “transcendental,” but exemplified <img alt="{\bf m = 4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbf+m+%3D+4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bf m = 4}"/> in a highly nontrivial manner. The technical point that makes this work is interactions among these numbers that cannot be captured just by considering any one of them separately. This has <img alt="{\bf m = 4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbf+m+%3D+4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bf m = 4}"/>.</p>
<p>
</p><p/><h2> Joining Functions </h2><p/>
<p/><p>
The issue is this: Suppose that we have a list of several boolean functions <img alt="{f_{1}(x),\dots,f_{m}(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_%7B1%7D%28x%29%2C%5Cdots%2Cf_%7Bm%7D%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_{1}(x),\dots,f_{m}(x)}"/>. Then we can join them together to form one function <img alt="{g(x,y)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%28x%2Cy%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{g(x,y)}"/> so that 	</p>
<p align="center"><img alt="\displaystyle  g(x,1) = f_{1}(x), \cdots, g(x,m) = f_{m}(x). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++g%28x%2C1%29+%3D+f_%7B1%7D%28x%29%2C+%5Ccdots%2C+g%28x%2Cm%29+%3D+f_%7Bm%7D%28x%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  g(x,1) = f_{1}(x), \cdots, g(x,m) = f_{m}(x). "/></p>
<p>Clearly the function <img alt="{g(x,y)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%28x%2Cy%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{g(x,y)}"/> is easy implies that all of the <img alt="{f_{y}(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_%7By%7D%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_{y}(x)}"/> are easy. This join trick shows that we can encode several boolean functions into one function. Note, we can even make <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y}"/> have only order <img alt="{\log(n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\log(n)}"/> where <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> has <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> bits.</p>
<p>
Thus we can join any collection of functions to make a “universal” one that is at least as hard as the worst of the single functions. More precisely, 	</p>
<p align="center"><img alt="\displaystyle  \mathsf{complexity}(g) \ge \mathsf{complexity}(f_{y}) \text{ for } y=1,\dots,m. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathsf%7Bcomplexity%7D%28g%29+%5Cge+%5Cmathsf%7Bcomplexity%7D%28f_%7By%7D%29+%5Ctext%7B+for+%7D+y%3D1%2C%5Cdots%2Cm.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \mathsf{complexity}(g) \ge \mathsf{complexity}(f_{y}) \text{ for } y=1,\dots,m. "/></p>
<p>Here <img alt="{\mathsf{complexity}(h)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7Bcomplexity%7D%28h%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{complexity}(h)}"/> is the circuit complexity of the boolean function <img alt="{h}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bh%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{h}"/>.</p>
<p>
If <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m}"/> is bigger than <img alt="{2^{O(n)}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5E%7BO%28n%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2^{O(n)}}"/>, that is if <img alt="{m = 2^{\omega(n)}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm+%3D+2%5E%7B%5Comega%28n%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m = 2^{\omega(n)}}"/>, then the joined function has more than linearly many variables. Can we possibly establish nontrivial interactions among so many functions, say <img alt="{{\bf m} = n^{2n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cbf+m%7D+%3D+n%5E%7B2n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{\bf m} = n^{2n}}"/>?</p>
<p>
One can also try to get this effect with fewer or no additional variables by taking the XOR of some subset of functions in the list. If this is done randomly for each input length <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> then one can expect hard functions to show up for many <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>. If this process can then be <em>de-randomized</em>, then this may yield an explicit hard function. We wonder how this idea might meld with Andy Yao’s famous XOR Lemma and conditions to <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.441.2818&amp;rep=rep1&amp;type=pdf">de-randomize</a> it.</p>
<p>
</p><p/><h2> Joining Numbers </h2><p/>
<p/><p>
Ken and I thought about the above simple fact about joins, which seems special to functions. Joining by interleaving the decimal expansions is not an arithmetic operation. However, it appears that there may be a similar result possible for transcendental numbers. </p>
<blockquote><p><b>Lemma 1</b> <em> Suppose that <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\alpha}"/> and <img alt="{\beta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\beta}"/> are real numbers. Then 	</em></p><em>
<p align="center"><img alt="\displaystyle  \alpha + i\beta " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Calpha+%2B+i%5Cbeta+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="\displaystyle  \alpha + i\beta "/></p>
</em><p><em>is a transcendental complex number if at least one of <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\alpha}"/> or <img alt="{\beta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\beta}"/> are transcendental. </em>
</p></blockquote>
<p/><p>
<em>Proof:</em>  Let <img alt="{\gamma = \alpha + i\beta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cgamma+%3D+%5Calpha+%2B+i%5Cbeta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\gamma = \alpha + i\beta}"/> be an algebraic number. Thus there must be a polynomial <img alt="{q(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q(x)}"/> with integer coefficients so that 	</p>
<p align="center"><img alt="\displaystyle  q(\gamma) = q(\alpha + i\beta) = 0. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++q%28%5Cgamma%29+%3D+q%28%5Calpha+%2B+i%5Cbeta%29+%3D+0.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  q(\gamma) = q(\alpha + i\beta) = 0. "/></p>
<p>Then it follows by complex conjugation that 	</p>
<p align="center"><img alt="\displaystyle  q(\alpha - i\beta) = 0. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++q%28%5Calpha+-+i%5Cbeta%29+%3D+0.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  q(\alpha - i\beta) = 0. "/></p>
<p>	 Therefore <img alt="{\alpha + i\beta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha+%2B+i%5Cbeta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha + i\beta}"/> and <img alt="{\alpha -i\beta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha+-i%5Cbeta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha -i\beta}"/> are both algebraic; thus, so is their sum which is <img alt="{2\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2\alpha}"/>. Thus <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> is algebraic. It follows that <img alt="{\beta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\beta}"/> is also algebraic. This shows that <img alt="{\gamma}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cgamma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\gamma}"/> is transcendental. <img alt="\Box" class="latex" src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Box"/></p>
<p>
A question: Can we show that we can do a “join” operation for three or more numbers? That is given numbers <img alt="{x_{1},\dots,x_{m}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_%7B1%7D%2C%5Cdots%2Cx_%7Bm%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x_{1},\dots,x_{m}}"/> can we construct a number <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y}"/> that is transcendental if and only if at least one of <img alt="{x_{i}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_%7Bi%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x_{i}}"/> is transcendental?</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Is the <img alt="{\bf m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbf+m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bf m}"/> model useful? Is it possible for it to succeed where a direct explicit argument (<img alt="{{\bf m} = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cbf+m%7D+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{\bf m} = 1}"/>) does not? Does it need <img alt="{{\bf m} \gg 2^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cbf+m%7D+%5Cgg+2%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{\bf m} \gg 2^n}"/> to rise above technical dependence on the <img alt="{\bf m = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbf+m+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bf m = 1}"/> case via the join construction?</p>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2019/04/valentine-sandan-test-action-small.jpeg"><img alt="" class="aligncenter wp-image-15770" height="158" src="https://rjlipton.files.wordpress.com/2019/04/valentine-sandan-test-action-small.jpeg?w=235&amp;h=158" width="235"/></a>
</td>
</tr>
<tr>
<td class="caption alignright">
<font size="-2">Maybe the barriers just need 3-Dan martial-arts treatment.  <a href="https://www.vancouverwestaikikai.com/programs/intro-beginner.shtml">Source</a>—our congrats.<br/>
</font>
</td>
</tr>
</tbody></table></font></font></div>
    </content>
    <updated>2019-04-18T22:16:11Z</updated>
    <published>2019-04-18T22:16:11Z</published>
    <category term="All Posts"/>
    <category term="Ideas"/>
    <category term="P=NP"/>
    <category term="People"/>
    <category term="circuit complexity"/>
    <category term="circuits"/>
    <category term="lower bounds"/>
    <category term="transcendental numbers"/>
    <category term="Valentine Kabanets"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-04-23T21:20:34Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-27705661.post-4286404438772500234</id>
    <link href="http://processalgebra.blogspot.com/feeds/4286404438772500234/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=27705661&amp;postID=4286404438772500234" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/4286404438772500234" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/4286404438772500234" rel="self" type="application/atom+xml"/>
    <link href="http://processalgebra.blogspot.com/2019/04/the-complexity-of-identifying.html" rel="alternate" type="text/html"/>
    <title>The Complexity of Identifying Characteristic Formulae</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">One of the classic results in concurrency theory is the Hennessy-Milner Theorem. This result states that<br/><ol><li>two bisimilar states in a labelled transition system satisfy exactly the same formulae in a multi-modal logic now called Hennessy-Milner logic, and </li><li>two states in a labelled transition system that satisfy a mild finiteness constraint (called image finiteness)  and enjoy the same properties expressible in Hennessy-Milner logic are bisimilar.</li></ol>See, for instance, Section 1.2 in <a href="http://homepages.inf.ed.ac.uk/cps/chapbisim.pdf">these notes by Colin Stirling</a> for an exposition of that result. A consequence of the Hennessy-Milner Theorem is that whenever two states <i>p </i>and <i>q </i>in a labelled transition system are <i>not</i> bisimilar, one can come up with a formula in Hennessy-Milner logic that <i>p </i>satisfies, but<i> q </i>does not<i>. </i>Moreover, for each state <i>p </i>in a finite, loop-free labelled transition systems, it is possible to construct a formula <i>F(p) </i>in Hennessy-Milner logic that completely characterizes <i>p</i> up to bisimilarity. This means that, for each state <i>q</i>, <i>p</i> is bisimilar to <i>q</i> if, and only if, <i>q</i> satisfies <i>F(p)</i>. The formula<i> F(p) </i>is called a characteristic formula for<i> p </i>up to bisimilarity.<i> </i>One can obtain a similar result for states in finite labelled transition systems by extending Hennessy-Milner logic with greatest fixed points. <i><br/></i><br/><br/>Characteristic formulae have a long history in concurrency theory. However, to be best of my knowledge, the complexity of determining whether a formula is characteristic had not been studied before <a href="https://sites.google.com/view/antonisachilleos">Antonis Achilleos</a> first addressed the problem in <a href="https://arxiv.org/abs/1605.01004">this conference paper</a>. In that paper, Antonis focused on the complexity of the problem of determining whether a formula <i>F</i> is complete, in the sense that, for each formula <i>G</i>, it can derive either <i>G</i> or its negation.<br/><br/>Our recent preprint    <a href="http://icetcs.ru.is/theofomon/CharFormComplexity.pdf"><i>The   Complexity of Identifying Characteristic Formulae</i></a> extends the results originally obtained by Antonis to a variety of modal logics, possibly including least and greatest fixed-point operators. In the paper, we show that completeness, characterization, and validity have the same complexity — with some exceptions for which there are, in general, no complete formulae. So, for most modal logics of interest, the problem is coNP-complete or PSPACE-complete, and becomes EXPTIME-complete for modal logics with fixed points. To prove our upper bounds, we present a nondeterministic procedure with an oracle for validity that combines tableaux and a test for bisimilarity, and determines whether a formula is complete.<br/><br/>I think that there is still a lot of work that can be done in studying this problem, with respect to a variety of other notions of equivalence considered in concurrency theory, so stay tuned for further updates. </div>
    </content>
    <updated>2019-04-18T17:19:00Z</updated>
    <published>2019-04-18T17:19:00Z</published>
    <author>
      <name>Luca Aceto</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/01092671728833265127</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-27705661</id>
      <author>
        <name>Luca Aceto</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/01092671728833265127</uri>
      </author>
      <link href="http://processalgebra.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://processalgebra.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Papers I find interesting---mostly, but not solely, in Process Algebra---, and some fun stuff in Mathematics and Computer Science at large and on general issues related to research, teaching and academic life.</subtitle>
      <title>Process Algebra Diary</title>
      <updated>2019-04-22T08:46:05Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/060</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/060" rel="alternate" type="text/html"/>
    <title>TR19-060 |  Gentle Measurement of Quantum States and Differential Privacy | 

	Scott Aaronson, 

	Guy Rothblum</title>
    <summary>In differential privacy (DP), we want to query a database about $n$ users, in a way that "leaks at most $\varepsilon$ about any individual user," even conditioned on any outcome of the query.  Meanwhile, in gentle measurement, we want to measure $n$ quantum states, in a way that "damages the states by at most $\alpha$," even conditioned on any outcome of the measurement.  In both cases, we can achieve the goal by techniques like deliberately adding noise to the outcome before returning it.  This paper proves a new and general connection between the two subjects. Specifically, we show that on products of $n$ quantum states, any measurement that is $\alpha$-gentle for small $\alpha$ is also $O( \alpha)$-DP, and any product measurement that is $\varepsilon$-DP is also $O(\varepsilon\sqrt{n})$-gentle.

Illustrating the power of this connection, we apply it to the recently studied problem of shadow tomography.  Given an unknown $d$-dimensional quantum state $\rho$, as well as known two-outcome measurements $E_{1},\ldots,E_{m}$, shadow tomography asks us to estimate $\Pr\left[  E_{i}\text{ accepts }\rho\right]  $, for every $i\in\left[ m\right]  $, by measuring few copies of $\rho$. Using our connection theorem, together with a quantum analog of the so-called private multiplicative weights algorithm of Hardt and Rothblum, we give a protocol to solve this problem using $O\left( \left(  \log m\right)  ^{2}\left(  \log d\right)  ^{2}\right)$ copies of $\rho$, compared to Aaronson's previous bound of $\widetilde{O} \left(\left(  \log m\right) ^{4}\left( \log d\right)\right) $.  Our protocol has the advantages of being online (that is, the $E_{i}$'s are processed one at a time), gentle, and conceptually simple.

Other applications of our connection include new lower bounds for shadow tomography from lower bounds on DP, and a result on the safe use of estimation algorithms as subroutines inside larger quantum algorithms.</summary>
    <updated>2019-04-18T12:48:21Z</updated>
    <published>2019-04-18T12:48:21Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-04-23T21:20:28Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-2053726780224405945</id>
    <link href="https://blog.computationalcomplexity.org/feeds/2053726780224405945/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/04/physics-of-everday-life.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/2053726780224405945" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/2053726780224405945" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/04/physics-of-everday-life.html" rel="alternate" type="text/html"/>
    <title>Physics of Everday Life</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Based on <a href="https://www.scottaaronson.com/blog/?p=3654">Scott's review</a>, I read through Stephen Pinker's <a href="https://www.amazon.com/Enlightenment-Now-Science-Humanism-Progress-ebook/dp/B073TJBYTB/ref=as_li_ss_tl?crid=2O1U6VZR84R2Q&amp;keywords=enlightenment+now&amp;qid=1554897483&amp;s=gateway&amp;sprefix=engligh,aps,597&amp;sr=8-1&amp;linkCode=ll1&amp;tag=computation09-20&amp;linkId=8f668f77297b7cd8b57a85dca27802b0&amp;language=en_US">Enlightenment Now</a>. I can't top Scott's exposition of the book, but it is pretty incredible how far humanity has gone when you step back to look at the big picture.<br/>
<br/>
One line intrigued me, one that Pinker credits to a book called <a href="https://www.amazon.com/Big-Picture-Origins-Meaning-Universe/dp/1101984252/ref=as_li_ss_tl?ie=UTF8&amp;linkCode=ll1&amp;tag=computation09-20&amp;linkId=6c644c72e1d0c1f818a5907f9b221ce1&amp;language=en_US">The Big Picture</a> by Sean Carroll<br/>
<blockquote class="tr_bq">
The laws of physics underlying everyday life (that is excluding extreme values of energy and gravitation like black holes, dark matter and the Big Bang) are <i>completely known.</i></blockquote>
Hasn't this statement almost always been true, in the sense that the leading minds would make this claim at many times in history. The ancient Greeks probably believed they understood physics that underlies everyday life. So did physicists after Newton. Life back then not today. My everyday life involves using a GPS device that requires understanding relativistic effects and computer chips that needed other scientific advances.<br/>
<br/>
Is it possible we could do more in everyday life if we knew more physics? I'd certainly use a teleporter in everyday life.<br/>
<br/>
And is the statement even true today? We all use public key cryptography, even to read this blog. It's not completely clear if we understand the physics enough to know how or if large-scale quantum computers capable of breaking those systems can be built.<br/>
<br/>
Everday life is relative.</div>
    </content>
    <updated>2019-04-18T11:40:00Z</updated>
    <published>2019-04-18T11:40:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-04-23T14:16:00Z</updated>
    </source>
  </entry>
</feed>
