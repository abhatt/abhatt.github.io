<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2021-06-20T12:22:50Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.09689</id>
    <link href="http://arxiv.org/abs/2106.09689" rel="alternate" type="text/html"/>
    <title>Statistical Query Lower Bounds for List-Decodable Linear Regression</title>
    <feedworld_mtime>1624060800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Diakonikolas:Ilias.html">Ilias Diakonikolas</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kane:Daniel_M=.html">Daniel M. Kane</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pensia:Ankit.html">Ankit Pensia</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pittas:Thanasis.html">Thanasis Pittas</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Stewart:Alistair.html">Alistair Stewart</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.09689">PDF</a><br/><b>Abstract: </b>We study the problem of list-decodable linear regression, where an adversary
can corrupt a majority of the examples. Specifically, we are given a set $T$ of
labeled examples $(x, y) \in \mathbb{R}^d \times \mathbb{R}$ and a parameter
$0&lt; \alpha &lt;1/2$ such that an $\alpha$-fraction of the points in $T$ are i.i.d.
samples from a linear regression model with Gaussian covariates, and the
remaining $(1-\alpha)$-fraction of the points are drawn from an arbitrary noise
distribution. The goal is to output a small list of hypothesis vectors such
that at least one of them is close to the target regression vector. Our main
result is a Statistical Query (SQ) lower bound of $d^{\mathrm{poly}(1/\alpha)}$
for this problem. Our SQ lower bound qualitatively matches the performance of
previously developed algorithms, providing evidence that current upper bounds
for this task are nearly best possible.
</p></div>
    </summary>
    <updated>2021-06-19T22:40:12Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-06-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.09663</id>
    <link href="http://arxiv.org/abs/2106.09663" rel="alternate" type="text/html"/>
    <title>A Short Note of PAGE: Optimal Convergence Rates for Nonconvex Optimization</title>
    <feedworld_mtime>1624060800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Zhize.html">Zhize Li</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.09663">PDF</a><br/><b>Abstract: </b>In this note, we first recall the nonconvex problem setting and introduce the
optimal PAGE algorithm (Li et al., ICML'21). Then we provide a simple and clean
convergence analysis of PAGE for achieving optimal convergence rates. Moreover,
PAGE and its analysis can be easily adopted and generalized to other works. We
hope that this note provides the insights and is helpful for future works.
</p></div>
    </summary>
    <updated>2021-06-19T22:43:26Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-06-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.09481</id>
    <link href="http://arxiv.org/abs/2106.09481" rel="alternate" type="text/html"/>
    <title>Stochastic Bias-Reduced Gradient Methods</title>
    <feedworld_mtime>1624060800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Asi:Hilal.html">Hilal Asi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Carmon:Yair.html">Yair Carmon</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jambulapati:Arun.html">Arun Jambulapati</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jin:Yujia.html">Yujia Jin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sidford:Aaron.html">Aaron Sidford</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.09481">PDF</a><br/><b>Abstract: </b>We develop a new primitive for stochastic optimization: a low-bias, low-cost
estimator of the minimizer $x_\star$ of any Lipschitz strongly-convex function.
In particular, we use a multilevel Monte-Carlo approach due to Blanchet and
Glynn to turn any optimal stochastic gradient method into an estimator of
$x_\star$ with bias $\delta$, variance $O(\log(1/\delta))$, and an expected
sampling cost of $O(\log(1/\delta))$ stochastic gradient evaluations. As an
immediate consequence, we obtain cheap and nearly unbiased gradient estimators
for the Moreau-Yoshida envelope of any Lipschitz convex function, allowing us
to perform dimension-free randomized smoothing.
</p>
<p>We demonstrate the potential of our estimator through four applications.
First, we develop a method for minimizing the maximum of $N$ functions,
improving on recent results and matching a lower bound up logarithmic factors.
Second and third, we recover state-of-the-art rates for projection-efficient
and gradient-efficient optimization using simple algorithms with a transparent
analysis. Finally, we show that an improved version of our estimator would
yield a nearly linear-time, optimal-utility, differentially-private non-smooth
stochastic optimization method.
</p></div>
    </summary>
    <updated>2021-06-19T22:37:58Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-06-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.09374</id>
    <link href="http://arxiv.org/abs/2106.09374" rel="alternate" type="text/html"/>
    <title>Quantum algorithm for Dyck Language with Multiple Types of Brackets</title>
    <feedworld_mtime>1624060800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Khadiev:Kamil.html">Kamil Khadiev</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kravchenko:Dmitry.html">Dmitry Kravchenko</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.09374">PDF</a><br/><b>Abstract: </b>We consider the recognition problem of the Dyck Language generalized for
multiple types of brackets. We provide an algorithm with quantum query
complexity $O(\sqrt{n}(\log n)^{0.5k})$, where $n$ is the length of input and
$k$ is the maximal nesting depth of brackets. Additionally, we show the lower
bound for this problem which is $O(\sqrt{n}c^{k})$ for some constant $c$.
</p>
<p>Interestingly, classical algorithms solving the Dyck Language for multiple
types of brackets substantially differ form the algorithm solving the original
Dyck language. At the same time, quantum algorithms for solving both kinds of
the Dyck language are of similar nature and requirements.
</p></div>
    </summary>
    <updated>2021-06-19T22:37:36Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2021-06-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.09363</id>
    <link href="http://arxiv.org/abs/2106.09363" rel="alternate" type="text/html"/>
    <title>Similarity of particle systems using an invariant root mean square deviation measure</title>
    <feedworld_mtime>1624060800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bulin:Johannes.html">Johannes Bulin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hamaekers:Jan.html">Jan Hamaekers</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.09363">PDF</a><br/><b>Abstract: </b>Determining whether two particle systems are similar is a common problem in
particle simulations. When the comparison should be invariant under
permutations, orthogonal transformations, and translations of the systems,
special techniques are needed. We present an algorithm that can test particle
systems of finite size for similarity and, if they are similar, can find the
optimal alignment between them. Our approach is based on an invariant version
of the root mean square deviation (RMSD) measure and is capable of finding the
globally optimal solution in $O(n^3)$ operations where $n$ is the number of
three-dimensional particles.
</p></div>
    </summary>
    <updated>2021-06-19T22:39:14Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-06-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.09350</id>
    <link href="http://arxiv.org/abs/2106.09350" rel="alternate" type="text/html"/>
    <title>Identifiability of AMP chain graph models</title>
    <feedworld_mtime>1624060800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Yuhao.html">Yuhao Wang</a>, Arnab Bhattacharyya <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.09350">PDF</a><br/><b>Abstract: </b>We study identifiability of Andersson-Madigan-Perlman (AMP) chain graph
models, which are a common generalization of linear structural equation models
and Gaussian graphical models. AMP models are described by DAGs on chain
components which themselves are undirected graphs.
</p>
<p>For a known chain component decomposition, we show that the DAG on the chain
components is identifiable if the determinants of the residual covariance
matrices of the chain components are monotone non-decreasing in topological
order. This condition extends the equal variance identifiability criterion for
Bayes nets, and it can be generalized from determinants to any super-additive
function on positive semidefinite matrices. When the component decomposition is
unknown, we describe conditions that allow recovery of the full structure using
a polynomial time algorithm based on submodular function minimization. We also
conduct experiments comparing our algorithm's performance against existing
baselines.
</p></div>
    </summary>
    <updated>2021-06-19T22:43:33Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-06-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.09207</id>
    <link href="http://arxiv.org/abs/2106.09207" rel="alternate" type="text/html"/>
    <title>On the Power of Preconditioning in Sparse Linear Regression</title>
    <feedworld_mtime>1624060800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Jonathan Kelner, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Koehler:Frederic.html">Frederic Koehler</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Meka:Raghu.html">Raghu Meka</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rohatgi:Dhruv.html">Dhruv Rohatgi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.09207">PDF</a><br/><b>Abstract: </b>Sparse linear regression is a fundamental problem in high-dimensional
statistics, but strikingly little is known about how to efficiently solve it
without restrictive conditions on the design matrix. We consider the
(correlated) random design setting, where the covariates are independently
drawn from a multivariate Gaussian $N(0,\Sigma)$ with $\Sigma : n \times n$,
and seek estimators $\hat{w}$ minimizing $(\hat{w}-w^*)^T\Sigma(\hat{w}-w^*)$,
where $w^*$ is the $k$-sparse ground truth. Information theoretically, one can
achieve strong error bounds with $O(k \log n)$ samples for arbitrary $\Sigma$
and $w^*$; however, no efficient algorithms are known to match these guarantees
even with $o(n)$ samples, without further assumptions on $\Sigma$ or $w^*$. As
far as hardness, computational lower bounds are only known with worst-case
design matrices. Random-design instances are known which are hard for the
Lasso, but these instances can generally be solved by Lasso after a simple
change-of-basis (i.e. preconditioning).
</p>
<p>In this work, we give upper and lower bounds clarifying the power of
preconditioning in sparse linear regression. First, we show that the
preconditioned Lasso can solve a large class of sparse linear regression
problems nearly optimally: it succeeds whenever the dependency structure of the
covariates, in the sense of the Markov property, has low treewidth -- even if
$\Sigma$ is highly ill-conditioned. Second, we construct (for the first time)
random-design instances which are provably hard for an optimally preconditioned
Lasso. In fact, we complete our treewidth classification by proving that for
any treewidth-$t$ graph, there exists a Gaussian Markov Random Field on this
graph such that the preconditioned Lasso, with any choice of preconditioner,
requires $\Omega(t^{1/20})$ samples to recover $O(\log n)$-sparse signals when
covariates are drawn from this model.
</p></div>
    </summary>
    <updated>2021-06-19T22:39:26Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-06-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-27705661.post-1664874822018320731</id>
    <link href="http://processalgebra.blogspot.com/feeds/1664874822018320731/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=27705661&amp;postID=1664874822018320731" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/1664874822018320731" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/1664874822018320731" rel="self" type="application/atom+xml"/>
    <link href="http://processalgebra.blogspot.com/2021/06/interview-with-concur-2021-tot-award.html" rel="alternate" type="text/html"/>
    <title>Interview with CONCUR 2021 ToT Award recipients, Part 1: Rajeev Alur, Thomas Henzinger, Orna Kupferman and Moshe Vardi</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Last year, the CONCUR conference series inaugurated its Test-of-Time Award, whose purpose is to recognise important achievements in  Concurrency Theory that were published at the CONCUR conference and have  stood the test of time.  This year, the following <a href="https://qonfest2021.lacl.fr/test-of-time.php" target="_blank">four papers</a> were chosen to receive the CONCUR Test-of-Time  Awards for the periods 1994–1997 and 1996–1999 by a jury consisting of Rob van Glabbeek (chair), Luca de Alfaro, Nathalie  Bertrand, Catuscia Palamidessi, and Nobuko Yoshida: </p><ul style="text-align: left;"><li>  David Janin and Igor Walukiewicz. <a href="http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=F31F028FFA1E754B87E7378032EAD6E7?doi=10.1.1.35.9156&amp;rep=rep1&amp;type=pdf" target="_blank">On the Expressive Completeness of the Propositional mu-Calculus with respect to Monadic Second Order Logic</a>. </li><li>Uwe Nestmann and Benjamin C. Pierce. <a href="http://www.cis.upenn.edu/~bcpierce/papers/choice.ps" target="_blank">Decoding Choice Encodings</a>.</li><li>Ahmed Bouajjani, Javier Esparza, and the late Oded Maler. <a href="http://www-verimag.imag.fr/~maler/Papers/pda.pdf" target="_blank">Reachability Analysis of Pushdown Automata: Application to Model-checking</a>.</li><li>Rajeev Alur, Thomas A. Henzinger, Orna Kupferman, and Moshe Y. Vardi. <a href="https://doi.org/10.1007/BFb0055622" target="_blank">Alternating Refinement Relations</a>. <br/></li></ul><p>Last year, I interviewed the <a href="http://concur2020.forsyte.at/test-of-time.html" target="_blank">CONCUR 2020 Test-of-Time Award recipients</a> and was asked by Javier Esparza (chair of the CONCUR SC) and Ilaria Castellani (outgoing chair of the IFIP WG 1.8 on Concurrency Theory) to do the same with the current batch of awardees. (In passing, let me thank <a href="http://people.rennes.inria.fr/Nathalie.Bertrand/" target="_blank">Nathalie Bertrand</a> and <a href="https://www.imperial.ac.uk/people/n.yoshida" target="_blank">Nobuko Yoshida</a> for their kind help with the interviews!)<br/></p><p>This post is devoted to the interview I conducted via email with <a href="https://www.cis.upenn.edu/~alur/" target="_blank">Rajeev Alur</a>, <a href="http://pub.ist.ac.at/~tah/" target="_blank">Thomas A. Henzinger</a>, <a href="https://www.cs.huji.ac.il/~ornak/" target="_blank">Orna Kupferman</a> and <a href="https://www.cs.rice.edu/~vardi/" target="_blank">Moshe Y. Vardi</a>. Reading the answers I received from that dream team of colleagues was like a masterclass for me and I trust that their thoughts on their award-winning paper will be of interest to many of the readers of this blog. Enjoy!<br/></p><p><b>Luca:</b> You receive the CONCUR ToT Award 2021 for your paper <a href="https://doi.org/10.1007/BFb0055622" target="_blank">Alternating Refinement Relations</a>, which appeared at CONCUR 1998. In that article, you gave what I consider to be a fundamental contribution, namely the introduction of refinement relations for alternating transition systems. Could you briefly explain to our readers what alternating transition systems are? Could you also tell us how you came to study the question addressed in your award-winning article and why you focused on simulation- and trace-based refinement relations? Which of the results in your paper did you find most surprising or challenging? </p><p><b>Answer:</b> When we model a system by a graph, our model abstracts away some details of the system. In particular, even when systems are deterministic, states in the model may have several successors. The nondeterminism introduced in the model often corresponds to different actions taken by the system when it responds to different inputs from its environment. Indeed, a transition in a graph that models a composite system corresponds to a step of the system that may involve some components. Alternating transition systems (ATSs) enable us to model composite systems in more detail. In an ATS, each transition corresponds to a possible move in a game between the components, which are called agents. In each move of the game, all agents choose actions, and the successor state is deterministically determined by all actions. Consequently, ATSs can distinguish between collaborative and adversarial relationships among components in a composite system. For example, the environment is typically viewed adversarially, meaning that a component may be required to meet its specification no matter how the environment behaves. </p><p>In an earlier <a href="https://www.cis.upenn.edu/~alur/Jacm02.pdf" target="_blank">paper</a>, some of us introduced ATSs and Alternating Temporal Logics, which can specify properties of agents in a composite system. The CONCUR 1998 paper provided refinement relations between ATSs which correspond to alternating temporal logics. Refinement is a central issue in a formal approach to the design and analysis of reactive systems. The relation “I refines S '' intuitively means that system S has more behaviors than system I. It is useful to think about S being a specification and I an implementation. Now, if we consider a composite implementation I||E and specification S||E and we want to check that the component I refines the component S, then the traditional refinement preorders are inappropriate, as they allow I to achieve refinement of I||E with respect to S||E by constraining its environment E.  Alternating refinement relations are defined with respect to ATSs that model the interaction among the underlying components, and they enable us to check, for example, that component I has fewer behaviors than component S no matter how component E behaves. They are called “alternating” because refinement may restrict implementation actions but must not restrict environment actions. In other words, refinement may admit fewer system actions but, at the same time, more environment actions. </p><p>It was nice to see how theoretical properties of preorders in the traditional setting are carried over to the game setting, and so are the results known then about the computational price of moving to a game setting. First, the efficiency of the local preorder of simulation with respect to the global preorder of trace containment is maintained. As in the traditional setting, alternating simulation can be checked in polynomial time, whereas alternating trace-containment is much more complex. Second, the branching vs. linear characterizations of the two preorders is preserved: alternating simulation implies alternating trace containment, and the logical characterization of simulation and trace-containment by CTL and LTL, respectively, is carried over to their alternating temporal logics counterparts. The doubly-exponential complexity of alternating trace containment, as opposed to the PSPACE complexity of trace containment, is nicely related to the doubly-exponential complexity of LTL synthesis, as opposed to its PSPACE model-checking complexity,</p><p>   <b>Luca:</b> In your paper, you give logical characterisations of your alternating refinement relations in terms of fragments of alternating temporal logic. Logical characterisations of refinement relations are classic results in our field and I find them very satisfying. Since I teach a number of those results in my courses, I'd be interested in hearing how you would motivate their interest and usefulness to a student or a colleague. What would your "sales pitch" be? </p><p><b>Answer:</b> There is extensive research on the expressive power of different formalisms. Logical characterization of refinement relations tells us something about the distinguishing power of formalisms. For example, while the temporal logic CTL* is more expressive than the temporal logic CTL, the two logics have the same distinguishing power: if you have two systems and can distinguish between them with a CTL* formula (that is, your formula is satisfied only in one of the systems), then you should be able to distinguish between the two systems also with a CTL formula. Moreover, while CTL is not more expressive than LTL, we know that CTL is “more distinguishing” than LTL. These results have to do with the logical characterizations of trace containment and simulation. The distinguishing power of a specification formalism is useful when we compare systems, in particular an implementation and its abstraction: if we know that the properties we care about are specified in some formalism L, and our system refines the abstraction according to a refinement relation in which the satisfaction of specifications in L is preserved, then we can perform verification on the abstraction.</p><p> <b>Luca:</b> I am interested in how research collaborations start, as I like to tell "research-life stories" to PhD students and young researchers of all ages. Could you tell us how you started your collaboration on the award-winning paper? </p><p><b>Answer:</b>Subsets of us were already collaborating on other topics related to reactive models and model checking, and all of us shared a common belief that the field was in need to move from the limited setting of closed systems to a more general setting of open systems, that is, systems that interact with an environment. Open systems occur not only when the environment is fully or partly unknown, but also when a closed system is decomposed into multiple components, each of them representing an open system. To build “openness” into models and specifications as first-class citizens quickly leads to the game-theoretic (or “alternating”) setting. It was this realization and the joint wish to provide a principled and systematic foundation for the modeling and verification of open systems which naturally led to this collaboration.</p><p> <b>Luca:</b> Did any of your subsequent research build explicitly on the results and the techniques you developed in your award-winning paper? Which of your subsequent results on alternating transition systems and their refinement relations do you like best? Is there any result obtained by other researchers that builds on your work and that you like in particular or found surprising? </p><p><b>Answer: </b>Various subsets of us pursued multiple research directions that developed the game-theoretic setting for modeling and verification further, and much remains to be done. Here are two examples. First, the game-theoretic setting and the alternating nature of inputs and outputs are now generally accepted as providing the proper semantic foundation for interface and contract formalisms for component-based design. Second, studying strategic behavior in multi-player games quickly leads to the importance of probabilistic behavior, say in the form of randomized decisions and strategies, of equilibria, when players have non-complementary objectives, and of auctions, when players need to spend resources for decisions. All of these are still very active topics of research in computer-aided verification, and they also form a bridge to the algorithmic game theory community.    </p><p><b>Luca:</b> One can view your work as a bridge between concurrency theory and multi-agent systems. What impact do you think that your work has had on the multi-agent-system community? And what has our community learnt from the work done in the field of multi-agent systems? To your mind, what are the main differences and points of contact in the work done within those communities? </p><p><b>Answer:</b> Modeling interaction in multi-agent systems is of natural interest to planning problems studied in the AI community. In 2002, the <a href="http://www.ifaamas.org/index.html" target="_blank">International Foundation for Autonomous Agents and Multiagent Systems</a> (IFAAMAS) was formed and the annual <a href="https://aamas2021.soton.ac.uk/" target="_blank">International Conference on Autonomous Agents and Multiagent Systems</a> (AAMAS) was launched. The models, logics, and algorithms developed in the concurrency and formal methods communities have had a strong influence on research presented at AAMAS conferences over the past twenty years. Coincidentally, this year our <a href="https://www.cis.upenn.edu/~alur/Jacm02.pdf" target="_blank">paper on Alternating-Time Temporal Logic</a> was chosen for the <a href="http://www.ifaamas.org/award-influential.html#:~:text=IFAAMAS%3A%20Awards%3A%20Influential%20Paper&amp;text=The%20Influential%20Paper%20Award%20seeks,lasting%20contributions%20to%20the%20field." target="_blank">IFAAMAS Influential Paper Award</a>. </p> <b>Luca:</b> What are the research topics that you find most interesting right now? Is there any specific problem in your current field of interest that you'd like to see solved? <p><b>Answer:</b>Research on formal verification and synthesis, including our paper, assumes that the model of the system is known. Reinforcement learning has emerged as a promising approach to the design of policies in scenarios where the model is not known and has to be learned by agents by exploration. This leads to an opportunity for research at the intersection of reactive synthesis and reinforcement learning. A potentially promising direction is to consider reinforcement learning for systems with multiple agents with both cooperative and adversarial interactions. </p><p>The realization that reactive systems have to satisfy their specifications in all environments has led to extensive research relating formal methods with game theory. Our paper added alternation to refinement relations. The transition from one to multiple players has been studied in computer science in several other contexts. For the basic problem of reachability in graphs, it amounts to moving from reachability to alternating reachability. We recently studied this shift in other fundamental graph problems, like the generation of weighted spanning trees, flows in networks, vertex covers, and more. In all these extensions, we consider a game between two players that take turns in jointly generating the outcome. One player aims at maximizing the value of the outcome (e.g., maximize the weight of the spanning tree, the amount of flow that travels in the network, or the size of the vertex cover), whereas the second aims at minimizing the value. It is interesting to see how some fundamental properties of graph algorithms are lost in the alternating setting. For example, following a greedy strategy is not beneficial in alternating spanning trees, optimal strategies in alternating flow networks may use fractional flows, and while the vertex-cover problem is NP-complete, an optimal strategy for the maximizer player can be found in polynomial time. Many more questions in this setting are still open. </p><p><b>Luca:</b> What advice would you give to a young researcher who is keen to start working on topics related to alternating transition systems and logics? </p><b>Answer:</b> One important piece of advice to young researchers is to question the orthodoxy. Sometimes it is necessary to learn everything that is known about a topic but then take a step back, look at the bigger picture, reexamine some of the fundamental assumptions behind the established ways of thinking, change the models that everyone has been using, and go beyond the incremental improvement of previous results. This is particularly true in formal methods, where no single model or approach fits everything. And young researchers stand a much better chance of having a really fresh new thought than those who have been at it for many years.</div>
    </content>
    <updated>2021-06-18T16:37:00Z</updated>
    <published>2021-06-18T16:37:00Z</published>
    <author>
      <name>Luca Aceto</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/01092671728833265127</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-27705661</id>
      <author>
        <name>Luca Aceto</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/01092671728833265127</uri>
      </author>
      <link href="http://processalgebra.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://processalgebra.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Papers I find interesting---mostly, but not solely, in Process Algebra---, and some fun stuff in Mathematics and Computer Science at large and on general issues related to research, teaching and academic life.</subtitle>
      <title>Process Algebra Diary</title>
      <updated>2021-06-20T11:17:16Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://francisbach.com/?p=5861</id>
    <link href="https://francisbach.com/quest-for-adaptivity/" rel="alternate" type="text/html"/>
    <title>The quest for adaptivity</title>
    <summary>Most machine learning classes and textbooks mention that there is no universal supervised learning algorithm that can do reasonably well on all learning problems. Indeed, a series of “no free lunch theorems” state that even in a simple input space, for any learning algorithm, there always exists a bad conditional distribution of outputs given inputs...</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p class="justify-text">Most machine learning classes and textbooks mention that there is no universal supervised learning algorithm that can do reasonably well on all learning problems. Indeed, a series of “no free lunch theorems” state that even in a simple input space, for any learning algorithm, there always exists a bad conditional distribution of outputs given inputs where this algorithm performs arbitrarily bad. </p>



<p class="justify-text">For example, from the classic book of Luc Devroye, László Györfi, and Gábor Lugosi [<a href="https://www.szit.bme.hu/~gyorfi/pbook.pdf">1</a>, Theorem 7.2 and its extensions], for inputs uniformly distributed in \([0,1]\), for any decreasing sequence \((\varepsilon_n)_{n \geqslant 0}\) which is less than 1/16, for any learning algorithm (which takes pairs of observations and outputs a prediction function), there exists a conditional distribution on \(\{-1,1\}\) for which the expected risk of the classifier learned from \(n\) independent and identically distributed observations of (input,output) pairs is greater than \(\varepsilon_n\) for all \(n \geqslant 1\), while the best possible expected error rate is zero.</p>



<p class="justify-text">Such theorems do not imply that all learning methods are equally bad, but rather that all learning methods will suffer from some weaknessess. Throughout this blog we will try to better understand the weaknessess and strengths of popular methods through learning theory.</p>



<p class="justify-text">The key is to control the potential weaknesses of a learning method by making sure that in “favorable” scenarios, it leads to strong guarantees. When taking the simplest example of vectorial inputs in \(\mathbb{R}^d\), we can construct model classes of increasing complexity for which we can start to draw useful comparisons between learning methods.</p>



<p class="justify-text">Several aspects of the joint distribution of (input,output) \((X,Y)\) make the problem easy or hard. For concreteness and simplicity, I will focus on regression problems where the output space is \(\mathcal{Y} = \mathbb{R}\) and with the square loss, so that the optimal function, the “target” function, is \(f^\ast(x) = \mathbb{E}(Y|X=x)\). But much of the discussion extends to classification or even more complex outputs (see, e.g., [1]).</p>



<p class="justify-text"><strong>Curse of dimensionality.</strong> In the context of vectorial inputs, the slowness of universal learning algorithms can be characterized more precisely, and leads to the classical <a href="https://en.wikipedia.org/wiki/Curse_of_dimensionality">curse of dimensionality</a>. Only assuming that the optimal target function is Lipschitz-continuous, that is, for all \(x,x’\), \(| f^\ast(x)-f^\ast(x’)| \leqslant  L \| x – x’\|\) (for any arbitrary norm on \(\mathbb{R}^d\)), the optimal excess risk of a prediction function \(\hat{f}\) obtained from \(n\) observations, that is, the expected squared difference between \(f^\ast(x)\) and \(\hat{f}(x)\) cannot be less than a constant times \(n^{-2/(d+2)}\), that is, in order for this rate to be smaller than some \(\varepsilon &lt;1 \), we need \(n\) to be larger than \(\displaystyle ( {1}/{\varepsilon} )^{d/2+1}\), with thus an exponential dependence in \(d\) (see [<a href="https://web.stanford.edu/class/ee378a/books/book1.pdf">2</a>]).</p>



<p class="justify-text">In other words, exponentially many observations are needed for a reasonable performance on all problems with a minimal set of assumptions (here Lipschitz-continuity), and this bad behavior is unavoidable unless extra assumptions are added, which we now describe.</p>



<h2>Support, smoothness and latent variables</h2>



<p class="justify-text"><strong>Low-dimensional support. </strong>If the data occupy only a \(r\)-dimensional subspace of \(\mathbb{R}^d\), with \(r \leqslant d\) (and typically much smaller), then one should expect a better convergence rate. This also extends to data supported on a (smooth) <a href="https://en.wikipedia.org/wiki/Manifold">manifold</a>, as illustrated below. Note that this assumption does not concern the outputs, and can reasonably be checked given the data by performing principal component analysis or some form of <a href="https://en.wikipedia.org/wiki/Nonlinear_dimensionality_reduction">manifold learning</a>. Essentially, in terms of convergence rates, \(d\) is replaced by \(r\). This is obvious if the learning algorithm has access to the \(r\)-dimensional representation, and it requires more work if not.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-5959" height="225" src="https://francisbach.com/wp-content/uploads/2021/06/support.png" width="508"/>Left: samples from the uniform distribution in the unit disk in \(\mathbb{R}^2\). Right: samples from the uniform distribution in the unit circle in \(\mathbb{R}^2\), which is a one-dimensional smooth manifold.</figure></div>



<p class="justify-text"><strong>Smoothness of the target function. </strong>This is done by assuming some bounded derivatives for the target function \(f^\ast\). With bounded \(s\)-th order derivatives, we could expect that the problem is easier (note that Lipschitz-continuity corresponds to \(s=1\)). This is illustrated below with one-dimensional inputs. Essentially, in terms of rates, \(d\) is replaced by \(d/s\) [<a href="https://web.stanford.edu/class/ee378a/books/book1.pdf">2</a>, Theorem 3.2]. Therefore, when the smoothness order \(s\) is of order \(d\), the dependence in the dimension disappears.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-5961" height="225" src="https://francisbach.com/wp-content/uploads/2021/06/smooth-1024x445.png" width="517"/>Regression problem with one-dimensional inputs, with target function in red, and observations in blue. Left: non-smooth (even not Lipschitz-continuous) function, right: smooth function.</figure></div>



<p class="justify-text"><strong>Latent variables.</strong> If we assume that the target function depends only on a \(r\)-dimensional linear projection of the input, then we should expect a better complexity. The most classical example is the dependence on a subset of the \(d\) original variables. Essentially, in terms of rates, \(d\) is replaced by \(r\). This is obvious when the latent variables are known (as we can replace input data by the \(r\) latent variables), totally not otherwise, as this requires some form of <em>adaptivity</em> (see below).</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-5964" height="252" src="https://francisbach.com/wp-content/uploads/2021/06/latent-1024x467.png" width="553"/>Regression problem with two-dimensional inputs, with target function (with no noise). Left:  function that cannot be written with a latent variable, right: function that has a (linear) latent variable representation (there exists a direction with no variation).</figure></div>



<p class="justify-text"><strong>Need for adaptivity.</strong> We typically don’t know in advance if these properties are satisfied or not, as some are easily testable (support of distribution) without knowing the target function \(f^\ast\), while others are not.</p>



<p class="justify-text">The goal is to have a single method that can adapt to all of these situations (which are non-exclusive). That is, if the problem has any of these reasons to be easy, will the learning method benefit from it? Typically, most learning methods have at least one hyperparameter controlling overfitting (e.g., a regularization parameter), and the precise value of this hyperparameter will depend on the difficulty of the problem, and we will assume that we have a reasonable way to estimate this hyperparameter (e.g., cross-validation). A method is then said adaptive if with a well chosen value of the hyperparameter, we get the optimal (or close to optimal) rate of estimation that benefits from the extra assumption.</p>



<p class="justify-text"><strong>Quest for adaptivity: who wins?</strong> Among classical learning techniques, which ones are adaptive to which properties? In short, <em>barring computational and optimization issues</em>: $$\mbox{ local averaging } &lt; \mbox{ positive definite kernels } &lt; \mbox{ neural networks }.$$ Every time, the next method in the list gains adaptivity to support, smoothness and then latent variables. <span class="has-inline-color has-vivid-red-color">Note however that optimization for neural networks is more delicate (see below).</span></p>



<p class="justify-text">Let’s now briefly look at these methods one by one. I will assume basic knowledge of these, for more details see [<a href="https://www.dropbox.com/s/7voitv0vt24c88s/10290.pdf?dl=1">4</a>, <a href="https://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/understanding-machine-learning-theory-algorithms.pdf">5</a>] or my <a href="https://francisbach.com/i-am-writing-a-book/">new book in preparation</a>.</p>



<h2>Local averaging</h2>



<p class="justify-text">The earliest and simplest learning methods that could adapt to any target functions were <em>local averaging</em> methods aiming at approximating directly the conditional expectation \(f^\ast(x) = \mathbb{E}(Y|X=x)\), with the most classical examples being <a href="https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm"><em>k</em>-nearest neighbors</a> and <a href="https://en.wikipedia.org/wiki/Kernel_regression">Nadaraya-Watson</a> estimators.</p>



<p class="justify-text">These methods are naturally adaptive to having a reduced support for inputs. Indeed, in the simplest case of a distribution supported in a low-dimensional subspace, the global metric is equivalent to a local metric on the support, without any need to explicitly know the subspace, a situation which extends to smooth manifolds. In order to be adaptive, the hyperparameter has to depend on the dimension \(r\) of the manifold, e.g., for \(k\)-nearest-neighbors, \(k\) has to be taken proportional to \(n^{2/(2+r)}\) (see [<a href="http://www.columbia.edu/~skk2175/Papers/kNNRegressionLocRatesFullVersion.pdf">3</a>]).</p>



<p class="justify-text">However, there is no adaptivity to the smoothness of the target function or to potential latent variables unless dedicated algorithms are used such as <a href="https://en.wikipedia.org/wiki/Local_regression">local regression</a>. Kernel methods and neural networks lead to such adaptivity.</p>



<h2>From kernels to neural networks</h2>



<p class="justify-text">We consider prediction functions of the form $$f(x) = \sum_{j=1}^m a_j ( b_j^\top x )_+,$$ which is the traditional single hidden layer fully connected neural network with ReLU activation functions (a constant term can be added to the linear term within the ReLU by simply appending \(1\) to \(x\), please do not call these terms “biases” as this has <a href="https://en.wikipedia.org/wiki/Bias_(statistics)">another meaning in statistics</a>).</p>



<p class="justify-text">The vector \(a \in \mathbb{R}^m\) represents <em>output weights</em>, while the matrix \(b \in \mathbb{R}^{m \times d}\) represents <em>input weights</em>.</p>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-5975" height="300" src="https://francisbach.com/wp-content/uploads/2021/06/nn_blog-1024x546.png" width="564"/></figure></div>



<p class="justify-text"><strong>Empirical risk minimization (ERM). </strong>We assume given \(n\) i.i.d. observations \((x_1,y_1),\dots,(x_n,y_n) \in \mathbb{R}^d \times \mathbb{R}\), and we will fit models by minimizing the \(\ell_2\)-regularized empirical risk (you can call it “weight decay” but it  already has a better name in machine learning and statistics). That is, we minimize $$R(a,b) = \frac{1}{2n} \sum_{i=1}^n \Big( y_i \, – \sum_{j=1}^m a_j ( b_j^\top x_i )_+ \Big) ^2 + \frac{\lambda}{2} \sum_{j=1}^m \Big\{ a_j^2 + \| b_j\|_2^2 \Big\},$$ where \(\lambda &gt; 0\) is a regularization parameter.</p>



<p class="justify-text"><strong>Overparametrization. </strong>We will consider the limit of large number \(m\) of hidden neurons. Depending whether we optimize over both input weights \(b\) and output weights \(a\), or simply output weights (with then a proper initialization of the input weights), we get different behaviors.</p>



<h2>Kernel regime</h2>



<p class="justify-text">We assume that the input weights \(b_j \in \mathbb{R}^d\) are sampled uniformly from the Euclidean sphere of radius \(1 / \sqrt{m}\), and that we only optimize over the output weights \(a_j, j = 1,\dots,m\). This is exactly a <a href="https://en.wikipedia.org/wiki/Ridge_regression">ridge regression</a> problem (square loss and squared Euclidean penalty), for which the theory of positive definite kernels applies and will lead to an interesting behavior for infinite \(m\) [7, <a href="https://papers.nips.cc/paper/2007/file/013a006f03dbc5392effeb8f18fda755-Paper.pdf">8</a>]. That is, the solution can be obtained by using the kernel function \(\hat{k}\) defined as $$\hat{k}(x,x’) = \sum_{j=1}^m ( b_j^\top x )_+( b_j^\top x’ )_+,$$ and looking for prediction functions of the form $$f(x) = \sum_{i=1}^n \alpha_i \hat{k}(x,x_i).$$ See, e.g., [6] for details. In particular, as long as \(\hat{k}(x,x’)\) can be computed efficiently, the complexity of solving the ERM problem is independent of the number of neurons \(m\). We will now discuss in further detail the over-parameterized case where \(m=\infty\).</p>



<p class="justify-text">When \(m\) tends to infinity, If the input weights are fixed and initialized randomly from the \(\ell_2\)-sphere of radius \(1/\sqrt{m}\), then by the law of large numbers, \(\hat{k}(x,x’)\) tends to $$k(x,x’) = \mathbb{E}_{b \sim {\rm uniform} (\mathbb{S}^{d-1}) } (b^\top x )_+ (b^\top x’)_+,$$ where \(\mathbb{S}^{d-1}\) is the unit \(\ell_2\)-sphere in \(d\) dimensions. This kernel has a closed form and happens to be equal to (see [<a href="https://papers.nips.cc/paper/2009/file/5751ec3e9a4feab575962e78e006250d-Paper.pdf">9</a>]) $$ \frac{1}{2\pi d}  \|x\|_2   \| x’\|_2 \big[ ( \pi \, – \varphi) \cos \varphi + \sin \varphi \big],$$ where \(\cos \varphi = \frac{ x^\top x’  }{{ \|x\|_2  } { \| x’\|_2   } }\). It can also be seen (see, e.g., [<a href="https://jmlr.org/papers/volume18/14-546/14-546.pdf">10</a>] for details) as using predictors of the form $$f(x) = \int_{\mathbb{S}^{d-1}}  ( b^\top x)_+ d \mu(b),$$ for some measure \(\mu\) on \(\mathbb{S}^{d-1}\), with the penalty $$\frac{\lambda}{2} \int_{\mathbb{S}^{d-1}} \big| \frac{d\mu}{d\tau}(b) \big|^2 d\tau(b),$$ for the uniform probability measure \(d\tau\) on the hypersphere \(\mathbb{S}^{d-1}\). This representation will be useful for the comparison with neural networks.</p>



<p class="justify-text">Note that here we use random features in a different way from their common use [<a href="https://papers.nips.cc/paper/2007/file/013a006f03dbc5392effeb8f18fda755-Paper.pdf">8</a>], where the kernel \(k\) comes first and is approximated by \(\hat{k}\) to obtain fast algorithms, typically with \(m &lt; n\). Here we start from \(\hat{k}\) and find the limiting \(k\) to understand the behavior of overparameterization. The resulting function space is a (<a href="https://en.wikipedia.org/wiki/Sobolev_space">Sobolev</a>) space of functions on the sphere with all \(s\)-th order derivatives which are square-integrable, with \(s = d/2+3/2\) [<a href="https://jmlr.org/papers/volume18/14-546/14-546.pdf">10</a>].</p>



<p>Finally, the number of neurons \(m\) needed to reach the kernel regime is well understood, at least in simple situations [<a href="https://papers.nips.cc/paper/2015/file/03e0704b5690a2dee1861dc3ad3316c9-Paper.pdf">15</a>, <a href="https://proceedings.neurips.cc/paper/2017/file/61b1fb3f59e28c67f3925f3c79be81a1-Paper.pdf">16</a>].</p>



<p class="justify-text">We can now look at the various forms of adaptivity of kernel methods based on Sobolev spaces.</p>



<p class="justify-text"><strong>Adaptivity to reduced support.</strong> Like model averaging techniques, adaptivity to input data supported on a subspace is rather straightforward, and it extends to smooth manifolds (see, e.g., [<a href="https://arxiv.org/pdf/2003.06202.pdf">12</a>] for a proof for the Gaussian kernel).</p>



<p class="justify-text"><strong>Adaptive to smoothness.</strong> A key attractive feature of kernel methods is that they can circumvent the curse of dimensionality for <em>smooth</em> target functions, and, by simply ajusting the regularization parameter \(\lambda\), ridge regression will typically adapt to the smoothness of the target function, and thus benefit from easy problems.</p>



<p class="justify-text">The simplest instance is when the target function is within the space of functions defined above, where we immediately get estimation rates which are independent of dimension (at least in the exponent). This however requires at least \(s&gt;d/2\) derivatives (because Sobolev spaces are <a href="https://en.wikipedia.org/wiki/Reproducing_kernel_Hilbert_space">reproducing kernel Hilbert spaces</a> (RKHS) only in this situation), but the adaptivity extends to functions outside of the RKHS (see, e.g., [11]).</p>



<p class="justify-text"><strong>Adaptivity to linear latent variables.</strong> Unfortunately, kernel methods are not adaptive even to basic linear structures. That is, if \(f^\ast\) depends only on the first component of \(x\), then ridge regression, if not modified, will not take advantage of it. In the context of neural networks, one striking example is that a single neuron \(x \mapsto (b^\top x)_+\) <em>does not belong to the RKHS</em>, and leads to bad estimation rates (see, e.g., [<a href="https://jmlr.org/papers/volume18/14-546/14-546.pdf">10</a>, <a href="http://proceedings.mlr.press/v125/chizat20a/chizat20a.pdf">13</a>]).</p>



<p class="justify-text">Before looking at some experiments, let’s look at some optimization considerations, that will be important later for neural networks.</p>



<p class="justify-text"><strong>Avoiding overparameterized neuron representations.</strong> In the kernel regime, optimizing directly the cost function with \(m\) neurons by gradient descent is problematic for two reasons when \(m\) is large:</p>



<ul class="justify-text"><li>The optimization problem, although convex, is severely ill-conditioned as can be seen from the spectrum of the covariance matrix of the feature vector, with the \(i\)-th eigenvalue equivalent to \(i^{-1-3/d}\) for the uniform input distribution (see [14, Section 2.3]). Therefore, (stochastic) gradient descent will take a lot of time to converge.</li><li>We can use kernels directly (for \(m = +\infty\)) to avoid using \(m\) very large (which would be useless in practice). The running-time complexity is then of the order \(O(n^2)\) if done naively, with lots of ways to go below \(O(n^2)\), such as column sampling (see a nice analysis in [<a href="https://papers.nips.cc/paper/2015/file/03e0704b5690a2dee1861dc3ad3316c9-Paper.pdf">15</a>]).</li></ul>



<p class="justify-text"><strong>Experiments.</strong> We first consider a very simple one-dimensional example, where we look at how the estimation with the kernel function \(k\) varies as a function of the hyperparameter \(\lambda\), from underfitting to overfitting. We can observe that all learned functions are smooth, as expected.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-full is-resized"><img alt="" class="wp-image-6045" height="252" src="https://francisbach.com/wp-content/uploads/2021/06/rff_biplot.gif" width="574"/>Regression problems in one dimension with kernels (left: smooth target, right: non-smooth target), with \(n=32\) observations, with varying regularization parameters, with the optimal one shown below.</figure></div>



<p class="justify-text">We can now compare the convergence rates for the excess risk (expected squared distance beween \(f\) and \(f^\ast\)). We can see that the rates are better for smooth functions, and with the proper choice of regularization parameter, the kernel method adapts to it.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-full is-resized"><img alt="" class="wp-image-6042" height="241" src="https://francisbach.com/wp-content/uploads/2021/06/simulations_adaptivity_rff_subplots.png" width="925"/>Left: estimation with the optimal regularization parameter for smooth target function and kernel methods. Middle: estimation with a non-smooth target function. Right: convergence rates when the number \(n\) of observations increases, averaged over 32 replications.</figure></div>



<h2>Neural networks</h2>



<p class="justify-text">We can now optimize over all weights, output \(a\) <em>and</em> input \(b\). Four natural questions come to mind:</p>



<ol class="justify-text"><li>Where does it converge to when the number \(m\) of hidden neurons tends to infinity?</li><li>What are the adaptivity properties of the resulting predictor?</li><li>How big \(m\) needs to be to achieve the infinite width behavior?</li><li>Can we actually solve the non-convex optimization problem?</li></ol>



<p class="justify-text"><strong>Overparameterization limit (feature learning regime).</strong> When optimizing over both sets of weights, we can first note that the prediction function is invariant by the change of variable $$ a_j \leftarrow \mu_j a_j \ , \ \ b_j \leftarrow \mu_j^{-1} b_j.$$ Then by optimizing over \(\mu_j\) which is only involved in the penalty term \(\frac{\lambda}{2} \big( a_j^2 + \|b_j\|_2^2 \big)\), we get \(\mu_j^\ast = a_j^{-2} \| b_j \|_2^2\), and the penalty \(\lambda |a_j| \| b_j\|_2\). We thus get the equivalent optimization problem of minimizing $$\tilde{R}(a,b) = \frac{1}{2n} \sum_{i=1}^n \Big( y_i \, – \sum_{j=1}^m a_j ( b_j^\top x_i )_+ \Big) ^2 + {\lambda} \sum_{j=1}^m |a_j| \| b_j\|_2 .$$ By restricting the \(b_j\) on the unit sphere (which is OK because by optimizing over \(\mu_j\) we become scale-invariant), we can write $$\sum_{j=1}^m a_j ( b_j^\top x_i )_+ = \int_{\mathbb{S}^{d-1}} (b^\top x)_+ d\mu(b), $$ for $$ \mu = \sum_{j=1}^m a_j \delta_{b_j}$$ a weighted sum of Diracs, and \(\sum_{j=1}^m |a_j| \| b_j\|_2 = \int_{\mathbb{S}^{d-1}} \! | d\mu(b)|\) the <a href="https://en.wikipedia.org/wiki/Total_variation">total variation</a> of \(\mu\). Thus, letting \(m\) go to infinity, the infinite sums become integrals of general measures, and we end up considering the set of functions that can be written as (see [<a href="https://jmlr.org/papers/volume18/14-546/14-546.pdf">10</a>] and the many references therein for details): $$f(x) = \int_{\mathbb{S}^{d-1}}   ( b^\top x)_+ d \mu(b),$$ with the penalty $$\lambda \int_{\mathbb{S}^{d-1}} \! | d\mu(b)|.$$ It has an \(\ell_1\)-norm flavor (as opposed to the \(\ell_2\)-norm for kernels), and leads to further adaptivity, if optimization problems are resolved (which is itself not easy in polynomial time, see below).</p>



<p class="justify-text">The minimal number of neurons to achieve the limiting behavior in terms of predictive performance (assuming optimization problems are resolved) can also be characterized, and grows exponentially in dimension without strong assumptions like the ones made in this blog post (see [<a href="https://jmlr.org/papers/volume18/14-546/14-546.pdf">10</a>]). We will now study the adaptivity properties of using the function space above.</p>



<p class="justify-text"><strong>Adaptive to low-dimensional support and smoothness.</strong> It turns out that the adaptivity properties of kernel methods are preserved, both with respect to the support and the smoothness of the target function (see, e.g., [17, <a href="https://jmlr.org/papers/volume18/14-546/14-546.pdf">10</a>]). However, neural networks can do better!</p>



<p class="justify-text"><strong>Adaptive to linear substructures for one hidden layer.</strong> Given that the training of neural networks involves finding the best possible input weights, which are involved in the first linear layer, it is no surprise that we obtain adaptivity to linear latent variables. That is, if we can write \(f^\ast(x) = g(c_1^\top x, \dots, c_r^\top x)\) for some function \(g: \mathbb{R}^r \to \mathbb{R}\), then the vectors \(c_j\)’s will be essentially estimated among the \(b_j\)’s by the optimization algorithm. Therefore, when using the \(\ell_1\)-based function space, the convergence rate in the excess risk will depend on \(r\) and not \(d\) in the exponent [<a href="https://jmlr.org/papers/volume18/14-546/14-546.pdf">10</a>, <a href="http://proceedings.mlr.press/v125/chizat20a/chizat20a.pdf">13</a>]. In particular, neural networks can perform <em>non-linear</em> variable selection (while the <a href="https://en.wikipedia.org/wiki/Lasso_(statistics)">Lasso</a> only performs <em>linear</em> variable selection). See a nice experiment in [<a href="http://proceedings.mlr.press/v125/chizat20a/chizat20a.pdf">13</a>] for binary classification.</p>



<p class="justify-text">One could imagine that with more hidden layers, this extends to non-linear smooth projections of the data, that is, to cases where we assume that \(f^\ast(x) = g(h(x))\) where \(h: \mathbb{R}^d \to \mathbb{R}^r\) is a smooth function. </p>



<p class="justify-text">Thus, we obtain a stronger adaptivity for infinite \(m\) and the good choice of regularization parameter \(\lambda\). We could then try to reproduce for neural networks the figures obtained for kernel methods with varying \(\lambda\). Unfortunately, this is where non-convex optimization will make everything harder.</p>



<h2>Overfitting with a single hidden layer is hard!</h2>



<p class="justify-text"><strong>Global convergence of gradient flow for infinite width. </strong>The traditional algorithm to minimize the empirical risk is gradient descent and its stochastic extensions. In this blog post, we consider gradient descent with small step-sizes, which can be approximated by a gradient flow (as explained in <a href="https://francisbach.com/gradient-descent-neural-networks-global-convergence/">last June blog post</a>). All parameters are randomly initialized, and we consider \(b_j\) uniformly distributed on the sphere of radius \(1/\sqrt{m}\), and \(a_j\) uniformly distributed in \(\{-1/\sqrt{m},1/\sqrt{m}\}\) (this is essentially equivalent to the traditional “Glorot” initialization [<a href="https://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf">18</a>]).</p>



<p class="justify-text">This corresponds to the “mean-field” scaling of initialization where neurons from both layers move (see more details in <a href="https://francisbach.com/gradient-descent-neural-networks-global-convergence/">last </a><a href="https://francisbach.com/gradient-descent-for-wide-two-layer-neural-networks-implicit-bias/">July</a><a href="https://francisbach.com/gradient-descent-neural-networks-global-convergence/"> blog post</a> for other scalings). As shown in a joint work with Lénaïc Chizat [<a href="http://papers.nips.cc/paper/7567-on-the-global-convergence-of-gradient-descent-for-over-parameterized-models-using-optimal-transport.pdf">19</a>] and explained in <a href="https://francisbach.com/gradient-descent-neural-networks-global-convergence/">last June blog post</a>, when \(m\) tends to infinity, then the gradient flow can only converge to the global minimum of the objective function, which is a non-trivial result because the cost function is not convex in \((a,b)\). </p>



<p class="justify-text"><strong>Apparent good properties for small \(m\).</strong> A key property which is not yet well understood is that the global convergence behavior can be observed for \(m\) relatively small. For example, considering the one-dimensional regression example below, where the target function is the combination of 5 hidden neurons, with \(m=32\) hidden neurons, it is already possible to learn a good function with high probability (this would not be the case with \(m=5\)).</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-full is-resized"><img alt="" class="wp-image-6048" height="292" src="https://francisbach.com/wp-content/uploads/2021/06/regular_flow_triangular_noisy_32.png" width="319"/>One-dimensional regression from \(n = 64\) observations, by minimizing with gradient descent (and small step-size) the unregularized empirical risk.</figure></div>



<p class="justify-text">One extra benefit here is that no regularization (e.g., no penalty) seems needed to obtain this good behavior. Therefore it seems that we get the best of both worlds: reasonably small \(m\) (so not too costly algorithmically), and no need to regularize.</p>



<p class="justify-text">However, like in any situation where overfitting is not observed, there is the possibility of <em>underfitting</em>. To study this, let us consider a noiseless problem where \(y\) is a deterministic function of \(x\), and with a sligthly more complicated target function, which now requires 9 hidden neurons.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-full is-resized"><img alt="" class="wp-image-6077" height="277" src="https://francisbach.com/wp-content/uploads/2021/06/regular_flow_hard_noiseless_8192.png" width="327"/>One-dimensional noiseless regression from \(n = 64\) observations, by minimizing with gradient descent (and small step-size) the unregularized empirical risk.</figure></div>



<p class="justify-text">Even with \(m = 8192\) hidden neurons, the resulting function is not able to fit the data, which is one extreme form of simplicity bias [<a href="https://proceedings.neurips.cc/paper/2020/file/6cfe0e6127fa25df2a0ef2ae1067d915-Paper.pdf">21</a>]. There is thus strong underfitting with a single hidden layer (the situation seems to be different with deeper networks). How can this be alleviated? </p>



<h2>Kernel learning to the rescue</h2>



<p class="justify-text">A simple way to avoid the underfitting phenomenon above (but potentially get overfitting, see below) is to minimize the cost \(R(a,b)\) by leveraging a convex sub-problem, as done in the glorious days of <a href="https://en.wikipedia.org/wiki/Kernel_method">kernel methods</a>.</p>



<p class="justify-text">In the cost function $$R(a,b) = \frac{1}{2n} \sum_{i=1}^n \Big( y_i \, – \sum_{j=1}^m a_j ( b_j^\top x_i )_+ \Big) ^2 + \frac{\lambda}{2} \sum_{j=1}^m \Big\{ a_j^2 + \| b_j\|_2^2 \Big\},$$ the problem is convex with respect to all \((a_j)\)’s; moreover, it is a least-squares problems which can be solved in closed form by matrix inversion (with algorithms that are much more robust to ill-conditioning than gradient descent). </p>



<p class="justify-text">Then, if we denote by \(\Phi(b) \in \mathbb{R}^{n \times m}\) the matrix with elements \((b_j^\top x_i)_+\), the cost function can be written as a function of \(a \in \mathbb{R}^m\) as $$R(a,b) = \frac{1}{2n} \| y \, – \Phi(b) a \|_2^2 +\frac{\lambda}{2}\| a\|_2^2 +  \frac{\lambda}{2} \sum_{j=1}^m \| b_j\|_2^2.$$ It can be minimized in closed form as $$ a = ( \Phi(b)^\top \Phi(b) + n \lambda I)^{-1} \Phi(b)^\top y = \Phi(b)^\top ( \Phi(b)\Phi(b)^\top + n \lambda I)^{-1} y,$$ where the matrix inversion lemma has been used. This leads to: $$S(b) = \inf_{a \in \mathbb{R}^m} R(a,b) = \frac{\lambda}{2} y^\top  ( \Phi(b)\Phi(b)^\top + n \lambda I)^{-1} y + \frac{\lambda}{2} \sum_{j=1}^m \| b_j\|_2^2.$$ The matrix \(\Phi(b)\Phi(b)^\top \in \mathbb{R}^{n \times n}\) is the traditional kernel matrix of the associated non-linear features. The resulting optimization problem is exactly one used in kernel learning [<a href="https://link.springer.com/content/pdf/10.1023/a:1012450327387.pdf">20</a>].</p>



<p class="justify-text">Computing \(S(b)\) and its gradient with respect to \(b\) can be done in time \(O(n^2 m)\) when \(m\) is large. Since given the hidden neurons, we get the global optimum, we avoid the underfitting problem as well as the ill-conditioning issues.</p>



<p class="justify-text">When \(m\) tends to infinity, then the optimization problem fits our analysis in [<a href="http://papers.nips.cc/paper/7567-on-the-global-convergence-of-gradient-descent-for-over-parameterized-models-using-optimal-transport.pdf">19</a>], that is, we can see the limiting flow as a Wasserstein gradient flow that can only converge to the global optimum of the associated cost function although the overall problem is not convex (as opposed to what happens in multiple kernel learning described in this <a href="https://francisbach.com/the-eta-trick-reloaded-multiple-kernel-learning/">older post</a>). While there is currently no further quantitative theoretical evidence that a good optimization behavior can be reached for a smaller \(m\), it empirically solves the underfitting issue above, as shown below.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-full is-resized"><img alt="" class="wp-image-6050" height="254" src="https://francisbach.com/wp-content/uploads/2021/06/two_flows_hard_noiseless_128.png" width="607"/>Comparison of the the two flows. Right: regular gradient flow on both sets of weights (normal training), left: gradient flow on the cost function where the output weights are maximized out.</figure></div>



<p>We can now perform experiments with varying \(\lambda\)’s.</p>



<p class="justify-text"><strong>Experiments. </strong>The two plots below depict the learnt functions for a smooth and non-smooth objective as \(\lambda\) is varied, highlighting the importance of regularization.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-full is-resized"><img alt="" class="wp-image-6046" height="261" src="https://francisbach.com/wp-content/uploads/2021/06/nn_biplot.gif" width="592"/>Regression problems in one dimension with neural networks (left: smooth target, right: non-smooth target), with \(n=32\) observations, with varying regularization parameters, with the optimal one shown below.</figure></div>



<p class="justify-text">We can now compare the convergence rates for the excess risk (expected squared distance beween \(f\) and \(f^\ast\)). We can see that the rates are better for smooth functions, and with the proper choice of regularization parameter, neural networks adapt to it. For adaptivity to linear latent variables, see [<a href="http://proceedings.mlr.press/v125/chizat20a/chizat20a.pdf">13</a>].</p>



<figure class="wp-block-image size-full justify-text"><img alt="" class="wp-image-6043" height="480" src="https://francisbach.com/wp-content/uploads/2021/06/simulations_adaptivity_nn_subplots.png" width="1833"/>Left: estimation with the optimal regularization parameter for smooth target function and neural networks. Middle: estimation with a non-smooth target function. Right: convergence rates when the number \(n\) of observations increases, averaged over 32 replications.</figure>



<h2>Conclusion</h2>



<p class="justify-text">As I tried to show in this blog post, adaptivity is a key driver of good predictive performance of learning methods. It turns out that for the three classes of methods I considered, the more complex algorithms led to more adaptivity: no optimization for local averaging, finite-dimensional convex optimization for kernel methods and then non-convex optimization for neural networks (or equivalently infinite-dimensional convex optimization).</p>



<p class="justify-text">While neural networks led to more adaptivity, they are still not totally well understood, in particular in terms of the various biases that their training implies, both for shallow and deep networks. This makes a lot of research directions to follow!</p>



<p class="justify-text"><strong>Acknowledgements</strong>. I would like to thank Lénaïc Chizat and Lawrence Stewart for proofreading this blog post and making good clarifying suggestions.</p>



<h2>References</h2>



<p class="justify-text">[1] Luc Devroye, László Györfi, and Gábor Lugosi. <em><a href="https://www.szit.bme.hu/~gyorfi/pbook.pdf">A Probabilistic Theory of Pattern Recognition</a></em>,<br/>volume 31. Springer Science &amp; Business Media, 1996.<br/>[2] László Györfi, Michael Kohler, Adam Krzyżak, Harro Walk<em>.</em> <em><a href="https://web.stanford.edu/class/ee378a/books/book1.pdf">A Distribution-free Theory of Nonparametric Regression</a></em>. New York : Springer, 2002.<br/>[3] Samory Kpotufe.<a href="http://www.columbia.edu/~skk2175/Papers/kNNRegressionLocRatesFullVersion.pdf"> k-NN regression adapts to local intrinsic dimension</a>. In Advances in Neural Information Processing Systems, 2011.<br/>[4] Mehryar Mohri, Afshin Rostamizadeh, and Ameet Talwalkar. <em><a href="https://www.dropbox.com/s/7voitv0vt24c88s/10290.pdf?dl=1">Foundations of Machine Learning</a></em>. MIT Press, 2018.<br/>[5] Shai Shalev-Shwartz and Shai Ben-David. <em><a href="https://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/understanding-machine-learning-theory-algorithms.pdf">Understanding Machine Learning: From Theory to Algorithms</a></em>. Cambridge University Press, 2014.<br/>[6] Bernhard Schölkopf and Alexander J. Smola. <em>Learning with Kernels</em>. MIT Press, 2001.<br/>[7] Radford M. Neal. <a href="https://www.cs.toronto.edu/~radford/ftp/thesis.ps">Bayesian Learning for Neural Networks</a>. PhD thesis, University of Toronto, 1995.<br/>[8] Ali Rahimi and Benjamin Recht. <a href="https://papers.nips.cc/paper/2007/file/013a006f03dbc5392effeb8f18fda755-Paper.pdf">Random features for large-scale kernel machines</a>. In Advances in Neural Information Processing Systems, 2008.<br/>[9] Youngmin Cho and Lawrence K. Saul. <a href="https://papers.nips.cc/paper/2009/file/5751ec3e9a4feab575962e78e006250d-Paper.pdf">Kernel methods for deep learning</a>. In Advances in Neural Information Processing Systems, 2009.<br/>[10] Francis Bach. <a href="https://jmlr.org/papers/volume18/14-546/14-546.pdf">Breaking the curse of dimensionality with convex neural networks</a>. The Journal of Machine Learning Research, 18(1):629–681, 2017.<br/>[11] Andreas Christmann, Ingo Steinwart. Support Vector Machines. Springer, 2008.<br/>[12] Thomas Hamm, Ingo Steinwart. <a href="https://arxiv.org/pdf/2003.06202.pdf">Adaptive Learning Rates for Support Vector Machines Working on Data with Low Intrinsic Dimension</a>. Technical report, Arxiv 2003.06202, 2021.<br/>[13] Lénaïc Chizat, Francis Bach. <a href="http://proceedings.mlr.press/v125/chizat20a/chizat20a.pdf">Implicit Bias of Gradient Descent for Wide Two-layer Neural Networks Trained with the Logistic Loss</a>. <em>Proceedings of the Conference on Learning Theory (COLT)</em>, 2020.<br/>[14] Francis Bach. <a href="http://jmlr.org/papers/volume18/15-178/15-178.pdf">On the Equivalence between Kernel Quadrature Rules and Random Feature Expansions</a>. <em>Journal of Machine Learning Research</em>, 18(19):1-38, 2017. <br/>[15] Alessandro Rudi, Raffaello Camoriano, and Lorenzo Rosasco. <a href="https://papers.nips.cc/paper/2015/file/03e0704b5690a2dee1861dc3ad3316c9-Paper.pdf">Less is more: Nyström computational regularization</a>. In Advances in Neural Information Processing Systems, pages 1657–1665, 2015.<br/>[16] Alessandro Rudi, Lorenzo Rosasco. <a href="https://proceedings.neurips.cc/paper/2017/file/61b1fb3f59e28c67f3925f3c79be81a1-Paper.pdf">Generalization properties of learning with random features</a>. In Advances in Neural Information Processing Systems, 2017.<br/>[17] Ryumei Nakada, Masaaki Imaizumi. <a href="https://jmlr.org/papers/volume21/20-002/20-002.pdf">Adaptive Approximation and Generalization of Deep Neural Network with Intrinsic Dimensionality</a>. <em>Journal of Machine Learning Research</em>, 21(174):1−38, 2020.<br/>[18] Xavier Glorot, Yoshua Bengio. <a href="https://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf">Understanding the difficulty of training deep feedforward neural networks</a>. <em>Proceedings of the International Conference on Artificial Intelligence and Statistics</em>, 2010.<br/>[19] Lénaïc Chizat, Francis Bach. <a href="http://papers.nips.cc/paper/7567-on-the-global-convergence-of-gradient-descent-for-over-parameterized-models-using-optimal-transport.pdf">On the Global Convergence of Gradient Descent for Over-parameterized Models using Optimal Transport</a>. <em>Advances in Neural Information Processing Systems</em>, 2018<br/>[20] Olivier Chapelle, Vladimir Vapnik, Olivier Bousquet, Sayan Mukherjee. <a href="https://link.springer.com/content/pdf/10.1023/a:1012450327387.pdf">Choosing multiple parameters for support vector machines</a>. <em>Machine Learning</em>, 46(1):131-159, 2002.<br/>[21] Harshay Shah, Kaustav Tamuly, Aditi Raghunathan, Prateek Jain, Praneeth Netrapalli. <a href="https://proceedings.neurips.cc/paper/2020/file/6cfe0e6127fa25df2a0ef2ae1067d915-Paper.pdf">The Pitfalls of Simplicity Bias in Neural Networks</a>. In Advances in Neural Information Processing Systems, 2020.</p></div>
    </content>
    <updated>2021-06-17T16:51:38Z</updated>
    <published>2021-06-17T16:51:38Z</published>
    <category term="Machine learning"/>
    <category term="Optimization"/>
    <author>
      <name>Francis Bach</name>
    </author>
    <source>
      <id>https://francisbach.com</id>
      <link href="https://francisbach.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://francisbach.com" rel="alternate" type="text/html"/>
      <subtitle>Francis Bach</subtitle>
      <title>Machine Learning Research Blog</title>
      <updated>2021-06-20T12:22:46Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-1222818111730421374</id>
    <link href="https://blog.computationalcomplexity.org/feeds/1222818111730421374/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2021/06/benny-chor-1956-2021.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/1222818111730421374" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/1222818111730421374" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2021/06/benny-chor-1956-2021.html" rel="alternate" type="text/html"/>
    <title>Benny Chor (1956-2021)</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p/><div class="separator" style="clear: both; text-align: center;"><a href="https://1.bp.blogspot.com/-MVD3X8JUWlI/YMtAmUG2rnI/AAAAAAAB8VM/GFZrtRW5Y707KiQ4KZOTB3c7vaCVV-kHgCLcBGAsYHQ/s137/benny3.jpg" style="clear: left; float: left; margin-bottom: 1em; margin-right: 1em;"><img border="0" height="200" src="https://1.bp.blogspot.com/-MVD3X8JUWlI/YMtAmUG2rnI/AAAAAAAB8VM/GFZrtRW5Y707KiQ4KZOTB3c7vaCVV-kHgCLcBGAsYHQ/w118-h200/benny3.jpg" width="118"/></a></div><br/>Benny Chor passed away on June 10, 2021. Luca Trevisan had a <a href="https://lucatrevisan.wordpress.com/2021/06/10/benny-chor/">blog post</a> on the news.<p/><p>We present a guest post on Benny Chor's life and works by Oded Goldreich. The post has many refs to papers. They will appear at the end with pointers to them.</p><hr/><p>Benny Chor was born on December 23rd 1956  and grew-up in Tel-Aviv, Israel. He studied Mathematics in the Hebrew University, receiving a B.Sc. in 1980 and an M.Sc. in 1981. He then switched to studying Computer Science at MIT, and graduated in 1985 with a PhD thesis titled</p><p> <i>Two Issues in Public Key Cryptography -- RSA Bit Security and a New Knapsack Type System</i></p><p>which received an ACM Distinguished Dissertation award. After post-doctoral periods at MIT and Harvard, he took a faculty position at the Computer Science Department of the Technion (1987-2001), and then at Tel-Aviv University, where he served as the chairman of the department for two years. He died on June 10th 2021, from a terminal disease.</p><p>Although Benny was a very articulated and verbal person, I find it impossible to describe his personality in words. The point is that words cannot capture the experience of interacting with him, which was always sheer fun. Still, I guess I should say something personal as a close friend of his. So I will just mention that he lived happily with Metsada, whom he met in the summer of 1981, and that they lovingly raised three kids: Arnon, Omer and Aya. Actually, let me also mention his life-long close relationship with his brother, Kobi.</p><p>Focusing on his contributions to science, I will confine myself to the areas of cryptography and randomized computation. Still, let me mention that in the mid 1990s, Benny's research interests gradually shifted to computational biology, but I will not review his contributions to that area, since it is very remote from my own expertise.</p><div><div>In my opinion, Benny's most important contribution to cryptography is the fundamental</div><div>paper on Verifiable Secret Sharing [CGMA].  Loosely speaking, Verifiable Secret Sharing</div><div>is a method to share a secret so that any majority of share-holders may reconstruct the</div><div>secret, whereas no minority may do so, and still each share-holder can verify that the</div><div>share that they got is a valid one.  This primitive had a tremendous impact on the</div><div>development of secure multi-party protocols, and almost all subsequent works in this</div><div>area utilize it.</div><div><br/></div><div>Additional research milestones of Benny, in the area of Cryptography, include the proof</div><div>of the existence of a ``hard-core'' in the RSA and Rabin functions [BCS, ACGS], the</div><div>introduction and design of Private Information Retrieval (PIR) schemes [CGKS] (as well</div><div>as their computational counterparts [CG97]), and the introduction and design of</div><div>Tracing Traitor schemes [CFNP].  Each of these works deserves more than the foregoing</div><div>brief mention, yet I'm not even mentioning other important works like [CK].</div><div><br/></div><div>Turning to the area of Randomized Computation, Benny's contributions span diverse areas</div><div>ranging from the manipulation of randomness to the use of randomness in complexity theory</div><div>and distributed computing.  In particular, his work on weak sources of randomness [CG88]</div><div>identified min-entropy (of the source) as the key parameter for randomness extraction and</div><div>presented a simple two-source extractor.  Distilling an aspect of [ACGS], his work on</div><div>pairwise-independent sampling [CG89] demonstrates the general applicability of this method. His works in distributed computing include a randomized Byzantine Agreement protocol [CC] that beats the deterministic bound without using unproven assumptions.  Lastly, let me just mention a couple of his complexity-theoretic works: [BCGL, CCGHHRR].</div><div><br/></div><div>Benny was a superb teacher and a devoted graduate student adviser.  It is tempting to try</div><div>listing the numerous educational projects that he initiated, and his former students, but</div><div>these lists will be too long and the risk of a crucial omissions is too high.  So let me</div><div>end by expressing the feeling of loss that is shared by many in our community,</div><div>which adds to my personal sorrow.</div></div><div><br/></div><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto;"><tbody><tr><td style="text-align: center;"><a href="https://1.bp.blogspot.com/-VxGM4xSHMwU/YMtBVdfDCMI/AAAAAAAB8Vo/47D34yqw-pEpjSLuzOk-lvHn6HFOPTyVACLcBGAsYHQ/s634/benny2.jpg" style="margin-left: auto; margin-right: auto;"><img border="0" src="https://1.bp.blogspot.com/-VxGM4xSHMwU/YMtBVdfDCMI/AAAAAAAB8Vo/47D34yqw-pEpjSLuzOk-lvHn6HFOPTyVACLcBGAsYHQ/s320/benny2.jpg" width="320"/></a></td></tr><tr><td class="tr-caption" style="text-align: center;">Oded and Benny</td></tr></tbody></table><br/><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto;"><tbody><tr><td style="text-align: center;"><a href="https://1.bp.blogspot.com/-TJNVzF4e9HE/YMtBVWGdtXI/AAAAAAAB8Vs/jvxumCSZxPw-Oqr4cqQGf35n8ds3KLaDwCLcBGAsYHQ/s1415/benny4.jpg" style="margin-left: auto; margin-right: auto;"><img border="0" src="https://1.bp.blogspot.com/-TJNVzF4e9HE/YMtBVWGdtXI/AAAAAAAB8Vs/jvxumCSZxPw-Oqr4cqQGf35n8ds3KLaDwCLcBGAsYHQ/s320/benny4.jpg" width="320"/></a></td></tr><tr><td class="tr-caption" style="text-align: center;">Benny with his family's namesake (Chor = Bull)</td></tr></tbody></table><br/><div>[ACGS] Werner Alexi, Benny Chor, Oded Goldreich, Claus-Peter Schnorr:</div><div><div>RSA and Rabin Functions: Certain Parts are as Hard as the Whole.</div><div>SIAM J. Comput. 17(2): 194-209 (1988) <a href="https://epubs.siam.org/doi/abs/10.1137/0217013">LINK</a></div><div><br/></div><div>[BCGL] Shai Ben-David, Benny Chor, Oded Goldreich, Michael Luby:</div><div>On the Theory of Average Case Complexity. J. Comput. Syst. Sci. 44(2): 193-219 (1992) <a href="https://www.sciencedirect.com/science/article/pii/002200009290019F">LINK</a></div><div><br/></div><div>[BCS] Michael Ben-Or, Benny Chor, Adi Shamir: On the Cryptographic Security of Single RSA Bits STOC 1983: 421-430. <a href="https://dl.acm.org/doi/10.1145/800061.808773">LINK</a></div><div><br/></div><div>[CCGHHRR] Richard Chang, Benny Chor, Oded Goldreich, Juris Hartmanis, Johan Håstad, Desh Ranjan, Pankaj Rohatgi: The Random Oracle Hypothesis Is False.</div><div>J. Comput. Syst. Sci. 49(1): 24-39 (1994) <a href="https://www.sciencedirect.com/science/article/pii/S0022000005800844">LINK</a></div><div><br/></div><div>[CC] Benny Chor, Brian A. Coan:</div><div>A Simple and Efficient Randomized Byzantine Agreement Algorithm.</div><div>IEEE Trans. Software Eng. 11(6): 531-539 (1985) <a href="https://ieeexplore.ieee.org/document/1702050">LINK</a></div><div><br/></div><div>[CFNP] Benny Chor, Amos Fiat, Moni Naor, Benny Pinkas:</div><div>Tracing traitors. IEEE Trans. Inf. Theory 46(3): 893-910 (2000) <a href="https://ieeexplore.ieee.org/document/841169">LINK</a></div><div><br/></div><div>[CG97] Benny Chor, Niv Gilboa:</div><div>Computationally Private Information Retrieval. STOC 1997: 304-313 <a href="https://dl.acm.org/doi/10.1145/258533.258609">LINK</a></div><div><br/></div><div>[CG88] Benny Chor, Oded Goldreich:</div><div>Unbiased Bits from Sources of Weak Randomness and Probabilistic Communication Complexity.</div><div>SIAM J. Comput. 17(2): 230-261 (1988) <a href="https://epubs.siam.org/doi/10.1137/0217015">LINK</a></div><div><br/></div><div>[CG89] Benny Chor, Oded Goldreich:</div><div>On the power of two-point based sampling. J. Complex. 5(1): 96-106 (1989) <a href="https://doi.org/10.1016/0885-064X(89)90015-0">LINK</a></div><div><br/></div><div>[CGKS] Benny Chor, Oded Goldreich, Eyal Kushilevitz, Madhu Sudan:</div><div>Private Information Retrieval. J. ACM 45(6): 965-981 (1998) <a href="https://doi.org/10.1145/293347.293350">LINK</a></div><div><br/></div><div>[CGMA] Benny Chor, Shafi Goldwasser, Silvio Micali, Baruch Awerbuch:</div><div>Verifiable Secret Sharing and Achieving Simultaneity in the Presence of Faults.</div><div>FOCS 1985: 383-395. <a href="https://doi.org/10.1109/SFCS.1985.64">LINK</a></div></div><div><div><br/></div><div>[CK] Benny Chor, Eyal Kushilevitz:</div><div>A Zero-One Law for Boolean Privacy.  STOC 1989: 62-72. <a href="https://doi.org/10.1145/73007.73013">LINK</a></div><div><br/></div></div><div><br/></div><div><br/></div><div><br/></div></div>
    </content>
    <updated>2021-06-17T14:07:00Z</updated>
    <published>2021-06-17T14:07:00Z</published>
    <author>
      <name>gasarch</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03004932739846901628</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2021-06-19T20:06:19Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/082</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/082" rel="alternate" type="text/html"/>
    <title>TR21-082 |  Hardness on any Samplable Distribution Suffices: New Characterizations of One-Way Functions by Meta-Complexity | 

	Rahul Santhanam, 

	Hanlin Ren, 

	Rahul Ilango</title>
    <summary>We show that one-way functions exist if and only if there is some samplable distribution D such that it is hard to approximate the Kolmogorov complexity of a string sampled from D. Thus we characterize the existence of one-way functions by the average-case hardness of a natural \emph{uncomputable} problem on samplable distributions, extending a recent line of work by Liu and Pass (FOCS'20, STOC'21) and Ren and Santhanam (CCC'21).

    We also show that the average-case hardness of approximating Minimum Circuit Size on a locally samplable distribution (where the sampler runs in sub-linear time by using random access to its input) is equivalent to the existence of one-way functions. This is the first characterization of one-way functions by a natural average-case hardness assumption on the Minimum Circuit Size Problem. We present several other characterizations and connections between one-way functions and average-case hardness of meta-complexity problems (problems about complexity) on samplable distributions.

    We give various applications of these results to the foundations of cryptography and the theory of meta-complexity. We show that the average-case hardness of deciding k-SAT or Clique on any samplable distribution of high enough entropy implies the existence of one-way functions. Thus one-way functions follow from general assumptions on the average-case hardness of NP-complete problems. We observe that our assumptions are implied by standard cryptographic assumptions such as the Planted Clique hypothesis and the pseudorandomness of Goldreich's local functions.

    Our results imply a range of \emph{equivalences} between various meta-complexity problems, showing that the theory of meta-complexity is very \emph{robust} when considering average-case complexity. We use our results to unconditionally solve various meta-complexity problems in CZK (computational zero-knowledge) on average, and give implications of our results for the classic question of proving NP-hardness for the Minimum Circuit Size Problem.</summary>
    <updated>2021-06-16T15:57:38Z</updated>
    <published>2021-06-16T15:57:38Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-06-20T12:20:31Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2021/06/15/linkage</id>
    <link href="https://11011110.github.io/blog/2021/06/15/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>What is a natural question? (\(\mathbb{M}\)) Gasarch on distinguishing notions of interestingness of mathematical problems based on ability to answer them, versus whether they lead to deeper mathematics.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><ul>
  <li>
    <p><a href="https://blog.computationalcomplexity.org/2021/05/what-is-natural-question-who-should.html">What is a natural question?</a> (<a href="https://mathstodon.xyz/@11011110/106339474749439957">\(\mathbb{M}\)</a>) Gasarch on distinguishing notions of interestingness of mathematical problems based on ability to answer them, versus whether they lead to deeper mathematics.</p>
  </li>
  <li>
    <p>Bad geometry in an illustration of parallel parking advice to change steering lock-to-lock when you reach a 45° angle (<a href="https://mathstodon.xyz/@11011110/106345620085904810">\(\mathbb{M}\)</a>): this car is going to end up halfway over the curb. Really the inflection angle depends on the distance from curb and your car’s turning radius. You should switch direction when the rear axle midpoint is halfway between its starting and ending lines of motion, or approximately when the passenger rear wheel is a bit less than halfway to the curb. This car went past that point and can’t straighten before reaching the curb.</p>

    <p style="text-align: center;"><img alt="Top-down view of parallel parking, with the path of the rear-axle centerline shown in red. With the centerline ending up on the curb at the end of the path, the car itself will be well over the curb." src="https://11011110.github.io/blog/assets/2021/parallel-park.jpg" width="60%"/></p>
  </li>
  <li>
    <p><a href="https://www.quantamagazine.org/mathematicians-identify-threshold-at-which-shapes-give-way-20210603/">How smooth can Nash–Kuiper embeddings be?</a> (<a href="https://mathstodon.xyz/@11011110/106347809760355726">\(\mathbb{M}\)</a>) Recent progress identifies a strict threshold at \(C^{1,1/2}\). A new popularized and high-level survey on <em>Quanta</em>. See Wikipedia for more on the <a href="https://en.wikipedia.org/wiki/Nash_embedding_theorem">Nash embedding theorem</a> (here, in the form that all 2d surfaces have non-smooth embeddings in 3d preserving distances along surface curves) and on <a href="https://en.wikipedia.org/wiki/H%C3%B6lder_condition">the notions of fractional smoothness considered here</a>, left unexplained by the <em>Quanta</em> article.</p>
  </li>
  <li>
    <p><a href="https://xenaproject.wordpress.com/2021/06/05/half-a-year-of-the-liquid-tensor-experiment-amazing-developments/">Interesting progress report by Peter Scholze on the formalized and computer-verified proof of some difficult material in analytic geometry</a> (<a href="https://mathstodon.xyz/@11011110/106359088815982703">\(\mathbb{M}\)</a>).</p>
  </li>
  <li>
    <p><a href="http://web.stanford.edu/~mleake/projects/paperpiecing/">A mathematical foundation for foundation paper pieceable quilts</a> (<a href="https://mathstodon.xyz/@11011110/106362497443237500">\(\mathbb{M}\)</a>, <a href="https://www.metafilter.com/191666/Quilters-are-the-best-at-graph-theory">via</a>). They formalize things by hypergraphs, but I prefer <a href="https://en.wikipedia.org/wiki/Antimatroid">antimatroids</a>: a pattern is piecable if and only if you can slice off one piece at a time by guillotine cuts, eventually slicing everything. The possible slicing orders form an antimatroid, because a piece, once sliceable, remains so until it is sliced. The piecing order is the reverse of a slicing order.</p>
  </li>
  <li>
    <p>Firefox’s “reader mode”, in which you can click on little page-with-text icon next to the url, and get view of text stripped of extraneous framing, is useful (<a href="https://mathstodon.xyz/@11011110/106370852134898457">\(\mathbb{M}\)</a>), but it would be more useful <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1466044">if it actually worked for pages with mathematical content</a>.</p>
  </li>
  <li>
    <p>One of the footpaths through my neighborhood is next to a small field with two chess tables (<a href="https://mathstodon.xyz/@11011110/106372538313055882">\(\mathbb{M}\)</a>). They’ve been overgrown and largely unused for quite a while, but a few months back the neighborhood association’s gardeners cleared the field and planted some ginkgo trees around the tables. Someone has been playing chess there with pine cones:</p>

    <p style="text-align: center;"><img alt="UCI Ecological Preserve" src="https://www.ics.uci.edu/~eppstein/pix/uhchess/Chess-m.jpg" style="border-style: solid; border-color: black;" width="80%"/></p>
  </li>
  <li>
    <p><a href="https://www.quantamagazine.org/why-is-quantum-computing-so-hard-to-explain-20210608/">Scott Aaronson, in <em>Quanta</em>, on why the glib popularizations of quantum computing typically found in publications like <em>Quanta</em> are usually wrong</a> (<a href="https://mathstodon.xyz/@11011110/106377151244377180">\(\mathbb{M}\)</a>, <a href="https://www.scottaaronson.com/blog/?p=5539">see also</a>).</p>
  </li>
  <li>
    <p><a href="https://nautil.us/issue/23/dominoes/the-amazing-autotuning-sandpile">The amazing, autotuning sandpile</a> (<a href="https://mathstodon.xyz/@11011110/106389220646874351">\(\mathbb{M}\)</a>). Jordan Ellenberg on <a href="https://en.wikipedia.org/wiki/Abelian_sandpile_model">abelian sandpile models</a>, with pretty pictures of the fractal patterns they generate, from 2015. These patterns are still a topic of active research; see e.g. “<a href="https://annals.math.princeton.edu/2017/186-1/p01">The Apollonian structure of integer superharmonic matrices</a>”, <em>Ann. Math.</em> 2017, , and “<a href="https://doi.org/10.1073/pnas.1812015116">Harmonic dynamics of the abelian sandpile</a>”, <em>PNAS</em> 2019.</p>
  </li>
  <li>
    <p><a href="https://mathemalchemy.org/2021/01/19/dodecahedral-trajectory/">Dodecahedral trajectory</a> (<a href="https://mathstodon.xyz/@11011110/106395952293245848">\(\mathbb{M}\)</a>). Mathematical glass artist Bronna Butler visualizes closed geodesics from and returning to a single vertex on the dodecahedron, using stained glass. These paths exist only on the dodecahedron, among the Platonic solids: geodesics starting from a vertex on the other solids will either hit another vertex before returning, or never return.</p>
  </li>
  <li>
    <p><a href="https://www.wired.com/story/twitter-photo-crop-algorithm-favors-white-faces-women/">Automatic face-recognition systems used to auto-crop social media photos discovered to be racist and sexist</a> (<a href="https://mathstodon.xyz/@11011110/106402230076815482">\(\mathbb{M}\)</a>). This sort of thing is part of a long line of stories of computer systems learning to replicate the biases of their developers, and one of many reasons we need greater diversity in CS.</p>
  </li>
  <li>
    <p><em><a href="https://doi.org/10.1007/978-981-15-4470-5">Introduction to Computational Origami</a></em> (<a href="https://mathstodon.xyz/@11011110/106407675350595758">\(\mathbb{M}\)</a>), Ryuhei Uehara’s 2020 book, is the subject of <a href="https://www.maa.org/press/maa-reviews/introduction-to-computational-origami">a new featured review by Tom Hull on <em>MAA Reviews</em></a>.</p>
  </li>
  <li>
    <p><a href="http://gregegan.net/SCIENCE/Howell/Howell.html">Howell’s moving orbits</a> (<a href="https://mathstodon.xyz/@11011110/106413218848247270">\(\mathbb{M}\)</a>). Greg Egan explains the early research of <a href="https://en.wikipedia.org/wiki/Kathleen_Howell">Kathleen Howell</a> on the existence of first-order-stable <a href="https://en.wikipedia.org/wiki/Halo_orbit">halo orbits</a> of a third small body under the gravitational influence of two larger bodies, related to the (unstable) L1 and L2 Lagrange points.</p>
  </li>
  <li>
    <p><a href="http://gallery.bridgesmathart.org/exhibitions/2021-bridges-conference">The 2021 Bridges Conference Mathematical Art Galleries</a> (<a href="https://mathstodon.xyz/@11011110/106418890356129959">\(\mathbb{M}\)</a>) are online even though <a href="https://www.bridgesmathart.org/b2021/">the online conference itself is not until August</a>. I haven’t yet had time to explore all of them but there are lots of good pieces in there.</p>
  </li>
</ul></div>
    </content>
    <updated>2021-06-15T23:31:00Z</updated>
    <published>2021-06-15T23:31:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2021-06-16T06:33:12Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://rjlipton.wpcomstaging.com/?p=18896</id>
    <link href="https://rjlipton.wpcomstaging.com/2021/06/15/thursday-june-17th-a-debate-on-program-correctness/" rel="alternate" type="text/html"/>
    <title>Thursday—June 17th—A Debate on Program Correctness</title>
    <summary>There are two ways to write error free programs; only the third one works–Alan Perlis Perlis on Coding Joy source Alan Perlis, the first Turing Award winner, summarized the whole issue of program correctness in his single quote. Maybe there is nothing more to say about it. But this coming Thursday, if you want to […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>There are two ways to write error free programs; only the third one works–Alan Perlis</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2021/06/15/thursday-june-17th-a-debate-on-program-correctness/1_qkgjghs7wcpoq09rklc_jq/" rel="attachment wp-att-18919"><img alt="" class="alignright wp-image-18919" height="130" src="https://i2.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/06/1_QkGJGhS7wCPoq09rkLC_JQ.jpeg?resize=200%2C130&amp;ssl=1" width="200"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Perlis on Coding Joy <a href="https://www.freecodecamp.org/news/perlis-on-tech-evangelism-10-epigrams-5ea6dcf3faf5/">source</a></font></td>
</tr>
</tbody>
</table>
<p>
Alan Perlis, the first Turing Award winner, summarized the whole issue of program correctness in his single quote.  Maybe there is nothing more to say about it.</p>
<p>
But this coming Thursday, if you want to hear more about it, you can tune in for a debate with Rich de Millo and myself.  It will be 7:00–8:30pm Eastern time.</p>
<p>
Harry Lewis of Harvard University will moderate.  It will be broadcast <a href="https://scp.cc.gatech.edu/2021/05/26/debate-that-changed-programming-living-history/">LIVE HERE</a>. It’s free.</p>
<p>
 <br/>
<a href="https://rjlipton.wpcomstaging.com/2021/06/15/thursday-june-17th-a-debate-on-program-correctness/pic-10/" rel="attachment wp-att-18898"><img alt="" class="aligncenter wp-image-18898" height="312" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/06/pic.png?resize=550%2C312&amp;ssl=1" width="550"/></a></p>
<p/><p>
 <br/>
</p><h2> The Paper </h2><p/>
<p/><p>
Perlis and Rich DeMillo and I wrote the <a href="https://www.cs.umd.edu/~gasarch/BLOGPAPERS/social.pdf">paper</a> “Social Processes and Proofs of Theorems<br/>
and Programs” in the middle of the second half of the last century—pushing towards fifty years ago. We were responding to the then-common view that programs should be proved correct—proved in the same manner that one proves theorems like: </p>
<blockquote><p><b>Theorem 1 (Euclid)</b> <em> There are an infinite number of prime numbers. </em>
</p></blockquote>
<p>We begged to object: We felt that correctness of programs was fundamentally a different issue. This is what the debate is all about. </p>
<p>
The debate will give us all a chance to reflect now almost 50 years later when programs enrich and regulate so much more of our lives.  Perhaps the real winner in society goes according to the proverb: “the one who ends up with the most toys.”  In that case, Harry the moderator will win hands down:</p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2021/06/15/thursday-june-17th-a-debate-on-program-correctness/harrylewis_harvard_officeknickknacks/" rel="attachment wp-att-18914"><img alt="" class="aligncenter wp-image-18914" height="160" src="https://i2.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/06/HarryLewis_Harvard_OfficeKnickKnacks.jpg?resize=240%2C160&amp;ssl=1" width="240"/></a></p>
<p>
</p><p/><h2> The Writing </h2><p/>
<p/><p>
Mary-Claire van Leunen is an expert on writing, especially for technical articles. See her famous <a href="https://www.amazon.com/s?i=stripbooks&amp;rh=p_27%3AMary-Claire+van+Leunen&amp;s=relevancerank&amp;text=Mary-Claire+van+Leunen&amp;ref=dp_byline_sr_book_1">book</a>.</p>
<p>
The article was heavily written by Rich with input from Alan and myself. The ideas are due to all of us. The actual details, the words, the punctuation owe more to Rich with strong input from Mary-Claire. </p>
<p>
Our paper is one of forty-six papers included in the <a href="https://mitpress.mit.edu/books/ideas-created-future">book</a> <i>Ideas That Created the Future: Classic Papers of Computer Science</i>, which was edited by Harry for MIT Press (2020).  They are presented in chronological order beginning with Aristotle (~350 BCE).  The median year is 1962-63.  </p>
<p/><h2> Open Problems </h2><p/>
<p/><p>
See <a href="https://www.sigplan.org/Resources/Advice/VanLeunen-Lipton/">How to Have Your Abstract Rejected</a> for a tongue-in-cheek view of writing technical material. It was written by Mary-Claire and myself.</p>
<p>
See you Thursday. </p>
<p/></font></font></div>
    </content>
    <updated>2021-06-15T14:57:13Z</updated>
    <published>2021-06-15T14:57:13Z</published>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="Oldies"/>
    <category term="People"/>
    <category term="correctness"/>
    <category term="debate"/>
    <category term="DeMillo"/>
    <category term="Lipton"/>
    <category term="Perlis"/>
    <category term="programs"/>
    <category term="Proof"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wpcomstaging.com</id>
      <logo>https://s0.wp.com/i/webclip.png</logo>
      <link href="https://rjlipton.wpcomstaging.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wpcomstaging.com" rel="alternate" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel's Lost Letter and P=NP</title>
      <updated>2021-06-20T12:20:39Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/081</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/081" rel="alternate" type="text/html"/>
    <title>TR21-081 |  Superpolynomial Lower Bounds Against Low-Depth Algebraic Circuits | 

	Sébastien Tavenas, 

	Srikanth Srinivasan, 

	Nutan Limaye</title>
    <summary>An Algebraic Circuit for a polynomial $P\in F[x_1,\ldots,x_N]$ is a computational model for constructing the polynomial $P$ using only additions and multiplications. It is a \emph{syntactic} model of computation, as opposed to the Boolean Circuit model, and hence lower bounds for this model are widely expected to be easier to prove than lower bounds for Boolean circuits. Despite this, we do not have superpolynomial lower bounds against general algebraic circuits of depth 3 (except over constant-sized finite fields) and depth 4 (over any field), while constant-depth Boolean circuit lower bounds have been known since the early 1980s.

In this paper, we prove the first superpolynomial lower bounds against general algebraic circuits of all constant depths over all fields of characteristic $0$ (or large). We also prove the first lower bounds against homogeneous algebraic circuits of constant depth over any field.

Our approach is surprisingly simple. We first prove superpolynomial lower bounds for constant-depth Set-Multilinear circuits. While strong lower bounds were already known against such circuits, most previous lower bounds were of the form $f(d)\cdot poly(N)$, where $d$ denotes the degree of the polynomial.  In analogy with Parameterized complexity, we call this an FPT lower bound. We extend a well-known technique of Nisan and Wigderson (FOCS 1995) to prove non-FPT lower bounds against constant-depth set-multilinear circuits computing the Iterated Matrix Multiplication polynomial $IMM_{n,d}$ (which computes a fixed entry of the product of $d$ $n\times n$ matrices). More precisely, we prove that  any set-multilinear circuit of depth $\Delta$ computing $IMM_{n,d}$ must have size at least $n^{d^{\exp(-O(\Delta))}}.$ This result holds over any field.

We then show how to convert any constant-depth algebraic circuit of size $s$ to a constant-depth set-multilinear circuit with a blow-up in size that is exponential in $d$ but only polynomial in $s$ over fields of characteristic $0$. (For depths greater than $3$, previous results of this form increased the depth of the resulting circuit to $\Omega(\log s)$.) This implies our constant-depth circuit lower bounds for $d$ that is a slow-growing function of $n$.

Finally, we observe that our superpolynomial lower bound for constant-depth circuits  implies the first deterministic sub-exponential time algorithm for solving the Polynomial Identity Testing (PIT) problem for all small depth circuits  using the known connection between algebraic hardness and randomness.</summary>
    <updated>2021-06-15T05:50:00Z</updated>
    <published>2021-06-15T05:50:00Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-06-20T12:20:31Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://decentralizedthoughts.github.io/2021-06-14-neither-non-equivocation-nor-transferability-alone-is-enough-for-tolerating-minority-corruptions-in-asynchrony/</id>
    <link href="https://decentralizedthoughts.github.io/2021-06-14-neither-non-equivocation-nor-transferability-alone-is-enough-for-tolerating-minority-corruptions-in-asynchrony/" rel="alternate" type="text/html"/>
    <title>Neither Non-equivocation nor Transferability alone is enough for tolerating minority corruptions in asynchrony</title>
    <summary>In this post, we explore a theorem of Clement, Junqueira, Kate, and Rodrigues from PODC 2012 regarding the limits of non-equivocation. Informally, this theorem says that neither Non-equivocation nor Transferability alone is enough for tolerating minority corruptions in asynchrony. Theorem CJKR12: Neither non-equivocation nor transferability is individually sufficient to solve...</summary>
    <updated>2021-06-14T16:04:00Z</updated>
    <published>2021-06-14T16:04:00Z</published>
    <source>
      <id>https://decentralizedthoughts.github.io</id>
      <author>
        <name>Decentralized Thoughts</name>
      </author>
      <link href="https://decentralizedthoughts.github.io" rel="alternate" type="text/html"/>
      <link href="https://decentralizedthoughts.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Decentralized thoughts about decentralization</subtitle>
      <title>Decentralized Thoughts</title>
      <updated>2021-06-19T22:46:48Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=8148</id>
    <link href="https://windowsontheory.org/2021/06/14/machine-learning-for-algorithms-virtual-workshop/" rel="alternate" type="text/html"/>
    <title>Machine Learning for Algorithms – virtual workshop</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">[H/T Jelani Nelson] In recent years there has been increasing interest in using machinelearning to improve the performance of classical algorithms incomputer science, by fine-tuning their behavior to adapt to theproperties of the input distribution. This “data-driven” or“learning-based” approach to algorithm design has the potential tosignificantly improve the efficiency of some of the most widely … <a class="more-link" href="https://windowsontheory.org/2021/06/14/machine-learning-for-algorithms-virtual-workshop/">Continue reading <span class="screen-reader-text">Machine Learning for Algorithms – virtual workshop</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>[H/T Jelani Nelson]</p>



<p>In recent years there has been increasing interest in using machine<br/>learning to improve the performance of classical algorithms in<br/>computer science, by fine-tuning their behavior to adapt to the<br/>properties of the input distribution. This “data-driven” or<br/>“learning-based” approach to algorithm design has the potential to<br/>significantly improve the efficiency of some of the most widely used<br/>algorithms. For example, it has been used to design better data<br/>structures, online algorithms, streaming and sketching algorithms,<br/>market mechanisms and algorithms for combinatorial optimization,<br/>similarity search and inverse problems. This virtual workshop will<br/>feature talks from experts at the forefront of this exciting area.</p>



<p>The workshop will take place virtually on <strong>July 13-14, 2021</strong>. <br/>Registration is <strong>free but mandatory</strong>. Link to register: <a href="https://fodsi.us/ml4a.html" rel="noreferrer noopener" target="_blank">https://fodsi.us/ml4a.html</a></p>



<p><strong>Confirmed Speakers:</strong></p>



<ul><li>Alex Dimakis (UT Austin)</li><li>Yonina Eldar (Weizmann)</li><li>Anna Goldie (Google Brain, Stanford)</li><li>Reinhard Heckel (Technical University of Munich)</li><li>Stefanie Jegelka (MIT)</li><li>Tim Kraska (MIT)</li><li>Benjamin Moseley (CMU)</li><li>David Parkes (Harvard)</li><li>Ola Svensson (EPFL)</li><li>Tuomas Sandholm (CMU, Optimized Markets, Strategy Robot, Strategic Machine)</li><li>Sergei Vassilvitski (Google)</li><li>Ellen Vitercik (CMU/UC Berkeley)</li><li>David Woodruff (CMU)</li></ul>



<p><strong>Organizers:</strong></p>



<ul><li>Costis Daskalakis (MIT)</li><li>Paul Hand (Northeastern)</li><li>Piotr Indyk (MIT)</li><li>Michael Mitzenmacher (Harvard)</li><li>Ronitt Rubinfeld (MIT)</li><li>Jelani Nelson (UC Berkeley)</li></ul>



<h2 class="has-text-color" style="color: #a30023;"><strong>Unrelated announcement: JACM looking for editor in chief</strong> </h2>



<p>(h/t Salil Vadhan)</p>



<p>The Journal of the ACM is looking for a new editor in chief: see the <a href="https://dl.acm.org/pb-assets/static_journal_pages/jacm/pdf/JACM-Call-2021-BAM-1623181914103.pdf">call for nominations</a>. The (soft) deadline to submit nominations (including self nominations) is <strong>July 19th</strong> and you can do so by emailing  Chris Hankin at c.hankin@imperial.ac.uk </p>



<p/></div>
    </content>
    <updated>2021-06-14T13:29:56Z</updated>
    <published>2021-06-14T13:29:56Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2021-06-20T12:21:03Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://rjlipton.wpcomstaging.com/?p=18876</id>
    <link href="https://rjlipton.wpcomstaging.com/2021/06/12/tardos-is-off-with-good-behavior/" rel="alternate" type="text/html"/>
    <title>Tardos Is Off With Good Behavior</title>
    <summary>A call for nominations for her successor In her original orange Éva Tardos’s sentence as Editor-in-Chief (EiC) of the Journal of the ACM (JACM) is coming to an end. She has served almost six years. She will be paroled soon for her good behavior. Today we announce that a grand jury is being convened. This […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>A call for nominations for her successor</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2021/06/12/tardos-is-off-with-good-behavior/20170912-142623-1_edit/" rel="attachment wp-att-18887"><img alt="" class="alignright size-full wp-image-18887" height="123" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/06/20170912-142623-1_edit.jpg?resize=114%2C123&amp;ssl=1" width="114"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">In her original <a href="https://research.cornell.edu/researchers/eva-tardos">orange</a></font></td>
</tr>
</tbody>
</table>
<p>
Éva Tardos’s sentence as Editor-in-Chief (EiC) of the <i>Journal of the ACM</i> (JACM) is coming to an end. She has served almost six years. She will be paroled soon for her good behavior. </p>
<p>
Today we announce that a grand jury is being convened. This group is charged with finding the right person to be indicted as the next editor-in-chief of the JACM.<br/>
<span id="more-18876"/></p>
<p>
Tips on possible suspects should be directed to lieutenant Chris Hankin <a href="https://www.imperial.ac.uk/people/c.hankin">here</a>. Note that the location is not far from Scotland Yard. He is in charge of the grand jury:</p>
<p>
Laura Haas (University of Massachusetts Amherst, US) <br/>
Orna Kupferman (Hebrew University, Israel) <br/>
Marta Kwiatkowska (University of Oxford, UK) <br/>
Brad Myers (Carnegie Mellon University, US) <br/>
Salil Vadhan (Harvard University, US) <br/>
Albert Zomaya (University of Sydney, Australia) <br/>
Divesh Srivastava (AT&amp;T, US), ACM Pubs Board Liaison</p>
<p>
</p><p/><h2> History </h2><p/>
<p/><p>
The JACM was established in 1954 and has published over 3,000 papers, since then. There were 196 submissions received in 2020 alone. The current editorial board is <a href="https://dl.acm.org/journal/jacm/editorial-board#editor-in-chief">this</a>. Previous editors-in-chief are:</p>
<p>
1954 – 1958: Franz Alt<br/>
1959 – 1962: Mario Juncosa<br/>
1963 – 1965: Richard Hamming<br/>
1966 – 1968: Calvin Gotlieb<br/>
1969 – 1972: Gerard Salton<br/>
1973 – 1975: Raymond Miller<br/>
1976 – 1979: Edward Coffman, Jr.<br/>
1979 – 1982: Michael Garey<br/>
1983 – 1986: Michael Fischer<br/>
1986 – 1990: Daniel Rosenkrantz<br/>
1991 -1997: Tom Leighton<br/>
1997 – 2003: Joseph Halpern<br/>
2003 – 2009: Prabhakar Raghavan<br/>
2009 – 2015: Victor Vianu<br/>
2015 – currently: Éva Tardos</p>
<p>
</p><p/><h2> Selection </h2><p/>
<p/><p>
Typically many candidates are available, but only the most dramatic cases will be considered. Nominations should include a vita along with a brief statement of why the nominee should be considered. Why they are <b>un</b>-worthy to be made into the editor-in-chief? A vision statement is highly encouraged. The relevant law is found here:</p>
<p>
<a href="https://www.acm.org/publications/policies/roles-and-responsibilities">Roles and Responsibilities in ACM Publishing</a></p>
<p>
<a href="https://www.acm.org/publications/policies/eic-evaluation">ACM’s Evaluation Criteria for Editors-in-Chief</a></p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p>All kidding aside. We thank Éva for her hard work keeping the JACM one of the top journals in the world. We can only hope that the next chief will be nearly as sucessful as she has been.</p></font></font></div>
    </content>
    <updated>2021-06-12T12:25:16Z</updated>
    <published>2021-06-12T12:25:16Z</published>
    <category term="History"/>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="People"/>
    <category term="chief"/>
    <category term="editor"/>
    <category term="JACM"/>
    <category term="search"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wpcomstaging.com</id>
      <logo>https://s0.wp.com/i/webclip.png</logo>
      <link href="https://rjlipton.wpcomstaging.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wpcomstaging.com" rel="alternate" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel's Lost Letter and P=NP</title>
      <updated>2021-06-20T12:20:40Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2021/06/12/carrying-chip-firing</id>
    <link href="https://11011110.github.io/blog/2021/06/12/carrying-chip-firing.html" rel="alternate" type="text/html"/>
    <title>Carrying as chip-firing for the Zeckendorf representation</title>
    <summary>You may have heard of the Zeckendorf representation according to which any positive integer can be represented as a sum of non-consecutive Fibonacci numbers. Its uses include the optimal strategy in the game of Fibonacci nim. But did you know that it’s possible to efficiently add and subtract Zeckendorf representations?1 The algorithm from the paper linked above takes three passes over the input digit sequences using finite state automata, much like binary number addition can be performed by a single pass of a finite state automaton. I thought it might be interesting to describe an alternative path to the same result, using chip-firing games. Connor Ahlbach, Jeremy Usatine, Christiane Frougny, and Nicholas Pippenger (2013), “Efficient algorithms for Zeckendorf arithmetic”, Fibonacci Quarterly 51 (3): 249–255, arXiv:1207.4497, MR3093678. ↩</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>You may have heard of the <a href="https://en.wikipedia.org/wiki/Zeckendorf%27s_theorem">Zeckendorf representation</a> according to which any positive integer can be represented as a sum of non-consecutive Fibonacci numbers. Its uses include the optimal strategy in the game of <a href="https://en.wikipedia.org/wiki/Fibonacci_nim">Fibonacci nim</a>. But did you know that <a href="https://www.irif.fr/~cf/publications/AUFP.pdf">it’s possible to efficiently add and subtract Zeckendorf representations</a>?<sup id="fnref:a"><a class="footnote" href="https://11011110.github.io/blog/2021/06/12/carrying-chip-firing.html#fn:a" rel="footnote">1</a></sup> The algorithm from the paper linked above takes three passes over the input digit sequences using finite state automata, much like binary number addition can be performed by a single pass of a finite state automaton. I thought it might be interesting to describe an alternative path to the same result, using <a href="https://en.wikipedia.org/wiki/Chip-firing_game">chip-firing games</a>.</p>

<h1 id="the-chip-firing-antimatroid">The chip-firing antimatroid</h1>

<p><a href="https://en.wikipedia.org/wiki/Chip-firing_game">Chip-firing games</a>, or <a href="https://en.wikipedia.org/wiki/Abelian_sandpile_model">sandpile models</a>, are systems described by a graph, with markers of some kind such as coins on its vertices. The graph may possibly be directed, although in the simplest examples it is undirected, and it may be infinite. Each vertex may have arbitrarily many coins on it. But, if a vertex has at least as many coins as it has outgoing edges, we can “fire” the vertex, moving one coin to each neighbor. This repeats until no more such events are possible. Doing this on an infinite square grid with an initial state that piles many coins on a single vertex leads to pretty fractals; here’s a detail of <a href="https://commons.wikimedia.org/wiki/File:Sandpile_on_infinite_grid,_3e7_grains.png">the result of starting with 30 million coins</a>:</p>

<p style="text-align: center;"><img alt="Detail of abelian sandpile model on square grid with 3x10^7 starting coins, extracted from CC-BY-SA image https://commons.wikimedia.org/wiki/File:Sandpile_on_infinite_grid,_3e7_grains.png by colt_browning" src="https://11011110.github.io/blog/assets/2021/sandpile-30M-detail.png" width="80%"/></p>

<p>However, we’ll be looking at this sort of system on one-dimensional infinite graphs, where their behavior is not quite as complicated.</p>

<p>Chip-firing, on any graph and any placement of coins for which it terminates, forms an <a href="https://en.wikipedia.org/wiki/Antimatroid">antimatroid</a>.<sup id="fnref:bls"><a class="footnote" href="https://11011110.github.io/blog/2021/06/12/carrying-chip-firing.html#fn:bls" rel="footnote">2</a></sup> <sup id="fnref:k"><a class="footnote" href="https://11011110.github.io/blog/2021/06/12/carrying-chip-firing.html#fn:k" rel="footnote">3</a></sup> A vertex \(v\) can fire for the \(i\)th time, as long as it has already fired \(i-1\) times and a total of \(i\cdot\deg(v)\) coins have reached it. Once these conditions are met, they remain true until \(v\) fires. This idea, that once the item \((v,i)\) becomes available to be added to the sequence of firings it remains available until it is added, is the defining principle of an antimatroid. From it one can prove that, if any firing sequence terminates in a stable configuration, then all sequences terminate, they all fire the same vertices the same numbers of times, and they all end in the same stable configuration.</p>

<h1 id="binary-carrying-as-chip-firing">Binary carrying as chip-firing</h1>

<p>A binary representation of a number \(x\) is just a set of distinct powers of two, summing to \(x\). If you add two binary numbers \(x\) and \(y\), you can combine their sets into a single multiset; carrying can be thought of as a systematic method of getting rid of the duplicate powers of two in this multiset. Whenever you have two equal powers of two in a multiset, whose sum you are trying to represent, you can merge them with the fusion rule</p>

\[2^i+2^i \Rightarrow 2^{i+1}.\]

<p>This can be thought of as a chip-firing game on a graph where there is a vertex for every power of two, an edge to the next larger power of two, and an edge to a “<a href="https://en.wikipedia.org/wiki/Bit_bucket">bit bucket</a>” vertex with no outgoing edges (which cannot be fired). Each instantiation of the fusion rule fires vertex \(2^i\), moving one coin to \(2^{i+1}\) and one to the bit bucket.</p>

<p>This is exactly what we are doing when we carry a term in binary addition: taking two powers of two from a column of the addition problem and fusing them into a single power of two in the next column. We can also think of this physically, using a one-dimensional array of cells with poker chips or coins on them, with a coin on cell \(i\) representing the number \(2^i\). The fusion rule takes two coins from any cell and replaces them by a single coin in the next cell. In binary addition of pairs of numbers, there are at most three coins per cell (the two that started out there and one carry), but you could use the same fusion rule for addition of more than two numbers, using an array of cells that can each contain a large pile of coins.</p>

<p style="text-align: center;"><img alt="Five stacks of coins. Image Money-2180330 1920.jpg on Wikimedia commons, uploaded by Stella Vogt from pixabay free images, described as &quot;probably free&quot; but tagged with a CC-BY-SA license." src="https://11011110.github.io/blog/assets/2021/stacks-of-coins.jpg" style="border-style: solid; border-color: black;" width="80%"/></p>

<p>Carrying the coin analogy further, we might imagine that the coins have values that are powers of two, and that we are making change by replacing pairs of small coins by a single larger coin of equal value.</p>

<p>Conventional binary arithmetic does these fusion steps in a systematic order, from low-order bits of the binary representation (smaller powers of two) to higher-order bits (larger powers of two). It’s that systematic order, together with the observation that each pile has at most three coins, that makes this method suitable for a finite state machine. But actually, you could apply the fusion rule in any order, and it would work equally well. Each step reduces the number of coins by one, so you can never do more steps than your starting number of coins. We can only halt when we reach the binary representation of the sum, which is uniquely determined, so this process is <a href="https://en.wikipedia.org/wiki/Confluence_(abstract_rewriting)">confluent</a>: every sequence of choices leads to the same eventual outcome. In this case, confluence can also be seen from the antimatroid property of chip-firing games.</p>

<p>This observation about reducing the number of powers of two gives an immediate proof of a fact about binary representations that you may not have known: the binary representation of \(x+y\) has at most as many nonzero bits as there are in \(x\) and \(y\) separately.</p>

<h1 id="chip-firing-for-fibonacci-numbers">Chip-firing for Fibonacci numbers</h1>

<p>Now, instead of coins with power-of-two values, let’s suppose that they have Fibonacci numbers as their values, representing any multiset of Fibonacci numbers. We can still combine pairs of Fibonacci numbers by a fusion rule, that now applies when we have two coins in adjacent piles:</p>

\[F_i + F_{i+1} \Rightarrow F_{i+2}.\]

<p>But in order to get the Zeckendorf representation of the sum of the multiset, we also need to deal with pairs of coins that have the same value, because repeated copies of the same Fibonacci number are not allowed in the Zeckendorf representation. We can accomplish this by a “fission” rule, that steps backwards according to the fusion rule in order to take a bigger step forwards:</p>

\[F_i+F_i \Rightarrow F_{i-2}+F_{i-1}+F_i\Rightarrow F_{i-2}+F_{i+1}.\]

<p>This makes sense even when \(F_i\) is \(1\) or \(2\): for \(F_i=1\), the \(F_{i-2}\) term is zero and can be dropped from the sum, and for \(F_i=2\) it equals one, a Fibonacci number. So as special cases of this rule we have \(1+1\Rightarrow 2\) and \(2+2\Rightarrow 1+3\).</p>

<p>Several issues complicate the analysis of this replacement system. First, although fission by itself is a chip-firing rule on an infinite graph with outdegree two, fission and fusion together make a more complicated system that is not an antimatroid, so different orderings of choosing what to do may lead to different numbers of steps. Second, the fission rule changes the piles of coins both to the left and to the right of the pile to which it applies, making it harder to find a consistent ordering in which to apply these rules. And third, fission preserves the number of coins rather than reducing them, making both the eventual termination of the system and the analysis of how many steps it takes less obvious. But assuming it does terminate, it can only terminate at the Zeckendorf representation, which is unique. So termination implies confluence.</p>

<h1 id="fission-without-fusion">Fission without fusion</h1>

<p>First let’s see what happens if we just use the fission rule, forgetting about the fusion rule. Because fission by itself is a chip-firing rule, any initial state has an invariant number of firings and an invariant final state, regardless of the order of operations. For an initial state with \(n\) copies of \(F_i\), the final state gives us an expansion of \(F_i\) into a sum of \(n\) distinct Fibonacci numbers:</p>

\[F_i = F_i\]

\[2\,F_i = F_{i-2}+F_{i+1}\]

\[3\,F_i=F_{i-2}+F_i+F_{i+1}\]

\[4\,F_i=F_{i-4}+F_{i-3}+F_i+F_{i+2}\]

\[\vdots\]

<p>The indexes appearing in these identities can be summarized in a <a href="https://en.wikipedia.org/wiki/Category:Triangles_of_numbers">triangle of numbers</a>:</p>

\[\begin{array}{ccccccc}
&amp;&amp;&amp;&amp;&amp;&amp;0&amp;&amp;&amp;&amp;&amp;&amp;\\
&amp;&amp;&amp;&amp;&amp;-2&amp;&amp;\ 1\ &amp;&amp;&amp;&amp;&amp;\\
&amp;&amp;&amp;&amp;-2&amp;&amp;0&amp;&amp;\ 1\ &amp;&amp;&amp;&amp;\\
&amp;&amp;&amp;-4&amp;&amp;-3&amp;&amp;0&amp;&amp;\ 2\ &amp;&amp;&amp;\\
&amp;&amp;-4&amp;&amp;-3&amp;&amp;-2&amp;&amp;1&amp;&amp;\ 2\ &amp;&amp;\\
&amp;-4&amp;&amp;-3&amp;&amp;-2&amp;&amp;0&amp;&amp;1&amp;&amp;\ 2\ &amp;\\
-6&amp;&amp;-5&amp;&amp;-4&amp;&amp;-3&amp;&amp;-1&amp;&amp;1&amp;&amp;\ 3\ \\
&amp;&amp;&amp;&amp;&amp;&amp;\vdots&amp;&amp;&amp;&amp;&amp;&amp;\\
\end{array}\]

<p>The largest number in each row grows only logarithmically with \(n\), because of the way the values of the Fibonacci numbers grow exponentially as a function of their index. The fission rule cannot create gaps of three or more empty cells,
so consecutive numbers in a row differ by at most three, implying that the smallest number in each row is greater than \(-3n\). Because of this linear bound on how far fission can move the coins, we get a quadratic bound on the total number of firing events: each firing decreases the total distance of the coins from cell \(-3n\). This total distance starts at \(3n^2\) and remains positive, so there can  be at most \(3n^2\) firings. In computational experiments up to \(n=10000\) the actual number of firings never exceeded \(n^2\) and appeared to be growing as \(n^2\bigl(1-o(1)\bigr)\). This is a big contrast from the behavior of the similar-looking chip-firing rule on a line of cells that replaces pairs of coins by a coin one cell to the left and a coin one cell to the right, which (with \(n\) chips starting in a pile on one cell) produces a <a href="https://en.wikipedia.org/wiki/Square_pyramidal_number">square pyramidal number</a> of firings, cubic in \(n\).</p>

<p>For initial coins that are not all in one big pile, it remains impossible for fission to produce new long gaps, and we can decompose the sequence of cells into subsequences of linear length separated by gaps too long to be crossed. The same analysis of total distance of coins from the starts of sequences of cells shows that, regardless of starting state, and even if we also allow fusion rules, we get an \(O(n^2)\) bound on the total number of steps. In particular, this system always terminates.</p>

<h1 id="taking-few-steps">Taking few steps</h1>

<p>Fortunately, we don’t have to take quadratic time to simplify sums of Fibonacci numbers into their Zeckendorf representations using these rules. The problem with the previous analysis was that we were doing too much fission before we did any fusion. Suppose we sidestep that with the following prioritization:</p>

<ul>
  <li>If any fusion step would put a coin into a pile that is currently empty, do it.</li>
  <li>Otherwise, perform a fission step at the pile with the largest possible index.</li>
</ul>

<p>If any fusion steps are possible, there must be at least one (for instance, the one with the largest index) that is prioritized. To analyze these prioritized steps, define \(N\) to be the current number of coins, and \(M\) to be the number of coins that are at or below a pile with two or more coins on it. The key insight is that whenever a step moves a coin to a pile with a larger index, it cannot form a new larger-index multi-coin pile, so both \(M\) and \(N\) are non-decreasing. They can stay the same only for a fission step at a pile of three or more coins, but in that case the next step must be a fusion. \(M\) and \(N\) are both \(\le n\), and their sum decreases at least once for every two steps, so the total number of steps is \(\le 4n\). Thus, this prioritized chip-firing method can reduce any sum of Fibonacci numbers to its Zeckendorf representation in a linear number of steps. It’s also not difficult to implement so that it takes linear time.</p>

<h1 id="zeckendorf-arithmetic">Zeckendorf arithmetic</h1>

<p>Anyway, now that we have a way of simplifying sums of Fibonacci numbers to their Zeckendorf form, let’s use it for arithmetic on Zeckendorf representations, without the need to reduce them to simpler forms.</p>

<p>First, addition. This is very easy: Add the two Zeckendorf representations as multisets (producing piles of coins that might be adjacent, or might have two coins in them) and then simplify. The result is a linear time for adding two Zeckendorf representations, as was already known. But because it isn’t based on finite state machines, it can also handle more than two coins, for instance by adding multiple numbers at once rather than having to reduce the problem to multiple pairwise additions. As with binary arithmetic, the chip-firing method gives a quick proof of a non-obvious fact: the Zeckendorf representation of \(x+y\) has at most as many nonzero terms as there are in \(x\) and \(y\) put together.</p>

<p>It’s also possible to use this technique (or really, any linear-time Zeckendorf addition algorithm) as part of a long multiplication algorithm for Zeckendorf representations. To multiply two numbers \(x\) and \(y\), both given by their Zeckendorf representations, first perform a sequence of additions to compute the representations of the numbers \(F_i\cdot x\), each computed as \((F_{i-1}\cdot x)+(F_{i-2}\cdot x)\) in a single addition from earlier numbers in the sequence. Then pick out the subset of these representations for which \(F_i\) belongs to the Zeckendorf representation of \(y\), and add them together. (Or interleave the computation of \(F_i\cdot x\) and the sum of these representations, to save space.) The total time for \(\ell\)-bit inputs is \(O(\ell^2)\), as it is for the usual long multiplication algorithm. I’m using the different variable \(\ell\), because the time here is a function of all the bits in the input Zeckendorf representation, rather than just the number of nonzero bits.</p>

<p>You can convert a binary number to Zeckendorf with the same idea, computing the sequence of powers of two and then picking out and adding together the subset of these powers used in the binary representation of the input. In the other direction, you can convert a Zeckendorf representation to binary by computing the Fibonacci sequence in binary, picking out the terms from the given Zeckendorf representation, and adding them. Both directions of conversion take time \(O(\ell^2)\). A recent paper by Sergeev shows how to do these conversions much more efficient, only logarithmically slower than binary-number multiplication.<sup id="fnref:s"><a class="footnote" href="https://11011110.github.io/blog/2021/06/12/carrying-chip-firing.html#fn:s" rel="footnote">4</a></sup> Based on Sergeev’s results it would also be much more efficient (in theory at least, if not necessarily in practice) to multiply Zeckendorf representations by converting to binary, multiplying in binary, and converting back.</p>

<p>As the article I linked at the start hints, the direct algorithms described here are a bit unsatisfactory from the point of view of circuit complexity: the circuit size is ok but the circuit depth is much larger than it would be for binary arithmetic. I’m not convinced that this is a serious deficiency, because we’re not likely to build computers that use this arithmetic at the circuit level. Any algorithms like this are more likely to be used only in specialized situations where Zeckendorf arithmetic is relevant, like the analysis of certain combinatorial games.</p>

<div class="footnotes">
  <ol>
    <li id="fn:a">
      <p>Connor Ahlbach, Jeremy Usatine, Christiane Frougny, and Nicholas Pippenger (2013), “Efficient algorithms for Zeckendorf arithmetic”, <em>Fibonacci Quarterly</em> 51 (3): 249–255, <a href="https://arxiv.org/abs/1207.4497">arXiv:1207.4497</a>, <a href="https://www.ams.org/mathscinet-getitem?mr=3093678">MR3093678</a>. <a class="reversefootnote" href="https://11011110.github.io/blog/2021/06/12/carrying-chip-firing.html#fnref:a">↩</a></p>
    </li>
    <li id="fn:bls">
      <p>Anders Björner, László Lovász, and Peter Shor (1991), “Chip-firing games on graphs”, <em>European Journal on Combinatorics</em> 12 (4): 283–291, <a href="https://doi.org/10.1016/S0195-6698(13)80111-4">doi:10.1016/S0195-6698(13)80111-4</a>, <a href="https://www.ams.org/mathscinet-getitem?mr=1120415">MR1120415</a>. <a class="reversefootnote" href="https://11011110.github.io/blog/2021/06/12/carrying-chip-firing.html#fnref:bls">↩</a></p>
    </li>
    <li id="fn:k">
      <p>Kolja Knauer (2009), “Chip-firing, antimatroids, and polyhedra”, EuroComb 2009, <em>Electronic Notes in Discrete Mathematics</em> 34: 9–13, <a href="https://doi.org/10.1016/j.endm.2009.07.002">doi:10.1016/j.endm.2009.07.002</a>, <a href="https://www.ams.org/mathscinet-getitem?mr=2591410">MR2591410</a>. <a class="reversefootnote" href="https://11011110.github.io/blog/2021/06/12/carrying-chip-firing.html#fnref:k">↩</a></p>
    </li>
    <li id="fn:s">
      <p>I. S. Sergeev (2018), “On the complexity of Fibonacci coding”, <em>Problems of Information Transmission</em> 54: 343–350, <a href="https://doi.org/10.1134/S0032946018040038">doi:10.1134/S0032946018040038</a>, <a href="https://www.ams.org/mathscinet-getitem?mr=3917588">MR3917588</a>. <a class="reversefootnote" href="https://11011110.github.io/blog/2021/06/12/carrying-chip-firing.html#fnref:s">↩</a></p>
    </li>
  </ol>
</div>

<p>(<a href="https://mathstodon.xyz/@11011110/106399026271211456">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2021-06-12T10:47:00Z</updated>
    <published>2021-06-12T10:47:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2021-06-16T06:33:12Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://grigory.github.io/blog/theory-jobs-2021</id>
    <link href="http://grigory.github.io/blog/theory-jobs-2021/" rel="alternate" type="text/html"/>
    <title xml:lang="en">Theory Jobs 2021</title>
    <content type="xhtml" xml:lang="en"><div xmlns="http://www.w3.org/1999/xhtml"><p>While in theory bipartite matching should be easy, it has been observed in practice that real instances of matching theoreticians with jobs are hard. It’s been a particularly unusual year with the entire cycle going virtual. Congrats to matched vertices on both sides!</p>

<p><a href="https://docs.google.com/spreadsheets/d/1kobGLgx5QgJb9AvDENg5c8wEbwBUUkVlMTsBV9quEEY/edit?usp=sharing">Here is a link</a> to a crowdsourced spreadsheet created to collect information about theory hires this year. 
I put in a biased pseudorandom seed, please help populate and share!
Rules for the spreadsheet have been copied from previous years and all edits to the document are anonymized. Please, feel free to contact me directly or post a comment if you have any suggestions about the rules.</p>
<ul>
 <li>You are welcome to add yourself, or people your department has hired. </li>
 <li>Separate sheets for faculty, industry and postdocs/visitors. </li>
 <li>Hires should be connected to theoretical computer science, broadly defined.</li>
 <li>Only add jobs that you are <b>absolutely sure have been offered and accepted</b>. This is not the place for speculation and rumors. Please, be particularly careful when adding senior hires (people who already have an academic or industrial job) -- end dates of their current positions might be still in the future. </li>
</ul>


  <p><a href="http://grigory.github.io/blog/theory-jobs-2021/">Theory Jobs 2021</a> was originally published by Grigory Yaroslavtsev at <a href="http://grigory.github.io/blog">The Big Data Theory</a> on June 12, 2021.</p></div>
    </content>
    <updated>2021-06-12T00:00:00Z</updated>
    <published>2021-06-12T00:00:00Z</published>
    <author>
      <name>Grigory Yaroslavtsev</name>
      <email>grigory@grigory.us</email>
      <uri>http://grigory.github.io/blog</uri>
    </author>
    <source>
      <id>http://grigory.github.io/blog/</id>
      <author>
        <name>Grigory Yaroslavtsev</name>
        <email>grigory@grigory.us</email>
        <uri>http://grigory.github.io/blog/</uri>
      </author>
      <link href="http://grigory.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="http://grigory.github.io/blog" rel="alternate" type="text/html"/>
      <title xml:lang="en">The Big Data Theory</title>
      <updated>2021-06-12T17:03:49Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=8133</id>
    <link href="https://windowsontheory.org/2021/06/11/causality-and-fairness/" rel="alternate" type="text/html"/>
    <title>Causality and Fairness</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Scribe notes by Junu Lee, Yash Nair, and Richard Xu. Previous post: Toward a theory of generalization learning Next post: TBD. See also all seminar posts and course webpage. lecture slides (pdf) – lecture slides (Powerpoint with animation and annotation) – video Much of the material on causality is taken from the wonderful book by … <a class="more-link" href="https://windowsontheory.org/2021/06/11/causality-and-fairness/">Continue reading <span class="screen-reader-text">Causality and Fairness</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><em>Scribe notes by Junu Lee, Yash Nair, and <a href="https://github.com/rxu18">Richard Xu</a>.</em></p>



<p><strong>Previous post:</strong> <a href="https://windowsontheory.org/2021/04/24/towards-a-theory-of-generalization-in-reinforcement-learning-guest-lecture-by-sham-kakade/">Toward a theory of generalization learning</a> <strong>Next post:</strong> TBD. </p>



<p>See also <a href="https://windowsontheory.org/category/ml-theory-seminar/">all seminar posts</a> and <a href="https://boazbk.github.io/mltheoryseminar/cs229br.html#plan">course webpage</a>.</p>



<p><a href="http://files.boazbarak.org/misc/mltheory/ML_seminar_lecture_6.pdf">lecture slides (pdf)</a> – <a href="http://files.boazbarak.org/misc/mltheory/ML_seminar_lecture_6.pptx">lecture slides (Powerpoint with animation and annotation)</a> – <a href="https://harvard.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=87a43259-6b47-49f1-931f-acfa0177fe20">video</a></p>



<p>Much of the material on causality is taken from the wonderful <a href="https://mlstory.org/">book by Hardt and Recht</a>.</p>



<p>For fairness, a central source was the <a href="https://fairmlbook.org/">book in preparation by Barocas, Hardt, and Narayanan</a> as well as the related <a href="https://fairmlbook.org/tutorial1.html">NeurIPS 2017 tutorial</a>, and other papers mentioned below.</p>



<h1>Causality</h1>



<p>We may have heard that <strong>“correlation does not imply causation”</strong>. How can we mathematically represent this statement, and furthermore differentiate the two rigorously?</p>



<p>Roughly speaking, <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> are correlated if <img alt="P(B=b|A=a)" class="latex" src="https://s0.wp.com/latex.php?latex=P%28B%3Db%7CA%3Da%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is different for different values of <img alt="a" class="latex" src="https://s0.wp.com/latex.php?latex=a&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. To represent causation, we change the second part of the formula: <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> causes <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> if <em>intervening</em> to change <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> to some value <img alt="a" class="latex" src="https://s0.wp.com/latex.php?latex=a&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> changes the probability of <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. That is,</p>



<p><img alt="Pr(B=b|\text{ do }A\leftarrow a)" class="latex" src="https://s0.wp.com/latex.php?latex=Pr%28B%3Db%7C%5Ctext%7B+do+%7DA%5Cleftarrow+a%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>depends on <img alt="a" class="latex" src="https://s0.wp.com/latex.php?latex=a&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>.</p>



<h2>Example of Causality</h2>



<p>Suppose we have the random variables <img alt="X,W,H" class="latex" src="https://s0.wp.com/latex.php?latex=X%2CW%2CH&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> (taken over choice of a random person), which represent e<strong>X</strong>ercising, being over<strong>W</strong>eight and having <strong>H</strong>eart disease, respectively. We put forth the following (hypothetical! this is not medical advice!) scenarios for their relationships:</p>



<p><strong>Scenario 1.</strong> <img alt="X\sim Bern(1/2)" class="latex" src="https://s0.wp.com/latex.php?latex=X%5Csim+Bern%281%2F2%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. Now <img alt="W" class="latex" src="https://s0.wp.com/latex.php?latex=W&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, the overweight indicator, follows the causal relation:</p>



<p><img alt="W \sim \begin{cases} 0 &amp; \text{if } X = 1\\ Bern(1/2) &amp; \text{if } X=0\end{cases}" class="latex" src="https://s0.wp.com/latex.php?latex=W+%5Csim+%5Cbegin%7Bcases%7D+0+%26+%5Ctext%7Bif+%7D+X+%3D+1%5C%5C+Bern%281%2F2%29+%26+%5Ctext%7Bif+%7D+X%3D0%5Cend%7Bcases%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>and the heart disease indicator <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> follows the same rule</p>



<p><img alt="H \sim \begin{cases} 0 &amp; \text{if } X = 1\\ Bern(1/2) &amp; \text{if } X=0\end{cases}" class="latex" src="https://s0.wp.com/latex.php?latex=H+%5Csim+%5Cbegin%7Bcases%7D+0+%26+%5Ctext%7Bif+%7D+X+%3D+1%5C%5C+Bern%281%2F2%29+%26+%5Ctext%7Bif+%7D+X%3D0%5Cend%7Bcases%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>So, in this scenario, exercise prevents heart disease and being overweight, while if we don’t exercise, we may be overweight or suffer from heart disease with probability 1/2 independently..</p>



<p><strong>Scenario 2.</strong> <img alt="W\sim Bern(1/4)" class="latex" src="https://s0.wp.com/latex.php?latex=W%5Csim+Bern%281%2F4%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p><img alt="X\sim \begin{cases} 0 &amp; \text{if } W= 1\\ Bern(2/3) &amp; \text{if } W=0 \end{cases}" class="latex" src="https://s0.wp.com/latex.php?latex=X%5Csim+%5Cbegin%7Bcases%7D+0+%26+%5Ctext%7Bif+%7D+W%3D+1%5C%5C+Bern%282%2F3%29+%26+%5Ctext%7Bif+%7D+W%3D0+%5Cend%7Bcases%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>and <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> still depends on <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> in the same rule in the previous scenario. So, in this scenario, people are naturally prone to being overweight with probability 1/4, and being overweight makes you less likely to exercise, rather than the causal relation being in the other way around. As before, exercise prevents heart disease, and someone who did not exercise will get heart disease with probability 1/2.</p>



<p>We find that in scenario 1, <img alt="P(W=1|X=0)=1/2" class="latex" src="https://s0.wp.com/latex.php?latex=P%28W%3D1%7CX%3D0%29%3D1%2F2&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. In scenario 2,</p>



<p><img alt="P(W=1|X=0)=\frac{P(W=1)P(X=0|W=1)}{P(X=0)}=\frac{\frac14\cdot 1}{\frac14+\frac34\frac13}=\frac12." class="latex" src="https://s0.wp.com/latex.php?latex=P%28W%3D1%7CX%3D0%29%3D%5Cfrac%7BP%28W%3D1%29P%28X%3D0%7CW%3D1%29%7D%7BP%28X%3D0%29%7D%3D%5Cfrac%7B%5Cfrac14%5Ccdot+1%7D%7B%5Cfrac14%2B%5Cfrac34%5Cfrac13%7D%3D%5Cfrac12.&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>In fact, as this table shows, the probabilities for all combinations of <img alt="X,W,H" class="latex" src="https://s0.wp.com/latex.php?latex=X%2CW%2CH&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> are identical in the two scenarios!</p>



<figure class="wp-block-image"><img alt="" src="https://i.imgur.com/HGYQ4eh.png"/></figure>



<p>Now, consider the intervention of setting <img alt="X=0" class="latex" src="https://s0.wp.com/latex.php?latex=X%3D0&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, i.e. stop exercising. That is, we change the generating model for <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> to be <img alt="X:=0" class="latex" src="https://s0.wp.com/latex.php?latex=X%3A%3D0&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. In scenario 1, <img alt="P(W=1|\text{ do }X=0)" class="latex" src="https://s0.wp.com/latex.php?latex=P%28W%3D1%7C%5Ctext%7B+do+%7DX%3D0%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is still <img alt="1/2" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F2&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. In scenario 2, <img alt="X=0" class="latex" src="https://s0.wp.com/latex.php?latex=X%3D0&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> tells us nothing about <img alt="W" class="latex" src="https://s0.wp.com/latex.php?latex=W&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> now so we get <img alt="P(W=1|\text{ do }X=0)=1/4" class="latex" src="https://s0.wp.com/latex.php?latex=P%28W%3D1%7C%5Ctext%7B+do+%7DX%3D0%29%3D1%2F4&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. Now that we added in an intervention, the two scenarios are different!</p>



<p>This is an example of why <strong>correlations are not causations</strong>: while the conditional probabilities <img alt="\Pr( W=1 |X=0)" class="latex" src="https://s0.wp.com/latex.php?latex=%5CPr%28+W%3D1+%7CX%3D0%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> identical in the two scenarios, the causal probabilities are diffent <img alt="P(W=1|\text{ do }X=0)" class="latex" src="https://s0.wp.com/latex.php?latex=P%28W%3D1%7C%5Ctext%7B+do+%7DX%3D0%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>.</p>



<figure class="wp-block-image"><img alt="" src="https://i.imgur.com/LGEGtvR.png"/></figure>



<p><strong><span class="has-inline-color" style="color: #a30000;">NOTE:</span></strong> Working out this example,  and understanding <strong>(a)</strong> why the two scenarios induce identical probabilities, and in particular all conditional probabilities are identical and <strong>(b)</strong> why the causal probabilities differ from the conditional probabilities in Scenario 2, is a great way to get intuition for causality and its pitfalls.</p>



<h2>Causal Probabilities and confounders</h2>



<p>Consider Scenario 1, where the causal structure is as follows:</p>



<figure class="wp-block-image"><img alt="" src="https://i.imgur.com/FJlQyaO.png"/></figure>



<p>Looking at the table above, we see that the unconditional probability <img alt="P(H=1)" class="latex" src="https://s0.wp.com/latex.php?latex=P%28H%3D1%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> equals <img alt="1/4" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F4&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. Since in this scenario, there is no causal relation between being overweight and suffering from heat disease, the causal probability  <img alt="P(H=1 | \text{ do } W \leftarrow 0)" class="latex" src="https://s0.wp.com/latex.php?latex=P%28H%3D1+%7C+%5Ctext%7B+do+%7D+W+%5Cleftarrow+0%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>  is also equal to  <img alt="1/4" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F4&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>.</p>



<p>However, we can calculate the conditional probability from the table and see that <img alt="P(H=1|W=0)=1/6" class="latex" src="https://s0.wp.com/latex.php?latex=P%28H%3D1%7CW%3D0%29%3D1%2F6&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>.<br/>That means that even though in this scenario, there is no causal relation between being overweight and getting heart disease, conditioning on not being overweight reduces the probability of getting heart disease.<br/>Once again we see here a <strong>gap</strong> between the <strong>conditional </strong>and <strong>causal</strong> probabilities.</p>



<p>The reason is for this gap is that there is a <strong>counfounding variable</strong>, namely <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> that is a common cause of both <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and <img alt="W" class="latex" src="https://s0.wp.com/latex.php?latex=W&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>.</p>



<p><strong>Definition:</strong> <img alt="H,W" class="latex" src="https://s0.wp.com/latex.php?latex=H%2CW&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> are <em>confounded</em> if there are values <img alt="h,w" class="latex" src="https://s0.wp.com/latex.php?latex=h%2Cw&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> such that</p>



<p><img alt="P(H=h|\text{ do }W=w)\neq P(H=h|W=e)," class="latex" src="https://s0.wp.com/latex.php?latex=P%28H%3Dh%7C%5Ctext%7B+do+%7DW%3Dw%29%5Cneq+P%28H%3Dh%7CW%3De%29%2C&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>To fix the effect of a confounder, we condition on <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. It also allows us to find the probability of an intervention. The general <strong>deconfounding formula</strong> is</p>



<p><img alt="P(H=h|\text{ do }W=w)=\sum_x P(H=h|W=w, X=x) P(X=x)\;\;" class="latex" src="https://s0.wp.com/latex.php?latex=P%28H%3Dh%7C%5Ctext%7B+do+%7DW%3Dw%29%3D%5Csum_x+P%28H%3Dh%7CW%3Dw%2C+X%3Dx%29+P%28X%3Dx%29%5C%3B%5C%3B&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>   (★),</p>



<p>where <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> ranges over all the immediate causes of <img alt="W" class="latex" src="https://s0.wp.com/latex.php?latex=W&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>.</p>



<p>Contrast this with the formula for computing the conditional probability which is</p>



<p><img alt="P(H=h | W=w) = \sum_x P(H=h | W=w, X=x) P(X=x | W=w)" class="latex" src="https://s0.wp.com/latex.php?latex=P%28H%3Dh+%7C+W%3Dw%29+%3D+%5Csum_x+P%28H%3Dh+%7C+W%3Dw%2C+X%3Dx%29+P%28X%3Dx+%7C+W%3Dw%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>Using the deconfounding formula (★) requires <strong>(a)</strong> knowing the causal graph, and <strong>(b)</strong> observing the confounders. If we get this wrong and control for the wrong confounders we can get the causal probabilities wrong, as demonstrated by the following example.</p>



<p><br/>One way to describe causality theory is that it aims to clarify the situations under which <strong>correlation does in fact equal causation</strong> (i.e., the <strong>conditional probabilities are equal to the causal probabilities</strong>), and how (by appropriately controlling for confounders) we can get to such a situation.</p>



<p><strong>Example (two diseases)</strong> Consider the diagram below where there are two diseases <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and <img alt="Y" class="latex" src="https://s0.wp.com/latex.php?latex=Y&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> such that each occurs independently with probability <img alt="p" class="latex" src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. We assume each will send you to the hospital (variable <img alt="Z" class="latex" src="https://s0.wp.com/latex.php?latex=Z&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>) and those are the only reason to arrive at the hospital.</p>



<p>If you control for <img alt="Z" class="latex" src="https://s0.wp.com/latex.php?latex=Z&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> (i.e look at only people who went to the hospital), we find that the probabilities are now correlated: A priori the probability is <img alt="p/(2p-p^2)\approx 1/2" class="latex" src="https://s0.wp.com/latex.php?latex=p%2F%282p-p%5E2%29%5Capprox+1%2F2&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, and conditioned on <img alt="X=1" class="latex" src="https://s0.wp.com/latex.php?latex=X%3D1&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, the probability is <img alt="p^2/p=p &lt;1/2" class="latex" src="https://s0.wp.com/latex.php?latex=p%5E2%2Fp%3Dp+%3C1%2F2&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>.</p>



<figure class="wp-block-image"><img alt="" src="https://i.imgur.com/9mETSEo.png"/></figure>



<p>This relates to the joke “the probability of having 2 bombs on a plane is very low, so if I bring a bomb then it is very unlikely that there will be another bomb.”</p>



<p>In general, the causal graph can look as one of the following shapes:</p>



<figure class="wp-block-image"><img alt="" src="https://i.imgur.com/ARygORn.png"/></figure>



<p>If <img alt="Z" class="latex" src="https://s0.wp.com/latex.php?latex=Z&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is a fork then controlling for <img alt="Z" class="latex" src="https://s0.wp.com/latex.php?latex=Z&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> can tease out the causal relation. If <img alt="Z" class="latex" src="https://s0.wp.com/latex.php?latex=Z&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is a mediator or collider then controlling for <img alt="Z" class="latex" src="https://s0.wp.com/latex.php?latex=Z&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> can actually make things worse. –&gt;</p>



<p><strong>Backdoor paths:</strong> If <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and <img alt="Y" class="latex" src="https://s0.wp.com/latex.php?latex=Y&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> are two random variables, we say that there is a “backdoor path” from <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> to <img alt="Y" class="latex" src="https://s0.wp.com/latex.php?latex=Y&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> if there is direct ancestor <img alt="Z" class="latex" src="https://s0.wp.com/latex.php?latex=Z&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> of <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> that is connected in the undirected version of the causal graph in a path not going through <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>.</p>



<figure class="wp-block-image"><img alt="" src="https://i.imgur.com/n45KXt9.png"/></figure>



<p>We can show the following theorem:</p>



<p><strong>Theorem:</strong> If there is no backdoor path then <img alt="P(Y=y | \text{ do } X \leftarrow X) = P(Y=y|X=x)" class="latex" src="https://s0.wp.com/latex.php?latex=P%28Y%3Dy+%7C+%5Ctext%7B+do+%7D+X+%5Cleftarrow+X%29+%3D+P%28Y%3Dy%7CX%3Dx%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>Here is a “proof by picture”:</p>



<figure class="wp-block-image"><img alt="" src="https://i.imgur.com/UAC2lWE.png"/></figure>



<p>If there isn’t a backdoor path, we sort the graph in topological order, so that all the events that happen before <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> are not connected to <img alt="Y" class="latex" src="https://s0.wp.com/latex.php?latex=Y&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> except through <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. So we can first generate all the variables <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> that result in <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. Then the probability distribution of the events <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> between <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and <img alt="Y" class="latex" src="https://s0.wp.com/latex.php?latex=Y&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> only depends on the value <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> of <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, and so similarly <img alt="Y" class="latex" src="https://s0.wp.com/latex.php?latex=Y&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is generated from some probability distribution that only depends on <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>.</p>



<h2>Experimental Design</h2>



<p>When we design experiments, we often want to estimate <em>causal effects</em>, and to do so we try to make sure we eliminate backdoor paths.<br/>Consider the example of a COVID vaccine trial.<br/>We let <img alt="V=1" class="latex" src="https://s0.wp.com/latex.php?latex=V%3D1&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> be the event that a trial participant obtained a vaccine, and <img alt="C=1" class="latex" src="https://s0.wp.com/latex.php?latex=C%3D1&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> be the event that the participant was infected with COVID.<br/>We want to figure out <img alt="P(C=1|\text{ do }V=1)" class="latex" src="https://s0.wp.com/latex.php?latex=P%28C%3D1%7C%5Ctext%7B+do+%7DV%3D1%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>.<br/>However, there is a “backdoor path”.<br/>You will not get the vaccine if you don’t participate in the trial (which we denote by <img alt="V=1" class="latex" src="https://s0.wp.com/latex.php?latex=V%3D1&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>), but particpating in the trial could change your behavior and hence have a causal effect on <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>.</p>



<p>To fix this we can cut the backdoor path using a placebo: it cuts the backward path by removing the confounding variable of participation, since it ensure that (conditioning on <img alt="P=1" class="latex" src="https://s0.wp.com/latex.php?latex=P%3D1&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>), <img alt="V" class="latex" src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is now an independent variable from any behavioral changes that might impact <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>.</p>



<figure class="wp-block-image"><img alt="" src="https://i.imgur.com/TfH4Bzn.png"/></figure>



<h2>Conditioning</h2>



<p>In general, how does conditioning on some variable <img alt="Z" class="latex" src="https://s0.wp.com/latex.php?latex=Z&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> affect correlations? It may introduce correlations in events that occur before <img alt="Z" class="latex" src="https://s0.wp.com/latex.php?latex=Z&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, but cuts any path that depends on <img alt="Z" class="latex" src="https://s0.wp.com/latex.php?latex=Z&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>.<br/><img alt="" src="https://i.imgur.com/Qk5p0s7.png"/></p>



<h2>Average Treatment Effect and Propensity Score</h2>



<p>Suppose we have some treatment variable <img alt="T" class="latex" src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> that we don’t get to control (e.g. in a natural experiment). Let <img alt="Y_t = Y| \text{ do } T=t" class="latex" src="https://s0.wp.com/latex.php?latex=Y_t+%3D+Y%7C+%5Ctext%7B+do+%7D+T%3Dt&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> , and we hope to estimate <img alt="E(Y_1)-E(Y_0)" class="latex" src="https://s0.wp.com/latex.php?latex=E%28Y_1%29-E%28Y_0%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> which is known as the the <strong>treatment effect</strong>.<br/>However, we worry that some underlying variable <img alt="Z" class="latex" src="https://s0.wp.com/latex.php?latex=Z&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> (e.g. healthy lifestyle) can affect both <img alt="Y" class="latex" src="https://s0.wp.com/latex.php?latex=Y&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and <img alt="T" class="latex" src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>.</p>



<p>The <em>propensity score</em>, defined as <img alt="e(z)=E(T|Z=z)" class="latex" src="https://s0.wp.com/latex.php?latex=e%28z%29%3DE%28T%7CZ%3Dz%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, allows us to calculate <img alt="E(Y|\text{ do T}=1)" class="latex" src="https://s0.wp.com/latex.php?latex=E%28Y%7C%5Ctext%7B+do+T%7D%3D1%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. We claim that as long as <img alt="Z" class="latex" src="https://s0.wp.com/latex.php?latex=Z&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is a valid confounder (for which the formula (★) holds)</p>



<p><img alt="E(Y|\text{ do T}=1)=E(YT/e(Z))." class="latex" src="https://s0.wp.com/latex.php?latex=E%28Y%7C%5Ctext%7B+do+T%7D%3D1%29%3DE%28YT%2Fe%28Z%29%29.&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>The proof is obtained by expanding out the claim, see below</p>



<figure class="wp-block-image"><img alt="" src="https://i.imgur.com/gyKYlZn.png"/></figure>



<p>Intuitively, knowing the probability that different groups of people get treatment allows us to make <img alt="T" class="latex" src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> independent from <img alt="(Y_0,Y_1)" class="latex" src="https://s0.wp.com/latex.php?latex=%28Y_0%2CY_1%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and calculate the treatment effect.</p>



<p><strong>Calculating treatment effect using ML.</strong> Suppose that the treatment effect is <img alt="\tau" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctau&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and <img alt="Y=\psi(Z)+\tau T+\text{ noise}" class="latex" src="https://s0.wp.com/latex.php?latex=Y%3D%5Cpsi%28Z%29%2B%5Ctau+T%2B%5Ctext%7B+noise%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. Now, if we learn a model <img alt="f(z)\approx E(Y|Z=z)" class="latex" src="https://s0.wp.com/latex.php?latex=f%28z%29%5Capprox+E%28Y%7CZ%3Dz%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, then</p>



<p><img alt="Y-f(z)\approx \tau(T-e(z))." class="latex" src="https://s0.wp.com/latex.php?latex=Y-f%28z%29%5Capprox+%5Ctau%28T-e%28z%29%29.&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>Since both <img alt="Y-f(z)" class="latex" src="https://s0.wp.com/latex.php?latex=Y-f%28z%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and <img alt="T-e(z)" class="latex" src="https://s0.wp.com/latex.php?latex=T-e%28z%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> are calculable, we only need to do a linear regression.</p>



<h2>Instrumental Variables</h2>



<p>When we cannot observe the counfounding variable, we can still sometimes use <em>instrumental variables</em> to estimate a causal effect.</p>



<figure class="wp-block-image"><img alt="" src="https://i.imgur.com/XHo3Q5e.png"/></figure>



<p>Assume a linear model <img alt="Y=\tau T+f(W)" class="latex" src="https://s0.wp.com/latex.php?latex=Y%3D%5Ctau+T%2Bf%28W%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, where <img alt="W" class="latex" src="https://s0.wp.com/latex.php?latex=W&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is the stuff we don’t observe. If <img alt="Z" class="latex" src="https://s0.wp.com/latex.php?latex=Z&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is some variable that satisfies <img alt="Cov(Z,f(W))=0" class="latex" src="https://s0.wp.com/latex.php?latex=Cov%28Z%2Cf%28W%29%29%3D0&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> then</p>



<p><img alt="\tau=\frac{Cov(Z,Y)}{Cov(Z,T)}," class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctau%3D%5Cfrac%7BCov%28Z%2CY%29%7D%7BCov%28Z%2CT%29%7D%2C&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>which is the ratio between two observable quantities.</p>



<h1>Fairness</h1>



<p>We focus on fairness in classification problems, rather than fairness in learning generative models or representation (which also have their own issues, see in particular <a href="https://dl.acm.org/doi/10.1145/3442188.3445922">this paper</a> by Bender, Gebru, McMillan-Major, and “Shmitchell”).</p>



<p>In the public image, AI has been perceived to be very successful for some tasks, and some people might hope that it is more “objective” or “impartial” than human decisions which are known to be <a href="https://www.nber.org/papers/w9873">fraught with bias</a>). However, there are some works suggesting this might not be the case:</p>



<ul><li>Usage in prediciting recidivism for bail decisions. For example in ProPublica <a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing">Angwin, Larson, Mattu, and Kirchner</a> showed that 44.9% of African Americans who didn’t reoffend were labeled higher risk, whereas only 23.5% of white defendants who didn’t reoffend were labeled as such.</li><li>Machine vision can sometimes work better on some segments of population than others. For example, <a href="http://gendershades.org/">Buolamwini and Gebrue</a> showed that some “gender classifiers” achieve 99.7% accuracy on white men but only 65.3% accuracy (not much better than coin toss) on black women.</li><li><a href="https://rss.onlinelibrary.wiley.com/doi/full/10.1111/j.1740-9713.2016.00960.x">Lum and Isaac</a> gave an example of a “positive feedback loop” in predictive policing in Oakland, CA. While drug use is fairly uniform across the city, the arrests are centered on particular neighborhood (that have more minority residents). In predictive policing, more police would be sent out to the places where arrests occured, hence only exercabating this disparate treatment.</li></ul>



<p>Drug use in Oakland:<br/><img alt="" src="https://i.imgur.com/nrH0dEy.png"/></p>



<p>Drug arrests in Oakland:</p>



<figure class="wp-block-image"><img alt="" src="https://i.imgur.com/hIvgmEK.png"/></figure>



<p>While algorithms can sometimes also help, the populations they help might not be distributed equally. For example, see this table from <a href="https://www.tandfonline.com/doi/abs/10.1080/10511482.2002.9521447">Gates, Perry and Zorn</a>. A more accurate underwriting model (that can better predict the default probability) enables a lender to use a more agressive risk cut off and so end up lending to more people.</p>



<figure class="wp-block-image"><img alt="" src="https://i.imgur.com/xxms8Jk.png"/></figure>



<p>However, this is true within each subpopulation too, so it may be that if the model is less accurate in a certain subpopulation, then a profit-maximizing lender will unfairly offer fewer loans to this subpopulation.</p>



<h2>Formalizing Unfairness</h2>



<p>In the case of employment discrimination in the U.S., we have the following components:</p>



<ul><li>Protected class<ul><li>categories such as race, sex, nationality, citizenship, veteran status, etc.</li></ul></li><li>An unfairness metric, measuring either:<ul><li>disparate treatment</li><li>disparate impact.</li></ul></li></ul>



<p>Employers are not allowed to discriminate across protected classes when hiring. The unfairness metric gives us a way to measure if there is discrimination with respected to a protected class. In particular, disparate impacts across different protected classes is often <em>necessary</em> but <em>not sufficient</em> evidence of discrimination.</p>



<h2>Algorithms for Fairness: an Example</h2>



<p>To see why algorithms, which at first glance seem agnostic to group membership, may exhibit disparate treatment or impact, we consider the following <a href="https://research.google.com/bigpicture/attacking-discrimination-in-ml/">Google visualization by Wattenberg, Viégas, and Hardt</a>.</p>



<p>Consider a blue population and an orange population for which there is no difference in the probability of a member of either population paying back the loan, but for which our model has different accuracies—in particular, the model is more accurate on the orange population. This is described by the plot below, in which the scores correspond to the model’s prediction of the probability of paying back the loan and opaque circles correspond to those who actually do not pay back the loan, whereas filled in circles correspond to those who do.</p>



<figure class="wp-block-image"><img alt="" src="https://i.imgur.com/BEy6yqi.png"/></figure>



<p>Suppose we are in charge of making a lending decision given the model prediction.<br/>A scenario in which we give everyone a loan would be fair, but would be bad us —we would go bankrupt!</p>



<p>Profit when giving everyone a loan:</p>



<figure class="wp-block-image"><img alt="" src="https://i.imgur.com/1uCdp2Q.png"/></figure>



<p>If we wanted to <strong>maximize profit</strong>, we would, however, give more loans to the orange population (since we’re more sure about which members of the orange population would actually pay back their loans) by setting a lower threshold (in terms of the score given by our algorithm) above which we give out loans.</p>



<figure class="wp-block-image"><img alt="" src="https://i.imgur.com/Njtg1FU.png"/></figure>



<p>This maximizes profit but is blatantly unfair. We are treating the identical blue and orange groups differently, just because our model is more accurate on one than the other, and we also have disparate impact on the two groups. A non-defaulting applicant would be 78% likely to get a loan if they are a member of the orange group, but only 60% likely to get a loan if they are a member of the orange group.</p>



<p>This “profit maximization” is likely the end result of any sufficiently complex lending algorithm in the absence of a fairness intervention. Even if the algorithm does not explicitly rely on the group membership attribute, by simply optimizing it to maximize profit, it may well pick up on attributes that are correlated with group membership.</p>



<p>Suppose on the other hand that we wanted to mandate “equal treatment” in the sense of keeping the same thresholds for the blue and orange group. The result would be the following:</p>



<figure class="wp-block-image"><img alt="" src="https://i.imgur.com/c13O4Ly.png"/></figure>



<p>In this case, since the threshold are identical, the algorithm will be <strong>calibrated</strong>. 79% of the decisions we make will be the correct ones, for both the blue and orange population. So, from our point of view, the algorithm is fair and treats the blue and orange populations identically. However, from the point of view of the applicants, this is not the case. If you are a blue applicant that will pay your loan, you have 81% chance of getting a loan, but if you are an orange customer you only have 60% of getting it. This demonstrates that defining fairness is quite delicate. In particular the above “color blind” algorithm is still arguable unfair.</p>



<p>This difference between the point of view of the lender and lendee also arose in the recidivism case mentioned above. From the point of view of the defendant that would not recidivate, the algorithm was more likely to label them as “high risk” if they were Black than if they were white. From the point of view of the decision maker, the algorithm was calibrated, and if anything it was a bit more likely that a white defendant labeled high risk would not recidivate than a Black defendant. See (slightly rounded and simplified) data below</p>



<figure class="wp-block-image"><img alt="" src="https://i.imgur.com/M73xLoe.png"/></figure>



<p/>



<p>If we wanted to achieve demographic parity (both populations get same total number of loans) or equal opportunity (true positive rate same for both) then we can do so, but again using different thresholds for each group:</p>



<figure class="wp-block-image"><img alt="" src="https://i.imgur.com/uMHsFPz.png"/></figure>



<figure class="wp-block-image"><img alt="" src="https://i.imgur.com/pAnbY6m.png"/></figure>



<h2>Fico Scores and Different Types of Fairness</h2>



<p>While the above was a hypothetical scenario, a real life example was shown by <a href="https://arxiv.org/abs/1610.02413">Hardt, Price and Srebro</a> using credit (also known as FICO) scores, as described by the plot below:</p>



<figure class="wp-block-image"><img alt="" src="https://i.imgur.com/S8H0gjj.png"/></figure>



<p>For a single threshold, around 75% of Asian candidates will get loans, whereas only around 20% of Black candidates will get loans. To ensure that all groups get loans at the same rate, we would need to set the thresholds differently. In order to equalize opportunity, we’d also need to initialize the thresholds differently as well.</p>



<p>We see that we have different notions of what it means to be <em>fair</em> and that each of these different notions result in different algorithms.</p>



<h2>Fairness and Causality</h2>



<p>Berkeley graduate admissions in 1973 had the following statistics:</p>



<ul><li>44% male applicants admitted, 35% female applicants admitted;</li><li>However, female acceptance rate was higher at the <em>department level</em>, for most departments.</li></ul>



<figure class="wp-block-image"><img alt="" src="https://i.imgur.com/MizH3NY.png"/></figure>



<p>This paradox is commonly referred to as <a href="https://en.wikipedia.org/wiki/Simpson%27s_paradox">Simpson’s Paradox</a>.</p>



<p>A “fair” causal model for this scenario might be as follows:</p>



<figure class="wp-block-image"><img alt="" src="https://i.imgur.com/sVG4l7l.png"/></figure>



<p>In the above, perhaps gender has a causal impact on the choice of department to which the applicant applies. However, a fair application process would, conditional on the department, be independent of gender of the applicant.</p>



<p>However, not all models that follow this causal structure are necessarily <em>fair</em>. In the case Griggs v. Duke Power Co., 1971, the court ruled that decision-making under the following causal model was <em>unfair</em>:</p>



<figure class="wp-block-image"><img alt="" src="https://i.imgur.com/9f6iEKH.png"/></figure>



<p>While the model appears to be fair, since the job offer is conditionall independent of race, given the diploma, the court ruled that the job did not actually require a high school diploma. Hence, using the diploma as a factor in hiring decisions was really just a proxy for race, resulting in essentially purposeful unfair discrimination based on race. This creation of proxies is referred to as <a href="https://en.wikipedia.org/wiki/Redlining">redlining</a>.</p>



<h1>Bottom Line</h1>



<p>We cannot come up with universal fairness criteria. The notion of fairness itself is based on assumptions about:</p>



<ul><li>representation of data</li><li>relationships to unmeasured inputs and outcomes</li><li>causal relation of inputs, predictions, outcomes.</li></ul>



<p>Fairness depends on what we choose to measure to observe, in both inputs and outputs, and how we choose to act upon them. In particular, we have the following causal structure, wherein measure inputs, decision-making, and measured outcomes all play a role in affecting the real-world and function together in a feedback cycle:</p>



<figure class="wp-block-image"><img alt="" src="https://i.imgur.com/LcW07id.png"/></figure>



<p>A more comprehensive illustration is given in this paper of <a href="https://cacm.acm.org/magazines/2021/4/251365-the-impossibility-of-fairness/fulltext">Friedler, Scheidegger, and Venkatasubramanian</a>:</p>



<figure class="wp-block-image"><img alt="" src="https://i.imgur.com/4BaQTSH.png"/></figure></div>
    </content>
    <updated>2021-06-11T20:42:13Z</updated>
    <published>2021-06-11T20:42:13Z</published>
    <category term="ML Theory seminar"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2021-06-20T12:21:04Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://lucatrevisan.wordpress.com/?p=4522</id>
    <link href="https://lucatrevisan.wordpress.com/2021/06/10/benny-chor/" rel="alternate" type="text/html"/>
    <title>Benny Chor</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">I just heard that Benny Chor died this morning. Chor did very important work on computational biology and distributed algorithms, but I (and probably many of my readers) know him primarily for his work on cryptography, for his work on … <a href="https://lucatrevisan.wordpress.com/2021/06/10/benny-chor/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I just heard that Benny Chor died this morning. Chor did very important work on computational biology and distributed algorithms, but I (and probably many of my readers) know him primarily for his work on cryptography, for his work on randomness extraction and for introducing the notion of private information retrieval.</p>



<p>I only met him once, at the event for <a href="https://lucatrevisan.wordpress.com/2017/04/20/fests/">Oded Goldreich’s 60th birthday</a>. On the occasion, he gave a talk on the Chor-Goldreich paper, which introduced the problem of randomness extraction from independent sources, and which introduced min-entropy as the right parameter by which to quantify the randomness content of random sources. He did so using the original slides used for the FOCS 1985 talk.</p>



<figure class="wp-block-image size-large"><a href="https://lucatrevisan.files.wordpress.com/2017/04/img_6726.jpg"><img alt="" class="wp-image-3735" src="https://lucatrevisan.files.wordpress.com/2017/04/img_6726.jpg?w=768"/></a></figure>



<p>I took a picture during the talk, which I posted online, and later he sent me an email asking for the original. Sadly, this was the totality of our correspondence. I heard that besides being a brilliant and generous researchers, he was a very playful, likeable and nice person. My thoughts are with his family and his friends.</p></div>
    </content>
    <updated>2021-06-10T20:18:16Z</updated>
    <published>2021-06-10T20:18:16Z</published>
    <category term="theory"/>
    <category term="Benny Chor"/>
    <author>
      <name>luca</name>
    </author>
    <source>
      <id>https://lucatrevisan.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://lucatrevisan.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://lucatrevisan.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://lucatrevisan.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://lucatrevisan.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>"Marge, I agree with you - in theory. In theory, communism works. In theory." -- Homer Simpson</subtitle>
      <title>in   theory</title>
      <updated>2021-06-20T12:20:09Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://lucatrevisan.wordpress.com/?p=4515</id>
    <link href="https://lucatrevisan.wordpress.com/2021/06/10/the-simons-institute-reopens/" rel="alternate" type="text/html"/>
    <title>The Simons Institute Reopens</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">This coming Fall semester the Simons Institute for the Theory of Computing in Berkeley will have in-person activities, including the really interesting program on the complexity of statistical inference, within which I will co-organize a workshop on cryptography, average-case complexity, … <a href="https://lucatrevisan.wordpress.com/2021/06/10/the-simons-institute-reopens/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>This coming Fall semester the Simons Institute for the Theory of Computing in Berkeley will have in-person activities, including the really interesting program on the complexity of statistical inference, within which I will co-organize a <a href="https://simons.berkeley.edu/programs/si2021">workshop</a> on cryptography, average-case complexity, and the complexity of statistical problems.</p>
<p>As it had been the case before the pandemic, all Simons Institute events will be streamed and available remotely. This includes a new series of <a href="https://simons.berkeley.edu/events">Public Lectures</a> called <a href="https://simons.berkeley.edu/news/institute-launches-breakthroughs-lecture-series">“Breakthroughs”</a> that starts next week with a talk by Virginia Williams on matrix multiplication.</p></div>
    </content>
    <updated>2021-06-10T20:00:51Z</updated>
    <published>2021-06-10T20:00:51Z</published>
    <category term="Berkeley"/>
    <category term="theory"/>
    <category term="Simons Institute"/>
    <category term="Virginia Williams"/>
    <author>
      <name>luca</name>
    </author>
    <source>
      <id>https://lucatrevisan.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://lucatrevisan.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://lucatrevisan.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://lucatrevisan.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://lucatrevisan.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>"Marge, I agree with you - in theory. In theory, communism works. In theory." -- Homer Simpson</subtitle>
      <title>in   theory</title>
      <updated>2021-06-20T12:20:09Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=5542</id>
    <link href="https://www.scottaaronson.com/blog/?p=5542" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=5542#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=5542" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">On Guilt</title>
    <summary xml:lang="en-US">The other night Dana and I watched “The Internet’s Own Boy,” the 2014 documentary about the life and work of Aaron Swartz, which I’d somehow missed when it came out. Swartz, for anyone who doesn’t remember, was the child prodigy who helped create RSS and Reddit, who then became a campaigner for an open Internet, […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>The other night Dana and I watched <a href="https://www.youtube.com/watch?v=9vz06QO3UkQ">“The Internet’s Own Boy,”</a> the 2014 documentary about the life and work of <a href="https://en.wikipedia.org/wiki/Aaron_Swartz">Aaron Swartz</a>, which I’d somehow missed when it came out.  Swartz, for anyone who doesn’t remember, was the child prodigy who helped create RSS and Reddit, who then became a campaigner for an open Internet, who was arrested for using a laptop in an MIT supply closet to download millions of journal articles and threatened with decades in prison, and who then committed suicide at age 26.  I regret that I never knew Swartz, though he did once send me a fan email about <em>Quantum Computing Since Democritus</em>.</p>



<p>Say whatever you want about the tactical wisdom or the legality of Swartz’s actions; it seems inarguable to me that he was <em>morally</em> correct, that certain categories of information (e.g. legal opinions and taxpayer-funded scientific papers) need to be made freely available, and that sooner or later our civilization will catch up to Swartz and regard his position as completely obvious.  The beautifully-made documentary filled me with rage and guilt not only that the world had failed Swartz, but that I personally had failed him.</p>



<p>At the time of Swartz’s arrest, prosecution, and suicide, I was an MIT CS professor who’d previously <a href="https://www.scottaaronson.com/writings/journal.html">written</a> in strong support of open access to scientific literature, and who had the platform of this blog.  Had I understood what was going on with Swartz—had I <em>taken the time to find out</em> what was going on—I could have been in a good position to help organize a grassroots campaign to pressure the MIT administration to urge prosecutors to drop the case (like JSTOR had already done), which could plausibly have made a difference.  As it was, I was preoccupied in those years with BosonSampling, getting married, etc., I didn’t bother to learn whether anything was being done or <em>could</em> be done about the Aaron Swartz matter, and then before I knew it, Swartz had joined Alan Turing in computer science’s pantheon of lost geniuses.</p>



<p>But maybe there was something deeper to my inaction.  If I’d strongly defended the substance of what Swartz had done, it would’ve raised the question: <em>why wasn’t I doing the same?</em>  Why was I merely complaining about paywalled journals from the comfort of my professor’s office, rather than putting my own freedom on the line like Swartz was?  It was as though I <em>had</em> to put some psychological distance between myself and the situation, in order to justify my life choices to myself.</p>



<p>Even though I see the error in that way of “thinking,” it keeps recurring, keeps causing me to make choices that I feel guilt or at least regret about later.  In February 2020, there were a few smart people saying that a new viral pneumonia from Wuhan was about to upend life on earth, but the people around me certainly weren’t <em>acting</em> that way, and <em>I</em> wasn’t acting that way either … and so, “for the sake of internal consistency,” I didn’t spend much time thinking about it or investigating it.  After all, if the fears of a global pandemic had a good chance of being true, I should be dropping everything else and panicking, shouldn’t I?  But I <em>wasn’t</em> dropping everything else and panicking … so how could the fears be true?</p>



<p>Then I <a href="https://www.scottaaronson.com/blog/?p=4695">publicly repented</a>, and resolved not to make such an error again.  And now, 15 months later, I realize that I <em>have</em> made such an error again.</p>



<p>All throughout the pandemic, I’d ask my friends, privately, why the hypothesis that the virus had accidentally leaked from the Wuhan Institute of Virology wasn’t being taken far more seriously, given what seemed like a shockingly strong <em>prima facie</em> case.  But I didn’t discuss the lab leak scenario on this blog, except once in passing.  I could <em>say</em> I didn’t discuss it because I’m not a virologist and I had nothing new to contribute.  But I worry that I also didn’t discuss it because it seemed incompatible with my self-conception as a cautious scientist who’s skeptical of lurid coverups and conspiracies—and because I’d already spent my “weirdness capital” on other issues, and didn’t relish the prospect of being sneered at on social media yet again.  Instead I simply waited for discussion of the lab leak hypothesis to become “safe” and “respectable,” as today it finally has, thanks to writers who were more courageous than I was.  I became, basically, another sheep in one of the conformist herds that we rightly despise when we read about them in history.</p>



<p>(For all that, it’s still plausible to me that the virus had a natural origin after all.  What’s become clear is simply that, <em>even if so</em>, the failure to take the possibility of a lab escape more seriously back when the trail of evidence was fresher will stand as a major intellectual scandal of our time.)</p>



<p>Sometimes people are wracked with guilt, but over completely different things than the world <em>wants</em> them to be wracked with guilt over.  This was one of the great lessons that I learned from reading Richard Rhodes’s <em><a href="https://www.amazon.com/Making-Atomic-Bomb-Richard-Rhodes/dp/1451677618">The Making of the Atomic Bomb</a></em>.  Many of the Manhattan Project physicists felt lifelong guilt, <em>not</em> that they’d participated in building the bomb, but only that they hadn’t <em>finished</em> the bomb by 1943, when it could have ended the war in Europe and the Holocaust.</p>



<p>On a much smaller scale, I suppose some readers would still like me to feel guilt about comment 171, or some of the other stuff I wrote about nerds, dating, and feminism … or if not that, then maybe about my defense of a two-state solution for Israel and Palestine, or of standardized tests and accelerated math programs, or maybe my vehement condemnation of Trump and his failed insurrection.  Or any of the dozens of other times when I stood up and said something I actually believed, or when I recounted my experiences as accurately as I could.  The truth is, though, I don’t.</p>



<p>Looking back—which, now that I’m 40, I confess is an increasingly large fraction of my time—the pattern seems consistent.  I feel guilty, not for having stood up for what I strongly believed in, but for having <em>failed</em> to do so.  This suggests that, if I want fewer regrets, then I should click “Publish” on more potentially controversial posts!  I don’t know how to force myself to do that, but maybe this post itself is a step.</p></div>
    </content>
    <updated>2021-06-10T17:38:24Z</updated>
    <published>2021-06-10T17:38:24Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Embarrassing Myself"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Nerd Self-Help"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Self-Referential"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2021-06-10T17:41:45Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-2554136414226144895</id>
    <link href="https://blog.computationalcomplexity.org/feeds/2554136414226144895/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2021/06/the-future-of-faculty-hiring.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/2554136414226144895" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/2554136414226144895" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2021/06/the-future-of-faculty-hiring.html" rel="alternate" type="text/html"/>
    <title>The Future of Faculty Hiring</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Faculty hiring in computer science is a <a href="https://blog.computationalcomplexity.org/2016/12/fixing-academic-job-market.html">process long due for an overhaul</a>. The pandemic certainly changed some of the dynamics moving most of the interviews online and saving a ton of money and time. Will this be the start of a fresh approach to recruiting?</p><p>A typical search in the past few years had some schools flying in 30-40 candidates, typically costing over a $1000 each and a full-time job for a staff member during the search. We'd justify the expense as small compared to the millions we'd invest in a faculty member throughout their career, but it is generally the largest discretionary expense for a CS department. It also gives advantages to rich departments over others.</p><p>During the pandemic all those interviews moved online and worked reasonably well at virtually no additional cost. Also no need to scrounge around to find faculty willing to skip family meals to have dinner with the candidates. And if a faculty had a conflict with a candidate on the interview day, they could schedule on a different day. There really is no reason to have all the meetings on the same day.</p><p>With the pandemic mostly behind us, will we go back to in-person interviews moving forward. I suspect the <a href="https://www.chronicle.com/article/whiffing-the-airport-interview/">airport interview</a>, where you fly out 20 or so candidates to have hour long interviews in a hotel near an airport with a search committee for an administrative position, will be the first to go completely virtual. </p><p>Even for regular faculty interviews, there will be great pressure to reduce the number of in-person visits, perhaps to just the top candidates, or just the ones who have offers--make the "second visit" the only visit. Richer departments may find the expense worthwhile to make a bigger impression on the candidates and that will only expand the advantage of wealthier universities.</p><p>Times like this are the perfect opportunity for CS leadership to come in and give some sanity to the hiring process but I'm not holding my breath.</p></div>
    </content>
    <updated>2021-06-10T13:10:00Z</updated>
    <published>2021-06-10T13:10:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2021-06-19T20:06:19Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/080</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/080" rel="alternate" type="text/html"/>
    <title>TR21-080 |  Hardness vs Randomness, Revised: Uniform, Non-Black-Box, and Instance-Wise | 

	Lijie Chen, 

	Roei Tell</title>
    <summary>We propose a new approach to the hardness-to-randomness framework and to the promise-BPP=promise-P conjecture. Classical results rely on non-uniform hardness assumptions to construct derandomization algorithms that work in the worst-case, or rely on uniform hardness assumptions to construct derandomization algorithms that work only in the average-case. In both types of results, the derandomization algorithm is ``black-box'' and uses the standard PRG approach. In this work we present results that closely relate **new and natural uniform hardness assumptions** to **worst-case derandomization** of promise-BPP, where the algorithms underlying the latter derandomization are **non-black-box**.

In our main result, we show that promise-BPP=promise-P if the following holds: There exists a multi-output function computable by logspace-uniform circuits of polynomial size and depth $n^2$ that cannot be computed by uniform probabilistic algorithms in time $n^c$, for some universal constant $c&gt;1$, on **almost all inputs**. The required failure on ``almost all inputs'' is stronger than the standard requirement of failing on one input of each length; however, the same assumption without the depth restriction on $f$ is **necessary** for the conclusion. This suggests a potential equivalence between worst-case derandomization of promise-BPP of any form (i.e., not necessarily by a black-box algorithm) and the existence of efficiently computable functions that are hard for probabilistic algorithms on almost all inputs.

In our second result, we introduce a new and uniform hardness-to-randomness tradeoff for the setting of **superfast average-case derandomization**; prior to this work, superfast average-case derandomization was known only under non-uniform hardness assumptions. In an extreme instantiation of our new tradeoff, under appealing uniform hardness assumptions, we show that for every polynomial $T(n)$ and constant $\epsilon&gt;0$ it holds that $BPTIME[T]\subseteq heur-DTIME[T\cdot n^{\epsilon}]$, where the ``heur'' prefix means that no polynomial-time algorithm can find, with non-negligible probability, an input on which the deterministic simulation errs.

Technically, our approach is to design **targeted PRGs and HSGs**, as introduced by Goldreich (LNCS, 2011). The targeted PRGs/HSGs ``produce randomness from the input'', as suggested by Goldreich and Wigderson (RANDOM 2002); and their analysis relies on non-black-box versions of the reconstruction procedure of Impagliazzo and Wigderson (FOCS 1998). Our main reconstruction procedure crucially relies on the ideas underlying the proof system of Goldwasser, Kalai, and Rothblum (J. ACM 2015).</summary>
    <updated>2021-06-10T07:46:31Z</updated>
    <published>2021-06-10T07:46:31Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-06-20T12:20:31Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/079</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/079" rel="alternate" type="text/html"/>
    <title>TR21-079 |  The zero-rate threshold for adversarial bit-deletions is less than 1/2 | 

	Venkatesan Guruswami, 

	Xiaoyu He, 

	Ray Li</title>
    <summary>We prove that there exists an absolute constant $\delta&gt;0$ such any binary code $C\subset\{0,1\}^N$ tolerating $(1/2-\delta)N$ adversarial deletions must satisfy $|C|\le 2^{\poly\log N}$ and thus have rate asymptotically approaching $0$. This is the first constant fraction improvement over the trivial bound that codes tolerating $N/2$ adversarial deletions must have rate going to $0$ asymptotically.  Equivalently, we show that there exists absolute constants $A$ and $\delta&gt;0$ such that any set $C\subset\{0,1\}^N$ of $2^{\log^A N}$ binary strings must contain two strings $c$ and $c'$ whose longest common subsequence has length at least $(1/2+\delta)N$. As an immediate corollary, we show that $q$-ary codes tolerating a fraction $1-(1+2\delta)/q$ of adversarial deletions must also have rate approaching $0$.
 
Our techniques include string regularity arguments and a structural lemma that classifies binary strings by their oscillation patterns.  Leveraging these tools, we find in any large code two strings with similar oscillation patterns, which is exploited to find a long common subsequence.</summary>
    <updated>2021-06-09T16:59:13Z</updated>
    <published>2021-06-09T16:59:13Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-06-20T12:20:31Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=21799</id>
    <link href="https://gilkalai.wordpress.com/2021/06/09/to-cheer-you-up-in-difficult-times-26-two-real-life-lectures-yesterday-at-the-technion/" rel="alternate" type="text/html"/>
    <title>To cheer you up in difficult times 26: Two real-life lectures yesterday at the Technion</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">After 16 months without lecturing to an audience in my same location, I gave yesterday two lectures at the Technion in front of a live audience (and some additional audience in remote locations). The main lecture was in COMSOC 2021, … <a href="https://gilkalai.wordpress.com/2021/06/09/to-cheer-you-up-in-difficult-times-26-two-real-life-lectures-yesterday-at-the-technion/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>After 16 months without lecturing to an audience in my same location, I gave yesterday two lectures at the Technion in front of a live audience (and some additional audience in remote locations). The main lecture was in <a href="https://comsoc2021.net.technion.ac.il/">COMSOC 2021,</a> an international conference on computational social choice,  and earlier I gave a guest lecture in Roy Meshulam’s class about simple polytopes. I also met many friends. </p>
<p><a href="https://reshef.net.technion.ac.il/">Reshef Meir</a> who organized (with Bill Zwicker) COMSOC 2021 wrote:</p>
<blockquote>
<div><span style="color: #993366;"><em>Hi all, </em></span></div>
<div><span style="color: #993366;"><em>today was beyond expectations – the first feeling of a real actual conference after almost a year and a half!  We had about 40 people attending, viewing posters, and listening to talks. I truly hope this will return to be a common scene and that we can all meet face to face soon.</em></span></div>
</blockquote>
<div> </div>
<p>In my COMSOC lecture I talked about some earlier ideas and results in my work on social choice, starting with my paper with Ariel Rubinstein and Rani Spiegler on rationalizing individual choice by multiple rationals, and my subsequent attempt to use learnability as a tool for understanding choices of economic agents. This led to interesting questions on social choice <a href="https://gilkalai.wordpress.com/2009/06/02/social-choice-preview/">that are discussed in this 2009 post.</a></p>
<p>In Roy’s course I explained <img alt="h" class="latex" src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/>-vectors of polytopes and the Dehn-Sommerville relations based on counting outdegrees of the graph of the polytope when we direct its edges based on a generic abstract objective function. I moved on to present a proof of Blind-Mani’s theorem that the graph of the polytope determines the full combinatorics. This proof is probably the one proof I presented the most and it is given in <a href="https://gilkalai.wordpress.com/2009/01/16/telling-a-simple-polytope-from-its-graph/">this 2009 post</a>.</p>
<p><img alt="sc1" class="alignnone size-full wp-image-21802" height="391" src="https://gilkalai.files.wordpress.com/2021/06/sc1.png" width="420"/></p>
<p><span style="color: #ff0000;">In my  COMSOC lecture I described how to fill the two question marks in the table above.</span></p>
<p><img alt="sc2" class="alignnone size-full wp-image-21803" height="391" src="https://gilkalai.files.wordpress.com/2021/06/sc2.png" width="420"/></p>


<p/></div>
    </content>
    <updated>2021-06-09T06:30:14Z</updated>
    <published>2021-06-09T06:30:14Z</published>
    <category term="Combinatorics"/>
    <category term="Convex polytopes"/>
    <category term="Economics"/>
    <category term="Games"/>
    <category term="Rationality"/>
    <category term="COMSOC 2021"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2021-06-20T12:20:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://ptreview.sublinear.info/?p=1526</id>
    <link href="https://ptreview.sublinear.info/?p=1526" rel="alternate" type="text/html"/>
    <title>News for May 2021</title>
    <summary>We hope you are all staying safe. With massive vaccination programs across the globe we hope you and your loved ones are getting back to what used to be normal. With that out of the way, let us circle back to Property Testing. This month was less sleepy as compared to the two preceding months […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>We hope you are all staying safe. With massive vaccination programs across the globe we hope you and your loved ones are getting back to what used to be normal. With that out of the way, let us circle back to Property Testing. This month was less sleepy as compared to the two preceding months and we saw six papers in total (two of them explore problems in quantum property testing). Without further ado, let us take a deeper dive.</p>



<p/>



<p><strong>GSF-locality is not sufficient for proximity-oblivious testing</strong>, by Isolde Adler, Noleen Kohler, Pan Peng (<a href="https://arxiv.org/abs/2105.08490">arXiv</a>) The notion of proximity oblivious testers was made explicit in the seminal work of Goldreich and Ron in 2009 [GR09]. A proximity oblivious tester for a graph property is a constant query tester that rejects a graph with probability that monotonically increases with distance to the property. (<strong>Edit</strong>: <em>Correction</em>) A property is called proximity oblivious testable (or PO testable) if it has a one sided proximity oblivious tester. [GR09] gave a characterization of which properties \(\Pi\) are PO testable in the bounded degree model <em>if and only if</em> it is a “local” property of some kind which satisfies a certain non propagation condition. [GR09] conjectured that all such “local” properties satisfy this non propagation condition. This paper refutes the above conjecture from [GR09].</p>



<p/>



<p>Coming up next. More action on triangle freeness.</p>



<p><strong>Testing Triangle Freeness in the General Model in Graphs with Arboricity \(O(\sqrt n)\)</strong>, by Reut Levi (<a href="https://arxiv.org/abs/2105.04809">arXiv</a>) PTReview readers are likely to be aware that triangle freeness has been a rich source of problems for developing new sublinear time algorithms. This paper considers the classic problem of testing triangle freeness in general graphs. In the dense case, algorithms with running time depending only on \(\varepsilon\) are known thanks to the work of Alon, Fischer, Krivelevich and Szegedy. In the bounded degree case, Goldreich and Ron gave testers with query complexity \(O(1/\varepsilon)\). This paper explores the problem in general graph case and proves an upper bound of \(O(\Gamma/d_{avg} + \Gamma)\) where \(\Gamma\) is the arboricity of the graph. The author also shows that this upperbound is tight for graphs with arboricity at most \(O(\sqrt n)\). Curiously enough, the algorithm does not take arboricity of the graph as an input and yet \(\Gamma\) (the arboricity) shows up in the upper and lower bounds.</p>



<p/>



<p><strong>Testing Dynamic Environments: Back to Basics</strong>, by Yonatan Nakar and Dana Ron (<a href="https://arxiv.org/abs/2105.00759">arXiv</a>) Goldreich and Ron introduced the problem of testing “dynamic environments” in 2014. Here is the setup for this problem. You are given an environment that evolves according to a local rule.  Your goal is to query some of the states in the system at some point of time and determine if the system is evolving according to some fixed rule or is far from it. In this paper, the authors consider environments defined by elementary cellular automata which evolve according to threshold rules as one of the first steps towards understanding what makes a dynamic environment tested efficiently.  The main result proves the following: if your local rules satisfy some <em>conditions</em>, you can use a meta algorithm with query complexity \(poly(1/\varepsilon)\) which is non adaptive and has one sided error. And all the threshold rules indeed satisfy these <em>conditions</em> which means they can be tested efficiently. </p>



<p/>



<p><strong>Identity testing under label mismatch</strong>, by Clement Canonne and Karl Wimmer (<a href="https://arxiv.org/abs/2105.01856">arXiv</a>) This paper considers a classic problem distribution testing with the following twist. Let \(q\) denote a distribution supported on \([n]\). You are given access to samples from another distribution \(p\) where \(p  = q \circ \pi\) where \(\pi\) is some unknown permutation. Thus, I relabel the data and I give you access to samples from the relabeled dataset. Under this promise, note that identity testing becomes a trivial problem if \(q\) is known to be uniform over \([n]\). The authors develop algorithms for testing and tolerant testing of distributions under this additional promise of \(p\) being a permutation of some known distribution \(q\). The main result shows as exponential gap between the sample complexity of testing and tolerant testing under this promise. In particular, identity testing under the promise of permutation has sample complexity \(\Theta(\log^2 n)\) whereas tolerant identity testing under this promise has sample complexity \(\Theta(n^{1-o(1)})\).</p>



<p/>



<p><strong>Testing symmetry on quantum computers</strong>, by Margarite L. LaBorde and Mark M. Wilde (<a href="https://arxiv.org/abs/2105.12758">arXiv</a>) This paper develops algorithms which test symmetries of a quantum states and changes generated by quantum circuits. These tests additionally also quantify how symmetric these states (or channels) are. For testing what are called “Bose states” the paper presents efficient algorithms. The tests for other kinds of symmetry presented in the paper rely on some aid from a quantum prover.</p>



<p/>



<p><strong>Quantum proofs of proximity</strong>, by Marcel Dall’Agnol, Tom Gur, Subhayan Roy Moulik, Justin Thaler (<a href="https://eccc.weizmann.ac.il/report/2021/068/">ECCC</a>) The sublinear time (quantum) computation model has been gathering momentum steadily over the past several years. This paper seeks to understand the power of \({\sf QMA}\) proofs of proximity for property testing (recall \({\sf QMA}\) is the quantum analogue of \({\sf NP}\)). On the algorithmic front, the paper develops sufficient conditions for properties to admit efficient \({\sf QMA}\) proofs of proximity. On the complexity front, the paper demonstrates a property which admits  an efficient \({\sf QMA}\) proof but does not admit a \({\sf MA}\) or an interactive proof of proximity.</p></div>
    </content>
    <updated>2021-06-09T05:31:17Z</updated>
    <published>2021-06-09T05:31:17Z</published>
    <category term="Monthly digest"/>
    <author>
      <name>Akash</name>
    </author>
    <source>
      <id>https://ptreview.sublinear.info</id>
      <link href="https://ptreview.sublinear.info/?feed=rss2" rel="self" type="application/atom+xml"/>
      <link href="https://ptreview.sublinear.info" rel="alternate" type="text/html"/>
      <subtitle>The latest in property testing and sublinear time algorithms</subtitle>
      <title>Property Testing Review</title>
      <updated>2021-06-19T22:46:32Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=5539</id>
    <link href="https://www.scottaaronson.com/blog/?p=5539" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=5539#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=5539" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">More quantum computing popularization!</title>
    <summary xml:lang="en-US">I now have a feature article up at Quanta magazine, entitled “What Makes Quantum Computing So Hard To Explain?” I.e., why do journalists, investors, etc. so consistently get central points wrong, even after the subject has been in public consciousness for more than 25 years? Perhaps unsurprisingly, I found it hard to discuss that meta-level […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>I now have a feature article up at <em>Quanta</em> magazine, entitled <a href="https://www.quantamagazine.org/why-is-quantum-computing-so-hard-to-explain-20210608/">“What Makes Quantum Computing So Hard To Explain?”</a>  I.e., why do journalists, investors, etc. so consistently get central points wrong, even after the subject has been in public consciousness for more than 25 years?  Perhaps unsurprisingly, I found it hard to discuss that meta-level question, as <em>Quanta</em>‘s editors asked me to do, without also engaging in the object-level task of actually explaining QC.  For regular <em>Shtetl-Optimized</em> readers, there will be nothing new here, but I’m happy with how the piece turned out.</p>



<p>Accompanying the <em>Quanta</em> piece is a <a href="https://www.youtube.com/watch?v=jHoEjvuPoB8&amp;t=6s">10-minute YouTube explainer on quantum computing</a>, which (besides snazzy graphics) features interviews with me, John Preskill, and Dorit Aharonov.</p>



<p>On a different note, my colleague <a href="https://www.markwilde.com/">Mark Wilde</a> has recorded a <a href="https://soundcloud.com/mark-m-wilde/quantum-computer">punk-rock song about BosonSampling</a>.  I can honestly report that it’s some of the finest boson-themed music I’ve heard in years.  It includes the following lyrics:</p>



<blockquote class="wp-block-quote"><p>Quantum computer, Ain’t no loser<br/>Quantum computer, Quantum computer</p><p>People out on the streets<br/>They don’t know what it is<br/>They think it finds the cliques<br/>Or finds graph colorings<br/>But it don’t solve anything<br/>Said it don’t solve anything<br/>Bosonic slot machine<br/>My lil’ photonic dream</p></blockquote>



<p>Speaking of BosonSampling, A. S. Popova and A. N. Rubtsov, of the Skolkovo Institute in Moscow, have a new preprint entitled <a href="https://arxiv.org/abs/2106.01445">Cracking the Quantum Advantage threshold for Gaussian Boson Sampling</a>.  In it, they claim to give an efficient classical algorithm to simulate noisy GBS experiments, like the <a href="https://www.scottaaronson.com/blog/?p=5159">one six months ago</a> from USTC in China.  I’m still unsure how well this scales from 30-40 photons up to 50-70 photons; which imperfections of the USTC experiment are primarily being taken advantage of (photon losses?); and how this relates to the earlier proposed classical algorithms for simulating noisy BosonSampling, like the one by <a href="https://arxiv.org/abs/1409.3093">Kalai and Kindler</a>.  Anyone with any insight is welcome to share!</p>



<p>OK, one last announcement: the Simons Institute for the Theory of Computing, in Berkeley, has a new online lecture series called <a href="https://simons.berkeley.edu/news/institute-launches-breakthroughs-lecture-series">“Breakthroughs,”</a> which many readers of this blog might want to check out.</p></div>
    </content>
    <updated>2021-06-08T20:29:24Z</updated>
    <published>2021-06-08T20:29:24Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Announcements"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Complexity"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Quantum"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2021-06-10T17:41:45Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-8890204.post-7554871212591440842</id>
    <link href="http://mybiasedcoin.blogspot.com/feeds/7554871212591440842/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=8890204&amp;postID=7554871212591440842" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/8890204/posts/default/7554871212591440842" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/8890204/posts/default/7554871212591440842" rel="self" type="application/atom+xml"/>
    <link href="http://mybiasedcoin.blogspot.com/2021/06/machlne-learning-for-algorithms.html" rel="alternate" type="text/html"/>
    <title>Machine Learning for Algorithms Workshop (July 13-14)</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>We're having an online workshop on "Machine Learning for Algorithms" on July 13-14, with a great group of speakers.  Announcement below, link at <a href="https://fodsi.us/ml4a.html">https://fodsi.us/ml4a.html</a>, free registration (but please register in advance)!</p><div class="gmail_default" style="font-size: small;">In recent years there has been increasing interest in using machine learning to improve the performance of classical algorithms in computer science, by fine-tuning their behavior to adapt to the properties of the input distribution. This "data-driven" or "learning-based" approach to algorithm design has the potential to significantly improve the efficiency of some of the most widely used algorithms. For example, they have been used to design better data structures, online algorithms, streaming and sketching algorithms, market mechanisms and algorithms for combinatorial optimization, similarity search and inverse problems.  This virtual workshop will feature talks from experts at the forefront of this exciting area.<br/><br/>The workshop is organized by Foundations of Data Science Institute (FODSI), a project supported by the NSF TRIPODS program (see fodsi.us). To attend, please register at    <br/> <br/><a href="https://fodsi.us/ml4a.html">https://fodsi.us/ml4a.html</a>  </div></div>
    </content>
    <updated>2021-06-08T19:04:00Z</updated>
    <published>2021-06-08T19:04:00Z</published>
    <author>
      <name>Michael Mitzenmacher</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/02161161032642563814</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-8890204</id>
      <category term="conferences"/>
      <category term="research"/>
      <category term="society"/>
      <category term="algorithms"/>
      <category term="administration"/>
      <category term="teaching"/>
      <category term="Harvard"/>
      <category term="papers"/>
      <category term="graduate students"/>
      <category term="funding"/>
      <category term="talks"/>
      <category term="blogs"/>
      <category term="codes"/>
      <category term="jobs"/>
      <category term="reviews"/>
      <category term="personal"/>
      <category term="travel"/>
      <category term="undergraduate students"/>
      <category term="books"/>
      <category term="open problems"/>
      <category term="PCs"/>
      <category term="consulting"/>
      <category term="randomness"/>
      <category term="CCC"/>
      <category term="blog book project"/>
      <category term="research labs"/>
      <category term="ISIT"/>
      <category term="tenure"/>
      <category term="comments"/>
      <category term="recommendations"/>
      <category term="outreach"/>
      <category term="students"/>
      <author>
        <name>Michael Mitzenmacher</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06738274256402616703</uri>
      </author>
      <link href="http://mybiasedcoin.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/8890204/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://mybiasedcoin.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/8890204/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">My take on computer science -- <br/> 
algorithms, networking, information theory -- <br/> 
and related items.</div>
      </subtitle>
      <title>My Biased Coin</title>
      <updated>2021-06-12T20:14:54Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/078</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/078" rel="alternate" type="text/html"/>
    <title>TR21-078 |  A direct product theorem for quantum communication complexity with applications to device-independent QKD | 

	Rahul  Jain, 

	Srijita Kundu</title>
    <summary>We give a direct product theorem for the entanglement-assisted interactive quantum communication complexity of an $l$-player predicate $V$. In particular we show that for a distribution $p$ that is product across the input sets of the $l$ players, the success probability of any entanglement-assisted quantum communication protocol for computing $n$ copies of $V$, whose communication is $o(\log(\mathrm{eff}^*(V,p))\cdot n)$, goes down exponentially in $n$. Here $\mathrm{eff}^*(V, p)$ is a distributional version of the quantum efficiency or partition bound introduced by Laplante, Lerays and Roland (2014), which is a lower bound on the distributional quantum communication complexity of computing a single copy of $V$ with respect to $p$.
  As an application of our result, we show that it is possible to do device-independent quantum key distribution (DIQKD) without the assumption that devices do not leak any information after inputs are provided to them. We analyze the DIQKD protocol given by Jain, Miller and Shi (2017), and show that when the protocol is carried out with devices that are compatible with $n$ copies of the Magic Square game, it is possible to extract $\Omega(n)$ bits of key from it, even in the presence of $O(n)$ bits of leakage. Our security proof is parallel, i.e., the honest parties can enter all their inputs into their devices at once, and works for a leakage model that is arbitrarily interactive, i.e., the devices of the honest parties Alice and Bob can exchange information with each other and with the eavesdropper Eve in any number of rounds, as long as the total number of bits or qubits communicated is bounded.</summary>
    <updated>2021-06-08T12:31:43Z</updated>
    <published>2021-06-08T12:31:43Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-06-20T12:20:31Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://gradientscience.org/3db-light/</id>
    <link href="https://gradientscience.org/3db-light/" rel="alternate" type="text/html"/>
    <title>3DB: A Framework for Debugging Vision Models</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a class="bbutton" href="https://arxiv.org/abs/2106.03805" style="float: left; width: 45%; margin-bottom: 0;">
<i class="fas fa-file-pdf"/>
    Paper
</a>
<a class="bbutton" href="https://github.com/3db/3db/" style="float: left; width: 45%; margin-bottom: 0;">
<i class="fab fa-github"/>
   Project Repo
</a>
<a class="bbutton" href="https://3db.github.io/3db/usage/quickstart.html" style="float: left; width: 45%;">
<i class="fas fa-file-alt"/>
   Documentation and Guides
</a> 
<a class="bbutton" href="https://github.com/3db/blog_demo/" style="float: left; width: 45%;">
<i class="fab fa-github"/>
   Blog Demo
</a> 
<br/></p>

<p><i>In our <a href="https://arxiv.org/abs/2106.03805">latest paper</a>, in collaboration with Microsoft Research, we introduce
3DB: an extendable, unified framework for debugging and analyzing vision models
using photorealistic simulation. We’re releasing 3DB as a package, accompanied
by extensive API documentation, guides, and demos.</i></p>

<p><em>Note: You are now viewing the Javascript-free/lightweight version of this
post—to see the full version (with interactive plots, diagrams, and models!),
click <a href="https://gradientscience.org/3db/">here</a></em></p>

<p>Identifying failure modes and biases in vision models is a rapidly
emerging challenge in machine learning. In high-stakes
applications, simply deploying models and collecting failures that arise in
the wild is often difficult, expensive, and irresponsible. To this end, a
recent line of work in vision focuses on identifying model failure
modes via in-depth analyses of <a href="https://arxiv.org/abs/1712.02779">image transformations</a> and 
<a href="https://arxiv.org/abs/1903.12261">corruptions</a>, <a href="https://objectnet.dev">object orientations</a>,
<a href="https://gradientscience.org/background/">backgrounds</a>, or <a href="https://arxiv.org/abs/1811.12231v2">shape-texture conflicts</a>. These studies 
(and other similarly important ones) reveal a variety of patterns of
performance degradation in vision models. Still, performing each such study
requires time, developing (often complex)
toolingFor <a href="https://gradientscience.org/background/">our study of image backgrounds</a>, for example, we used a
combination of bounding boxes and classical computer vision tools to crop out
image backgrounds. We then had to manually filter out the images for which
the tools failed. Even for the images where the toolkit succeeded, there
remained inevitable cropping artifacts., and a willingness to settle for less than perfect simulations of each
potential failure mode. Our question is: can we support reliable discovery of model failures in a systematic,
automated, and unified way?</p>

<h2 id="3db-a-rendering-based-debugging-platform">3DB: A Rendering-based Debugging Platform</h2>

<p><img alt="A sampling of the analyses enabled by 3DB." class="bigimg" src="https://gradientscience.org/assets/3db/3db_headline.png"/></p>
<div class="caption" style="margin-top: 0;">
A sampling of the analyses enabled by 3DB.
</div>

<p>In our <a href="https://arxiv.org/abs/2106.03805">latest paper</a>, we try to make progress on this question and propose
3DB, a platform for automatically identifying and analyzing the failure modes
of computer vision models using 3D rendering. 3DB aims to allow users to go
from a testable, robustness-based hypothesis to concrete, photorealistic
experimental evidence with minimal time and effort.</p>

<p>The platform revolves around the modular workflow pictured below. First,
users specify a set of 3D objects and environments, as well as a set of 3D
(or 2D) transformations called controls that determine the space of
admissible object-environment configurations. 3DB then renders a myriad of
admissible scenes and feeds them through the user’s computer vision model of
choice. The user can finally stratify, aggregate, or otherwise analyze the
results either by reading the outputted JSON, or through the pre-packaged
dashboard.</p>

<p><img alt="An illustration of the 3DB workflow." class="bigimg" src="https://gradientscience.org/assets/3db/workflow.png"/></p>

<p>3DB easily adapts to a variety of use cases: in particular, users can
modify and swap out any part of this pipeline (e.g., the renderer, the
logger, the model type, or the controls) for their own custom-written
components, without needing to modify any of the 3DB codebase. We’ve compiled <a href="https://3db.github.io/3db/">guides</a>,
extensive <a href="https://3db.github.io/3db/api_doc.html">API documentation</a>, and a
<a href="https://github.com/3db/demo">full demo</a> showing how 3DB streamlines model debugging.</p>

<p><strong>In fact, this blog post will double as another demo! We’ll present the (short) code
necessary to reproduce every plot in the post below using 3DB. You can download 
the aggregated code for this blog post <a href="https://github.com/3db/blog_demo">here</a>.</strong></p>

<p><em>To set up, follow the steps below—then, in the remainder of this post, press
“Show/hide code and instructions” to see the steps necessary to reproduce each
experiment below.</em></p>
<div class="code-container">
  <input checked="" class="tab1" id="general-tab1" name="general-tab" type="radio"/>
  <label for="general-tab1"><i class="fa fa-gear"/>  Setup</label>
  <input class="tab2" id="general-tab2" name="general-tab" type="radio"/>
  <label for="general-tab2"><i class="fa fa-code"/>  Config (base.yaml)</label>
  <div class="line"/>
  <div class="content-container">
<div class="content c1">
<!-- <pre class='wrapped'><code class="markdown"> -->
<ol class="instructions">
<li>Clone the  <a href="https://github.com/3db/blog_demo">blog demo <i class="fab fa-github"/></a> repo</li>
<li>Run <pre>cd blog_demo</pre>, then <pre>bash setup.sh</pre> (assumes
<pre>unzip</pre> is installed) to download a large Blender environment, then
<pre>cd ../</pre></li>
<li>Install 3DB: <pre>curl -L https://git.io/Js8eT | bash /dev/stdin threedb</pre></li>
<li>Run <pre>conda activate threedb</pre></li>
<li>Our experiments below will need a <pre>BLENDER_DATA</pre> folder that contains two
subfolders: <pre>blender_models/</pre> containing 3D models (<pre>.blend</pre> files with a single
object whose name matches the filename), and <pre>blender_environments/</pre>
containing environments. We will provide you with these later</li> 
<li>Separately, make a file called <pre>base.yaml</pre> and paste in the configuration from the next pane.</li>
</ol>
<!-- </code></pre> -->
</div>
<div class="content c2"><pre><code class="YAML">
inference:
  module: 'torchvision.models'
  label_map: 'blog_demo/resources/imagenet_mapping.json'
  class: 'resnet18'
  normalization:
    mean: [0.485, 0.456, 0.406]
    std: [0.229, 0.224, 0.225]
  resolution: [224, 224]
  args:
    pretrained: True
evaluation:
  module: 'threedb.evaluators.classification'
  args:
    classmap_path: 'blog_demo/resources/ycb_to_IN.json'
    topk: 1
render_args:
  engine: 'threedb.rendering.render_blender'
  resolution: 256
  samples: 16
policy:
  module: "threedb.policies.random_search"
  samples: 5
logging:
  logger_modules:
    - "threedb.result_logging.image_logger"
    - "threedb.result_logging.json_logger"

</code></pre></div>
 </div>
</div>

<h2 id="using-3db">Using 3DB</h2>

<p>Prior works have already used 3D rendering (to great effect) to study biases
of machine learning models, including pose and context-based biases. Our goal
is not to propose a specific 3D-rendering based analysis, but
rather to provide an easy-to-use, highly extendable framework that unifies
prior analyses (both 3D and 2D) while enabling users to (a) conduct a host of
new analyses with the same ease and with realistic results; and (b)
effortlessly <em>compose</em> different factors of variation to understand their
interplay.</p>

<p>We’ll dedicate the rest of this post to illustrating how one
might actually use 3DB in practice, focusing on a single example 3D
model3DB works with any 3D model, and we refer the reader to 
<a href="https://arxiv.org/abs/2106.03805">our paper</a> for more examples and details.:</p>

<p style="text-align: center;">
<img src="https://gradientscience.org/assets/3db/plain_mug/plain_mug_1.png" style="display: inline; width: 18%;"/>
<img src="https://gradientscience.org/assets/3db/plain_mug/plain_mug_2.png" style="display: inline; width: 18%;"/>
<img src="https://gradientscience.org/assets/3db/plain_mug/plain_mug_3.png" style="display: inline; width: 18%;"/>
<img src="https://gradientscience.org/assets/3db/plain_mug/plain_mug_4.png" style="display: inline; width: 18%;"/>
<img src="https://gradientscience.org/assets/3db/plain_mug/plain_mug_5.png" style="display: inline; width: 18%;"/>
</p>
<div class="caption" style="margin-top: 0px; margin-bottom: 15px;">
    The 3D mug model that we'll be using throughout this post.
</div>

<p>In what follows, we will walk through example applications of 3DB to discover biases of
ML models (some previously documented, others not). For the sake of brevity,
we’ll highlight just a few of these (re-)discoveries—to see more, check out
the <a href="https://arxiv.org/abs/2106.03805">paper</a>. We’ll then demonstrate that the discoveries of 3DB
transfer pretty reliably to the real world!</p>

<p>Our experiments will all operate on an ImageNet-pretrained
ResNet-18The classifier has a ~70% validation-set
accuracy. that has 42% accuracy on images from the
“coffee mug” ImageNet subclass. While we only study classification in this blog post,
3DB also supports object detection and can be easily extended to support other
image-based tasks, such as semantic segmentation, too.</p>

<h2 id="image-background-sensitivity">Image Background Sensitivity</h2>

<p>In one of our <a href="https://gradientscience.org/background/">previous posts</a>,
we continued a long line of prior work (see, e.g.,
<a href="https://hal.archives-ouvertes.fr/hal-00171412/file/ZhangMarszalekLazebnikSchmid-IJCV07-ClassificationStudy.pdf">here</a>, <a href="https://arxiv.org/abs/1611.06596">here</a>, <a href="https://arxiv.org/abs/1911.08731">here</a>, etc.) showing that models can be
over-reliant on image backgrounds, and demonstrated that they are easily
broken by adversarially chosen backgrounds. To accomplish this, our prior
analysis used classical computer vision tools to separate foregrounds from
backgrounds, then pasted foregrounds from one image onto backgrounds from
another. This process was slow and required extensive quality control to
ensure that backgrounds and foregrounds were being extracted properly—and
even when they were, a few artifacts remained:</p>

<div style="margin-bottom: 15px; overflow: hidden; text-align: center;">
    
        <img src="https://gradientscience.org/assets/3db/backgrounds-manual/1.JPEG" style="width: 15%; margin: 2px; display: inline;"/>
    
        <img src="https://gradientscience.org/assets/3db/backgrounds-manual/2.JPEG" style="width: 15%; margin: 2px; display: inline;"/>
    
        <img src="https://gradientscience.org/assets/3db/backgrounds-manual/3.JPEG" style="width: 15%; margin: 2px; display: inline;"/>
    
        <img src="https://gradientscience.org/assets/3db/backgrounds-manual/4.JPEG" style="width: 15%; margin: 2px; display: inline;"/>
    
        <img src="https://gradientscience.org/assets/3db/backgrounds-manual/5.JPEG" style="width: 15%; margin: 2px; display: inline;"/>
    
        <img src="https://gradientscience.org/assets/3db/backgrounds-manual/6.JPEG" style="width: 15%; margin: 2px; display: inline;"/>
    
</div>

<p>3DB lets us reproduce these findings effortlessly and without introducing
such artifacts. To demonstrate this, we use 3DB to render our mug 3D model on
hundreds of HDRI backgrounds, resulting in images such as:</p>

<div style="margin-bottom: 15px; overflow: hidden;">
    
        <img src="https://gradientscience.org/assets/3db/background-renders/1.png" style="float: right; width: 20%;"/>
    
        <img src="https://gradientscience.org/assets/3db/background-renders/2.png" style="float: right; width: 20%;"/>
    
        <img src="https://gradientscience.org/assets/3db/background-renders/3.png" style="float: right; width: 20%;"/>
    
        <img src="https://gradientscience.org/assets/3db/background-renders/4.png" style="float: right; width: 20%;"/>
    
        <img src="https://gradientscience.org/assets/3db/background-renders/5.png" style="float: right; width: 20%;"/>
    
        <img src="https://gradientscience.org/assets/3db/background-renders/6.png" style="float: right; width: 20%;"/>
    
        <img src="https://gradientscience.org/assets/3db/background-renders/7.png" style="float: right; width: 20%;"/>
    
        <img src="https://gradientscience.org/assets/3db/background-renders/8.png" style="float: right; width: 20%;"/>
    
        <img src="https://gradientscience.org/assets/3db/background-renders/9.png" style="float: right; width: 20%;"/>
    
        <img src="https://gradientscience.org/assets/3db/background-renders/10.png" style="float: right; width: 20%;"/>
    
</div>

<p>We then analyze the performance of a pretrained ResNet-18Recall that this model
obtains 42% accuracy on the corresponding "coffee mug" ImageNet class subset.on these images. We
find that the performance of the classifier varies significantly across
backgrounds, and that accuracy correlates with a crude measure of
“background simplicity” (the JPEG compressed size of the image—with smaller size corresponding to being more simple).</p>

<p><img alt="Simplicity versus model accuracy for HDRI backgrounds" src="https://gradientscience.org/assets/3db/mug_background_complexity.png"/></p>

<div class="caption">
A graph plotting average accuracy of our pre-trained ImageNet model (y-axis) on
images rendered by 3DB while varying the complexity of the rendering backgrounds
(x-axis). 
</div>

<p><strong>A note on compositionality</strong>: An important part of 3DB that we don’t discuss here is compositionality, i.e., the ability to put together multiple controls and study their joint effect. For example, in our paper we studied how a model’s prediction vary with various zoom levels and backgrounds of an object. We found that the optimal zoom level varies a lot by background.</p>

<details>
<strong>Show/hide code and instructions</strong>
<div class="code-container">
    <input checked="" class="tab1" id="bg-tab1" name="bg-tab" type="radio"/>
    <label for="bg-tab1"><i class="fa fa-gear"/>  Setup</label>
    <input class="tab2" id="bg-tab2" name="bg-tab" type="radio"/>
    <label for="bg-tab2"><i class="fa fa-code"/>  Config (backgrounds.yaml)</label>
    <input class="tab3" id="bg-tab3" name="bg-tab" type="radio"/>
    <label for="bg-tab3"><i class="fa fa-search"/>  Analysis (analyze_bgs.py)</label>
    <div class="line"/>
    <div class="content-container">
<div class="content c1"><pre class="wrapped"><code class="bash">
# $BLENDER_DATA/blender_environments` contains several backgrounds and
# $BLENDER_DATA/blender_models contains the 3D model of a mug.
export BLENDER_DATA=$(realpath blog_demo)/data/backgrounds
# if you want to use the pre-written material in blog_demo, uncomment:
# cd blog_demo

# (Optional) Download additional backgrounds you want---e.g., from
# https://hdrihaven.com/hdris/ (both `.hdr` and `.blend` files work) and put
# them in BLENDER_DATA/blender_environments. 
wget https://hdrihaven.com/hdris/PATH/TO/HDRI \
    -O $BLENDER_DATA/blender_environments

# Direct results
export RESULTS_FOLDER='results_backgrounds'

# Run 3DB (with the YAML file from the next pane saved as `backgrounds.yaml`):
threedb_workers 1 $BLENDER_DATA 5555 &gt; client.log &amp;
threedb_master $BLENDER_DATA backgrounds.yaml $RESULTS_FOLDER 5555

# Analyze results in the dashboard
python -m threedboard $RESULTS_FOLDER --port 3000
# Navigate to localhost:3000 to view the results!

# Finally, run analysis using pandas (third pane)
python analyze_bgs.py

</code></pre></div>
<div class="content c2"><pre><code class="YAML">
base_config: "base.yaml"
policy:
  module: "threedb.policies.random_search"
  samples: 20
controls:
  - module: "threedb.controls.blender.orientation"
  - module: "threedb.controls.blender.camera"
    zoom_factor: [0.7, 1.3]
    aperture: 8.
    focal_length: 50.
  - module: "threedb.controls.blender.denoiser"

</code></pre></div>
<div class="content c3"><pre><code class="python">
import pandas as pd
import numpy as np
import json

log_lines = open('results_backgrounds/details.log').readlines()
class_map = json.load(open('results_backgrounds/class_maps.json'))
df = pd.DataFrame.from_records(list(map(json.loads, log_lines)))
df['prediction'] = df['prediction'].apply(lambda x: class_map[x[0]])
df['is_correct'] = (df['is_correct'] == 'True')

res = df.groupby('environment').agg(accuracy=('is_correct', 'mean'),
        most_frequent_prediction=('prediction', lambda x: x.mode()))
print(res)

</code></pre></div>
</div>
</div>
</details>

<h2 id="texture-bias">Texture Bias</h2>
<p>Another <a href="https://arxiv.org/abs/1811.12231v2">recent study</a> of neural network biases showed that in
contrast to humans, convolutional neural networks (CNNs) rely more on texture
to recognize objects than on shape. The example below typifies this
phenomenon—a cat with an elephant texture is recognized as a cat by humans,
but as an elephant by CNNs:</p>

<p><img alt="Cue-conflict images introduced by Geirhos et al." src="https://gradientscience.org/assets/3db/cue_conflict.png"/></p>
<div class="caption">
An example of the cue-conflict images introduced by Geirhos et al. Combining the
elephant texture with the cat shape results in a mixed image on which CNNs
consistently predict with the texture signal.
</div>

<p>This example and others like it (dubbed ‘cue-conflict’ images) provide a
striking illustration of the contrast between human and CNN-based
classification mechanisms. Still, just as in the case of image backgrounds,
creating such images typically necessitates time, technical skill,
quality control, and/or introduction of unwanted artifacts (for example, in the above figure,
ideally we would modify only the texture of the cat without altering the background).</p>

<p>However, using 3DB we can easily collect photorealistic empirical evidence of
texture bias. Without modifying the internal 3DB codebase at all,
one can write a <a href="https://github.com/3db/3db/blob/main/threedb/controls/blender/material.py">custom control</a> that modifies the texture of
objects in the scene while keeping the rest intact. With this custom control
in placeIn fact, the texture-swapping control for this experiment is now 
pre-packaged with 3DB, since we already wrote it ourselves!, one can simply 
randomize the texture of the mug across various
backgrounds, poses and camera parameters before stratifying results:</p>

<p><img alt="Chungus" src="https://gradientscience.org/assets/3db/texture_swap_histograms.png"/></p>

<p>The performance of the pretrained model on mugs (and other objects)
deteriorates severely upon replacing the mug’s texture with a “wrong” one,
providing clear corroborating evidence of the texture bias! We noticed in our
experiments that for some textures (e.g., zebra), the coffee mug was
consistently misclassified as the corresponding animal, whereas for others
(e.g., crocodile), the mug is misclassified as either a related class (e.g.,
turtle or other reptile), or as an unrelated object (e.g., a trash can).</p>

<details>
<strong>Show/hide code and instructions</strong>
<div class="code-container">
    <input checked="" class="tab1" id="texture-tab1" name="texture-tab" type="radio"/>
    <label for="texture-tab1"><i class="fa fa-gear"/>  Setup</label>
    <input class="tab2" id="texture-tab2" name="texture-tab" type="radio"/>
    <label for="texture-tab2"><i class="fa fa-code"/>  Config (texture_swaps.yaml)</label>
    <input class="tab3" id="texture-tab3" name="texture-tab" type="radio"/>
    <label for="texture-tab3"><i class="fa fa-search"/>  Analysis (analyze_ts.py)</label>
    <div class="line"/>
    <div class="content-container">
<div class="content c1">
<pre class="wrapped"><code class="bash">
# ${BLENDER_DATA}/blender_environments contains several backgrounds,
# ${BLENDER_DATA}/blender_models contain the 3D model of a mug.
export BLENDER_DATA=$(realpath blog_demo)/data/texture_swaps

# List the materials that we will use for this post:
ls blog_demo/data/texture_swaps/blender_control_material
# You can also make or download blender materials corresponding 
# to other textures you want to test, and add them to that folder 

# if you want to use the pre-written material in blog_demo, uncomment:
# cd blog_demo

export RESULTS_FOLDER=results_texture

# Run 3DB (with the YAML file from the next pane saved as texture_swaps.yaml):
threedb_workers 1 $BLENDER_DATA 5555 &gt; client.log &amp;
threedb_master $BLENDER_DATA texture_swaps.yaml $RESULTS_FOLDER 5555

# Analyze results in the dashboard
python -m threedboard $RESULTS_FOLDER --port 3000
# Navigate to localhost:3000 to view the results!

# Finally, run analysis using pandas (copy from third pane)
python analyze_ts.py

</code></pre>
</div>
<div class="content c2"><pre><code class="YAML">
base_config: "base.yaml"
controls:
  - module: "threedb.controls.blender.orientation"
    rotation_x: -1.57
    rotation_y: 0.
    rotation_z: [-3.14, 3.14]
  - module: "threedb.controls.blender.position"
    offset_x: 0.
    offset_y: 0.5
    offset_z: 0.
  - module: "threedb.controls.blender.pin_to_ground"
    z_ground: 0.25
  - module: "threedb.controls.blender.camera"
    zoom_factor: [0.7, 1.3]
    view_point_x: 1.
    view_point_y: 1.
    view_point_z: [0., 1.]
    aperture: 8.
    focal_length: 50.
  - module: "threedb.controls.blender.material"
    replacement_material: ["cow.blend", "elephant.blend", "zebra.blend", "crocodile.blend", "keep_original"]
  - module: "threedb.controls.blender.denoiser"

</code></pre></div>
<div class="content c3"><pre><code class="python">
import pandas as pd
import numpy as np
import json

log_lines = open('results_texture/details.log').readlines()
class_map = json.load(open('results_texture/class_maps.json'))
df = pd.DataFrame.from_records(list(map(json.loads, log_lines)))
df = df.drop('render_args', axis=1).join(pd.DataFrame(df.render_args.values.tolist()))
df['prediction'] = df['prediction'].apply(lambda x: class_map[x[0]])
df['is_correct'] = (df['is_correct'] == 'True')

res = df.groupby('MaterialControl.replacement_material').agg(acc=('is_correct', 'mean'),
      most_frequent_prediction=('prediction', lambda x: x.mode()))
print(res)

</code></pre></div>
    </div>
</div>
</details>

<h2 id="part-of-object-attribution">Part-of-Object Attribution</h2>

<p>Beyond general hypotheses about model biases, 3DB allows us to test vision
systems on a more fine-grained level. In the case of our running mug example,
for instance, we can use the platform to understand which specific parts of
its 3D mesh correlate with classifier accuracy. Specifically, below we
generate (and classify) scenes with random mug positions, rotations, and
backgrounds. Since 3DB stores texture-coordinate information for each
rendering, we can reconstruct a three-dimensional heatmap that encodes, for
each point on the surface of the mug, the classifier’s accuracy conditioned
on that point being visible:</p>

<p style="text-align: center;">
    <img src="https://gradientscience.org/assets/3db/heatmap_mug/heatmap_mug_1.png" style="width: 18%; display: inline;"/>
    <img src="https://gradientscience.org/assets/3db/heatmap_mug/heatmap_mug_2.png" style="width: 18%; display: inline;"/>
    <img src="https://gradientscience.org/assets/3db/heatmap_mug/heatmap_mug_3.png" style="width: 18%; display: inline;"/>
    <img src="https://gradientscience.org/assets/3db/heatmap_mug/heatmap_mug_4.png" style="width: 18%; display: inline;"/>
    <img src="https://gradientscience.org/assets/3db/heatmap_mug/heatmap_mug_5.png" style="width: 18%; display: inline;"/>
</p>
<div class="caption" style="margin-top: 0px; margin-bottom: 15px;">
    A part-of-object attribution heatmap for our mug 3D model. <span style="color: red;">Red</span> pixels indicate areas whose visibility most
    improves accuracy, whereas <span style="color: blue;">blue</span> areas'
    visibility correlates with incorrect classifications.
</div>

<p>A number of phenomena stand out from this heatmap, including:</p>

<ol>
  <li>The classifier is worse when the side of the mug opposite the handle is seen.</li>
  <li>The classifier is more accurate when the bottom rim is visible.</li>
  <li>The classifier performs worst when the inside of the mug is visible.</li>
</ol>

<details>
<strong>Show/hide code and instructions</strong>
<div class="code-container">
    <input checked="" class="tab1" id="pobj-tab1" name="pobj-tab" type="radio"/>
    <label for="pobj-tab1"><i class="fa fa-gear"/>  Setup</label>
    <input class="tab2" id="pobj-tab2" name="pobj-tab" type="radio"/>
    <label for="pobj-tab2"><i class="fa fa-code"/>  Config (part_of_object.yaml)</label>
    <input class="tab3" id="pobj-tab3" name="pobj-tab" type="radio"/>
    <label for="pobj-tab3"><i class="fa fa-search"/>  Analysis (analyze_po.py)</label>
    <div class="line"/>
    <div class="line"/>
    <div class="content-container">
<div class="content c1"><pre class="wrapped"><code class="makefile">
# point BLENDER_DATA to the environments and models for this experiment
export BLENDER_DATA=$(realpath blog_demo)/data/part_of_object
# if you want to use the pre-written material in blog_demo, uncomment:
# cd blog_demo

# Optionally: download additional backgrounds (`.hdr` or `.blend`) e.g.,
wget URL -O $BLENDER_DATA/blender_environments/new_env.hdr

# Point results folder to where you want output written
export RESULTS_FOLDER='results_part_of_object'

# Run 3DB (with the YAML file from the next pane):
threedb_workers 1 $BLENDER_DATA 5555 &gt; client.log &amp;
threedb_master $BLENDER_DATA part_of_object.yaml $RESULTS_FOLDER 5555

# Analyze results in the dashboard
python -m threedboard $RESULTS_FOLDER --port 3000
# Navigate to localhost:3000 to view the results!

# Run `part_of_object.py` (third pane) to generate the heat map of the mug.
python po_analysis.py

</code></pre></div>
<div class="content c2"><pre><code class="YAML">
base_config: "base.yaml"
policy:
  module: "threedb.policies.random_search"
  samples: 20
render_args:
  engine: 'threedb.rendering.render_blender'
  resolution: 256
  samples: 16
  with_uv: True
controls:
  - module: "threedb.controls.blender.orientation"
    rotation_x: -1.57
    rotation_y: 0.
    rotation_z: [-3.14, 3.14]
  - module: "threedb.controls.blender.camera"
    zoom_factor: [0.7, 1.3]
    view_point_x: 1.
    view_point_y: 1.
    view_point_z: 1.
    aperture: 8.
    focal_length: 50.
  - module: "threedb.controls.blender.denoiser"
  - module: "threedb.controls.blender.background"
    H: 1.
    S: 0.
    V: 1.
</code></pre></div>
<div class="content c3"><pre><code class="python">
import pandas as pd
import numpy as np
import json
from PIL import Image

DIR = 'results_part_of_object'
log_lines = open(f'{DIR}/details.log').readlines()
df = pd.DataFrame.from_records(list(map(json.loads, log_lines)))

# From class index to class name (for readability)
class_map = json.load(open(f'{DIR}/class_maps.json'))
df['prediction'] = df['prediction'].apply(lambda x: class_map[x[0]])

# We'll be a little lenient here to get a more interesting heatmap
df['is_correct'] = df['prediction'].isin(['cup', 'coffee mug'])

uv_num_correct = np.zeros((256, 256))
uv_num_visible = np.zeros((256, 256))
for imid in df["id"].unique().tolist():
    is_correct = float(df.set_index('id').loc[imid]['is_correct'])
    vis_coords_im = Image.open(f'{DIR}/images/{imid}_uv.png')
    vis_coords = np.array(vis_coords_im).reshape(-1, 3)
    # R and G channels encode texture coordinates (x, y), 
    # B channel is 255 for object and 0 for background
    # So we will filter by B then only look at R and G.
    vis_coords = vis_coords[vis_coords[:,2] &gt; 0][:,:2]

    uv_num_visible[vis_coords[:,0], vis_coords[:,1]] += 1.
    uv_num_correct[vis_coords[:,0], vis_coords[:,1]] += is_correct

# Accuracy = # correct / # visible
uv_accuracy = uv_num_correct / (uv_num_visible + 1e-4)

# Saves a black-and-white heatmap
Image.fromarray((255 * uv_accuracy).astype('uint8'))

</code></pre></div>
</div>
</div>
</details>
<p><br/></p>

<p>Now that we have hypotheses regarding model performance, we can test them! Inspecting
the ImageNet validation set, we found that our classifier indeed (a) struggles on coffee mugs when the
handle is not showing (providing a feasible explanation for (1), since the side
opposite the handle is only visible when the handle itself isn’t), and (b)
performs worse at higher camera angles (providing a plausible explanation for
(2)). We want to focus, however, on the third phenomenon,
i.e., that the classifier performs quite poorly whenever the inside of the
mug is visible. Why could this be the case? We can use 3DB to gain insight into the
phenomenon. Specifically, we want to test the following hypothesis: when
classifying mugs, does our ImageNet model rely on the exact liquid inside the
cup?</p>

<p>We investigate this hypothesis by writing a custom control that fills
our mug with various liquids (more precisely, a parameterized mixture of
water, milk, and coffee):</p>

<p><img alt="Examples of the mugs rendered in this experiment" src="https://gradientscience.org/assets/3db/mug_liquid_experiment_samples.png"/></p>
<div class="caption">
Our running example mug, filled with different parameterized liquids: 100% water
(top left), 100% coffee (top right), 100% milk (bottom right), and a coffee-milk
mixture (bottom left)
</div>

<p>In contrast to the last experiment (where we varied the orientation of the
mug), we render scenes containing the mug in a fixed set of poses that reveal
the contents—just as in the last experiment, however, we still vary
background and mug location. We visualize the results below—each cell in
the heatmap corresponds to a fixed mixture of coffee, water, and milk (i.e.,
the labeled corners are 100% coffee, 100% milk, and 100% water, and the other
cells are linear interpolations of these ratios) and the color of the cell
encodes the relative accuracy of the classifier when the mug is filled with
that liquid:</p>

<!-- <img src="/assets/3db/mug_liquid_experiment_simplex.png" 
    class="bigimg" alt="A diagram illustrating how ImageNet classifiers are
    sensitive to the liquid inside of the rendered mug." /> -->

<p><img alt="" src="https://gradientscience.org/assets/3db/mug_liquid_experiment_simplex.png"/></p>

<div class="caption">
Measuring the relative effect of the liquid mixture in the mug on model
predictions. Each cell represents a specific liquid mixture, and the color of
the cell represents the tendency of the model (averaged over random viewpoints
and relative to the other cells) to predict "cup"/"pill bottle," "bucket," or
"mug."
</div>

<p>It turns out that mug content indeed highly impacts classification:
our model is much less likely to correctly classify a mug that doesn’t contain coffee!
This is just one example of how 3DB can help in proving or disproving hypotheses
about model behavior.</p>

<h2 id="from-simulation-to-reality">From Simulation to Reality</h2>

<p>So far, we’ve used 3DB to discover ML models’ various failure modes and biases
via photorealistic rendering. To what extent though do the insights
gleaned from simulated 3DB experiments actually “transfer” to the physical
world?</p>

<p>To test such transferability, we began by creating a 3D model of a physical room we
had access to. We also collected eight different 3D models with closely matching
physical world counterparts—including the mug analyzed above. Next, we used 3DB to find correctly and incorrectly classified
configurations (pose, orientation, location) of these eight objects inside that
room. Finally, we replicated these poses (to
the best of our abilities) in the physical room, and took photos with a
cellphone camera:</p>

<p><img alt="Samples from our physical-world experiment." class="bigimg" src="https://gradientscience.org/assets/3db/real_life_exp_samples.png"/></p>

<div class="caption">
Examples of simulated scenes (top) and their re-created counterparts (bottom)
from our physical-world experiment.
</div>

<p>We classified these photos with the same vision model as before and measured
how often the simulated classifier correctness matched correctness on the
real photographs. We observed an ~85% match! So the failure
modes identified by 3DB are not merely simulation artifacts, and can indeed arise in
the real world.</p>

<h2 id="conclusion">Conclusion</h2>

<p>3DB is a flexible, easy-to-use, and extensible framework for
identifying model failure modes, uncovering biases, and testing fine-grained
hypotheses about model behavior. We hope it will prove to be a useful tool
for debugging vision models.</p>
<h2 id="bonus-object-detection-web-dashboard-and-more">Bonus: Object Detection, Web Dashboard, and more!</h2>

<p>We’ll wrap up by highlighting some additional capabilities of 3DB that we didn’t
get to demonstrate in this blog post:</p>

<h3 id="3dboard-a-web-interface-for-exploring-results">3DBoard: a web interface for exploring results</h3>

<p>In all of the code examples above, we showed how to analyze the results of a 3DB
experiment by loading the output into a <code class="language-plaintext highlighter-rouge">pandas</code> dataframe. For additional
convenience, however, 3DB also comes with a web-based dashboard for exploring
experimental results. The following command suffices to visualize the texture swaps experiment from earlier:</p>

<pre style="padding: 0; margin: 0;"><code class="bash">
python -m threedboard results_texture/ --port 3000

</code>
</pre>

<p>Navigating to <code class="language-plaintext highlighter-rouge">YOUR_IP:3000</code> should lead you to a page that looks like this:</p>

<p><img alt="Dashboard screenshot" src="https://gradientscience.org/assets/3db/dashboard_screenshot.png"/></p>

<h3 id="object-detection-and-other-tasks">Object detection and other tasks</h3>

<p>In this blog post, we focused on using 3DB to analyze image classification
models. However, the library also supports object detection out-of-the-box, and
can easily be extended to support a variety of image-based tasks (e.g.,
segmentation or regression-based tasks). For example, below we provide a simple
end-to-end object detection example:</p>

<details>
<strong>Show/hide code and instructions</strong>
<div class="code-container">
    <input checked="" class="tab1" id="objdet-tab1" name="objdet-tab" type="radio"/>
    <label for="objdet-tab1"><i class="fa fa-gear"/>  Setup</label>
    <input class="tab2" id="objdet-tab2" name="objdet-tab" type="radio"/>
    <label for="objdet-tab2"><i class="fa fa-code"/>  Config (part_of_object.yaml)</label>
    <div class="line"/>
    <div class="line"/>
    <div class="content-container">
<div class="content c1"><pre class="wrapped"><code class="makefile">
# The object detection example is separate from the rest of the blog demo, so
# run the following in a separate repo:
git clone https://github.com/3db/object_detection_demo

# The repo has a data/ folder containing the Blender model (a banana) and some
# HDRI backgrounds, a classmap.json file mapping the UID of the model to a COCO
# class, and the detection.yaml file from the next pane.
cd object_detection_demo/

export BLENDER_DATA=data/
export RESULTS_FOLDER=results/

# Run 3DB
threedb_workers 1 $BLENDER_DATA 5555 &gt; client.log &amp; 
threedb_master $BLENDER_DATA detection.yaml $RESULTS_FOLDER 5555

# Analyze results in the dashboard
python -m threedboard $RESULTS_FOLDER --port 3000
# Navigate to localhost:3000 to view the results!

</code></pre></div> 
<div class="content c2"><pre><code class="YAML">
inference:
  module: 'torchvision.models.detection'
  class: 'retinanet_resnet50_fpn'
  label_map: './resources/coco_mapping.json'
  normalization:
    mean: [0., 0., 0.]
    std: [1., 1., 1.]
  resolution: [224, 224]
  args:
    pretrained: True
evaluation:
  module: 'threedb.evaluators.detection'
  args:
    iou_threshold: 0.5
    nms_threshold: 0.1
    max_num_boxes: 10
    classmap_path: 'classmap.json'
render_args:
  engine: 'threedb.rendering.render_blender'
  resolution: 256
  samples: 16
  with_segmentation: true
policy:
  module: "threedb.policies.random_search"
  samples: 2
logging:
  logger_modules:
    - "threedb.result_logging.image_logger"
    - "threedb.result_logging.json_logger"
controls:
  - module: "threedb.controls.blender.orientation"
  - module: "threedb.controls.blender.camera"
    zoom_factor: [0.7, 1.3]
    aperture: 8.
    focal_length: 50.
  - module: "threedb.controls.blender.denoiser"

</code></pre></div>
</div>
</div>
</details></div>
    </summary>
    <updated>2021-06-08T00:00:00Z</updated>
    <published>2021-06-08T00:00:00Z</published>
    <source>
      <id>https://gradientscience.org/</id>
      <author>
        <name>Gradient Science</name>
      </author>
      <link href="https://gradientscience.org/" rel="alternate" type="text/html"/>
      <link href="https://gradientscience.org/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Research highlights and perspectives on machine learning and optimization from MadryLab.</subtitle>
      <title>gradient science</title>
      <updated>2021-06-19T22:44:30Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://gradientscience.org/3db/</id>
    <link href="https://gradientscience.org/3db/" rel="alternate" type="text/html"/>
    <title>3DB: A Framework for Debugging Vision Models</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a class="bbutton" href="https://arxiv.org/abs/2106.03805" style="float: left; width: 45%; margin-bottom: 0;">
<i class="fas fa-file-pdf"/>
    Paper
</a>
<a class="bbutton" href="https://github.com/3db/3db/" style="float: left; width: 45%; margin-bottom: 0;">
<i class="fab fa-github"/>
   Project Repo
</a>
<a class="bbutton" href="https://3db.github.io/3db/usage/quickstart.html" style="float: left; width: 45%;">
<i class="fas fa-file-alt"/>
   Documentation and Guides
</a> 
<a class="bbutton" href="https://github.com/3db/blog_demo/" style="float: left; width: 45%;">
<i class="fab fa-github"/>
   Blog Demo
</a> 
<br/></p>

<p><i>In our <a href="https://arxiv.org/abs/2106.03805">latest paper</a>, in collaboration with Microsoft Research, we introduce
3DB: an extendable, unified framework for debugging and analyzing vision models
using photorealistic simulation. We’re releasing 3DB as a package, accompanied
by extensive API documentation, guides, and demos.</i></p>

<p><em>Note: this post contains some interactive plots and 3D models that use
JavaScript: click <a href="https://gradientscience.org/3db-light/">here</a> for a JS-free version of this post.</em></p>

<p>Identifying failure modes and biases in vision models is a rapidly
emerging challenge in machine learning. In high-stakes
applications, simply deploying models and collecting failures that arise in
the wild is often difficult, expensive, and irresponsible. To this end, a
recent line of work in vision focuses on identifying model failure
modes via in-depth analyses of <a href="https://arxiv.org/abs/1712.02779">image transformations</a> and 
<a href="https://arxiv.org/abs/1903.12261">corruptions</a>, <a href="https://objectnet.dev">object orientations</a>,
<a href="https://gradientscience.org/background/">backgrounds</a>, or <a href="https://arxiv.org/abs/1811.12231v2">shape-texture conflicts</a>. These studies 
(and other similarly important ones) reveal a variety of patterns of
performance degradation in vision models. Still, performing each such study
requires time, developing (often complex)
toolingFor <a href="https://gradientscience.org/background/">our study of image backgrounds</a>, for example, we used a
combination of bounding boxes and classical computer vision tools to crop out
image backgrounds. We then had to manually filter out the images for which
the tools failed. Even for the images where the toolkit succeeded, there
remained inevitable cropping artifacts., and a willingness to settle for less than perfect simulations of each
potential failure mode. Our question is: can we support reliable discovery of model failures in a systematic,
automated, and unified way?</p>

<h2 id="3db-a-rendering-based-debugging-platform">3DB: A Rendering-based Debugging Platform</h2>

<p><img alt="A sampling of the analyses enabled by 3DB." class="bigimg" src="https://gradientscience.org/assets/3db/3db_headline.png"/></p>
<div class="caption" style="margin-top: 0;">
A sampling of the analyses enabled by 3DB.
</div>

<p>In our <a href="https://arxiv.org/abs/2106.03805">latest paper</a>, we try to make progress on this question and propose
3DB, a platform for automatically identifying and analyzing the failure modes
of computer vision models using 3D rendering. 3DB aims to allow users to go
from a testable, robustness-based hypothesis to concrete, photorealistic
experimental evidence with minimal time and effort.</p>

<p>The platform revolves around the modular workflow pictured below. First,
users specify a set of 3D objects and environments, as well as a set of 3D
(or 2D) transformations called controls that determine the space of
admissible object-environment configurations. 3DB then renders a myriad of
admissible scenes and feeds them through the user’s computer vision model of
choice. The user can finally stratify, aggregate, or otherwise analyze the
results either by reading the outputted JSON, or through the pre-packaged
dashboard.</p>

<p><img alt="An illustration of the 3DB workflow." class="bigimg" src="https://gradientscience.org/assets/3db/workflow.png"/></p>

<p>3DB easily adapts to a variety of use cases: in particular, users can
modify and swap out any part of this pipeline (e.g., the renderer, the
logger, the model type, or the controls) for their own custom-written
components, without needing to modify any of the 3DB codebase. We’ve compiled <a href="https://3db.github.io/3db/">guides</a>,
extensive <a href="https://3db.github.io/3db/api_doc.html">API documentation</a>, and a
<a href="https://github.com/3db/demo">full demo</a> showing how 3DB streamlines model debugging.</p>

<p><strong>In fact, this blog post will double as another demo! We’ll present the (short) code
necessary to reproduce every plot in the post below using 3DB. You can download 
the aggregated code for this blog post <a href="https://github.com/3db/blog_demo">here</a>.</strong></p>

<p><em>To set up, follow the steps below—then, in the remainder of this post, press
“Show/hide code and instructions” to see the steps necessary to reproduce each
experiment below.</em></p>
<div class="code-container">
  <input checked="" class="tab1" id="general-tab1" name="general-tab" type="radio"/>
  <label for="general-tab1"><i class="fa fa-gear"/>  Setup</label>
  <input class="tab2" id="general-tab2" name="general-tab" type="radio"/>
  <label for="general-tab2"><i class="fa fa-code"/>  Config (base.yaml)</label>
  <div class="line"/>
  <div class="content-container">
<div class="content c1">
<!-- <pre class='wrapped'><code class="markdown"> -->
<ol class="instructions">
<li>Clone the  <a href="https://github.com/3db/blog_demo">blog demo <i class="fab fa-github"/></a> repo</li>
<li>Run <pre>cd blog_demo</pre>, then <pre>bash setup.sh</pre> (assumes
<pre>unzip</pre> is installed) to download a large Blender environment, then
<pre>cd ../</pre></li>
<li>Install 3DB: <pre>curl -L https://git.io/Js8eT | bash /dev/stdin threedb</pre></li>
<li>Run <pre>conda activate threedb</pre></li>
<li>Our experiments below will need a <pre>BLENDER_DATA</pre> folder that contains two
subfolders: <pre>blender_models/</pre> containing 3D models (<pre>.blend</pre> files with a single
object whose name matches the filename), and <pre>blender_environments/</pre>
containing environments. We will provide you with these later</li> 
<li>Separately, make a file called <pre>base.yaml</pre> and paste in the configuration from the next pane.</li>
</ol>
<!-- </code></pre> -->
</div>
<div class="content c2"><pre><code class="YAML">
inference:
  module: 'torchvision.models'
  label_map: 'blog_demo/resources/imagenet_mapping.json'
  class: 'resnet18'
  normalization:
    mean: [0.485, 0.456, 0.406]
    std: [0.229, 0.224, 0.225]
  resolution: [224, 224]
  args:
    pretrained: True
evaluation:
  module: 'threedb.evaluators.classification'
  args:
    classmap_path: 'blog_demo/resources/ycb_to_IN.json'
    topk: 1
render_args:
  engine: 'threedb.rendering.render_blender'
  resolution: 256
  samples: 16
policy:
  module: "threedb.policies.random_search"
  samples: 5
logging:
  logger_modules:
    - "threedb.result_logging.image_logger"
    - "threedb.result_logging.json_logger"

</code></pre></div>
 </div>
</div>

<h2 id="using-3db">Using 3DB</h2>

<p>Prior works have already used 3D rendering (to great effect) to study biases
of machine learning models, including pose and context-based biases. Our goal
is not to propose a specific 3D-rendering based analysis, but
rather to provide an easy-to-use, highly extendable framework that unifies
prior analyses (both 3D and 2D) while enabling users to (a) conduct a host of
new analyses with the same ease and with realistic results; and (b)
effortlessly <em>compose</em> different factors of variation to understand their
interplay.</p>

<p>We’ll dedicate the rest of this post to illustrating how one
might actually use 3DB in practice, focusing on a single example 3D
model3DB works with any 3D model, and we refer the reader to 
<a href="https://arxiv.org/abs/2106.03805">our paper</a> for more examples and details.:</p>





<div id="mug-blocker" style="text-align: center;">
    
        
            
        
        
    
</div>
<div class="caption" style="margin-top: 0px; margin-bottom: 15px;">
    The 3D mug model that we'll be using throughout this post. <strong>
    Click to <a id="mug-interact">enable 
    interactivity</a>.</strong>
</div>

<p>In what follows, we will walk through example applications of 3DB to discover biases of
ML models (some previously documented, others not). For the sake of brevity,
we’ll highlight just a few of these (re-)discoveries—to see more, check out
the <a href="https://arxiv.org/abs/2106.03805">paper</a>. We’ll then demonstrate that the discoveries of 3DB
transfer pretty reliably to the real world!</p>

<p>Our experiments will all operate on an ImageNet-pretrained
ResNet-18The classifier has a ~70% validation-set
accuracy. that has 42% accuracy on images from the
“coffee mug” ImageNet subclass. While we only study classification in this blog post,
3DB also supports object detection and can be easily extended to support other
image-based tasks, such as semantic segmentation, too.</p>

<h2 id="image-background-sensitivity">Image Background Sensitivity</h2>

<p>In one of our <a href="https://gradientscience.org/background/">previous posts</a>,
we continued a long line of prior work (see, e.g.,
<a href="https://hal.archives-ouvertes.fr/hal-00171412/file/ZhangMarszalekLazebnikSchmid-IJCV07-ClassificationStudy.pdf">here</a>, <a href="https://arxiv.org/abs/1611.06596">here</a>, <a href="https://arxiv.org/abs/1911.08731">here</a>, etc.) showing that models can be
over-reliant on image backgrounds, and demonstrated that they are easily
broken by adversarially chosen backgrounds. To accomplish this, our prior
analysis used classical computer vision tools to separate foregrounds from
backgrounds, then pasted foregrounds from one image onto backgrounds from
another. This process was slow and required extensive quality control to
ensure that backgrounds and foregrounds were being extracted properly—and
even when they were, a few artifacts remained:</p>

<div style="margin-bottom: 15px; overflow: hidden; text-align: center;">
    
        <img src="https://gradientscience.org/assets/3db/backgrounds-manual/1.JPEG" style="width: 15%; margin: 2px; display: inline;"/>
    
        <img src="https://gradientscience.org/assets/3db/backgrounds-manual/2.JPEG" style="width: 15%; margin: 2px; display: inline;"/>
    
        <img src="https://gradientscience.org/assets/3db/backgrounds-manual/3.JPEG" style="width: 15%; margin: 2px; display: inline;"/>
    
        <img src="https://gradientscience.org/assets/3db/backgrounds-manual/4.JPEG" style="width: 15%; margin: 2px; display: inline;"/>
    
        <img src="https://gradientscience.org/assets/3db/backgrounds-manual/5.JPEG" style="width: 15%; margin: 2px; display: inline;"/>
    
        <img src="https://gradientscience.org/assets/3db/backgrounds-manual/6.JPEG" style="width: 15%; margin: 2px; display: inline;"/>
    
</div>

<p>3DB lets us reproduce these findings effortlessly and without introducing
such artifacts. To demonstrate this, we use 3DB to render our mug 3D model on
hundreds of HDRI backgrounds, resulting in images such as:</p>

<div style="margin-bottom: 15px; overflow: hidden;">
    
        <img src="https://gradientscience.org/assets/3db/background-renders/1.png" style="float: right; width: 20%;"/>
    
        <img src="https://gradientscience.org/assets/3db/background-renders/2.png" style="float: right; width: 20%;"/>
    
        <img src="https://gradientscience.org/assets/3db/background-renders/3.png" style="float: right; width: 20%;"/>
    
        <img src="https://gradientscience.org/assets/3db/background-renders/4.png" style="float: right; width: 20%;"/>
    
        <img src="https://gradientscience.org/assets/3db/background-renders/5.png" style="float: right; width: 20%;"/>
    
        <img src="https://gradientscience.org/assets/3db/background-renders/6.png" style="float: right; width: 20%;"/>
    
        <img src="https://gradientscience.org/assets/3db/background-renders/7.png" style="float: right; width: 20%;"/>
    
        <img src="https://gradientscience.org/assets/3db/background-renders/8.png" style="float: right; width: 20%;"/>
    
        <img src="https://gradientscience.org/assets/3db/background-renders/9.png" style="float: right; width: 20%;"/>
    
        <img src="https://gradientscience.org/assets/3db/background-renders/10.png" style="float: right; width: 20%;"/>
    
</div>

<p>We then analyze the performance of a pretrained ResNet-18Recall that this model
obtains 42% accuracy on the corresponding "coffee mug" ImageNet class subset.on these images. We
find that the performance of the classifier varies significantly across
backgrounds, and that accuracy correlates with a crude measure of
“background simplicity” (the JPEG compressed size of the image—with smaller size corresponding to being more simple).</p>

<div>
  <canvas id="myChart"/>
</div>

<div class="caption">
A graph plotting average accuracy of our pre-trained ImageNet model (y-axis) on
images rendered by 3DB while varying the complexity of the rendering backgrounds
(x-axis). 
</div>

<p><strong>A note on compositionality</strong>: An important part of 3DB that we don’t discuss here is compositionality, i.e., the ability to put together multiple controls and study their joint effect. For example, in our paper we studied how a model’s prediction vary with various zoom levels and backgrounds of an object. We found that the optimal zoom level varies a lot by background.</p>

<details>
<strong>Show/hide code and instructions</strong>
<div class="code-container">
    <input checked="" class="tab1" id="bg-tab1" name="bg-tab" type="radio"/>
    <label for="bg-tab1"><i class="fa fa-gear"/>  Setup</label>
    <input class="tab2" id="bg-tab2" name="bg-tab" type="radio"/>
    <label for="bg-tab2"><i class="fa fa-code"/>  Config (backgrounds.yaml)</label>
    <input class="tab3" id="bg-tab3" name="bg-tab" type="radio"/>
    <label for="bg-tab3"><i class="fa fa-search"/>  Analysis (analyze_bgs.py)</label>
    <div class="line"/>
    <div class="content-container">
<div class="content c1"><pre class="wrapped"><code class="bash">
# $BLENDER_DATA/blender_environments` contains several backgrounds and
# $BLENDER_DATA/blender_models contains the 3D model of a mug.
export BLENDER_DATA=$(realpath blog_demo)/data/backgrounds
# if you want to use the pre-written material in blog_demo, uncomment:
# cd blog_demo

# (Optional) Download additional backgrounds you want---e.g., from
# https://hdrihaven.com/hdris/ (both `.hdr` and `.blend` files work) and put
# them in BLENDER_DATA/blender_environments. 
wget https://hdrihaven.com/hdris/PATH/TO/HDRI \
    -O $BLENDER_DATA/blender_environments

# Direct results
export RESULTS_FOLDER='results_backgrounds'

# Run 3DB (with the YAML file from the next pane saved as `backgrounds.yaml`):
threedb_workers 1 $BLENDER_DATA 5555 &gt; client.log &amp;
threedb_master $BLENDER_DATA backgrounds.yaml $RESULTS_FOLDER 5555

# Analyze results in the dashboard
python -m threedboard $RESULTS_FOLDER --port 3000
# Navigate to localhost:3000 to view the results!

# Finally, run analysis using pandas (third pane)
python analyze_bgs.py

</code></pre></div>
<div class="content c2"><pre><code class="YAML">
base_config: "base.yaml"
policy:
  module: "threedb.policies.random_search"
  samples: 20
controls:
  - module: "threedb.controls.blender.orientation"
  - module: "threedb.controls.blender.camera"
    zoom_factor: [0.7, 1.3]
    aperture: 8.
    focal_length: 50.
  - module: "threedb.controls.blender.denoiser"

</code></pre></div>
<div class="content c3"><pre><code class="python">
import pandas as pd
import numpy as np
import json

log_lines = open('results_backgrounds/details.log').readlines()
class_map = json.load(open('results_backgrounds/class_maps.json'))
df = pd.DataFrame.from_records(list(map(json.loads, log_lines)))
df['prediction'] = df['prediction'].apply(lambda x: class_map[x[0]])
df['is_correct'] = (df['is_correct'] == 'True')

res = df.groupby('environment').agg(accuracy=('is_correct', 'mean'),
        most_frequent_prediction=('prediction', lambda x: x.mode()))
print(res)

</code></pre></div>
</div>
</div>
</details>

<h2 id="texture-bias">Texture Bias</h2>
<p>Another <a href="https://arxiv.org/abs/1811.12231v2">recent study</a> of neural network biases showed that in
contrast to humans, convolutional neural networks (CNNs) rely more on texture
to recognize objects than on shape. The example below typifies this
phenomenon—a cat with an elephant texture is recognized as a cat by humans,
but as an elephant by CNNs:</p>

<p><img alt="Cue-conflict images introduced by Geirhos et al." src="https://gradientscience.org/assets/3db/cue_conflict.png"/></p>
<div class="caption">
An example of the cue-conflict images introduced by Geirhos et al. Combining the
elephant texture with the cat shape results in a mixed image on which CNNs
consistently predict with the texture signal.
</div>

<p>This example and others like it (dubbed ‘cue-conflict’ images) provide a
striking illustration of the contrast between human and CNN-based
classification mechanisms. Still, just as in the case of image backgrounds,
creating such images typically necessitates time, technical skill,
quality control, and/or introduction of unwanted artifacts (for example, in the above figure,
ideally we would modify only the texture of the cat without altering the background).</p>

<p>However, using 3DB we can easily collect photorealistic empirical evidence of
texture bias. Without modifying the internal 3DB codebase at all,
one can write a <a href="https://github.com/3db/3db/blob/main/threedb/controls/blender/material.py">custom control</a> that modifies the texture of
objects in the scene while keeping the rest intact. With this custom control
in placeIn fact, the texture-swapping control for this experiment is now 
pre-packaged with 3DB, since we already wrote it ourselves!, one can simply 
randomize the texture of the mug across various
backgrounds, poses and camera parameters before stratifying results:</p>

<div class="widget">
    <div class="choices_one_full" id="gen">
    <span class="widgetheading" id="genclass">Choose an Image</span>
    </div>
    <div style="border-right: 3px white solid;">
        <div class="image-container" style="width: 32%; margin-right: 2%;">
            <h4 style="text-align: center;">Average accuracy (compare to 42% on ImageNet val set)</h4>
            <canvas id="gen1"/>
        </div>
        <div class="image-container" id="gen2" style="width: 66%;">
            <img class="example-texture" id="gen2-0"/>
            <img class="example-texture" id="gen2-1"/>
            <img class="example-texture" id="gen2-2"/>
            <img class="example-texture" id="gen2-3"/>
            <img class="example-texture" id="gen2-4"/>
            <img class="example-texture" id="gen2-5"/>
            <img class="example-texture" id="gen2-6"/>
            <img class="example-texture" id="gen2-7"/>
        </div>
    </div>
</div>
<div style="clear: both;"/>
<div class="caption">
<strong>Interactive demo</strong>: select any image in the top two rows to see additional
samples of that class.
</div>

<p>The performance of the pretrained model on mugs (and other objects)
deteriorates severely upon replacing the mug’s texture with a “wrong” one,
providing clear corroborating evidence of the texture bias! We noticed in our
experiments that for some textures (e.g., zebra), the coffee mug was
consistently misclassified as the corresponding animal, whereas for others
(e.g., crocodile), the mug is misclassified as either a related class (e.g.,
turtle or other reptile), or as an unrelated object (e.g., a trash can).</p>

<details>
<strong>Show/hide code and instructions</strong>
<div class="code-container">
    <input checked="" class="tab1" id="texture-tab1" name="texture-tab" type="radio"/>
    <label for="texture-tab1"><i class="fa fa-gear"/>  Setup</label>
    <input class="tab2" id="texture-tab2" name="texture-tab" type="radio"/>
    <label for="texture-tab2"><i class="fa fa-code"/>  Config (texture_swaps.yaml)</label>
    <input class="tab3" id="texture-tab3" name="texture-tab" type="radio"/>
    <label for="texture-tab3"><i class="fa fa-search"/>  Analysis (analyze_ts.py)</label>
    <div class="line"/>
    <div class="content-container">
<div class="content c1">
<pre class="wrapped"><code class="bash">
# ${BLENDER_DATA}/blender_environments contains several backgrounds,
# ${BLENDER_DATA}/blender_models contain the 3D model of a mug.
export BLENDER_DATA=$(realpath blog_demo)/data/texture_swaps

# List the materials that we will use for this post:
ls blog_demo/data/texture_swaps/blender_control_material
# You can also make or download blender materials corresponding 
# to other textures you want to test, and add them to that folder 

# if you want to use the pre-written material in blog_demo, uncomment:
# cd blog_demo

export RESULTS_FOLDER=results_texture

# Run 3DB (with the YAML file from the next pane saved as texture_swaps.yaml):
threedb_workers 1 $BLENDER_DATA 5555 &gt; client.log &amp;
threedb_master $BLENDER_DATA texture_swaps.yaml $RESULTS_FOLDER 5555

# Analyze results in the dashboard
python -m threedboard $RESULTS_FOLDER --port 3000
# Navigate to localhost:3000 to view the results!

# Finally, run analysis using pandas (copy from third pane)
python analyze_ts.py

</code></pre>
</div>
<div class="content c2"><pre><code class="YAML">
base_config: "base.yaml"
controls:
  - module: "threedb.controls.blender.orientation"
    rotation_x: -1.57
    rotation_y: 0.
    rotation_z: [-3.14, 3.14]
  - module: "threedb.controls.blender.position"
    offset_x: 0.
    offset_y: 0.5
    offset_z: 0.
  - module: "threedb.controls.blender.pin_to_ground"
    z_ground: 0.25
  - module: "threedb.controls.blender.camera"
    zoom_factor: [0.7, 1.3]
    view_point_x: 1.
    view_point_y: 1.
    view_point_z: [0., 1.]
    aperture: 8.
    focal_length: 50.
  - module: "threedb.controls.blender.material"
    replacement_material: ["cow.blend", "elephant.blend", "zebra.blend", "crocodile.blend", "keep_original"]
  - module: "threedb.controls.blender.denoiser"

</code></pre></div>
<div class="content c3"><pre><code class="python">
import pandas as pd
import numpy as np
import json

log_lines = open('results_texture/details.log').readlines()
class_map = json.load(open('results_texture/class_maps.json'))
df = pd.DataFrame.from_records(list(map(json.loads, log_lines)))
df = df.drop('render_args', axis=1).join(pd.DataFrame(df.render_args.values.tolist()))
df['prediction'] = df['prediction'].apply(lambda x: class_map[x[0]])
df['is_correct'] = (df['is_correct'] == 'True')

res = df.groupby('MaterialControl.replacement_material').agg(acc=('is_correct', 'mean'),
      most_frequent_prediction=('prediction', lambda x: x.mode()))
print(res)

</code></pre></div>
    </div>
</div>
</details>

<h2 id="part-of-object-attribution">Part-of-Object Attribution</h2>

<p>Beyond general hypotheses about model biases, 3DB allows us to test vision
systems on a more fine-grained level. In the case of our running mug example,
for instance, we can use the platform to understand which specific parts of
its 3D mesh correlate with classifier accuracy. Specifically, below we
generate (and classify) scenes with random mug positions, rotations, and
backgrounds. Since 3DB stores texture-coordinate information for each
rendering, we can reconstruct a three-dimensional heatmap that encodes, for
each point on the surface of the mug, the classifier’s accuracy conditioned
on that point being visible:</p>

<div id="heatmap-blocker" style="text-align: center;">
    
        
            
        
        
        
    
</div>
<div class="caption" style="margin-top: 0px; margin-bottom: 15px;">
    A part-of-object attribution heatmap for our mug 3D model. <span style="color: red;">Red</span> pixels indicate areas whose visibility most
    improves accuracy, whereas <span style="color: blue;">blue</span> areas'
    visibility correlates with incorrect classifications. <strong>Click here to <a id="heatmap-interact">enable
    interactivity</a>.</strong>
</div>

<p>A number of phenomena stand out from this heatmap, including:</p>

<ol>
  <li>The classifier is worse when the side of the mug opposite the handle is seen.</li>
  <li>The classifier is more accurate when the bottom rim is visible.</li>
  <li>The classifier performs worst when the inside of the mug is visible.</li>
</ol>

<details>
<strong>Show/hide code and instructions</strong>
<div class="code-container">
    <input checked="" class="tab1" id="pobj-tab1" name="pobj-tab" type="radio"/>
    <label for="pobj-tab1"><i class="fa fa-gear"/>  Setup</label>
    <input class="tab2" id="pobj-tab2" name="pobj-tab" type="radio"/>
    <label for="pobj-tab2"><i class="fa fa-code"/>  Config (part_of_object.yaml)</label>
    <input class="tab3" id="pobj-tab3" name="pobj-tab" type="radio"/>
    <label for="pobj-tab3"><i class="fa fa-search"/>  Analysis (analyze_po.py)</label>
    <div class="line"/>
    <div class="line"/>
    <div class="content-container">
<div class="content c1"><pre class="wrapped"><code class="makefile">
# point BLENDER_DATA to the environments and models for this experiment
export BLENDER_DATA=$(realpath blog_demo)/data/part_of_object
# if you want to use the pre-written material in blog_demo, uncomment:
# cd blog_demo

# Optionally: download additional backgrounds (`.hdr` or `.blend`) e.g.,
wget URL -O $BLENDER_DATA/blender_environments/new_env.hdr

# Point results folder to where you want output written
export RESULTS_FOLDER='results_part_of_object'

# Run 3DB (with the YAML file from the next pane):
threedb_workers 1 $BLENDER_DATA 5555 &gt; client.log &amp;
threedb_master $BLENDER_DATA part_of_object.yaml $RESULTS_FOLDER 5555

# Analyze results in the dashboard
python -m threedboard $RESULTS_FOLDER --port 3000
# Navigate to localhost:3000 to view the results!

# Run `part_of_object.py` (third pane) to generate the heat map of the mug.
python po_analysis.py

</code></pre></div>
<div class="content c2"><pre><code class="YAML">
base_config: "base.yaml"
policy:
  module: "threedb.policies.random_search"
  samples: 20
render_args:
  engine: 'threedb.rendering.render_blender'
  resolution: 256
  samples: 16
  with_uv: True
controls:
  - module: "threedb.controls.blender.orientation"
    rotation_x: -1.57
    rotation_y: 0.
    rotation_z: [-3.14, 3.14]
  - module: "threedb.controls.blender.camera"
    zoom_factor: [0.7, 1.3]
    view_point_x: 1.
    view_point_y: 1.
    view_point_z: 1.
    aperture: 8.
    focal_length: 50.
  - module: "threedb.controls.blender.denoiser"
  - module: "threedb.controls.blender.background"
    H: 1.
    S: 0.
    V: 1.
</code></pre></div>
<div class="content c3"><pre><code class="python">
import pandas as pd
import numpy as np
import json
from PIL import Image

DIR = 'results_part_of_object'
log_lines = open(f'{DIR}/details.log').readlines()
df = pd.DataFrame.from_records(list(map(json.loads, log_lines)))

# From class index to class name (for readability)
class_map = json.load(open(f'{DIR}/class_maps.json'))
df['prediction'] = df['prediction'].apply(lambda x: class_map[x[0]])

# We'll be a little lenient here to get a more interesting heatmap
df['is_correct'] = df['prediction'].isin(['cup', 'coffee mug'])

uv_num_correct = np.zeros((256, 256))
uv_num_visible = np.zeros((256, 256))
for imid in df["id"].unique().tolist():
    is_correct = float(df.set_index('id').loc[imid]['is_correct'])
    vis_coords_im = Image.open(f'{DIR}/images/{imid}_uv.png')
    vis_coords = np.array(vis_coords_im).reshape(-1, 3)
    # R and G channels encode texture coordinates (x, y), 
    # B channel is 255 for object and 0 for background
    # So we will filter by B then only look at R and G.
    vis_coords = vis_coords[vis_coords[:,2] &gt; 0][:,:2]

    uv_num_visible[vis_coords[:,0], vis_coords[:,1]] += 1.
    uv_num_correct[vis_coords[:,0], vis_coords[:,1]] += is_correct

# Accuracy = # correct / # visible
uv_accuracy = uv_num_correct / (uv_num_visible + 1e-4)

# Saves a black-and-white heatmap
Image.fromarray((255 * uv_accuracy).astype('uint8'))

</code></pre></div>
</div>
</div>
</details>
<p><br/></p>

<p>Now that we have hypotheses regarding model performance, we can test them! Inspecting
the ImageNet validation set, we found that our classifier indeed (a) struggles on coffee mugs when the
handle is not showing (providing a feasible explanation for (1), since the side
opposite the handle is only visible when the handle itself isn’t), and (b)
performs worse at higher camera angles (providing a plausible explanation for
(2)). We want to focus, however, on the third phenomenon,
i.e., that the classifier performs quite poorly whenever the inside of the
mug is visible. Why could this be the case? We can use 3DB to gain insight into the
phenomenon. Specifically, we want to test the following hypothesis: when
classifying mugs, does our ImageNet model rely on the exact liquid inside the
cup?</p>

<p>We investigate this hypothesis by writing a custom control that fills
our mug with various liquids (more precisely, a parameterized mixture of
water, milk, and coffee):</p>

<p><img alt="Examples of the mugs rendered in this experiment" src="https://gradientscience.org/assets/3db/mug_liquid_experiment_samples.png"/></p>
<div class="caption">
Our running example mug, filled with different parameterized liquids: 100% water
(top left), 100% coffee (top right), 100% milk (bottom right), and a coffee-milk
mixture (bottom left)
</div>

<p>In contrast to the last experiment (where we varied the orientation of the
mug), we render scenes containing the mug in a fixed set of poses that reveal
the contents—just as in the last experiment, however, we still vary
background and mug location. We visualize the results below—each cell in
the heatmap corresponds to a fixed mixture of coffee, water, and milk (i.e.,
the labeled corners are 100% coffee, 100% milk, and 100% water, and the other
cells are linear interpolations of these ratios) and the color of the cell
encodes the relative accuracy of the classifier when the mug is filled with
that liquid:</p>

<!-- <img src="/assets/3db/mug_liquid_experiment_simplex.png" 
    class="bigimg" alt="A diagram illustrating how ImageNet classifiers are
    sensitive to the liquid inside of the rendered mug." /> -->

<p><img alt="" src="https://gradientscience.org/assets/3db/mug_liquid_experiment_simplex.png"/></p>

<div class="caption">
Measuring the relative effect of the liquid mixture in the mug on model
predictions. Each cell represents a specific liquid mixture, and the color of
the cell represents the tendency of the model (averaged over random viewpoints
and relative to the other cells) to predict "cup"/"pill bottle," "bucket," or
"mug."
</div>

<p>It turns out that mug content indeed highly impacts classification:
our model is much less likely to correctly classify a mug that doesn’t contain coffee!
This is just one example of how 3DB can help in proving or disproving hypotheses
about model behavior.</p>

<h2 id="from-simulation-to-reality">From Simulation to Reality</h2>

<p>So far, we’ve used 3DB to discover ML models’ various failure modes and biases
via photorealistic rendering. To what extent though do the insights
gleaned from simulated 3DB experiments actually “transfer” to the physical
world?</p>

<p>To test such transferability, we began by creating a 3D model of a physical room we
had access to. We also collected eight different 3D models with closely matching
physical world counterparts—including the mug analyzed above. Next, we used 3DB to find correctly and incorrectly classified
configurations (pose, orientation, location) of these eight objects inside that
room. Finally, we replicated these poses (to
the best of our abilities) in the physical room, and took photos with a
cellphone camera:</p>

<p><img alt="Samples from our physical-world experiment." class="bigimg" src="https://gradientscience.org/assets/3db/real_life_exp_samples.png"/></p>

<div class="caption">
Examples of simulated scenes (top) and their re-created counterparts (bottom)
from our physical-world experiment.
</div>

<p>We classified these photos with the same vision model as before and measured
how often the simulated classifier correctness matched correctness on the
real photographs. We observed an ~85% match! So the failure
modes identified by 3DB are not merely simulation artifacts, and can indeed arise in
the real world.</p>

<h2 id="conclusion">Conclusion</h2>

<p>3DB is a flexible, easy-to-use, and extensible framework for
identifying model failure modes, uncovering biases, and testing fine-grained
hypotheses about model behavior. We hope it will prove to be a useful tool
for debugging vision models.</p>
<h2 id="bonus-object-detection-web-dashboard-and-more">Bonus: Object Detection, Web Dashboard, and more!</h2>

<p>We’ll wrap up by highlighting some additional capabilities of 3DB that we didn’t
get to demonstrate in this blog post:</p>

<h3 id="3dboard-a-web-interface-for-exploring-results">3DBoard: a web interface for exploring results</h3>

<p>In all of the code examples above, we showed how to analyze the results of a 3DB
experiment by loading the output into a <code class="language-plaintext highlighter-rouge">pandas</code> dataframe. For additional
convenience, however, 3DB also comes with a web-based dashboard for exploring
experimental results. The following command suffices to visualize the texture swaps experiment from earlier:</p>

<pre style="padding: 0; margin: 0;"><code class="bash">
python -m threedboard results_texture/ --port 3000

</code>
</pre>

<p>Navigating to <code class="language-plaintext highlighter-rouge">YOUR_IP:3000</code> should lead you to a page that looks like this:</p>

<p><img alt="Dashboard screenshot" src="https://gradientscience.org/assets/3db/dashboard_screenshot.png"/></p>

<h3 id="object-detection-and-other-tasks">Object detection and other tasks</h3>

<p>In this blog post, we focused on using 3DB to analyze image classification
models. However, the library also supports object detection out-of-the-box, and
can easily be extended to support a variety of image-based tasks (e.g.,
segmentation or regression-based tasks). For example, below we provide a simple
end-to-end object detection example:</p>

<details>
<strong>Show/hide code and instructions</strong>
<div class="code-container">
    <input checked="" class="tab1" id="objdet-tab1" name="objdet-tab" type="radio"/>
    <label for="objdet-tab1"><i class="fa fa-gear"/>  Setup</label>
    <input class="tab2" id="objdet-tab2" name="objdet-tab" type="radio"/>
    <label for="objdet-tab2"><i class="fa fa-code"/>  Config (part_of_object.yaml)</label>
    <div class="line"/>
    <div class="line"/>
    <div class="content-container">
<div class="content c1"><pre class="wrapped"><code class="makefile">
# The object detection example is separate from the rest of the blog demo, so
# run the following in a separate repo:
git clone https://github.com/3db/object_detection_demo

# The repo has a data/ folder containing the Blender model (a banana) and some
# HDRI backgrounds, a classmap.json file mapping the UID of the model to a COCO
# class, and the detection.yaml file from the next pane.
cd object_detection_demo/

export BLENDER_DATA=data/
export RESULTS_FOLDER=results/

# Run 3DB
threedb_workers 1 $BLENDER_DATA 5555 &gt; client.log &amp; 
threedb_master $BLENDER_DATA detection.yaml $RESULTS_FOLDER 5555

# Analyze results in the dashboard
python -m threedboard $RESULTS_FOLDER --port 3000
# Navigate to localhost:3000 to view the results!

</code></pre></div> 
<div class="content c2"><pre><code class="YAML">
inference:
  module: 'torchvision.models.detection'
  class: 'retinanet_resnet50_fpn'
  label_map: './resources/coco_mapping.json'
  normalization:
    mean: [0., 0., 0.]
    std: [1., 1., 1.]
  resolution: [224, 224]
  args:
    pretrained: True
evaluation:
  module: 'threedb.evaluators.detection'
  args:
    iou_threshold: 0.5
    nms_threshold: 0.1
    max_num_boxes: 10
    classmap_path: 'classmap.json'
render_args:
  engine: 'threedb.rendering.render_blender'
  resolution: 256
  samples: 16
  with_segmentation: true
policy:
  module: "threedb.policies.random_search"
  samples: 2
logging:
  logger_modules:
    - "threedb.result_logging.image_logger"
    - "threedb.result_logging.json_logger"
controls:
  - module: "threedb.controls.blender.orientation"
  - module: "threedb.controls.blender.camera"
    zoom_factor: [0.7, 1.3]
    aperture: 8.
    focal_length: 50.
  - module: "threedb.controls.blender.denoiser"

</code></pre></div>
</div>
</div>
</details></div>
    </summary>
    <updated>2021-06-08T00:00:00Z</updated>
    <published>2021-06-08T00:00:00Z</published>
    <source>
      <id>https://gradientscience.org/</id>
      <author>
        <name>Gradient Science</name>
      </author>
      <link href="https://gradientscience.org/" rel="alternate" type="text/html"/>
      <link href="https://gradientscience.org/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Research highlights and perspectives on machine learning and optimization from MadryLab.</subtitle>
      <title>gradient science</title>
      <updated>2021-06-19T22:44:30Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=8127</id>
    <link href="https://windowsontheory.org/2021/06/07/new-seminar-series-in-simons-institute/" rel="alternate" type="text/html"/>
    <title>New seminar series in Simons Institute</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">The Simons institute started a new virtual seminar series highlighting recent advances in theoretical computer science. The first two talks in the series will be: June 16th 10am-11am PDT (1pm-2pm EDT). Virginia Vassilevska Williams on a  Refined Laser Method and Faster Matrix Multiplication August 5 10am-11am PDT (1pm-2pm EDT) Yuansi Chen on An Almost Constant … <a class="more-link" href="https://windowsontheory.org/2021/06/07/new-seminar-series-in-simons-institute/">Continue reading <span class="screen-reader-text">New seminar series in Simons Institute</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Simons institute started a <a href="https://simons.berkeley.edu/news/institute-launches-breakthroughs-lecture-series">new virtual seminar</a> series highlighting recent advances in theoretical computer science. The first two talks in the series will be:</p>



<ul><li>June 16th 10am-11am PDT (1pm-2pm EDT). Virginia Vassilevska Williams on a  <a href="https://simons.berkeley.edu/events/breakthroughs-refined-laser-method-and-faster-matrix-multiplication">Refined Laser Method and Faster Matrix Multiplication</a></li><li>August 5 10am-11am PDT (1pm-2pm EDT) Yuansi Chen on <a href="https://simons.berkeley.edu/events/breakthroughs-almost-constant-lower-bound-isoperimetric-coefficient-kls-conjecture-0">An Almost Constant Lower Bound of the Isoperimetric Coefficient in the KLS Conjecture</a></li></ul>



<p/></div>
    </content>
    <updated>2021-06-07T18:18:32Z</updated>
    <published>2021-06-07T18:18:32Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2021-06-20T12:21:03Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://differentialprivacy.org/icml2021/</id>
    <link href="https://differentialprivacy.org/icml2021/" rel="alternate" type="text/html"/>
    <title>Conference Digest - ICML 2021</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="https://icml.cc/Conferences/2021">ICML 2021</a>, one of the biggest conferences in machine learning, naturally has a ton of interesting sounding papers on the topic of differential privacy.
We went through this year’s <a href="https://icml.cc/Conferences/2021/AcceptedPapersInitial">accepted papers</a> and aggregated all the relevant papers we could find.
In addition, this year features three workshops on the topic of privacy, as well as a tutorial.
As always, please inform us if we overlooked any papers on differential privacy.</p>

<h2 id="workshops">Workshops</h2>

<ul>
  <li>
    <p><a href="http://federated-learning.org/fl-icml-2021/">Federated Learning for User Privacy and Data Confidentiality</a></p>
  </li>
  <li>
    <p><a href="https://sites.google.com/view/ml4data">Machine Learning for Data: Automated Creation, Privacy, Bias</a></p>
  </li>
  <li>
    <p><a href="https://tpdp.journalprivacyconfidentiality.org/2021/">Theory and Practice of Differential Privacy</a></p>
  </li>
</ul>

<h2 id="tutorial">Tutorial</h2>

<ul>
  <li><a href="https://icml.cc/Conferences/2021/Schedule?showEvent=10839">Privacy in Learning: Basics and the Interplay</a><br/>
<a href="https://www.microsoft.com/en-us/research/people/huzhang/">Huishuai Zhang</a>, <a href="https://www.microsoft.com/en-us/research/people/weic/">Wei Chen</a></li>
</ul>

<h2 id="papers">Papers</h2>

<ul>
  <li>
    <p><a href="https://arxiv.org/abs/2009.02668">A Framework for Private Matrix Analysis in Sliding Window Model</a><br/>
<a href="https://sites.google.com/view/jalajupadhyay/home">Jalaj Upadhyay</a>, <a href="https://www.fujitsu.com/us/about/businesspolicy/tech/rd/research-staff/sarvagya.html">Sarvagya Upadhyay</a></p>
  </li>
  <li>
    <p>Accuracy, Interpretability, and Differential Privacy via Explainable Boosting<br/>
<a href="https://scholar.google.com/citations?user=HmxjgMAAAAAJ">Harsha Nori</a>, <a href="https://www.microsoft.com/en-us/research/people/rcaruana/">Rich Caruana</a>, <a href="https://sites.google.com/view/zhiqi-bu">Zhiqi Bu</a>, <a href="https://heyyjudes.github.io/">Judy Hanwen Shen</a>, <a href="https://www.microsoft.com/en-us/research/people/jakul/">Janardhan Kulkarni</a></p>
  </li>
  <li>
    <p>Differentially Private Aggregation in the Shuffle Model: Almost Central Accuracy in Almost a Single Message<br/>
<a href="https://sites.google.com/view/badihghazi/home">Badih Ghazi</a>, <a href="https://sites.google.com/site/ravik53/">Ravi Kumar</a>, <a href="https://pasin30055.github.io/">Pasin Manurangsi</a>, <a href="https://rasmuspagh.net/">Rasmus Pagh</a>, <a href="https://www.linkedin.com/in/amersinha/">Amer Sinha</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2011.00467">Differentially Private Bayesian Inference for Generalized Linear Models</a><br/>
<a href="https://warwick.ac.uk/fac/sci/dcs/people/u1554597">Tejas Kulkarni</a>, <a href="https://users.aalto.fi/~jalkoj1/">Joonas Jälkö</a>, <a href="https://scholar.google.com/citations?user=Y_EvCPAAAAAJ">Antti Koskela</a>, <a href="https://people.aalto.fi/samuel.kaski">Samuel Kaski</a>, <a href="https://www.cs.helsinki.fi/u/ahonkela/">Antti Honkela</a></p>
  </li>
  <li>
    <p>Differentially-Private Clustering of Easy Instances<br/>
<a href="http://www.cohenwang.com/edith/">Edith Cohen</a>, <a href="http://www.cs.tau.ac.il/~haimk/">Haim Kaplan</a>, <a href="https://www.tau.ac.il/~mansour/">Yishay Mansour</a>, <a href="https://www.uri.co.il/">Uri Stemmer</a>, <a href="https://www.linkedin.com/in/eliad-tsfadia-21482b96/">Eliad Tsfadia</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2102.08885">Differentially Private Correlation Clustering</a><br/>
<a href="https://cs-people.bu.edu/mbun/">Mark Bun</a>, <a href="https://elias.ba30.eu/">Marek Elias</a>, <a href="https://www.microsoft.com/en-us/research/people/jakul/">Janardhan Kulkarni</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2105.13287">Differentially Private Densest Subgraph Detection</a><br/>
<a href="https://biocomplexity.virginia.edu/person/dung-nguyen">Dung Nguyen</a>, <a href="https://engineering.virginia.edu/faculty/anil-vullikanti">Anil Vullikanti</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2102.08244">Differentially Private Quantiles</a><br/>
<a href="http://jgillenw.com/">Jennifer Gillenwater</a>, <a href="https://www.majos.net/">Matthew Joseph</a>, <a href="https://www.alexkulesza.com/">Alex Kulesza</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2103.06641">Differentially Private Query Release Through Adaptive Projection</a><br/>
<a href="https://sergulaydore.github.io/">Sergul Aydore</a>, <a href="https://wibrown.github.io/">William Brown</a>, <a href="https://www.cis.upenn.edu/~mkearns/">Michael Kearns</a>, <a href="http://www-cs-students.stanford.edu/~kngk/">Krishnaram Kenthapadi</a>, <a href="https://www.lucamel.is/">Luca Melis</a>, <a href="https://www.cis.upenn.edu/~aaroth/">Aaron Roth</a>, <a href="https://ankitsiva.xyz/">Ankit Siva</a></p>
  </li>
  <li>
    <p>Differentially Private Sliced Wasserstein Distance<br/>
<a href="http://asi.insa-rouen.fr/enseignants/~arakoto/">Alain Rakotomamonjy</a>, <a href="https://pageperso.lif.univ-mrs.fr/~liva.ralaivola/doku.php">Liva Ralaivola</a></p>
  </li>
  <li>
    <p>Large Scale Private Learning via Low-rank Reparametrization<br/>
<a href="https://scholar.google.com/citations?user=FcRGdiwAAAAJ">Da Yu</a>, <a href="https://www.microsoft.com/en-us/research/people/huzhang/">Huishuai Zhang</a>, <a href="https://www.microsoft.com/en-us/research/people/weic/">Wei Chen</a>, Jian Yin, <a href="https://www.microsoft.com/en-us/research/people/tyliu/">Tie-Yan Liu</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2102.08598">Leveraging Public Data for Practical Private Query Release</a><br/>
<a href="https://www.linkedin.com/in/terrance-liu-26796974/">Terrance Liu</a>, <a href="https://sites.google.com/umn.edu/giuseppe-vietri/home">Giuseppe Vietri</a>, <a href="http://www.thomas-steinke.net/">Thomas Steinke</a>, <a href="https://www.ccs.neu.edu/home/jullman/">Jonathan Ullman</a>, <a href="https://zstevenwu.com/">Steven Wu</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2104.09734">Locally Private k-Means in One Round</a><br/>
Alisa Chang, <a href="https://sites.google.com/view/badihghazi/home">Badih Ghazi</a>, <a href="https://sites.google.com/site/ravik53/">Ravi Kumar</a>, <a href="https://pasin30055.github.io/">Pasin Manurangsi</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2102.12099">Lossless Compression of Efficient Private Local Randomizers</a><br/>
<a href="http://vtaly.net/">Vitaly Feldman</a>, <a href="http://kunaltalwar.org/">Kunal Talwar</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2105.08233">Oneshot Differentially Private Top-k Selection</a><br/>
<a href="https://lsa.umich.edu/stats/people/phd-students/qiaogang.html">Gang Qiao</a>, <a href="http://www-stat.wharton.upenn.edu/~suw/">Weijie Su</a>, <a href="https://research.google/people/LiZhang/">Li Zhang</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2002.12321">PAPRIKA: Private Online False Discovery Rate Control</a><br/>
<a href="https://wanrongz.github.io/">Wanrong Zhang</a>, <a href="http://www.gautamkamath.com/">Gautam Kamath</a>, <a href="https://sites.gatech.edu/rachel-cummings/">Rachel Cummings</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2103.00039">Practical and Private (Deep) Learning without Sampling or Shuffling</a><br/>
<a href="https://kairouzp.github.io/">Peter Kairouz</a>, <a href="https://research.google/people/author35837/">Brendan McMahan</a>, <a href="https://shs037.github.io/">Shuang Song</a>, <a href="http://www.omthakkar.com/">Om Thakkar</a>, <a href="https://athakurta.squarespace.com/">Abhradeep Thakurta</a>, <a href="https://research.google/people/106689/">Zheng Xu</a></p>
  </li>
  <li>
    <p>Private Adaptive Gradient Methods for Convex Optimization<br/>
<a href="http://web.stanford.edu/~asi/">Hilal Asi</a>, <a href="https://web.stanford.edu/~jduchi/">John Duchi</a>, <a href="https://afallah.lids.mit.edu/">Alireza Fallah</a>, <a href="https://scholar.google.com/citations?user=_JXjrEp9FhYC">Omid Javidbakht</a>, <a href="http://kunaltalwar.org/">Kunal Talwar</a></p>
  </li>
  <li>
    <p>Private Alternating Least Squares: (Nearly) Optimal Privacy/Utility Trade-off for Matrix Completion<br/>
Steve Chien, <a href="https://www.prateekjain.org/">Prateek Jain</a>, <a href="http://walid.krichene.net/">Walid Krichene</a>, <a href="https://scholar.google.com/citations?user=yR-ugIoAAAAJ">Steffen Rendle</a>, <a href="https://shs037.github.io/">Shuang Song</a>, <a href="https://athakurta.squarespace.com/">Abhradeep Thakurta</a>, <a href="https://research.google/people/LiZhang/">Li Zhang</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2103.01516">Private Stochastic Convex Optimization: Optimal Rates in L1 Geometry</a><br/>
<a href="http://web.stanford.edu/~asi/">Hilal Asi</a>, <a href="http://vtaly.net/">Vitaly Feldman</a>, <a href="https://tomerkoren.github.io/">Tomer Koren</a>, <a href="http://kunaltalwar.org/">Kunal Talwar</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2102.06387">The Distributed Discrete Gaussian Mechanism for Federated Learning with Secure Aggregation</a><br/>
<a href="https://kairouzp.github.io/">Peter Kairouz</a>, <a href="https://kenziyuliu.github.io/">Ziyu Liu</a>, <a href="http://www.thomas-steinke.net/">Thomas Steinke</a></p>
  </li>
</ul></div>
    </summary>
    <updated>2021-06-07T16:30:00Z</updated>
    <published>2021-06-07T16:30:00Z</published>
    <author>
      <name>Gautam Kamath</name>
    </author>
    <source>
      <id>https://differentialprivacy.org</id>
      <link href="https://differentialprivacy.org" rel="alternate" type="text/html"/>
      <link href="https://differentialprivacy.org/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Website for the differential privacy research community</subtitle>
      <title>Differential Privacy</title>
      <updated>2021-06-19T22:46:54Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://emanueleviola.wordpress.com/?p=857</id>
    <link href="https://emanueleviola.wordpress.com/2021/06/07/data-structure-lower-bounds-without-encoding-arguments/" rel="alternate" type="text/html"/>
    <title>Data-structure lower bounds without encoding arguments</title>
    <summary>I have recently posted the paper [Vio21] (download) which does something that I have been trying to do for a long time, more than ten years, on and off. Consider the basic data-structure problem of storing bits of data into bits so that the prefix-sum queries can be computed by probing cells (or words) of […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><!--?xml version="1.0" encoding="iso-8859-1" ?-->     <!--http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd-->                 <!-- html,xhtml,-css,NoFonts -->  </p>
<p style="text-align: justify;">I have recently posted the paper <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#Xviola-rank-samp">Vio21</a>]</span> (<a href="https://eccc.weizmann.ac.il/report/2021/073/">download</a>) which does something that I have been trying to do for a long time, more than ten years, on and off. Consider the basic data-structure problem of storing <img alt="m" class="latex" src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/> bits of data <img alt="x\in \{0,1\}^{m}" class="latex" src="https://s0.wp.com/latex.php?latex=x%5Cin+%5C%7B0%2C1%5C%7D%5E%7Bm%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/> into <img alt="m+r" class="latex" src="https://s0.wp.com/latex.php?latex=m%2Br&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/> bits so that the <em>prefix-sum queries</em></p>
<div style="text-align: center;"> <img alt="\begin{aligned} \mathbb {\text {\textsc {Rank}}}(i):=\sum _{j\le i}x_{j} \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7B%5Ctext+%7B%5Ctextsc+%7BRank%7D%7D%7D%28i%29%3A%3D%5Csum+_%7Bj%5Cle+i%7Dx_%7Bj%7D+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/></div>
<p style="text-align: justify;">   can be computed by probing <img alt="q" class="latex" src="https://s0.wp.com/latex.php?latex=q&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/> <em>cells</em> (or <em>words</em>) of <img alt="w" class="latex" src="https://s0.wp.com/latex.php?latex=w&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/> bits each. (You can think <img alt="w=\log m" class="latex" src="https://s0.wp.com/latex.php?latex=w%3D%5Clog+m&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/> throughout this post.) The paper <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XPatrascuV10">PV10</a>]</span> with Pǎtraşcu shows that <img alt="r\ge m/w^{O(q)}" class="latex" src="https://s0.wp.com/latex.php?latex=r%5Cge+m%2Fw%5E%7BO%28q%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/>, and this was recently shown to be tight by Yu <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/conf/stoc/Yu19">Yu19</a>]</span> (building on the breakthrough data structure <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XPatrascu08Succincter">Pǎt08</a>]</span> which motivated the lower bound and is not far from it).</p>
<p style="text-align: justify;">   As is common in data-structure lower bounds, the proof in <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XPatrascuV10">PV10</a>]</span> is an <em>encoding argument</em>. In the recently posted paper, an alternative proof is presented which avoids the encoding argument and is perhaps more in line with other proofs in complexity lower bounds. Of course, <em>everything</em> is an encoding argument, and <em>nothing </em>is an encoding argument, and this post won’t draw a line.</p>
<p style="text-align: justify;">   The new proof establishes an <em>intrinsic property</em> of efficient data structures, whereas typical proofs including <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XPatrascuV10">PV10</a>]</span> are somewhat tailored to the problem at hand. The property is called the <em>separator</em> and is a main technical contribution of the work. At the high level the separator shows that in any efficient data structure you can restrict the input space a little so that many queries are nearly <em>pairwise independent</em>.</p>
<p style="text-align: justify;">   Also, the new proof rules out a stronger object: a <em>sampler</em> (<a href="https://emanueleviola.wordpress.com/2014/11/09/is-nature-a-low-complexity-sampler/">see previous post here</a> on sampling lower bounds). Specifically, the distribution Rank<img alt="(U)" class="latex" src="https://s0.wp.com/latex.php?latex=%28U%29&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/> where <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/> is the uniform distribution cannot be sampled, not even slightly close, by an efficient cell-probe algorithm. This implies the data-structure result, and it can be informally interpreted as saying that the “reason” why the lower bound holds is not that the data is compressed, but rather that one can’t generate the type of dependencies occurring in Rank via an efficient cell-probe algorithm, regardless of what the input is.</p>
<p style="text-align: justify;">   Building on this machinery, one can prove several results about sampling, like showing that cell-probe samplers are strictly weaker than AC0 samplers. While doing this, it occurred to me that one gets a corollary for data structures which I had not seen in the literature. The corollary is a <em>probe hierarchy</em>, showing that some problem can be solved with zero redundancy (<img alt="r=0" class="latex" src="https://s0.wp.com/latex.php?latex=r%3D0&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/>) with <img alt="O(q)" class="latex" src="https://s0.wp.com/latex.php?latex=O%28q%29&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/> probes, while it requires almost linear <img alt="r" class="latex" src="https://s0.wp.com/latex.php?latex=r&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/> for <img alt="q" class="latex" src="https://s0.wp.com/latex.php?latex=q&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/> probes. For example I don’t know of a result yielding this for small <img alt="q" class="latex" src="https://s0.wp.com/latex.php?latex=q&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/> such as <img alt="q=O(1)" class="latex" src="https://s0.wp.com/latex.php?latex=q%3DO%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/>; I would appreciate a reference. (As mentioned in the                                                                                                                                                        paper, the sampling viewpoint is not essential and just like for Rank one can prove the data-structure corollaries directly. Personally, and obviously, I find the sampling viewpoint useful.)</p>
<p style="text-align: justify;">   One of my favorite open problems in the area still is: can a uniform distribution over <img alt="[m]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Bm%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/> be approximately sampled by an efficient cell-probe algorithm? I can’t even rule out samplers making <em>two </em>probes!</p>
<h3 class="likesectionHead"><a id="x1-1000"/>References</h3>
<p style="text-align: justify;">
</p><div class="thebibliography">
<p class="bibitem"><span class="biblabel">  [Pǎt08]<span class="bibsp">   </span></span><a id="XPatrascu08Succincter"/>Mihai  Pǎtraşcu.      Succincter.      In  49th  IEEE  Symp. on         Foundations of Computer Science (FOCS). IEEE, 2008.</p>
<p class="bibitem"><span class="biblabel">  [PV10]<span class="bibsp">   </span></span><a id="XPatrascuV10"/>Mihai Pǎtraşcu and Emanuele Viola.  Cell-probe lower bounds         for succinct partial sums.  In 21th ACM-SIAM Symp. on Discrete         Algorithms (SODA), pages 117–122, 2010.</p>
<p class="bibitem"><span class="biblabel">  [Vio21]<span class="bibsp">   </span></span><a id="Xviola-rank-samp"/>Emanuele       Viola.                    Lower       bounds       for         samplers and data structures via the cell-probe separator. Available         at <a href="http://www.ccs.neu.edu/home/viola/" rel="nofollow">http://www.ccs.neu.edu/home/viola/</a>, 2021.</p>
<p class="bibitem"><span class="biblabel">  [Yu19] <span class="bibsp">   </span></span><a id="XDBLP:conf/stoc/Yu19"/>Huacheng  Yu.     Optimal  succinct  rank  data  structure  via         approximate nonnegative tensor decomposition.  In Moses Charikar         and Edith Cohen, editors, ACM Symp. on the Theory of Computing         (STOC), pages 955–966. ACM, 2019.</p>
</div></div>
    </content>
    <updated>2021-06-07T15:49:53Z</updated>
    <published>2021-06-07T15:49:53Z</published>
    <category term="Uncategorized"/>
    <category term="Behind the papers"/>
    <category term="lower bounds"/>
    <author>
      <name>Manu</name>
    </author>
    <source>
      <id>https://emanueleviola.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://emanueleviola.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://emanueleviola.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://emanueleviola.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://emanueleviola.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>by Manu</subtitle>
      <title>Thoughts</title>
      <updated>2021-06-20T12:21:33Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://rjlipton.wpcomstaging.com/?p=18838</id>
    <link href="https://rjlipton.wpcomstaging.com/2021/06/07/happy-moms-day/" rel="alternate" type="text/html"/>
    <title>Happy Mom’s Day</title>
    <summary>You know, I loved math. My mom was a math teacher—Joan Cusack Mary Kay Farley, my dear wife’s mom, and Dorothy Lipton, my mom, have unfortunately both passed away. Kathryn and I miss them greatly. Both women shared keen mathematical skills, a fascination with the game of baseball and a commitment to living a well-ordered […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>You know, I loved math. My mom was a math teacher—Joan Cusack</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<p><a href="https://rjlipton.wpcomstaging.com/2021/06/07/happy-moms-day/kfrlmothers/" rel="attachment wp-att-18865"><img alt="" class="alignright size-full wp-image-18865" height="139" src="https://i2.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/06/KFRLmothers.jpg?resize=212%2C139&amp;ssl=1" width="212"/></a></p>
<p>
Mary Kay Farley, my dear wife’s mom, and Dorothy Lipton, my mom, have unfortunately both passed away. Kathryn and I miss them greatly. Both women shared keen mathematical skills, a fascination with the game of baseball and a commitment to living a well-ordered life.  </p>
<p>
Today is <b>not</b> Mother’s Day. We still hope all mothers everywhere are enjoying their day.</p>
<p>
We will take this time to thank all of you out there. We missed doing so last month, but the pandemic has distended time anyway. What we are hearing now are stories of mothers and children and grandchildren finally being able to think of seeing each other in person rather than via video.</p>
<p>
</p><p/><h2> Another Kind of Parentage </h2><p/>
<p/><p>
This has blended with musings on our recent <a href="https://rjlipton.wpcomstaging.com/2021/03/26/congrats-avi-and-laci-on-the-abel-prize/">post</a> in which I (Dick) noted that Dorit Aharonov is an academic grandchild of mine, in that Avi Wigderson co-supervised her doctoral thesis and I supervised Avi’s. </p>
<p>
Years ago we featured on Father’s Day a <a href="https://rjlipton.wpcomstaging.com/2011/06/19/who's-your-doktorvater/">post</a> with the title “Who’s Your <em>Doktorvater</em>?”—which was a play on the <a href="https://bosoxinjection.com/2014/09/24/ten-years-gone-pedro-martinez-calls-yankees-daddy/">expression</a> “who’s your daddy?” Now it is high time to note that there are many “doctor mothers”—as Dorit has herself <a href="https://www.genealogy.math.ndsu.nodak.edu/id.php?id=102209">become</a>. </p>
<p>
One difference from human genealogy is that most often there is only one “doctor parent.” My <a href="https://www.genealogy.math.ndsu.nodak.edu/id.php?id=86340&amp;fChrono=1">advisor</a>, David Parnas, has two: Alan Perlis and Everard Williams. From Perlis it is a straight shot back to Siméon Poisson, whose 1800 dissertation was co-advised by Joseph Lagrange and Pierre Laplace. For Lagrange there is a strange <a href="https://www.mathgenealogy.org/id.php?id=17864">note</a> of Leonhard Euler as a virtual advisor, but the real one is Giovanni Beccaria—who has no listed parent. Going through Laplace also dead-ends. But selecting Euler includes a chain that ends in the 1100s with Sharaf al-Dīn al-Ṭūsī, who <a href="https://en.wikipedia.org/wiki/Sharaf_al-Din_al-Tusi#Mathematics">improved</a> the complexity of approximately solving cubic equations.</p>
<p>
I appear not to have any female ancestors in my doctoral genealogy. I have two female PhD graduates, one of whom is a <em>Doktormutter</em>. Ken’s first female doctoral student, co-advised, had a successful thesis defense last week; he has another nearing the ABD stage. But I have known quite a few other “doctor mothers” personally. Today, Ken and I thought to recognize them.</p>
<p>
</p><p/><h2> Some Doctor Moms I Know </h2><p/>
<p/><p>
Here are some that I have had the honor to know. They are in a certain order—do you see what it is? I give only the surname on purpose—click the second name and note its URL for a singular reflection of this.</p>
<ul>
<li>
<a href="https://en.wikipedia.org/wiki/Monica_S._Lam">Lam</a>: <a href="https://mathgenealogy.org/id.php?id=50307">advisees</a> <p/>
</li><li>
<a href="https://mathshistory.st-andrews.ac.uk/Biographies/Blum/">Blum</a>: <a href="http://www.cs.cmu.edu/~lblum/PAPERS/lblumShortVita.pdf">co-advisees</a> <p/>
</li><li>
<a href="https://en.wikipedia.org/wiki/Mary_Shaw_(computer_scientist)">Shaw</a>: <a href="https://www.mathgenealogy.org/id.php?id=50083">advisees</a> <p/>
</li><li>
<a href="https://mathshistory.st-andrews.ac.uk/Biographies/Chung/">Chung</a>: <a href="https://www.mathgenealogy.org/id.php?id=23154">advisees</a> <p/>
</li><li>
<a href="https://en.wikipedia.org/wiki/Maria_Klawe">Klawe</a>: <a href="https://www.mathgenealogy.org/id.php?id=43243">advisee</a> <p/>
</li><li>
<a href="https://people.csail.mit.edu/lynch/">Lynch</a>: <a href="https://www.mathgenealogy.org/id.php?id=81227">advisees</a> <p/>
</li><li>
<a href="https://en.wikipedia.org/wiki/Ruzena_Bajcsy">Bajcsy</a>: <a href="https://www.mathgenealogy.org/id.php?id=39957">advisees</a> <p/>
</li><li>
<a href="https://www2.eecs.berkeley.edu/Faculty/Homepages/graham-s.html">Graham</a>: <a href="https://www.mathgenealogy.org/id.php?id=22787">advisees</a> <p/>
</li><li>
<a href="https://en.wikipedia.org/wiki/Barbara_Liskov">Liskov</a>: <a href="https://www.mathgenealogy.org/id.php?id=61932">advisees</a> <p/>
</li><li>
<a href="https://en.wikipedia.org/wiki/Eva_Tardos">Tardos</a>: <a href="https://www.mathgenealogy.org/id.php?id=39422">advisees</a> <p/>
</li><li>
<a href="https://annacgilbert.github.io/">Gilbert</a>: <a href="https://www.mathgenealogy.org/id.php?id=24150">advisees</a> <p/>
</li><li>
<a href="https://people.math.gatech.edu/~randall/">Randall</a>: <a href="https://www.mathgenealogy.org/id.php?id=81757">advisees</a> <p/>
</li><li>
<a href="https://mathshistory.st-andrews.ac.uk/Biographies/Rasiowa/">Rasiowa</a>: <a href="https://www.mathgenealogy.org/id.php?id=22601">advisees</a> <p/>
</li><li>
<a href="https://en.wikipedia.org/wiki/Sheila_Greibach">Greibach</a>: <a href="https://www.mathgenealogy.org/id.php?id=25274">advisees</a> <p/>
</li><li>
<a href="https://en.wikipedia.org/wiki/Shafi_Goldwasser">Goldwasser</a>: <a href="https://www.mathgenealogy.org/id.php?id=35879">advisees</a> <p/>
</li><li>
<a href="https://mathshistory.st-andrews.ac.uk/Biographies/Daubechies/">Daubechies</a>: <a href="https://www.mathgenealogy.org/id.php?id=44561">advisees</a>
</li></ul>
<p>
The last gives us an all-female tree, not just one branch, of people we know. Besides Anna Gilbert, another of Ingrid Daubechies’s students, who herself has <a href="https://www.mathgenealogy.org/id.php?id=92059">advisees</a>, is Cynthia Rudin of Duke, whom Ken knew and taught while she was an undergraduate at Buffalo.</p>
<p>
There are others I could mention who went into research labs where there are different relationships besides PhD advising. They include Irene Greif, Tal Rabin, Lynn Conway, and Jean Sammet. I could include Jamie Morgenstern, whom we recently <a href="https://rjlipton.wpcomstaging.com/2021/03/10/making-algorithms-fair/">featured</a> and who his <a href="https://jamiemorgenstern.com/">advising</a> her first students at the University of Washington—do they have to be “born” yet to count you as a <em>Doktormutter</em>? I’ve left others out—apologies for that—but the ones I’ve listed make a nice <img alt="{4 \times 4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B4+%5Ctimes+4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> collage:</p>
<p/><p><br/>
<a href="https://rjlipton.wpcomstaging.com/2021/06/07/happy-moms-day/comoms2/" rel="attachment wp-att-18841"><img alt="" class="aligncenter size-full wp-image-18841" height="486" src="https://i2.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/06/comoms2.png?resize=450%2C486&amp;ssl=1" width="450"/></a></p>
<p>
</p><p/><h2> My Upbringing </h2><p/>
<p/><p>
Of these, the one with the most formative impact on me was Helena Rasiowa. I learned advanced logic from her when I was an undergraduate. </p>
<p>
Here is a tribute to <a href="http://comet.lehman.cuny.edu/fitting/bookspapers/pdf/papers/Rasiowa.pdf">her</a> by Melvin Fitting: </p>
<blockquote><p><b> </b> <em> I once heard Dana Scott criticize her <a href="https://www.amazon.com/Mathematics-Metamathematics-Helena-SIKORSKI-RASIOWA/dp/B005JGKZXW">book</a>, <em>The Mathematics of Metamathematics</em> with Roman Sikorski, because, while it took an algebraic approach to logic, it did not carry the work further and consider set theory. If it had, then <a href="https://en.wikipedia.org/wiki/Forcing_(mathematics)">forcing</a> would have been discovered years earlier than it was. This is not, at heart, a criticism, but a tribute. The building of mathematics always goes on. Foundations, firmly laid, enable later construction, and the foundations laid by that book were powerfully firm. </em>
</p></blockquote>
<p>
Ken also points to logic as a formative influence—though from men at Oxford.  Both of us were attracted to Gödel-type undecidability issues in complexity theory in the early 1980s.  The nexus of logic and algebra has been important to us in different ways, Ken more with finite automata and descriptive complexity.  Courses in logic gave both of us a habit of framing problems along formal lines.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Which “doctor mothers” have you known or been influenced by?</p>
<p/><p><br/>
[Added and re-formatted photos at top]</p></font></font></div>
    </content>
    <updated>2021-06-07T04:58:14Z</updated>
    <published>2021-06-07T04:58:14Z</published>
    <category term="All Posts"/>
    <category term="People"/>
    <category term="doctoral advising"/>
    <category term="mathematical genealogy"/>
    <category term="Mother's Day"/>
    <category term="women in computing"/>
    <category term="women in mathematics"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wpcomstaging.com</id>
      <logo>https://s0.wp.com/i/webclip.png</logo>
      <link href="https://rjlipton.wpcomstaging.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wpcomstaging.com" rel="alternate" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel's Lost Letter and P=NP</title>
      <updated>2021-06-20T12:20:39Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2021/06/07/workshop-on-machine-learning-for-algorithms/</id>
    <link href="https://cstheory-events.org/2021/06/07/workshop-on-machine-learning-for-algorithms/" rel="alternate" type="text/html"/>
    <title>Workshop on Machine Learning for Algorithms</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">July 13-14, 2021 Foundations of Data Science Institute (FODSI) https://fodsi.us/ml4a.html In recent years there has been increasing interest in using machine learning to improve the performance of classical algorithms in computer science, by fine-tuning their behavior to adapt to the properties of the input distribution. This “data-driven” or “learning-based” approach to algorithm design has the … <a class="more-link" href="https://cstheory-events.org/2021/06/07/workshop-on-machine-learning-for-algorithms/">Continue reading <span class="screen-reader-text">Workshop on Machine Learning for Algorithms</span></a></div>
    </summary>
    <updated>2021-06-07T04:13:38Z</updated>
    <published>2021-06-07T04:13:38Z</published>
    <category term="workshop"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2021-06-20T12:21:55Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-562506050674619397</id>
    <link href="https://blog.computationalcomplexity.org/feeds/562506050674619397/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2021/06/when-do-you-use-et-al-as-opposed-to.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/562506050674619397" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/562506050674619397" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2021/06/when-do-you-use-et-al-as-opposed-to.html" rel="alternate" type="text/html"/>
    <title>When do you use et al. as opposed to listing out the authors? First names? Middle initials? Jr?</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p> If I was refering to the paper with bibtex entry: </p><p><br/></p><p>@misc{BCDDL-2018,</p><p>  author    = {Jeffrey Bosboom and</p><p>               Spencer Congero and</p><p>               Erik D. Demaine and</p><p>               Martin L. Demaine and</p><p>               Jayson Lynch},</p><p>  title     = {Losing at Checkers is Hard},</p><p>  year      = {2018},</p><p>  note      = {\newline\url{http://arxiv.org/abs/1806.05657}},</p><p>}</p><p>(The paper is <a href="http://arxiv.org/abs/1806.05657">here</a>.)</p><p>I would write </p><p><i>Bosboom et al.~\cite{BCDDL-2018} proved that trying to lose at checkers (perhaps you are playing a child and want to keep up their self-esteem, or a Wookie and don't want your arms to be torn off your shoulders   (see <a href="https://www.starwars.com/video/let-the-wookiee-win">here</a>),  or a Wookie child) is hard. </i></p><p><br/></p><p>Why did I use<i> et al. </i>?<i> </i>Because it would be a pain to write out all of those names. </p><p>How many names does it take to make you write <i>et al. </i>? Are there exceptions? </p><p>I have not seen any discussion of this point on the web. So here are my rules of thumb and some questions.(CORRECTION- a commenter points out that this IS discussed on the web. Even so, you can comment on my thoughts or give your thoughts or whatever you like.) </p><p>1) If  there are 3 or more people than use et al. Exception: If the three are VERY WELL KNOWN as a triple. E.g., <i>the double play was Tinker to Evers to Chance. </i>Well, that would not really come up since in baseball nobody ever says <i>the double play was Tinker et al.</i>  More relevant examples:</p><p>Aho, Hopcroft, and Ullman</p><p>Cormen, Leiserson, and Rivest, also known as CLR</p><p>The more recent edition is</p><p>Cormen, Leiserson, Rivest, and Stein. I have heard CLRS but I don't know if people WRITE all four names. </p><p>Lenstra-Lenstra-Lovasz also usually mentions all three. </p><p>2) If there is one name do not use <i>et al</i>.  unless that one person has a multiple personality disorder.</p><p>3) If there are 2 people it can be tricky and perhaps unfair. If the second one has a long name then I am tempted to use<i> et al.</i> For example</p><p>Lewis and Papadimitriou (If I mispelled Christos's name-- well- that's  the point!- to avoid spelling errors I want to use <i>et al.</i> )</p><p>Lampropoulos and Paraskevopoulou (the first one is UMCP new faculty!). After typing in the first name I would not be in the mood to type in the second. </p><p>Similar if there are lots of accents in the name making it hard to type in LaTeX (though I have macros for some people like Erdos who come up a lot) then I might use<i> et al. </i></p><p>(ADDED LATER- some of the commenters object to my `rule' of leaving out the last name if its complicated. That is not really my rule- the point of this post was to get a discussion going about the issue, which I am happy to say has happened.) </p><p>----------</p><p>There are other issues along these lines: when to include the first name (when there is more than one person with that last name, e.g. Ryan Williams and Virginia  Vassilevska Williams), when to use middle initials (in the rare case where there is someone with the same first and last name- Michael  J. Fox added the J and uses it since there was an actor named Michael Fox.)</p><p>I will soon give a quote from a math paper that amused me, but first some context.  The problem of determining if a poly in n variables over Z has an integer solution is called E(n). By the solution to Hilbert's 10th problem we know that there exists n such that E(n) is undecidable. E(9) is undecidable, but the status of E(8) is unknown (as of May 2021) and has been since the early 1980's. </p><p>Here is the quote (from <a href="http://maths.nju.edu.cn/~zwsun/14z.pdf">here</a>).</p><p><i>Can we replace 9 by a smaller number? It is believed so. In fact, A. Baker, Matiyasevich and J.Robinson  even conjectured that E(3) is undecidable over N.</i></p><p>Note that Baker and Robinson get their first initial but Matiyasevich does not.</p><p>I suspect that they use J. Robinson since there is another mathematician with last name Robinson: Rafael Robinson who was Julia's Robinson's husband (to my younger readers--- there was a time when a women who got married took her husband's last name). There is at least one other Math-Robinson: Robert W Robinson. I do not think he is closely related. </p><p>Baker: I do not know of another mathematician named Baker. I tried Google, but the Bakers  I found were   not in the right time frame. I also kept finding hits to an anecdote about Poincare and a man whose profession was a baker (see <a href="https://gilkalai.wordpress.com/2019/10/13/the-story-of-poincare-and-his-friend-the-baker/">here</a> though its later in that blog post). However, I suspect there was another mathematician named Baker which is why the author uses the first initial.  Its possible the author did not want to confuse Alan  Baker with Theodore Baker, one of the authors of Baker-Gill-Solovay that showed there were oracles that made P = NP and others that made P NE NP.  But somehow, that just doesn't seem right to me. I suspect there is only one mathematician with last name Matijsavic. </p><p>Thomas Alva Edison named his son Thomas Alva Edison Jr.  This was a bad idea but not for reasons of authorship, see <a href="http://edisontinfoil.com/taejr/edisonjr.htm">here</a>.</p><p><br/></p></div>
    </content>
    <updated>2021-06-07T03:23:00Z</updated>
    <published>2021-06-07T03:23:00Z</published>
    <author>
      <name>gasarch</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03004932739846901628</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2021-06-19T20:06:19Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/077</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/077" rel="alternate" type="text/html"/>
    <title>TR21-077 |  Lower Bounds on Stabilizer Rank | 

	Shir Peleg, 

	Amir Shpilka, 

	Ben Lee Volk</title>
    <summary>The stabilizer rank of a quantum state $\psi$ is the minimal $r$ such that $\left| \psi \right \rangle = \sum_{j=1}^r c_j \left|\varphi_j \right\rangle$ for $c_j \in \mathbb{C}$ and stabilizer states $\varphi_j$. The running time of several classical simulation methods for quantum circuits is determined by the stabilizer rank of the $n$-th tensor power of single-qubit magic states.

We prove a lower bound of $\Omega(n)$ on the stabilizer rank of such states, improving a previous lower bound of $\Omega(\sqrt{n})$ of Bravyi, Smith and Smolin [BSS16]. Further, we prove that for a sufficiently small constant $\delta$, the stabilizer rank of any state which is $\delta$-close to those states is $\Omega(\sqrt{n}/\log n)$. This is the first non-trivial lower bound for approximate stabilizer rank.

Our techniques rely on the representation of stabilizer states as quadratic functions over affine subspaces of $\mathbb{F}_2^n$, and we use tools from analysis of boolean functions and complexity theory. The proof of the first result involves a careful analysis of directional derivatives of quadratic polynomials, whereas the proof of the second result uses Razborov-Smolensky low degree polynomial approximations and correlation bounds against the majority function.</summary>
    <updated>2021-06-06T19:23:20Z</updated>
    <published>2021-06-06T19:23:20Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-06-20T12:20:31Z</updated>
    </source>
  </entry>
</feed>
