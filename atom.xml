<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2021-11-17T18:22:04Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.08698</id>
    <link href="http://arxiv.org/abs/2111.08698" rel="alternate" type="text/html"/>
    <title>On the Randomized Metric Distortion Conjecture</title>
    <feedworld_mtime>1637107200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Haripriya Pulyassary, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Swamy:Chaitanya.html">Chaitanya Swamy</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.08698">PDF</a><br/><b>Abstract: </b>In the single winner determination problem, we have n voters and m candidates
and each voter j incurs a cost c(i, j) if candidate i is chosen. Our objective
is to choose a candidate that minimizes the expected total cost incurred by the
voters; however as we only have access to the agents' preference rankings over
the outcomes, a loss of efficiency is inevitable. This loss of efficiency is
quantified by distortion. We give an instance of the metric single winner
determination problem for which any randomized social choice function has
distortion at least 2.063164. This disproves the long-standing conjecture is
that there exists a randomized social choice function that has a worst-case
distortion of at most 2.
</p></div>
    </summary>
    <updated>2021-11-17T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-11-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.08520</id>
    <link href="http://arxiv.org/abs/2111.08520" rel="alternate" type="text/html"/>
    <title>Hyperbolicity Computation through Dominating Sets *</title>
    <feedworld_mtime>1637107200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Coudert:David.html">David Coudert</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nusser:Andr=eacute=.html">André Nusser</a>, Laurent Viennot) <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.08520">PDF</a><br/><b>Abstract: </b>Hyperbolicity is a graph parameter related to how much a graph resembles a
tree with respect to distances. Its computation is challenging as the main
approaches consist in scanning all quadruples of the graph or using fast matrix
multiplication as building block, both are not practical for large graphs. In
this paper, we propose and evaluate an approach that uses a hierarchy of
distance-k dominating sets to reduce the search space. This technique, compared
to the previous best practical algorithms, enables us to compute the
hyperbolicity of graphs with unprecedented size (up to a million nodes) and
speeds up the computation of previously attainable graphs by up to 3 orders of
magnitude while reducing the memory consumption by up to more than a factor of
23.
</p></div>
    </summary>
    <updated>2021-11-17T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-11-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.08238</id>
    <link href="http://arxiv.org/abs/2111.08238" rel="alternate" type="text/html"/>
    <title>A Simple Algorithm for Computing the Zone of a Line in an Arrangement of Lines</title>
    <feedworld_mtime>1637107200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Haitao.html">Haitao Wang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.08238">PDF</a><br/><b>Abstract: </b>Let $L$ be a set of $n$ lines in the plane. The zone $Z(\ell)$ of a line
$\ell$ in the arrangement $\mathcal{A}(L)$ of $L$ is the set of faces of
$\mathcal{A}(L)$ whose closure intersects $\ell$. It is known that the
combinatorial size of $Z(\ell)$ is $O(n)$. Given $L$ and $\ell$, computing
$Z(\ell)$ is a fundamental problem. Linear-time algorithms exist for computing
$Z(\ell)$ if $\mathcal{A}(L)$ has already been built, but building
$\mathcal{A}(L)$ takes $O(n^2)$ time. On the other hand, $O(n\log n)$-time
algorithms are also known for computing $Z(\ell)$ without relying on
$\mathcal{A}(L)$, but these algorithms are relatively complicated. In this
paper, we present a simple algorithm that can compute $Z(\ell)$ in $O(n\log n)$
time. More specifically, once the sorted list of the intersections between
$\ell$ and the lines of $L$ is known, the algorithm runs in $O(n)$ time. A big
advantage of our algorithm, which mainly involves a Graham's scan style
procedure, is its simplicity.
</p></div>
    </summary>
    <updated>2021-11-17T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-11-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.08148</id>
    <link href="http://arxiv.org/abs/2111.08148" rel="alternate" type="text/html"/>
    <title>Improved Bounds for Scheduling Flows under Endpoint Capacity Constraints</title>
    <feedworld_mtime>1637107200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Searidang Pa, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rajaraman:Rajmohan.html">Rajmohan Rajaraman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Stalfa:David.html">David Stalfa</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.08148">PDF</a><br/><b>Abstract: </b>We study flow scheduling under node capacity constraints. We are given
capacitated nodes and an online sequence of jobs, each with a release time and
a demand to be routed between two nodes. A schedule specifies which jobs are
routed in each step, guaranteeing that the total demand on a node in any step
is at most its capacity. A key metric in this scenario is response time: the
time between a job's release and its completion. Prior work shows no
un-augmented algorithm is competitive for average response time, and that a
constant factor competitive ratio is achievable with augmentation exceeding 2
(Dinitz-Moseley Infocom 2020). For maximum response time, the best known result
is a 2-competitive algorithm with a augmentation 4 (Jahanjou et al SPAA 2020).
We improve these bounds under various response time objectives. We show that,
without resource augmentation, the best competitive ratio for maximum response
time is $\Omega(n)$, where $n$ is the number of nodes. Our Proportional
Allocation algorithm uses $(1+\varepsilon)$ resource augmentation to achieve a
$(1/\varepsilon)$-competitive ratio in the setting with general demands and
capacities, and splittable jobs. Our Batch Decomposition algorithm is
$2$-competitive (resp., optimal) for maximum response time using resource
augmentation 2 (resp., 4) in the setting with unit demands and capacities, and
unsplittable jobs. We also derive bounds for the simultaneous approximation of
average and maximum response time metrics.
</p></div>
    </summary>
    <updated>2021-11-17T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-11-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.08138</id>
    <link href="http://arxiv.org/abs/2111.08138" rel="alternate" type="text/html"/>
    <title>Improved Approximations for CVRP with Unsplittable Demands</title>
    <feedworld_mtime>1637107200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Friggstad:Zachary.html">Zachary Friggstad</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mousavi:Ramin.html">Ramin Mousavi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rahgoshay:Mirmahdi.html">Mirmahdi Rahgoshay</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Salavatipour:Mohammad_R=.html">Mohammad R. Salavatipour</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.08138">PDF</a><br/><b>Abstract: </b>In this paper, we present improved approximation algorithms for the
(unsplittable) Capacitated Vehicle Routing Problem (CVRP) in general metrics.
In CVRP, introduced by Dantzig and Ramser (1959), we are given a set of points
(clients) $V$ together with a depot $r$ in a metric space, with each $v\in V$
having a demand $d_v&gt;0$, and a vehicle of bounded capacity $Q$. The goal is to
find a minimum cost collection of tours for the vehicle, each starting and
ending at the depot, such that each client is visited at least once and the
total demands of the clients in each tour is at most $Q$. In the unsplittable
variant we study, the demand of a node must be served entirely by one tour. We
present two approximation algorithms for unsplittable CVRP: a combinatorial
$(\alpha+1.75)$-approximation, where $\alpha$ is the approximation factor for
the Traveling Salesman Problem, and an approximation algorithm based on LP
rounding with approximation guarantee $\alpha+\ln(2) + \delta \approx 3.194 +
\delta$ in $n^{O(1/\delta)}$ time. Both approximations can further be improved
by a small amount when combined with recent work by Blauth, Traub, and Vygen
(2021), who obtained an $(\alpha + 2\cdot (1 -\epsilon))$-approximation for
unsplittable CVRP for some constant $\epsilon$ depending on $\alpha$ ($\epsilon
&gt; 1/3000$ for $\alpha = 1.5$).
</p></div>
    </summary>
    <updated>2021-11-17T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-11-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.08093</id>
    <link href="http://arxiv.org/abs/2111.08093" rel="alternate" type="text/html"/>
    <title>Capturing Acceleration in Monotone Inclusion: A Closed-Loop Control Perspective</title>
    <feedworld_mtime>1637107200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lin:Tianyi.html">Tianyi Lin</a>, Michael. I. Jordan <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.08093">PDF</a><br/><b>Abstract: </b>We propose and analyze a new dynamical system with \textit{a closed-loop
control law} in a Hilbert space $\mathcal{H}$, aiming to shed light on the
acceleration phenomenon for \textit{monotone inclusion} problems, which unifies
a broad class of optimization, saddle point and variational inequality (VI)
problems under a single framework. Given an operator $A: \mathcal{H}
\rightrightarrows \mathcal{H}$ that is maximal monotone, we study a closed-loop
control system that is governed by the operator $I - (I + \lambda(t)A)^{-1}$
where $\lambda(\cdot)$ is tuned by the resolution of the algebraic equation
$\lambda(t)\|(I + \lambda(t)A)^{-1}x(t) - x(t)\|^{p-1} = \theta$ for some
$\theta \in (0, 1)$. Our first contribution is to prove the existence and
uniqueness of a global solution via the Cauchy-Lipschitz theorem. We present a
Lyapunov function that allows for establishing the weak convergence of
trajectories and strong convergence results under additional conditions. We
establish a global ergodic rate of $O(t^{-(p+1)/2})$ in terms of a gap function
and a global pointwise rate of $O(t^{-p/2})$ in terms of a residue function.
Local linear convergence is established in terms of a distance function under
an error bound condition. Further, we provide an algorithmic framework based on
implicit discretization of our system in a Euclidean setting, generalizing the
large-step HPE framework of~\citet{Monteiro-2012-Iteration}. While the
discrete-time analysis is a simplification and generalization of the previous
analysis for bounded domain, it is motivated by the aforementioned
continuous-time analysis, illustrating the fundamental role that the
closed-loop control plays in acceleration in monotone inclusion. A highlight of
our analysis is set of new results concerning $p$-th order tensor algorithms
for monotone inclusion problems, which complement the recent analysis for
saddle point and VI problems.
</p></div>
    </summary>
    <updated>2021-11-17T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-11-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.08057</id>
    <link href="http://arxiv.org/abs/2111.08057" rel="alternate" type="text/html"/>
    <title>Margin-Independent Online Multiclass Learning via Convex Geometry</title>
    <feedworld_mtime>1637107200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Guruganesh:Guru.html">Guru Guruganesh</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liu:Allen.html">Allen Liu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schneider:Jon.html">Jon Schneider</a>, Joshua Wang <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.08057">PDF</a><br/><b>Abstract: </b>We consider the problem of multi-class classification, where a stream of
adversarially chosen queries arrive and must be assigned a label online. Unlike
traditional bounds which seek to minimize the misclassification rate, we
minimize the total distance from each query to the region corresponding to its
correct label. When the true labels are determined via a nearest neighbor
partition -- i.e. the label of a point is given by which of $k$ centers it is
closest to in Euclidean distance -- we show that one can achieve a loss that is
independent of the total number of queries. We complement this result by
showing that learning general convex sets requires an almost linear loss per
query. Our results build off of regret guarantees for the geometric problem of
contextual search. In addition, we develop a novel reduction technique from
multiclass classification to binary classification which may be of independent
interest.
</p></div>
    </summary>
    <updated>2021-11-17T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-11-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.07829</id>
    <link href="http://arxiv.org/abs/2111.07829" rel="alternate" type="text/html"/>
    <title>Hybrid transforms of constructible functions</title>
    <feedworld_mtime>1637107200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lebovici:Vadim.html">Vadim Lebovici</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.07829">PDF</a><br/><b>Abstract: </b>We introduce a general definition of hybrid transforms for constructible
functions. These are integral transforms combining Lebesgue integration and
Euler calculus. Lebesgue integration gives access to well-studied kernels and
to regularity results, while Euler calculus conveys topological information and
allows for compatibility with operations on constructible functions. We conduct
a systematic study of such transforms and introduce two new ones: the
Euler-Fourier and Euler-Laplace transforms. We show that the first has a left
inverse and that the second provides a satisfactory generalization of Govc and
Hepworth's persistent magnitude to constructible sheaves, in particular to
multi-parameter persistent modules. Finally, we prove index-theoretic formulae
expressing a wide class of hybrid transforms as generalized Euler integral
transforms. This yields expectation formulae for transforms of constructible
functions associated to (sub)level-sets persistence of random Gaussian
filtrations.
</p></div>
    </summary>
    <updated>2021-11-17T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2021-11-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.07647</id>
    <link href="http://arxiv.org/abs/2111.07647" rel="alternate" type="text/html"/>
    <title>Enumerating Minimal Separators in Ranked Order</title>
    <feedworld_mtime>1637107200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kenig:Batya.html">Batya Kenig</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.07647">PDF</a><br/><b>Abstract: </b>Let $G$ be an $n$-vertex graph, and $s,t$ vertices of $G$. We present an
efficient algorithm which enumerates the set of minimal $st$-separators of $G$
in ascending order of cardinality, with a delay of $O(n^{3.5})$ per separator.
In particular, we present an algorithm that lists, in ascending order of
cardinality, all minimal separators with at most $k$ vertices. In that case, we
show that the delay of the enumeration algorithm is $O(kn^{2.5})$ per
separator. Our process is based on a new method that can decide, in polynomial
time, whether the set of minimal separators under certain inclusion, exclusion,
and cardinality constraints is empty.
</p></div>
    </summary>
    <updated>2021-11-17T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-11-16T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.07629</id>
    <link href="http://arxiv.org/abs/2111.07629" rel="alternate" type="text/html"/>
    <title>Improved Decoding of Expander Codes</title>
    <feedworld_mtime>1637107200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Xue.html">Xue Chen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cheng:Kuan.html">Kuan Cheng</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Xin.html">Xin Li</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Ouyang:Minghui.html">Minghui Ouyang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.07629">PDF</a><br/><b>Abstract: </b>We study the classical expander codes, introduced by Sipser and Spielman
\cite{SS96}. Given any constants $0&lt; \alpha, \varepsilon &lt; 1/2$, and an
arbitrary bipartite graph with $N$ vertices on the left, $M &lt; N$ vertices on
the right, and left degree $D$ such that any left subset $S$ of size at most
$\alpha N$ has at least $(1-\varepsilon)|S|D$ neighbors, we show that the
corresponding linear code given by parity checks on the right has distance at
least roughly $\frac{\alpha N}{2 \varepsilon }$. This is strictly better than
the best known previous result of $2(1-\varepsilon ) \alpha N$
\cite{Sudan2000note, Viderman13b} whenever $\varepsilon &lt; 1/2$, and improves
the previous result significantly when $\varepsilon $ is small. Furthermore, we
show that this distance is tight in general, thus providing a complete
characterization of the distance of general expander codes.
</p>
<p>Next, we provide several efficient decoding algorithms, which vastly improve
previous results in terms of the fraction of errors corrected, whenever
$\varepsilon &lt; \frac{1}{4}$. Finally, we also give a bound on the list-decoding
radius of general expander codes, which beats the classical Johnson bound in
certain situations (e.g., when the graph is almost regular and the code has a
high rate).
</p>
<p>Our techniques exploit novel combinatorial properties of bipartite expander
graphs. In particular, we establish a new size-expansion tradeoff, which may be
of independent interests.
</p></div>
    </summary>
    <updated>2021-11-17T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-11-16T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.07483</id>
    <link href="http://arxiv.org/abs/2111.07483" rel="alternate" type="text/html"/>
    <title>Tradeoffs for small-depth Frege proofs</title>
    <feedworld_mtime>1637107200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pitassi:Toniann.html">Toniann Pitassi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Ramakrishnan:Prasanna.html">Prasanna Ramakrishnan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tan:Li=Yang.html">Li-Yang Tan</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.07483">PDF</a><br/><b>Abstract: </b>We study the complexity of small-depth Frege proofs and give the first
tradeoffs between the size of each line and the number of lines. Existing lower
bounds apply to the overall proof size -- the sum of sizes of all lines -- and
do not distinguish between these notions of complexity.
</p>
<p>For depth-$d$ Frege proofs of the Tseitin principle where each line is a
size-$s$ formula, we prove that $\exp(n/2^{\Omega(d\sqrt{\log s})})$ many lines
are necessary. This yields new lower bounds on line complexity that are not
implied by H{\aa}stad's recent $\exp(n^{\Omega(1/d)})$ lower bound on the
overall proof size. For $s = \mathrm{poly}(n)$, for example, our lower bound
remains $\exp(n^{1-o(1)})$ for all $d = o(\sqrt{\log n})$, whereas H{\aa}stad's
lower bound is $\exp(n^{o(1)})$ once $d = \omega_n(1)$.
</p>
<p>Our main conceptual contribution is the simple observation that techniques
for establishing correlation bounds in circuit complexity can be leveraged to
establish such tradeoffs in proof complexity.
</p></div>
    </summary>
    <updated>2021-11-17T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2021-11-16T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.07481</id>
    <link href="http://arxiv.org/abs/2111.07481" rel="alternate" type="text/html"/>
    <title>On a Partition LP Relaxation for Min-Cost 2-Node Connected Spanning Subgraphs</title>
    <feedworld_mtime>1637107200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Grout:Logan.html">Logan Grout</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cheriyan:Joseph.html">Joseph Cheriyan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Laekhanukit:Bundit.html">Bundit Laekhanukit</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.07481">PDF</a><br/><b>Abstract: </b>Our motivation is to improve on the best approximation guarantee known for
the problem of finding a minimum-cost 2-node connected spanning subgraph of a
given undirected graph with nonnegative edge costs. We present an LP (Linear
Programming) relaxation based on partition constraints.
</p>
<p>The special case where the input contains a spanning tree of zero cost is
called 2NC-TAP. We present a greedy algorithm for 2NC-TAP, and we analyze it
via dual-fitting for our partition LP relaxation.
</p>
<p>Keywords: 2-node connected graphs, approximation algorithms, connectivity
augmentation, greedy algorithm, network design, partition relaxation
</p></div>
    </summary>
    <updated>2021-11-17T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-11-16T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.07474</id>
    <link href="http://arxiv.org/abs/2111.07474" rel="alternate" type="text/html"/>
    <title>A Polynomial Lower Bound on the Number of Rounds for Parallel Submodular Function Minimization and Matroid Intersection</title>
    <feedworld_mtime>1637107200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chakrabarty:Deeparnab.html">Deeparnab Chakrabarty</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Yu.html">Yu Chen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Khanna:Sanjeev.html">Sanjeev Khanna</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.07474">PDF</a><br/><b>Abstract: </b>Submodular function minimization (SFM) and matroid intersection are
fundamental discrete optimization problems with applications in many fields. It
is well known that both of these can be solved making $\mathrm{poly}(N)$
queries to a relevant oracle (evaluation oracle for SFM and rank oracle for
matroid intersection), where $N$ denotes the universe size. However, all known
polynomial query algorithms are highly adaptive, requiring at least $N$ rounds
of querying the oracle. A natural question is whether these can be efficiently
solved in a highly parallel manner, namely, with $\mathrm{poly}(N)$ queries
using only poly-logarithmic rounds of adaptivity.
</p>
<p>An important step towards understanding the adaptivity needed for efficient
parallel SFM was taken recently in the work of Balkanski and Singer who showed
that any SFM algorithm making $\mathrm{poly}(N)$ queries necessarily requires
$\Omega(\log N/\log \log N)$ rounds. This left open the possibility of
efficient SFM algorithms in poly-logarithmic rounds. For matroid intersection,
even the possibility of a constant round, $\mathrm{poly}(N)$ query algorithm
was not hitherto ruled out.
</p>
<p>In this work, we prove that any, possibly randomized, algorithm for
submodular function minimization or matroid intersection making
$\mathrm{poly}(N)$ queries requires $\tilde{\Omega}\left(N^{1/3}\right)$ rounds
of adaptivity. In fact, we show a polynomial lower bound on the number of
rounds of adaptivity even for algorithms that make at most $2^{N^{1-\delta}}$
queries, for any constant $\delta&gt; 0$. Therefore, even though SFM and matroid
intersection are efficiently solvable, they are not highly parallelizable in
the oracle model.
</p></div>
    </summary>
    <updated>2021-11-17T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-11-16T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.07414</id>
    <link href="http://arxiv.org/abs/2111.07414" rel="alternate" type="text/html"/>
    <title>Combinatorial Algorithms for Rooted Prize-Collecting Walks and Applications to Orienteering and Minimum-Latency Problems</title>
    <feedworld_mtime>1637107200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Sina Dezfuli, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Friggstad:Zachary.html">Zachary Friggstad</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Post:Ian.html">Ian Post</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Swamy:Chaitanya.html">Chaitanya Swamy</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.07414">PDF</a><br/><b>Abstract: </b>We consider the rooted prize-collecting walks (PCW) problem, wherein we seek
a collection $C$ of rooted walks having minimum prize-collecting cost, which is
the (total cost of walks in $C$) + (total node-reward of nodes not visited by
any walk in $C$). This problem arises naturally as the Lagrangian relaxation of
both orienteering, where we seek a length-bounded walk of maximum reward, and
the $\ell$-stroll problem, where we seek a minimum-length walk covering at
least $\ell$ nodes. Our main contribution is to devise a simple, combinatorial
algorithm for the PCW problem in directed graphs that returns a rooted tree
whose prize-collecting cost is at most the optimum value of the
prize-collecting walks problem.
</p>
<p>We utilize our algorithm to develop combinatorial approximation algorithms
for two fundamental vehicle-routing problems (VRPs): (1) orienteering; and (2)
$k$-minimum-latency problem ($k$-MLP), wherein we seek to cover all nodes using
$k$ paths starting at a prescribed root node, so as to minimize the sum of the
node visiting times. Our combinatorial algorithm allows us to sidestep the part
where we solve a preflow-based LP in the LP-rounding algorithms of Friggstand
and Swamy (2017) for orienteering, and in the state-of-the-art
$7.183$-approximation algorithm for $k$-MP in Post and Swamy (2015).
Consequently, we obtain combinatorial implementations of these algorithms with
substantially improved running times compared with the current-best
approximation factors.
</p>
<p>We report computational results for our resulting (combinatorial
implementations of) orienteering algorithms, which show that the algorithms
perform quite well in practice, both in terms of the quality of the solution
they return, as also the upper bound they yield on the orienteering optimum
(which is obtained by leveraging the workings of our PCW algorithm).
</p></div>
    </summary>
    <updated>2021-11-17T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-11-16T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.07372</id>
    <link href="http://arxiv.org/abs/2111.07372" rel="alternate" type="text/html"/>
    <title>Fast Doubly-Adaptive MCMC to Estimate the Gibbs Partition Function with Weak Mixing Time Bounds</title>
    <feedworld_mtime>1637107200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Haddadan:Shahrzad.html">Shahrzad Haddadan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhuang:Yue.html">Yue Zhuang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cousins:Cyrus.html">Cyrus Cousins</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/u/Upfal:Eli.html">Eli Upfal</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.07372">PDF</a><br/><b>Abstract: </b>We present a novel method for reducing the computational complexity of
rigorously estimating the partition functions (normalizing constants) of Gibbs
(Boltzmann) distributions, which arise ubiquitously in probabilistic graphical
models. A major obstacle to practical applications of Gibbs distributions is
the need to estimate their partition functions. The state of the art in
addressing this problem is multi-stage algorithms, which consist of a cooling
schedule, and a mean estimator in each step of the schedule. While the cooling
schedule in these algorithms is adaptive, the mean estimation computations use
MCMC as a black-box to draw approximate samples. We develop a doubly adaptive
approach, combining the adaptive cooling schedule with an adaptive MCMC mean
estimator, whose number of Markov chain steps adapts dynamically to the
underlying chain. Through rigorous theoretical analysis, we prove that our
method outperforms the state of the art algorithms in several factors: (1) The
computational complexity of our method is smaller; (2) Our method is less
sensitive to loose bounds on mixing times, an inherent component in these
algorithms; and (3) The improvement obtained by our method is particularly
significant in the most challenging regime of high-precision estimation. We
demonstrate the advantage of our method in experiments run on classic factor
graphs, such as voting models and Ising models.
</p></div>
    </summary>
    <updated>2021-11-17T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-11-16T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.07360</id>
    <link href="http://arxiv.org/abs/2111.07360" rel="alternate" type="text/html"/>
    <title>A Simple Algorithm for Multiple-Source Shortest Paths in Planar Digraphs</title>
    <feedworld_mtime>1637107200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Debarati Das, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kipouridis:Evangelos.html">Evangelos Kipouridis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gutenberg:Maximilian_Probst.html">Maximilian Probst Gutenberg</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wulff=Nilsen:Christian.html">Christian Wulff-Nilsen</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.07360">PDF</a><br/><b>Abstract: </b>Given an $n$-vertex planar embedded digraph $G$ with non-negative edge
weights and a face $f$ of $G$, Klein presented a data structure with $O(n\log
n)$ space and preprocessing time which can answer any query $(u,v)$ for the
shortest path distance in $G$ from $u$ to $v$ or from $v$ to $u$ in $O(\log n)$
time, provided $u$ is on $f$. This data structure is a key tool in a number of
state-of-the-art algorithms and data structures for planar graphs.
</p>
<p>Klein's data structure relies on dynamic trees and the persistence technique
as well as a highly non-trivial interaction between primal shortest path trees
and their duals. The construction of our data structure follows a completely
different and in our opinion very simple divide-and-conquer approach that
solely relies on Single-Source Shortest Path computations and contractions in
the primal graph. Our space and preprocessing time bound is $O(n\log |f|)$ and
query time is $O(\log |f|)$ which is an improvement over Klein's data structure
when $f$ has small size.
</p></div>
    </summary>
    <updated>2021-11-17T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-11-16T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.07304</id>
    <link href="http://arxiv.org/abs/2111.07304" rel="alternate" type="text/html"/>
    <title>Area-Optimal Simple Polygonalizations: The CG Challenge 2019</title>
    <feedworld_mtime>1637107200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Demaine:Erik_D=.html">Erik D. Demaine</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fekete:S=aacute=ndor_P=.html">Sándor P. Fekete</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Keldenich:Phillip.html">Phillip Keldenich</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Krupke:Dominik.html">Dominik Krupke</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mitchell:Joseph_S=_B=.html">Joseph S. B. Mitchell</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.07304">PDF</a><br/><b>Abstract: </b>We give an overview of theoretical and practical aspects of finding a simple
polygon of minimum (Min-Area) or maximum (Max-Area) possible area for a given
set of n points in the plane. Both problems are known to be NP-hard and were
the subject of the 2019 Computational Geometry Challenge, which presented the
quest of finding good solutions to more than 200 instances, ranging from n = 10
all the way to n = 1, 000, 000.
</p></div>
    </summary>
    <updated>2021-11-17T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2021-11-16T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.07244</id>
    <link href="http://arxiv.org/abs/2111.07244" rel="alternate" type="text/html"/>
    <title>A Simple Approximation Algorithm for Vector Scheduling and Applications to Stochastic Min-Norm Load Balancing</title>
    <feedworld_mtime>1637107200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Ibrahimpur:Sharat.html">Sharat Ibrahimpur</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Swamy:Chaitanya.html">Chaitanya Swamy</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.07244">PDF</a><br/><b>Abstract: </b>We consider the Vector Scheduling problem on identical machines: we have m
machines, and a set J of n jobs, where each job j has a processing-time vector
$p_j\in \mathbb{R}^d_{\geq 0}$. The goal is to find an assignment $\sigma:J\to
[m]$ of jobs to machines so as to minimize the makespan $\max_{i\in
[m]}\max_{r\in [d]}( \sum_{j:\sigma(j)=i}p_{j,r})$. A natural lower bound on
the optimal makespan is lb $:=\max\{\max_{j\in J,r\in [d]}p_{j,r},\max_{r\in
[d]}(\sum_{j\in J}p_{j,r}/m)\}$. Our main result is a very simple O(log
d)-approximation algorithm for vector scheduling with respect to the lower
bound lb: we devise an algorithm that returns an assignment whose makespan is
at most O(log d)*lb.
</p>
<p>As an application, we show that the above guarantee leads to an O(log log
m)-approximation for Stochastic Minimum-Norm Load Balancing (StochNormLB). In
StochNormLB, we have m identical machines, a set J of n independent stochastic
jobs whose processing times are nonnegative random variables, and a monotone,
symmetric norm $f:\mathbb{R}^m \to \mathbb{R}_{\geq 0}$. The goal is to find an
assignment $\sigma:J\to [m]$ that minimizes the expected $f$-norm of the
induced machine-load vector, where the load on machine i is the (random) total
processing time assigned to it. Our O(log log m)-approximation guarantee is in
fact much stronger: we obtain an assignment that is simultaneously an O(log log
m)-approximation for StochNormLB with all monotone, symmetric norms. Next, this
approximation factor significantly improves upon the O(log m/log log
m)-approximation in (Ibrahimpur and Swamy, FOCS 2020) for StochNormLB, and is a
consequence of a more-general black-box reduction that we present, showing that
a $\gamma(d)$-approximation for d-dimensional vector scheduling with respect to
the lower bound lb yields a simultaneous $\gamma(\log m)$-approximation for
StochNormLB with all monotone, symmetric norms.
</p></div>
    </summary>
    <updated>2021-11-17T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-11-16T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.07235</id>
    <link href="http://arxiv.org/abs/2111.07235" rel="alternate" type="text/html"/>
    <title>Online Max-min Fair Allocation</title>
    <feedworld_mtime>1637107200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kawase:Yasushi.html">Yasushi Kawase</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sumita:Hanna.html">Hanna Sumita</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.07235">PDF</a><br/><b>Abstract: </b>We study an online version of the max-min fair allocation problem for
indivisible items. In this problem, items arrive one by one, and each item must
be allocated irrevocably on arrival to one of $n$ agents, who have additive
valuations for the items. Our goal is to make the least happy agent as happy as
possible. In research on the topic of online allocation, this is a fundamental
and natural problem. Our main result is to reveal the asymptotic competitive
ratios of the problem for both the adversarial and i.i.d. input models. We
design a polynomial-time deterministic algorithm that is asymptotically
$1/n$-competitive for the adversarial model, and we show that this guarantee is
optimal. To this end, we present a randomized algorithm with the same
competitive ratio first and then derandomize it. A natural derandomization
fails to achieve the competitive ratio of $1/n$. We instead build the algorithm
by introducing a novel technique. When the items are drawn from an unknown
identical and independent distribution, we construct a simple polynomial-time
deterministic algorithm that outputs a nearly optimal allocation. We analyze
the strict competitive ratio and show almost tight bounds for the solution. We
further mention some implications of our results on variants of the problem.
</p></div>
    </summary>
    <updated>2021-11-17T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-11-16T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.07222</id>
    <link href="http://arxiv.org/abs/2111.07222" rel="alternate" type="text/html"/>
    <title>Stochastic and Worst-Case Generalized Sorting Revisited</title>
    <feedworld_mtime>1637107200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kuszmaul:William.html">William Kuszmaul</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Narayanan:Shyam.html">Shyam Narayanan</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.07222">PDF</a><br/><b>Abstract: </b>The \emph{generalized sorting problem} is a restricted version of standard
comparison sorting where we wish to sort $n$ elements but only a subset of
pairs are allowed to be compared. Formally, there is some known graph $G = (V,
E)$ on the $n$ elements $v_1, \dots, v_n$, and the goal is to determine the
true order of the elements using as few comparisons as possible, where all
comparisons $(v_i, v_j)$ must be edges in $E$. We are promised that if the true
ordering is $x_1 &lt; x_2 &lt; \cdots &lt; x_n$ for $\{x_i\}$ an unknown permutation of
the vertices $\{v_i\}$, then $(x_i, x_{i+1}) \in E$ for all $i$: this
Hamiltonian path ensures that sorting is actually possible.
</p>
<p>In this work, we improve the bounds for generalized sorting on both random
graphs and worst-case graphs. For Erd\H{o}s-Renyi random graphs $G(n, p)$ (with
the promised Hamiltonian path added to ensure sorting is possible), we provide
an algorithm for generalized sorting with an expected $O(n \log (np))$
comparisons, which we prove to be optimal for query complexity. This strongly
improves over the best known algorithm of Huang, Kannan, and Khanna (FOCS
2011), which uses $\tilde{O}(\min(n \sqrt{np}, n/p^2))$ comparisons. For
arbitrary graphs $G$ with $n$ vertices and $m$ edges (again with the promised
Hamiltonian path), we provide an algorithm for generalized sorting with
$\tilde{O}(\sqrt{mn})$ comparisons. This improves over the best known algorithm
of Huang et al., which uses $\min(m, \tilde{O}(n^{3/2}))$ comparisons.
</p></div>
    </summary>
    <updated>2021-11-17T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-11-16T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.07217</id>
    <link href="http://arxiv.org/abs/2111.07217" rel="alternate" type="text/html"/>
    <title>Cardinality constrained submodular maximization for random streams</title>
    <feedworld_mtime>1637107200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liu:Paul.html">Paul Liu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rubinstein:Aviad.html">Aviad Rubinstein</a>, Jan Vondrak, Junyao Zhao <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.07217">PDF</a><br/><b>Abstract: </b>We consider the problem of maximizing submodular functions in single-pass
streaming and secretaries-with-shortlists models, both with random arrival
order. For cardinality constrained monotone functions, Agrawal, Shadravan, and
Stein gave a single-pass $(1-1/e-\varepsilon)$-approximation algorithm using
only linear memory, but their exponential dependence on $\varepsilon$ makes it
impractical even for $\varepsilon=0.1$. We simplify both the algorithm and the
analysis, obtaining an exponential improvement in the $\varepsilon$-dependence
(in particular, $O(k/\varepsilon)$ memory). Extending these techniques, we also
give a simple $(1/e-\varepsilon)$-approximation for non-monotone functions in
$O(k/\varepsilon)$ memory. For the monotone case, we also give a corresponding
unconditional hardness barrier of $1-1/e+\varepsilon$ for single-pass
algorithms in randomly ordered streams, even assuming unlimited computation.
</p>
<p>Finally, we show that the algorithms are simple to implement and work well on
real world datasets.
</p></div>
    </summary>
    <updated>2021-11-17T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-11-16T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.07059</id>
    <link href="http://arxiv.org/abs/2111.07059" rel="alternate" type="text/html"/>
    <title>Classical and quantum dynamic programming for Subset-Sum and variants</title>
    <feedworld_mtime>1637107200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Allcock:Jonathan.html">Jonathan Allcock</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hamoudi:Yassine.html">Yassine Hamoudi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Joux:Antoine.html">Antoine Joux</a>, Felix Klingelhöfer, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Santha:Miklos.html">Miklos Santha</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.07059">PDF</a><br/><b>Abstract: </b>Subset-Sum is an NP-complete problem where one must decide if a multiset of
$n$ integers contains a subset whose elements sum to a target value $m$. The
best known classical and quantum algorithms run in time $\tilde{O}(2^{n/2})$
and $\tilde{O}(2^{n/3})$, respectively, based on the well-known
meet-in-the-middle technique. Here we introduce a novel dynamic programming
data structure with applications to Subset-Sum and a number of variants,
including Equal-Sums (where one seeks two disjoint subsets with the same sum),
2-Subset-Sum (a relaxed version of Subset-Sum where each item in the input set
can be used twice in the summation), and Shifted-Sums, a generalization of both
of these variants, where one seeks two disjoint subsets whose sums differ by
some specified value.
</p>
<p>Given any modulus $p$, our data structure can be constructed in time $O(np)$,
after which queries can be made in time $O(n)$ to the lists of subsets summing
to a same value modulo $p$. We use this data structure to give new
$\tilde{O}(2^{n/2})$ and $\tilde{O}(2^{n/3})$ classical and quantum algorithms
for Subset-Sum, not based on the meet-in-the-middle method. We then use the
data structure in combination with variable time amplitude amplification and a
quantum pair finding algorithm, extending quantum element distinctness and claw
finding algorithms to the multiple solutions case, to give an $O(2^{0.504n})$
quantum algorithm for Shifted-Sums, an improvement on the best known
$O(2^{0.773n})$ classical running time. We also study Pigeonhole Equal-Sums and
Pigeonhole Modular Equal-Sums, where the existence of a solution is guaranteed
by the pigeonhole principle. For the former problem we give classical and
quantum algorithms with running time $\tilde{O}(2^{n/2})$ and
$\tilde{O}(2^{2n/5})$, respectively. For the more general modular problem we
give a classical algorithm which also runs in time $\tilde{O}(2^{n/2})$.
</p></div>
    </summary>
    <updated>2021-11-17T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-11-16T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.07049</id>
    <link href="http://arxiv.org/abs/2111.07049" rel="alternate" type="text/html"/>
    <title>Prefix Discrepancy, Smoothed Analysis, and Combinatorial Vector Balancing</title>
    <feedworld_mtime>1637107200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bansal:Nikhil.html">Nikhil Bansal</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jiang:Haotian.html">Haotian Jiang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Meka:Raghu.html">Raghu Meka</a>, Sahil Singla, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sinha:Makrand.html">Makrand Sinha</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.07049">PDF</a><br/><b>Abstract: </b>A well-known result of Banaszczyk in discrepancy theory concerns the prefix
discrepancy problem (also known as the signed series problem): given a sequence
of $T$ unit vectors in $\mathbb{R}^d$, find $\pm$ signs for each of them such
that the signed sum vector along any prefix has a small $\ell_\infty$-norm?
This problem is central to proving upper bounds for the Steinitz problem, and
the popular Koml\'os problem is a special case where one is only concerned with
the final signed sum vector instead of all prefixes. Banaszczyk gave an
$O(\sqrt{\log d+ \log T})$ bound for the prefix discrepancy problem. We
investigate the tightness of Banaszczyk's bound and consider natural
generalizations of prefix discrepancy:
</p>
<p>We first consider a smoothed analysis setting, where a small amount of
additive noise perturbs the input vectors. We show an exponential improvement
in $T$ compared to Banaszczyk's bound. Using a primal-dual approach and a
careful chaining argument, we show that one can achieve a bound of
$O(\sqrt{\log d+ \log\!\log T})$ with high probability in the smoothed setting.
Moreover, this smoothed analysis bound is the best possible without further
improvement on Banaszczyk's bound in the worst case.
</p>
<p>We also introduce a generalization of the prefix discrepancy problem where
the discrepancy constraints correspond to paths on a DAG on $T$ vertices. We
show that an analog of Banaszczyk's $O(\sqrt{\log d+ \log T})$ bound continues
to hold in this setting for adversarially given unit vectors and that the
$\sqrt{\log T}$ factor is unavoidable for DAGs. We also show that the
dependence on $T$ cannot be improved significantly in the smoothed case for
DAGs.
</p>
<p>We conclude by exploring a more general notion of vector balancing, which we
call combinatorial vector balancing. We obtain near-optimal bounds in this
setting, up to poly-logarithmic factors.
</p></div>
    </summary>
    <updated>2021-11-17T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-11-16T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.07024</id>
    <link href="http://arxiv.org/abs/2111.07024" rel="alternate" type="text/html"/>
    <title>Optimal Window Queries on Line Segments using the Trapezoidal Search DAG</title>
    <feedworld_mtime>1637107200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Brankovic:Milutin.html">Milutin Brankovic</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Seybold:Martin_P=.html">Martin P. Seybold</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.07024">PDF</a><br/><b>Abstract: </b>We propose new query applications of the well known randomized incremental
construction of the Trapezoidal Search DAG (TSD) on a set of $n$ line segments
in the plane, where queries are allowed to be any axis aligned window.
</p>
<p>We show that our algorithm reports the $m$ trapezoids that are intersected by
the query in $\mathcal{O}(m+\log n)$ expected time, regardless of the spatial
location of the segment set and the query. In case the query is a {\em vertical
segment}, the query time bound reduces to $\mathcal{O}(k +\log n)$ where $k$ is
the number of segments that are intersected. This improves on the query and
space bound of the well known Segment Tree based approach, which is to date the
theoretical bottleneck for optimal query time. In the case where the set of
segments is a connected planar subdivision, this method can easily be extended
to an algorithm which reports the $k$ segments which intersect an axis aligned
query window in $\mathcal{O}(k + \log n)$ expected time.
</p>
<p>Our publicly available implementation handles degeneracies exactly, including
segments with overlap and multi-intersections. Experiments show that the method
is practical and provides more reliable query times in comparison to R-trees
and the segment tree based data structure on real-world and synthetic data
sets.
</p></div>
    </summary>
    <updated>2021-11-17T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-11-16T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.06967</id>
    <link href="http://arxiv.org/abs/2111.06967" rel="alternate" type="text/html"/>
    <title>CSAT is not in P</title>
    <feedworld_mtime>1637107200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Romano:Fabio.html">Fabio Romano</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.06967">PDF</a><br/><b>Abstract: </b>In this paper we have to demonstrate that if we claim to have an algorithm
that solves CSAT in polynomial time with a DTM (Deterministic Turing Machine),
then we have to admit that: there is a counterexample that invalidates the
correctness of the algorithm. This is because if we suppose that it can prove
that an elenkhos formula (a formula that lists the negated codes of all models)
is a contradiction, and if we change exactly a specific boolean variable of
that formula, then we have proven that: in this case the algorithm will always
fail.
</p></div>
    </summary>
    <updated>2021-11-17T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2021-11-16T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://scottaaronson.blog/?p=6111</id>
    <link href="https://scottaaronson.blog/?p=6111" rel="alternate" type="text/html"/>
    <link href="https://scottaaronson.blog/?p=6111#comments" rel="replies" type="text/html"/>
    <link href="https://scottaaronson.blog/?feed=atom&amp;p=6111" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Scott Aaronson, when reached for comment, said…</title>
    <summary xml:lang="en-US">About IBM’s new 127-qubit superconducting chip: As I told New Scientist, I look forward to seeing the actual details! As far as I could see, the marketing materials that IBM released yesterday take a lot of words to say absolutely nothing about what, to experts, is the single most important piece of information: namely, what […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p><strong>About IBM’s new <a href="https://research.ibm.com/blog/127-qubit-quantum-processor-eagle">127-qubit superconducting chip</a>:</strong> As I <a href="https://www.newscientist.com/article/2297583-ibm-creates-largest-ever-superconducting-quantum-computer/">told <em>New Scientist</em></a>, I look forward to seeing the actual details!  As far as I could see, the marketing materials that IBM released yesterday take a lot of words to say absolutely nothing about what, to experts, is the single most important piece of information: namely, <em>what are the gate fidelities?</em>  How deep of a quantum circuit can they apply?  How have they benchmarked the chip?  Right now, all I have to go on is a <a href="https://quantum-computing.ibm.com/services?services=systems&amp;order=qubits%20DESC&amp;view=table&amp;system=ibm_washington">stats page</a> for the new chip, <s>which reports its average CNOT error as 0.9388—in other words, close to 1, or terrible! (But see also a <a href="https://twitter.com/decodoku/status/1460622008916627456?s=21">tweet by James Wootton</a>, which explains that such numbers are often highly misleading when a new chip is first rolled out.)  Does anyone here have more information?</s>  <strong><span class="has-inline-color has-vivid-red-color">Update (11/17):</span></strong> As of this morning, the average CNOT error has been updated to 2%.  Thanks to multiple commenters for letting me know!</p>



<p><strong>About the <a href="https://arxiv.org/abs/2110.14502">new simulation</a> of Google’s 53-qubit Sycamore chip in 5 minutes on a Sunway supercomputer (see also <a href="https://arxiv.org/abs/2111.01066">here</a>):</strong> This is an exciting step forward on the classical validation of quantum supremacy experiments, and—ironically, what currently amounts to almost the same thing—on the classical <em>spoofing</em> of those experiments.  Congratulations to the team in China that achieved this!  But there are two crucial things to understand.  First, “5 minutes” refers to the time needed to calculate a <em>single</em> amplitude (or perhaps, several correlated amplitudes) using tensor network contraction.  It doesn’t refer to the time needed to generate millions of <em>independent</em> noisy samples, which is what Google’s Sycamore chip does in 3 minutes.  For the latter task, more like a week still seems to be needed on the supercomputer.  (I’m grateful to Chu Guo, a coauthor of the new work who spoke in UT Austin’s weekly quantum Zoom meeting, for clarifying this point.)  Second, the Sunway supercomputer has parallel processing power equivalent to approximately ten million of your laptop.  Thus, even if we agreed that Google no longer had quantum supremacy as measured by time, it would still have quantum supremacy as measured by carbon footprint!  (And this despite the fact that the quantum computer itself requires a noisy, closet-sized dilution fridge.)  Even so, for me the new work underscores the point that quantum supremacy is not yet a done deal.  Over the next few years, I hope that Google and USTC, as well as any new entrants to this race (IBM? IonQ? Harvard? Rigetti?), will push forward with more qubits and, even more importantly, better gate fidelities leading to higher Linear Cross-Entropy scores.  Meanwhile, we theorists should try to do our part by inventing new and better protocols with which to demonstrate near-term quantum supremacy—<em>especially</em> protocols for which the classical verification is easier.</p>



<p><strong>About the new anti-woke <a href="https://bariweiss.substack.com/p/we-cant-wait-for-universities-to">University of Austin</a> (UATX):</strong> In general, I’m extremely happy for people to experiment with new and different institutions, and of course I’m happy for more intellectual activity in my adopted city of Austin.  And, as <em>Shtetl-Optimized</em> readers will know, I’m probably more sympathetic than most to the reality of the problem that UATX is trying to solve—living, as we do, in an era when one academic after another has been cancelled for ideas that a mere decade ago would’ve been considered unexceptional, moderate, center-left.  Having said all that, I wish I could feel more optimistic about UATX’s prospects.  I found its <a href="https://www.uaustin.org/">website</a> heavy on free-speech rhetoric but frustratingly light on what the new university is actually going to <em>do</em>: what courses it will offer, who will teach them, where the campus will be, etc. etc.  Arguably this is all excusable for a university still in ramp-up mode, but had I been in their shoes, I might have held off on the public launch until I had at least some sample content to offer.  Certainly, the fact that Steven Pinker has <a href="https://www.uaustin.org/news/uatx-statement-about-robert-zimmer-and-steven-pinker">quit UATX’s advisory board</a> is a discouraging sign.  If UATX asks me to get involved—to lecture there, to give them advice about their CS program, etc.—I’ll consider it as I would any other request.  So far, though, they haven’t.</p>



<p><strong>About the Association for Mathematical Research:</strong> Last month, some colleagues invited me to join a brand-new society called the <a href="https://amathr.org/">Association for Mathematical Research</a>.  Many of the other founders (Joel Hass, Abigail Thompson, Colin Adams, Richard Borcherds, Jeff Cheeger, Pavel Etingof, Tom Hales, Jeff Lagarias, Mark Lackenby, Cliff Taubes, …) were brilliant mathematicians who I admired, they seemed like they could use a bit of theoretical computer science representation, there was no time commitment, maybe they’d eventually do something good, so I figured why not?  Alas, to say that AMR has proved unpopular on Twitter would be an understatement: it’s received the same contemptuous reception that UATX has.  The argument seems to be: starting a new mathematical society, even an avowedly diverse and apolitical one, is really just an implicit claim that the existing societies, like the <a href="https://www.maa.org/">Mathematical Association of America (MAA)</a>  and the <a href="https://www.ams.org/home/page">American Mathematical Society (AMS)</a>, have been co-opted by woke true-believers.  But that’s paranoid and insane!  I mean, it’s not as if an <a href="https://blogs.ams.org/inclusionexclusion/">AMS blog</a> has called for the <a href="https://blogs.ams.org/inclusionexclusion/2017/05/11/get-out-the-way/#more-772">mass resignation</a> of white male mathematicians to make room for the marginalized, or the boycott of Israeli universities, or the abolition of the criminal justice system <font size="-3"><em>(what to do about Kyle Rittenhouse though?)</em></font>.  Still, even though claims of that sort of co-option are obviously far-out, rabid fantasies, yeah, I did decide to give a new organization the benefit of the doubt.  AMR might well fail or languish in obscurity, just like UATX might.  On the other hand, the barriers to making a positive difference for the intellectual world, the world I love, the world under constant threat from the self-certain ideologues of every side, do strike me as orders of magnitude smaller for a new professional society than they do for a new university.</p></div>
    </content>
    <updated>2021-11-16T23:06:35Z</updated>
    <published>2021-11-16T23:06:35Z</published>
    <category scheme="https://scottaaronson.blog" term="Announcements"/>
    <category scheme="https://scottaaronson.blog" term="Complexity"/>
    <category scheme="https://scottaaronson.blog" term="Obviously I'm Not Defending Aaronson"/>
    <category scheme="https://scottaaronson.blog" term="Quantum"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://scottaaronson.blog/?feed=atom</id>
      <icon>https://scottaaronson.blog/wp-content/uploads/2021/10/cropped-Jacket-32x32.gif</icon>
      <link href="https://scottaaronson.blog" rel="alternate" type="text/html"/>
      <link href="https://scottaaronson.blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2021-11-17T15:32:33Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://dstheory.wordpress.com/?p=105</id>
    <link href="https://dstheory.wordpress.com/2021/11/16/thursday-nov-18th-nicole-immorlica-from-msr/" rel="alternate" type="text/html"/>
    <title>Thursday Nov 18th — Nicole Immorlica  from Microsoft Research</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">The next Foundations of Data Science virtual talk will take place on Thursday, Nov 18th at 10:00 AM Pacific Time (13:00 Eastern Time, 19:00 Central European Time, 18:00 UTC). Nicole Immorlica from Microsoft Research will speak about “Communicating with Anecdotes”. Please register here to join the virtual talk. Abstract: Classic models of communication in economics typically assume<a class="more-link" href="https://dstheory.wordpress.com/2021/11/16/thursday-nov-18th-nicole-immorlica-from-msr/">Continue reading <span class="screen-reader-text">"Thursday Nov 18th — Nicole Immorlica  from Microsoft Research"</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p class="has-text-align-justify">The next <a href="https://sites.google.com/view/dstheory/home" rel="noreferrer noopener" target="_blank">Foundations of Data Science</a> virtual talk will take place on <strong>Thursday, Nov 18</strong>th at <strong>10:00 AM Pacific Time</strong> (13:00 Eastern Time, 19:00 Central European Time, 18:00 UTC). <strong><a href="https://immorlica.com/" rel="noreferrer noopener" target="_blank">Nicole Immorlica</a></strong> from<strong> Microsoft Research</strong> will speak about “Communicating with Anecdotes”.</p>



<p><a href="https://sites.google.com/view/dstheory" rel="noreferrer noopener" target="_blank">Please register here to join the virtual talk.</a></p>



<p class="has-text-align-justify"><strong>Abstract</strong>: Classic models of communication in economics typically assume agents can communicate any message.  However, many important communications, such as those in newspapers or politicians’ speeches, use data to convey information.  In this talk, we explore how the reliance on data impacts communication.  In our model, there are two Bayesian agents (a sender and a receiver) who wish to communicate. The receiver must take an action whose payoff depends on their personal preferences and an unknown state of the world. The sender has access to a collection of data points correlated with the state of the world and can send exactly one of these to the receiver in order to influence her choice of action. Importantly, the sender’s personal preferences may differ from the receiver’s, which affects the sender’s strategic choice of what to send. We show that in a Nash equilibrium even a small difference in preferences can lead to a significant bias in the communicated datum. This can significantly reduce informativeness of the communication, leading to substantial utility loss for both sides. One implication is informational homophily: a receiver can rationally prefer to obtain data from a poorly-informed sender with aligned preferences, rather than a knowledgeable expert whose preferences may differ from her own.  </p>



<p>Joint work with Nika Haghtalab, Brendan Lucier, Markus Mobius and Divya Mohan.</p>



<p>The series is supported by the <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1934846&amp;HistoricalAwards=false">NSF HDR TRIPODS Grant 1934846</a>.</p></div>
    </content>
    <updated>2021-11-16T17:07:03Z</updated>
    <published>2021-11-16T17:07:03Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>dstheory</name>
    </author>
    <source>
      <id>https://dstheory.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://dstheory.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://dstheory.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://dstheory.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://dstheory.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Foundation of Data Science – Virtual Talk Series</title>
      <updated>2021-11-17T18:21:54Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/161</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/161" rel="alternate" type="text/html"/>
    <title>TR21-161 |  On Worst-Case Learning in Relativized Heuristica | 

	Mikito Nanashima, 

	Shuichi Hirahara</title>
    <summary>A PAC learning model involves two worst-case requirements: a learner must learn all functions in a class on all example distributions. However, basing the hardness of learning on NP-hardness has remained a key challenge for decades. In fact, recent progress in computational complexity suggests the possibility that a weaker assumption might be sufficient for worst-case learning than the feasibility of worst-case algorithms for NP problems.

In this study, we investigate whether these worst-case requirements for learning are satisfied on the basis of only average-case assumptions in order to understand the nature of learning. First, we construct a strong worst-case learner based on the assumption that DistNP $\subseteq$ AvgP, i.e., in Heuristica. Our learner agnostically learns all polynomial-size circuits on all unknown P/poly-samplable distributions in polynomial time, where the complexity of learning depends on the complexity of sampling examples. Second, we study the limitation of relativizing constructions of learners based on average-case heuristic algorithms. Specifically, we construct a powerful oracle such that DistPH $\subseteq$ AvgP, i.e., every problem in PH is easy on average, whereas UP $\cap$ coUP and PAC learning on almost-uniform distributions are hard even for $2^{n/\omega(\log n)}$-time algorithms in the relativized world, which improves the oracle separation presented by Impagliazzo (CCC 2011). The core concept of our improvements is the consideration of a switching lemma on a large alphabet, which may be of independent interest. The lower bound on the time complexity is nearly optimal because Hirahara (STOC 2021) showed that DistPH $\subseteq$ AvgP implies that PH can be solved in time $2^{O(n / \log n)}$ under any relativized world.</summary>
    <updated>2021-11-16T15:16:47Z</updated>
    <published>2021-11-16T15:16:47Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-11-17T18:20:31Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/11/16/assistant-professor-tenure-track-in-quantum-computing-quantum-information-theory-at-qici-department-of-computer-science-the-university-of-hong-kong-apply-by-december-15-2021/</id>
    <link href="https://cstheory-jobs.org/2021/11/16/assistant-professor-tenure-track-in-quantum-computing-quantum-information-theory-at-qici-department-of-computer-science-the-university-of-hong-kong-apply-by-december-15-2021/" rel="alternate" type="text/html"/>
    <title>Assistant Professor (Tenure Track) in Quantum Computing/Quantum Information Theory at QICI, Department of Computer Science, The University of Hong Kong (apply by December 15, 2021)</title>
    <summary>Eligible candidates will have a strong track record in quantum computing and/or quantum information theory, and will hold a PhD in Computer Science, Physics, or Mathematics. The official deadline for applications is March 31 2022. To receive full consideration, candidates are recommended to submit their applications before December 15 2021. Website: https://qici.weebly.com/ Email: giulio@cs.hku.hk</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Eligible candidates will have a strong track record in quantum computing and/or quantum information theory, and will hold a PhD in Computer Science, Physics, or Mathematics.</p>
<p>The official deadline for applications is March 31 2022. To receive full consideration, candidates are recommended to submit their applications before December 15 2021.</p>
<p>Website: <a href="https://qici.weebly.com/">https://qici.weebly.com/</a><br/>
Email: giulio@cs.hku.hk</p></div>
    </content>
    <updated>2021-11-16T06:23:08Z</updated>
    <published>2021-11-16T06:23:08Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-11-17T18:20:45Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/11/15/postdoc-at-the-university-of-texas-at-austin-apply-by-january-15-2022/</id>
    <link href="https://cstheory-jobs.org/2021/11/15/postdoc-at-the-university-of-texas-at-austin-apply-by-january-15-2022/" rel="alternate" type="text/html"/>
    <title>postdoc at The University of Texas at Austin (apply by January 15, 2022)</title>
    <summary>The NSF AI Institute for Foundations of Machine Learning (https://ifml.institute/), and the NSF TRIPODS program at UT-Austin seek candidates for UT Machine Learning Postdoctoral Fellowships. Appointments will begin Summer or Fall 2022. Fellows can collaborate with researchers involved in IFML partner institutions: UT-Austin, UW, MSR Redmond, and WSU. Website: http://apply.interfolio.com/98753 Email: ifml@austin.utexas.edu</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The NSF AI Institute for Foundations of Machine Learning (<a href="https://ifml.institute/">https://ifml.institute/</a>), and the NSF TRIPODS program at UT-Austin seek candidates for UT Machine Learning Postdoctoral Fellowships. Appointments will begin Summer or Fall 2022. Fellows can collaborate with researchers involved in IFML partner institutions: UT-Austin, UW, MSR Redmond, and WSU.</p>
<p>Website: <a href="http://apply.interfolio.com/98753">http://apply.interfolio.com/98753</a><br/>
Email: ifml@austin.utexas.edu</p></div>
    </content>
    <updated>2021-11-15T23:50:42Z</updated>
    <published>2021-11-15T23:50:42Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-11-17T18:20:45Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/160</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/160" rel="alternate" type="text/html"/>
    <title>TR21-160 |  Tight Bounds for General Computation in Noisy Broadcast Networks | 

	Klim Efremenko, 

	Gillat Kol, 

	Dmitry Paramonov, 

	Raghuvansh Saxena</title>
    <summary>Let $\Pi$ be a protocol over the $n$-party broadcast channel, where in each round, a pre-specified party broadcasts a symbol to all other parties. We wish to design a scheme that takes such a protocol $\Pi$ as input and outputs a noise resilient protocol $\Pi'$ that simulates $\Pi$ over the noisy broadcast channel, where each received symbol is flipped with a fixed constant probability, independently. What is the minimum overhead in the number of rounds that is incurred by any such simulation scheme?

A classical result by Gallager from the 80's shows that non-interactive $T$-round protocols, where the bit communicated in every round is independent of the communication history, can be converted to noise resilient ones with only an $\mathcal{O}(\log \log T)$ multiplicative overhead in the number of rounds. Can the same be proved for any protocol? Or, are there protocols whose simulation requires an $\Omega(\log T)$ overhead (which always suffices)? 

We answer both the above questions in the negative: We give a simulation scheme with an $\tilde{O}(\sqrt{\log T})$ overhead for every protocol and channel alphabet. We also prove an (almost) matching lower bound of $\Omega(\sqrt{\log T})$ on the overhead required to simulate the pointer chasing protocol with $T=n$ and polynomial alphabet.</summary>
    <updated>2021-11-15T21:18:44Z</updated>
    <published>2021-11-15T21:18:44Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-11-17T18:20:31Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2021/11/15/linkage</id>
    <link href="https://11011110.github.io/blog/2021/11/15/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>How to tell someone how to get to your house without knowing where they’re starting (\(\mathbb{M}\)), how to tell someone how to get to your house without knowing where they’re starting, how to translate a Penn &amp; Teller trick into Spanish, and other applications of the Černý conjecture on synchronizing words. This video by Nóra Szakács is one of an enormous number of recent mathematics explanation videos in the “Some1” summer of math exposition video project.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><ul>
  <li>
    <p><a href="https://www.youtube.com/watch?v=4gsp3CZUtV0">How to tell someone how to get to your house without knowing where they’re starting</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107206208305724024">\(\mathbb{M}\)</a>),</span> how to tell someone how to get to your house without knowing where they’re starting, how to translate a Penn &amp; Teller trick into Spanish, and other applications of the <a href="https://en.wikipedia.org/wiki/Synchronizing_word">Černý conjecture on synchronizing words</a>. This video by Nóra Szakács is one of an enormous number of recent mathematics explanation videos in the <a href="https://www.youtube.com/watch?v=F3Qixy-r_rQ">“Some1” summer of math exposition video project</a>.</p>
  </li>
  <li>
    <p>One of our instructor’s strategies for dealing with sites like Chegg that cater to homework answer-copiers <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107217545955814360">\(\mathbb{M}\)</a>):</span> seek out and assign homework questions that already have particularly bad answers on Chegg. That way the copiers are more easily caught and the students who actually do the work have a better chance to shine over their copying peers. And if doing this ends up causing Chegg to get more of a reputation for inaccuracy, that’s not a bad thing either.</p>
  </li>
  <li>
    <p><a href="https://www.nature.com/articles/d41586-021-02906-8">Facebook isn’t the only company changing its name in an unsuccessful attempt to separate itself from its poor reputation</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107223269542696792">\(\mathbb{M}\)</a>).</span> Around when the FTC fined OMICS for predatory practices, it began rebranding its journals and past papers with other publisher names (Hilaris, Longdom, iMedPub, and Research &amp; Reviews), rewriting the editorship history of its journals, and even lifting other publishers’ papers to fabricate a legitimate-looking backlog for its journals.</p>
  </li>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/Constructible_number">Constructible number</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107233293561788882">\(\mathbb{M}\)</a>),</span> now a Good Article on Wikipedia. This concerns the correspondence between compass-and-straightedge constructions and formulas using square roots, and the use of that correspondence to prove the impossibility of classical geometric construction problems. Relatedly, see <a href="http://jdh.hamkins.org/the-hierarchy-of-geometric-constructibility-can-we-go-back/">Joel Hamkins’ new blog post</a> on how constructibility of one set of points from another produces an equivalence relation on pairs of points.</p>
  </li>
  <li>
    <p><a href="https://www.smh.com.au/national/nsw/quantum-computers-to-run-sydney-s-transport-network-20211107-p596r5.html">Quantum computers to run Sydney’s transport network</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107236800356354250">\(\mathbb{M}\)</a>,</span> <a href="https://news.ycombinator.com/item?id=29139633">via</a>). In other news, Sydney politicians are unable to distinguish hype from actual technology advancements, or maybe more cynically unwilling to do so when the hype would let them dole out lucrative contracts.</p>
  </li>
  <li>
    <p><a href="https://terrytao.wordpress.com/2021/11/07/venn-and-euler-type-diagrams-for-vector-spaces-and-abelian-groups/">Terry Tao attempts to visualize vector spaces, linear maps, and exact sequences using arrows from arrows to arrows</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107240160987527319">\(\mathbb{M}\)</a>).</span> Ok, some of the arrows are really supposed to be half-open intervals, but drawn with a barred closed end and a pointy open end they look a lot like <span style="white-space: nowrap;">\(\mapsto\).</span></p>
  </li>
  <li>
    <p><a href="https://www.inputmag.com/culture/pinterest-sucks-google-image-photo-search-ruining-internet">How Pinterest utterly ruined photo search on the internet</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107246007841558595">\(\mathbb{M}\)</a>, <a href="https://news.ycombinator.com/item?id=29151055">via</a>).</span> The title is a bit of an exaggeration given how easy it is to add <code class="language-plaintext highlighter-rouge">-pinterest</code> to every single image search you do (with quick feedback for why you need to do it when you forget). But they’re not wrong about it being a useless annoyance.</p>
  </li>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/Farthest-first_traversal">Farthest-first traversal / greedy permutation</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107251720248944263">\(\mathbb{M}\)</a>):</span> generate a sequence of points, choosing each one to be as far as possible from already chosen points. Its first \(k\) points form good cluster centers (approximating min-max-diameter or min-max-radius clustering) and are well separated (approximating max-min distance). Its applications include halftoning, color quantization, sensor network distribution, and underwater robot task planning. Now another Wikipedia Good Article.</p>
  </li>
  <li>
    <p>Today in amusingly-named concepts: the <a href="https://en.wikipedia.org/wiki/Lorentz%E2%80%93Lorenz_equation">Lorentz–Lorenz equation</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107257423214935119">\(\mathbb{M}\)</a>)</span> relating refractive index to polarizability. Even more amusingly, it was not a deliberate collaboration: Lorentz and Lorenz discovered the equation independently! Via a comment over on that other site, in <a href="https://twitter.com/hollykrieger/status/1456321630733574144">a thread making fun of the new Meta logo for its resemblance to a strange attractor</a>. Now if only we could somehow connect it to <a href="https://read.somethingorotherwhatever.com/entry/ItislikeeggPaulLorenzenandthecollapseofproofsofconsistency">Paul Lorenzen</a>…</p>
  </li>
  <li>
    <p><a href="https://mathstodon.xyz/@christianp/107258956124702057">How to search for number facts sites without searching for number facts sites</a> and <a href="https://mathstodon.xyz/@jsiehler/107259309683467429">how to search for the mathematics of poker without getting a bunch of sketchy gambling sites</a>: search for the numbers, not the words.</p>
  </li>
  <li>
    <p><a href="https://eli.thegreenplace.net/2021/rust-data-structures-with-circular-references/">How memory-safe programming in Rust can complicate the design of data structures</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107271384674149840">\(\mathbb{M}\)</a>,</span> <a href="https://news.ycombinator.com/item?id=29207397">via</a>, <a href="https://lobste.rs/s/ydstwh/rust_data_structures_with_circular">via2</a>). Rust data structures cannot have circular references, so if you need them you can either fall back to non-memory-safe techniques (reference counting or unsafe blocks) or make your top-level structure implement its own memory allocator and refer to everything by indexes into its vector of objects instead of by proper references.</p>
  </li>
  <li>
    <p><a href="https://rjlipton.wpcomstaging.com/2021/11/13/popl-2022-et-tu-brute/">Too few women at POPL 2022</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107272383946893132">\(\mathbb{M}\)</a>).</span> The low 11% representation on the program committee is especially striking in contrast to the significant historical contributions of women to programming languages (Kathleen Booth, Cicely Popplewell, Grace Hopper, Jean Sammet, Mary Hawes, Gertrude Tierney, and Barbara Liskov among them). According to the same post, the major theoretical computer science conferences are only slightly better.</p>
  </li>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/Handshaking_lemma">Handshaking lemma</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107284266077522291">\(\mathbb{M}\)</a>),</span> now another Good Article on Wikipedia. This is really about two different but closely-related results, both proved by Euler in his 1736 paper that kicked off the field of graph theory: in any finite undirected graph, the sum of vertex degrees equals twice the number of edges, and the number of odd-degree vertices is even.</p>
  </li>
</ul></div>
    </content>
    <updated>2021-11-15T18:25:00Z</updated>
    <published>2021-11-15T18:25:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2021-11-16T07:29:26Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/159</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/159" rel="alternate" type="text/html"/>
    <title>TR21-159 |  Constructive Separations and Their Consequences | 

	Lijie Chen, 

	Ce Jin, 

	Rahul Santhanam, 

	Ryan Williams</title>
    <summary>For a complexity class $C$ and language $L$, a constructive separation of $L \notin C$ gives an efficient algorithm (also called a refuter) to find counterexamples (bad inputs) for every $C$-algorithm attempting to decide $L$. We study the questions: Which lower bounds can be made constructive? What are the consequences of constructive separations? We build a case that  ``constructiveness'' serves as a dividing line between many weak lower bounds we know how to prove, and strong lower bounds against $P$, $ZPP$, and $BPP$. Put another way, constructiveness is the opposite of a complexity barrier: it is a property we want lower bounds to have. Our results fall into three broad categories.
		
1. For many separations, making them constructive would imply breakthrough lower bounds. Our first set of results shows that, for many well-known lower bounds against streaming algorithms, one-tape Turing machines, and query complexity, as well as lower bounds for the Minimum Circuit Size Problem, making these lower bounds constructive would imply breakthrough separations ranging from $EXP \neq BPP$ to even $P \neq NP$. 

2. Most conjectured uniform separations can be made constructive. Our second set of results shows that for most major open problems in lower bounds against $P$, $ZPP$, and $BPP$, including $P \neq NP$, $P \neq PSPACE$, $P \neq PP$, $ZPP \neq EXP$, and $BPP \neq NEXP$, any proof of the separation would further imply a constructive separation. Our results generalize earlier results for $P \neq NP$ [Gutfreund, Shaltiel, and Ta-Shma, CCC 2005] and $BPP \neq NEXP$ [Dolev, Fandina and Gutfreund, CIAC 2013]. Thus any proof of these strong lower bounds must also yield a constructive version, compared to many weak lower bounds we currently know.
		
3. Some separations cannot be made constructive. Our third set of results shows that certain complexity separations cannot be made constructive. We observe that for all super-polynomially growing functions $t$, there are no constructive separations for detecting high $t$-time Kolmogorov complexity (a task which is known to be not in $P$) from any complexity class, unconditionally. We also show that under plausible conjectures, there are languages in $NP - P$ for which there are no constructive separations from any complexity class.</summary>
    <updated>2021-11-15T17:32:35Z</updated>
    <published>2021-11-15T17:32:35Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-11-17T18:20:31Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-378272747883656707</id>
    <link href="http://blog.computationalcomplexity.org/feeds/378272747883656707/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2021/11/when-did-computer-science-theory-get-so.html#comment-form" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/378272747883656707" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/378272747883656707" rel="self" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2021/11/when-did-computer-science-theory-get-so.html" rel="alternate" type="text/html"/>
    <title>When did Computer Science Theory Get so Hard?</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p> I posted on <a href="https://blog.computationalcomplexity.org/2019/07/when-did-math-get-so-hard.html">When did Math get so hard?</a> a commenter pointed out that one can also ask </p><p><br/></p><p><i>When did Computer Science Theory Get so Hard?</i></p><p>For the Math-question I could only speculate. For CS- I WAS THERE! When I was in Grad School one could learn all of Complexity theory in a year-long course (a hard one, but still!). The main tools were logic and combinatorics. No Fourier Transforms over finite fields. I am NOT going to say</p><p><i>Those were the good old days.</i></p><p>I will say that it was easier to make a contribution without knowing much. Oddly enough, it is MORE common for ugrads and grad students to publish NOW then it was THEN, so that may be a pair of ducks.</p><p><b>Random Thoughts on This Question</b></p><p>1) The Graph Minor Theorem was when P lost its innocence. Before the GMT most (though not all)  problems in P had easy-to-understand  algorithms using algorithmic paradigms (e.g., Dynamic  Programming) and maybe some combinatorics. Computational Number Theory used.... Number Theory (duh), but I don't think it was hard number theory. One exception was Miller's Primality test which needed to assume the Extended Riemann Hypothesis- but you didn't have to understand ERH to use it. </p><p>1.5) GMT again. This did not only give hard-deep-math algorithms to get problems in P. It  also pointed to  how hard proving P NE NP would be--- to rule out something like a GMT-type result to get SAT in P seems rather hard. </p><p>2) Oracle Constructions were fairly easy diagonalizations. It was bummed out that I never had to use an infinite injury priority argument. That is, I knew some complicated recursion theory, but it was never used. </p><p>2.5) Oracles again. Dana Angluin had a paper which used some complicated combinatorics to construct an oracle, see <a href="https://www.sciencedirect.com/science/article/pii/0304397580900274?via%3Dihub">here</a>. Later Andy Yao showed that there is an oracle A such that  PH^A NE  PSPACE^A. You might know that result better as</p><p><i>Constant depth circuits for parity must have exponential size. </i></p><p>I think we now care about circuits more than oracles, see my post <a href="https://blog.computationalcomplexity.org/2015/04/the-new-oracle-result-new-circuit.html">here</a> about that issue. Anyway, oracle results since then have used hard combinatorial and other math arguments. </p><p>3) The PCP result was a leap forward for difficulty. I don't know which paper to pick as THE Leap since there were several. And papers after that were also rather difficult.  </p><p>4) I had a blog post <a href="https://blog.computationalcomplexity.org/2021/04/do-any-np-reductions-use-deep.html#comment-form">here</a> where I asked if REDUCTIONS ever use hard math. Some of the comments are relevant here:</p><p>Stella Biderman: The deepest part of the original PCP theorem is the invention of the VC paradigm in the 1990's.</p><p>Eldar: Fourier Theory was introduced to CS with Hastad's Optimal Approximation results. Today it might not be considered deep, but I recall when it was.</p><p>Also there are Algebraic Geometry codes which use downright arcane mathematics...</p><p>Hermann Gruber refers to Comp Topology and Comp Geometry and points to the result that 3-manifold knot genus is NP-complete, see <a href="https://dl.acm.org/doi/10.1145/509907.510016">here</a>.</p><p>Anonymous (they leave many comments) points to the deep math reductions in arithmetic versions of P/NP classes, and Mulmuley's work (Geometric Complexity Theory).</p><p>Timothy Chow points out that `deep' could mean several things and points to a math overflow post on the issue of depth, <a href="https://mathoverflow.net/questions/139607/what-are-some-deep-theorems-and-why-are-they-considered-deep">here</a>.</p><p>Marzio De Biasi points out that even back in 1978 there was a poly reduction that required a good amount of number theory: the NPC of the Diophantine binary quad equation</p><p>ax^2 + by + c = 0 </p><p>by Manders and Adelman, see <a href="https://www.sciencedirect.com/science/article/pii/0022000078900442?via%3Dihub">here</a>.</p><p>(Bill Comment) I tend to think this is an outlier- for the most part, CS theory back in the 1970's did not hard math. </p><p>4) Private Info Retrieval (PIR). k databases each have the same n-bit string and cannot talk to each other. a server wants the ith bit and (in the info-theoretic case) wants the DBs to know NOTHING about the question i. </p><p>Easy results (to understand) 2-server, n^{1/3}. <a href="http://www.cs.umd.edu/~gasarch/TOPICS/pir/first.pdf">here</a>.</p><p>Hard results: 2-server n^{O(\sqrt{loglogn/log n)},  <a href="https://www.cs.princeton.edu/~zdvir/papers/DvirGopi14.pdf">here</a>.</p><p>(I have a website on PIR, not maintained,  <a href="http://www.cs.umd.edu/~gasarch/TOPICS/pir/pir.html">here</a>.)</p><p>5) Babai's algorithm for GI in quasi-poly time used hard math. </p><p>6) If I knew more CS theory I am sure I would have more papers listed.</p><p>But now its your turn: </p><p>When did you realize Gee, <b>CS theory is harder than (a) you thought, (b) it used to be.</b></p><p><b><br/></b></p><p><br/></p><p><br/></p><p><br/></p><p><br/></p></div>
    </content>
    <updated>2021-11-15T03:50:00Z</updated>
    <published>2021-11-15T03:50:00Z</published>
    <author>
      <name>gasarch</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03004932739846901628</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="http://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2021-11-17T16:58:54Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/11/15/faculty-at-northwestern-university-apply-by-december-10-2021/</id>
    <link href="https://cstheory-jobs.org/2021/11/15/faculty-at-northwestern-university-apply-by-december-10-2021/" rel="alternate" type="text/html"/>
    <title>Faculty at Northwestern University (apply by December 10, 2021)</title>
    <summary>We invite candidates to apply for new positions as Assistant, Associate and Full Professor of Computer Science. We are interested in applications from outstanding candidates in all areas of Computer Science. See the website for cross-cutting areas of interest. Website: https://www.mccormick.northwestern.edu/computer-science/careers/ Email: nu.cstheory@gmail.com</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>We invite candidates to apply for new positions as Assistant, Associate and Full Professor of Computer Science. We are interested in applications from outstanding candidates in all areas of Computer Science. See the website for cross-cutting areas of interest.</p>
<p>Website: <a href="https://www.mccormick.northwestern.edu/computer-science/careers/">https://www.mccormick.northwestern.edu/computer-science/careers/</a><br/>
Email: nu.cstheory@gmail.com</p></div>
    </content>
    <updated>2021-11-15T01:34:05Z</updated>
    <published>2021-11-15T01:34:05Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-11-17T18:20:45Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/11/14/postdoc-at-university-of-waterloo-apply-by-december-31-2021/</id>
    <link href="https://cstheory-jobs.org/2021/11/14/postdoc-at-university-of-waterloo-apply-by-december-31-2021/" rel="alternate" type="text/html"/>
    <title>Postdoc at University of Waterloo (apply by December 31, 2021)</title>
    <summary>The Algorithms &amp; Complexity group at the University of Waterloo is offering postdoctoral positions starting in the Fall of 2022. We seek candidates from all areas of theoretical computer science. Interested applicants should have their CV, research statement, and three recommendation letters emailed to theory.waterloo@gmail.com. Applications are due December 31st. Website: https://algcomp.uwaterloo.ca/positions/ Email: theory.waterloo@gmail.com</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Algorithms &amp; Complexity group at the University of Waterloo is offering postdoctoral positions starting in the Fall of 2022. We seek candidates from all areas of theoretical computer science.</p>
<p>Interested applicants should have their CV, research statement, and three recommendation letters emailed to theory.waterloo@gmail.com. Applications are due December 31st.</p>
<p>Website: <a href="https://algcomp.uwaterloo.ca/positions/">https://algcomp.uwaterloo.ca/positions/</a><br/>
Email: theory.waterloo@gmail.com</p></div>
    </content>
    <updated>2021-11-14T20:59:51Z</updated>
    <published>2021-11-14T20:59:51Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-11-17T18:20:45Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2021/11/14/random-independent-sets</id>
    <link href="https://11011110.github.io/blog/2021/11/14/random-independent-sets.html" rel="alternate" type="text/html"/>
    <title>Random independent sets in bounded-treewidth graphs</title>
    <summary>This week my student Daniel Frishberg posted our new preprint “Rapid mixing of the hardcore Glauber dynamics and other Markov chains in bounded-treewidth graphs”, arXiv:2111.03898. Despite the somewhat-technical title and content, it’s on an easy-to-explain problem, of generating random combinatorial objects (like independent sets in graphs) using random walks. Start with an undirected graph and an empty subset of its vertices, and then repeatedly choose a random vertex, flipping whether it is in or out of the subset whenever the resulting subset remains independent. How many of these steps does it take until the resulting random distribution on independent sets is nearly uniform?</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>This week my student Daniel Frishberg posted our new preprint “Rapid mixing of the hardcore Glauber dynamics and other Markov chains in bounded-treewidth graphs”, <a href="https://arxiv.org/abs/2111.03898">arXiv:2111.03898</a>. Despite the somewhat-technical title and content, it’s on an easy-to-explain problem, of generating random combinatorial objects (like independent sets in graphs) using random walks. Start with an undirected graph and an empty subset of its vertices, and then repeatedly choose a random vertex, flipping whether it is in or out of the subset whenever the resulting subset remains independent. How many of these steps does it take until the resulting random distribution on independent sets is nearly uniform?</p>

<p>In general, this can take exponentially many steps, but our paper proves that in graphs of bounded <a href="https://en.wikipedia.org/wiki/Treewidth">treewidth</a> it is only polynomial. Our proof’s exponent depends on the treewidth, but maybe a better proof can get the dependence on treewidth out of the exponent and into the constant factor of the polynomial instead. However, if all you want to do is generate random independent sets, this is not the right way to do it. The point of the paper is less about fast algorithms and more about the connectivity of the space of independent sets. So if you do want a fast algorithm for random generation, what should you do?</p>

<p>This is, unfortunately, an area where some care is required and much of the literature does not take the required care. Problematic issues include:</p>

<ul>
  <li>
    <p>What is the model of computation for arithmetic operations? Much of the literature for the design and analysis of graph algorithms assumes without much attention that all arithmetic operations take unit time. This is a reasonable assumption for small numbers (of at most polynomial magnitude), as occur in many algorithms including the random walk above. In those cases it is a close match to the kind of operation that can be done in a single instruction on a modern CPU. It is not a reasonable assumption for counting algorithms dealing with numbers of exponential magnitude. Counting is an important subproblem for exact random generation, so we need large numbers. Typically, the number of independent sets is linear in the input size, the number of bits required to store this number is linear, and the amount of time needed to perform a single operation on a number this large should again be assumed to involve a bignum-package subroutine. The slow steps are multiplications, which can by <a href="https://www.jstor.org/stable/10.4007/annals.2021.193.2.4">recent results of Harvey and van der Hoeven</a> be assumed to take \(O(n\log n)\) time.</p>
  </li>
  <li>
    <p>What is the model for generating random numbers? If random numbers are generated as bits, this only allows the direct generation of random choices with probabilities that are <a href="https://en.wikipedia.org/wiki/Dyadic_rational">dyadic rational</a>. For independent sets, we need other probabilities. <a href="https://en.wikipedia.org/wiki/Rejection_sampling">Rejection sampling</a> leads to an algorithm whose running time is itself a random variable, so we need to use expected time or high-probability bounds instead of worst-case time analysis.</p>
  </li>
  <li>
    <p>How is the input presented? For the random-walk method, it is just a graph, but for other algorithms taking advantage of low treewidth we need a good <a href="https://en.wikipedia.org/wiki/Tree_decomposition">tree decomposition</a>, and finding one is nontrivial. We should either state explicitly that a tree decomposition is given and that its width rather than the graph width controls the algorithm’s runtime, or factor in the time to find a decomposition and the width of decomposition that we find.</p>
  </li>
</ul>

<p>With that all said, how might we go about computing a random independent set for a given \(n\)-vertex graph of treewidth \(w\), achieving the best theoretical performance?</p>

<p>First, we should find an approximate tree decomposition. There are many known algorithms for this problem, but I think the right choice is the one from the recent paper “An improvement of Reed’s treewidth approximation”, Belbasi and Fürer, WALCOM 2021, <a href="https://arxiv.org/abs/2010.03105">arXiv:2010.03105</a>. It finds a tree decomposition of width at most \(5w\), in time \(O(2^{8.8w}n\log n)\). There are other algorithms with a linear dependence on \(n\), but much worse dependence on \(w\), and the \(n\log n\) part of the bound will be dominated by later steps. We can also bootstrap this decomposition, using dynamic programming on it to find a better decomposition, but I think this is too expensive for the savings it produces.</p>

<p>Second, we should count independent sets. Root the tree decomposition, so that we can talk about the subtree descending from any bag and the subgraph of the given graph that it corresponds to. Then for each bag of the decomposition (in bottom-up order), and each independent subset of the bag, we want to count the number of independent sets in the corresponding subgraph that intersect the bag in the given subset. These independent sets are formed by combining choices of independent sets in child nodes. Therefore, we need to find the numbers of independent sets in each child node that are consistent with the choice of subset at the parent, and multiply them together. Each subset of a bag contributes to exactly one such computation at its parent, so the total number of arithmetic operations for this computation is the product of the number of bags and the number of subsets per bag. With bignum arithmetic, the total time for computing all of these counts is \(O(2^{5w}n^2\log n)\). Our new preprint cites a paper for this subproblem that isn’t sufficiently careful about bignum arithmetic, but still somehow ends up with a slower cubic total time bound; I think they’re just being sloppy and overcounting somehow.</p>

<p>Third, we can then reverse the counting process and step downward through the tree decomposition choosing how the random independent set intersects each bag. When we do this for a bag, we already know the intersection of the independent set with the parent bag. Therefore, all we have to do is choose among the subsets of the child bag that are consistent with that already-made choice, using probabilities that are proportional to the numbers of independent sets that can be formed for each consistent subset. We know these numbers because we already computed them in the second stage. So it’s just a single random choice per bag, which (because it involves bignum probabilities that are not dyadic rational) can reasonably be assumed to take a random amount of time whose expectation is linear. For the overall algorithm, the total expected time is \(O(n^2)\). Also, this stage of the algorithm can be repeated over and over, generating new random independent sets, without having to generate new tree decompositions or new counts.</p>

<p>Putting it all together, it appears that the total time for randomly generating independent sets, using dynamic programming on the tree decomposition to count these sets, and assuming fast bignum arithmetic, is \(O(2^{O(w)}n^2\log n)\) for the preprocessing stages of the algorithm, and then \(O(n^2)\) for each successive generated set.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/107278583702646630">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2021-11-14T16:41:00Z</updated>
    <published>2021-11-14T16:41:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2021-11-16T07:29:26Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/11/14/postdoc-at-princeton-university-apply-by-december-1-2021/</id>
    <link href="https://cstheory-jobs.org/2021/11/14/postdoc-at-princeton-university-apply-by-december-1-2021/" rel="alternate" type="text/html"/>
    <title>Postdoc at Princeton University  (apply by December 1, 2021)</title>
    <summary>Princeton ORFE invites applications for a postdoctoral position, starting June 1, 2022, in deep learning theory supported through an NSF Grant of ORFE Assistant Professor Boris Hanin. The position is for one year with the possibility of reappointment for up to two years additional years based on satisfactory performance and availability of funding. Website: https://puwebp.princeton.edu/AcadHire/apply/application.xhtml?listingId=22221 […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Princeton ORFE invites applications for a postdoctoral position, starting June 1, 2022, in deep learning theory supported through an NSF Grant of ORFE Assistant Professor Boris Hanin. The position is for one year with the possibility of reappointment for up to two years additional years based on satisfactory performance and availability of funding.</p>
<p>Website: <a href="https://puwebp.princeton.edu/AcadHire/apply/application.xhtml?listingId=22221">https://puwebp.princeton.edu/AcadHire/apply/application.xhtml?listingId=22221</a><br/>
Email: Bhanin@princeton.edu</p></div>
    </content>
    <updated>2021-11-14T13:07:41Z</updated>
    <published>2021-11-14T13:07:41Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-11-17T18:20:45Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://emanueleviola.wordpress.com/?p=956</id>
    <link href="https://emanueleviola.wordpress.com/2021/11/14/i-doubt-that-there-will-be-eight-i-highly-doubt-there-will-be-eight/" rel="alternate" type="text/html"/>
    <title>“I doubt that there will be eight, I highly doubt there will be eight.”</title>
    <summary>Says campaign strategist at 1:13 on this clip from almost exactly 3 years ago. For background readers can look at this tag. Where are we today? (Official communication.) Union Twist, 1158 Beacon Street in Newton Centre/Four Corners, has been unanimously approved by the City Council for its Special Permit. Union Twist plans to demolish the […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="https://www.nbcboston.com/news/local/newton-voters-reject-measures-to-ban-or-limit-marijuana-shops/104470/">Says campaign strategist at 1:13 on this clip from almost exactly 3 years ago.</a></p>



<p>For background readers can look <a href="https://emanueleviola.wordpress.com/tag/marijuana/">at this tag</a>.</p>



<p>Where are we today?  (Official communication.)</p>



<ul><li>Union Twist, 1158 Beacon Street in Newton Centre/Four Corners, has been unanimously approved by the City Council for its Special Permit. Union Twist plans to demolish the current building on the site consisting of a dry cleaner and restaurant and build a new 2,300-square foot, one story retail building with 22 on-site parking spaces. For at least the first six months of operation, there will be an appointment only requirement for customers at the store. As their Special Permit has been approved, they can move forward with their state Cannabis Control Commission (CCC) licensing approval process.</li></ul>



<ul><li>Garden Remedies, Newton’s first adult-use retail marijuana store, opened at 697 Washington Street in Newtonville more than two years ago in May 2019. Since opening, Garden Remedies has sold to customers by appointment only. The request from Garden Remedies to amend its current Special Permit to remove the appointment only condition for their retail shop was approved by the City Council Land Use Committee. (The vote was 5-0, with three abstentions.) The full City Council will vote on lifting the appointment only condition at their meeting this Monday, Nov. 15.</li></ul>



<ul><li>Redi, Newton’s second adult-use retail marijuana establishment (formerly known as Cypress Tree) opened in July 2021 at 24 Eliot Street at the intersection with Boylston Street/Route 9 in Upper Falls. (It was (formerly known as Cypress Tree.) The Special Permit approved by the City Council requires that Redi’s retail customers must have an appointment to shop or pick-up products for at least the first six months of operation. </li></ul>



<ul><li>Ascend, 1089 Washington Street/58 Cross Street just outside West Newton Square, has a signed provisional HCA and an approved Special Permit. Construction is nearing completion and they are awaiting licensing approval by the CCC to open.</li></ul>



<ul><li>MedMen, 232 Boylston Street/ Rte. 9 in Chestnut Hill (at the former Shreve, Crump &amp; Low location), has a signed provisional Host Community Agreement (HCA) and an approved Special Permit. They are both awaiting licensing approval by the CCC to open as well as a building permit from the City of Newton to begin work on the building.</li></ul>



<ul><li>Green Lady, 740 Beacon Street in Newton Centre, a woman and minority owned business, has a signed provisional HCA and the City Council Land Use Committee is currently hearing its Special Permit application. If their Special Permit is approved, they can then move forward with their CCC licensing approval process </li></ul>



<ul><li>Verilife, 131 Rumford Avenue in Auburndale, has a signed provisional HCA and the City Council Land Use Committee is currently hearing its Special Permit application. If their Special Permit is approved, they can then move forward with their CCC licensing approval process.</li></ul>



<ul><li>Nuestra, 1185 Chestnut Street in Newton Upper Falls, has a signed provisional HCA. Nuestra is a Cannabis Control Commission certified Economic Empowerment Applicant. They have not yet started the City Council Special Permit approval process which they need to do before moving forward in the state licensing approval process.</li></ul>



<p/></div>
    </content>
    <updated>2021-11-14T10:11:08Z</updated>
    <published>2021-11-14T10:11:08Z</published>
    <category term="Uncategorized"/>
    <category term="marijuana"/>
    <author>
      <name>Manu</name>
    </author>
    <source>
      <id>https://emanueleviola.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://emanueleviola.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://emanueleviola.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://emanueleviola.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://emanueleviola.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>by Manu</subtitle>
      <title>Thoughts</title>
      <updated>2021-11-17T18:21:08Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/11/14/tenure-track-assistant-professor-position-in-security-and-privacy-at-graz-university-of-technology-apply-by-november-30-2021/</id>
    <link href="https://cstheory-jobs.org/2021/11/14/tenure-track-assistant-professor-position-in-security-and-privacy-at-graz-university-of-technology-apply-by-november-30-2021/" rel="alternate" type="text/html"/>
    <title>Tenure-Track Assistant Professor Position in Security and Privacy at Graz University of Technology (apply by November 30, 2021)</title>
    <summary>The department for computer science and biomedical engineering at Graz University of Technology invites applications for the position of a tenure track professor of Security &amp; Privacy. The position will be part of a IAIK, which provides a research environment with more than 60 researchers in Security &amp; Privacy. Website: https://www.tugraz.at/fakultaeten/csbme/news/jobs-grants-calls/tenure-track-professor-in-security-and-privacy/ Email: Stefan.Mangard@iaik.tugraz.at</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The department for computer science and biomedical engineering at Graz University of Technology invites applications for the position of a tenure track professor of Security &amp; Privacy. The position will be part of a IAIK, which provides a research environment with more than 60 researchers in Security &amp; Privacy.</p>
<p>Website: <a href="https://www.tugraz.at/fakultaeten/csbme/news/jobs-grants-calls/tenure-track-professor-in-security-and-privacy/">https://www.tugraz.at/fakultaeten/csbme/news/jobs-grants-calls/tenure-track-professor-in-security-and-privacy/</a><br/>
Email: Stefan.Mangard@iaik.tugraz.at</p></div>
    </content>
    <updated>2021-11-14T06:14:43Z</updated>
    <published>2021-11-14T06:14:43Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-11-17T18:20:45Z</updated>
    </source>
  </entry>
</feed>
