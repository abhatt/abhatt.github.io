<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2019-03-26T04:21:25Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=7484</id>
    <link href="https://windowsontheory.org/2019/03/26/news-addicts-sign-up-for-the-catcs-newsletter/" rel="alternate" type="text/html"/>
    <title>News addicts: Sign up for the CATCS newsletter</title>
    <summary>If, like others following the pace of modern life, you’re the kind of person that needs to get just on time updates on the state of theoretical computer science, consider signing up for the newsletter of CATCS. You can get information about funding opportunities, advocacy efforts, and more. Sure, at the hectic rate of two […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>If, like others following <a href="https://xkcd.com/1227/">the pace of modern life</a>, you’re the kind of person that needs to get just on time updates on the state of theoretical computer science, consider signing up for the newsletter of CATCS.  You can get information about funding opportunities, advocacy efforts, and more. Sure, at the hectic rate of two messages per year, it might flood your inbox, but it is worth it.</p>



<p/>



<p>Dear Theoretical Computer Scientist,</p>



<p><br/>The <a href="https://thmatters.wordpress.com/catcs/">Committee for the Advancement of Theoretical Computer Science </a>(CATCS) was established by SIGACT to deal with funding, outreach, and advocacy issues for our community. If you would like to receive our newsletter (no more than twice annually) we encourage you to sign up for the Google group below:<br/><a href="https://groups.google.com/forum/#!forum/catcs-news" rel="noreferrer noopener" target="_blank">https://groups.google.com/forum/#!forum/catcs-news</a><br/>(Navigate to the page above and click “Join group.” You can unsubscribe at any time from the same page.)<br/>Best wishes, CATCS </p></div>
    </content>
    <updated>2019-03-26T04:03:53Z</updated>
    <published>2019-03-26T04:03:53Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>windowsontheory</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2019-03-26T04:20:50Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/03/25/postdoc-at-bar-ilan-university-apply-by-may-1-2019/</id>
    <link href="https://cstheory-jobs.org/2019/03/25/postdoc-at-bar-ilan-university-apply-by-may-1-2019/" rel="alternate" type="text/html"/>
    <title>postdoc at Bar Ilan University (apply by May 1, 2019)</title>
    <summary>In the our big data lab, we have several postdoctoral positions in Algorithms, Data Structures, Distributed, and Compress Sensing. Website: http://www.cs.biu.ac.il/~porately/ Email: porately@cs.biu.ac.il</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>In the our big data lab, we have several postdoctoral positions in Algorithms, Data Structures, Distributed, and Compress Sensing.</p>
<p>Website: <a href="http://www.cs.biu.ac.il/~porately/">http://www.cs.biu.ac.il/~porately/</a><br/>
Email: porately@cs.biu.ac.il</p></div>
    </content>
    <updated>2019-03-25T08:20:15Z</updated>
    <published>2019-03-25T08:20:15Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-03-26T04:20:38Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1903.09416</id>
    <link href="http://arxiv.org/abs/1903.09416" rel="alternate" type="text/html"/>
    <title>Rods and Rings: Soft Subdivision Planner for R^3 x S^2</title>
    <feedworld_mtime>1553472000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hsu:Ching=Hsiang.html">Ching-Hsiang Hsu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chiang:Yi=Jen.html">Yi-Jen Chiang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yap:Chee.html">Chee Yap</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1903.09416">PDF</a><br/><b>Abstract: </b>We consider path planning for a rigid spatial robot moving amidst polyhedral
obstacles. Our robot is either a rod or a ring. Being axially-symmetric, their
configuration space is R^3 x S^2 with 5 degrees of freedom (DOF). Correct,
complete and practical path planning for such robots is a long standing
challenge in robotics. While the rod is one of the most widely studied spatial
robots in path planning, the ring seems to be new, and a rare example of a
non-simply-connected robot. This work provides rigorous and complete algorithms
for these robots with theoretical guarantees. We implemented the algorithms in
our open-source Core Library. Experiments show that they are practical,
achieving near real-time performance. We compared our planner to
state-of-the-art sampling planners in OMPL.
</p>
<p>Our subdivision path planner is based on the twin foundations of
\epsilon-exactness and soft predicates. Correct implementation is relatively
easy. The technical innovations include subdivision atlases for S^2,
introduction of \Sigma_2 representations for footprints, and extensions of our
feature-based technique for "opening up the blackbox of collision detection".
</p></div>
    </summary>
    <updated>2019-03-25T23:31:13Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-03-25T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1903.09358</id>
    <link href="http://arxiv.org/abs/1903.09358" rel="alternate" type="text/html"/>
    <title>Efficient Algorithms for Geometric Partial Matching</title>
    <feedworld_mtime>1553472000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Agarwal:Pankaj_K=.html">Pankaj K. Agarwal</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chang:Hsien=Chih.html">Hsien-Chih Chang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/x/Xiao:Allen.html">Allen Xiao</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1903.09358">PDF</a><br/><b>Abstract: </b>Let $A$ and $B$ be two point sets in the plane of sizes $r$ and $n$
respectively (assume $r \leq n$), and let $k$ be a parameter. A matching
between $A$ and $B$ is a family of pairs in $A \times B$ so that any point of
$A \cup B$ appears in at most one pair. Given two positive integers $p$ and
$q$, we define the cost of matching $M$ to be $c(M) = \sum_{(a, b) \in
M}\|{a-b}\|_p^q$ where $\|{\cdot}\|_p$ is the $L_p$-norm. The geometric partial
matching problem asks to find the minimum-cost size-$k$ matching between $A$
and $B$.
</p>
<p>We present efficient algorithms for geometric partial matching problem that
work for any powers of $L_p$-norm matching objective: An exact algorithm that
runs in $O((n + k^2) {\mathop{\mathrm{polylog}}} n)$ time, and a $(1 +
\varepsilon)$-approximation algorithm that runs in $O((n + k\sqrt{k})
{\mathop{\mathrm{polylog}}} n \cdot \log\varepsilon^{-1})$ time. Both
algorithms are based on the primal-dual flow augmentation scheme; the main
improvements involve using dynamic data structures to achieve efficient flow
augmentations. With similar techniques, we give an exact algorithm for the
planar transportation problem running in $O(\min\{n^2, rn^{3/2}\}
{\mathop{\mathrm{polylog}}} n)$ time.
</p></div>
    </summary>
    <updated>2019-03-25T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-03-25T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1903.09245</id>
    <link href="http://arxiv.org/abs/1903.09245" rel="alternate" type="text/html"/>
    <title>Trainable Time Warping: Aligning Time-Series in the Continuous-Time Domain</title>
    <feedworld_mtime>1553472000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Khorram:Soheil.html">Soheil Khorram</a>, Melvin G McInnis, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Provost:Emily_Mower.html">Emily Mower Provost</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1903.09245">PDF</a><br/><b>Abstract: </b>DTW calculates the similarity or alignment between two signals, subject to
temporal warping. However, its computational complexity grows exponentially
with the number of time-series. Although there have been algorithms developed
that are linear in the number of time-series, they are generally quadratic in
time-series length. The exception is generalized time warping (GTW), which has
linear computational cost. Yet, it can only identify simple time warping
functions. There is a need for a new fast, high-quality multisequence alignment
algorithm. We introduce trainable time warping (TTW), whose complexity is
linear in both the number and the length of time-series. TTW performs alignment
in the continuous-time domain using a sinc convolutional kernel and a
gradient-based optimization technique. We compare TTW and GTW on 85 UCR
datasets in time-series averaging and classification. TTW outperforms GTW on
67.1% of the datasets for the averaging tasks, and 61.2% of the datasets for
the classification tasks.
</p></div>
    </summary>
    <updated>2019-03-25T23:20:30Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-03-25T01:30:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-2572656159267507055</id>
    <link href="https://blog.computationalcomplexity.org/feeds/2572656159267507055/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/03/random-thoughts-on-admissions-scandal.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/2572656159267507055" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/2572656159267507055" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/03/random-thoughts-on-admissions-scandal.html" rel="alternate" type="text/html"/>
    <title>Random Thoughts on the admissions scandal</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">In light of the recent academic scandal I am going to list ways I've heard to help get your kid into college and thoughts on how ethical they are (hint: bribing a coach to claim your kid is on the rowing team is not ethical).<br/>
<br/>
1) Your kid likes (1) helping the homeless and (2)  Ramsey Theory and (3)  helping the homeless learn Ramsey Theory. Or perhaps they like  rowing or Latin or fencing or Pig Latin or....  Great! encourage them, get them books and tutors,  and whatever they need. You have an eye towards how this will look on for college admissions; however, it is your kids choice as to what they like. Also note that these activities are in addition to doing well in school, SATs, etc, not instead of it.  Perfectly ethical, though I note that this avenue is not open to poor families and in some cases even middle class families.<br/>
<br/>
2) Item 1 is the extreme on a spectrum in terms of how much are the extra things the kid does there idea OR planned by you to GET INTO A GOOD COLLEGE. This item will be the other extreme, but realize there is a continuum (actually I doubt there are a continuum number of options here, but there are many in between. Maybe its omega + omega*.) You have heard that being on the <a href="https://en.wikipedia.org/wiki/Chess_boxing">chess boxing</a> teams is good on a college application so you TELL YOUR KID that they  likes both Chess AND Boxing and should be on the team. You also hear this about being on the fencing team and knowing <a href="https://en.wikipedia.org/wiki/Pig_Latin">pig latin</a>, so your kid can taunt their opponents like this:<br/>
<br/>
youah, aint-kay ence-fay orth-way eans-bay<br/>
<br/>
This might not be as bad as it sounds if the kid learns to like Chess-Boxing.  But it may be worse than it sounds if the kid rebels against all of this and becomes a crack whore.<br/>
<br/>
Is this ethical? It may be bad for the kid, but it may push him into things he ends up liking. One drawback: you've HEARD that being on the chess boxing team is good for college admissions, but is it true?<br/>
<br/>
And again, not open to some families.<br/>
<br/>
3) Item 2 (or even 1) but with an addition: Hire a college adviser to help you. Someone who knows (or claims to know) what colleges look for- Trombone, Latin, Chess-boxing, whatever. Still ethical but I again worry about the kids future rehab bills.<br/>
<br/>
4) Here is where it gets murky. The college adviser helps:<br/>
<br/>
a) Polish the kids essay (my parents, who are both in English, helped polish my essay to get into graduate school (I don't recall if there was one for ugrad). They told me to use lots of `ing' words so it sounds like I am actively doing things. They also helped me figure out when recursion-theoretic is hyphenated. I got into Harvard but not MIT, so make of that what you will.) Polishing, proofreading, that could be okay. But it can slip into b or c below.<br/>
<br/>
b) The adviser (or the parents) talk to the kids to find out what to write, but then writes it. Maybe the kid proofreads and polishes. Maybe not even. The adviser is  a ghostwriter. Clearly unethical but the line between helping-to-polish and adviser-wrote-it is again a continuum.<br/>
<br/>
c) Adviser writes it and it is completely fictional. I once heard a rumor that a particular sample of an essay to get into med school was used  by several  med school applicant. Gee,they can't all have gotten inspired by watching their grandfather in his pajamas die of cancer. This is awful of course, but I wonder- what if the student writes a fictional essay all by themselves! Some combination of how much the essay is true and how much help you got on it is unethical. But some might be okay. Is it bad to polish stories that are basically true to make them flow more easily?  Prob not. But there is a 2-dim continuum based on both accuracy and how much help the student got.<br/>
<br/>
As a side note- how much does the personal statement matter for admissions? I suspect that if an elite school gets LOTS of REALLY QUALIFIED applicants, the essay may be all that distinguishes them.So it can be important. I also wonder if people on admissions can tell if an essay is not written by the applicant. Or maybe if there is an interview that can help detect it.<br/>
<br/>
5) Parents give X amount of money to the college and the kid gets in. This is talked about a lot though I don't know how common it is for someone NOT qualified to GET IN based on money. College admissions has many factors so its not quite so clear cut what NOT qualified means. Even so, if seems odd that this is not in any way shape or form illegal. It IS transparent, so I guess thats a plus. The argument I've heard is that the money is used for scholarships to fund students who get in but can't afford to go. I do not know if this is true. And this one  is only available to the top Z %, not sure what Z is, but there are people who can do 1,2,3,4 who can't do 5. I would call this unethical though colleges don't seem to think so. Or they do but they do it anyway.<br/>
<br/>
6) Before I list the current scandal I want to list another issue: having a psychologist (or whoever it is who judges these things) say your kid is Learning Disabled so they get more time on the SATs. Perhaps bribing them, or perhaps its understood what you want.  Again, I do not know how common this is.  An alternative if you can't afford some of the above options, or done in conjunction with a lot of the above options.<br/>
<br/>
7) The current scandal. Obviously unethical. A few things I wonder about:<br/>
<br/>
a) One story was that they bribed someone to say their daughter was Learning Disabled and had to take the SAT (or whatever it was) in a separate room, making it easier to change the answers to the correct ones.  So twice unethical.<br/>
<br/>
b) Some of the students  were clearly NOT qualified.<br/>
<br/>
c) A parent does unethical things to get the kid into college.<br/>
<br/>
The kid later lies to the parents about their grades or their plans<br/>
<br/>
The parents are SHOCKED that their kids lie and wonder where the learned such behaviour!<br/>
<br/>
8) Actually Item 2 --Parent has kid do things to plan to get into college-- is interesting for another reason. Are you your resume?<br/>
<br/>
Imagine that Alice helps the homeless her Sophmore year in High School NOT because she cares about the homeless but because its good for college admissions.<br/>
<br/>
Alice goes on to do other things that look good for college, NOT because she likes them or cares, but just to get into a good college.<br/>
<br/>
She gets into an elite college<br/>
<br/>
Did they take her in the hope she would KEEP doing these things or because she is the KIND OF PERSON who does these things?<br/>
<br/>
And it gets weirder- she DOES keep doing these things since she's heard its good for Business School (disclaimer- I do not know if its good for B-school)<br/>
<br/>
More generally, she keeps doing things she doesn't care about to advance. So her outward self really is doing good deeds and such, but her heart is not in it. So if her college or B-school or Job hired her because she DOES these things, that is NOT a lie. If they hired her because they want this KIND OF PERSON then... its a lie but I'm not sure what to make of that.<br/>
<br/>
9) Is there ANY reason to have legacy matter for admissions? This seems like the dumbest and most easily fixed aspect of the whole process.  I have never heard a good argument for it. Ever.<br/>
<br/>
10) College Sports--- that's an entire blog post or book all by itself, so I won't go there.<br/>
<br/>
11) One can argue whether helping the homeless, or being on the rowing team, or teaching the homeless how to row, should matter for college anyway. But lets assume that its legit to want people at your college who have lead interesting lives. So charity work or sports might be a MEASURE of that. But beware Goodhart's law:<br/>
<br/>
                         <i> When a measure becomes a target is ceases to be a measure.</i><br/>
<i><br/></i>
The recent scandal is Goodhart's law on steroids.<br/>
(NOTE- I had in earlier version `Goodwin's law' but a commenter corrected me and reminded me that Goodwin's law is that if an internet discussion goes on long enough someone will be compared to Hitler. I wonder if that also applies in discussions by Nazi's.)<br/>
<br/>
12) Does getting into an Elite College really increase your income or happiness (these are two very different questions) over the course of your life? I do not know-- if you do, please comment.<br/>
<br/>
13) (ADDED LATER) A commenter pointed out that one could also go to a school outside of  the USA that values proficiency in the chosen discipline over the items above. Excellent question that raises a few more:<br/>
<br/>
Do schools outside of the USA hold Americans (or for that matter any non-citizen of their country) to a higher standard for admissions? I ask non-rhetorically.<br/>
<br/>
If you get a degree from outside of the USA will that help or hurt your job prospects in the USA? Of course this depends on the school you goto, but even with that I do not know the answer.<br/>
<br/>
<br/>
<br/></div>
    </content>
    <updated>2019-03-24T21:13:00Z</updated>
    <published>2019-03-24T21:13:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>https://plus.google.com/101693130490639305932</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-03-25T08:11:59Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/043</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/043" rel="alternate" type="text/html"/>
    <title>TR19-043 |  Nondeterministic and Randomized Boolean Hierarchies in Communication Complexity | 

	Toniann Pitassi, 

	Morgan Shirley, 

	Thomas Watson</title>
    <summary>We study the Boolean Hierarchy in the context of two-party communication complexity, as well as the analogous hierarchy defined with one-sided error randomness instead of nondeterminism. Our results provide a complete picture of the relationships among complexity classes within and across these two hierarchies. In particular, we prove a query-to-communication lifting theorem for all levels of the Boolean Hierarchy and use it to resolve an open problem stated in the paper by Halstenberg and Reischuk (CCC 1988) which initiated this topic.</summary>
    <updated>2019-03-24T07:12:18Z</updated>
    <published>2019-03-24T07:12:18Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-03-26T04:20:29Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=17209</id>
    <link href="https://gilkalai.wordpress.com/2019/03/22/danny-nguyen-and-igor-pak-presburger-arithmetic-problem-solved/" rel="alternate" type="text/html"/>
    <title>Danny Nguyen and Igor Pak: Presburger Arithmetic Problem Solved!</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Short Presburger arithmetic is hard! This is a belated report on a remarkable breakthrough from 2017. The paper is Short Presburger arithmetic is hard, by Nguyen and Pak. Danny Nguyen Integer programming in bounded dimension: Lenstra’s Theorem Algorithmic tasks are … <a href="https://gilkalai.wordpress.com/2019/03/22/danny-nguyen-and-igor-pak-presburger-arithmetic-problem-solved/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><h2>Short Presburger arithmetic is hard!</h2>
<p>This is a belated report on a remarkable breakthrough from 2017. The paper is <a href="http://www.math.ucla.edu/~pak/papers/hard_presburger3.pdf">Short Presburger arithmetic is hard</a>, by Nguyen and Pak.</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/03/ngoyen.jpg"><img alt="" class="alignnone size-full wp-image-17213" src="https://gilkalai.files.wordpress.com/2019/03/ngoyen.jpg?w=640"/></a></p>
<p><strong><span style="color: #ff0000;">Danny Nguyen</span></strong></p>
<h3>Integer programming in bounded dimension: Lenstra’s Theorem</h3>
<p>Algorithmic tasks are often intractable. But there are a few miracles where efficient algorithms exist: Solving systems of linear equations, linear programming, testing primality,  and solving integer programming problems when the number of variables is bounded. The last miracle is a historic 1983 theorem of Hendrik Lenstra (Here <a href="https://people.csail.mit.edu/rrw/presentations/Lenstra81.pdf">is the paper</a>) and it is the starting point of this post.</p>
<p><strong>Lensra’s theorem:</strong> Consider a system of linear inequalities</p>
<h3 style="text-align: center;"><em>Ax ≤ b</em></h3>
<p>where <img alt="x=(x_1,x_2,\dots x_k)" class="latex" src="https://s0.wp.com/latex.php?latex=x%3D%28x_1%2Cx_2%2C%5Cdots+x_k%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x=(x_1,x_2,\dots x_k)"/> is a vector of <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/> variables, <em>A</em> is an integral <em>k</em> by <em>n</em> matrix and <em>b</em> is an integral vector of length <em>n</em>.</p>
<p>Let <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/> be a fixed integer. There is a polynomial time algorithm to determine if the system has an integral solution.</p>
<p>Of course, the full Integer Programming problem when <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/> is part of the input, is <strong>NP-complete</strong>. This problem came already (second in Karp’s list!) in<a href="https://people.eecs.berkeley.edu/~luca/cs172/karp.pdf"> the Mayflower of NP-complete problems –  Karp’s paper</a>.</p>
<p>Sasha Barvinok famously showed in 1993 that even counting the number of solutions is in <strong>P</strong>. (Barvinok utilized the short generating function approach pioneered by Brion, Vergne and others.)</p>
<h3>Kannan’s theorem</h3>
<p>Next,  I want to describe an amazing 1990 theorem of Ravi Kannan,</p>
<p>Kannan’s theorem considers formulas with one quantifier alternation in the Presburger arithmetic and it asserts that when the number of variables is fixed,  there is a polynomial time algorithm to decide if the formula is satisfiable.</p>
<p>(Here is a free version of <a href="http://www.cs.yale.edu/homes/kannan/Papers/forall.pdf">Kannan’s paper</a>.) Also here the counting problems were tackled with great success. Barvinok and Kevin Woods remarkably showed <a href="http://www.ams.org/journals/jams/2003-16-04/S0894-0347-03-00428-4/S0894-0347-03-00428-4.pdf">how to count projections of integer points in a (single) polytope in polynomial time</a>, and subsequently Woods <a href="http://www2.oberlin.edu/faculty/kwoods/research/Presburger_full.pdf">extended this approach</a> to general Presburger expressions Φ with a fixed number of inequalities!</p>
<p>An important strengthening was achieved by Friedrich Eisenbrand and  Gennady Shmonin in the 2008 paper <a href="https://arxiv.org/abs/0801.4336">Parametric integer programming in fixed dimension</a>. See also the survey chapter by Barvinok <a href="https://www.csun.edu/~ctoth/Handbook/chap7.pdf">Lattice points and lattice polytopes</a>.</p>
<p>You can find the formulation of Kannan’s theorem in full generality a little further but let me present now a special case related to the famous Frobenius coin problem. (See <a href="https://rjlipton.wordpress.com/2009/03/07/finite-state-automata-binary-decision-diagrams-and-presburger-arithmetic/">this post on GLL</a> for more on Presburger arithmetic)</p>
<h3>Frobenius coin problem</h3>
<p>Given <em>k</em> coins with integral values, the <a href="https://en.wikipedia.org/wiki/Coin_problem">Frobinius coin problem</a> is to determine the largest integer that cannot be described as positive integer combinations of the values of the coins. (See also <a href="https://rjlipton.wordpress.com/2011/04/30/congrats-ravi-kannan/">this post</a> on GLL.)</p>
<p><strong>Theorem (Kannan):</strong> There is a polynomial time algorithm to solve the Frobenius coin problem for every fixed number of coins.</p>
<p>The issue of the way theory meets practice for the problems discussed in this post is very interesting but we will not discuss it. Let me remark that Herb Scarf (who along with Kannan played a role in B-L (Before Lenstra) developments) offered another approach for the solution of the Frobenius coin problem and related IP (Integer Programming)  problems based on his theory of maximal lattice-free convex bodies. See <a href="https://gilkalai.wordpress.com/2013/02/22/ann-lehmans-sculpture-based-on-herb-scarfs-maximal-lattice-free-convex-bodies/">this related post</a>.</p>
<h3>More than one quantifier</h3>
<p>Given the result of Kannan and later that of Barvinok and Woods, many people expected that also for two alternations, or even for any other fixed number of alternations, Presburger arithmetic would be in polynomial time. Nguyen and Pak proved that the problem is <strong>NP-complete</strong> already for two quantifier alternations! Here is the link to the paper <a href="http://www.math.ucla.edu/~pak/papers/hard_presburger3.pdf">Short Presburger arithmetic is hard</a>. Igor Pak’s homepage has a few other <a href="http://www.math.ucla.edu/~pak/papers/research.htm#ip">related papers</a>.</p>
<p>Let me bring here Sasha Barvinok’s <a href="http://www.math.ucla.edu/~pak/papers/PA-Barv-rev.pdf">MathSciNet featured review</a> of Nguyen and Pak’s paper which tells the story better than I could.</p>
<h2>Barvinok’s featured review to Nguyen and Pak’s paper</h2>
<p>Presburger arithmetic allows integer variables, integer constants, Boolean operations (&amp;, ∧, ¬), quantifiers (∃, ∀), equations and inequalities (=, &lt;, &gt;, ≤, ≥), addition and subtraction (+, −) and multiplication by integer constants. It does not allow multiplication of variables (if we allow multiplication of variables, we get Peano arithmetic).</p>
<p>Geometrically, a quantifier-free formula of Presburger arithmetic describes the set of integer points in a Boolean combination of rational polyhedra (that is, in the set obtained from finitely many rational polyhedra by taking unions, intersections and complements). Similarly, a formula of Presburger arithmetic with existential quantifiers only describes the set of integer points obtained from the set of integer points in a Boolean combination of polyhedra by a projection along some coordinates.</p>
<p>Unlike Peano arithmetic, Presburger arithmetic is decidable. Here the authors zoom in on the computational complexity of Presburger arithmetic, once the combinatorial complexity of the formula is bounded in advance. If we fix the number of variables, the validity of a formula with no quantifier alternations (that is, of the type ∃<img alt="x_1" class="latex" src="https://s0.wp.com/latex.php?latex=x_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_1"/> . . . ∃<img alt="x_k" class="latex" src="https://s0.wp.com/latex.php?latex=x_k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_k"/>Φ(<img alt="x_1, \dots , latex x_k" class="latex" src="https://s0.wp.com/latex.php?latex=x_1%2C+%5Cdots+%2C+latex+x_k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_1, \dots , latex x_k"/>) or of the type ∀<img alt="x_1" class="latex" src="https://s0.wp.com/latex.php?latex=x_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_1"/> . . . ∀<img alt="x_k" class="latex" src="https://s0.wp.com/latex.php?latex=x_k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_k"/>Φ(<img alt="x_1, \dots , x_k" class="latex" src="https://s0.wp.com/latex.php?latex=x_1%2C+%5Cdots+%2C+x_k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_1, \dots , x_k"/>)) can be established in polynomial time by Lenstra’s integer programming algorithm [see H. W. Lenstra Jr., Math. Oper. Res. 8 (1983), no. 4, 538–548; MR0727410].</p>
<p>For a fixed number of variables, formulas with one quantifier alternation (∃<img alt="x_1" class="latex" src="https://s0.wp.com/latex.php?latex=x_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_1"/> . . . ∃<img alt="x_k" class="latex" src="https://s0.wp.com/latex.php?latex=x_k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_k"/>∀<img alt="y_1" class="latex" src="https://s0.wp.com/latex.php?latex=y_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y_1"/> . . . ∀<img alt="y_m" class="latex" src="https://s0.wp.com/latex.php?latex=y_m&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y_m"/>Φ(<img alt="x_1, \dots , x_k, y_1, \dots , y_m" class="latex" src="https://s0.wp.com/latex.php?latex=x_1%2C+%5Cdots+%2C+x_k%2C+y_1%2C+%5Cdots+%2C+y_m&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_1, \dots , x_k, y_1, \dots , y_m"/>)) can also be solved in polynomial time, as shown by R. Kannan [in Polyhedral combinatorics (Morristown, NJ, 1989), 39–47, DIMACS Ser. Discrete Math. Theoret. Comput. Sci., 1, Amer. Math. Soc., Providence, RI, 1990; MR1105115]. The decision procedure can be characterized as a polynomial time algorithm for parametric integer programming.</p>
<p>Suppose now that we fix the number of variables and the number of Boolean operations in advance (and hence get what is called a short formula of Presburger arithmetic). Thus the only parameters of the formula are the numerical values of the constants in the formula. The authors show that deciding validity becomes <strong>NP-complete</strong> if one allows<br/>
two quantifier alternations. Remarkably, they present an example of a formula</p>
<p>∃z ∈ <img alt="\mathbb Z" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+Z&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb Z"/> ∀y ∈ <img alt="\mathbb Z^2" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+Z%5E2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb Z^2"/> ∃x ∈ <img alt="\mathbb Z^2" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+Z%5E2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb Z^2"/> Φ(x, y, z)</p>
<p>with an <strong>NP-complete</strong> decision problem, even though Φ contains at most 10 inequalities.<br/>
Another remarkable example is an <strong>NP-complete</strong> decision problem for a formula of the<br/>
type</p>
<p>∃z ∈ <img alt="\mathbb Z" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+Z&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb Z"/> ∀y ∈ <img alt="\mathbb Z^2" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+Z%5E2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb Z^2"/> ∃x ∈ <img alt="\mathbb Z^6" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+Z%5E6&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb Z^6"/>: <em>Ax + By + Cz ≤ b,  </em></p>
<p>with at most 24 inequalities.</p>
<p>As the number of quantifier alternations is allowed to increase, the computational complexity in the polynomial hierarchy also moves up. The authors also describe the computational complexity of corresponding counting problems.</p>
<p>The proof is very clever; it uses the continued fraction expansion of a rational number to encode a growing family of intervals, with the help of which the authors build an <strong>NP-complete</strong> problem.</p>
<p> </p></div>
    </content>
    <updated>2019-03-22T09:47:48Z</updated>
    <published>2019-03-22T09:47:48Z</published>
    <category term="Combinatorics"/>
    <category term="Computer Science and Optimization"/>
    <category term="Convex polytopes"/>
    <category term="Danny Nguyen"/>
    <category term="Frobenius coin problem"/>
    <category term="Hendrik Lenstra"/>
    <category term="Herb Scarf"/>
    <category term="Igor Pak"/>
    <category term="Kevin Woods"/>
    <category term="Persburger Arithmetic"/>
    <category term="Ravi Kannan"/>
    <category term="Sasha Barvinok"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-03-26T04:20:33Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2019/03/22/workshop-on-algebraic-complexity-theory/</id>
    <link href="https://cstheory-events.org/2019/03/22/workshop-on-algebraic-complexity-theory/" rel="alternate" type="text/html"/>
    <title>Workshop on Algebraic Complexity Theory</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">March 25-29, 2019 The International Centre for Theoretical Sciences (ICTS), Bengaluru (India) https://www.icts.res.in/discussion-meeting/wact2019 The primary objective of this workshop is to bring together experts in the field of algebraic complexity and related areas to present their research, initiate collaborations etc. The idea is to continue the tradition of having a Workshop on Algebraic Complexity Theory … <a class="more-link" href="https://cstheory-events.org/2019/03/22/workshop-on-algebraic-complexity-theory/">Continue reading <span class="screen-reader-text">Workshop on Algebraic Complexity Theory</span></a></div>
    </summary>
    <updated>2019-03-22T09:16:07Z</updated>
    <published>2019-03-22T09:16:07Z</published>
    <category term="workshop"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2019-03-26T04:21:10Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>http://corner.mimuw.edu.pl/?p=1076</id>
    <link href="http://corner.mimuw.edu.pl/?p=1076" rel="alternate" type="text/html"/>
    <title>The Curse of Euclidean Metric: Square Roots</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">The deadline was approaching without mercy and there was, of course, still some polishing to be done for our SODA paper. But then we run into an issue. To make things worse, this issue turned out to be a hard … <a href="http://corner.mimuw.edu.pl/?p=1076">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p style="text-align: justify;"><a href="https://duch.mimuw.edu.pl/~tugboat/wp-content/uploads/2019/03/curseOfMetricIsland.png"><img align="right" alt="The Curse of Metric Island" class="wp-image-587 alignright" src="https://duch.mimuw.edu.pl/~tugboat/wp-content/uploads/2019/03/curseOfMetricIsland_small.png"/></a></p>
<p>The deadline was approaching without mercy and there was, of course, still some polishing to be done for <a href="https://doi.org/10.1137/1.9781611975482.67">our SODA paper</a>. But then we run into an issue. To make things worse, this issue turned out to be a hard one, a fundamental known open problem in computational geometry. The good thing is, I liked the problem so much that I decided to dedicate it this post. This is the story about the Sum of Square Roots problem and how we bypassed (ignored) it without solving it.</p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:paragraph {"align":"justify"} --></p>
<p style="text-align: justify;">Everything began in the haze of the 70's of the last millennium. It is nebulous who stumbled first upon this enigma. <a href="https://www.ics.uci.edu/~eppstein/junkyard/small-dist.html">Some say</a> that Ron Graham has discussed the problem in public lectures, <a href="https://www.jstor.org/stable/2321488">some others</a> say that Joseph O'Rourke has posed it as an open question in the American Mathematical Monthly, while <a href="http://cs.smith.edu/~jorourke/TOPP/P33.html">some others</a> suspect that the problem had been already hiding in older different formulations. However, it is a historical fact that one shinny/cloudy day, three computer scientists finished polishing a manuscript that became a classical paper known as "<a href="https://doi.org/10.1145/800113.803626">Some NP-complete geometric problems</a>". In this paper, Michael Garey, Ron Graham and David Johnson showed the NP-hardness of two important problems in geometric metrics: Steiner Tree and Traveling Salesman. For the Euclidean plane, they showed only NP-hardness as they did not manage to show that these problems are contained in NP. Moreover, they accentuated that we cannot even rule out that the decision version of Euclidean Minimum Spanning Tree is outside of NP. What a seeming paradox given that we can compute such a minimum tree in polynomial time! So, whom did they blame? The short answer: The Euclidean metric. Garey and his coauthors explain that all these problems have a common hidden issue: They rely on comparing Euclidean lengths, that is, they rely on comparing irrational numbers based on square roots. Whereas this task is trivial if we just want to compare two line segments (e.g. by comparing the radicands), the problem starts when we want to compare two polygonal paths. Even assuming rational (or, after scaling, integer) coordinates, this problem translates into a question that is fundamental in computational geometry: Given two lists of integers, <em>a<sub>1</sub></em> ... and <em>b<sub>1</sub></em> ..., can we decide whether "<em>∑ √a<sub>i</sub> ≥ ∑ √b<sub>i</sub></em>" in P? Put into words: <strong>Can we efficiently compare two sums of square roots over integers?</strong></p>
<p><span id="more-1076"/></p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:paragraph {"align":"justify"} --></p>
<p style="text-align: justify;">To emphasize the significance of this question, let me cite <a href="http://cs.smith.edu/~jorourke/TOPP/P33.html">David Eppstein</a>: "A major bottleneck in proving NP-completeness for geometric problems is a mismatch between the real-number and Turing machine models of computation: one is good for geometric algorithms but bad for reductions, and the other vice versa. Specifically, it is not known on Turing machines how to quickly compare a sum of distances (square roots of integers) with an integer or other similar sums, so even (decision versions of) easy problems such as the minimum spanning tree are not known to be in NP."</p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:paragraph {"align":"justify"} --></p>
<p style="text-align: justify;">"Is this problem computable at all?" - might the curious reader ask after realizing that the approach of iteratively increasing the precision until the first difference in digits will never terminate if both numbers happen to be equal. Luckily, <a href="https://doi.org/10.1016/S0747-7171(85)80013-4">Allan Borodin et al.</a> and <a href="https://refubium.fu-berlin.de/handle/fub188/18449">Johannes Blömer</a> showed that polynomial time is enough to decide whether two such sums have the same value. Therefore, it is astonishing that the problem of deciding the sign of their difference, a question that seems only slightly harder, has been only recently spotted by <a href="https://doi.org/10.1137/070697926">Eric Allender et al</a> on an island of the counting hierarchy CH (3rd level) located in the wide ocean of PSPACE. Thus, it is still far far away from the needle head of P, where <a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.44.5325">Gregorio Malajovich</a> conjectured it to live. Until this will be shown, <a href="https://cstheory.stackexchange.com/questions/4053/sum-of-square-roots-hard-problems">Jeff Erickson</a> proposes to study which problems are (<a href="https://cstheory.stackexchange.com/questions/4053/sum-of-square-roots-hard-problems">non-boringly</a>) Σ√-hard.</p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:paragraph {"align":"justify"} --></p>
<p style="text-align: justify;">Oh, if we could only sufficiently bound the difference of the sums from below! Then we could bound from above the precision required to determine the correct sign of the difference: Just image that <em>B</em> is such a lower bound on the difference. Now, take a precision that allows us to compute an approximate difference being only <em>B/2</em> away from the real one. Then it is easy to verify that the following procedure determines the correct sign: Output the sign of the approximate difference if it is outside of <em>[-B/2,B/2]</em>, otherwise output <em>0</em>. What is the run time of this procedure? It is proportional to the precision, which corresponds to the length of <em>B</em>, that is, to <em>-log B</em>. Hence, if <em>-log B</em> is bounded from above by a polynomial in the length of the input, then we are in P! So, is there any reasonable lower bound for the worst case? That is, <strong>what is the smallest positive difference between any two sums of <em>k</em> square roots of integers of size at most <em>n</em>?</strong> Welcome to <a href="http://cs.smith.edu/~jorourke/TOPP/P33.html">Problem 33</a> of <a href="http://cs.smith.edu/~jorourke/TOPP/Welcome.html">The Open Problems Project</a>! Let <em>r(n,k)</em> denote such a minimum difference as a function of <em>n</em> and <em>k</em>. For instance, consider <em>n=20</em> and <em>k=2</em>. Then <em>r(n,k)</em> is roughly <em>0.0002</em> and it is attained by <em>√{10} + √{11} - √{5} - √{18}</em>. As being an open problem, there is no tight bound known for <em>r(n,k)</em>. <a href="https://doi.org/10.1016/j.ipl.2006.05.002">Jianbo Qian and Cao An Wang</a> as well as <a href="https://doi.org/10.1016/j.tcs.2011.06.014">Qi Cheng and Yu-Hsin Li</a> proved(*) that there are sums where <em>-log r(n,k)</em> is at least in the order of magnitude of <em>k log n</em>. However, these lower bounds constitute an exponentially gap to the best known upper bounds which are <em>O(2<sup>2k</sup> log n)</em> [<a href="https://doi.org/10.1007/s004530010005">Christoph Burnikel et al.</a>(**)] and <em>2<sup>O(n/log n)</sup></em> [<a href="https://doi.org/10.1016/j.tcs.2011.06.014">Qi Cheng et al.</a>]. So, maybe you, dear reader, will be the one to close the gap?</p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:paragraph {"align":"justify"} --></p>
<p style="text-align: justify;">In the dramatic opening of this post, I mentioned <a href="https://doi.org/10.1137/1.9781611975482.67">our paper</a>, where the problem of Sum of Square Roots appeared. There, we design a PTAS for the Traveling Salesman problem (TSP) with hyperplane neighborhoods, that is, we look for a <em>(1+ε)</em>-approximation of a minimum-length tour that, instead of points, visits a given set of hyperplanes in ℝ<sup><em>d</em></sup> with <em>d</em> being fixed. The basis of our algorithm is an integer grid of constant size (depending on <em>ε</em> and <em>d</em>). Our key observation is that there is a translation and scaling of the grid such that snapping an (adequately sparsified) optimum solution to the grid results in a <em>(1+ε</em>)-approximation. Using this insight, we let our algorithm enumerate all (reasonable) TSP tours lying in our integer grid. With a simple LP, we translate and scale each tour such that it visits all the hyperplanes of the input whilst minimizing its tour length (i.e., the scaling factor). At the end, we obtain a set of feasible TSP tours and output the shortest one. And here we were confronted with the Sum of Square Roots problem. Which of the tours is the shortest one? Was all our work devastated, all our blood, sweat and tears in vain? Just because the very last line of our algorithm had unknown complexity? Our solution was simple: We just skipped the issue and our paper got accepted. Why? Well, the issue wasn't one for the following three reasons:</p>
<ul>
<li>We could be lazy and assume the real RAM computational model with constant time for square root operations (as often done in computational geometry).</li>
<li>We could be industrious and approximate the real tour lengths with a sufficiently small error since we look anyway for an approximation in overall.</li>
<li>We could think and then realize that our candidate tours consist of only constant many vertices as our integer grid has constant size. Indeed, the best known lower bound on the difference <em>r(n,k)</em> implies the following nice take-away which shall conclude this epilogue:</li>
</ul>
<p><strong>We can compare two sums of square roots in polynomial time if the number of square roots is constant!</strong></p>
<p><!-- /wp:paragraph --></p>
<p><em><a href="https://duch.mimuw.edu.pl/~tugboat/about-us/krzysztof-fleszar/">Krzysztof Fleszar</a></em></p>
<p><!-- wp:paragraph {"align":"justify"} --></p>
<p style="text-align: justify;">-------------------------</p>
<p>Proof sketches for the interested reader of the lower and upper bounds on <em>r(n,k)</em>:</p>
<p>(*) <em>Ω(k log n)</em> [<a href="https://doi.org/10.1016/j.tcs.2011.06.014">Cheng et al.</a>]: The interval <em>[k, k √{n}]</em> contains so many distinct sums of square roots (over square-free integers) that, by a pigeonhole argument, there are two sums with very small distance.</p>
<p>(**) <em>O(2<sup>2k</sup> log n)</em> [<a href="https://doi.org/10.1007/s004530010005">Burnikel et al.</a>]: The difference is an algebraic integer and, consequently, the root of a polynomial with integer coefficients and degree at most <em>2<sup>2k</sup></em>. A simple inequality yields the bound.</p>
<p><!-- /wp:paragraph --></p></div>
    </content>
    <updated>2019-03-22T08:54:27Z</updated>
    <published>2019-03-22T08:54:27Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Renata Czarniecka</name>
    </author>
    <source>
      <id>http://corner.mimuw.edu.pl</id>
      <link href="http://corner.mimuw.edu.pl/?feed=rss2" rel="self" type="application/atom+xml"/>
      <link href="http://corner.mimuw.edu.pl" rel="alternate" type="text/html"/>
      <subtitle>University of Warsaw</subtitle>
      <title>Banach's Algorithmic Corner</title>
      <updated>2019-03-25T23:33:47Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=15698</id>
    <link href="https://rjlipton.wordpress.com/2019/03/21/the-shortest-path-to-the-abel-prize/" rel="alternate" type="text/html"/>
    <title>The Shortest Path To The Abel Prize</title>
    <summary>While melding topology, geometry, and analysis IAS page Karen Uhlenbeck is a mathematician who has won a number of awards in the past and has just now been announced as winner of the 2019 Abel Prize. Today Ken and I want to explain a tiny bit about what Uhlenbeck did. The Abel Prize citation says […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><font color="#0044cc"><br/>
<em>While melding topology, geometry, and analysis</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2019/03/uhlenbeckias.jpg"><img alt="" class="alignright wp-image-15699" height="180" src="https://rjlipton.files.wordpress.com/2019/03/uhlenbeckias.jpg?w=150&amp;h=180" width="150"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">IAS <a href="https://www.ias.edu/scholars/karen-uhlenbeck">page</a></font></td>
</tr>
</tbody>
</table>
<p>
Karen Uhlenbeck is a mathematician who has won a number of awards in the past and has just now been announced as winner of the 2019 Abel Prize. </p>
<p>
Today Ken and I want to explain a tiny bit about what Uhlenbeck did.</p>
<p>
The Abel Prize <a href="http://www.abelprize.no/c73996/seksjon/vis.html?tid=74013">citation</a> says that Uhlenbeck won for</p>
<blockquote><p><b> </b> <em> “pioneering achievements in geometric partial differential equations, gauge theory, and integrable systems, and for the fundamental impact on analysis, geometry and mathematical physics.” </em>
</p></blockquote>
<p/><p>
A <a href="https://www.quantamagazine.org/karen-uhlenbeck-uniter-of-geometry-and-analysis-wins-abel-prize-20190319/">story</a> in <em>Quanta</em> and <a href="https://www.scientificamerican.com/article/soap-bubble-pioneer-is-first-woman-to-win-prestigious-math-prize/">another</a> in <em>Scientific American</em> are among those with readable summaries of the general nature of this work. The latter describes Uhlenbeck’s discovery with the mathematician Jonathan Sacks of a phenomenon called <em>bubbling</em> as follows: </p>
<blockquote><p><b> </b> <em> Sacks and Uhlenbeck were studying ‘minimal surfaces,’ the mathematical theory of how soap films arrange themselves into shapes that minimize their energy. But the theory had been marred by the appearance of points at which energy appeared to become infinitely concentrated. Uhlenbeck’s insight was to “zoom in” on those points to that this were caused by a new bubble splitting off the surface. </em>
</p></blockquote>
<p/><p>
Some of the coolest comments are by Uhlenbeck’s doctoral graduate Mark Haskins in the <a href="https://www.nature.com/articles/d41586-019-00932-1">story</a> in the current issue of <em>Nature</em>. </p>
<blockquote><p><b> </b> <em> Haskins says Uhlenbeck is one of those mathematicians who have ‘an innate sense of what should be true,’ even if they cannot always explain why. </em>
</p></blockquote>
<p/><p>
The story recounts his often being baffled by answers to his questions, thinking Uhlenbeck had misheard them. But</p>
<blockquote><p><b> </b> <em> “maybe weeks later, you would realize that you had not asked the correct question.” </em>
</p></blockquote>
<p>
</p><p/><h2> Calculus Of Variations </h2><p/>
<p/><p>
Simon Donaldson wrote a <a href="https://www.ams.org/journals/notices/201903/rnoti-p303.pdf">piece</a> in the current issue of <i>AMS Notices</i> that explains Uhlenbeck’s research in the Calculus of Variations. The article starts with 	</p>
<p align="center"><img alt="\displaystyle  F(u) = \int \Phi(u,u') dx. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++F%28u%29+%3D+%5Cint+%5CPhi%28u%2Cu%27%29+dx.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  F(u) = \int \Phi(u,u') dx. "/></p>
<p>You can think of <img alt="{F(u)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%28u%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F(u)}"/> as assigning a cost to a function <img alt="{u=u(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu%3Du%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u=u(x)}"/>. The goal of the calculus of variations is to find the best <img alt="{u}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u}"/> that minimizes <img alt="{F(u)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%28u%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F(u)}"/> subject to some conditions on <img alt="{u}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u}"/>. This is a huge generalization of simple minimization problems that arise in basic calculus. He then goes on to explain that in order to study the minimum solutions of such a function one quickly needs to examine partial differential equations. The math gets complex and beautiful very quickly. </p>
<p>
As computer scientists who like discrete structures this is not our sweet spot. We rarely use partial derivatives in our work. Well not very often. See <a href="https://rjlipton.wordpress.com/2010/03/27/fast-matrix-products-and-other-amazing-results/">these</a> two <a href="https://rjlipton.wordpress.com/2010/08/19/projections-can-be-tricky/">posts</a> for an example. </p>
<p>
To get a taste of this area, we will consider a classic variation problem coming out of these helpful online <a href="http://farside.ph.utexas.edu/teaching/336k/Newtonhtml/node86.html">notes</a>. It leads to integrals such as 	 </p>
<p align="center"><img alt="\displaystyle  \int_{0}^{a} (1+u'(x)^{2})^{1/2} dx. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cint_%7B0%7D%5E%7Ba%7D+%281%2Bu%27%28x%29%5E%7B2%7D%29%5E%7B1%2F2%7D+dx.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \int_{0}^{a} (1+u'(x)^{2})^{1/2} dx. "/></p>
<p>Well, we take to integrals even less than partial derivatives. </p>
<p>
</p><p/><h2> Straight-line Shortest Path </h2><p/>
<p/><p>
We will change things up by starting with a discrete approach—as is our wont. Our given task is to prove in general that a straight line is the shortest path from the origin to a given point <img alt="{p = (a,b)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp+%3D+%28a%2Cb%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p = (a,b)}"/>. We first consider polygonal paths with <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> line segments. </p>
<p>
First, if <img alt="{n = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n = 1}"/> then the only option allowed is to go from <img alt="{(0,0)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%280%2C0%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(0,0)}"/> to <img alt="{(a,b)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28a%2Cb%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(a,b)}"/> in one line segment. Thus the conclusion holds trivially: the Euclidean distance <img alt="{d(0,p)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%280%2Cp%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d(0,p)}"/> is the minimum length of a <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>-segment path.</p>
<p>
Now let <img alt="{n \geq 2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn+%5Cgeq+2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n \geq 2}"/>. Let </p>
<p align="center"><img alt="\displaystyle  P = (0,0) \rightarrow x_1 \rightarrow x_2 \rightarrow \cdots \rightarrow x_n = (a,b) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++P+%3D+%280%2C0%29+%5Crightarrow+x_1+%5Crightarrow+x_2+%5Crightarrow+%5Ccdots+%5Crightarrow+x_n+%3D+%28a%2Cb%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  P = (0,0) \rightarrow x_1 \rightarrow x_2 \rightarrow \cdots \rightarrow x_n = (a,b) "/></p>
<p>be a series of line segments that form the shortest path from <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/> to <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/>. Now by induction, the minimum length of a path of up to <img alt="{n-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n-1}"/> segments from <img alt="{x_1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x_1}"/> to <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> is <img alt="{d(x_1,p)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%28x_1%2Cp%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d(x_1,p)}"/> via a straight line from <img alt="{x_1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x_1}"/> to <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/>. And the length of the segment from the origin <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/> to <img alt="{x_1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x_1}"/> of course is <img alt="{d(0,x_1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%280%2Cx_1%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d(0,x_1)}"/>. Now the Euclidean triangle inequality says that the length <img alt="{d(0,x_1) + d(x_1,p)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%280%2Cx_1%29+%2B+d%28x_1%2Cp%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d(0,x_1) + d(x_1,p)}"/> which bounds the length of this path from below is not less than <img alt="{d(0,p)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%280%2Cp%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d(0,p)}"/>. Thus we have proved it for <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> and the induction goes through.</p>
<p>
What we really want to do, however, is prove that <img alt="{d(0,p)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%280%2Cp%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d(0,p)}"/> is the shortest length for any path, period. The path need not have any straight segments. It may go in circular arcs, continually changing direction. The arcs need not be circular per-se; they could be anything.</p>
<p>
The idea that occurs to us computer scientists is to let <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> go to infinity. That is, we want to consider any path as being a limit of polygonal paths. But is this really legitimate? We can certainly approximate any path by paths of segments. But real analysis is littered with examples of complicated curves—themselves defined by limits—that defeat many intuitive expectations about continuity and limits. So how can we make such an infinitistic proof go through rigorously? This is where the calculus of variations takes over.</p>
<p>
</p><p/><h2> Minimizers of Functionals </h2><p/>
<p/><p>
To set up the problem for fully general paths, we could represent them as functions <img alt="{f(t) = (x(t),y(t))}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28t%29+%3D+%28x%28t%29%2Cy%28t%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(t) = (x(t),y(t))}"/> such that <img alt="{f(0) = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%280%29+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(0) = 0}"/> and <img alt="{f(1) = p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%281%29+%3D+p%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(1) = p}"/>. The length of the path is then obtained by integrating all the horizontal and vertical displacements: <a name="length1"/></p><a name="length1">
<p align="center"><img alt="\displaystyle  \ell(f)(0,p) = \int_{t=0}^{t=1} \sqrt{\left(\frac{dx(t)}{dt}\right)^2 + \left(\frac{dy(t)}{dt}\right)^2} dt. \ \ \ \ \ (1)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cell%28f%29%280%2Cp%29+%3D+%5Cint_%7Bt%3D0%7D%5E%7Bt%3D1%7D+%5Csqrt%7B%5Cleft%28%5Cfrac%7Bdx%28t%29%7D%7Bdt%7D%5Cright%29%5E2+%2B+%5Cleft%28%5Cfrac%7Bdy%28t%29%7D%7Bdt%7D%5Cright%29%5E2%7D+dt.+%5C+%5C+%5C+%5C+%5C+%281%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \ell(f)(0,p) = \int_{t=0}^{t=1} \sqrt{\left(\frac{dx(t)}{dt}\right)^2 + \left(\frac{dy(t)}{dt}\right)^2} dt. \ \ \ \ \ (1)"/></p>
</a><p><a name="length1"/> Wrangling this integral seems daunting enough, but the real action involving <img alt="{\ell(f)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell%28f%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\ell(f)}"/> only begins after doing so. Both the length <img alt="{\ell(f)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell%28f%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\ell(f)}"/> and the body of the integral are <em>functionals</em>—that is, functions of a function. We need to minimize <img alt="{\ell(f)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell%28f%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\ell(f)}"/> over all functions <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/>. This is a higher-order task than minimizing a function at a point. </p>
<p>
Our source simplifies the problem by assuming without loss of generality that <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> increases from <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/> to <img alt="{a}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a}"/>, giving the function <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/> as <img alt="{y(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y(x)}"/> instead. Then the problem becomes to minimize <a name="length21"/></p><a name="length21">
<p align="center"><img alt="\displaystyle  \ell(f) = \int_{x=0}^{x=a} \sqrt{1 + \left(\frac{dy(x)}{dx}\right)^2} dx. \ \ \ \ \ (2)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cell%28f%29+%3D+%5Cint_%7Bx%3D0%7D%5E%7Bx%3Da%7D+%5Csqrt%7B1+%2B+%5Cleft%28%5Cfrac%7Bdy%28x%29%7D%7Bdx%7D%5Cright%29%5E2%7D+dx.+%5C+%5C+%5C+%5C+%5C+%282%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \ell(f) = \int_{x=0}^{x=a} \sqrt{1 + \left(\frac{dy(x)}{dx}\right)^2} dx. \ \ \ \ \ (2)"/></p>
</a><p><a name="length21"/> The body can be abstracted as a functional <img alt="{F(u,u')}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%28u%2Cu%27%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F(u,u')}"/> where <img alt="{u}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u}"/> and its derivative <img alt="{u'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u'}"/> are functions of <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/>. Here we have <img alt="{u = y(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu+%3D+y%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u = y(x)}"/> and <img alt="{u' = \frac{dy}{dx}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu%27+%3D+%5Cfrac%7Bdy%7D%7Bdx%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u' = \frac{dy}{dx}}"/>. The condition for <img alt="{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F}"/> to minimize <img alt="{\mathcal{F} = \int_x F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BF%7D+%3D+%5Cint_x+F%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{F} = \int_x F}"/> was derived by Leonhard Euler and Joseph Lagrange: <a name="EL"/></p><a name="EL">
<p align="center"><img alt="\displaystyle  \frac{d}{dx}\left(\frac{\partial F}{\partial u'}\right) = \frac{\partial F}{\partial u}\;. \ \ \ \ \ (3)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7Bd%7D%7Bdx%7D%5Cleft%28%5Cfrac%7B%5Cpartial+F%7D%7B%5Cpartial+u%27%7D%5Cright%29+%3D+%5Cfrac%7B%5Cpartial+F%7D%7B%5Cpartial+u%7D%5C%3B.+%5C+%5C+%5C+%5C+%5C+%283%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \frac{d}{dx}\left(\frac{\partial F}{\partial u'}\right) = \frac{\partial F}{\partial u}\;. \ \ \ \ \ (3)"/></p>
</a><p><a name="EL"/> We won’t reproduce here how our source derives this but give some interpretation. This is a kind of regularity property that <img alt="{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F}"/> must obey in order to minimize <img alt="{\mathcal{F}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BF%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{F}}"/>. To quote Donaldson’s survey:</p>
<blockquote><p><b> </b> <em> Then the condition that <img alt="{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{F}"/> is stationary with respect to compactly supported variations of <img alt="{u}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{u}"/> is a second order differential equation—the Euler-Lagrange equation associated to the functional. </em>
</p></blockquote>
<p/><p>
However you slice it, the point is that the equation (<a href="https://rjlipton.wordpress.com/feed/#EL">3</a>), when applied to cases like the above, is attackable. In the minimum-length path example, our source—after doing eight more equation lines of work—deduces that <img alt="{u' = \frac{dy}{dx}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu%27+%3D+%5Cfrac%7Bdy%7D%7Bdx%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u' = \frac{dy}{dx}}"/> must be constant. Any function argument <img alt="{F = y(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF+%3D+y%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F = y(x)}"/> that yields this must be a straight line. The initial conditions force this to be the straight line from <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/> to <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/>.</p>
<p>
</p><p/><h2> Some of Uhlenbeck’s Work </h2><p/>
<p/><p>
The point we are emphasizing is that this simple case of paths in the plane—and its abstraction via functionals <img alt="{\mathcal{F}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BF%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{F}}"/> that are ultimately founded on one variable <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/>—have a ready-made minimization scheme, thanks to Euler and Lagrange. The scheme is fully general—not subject to the caveats about our simple approximation by line segments.</p>
<p>
What happens in higher-dimensional cases? We can quote from the wonderful two-page <a href="http://www.abelprize.no/c73996/binfil/download.php?tid=74177">essay</a> accompanying the Abel Prize citation. It first notes the importance of a <a href="https://en.wikipedia.org/wiki/Palais-Smale_compactness_condition">condition</a> on functionals and their ambient spaces named for Richard Palais and Stephen Smale, which however fails for many cases of interest including harmonic maps.</p>
<blockquote><p><b> </b> <em> [T]he Palais-Smale compactness condition … guarantees existence of minimizers of geometric functionals and is successful in the case of 1-dimensional domains, such as closed geodesics. Uhlenbeck realized that the condition of Palais-Smale fails in the case of surfaces due to topological reasons. </em>
</p></blockquote>
<p/><p>
The papers with Sacks explored the roots of these breakdowns and found a way to patch them. The violation of the Palais-Smale condition allows minimizing sequences of functionals to converge with dependence on points outside the space being analyzed. But those loci are governed by a finite set of singular points within the space. This enables the calculus outside the space to be treated as a re-scaling of what goes on inside the space. </p>
<p>
In general cases the view of the process from inside to outside can be described and analyzed as bubbles emerging from the singular locations. More than this picture and interpretation, the Sacks-Uhlenbeck papers produced a now-standard tool-set for higher-dimensional minimization of functionals. It is also another successful marriage of topology—determining the singularities—and analysis.</p>
<p>
This work was extensible to more-general kinds of functionals such as a central one of Yang-Mills theory in physics. Geometric properties of a Riemannian manifold <img alt="{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M}"/> are expressed via the concept of a <a href="https://en.wikipedia.org/wiki/Connection_(mathematics)">connection</a> <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/> and the functional associates to <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/> its <em>curvature</em> <img alt="{F(A)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%28A%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F(A)}"/>. This is the body for the Yang-Mills functional </p>
<p align="center"><img alt="\displaystyle  \mathcal{F} = \int_M |F(A)|^2. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathcal%7BF%7D+%3D+%5Cint_M+%7CF%28A%29%7C%5E2.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \mathcal{F} = \int_M |F(A)|^2. "/></p>
<p>There is a corresponding lifting of the Euler-Lagrange equation. This led to developments very much along lines of the previous work with Sacks and more besides. There was particular success analyzing cases where <img alt="{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M}"/> has dimension 4 that were soon relevant to Donaldson’s own Fields Medal-winning research on these spaces. Most in particular, Uhlenbeck working solo proved that these cases were immune to the “bubbling” issue—with the consequence as related in <em>Quanta</em> that</p>
<blockquote><p><b> </b> <em> any finite-energy solution to the Yang-Mills equations that is well-defined in the neighborhood of a point will also extend smoothly to the point itself. </em>
</p></blockquote>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
We’ve been happy to report that Uhlenbeck has won the prestigious Abel Prize. We have avoided referencing one aspect—despite giving numerous quotes verbatim—that can be appreciated in subsequent fullness <a href="https://www.ias.edu/news/2018/women-and-mathematics-twenty-five-years">here</a> and <a href="https://www.ias.edu/pcmi">here</a> and in <a href="https://impa.br/en_US/page-noticias/karen-uhlenbeck-the-struggle-for-a-place-in-the-sun/">this</a>. By so doing we’ve abided the desire stated in the twelfth paragraph of this <a href="https://web.ma.utexas.edu/users/uhlen/vita/pers.html">essay</a>. We wonder if this is the right way to do things. What do you think?</p>
<p/></font></font></div>
    </content>
    <updated>2019-03-22T02:45:15Z</updated>
    <published>2019-03-22T02:45:15Z</published>
    <category term="All Posts"/>
    <category term="News"/>
    <category term="People"/>
    <category term="Results"/>
    <category term="analysis"/>
    <category term="calculus of variations"/>
    <category term="geometry"/>
    <category term="Jonathan Sacks"/>
    <category term="Karen Uhlenbeck"/>
    <category term="minimization"/>
    <category term="Physics"/>
    <category term="Simon Donaldson"/>
    <category term="topology"/>
    <category term="Yang-Mills theory"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-03-26T04:20:36Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-2570215373323645628</id>
    <link href="https://blog.computationalcomplexity.org/feeds/2570215373323645628/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/03/back-at-dagstuhl.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/2570215373323645628" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/2570215373323645628" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/03/back-at-dagstuhl.html" rel="alternate" type="text/html"/>
    <title>Back at Dagstuhl</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div class="separator" style="clear: both; text-align: center;">
<a href="https://www.dagstuhl.de/Gruppenbilder/19121.01.l.jpg"><img border="0" height="212" src="https://www.dagstuhl.de/Gruppenbilder/19121.01.l.jpg" width="320"/></a></div>
<table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody>
<tr><td style="text-align: center;"><a href="https://4.bp.blogspot.com/-GEp5KM-SUA4/XJJZrdR0SrI/AAAAAAABmzo/-77gRJWCTY814teJFCINLxABFNIohHF8QCKgBGAs/s1600/IMG_20190320_090009.jpg" style="margin-left: auto; margin-right: auto;"><img border="0" height="240" src="https://4.bp.blogspot.com/-GEp5KM-SUA4/XJJZrdR0SrI/AAAAAAABmzo/-77gRJWCTY814teJFCINLxABFNIohHF8QCKgBGAs/s320/IMG_20190320_090009.jpg" width="320"/></a></td></tr>
<tr><td class="tr-caption" style="text-align: center;">Participants and Their Research Interests</td></tr>
</tbody></table>
<br/>
This week I'm in Germany for the Dagstuhl workshop on <a href="https://www.dagstuhl.de/en/program/calendar/semhp/?semnr=19121">Computational Complexity of Discrete Problems</a> well timed for Georgia Tech spring break. No Bill, so no <a href="https://blog.computationalcomplexity.org/2018/09/still-typecasting-from-dagstuhl.html">typecast</a>, no <a href="https://blog.computationalcomplexity.org/2017/03/the-dagstuhl-family.html">family</a>, just a bunch of fellow theorists. New this year, beer.<br/>
<br/>
Dagstuhl always had bottled beer (and wine), after all this is Germany. However, Ronen Shaltiel is living his lifelong dream of bringing a keg to Dagstuhl. Turns out Dagstuhl had a refrigerator/tap for a beer keg, one only needs to order and pay for the beer. Ronen's daughter designed a special logo, though the keg contains Bitburger, a fine German pilsner. Prost to Ronen and thanks for the beer.<br/>
<br/>
<div class="separator" style="clear: both; text-align: center;">
<a href="https://3.bp.blogspot.com/-L7gbzTPK6t8/XJIeFNgMlwI/AAAAAAABmyU/8HxYbP69pVI91P9I-m3y4aXhlYEzwWqxwCKgBGAs/s1600/MVIMG_20190318_181047.jpg" style="clear: right; float: right; margin-bottom: 1em; margin-left: 1em;"><img border="0" height="200" src="https://3.bp.blogspot.com/-L7gbzTPK6t8/XJIeFNgMlwI/AAAAAAABmyU/8HxYbP69pVI91P9I-m3y4aXhlYEzwWqxwCKgBGAs/s200/MVIMG_20190318_181047.jpg" width="150"/></a><a href="https://1.bp.blogspot.com/-3yFv9qZFvkM/XJIeFPPmYSI/AAAAAAABmyU/iF8pnxyAO7wh8owT8A3RhFnMsCmvlzySgCKgBGAs/s1600/IMG_20190318_193159.jpg" style="clear: left; float: left; margin-bottom: 1em; margin-right: 1em;"><img border="0" height="200" src="https://1.bp.blogspot.com/-3yFv9qZFvkM/XJIeFPPmYSI/AAAAAAABmyU/iF8pnxyAO7wh8owT8A3RhFnMsCmvlzySgCKgBGAs/s200/IMG_20190318_193159.jpg" width="150"/></a><a href="https://2.bp.blogspot.com/-XLdHqofvmbQ/XJIfEQ3YBSI/AAAAAAABmyg/sfQphG1tRLQruYk30IytbJ_yKYYxpWAdQCLcBGAs/s1600/shaltieliner.jpg" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="200" src="https://2.bp.blogspot.com/-XLdHqofvmbQ/XJIfEQ3YBSI/AAAAAAABmyg/sfQphG1tRLQruYk30IytbJ_yKYYxpWAdQCLcBGAs/s200/shaltieliner.jpg" width="200"/></a></div>
<br/>
Of course the fun is hanging with colleagues old and new. Talking about open problems old and new. Used to solve more of them back in the day, now it seems harder.<br/>
<br/>
I did learn a new old theorem, planarity testing, whether you can embed a given graph in the plane so no two edges cross, is computable in log space. In 2000 Eric Allender and Meena Mahajan <a href="https://doi.org/10.1016/j.ic.2003.09.002">showed</a> that you can test for planarity in symmetric log space, basically the complexity class whose complete problem is undirected connectivity. In 2005, Omer Reingold <a href="https://doi.org/10.1145/1391289.1391291">famously showed</a> that undirected connectivity is computable in log-space. Thus planarity testing is in log-space, a result you might have missed if you didn't know both papers.<br/>
<br/>
This came out in Eric's talk on his work with Archit Chauhan, Samir Datta and Anish Mukherjee <a href="https://eccc.weizmann.ac.il/report/2019/039/">showing</a> that checked whether there is a directed path from a given node s to a given node t in planar graphs can be computed by concurrent-read exclusive-write on parallel random-access machines in logarithmic time, and thus likely weaker than directed s-t paths on general graphs.</div>
    </content>
    <updated>2019-03-21T10:11:00Z</updated>
    <published>2019-03-21T10:11:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>https://plus.google.com/101693130490639305932</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>https://plus.google.com/101693130490639305932</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-03-25T08:11:59Z</updated>
    </source>
  </entry>

  <entry>
    <id>http://offconvex.github.io/2019/03/19/CURL/</id>
    <link href="http://offconvex.github.io/2019/03/19/CURL/" rel="alternate" type="text/html"/>
    <title>Contrastive Unsupervised Learning of Semantic Representations&amp;#58; A Theoretical Framework</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><em>Semantic representations</em> (aka  <em>semantic embeddings</em>) of complicated data types (e.g. images, text, video) have become central in machine learning, and also crop up in machine translation, language models, GANs, domain transfer, etc. 
These involve learning a <em>representation function</em> $f$ such that for any data point $x$ its representation $f(x)$ is “high level” (retains semantic information while discarding low level details, such as color of individual pixels in an image) and “compact” (low dimensional). 
The test of a good representation is that it should greatly simplify solving <em>new</em> classification tasks, by allowing them to be solved via linear classifiers (or other low-complexity classifiers) using small amounts of labeled data.</p>

<p>Researchers are most interested in <em>unsupervised</em> representation learning using unlabeled data. A popular approach is to use objectives similar to the <strong>word2vec</strong> algorithm for word embeddings, which work well for diverse data types such as molecules, social networks, images, text etc. 
See the <a href="https://en.wikipedia.org/wiki/Word2vec">wikipage of word2vec</a> for references. 
Why do such objectives succeed in such diverse settings? 
This post is about an explanation for these methods by using our <a href="https://arxiv.org/abs/1902.09229">new theoretical framework</a> with coauthor Misha Khodak. 
The framework makes minimalistic assumptions, which is a good thing, since word2vec-like algorithms apply to vastly different data types and it is unlikely that they can share a common Bayesian generative model for the data. 
(An example of generative models in this space is described in an earlier <a href="http://www.offconvex.org/2016/02/14/word-embeddings-2/">blog post on the RAND-WALK model</a>.)
As a bonus this framework also yields principled ways to design new variants of the training objectives.</p>

<h2 id="semantic-representations-learning">Semantic representations learning</h2>
<p>Do good, broadly useful representations even <em>exist</em> in the first place? 
In domains such as computer vision, we know the answer is “yes” because deep convolutional neural networks (CNNs), when  trained to high accuracy on large multiclass labeled datasets such as <a href="http://www.image-net.org/">ImageNet</a>, end up learning very powerful and succinct representations along the way. The penultimate layer of the net — the input into the final <a href="https://en.wikipedia.org/wiki/Softmax_function">softmax layer</a> — serves as a good semantic embedding of the image in new unrelated visual tasks. 
(Other layers from the trained net can also serve as good embeddings.) 
In fact the availability of such embeddings from pre-trained (on large multiclass datasets) nets has led to a revolution in computer vision, allowing a host of new classification tasks to be solved with low-complexity classifiers (e.g. linear classifiers) using very little labeled data. 
Thus they are the gold standard to compare to if we try to learn embeddings via unlabeled data.</p>

<p style="text-align: center;">
<img src="http://www.offconvex.org/assets/CURLheadless1.svg" width="50%"/>
</p>

<h3 id="word2vec-like-methods-curl">word2vec-like methods: CURL</h3>

<p>Since the success of <a href="https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf">word2vec</a>, similar approaches were used to learn embeddings for <a href="https://arxiv.org/pdf/1803.02893.pdf">sentences and paragraphs</a>, <a href="https://arxiv.org/abs/1505.00687">images</a> and <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4640716/">biological sequences</a>.
All of these methods share a key idea: they leverage access to pairs of similar data points $x, x^+$, and learn an embedding function $f$ such that the inner product of $f(x)$ and $f(x^+)$ is on average higher than the inner product of $f(x)$ and $f(x^-)$, where $x^{-}$ is a random data point (and thus presumably dissimilar to $x$). 
In practice similar data points are usually found heuristically, often using co-occurrences, e.g. consecutive sentences in a large text corpus, nearby frames in a video clip, different patches in the same image, etc.</p>

<p>A good example of such methods is <strong>Quick Thoughts</strong> (QT) from <a href="https://arxiv.org/pdf/1803.02893.pdf">Logeswaran and Lee</a>, which is the state-of-the-art unsupervised text embedding on many tasks. To learn a representation function $f$, QT minimizes the following loss function on a large text corpus</p>



<p>where $(x, x^+)$ are consecutive sentences and presumably “semantically similar” and $x^-$ is a random negative sample.
For images $x$ and $x^+$ could be <a href="https://arxiv.org/abs/1505.00687">nearby frames</a> from a video.
For text, two successive sentences serve as good candidates for a similar pair: for example, the following are two successive sentences in the Wikipedia page on word2vec: <em>“High frequency words often provide little information.”</em> and <em>“Words with frequency above a certain threshold may be subsampled to increase training speed.”</em>
Clearly they are much more similar than a random pair of sentences, and the learner exploits this. 
From now on we use <em>Contrastive Unsupervised Representation Learning (CURL)</em> to refer to  methods that leverage similar pairs of data points and our goal is to analyze these methods.</p>

<h3 id="need-for-a-new-framework">Need for a new framework</h3>

<p>The standard framework for machine learning involves minimizing some loss function, and learning is said to succeed (or <em>generalize</em>) if the loss is roughly the same on the average training data point and the average test data point.
In contrastive learning, however, the objective used at test time is very different from the training objective: generalization error is not the right way to think about this.</p>

<blockquote>
  <p><strong>Main Hurdle for Theory:</strong> We have to show that doing well on task A (minimizing the word2vec-like objective) allows the representation to do well on task B (i.e., classification tasks revealed later).</p>
</blockquote>

<p>Earlier methods along such lines include <em>kernel learning</em> and <em>semi-supervised learning</em>, but there training typically requires at least a few labeled examples from the classification tasks of future interest. Bayesian approaches using generative models are also well-established in simpler settings, but have proved difficult for complicated data such as images and text. 
Furthermore, the simple word2vec-like learners described above do not appear to operate like Bayesian optimizers in any obvious way, and also work for very different data types.</p>

<p>We tackle this problem by proposing a framework that formalizes the notion of semantic similarity that is implicitly used by these algorithms and use the framework to show why contrastive learning gives good representations, while defining what <em>good representations</em> mean in this context.</p>

<h2 id="our-framework">Our framework</h2>

<p>Clearly, the implicit/heuristic notion of similarity used in contrastive learning is connected to the downstream tasks in some way — e.g., similarity carries a strong <em>hint</em> that on average the “similar pairs” tend to be assigned the same labels in many downstream tasks (though there is no hard guarantee per se). We present a simple and minimalistic framework to formalize such a notion of similarity. 
For purposes of exposition we’ll refer to data points as “images”.</p>

<h3 id="semantic-similarity">Semantic similarity</h3>

<p>We assume nature has many <em>classes</em> of images, and has a measure $\rho$ on a set of classes $\mathcal{C}$, so that if asked to pick a class it selects $c$  with probability $\rho(c)$. 
Each class $c$ also has an associated distribution $D_c$ on images i.e. if nature is asked to furnish examples of class $c$ (e.g., the class “dogs”) then it picks image $x$ with probability $D_c(x)$. 
Note that classes can have arbitrary overlap, including no overlap. 
To formalize a notion of <em>semantic similarity</em> we assume that when asked to provide “similar” images, nature picks a class $c^+$ from $\mathcal{C}$ using measure $\rho$ and then picks two i.i.d. samples $x, x^{+}$ from the distribution $D_{c^+}$. 
The dissimilar example $x^{-}$ is picked by selecting another class $c^-$ from measure $\rho$ and picking a random sample $x^{-}$ from $D_{c^-}$.</p>

<p style="text-align: center;">
<img src="http://www.offconvex.org/assets/CURLframework.svg" width="80%"/>
</p>

<p>The training objective for learning the representation is exactly the QT objective from earlier, but now inherits the following interpretation from the framework
</p>

<p>Note that the function class $\mathcal{F}$ is an arbitrary deep net architecture mapping images to embeddings (neural net sans the final layer), and one would learn $f$ via gradient descent/back-propagation as usual. 
Of course, no theory currently exists for explaining when optimization succeeds for complicated deep nets, so our framework will simply assume that gradient descent has already resulted in some representation $f$ that achieves low loss, and studies how well this does in downstream classification tasks.</p>

<h3 id="testing-representations">Testing representations</h3>

<p>What defines a good representation? 
We assume that the quality of the representation is tested by using it to solve a binary (i.e., two-way) classification task using a linear classifier. 
(The paper also studies extensions to $k$-way classification in the downstream task.) 
How is this binary classification task selected? 
Nature picks two classes $c_1, c_2$ randomly according to measure $\rho$ and picks data points for each class according to the associated probability distributions $D_{c_1}$ and $D_{c_2}$. 
The representation is then used to solve this binary task via logistic regression: namely, find two vectors $w_1, w_2$ so as to minimize the following loss
</p>

<p>The quality of the representation is estimated as the <em>average</em> loss over nature’s choices of binary classification tasks.
</p>

<p>It is important to note that the latent classes present in the unlabeled data are the <em>same</em> classes present in the classification tasks. 
This allows us to formalize a sense of ‘semantic similarity’ as alluded to above: the classes from which data points appear together more frequently are the classes that make up <em>relevant</em> classification tasks. 
Note that if the number of classes is large, then typically the data used in unsupervised training may involve <em>no samples</em> from the classes used at test time. 
Indeed, we are hoping to show that the learned representations are useful for classification on potentially unseen classes.</p>

<h2 id="provable-guarantees-for-unsupervised-learning">Provable guarantees for unsupervised learning</h2>

<p>What would be a dream result for theory? Suppose we fix a class of representation functions ${\mathcal F}$, say those computable by a ResNet 50 architecture with some choices of layer sizes etc.</p>

<blockquote>
  <p><strong>Dream Theorem:</strong> Minimizing the unsupervised loss (using modest amount of unlabeled data) yields a representation function $f \in {\mathcal F}$ that is competitive with the <strong>best</strong> representation from ${\mathcal F}$ on downstream classification tasks, even with very few labeled examples per task.</p>
</blockquote>

<p>While the number of unlabeled data pairs needed to learn an approximate minimizer can be controlled using Rademacher complexity arguments (see paper), we show that the dream theorem is impossible as phrased: we can exhibit a simple class ${\mathcal F}$ where the contrastive objective does not yield representations even remotely competitive with the best in the class.
This should not be surprising and only suggests that further progress towards such a dream result would require making more assumptions than the above minimalistic ones.</p>

<p>Instead, our paper makes progress by showing that under the above framework, if the unsupervised loss happens to be small at the end of contrastive learning then the resulting representations perform well on downstream classification.</p>

<blockquote>
  <p><strong>Simple Lemma:</strong> The average classification loss on downstream binary tasks is upper bounded by the unsupervised loss.

where $\alpha$ depends on $\rho$. ($\alpha\rightarrow 1$ when $|\mathcal{C}|\rightarrow\infty$, for uniform $\rho$)</p>
</blockquote>

<p>This says that the unsupervised loss function can be treated as a <strong>surrogate</strong> for the performance on downstream supervised tasks solved using linear classification, so minimizing it makes sense.
Furthermore, just a few labeled examples are needed to learn the linear classifiers in future downstream tasks.
Thus our minimalistic framework lets us show guarantees for contrastive learning and also highlights the labeled sample complexity benefits provided by it. For details as well as more finegrained analysis see <a href="https://arxiv.org/abs/1902.09229">the paper</a>.</p>

<h2 id="extensions-of-the-theoretical-analysis">Extensions of the theoretical analysis</h2>

<p>This conceptual framework not only allows us to reason about empirically successful variants of (1), but also leads to the design of new, theoretically grounded unsupervised objective functions. 
Here we give a high level view; details are in  <a href="https://arxiv.org/abs/1902.09229">our paper</a>.</p>

<p><em>A priori,</em> one might imagine that the log and exponentials in (1) have some information-theoretic interpretation; here we relate the functional form to the fact that logistic regression is going to be used in the downstream classification tasks. 
Analogously, if the classification is done via hinge loss, then (2) is true for a different unsupervised loss that uses a hinge-like loss instead. 
This objective, for instance, was used to learn image representations from videos by <a href="https://arxiv.org/abs/1505.00687">Wang and Gupta</a>. 
Also, usually in practice $k&gt;1$ negative samples are contrasted with each positive sample $(x,x^+)$ and the unsupervised objective looks like the $k$-class cross-entropy loss. 
We prove a statement similar to (2) for this setting, where the supervised loss now is the average $(k+1)$-way classification loss.</p>

<p>Finally, the framework provides guidelines for designing new unsupervised objectives when <em>blocks</em> of similar data are available (e.g., sentences in a paragraph). 
Replacing $f(x^+)$ and $f(x^-)$ in (1) with the average of the representations from the positive and the negative block respectively, we get a new objective which comes with stronger guarantees and better performance in practice. 
We experimentally verify the effectiveness of this variant in our paper.</p>

<h2 id="experiments">Experiments</h2>

<p>We report some controlled experiments to verify the theory. Lacking a canonical multiclass problem for text, we constructed a new 3029-class labeled dataset where a class is one of 3029 articles from Wikipedia,  and datapoints are one of $200$ sentences in these articles. Representations will be tested on a random binary classification task that involves two articles, where the labels of the data point is which of the two articles it belongs to. (A 10-way classification task is similarly defined.)  Datapoints for the test tasks will be held out while training representations. The class of sentence representation ${\mathcal F}$ is a simple multilayer architecture one based on Gated Recurrent Unit (GRU).</p>

<p>The supervised method for learning representations trains a multiclass classifier on the 3029-way task and the representation is taken from the layer before the final softmax output. This was the gold standard in above discussions.</p>

<p>The unsupervised method is fed pairs of similar data points generated according to our theory: similar data points are just pairs of sentences sampled from the same article. Representations are learnt by minimizing the above unsupervised loss objectives.</p>

<p style="text-align: center;">
<img src="http://www.offconvex.org/assets/CURLexperiment.svg" width="60%"/>
</p>
<p>The highlighted parts in the table show that the unsupervised representations compete well with the supervised representations on the average $k$-way classification task ($k=2, 10$).</p>

<p>Additionally, even though not covered by our theory, the representation also performs respectably on the full  multiclass problem.
We find some support for a suggestion of our theory that the mean (centroid) of the unsupervised representations in each class should be good classifiers for average $k$-way supervised tasks. We find this to be true for unsupervised representations, and surprisingly for supervised representations as well.</p>

<p>The paper also has other experiments studying the effect of number of negative samples and larger blocks of similar data points, including experiments on the CIFAR-100 image dataset.</p>

<h2 id="conclusions">Conclusions</h2>
<p>While contrastive learning is a well-known <em>intuitive</em> algorithm, its practical success has been a mystery for theory. 
Our conceptual framework lets us formally show guarantees for representations learnt using such algorithms. 
While shedding light on such algorithms, the framework also lets us come up with and analyze variants of it. 
It also provides insights into what guarantees are provable and shapes the search for new assumptions that would allow stronger guarantees. 
While this is a first cut, possible extensions include imposing a metric structure among the latent classes.
Connections to meta-learning and transfer learning may also arise.
We hope that this framework influences and guides practical implementations in the future.</p></div>
    </summary>
    <updated>2019-03-19T19:00:00Z</updated>
    <published>2019-03-19T19:00:00Z</published>
    <source>
      <id>http://offconvex.github.io/</id>
      <author>
        <name>Off the Convex Path</name>
      </author>
      <link href="http://offconvex.github.io/" rel="alternate" type="text/html"/>
      <link href="http://offconvex.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Algorithms off the convex path.</subtitle>
      <title>Off the convex path</title>
      <updated>2019-03-25T23:34:26Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/042</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/042" rel="alternate" type="text/html"/>
    <title>TR19-042 |  Determinant equivalence test over finite fields and over $\mathbf{Q}$ | 

	Ankit Garg, 

	Nikhil Gupta, 

	Neeraj Kayal, 

	Chandan Saha</title>
    <summary>The determinant polynomial $Det_n(\mathbf{x})$ of degree $n$ is the determinant of a $n \times n$ matrix of formal variables. A polynomial $f$ is equivalent to $Det_n$ over a field $\mathbf{F}$ if there exists a $A \in GL(n^2,\mathbf{F})$ such that $f = Det_n(A \cdot \mathbf{x})$. Determinant equivalence test over $\mathbf{F}$ is the following algorithmic task: Given black-box access to a $f \in \mathbf{F}[\mathbf{x}]$, check if $f$ is equivalent to $Det_n$ over $\mathbf{F}$, and if so then output a transformation matrix $A \in GL(n^2,\mathbf{F})$. In Kayal (2012), a randomized polynomial time determinant equivalence test was given over $\mathbf{C}$. But, to our knowledge, the complexity of the problem over finite fields and over rationals was not well understood. 

In this work, we give a randomized $poly(n,\log |\mathbf{F}|)$ time determinant equivalence test over finite fields $\mathbf{F}$ (under mild restrictions on the characteristic and size of $\mathbf{F}$). Over rationals, we give an efficient randomized reduction from factoring square-free integers to determinant equivalence test for quadratic forms (i.e. the $n=2$ case), assuming GRH. This shows that designing a polynomial-time determinant equivalence test over rationals is a challenging task. Nevertheless, we show that determinant equivalence test over rationals is decidable: For bounded $n$, there is a randomized polynomial-time determinant equivalence test over rationals with access to an oracle for integer factoring. Moreover, for any $n$, there is a randomized polynomial-time algorithm that takes input black-box access to a rational polynomial $f$ and if $f$ is equivalent to $Det_n$ over rationals then it returns a $A \in GL(n^2,\mathbf{L})$ such that $f = Det_n(A \cdot \mathbf{x})$, where $\mathbf{L}$ is an extension field of $\mathbf{Q}$ of degree at most $n$. 

The above algorithms over finite fields and over rationals are obtained by giving a polynomial-time randomized reduction from determinant equivalence test to another problem, namely the full matrix algebra isomorphism problem. We also show a reduction in the converse direction which is efficient if $n$ is bounded. These reductions, which hold over any $\mathbf{F}$ (under mild restrictions on the characteristic and size of $\mathbf{F}$), establish a close connection between the complexity of the two problems. This then lead to our results via applications of known results on the full algebra isomorphism problem over finite fields and over $\mathbf{Q}$.</summary>
    <updated>2019-03-18T12:28:35Z</updated>
    <published>2019-03-18T12:28:35Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-03-26T04:20:29Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-4318994903152354716</id>
    <link href="https://blog.computationalcomplexity.org/feeds/4318994903152354716/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/03/third-poll-on-p-vs-np-and-related.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/4318994903152354716" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/4318994903152354716" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/03/third-poll-on-p-vs-np-and-related.html" rel="alternate" type="text/html"/>
    <title>Third Poll on P vs NP and related Questions is out now! And the winner is Harambe!</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><br/>
I took a poll of the theory community (and others) about P vs NP and related issues in 2002, 2012, and 2019 (sorry its not an arithmetic  sequence --- read the third poll article to see why).  The 2002 and 2012 polls are on the web (see <a href="https://www.cs.umd.edu/users/gasarch/BLOGPAPERS/pollpaper1.pdf">here</a> and <a href="https://www.cs.umd.edu/users/gasarch/BLOGPAPERS/pollpaper2.pdf">here</a> ), and now the third poll is out and its <a href="https://www.cs.umd.edu/users/gasarch/BLOGPAPERS/pollpaper3.pdf">here</a> or <a href="https://dl.acm.org/citation.cfm?doid=3319627.3319636">here</a> . All three appear in Lane's Complexity Column in SIGACT News.<a href="https://www.cs.umd.edu/users/gasarch/BLOGPAPERS/pollpaper1.pdf"/><br/>
<br/>
I'll give some highlights and thought about the third poll, but for more read the article. Or read all three and see how opinions have changed over time.<br/>
<br/>
0) How many respondents: 100 the first time, and 152 the second time, 124 the third time.<br/>
<br/>
1) P≠NP is at about 80%. When restricted to people who have thought about the problem a lot (my judgement) then it goes to 99%. The strongest P≠NP is by Lance who says<br/>
<br/>
                                People who think P=NP are like people who believe Elvis is alive.<br/>
<br/>
I disagree. I think Elvis is alive and is trying to prove P=NP.<br/>
<br/>
2) When will it be solved? 66% thought it would be solved before 2100, a bit more than in prior years. But also more thought it would never be solved. Some commented that a computer might solve it.  I doubt that, but I do think this poll will be done by a computer in 10 years.<br/>
<br/>
3) Because I used Survey monkey (1) each question got more answers, and (2) most  questions got a forced YES or NO  so less funny comments or room for creative answers. People could still leave comments, and some did.<br/>
<br/>
4) Related to point (3): The last time I did the poll P=BPP was thought by everyone <i>who answered</i> <i>the question</i>. This year far more people answered it and quite a few thought P≠BPP. This may be because Survey monkey had a psychological affect of making people vote even if they didn't really know (people who have thought a lot about P vs NP  all thought P=BPP). Has  there been evidence that P≠BPP that I am unaware of? Or since there has not been that much progress on it maybe they are unequal.  10  years ago I would have thought we would have L=RL by now.<br/>
<br/>
5) The last time I did the poll 10 people thought factoring IS in P and the NSA or the KGB knows that. This time around nobody thought that. Why? Those 10 people have vanished mysteriously.<br/>
<br/>
6) Five people thought P vs NP will be resolved by Harambe. That is more than any person got.<br/>
<br/>
7)  Is this poll worth doing? I would say yes (gee, I have to having done his poll three times) because it is good to have an objective record of subjective opinion. <br/>
<br/>
8) I'll give some of my answers: P≠NP, Elvis is dead, and both will be proven in the year 2525. For more about the future see <a href="https://www.youtube.com/watch?v=yesyhQkYrQM">this</a>.<br/>
<br/></div>
    </content>
    <updated>2019-03-17T22:55:00Z</updated>
    <published>2019-03-17T22:55:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>https://plus.google.com/101693130490639305932</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-03-25T08:11:59Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/041</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/041" rel="alternate" type="text/html"/>
    <title>TR19-041 |  Quantum hardness of learning shallow classical circuits | 

	Srinivasan Arunachalam, 

	Alex Bredariol Grilo, 

	Aarthi Sundaram</title>
    <summary>In this paper we study the quantum learnability of constant-depth classical circuits under the uniform distribution and in the distribution-independent framework of PAC learning.  In order to attain our results, we  establish connections between quantum learning and quantum-secure  cryptosystems. We then achieve the following results. 

1) Hardness of learning $AC^0$ and $TC^0$ under the uniform distribution. Our first result concerns the concept class $TC^0$ (resp. $AC^0$), the class of constant depth and polynomial-sized circuits with unbounded fan-in majority gates (resp. AND, OR, NOT gates). We show that if there exists no quantum polynomial time (resp. sub-exponential time) algorithm to solve the Learning with Errors (LWE) problem, then there exists no polynomial time quantum learning algorithm for $TC^0$ (resp. $AC^0$) under the uniform distribution (even with access to quantum membership queries). The main technique in this result uses explicit pseudo-random generators that are believed to be quantum-secure to construct concept classes that are hard to learn quantumly under the uniform distribution. 


2) Hardness of learning $TC^0_2$ in the PAC setting. Our second result shows that if there exists no quantum polynomial time algorithm for the LWE problem, then there exists no polynomial time quantum PAC learning algorithm for the class $TC^0_2$, i.e., depth-$2$ $TC^0$ circuits. The main technique in this result is to establish a connection between the quantum security of public-key cryptosystems and the learnability of a concept class that consists of decryption functions of the cryptosystem. 


This gives a strong conditional negative answer to one of the "Ten Semi-Grand Challenges for Quantum Computing Theory" raised by Aaronson, who asked if $AC^0$ and $TC^0$ can be PAC-learned in quantum polynomial time.</summary>
    <updated>2019-03-17T07:55:06Z</updated>
    <published>2019-03-17T07:55:06Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-03-26T04:20:29Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=15684</id>
    <link href="https://rjlipton.wordpress.com/2019/03/16/leprechauns-go-universal/" rel="alternate" type="text/html"/>
    <title>Leprechauns Go Universal</title>
    <summary>Facing nonexistential realities Neil L. is a Leprechaun. He has graced these pages before. Today, the day before St. Patrick’s Day, we ponder universal riddles of existence. Ken, who will visit me this coming week, insisted on reporting what happened this morning. I woke up early, walked alone into our living room, and was amazed […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Facing nonexistential realities</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<p><a href="https://rjlipton.files.wordpress.com/2019/03/neillcounterfactual.png"><img alt="" class="alignright size-thumbnail wp-image-15685" height="150" src="https://rjlipton.files.wordpress.com/2019/03/neillcounterfactual.png?w=143&amp;h=150" width="143"/></a></p>
<p><font color="green"/></p><font color="green">
<p>
Neil L. is a Leprechaun. He has <a href="https://rjlipton.wordpress.com/2009/03/16/happy-st-patricks-day-and-sum-of-squares/">graced</a> <a href="https://rjlipton.wordpress.com/2010/03/17/happy-st-patrick-day-again/">these</a> <a href="https://rjlipton.wordpress.com/2011/03/17/happy-st-patricks-day-again-again/">pages</a> <a href="https://rjlipton.wordpress.com/2013/03/17/happy-st-patricks-day-again-and-again-and-again-and-again/">before</a>.</p>
<p>
Today, the day before St. Patrick’s Day, we ponder universal riddles of existence. Ken, who will visit me this coming week, insisted on reporting what happened this morning.<br/>
<span id="more-15684"/></p>
<p>
I woke up early, walked alone into our living room, and was amazed to see Neil already here. He was looking out the window at dawn sunlight flooding over St. Patrick’s Cathedral and the many other landmarks we can see from our apartment in midtown Manhattan. </p>
<p>
Spring has at last given an earnest of coming. The scene was transfixing, exhilirating, all the glory of nature except for the green-clad little man puffing his pipe with his back to me.</p>
<p>
“Neil—?”</p>
<p>
He turned and tipped his hat to me but then turned back to the window. I wondered if I had caught him in meditation. I stood back until he turned a second time. He had always visited me late on the evening before St. Patrick’s Day, or the morning of it.</p>
<p>
“You’re here early.”</p>
<blockquote><p>
<font color="green"><br/>
“Aye. Top o’ the morning to ye.”<br/>
</font>
</p></blockquote>
<p>
“Why?”</p>
<p>
He gave me a long stare but warmly, not hostile. </p>
<blockquote><p>
<font color="green"><br/>
“By the living daylights in ye…”<br/>
</font>
</p></blockquote>
<p>
Then I understood. The Romans have their Ides, the Irish have the 17th, but I got the day in between—when last year I was not here but in an operating room for long hours.</p>
<p>
“Thanks” was all I could say. I had actually come out to look up a mathematical idea for a “part 2” post I’ve been struggling with ever since posting the “part 1” years ago. This pulled me back to math, then to how Neil has always tricked me and I’ve never been able to pin him down. I realized this might be my best opportunity.</p>
<p>
“Neil, may I ask you a Big Question? Not directly personal.”</p>
<p>
He simply said, “Aye.” No tricks yet.</p>
<p>
</p><p/><h2> The Question </h2><p/>
<p/><p>
I had my chance—something I’ve wanted to ask him for years but not had an opening for.</p>
<p>
“Neil, what can you tell me about <em>female</em> Leprechauns?” </p>
<p>
Neil had mentioned family, cousins, even siblings—I figured they had to come from somewhere. But nothing I’d read mentioned female leprechauns. I braced for silence again, but Neil’s reply was immediate and forthright:</p>
<blockquote><p>
<font color="green"><br/>
“They comprise the most heralded subset of our people. They are included in everything we do.”<br/>
</font>
</p></blockquote>
<p>
“How so?”</p>
<blockquote><p>
<font color="green"><br/>
“Our society agreed early on that every female leprechaun should have the highest station. All female leprechauns are sent to the best schools, with personal tutoring reserved in advanced subjects. They are our superpartners in every way.”<br/>
</font>
</p></blockquote>
<p>
“How do you treat them?”</p>
<blockquote><p>
<font color="green"><br/>
“If a lady leprechaun applies for a position, she is given full consideration. Whenever a lady leprechaun gives advice, it is harkened to. None of us has ever ‘malesplained’ or demeaned a lady leprechaun in any way.”<br/>
</font>
</p></blockquote>
<p>
“Are they as short—uh, tall—as you?”</p>
<blockquote><p>
<font color="green"><br/>
“Every adult female leprechaun is between one cubit and one-and-a-half in stature, like us menfolk. We don’t have quite the variation of your human species.”<br/>
</font>
</p></blockquote>
<p>
“I would surely like to meet one.”</p>
<p>
Neil heaved a sigh. </p>
<blockquote><p>
<font color="green"><br/>
“Ye know the trepidation with us and your womenfolk.” Indeed, I recalled Neil’s <a href="https://rjlipton.wordpress.com/2015/03/17/leprechauns-will-find-you/">story</a> of what was evidently his own harrowing encounter with the wife of William Hamilton. “It is symmetrical, I’m afraid. No female leprechaun has ventured into your world.”<br/>
</font>
</p></blockquote>
<p>
I had figured that. </p>
<p>
“But can you give me an <em>example</em> of a female leprechaun? Someone who has done something notable.”</p>
<p>
</p><p/><h2> The Reality </h2><p/>
<p/><p>
Neil puffed on his pipe. I knew I had him cornered and moved in.</p>
<p>
“Neil, is everything you just said about female leprechauns <em>true</em>?”</p>
<p>
To my surprise, he answered quickly.</p>
<blockquote><p>
<font color="green"><br/>
“<em>Aye.</em> As in mathematics, each of my statements was perfectly true.”<br/>
</font>
</p></blockquote>
<p>
Oh. Then I realized how empty domains are treated in mathematical logic. I looked at him sharply. </p>
<p>
“Neil, there <a href="https://thefw.com/things-you-didnt-know-about-leprechauns/">are</a> <a href="https://www.circa.com/story/2019/03/15/art-culture/where-are-all-the-female-leprechauns-we-asked-an-expert">no</a> female leprechauns. All of your statements have been vacuous, bull-.”</p>
<blockquote><p>
<font color="green"><br/>
“That’s not right or fair. That which I told ye have been important values of our society from the beginning. Many studies of female leprechauns have established their natures precisely. We have devoted vast resources to the quest for female leprechauns. Readiness—how we would integrate them—this is enshrined in all of our laws. Even your late Senator, <a>Birch</a> <a href="https://books.google.com/books?id=O-sOBAAAQBAJ&amp;pg=PT275&amp;lpg=PT275&amp;dq=Bayh+Irish+name&amp;source=bl&amp;ots=bECfTQqWkJ&amp;sig=ACfU3U2yp53w6HQk_aXp2uT6okbmEG7Y3w&amp;hl=en&amp;sa=X&amp;ved=2ahUKEwjtzKG6iIfhAhVuQt8KHdB5DmgQ6AEwDnoECAAQAQ#v=onepage&amp;q=Bayh Irish name&amp;f=false">Bayh</a>, was <a href="https://scholarship.law.nd.edu/ndlr/vol48/iss1/4/">informed</a> by us at Notre Dame.”<br/>
</font>
</p></blockquote>
<p>
Neil’s sincerity was evident. I still felt bamboozled. He carried on.</p>
<blockquote><p>
<font color="green"><br/>
“Ye have whole brilliant careers studying physical objects that may not exist. The analysis of them is still important in mathematics and other scientific applications. And in mathematics itself—”<br/>
</font>
</p></blockquote>
<p>
I was actually relieved to turn the subject back toward mathematics, as Neil and I usually talked about.</p>
<blockquote><p>
<font color="green"><br/>
“—your most storied advance of the past quarter century was achieved by ten years’ concerted study of the Frey-Hellegouarch <a href="https://en.wikipedia.org/wiki/Frey_curve">curve</a>. Which by Fermat’s Last Theorem does not exist.”<br/>
</font>
</p></blockquote>
<p>
</p><p/><h2> Existence </h2><p/>
<p/><p>
I could not argue with that. This set me pondering. Whether mathematical objects <em>exist</em> in reality defines the debate over Platonism. But what, then, is the reality of <em>nonexistent</em> mathematical objects? </p>
<p>
Nonexistent objects still follow rules and aid deductions about objects that do exist. So, they too exist? Moreover, we often cannot prove that those objects do not exist—for all we know they may be just as real. Polynomial-time algorithms for satisfiability and many other problems—those are bread and butter in theory. I wanted Neil to tell me more about some of them.</p>
<p>
“Neil, have your folk worked on the projective plane of order 10?”</p>
<blockquote><p>
<font color="green"><br/>
“<em>Aye</em>. Not only did we long ago have all the results of this <a href="https://www.sciencedirect.com/science/article/pii/0097316573900642">paper</a> on them, our engineers recommended it as the thoroughfare pattern for new towns.”<br/>
</font>
</p></blockquote>
<p>
“You have built them?”</p>
<blockquote><p>
<font color="green"><br/>
“Indeed—in two new districts around Carlingford back home.”<br/>
</font>
</p></blockquote>
<p>
“But they don’t exist.”</p>
<blockquote><p>
<font color="green"><br/>
“By our laws and treaties they exist until your people prove they don’t. Then they have a 50-year sunset. Which <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.39.8684&amp;rep=rep1&amp;type=pdf">means</a> the towns have 20 years left.<br/>
</font>
</p></blockquote>
<p>
“That’s sad.”</p>
<blockquote><p>
<font color="green"><br/>
“It’s actually a much better system than the Scots have. Their villages of this type such as <a href="https://en.wikipedia.org/wiki/Brigadoon">Brigadoon</a> come <a href="https://www.glenlaurel.com/about-us/blog/the-legend-of-brigadoon">back</a> every 100 years just for one day. But Brexit may put paid to our two towns sooner. We are <a href="https://www.irishcentral.com/travel/leprechauns-protected-european-law">protected</a> under E.U. law, but those towns are just over the Northern Ireland border.<br/>
</font>
</p></blockquote>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2019/03/carlingfordsign.png"><img alt="" class="aligncenter wp-image-15686" height="205" src="https://rjlipton.files.wordpress.com/2019/03/carlingfordsign.png?w=350&amp;h=205" width="350"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Cropped from <a href="https://thefw.com/things-you-didnt-know-about-leprechauns/">src1</a>, <a href="https://en.wikipedia.org/wiki/Carlingford,_County_Louth">src2</a></font>
</td>
</tr>
</tbody></table>
<p>
“How about odd perfect numbers?”</p>
<blockquote><p>
<font color="green"><br/>
“<em>Nay</em>. Ye know the rules. We can nay tell that which your folk do not know, unless there is nothing else ye learn that ye could not learn without us.”<br/>
</font>
</p></blockquote>
<p>
I pondered: what could I ask about computational complexity that Neil could respond to in this kind of zero-knowledge way? But Neil cut in.</p>
<blockquote><p>
<font color="green"><br/>
“It will be much more fruitful to discuss objects that ye <em>know</em> do not exist—and yet ye <em>use</em> them anyway.”<br/>
</font>
</p></blockquote>
<p>
</p><p/><h2> Mathematical Leprechauns </h2><p/>
<p/><p>
I thought, which could he mean? I recalled the story we <a href="https://rjlipton.wordpress.com/2010/01/23/definitions-definitions-do-we-need-them/">told</a> about a student getting his degree for a thesis with many new results on a strong kind of Lipschitz/Hölder function even though an examiner observed that non-constant ones do not exist. Ken heard the same story as an undergraduate, with the detail that it was an undergraduate senior thesis, not PhD. The Dirac delta function? Well, that definitely exists as a <a href="https://en.wikipedia.org/wiki/Dirac_delta_function#As_a_measure">measure</a>. I forgot an obvious example until Neil said it.</p>
<blockquote><p>
<font color="green"><br/>
“There is the field with one element: <img alt="{\mathbb{F}_1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BF%7D_1%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\mathbb{F}_1}"/>.”
</font></p></blockquote><font color="green">
<p>
Of course. We <a href="https://rjlipton.wordpress.com/2012/08/23/do-we-need-mysticism-in-theory/">posted</a> about it. </p>
<blockquote><p>
<font color="green"><br/>
“It is an active research subject, especially in the past dozen years. Your Fields medalist Alain Connes has co-written a <a href="https://arxiv.org/pdf/0806.2401v1.pdf">whole</a> <a href="https://arxiv.org/abs/0809.2926">series</a> of <a href="https://arxiv.org/abs/0903.2024">papers</a> on it. Yuri Manin <a href="https://arxiv.org/abs/0809.1564">also</a>. Your blog friend Henry Cohn got a <a href="https://arxiv.org/abs/math/0407093">paper</a> on it into the <em>Monthly</em>—think of the youngsters… Edifices are even <a href="https://arxiv.org/abs/0909.0069">being</a> <a href="https://link.springer.com/content/pdf/10.1007/s00209-009-0638-0.pdf">built</a> <a href="https://arxiv.org/abs/1709.05831">upon</a> it.”<br/>
</font>
</p></blockquote>
<p>
“Can you give some less-obvious ones for our readers?”</p>
<blockquote><p>
<font color="green"><br/>
“There is the uniform distribution on the natural numbers. This <a href="http://www.stat.cmu.edu/tr/tr814/tr814.pdf">paper</a> gives variations that do exist, but it makes the need and use of the original concept clear.”<br/>
</font>
</p></blockquote>
<p>
Ken had in fact once finished a lecture on Kolmogorov complexity when short on time by appealing to it.</p>
<blockquote><p>
<font color="green"><br/>
“There are fields <i>F</i> whose algebraic closures have degrees 3 and 5 over <i>F</i>. Those are highly useful.”<br/>
</font>
</p></blockquote>
<p>
I knew by a <a href="https://kconrad.math.uconn.edu/blurbs/galoistheory/artinschreier.pdf">theorem</a> of Emil Artin and Otto Schreier that they cannot exist. But it struck me as natural that they <em>should</em> exist. I wondered how much one would need to tweak the rules of group theory to make them possible.</p>
<blockquote><p>
<font color="green"><br/>
“Then there is the free complete lattice on 3 generators.”<br/>
</font>
</p></blockquote>
<p>
Wait—I thought <a href="https://en.wikipedia.org/wiki/Complete_lattice#Free_complete_lattices">that</a> could exist if one loosened up set theory. So I asked:</p>
<p>
“Neil, do some of these objects exist in alternative worlds known to leprechauns in which the rules of mathematics are crazy, not like the real world?”</p>
<blockquote><p>
<font color="green"><br/>
“What makes you think ye don’t live in one of those other worlds?”<br/>
</font>
</p></blockquote>
<p>
Before I could react, Neil picked up a solid glass sphere art object that belonged to Kathryn. He pulled out a diamond-encrusted knife and slashed it as green light flashed in every direction until he stopped. Then from his hands he gave me <a href="https://en.wikipedia.org/wiki/Banach-Tarski_paradox">two</a> glass spheres of the same size. </p>
<blockquote><p>
<font color="green"><br/>
“For the happy couple—<em>la le Padraig suna ye-uv!</em>”<br/>
</font>
</p></blockquote>
<p>
And he was gone.</p>
<p>
</p><p>
</p><p/><h2> Open Problems </h2><p/>
<p/></font><p><font color="green">
What is your view on the nature of mathematical reality? Do nonexistent mathematical objects exist? What are your favorite examples?  </font></p>
<p/></font></font></font></div>
    </content>
    <updated>2019-03-17T04:42:02Z</updated>
    <published>2019-03-17T04:42:02Z</published>
    <category term="All Posts"/>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="Oldies"/>
    <category term="trick"/>
    <category term="Birch Bayh"/>
    <category term="Brexit"/>
    <category term="Leprechaun"/>
    <category term="mathematical objects"/>
    <category term="Neil L."/>
    <category term="nonexistence"/>
    <category term="philosophy"/>
    <category term="Platonism"/>
    <category term="St. Patrick's Day"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-03-26T04:20:36Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/03/15/linkage</id>
    <link href="https://11011110.github.io/blog/2019/03/15/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>It’s the last day of classes for the winter quarter here at UCI, and a good time for some spring cleaning of old bookmarked links. Probably also a good time for a reminder that Google+ is shutting down in two weeks so if, like me, you still have links to it then you don’t have long to replace them with archived copies before it gets significantly more difficult.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>It’s the last day of classes for the winter quarter here at UCI, and a good time for some spring cleaning of old bookmarked links. Probably also a good time for a reminder that Google+ is shutting down in two weeks so if, like me, you still have links to it then you don’t have long to replace them with archived copies before it gets significantly more difficult.</p>

<ul>
  <li>
    <p><a href="https://www.universityofcalifornia.edu/press-room/uc-terminates-subscriptions-worlds-largest-scientific-publisher-push-open-access-publicly">The University of California cancels its subscriptions to Elsevier journals after failing to agree on open access</a> (<a href="https://mathstodon.xyz/@11011110/101672959195728560"/>). I support this decision, but it means that new papers in Elsevier journals will be harder for me to read. (I will still have access to pre-2019 papers.) More recently, <a href="https://www.insidehighered.com/quicktakes/2019/03/13/norwegian-universities-ditch-elsevier">Norway has also cancelled its subscriptions</a>.</p>
  </li>
  <li>
    <p>My keyboard needed replacement but fortunately the <a href="https://www.apple.com/support/keyboard-service-program-for-macbook-and-macbook-pro/">Apple Keyboard Service Program</a> came through (<a href="https://mathstodon.xyz/@11011110/101683848227213394"/>).</p>

    <p style="text-align: center;"><img alt="Broken MacBook Pro Keyboard" src="https://www.ics.uci.edu/~eppstein/pix/keyboard/keyboard-m.jpg" style="border-style: solid; border-color: black;"/></p>
  </li>
  <li>
    <p><a href="https://inference-review.com/article/a-crisis-of-identification">A crisis of identification</a> (<a href="https://mathstodon.xyz/@11011110/101689960199735892"/>, <a href="https://thehighergeometer.wordpress.com/2019/03/02/something-i-wrote/">via</a>). David Roberts summarizes the state of play in the claimed proof of the <a href="https://en.wikipedia.org/wiki/abc_conjecture"> conjecture</a>. The linked site, <em>Inference Review</em>, looks like an interesting platform for <a href="https://inference-review.com/topic/mathematics/">essays on mathematics</a>.</p>
  </li>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/Plan_S">Plan S</a> is a push for funding agencies to require research to be open access. While it’s no surprise that <a href="https://www.insidehighered.com/news/2019/02/19/publishers-express-concern-about-unintended-consequences-plan-s">publishers would push back</a>, there are concerns from the side of open access “that the technical requirements are too high and will result in only large, well-funded publishers and repositories to become compliant”. See the opinions from the <a href="https://euro-math-soc.eu/news/19/02/8/feedback-ems-implementation-plan-s">European Mathematical Society</a>, <a href="https://blogs.cornell.edu/arxiv/2019/02/04/arxivs-feedback-on-the-guidance-on-the-implementation-of-plan-s/">arXiv</a>, and <a href="https://www.coar-repositories.org/news-media/coar-feedback-on-the-guidance-on-implementation-of-plan-s/">Confederation of Open Access Repositories</a> (<a href="https://mathstodon.xyz/@11011110/101699226916200843"/>).</p>
  </li>
  <li>
    <p><a href="https://arstechnica.com/science/2019/03/nasa-visualizes-supersonic-shockwaves-in-a-new-awe-inspiring-way/">Visualization of the shockwaves created by supersonic aircraft</a> (<a href="https://mathstodon.xyz/@11011110/101704826218861968"/>), created by NASA using aerial <a href="https://en.wikipedia.org/wiki/Schlieren_photography">schlieren photography</a> and stunt piloting.</p>
  </li>
  <li>
    <p>I’m currently preparing a couple of papers, in the LaTeX format for the <a href="https://www.dagstuhl.de/publikationen/lipics/">LIPIcs computer science conference proceedings series</a>. I’ve written here before about <a href="https://11011110.github.io/blog/2018/05/25/lipics-autoref-lemma.html">the trickery needed to get the hyperref package and autoref macro to work in LIPIcs</a>. Now, finally, with the v2019 version of LIPIcs format, it’s much easier: just add [autoref] to the options in the documentclass. Why they don’t turn this on by default is beyond me (<a href="https://mathstodon.xyz/@11011110/101705996579583347"/>).</p>
  </li>
  <li>
    <p><a href="http://digg.com/2019/straight-line-uk-to-new-zealand">Today we learned you can sail in a straight line from the UK to New Zealand</a> (<a href="https://mathstodon.xyz/@jhertzli/101558721134407781"/>).</p>
  </li>
  <li>
    <p><a href="https://mathscinet.ams.org/mathscinet-getitem?mr=3791763">László Szabó reviews my book for MathSciNet</a> (<a href="https://mathstodon.xyz/@11011110/101718165708839697"/>, subscription required).</p>
  </li>
  <li>
    <p><a href="https://doi.org/10.1080/00029890.2019.1535735">Cantarella, Needham, Shonkwiler, and Stewart write in the <em>Monthly</em> about an interesting smooth probability distribution on the shapes of triangles</a> (<a href="https://mathstodon.xyz/@shonk/101723146578421634"/>).</p>
  </li>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/Sums_of_three_cubes">Sums of three cubes</a> (<a href="https://mathstodon.xyz/@11011110/101725333452262574"/>, <a href="https://gilkalai.wordpress.com/2019/03/09/8866128975287528%C2%B3-8778405442862239%C2%B3-2736111468807040%C2%B3/">via</a>), a notoriously hard Diophantine equation for which <a href="https://people.maths.bris.ac.uk/~maarb/papers/cubesv1.pdf">Andrew Booker has found</a> the new solution</p>

    

    <p>But don’t listen to Stephen Wolfram when he tells you that <a href="https://www.wolframscience.com/nks/p789--implications-for-mathematics-and-its-foundations/">the simplest representation for </a> is</p>

    
  </li>
  <li>
    <p><a href="https://hungarytoday.hu/mta-head-minister-sign-letter-of-intent-on-future-of-academy-research-network/">László Lovász has agreed to allow the  researchers of the Hungarian Academy of Sciences (MTA) to be separated from the academy itself</a> (<a href="https://mathstodon.xyz/@11011110/101735747787440743"/>). And <a href="https://www.chronicle.com/blogs/letters/open-letter-to-the-president-of-the-hungarian-academy-of-sciences-laszlo-lovasz/">an open letter</a> asks him to resist pressure from the Hungarian government to dismantle the MTA’s research centers and place researchers under “direct political control”. I don’t know enough to tell whether his agreement is resistance or a concession, but it warrants continued attention.</p>
  </li>
  <li>
    <p><a href="https://www.youtube.com/watch?v=imfqczglelI">Vi Hart’s -day video</a> (<a href="https://mathstodon.xyz/@11011110/101753216836690906"/>) conveys what I feel about the significance of random concatenations of digits. <a href="https://mathstodon.xyz/@andrewt">Andrew Taylor’s</a> Aperiodical piece on <a href="https://aperiodical.com/2019/03/buzz-in-when-you-think-you-know-the-answer/">average numbers of representations as sums of squares</a> is good too.</p>
  </li>
  <li>
    <p><a href="https://www.quantamagazine.org/math-duo-maps-the-infinite-terrain-of-minimal-surfaces-20190312/"><em>Quanta</em> on the work of Fernando Codá Marques and André Neves on the existence of minimal surfaces within arbitrary geometric manifolds</a> (<a href="https://mathstodon.xyz/@11011110/101758577189877053"/>). The vague non-technical language is a little frustrating but I think that’s what they mean by “shape”.</p>
  </li>
</ul></div>
    </content>
    <updated>2019-03-15T22:53:00Z</updated>
    <published>2019-03-15T22:53:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-03-20T07:21:58Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4147</id>
    <link href="https://www.scottaaronson.com/blog/?p=4147" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4147#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4147" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Can we reverse time to before this hypefest started?</title>
    <summary xml:lang="en-US">The purpose of this post is mostly just to signal-boost Konstantin Kakaes’s article in MIT Technology Review, entitled “No, scientists didn’t just ‘reverse time’ with a quantum computer.” The title pretty much says it all—but if you want more, you should read the piece, which includes the following droll quote from some guy calling himself […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>The purpose of this post is mostly just to signal-boost Konstantin Kakaes’s article in MIT <em>Technology Review</em>, entitled <a href="https://www.technologyreview.com/s/613123/no-ibm-didnt-just-reverse-time-with-a-quantum-computer/">“No, scientists didn’t just ‘reverse time’ with a quantum computer.”</a>  The title pretty much says it all—but if you want more, you should read the piece, which includes the following droll quote from some guy calling himself “Director of the Quantum Information Center at the University of Texas at Austin”:</p>



<blockquote class="wp-block-quote"><p>If you’re simulating a time-reversible process on your computer, then you can ‘reverse the direction of time’ by simply reversing the direction of your simulation. From a quick look at the paper, I confess that I didn’t understand how this becomes more profound if the simulation is being done on IBM’s quantum computer.</p></blockquote>



<p>Incredibly, the time-reversal claim has now gotten uncritical attention in <em>Newsweek</em>, <em>Discover</em>, <em>Cosmopolitan</em>, my Facebook feed, and elsewhere—hence this blog post, which has basically no content except “the claim to have ‘reversed time,’ by running a simulation backwards, is exactly as true and as earth-shattering as a layperson might think it is.”</p>



<p>If there’s anything interesting here, I suppose it’s just that “scientists use a quantum computer to reverse time” is one of the purest examples I’ve ever seen of a scientific claim that basically amounts to a mind-virus or meme optimized for sharing on social media—discarding all nontrivial “science payload” as irrelevant to its propagation. </p></div>
    </content>
    <updated>2019-03-15T18:49:20Z</updated>
    <published>2019-03-15T18:49:20Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Quantum"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Rage Against Doofosity"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2019-03-15T21:30:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=17124</id>
    <link href="https://gilkalai.wordpress.com/2019/03/15/news-on-fractional-helly-colorful-helly-and-radon/" rel="alternate" type="text/html"/>
    <title>News on Fractional Helly, Colorful Helly, and Radon</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">My 1983 Ph D thesis was on Helly-type theorems which is an exciting part of discrete geometry and, in the last two decades, I have had an ongoing research project with Roy Meshulam on topological Helly-type theorems. The subject found … <a href="https://gilkalai.wordpress.com/2019/03/15/news-on-fractional-helly-colorful-helly-and-radon/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>My 1983 Ph D thesis was on Helly-type theorems which is an exciting part of discrete geometry and, in the last two decades, I have had an ongoing research project with Roy Meshulam on topological Helly-type theorems. The subject found new connections with structural graph theory and <span class="abstract-full has-text-grey-dark mathjax" id="1903.00245v1-abstract-full">Gyárfás-type problems, and also with high-dimensional expanders. </span> We already devoted quite a few posts directly and indirectly to Helly-type theorems.</p>
<p>In this post I would like to report on two recent related breakthroughs, <a href="https://arxiv.org/abs/1903.01068">one by Andreas Holmsen and Dong-Gyu Lee</a>, and the other <a href="https://arxiv.org/abs/1903.00245">by Andreas Holmsen</a>. These developments are related to problems that are described in <a href="https://gilkalai.files.wordpress.com/2017/05/imre.pdf">Problems for Imre Bárány’s birthday,</a> and to my earlier 2004 Oberwolfach report “<a href="https://gilkalai.files.wordpress.com/2019/03/ow04.pdf">Expectations from commutative algebra</a>“. While at it I will mention some earlier important papers <a href="https://arxiv.org/abs/1402.3413">by Pauline <span class="content"><span class="text surname">Sarrabezolles</span></span></a>, <a href="https://arxiv.org/abs/1707.05381">by Shay Moran and Amir Yehudayoff</a>, and <a href="https://arxiv.org/abs/1009.2384">by Boris Bukh</a>.</p>
<h3>Helly theorem, colorful Helly, and the Fractional Helly Theorem.</h3>
<p>You can find the statements of Helly theorem, Radon theorem, and the colorful Caratheodory theorem in <a href="https://gilkalai.wordpress.com/2008/11/24/sarkarias-proof-of-tverbergs-theorem-1/">this post</a>.  The colorful Helly theorem was first observed by Lovasz. The fractional Helly theorem was first proved by Katchalski and Liu.</p>
<p><strong>The colorful Helly theorem:</strong> Let <img alt="{\cal K}_1, {\cal K}_2, \dots, {\cal K}_{d+1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+K%7D_1%2C+%7B%5Ccal+K%7D_2%2C+%5Cdots%2C+%7B%5Ccal+K%7D_%7Bd%2B1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{\cal K}_1, {\cal K}_2, \dots, {\cal K}_{d+1}"/> be <img alt="d+1" class="latex" src="https://s0.wp.com/latex.php?latex=d%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d+1"/> nonempty families of convex sets in <img alt="\mathbb R^d" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb R^d"/>. If for every choice of a <em>transversal</em> – one set from every family – there is a point in common to all the chosen sets then for one of the families, there is a point in common to all sets in the family.</p>
<p>[Sorry, I got it wrong first, thanks to Shakhar Smorodinsky for alerting me.<del><span style="color: #555555;"><span style="text-decoration: line-through;">]</span></span></del></p>
<p><strong>The fractional Helly theorem:</strong> For every <img alt="\alpha &gt;0" class="latex" src="https://s0.wp.com/latex.php?latex=%5Calpha+%3E0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\alpha &gt;0"/> there is <img alt="\beta &gt;0" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbeta+%3E0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\beta &gt;0"/> such that if <img alt="K_1,K_2,\dots, K_n" class="latex" src="https://s0.wp.com/latex.php?latex=K_1%2CK_2%2C%5Cdots%2C+K_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K_1,K_2,\dots, K_n"/> are <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> convex sets in <img alt="\mathbb R^d" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb R^d"/> and at least <img alt="\alpha" class="latex" src="https://s0.wp.com/latex.php?latex=%5Calpha&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\alpha"/> fraction of <img alt="(d+1)" class="latex" src="https://s0.wp.com/latex.php?latex=%28d%2B1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(d+1)"/>-tuples of the sets have a point in common then a fraction of at least <img alt="\beta" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbeta&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\beta"/> of the sets have a point in common.</p>
<p>I should mention that these theorems do not follow combinatorially from Helly’s theorem itself. They manifest deep properties of hypergraphs coming from geometry, and it is an important question to give general abstract properties, combinatorial or topological leading to such properties.</p>
<p>The result of Holmsen and Lee asserts roughly that the fractional Helly property follows combinatorially from Radon’s theorem! Holmsen’s result asserts that  the fractional Helly property follows combinatorially from the colorful Helly theorem!</p>
<h2>Andreas Holmsen Dong-Gyu Lee: Fractional Helly from Radon</h2>
<p><a href="https://arxiv.org/abs/1903.01068">Radon numbers and the fractional Helly theorem</a></p>
<p>Authors: Andreas Holmsen Dong-Gyu Lee</p>
<p><strong>Abstract:</strong> A basic measure of the combinatorial complexity of a convexity space is its Radon number. In this paper we show a fractional Helly theorem for convexity spaces with a bounded Radon number, answering a question of Kalai. As a consequence we also get a weak epsilon-net theorem for convexity spaces with a bounded Radon number. This answers a question of Bukh and extends a recent result of Moran and Yehudayoff.</p>
<h2>Andreas Holmsen: Fractional Helly follows from colorful Helly</h2>
<p class="title is-5 mathjax"><a href="https://arxiv.org/abs/1903.00245">Large cliques in hypergraphs with forbidden substructures</a></p>
<p class="authors"><span class="search-hit">Author:</span> Andreas F. Holmsen</p>
<p><strong>Abstract: </strong>A result due to Gyárfás, Hubenko, and Solymosi (answering a question of Erdös) states that if a graph G on n vertices does not contain <img alt="K_{2,2}" class="latex" src="https://s0.wp.com/latex.php?latex=K_%7B2%2C2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K_{2,2}"/> as an induced subgraph yet has at least <img alt="c{{n} \choose {2}}" class="latex" src="https://s0.wp.com/latex.php?latex=c%7B%7Bn%7D+%5Cchoose+%7B2%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c{{n} \choose {2}}"/> edges, then G has a complete subgraph on at least <img alt="c^2/10n" class="latex" src="https://s0.wp.com/latex.php?latex=c%5E2%2F10n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c^2/10n"/> vertices. In this paper we suggest a “higher-dimensional” analogue of the notion of an induced <img alt="K_{2,2}" class="latex" src="https://s0.wp.com/latex.php?latex=K_%7B2%2C2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K_{2,2}"/> which allows us to generalize their result to k-uniform hypergraphs. Our result also has an interesting consequence in discrete geometry. In particular, it implies that the fractional Helly theorem can be derived as a purely combinatorial consequence of the colorful Helly theorem.</p>
<p> </p>
<p><span class="abstract-full has-text-grey-dark mathjax" id="1903.00245v1-abstract-full">Let me mention that Gyárfás’ type problems in graph theory and a little on the connection with fractional Helly were mentioned in the post <a href="https://gilkalai.wordpress.com/2014/12/19/when-a-few-colors-suffice/">When a few colors suffice</a>. On this front major advances has happened in a series of recent papers and I will discuss them at a later post. (But, for now see, Alex Scott and Paul Seymour’s <a href="https://arxiv.org/abs/1812.07500">A survey of <span class="MathJax" id="MathJax-Element-44-Frame"><span class="math" id="MathJax-Span-232"><span class="mrow" id="MathJax-Span-233"><span class="texatom" id="MathJax-Span-234"><span class="mrow" id="MathJax-Span-235"><span class="mo" id="MathJax-Span-236">χ</span></span></span></span></span></span>-boundedness</a>, and <a href="https://arxiv.org/abs/1810.00065">Proof of the Kalai-Meshulam conjecture</a> by Maria Chudnovsky, Alex Scott, Paul Seymour, Sophie Spirkl.)</span></p>
<h2><span class="content"><span class="text given-name">Pauline </span><span class="text surname">Sarrabezolles: The number of tranversals in the colorful Helly theorem</span></span></h2>
<p><span id="more-17124"/></p>
<p>How many tranversals can we guarantee in colorful Carathéodory? This is a very interesting problem on its own, and may be also related to Sierksma’s conjecture on the number of Tverberg’s partitions that we mentioned in <a href="https://gilkalai.wordpress.com/2019/02/16/attila-pors-universality-result-for-tverberg-partitions/">this recent post</a> (and in this <a href="https://gilkalai.wordpress.com/2008/12/23/seven-problems-around-tverbergs-theorem/">old one</a>).</p>
<p><a href="https://arxiv.org/abs/1402.3413"><span dir="ltr">The colourful simplicial depth conjecture</span></a> (2014)</p>
<p><span class="content"><span class="text given-name">Pauline </span><span class="text surname">Sarrabezolles</span></span></p>
<p><strong>Abstract:</strong><br/>
Given d+1 sets of points, or colours, <img alt="S_1,\dots ,S_{d+1}" class="latex" src="https://s0.wp.com/latex.php?latex=S_1%2C%5Cdots+%2CS_%7Bd%2B1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S_1,\dots ,S_{d+1}"/> in <img alt="\mathbb R ^d" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R+%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb R ^d"/>, a colourful simplex is a set <img alt="T\subset \cup _{i=1}^{d+1}S_i" class="latex" src="https://s0.wp.com/latex.php?latex=T%5Csubset+%5Ccup+_%7Bi%3D1%7D%5E%7Bd%2B1%7DS_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T\subset \cup _{i=1}^{d+1}S_i"/> such that |T∩Si|≤1, for all i∈{1,…,d+1}. The colourful Carathéodory theorem states that, if 0 is in the convex hull of each <img alt="S_i" class="latex" src="https://s0.wp.com/latex.php?latex=S_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S_i"/>, then there exists a colourful simplex T containing 0 in its convex hull. Deza, Huang, Stephen, and Terlaky (Colourful simplicial depth, Discrete Comput. Geom., 35, 597–604 (2006)) conjectured that, when <img alt="|S_i|=d+1" class="latex" src="https://s0.wp.com/latex.php?latex=%7CS_i%7C%3Dd%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|S_i|=d+1"/> for all i∈{1,…,d+1}, there are always at least <img alt="d^2+1" class="latex" src="https://s0.wp.com/latex.php?latex=d%5E2%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d^2+1"/> colourful simplices containing 0 in their convex hulls. We prove this conjecture via a combinatorial approach.</p>
<p class="title mathjax"><a href="https://arxiv.org/abs/1707.05381">On weak <span class="MathJax" id="MathJax-Element-1-Frame"><span class="math" id="MathJax-Span-1"><span class="mrow" id="MathJax-Span-2"><span class="texatom" id="MathJax-Span-3"><span class="mrow" id="MathJax-Span-4"><span class="mo" id="MathJax-Span-5">ε</span></span></span></span></span></span>-nets and the Radon number</a> (2017)</p>
<p>Shay Moran, Amir Yehudayoff</p>
<p><strong>Abstract: </strong>We show that the Radon number characterizes the existence of weak nets in separable convexity spaces (an abstraction of the euclidean notion of convexity). The construction of weak nets when the Radon number is finite is based on Helly’s property and on metric properties of VC classes. The lower bound on the size of weak nets when the Radon number is large relies on the chromatic number of the Kneser graph. As an application, we prove a boosting-type result for weak <span class="MathJax" id="MathJax-Element-2-Frame"><span class="math" id="MathJax-Span-6"><span class="mrow" id="MathJax-Span-7"><span class="mi" id="MathJax-Span-8">ϵ</span></span></span></span>-nets.</p>
<h2>Boris Bukh: Beyond nerves, the abstract setting for the disproof of the partition conjecture</h2>
<p>We already mentioned Boris Bukh’s beautiful counter example to Eckhoff’s partition conjecture in the 2010 paper <a href="https://arxiv.org/abs/1009.2384">Radon partitions in convexity spaces</a>.  Let me mention a general object used by Boris which is of much independent interest.</p>
<p>Let <img alt="A=\{a_1,a_2,\dots, a_n\}" class="latex" src="https://s0.wp.com/latex.php?latex=A%3D%5C%7Ba_1%2Ca_2%2C%5Cdots%2C+a_n%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A=\{a_1,a_2,\dots, a_n\}"/> be a set of points in <img alt="\mathbb R^d" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb R^d"/>. For <img alt="S \subset [n]" class="latex" src="https://s0.wp.com/latex.php?latex=S+%5Csubset+%5Bn%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S \subset [n]"/> let <img alt="A_S=conv \{a_i: i \in S\}" class="latex" src="https://s0.wp.com/latex.php?latex=A_S%3Dconv+%5C%7Ba_i%3A+i+%5Cin+S%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_S=conv \{a_i: i \in S\}"/>, and let <img alt="N" class="latex" src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N"/> be the nerve of all the sets <img alt="A_S: S \subset [n]" class="latex" src="https://s0.wp.com/latex.php?latex=A_S%3A+S+%5Csubset+%5Bn%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_S: S \subset [n]"/>. <img alt="N" class="latex" src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N"/> is a simplicial complex whose vertices are indexed by all non empty subsets of <img alt="[n]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Bn%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="[n]"/>. The abstract setting we have here is that of a simplicial complex, whose vertices are indexed by all subsets of <img alt="[n]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Bn%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="[n]"/> and such that a collection of vertices which represent a family of subsets with non empty intersection must be a face of the complex.</p></div>
    </content>
    <updated>2019-03-15T13:29:06Z</updated>
    <published>2019-03-15T13:29:06Z</published>
    <category term="Combinatorics"/>
    <category term="Convexity"/>
    <category term="Amir Yehudayoff"/>
    <category term="Andreas Holmsen"/>
    <category term="Boris Bukh"/>
    <category term="Colorful Helly theorem"/>
    <category term="Dong-Gyu Lee"/>
    <category term="fractional Helly theorem"/>
    <category term="Helly type theorems"/>
    <category term="Pauline Sarrabezolles"/>
    <category term="Radon's theorem"/>
    <category term="Shay Moran"/>
    <category term="Tverberg's theorem"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-03-26T04:20:33Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>http://corner.mimuw.edu.pl/?p=1071</id>
    <link href="http://corner.mimuw.edu.pl/?p=1071" rel="alternate" type="text/html"/>
    <title>How to identify m numbers using m/log m checks</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Here's an old trick that we found useful for proving some tight complexity lower bounds. You are given m coins, each of weight either a or b, and a modern scale that can tell you the total weight of any chosen … <a href="http://corner.mimuw.edu.pl/?p=1071">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><!-- wp:paragraph --></p>
<p>Here's an old trick that we found useful for proving some tight complexity lower bounds. You are given <em>m</em> coins, each of weight either <em>a</em> or <em>b</em>, and a modern scale that can tell you the total weight of any chosen subset of coins. How many weighings do you need to identify which coin is which? Checking each coin individually uses <em>m</em> weighings, but can you do less?</p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:paragraph --></p>
<p>In any weighing, we try some unknown number of weight-<em>a</em> coins between 0 and <em>m</em>, so this results in one of <em>m</em> + 1 possible values, giving us at most log(<em>m</em> + 1) bits of information. In total we need m bits of information to identify each coin, so clearly we will need at least Ω(<em>m</em> / log <em>m</em>) weighings.</p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:paragraph --></p>
<p>It turns out that this many is in fact enough, and this generalizes to various other settings with less restricted weights. This is the basis for two of our recent results: a tight complexity lower bound for Integer Linear Programming with few constraints and for multicoloring (a.k.a. <a href="https://en.wikipedia.org/wiki/Fractional_coloring#Definitions">b-fold coloring</a>), assuming the Exponential Time Hypothesis. The trick allows us to use constraints that check the value of some number between 0 and <em>m</em> to indeed extract about log(<em>m</em>) bits of new information from each, in a way that is general enough to check <em>m</em> clauses of a 3-CNF-SAT instance using only <em>O</em>(<em>m</em> / log <em>m</em>) constraints.</p>
<p><span id="more-1071"/></p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:heading --></p>
<h2>Detecting matrices</h2>
<p><!-- /wp:heading --></p>
<p><!-- wp:paragraph --></p>
<p>One way to rephrase this coin-weighing problem is as follows: the unknown coin weights are described by a (column) vector <em>x</em> in {<em>a</em>,<em>b</em>}<sup><em>m</em></sup>. A subset of coins is described by a characteristic (row) vector <em>v</em> in {0,1}<sup><em>m</em></sup> and the resulting value of the weighing is the dot product <em>v</em> <strong>·</strong> <em>x</em>.</p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:paragraph --></p>
<p>For a number of weighings <em>k</em>, the row vectors form a 0-1 matrix <em>M</em> with <em>k</em> rows and <em>m</em> columns, while the obtained values are simply the <em>k</em>-element vector <em>M x</em>. The condition that these values are enough to identify each entry of <em>x</em> is formalized as follows:</p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:paragraph {"align":"center"} --></p>
<p style="text-align: center;">For all <em>m</em>, there is a 0-1 matrix <em>M</em> with k=<em>O</em>(<em>m</em> / log <em>m</em>) rows and <em>m</em> columns<br/>
such that for any <em>x</em>, <em>y</em> in {<em>a</em>,<em>b</em>}<sup><em>m</em></sup>, x ≠ y implies <em>M x</em> ≠ <em>M y</em>.</p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:paragraph --></p>
<p>This is called a <em>detecting matrix</em>. In other words, instead of checking x = y entry by entry, it suffices to compare the k entries of M x and M y. (An equivalent definition is to require that the kernel of <em>M</em> is trivial on {-1,0,1}<sup><em>m</em></sup>, since we could instead compare (<em>x</em> - <em>y</em>)/(<em>a</em> - <em>b</em>) with zero). A generalization for <em>x</em>, <em>y</em> in {0, 1, …, <em>d</em> - 1}<sup><em>m</em></sup> was first proved by <a href="https://doi.org/10.4153/CMB-1965-034-2">(Lindström 1965)</a> (in fact he proves the constant hidden behind <em>O</em> is 2 log<sub>2</sub>(<em>d</em>) and cannot be improved, for any <em>d</em>), giving a deterministic, poly-time construction. <a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.162.2327">(Bshouty 2009)</a> gives a more direct and general construction using Fourier analysis. However, a random matrix can be shown to be detecting with fairly elementary methods.</p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:heading --></p>
<h2>Integer Linear Programming</h2>
<p><!-- /wp:heading --></p>
<p><!-- wp:paragraph --></p>
<p>In ILP we are given a matrix <em>A</em> with <em>n</em> columns and <em>m</em> rows, a vector <em>b</em> with <em>m</em> entries, and we ask for a vector <em>x</em> with <em>n</em> non-negative integer entries such that <em>A x</em> = <em>b</em>. So each of the <em>m</em> rows is a linear equality to be satisfied. What is the complexity for small <em>m</em>?</p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:paragraph --></p>
<p>We start with an instance <em>A x</em> = <em>b</em> encoding a suitable 3-CNF-SAT instance of size <em>O</em>(<em>m</em>) in a straightforward way, using only {0,1,2,3} entries in <em>A</em> and <em>b</em>. Instead of checking each row individually, we use detecting matrices to check them in bunches, reducing our problem to an equivalent instance <em>M A x</em> = <em>M b</em>. The matrix <em>M A </em>of the new instance has only O(<em>m</em> / log <em>m</em>) rows (at the cost of having larger entries in <em>M b</em>). With some tinkering, this simple reduction shows that, assuming ETH, ILP with <em>m</em> constraints cannot be solved in time 2<sup><em>o</em>(<em>m</em> log <em>m</em>)</sup>, even when the matrix has only 0-1 entries and <em>b</em> has poly(<em>m</em>) entries. This matches a recent (surprisingly simple and clever!) 2<sup><em>O</em>(<em>m</em> log <em>m</em>)</sup> algorithm by <a href="https://dl.acm.org/citation.cfm?id=3175322">Eisenbrand and Weismantel (SODA 2018)</a>.</p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:paragraph --></p>
<p>One caveat when applying detecting matrices is that we do not know any bound on one side, <em>A x</em>, except that it is a non-negative integer vector. Fortunately, <a href="https://doi.org/10.1007/s004530010033">(Grebinsky &amp; Kucherov 2000)</a> showed that a random 0-1 matrix satisfies the following:</p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:paragraph {"align":"center"} --></p>
<p style="text-align: center;">For all <em>d</em>,<em>m</em>, there is a 0-1 matrix <em>M</em> with k=<em>O</em>(<em>m</em> <em>log</em> <em>d</em> / log <em>m</em>) rows and <em>m</em> columns<br/>
such that for any <em>x</em>, <em>y</em> in ℕ<sup><em>m</em></sup> with ‖<em>y</em>‖<sub>1</sub> ≤ <em>d</em> <em>m</em>, x ≠ y implies <em>M x</em> ≠ <em>M y</em>.</p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:paragraph --></p>
<p>Here no upper bound on <em>x</em> is needed, because a single row in <em>M</em> full of ones is enough to guarantee that the sum of entries is the same: ‖<em>x</em>‖<sub>1</sub> = ‖<em>y</em>‖<sub>1</sub>. However, it remains an open problem to find a deterministic construction (we work around this by giving a somewhat weaker construction). See <a href="https://arxiv.org/pdf/1811.01296.pdf">the full paper (STACS 2019)</a> for details (with Dušan Knop and Michał Pilipczuk). The reduction for <em>multicoloring</em> is quite different and more problem-specific, see <a href="https://arxiv.org/abs/1607.03432">the full paper (ESA 2017)</a> for definitions (with Marthe Bonamy, Łukasz Kowalik, Michał Pilipczuk and Arkadiusz Socała).</p>
<p> </p>
<p><em>Marcin Wrochna</em></p>
<p><!-- /wp:paragraph --></p></div>
    </content>
    <updated>2019-03-15T08:59:51Z</updated>
    <published>2019-03-15T08:59:51Z</published>
    <category term="post"/>
    <author>
      <name>Renata Czarniecka</name>
    </author>
    <source>
      <id>http://corner.mimuw.edu.pl</id>
      <link href="http://corner.mimuw.edu.pl/?feed=rss2" rel="self" type="application/atom+xml"/>
      <link href="http://corner.mimuw.edu.pl" rel="alternate" type="text/html"/>
      <subtitle>University of Warsaw</subtitle>
      <title>Banach's Algorithmic Corner</title>
      <updated>2019-03-25T23:33:47Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2019/03/14/summer-school-on-artificial-intelligence/</id>
    <link href="https://cstheory-events.org/2019/03/14/summer-school-on-artificial-intelligence/" rel="alternate" type="text/html"/>
    <title>Summer School on Artificial Intelligence</title>
    <summary>July 4-7, 2019 Moscow, Russia http://school-raai.org/ RAAI Summer School is a 4-day school with tutorials and practical workshops on: Machine Learning and Data Analysis Simulation of Human Cognitive Functions Natural Language Processing Multi-Agent Systems and Coalitions Together with the school, there will be a hackathon in reinforcement learning using computer vision tasks.</summary>
    <updated>2019-03-14T18:44:36Z</updated>
    <published>2019-03-14T18:44:36Z</published>
    <category term="school"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2019-03-26T04:21:10Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://tcsplus.wordpress.com/?p=343</id>
    <link href="https://tcsplus.wordpress.com/2019/03/14/tcs-talk-wednesday-march-20th-aleksandar-nikolov-university-of-toronto/" rel="alternate" type="text/html"/>
    <title>TCS+ talk: Wednesday, March 20th, Aleksandar Nikolov, University of Toronto</title>
    <summary>The next TCS+ talk will take place this coming Wednesday, March 20th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 18:00 Central European Time, 17:00 UTC). Aleksandar Nikolov from University of Toronto will speak about “Sticky Brownian Rounding and its Applications to Constraint Satisfaction Problems” (abstract below). Please make sure you reserve a spot […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The next TCS+ talk will take place this coming Wednesday, March 20th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 18:00 Central European Time, 17:00 UTC). <strong>Aleksandar Nikolov</strong> from University of Toronto will speak about “<em>Sticky Brownian Rounding and its Applications to Constraint Satisfaction Problems</em>” (abstract below).</p>
<p>Please make sure you reserve a spot for your group to join us live by signing up on <a href="https://sites.google.com/site/plustcs/livetalk/live-seat-reservation">the online form</a>. As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/site/plustcs/suggest">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/site/plustcs/">the website</a>.</p>
<blockquote><p>Abstract: Semidefinite programming is a powerful tool in the design and analysis of approximation algorithms for combinatorial optimization problems. In particular, the random hyperplane rounding method of Goemans and Williamson has been extensively studied for more than two decades, resulting in various extensions to the original technique and beautiful algorithms for a wide range of applications. Despite the fact that this approach yields tight approximation guarantees for some problems, like Max Cut, for many others, like Max Sat, Max DiCut, and constraint satisfaction problems with global constraints, the tight approximation ratio is still unknown. One of the main reasons for this is the fact that very few techniques for rounding semi-definite relaxations are known.</p>
<p>In this work, we present a new general and simple method for rounding semi-definite programs, based on Brownian motion. Our approach is inspired by recent results in algorithmic discrepancy theory. We develop and present tools for analyzing our new rounding algorithms, utilizing mathematical machinery from the theory of Brownian motion, complex analysis, and partial differential equations. Focusing on constraint satisfaction problems, we apply our method to several classical problems, including Max Cut, Max 2-Sat, and Max DiCut, and derive new algorithms that are competitive with the best known results. We further show that our algorithms can be used, together with the Sum of Squares hierarchy, to approximate constraint satisfaction problems subject to multiple global cardinality constraints.</p>
<p>Join work with Sepehr Abbasi-Zadeh, Nikhil Bansal, Guru Guruganesh, Roy Schwartz, and Mohit Singh</p></blockquote>
<p> </p></div>
    </content>
    <updated>2019-03-14T16:30:42Z</updated>
    <published>2019-03-14T16:30:42Z</published>
    <category term="Announcements"/>
    <author>
      <name>plustcs</name>
    </author>
    <source>
      <id>https://tcsplus.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://tcsplus.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://tcsplus.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://tcsplus.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://tcsplus.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A carbon-free dissemination of ideas across the globe.</subtitle>
      <title>TCS+</title>
      <updated>2019-03-26T04:21:08Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-7275002484261338073</id>
    <link href="https://blog.computationalcomplexity.org/feeds/7275002484261338073/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/03/captain-einstein.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7275002484261338073" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7275002484261338073" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/03/captain-einstein.html" rel="alternate" type="text/html"/>
    <title>Captain Einstein</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">If the president of the United States uses "complexity" in a tweet, I can't leave it alone.<br/>
<blockquote class="twitter-tweet">
<div dir="ltr" lang="en">
Airplanes are becoming far too complex to fly. Pilots are no longer needed, but rather computer scientists from MIT. I see it all the time in many products. Always seeking to go one unnecessary step further, when often old and simpler is far better. Split second decisions are....</div>
— Donald J. Trump (@realDonaldTrump) <a href="https://twitter.com/realDonaldTrump/status/1105468569800839169?ref_src=twsrc%5Etfw">March 12, 2019</a></blockquote>


<br/>
<blockquote class="twitter-tweet">
<div dir="ltr" lang="en">
....needed, and the complexity creates danger. All of this for great cost yet very little gain. I don’t know about you, but I don’t want Albert Einstein to be my pilot. I want great flying professionals that are allowed to easily and quickly take control of a plane!</div>
— Donald J. Trump (@realDonaldTrump) <a href="https://twitter.com/realDonaldTrump/status/1105471621672960000?ref_src=twsrc%5Etfw">March 12, 2019</a></blockquote>
I got my MIT degree in Applied Mathematics so I don't count, but I know plenty of MIT computer scientists and the one undeniable truth is that I don't want any of them flying my plane.<br/>
<br/>
I also agree with the Donald that a complex environment can often lead to confusion, especially in an emergency. HCI matters.<br/>
<br/>
But that's where it stops. Better technology in the plane and on the ground, combined with better procedures have all but eliminated deadly major commercial airplane crashes in the US and quite rare in the world at large. I'll call that more than a "little gain". I remember the "old and simpler" days where we had deadly airline crashes every few months. No thanks.<br/>
<br/>
I've had great discussions with some of the aerospace engineering professors at Georgia Tech. The amount of effort to get the "front-of-the-plane" software right via formal methods and rigorous testings has become harder to engineer than the plane itself. The "back-of-the-plane" software that controls the video screens and WiFi gets less attention. I can live with safety over movies.<br/>
<br/>
When technology makes things much safer, whether it be planes or self-driving cars, the rare accidents become far more noticeable. while we should use these opportunities to learn and make things safer, the rare accidents help us realize just how much more safer technology can make us.<br/></div>
    </content>
    <updated>2019-03-14T14:08:00Z</updated>
    <published>2019-03-14T14:08:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>https://plus.google.com/101693130490639305932</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>https://plus.google.com/101693130490639305932</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-03-25T08:11:59Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-27705661.post-8733572122343010716</id>
    <link href="http://processalgebra.blogspot.com/feeds/8733572122343010716/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=27705661&amp;postID=8733572122343010716" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/8733572122343010716" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/8733572122343010716" rel="self" type="application/atom+xml"/>
    <link href="http://processalgebra.blogspot.com/2019/03/seven-phd-positions-in-cs-at-gssi.html" rel="alternate" type="text/html"/>
    <title>Seven PhD positions in CS at the GSSI</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><i>This call for PhD positions might be of interest to some of your students or you. Please distribute it as you see fit.  </i><br/><br/>The <a href="http://www.gssi.it/">GSSI - Gran Sasso Science Institute</a> offers seven PhD fellowships in Computer Science for the academic year 2019/20. One of those positions is earmarked for the development of efficient techniques and tools for the analysis of large genomic data and is supported by the genomic-research start-up <a href="https://www.dantelabs.com/" target="_blank">Dante Labs srl</a>.  The official language for all PhD courses is English.<br/><br/>The fellowships are awarded for 4 years and their yearly amount is € 16.159,91 gross. All PhD students have free accommodation at the GSSI facilities and use of the canteen.<br/><br/>The application must be submitted through the online form available <a href="http://www.gssi.it/phd/" target="_blank">here</a> by <b>18 June 2019 at 6 pm (Italian time zone). </b><br/><br/> The GSSI-Gran Sasso Science Institute is an international PhD school and a center for research and higher education in the areas of Physics, Mathematics, Computer Science and Social Sciences. Founded in 2012 in L’Aquila (Italy) as Center for Advanced Studies of the National Institute for Nuclear Physics (INFN) and then established in March 2016 as a School of Advanced Studies providing post-graduate education. Through a day-to-day collaboration and interaction, researchers and students have the opportunity to build a sound knowledge of the research methods and to experiment contamination of interests, innovative approaches and multicultural exchanges in all the GSSI activities. In addressing the complexity of today’s world, GSSI is committed to removing all barriers between its areas of study and research. The dissemination of scientific results towards society and the promotion of cultural events for generic public, citizens and schools are among GSSI goals.<br/><br/>See <a href="http://www.gssi.it/communication/news-events/item/5739-new-call-for-gssi-phd-applications-2019-20-now-open" target="_blank">here</a> for further details. </div>
    </content>
    <updated>2019-03-14T11:50:00Z</updated>
    <published>2019-03-14T11:50:00Z</published>
    <author>
      <name>Luca Aceto</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/01092671728833265127</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-27705661</id>
      <author>
        <name>Luca Aceto</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/01092671728833265127</uri>
      </author>
      <link href="http://processalgebra.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://processalgebra.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Papers I find interesting---mostly, but not solely, in Process Algebra---, and some fun stuff in Mathematics and Computer Science at large and on general issues related to research, teaching and academic life.</subtitle>
      <title>Process Algebra Diary</title>
      <updated>2019-03-21T09:08:26Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-27705661.post-2535811260434248745</id>
    <link href="http://processalgebra.blogspot.com/feeds/2535811260434248745/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=27705661&amp;postID=2535811260434248745" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/2535811260434248745" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/2535811260434248745" rel="self" type="application/atom+xml"/>
    <link href="http://processalgebra.blogspot.com/2019/03/fully-funded-four-year-phd-scholarships.html" rel="alternate" type="text/html"/>
    <title>Fully-funded four-year PhD scholarships at IMT Lucca</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><span class="im"/><br/><span class="im"/><br/><span class="im"><br/><a href="https://www.imtlucca.it/" target="_blank">IMT School for Advanced Studies Lucca</a> invites applications for PhD<br/>positions in the Systems Science program, and specifically for its Computer<br/>Science and Systems Engineering</span>&lt;<a href="https://www.imtlucca.it/en/programma-dottorato/anno-accademico-2019-20/systems-science/csse" rel="noreferrer" target="_blank">https://www.imtlucca.it/en/programma-dottorato/anno-accademico-2019-20/systems-science/csse</a>&gt;<span class="im"><br/>track.<br/><br/>We carry out foundational, applied, and interdisciplinary research on the<br/>modeling and analysis of systems, broadly construed. The SYSMA</span>&lt;<a href="http://sysma.imtlucca.it/" rel="noreferrer" target="_blank">http://sysma.imtlucca.it/</a>&gt; research unit welcomes applications from<span class="im"><br/>candidates in Computer Science with an interest in any of the following<br/>topics:<br/><br/>- cloud computing;<br/><br/>- computational methods for the analysis of cyber-physical systems;<br/><br/>- cybersecurity;<br/><br/>- modeling and verification of concurrent, distributed, and self-adaptive<br/>systems;<br/><br/>- program analysis;<br/><br/>- smart contracts and blockchain technology;<br/><br/>- software performance evaluation.<br/><br/>A non-exhaustive list of suggested PhD topics is available here</span>&lt;<a href="https://sysma.imtlucca.it/phd/phd-projects/" rel="noreferrer" target="_blank">https://sysma.imtlucca.it/phd/phd-projects/</a>&gt;. Prospective candidates are<span class="im"><br/>warmly encouraged to get in touch with members</span>&lt;<a href="https://sysma.imtlucca.it/people/" rel="noreferrer" target="_blank">https://sysma.imtlucca.it/people/</a>&gt; of the SYSMA unit for informal<span class="im"><br/>enquiries.<br/><br/>The scholarship is for 4 years and consists of grant amounting to € 15,300<br/>gross/year, in addition to free accommodation and board at the IMT Campus</span>&lt;<a href="https://www.imtlucca.it/en/campus/overview" rel="noreferrer" target="_blank">https://www.imtlucca.it/en/campus/overview</a>&gt;. PhD candidates have the<span class="im"><br/>possibility to defend their thesis from the beginning of the fourth year of<br/>the program, but no earlier as per Italian legislation.<br/><br/>The initial start date of the PhD program is 1 November 2019. The working<br/>language at IMT is English.<br/><br/>Application deadline is 23 April 2019. Note that candidates who have not<br/>obtained their undergraduate degree by the deadline can still apply, and<br/>can be admitted if they graduate no later than 31 October 2019.<br/><br/>Applications must be submitted through the online form at:<br/><br/><a href="https://www.imtlucca.it/en/programma-dottorato/ammissione/procedure" rel="noreferrer" target="_blank">https://www.imtlucca.it/en/programma-dottorato/ammissione/procedure</a></span></div>
    </content>
    <updated>2019-03-14T11:44:00Z</updated>
    <published>2019-03-14T11:44:00Z</published>
    <author>
      <name>Luca Aceto</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/01092671728833265127</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-27705661</id>
      <author>
        <name>Luca Aceto</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/01092671728833265127</uri>
      </author>
      <link href="http://processalgebra.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://processalgebra.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Papers I find interesting---mostly, but not solely, in Process Algebra---, and some fun stuff in Mathematics and Computer Science at large and on general issues related to research, teaching and academic life.</subtitle>
      <title>Process Algebra Diary</title>
      <updated>2019-03-21T09:08:26Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/03/14/postdoc-position-at-bar-ilan-university-israel-apply-by-april-15-2019/</id>
    <link href="https://cstheory-jobs.org/2019/03/14/postdoc-position-at-bar-ilan-university-israel-apply-by-april-15-2019/" rel="alternate" type="text/html"/>
    <title>Postdoc position at Bar-Ilan University (ISRAEL) (apply by April 15, 2019)</title>
    <summary>We offer a postdoctoral position at Bar-Ilan University, Israel, in the field of coding theory and distributed computations. The appointment is for 1 or 2 years, depending on funding and progress, with starting date in October 2019 (flexible). The university resides in Tel-Aviv area. Apply by sending CV and a short research statement by 15.4.2019. […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>We offer a postdoctoral position at Bar-Ilan University, Israel, in the field of coding theory and distributed computations. The appointment is for 1 or 2 years, depending on funding and progress, with starting date in October 2019 (flexible). The university resides in Tel-Aviv area.</p>
<p>Apply by sending CV and a short research statement by 15.4.2019.</p>
<p>Website: <a href="https://www.eng.biu.ac.il/gellesr/">https://www.eng.biu.ac.il/gellesr/</a><br/>
Email: ran.gelles@biu.ac.il</p></div>
    </content>
    <updated>2019-03-14T10:00:34Z</updated>
    <published>2019-03-14T10:00:34Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-03-26T04:20:38Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=7478</id>
    <link href="https://windowsontheory.org/2019/03/13/submit-your-failures-to-cfail-2019/" rel="alternate" type="text/html"/>
    <title>Submit your failures to CFAIL 2019</title>
    <summary>[Posted at the request of Craig Gentry. I think this is actually a great idea that should be imitated by other sub-areas of TCS as well. –Boaz] Update: The Conference for Failed Approaches and Insightful Losses in cryptology is celebrating our first failure early: the failure to keep a deadline! We are extending the submission […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><em>[Posted at the request of Craig Gentry. I think this is actually a great idea that should be imitated by other sub-areas of TCS as well. –Boaz]</em></p>



<p><strong>Update:</strong>  The Conference for Failed Approaches and Insightful Losses in cryptology is celebrating our first failure early: the failure to keep a deadline! We are extending the submission deadline to <strong>11:59 pm EST on April 7 </strong>to give everyone more time to work on submissions. In these last weeks leading up to the deadline, you can follow the @cfail2019 twitter account for inspiring jokes about failure to help you reach the finish line!</p>



<p>The CFAIL 2019 program chairs would like to remind you that some failures are good.  Failure to attack a cryptosystem? Good! It might be a strong cryptosystem. Failure to publish in Eurocrypt? No problem! You’ll get ’em next time.  Failure to cut back on caffeine like you promised in your New Year’s resolution? Good! You must be full of energy!</p>



<p>But failure to submit to CFAIL… lame! <br/>Work on those submissions, cryptologists! We want to see your failures in all their glory! <br/>Just a friendly reminder that the CFAIL submission deadline is <del>April 1</del> <strong>April 7th</strong>. </p>



<p><a href="https://www.cfail2019.com/" rel="noreferrer noopener" target="_blank">https://www.cfail2019.com/</a><br/></p></div>
    </content>
    <updated>2019-03-14T01:30:15Z</updated>
    <published>2019-03-14T01:30:15Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>windowsontheory</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2019-03-26T04:20:50Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/03/13/planar-graphs-needing</id>
    <link href="https://11011110.github.io/blog/2019/03/13/planar-graphs-needing.html" rel="alternate" type="text/html"/>
    <title>Planar graphs needing many lines</title>
    <summary>As I said in my previous post my two SoCG papers both involved trying and failing to prove something else, and writing down what I could prove instead. For the one that appears today, “Cubic planar graphs that cannot be drawn on few lines” (arXiv:1903.05256), that something else was Open Problem 16.14 of my book, which can be rephrased as: does there exist a family of planar graphs that cannot be drawn planarly with all vertices on a constant number of convex curves?</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>As I said in <a href="https://11011110.github.io/blog/2019/03/12/counting-polygon-triangulations.html">my previous post</a> my two SoCG papers both
involved trying and failing to prove something else, and writing down
what I could prove instead. For the one that appears today, “Cubic
planar graphs that cannot be drawn on few lines” (<a href="http://arxiv.org/abs/1903.05256">arXiv:1903.05256</a>),
that something else was Open Problem 16.14 of my book, which can be
rephrased as: does there exist a family of planar graphs that cannot be
drawn planarly with all vertices on a constant number of convex curves?</p>

<p>Instead I expand on something that was already known, the existence of
planar graphs that cannot be drawn with all vertices on a constant
number of lines.</p>

<p>There were two previously known methods for constructing such graphs:</p>

<ul>
  <li>Use a <a href="https://en.wikipedia.org/wiki/Apollonian_network">planar
3-tree</a>. This
is a planar graph formed by recursively subdividing triangles into three
smaller triangles. If the vertices are drawn on some family of lines,
the line through the subdivision point must miss one of the three
smaller triangles, so by induction you can be forced to use a
non-constant number of lines. But the bound you get is only logarithmic.<sup id="fnref:book"><a class="footnote" href="https://11011110.github.io/blog/2019/03/13/planar-graphs-needing.html#fn:book">1</a></sup></li>
</ul>

<p style="text-align: center;"><img alt="Planar 3-tree" src="https://11011110.github.io/blog/assets/2019/planar-3-tree.svg"/></p>

<ul>
  <li>Use a maximal planar graph whose dual graph has no long paths.
In a maximal planar graph, any line through many vertices can be
translated into a path through many dual vertices. So if there is no
long dual path there must be many lines. This gives a polynomial lower
bound on the number of lines, but with a tiny exponent.<sup id="fnref:dual"><a class="footnote" href="https://11011110.github.io/blog/2019/03/13/planar-graphs-needing.html#fn:dual">2</a></sup></li>
</ul>

<p>The new paper finds a third method:</p>

<ul>
  <li>Use a graph that has many disjoint collections of many nested cycles.
Drawing a big set of nested cycles on a small
number of lines necessarily uses up one of the crossing points of the lines.
So if there are more nests than crossing points, one of them will have
to use many lines.</li>
</ul>

<p style="text-align: center;"><img alt="Graph with many disjoint collections of many nested cycles" src="https://11011110.github.io/blog/assets/2019/spiderwebs.svg"/></p>

<p>This leads to stronger polynomial bounds, but also (more importantly I
think) wider families of planar graphs that need non-constant numbers of
lines. For instance, it works for series-parallel graphs of maximum
degree three, which are far from being maximal planar. And even though
every tree can be drawn with its vertices on two lines, adding a single
vertex to a tree can produce a graph that requires a non-constant number
of lines.</p>

<p style="text-align: center;"><img alt="Tree plus one vertex requiring a non-constant number of lines" src="https://11011110.github.io/blog/assets/2019/apex-tree.svg"/></p>

<div class="footnotes">
  <ol>
    <li id="fn:book">
      <p><a href="https://www.ics.uci.edu/~eppstein/forbidden/"><em>Forbidden Configurations in Discrete Geometry</em></a>, Theorem 16.13. <a class="reversefootnote" href="https://11011110.github.io/blog/2019/03/13/planar-graphs-needing.html#fnref:book">↩</a></p>
    </li>
    <li id="fn:dual">
      <p>Ravsky, Alexander, and Verbitsky, Oleg (2011), “<a href="https://doi.org/10.1007/978-3-642-25870-1_27">On collinear sets in straight-line drawings</a>”, <em>37th Int. Worksh. Graph-Theoretic Concepts in Computer Science (WG 2011)</em>, LNCS 6986, Springer, pp. 295–306; Chaplick, Steven, Fleszar, Krzysztof, Lipp, Fabian, Verbitsky, Oleg, and Wolff, Alexander (2016), “<a href="https://doi.org/10.1007/978-3-319-50106-2_14">Drawing graphs on few lines and few planes</a>”, <em>24th Int. Symp. Graph Drawing and Network Visualization (GD 2016)</em>, LNCS 9801, Springer, pp. 166–180. <a class="reversefootnote" href="https://11011110.github.io/blog/2019/03/13/planar-graphs-needing.html#fnref:dual">↩</a></p>
    </li>
  </ol>
</div>

<p>(<a href="https://mathstodon.xyz/@11011110/101747562081254313">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2019-03-13T18:37:00Z</updated>
    <published>2019-03-13T18:37:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-03-20T07:21:58Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4145</id>
    <link href="https://www.scottaaronson.com/blog/?p=4145" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/aar-manolis.mp4" length="88324077" rel="enclosure" type="video/mp4"/>
    <link href="https://www.scottaaronson.com/blog/?p=4145#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4145" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">“Quantum Computing and the Meaning of Life”</title>
    <summary xml:lang="en-US">Manolis Kellis is a computational biologist at MIT, known as one of the leaders in applying big data to genomics and gene regulatory networks. Throughout my 9 years at MIT, Manolis was one of my best friends there, even though our research styles and interests might seem distant. He and I were in the same […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="http://web.mit.edu/manoli/">Manolis Kellis</a> is a computational biologist at MIT, known as one of the leaders in applying big data to genomics and gene regulatory networks.  Throughout my 9 years at MIT, Manolis was one of my best friends there, even though our research styles and interests might seem distant.  He and I were in the same <a href="https://en.wikipedia.org/wiki/Presidential_Early_Career_Award_for_Scientists_and_Engineers">PECASE</a> class; see if you can spot us both in <a href="https://www.scottaaronson.com/pecase.jpg">this photo</a> (in the rows behind America’s last sentient president).  My and Manolis’s families also became close after we both got married and had kids.  We still keep in touch.</p>



<p>Today Manolis will be celebrating his 42nd birthday, with a <a href="https://twitter.com/manoliskellis/status/1104873813685272576">symposium on the meaning of life</a> (!).  He asked his friends and colleagues to contribute talks and videos reflecting on that weighty topic.</p>



<p><a href="https://www.youtube.com/watch?v=w2PXd46ExiM&amp;feature=youtu.be&amp;fbclid=IwAR3QVXxCRC9_N6WjLTgqkSlhCMZcSyvQK5SpP1MzPxIRPJSQqYAH8ElD0f0">Here’s a 15-minute video interview</a> that Manolis and I recorded last night, where he asks me to pontificate about the implications of quantum mechanics for consciousness and free will and whether the universe is a computer simulation—and also about, uh, how to balance blogging with work and family.</p>



<p>Also, <a href="https://www.scottaaronson.com/aar-manolis.mp4">here’s a 2-minute birthday video</a> that I made for Manolis before I really understood what he wanted.  Unlike the first video, this one has no academic content, but it does involve me wearing a cowboy hat and swinging a makeshift “lasso.”</p>



<p>Happy birthday Manolis!</p></div>
    </content>
    <updated>2019-03-13T16:45:04Z</updated>
    <published>2019-03-13T16:45:04Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Adventures in Meatspace"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Metaphysical Spouting"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Quantum"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2019-03-15T21:30:35Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/03/12/counting-polygon-triangulations</id>
    <link href="https://11011110.github.io/blog/2019/03/12/counting-polygon-triangulations.html" rel="alternate" type="text/html"/>
    <title>Counting polygon triangulations is hard</title>
    <summary>In some sense both of my accepted papers at SoCG are about a situation where I really wanted to prove something else, wasn’t able to, and wrote up what I could prove instead. The one whose preprint appears today, “Counting polygon triangulations is hard” (arXiv:1903.04737), proves that it’s -complete to count the triangulations of a polygon with holes.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>In some sense both of my accepted papers at SoCG are about a situation where I really wanted to prove something else, wasn’t able to, and wrote up what I could prove instead. The one whose preprint appears today, “Counting polygon triangulations is hard” (<a href="http://arxiv.org/abs/1903.04737">arXiv:1903.04737</a>), proves that it’s -complete to count the triangulations of a polygon with holes.</p>

<p>It’s easy to prove that it’s -hard to count maximum non-crossing subsets of line segment arrangements: the intersections graphs of line segments include all the planar graphs, so this follows immediately from the -completeness of maximum independent sets in planar graphs. The gadgets in my paper (drawn below) turn a single line segment into a part of a polygon for which many triangulations use diagonals in approximately the same position as the line segment, and there are few other triangulations. By using these gadgets, one could easily construct a polygon in which most of the triangulations correspond to maximum non-crossing subsets, showing that it’s also -hard to count triangulations. But this is unsatisfactory because it’s the wrong kind of completeness. For counting problems, we want -completeness, not just -hardness.</p>

<p style="text-align: center;"><img alt="Gadgets for proving hardness of polygon triangulation" src="https://11011110.github.io/blog/assets/2019/tricount-gadgets.svg"/></p>

<p>The reason the outline above isn’t already a -completeness proof is that we need to control the rest of the triangulation better. It’s not enough for most triangulations to come from maximum non-crossing subsets. We need each maximum non-crossing subset of line segments to contribute exactly the same number of triangulations (or at least a predictable and controlled number) so that we can recover the number of maximum non-crossing subsets from the number of triangulations. The gadgets control the parts of the triangulation near each segment of the non-crossing subsets, but we also need to control the parts of the triangulation that are not near those segments. Achieving this took much of the work in my new paper. There are two main ideas: First, we use special arrangements with the property that, when you close off the gadgets of a maximum non-crossing subset, the remaining parts of the polygon form pieces of predictable shapes for which we can count the triangulations. In these arrangements, there are two colors of segments, red and blue; each blue segment is crossed by two red segments, and each red segment is crossed in the order blue-red-blue. So we need a new counting reduction from graph independent sets that produces arrangements of this type. And second, we decompose the total number of maximum non-crossing subsets into a sum of smaller numbers, of subsets that have a given number of red segments. Subsets with the same number of red segments leads to the same numbers of triangulations, allowing the terms in the sum to be recovered from the number of triangulations.</p>

<p>A secondary goal was to do this all using a <a href="https://en.wikipedia.org/wiki/Polynomial-time_counting_reduction">polynomial-time counting reduction</a> rather than the <a href="https://en.wikipedia.org/wiki/Turing_reduction">Turing reductions</a> that are more commonly used for -completeness. One cannot use an even stronger notion of reduction, <a href="https://en.wikipedia.org/wiki/Parsimonious_reduction">parsimonious reductions</a>, to reduce  problems that might have zero solutions to a problem like triangulation that always has at least one. But to me, counting reductions are more closely analogous to the many-one reductions used for -completeness. We can use them, so we should use them. So the reductions in the paper are polynomial-time counting reductions, but more work would be needed to prove that the starting graph problem I used (counting independent sets in regular planar graphs) is complete for those reductions.</p>

<p>Surprisingly to me, this appears to be the first published proof of a -completeness result in two-dimensional computational geometry. And although some 2d geometric structures have been proven -hard to construct (and therefore -hard to count) it seems to be the first hardness proof of any kind for counting 2d structures that can be constructed rather than counted in polynomial time. But as I said at the top of this post, it’s not what I really wanted to prove. I was hoping to prove hardness for counting non-crossing structures on point sets, such as simple polygons, triangulations, non-crossing matchings, or pointed pseudotriangulations. The polygon question was suggested to me by Sara Billey when I visited her last April, in connection with a different problem we were working on (and still haven’t published). And counting the triangulations of a point set would fit the theme of my recent book, because this count is a numerical parameter that depends only on the order type of the points and mostly behaves monotonically under point deletion (exception: delete the center point of a <a href="https://en.wikipedia.org/wiki/Quincunx">quincunx</a>). Instead I had to settle for polygon triangulations. But maybe another paper can take this line of research one step farther, to counting problems on points.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/101741985429465998">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2019-03-12T18:48:00Z</updated>
    <published>2019-03-12T18:48:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-03-20T07:21:58Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/040</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/040" rel="alternate" type="text/html"/>
    <title>TR19-040 |  The Complexity of Finding {$S$}-factors in Regular Graphs | 

	Sanjana Kolisetty, 

	Linh Le, 

	Ilya Volkovich, 

	Mihalis Yannakakis</title>
    <summary>A graph $G$ has an \emph{$S$-factor} if there exists a spanning subgraph $F$ of $G$ such that for all $v \in V: \deg_F(v) \in S$.
The simplest example of such factor is a $1$-factor, which corresponds to a perfect matching in a graph. In this paper we study the computational complexity of finding $S$-factors in regular graphs.
Our techniques combine some classical as well as recent tools from graph theory.</summary>
    <updated>2019-03-12T17:07:28Z</updated>
    <published>2019-03-12T17:07:28Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-03-26T04:20:29Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/039</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/039" rel="alternate" type="text/html"/>
    <title>TR19-039 |  Planarity, Exclusivity, and Unambiguity | 

	Eric Allender, 

	Archit Chauhan, 

	Samir Datta, 

	Anish Mukherjee</title>
    <summary>We provide new upper bounds on the complexity of the s-t-connectivity problem in planar graphs, thereby providing additional evidence that this problem is not complete for NL. This also yields a new upper bound on the complexity of computing edit distance. Building on these techniques, we provide new upper bounds on the complexity of several other computational problems on planar graphs. All of these problems are shown to be solvable in logarithmic time on a concurrent-read exclusive-write (CREW) PRAM. The new upper bounds are provided by making use of a known characterization of CREW algorithms in terms of "unambiguous" AC$^1$ circuits. This seems to be the first occasion where this characterization has been used in order to provide new upper bounds on natural problems.</summary>
    <updated>2019-03-12T04:11:48Z</updated>
    <published>2019-03-12T04:11:48Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-03-26T04:20:29Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>http://corner.mimuw.edu.pl/?p=1067</id>
    <link href="http://corner.mimuw.edu.pl/?p=1067" rel="alternate" type="text/html"/>
    <title>HALG 2019 (Highlights of Algorithms) - Final Call for Short Contributed Presentations</title>
    <summary>I think we have an exciting program that awaits us during HALG 2019: http://highlightsofalgorithms.org/speakers. Please remember that the call for short contributed talks ends this week - on 15th of March. </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I think we have an exciting program that awaits us during HALG 2019: http://highlightsofalgorithms.org/speakers. Please remember that the call for short contributed talks ends this week - on 15th of March. </p></div>
    </content>
    <updated>2019-03-11T21:17:51Z</updated>
    <published>2019-03-11T21:17:51Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>sank</name>
    </author>
    <source>
      <id>http://corner.mimuw.edu.pl</id>
      <link href="http://corner.mimuw.edu.pl/?feed=rss2" rel="self" type="application/atom+xml"/>
      <link href="http://corner.mimuw.edu.pl" rel="alternate" type="text/html"/>
      <subtitle>University of Warsaw</subtitle>
      <title>Banach's Algorithmic Corner</title>
      <updated>2019-03-25T23:33:47Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/03/11/postdoc-at-technion-israel-institute-of-technology-apply-by-april-30-2019/</id>
    <link href="https://cstheory-jobs.org/2019/03/11/postdoc-at-technion-israel-institute-of-technology-apply-by-april-30-2019/" rel="alternate" type="text/html"/>
    <title>Postdoc at Technion Israel Institute of Technology (apply by April 30, 2019)</title>
    <summary>For an exciting project funded by the European Commission for Research (ERC), I currently have several openings for post-docs working in the intersection of theoretical computer science and learning theory. Website: https://nailon.net.technion.ac.il/openings/ Email: nailon@cs.technion.ac.il</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>For an exciting project funded by the European Commission for Research (ERC), I currently have several openings for post-docs working in the intersection of theoretical computer science and learning theory.</p>
<p>Website: <a href="https://nailon.net.technion.ac.il/openings/">https://nailon.net.technion.ac.il/openings/</a><br/>
Email: nailon@cs.technion.ac.il</p></div>
    </content>
    <updated>2019-03-11T15:10:35Z</updated>
    <published>2019-03-11T15:10:35Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-03-26T04:20:38Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://adamsheffer.wordpress.com/?p=5378</id>
    <link href="https://adamsheffer.wordpress.com/2019/03/11/incidences-open-problem-part-1/" rel="alternate" type="text/html"/>
    <title>Incidences: Open Problems (part 1)</title>
    <summary>The past decade brought us several breakthroughs in the study of geometric incidences. Most importantly, Guth and Katz introduced polynomial partitioning, and this has become the main technique for studying incidences. The recent breakthroughs sometimes leads to a wrong impression about the state of this field. Actually, most of the main incidence problems are still […]</summary>
    <updated>2019-03-11T01:06:19Z</updated>
    <published>2019-03-11T01:06:19Z</published>
    <category term="Incidences"/>
    <author>
      <name>Adam Sheffer</name>
    </author>
    <source>
      <id>https://adamsheffer.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://adamsheffer.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://adamsheffer.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://adamsheffer.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://adamsheffer.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Discrete geometry and other typos</subtitle>
      <title>Some Plane Truths</title>
      <updated>2019-03-26T04:21:05Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-5113460714750651988</id>
    <link href="https://blog.computationalcomplexity.org/feeds/5113460714750651988/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/03/richard-karp-his-influence-and-how-to.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/5113460714750651988" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/5113460714750651988" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/03/richard-karp-his-influence-and-how-to.html" rel="alternate" type="text/html"/>
    <title>Richard Karp: His influence and how to honor him</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">When I first saw the definition of NP-Complete I first thought<i> if there are NP-complete problems I suspect they are contrived. </i>When I saw the proof that  SAT is NP-complete I thought <i>okay, so there is one natural problem  NP-complete by a trick of encoding, but I suspect there aren't any more.</i>  I then read Karp's article that had 22 NP-complete problems. I thought <i>okay, there are 22, but I suspect there are no more. </i>No I didn't think that. But the point is that Cook and Karp together birthed modern complexity theory by introduction NP-completeness and showing that there are MANY natural problems that are NP-complete.<br/>
<br/>
How many people has Richard Karp inspired? I don't know but I suspect it's a  cardinal between countable and the reals so it may depend on your model of set theory. Later in this post I will present Samir Khuller's story of how Richard Karp inspired him.<br/>
<br/>
How to honor him?  The Simons inst. is currently welcoming contributions to the Richard M Karp Fund, which honors the scientific contributions of Founding Director Dick Karp. The fund will provide vital support for the mission and activities of the Simons institute. They have a deadline of Pi-Day. You can go <a href="https://simons.berkeley.edu/support/donate">here</a> to contribute and/or <a href="https://www.cs.umd.edu/users/gasarch/BLOGPAPERS/goldwasserkarp.txt">here</a> for a letter from Shafi Goldwasser, Prabhakar Raghavan, and Umesh Vazirani about the fund.<br/>
<br/>
OKAY, Samir's story:<br/>
<br/>
<div>
<b>Mentoring and Influence via a Train Journey...</b></div>
<div>
<br/></div>
<div>
Almost to the day, 33 years ago I was running from my dorm room to catch an unreliable bus to the train station as I headed home for a mid-semester break.  On the way,I  stopped by the mailroom, and not knowing where to put the CACM that had just arrived,  stuffed it into the side of my bag and in the process, dropping my   notebook in the process. On the train, when I looked for my  notebook to go over  some material I realized it was missing! All I had was a CACM and a very long train ride. Skimming through the journal, I found Karp’s Turing Award article “Combinatorics, Complexity, and Randomness“. I  started reading this article, and was riveted! It was one of those life changing moments for me, when my immediate future became clear - I wanted to study Theoretical Computer Science and specifically the complexity of combinatorial problems. Without ever having met Dick Karp, he changed my life forever.</div>
<div>
<br/></div>
<div>
I met Dick long after he influenced me via his Turing Award Lecture and it was a real privilege to have had the opportunity to interview him via a fireside chat at Simons. See <a href="https://www.youtube.com/watch?v=g1DT_UeJwps">here</a>.</div>
<div>
<br/></div>
<div>
I am delighted about the fund Bill mentions above as the money that goes to it will help inspire others as Karp inspired me.</div>
<div>
<br/></div>
<div>
<br/></div>
<div>
<br/></div>
<br/>
<br/></div>
    </content>
    <updated>2019-03-10T21:26:00Z</updated>
    <published>2019-03-10T21:26:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>https://plus.google.com/101693130490639305932</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-03-25T08:11:59Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/03/10/postdoc-at-ist-austria-vienna-apply-by-april-15-2019/</id>
    <link href="https://cstheory-jobs.org/2019/03/10/postdoc-at-ist-austria-vienna-apply-by-april-15-2019/" rel="alternate" type="text/html"/>
    <title>Postdoc at IST Austria (Vienna) (apply by April 15, 2019)</title>
    <summary>The Distributed Algorithms Group at IST Austria (near Vienna) is looking for strong postdoc candidates in CS Theory, with a focus on (distributed) optimization. The starting date is (roughly) in Fall 2019. Website: http://people.csail.mit.edu/alistarh/ Email: d.alistarh@gmail.com</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Distributed Algorithms Group at IST Austria (near Vienna) is looking for strong postdoc candidates in CS Theory, with a focus on (distributed) optimization. The starting date is (roughly) in Fall 2019.</p>
<p>Website: <a href="http://people.csail.mit.edu/alistarh/">http://people.csail.mit.edu/alistarh/</a><br/>
Email: d.alistarh@gmail.com</p></div>
    </content>
    <updated>2019-03-10T20:48:31Z</updated>
    <published>2019-03-10T20:48:31Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-03-26T04:20:38Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=15674</id>
    <link href="https://rjlipton.wordpress.com/2019/03/10/problems-with-a-point/" rel="alternate" type="text/html"/>
    <title>Problems With a Point</title>
    <summary>Bill and Clyde’s new book Bill Gasarch and Clyde Kruskal are colleagues in Computer Science at the University of Maryland. They have just seen the publication of their book Problems With a Point. Today Dick and I congratulate them on the book and give a brief overview of it. The tandem of Bill and Clyde […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Bill and Clyde’s new book</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<p><a href="https://rjlipton.wordpress.com/2019/03/10/problems-with-a-point/gasarchkruskal/" rel="attachment wp-att-15675"><img alt="" class="alignright wp-image-15675" height="114" src="https://rjlipton.files.wordpress.com/2019/03/gasarchkruskal.png?w=200&amp;h=114" width="200"/></a></p>
<p/><p>
Bill Gasarch and Clyde Kruskal are colleagues in Computer Science at the University of Maryland. They have just seen the publication of their <a href="https://www.worldscientific.com/worldscibooks/10.1142/11261">book</a> <em>Problems With a Point</em>.</p>
<p>
Today Dick and I congratulate them on the book and give a brief overview of it.<br/>
<span id="more-15674"/></p>
<p>
The tandem of Bill and Clyde were <a href="https://rjlipton.wordpress.com/2011/12/06/theorems-are-forever-a-great-one-from-1492/">featured</a> before on this blog in connection with a <a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.138.6154">series</a> of <a href="http://www.cs.umd.edu/~gasarch/BLOGPAPERS/3apsurvey.pdf">papers</a> with James Glenn on sets of numbers that have no arithmetical progressions of length 3. </p>
<p>
Can a “series” have only two members? We could add a third <a href="https://link.springer.com/chapter/10.1007/11821069_13">paper</a> to the series, but it is by Glenn and Bill with Richard Beigel rather than Clyde and is on the different topic of multi-party communication complexity. But Clyde gets into the act since it is the topic of Chapter 19 of the book. That chapter analyzes a game form of problems that go back to a 1983 <a href="http://www.cs.umd.edu/~gasarch/BLOGPAPERS/multiparty-vdw.pdf">paper</a> by Dick with Ashok Chandra and Merrick Furst. Does this mean Dick should get some royalties? Note that this last link is to Bill’s website. And ‘vdw’ in this link seems to refer to van der Waerden’s <a href="https://en.wikipedia.org/wiki/Van_der_Waerden's_theorem">theorem</a>, which is a pillar of both Ramsey theory and number theory, which in turn receive much attention in the book.</p>
<p>
My last paragraph flits through divergent questions but they are representative of things that we working mathematical computing theorists think about every day—and of various kinds of content in the book. Of course, Bill partners on Lance Fortnow’s prominent <a href="https://blog.computationalcomplexity.org/">blog</a> and so has shared all kinds of these musings. The book, which incorporates numerous posts by Bill but is not a “blog book” <em>per-se</em>, furnishes contexts for them. Let’s look at the book.</p>
<p>
</p><p/><h2> The Book </h2><p/>
<p/><p>
The book has three main parts, titled:</p>
<ul>
<li>
Stories With a Point. <p/>
</li><li>
Problems With a Point. <p/>
</li><li>
Theorems With a Point.
</li></ul>
<p>
All the chapters except three are prefaced with a section titled “Point”—or “The Point” or “Points”—after one sentence on prior knowledge needed, which often reads, “None.”</p>
<p>
The first part begins with a chapter titled, “When Terms From Math are Used By Civilians,” one of several with social discussion. The second is about how human aspects of sports upset statistical regularities one might expect to see. For example, many more baseball hitters have had season batting averages of .300 than .299 or .301, evidently because .300 is a “goal number” everyone strives to meet. There are numerous things in the book I didn’t know. </p>
<p>
The next chapter largely reproduces this record-long <a href="https://blog.computationalcomplexity.org/2011/07/disproofing-myth-that-many-early.html">post</a> on the blog but adds much extra commentary. Then there are chapters on what makes a mathematical function worth defining, on how mathematical objects are named, on Bill’s visit to a “Gathering for [Martin] Gardner” <a href="http://www.gathering4gardner.org/">conference</a>, on coloring the plane, two on imagined applications of Ramsey Theory to medieval history, and one on the methodological and social impact of having theorems that represent barriers to ways of trying to prove other theorems. </p>
<p>
</p><p/><h2> Chapter Ten </h2><p/>
<p/><p>
This last chapter of Part I <a href="https://blog.computationalcomplexity.org/2010/04/lets-prove-something-instead-of-proving.html">draws</a> on <a href="https://blog.computationalcomplexity.org/2010/04/but-seriously-now-folks-what-do-you.html">several</a> of Bill’s <a href="https://blog.computationalcomplexity.org/2017/03/other-fields-of-math-dont-prove-barrier.html">posts</a>. It goes most to the heart of what we all in computational complexity grapple with daily and benefits from having more context: As we just mused in this blog’s 10-year anniversary <a href="https://rjlipton.wordpress.com/2019/02/18/have-ten-years-brought-us-closer/">post</a>, the major questions in complexity are not only as open as when we started, but as open as when the field started 50-plus years ago. There has barely been any discernible direct progress, and this is not only a concern for entering students but a retardant on everyone—about which we’ve given <a href="https://rjlipton.wordpress.com/2014/09/18/lets-mention-foundations/">exhortation</a>.</p>
<p>
There are instead <a href="https://rjlipton.wordpress.com/2012/11/29/barriers-to-pnp-proofs/">barrier</a> theorems saying <em>why</em> the main questions will not be resolvable by the very techniques that were used to build the field. Of three broad categories of barriers, “oracle results” de-fang all the methods typically taught in intro graduate complexity courses. Those methods meter computations at inputs and outputs but not how they “progress” inside toward a solution. Oracle languages supply blasts of external information that either make progress trivially quick or allow conditioning the terms of the complexity-class relation under analysis to information in the oracle that is tailored to obfuscate. Oracles of the former kind usually collapse complexity classes together, such as <img alt="{A =}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA+%3D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A =}"/> any polynomial-space complete language making <img alt="{\mathsf{P}^A = \mathsf{NP}^A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D%5EA+%3D+%5Cmathsf%7BNP%7D%5EA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{P}^A = \mathsf{NP}^A}"/>, whereas oracles <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B}"/> of the latter kind drive them apart (so <img alt="{\mathsf{P}^B \neq \mathsf{NP}^B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D%5EB+%5Cneq+%5Cmathsf%7BNP%7D%5EB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{P}^B \neq \mathsf{NP}^B}"/>) but often for reasons that frustrate as much as enlighten. When contemplating a new complexity class relation it is incumbent to frame a “relativized” version of it and see if some oracles can make it true and others false. Such oracle constructions were initially easy to come by—“fast food” for research—but their ultimate besideness-of-the-point is reflected in this early <a href="https://rjlipton.wordpress.com/2009/05/21/i-hate-oracle-results/">post</a> by Dick.</p>
<p>
Next after oracles is the “Natural Proofs” <a href="https://en.wikipedia.org/wiki/Natural_proof">barrier</a>, which basically cuts against all the techniques taught in advanced graduate complexity courses unless they can somehow be weirdly narrow or intensely complex in their conceptual framing. The attitude on those is captured by the title of another early <a href="https://rjlipton.wordpress.com/2009/03/25/whos-afraid-of-natural-proofs/">post</a> by Dick titled, “Who’s Afraid of Natural Proofs?” The third barrier is <a href="https://www.scottaaronson.com/papers/algstoc.pdf">algebrization</a>, which cuts <a href="https://en.wikipedia.org/wiki/P_versus_NP_problem#Results_about_difficulty_of_proof">against</a> efforts to escape from oracles. </p>
<p>
Amid all this environment of obstruction, what of consequence can we prove? Well, the chapter on this has by far the highest concentration of Bill’s trademark all-capital letters and exclamation points. The initial “Point” section is titled, “Rant.” (The chapter also includes a page on the attempts to prove Euclid’s parallel postulate, which might be called the original “problem with a point.”)</p>
<p>
</p><p/><h2> Part II </h2><p/>
<p/><p>
Much of Part II involves the kind of problems that were used or considered for high-school mathematics competitions. By definition those are not research problems but they often point toward frontiers by representing accessible cases of them. The appealing ones blend equal parts research relevance, amusement value, and reward of technical command. Often they require mathematical “street smarts” and a repertoire of useful tricks and proof patterns. Practicing researchers will find this aspect of the book most valuable. The problems are mainly on the number-theory side of recreational mathematics, plus geometric and coloring problems. Egyptian fractions, prime-factor puzzles, sums over digits, summation formulas, and of course Ramsey theory all make their appearance. Here is one problem I mention partly to correct a small content error, where the correction seems to make the problem more interesting. Say that <img alt="{C(n,m)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%28n%2Cm%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C(n,m)}"/> holds if there are integers <img alt="{n_1,\dots,n_m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn_1%2C%5Cdots%2Cn_m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n_1,\dots,n_m}"/> such that </p>
<p align="center"><img alt="\displaystyle  n_1 + \cdots + n_m = n \qquad\text{and}\qquad \frac{1}{n_1} + \cdots + \frac{1}{n_m} = 1. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++n_1+%2B+%5Ccdots+%2B+n_m+%3D+n+%5Cqquad%5Ctext%7Band%7D%5Cqquad+%5Cfrac%7B1%7D%7Bn_1%7D+%2B+%5Ccdots+%2B+%5Cfrac%7B1%7D%7Bn_m%7D+%3D+1.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  n_1 + \cdots + n_m = n \qquad\text{and}\qquad \frac{1}{n_1} + \cdots + \frac{1}{n_m} = 1. "/></p>
<p>A general principle discovered by Joseph Sylvester gives cases such as <img alt="{C(1861,5)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%281861%2C5%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C(1861,5)}"/> being witnessed by </p>
<p align="center"><img alt="\displaystyle  1861 = 2 + 3 + 7 + 43 + 1806 \qquad\text{and}\qquad 1 = \frac{1}{2} + \frac{1}{3} + \frac{1}{7} + \frac{1}{43} + \frac{1}{1806}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++1861+%3D+2+%2B+3+%2B+7+%2B+43+%2B+1806+%5Cqquad%5Ctext%7Band%7D%5Cqquad+1+%3D+%5Cfrac%7B1%7D%7B2%7D+%2B+%5Cfrac%7B1%7D%7B3%7D+%2B+%5Cfrac%7B1%7D%7B7%7D+%2B+%5Cfrac%7B1%7D%7B43%7D+%2B+%5Cfrac%7B1%7D%7B1806%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  1861 = 2 + 3 + 7 + 43 + 1806 \qquad\text{and}\qquad 1 = \frac{1}{2} + \frac{1}{3} + \frac{1}{7} + \frac{1}{43} + \frac{1}{1806}. "/></p>
<p>How can it and related ideas be extended to other cases? The particular problem is given <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> to find <img alt="{m_n =}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm_n+%3D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m_n =}"/> the least <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m}"/> such that <img alt="{C(n,m)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%28n%2Cm%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C(n,m)}"/> holds—and to find a witnessing sum. The error is an assertion that <img alt="{m_n \leq n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm_n+%5Cleq+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m_n \leq n}"/> “by writing <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> as a sum of <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>‘s,” but then the reciprocals add up to <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> not <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>. So is there any bound on <img alt="{m_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m_n}"/>? That is rather fun to think about. </p>
<p>
This problem’s chapter is made from a short <a href="https://blog.computationalcomplexity.org/2011/12/is-this-problem-too-hard-for-hs-math.html">post</a> with an enormous comments section.  There is also a chapter on the boundary between a fair problem and a “trick question” that much extends an April Fool’s post on the blog.</p>
<p>
</p><p/><h2> Part III </h2><p/>
<p/><p>
Part III continues the nature of the problem content with emphasis on the worths of proofs of theorems. One illustration involving perfect numbers and sums of cubes notes that the proof loses value because it also applies to certain non-perfect numbers. Two things <em>en-passant</em>: First, Lemma 21.1 in this chapter needs qualification that <img alt="{a,b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%2Cb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a,b}"/> are relatively prime and <img alt="{x+1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x+1}"/> is prime. Second, this prompts me to note <a href="https://gilkalai.wordpress.com/2019/03/09/">via</a> Gil Kalai the discovery by Tim Browning that the number 33 is a sum of three cubes: </p>
<p><br/></p>
<p align="center"><img alt="\displaystyle  33 = 8,\!866,\!128,\!975,\!287,\!528^3 + (-8,\!778,\!405,\!442,\!862,\!239)^3 + (-2,\!736,\!111,\!468,\!807,\!040)^3. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++33+%3D+8%2C%5C%21866%2C%5C%21128%2C%5C%21975%2C%5C%21287%2C%5C%21528%5E3+%2B+%28-8%2C%5C%21778%2C%5C%21405%2C%5C%21442%2C%5C%21862%2C%5C%21239%29%5E3+%2B+%28-2%2C%5C%21736%2C%5C%21111%2C%5C%21468%2C%5C%21807%2C%5C%21040%29%5E3.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  33 = 8,\!866,\!128,\!975,\!287,\!528^3 + (-8,\!778,\!405,\!442,\!862,\!239)^3 + (-2,\!736,\!111,\!468,\!807,\!040)^3. "/></p>
<p/><p><br/>
Gil points to a Quora <a href="https://affinemess.quora.com/HOLY-CRAP-33-IS-THE-SUM-OF-THREE-CUBES">post</a> by Alon Amit. There is only the bare equation on Browning’s <a href="http://pub.ist.ac.at/~tbrownin/">homepage</a>, and nothing about his methods or how much he used computer search is known. The theme of proofs by computer runs through several chapters of Bill and Clyde’s book. It is also <a href="https://www.scottaaronson.com/blog/?p=4133">current</a> on Scott Aaronson’s blog—we would be remiss if we did not mention Scott in this post—and more widely.</p>
<p>
The penultimate chapter covers the beautiful theory of rectangle-free colorings of grids. We mentioned Bill’s involvement with this Ramsey-style problem in a <a href="https://rjlipton.wordpress.com/2012/02/12/how-deep-is-your-coloring/">post</a> on what happened to be this blog’s third anniversary. We connected it to Kolmogorov complexity, which together with uncomputability is the subject of the last chapter. This and other chapters I’ve mentioned exemplify how the research ambit connects traditional mathematics with the terms and concerns of computing theory. How to work in this ambit may be the greatest value of the book for students. In all I found the book light, lighthearted, and enlightening.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
The big open problem with the book is how it might help gear us up to tackle the big open problems.</p>
<p>
[sourced chapter near end of Part II to blog]</p></font></font></div>
    </content>
    <updated>2019-03-10T19:43:13Z</updated>
    <published>2019-03-10T19:43:13Z</published>
    <category term="All Posts"/>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="People"/>
    <category term="primes"/>
    <category term="Proofs"/>
    <category term="Teaching"/>
    <category term="trick"/>
    <category term="Bill Gasarch"/>
    <category term="book"/>
    <category term="Clyde Kruskal"/>
    <category term="Problems"/>
    <category term="review"/>
    <category term="teaching"/>
    <author>
      <name>KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-03-26T04:20:36Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/038</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/038" rel="alternate" type="text/html"/>
    <title>TR19-038 |  Statistical Difference Beyond the Polarizing Regime | 

	Itay Berman, 

	Akshay Degwekar, 

	Ron D. Rothblum, 

	Prashant Nalini Vasudevan</title>
    <summary>The polarization lemma for statistical distance ($\mathrm{SD}$), due to Sahai and Vadhan (JACM, 2003), is an efficient transformation taking as input a pair of circuits $(C_0,C_1)$ and an integer $k$ and outputting a new pair of circuits $(D_0,D_1)$ such that if $\mathrm{SD}(C_0,C_1)\geq\alpha$ then $\mathrm{SD}(D_0,D_1) \geq 1-2^{-k}$ and if $\mathrm{SD}(C_0,C_1) \leq \beta$ then $\mathrm{SD}(D_0,D_1) \leq 2^{-k}$. The polarization lemma is known to hold for any constant values $\beta &lt; \alpha^2$, but extending the lemma to the regime in which $\alpha^2 \leq \beta &lt; \alpha$ has remained elusive. The focus of this work is in studying the latter regime of parameters. Our main results are:

1. Polarization lemmas for different notions of distance, such as Triangular Discrimination ($\mathrm{TD}$) and Jensen-Shannon Divergence ($\mathrm{JS}$), which enable polarization for some problems where the statistical distance satisfies $\alpha^2 &lt; \beta &lt; \alpha$. We also derive a polarization lemma for statistical distance with any inverse-polynomially small gap between $\alpha^2$ and $\beta$ (rather than a constant).

2. The average-case hardness of the statistical difference problem (i.e., determining whether the statistical distance between two given circuits is at least $\alpha$ or at most $\beta$), for any values of $\beta &lt; \alpha$, implies the existence of one-way functions. Such a result was previously only known for $\beta &lt; \alpha^2$.

3. A (direct) constant-round interactive proof for estimating the statistical distance between any two distributions (up to any inverse polynomial error) given circuits that generate them.</summary>
    <updated>2019-03-10T08:50:14Z</updated>
    <published>2019-03-10T08:50:14Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-03-26T04:20:29Z</updated>
    </source>
  </entry>
</feed>
