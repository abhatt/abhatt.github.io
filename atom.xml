<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2020-03-12T05:21:51Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2003.05332</id>
    <link href="http://arxiv.org/abs/2003.05332" rel="alternate" type="text/html"/>
    <title>Monotone Arc Diagrams with few Biarcs</title>
    <feedworld_mtime>1583971200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chaplick:Steven.html">Steven Chaplick</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/F=ouml=rster:Henry.html">Henry Förster</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hoffmann:Michael.html">Michael Hoffmann</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kaufmann:Michael.html">Michael Kaufmann</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2003.05332">PDF</a><br/><b>Abstract: </b>We show that every planar graph can be represented by a monotone topological
2-page book embedding where at most 15n/16 (of potentially 3n-6) edges cross
the spine exactly once.
</p></div>
    </summary>
    <updated>2020-03-12T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-03-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2003.05289</id>
    <link href="http://arxiv.org/abs/2003.05289" rel="alternate" type="text/html"/>
    <title>Balanced Independent and Dominating Sets on Colored Interval Graphs</title>
    <feedworld_mtime>1583971200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bhore:Sujoy.html">Sujoy Bhore</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Haunert:Jan=Henrik.html">Jan-Henrik Haunert</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Klute:Fabian.html">Fabian Klute</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Guangping.html">Guangping Li</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/N=ouml=llenburg:Martin.html">Martin Nöllenburg</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2003.05289">PDF</a><br/><b>Abstract: </b>We study two new versions of independent and dominating set problems on
vertex-colored interval graphs, namely \emph{$f$-Balanced Independent Set}
($f$-BIS) and \emph{$f$-Balanced Dominating Set} ($f$-BDS). Let $G=(V,E)$ be a
vertex-colored interval graph with a $k$-coloring $\gamma \colon V \rightarrow
\{1,\ldots,k\}$ for some $k \in \mathbb N$. A subset of vertices $S\subseteq V$
is called \emph{$f$-balanced} if $S$ contains $f$ vertices from each color
class. In the $f$-BIS and $f$-BDS problems, the objective is to compute an
independent set or a dominating set that is $f$-balanced. We show that both
problems are \NP-complete even on proper interval graphs. For the BIS problem
on interval graphs, we design two \FPT\ algorithms, one parameterized by
$(f,k)$ and the other by the vertex cover number of $G$. Moreover, we present a
2-approximation algorithm for a slight variation of BIS on proper interval
graphs.
</p></div>
    </summary>
    <updated>2020-03-12T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-03-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2003.05269</id>
    <link href="http://arxiv.org/abs/2003.05269" rel="alternate" type="text/html"/>
    <title>On Function Description</title>
    <feedworld_mtime>1583971200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vuckovac:Rade.html">Rade Vuckovac</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2003.05269">PDF</a><br/><b>Abstract: </b>The main result is that: function descriptions are not made equal, and they
can be categorised in at least two categories using various computational
methods for function evaluation. The result affects Kolmogorov complexity and
Random Oracle Model notions. More precisely, the idea that the size of an
object and the size of the smallest computer program defining that object is a
ratio that represents the object complexity needs additional definitions to
hold its original assertions.
</p></div>
    </summary>
    <updated>2020-03-12T01:22:18Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-03-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2003.05267</id>
    <link href="http://arxiv.org/abs/2003.05267" rel="alternate" type="text/html"/>
    <title>Hitting Long Directed Cycles is Fixed-Parameter Tractable</title>
    <feedworld_mtime>1583971200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/G=ouml=ke:Alexander.html">Alexander Göke</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Marx:D=aacute=niel.html">Dániel Marx</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mnich:Matthias.html">Matthias Mnich</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2003.05267">PDF</a><br/><b>Abstract: </b>In the Directed Long Cycle Hitting Set} problem we are given a directed graph
$G$, and the task is to find a set $S$ of at most $k$ vertices/arcs such that
$G-S$ has no cycle of length longer than $\ell$. We show that the problem can
be solved in time $2^{\mathcal O(\ell k^3\log k + k^5\log k\log\ell)}\cdot
n^{\mathcal O(1)}$, that is, it is fixed-parameter tractable (FPT)
parameterized by $k$ and $\ell$. This algorithm can be seen as a far-reaching
generalization of the fixed-parameter tractability of {\sc Mixed Graph Feedback
Vertex Set} [Bonsma and Lokshtanov WADS 2011], which is already a common
generalization of the fixed-parameter tractability of (undirected) {\sc
Feedback Vertex Set} and the {\sc Directed Feedback Vertex Set} problems, two
classic results in parameterized algorithms. The algorithm requires significant
insights into the structure of graphs without directed cycles length longer
than $\ell$ and can be seen as an exact version of the approximation algorithm
following from the Erd{\H{o}}s-P{\'o}sa property for long cycles in directed
graphs proved by Kreutzer and Kawarabayashi [STOC 2015].
</p></div>
    </summary>
    <updated>2020-03-12T01:23:48Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-03-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2003.05217</id>
    <link href="http://arxiv.org/abs/2003.05217" rel="alternate" type="text/html"/>
    <title>Scheduling.jl -- Collaborative and Reproducible Scheduling Research with Julia</title>
    <feedworld_mtime>1583971200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hunold:Sascha.html">Sascha Hunold</a>, Bartłomiej Przybylski <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2003.05217">PDF</a><br/><b>Abstract: </b>We introduce the Scheduling.jl Julia package, which is intended for
collaboratively conducting scheduling research and for sharing implementations
of algorithms. It provides the fundamental building blocks for implementing
scheduling algorithms following the three-field notation of Graham et al.,
i.e., it has functionality to describe machine environments, job
characteristics, and optimality criteria. Our goal is to foster algorithm and
code sharing in the scheduling community. Scheduling.jl can also be used to
support teaching scheduling theory in classes. We will show the main
functionalities of Scheduling.jl and give an example on how to use it by
comparing different algorithms for the problem of P||Cmax .
</p></div>
    </summary>
    <updated>2020-03-12T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-03-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2003.05185</id>
    <link href="http://arxiv.org/abs/2003.05185" rel="alternate" type="text/html"/>
    <title>Induced subgraphs of bounded treewidth and the container method</title>
    <feedworld_mtime>1583971200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Abrishami:Tara.html">Tara Abrishami</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chudnovsky:Maria.html">Maria Chudnovsky</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pilipczuk:Marcin.html">Marcin Pilipczuk</a>, Paweł Rzążewski, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Seymour:Paul.html">Paul Seymour</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2003.05185">PDF</a><br/><b>Abstract: </b>A hole in a graph is an induced cycle of length at least 4. A hole is long if
its length is at least 5. By $P_t$ we denote a path on $t$ vertices. In this
paper we give polynomial-time algorithms for the following problems: the
Maximum Weight Independent Set problem in long-hole-free graphs, and the
Feedback Vertex Set problem in $P_5$-free graphs. Each of the above results
resolves a corresponding long-standing open problem.
</p>
<p>An extended $C_5$ is a five-vertex hole with an additional vertex adjacent to
one or two consecutive vertices of the hole. Let $\mathcal{C}$ be the class of
graphs excluding an extended $C_5$ and holes of length at least $6$ as induced
subgraphs; $\mathcal{C}$ contains all long-hole-free graphs and all $P_5$-free
graphs. We show that, given an $n$-vertex graph $G \in \mathcal{C}$ with vertex
weights and an integer $k$, one can in time $n^{\Oh(k)}$ find a maximum-weight
induced subgraph of $G$ of treewidth less than $k$. This implies both
aforementioned results.
</p></div>
    </summary>
    <updated>2020-03-12T01:21:03Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-03-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2003.05175</id>
    <link href="http://arxiv.org/abs/2003.05175" rel="alternate" type="text/html"/>
    <title>Online Graph Matching Problems with a Worst-Case Reassignment Budget</title>
    <feedworld_mtime>1583971200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shin:Yongho.html">Yongho Shin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kim:Kangsan.html">Kangsan Kim</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lee:Seungmin.html">Seungmin Lee</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/An:Hyung=Chan.html">Hyung-Chan An</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2003.05175">PDF</a><br/><b>Abstract: </b>In the online bipartite matching with reassignments problem, an algorithm is
initially given only one side of the vertex set of a bipartite graph; the
vertices on the other side are revealed to the algorithm one by one, along with
its incident edges. The algorithm is required to maintain a matching in the
current graph, where the algorithm revises the matching after each vertex
arrival by reassigning vertices. Bernstein, Holm, and Rotenberg showed that an
online algorithm can maintain a matching of maximum cardinality by performing
amortized $O(\log^2 n)$ reassignments per arrival.
</p>
<p>In this paper, we propose to consider the general question of how requiring a
non-amortized hard budget $k$ on the number of reassignments affects the
algorithms' performances, under various models from the literature.
</p>
<p>We show that a simple, widely-used algorithm is a best-possible deterministic
algorithm for all these models. For the unweighted maximum-cardinality problem,
the algorithm is a $(1-\frac{2}{k+2})$-competitive algorithm, which is the best
possible for a deterministic algorithm both under vertex arrivals and edge
arrivals. Applied to the load balancing problem, this yields a bifactor online
algorithm. For the weighted problem, which is traditionally studied assuming
the triangle inequality, we show that the power of reassignment allows us to
lift this assumption and the algorithm becomes a $\frac{1}{2}$-competitive
algorithm for $k=4$, improving upon the $\frac{1}{3}$ of the previous algorithm
without reassignments. We show that this also is a best-possible deterministic
algorithm.
</p></div>
    </summary>
    <updated>2020-03-12T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-03-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2003.05152</id>
    <link href="http://arxiv.org/abs/2003.05152" rel="alternate" type="text/html"/>
    <title>A generalized Sylvester-Gallai type theorem for quadratic polynomials</title>
    <feedworld_mtime>1583971200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Shir Peleg, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shpilka:Amir.html">Amir Shpilka</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2003.05152">PDF</a><br/><b>Abstract: </b>In this work we prove a version of the Sylvester-Gallai theorem for quadratic
polynomials that takes us one step closer to obtaining a deterministic
polynomial time algorithm for testing zeroness of
$\Sigma^{[3]}\Pi\Sigma\Pi^{[2]}$ circuits. Specifically, we prove that if a
finite set of irreducible quadratic polynomials $\mathcal{Q}$ satisfy that for
every two polynomials $Q_1,Q_2\in \mathcal{Q}$ there is a subset
$\mathcal{K}\subset \mathcal{Q}$, such that $Q_1,Q_2 \notin \mathcal{K}$ and
whenever $Q_1$ and $Q_2$ vanish then also $\prod_{i\in \mathcal{K}} Q_i$
vanishes, then the linear span of the polynomials in $\mathcal{Q}$ has
dimension $O(1)$. This extends the earlier result [Shpilka19] that showed a
similar conclusion when $|\mathcal{K}| = 1$.
</p>
<p>An important technical step in our proof is a theorem classifying all the
possible cases in which a product of quadratic polynomials can vanish when two
other quadratic polynomials vanish. I.e., when the product is in the radical of
the ideal generates by the two quadratics. This step extends a result from
[Shpilka19]that studied the case when one quadratic polynomial is in the
radical of two other quadratics.
</p></div>
    </summary>
    <updated>2020-03-12T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-03-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2003.05141</id>
    <link href="http://arxiv.org/abs/2003.05141" rel="alternate" type="text/html"/>
    <title>On Degree Sequence Optimization</title>
    <feedworld_mtime>1583971200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Onn:Shmuel.html">Shmuel Onn</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2003.05141">PDF</a><br/><b>Abstract: </b>We consider the problem of finding a subgraph of a given graph which
maximizes a given function evaluated at its degree sequence. While the problem
is intractable already for convex functions, we show that it can be solved in
polynomial time for convex multi-criteria objectives. We next consider the
problem with separable objectives, which is NP-hard already when all vertex
functions are the square. We consider a colored extension of the separable
problem, which includes the notorious exact matching problem as a special case,
and show that it can be solved in polynomial time on graphs of bounded
tree-depth for any vertex functions. We mention some of the many remaining open
problems.
</p></div>
    </summary>
    <updated>2020-03-12T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-03-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2003.05119</id>
    <link href="http://arxiv.org/abs/2003.05119" rel="alternate" type="text/html"/>
    <title>Magic: the Gathering is as Hard as Arithmetic</title>
    <feedworld_mtime>1583971200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Biderman:Stella.html">Stella Biderman</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2003.05119">PDF</a><br/><b>Abstract: </b>Magic: the Gathering is a popular and famously complicated card game about
magical combat. Recently, several authors including Chatterjee and Ibsen-Jensen
(2016) and Churchill, Biderman, and Herrick (2019) have investigated the
computational complexity of playing Magic optimally. In this paper we show that
the ``mate-in-$n$'' problem for Magic is $\Delta^0_n$-hard and that optimal
play in two-player Magic is non-arithmetic in general. These results apply to
how real Magic is played, can be achieved using standard-size tournament legal
decks, and do not rely on stochasticity or hidden information. Our paper builds
upon the construction that Churchill, Biderman, and Herrick (2019) used to show
that this problem was at least as hard as the halting problem.
</p></div>
    </summary>
    <updated>2020-03-12T01:22:23Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-03-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2003.05101</id>
    <link href="http://arxiv.org/abs/2003.05101" rel="alternate" type="text/html"/>
    <title>Tensorized Random Projections</title>
    <feedworld_mtime>1583971200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Beheshteh T. Rakhshan, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rabusseau:Guillaume.html">Guillaume Rabusseau</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2003.05101">PDF</a><br/><b>Abstract: </b>We introduce a novel random projection technique for efficiently reducing the
dimension of very high-dimensional tensors. Building upon classical results on
Gaussian random projections and Johnson-Lindenstrauss transforms~(JLT), we
propose two tensorized random projection maps relying on the tensor train~(TT)
and CP decomposition format, respectively. The two maps offer very low memory
requirements and can be applied efficiently when the inputs are low rank
tensors given in the CP or TT format. Our theoretical analysis shows that the
dense Gaussian matrix in JLT can be replaced by a low-rank tensor implicitly
represented in compressed form with random factors, while still approximately
preserving the Euclidean distance of the projected inputs. In addition, our
results reveal that the TT format is substantially superior to CP in terms of
the size of the random projection needed to achieve the same distortion ratio.
Experiments on synthetic data validate our theoretical analysis and demonstrate
the superiority of the TT decomposition.
</p></div>
    </summary>
    <updated>2020-03-12T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-03-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2003.05023</id>
    <link href="http://arxiv.org/abs/2003.05023" rel="alternate" type="text/html"/>
    <title>Complexity of cutting planes and branch-and-bound in mixed-integer optimization</title>
    <feedworld_mtime>1583971200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Basu:Amitabh.html">Amitabh Basu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Conforti:Michele.html">Michele Conforti</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Summa:Marco_Di.html">Marco Di Summa</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jiang:Hongyi.html">Hongyi Jiang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2003.05023">PDF</a><br/><b>Abstract: </b>We investigate the theoretical complexity of branch-and-bound (BB) and
cutting plane (CP) algorithms for mixed-integer optimization. In particular, we
study the relative efficiency of BB and CP, when both are based on the same
family of disjunctions. We extend a result of Dash to the nonlinear setting
which shows that for convex 0/1 problems, CP does at least as well as BB, with
variable disjunctions. We sharpen this by giving instances of the stable set
problem where we can provably establish that CP does exponentially better than
BB. We further show that if one moves away from 0/1 sets, this advantage of CP
over BB disappears; there are examples where BB finishes in O(1) time, but CP
takes infinitely long to prove optimality, and exponentially long to get to
arbitrarily close to the optimal value (for variable disjunctions). We next
show that if the dimension is considered a fixed constant, then the situation
reverses and BB does at least as well as CP (up to a polynomial blow up), no
matter which family of disjunctions is used. This is also complemented by
examples where this gap is exponential (in the size of the input data).
</p></div>
    </summary>
    <updated>2020-03-12T01:20:28Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-03-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2003.04969</id>
    <link href="http://arxiv.org/abs/2003.04969" rel="alternate" type="text/html"/>
    <title>IoT Expunge: Implementing Verifiable Retention of IoT Data</title>
    <feedworld_mtime>1583971200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Panwar:Nisha.html">Nisha Panwar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sharma:Shantanu.html">Shantanu Sharma</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gupta:Peeyush.html">Peeyush Gupta</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Ghosh:Dhrubajyoti.html">Dhrubajyoti Ghosh</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mehrotra:Sharad.html">Sharad Mehrotra</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Venkatasubramanian:Nalini.html">Nalini Venkatasubramanian</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2003.04969">PDF</a><br/><b>Abstract: </b>The growing deployment of Internet of Things (IoT) systems aims to ease the
daily life of end-users by providing several value-added services. However, IoT
systems may capture and store sensitive, personal data about individuals in the
cloud, thereby jeopardizing user-privacy. Emerging legislation, such as
California's CalOPPA and GDPR in Europe, support strong privacy laws to protect
an individual's data in the cloud. One such law relates to strict enforcement
of data retention policies. This paper proposes a framework, entitled IoT
Expunge that allows sensor data providers to store the data in cloud platforms
that will ensure enforcement of retention policies. Additionally, the cloud
provider produces verifiable proofs of its adherence to the retention policies.
Experimental results on a real-world smart building testbed show that IoT
Expunge imposes minimal overheads to the user to verify the data against data
retention policies.
</p></div>
    </summary>
    <updated>2020-03-12T01:27:53Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-03-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.11867</id>
    <link href="http://arxiv.org/abs/2002.11867" rel="alternate" type="text/html"/>
    <title>Bridging the Gap between Spatial and Spectral Domains: A Survey on Graph Neural Networks</title>
    <feedworld_mtime>1583971200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Zhiqian.html">Zhiqian Chen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Fanglan.html">Fanglan Chen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Lei.html">Lei Zhang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Ji:Taoran.html">Taoran Ji</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fu:Kaiqun.html">Kaiqun Fu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhao:Liang.html">Liang Zhao</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Feng.html">Feng Chen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lu:Chang=Tien.html">Chang-Tien Lu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.11867">PDF</a><br/><b>Abstract: </b>The success of deep learning has been widely recognized in many machine
learning tasks during the last decades, ranging from image classification and
speech recognition to natural language understanding. As an extension of deep
learning, Graph neural networks (GNNs) are designed to solve the non-Euclidean
problems on graph-structured data which can hardly be handled by general deep
learning techniques. Existing GNNs under various mechanisms, such as random
walk, PageRank, graph convolution, and heat diffusion, are designed for
different types of graphs and problems, which makes it difficult to compare
them directly. Previous GNN surveys focus on categorizing current models into
independent groups, lacking analysis regarding their internal connection. This
paper proposes a unified framework and provides a novel perspective that can
widely fit existing GNNs into our framework methodologically. Specifically, we
survey and categorize existing GNN models into the spatial and spectral
domains, and reveal connections among subcategories in each domain. Further
analysis establishes a strong link across the spatial and spectral domains.
</p></div>
    </summary>
    <updated>2020-03-12T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-03-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1808.10073</id>
    <link href="http://arxiv.org/abs/1808.10073" rel="alternate" type="text/html"/>
    <title>Rational Neural Networks for Approximating Jump Discontinuities of Graph Convolution Operator</title>
    <feedworld_mtime>1583971200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Zhiqian.html">Zhiqian Chen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Feng.html">Feng Chen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lai:Rongjie.html">Rongjie Lai</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Xuchao.html">Xuchao Zhang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lu:Chang=Tien.html">Chang-Tien Lu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1808.10073">PDF</a><br/><b>Abstract: </b>For node level graph encoding, a recent important state-of-art method is the
graph convolutional networks (GCN), which nicely integrate local vertex
features and graph topology in the spectral domain. However, current studies
suffer from several drawbacks: (1) graph CNNs relies on Chebyshev polynomial
approximation which results in oscillatory approximation at jump
discontinuities; (2) Increasing the order of Chebyshev polynomial can reduce
the oscillations issue, but also incurs unaffordable computational cost; (3)
Chebyshev polynomials require degree $\Omega$(poly(1/$\epsilon$)) to
approximate a jump signal such as $|x|$, while rational function only needs
$\mathcal{O}$(poly log(1/$\epsilon$))\cite{liang2016deep,telgarsky2017neural}.
However, it's non-trivial to apply rational approximation without increasing
computational complexity due to the denominator. In this paper, the superiority
of rational approximation is exploited for graph signal recovering. RatioanlNet
is proposed to integrate rational function and neural networks. We show that
rational function of eigenvalues can be rewritten as a function of graph
Laplacian, which can avoid multiplication by the eigenvector matrix. Focusing
on the analysis of approximation on graph convolution operation, a graph signal
regression task is formulated. Under graph signal regression task, its time
complexity can be significantly reduced by graph Fourier transform. To overcome
the local minimum problem of neural networks model, a relaxed Remez algorithm
is utilized to initialize the weight parameters. Convergence rate of
RatioanlNet and polynomial based methods on jump signal is analyzed for a
theoretical guarantee. The extensive experimental results demonstrated that our
approach could effectively characterize the jump discontinuities, outperforming
competing methods by a substantial margin on both synthetic and real-world
graphs.
</p></div>
    </summary>
    <updated>2020-03-12T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-03-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/03/11/canada-research-chair-tier-2-at-university-of-victoria-apply-by-april-30-2020/</id>
    <link href="https://cstheory-jobs.org/2020/03/11/canada-research-chair-tier-2-at-university-of-victoria-apply-by-april-30-2020/" rel="alternate" type="text/html"/>
    <title>Canada Research Chair, Tier 2 at University of Victoria  (apply by April 30, 2020)</title>
    <summary>The Department of Electrical and Computer Engineering and Department of Computer Science, University of Victoria, invite applications for a Canada Research Chair (CRC) Tier 2 in Quantum Computing and Engineering. For full details, please visit our website at https://www.uvic.ca/opportunities/faculty-librarian/current/engn_220_102.php. Website: https://www.uvic.ca/opportunities/faculty-librarian/current/engn_220_102.php Email: engradr@uvic.ca</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Department of Electrical and Computer Engineering and Department of Computer Science, University of Victoria, invite applications for a Canada Research Chair (CRC) Tier 2 in Quantum Computing and Engineering.</p>
<p>For full details, please visit our website at <a href="https://www.uvic.ca/opportunities/faculty-librarian/current/engn_220_102.php.">https://www.uvic.ca/opportunities/faculty-librarian/current/engn_220_102.php.</a></p>
<p>Website: <a href="https://www.uvic.ca/opportunities/faculty-librarian/current/engn_220_102.php">https://www.uvic.ca/opportunities/faculty-librarian/current/engn_220_102.php</a><br/>
Email: engradr@uvic.ca</p></div>
    </content>
    <updated>2020-03-11T21:54:50Z</updated>
    <published>2020-03-11T21:54:50Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-03-12T05:20:37Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/031</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/031" rel="alternate" type="text/html"/>
    <title>TR20-031 |  Algebraic Branching Programs, Border Complexity, and Tangent Spaces | 

	Markus Bläser, 

	Christian Ikenmeyer, 

	Meena Mahajan, 

	Anurag Pandey, 

	Nitin Saurabh</title>
    <summary>Nisan showed in 1991 that the width of a smallest noncommutative single-(source,sink) algebraic branching program (ABP) to compute a noncommutative polynomial is given by the ranks of specific matrices. This means that the set of noncommutative polynomials with ABP width complexity at most $k$ is Zariski-closed, an important property in geometric complexity theory. It follows that approximations cannot help to reduce the required ABP width.

It was mentioned by Forbes that this result would probably break when going from single-(source,sink) ABPs to trace ABPs. We prove that this is correct. Moreover, we study the commutative monotone setting and prove a result similar to Nisan, but concerning the analytic closure. We observe the same behavior here: The set of polynomials with ABP width complexity at most $k$ is closed for single-(source,sink) ABPs and not closed for trace ABPs. The proofs reveal an intriguing connection between tangent spaces and the vector space of flows on the ABP.
We close with additional observations on VQP and the closure of VNP which allows us to establish a separation between the two classes.</summary>
    <updated>2020-03-11T08:31:35Z</updated>
    <published>2020-03-11T08:31:35Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-03-12T05:20:25Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2020/03/11/more-uniqueness-sudoku</id>
    <link href="https://11011110.github.io/blog/2020/03/11/more-uniqueness-sudoku.html" rel="alternate" type="text/html"/>
    <title>More on uniqueness in Sudoku</title>
    <summary>My first post on this blog, lo these nearly 15 years ago, discussed a program I had written to try to solve Sudoku puzzles deductively (rather than by the easier computational method, backtracking), with the goal of being able to automatically grade the puzzles and automatically generate explanations for how to solve a given puzzle. And a few months later I posted again, on deduction rules that take advantage of the assumption that a puzzle has a unique solution, by ruling out choices that would cause any solution consistent with them to become non-unique. Since then, that part of my solver has been relatively stable, although I have added other rules for Nishio and 2SAT and posted here about more general uniqueness deduction rules in map-coloring puzzles.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="https://11011110.github.io/blog/2005/07/20/updated-python-library.html">My first post on this blog</a>, lo these nearly 15 years ago, discussed a program I had written to try to solve Sudoku puzzles deductively (rather than by the easier computational method, backtracking), with the goal of being able to automatically grade the puzzles and automatically generate explanations for how to solve a given puzzle. And a few months later I posted again, on <a href="https://11011110.github.io/blog/2005/10/15/assuming-uniqueness-in.html">deduction rules that take advantage of the assumption that a puzzle has a unique solution</a>, by ruling out choices that would cause any solution consistent with them to become non-unique. Since then, that part of my solver has been relatively stable, although I have added other rules for <a href="https://11011110.github.io/blog/2012/02/23/solving-single-digit-sudoku.html">Nishio</a> and <a href="https://11011110.github.io/blog/2009/04/26/sudoku-and-2sat.html">2SAT</a> and posted here about <a href="https://11011110.github.io/blog/2019/07/28/any-order-puzzle.html">more general uniqueness deduction rules in map-coloring puzzles</a>.</p>

<p>I’ve also occasionally been using my program to generate puzzles for me to work on, and today it found an interesting test case, a puzzle that it thought would be much more difficult than it turned out to be for me. This mis-rating happened because the uniqueness deduction rules I’m using in my own deductions are stronger than the ones in my program (although some of its other rules are stronger than I typically apply myself). In its initial state, the puzzle looks like:</p>

<p style="text-align: center;"><img alt="Sudoku puzzle" src="https://11011110.github.io/blog/assets/2020/ambig-sudoku-givens.svg"/></p>

<p>My program tells me that it’s at the second highest level of difficulty that it knows about: it has to resort to using 2SAT, but it can successfully solve it that way. (The highest level is for puzzles where it is forced to use backtracking.) Usually, for me, puzzles at that level require me to use written notes to keep track of the deductions, rather than doing it all in my head, but not this time. Using more-or-less standard reasoning, one can fill in the cells of the puzzle to reach the state:</p>

<p style="text-align: center;"><img alt="Partially solved Sudoku puzzle" src="https://11011110.github.io/blog/assets/2020/ambig-sudoku-partial.svg"/></p>

<p>This is where my program gets stuck and has to resort to more powerful deduction rules. But as a human solving this puzzle, here is what I see: In row 3, the two empty cells must contain the pair of digits 3 and 5. In the center right block of nine cells, the two empty cells must again be 3 and 5. And in the center block of cells, the 5 digit is confined to three cells aligned with those two pairs of empty cells. If the 3 digit were also confined to the same three cells in the center block, it and the five would have to occupy the two diagonally aligned cells out of the three, because otherwise they would line up and prevent one of the other pairs of 3-5 cells from having any value. But then the 3-5 cells in row 3, the center block, and column 7 would form a closed system (shown by the red squares below): nothing else outside those cells could affect which of those six cells contains 3, and which contains 5. Within that closed system, there are two solutions, obtained from each other by swapping the locations of the 3 and the 5. But that would violate the assumption of uniqueness.</p>

<p style="text-align: center;"><img alt="Closed system of cells in a partially solved Sudoku puzzle" src="https://11011110.github.io/blog/assets/2020/ambig-sudoku-closed.svg"/></p>

<p>Even if the 7 in the center cell weren’t there, the same reasoning would apply. Since this closed system with a non-unique solution would happen automatically if we confine the digit 3 to the same three center-block cells as the digit 5, the digit 3 must be elsewhere in the center block, which can only mean that it is in column 4. Once we make this deduction, the rest of the puzzle falls into place.</p>

<p>My program only has built into it a couple of ad-hoc rules to prevent closed systems of four cells with two solutions, and it misses the one in this example because it involves six cells. It’s making me think that I need a more general description of the possible closed systems (at least the ones involving only two digit values, like this), in order to match the deductions I’m making by hand and make my program’s difficulty estimates more accurate.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/103803219892010865">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2020-03-11T00:06:00Z</updated>
    <published>2020-03-11T00:06:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2020-03-11T07:27:08Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2003.04873</id>
    <link href="http://arxiv.org/abs/2003.04873" rel="alternate" type="text/html"/>
    <title>Moving Target Monte Carlo</title>
    <feedworld_mtime>1583884800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Haoyun Ying, Keheng Mao, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mosegaard:Klaus.html">Klaus Mosegaard</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2003.04873">PDF</a><br/><b>Abstract: </b>The Markov Chain Monte Carlo (MCMC) methods are popular when considering
sampling from a high-dimensional random variable $\mathbf{x}$ with possibly
unnormalised probability density $p$ and observed data $\mathbf{d}$. However,
MCMC requires evaluating the posterior distribution $p(\mathbf{x}|\mathbf{d})$
of the proposed candidate $\mathbf{x}$ at each iteration when constructing the
acceptance rate. This is costly when such evaluations are intractable. In this
paper, we introduce a new non-Markovian sampling algorithm called Moving Target
Monte Carlo (MTMC). The acceptance rate at $n$-th iteration is constructed
using an iteratively updated approximation of the posterior distribution
$a_n(\mathbf{x})$ instead of $p(\mathbf{x}|\mathbf{d})$. The true value of the
posterior $p(\mathbf{x}|\mathbf{d})$ is only calculated if the candidate
$\mathbf{x}$ is accepted. The approximation $a_n$ utilises these evaluations
and converges to $p$ as $n \rightarrow \infty$. A proof of convergence and
estimation of convergence rate in different situations are given.
</p></div>
    </summary>
    <updated>2020-03-11T23:22:09Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-03-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2003.04863</id>
    <link href="http://arxiv.org/abs/2003.04863" rel="alternate" type="text/html"/>
    <title>Circulation Control for Faster Minimum Cost Flow in Unit-Capacity Graphs</title>
    <feedworld_mtime>1583884800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Axiotis:Kyriakos.html">Kyriakos Axiotis</a>, Aleksander Mądry, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vladu:Adrian.html">Adrian Vladu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2003.04863">PDF</a><br/><b>Abstract: </b>We present an $m^{11/8+o(1)} \log W$-time algorithm for solving the minimum
cost flow problem in graphs with unit capacity, where $W$ is the absolute
maximum weight of an edge in the graph. For sparse graphs, this improves over
the best known running time for this problem and, by well-known reductions,
also implies improved running times for the shortest path problem with negative
weights, minimum cost bipartite $\boldsymbol{\mathit{b}}$-matching when
$\|\boldsymbol{\mathit{b}}\|_1 = O(m)$, and recovers the running time of the
currently fastest algorithm for maximum flow in graphs with unit capacities
(Liu-Sidford).
</p>
<p>Our algorithm relies on developing an interior point method--based framework
which acts on the space of circulations in the underlying graph. From the
combinatorial point of view, this framework can be viewed as iteratively
improving the cost of a suboptimal solution by pushing flow around
circulations. These circulations are derived by computing a regularized version
of the standard Newton step, which can be done efficiently due to recent
developments on computing $\ell_p$-norm minimizing flows
(Kyng-Peng-Sachdeva-Wang). We obtain our faster algorithm by combining this
approach with a customized preconditioning method, which aims to ensure that
the graph on which these circulations are computed has sufficiently large
conductance.
</p></div>
    </summary>
    <updated>2020-03-11T23:22:20Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-03-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2003.04834</id>
    <link href="http://arxiv.org/abs/2003.04834" rel="alternate" type="text/html"/>
    <title>Algebraic Branching Programs, Border Complexity, and Tangent Spaces</title>
    <feedworld_mtime>1583884800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bl=auml=ser:Markus.html">Markus Bläser</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Ikenmeyer:Christian.html">Christian Ikenmeyer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mahajan:Meena.html">Meena Mahajan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pandey:Anurag.html">Anurag Pandey</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Saurabh:Nitin.html">Nitin Saurabh</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2003.04834">PDF</a><br/><b>Abstract: </b>Nisan showed in 1991 that the width of a smallest noncommutative
single-(source,sink) algebraic branching program (ABP) to compute a
noncommutative polynomial is given by the ranks of specific matrices. This
means that the set of noncommutative polynomials with ABP width complexity at
most $k$ is Zariski-closed, an important property in geometric complexity
theory. It follows that approximations cannot help to reduce the required ABP
width.
</p>
<p>It was mentioned by Forbes that this result would probably break when going
from single-(source,sink) ABPs to trace ABPs. We prove that this is correct.
Moreover, we study the commutative monotone setting and prove a result similar
to Nisan, but concerning the analytic closure. We observe the same behavior
here: The set of polynomials with ABP width complexity at most $k$ is closed
for single-(source,sink) ABPs and not closed for trace ABPs. The proofs reveal
an intriguing connection between tangent spaces and the vector space of flows
on the ABP. We close with additional observations on VQP and the closure of VNP
which allows us to establish a separation between the two classes.
</p></div>
    </summary>
    <updated>2020-03-11T23:20:30Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-03-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2003.04740</id>
    <link href="http://arxiv.org/abs/2003.04740" rel="alternate" type="text/html"/>
    <title>Drawing Graphs with Circular Arcs and Right Angle Crossings</title>
    <feedworld_mtime>1583884800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chaplick:Steven.html">Steven Chaplick</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/F=ouml=rster:Henry.html">Henry Förster</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kryven:Myroslav.html">Myroslav Kryven</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wolff:Alexander.html">Alexander Wolff</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2003.04740">PDF</a><br/><b>Abstract: </b>In a RAC drawing of a graph, vertices are represented by points in the plane,
adjacent vertices are connected by line segments, and crossings must form right
angles. Graphs that admit such drawings are RAC graphs. RAC graphs are
beyond-planar graphs and have been studied extensively. In particular, it is
known that a RAC graph with n vertices has at most 4n - 10 edges. We introduce
a superclass of RAC graphs, which we call arc-RAC graphs. In an arc-RAC
drawing, edges are drawn as circular arcs whereas crossings must still form
right angles. We provide a Tur\'an-type result showing that an arc-RAC graph
with n vertices has at most 14n - 12 edges and that there are n-vertex arc-RAC
graphs with 4.5n - o(n) edges.
</p></div>
    </summary>
    <updated>2020-03-11T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-03-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2003.04605</id>
    <link href="http://arxiv.org/abs/2003.04605" rel="alternate" type="text/html"/>
    <title>Maximizing Happiness in Graphs of Bounded Clique-Width</title>
    <feedworld_mtime>1583884800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bliznets:Ivan.html">Ivan Bliznets</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sagunov:Danil.html">Danil Sagunov</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2003.04605">PDF</a><br/><b>Abstract: </b>Clique-width is one of the most important parameters that describes
structural complexity of a graph. Probably, only treewidth is more studied
graph width parameter. In this paper we study how clique-width influences the
complexity of the Maximum Happy Vertices (MHV) and Maximum Happy Edges (MHE)
problems. We answer a question of Choudhari and Reddy '18 about
parameterization by the distance to threshold graphs by showing that MHE is
NP-complete on threshold graphs. Hence, it is not even in XP when parameterized
by clique-width, since threshold graphs have clique-width at most two. As a
complement for this result we provide a $n^{\mathcal{O}(\ell \cdot
\operatorname{cw})}$ algorithm for MHE, where $\ell$ is the number of colors
and $\operatorname{cw}$ is the clique-width of the input graph. We also
construct an FPT algorithm for MHV with running time
$\mathcal{O}^*((\ell+1)^{\mathcal{O}(\operatorname{cw})})$, where $\ell$ is the
number of colors in the input. Additionally, we show $\mathcal{O}(\ell n^2)$
algorithm for MHV on interval graphs.
</p></div>
    </summary>
    <updated>2020-03-11T23:21:57Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-03-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2003.04578</id>
    <link href="http://arxiv.org/abs/2003.04578" rel="alternate" type="text/html"/>
    <title>Optimal-size problem kernels for $d$-Hitting Set in linear time and space</title>
    <feedworld_mtime>1583884800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bevern:Ren=eacute=_van.html">René van Bevern</a>, Pavel V. Smirnov <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2003.04578">PDF</a><br/><b>Abstract: </b>We improve two linear-time data reduction algorithms for the d-Hitting Set
problem to work in linear space, thus obtaining the first algorithms for
computing problem kernels of asymptotically optimal size $O(k^d)$ for d-Hitting
Set in linear time and space. We experimentally compare the two algorithms to a
classical data reduction algorithm of Weihe and evaluate their combinations.
</p></div>
    </summary>
    <updated>2020-03-11T23:22:32Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-03-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2003.04523</id>
    <link href="http://arxiv.org/abs/2003.04523" rel="alternate" type="text/html"/>
    <title>Elder-rule-staircodes for Augmented Metric Spaces</title>
    <feedworld_mtime>1583884800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cai:Chen.html">Chen Cai</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kim:Woojin.html">Woojin Kim</a>, Facundo Memoli, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Yusu.html">Yusu Wang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2003.04523">PDF</a><br/><b>Abstract: </b>An augmented metric space $(X, d_X, f_X)$ is a metric space $(X, d_X)$
equipped with a function $f_X: X \to \mathbb{R}$. It arises commonly in
practice, e.g, a point cloud $X$ in $\mathbb{R}^d$ where each point $x\in X$
has a density function value $f_X(x)$ associated to it. Such an augmented
metric space naturally gives rise to a 2-parameter filtration. However, the
resulting 2-parameter persistence module could still be of wild representation
type, and may not have simple indecomposables.
</p>
<p>In this paper, motivated by the elder-rule for the zeroth homology of a
1-parameter filtration, we propose a barcode-like summary, called the
elder-rule-staircode, as a way to encode the zeroth homology of the 2-parameter
filtration induced by a finite augmented metric space. Specifically, given a
finite $(X, d_X, f_X)$, its elder-rule-staircode consists of $n = |X|$ number
of staircase-like blocks in the plane. We show that the fibered barcode, the
fibered merge tree, and the graded Betti numbers associated to the zeroth
homology of the 2-parameter filtration induced by $(X, d_X, f_X)$ can all be
efficiently computed once the elder-rule-staircode is given. Furthermore, for
certain special cases, this staircode corresponds exactly to the set of
indecomposables of the zeroth homology of the 2-parameter filtration. Finally,
we develop and implement an efficient algorithm to compute the
elder-rule-staircode in $O(n^2\log n)$ time, which can be improved to
$O(n^2\alpha(n))$ if $X$ is from a fixed dimensional Euclidean space
$\mathbb{R}^d$, where $\alpha(n)$ is the inverse Ackermann function.
</p></div>
    </summary>
    <updated>2020-03-11T23:20:54Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-03-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2003.04438</id>
    <link href="http://arxiv.org/abs/2003.04438" rel="alternate" type="text/html"/>
    <title>On the computational complexity of uncapacitated multi-plant lot-sizing problems</title>
    <feedworld_mtime>1583884800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>J. O. Cunha, H. H. Kramer, R. A. Melo <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2003.04438">PDF</a><br/><b>Abstract: </b>Production and inventory planning have become crucial and challenging in
nowadays competitive industrial and commercial sectors, especially when
multiple plants or warehouses are involved. In this context, this paper
addresses the complexity of uncapacitated multi-plant lot-sizing problems. We
consider a multi-item uncapacitated multi-plant lot-sizing problem with fixed
transfer costs and show that two of its very restricted special cases are
already NP-hard. Namely, we show that the single-item uncapacitated multi-plant
lot-sizing problem with a single period and the multi-item uncapacitated
two-plant lot-sizing problem with fixed transfer costs are NP-hard.
Furthermore, as a direct implication of the proven results, we also show that a
two-echelon multi-item lot-sizing with joint setup costs on transportation is
NP-hard.
</p></div>
    </summary>
    <updated>2020-03-11T23:21:46Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-03-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2020/03/10/workshop-in-quantum-information-complexity-cryptography/</id>
    <link href="https://cstheory-events.org/2020/03/10/workshop-in-quantum-information-complexity-cryptography/" rel="alternate" type="text/html"/>
    <title>Workshop in Quantum Information, Complexity &amp; Cryptography</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">June 11-12, 2020 University of York, UK https://sites.google.com/york.ac.uk/quicc/quicc We are organising a two-day event at the University of York in collaboration with York Interdisciplinary Centre for Cyber Security, which brings researchers in Quantum Information, Complexity and Cryptography together. The goal is to cover recent topics in these areas and facilitate interactions between them. The event … <a class="more-link" href="https://cstheory-events.org/2020/03/10/workshop-in-quantum-information-complexity-cryptography/">Continue reading <span class="screen-reader-text">Workshop in Quantum Information, Complexity &amp; Cryptography</span></a></div>
    </summary>
    <updated>2020-03-10T17:40:42Z</updated>
    <published>2020-03-10T17:40:42Z</published>
    <category term="workshop"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2020-03-12T05:21:19Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4671</id>
    <link href="https://www.scottaaronson.com/blog/?p=4671" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4671#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4671" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">National disgrace</title>
    <summary xml:lang="en-US">In this blog’s now 15-year-history, at Waterloo and then MIT and now UT Austin, I’ve tried to make it clear that I blog always as Scott, never as Dr. Aaronson of Such-and-Such Institution. (God knows I’ve written a few things that a prudent dean might prefer that I hadn’t—though if I couldn’t honestly say that, […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>In this blog’s now 15-year-history, at Waterloo and then MIT and now UT Austin, I’ve tried to make it clear that I blog <em>always</em> as Scott, never as Dr. Aaronson of Such-and-Such Institution.  (God knows I’ve written a few things that a prudent dean might prefer that I hadn’t—though if I couldn’t honestly say that, in what sense would I even enjoy “academic freedom”?)  Today, though, for <a href="https://www.scottaaronson.com/blog/?p=3167">only about</a> the second time, I’m also writing as a professor motivated by a duty of care toward his students.</p>



<p>A week ago, most of my grad students were in the Bay Area for a workshop; they then returned and spent a week hanging around the CS building like normal.  Yesterday I learned that at least one of those students developed symptoms consistent with covid19.  Of course, it’s much more likely to be a boring cold or flu—but still, in any sane regime, just to be certain, such a person would <strong>promptly get tested</strong>.</p>



<p>After quarantining himself, my student called the “24/7 covid19 hotline” listed in an email from the university’s president, but found no one answering the phone over the weekend.  Yesterday he finally got through—only to be told, flatly, that he couldn’t be tested due to insufficient capacity.  When I heard this, I asked my department chair and dean to look into the matter, and received confirmation that yeah, it sucks, but this is the situation.</p>



<p>If it’s true that, <a href="https://www.nytimes.com/2020/03/09/opinion/coronavirus-testing-new-york.html?fbclid=IwAR24o0pcDW2n6usYpyIC-bPhGUhoIkYAcvS_R4QvPv8yEdp0KsEF1XJWQv8">as I’ve read</a>, the same story is currently playing itself out all over the country, then this presumably isn’t the fault of anyone in UT’s health service or the city of Austin.  Rather, as they say in the movies, it goes all the way to the top, to the CDC director and ultimately the president—or rather, to the festering wound that now sits where the top used to be.</p>


<p>Speaking of movies, over the weekend Dana and I watched <a href="https://www.amazon.com/Contagion-Marion-Cotillard/dp/B006IVBSBU">Contagion</a>, as apparently many people are now doing.  I confess that I’d missed it when it came out in 2011.  I think it’s a cinematic masterpiece.  It freely violates many of the rules of movie narrative: characters are neither done in by their own hubris, nor saved by their faith or by being A-list stars.  But <em>Contagion</em> is also more than a glorified public service announcement about the importance of washing your hands.  It wants to show you the reality of the human world of its characters, and <em>also</em> the reality of a virus, and how the two realities affect each other despite obeying utterly different logic.  It will show a scene that’s important to the charaters for human reasons, and then it will show you the same scene again, except this time making you focus on whose hand touched which surface in which order.<br/><!--StartFragment--></p>
<p>But for all its excellence and now-obvious prescience, there are two respects in which Contagion failed to predict the reality of 2020.  The first is just a lucky throw of the RNA dice: namely, that the real coronavirus is perhaps an order of magnitude less fatal than the movie virus, and for some unknown reason it spares children.  But the second difference is terrifying.  All the public health authorities in the movie are ultra-empowered and competent.  They do badass things like injecting themselves with experimental vaccines.  If they stumble, it’s only in deeply understandable ways that any of us might (e.g., warning their own loved ones to evacuate a city before warning the public).</p>
<p>In other words, when the scriptwriters, writing their disaster movie, tried to imagine the worst, they failed to imagine a US government that would essentially abandon the public, by</p>
<p>(1) botching a simple test that dozens of other countries performed without issue,<br/>(2) preventing anyone else from performing their own tests, and then<br/>(3) turning around and using the lack of positive test results to justify its own inaction.</p>
<p>They failed to imagine a CDC that might as well not exist for all it would do in its hour of need: one that <a href="https://twitter.com/paulg/status/1236967513008877568">didn’t even bother to update its website on weekends</a>, and stopped publishing data once the data became too embarrassing.  The scriptwriters <em>did</em> imagine a troll gleefully spreading lies about the virus online, endangering anyone who listened to him.  They failed to imagine a universe where that troll was the president.</p>


<p>“I mean, don’t get me wrong,” they told me.  “Trump is a racist con artist, a demagogue, the precise thing that Adams and Hamilton and Franklin tried to engineer our republic to avoid.  Just, don’t get so <em>depressed</em> about it all the time!  Moaning about how we’re trapped in a <a href="https://www.scottaaronson.com/blog/?p=3294">freakishly horrible</a> branch of the wavefunction, blah blah.  I mean look on the bright side!  What an incredible run of luck we’ve had, that we elected a president with the mental horizons of a sadistic toddler, and yet <em>in three years he hasn’t caused even one apocalypse</em>.  You’re alive and healthy, your loved ones are alive and healthy.  It could be a lot worse!”</p>



<p>The above, I suspect, is a sentiment that will now forever date any writing containing it to January 2020 or earlier.</p></div>
    </content>
    <updated>2020-03-10T17:07:03Z</updated>
    <published>2020-03-10T17:07:03Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Adventures in Meatspace"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Rage Against Doofosity"/>
    <category scheme="https://www.scottaaronson.com/blog" term="The Fate of Humanity"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2020-03-10T17:22:33Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://theorydish.blog/?p=1559</id>
    <link href="https://theorydish.blog/2020/03/10/cacm-through-the-lens-of-a-passionate-theoretician/" rel="alternate" type="text/html"/>
    <title>CACM – Through the Lens of a Passionate Theoretician</title>
    <summary>Spending time in insulation? Nothing more to watch on Netflix? Looking for something to read instead? My CACM article, about Avi Wigderson‘s excellent book and about the reach of computation appeared recently. Enjoy!</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Spending time in insulation? Nothing more to watch on Netflix? Looking for something to read instead? <a href="https://cacm.acm.org/magazines/2020/3/243025-through-the-lens-of-a-passionate-theoretician/fulltext">My CACM article</a>, about <a href="https://www.math.ias.edu/avi/">Avi Wigderson</a>‘s <a href="https://www.math.ias.edu/avi/book">excellent book</a> and about the reach of computation appeared recently. Enjoy!</p></div>
    </content>
    <updated>2020-03-10T16:14:07Z</updated>
    <published>2020-03-10T16:14:07Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Omer Reingold</name>
    </author>
    <source>
      <id>https://theorydish.blog</id>
      <logo>https://theorydish.files.wordpress.com/2017/03/cropped-nightdish1.jpg?w=32</logo>
      <link href="https://theorydish.blog/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://theorydish.blog" rel="alternate" type="text/html"/>
      <link href="https://theorydish.blog/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://theorydish.blog/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Stanford's CS Theory Research Blog</subtitle>
      <title>Theory Dish</title>
      <updated>2020-03-12T05:21:25Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-2996231259381150068</id>
    <link href="https://blog.computationalcomplexity.org/feeds/2996231259381150068/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/03/theorist-paul-r-young-passed-away.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/2996231259381150068" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/2996231259381150068" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/03/theorist-paul-r-young-passed-away.html" rel="alternate" type="text/html"/>
    <title>Theorist Paul R Young passed away</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">In the early days of theoretical computer science, say 1960-1990 the main tools used were logic.<br/>
This made sense since, early on:<br/>
<br/>
a) Some of the basic notions like DTIME(T(n)), P, NP used Turing Machines in their definitions<br/>
<br/>
b) Some of the basic notions like reductions were modeled after similar concepts in<br/>
computability theory.<br/>
<br/>
One of the people who did much work in the interface between Logic and TCS was Paul Young.<br/>
He <a href="https://news.cs.washington.edu/2020/03/05/remembering-paul-young-1936-2019/">passed away</a> in December. Here are some highlights of his work:<br/>
<br/>
1) One of the first books that covered both computability and complexity:<br/>
<br/>
An Introduction to the general theory of Algorithms<br/>
by Machtey and Young.<br/>
<br/>
2) In Computability theory all many-one complete sets are computably isomorphic. Berman and<br/>
Hartmanis conjectured that the poly-many-one degree of the NP-complete sets was the same. This<br/>
would mean that all NP-complete sets were poly-isom (all of the known ones are).<br/>
<br/>
Mahaney and Young in the paper<br/>
<br/>
<i>Reductions Among Polynomial Isomorphism Types</i><br/>
<br/>
showed that every many-one poly degree either has one degree or has an infinite number of<br/>
degrees in a very complicated way.<br/>
<br/>
3) Recall that a <i>Cook Reduction from A to B </i>allows many queries to B, whereas a <i>Karp Reduction</i><br/>
only allows one query and your answer must be the same sense as the query.<br/>
Are there  cases where a Cook reduction is faster? Yes, from the paper<br/>
<br/>
<i>Cook reducibility is faster than Karp Reducibility</i><br/>
<br/>
by Longpre and Young<br/>
<br/>
(The original title was going to be <i>Cook is Faster than Karp</i>, but it was changed since it invoked<br/>
images of Cook and Karp in a footrace.  Hmmm. Which one would be faster?)<br/>
<br/>
<br/>
4) The <i>Boolean Hierarchy </i>is a hierarchy of iterations of NP sets. What if instead of starting with P<br/>
one started with RP (Randomized Poly time). What an intriguing notion! To find out read<br/>
<br/>
<br/>
<i>Generalized Boolean Hierarchies over RP</i><br/>
<br/>
by  Alberto Bertoni, Danilo Bruschi, Deborah Joseph, Meera Sitharam, Paul Young<br/>
<br/>
5) There are many more, mostly on the theme of the interaction of logic and computer science.<br/>
<br/>
                       I saw him speak on some of these topics and was inspired by how much one could<br/>
take notions of computability and translate them into complexity theory.  The field has gone in a<br/>
different direction since then (more combinatorial) but we still use many of the basic concepts<br/>
like reducibility.  As such we all owe a debit to Paul Young.</div>
    </content>
    <updated>2020-03-10T11:42:00Z</updated>
    <published>2020-03-10T11:42:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2020-03-11T20:16:03Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/030</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/030" rel="alternate" type="text/html"/>
    <title>TR20-030 |  Barriers for Rectangular Matrix Multiplication | 

	Matthias Christandl, 

	François Le Gall, 

	Vladimir Lysikov, 

	Jeroen Zuiddam</title>
    <summary>We study the algorithmic problem of multiplying large matrices that are rectangular. We prove that the method that has been used to construct the fastest algorithms for rectangular matrix multiplication cannot give optimal algorithms. In fact, we prove a precise numerical barrier for this method. Our barrier improves the previously known barriers, both in the numerical sense, as well as in its generality. We prove our result using the asymptotic spectrum of tensors. More precisely, we crucially make use of two families of real tensor parameters with special algebraic properties: the quantum functionals and the support functionals. In particular, we prove that any lower bound on the dual exponent of matrix multiplication $\alpha$ via the big Coppersmith-Winograd tensors cannot exceed 0.625.</summary>
    <updated>2020-03-09T15:23:38Z</updated>
    <published>2020-03-09T15:23:38Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-03-12T05:20:25Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://lucatrevisan.wordpress.com/?p=4322</id>
    <link href="https://lucatrevisan.wordpress.com/2020/03/09/i-have-been-practicing-for-this-my-whole-life/" rel="alternate" type="text/html"/>
    <title>I have been practicing for this my whole life</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">As the coronavirus epidemic advances in Italy with a 25-30% growth rate (meaning that the numbers are doubling every 3-4 days), and after two weeks of “lockdown-lite” in Northern Italy seems to have made no difference, the Italian government imposed … <a href="https://lucatrevisan.wordpress.com/2020/03/09/i-have-been-practicing-for-this-my-whole-life/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>As the coronavirus epidemic advances in Italy with a 25-30% growth rate (meaning that the numbers are doubling every 3-4 days), and after two weeks of “lockdown-lite” in Northern Italy seems to have made no difference, the Italian government imposed on Sunday morning a stricter lockdown on the region of Lombardy and some cities outside the region including Venice. Several people have reached out to ask how things are going, so here is a brief recap. </p>
<p><span id="more-4322"/></p>
<p>First of all, I would like to give a shoutout to Taiwan, which is currently the country that has done the <a href="https://www.zmescience.com/other/pieces/how-taiwan-managed-to-avoid-a-coronavirus-outbreak/">best job stopping an outbreak</a>. The Taiwanese have several things going for them: the SARS scare made the government plan for the next epidemic, instead of making it up as it would go along, and their preparedness was impressive. The plan focused on isolation, contact-tracing, and people being careful: kudos to the Taiwanese for how well they complied. From the little that I have learned about Taiwan after living there for two months a couple of years ago, the Taiwanese are not rule-followers the way the Swiss or the Singaporean can be. But if they bend or break rules, they do that after a lot of consideration for how this impacts others. Basically, people <i>care about strangers</i>, a disposition that helps a lot in controlling an epidemic (and which is not a big part of the Italian national mood).</p>
<p>But let’s talk about me. This is my mood right now:<br/>
<img alt="self_isolate" class="alignnone size-full wp-image-4326" src="https://lucatrevisan.files.wordpress.com/2020/03/self_isolate.png?w=584"/></p>
<p>(Image credit: <a href="https://xkcd.com/">xkcd</a> by Randall Munroe)</p>
<p>Since we are past isolation-and-contact-tracing, the main goal is to reduce person-to-person contact so that we can stop the exponential growth. For the past two weeks, besides the usual recommendations (do not kiss hello and goodbye, do not shake hands, wash hands frequently, do not touch your face) the government recommended keeping a one-meter distance from other people. There has been some inventive ways to keep going under these requirements. For example cinemas (in the regions in which they were not required to shut down) sold tickets for at most a third of the seats, asking people to leave two empty seats between any occupied seats. </p>
<p>Last Saturday, before the newest set of regulations were in place, I went out for a drink. The bar had cordoned off the counter area</p>
<p> <img alt="IMG_9383" class="alignnone size-full wp-image-4328" src="https://lucatrevisan.files.wordpress.com/2020/03/img_9383.jpg?w=584"/></p>
<p>They asked everybody who came in to seat down, at one of a few well-separated tables. Gloves-wearing servers took orders and brought some food (instead of the usual buffet). Once all tables were taken, a server stood outside preventing other people from coming in.</p>
<p>As we were drinking our aperitivi at a safe distance from each other, news began to leak of the new measures, which the government eventually announced at 2am Sunday morning. The leak suggested that Lombardy, Venice, and other places, would be included in the so-called <i>red zone</i>, which was a group of small towns that had been completely isolated for the past two weeks (nobody could go in and out except ambulances, trash collection trucks, and deliveries). In a development that might not have happened in Taiwan, a few hundred people rushed to train stations in Milan and Venice to flee South.</p>
<p>The actual regulations allowed travel in and out of the places affected by the new lockdown, but only for <i>demonstrated work or health reasons</i>. This is what the regulation said, but how would people prove their reason? The Italian genius for bureaucracy started cranking in the next few hours, and now, at train stations, people are required to sign an affidavit stating the existence of such a reason before boarding a train:</p>
<p><img alt="affidavit" class="alignnone size-full wp-image-4329" src="https://lucatrevisan.files.wordpress.com/2020/03/affidavit.jpeg?w=584"/></p>
<p>In the locked-down cities, all bars and restaurants have to close by 6pm, and all places where people may congregate (including churches, gyms, swimming pools, in addition to museums, schools and universities which were already closed) are closed all day. Even funeral and weddings are banned. Grocery stores will have to ensure that people stay within a meter of each other, making people wait outside and enter in small groups if necessary.</p>
<p>What about me? I am procrastinating on writing blog posts about online optimization and on reviewing papers for ICALP, I have started reading William Gibson’s latest novel <i>Agency</i> and watching the tv series <i>Pose</i>, and I am cooking every meal. Considering that I like to sleep and that I am spending a fair amount of time on the phone, I have got the whole day covered.</p>
<p>What is next? At this point in Lombardy about a person in 2,500, or 0.04% of the population, is infected, and we have run out of ICU beds. The rate of infection in Wuhan peaked at about 0.6% of the population, and this was well past the point at which they had run out of hospital beds in general. Hopefully, here we will peak well below that. On the other hand, left to its own devices, in the absence of any containment measures, I have seen estimates that the disease would peak a bit higher than a flu epidemic, at 20% or even 60% of the population.</p>
<p>So, find the Taiwanese in yourself, think about others, and wash those hands.</p></div>
    </content>
    <updated>2020-03-09T12:24:27Z</updated>
    <published>2020-03-09T12:24:27Z</published>
    <category term="Milan"/>
    <category term="Taiwan"/>
    <author>
      <name>luca</name>
    </author>
    <source>
      <id>https://lucatrevisan.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://lucatrevisan.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://lucatrevisan.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://lucatrevisan.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://lucatrevisan.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>"Marge, I agree with you - in theory. In theory, communism works. In theory." -- Homer Simpson</subtitle>
      <title>in   theory</title>
      <updated>2020-03-12T05:20:11Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16767</id>
    <link href="https://rjlipton.wordpress.com/2020/03/08/the-virtue-of-closed-problems/" rel="alternate" type="text/html"/>
    <title>The Virtue of Closed Problems</title>
    <summary>A new condition in property testing Composite crop of src1, src2 Maryam Aliakbarpour and Sandeep Silwal are PhD students at MIT. They have a joint paper titled, “Testing Properties of Multiple Distributions with Few Samples.” Aliakbarpour is advised by Ronitt Rubinfeld. Silwal has a different advisor, Piotr Indyk. Could we test which advisor is better […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>A new condition in property testing</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2020/03/aliakbarpoursilwal.png"><img alt="" class="alignright wp-image-16769" height="125" src="https://rjlipton.files.wordpress.com/2020/03/aliakbarpoursilwal.png?w=181&amp;h=125" width="181"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Composite crop of <a href="https://risingstars18-eecs.mit.edu/participant-aliakbarpour/">src1</a>, <a href="http://sandeepsilwal.com/">src2</a></font></td>
</tr>
</tbody>
</table>
<p>
Maryam Aliakbarpour and Sandeep Silwal are PhD students at MIT. They have a joint <a href="https://arxiv.org/pdf/1911.07324.pdf">paper</a> titled, “Testing Properties of Multiple Distributions with Few Samples.” Aliakbarpour is advised by Ronitt Rubinfeld. Silwal has a different advisor, Piotr Indyk. Could we test which advisor is better by sampling? Haha, not a chance…</p>
<p>
Today we will discuss this paper as an example of the power of computer science theory.</p>
<p>
Aliakbarpour and Silwal (AS) prove results on property testing, which is of course a long studied area in statistics, in mathematics, and in complexity theory. Many problems of property testing are open; many are very hard problems, and some are really impossible—such as distinguishing slight differences between distributions. With all due respect, the brilliance of their paper is not in solving open problems. Rather it is how they modify property testing in a novel manner. </p>
<p>
Their proofs are clever, are technically strong, but we feel more importantly is how they change the problems. That is, they show how to add a new constraint to property testing, where: </p>
<ol>
<li>
The constraint is reasonable and appears to be natural; <p/>
</li><li>
The constraint is powerful and allows efficient algorithms where previously none were possible.
</li></ol>
<p>Let’s look at this more closely.</p>
<p>
</p><p/><h2> Opening a Closed Problem </h2><p/>
<p/><p>
We all know about open problems and closed problems. There are however two kinds of closed problems: ones that have been settled and ones that have been proved impossible to settle. We also know that one can often take an open problem and define a meaningful subcase of it that can be solved. What may be less obvious is how one can do the same with the latter kind of closed problem.</p>
<p>
The work of AS is a perfect example of this phenomenon. They take a problem that is unsolvable and change it to one that is solvable. The details of their results are less important than their change to the underlying problem. One of the key insights throughout theory is that we often have made major progress by changing the ground rules. The AS work is a particularly clear case of this. </p>
<p/><h2> The New Condition </h2><p/>
<p/><p>
AS call it the <i>structural condition</i>. They postulate a consistency type of condition on property testing. Suppose that one is interesting in testing whether or not a collection of slot-machines are fair. That is, are they set to cheat players or not? This is known to be hard to do with few tests. But after adding their new constraint it becomes quite efficient.</p>
<p>
Among some examples to convey their definition, they postulate a row of slot machines in a casino that are supposed to give the same distribution of prizes <img alt="{j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{j}"/> with known <em>fair</em> probabilities <img alt="{q(j)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq%28j%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q(j)}"/>. As usual with property testing we want to distinguish between two hypotheses that are some distance apart: one that the machines conform to the fair distribution <img alt="{q}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q}"/> and an alternative hypothesis that each is far from fair. There are two relevant factors:</p>
<ol>
<li>
We do not get to make many tests on one machine of our choosing. The best we can do is watch people try the machines. They may try different machines and so give only a few sample results per machine. <p/>
</li><li>
There are cases of this situation 1 where although each machine is far from fair the joint distribution of a few samples cannot be told apart from fair. The authors mention a trivial case where <img alt="{q}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q}"/> is uniform and we get just one result from each machine, results all different from each other. These cannot be told apart. But there are less-trivial cases.
</li></ol>
<p>
Such situations are common with real-word data. The authors mention cases of medical data when one gets just one or a few blood readings from patients with disparate situational factors that can bias their samples. The joint effect of the biases may completely mask the systematic population tendency one is trying to test for. This is the setting in which the problem of distinguishing has been regarded as impossible, case closed. In the slot-machine example, Aliakbarpour and Silwal state their structural condition informally as follows:</p>
<blockquote><p><b> </b> <em> Our goal is to test whether all the machines were fair … or they are far from being fair. In this case, we can naturally assume that if the machines are unfair, the house will assign a lower probability to the expensive prizes, and higher probability to cheap ones. </em>
</p></blockquote>
<p/><p>
Of course, the house <em>could</em> cheat players without cheating in this uniform manner. More subtle rigging of the machines in different ways could mask the lowered expectation. But what AS are saying is: <i>Provided the house cheats in this consistent manner, then they can be discovered quickly</i>. </p>
<p>
</p><p/><h2> Formal Definition and Proof Idea </h2><p/>
<p/><p>
The formal definition is that each of the true source distributions is biased the same way in the same components as the expected (“fair”) distribution:</p>
<blockquote><p><b>Definition 1</b> <em> A sequence <img alt="{p^1,\dots, p^m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%5E1%2C%5Cdots%2C+p%5Em%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{p^1,\dots, p^m}"/> of distributions on a discrete domain <img alt="{[n]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Bn%5D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{[n]}"/> obeys the structural condition relative to the distribution <img alt="{q}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{q}"/> if there is a subset <img alt="{A \subset [n]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA+%5Csubset+%5Bn%5D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{A \subset [n]}"/> such that for all <img alt="{i \in [m]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi+%5Cin+%5Bm%5D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{i \in [m]}"/> and <img alt="{j \in [n]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bj+%5Cin+%5Bn%5D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{j \in [n]}"/>: </em></p><em>
<p align="center"><img alt="\displaystyle  \begin{cases} p^i(j) \geq q(j) &amp; \text{if } j \in A\\ p^i(j) \leq q(j) &amp; \text{otherwise}. \end{cases} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Bcases%7D+p%5Ei%28j%29+%5Cgeq+q%28j%29+%26+%5Ctext%7Bif+%7D+j+%5Cin+A%5C%5C+p%5Ei%28j%29+%5Cleq+q%28j%29+%26+%5Ctext%7Botherwise%7D.+%5Cend%7Bcases%7D+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="\displaystyle  \begin{cases} p^i(j) \geq q(j) &amp; \text{if } j \in A\\ p^i(j) \leq q(j) &amp; \text{otherwise}. \end{cases} "/></p>
</em><p><em/>
</p></blockquote>
<p/><p>
The term “structural condition” is vanilla and perhaps saying the <img alt="{p^i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%5Ei%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p^i}"/> are “conformally biased” relative to <img alt="{q}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q}"/> would be more descriptive. A major point which the authors emphasize right afterward is that the set <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/> is <em>unknown</em>. There are exponentially many possibilities for what <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/> could be—so we cannot try to guess it. Rather, proofs using this condition need to exploit how all the <img alt="{p^{i}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%5E%7Bi%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p^{i}}"/> distributions conform to the same <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/>. The slot-machine example arguably does not reflect this point in full—because we can know in advance what the major and minor prizes of a slot machine are (including “no prize” among the latter). The medical-data examples and others certainly do, however.</p>
<p>
We can convey briefly and intuitively how this condition is used for the case where <img alt="{q}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q}"/> is uniform distribution on <img alt="{[n]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Bn%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{[n]}"/>—which is quite general as testing for many distributions can be efficiently mapped into this case. A key property of uniform distribution is that among all distributions on <img alt="{[n]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Bn%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{[n]}"/>, it minimizes the probability of getting <em>collisions</em> from repeated samples. This idea has yielded the most effective test statistics for problems when there is only one distribution <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/>. When there are multiple <img alt="{p^i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%5Ei%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p^i}"/> the effectiveness can be blunted in instances like the one in the previous section—the instances that are impossible. </p>
<p>
However, AS show that their structural condition is just what’s needed to bridge the gap that keeps the impossible cases from being distinguished. Realizing that the compounded complications of having multiple <img alt="{p^i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%5Ei%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p^i}"/> can be resolved by this stroke is their act of brilliance. Their paper applies it successfully to two other problem settings—identity testing and closeness testing—and also shows meaningful instances that obey and are resolved by their definition but that escape an older condition involving product distributions. As usual, we say to see the <a href="https://arxiv.org/pdf/1911.07324.pdf">paper</a> for the details.</p>
<p>
</p><p/><h2> Consequences in Crypto and Inference? </h2><p/>
<p/><p>
It remains our place to ask, in which other cases might the AS condition arise and what uses might it have? I can think first of one implication for adversarial strategies in cryptography. It goes like this:</p>
<p>
We can view the AS theorems as saying that anyone who wishes to cheat others should <b>not</b> be consistent. Being consistent according to some utility criterion—<em>even an unknown one</em>—makes it easier for others to detect that they are cheating. </p>
<p>
Following their slot-machine example suggests this: Arrange the machines in total to cheat players. But make it so that they are not consistent. They can set some prizes up in probability and some lower, and importantly, do this differently on different machines. They could even make some machines pay out more than the legal expectation—while still giving a small profit to the casino so it does not become too obvious to customers that those machines are “lucky.” There is safety in non-conformity alone. </p>
<p align="center"><img alt="\displaystyle  \S " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5CS+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \S "/></p>
<p>
Ken notices a similarity to the chess-modeling situation he began describing in this recent <a href="https://rjlipton.wordpress.com/2019/11/29/predicating-predictivity/">post</a>. Instead of prizes of known value, in chess we have distributions over possible moves whose values are <em>not</em> so readily apparent to the player—that’s what makes chess challenging to play. </p>
<p>
In his case, giving any chess position <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t}"/> and a player <img alt="{P}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{P}"/> having that position, he postulates a true distribution <img alt="{p^t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%5Et%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p^t}"/> of moves <img alt="{P}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{P}"/> would make and wants to compare that with the distribution <img alt="{q^t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq%5Et%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q^t}"/> projected by his model. Now there can be many positions <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t}"/> with different characteristics, but Ken can treat the distributions <img alt="{q^t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq%5Et%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q^t}"/> coming from his model as one fixed point of reference <img alt="{q}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q}"/>, and he can give different positions the same ranks of legal moves <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/> (best), then <img alt="{2,\dots, n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%2C%5Cdots%2C+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2,\dots, n}"/>. If positions have different numbers of legal moves he can pad them out by treating illegal moves the same as completely losing blunders. </p>
<p>
So he has a situation like this: different <img alt="{p^t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%5Et%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p^t}"/> and one <img alt="{q}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q}"/> over a bunch of positions. Ken knows his model not only varies in accuracy but is biased in ways explained in that post. It appears that this bias is highly conformal. The model is trained to make the projection <img alt="{q(1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq%281%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q(1)}"/> of the probability of the first move accurate on average. Then the tendency is that the projections of the second-best and third-best moves are off one way, and the projections of all the other moves are off the other way. This is like having <img alt="{A = \{2,3\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA+%3D+%5C%7B2%2C3%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A = \{2,3\}}"/> or its complement most of the time. The new statistical tests that Ken is crafting also live under the specter of impossibility. A co-worker has demonstrated that they <em>fail</em> in cases randomly generated from normal distributions. But so far they are appearing to succeed in Ken’s more-structured situations from his real-world chess data. On this we will stay tuned.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Does the AS paper say something about cryptography? How widely does their condition apply?</p>
<p/></font></font></div>
    </content>
    <updated>2020-03-09T03:58:12Z</updated>
    <published>2020-03-09T03:58:12Z</published>
    <category term="All Posts"/>
    <category term="detection"/>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="Results"/>
    <category term="distributions"/>
    <category term="impossible"/>
    <category term="Maryam Aliakbarpour"/>
    <category term="Property testing"/>
    <category term="sampling"/>
    <category term="Sandeep Silwal"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2020-03-12T05:20:34Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2020/03/08/mathematics-books-women</id>
    <link href="https://11011110.github.io/blog/2020/03/08/mathematics-books-women.html" rel="alternate" type="text/html"/>
    <title>Mathematics books by women</title>
    <summary>It’s International Women’s Day, and The Aperiodical has a new piece up on “Books about Maths by Women”. One of my own projects for the last few weeks has been to create Wikipedia articles on noteworthy mathematics books, and so far roughly half of the creations have included at least one woman among their authors. They are (alphabetical by title):</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>It’s International Women’s Day, and <em>The Aperiodical</em> has a new piece up on “<a href="https://aperiodical.com/2020/03/iwd-2020-books-about-maths-by-women/">Books about Maths by Women</a>”. One of my own projects for the last few weeks has been to create Wikipedia articles on noteworthy mathematics books, and so far roughly half of the creations have included at least one woman among their authors. They are (alphabetical by title):</p>

<ul>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/The_Calculating_Machines">The Calculating Machines</a></em> (1992), by Ernst Martin, translated and edited by <a href="https://en.wikipedia.org/wiki/Peggy_A._Kidwell">Peggy A. Kidwell</a> and Michael R. Williams. A history of pre-World-War-II mechanical calculators.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Closing_the_Gap:_The_Quest_to_Understand_Prime_Numbers">Closing the Gap: The Quest to Understand Prime Numbers</a></em> (2017), by <a href="https://en.wikipedia.org/wiki/Vicky_Neale">Vicky Neale</a>. History and recent developments in the twin prime conjecture.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Combinatorics_of_Finite_Geometries">Combinatorics of Finite Geometries</a></em> (1986; 2nd ed. 1997), by <a href="https://en.wikipedia.org/wiki/Lynn_Batten">Lynn Batten</a>. An undergraduate textbook on finite projective planes, finite affine planes, and other finite geometries.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Complexities:_Women_in_Mathematics">Complexities: Women in Mathematics</a></em> (2005), edited by <a href="https://en.wikipedia.org/wiki/Bettye_Anne_Case">Bettye Anne Case</a> and <a href="https://en.wikipedia.org/wiki/Complexities:_Women_in_Mathematics">Anne M. Leggett</a>. A celebration of women in mathematics featuring the stories of over 80 women.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Crocheting_Adventures_with_Hyperbolic_Planes">Crocheting Adventures with Hyperbolic Planes</a></em> (2009; 2nd ed. 2018), by <a href="https://en.wikipedia.org/wiki/Daina_Taimina">Daina Taimina</a>. How to make hyperbolic surfaces out of crochet, and what we can learn mathematically from tactile interactions with these surfaces.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Difference_Equations:_From_Rabbits_to_Chaos">Difference Equations: From Rabbits to Chaos</a></em> (2005), by Paul Cull, <a href="https://en.wikipedia.org/wiki/Mary_Flahive">Mary Flahive</a>, and Robby Robson, an undergraduate textbook on finite difference equations, population dynamics, and related topics.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/A_Guide_to_the_Classification_Theorem_for_Compact_Surfaces">A Guide to the Classification Theorem for Compact Surfaces</a></em> (2013), by Jean Gallier and <a href="https://en.wikipedia.org/wiki/Dianna_Xu">Dianna Xu</a>. An exposition of the result that the topology of a two-dimensional surface can be completely described by its orientability, Euler characteristic, and number of punctures.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Introduction_to_Tropical_Geometry">Introduction to Tropical Geometry</a></em> (2015) by <a href="https://en.wikipedia.org/wiki/Diane_Maclagan">Diane Maclagan</a> and Bernd Sturmfels. What happens if you do algebraic geometry in an arithmetic where the two basic operations are addition and minimization, instead of multiplication and addition?</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Mathematics_in_Ancient_Egypt:_A_Contextual_History">Mathematics in Ancient Egypt: A Contextual History</a></em> (2016), by <a href="https://en.wikipedia.org/wiki/Annette_Imhausen">Annette Imhausen</a>. The length of time covered by this history is greater than the length of time since it happened. Its focus is on putting Egyptian mathematics into the context of the society of the times, rather than (as in earlier studies) trying to translate it into modern mathematical concepts and analyze the mathematical foundations of Egyptian calculational methods.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Pearls_in_Graph_Theory">Pearls in Graph Theory: A Comprehensive Introduction</a></em> (1990), by Gerhard Ringel and <a href="https://www.legacy.com/obituaries/skagitvalleyherald/obituary.aspx?n=nora-anne-hartsfield&amp;pid=153284332&amp;fhid=5497">Nora Hartsfield</a>. A collection of the authors’ favorite topics in graph theory, although not as comprehensive as the title makes out.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Poincar%C3%A9_and_the_Three-Body_Problem">Poincaré and the Three-Body Problem</a></em> (1997), by <a href="https://en.wikipedia.org/wiki/June_Barrow-Green">June Barrow-Green</a>. The history surrounding Poincaré’s work on the the three-body problem, which led to chaos theory, began a long dispute between mathematicians and  astronomers over the convergence of series, and was a big part of Poincaré’s own fame.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Proofs_That_Really_Count">Proofs That Really Count: the Art of Combinatorial Proof</a></em> (2003), by Arthur Benjamin and <a href="https://en.wikipedia.org/wiki/Jennifer_Quinn">Jennifer Quinn</a>. An exposition of the concept of bijective proofs, in which one proves the equality of two integer formulas by showing that both count the same set of mathematical objects.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Quasicrystals_and_Geometry">Quasicrystals and Geometry</a></em> (1995), by <a href="https://en.wikipedia.org/wiki/Marjorie_Senechal">Marjorie Senechal</a>. An investigation of the relation between the mathematical properties of aperiodic tilings like the Penrose tiling, and physical quasicrystals whose X-ray diffraction patterns show systems of Bragg peaks with five-way symmetry.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Symmetry_in_Mechanics">Symmetry in Mechanics: A Gentle, Modern Introduction</a></em> (2001), by <a href="https://en.wikipedia.org/wiki/Stephanie_Singer">Stephanie Singer</a>. How to use symplectic geometry to reduce the solution of the two-body problem from twelve dimensions (three for the position and momentum of each body) to two, leading to an elegant derivation of Kepler’s laws of planetary motion.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Taking_Sudoku_Seriously">Taking Sudoku Seriously: The math behind the world’s most popular pencil puzzle</a></em> (2011), by Jason Rosenhouse and <a href="https://en.wikipedia.org/wiki/Laura_Taalman">Laura Taalman</a>. An exploration of various topics in mathematics related to Sudoku puzzles and their solution, including Latin squares, graph coloring, algorithms for solving systems of polynomials, and extremal combinatorics.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/De_numeris_triangularibus_et_inde_de_progressionibus_arithmeticis:_Magisteria_magna">Thomas Harriot’s Doctrine of Triangular Numbers</a></em> (2009), by Thomas Harriot, edited and translated by <a href="https://en.wikipedia.org/wiki/Janet_Beery">Janet Beery</a> and <a href="https://en.wikipedia.org/wiki/Jackie_Stedall">Jackie Stedall</a>. An important precursor to the invention of calculus by Newton, using finite differences instead of infinitesimal differences.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Treks_Into_Intuitive_Geometry">Treks into Intuitive Geometry: The World of Polygons and Polyhedra</a></em> (2015), by Jin Akiyama and Kiyoko Matsunaga. A Socratic dialogue on tessellations, polyhedra, polygonal dissections, and polyhedral unfoldings.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Viewpoints:_Mathematical_Perspective_and_Fractal_Geometry_in_Art">Viewpoints: Mathematical Perspective and Fractal Geometry in Art</a></em> (2011), by Marc Frantz and <a href="https://en.wikipedia.org/wiki/Annalisa_Crannell">Annalisa Crannell</a>. An undergraduate general-education textbook on perspective geometry and fractal structure in art.</p>
  </li>
</ul>

<p>There are many more I could include, but haven’t yet (including most of the <em>Aperiodical</em> list). Many of these books are award-winners, but to a large extent inclusion in this list is driven by my personal taste in books, so many of these are somewhat specialized rather than being general-audience books. But the main criterion for inclusion on Wikipedia is that everything must have multiple in-depth sources, and everything in the article must come from those sources. For books those sources are not the book itself, but (typically) published book reviews. The bare minimum is two reviews, but I’ve been aiming for books with at least four. So for instance I would have liked to include <em>Geometry: The Line and the Circle</em> (2019), by Maureen T. Carroll and Elyn Rykken, but I could find only <a href="https://www.maa.org/press/maa-reviews/geometry-the-line-and-the-circle">one review of it</a>, and that’s not enough. To all the book reviewers out there: your efforts are appreciated, and helpful.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/103788964314558993">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2020-03-08T11:40:00Z</updated>
    <published>2020-03-08T11:40:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2020-03-11T07:27:08Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>http://ptreview.sublinear.info/?p=1270</id>
    <link href="https://ptreview.sublinear.info/?p=1270" rel="alternate" type="text/html"/>
    <title>News for February 2020</title>
    <summary>Despite a wealth of February conference deadlines, papers were fairly sparse. We found two EDIT: three EDIT EDIT: four papers for the month of February, please share if we missed any relevant papers. Monotone probability distributions over the Boolean cube can be learned with sublinear samples, by Ronitt Rubinfeld and Arsen Vasilyan (arXiv). By now, […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Despite a wealth of February conference deadlines, papers were fairly sparse. We found <s>two</s> <s>EDIT: three</s> EDIT EDIT: four papers for the month of February, please share if we missed any relevant papers.</p>



<p><strong>Monotone probability distributions over the Boolean cube can be learned with sublinear samples</strong>, by Ronitt Rubinfeld and Arsen Vasilyan (<a href="https://arxiv.org/abs/2002.03415">arXiv</a>). By now, it is well known that assuming an (unknown) distribution enjoys some sort of structure can lead to more efficient algorithms for learning and testing. Often one proves that the structure permits a convenient representation, and exploits this representation to solve the problem at hand. This paper studies the learning of monotone distributions over the Boolean hypercube. The authors exploit and extend a structural statement about monotone Boolean <em>functions</em> by <a href="https://link.springer.com/chapter/10.1007/978-3-662-43948-7_20">Blais, Håstad, Servedio, and Tan</a>, using it to provide sublinear algorithms for estimating the support size, distance to uniformity, and the distribution itself.</p>



<p><strong>Locally Private Hypothesis Selection</strong>, by Sivakanth Gopi, Gautam Kamath, Janardhan Kulkarni, Aleksandar Nikolov, Zhiwei Steven Wu, and Huanyu Zhang (<a href="https://arxiv.org/abs/2002.09465">arXiv</a>). Given a collection of \(k\) distributions and a set of samples from one of them, can we identify which distribution it is? This paper studies this problem (and an agnostic generalization of it) under the constraint of <em>local differential privacy</em>. The authors show that this problem requires \(\Omega(k)\) samples, in contrast to the \(O(\log k)\) complexity in the non-private model. Furthermore, they give \(\tilde O(k)\)-sample upper bounds in various interactivity models.</p>



<p><strong>Efficient Distance Approximation for Structured High-Dimensional Distributions via Learning</strong>, by Arnab Bhattacharyya, Sutanu Gayen, Kuldeep S. Meel, and N. V. Vinodchandran (<a href="https://arxiv.org/abs/2002.05378">arXiv</a>). Given samples from two distributions, can you estimate the total variation distance between them? This paper gives a framework for solving this problem for <em>structured</em> distribution classes, including Ising models, Bayesian networks, Gaussians, and causal models. The approach can be decomposed properly learning the distributions, followed by estimating the distance between the two hypotheses. Challenges arise when densities are hard to compute exactly.</p>



<p><strong>Profile Entropy: A Fundamental Measure for the Learnability and Compressibility of Discrete Distributions</strong>, by Yi Hao and Alon Orlitsky (<a href="https://arxiv.org/abs/2002.11665">arXiv</a>). The histogram of a dataset is the collection of frequency counts of domain elements. The <em>profile</em> of a dataset can be succinctly described as the histogram of the histogram. Recent works have shown that, in some sense, discarding information about your dataset by looking solely at the profile can be beneficial for certain problems in which it is “universal”. This work explores two new quantities, the entropy and dimension of the profile, which turn out to play a key role in quantifying the performance of estimators based on the profile.</p></div>
    </content>
    <updated>2020-03-08T02:54:24Z</updated>
    <published>2020-03-08T02:54:24Z</published>
    <category term="Monthly digest"/>
    <author>
      <name>Gautam Kamath</name>
    </author>
    <source>
      <id>https://ptreview.sublinear.info</id>
      <link href="https://ptreview.sublinear.info/?feed=rss2" rel="self" type="application/atom+xml"/>
      <link href="https://ptreview.sublinear.info" rel="alternate" type="text/html"/>
      <subtitle>The latest in property testing and sublinear time algorithms</subtitle>
      <title>Property Testing Review</title>
      <updated>2020-03-11T23:23:55Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4664</id>
    <link href="https://www.scottaaronson.com/blog/?p=4664" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4664#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4664" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Coronavirus: the second-weirdest solution?</title>
    <summary xml:lang="en-US">Many people have suggested coating handles, doorknobs and so forth with virus-killing copper tape. It’s a shame that this isn’t being tried on a wider scale. In the meantime, though, here’s a related but different idea that I had last night. Imagine we could coat every doorknob, every light switch, every railing, every other surface […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>Many people have suggested coating handles, doorknobs and so forth with <a href="https://www.lesswrong.com/posts/LwcKYR8bykM6vDHyo/coronavirus-justified-practical-advice-thread">virus-killing copper tape</a>.  It’s a shame that this isn’t being tried on a wider scale.  In the meantime, though, here’s a related but different idea that I had last night.</p>



<p>Imagine we could coat every doorknob, every light switch, every railing, every other surface that people might touch in public buildings, with some long-lasting disgusting, sticky, slimy substance.  For a variety of reasons, one probably wouldn’t use actual excrement, although it wouldn’t hurt if the substance <em>looked like</em> that.  Or it could be a sickly neon green or red, to make it impossible to conceal when you’d gotten the substance on your hands.</p>



<p>What would be the result?  Of course, people would avoid touching these surfaces.  If they had to, they’d do so with a napkin or glove whenever possible.  If they had to touch them bare-handedly, they’d rush to wash their hands with soap as soon as possible afterwards.  Certainly they wouldn’t touch their faces before having washed their hands.</p>



<p>In short, they’d show exactly the behaviors that experts agree are among the most helpful, if our goal is to slow the spread of the coronavirus.  In effect, we’d be plugging an unfortunate gap in our evolutionary programming—namely, that the surfaces where viruses can thrive aren’t intuitively disgusting to us, as (say) vomit or putrid meat are—by <em>making</em> those surfaces disgusting, as they ought to be in the middle of a pandemic.</p>



<p>Note that, even if it <em>somehow</em> turns out to be infeasible to coat all the touchable surfaces in public buildings with disgusting goo, you might still derive great personal benefit from <em>imagining</em> them so covered.  If you manage to pull that off, it will yield just the right heuristic for when and how often you should now be washing your hands (and avoiding touching your face), without no need for additional conscious reflection.</p>



<p>Mostly, having the above thoughts made me grateful for my friend <a href="https://en.wikipedia.org/wiki/Robin_Hanson">Robin Hanson</a>.  For as long Robin is around, <a href="https://twitter.com/robinhanson/status/1235020994110205953">tweeting</a> and <a href="http://www.overcomingbias.com/2020/02/consider-controlled-infection.html">blogging</a> from his unique corner of mindspace, no one will ever be able to say that <em>my</em> ideas for how to control the coronavirus were the world’s weirdest or most politically tone-deaf.</p></div>
    </content>
    <updated>2020-03-06T22:21:52Z</updated>
    <published>2020-03-06T22:21:52Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Embarrassing Myself"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Procrastination"/>
    <category scheme="https://www.scottaaronson.com/blog" term="The Fate of Humanity"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2020-03-10T17:22:33Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/029</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/029" rel="alternate" type="text/html"/>
    <title>TR20-029 |  Geometric Rank of Tensors and Subrank of Matrix Multiplication | 

	Guy Moshkovitz, 

	Swastik Kopparty, 

	Jeroen Zuiddam</title>
    <summary>Motivated by problems in algebraic complexity theory (e.g., matrix multiplication) and extremal combinatorics (e.g., the cap set problem and the sunflower problem), we introduce the geometric rank as a new tool in the study of tensors and hypergraphs. We prove that the geometric rank is an upper bound on the subrank of tensors and the independence number of hypergraphs. We prove that the geometric rank is smaller than the slice rank of Tao, and relate geometric rank to the analytic rank of Gowers and Wolf in an asymptotic fashion. As a first application, we use geometric rank to prove a tight upper bound on the (border) subrank of the matrix multiplication tensors, matching Strassen's well-known lower bound from 1987.</summary>
    <updated>2020-03-06T15:03:24Z</updated>
    <published>2020-03-06T15:03:24Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-03-12T05:20:25Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=19462</id>
    <link href="https://gilkalai.wordpress.com/2020/03/06/a-new-polytcs-blog/" rel="alternate" type="text/html"/>
    <title>A new PolyTCS blog!</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">A new PolyTCS blog The PolyTCS Project is a new blog to run collaborative Theoretical Computer Science projects. The initiative is by two graduate students Rupei Xu and Chloe Yang. The logo was designed by Grigory Yaroslavtsev. At this stage … <a href="https://gilkalai.wordpress.com/2020/03/06/a-new-polytcs-blog/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>A new PolyTCS blog</p>
<div class="site-logo"><a class="custom-logo-link" href="https://polytcs.wordpress.com/" rel="home"><img alt="The PolyTCS Project" class="custom-logo" height="96" src="https://polytcs.files.wordpress.com/2019/10/cropped-notequal.png?w=264&amp;h=96" width="264"/></a></div>
<p class="site-title"><a href="https://polytcs.wordpress.com/" rel="home">The PolyTCS Project</a> is a new blog to run collaborative Theoretical Computer Science projects. The initiative is by two graduate students <a href="https://sites.google.com/site/xurupei/">Rupei Xu</a> and Chloe Yang. The logo was designed by Grigory Yaroslavtsev.</p>
<p>At this stage the blog raised possible projects to pursue.  A few days ago Rupei Xu discussed a second possible exciting project:   Project 2: <a href="https://polytcs.wordpress.com/2020/03/06/is-semi-definite-programming-sdp-polynomial-time-solvable/">Is Semi-Definite Programming (SDP) Polynomial-Time Solvable?</a> The first project-proposal (Nov 1, 2019 by Jiapeng Zhang) was <a href="https://polytcs.wordpress.com/2019/11/01/the-entropy-influence-conjecture/">Project 1: The Entropy-Influence Conjecture</a>.</p>
<p>(Here is a <a href="https://rjlipton.wordpress.com/2014/03/15/could-we-have-felt-evidence-for-sdp-p/">2014  post on GLL</a> on the problem of Project 2, and here is <a href="https://terrytao.wordpress.com/2007/08/16/gil-kalai-the-entropyinfluence-conjecture/">my 2007 post on WN</a> on the problem of Project 1.)</p>
<p class="site-title">Good luck!!!</p>
<p> </p></div>
    </content>
    <updated>2020-03-06T14:05:32Z</updated>
    <published>2020-03-06T14:05:32Z</published>
    <category term="Combinatorics"/>
    <category term="Computer Science and Optimization"/>
    <category term="Mathematics over the Internet"/>
    <category term="Chloe Yang"/>
    <category term="Grigory Yaroslavtsev"/>
    <category term="Rupei Xi"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2020-03-12T05:20:29Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/03/06/postdoc-at-national-university-of-singapore-apply-by-april-15-2020/</id>
    <link href="https://cstheory-jobs.org/2020/03/06/postdoc-at-national-university-of-singapore-apply-by-april-15-2020/" rel="alternate" type="text/html"/>
    <title>Postdoc at National University of Singapore (apply by April 15, 2020)</title>
    <summary>Two post-doctoral positions are available for work on developing statistical and computational guarantees for causal inference algorithms. I am looking for candidates with strong publication records either in theoretical computer science and statistics or in causal inference. Please email me regarding your interest, along with your CV and names of two references. . Website: https://www.comp.nus.edu.sg/~arnab/causal-postdoc.html […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Two post-doctoral positions are available for work on developing statistical and computational guarantees for causal inference algorithms. I am looking for candidates with strong publication records either in theoretical computer science and statistics or in causal inference. Please email me regarding your interest, along with your CV and names of two references. .</p>
<p>Website: <a href="https://www.comp.nus.edu.sg/~arnab/causal-postdoc.html">https://www.comp.nus.edu.sg/~arnab/causal-postdoc.html</a><br/>
Email: arnabb@nus.edu.sg</p></div>
    </content>
    <updated>2020-03-06T09:06:13Z</updated>
    <published>2020-03-06T09:06:13Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-03-12T05:20:37Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4649</id>
    <link href="https://www.scottaaronson.com/blog/?p=4649" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4649#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4649" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Turn down the quantum volume</title>
    <summary xml:lang="en-US">Several people asked me to comment on the recent announcement by Honeywell that they’ll soon have what they call “the most powerful” quantum computer (see here for press release, here for Forbes article, here for paper). I’m glad that Honeywell, which many people might know as an air-conditioner manufacturer, has entered the race for trapped-ion […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>Several people asked me to comment on the recent announcement by Honeywell that they’ll soon have what they call “the most powerful” quantum computer (see <a href="https://www.honeywell.com/en-us/newsroom/news/2020/03/behind-the-scenes-of-a-major-quantum-breakthrough">here for press release</a>, <a href="https://www.forbes.com/sites/moorinsights/2020/03/03/honeywell-surprisingly-announces-it-will-be-releasing-the-most-powerful-quantum-computer-in-the-world/#c271c5114b4a">here for <em>Forbes</em> article</a>, <a href="https://www.honeywell.com/content/dam/honeywell/files/Beta_10_Quantum_3_3_2020.pdf">here for paper</a>).  </p>



<p>I’m glad that Honeywell, which many people might know as an air-conditioner manufacturer, has entered the race for trapped-ion QC.  I wish them success.  I’ve known about what they were doing in part because Drew Potter, my friend and colleague in UT Austin’s physics department, took a one-year leave from UT to contribute to their effort.</p>



<p>Here I wanted to comment about one detail in Honeywell’s announcement: namely, the huge emphasis on “quantum volume” as the central metric for judging quantum computing progress, and the basis for calling their own planned device the “most powerful.”  One journalist asked me to explain why quantum volume is such an important measure.  I had to give her an honest answer: I don’t know whether it is.</p>



<p>Quantum volume was invented a few years ago by a group at IBM.  According to one of <a href="https://arxiv.org/pdf/1811.12926.pdf">their papers</a>, it can be defined roughly as 2<sup>k</sup>, where k is the largest number such that you can run a k-qubit random quantum circuit, with depth k and with any-to-any connectivity, and have at least (say) 2/3 probability of measuring an answer that passes some statistical test.  (In the paper, they use what Lijie Chen and I named <a href="https://arxiv.org/abs/1612.05903">Heavy Output Generation</a>, though Google’s Linear Cross-Entropy Benchmark is similar.)</p>



<p>I don’t know why IBM takes the “volume” to be 2<sup>k</sup> rather than k itself.  Leaving that aside, though, the idea was to invent a single “goodness measure” for quantum computers that can’t be gamed <em>either</em> by building a huge number of qubits that don’t maintain nearly enough coherence (what one might call “the D-Wave approach”), <em>or</em> by building just one perfect qubit, <em>or</em> by building qubits that behave well in isolation but don’t interact easily.  Note that the any-to-any connectivity requirement makes things harder for architectures with nearest-neighbor interactions only, like the 2D superconducting chips being built by Google, Rigetti, or IBM itself.</p>



<p>You know the notion of a researcher’s <a href="https://en.wikipedia.org/wiki/H-index">h-index</a>—defined as the largest h such that she’s published h papers that garnered h citations each?  Quantum volume is basically an h-index for quantum computers.  It’s an attempt to take several different yardsticks of experimental progress, none terribly useful in isolation, and combine them into one “consumer index.”</p>



<p>Certainly I sympathize with the goal of broadening people’s focus beyond the “but how many qubits does it have?” question—since the answer to that question is meaningless without further information about what the qubits can <em>do</em>.  From that standpoint, quantum volume seems like a clear step in the right direction.</p>



<p>Alas, <a href="https://en.wikipedia.org/wiki/Goodhart%27s_law">Goodhart’s Law</a> states that “as soon as a measure becomes a target, it ceases to be a good measure.”  That happened years ago with the h-index, which now regularly pollutes academic hiring and promotion decisions, to the point where <a href="https://arxiv.org/abs/2001.09496">its inventor expressed regrets</a>.  Quantum volume is now looking to me like another example of Goodhart’s Law at work.</p>



<p>The position of Honeywell’s PR seems to be that, if they can build a device that can apply 6 layers of gates to 6 qubits, with full connectivity and good fidelity, that will then count as “the world’s most powerful quantum computer,” since it will have the largest volume.  One problem here is that such a device could be simulated by maintaining a vector of only 2<sup>6</sup>=64 amplitudes.  This is nowhere near quantum supremacy (i.e., beating classical computers at some well-defined task), which is a necessary though not sufficient condition for doing anything useful.</p>



<p>Think of a university that achieves an average faculty-to-student ratio of infinity by holding one class with zero students.  It gets the “best score” only by exploiting an obvious defect in the scoring system.</p>



<p>So what’s the alternative?  The policy <em>I</em> prefer is simply to tell the world all your system specs, as clearly as you can, with no attempts made to bury the lede.  How many qubits do you have?  With what coherence times?  With what connectivity?  What are the 1- and 2-qubit gate fidelities?  What depth of circuit can you do?  What resources do the standard classical algorithms need to simulate your system?  Most importantly: what’s the main drawback of your system, the spec that’s the <em>worst</em>, the one you most need to improve?  What prevents you from having a scalable quantum computer right now?  And are you going to tell me, or will you make me scour Appendix III.B in your paper, or worse yet, ask one of your competitors?</p>



<p>I confess that the answers to the above questions are hard to summarize in a single number (unless you, like, concatenated binary encodings of them or something).  But they <em>can</em> be ineffably combined, to produce a progress metric that one of my postdocs suggested calling “quantum scottness,” and which roughly equals the number of expressions of wide-eyed surprise minus the number of groans.</p></div>
    </content>
    <updated>2020-03-05T21:36:59Z</updated>
    <published>2020-03-05T21:36:59Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Quantum"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2020-03-10T17:22:33Z</updated>
    </source>
  </entry>
</feed>
