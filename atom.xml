<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2020-02-29T11:22:03Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.11933</id>
    <link href="http://arxiv.org/abs/2002.11933" rel="alternate" type="text/html"/>
    <title>On Metric DBSCAN with Low Doubling Dimension</title>
    <feedworld_mtime>1582934400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Ding:Hu.html">Hu Ding</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yang:Fan.html">Fan Yang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.11933">PDF</a><br/><b>Abstract: </b>The density based clustering method {\em Density-Based Spatial Clustering of
Applications with Noise (DBSCAN)} is a popular method for outlier recognition
and has received tremendous attention from many different areas. A major issue
of the original DBSCAN is that the time complexity could be as large as
quadratic. Most of existing DBSCAN algorithms focus on developing efficient
index structures to speed up the procedure in low-dimensional Euclidean space.
However, the research of DBSCAN in high-dimensional Euclidean space or general
metric space is still quite limited, to the best of our knowledge. In this
paper, we consider the metric DBSCAN problem under the assumption that the
inliers (excluding the outliers) have a low doubling dimension. We apply a
novel randomized $k$-center clustering idea to reduce the complexity of range
query, which is the most time consuming step in the whole DBSCAN procedure. Our
proposed algorithms do not need to build any complicated data structures and
are easy to be implemented in practice. The experimental results show that our
algorithms can significantly outperform the existing DBSCAN algorithms in terms
of running time.
</p></div>
    </summary>
    <updated>2020-02-28T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-02-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.11923</id>
    <link href="http://arxiv.org/abs/2002.11923" rel="alternate" type="text/html"/>
    <title>The Effectiveness of Johnson-Lindenstrauss Transform for High Dimensional Optimization with Outliers</title>
    <feedworld_mtime>1582934400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Ding:Hu.html">Hu Ding</a>, Ruizhe Qin, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Huang:Jiawei.html">Jiawei Huang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.11923">PDF</a><br/><b>Abstract: </b>{\em Johnson-Lindenstrauss (JL) Transform} is one of the most popular methods
for dimension reduction. In this paper, we study the effectiveness of JL
transform for solving the high dimensional optimization problems with outliers.
We focus on two fundamental optimization problems: {\em $k$-center clustering
with outliers} and {\em SVM with outliers}. In general, the time complexity for
dealing with outliers in high dimensional space could be very large. Based on
some novel insights in geometry, we prove that the complexities of these two
problems can be significantly reduced through JL transform. In the experiments,
we compare JL transform with several other well known dimension reduction
methods, and study their performances on synthetic and real datasets.
</p></div>
    </summary>
    <updated>2020-02-28T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-02-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.11912</id>
    <link href="http://arxiv.org/abs/2002.11912" rel="alternate" type="text/html"/>
    <title>Max-Affine Spline Insights into Deep Generative Networks</title>
    <feedworld_mtime>1582934400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Balestriero:Randall.html">Randall Balestriero</a>, Sebastien Paris, Richard Baraniuk <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.11912">PDF</a><br/><b>Abstract: </b>We connect a large class of Generative Deep Networks (GDNs) with spline
operators in order to derive their properties, limitations, and new
opportunities. By characterizing the latent space partition, dimension and
angularity of the generated manifold, we relate the manifold dimension and
approximation error to the sample size. The manifold-per-region affine subspace
defines a local coordinate basis; we provide necessary and sufficient
conditions relating those basis vectors with disentanglement. We also derive
the output probability density mapped onto the generated manifold in terms of
the latent space density, which enables the computation of key statistics such
as its Shannon entropy. This finding also enables the computation of the GDN
likelihood, which provides a new mechanism for model comparison as well as
providing a quality measure for (generated) samples under the learned
distribution. We demonstrate how low entropy and/or multimodal distributions
are not naturally modeled by DGNs and are a cause of training instabilities.
</p></div>
    </summary>
    <updated>2020-02-29T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-02-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.11904</id>
    <link href="http://arxiv.org/abs/2002.11904" rel="alternate" type="text/html"/>
    <title>Layered Sampling for Robust Optimization Problems</title>
    <feedworld_mtime>1582934400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Ding:Hu.html">Hu Ding</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Zixiu.html">Zixiu Wang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.11904">PDF</a><br/><b>Abstract: </b>In real world, our datasets often contain outliers. Moreover, the outliers
can seriously affect the final machine learning result. Most existing
algorithms for handling outliers take high time complexities (e.g. quadratic or
cubic complexity). {\em Coreset} is a popular approach for compressing data so
as to speed up the optimization algorithms. However, the current coreset
methods cannot be easily extended to handle the case with outliers. In this
paper, we propose a new variant of coreset technique, {\em layered sampling},
to deal with two fundamental robust optimization problems: {\em
$k$-median/means clustering with outliers} and {\em linear regression with
outliers}. This new coreset method is in particular suitable to speed up the
iterative algorithms (which often improve the solution within a local range)
for those robust optimization problems. Moreover, our method is easy to be
implemented in practice. We expect that our framework of layered sampling will
be applicable to other robust optimization problems.
</p></div>
    </summary>
    <updated>2020-02-28T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-02-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.11830</id>
    <link href="http://arxiv.org/abs/2002.11830" rel="alternate" type="text/html"/>
    <title>Polynomial algorithms for p-dispersion problems in a 2d Pareto Front</title>
    <feedworld_mtime>1582934400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dupin:Nicolas.html">Nicolas Dupin</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.11830">PDF</a><br/><b>Abstract: </b>Having many best compromise solutions for bi-objective optimization problems,
this paper studies p-dispersion problems to select $p\geqslant 2$
representative points in the Pareto Front(PF). Four standard variants of
p-dispersion are considered. A novel variant, denoted Max-Sum-Neighbor
p-dispersion, is introduced for the specific case of a 2d PF. Firstly, it is
proven that $2$-dispersion and $3$-dispersion problems are solvable in $O(n)$
time in a 2d PF. Secondly, dynamic programming algorithms are designed for
three p-dispersion variants, proving polynomial complexities in a 2d PF. The
Max-Min p-dispersion problem is proven solvable in $O(pn\log n)$ time and
$O(n)$ memory space. The Max-Sum-Min p-dispersion problem is proven solvable in
$O(pn^3)$ time and $O(pn^2)$ space. The Max-Sum-Neighbor p-dispersion problem
is proven solvable in $O(pn^2)$ time and $O(pn)$ space. Complexity results and
parallelization issues are discussed in regards to practical implementation.
</p></div>
    </summary>
    <updated>2020-02-29T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-02-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.11818</id>
    <link href="http://arxiv.org/abs/2002.11818" rel="alternate" type="text/html"/>
    <title>Finding large matchings in 1-planar graphs of minimum degree 3</title>
    <feedworld_mtime>1582934400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Therese Biedl, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Klute:Fabian.html">Fabian Klute</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.11818">PDF</a><br/><b>Abstract: </b>A matching is a set of edges without common endpoint. It was recently shown
that every 1-planar graph (i.e., a graph that can be drawn in the plane with at
most one crossing per edge) that has minimum degree 3 has a matching of size at
least $\frac{n+12}{7}$, and this is tight for some graphs. The proof did not
come with an algorithm to find the matching more efficiently than a
general-purpose maximum-matching algorithm. In this paper, we give such an
algorithm. More generally, we show that any matching that has no augmenting
paths of length 9 or less has size at least $\frac{n+12}{7}$ in a 1-planar
graph with minimum degree 3.
</p></div>
    </summary>
    <updated>2020-02-29T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-02-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.05357</id>
    <link href="http://arxiv.org/abs/1902.05357" rel="alternate" type="text/html"/>
    <title>Estimating the Circuit Deobfuscating Runtime based on Graph Deep Learning</title>
    <feedworld_mtime>1582934400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Zhiqian.html">Zhiqian Chen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kolhe:Gaurav.html">Gaurav Kolhe</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rafatirad:Setareh.html">Setareh Rafatirad</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/D=:Sai_Manoj_P=.html">Sai Manoj P. D.</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Homayoun:Houman.html">Houman Homayoun</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhao:Liang.html">Liang Zhao</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lu:Chang=Tien.html">Chang-Tien Lu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.05357">PDF</a><br/><b>Abstract: </b>Circuit obfuscation is a recently proposed defense mechanism to protect
digital integrated circuits (ICs) from reverse engineering by using camouflaged
gates i.e., logic gates whose functionality cannot be precisely determined by
the attacker. There have been effective schemes such as satisfiability-checking
(SAT)-based attacks that can potentially decrypt obfuscated circuits, called
deobfuscation. Deobfuscation runtime could have a large span ranging from few
milliseconds to thousands of years or more, depending on the number and layouts
of the ICs and camouflaged gates. And hence accurately pre-estimating the
deobfuscation runtime is highly crucial for the defenders to maximize it and
optimize their defense. However, estimating the deobfuscation runtime is a
challenging task due to 1) the complexity and heterogeneity of graph-structured
circuit, 2) the unknown and sophisticated mechanisms of the attackers for
deobfuscation. To address the above mentioned challenges, this work proposes
the first machine-learning framework that predicts the deobfuscation runtime
based on graph deep learning techniques. Specifically, we design a new model,
ICNet with new input and convolution layers to characterize and extract graph
frequencies from ICs, which are then integrated by heterogeneous deep
fully-connected layers to obtain final output. ICNet is an end-to-end framework
which can automatically extract the determinant features for deobfuscation
runtime. Extensive experiments demonstrate its effectiveness and efficiency.
</p></div>
    </summary>
    <updated>2020-02-28T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-02-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16744</id>
    <link href="https://rjlipton.wordpress.com/2020/02/28/reductions-and-jokes/" rel="alternate" type="text/html"/>
    <title>Reductions and Jokes</title>
    <summary>Plus a teaching idea that’s no joke? Cropped from Maths History source Emil Post was the first to use the formal notion of reduction between problems. We discussed Post’s wonderful work and its relevance to complexity earlier here. Today Ken and I want to discuss the notion of reduction, and also perhaps some jokes for […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Plus a teaching idea that’s no joke?</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2020/02/postcropped.png"><img alt="" class="alignright size-full wp-image-16746" src="https://rjlipton.files.wordpress.com/2020/02/postcropped.png?w=600"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Cropped from Maths History <a href="http://mathshistory.st-andrews.ac.uk/PictDisplay/Post.html">source</a></font></td>
</tr>
</tbody>
</table>
<p>
Emil Post was the first to use the formal notion of reduction between problems. We discussed Post’s wonderful work and its relevance to complexity earlier <a href="https://rjlipton.wordpress.com/2010/04/19/a-post-on-post/">here</a>.</p>
<p>
Today Ken and I want to discuss the notion of reduction, and also perhaps some jokes for your amusement.</p>
<p>
Reductions are used throughout mathematics. We regard Post’s definition from 1944 as quintessential. His are called <a href="https://en.wikipedia.org/wiki/Many-one_reduction">many-one</a> reductions. Here is the definition in a functional style that we’ve tried to promote in other cases: A problem <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/> reduces to a problem <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B}"/> if there is a computable function <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/> such that for any instance <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> of problem <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/>, </p>
<p align="center"><img alt="\displaystyle  A(x) = B(f(x)). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++A%28x%29+%3D+B%28f%28x%29%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  A(x) = B(f(x)). "/></p>
<p>If <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/> and <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B}"/> are languages then this gives the familiar condition <img alt="{x \in A \iff f(x) \in B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx+%5Cin+A+%5Ciff+f%28x%29+%5Cin+B%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x \in A \iff f(x) \in B}"/>. But the idea can be more general: <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/> and <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B}"/> can be functions.</p>
<p>
Alan Turing had earlier defined an even more general kind of reduction, in which given <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> one computes multiple <img alt="{y_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y_i}"/>, gets the answer <img alt="{B(y_i)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%28y_i%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B(y_i)}"/> for each of them, and finally pieces together the answers to obtain <img alt="{A(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A(x)}"/>. But this feels more like “expanding” than “reducing.” We want it to be: one <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/>, one <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y}"/>. That was Post’s notion.</p>
<p>
</p><p/><h2> Dating Reductions and Jokes </h2><p/>
<p/><p>
The idea of reduction is simple: When confronted with some problem, be lazy: Instead of solving the problem, show that it can be changed and then solved by some previously known method. That is, show that your problem is reduced to someone’s already solved problem. Be lazy.</p>
<p>
In this form, we can think of two mathematical examples that are much older than Post’s:</p>
<ul>
<li>
<em>Logarithms</em>. Multiplying two numbers <img alt="{a}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a}"/> and <img alt="{b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{b}"/> with many digits or decimals can be cumbersome. If you can compute <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/> and its inverse such that <p/>
<p align="center"><img alt="\displaystyle  a\cdot b = f^{-1}(f(a) + f(b)), " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++a%5Ccdot+b+%3D+f%5E%7B-1%7D%28f%28a%29+%2B+f%28b%29%29%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  a\cdot b = f^{-1}(f(a) + f(b)), "/></p>
<p>then your multiplication is reduced to a much easier addition. John Napier gave <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/> the name “logarithm” in 1614 and soon William Oughtred built a physical device to automate this reduction. If you are over 40, perhaps you have seen <a href="https://en.wikipedia.org/wiki/Slide_rule">one</a>. </p>
</li><li>
<em>Integration</em>. Do you have a hard integral <img alt="{\int A(x) dx}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cint+A%28x%29+dx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\int A(x) dx}"/>? Often tricks of defining <img alt="{y = f(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By+%3D+f%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y = f(x)}"/>, so <img alt="{dy = f'(x) dx}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bdy+%3D+f%27%28x%29+dx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{dy = f'(x) dx}"/>, and/or integrating by parts, yields an integral <img alt="{\int B(y) dy}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cint+B%28y%29+dy%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\int B(y) dy}"/> that is easier to solve, and whose solution completes your answer.
</li></ul>
<p>
The latter example is in Wikipedia’s article on <a href="https://en.wikipedia.org/wiki/Reduction_(mathematics)">reduction</a>. The former, however, has the signature idea of reduction <em>between</em> problems, more than massaging instances of the same problem. What we really want to know is:</p>
<blockquote><p><b> </b> <em> When was the process of transforming between problems first known by the term <b>reduction</b>? </em>
</p></blockquote>
<p/><p>
We wonder if tracing an old kind of joke can help. The point is that reductions are a neat source of jokes. Here is a classic one, taken from a big <a href="https://www.math.utah.edu/~cherk/mathjokes.html">list</a> of math jokes. The list gives a second form of the joke based on reductions and there are many others. More on the jokes later.</p>
<blockquote><p><b> </b> <em> A physicist and a mathematician are sitting in a faculty lounge. Suddenly, the coffee machine catches on fire. The physicist grabs a waste basket, empties the basket, leaps towards the sink, fills the basket with water, and puts out the fire. As this coffee machine has done this before they agree to keep a waste basket next to the coffee machine filled with water.</em></p><em>
</em><p><em>
The next day, the same two are sitting in the same lounge. Again, the coffee machine catches on fire. This time, the mathematician stands up, grabs the waste basket that is filled with water. Empties it, places some trash in the basket, and hands it to the physicist. Thus reducing the problem to a previously solved one. </em>
</p></blockquote>
<p/><p>
Instead of putting out a fire, the following <a href="https://thumbs.gfycat.com/DifficultVapidAmericanredsquirrel-size_restricted.gif?fbclid=IwAR2AXbtag_WFTP9bmipr4JOhvViHAQbvEgE8h1oCdG_71IttR28EgcSTqhg">video</a> is about retrieving a shoe that is floating away.</p>
<p>
</p><p/><h2> Another Example </h2><p/>
<p/><p>
Here is an example of reductions that are not so silly and a little less simple.</p>
<p>
Imagine that Alice and Bob are at it again. Bob wants to be able to multiply integers fast and he plans on building a hardware system that stores the answers in a table. Then his hardware system will be able to compute the product of two integers by just looking up the answers. Okay, there are really better ways to do this, but just play along for the moment. </p>
<p><a href="https://rjlipton.files.wordpress.com/2020/02/tables2.jpg"><img alt="" class="aligncenter wp-image-16747" height="200" src="https://rjlipton.files.wordpress.com/2020/02/tables2.jpg?w=200&amp;h=200" width="200"/></a></p>
<p>
Bob’s table is big and he is troubled. The above table has <img alt="{100}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B100%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{100}"/> entries just to multiply numbers less than <img alt="{10}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B10%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{10}"/>. Clearly for a more extensive table the cost grows fast. He asks his friend Alice for some help. She says:”Just store the diagonal values and I can show you how to handle the general case.” Here is her old trick. 	</p>
<p align="center"><img alt="\displaystyle  a \times b = \frac{\left(\left(a + b\right)^{2} - a^{2} - b^{2}\right)}{2}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++a+%5Ctimes+b+%3D+%5Cfrac%7B%5Cleft%28%5Cleft%28a+%2B+b%5Cright%29%5E%7B2%7D+-+a%5E%7B2%7D+-+b%5E%7B2%7D%5Cright%29%7D%7B2%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  a \times b = \frac{\left(\left(a + b\right)^{2} - a^{2} - b^{2}\right)}{2}. "/></p>
<p>Using this allows Bob to just store the diagonal of the multiplication table, and forget all the rest. It is a powerful reduction that shows:</p>
<blockquote><p><b> </b> <em> One can reduce integer multiplication to addition and taking the square of a number. </em>
</p></blockquote>
<p>
For example, </p>
<p align="center"><img alt="\displaystyle  \begin{array}{rcl}        37 \times 15 &amp;=&amp; ( 52^{2} - 37^{2} - 15^{2} )/2 \\              &amp;=&amp; (2704 - 1369 - 225)/2 \\            &amp;=&amp; 555. \end{array} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Barray%7D%7Brcl%7D++++++++37+%5Ctimes+15+%26%3D%26+%28+52%5E%7B2%7D+-+37%5E%7B2%7D+-+15%5E%7B2%7D+%29%2F2+%5C%5C++++++++++++++%26%3D%26+%282704+-+1369+-+225%29%2F2+%5C%5C++++++++++++%26%3D%26+555.+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \begin{array}{rcl}        37 \times 15 &amp;=&amp; ( 52^{2} - 37^{2} - 15^{2} )/2 \\              &amp;=&amp; (2704 - 1369 - 225)/2 \\            &amp;=&amp; 555. \end{array} "/></p>
<p>
</p><p/><h2> Complexity Reductions: No Joke? </h2><p/>
<p/><p>
Wikipedia actually gives the above as the first example in its <a href="https://en.wikipedia.org/wiki/Reduction_(complexity)">article</a> on the <em>complexity</em> kind of reduction. These kind of reductions not only define NP hardness and completeness, they are really needed to understand what the <img alt="{\mathsf{P=NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%3DNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{P=NP}}"/> problem is really about. </p>
<p>
For example, once one accepts that a language <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/> in <img alt="{\mathsf{NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{NP}}"/> can be represented by a uniform family of Boolean circuits <img alt="{C_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_n}"/>, one for each length <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> of instances <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> for <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/>, the reduction to SAT is quickly defined: The <img alt="{C_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_n}"/> have auxiliary inputs <img alt="{y_1,\dots,y_q}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By_1%2C%5Cdots%2Cy_q%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y_1,\dots,y_q}"/>, where <img alt="{q}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q}"/> is polynomial in <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>, such that there is a <img alt="{y \in \{0,1\}^q}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By+%5Cin+%5C%7B0%2C1%5C%7D%5Eq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y \in \{0,1\}^q}"/> making <img alt="{C_n(x,y) = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_n%28x%2Cy%29+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_n(x,y) = 1}"/> if and only if <img alt="{x \in A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx+%5Cin+A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x \in A}"/>. The circuit <img alt="{C_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_n}"/> can consist of binary NAND gates <img alt="{g}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{g}"/>, each with input wires <img alt="{u,v}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu%2Cv%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u,v}"/> (which may be inputs <img alt="{x_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x_i}"/> or <img alt="{y_j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y_j}"/>) and one or more output wires <img alt="{w}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{w}"/> (which may be the overall output <img alt="{w_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{w_0}"/>). The reduction <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/> first constructs the Boolean formula </p>
<p align="center"><img alt="\displaystyle  \phi_n = (w_0) \wedge \bigwedge_{g} (u \vee w) \wedge (v \vee w) \wedge (\bar{u} \vee \bar{v} \vee \bar{w}). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cphi_n+%3D+%28w_0%29+%5Cwedge+%5Cbigwedge_%7Bg%7D+%28u+%5Cvee+w%29+%5Cwedge+%28v+%5Cvee+w%29+%5Cwedge+%28%5Cbar%7Bu%7D+%5Cvee+%5Cbar%7Bv%7D+%5Cvee+%5Cbar%7Bw%7D%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \phi_n = (w_0) \wedge \bigwedge_{g} (u \vee w) \wedge (v \vee w) \wedge (\bar{u} \vee \bar{v} \vee \bar{w}). "/></p>
<p>To apply <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/> to a given <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/>, simply substitute the bits of <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> for the variables <img alt="{x_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x_i}"/> and simplify to make the formula <img alt="{\phi_x = f(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cphi_x+%3D+f%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\phi_x = f(x)}"/>. Then <img alt="{\phi_x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cphi_x%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\phi_x}"/> is satisfiable if and only if <img alt="{x \in A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx+%5Cin+A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x \in A}"/>. The reduction not only proves the <img alt="{\mathsf{NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{NP}}"/>-completeness of SAT (indeed, 3SAT) instantly, it conveys the character both of SAT and what <img alt="{\mathsf{NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{NP}}"/> is all about.</p>
<p>
This leads us to wonder something about teaching complexity theory. Maybe <b>reductions</b>, not <em>languages</em>, should be the principal objects of study. </p>
<p>
This may seem like a joke but there are benefits. The reductions are composable in ways that languages are not. They carry the source and target problems with them, at least in the form of the function’s arguments and values. Emphasizing reductions highlights the greatest success of complexity theory to date, which is proving relations between problems, rather than its failure to classify languages via lower bounds.</p>
<p>
</p><p/><h2> More Jokes </h2><p/>
<p/><p>
Here are a selection from a big <a href="https://www.math.utah.edu/~cherk/mathjokes.html">list</a> of math jokes that speak most to computing, plus one from <a href="https://www.quora.com/What-are-some-great-Computer-Science-jokes">here</a>. We have embellished a few of them: </p>
<ul>
<li>
A theory professor is one who talks in someone else’s sleep. <p/>
</li><li>
Two is the oddest prime of all, because it’s the only one that’s even. <p/>
</li><li>
A student comes to the department with a shiny new coffee cup, the sort of which you get when having won something. They explain: I won it in my Programming Class contest. They asked what <img alt="{7 + 7}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B7+%2B+7%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{7 + 7}"/> is. I said <img alt="{12}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B12%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{12}"/> and got 3rd place. <p/>
</li><li>
There are 10 types of people in the world, those who see it in binary and those who don’t. <p/>
</li><li>
An engineer thinks that his equations are an approximation to reality. A physicist thinks reality is an approximation to his equations. A mathematician doesn’t care. A computer scientist makes reality equal the equations. <p/>
</li><li>
There is no logical foundation for mathematical proof, and Gödel proved it! <p/>
</li><li>
Mathematics is like checkers in being suitable for the young, not too difficult, amusing, and<br/>
<i>without peril to the state</i>. [Plato wrote that 2,400 years ago; they did have <a href="http://www.checkerslounge.com/ancient-checkers.html">checkers</a>.]<br/>
Coding, on the other hand…<p/>
</li></ul>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
How should the concept of <em>reduction</em> be taught and emphasized? Can you trace the age of the classic reduction joke?</p>
<p>
There is a setting for multiplication where our Alice and Bob reduction example <em>fails</em>. Two of our latter list of jokes might suggest it to you. What is the issue? </p>
<p/></font></font></div>
    </content>
    <updated>2020-02-28T17:30:44Z</updated>
    <published>2020-02-28T17:30:44Z</published>
    <category term="All Posts"/>
    <category term="History"/>
    <category term="Ideas"/>
    <category term="Oldies"/>
    <category term="P=NP"/>
    <category term="Teaching"/>
    <category term="complexity theory"/>
    <category term="Emil Post"/>
    <category term="historical sourcing"/>
    <category term="humor"/>
    <category term="jokes"/>
    <category term="reductions"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2020-02-29T11:20:58Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=19402</id>
    <link href="https://gilkalai.wordpress.com/2020/02/28/remarkable-new-stochastic-methods-in-abf-ronen-eldan-and-renan-gross-found-a-new-proof-for-kkl-and-settled-a-conjecture-by-talagrand/" rel="alternate" type="text/html"/>
    <title>Remarkable New Stochastic Methods in ABF: Ronen Eldan and Renan Gross Found a New Proof for KKL and Settled a Conjecture by Talagrand</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">  The main conjecture from Talagrand’s paper on boundaries and influences was settled by Ronen Eldan and Renan Gross. Their paper introduces a new powerful method to the field of analysis of Boolean functions (ABF). This post is devoted to … <a href="https://gilkalai.wordpress.com/2020/02/28/remarkable-new-stochastic-methods-in-abf-ronen-eldan-and-renan-gross-found-a-new-proof-for-kkl-and-settled-a-conjecture-by-talagrand/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p> </p>
<p><a href="https://gilkalai.files.wordpress.com/2019/11/rr.png"><img alt="" class="alignnone size-medium wp-image-18565" height="282" src="https://gilkalai.files.wordpress.com/2019/11/rr.png?w=300&amp;h=282" width="300"/></a></p>
<p><span style="color: #ff0000;">The main conjecture from Talagrand’s paper on boundaries and influences was settled by Ronen Eldan and Renan Gross. Their paper introduces a new powerful method to the field of analysis of Boolean functions (ABF).</span></p>
<p>This post is devoted to a new breakthrough paper by Ronen Eldan and Renan Gross, <a href="https://arxiv.org/abs/1909.12067">Concentration on the Boolean hypercube via pathwise stochastic analysis.</a></p>
<p>The paper introduces remarkable new techniques based on stochastic calculus, (that bypass the use of hypercontractivity), that allow to settles several open problems on analysis of Boolean functions. (And on the way, to give a very different proof for KKL.)</p>
<p>Renan Gross recently wrote an excellent high-level explanation of the paper in his  blog: <a href="https://sarcasticresonance.wordpress.com/2020/02/06/new-paper-on-arxiv-concentration-on-the-boolean-hypercube-via-pathwise-stochastic-analysis/">New paper on arXiv: Concentration on the Boolean hypercube via pathwise stochastic analysis.</a> It is accompanied by a <a href="https://sarcasticresonance.wordpress.com/2020/02/05/catastrophic-cubic-crash-course">brief introduction to Boolean analysis, featuring the required Boolean material</a>:</p>
<p> </p>
<p>Before we move on, a trivia question:</p>
<h3><strong>Trivia question:</strong> Who invented the term hypercontractivity?</h3>
<p>(For a hint, see at the end of the post.)</p>
<p>Back to the paper by Ronen Eldan and Renan Gross. Perhaps the best way to explain what was achieved in this paper is to put one after the other the abstracts of the first version followed by the abstract of the second paper.</p>
<p> </p>
<h2>Ronen and Renan’s paper. Version 1, 26 Sept 2019.</h2>
<p><span style="color: #800080;">The title for version 1 was: Stability of Talagrand’s influence inequality</span></p>
<p><span style="color: #800080;">And here is the abstract: </span></p>
<p>We strengthen several classical inequalities concerning the influences of a Boolean function, showing that near-maximizers must have large vertex boundaries. An inequality due to Talagrand states that for a Boolean function</p>
<p><img alt="(1)~~~~~\mathrm{var}\left(f\right)\leq C\sum_{i=1}^{n}\frac{\mathrm{Inf}_{i}\left(f\right)}{1+\log\left(1/\mathrm{Inf}_{i}\left(f\right)\right)}" class="latex" src="https://s0.wp.com/latex.php?latex=%281%29%7E%7E%7E%7E%7E%5Cmathrm%7Bvar%7D%5Cleft%28f%5Cright%29%5Cleq+C%5Csum_%7Bi%3D1%7D%5E%7Bn%7D%5Cfrac%7B%5Cmathrm%7BInf%7D_%7Bi%7D%5Cleft%28f%5Cright%29%7D%7B1%2B%5Clog%5Cleft%281%2F%5Cmathrm%7BInf%7D_%7Bi%7D%5Cleft%28f%5Cright%29%5Cright%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(1)~~~~~\mathrm{var}\left(f\right)\leq C\sum_{i=1}^{n}\frac{\mathrm{Inf}_{i}\left(f\right)}{1+\log\left(1/\mathrm{Inf}_{i}\left(f\right)\right)}"/></p>
<p>where  <img alt="\mathrm{Inf}_{i}\left(f\right)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7BInf%7D_%7Bi%7D%5Cleft%28f%5Cright%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathrm{Inf}_{i}\left(f\right)"/> denote the influence of the <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/>-th coordinate. We give a lower bound for the size of the vertex boundary of functions saturating this inequality. As a corollary, we show that for sets that satisfy the edge-isoperimetric inequality or the Kahn-Kalai-Linial (KKL) inequality up to a constant, a constant proportion of the mass is in the inner vertex boundary. Our proofs rely on new techniques, based on stochastic calculus, and bypass the use of hypercontractivity common to previous proofs.</p>
<p><span style="color: #800080;">Let me say a few words about it. KKL theorem asserts that the maximal influence of a balanced Boolean function is at least <img alt="\Omega (\log n/n) var (f)" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega+%28%5Clog+n%2Fn%29+var+%28f%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega (\log n/n) var (f)"/>. The famous tribe example of Ben-Or and Linial shows that this is tight.  The KKL paper gave some statements about other norms of the influence vector and Talagrand’s inequality stated above (from the paper “On Russo’s 0-1 law”) gives a sharp description of the influence vectors. Ronen and Renan found a new method that gave new proofs for KKL’s theorem and the stronger Talagrand’s inequality. This new methods led to new stability result.</span></p>
<p>Now, lets move to version 2.</p>
<h2>Ronen and Renan’s paper: Version 2: 12 Nov 2019,</h2>
<p>Ronen Eldan and Renan Gross, <a href="https://arxiv.org/abs/1909.12067">Concentration on the Boolean hypercube via pathwise stochastic analysis.</a></p>
<p>Abstract: We develop a new technique for proving concentration inequalities which relate between the variance and influences of Boolean functions. Using this technique, we</p>
<p><strong>1.</strong> Settle a conjecture of Talagrand [Tal97] proving that</p>
<p><img alt="(2)~~~~~\int_{\left\{ -1,1\right\} ^{n}}\sqrt{h_{f}\left(x\right)}d\mu\geq C\cdot\mathrm{var}\left(f\right)\cdot\left(\log\left(\frac{1}{\sum\mathrm{Inf}_{i}^{2}\left(f\right)}\right)\right)^{1/2}," class="latex" src="https://s0.wp.com/latex.php?latex=%282%29%7E%7E%7E%7E%7E%5Cint_%7B%5Cleft%5C%7B+-1%2C1%5Cright%5C%7D+%5E%7Bn%7D%7D%5Csqrt%7Bh_%7Bf%7D%5Cleft%28x%5Cright%29%7Dd%5Cmu%5Cgeq+C%5Ccdot%5Cmathrm%7Bvar%7D%5Cleft%28f%5Cright%29%5Ccdot%5Cleft%28%5Clog%5Cleft%28%5Cfrac%7B1%7D%7B%5Csum%5Cmathrm%7BInf%7D_%7Bi%7D%5E%7B2%7D%5Cleft%28f%5Cright%29%7D%5Cright%29%5Cright%29%5E%7B1%2F2%7D%2C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(2)~~~~~\int_{\left\{ -1,1\right\} ^{n}}\sqrt{h_{f}\left(x\right)}d\mu\geq C\cdot\mathrm{var}\left(f\right)\cdot\left(\log\left(\frac{1}{\sum\mathrm{Inf}_{i}^{2}\left(f\right)}\right)\right)^{1/2},"/></p>
<p>where <img alt="h_f(x)" class="latex" src="https://s0.wp.com/latex.php?latex=h_f%28x%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h_f(x)"/> is the number of edges at <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/>  along which <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> changes its value, and <img alt="Inf_i(f)" class="latex" src="https://s0.wp.com/latex.php?latex=Inf_i%28f%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Inf_i(f)"/> is the influence of the <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/>-th coordinate.</p>
<p><strong>2.</strong> Strengthen several classical inequalities concerning the influences of a Boolean function, showing that near-maximizers must have large vertex boundaries. An inequality due to Talagrand states that for a Boolean function <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/></p>
<p><img alt="\mathrm{var}\left(f\right)\leq C\sum_{i=1}^{n}\frac{\mathrm{Inf}_{i}\left(f\right)}{1+\log\left(1/\mathrm{Inf}_{i}\left(f\right)\right)}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bvar%7D%5Cleft%28f%5Cright%29%5Cleq+C%5Csum_%7Bi%3D1%7D%5E%7Bn%7D%5Cfrac%7B%5Cmathrm%7BInf%7D_%7Bi%7D%5Cleft%28f%5Cright%29%7D%7B1%2B%5Clog%5Cleft%281%2F%5Cmathrm%7BInf%7D_%7Bi%7D%5Cleft%28f%5Cright%29%5Cright%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathrm{var}\left(f\right)\leq C\sum_{i=1}^{n}\frac{\mathrm{Inf}_{i}\left(f\right)}{1+\log\left(1/\mathrm{Inf}_{i}\left(f\right)\right)}"/></p>
<p>We give a lower bound for the size of the vertex boundary of functions saturating this inequality. As a corollary, we show that for sets that satisfy the edge-isoperimetric inequality or the Kahn-Kalai-Linial inequality up to a constant, a constant proportion of the mass is in the inner vertex boundary.</p>
<p><strong>3.</strong> Improve a quantitative relation between influences and noise stability given by Keller and Kindler.</p>
<p>Our proofs rely on techniques based on stochastic calculus, and bypass the use of hypercontractivity common to previous proofs.</p>
<p><span style="color: #800080;">Let me explain in a few words the main inequality that verified a conjecture by Talagrand. For other advances look at the paper itself.</span></p>
<p><span style="color: #800080;">The famous Margulis-Talagrand inequality asserts that</span></p>
<p><img alt="(3)~~~~~\int_{\left\{ -1,1\right\} ^{n}}\sqrt{h_{f}\left(x\right)}d\mu\geq C\cdot\mathrm{var}(f)." class="latex" src="https://s0.wp.com/latex.php?latex=%283%29%7E%7E%7E%7E%7E%5Cint_%7B%5Cleft%5C%7B+-1%2C1%5Cright%5C%7D+%5E%7Bn%7D%7D%5Csqrt%7Bh_%7Bf%7D%5Cleft%28x%5Cright%29%7Dd%5Cmu%5Cgeq+C%5Ccdot%5Cmathrm%7Bvar%7D%28f%29.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(3)~~~~~\int_{\left\{ -1,1\right\} ^{n}}\sqrt{h_{f}\left(x\right)}d\mu\geq C\cdot\mathrm{var}(f)."/></p>
<p><span style="color: #800080;">Let me say a little more. Talagrand’s proved in  his paper on Influence and boundary asserts that the right hand is a constant only if <img alt="II(f)" class="latex" src="https://s0.wp.com/latex.php?latex=II%28f%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="II(f)"/> – the sum of squares of the influences is a constant. He conjectured that we can actually add the square root of <img alt="\log II(f)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clog+II%28f%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\log II(f)"/> to the RHS.</span></p>
<p>A few remarks:</p>
<ol>
<li> For more background see my old post “<a href="https://gilkalai.wordpress.com/2008/05/26/natis-influence/">Nati’s influence</a>“.</li>
<li>Let me mention that Talagrand’s influence inequality (Equation (1) above) is sharp up to a multiplicative constant. This is shown in a 2015 paper: <a href="https://arxiv.org/abs/1506.06325">On the Converse of Talagrand’s Influence Inequality</a> by Saleet Klein, Amit Levi, Muli Safra, Clara Shikhelman, and Yinon Spinka.</li>
<li> Finding the best constant in KKL’s theorem is a well known challenge. So is the question of understanding balanced Boolean functions on n variables where the maximum influence is <img alt="C \log n/n" class="latex" src="https://s0.wp.com/latex.php?latex=C+%5Clog+n%2Fn&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C \log n/n"/>. Ehud Friedgit in his paper:<a href="http://www.ma.huji.ac.il/~ehudf/docs/kkl.ps"> Influences in Product Spaces, KKL and BKKKL Revisited</a>, have made important conjectures for such Boolean functions.</li>
<li> I expect that the new method will have many applications. Ronen Eldan in a paper <a href="https://arxiv.org/abs/1912.11641">Second-order bounds on correlations between increasing families</a>, found applicaions to correlation inequalities which I will discuss at some other time.</li>
<li> See the last part of <a href="https://gilkalai.wordpress.com/2019/09/22/jeff-kahn-and-jinyoung-park-maximal-independent-sets-and-a-new-isoperimetric-inequality-for-the-hamming-cube/">this post</a> for a description of Talagrand’s various relevant papers.</li>
<li>Renan Gross is building the <a href="https://booleanzoo.weizmann.ac.il/index.php/Main_Page">BooleanZoo</a> in a similar spirit to the famous complexityZoo.</li>
<li>I was in the process of writing a post about progress on ABS, mentioning twelve or so papers, apologizing for not mentioning others, promising to write in details about some of the papers, and making further apologetic remarks. But as this large post does not advance let me start with some of the promises.</li>
</ol>
<p><img alt="talabb" class="alignnone size-full wp-image-19444" src="https://gilkalai.files.wordpress.com/2020/02/talabb.png?w=640"/></p>
<h3>Hint to the trivia question:</h3>
<p><span id="more-19402"/></p>
<p>The <strong>very same person</strong> also coined the terms: Berry’s phase, TKN^2 integers, almost Matthieu, HVZ, Birman-Schwinger, infrared bounds, diamagnetic inequality, Verblunsky coefficient, Maryland model, ultracontractivity, …</p></div>
    </content>
    <updated>2020-02-28T14:21:18Z</updated>
    <published>2020-02-28T14:21:18Z</published>
    <category term="Analysis"/>
    <category term="Combinatorics"/>
    <category term="Probability"/>
    <category term="Michel Talagrand"/>
    <category term="Renan Gross"/>
    <category term="Ronen Eldan"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2020-02-29T11:20:46Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.12321</id>
    <link href="http://arxiv.org/abs/2002.12321" rel="alternate" type="text/html"/>
    <title>PAPRIKA: Private Online False Discovery Rate Control</title>
    <feedworld_mtime>1582848000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Wanrong.html">Wanrong Zhang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kamath:Gautam.html">Gautam Kamath</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cummings:Rachel.html">Rachel Cummings</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.12321">PDF</a><br/><b>Abstract: </b>In hypothesis testing, a false discovery occurs when a hypothesis is
incorrectly rejected due to noise in the sample. When adaptively testing
multiple hypotheses, the probability of a false discovery increases as more
tests are performed. Thus the problem of False Discovery Rate (FDR) control is
to find a procedure for testing multiple hypotheses that accounts for this
effect in determining the set of hypotheses to reject. The goal is to minimize
the number (or fraction) of false discoveries, while maintaining a high true
positive rate (i.e., correct discoveries).
</p>
<p>In this work, we study False Discovery Rate (FDR) control in multiple
hypothesis testing under the constraint of differential privacy for the sample.
Unlike previous work in this direction, we focus on the online setting, meaning
that a decision about each hypothesis must be made immediately after the test
is performed, rather than waiting for the output of all tests as in the offline
setting. We provide new private algorithms based on state-of-the-art results in
non-private online FDR control. Our algorithms have strong provable guarantees
for privacy and statistical performance as measured by FDR and power. We also
provide experimental results to demonstrate the efficacy of our algorithms in a
variety of data environments.
</p></div>
    </summary>
    <updated>2020-02-28T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-02-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.12159</id>
    <link href="http://arxiv.org/abs/2002.12159" rel="alternate" type="text/html"/>
    <title>Random-Order Models</title>
    <feedworld_mtime>1582848000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gupta:Anupam.html">Anupam Gupta</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Singla:Sahil.html">Sahil Singla</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.12159">PDF</a><br/><b>Abstract: </b>This chapter introduces the \emph{random-order model} in online algorithms.
In this model, the input is chosen by an adversary, then randomly permuted
before being presented to the algorithm. This reshuffling often weakens the
power of the adversary and allows for improved algorithmic guarantees. We show
such improvements for two broad classes of problems: packing problems where we
must pick a constrained set of items to maximize total value, and covering
problems where we must satisfy given requirements at minimum total cost. We
also discuss how random-order model relates to other stochastic models used for
non-worst-case competitive analysis.
</p></div>
    </summary>
    <updated>2020-02-28T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-02-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.12119</id>
    <link href="http://arxiv.org/abs/2002.12119" rel="alternate" type="text/html"/>
    <title>Tree Polymatrix Games are PPAD-hard</title>
    <feedworld_mtime>1582848000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Deligkas:Argyrios.html">Argyrios Deligkas</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fearnley:John.html">John Fearnley</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Savani:Rahul.html">Rahul Savani</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.12119">PDF</a><br/><b>Abstract: </b>We prove that it is PPAD-hard to compute a Nash equilibrium in a tree
polymatrix game with twenty actions per player. This is the first PPAD hardness
result for a game with a constant number of actions per player where the
interaction graph is acyclic. Along the way we show PPAD-hardness for finding
an $\epsilon$-fixed point of a 2D LinearFIXP instance, when $\epsilon$ is any
constant less than $(\sqrt{2} - 1)/2 \approx 0.2071$. This lifts the hardness
regime from polynomially small approximations in $k$-dimensions to constant
approximations in two-dimensions, and our constant is substantial when compared
to the trivial upper bound of $0.5$.
</p></div>
    </summary>
    <updated>2020-02-28T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-02-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.12050</id>
    <link href="http://arxiv.org/abs/2002.12050" rel="alternate" type="text/html"/>
    <title>Semantrix: A Compressed Semantic Matrix</title>
    <feedworld_mtime>1582848000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Brisaboa:Nieves_R=.html">Nieves R. Brisaboa</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fari=ntilde=a:Antonio.html">Antonio Fariña</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Navarro:Gonzalo.html">Gonzalo Navarro</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rodeiro:Tirso_V=.html">Tirso V. Rodeiro</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.12050">PDF</a><br/><b>Abstract: </b>We present a compact data structure to represent both the duration and length
of homogeneous segments of trajectories from moving objects in a way that, as a
data warehouse, it allows us to efficiently answer cumulative queries. The
division of trajectories into relevant segments has been studied in the
literature under the topic of Trajectory Segmentation. In this paper, we design
a data structure to compactly represent them and the algorithms to answer the
more relevant queries. We experimentally evaluate our proposal in the real
context of an enterprise with mobile workers (truck drivers) where we aim at
analyzing the time they spend in different activities. To test our proposal
under higher stress conditions we generated a huge amount of synthetic
realistic trajectories and evaluated our system with those data to have a good
idea about its space needs and its efficiency when answering different types of
queries.
</p></div>
    </summary>
    <updated>2020-02-28T23:25:47Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-02-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.12034</id>
    <link href="http://arxiv.org/abs/2002.12034" rel="alternate" type="text/html"/>
    <title>The Complexity of Contracts</title>
    <feedworld_mtime>1582848000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Duetting:Paul.html">Paul Duetting</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Roughgarden:Tim.html">Tim Roughgarden</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Talgam=Cohen:Inbal.html">Inbal Talgam-Cohen</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.12034">PDF</a><br/><b>Abstract: </b>We initiate the study of computing (near-)optimal contracts in succinctly
representable principal-agent settings. Here optimality means maximizing the
principal's expected payoff over all incentive-compatible contracts---known in
economics as "second-best" solutions. We also study a natural relaxation to
approximately incentive-compatible contracts.
</p>
<p>We focus on principal-agent settings with succinctly described (and
exponentially large) outcome spaces. We show that the computational complexity
of computing a near-optimal contract depends fundamentally on the number of
agent actions. For settings with a constant number of actions, we present a
fully polynomial-time approximation scheme (FPTAS) for the separation oracle of
the dual of the problem of minimizing the principal's payment to the agent, and
use this subroutine to efficiently compute a delta-incentive-compatible
(delta-IC) contract whose expected payoff matches or surpasses that of the
optimal IC contract.
</p>
<p>With an arbitrary number of actions, we prove that the problem is hard to
approximate within any constant c. This inapproximability result holds even for
delta-IC contracts where delta is a sufficiently rapidly-decaying function of
c. On the positive side, we show that simple linear delta-IC contracts with
constant delta are sufficient to achieve a constant-factor approximation of the
"first-best" (full-welfare-extracting) solution, and that such a contract can
be computed in polynomial time.
</p></div>
    </summary>
    <updated>2020-02-28T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-02-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.11880</id>
    <link href="http://arxiv.org/abs/2002.11880" rel="alternate" type="text/html"/>
    <title>Stochastic Matching with Few Queries: $(1-\varepsilon)$ Approximation</title>
    <feedworld_mtime>1582848000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Behnezhad:Soheil.html">Soheil Behnezhad</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Derakhshan:Mahsa.html">Mahsa Derakhshan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hajiaghayi:MohammadTaghi.html">MohammadTaghi Hajiaghayi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.11880">PDF</a><br/><b>Abstract: </b>Suppose that we are given an arbitrary graph $G=(V, E)$ and know that each
edge in $E$ is going to be realized independently with some probability $p$.
The goal in the stochastic matching problem is to pick a sparse subgraph $Q$ of
$G$ such that the realized edges in $Q$, in expectation, include a matching
that is approximately as large as the maximum matching among the realized edges
of $G$. The maximum degree of $Q$ can depend on $p$, but not on the size of
$G$.
</p>
<p>This problem has been subject to extensive studies over the years and the
approximation factor has been improved from $0.5$ to $0.5001$ to $0.6568$ and
eventually to $2/3$. In this work, we analyze a natural sampling-based
algorithm and show that it can obtain all the way up to $(1-\epsilon)$
approximation, for any constant $\epsilon &gt; 0$.
</p>
<p>A key and of possible independent interest component of our analysis is an
algorithm that constructs a matching on a stochastic graph, which among some
other important properties, guarantees that each vertex is matched
independently from the vertices that are sufficiently far. This allows us to
bypass a previously known barrier towards achieving $(1-\epsilon)$
approximation based on existence of dense Ruzsa-Szemer\'edi graphs.
</p></div>
    </summary>
    <updated>2020-02-28T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-02-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.11795</id>
    <link href="http://arxiv.org/abs/2002.11795" rel="alternate" type="text/html"/>
    <title>Quantum Distributed Complexity of Set Disjointness on a Line</title>
    <feedworld_mtime>1582848000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Frederic Magniez, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nayak:Ashwin.html">Ashwin Nayak</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.11795">PDF</a><br/><b>Abstract: </b>Given $x,y\in\{0,1\}^n$, Set Disjointness consists in deciding whether
$x_i=y_i=1$ for some index $i \in [n]$. We study the problem of computing this
function in a distributed computing scenario in which the inputs $x$ and $y$
are given to the processors at the two extremities of a path of length $d$. Set
Disjointness on a Line was introduced by Le Gall and Magniez (PODC 2018) for
proving lower bounds on the quantum distributed complexity of computing the
diameter of an arbitrary network in the CONGEST model.
</p>
<p>In this work, we prove an unconditional lower bound of
$\widetilde{\Omega}(\sqrt[3]{n d^2}+\sqrt{n} )$ rounds for Set Disjointness on
a Line. This is the first non-trivial lower bound when there is no restriction
on the memory used by the processors. The result gives us a new lower bound of
$\widetilde{\Omega} (\sqrt[3]{n\delta^2}+\sqrt{n} )$ on the number of rounds
required for computing the diameter $\delta$ of any $n$-node network with
quantum messages of size $O(\log n)$ in the CONGEST model.
</p>
<p>We draw a connection between the distributed computing scenario above and a
new model of query complexity. In this model, an algorithm computing a
bi-variate function $f$ has access to the inputs $x$ and $y$ through two
separate oracles $O_x$ and $O_y$, respectively. The restriction is that the
algorithm is required to alternately make $d$ queries to $O_x$ and $d$ queries
to $O_y$. The technique we use for deriving the round lower bound for Set
Disjointness on a Line also applies to the number of rounds in this query
model. We provide an algorithm for Set Disjointness in this query model with
round complexity that matches the round lower bound stated above, up to a
polylogarithmic factor. In this sense, the round lower bound we show for Set
Disjointness on a Line is optimal.
</p></div>
    </summary>
    <updated>2020-02-28T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-02-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://dstheory.wordpress.com/?p=26</id>
    <link href="https://dstheory.wordpress.com/2020/02/27/friday-february-28-jon-kleinberg-from-cornell-university/" rel="alternate" type="text/html"/>
    <title>Friday, February 28 — Jon Kleinberg from Cornell University</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">The first Foundations of Data Science virtual talk will take place this coming Friday, February 28th at 11:00 AM Pacific Time (2:00 pm Eastern Time, 20:00 Central European Time, 19:00 UTC). Jon Kleinberg from Cornell University will speak about “Fairness and Bias in Algorithmic Decision-Making”. Abstract: As data science has broadened its scope in recent years, a<a class="more-link" href="https://dstheory.wordpress.com/2020/02/27/friday-february-28-jon-kleinberg-from-cornell-university/">Continue reading <span class="screen-reader-text">"Friday, February 28 — Jon Kleinberg from Cornell University"</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The first Foundations of Data Science virtual talk will take place this coming Friday, February 28th at 11:00 AM Pacific Time (2:00 pm Eastern Time, 20:00 Central European Time, 19:00 UTC). <strong>Jon Kleinberg</strong> from Cornell University will speak about “<em>Fairness and Bias in Algorithmic Decision-Making</em>”.</p>



<p><strong>Abstract</strong>: As data science has broadened its scope in recent years, a number of domains have applied computational methods for classification and prediction to evaluate individuals in high-stakes settings. These developments have led to an active line of recent discussion in the public sphere about the consequences of algorithmic prediction for notions of fairness and equity. In part, this discussion has involved a basic tension between competing notions of what it means for such classifications to be fair to different groups. We consider several of the key fairness conditions that lie at the heart of these debates, and in particular how these properties operate when the goal is to rank-order a set of applicants by some criterion of interest, and then to select the top-ranking applicants. The talk will be based on joint work with Sendhil Mullainathan and Manish Raghavan.</p>



<p><a href="https://sites.google.com/view/dstheory">Link to join the virtual talk.</a></p>



<p>The series is supported by the <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1934846&amp;HistoricalAwards=false">NSF HDR TRIPODS Grant 1934846</a>. </p></div>
    </content>
    <updated>2020-02-27T23:30:00Z</updated>
    <published>2020-02-27T23:30:00Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>dstheory</name>
    </author>
    <source>
      <id>https://dstheory.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://dstheory.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://dstheory.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://dstheory.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://dstheory.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Foundation of Data Science – Virtual Talk Series</title>
      <updated>2020-02-29T11:21:59Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/028</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/028" rel="alternate" type="text/html"/>
    <title>TR20-028 |  A Super-Quadratic Lower Bound for Depth Four Arithmetic Circuits | 

	Nikhil Gupta, 

	Chandan Saha, 

	Bhargav Thankey</title>
    <summary>We show an $\widetilde{\Omega}(n^{2.5})$ lower bound for general depth four arithmetic circuits computing an explicit $n$-variate degree $\Theta(n)$ multilinear polynomial over any field of characteristic zero. To our knowledge, and as stated in the survey by Shpilka and Yehudayoff (FnT-TCS, 2010), no super-quadratic lower bound was known for depth four circuits over fields of characteristic other than 2 before this work. The previous best lower bound is $\widetilde{\Omega}(n^{1.5})$ shown in the work of Sharma (Master's Thesis, 2017), which is a slight quantitative improvement over the roughly $\Omega(n^{1.33})$ bound obtained by invoking the super-linear lower bound for constant depth circuits in the works of Raz (STOC, 2008) and Shoup and Smolensky (FOCS, 1991).

Our lower bound proof follows the approach of the almost cubic lower bound for depth three circuits in the work by Kayal, Saha and Tavenas (ICALP, 2016) by replacing the shifted partials measure with a suitable variant of the projected shifted partials measure, but it differs from their proof at a crucial step - namely, the way "heavy" product gates are handled. Loosely speaking, a heavy product gate has a relatively high fan-in. Product gates of a depth three circuit compute products of affine forms, and so, it is easy to prune $\Theta(n)$ many heavy product gates by projecting the circuit to a low-dimensional affine subspace as shown in the works by Kayal, Saha and Tavenas (ICALP, 2016) and Shpilka and Wigderson (CCC, 1999). However, in a depth four circuit, the second (from the top) layer of product gates compute products of polynomials having arbitrary degree, and hence it was not clear how to prune such heavy product gates from the circuit. We show that heavy product gates can also be eliminated from a depth four circuit by projecting the circuit to a low-dimensional affine subspace, unless the heavy gates together account for $\widetilde{\Omega}(n^{2.5})$ size. This part of our argument is inspired by a well-known greedy approximation algorithm for the weighted set-cover problem.</summary>
    <updated>2020-02-27T15:03:32Z</updated>
    <published>2020-02-27T15:03:32Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-02-29T11:20:41Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/027</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/027" rel="alternate" type="text/html"/>
    <title>TR20-027 |  The Power of Many Samples in Query Complexity | 

	Mika Göös, 

	Andrew Bassilakis, 

	Andrew Drucker, 

	Li-Yang Tan, 

	Lunjia Hu, 

	Weiyun Ma</title>
    <summary>The randomized query complexity $R(f)$ of a boolean function $f\colon\{0,1\}^n\to\{0,1\}$ is famously characterized (via Yao's minimax) by the least number of queries needed to distinguish a distribution $D_0$ over $0$-inputs from a distribution $D_1$ over $1$-inputs, maximized over all pairs $(D_0,D_1)$. We ask: Does this task become easier if we allow query access to infinitely many samples from either $D_0$ or $D_1$? We show the answer is no: There exists a hard pair $(D_0,D_1)$ such that distinguishing $D_0^\infty$ from $D_1^\infty$ requires $\Theta(R(f))$ many queries. As an application, we show that for any composed function $f\circ g$ we have $R(f\circ g) \geq \Omega(\mathrm{fbs}(f)R(g))$ where $\mathrm{fbs}$ denotes fractional block sensitivity.</summary>
    <updated>2020-02-26T19:45:16Z</updated>
    <published>2020-02-26T19:45:16Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-02-29T11:20:41Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://lucatrevisan.wordpress.com/?p=4301</id>
    <link href="https://lucatrevisan.wordpress.com/2020/02/26/i-live-in-milan-ama/" rel="alternate" type="text/html"/>
    <title>This year, for Lent, Milan gave up nightlife</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Greetings from Milan, in Italy’s “yellow zone” of areas bordering clusters of coronavirus infections. This week, all schools, universities, museums, theaters are closed, bars have to close by 6pm, and fairs and conferences are being postponed. The “red zone” of … <a href="https://lucatrevisan.wordpress.com/2020/02/26/i-live-in-milan-ama/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Greetings from Milan, in Italy’s “yellow zone” of areas bordering clusters of coronavirus infections. This week, all schools, universities, museums, theaters  are closed, bars have to close by 6pm, and fairs and conferences are being postponed. The “red zone” of small towns with the clusters of infections is on lockdown.</p>
<p>Milan has been unseasonably warm and sunny in the past few days, and walking through the city, with very light car and pedestrian traffic, has been lovely. This is apparently what the city usually looks like in August, but without the heat and humidity.<br/>
<span id="more-4301"/></p>
<p>Italians have the well deserved fame of being very dramatic people, but we have been taking the inconvenience in stride and with a mix of stoicism and good humor. Maybe I am wrong, but, apart from New York City, if a large American city had a cluster of infections in the suburbs, and it were similarly shut down, we would see riots and looting on the first night.</p>
<p>Over the weekend, the lockdown of the small towns was announced before any announcement of what to do about Milan, and the news showed long lines of people in those small towns waiting to buy groceries in the few open supermarkets. This induced some panic-buying on Sunday and Monday in Milan.</p>
<p>While people in Hong Kong and Singapore panic-bought toilet paper, Italians have mostly been buying pasta. Except, that is, <i>penne lisce</i>, like this Twitter user noted in a broadly shared picture. (Short cuts of pasta, like penne, are usually ribbed, to better catch sauce. Smooth short pasta like penne lisce makes no sense)</p>
<blockquote class="twitter-tweet">
<p dir="ltr" lang="it">Continuo a guardare questa foto fatta prima al supermercato e penso al fatto che il grande sconfitto da questo virus sono le penne lisce che agli italiani fanno cagare pure quando sono presi dal panico e si preparano all’apocalisse. <a href="https://t.co/Lq9Y06jdho">pic.twitter.com/Lq9Y06jdho</a></p>
<p>— 𝚍𝚒𝚘𝚍𝚎𝚐𝚕𝚒𝚣𝚒𝚕𝚕𝚊 <img alt="&#x1F926;&#x200D;&#x2642;&#xFE0F;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f926-200d-2642-fe0f.png" style="height: 1em;"/> (@diodeglizilla) <a href="https://twitter.com/diodeglizilla/status/1231680287815426049?ref_src=twsrc%5Etfw">February 23, 2020</a></p>
<p><img alt="ERfOsJlW4AMPQsc" class="alignnone size-full wp-image-4305" src="https://lucatrevisan.files.wordpress.com/2020/02/erfosjlw4ampqsc.jpeg?w=584"/></p>
</blockquote>
<p>By Sunday night, the government decided that Lombardy and Veneto would be subject to a series of measures with the goal of reducing person-to-person contact, such as the closures mentioned above of schools, universities, museums etc. The meme below is titled “Here in Milan we are going too far”.</p>
<p><img alt="download" class="alignnone size-full wp-image-4306" src="https://lucatrevisan.files.wordpress.com/2020/02/download.jpeg?w=584"/></p>
<p>So far, there has been no secondary infection in Rome. (The text says “This is why the coronavirus has not yet reached Rome”.)</p>
<p><img alt="87384731_1300944790095464_2136089705354100736_n" height="391" src="https://lucatrevisan.files.wordpress.com/2020/02/87384731_1300944790095464_2136089705354100736_n.png?w=638&amp;h=391" width="638"/></p>
<p>(Image credit: <a href="https://www.facebook.com/lepiubellefrasidiosho">facebook.com/lepiubellefrasidiosho</a>)</p>
<p>Most annoyingly, every other newspaper headline or tv news chyron has been of the form “X in the time of coronavirus”. I can’t take it any more. This is the Autumn of journalism, a foretold death of creativity. Journalists are lost in the labyrinth of cliches. I wish all those headline writers one hundred years of solitude. The real news is the kidnapping of new ideas. Anyways, I think I am going to live to tell the tale.</p>
<p>The silver linings are that I have not been paying attention to the Democratic primaries and that I have plenty of free time to restart my planned series of posts on applications of online convex optimization to computational complexity. The next post will be on Impagliazzo’s hard-core lemma, a milestone in the theory of average-case complexity and pseudorandomness.</p>
<p>I am happy to answer any questions in the comments.</p></div>
    </content>
    <updated>2020-02-26T16:15:37Z</updated>
    <published>2020-02-26T16:15:37Z</published>
    <category term="Milan"/>
    <category term="Gabriel Garcia Marquez"/>
    <author>
      <name>luca</name>
    </author>
    <source>
      <id>https://lucatrevisan.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://lucatrevisan.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://lucatrevisan.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://lucatrevisan.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://lucatrevisan.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>"Marge, I agree with you - in theory. In theory, communism works. In theory." -- Homer Simpson</subtitle>
      <title>in   theory</title>
      <updated>2020-02-29T11:20:19Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://decentralizedthoughts.github.io/2020-02-26-selfish-mining/</id>
    <link href="https://decentralizedthoughts.github.io/2020-02-26-selfish-mining/" rel="alternate" type="text/html"/>
    <title>Blockchain Selfish Mining</title>
    <summary>Proof of Work (PoW) Blockchains implement a form of State Machine Replication (SMR). Unlike classical SMR protocols, they are open, i.e., anyone can join the system, and the system incentivizes participants, called miners, to follow the protocol. Therefore, unlike classical SMR protocols, reasoning about blockchain security relies not only on...</summary>
    <updated>2020-02-26T15:00:00Z</updated>
    <published>2020-02-26T15:00:00Z</published>
    <source>
      <id>https://decentralizedthoughts.github.io</id>
      <author>
        <name>Decentralized Thoughts</name>
      </author>
      <link href="https://decentralizedthoughts.github.io" rel="alternate" type="text/html"/>
      <link href="https://decentralizedthoughts.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Decentralized thoughts about decentralization</subtitle>
      <title>Decentralized Thoughts</title>
      <updated>2020-02-29T02:21:38Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/026</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/026" rel="alternate" type="text/html"/>
    <title>TR20-026 |  Spectral Sparsification via Bounded-Independence Sampling | 

	Dean Doron, 

	Jack Murtagh, 

	Salil Vadhan, 

	David Zuckerman</title>
    <summary>We give a deterministic, nearly logarithmic-space algorithm for mild spectral sparsification of undirected graphs. Given a weighted, undirected graph $G$ on $n$ vertices described by a binary string of length $N$, an integer $k\leq \log n$ and an error parameter $\varepsilon &gt; 0$, our algorithm runs in space $\tilde{O}(k\log (N\cdot w_{\mathrm{max}}/w_{\mathrm{min}}))$ where $w_{\mathrm{max}}$ and $w_{\mathrm{min}}$ are the maximum and minimum edge weights in $G$, and produces a weighted graph $H$ with $\tilde{O}(n^{1+2/k}/\varepsilon^2)$ expected edges that spectrally approximates $G$, in the sense of Spielmen and Teng [ST04], up to an error of $\varepsilon$.

Our algorithm is based on a new bounded-independence analysis of Spielman and Srivastava's effective resistance based edge sampling algorithm [SS08] and uses results from recent work on space-bounded Laplacian solvers [MRSV17].  In particular, we demonstrate an inherent tradeoff (via upper and lower bounds) between the amount of (bounded) independence used in the edge sampling algorithm, denoted by $k$ above, and the resulting sparsity that can be achieved.</summary>
    <updated>2020-02-26T04:13:25Z</updated>
    <published>2020-02-26T04:13:25Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-02-29T11:20:41Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16720</id>
    <link href="https://rjlipton.wordpress.com/2020/02/24/should-we-teach-coding-in-high-school/" rel="alternate" type="text/html"/>
    <title>Should We Teach Coding in High School?</title>
    <summary>Robert Sedgewick and Larry Cuban faced off today in the Wall Street Journal (WSJ) on the issue: Should everyone be taught coding in high school? Today we will discuss their recent comments on this issue. Bob is a long-time friend of mine, so I want to say that that up front. He is a professor […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
Robert Sedgewick and Larry Cuban faced off today in the Wall Street Journal (WSJ) on the issue: </p>
<p><a href="https://rjlipton.wordpress.com/2020/02/24/should-we-teach-coding-in-high-school/unknown-1-5/" rel="attachment wp-att-16723"><img alt="" class="alignright  wp-image-16723" src="https://rjlipton.files.wordpress.com/2020/02/unknown-1-1.jpeg?w=150" width="150"/></a><br/>
<a href="https://rjlipton.wordpress.com/2020/02/24/should-we-teach-coding-in-high-school/unknown-136/" rel="attachment wp-att-16722"><img alt="" class="alignright wp-image-16722" src="https://rjlipton.files.wordpress.com/2020/02/unknown-3.jpeg?w=150" width="150"/></a></p>
<blockquote><p><b> </b> <em> 	Should everyone be taught coding in high school? </em>
</p></blockquote>
<p/><p>
Today we will discuss their recent <a href="https://www.wsj.com/articles/should-all-children-learn-to-code-by-the-end-of-high-school-11582513441">comments</a> on this issue.<br/>
<span id="more-16720"/></p>
<p>
Bob is a long-time friend of mine, so I want to say that that up front. He is a professor of computer science at Princeton. Cuban is an emeritus professor of education at Stanford. Note, I do not know Cuban but will call him Larry—I hope that is fine. Besides what they say in the article, Larry wrote a <a href="https://larrycuban.wordpress.com/2017/07/11/coding-the-new-vocationalism-part-1/">three</a>–<a href="https://larrycuban.wordpress.com/2017/07/14/coding-the-new-vocationalism-part-2/">part</a> <a href="https://larrycuban.wordpress.com/2017/07/17/coding-the-new-vocationalism-part-3/">series</a> in 2017 on his own education blog, while Bob was <a href="https://www.washingtonpost.com/news/the-switch/wp/2013/12/11/president-obama-talks-about-teaching-everyone-to-code-this-professor-does-it/">associated</a> with a 2013 White House-led <a href="https://www.wired.com/2013/12/obama-code/">initiative</a> on coding in schools.</p>
<p>
The WSJ article consists of ten short paragraphs by Bob followed by eleven from Larry. This is sequential structure—like with statements <img alt="{S_1; S_2;}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS_1%3B+S_2%3B%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S_1; S_2;}"/>—or like having candidate town-halls for consectuive hours on CNN and such. What we’d like to see is a debate—like having parallel processes that must sync and communicate. Below we imagine one based on statements in the article.</p>
<p>
</p><p/><h2> A Conversation </h2><p/>
<p/><p>
The following is a paraphrase that tries to re-structure some of the article in debate format.</p>
<p/><p>
<font color="#0044cc"><br/>
<em>Bob:</em> <font color="#000000"> Teaching students to code will help them understand logical thinking and foster creativity.</font></font></p><font color="#0044cc"><font color="#000000">
<p>
<font color="#0044cc"><br/>
<i>Larry:</i> <font color="#000000"> You could say the same for teaching writing, math, history, and many other subjects. There is no research that shows that coding is better than other topics in this regard.</font></font></p><font color="#0044cc"><font color="#000000">
<p>
<font color="#0044cc"><br/>
<i>Bob:</i> <font color="#000000"> I am not aware of any research that shows that each topic that is taught now is better than coding.</font></font></p><font color="#0044cc"><font color="#000000">
<p>
<font color="#0044cc"><br/>
<i>Larry:</i> <font color="#000000"> Yes that is true, but consider how durable core education has been for our society. A century ago, industrial groups pushed the federal government to require vocational training in schools for particular industrial and agricultural skills and to establish separate vocational schools. Those undermined the broader goals of social development and civic engagement.</font></font></p><font color="#0044cc"><font color="#000000">
<p>
<font color="#0044cc"><br/>
<i>Bob:</i> <font color="#000000"> Technology is basic to much of society’s issues. Perhaps the Iowa caucus fiasco could have been avoided if they had a better understanding of computing.</font></font></p><font color="#0044cc"><font color="#000000">
<p>
<font color="#0044cc"><br/>
<i>Larry:</i> <font color="#000000"> I think the main argument for coding is being pushed by technology CEOs. They need more coders. The educational system should not just do what they need. Do you not agree Bob?</font></font></p><font color="#0044cc"><font color="#000000">
<p>
<font color="#0044cc"><br/>
<i>Bob:</i> <font color="#000000">If we teach coding it seems that it may help in lessening economic and gender based gaps. In summary, in the last millennium, education was based on reading, writing, and arithmetic. Perhaps we should now switch to reading, writing, and computing. Coding includes arithmetic and a whole lot more.</font></font></p><font color="#0044cc"><font color="#000000">
<p>
<font color="#0044cc"><br/>
<i>Larry:</i> <font color="#000000"> I agree education should help students achieve their potential. I just do not see that coding will do this. And further, data and projections from the U.S. Bureau of Labor Statistics show only an 11 percent increase in IT jobs, from 4.5 to 5 million, between 2018 and 2028. That’s going out a whole decade and still IT will only be about 3 percent of all jobs. Health care will <em>grow</em> in that time by as many jobs as IT has total.</font></font></p><font color="#0044cc"><font color="#000000">
<p>
<font color="#0044cc"><br/>
<i>Bob:</i> <font color="#000000"> Those percentages hide much of the benefit. Only a fraction of the thousands I have taught—in person and online—work in tech companies. The rest have gone into a broad variety of careers. Coding literacy is becoming a necessity in health care, social assistance, business services, construction, entertainment, manufacturing, and even politics. </font></font></p><font color="#0044cc"><font color="#000000">
<p>
<font color="#0044cc"><br/>
<i>Larry:</i> <font color="#000000"> But what would you cut to make room? Foreign language? History? Arts or music? Or decrease other aspects of math and science? Curricula are already crowded with required courses and frequent testing.</font></font></p><font color="#0044cc"><font color="#000000">
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
What should the role of coding be in our society? Who is right?</p>
<p/><p><br/>
[some word and grammar tweaks]</p></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></div>
    </content>
    <updated>2020-02-24T21:26:21Z</updated>
    <published>2020-02-24T21:26:21Z</published>
    <category term="News"/>
    <category term="People"/>
    <category term="coding"/>
    <category term="debate"/>
    <category term="high school"/>
    <category term="teach"/>
    <category term="WSJ"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2020-02-29T11:20:58Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/025</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/025" rel="alternate" type="text/html"/>
    <title>TR20-025 |  Efficient Isolation of Perfect Matching in O(log n) Genus Bipartite Graphs | 

	Chetan Gupta, 

	Vimal Raj Sharma, 

	Raghunath Tewari</title>
    <summary>We show that given an embedding of an O(log n) genus bipartite graph, one can construct an edge weight function in logarithmic space, with respect to which the minimum weight perfect matching in the graph is unique, if one exists. 

As a consequence, we obtain that deciding whether the graph has a perfect matching or not is in SPL. In 1999, Reinhardt, Allender and Zhou proved that if one can construct a polynomially bounded weight function for a graph in logspace such that it isolates a minimum weight perfect matching in the graph, then the perfect matching problem can be solved in SPL. In this paper, we give a deterministic logspace construction of such a weight function.</summary>
    <updated>2020-02-24T10:15:00Z</updated>
    <published>2020-02-24T10:15:00Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-02-29T11:20:41Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/024</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/024" rel="alternate" type="text/html"/>
    <title>TR20-024 |  Randomized and Symmetric Catalytic Computation | 

	Samir Datta, 

	Chetan Gupta, 

	Rahul Jain, 

	Vimal Raj Sharma, 

	Raghunath Tewari</title>
    <summary>A catalytic Turing machine is a model of computation that is created by equipping a Turing machine with an additional auxiliary tape which is initially filled with arbitrary content; the machine can read or write on auxiliary tape during the computation but when it halts auxiliary tape’s initial content must be restored. In this paper, we study the power of catalytic Turing machines with O(log n)-sized clean tape and a polynomial-sized auxiliary tape.

We introduce the notion of randomized catalytic Turing machine and show that the resulting complexity class CBPL is contained in the class ZPP. We also introduce the notion of symmetricity in the context of catalytic computation and prove that, under a widely believed assumption, in the logspace setting the power of a randomized catalytic Turing machine and a symmetric catalytic Turing machine is equal to a deterministic catalytic Turing machine which runs in polynomial time.</summary>
    <updated>2020-02-24T10:07:32Z</updated>
    <published>2020-02-24T10:07:32Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-02-29T11:20:41Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/02/23/postdoc-at-university-of-chicago-apply-by-march-15-2020/</id>
    <link href="https://cstheory-jobs.org/2020/02/23/postdoc-at-university-of-chicago-apply-by-march-15-2020/" rel="alternate" type="text/html"/>
    <title>Postdoc at University of Chicago (apply by March 15, 2020)</title>
    <summary>The Econometrics and Statistics group at the Booth School of Business of the University of Chicago invites applications for a postdoctoral researcher working with Prof. Bryon Aragam. Potential candidates should have a background in statistics and machine learning, for example nonconvex optimization, nonparametric statistics, and/or learning theory. Website: https://uchicago.wd5.myworkdayjobs.com/External/job/Hyde-Park-Campus/Principal-Researcher_JR07406 Email: bryon@chicagobooth.edu</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Econometrics and Statistics group at the Booth School of Business of the University of Chicago invites applications for a postdoctoral researcher working with Prof. Bryon Aragam. Potential candidates should have a background in statistics and machine learning, for example nonconvex optimization, nonparametric statistics, and/or learning theory.</p>
<p>Website: <a href="https://uchicago.wd5.myworkdayjobs.com/External/job/Hyde-Park-Campus/Principal-Researcher_JR07406">https://uchicago.wd5.myworkdayjobs.com/External/job/Hyde-Park-Campus/Principal-Researcher_JR07406</a><br/>
Email: bryon@chicagobooth.edu</p></div>
    </content>
    <updated>2020-02-23T18:01:23Z</updated>
    <published>2020-02-23T18:01:23Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-02-29T11:21:01Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/023</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/023" rel="alternate" type="text/html"/>
    <title>TR20-023 |  Non-Malleability against Polynomial Tampering | 

	Eshan Chattopadhyay, 

	Jyun-Jie Liao, 

	Marshall Ball, 

	Tal Malkin, 

	Li-Yang Tan</title>
    <summary>We present the first explicit construction of a  non-malleable code that can handle tampering functions that are bounded-degree polynomials. 

Prior to our work, this was only known  for  degree-1 polynomials (affine tampering functions), due to  Chattopadhyay and Li (STOC 2017). As a direct corollary, we obtain an explicit non-malleable code that is secure against tampering by bounded-size arithmetic circuits.

We show applications of our non-malleable code in constructing   non-malleable secret sharing schemes that are robust against bounded-degree polynomial tampering. In fact our result is stronger: we can handle adversaries that can adaptively choose the polynomial tampering function based on initial leakage of a bounded number of shares.

Our results are derived from explicit constructions of  seedless non-malleable extractors that can handle bounded-degree polynomial tampering functions. Prior to our work, no such result was known even for degree-2 (quadratic) polynomials.</summary>
    <updated>2020-02-23T05:37:13Z</updated>
    <published>2020-02-23T05:37:13Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-02-29T11:20:41Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2020/02/22/applications-maximum-matching</id>
    <link href="https://11011110.github.io/blog/2020/02/22/applications-maximum-matching.html" rel="alternate" type="text/html"/>
    <title>Two applications of maximum matching</title>
    <summary>This quarter I’m teaching a course on graph algorithms (an upper-division elective, so only around 200 students; our required classes are much bigger) and we’ve reached the part of the course where we discuss matching. Motivating bipartite matching, perfect matching, weighted matching, and stable matching are all easy enough but I wanted a few more examples of applications of non-bipartite maximum-cardinality matching, so I asked my colleague Vijay Vazirani who responded with two cute ones that I wasn’t already familiar with.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>This quarter I’m teaching a course on graph algorithms (an upper-division elective, so only around 200 students; our required classes are much bigger) and we’ve reached the part of the course where we discuss <a href="https://en.wikipedia.org/wiki/Matching_(graph_theory)">matching</a>. Motivating bipartite matching, perfect matching, weighted matching, and stable matching are all easy enough but I wanted a few more examples of applications of non-bipartite <a href="https://11011110.github.io/blog/2020/02/22/Maximum cardinality matching">maximum-cardinality matching</a>, so I asked my colleague Vijay Vazirani who responded with two cute ones that I wasn’t already familiar with.</p>

<p>His first suggestion was two-processor scheduling. To keep things simple and concrete let’s assume that we have a collection of equal-length tasks, with a partial ordering (or DAG) describing their timing constraints. If we have one processor to perform them on (or one person to perform them), the obvious solution is to schedule them according to a linear extension of the partial order (a topological ordering of the DAG), allowing them to all be performed with no delays, in total time equal to the number of tasks. But now suppose that there are two processors or people performing the tasks, so we can process two tasks at a time and, ideally, finish twice as quickly. We would like to find a schedule with as many compatible pairs of tasks as we can, saving as many time slots as there are pairs. Two tasks are compatible if they are incomparable in the partial order (there is no path between them in the DAG), so it looks like we simply need to find a maximum matching in the incomparability graph of the partial order. This doesn’t quite work because two matched pairs can “cross”,
unable to both be used in the same schedule because each pair contains an element constrained to be earlier than an element of the other pair. But when this happens, it’s possible to uncross them and get another matching that’s at least as good, eventually reaching a matching without any crossings that can be topologically ordered to give an optimal schedule. The connection between this scheduling problem and matching appears to come from Fujii, Kasami, and Ninamiya, “<a href="https://doi.org/10.1137/0117070">Optimal sequencing of two equivalent processors</a>”, <em>SIAM J. Appl. Math.</em> 1969; for fast algorithms for this special case of matching see H. Gabow, “<a href="https://doi.org/10.1145/322326.322335">An almost-linear algorithm for two-processor scheduling</a>”, <em>JACM</em> 1982.</p>

<p>Another application, closer to the real world, comes from a problem of matching kidney donors to kidney donor recipients. But we don’t use the obvious bipartite graph of donors and recipients. Most kidney transplant recipients enter the matching process paired up already with a friend or relative who is willing to donote one of their kidneys, because otherwise there wouldn’t be enough kidneys to go around. But usually these donor-recipient pairs are incompatible with each other, so they need to find another donor-recipient pair such that the donors from each pair are compatible with the recipients from the other pair. Then, all four people get together at the same hospital and trade kidneys. More complicated exchanges of three or more pairs are not done, because that would require simultaneous operations with six or more people and significantly greater chances that one of them will back out at the last minute. So to save as many lives as possible, we need a maximum matching on a graph whose vertices are donor-recipient pairs and whose edges represent double compatibility of pairs. There’s a big literature on kidney exchange but the source for the connection to maximum matching appears to be A. E. Roth, T. Sönmez, and M. U. Ünver, “<a href="https://www.nber.org/papers/w10698.pdf">Pairwise kidney exchange</a>”, <em>J. Econ. Th.</em> 2005.
If pairwise compatibility is an equivalence relation then the matching part is trivial (it’s just matching in a <a href="https://en.wikipedia.org/wiki/Cluster_graph">disjoint union of cliques</a>) but this framework is flexible enough to handle arbitrary non-transitive compatibility relations.</p>

<p>I learned of the kidney donor matching application a little too late to incorporate it into my introductory lecture on matching, so I used the other one. But next time I’ll be prepared with both!</p>

<p>(<a href="https://mathstodon.xyz/@11011110/103705828147671738">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2020-02-22T17:55:00Z</updated>
    <published>2020-02-22T17:55:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2020-02-23T02:36:56Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/022</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/022" rel="alternate" type="text/html"/>
    <title>TR20-022 |  Interactive Error Resilience Beyond $\frac{2}{7}$ | 

	Klim Efremenko, 

	Gillat Kol, 

	Raghuvansh Saxena</title>
    <summary>Interactive error correcting codes can protect interactive communication protocols against a constant fraction of adversarial errors, while incurring only a constant multiplicative overhead in the total communication. What is the maximum fraction of errors that such codes can protect against? 

For the non-adaptive channel, where the parties must agree in advance on the order in which they communicate, Braverman and Rao prove that the maximum error resilience is~$\frac{1}{4}$ (STOC, 2011). Ghaffari, Haeupler, and Sudan (STOC, 2014) consider the {\em adaptive} channel, where the order in which the parties communicate may not be fixed, and give a clever protocol that is resilient to a $\frac{2}{7}$ fraction of errors. This was believed to be optimal. 

We revisit this result, and show how to overcome the $\frac{2}{7}$ barrier. Specifically, we show that, over the adaptive channel, every two-party communication protocol can be converted to a protocol that is resilient to $\frac{7}{24} &gt; \frac{2}{7}$ fraction of errors with only a constant multiplicative overhead to the total communication. The protocol is obtained by a novel implementation of a feedback mechanism over the adaptive channel.</summary>
    <updated>2020-02-22T02:29:22Z</updated>
    <published>2020-02-22T02:29:22Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-02-29T11:20:41Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/02/21/tenure-track-faculty-all-levels-at-boston-university-apply-by-february-21-2020/</id>
    <link href="https://cstheory-jobs.org/2020/02/21/tenure-track-faculty-all-levels-at-boston-university-apply-by-february-21-2020/" rel="alternate" type="text/html"/>
    <title>Tenure-track faculty, all levels at Boston University (apply by February 21, 2020)</title>
    <summary>The Faculty of Computing &amp; Data Sciences invites applications for multiple tenured and tenure-track faculty positions at all ranks. Founded in 2019, the Faculty of Computing &amp; Data Sciences is a new university-wide, degree-granting academic unit. Consideration and review of applications will be on a rolling basis. See the full ad for more information. Website: […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Faculty of Computing &amp; Data Sciences invites applications for multiple tenured and tenure-track faculty positions at all ranks. Founded in 2019, the Faculty of Computing &amp; Data Sciences is a new university-wide, degree-granting academic unit. Consideration and review of applications will be on a rolling basis. See the full ad for more information.</p>
<p>Website: <a href="https://www.bu.edu/cds-faculty/join-us/">https://www.bu.edu/cds-faculty/join-us/</a><br/>
Email: ads22@bu.edu</p></div>
    </content>
    <updated>2020-02-21T19:56:13Z</updated>
    <published>2020-02-21T19:56:13Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-02-29T11:21:01Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/02/21/lecturer-to-reader-tenured-assistant-professor-to-tenured-associate-professor-at-royal-holloway-university-of-london-apply-by-february-27-2020/</id>
    <link href="https://cstheory-jobs.org/2020/02/21/lecturer-to-reader-tenured-assistant-professor-to-tenured-associate-professor-at-royal-holloway-university-of-london-apply-by-february-27-2020/" rel="alternate" type="text/html"/>
    <title>Lecturer to Reader (tenured Assistant Professor to tenured Associate Professor) at Royal Holloway, University of London (apply by February 27, 2020)</title>
    <summary>The CS Department at Royal Holloway, University of London is looking to appoint up to six new academics to support our expansion in research and teaching. We carry out outstanding research and deliver excellent teaching at both undergraduate and postgraduate level. (The ad is not specific for theory of CS, but strong candidates in theory […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The CS Department at Royal Holloway, University of London is looking to appoint up to six new academics to support our expansion in research and teaching. We carry out outstanding research and deliver excellent teaching at both undergraduate and postgraduate level.<br/>
(The ad is not specific for theory of CS, but strong candidates in theory are encouraged. Vacancy open to all nationalities.)</p>
<p>Website: <a href="https://jobs.royalholloway.ac.uk/vacancy.aspx?ref=0120-036">https://jobs.royalholloway.ac.uk/vacancy.aspx?ref=0120-036</a><br/>
Email: carlos.matos@rhul.ac.uk</p></div>
    </content>
    <updated>2020-02-21T18:27:13Z</updated>
    <published>2020-02-21T18:27:13Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-02-29T11:21:01Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/021</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/021" rel="alternate" type="text/html"/>
    <title>TR20-021 |  NP-Hardness of Circuit Minimization for Multi-Output Functions | 

	Rahul Ilango, 

	Bruno Loff, 

	Igor Carboni Oliveira</title>
    <summary>Can we design efficient algorithms for finding fast algorithms? This question is captured by various circuit minimization problems, and algorithms for the corresponding tasks have significant practical applications. Following the work of Cook and Levin in the early 1970s, a central question is whether minimizing the circuit size of an explicitly given function is ${NP}$-complete. While this is known to hold in restricted models such as DNFs, making progress with respect to more expressive classes of circuits has been elusive.  

In this work, we establish the first ${NP}$-hardness result for circuit minimization of total functions in the setting of general (unrestricted) Boolean circuits. More precisely, we show that computing the minimum circuit size of a given multi-output Boolean function $f \colon \{0,1\}^n \to \{0,1\}^m$ is ${NP}$-hard under many-one polynomial-time randomized reductions. Our argument builds on a simpler ${NP}$-hardness proof for the circuit minimization problem for (single-output) Boolean functions under an extended set of generators.

Complementing these results, we investigate the computational hardness of minimizing communication. We establish that several variants of this problem are ${NP}$-hard under deterministic reductions. In particular, unless ${P} = {NP}$, no polynomial-time computable function can approximate the deterministic two-party communication complexity of a partial Boolean function up to a polynomial. This has consequences for the class of structural results that one might hope to show about the communication complexity of partial functions.</summary>
    <updated>2020-02-21T15:13:20Z</updated>
    <published>2020-02-21T15:13:20Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-02-29T11:20:41Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/020</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/020" rel="alternate" type="text/html"/>
    <title>TR20-020 |  Improved Approximate Degree Bounds For $k$-distinctness | 

	Shuchen Zhu, 

	Justin Thaler, 

	Nikhil Mande</title>
    <summary>An open problem that is widely regarded as one of the most important in quantum query complexity is to resolve the quantum query complexity of the $k$-distinctness function on inputs of size $N$. While the case of $k=2$ (also called Element Distinctness) is well-understood, there is a polynomial gap between the known upper and lower bounds for all constants $k&gt;2$. Specifically, the best known upper bound is $O(N^{(3/4)-1/(2^{k+2}-4)})$ (Belovs, FOCS 2012), while the best known lower bound for $k &gt;= 2$ is $\Omega(N^{2/3} + N^{(3/4)-1/(2k)})$ (Aaronson and Shi, J.~ACM 2004; Bun, Kothari, and Thaler, STOC 2018).
For any constant $k &gt;= 4$, we improve the lower bound to $\Omega(N^{(3/4)-1/(4k)})$. This yields, for example, the first proof that $4$-distinctness is strictly harder than Element Distinctness. Our lower bound applies more generally to approximate degree.
As a secondary result, we give a simple construction of an approximating polynomial of degree $O(N^{3/4})$ that applies whenever $k &lt;= polylog(N)$.</summary>
    <updated>2020-02-21T13:58:40Z</updated>
    <published>2020-02-21T13:58:40Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-02-29T11:20:41Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16702</id>
    <link href="https://rjlipton.wordpress.com/2020/02/20/pnp-a-story/" rel="alternate" type="text/html"/>
    <title>P=NP: A Story</title>
    <summary>The P=NP story without symbols. [ The Movie ] Dr. Strangelove is the classic 1964 movie about the potential for nuclear war between the US and the Soviet Union during the cold war. The film was directed by Stanley Kubrick and stars Peter Sellers, George Scott, Sterling Hayden, and Slim Pickens. Today we try to […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>The P=NP story without symbols.</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2020/02/20/pnp-a-story/unknown-135/" rel="attachment wp-att-16705"><img alt="" class="alignright size-full wp-image-16705" src="https://rjlipton.files.wordpress.com/2020/02/unknown-2.jpeg?w=600"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">[ The Movie ]</font></td>
</tr>
</tbody>
</table>
<p>
<em>Dr. Strangelove</em> is the classic 1964 movie about the potential for nuclear war between the US and the Soviet Union during the cold war. The film was directed by Stanley Kubrick and stars Peter Sellers, George Scott, Sterling Hayden, and Slim Pickens. </p>
<p>
Today we try to explain the P=NP problem in an “analog” fashion.</p>
<p>
In <a href="https://en.wikipedia.org/wiki/Dr._Strangelove">Dr. Strangelove</a>, US President Merkin Muffley wishes to recall a group of US bombers that are incorrectly about to drop nuclear weapons on Russia. He hopes to stop war. Here is the conversation between General Turgidson played by Scott and Muffley played by Sellers, in which Turgidson informs that the recall message will not be received…</p>
<blockquote><p>
<tt><br/>
<b>Turgidson:</b> 	…unless the message is preceded by the correct three-letter prefix. </tt></p><tt>
<p><b>Muffley:</b> 	Then do you mean to tell me, General Turgidson, that you will be unable to 	recall the aircraft? </p>
<p><b>Turgidson:</b> 	That’s about the size of it. However, we are plowing through every possible 	three letter combination of the code. But since there are seventeen thousand 	permutations it’s going to take us about two and a half days to transmit them all. </p>
<p><b>Muffley:</b> 	How soon did you say the planes would penetrate Russian radar cover? </p>
</tt><p><tt><b>Turgidson:</b> 	About eighteen minutes from now, sir.<br/>
</tt>
</p></blockquote>
<p>
This is the problem that P=NP addresses. How do you find a solution to a problem that has many potential solutions? In this case there are over thousands of possible combinations. Since each requires sending a message to an electronic unit that sits on a plane, thousands of miles away, and since messages cannot be sent too often, it will take much too long to find the secret message. </p>
<p>
The central P=NP question is: Can we do better than trying all possibilities? The answer is yes—at least in the case of the movie, the secret combination is indeed found. More on that in a moment.</p>
<p>
</p><p/><h2> Opening Mechanical Locks </h2><p/>
<p/><p>
In <em>Dr. Strangelove</em> the issue is finding the three letter code for a certain device that sits on the bombers. The protocol is: Send a three letter code to the bombers. If the code is correct, then the bombers will be recalled, and all is saved. If the code is wrong, then nothing happens. </p>
<p>
Instead of this, consider the same type of problem for finding the combination to a mechanical lock. That is a lock that is often at a gym, for example, to protect your belongings. Recall you spin the lock’s dial three times to the right, stop on the first number, then turn one time to the left, stop on the second number, and finally go to the right to stop at the third number. Then you pull the lock open.</p>
<p>
This works provided you know the combination. In general there are 64,000 such combinations. So unless you know the numbers, you are in trouble. Trying all possible combinations is not possible for mortals. But there is hope. It is possible to find the combination without knowing it. This is possible provided: <i>You have the combination lock in your hands</i>. </p>
<p>
If you only can send a possible combination to someone else to try, you are out of luck. Unfortunately in Dr. Strangelove the device on the bomber is not in your hands. So as the General says, we are trying all the possible combinations one at a time. But if the device is local you can do better.</p>
<p>
</p><p/><h3> Breaking The Locks </h3><p/>
<p/><p>
There are many <a href="https://www.wikihow.com/Open-Combination-Locks-Without-a-Code">sites</a> on the web that explain how to do much better. Here is one way to find the first number for a lock:</p>
<ol>
<li>
Pull up gently on the shackle and hold it in place. Turn the dial clockwise listening carefully until you hear the lock click. <p/>
</li><li>
Start with a good deal of pressure and gently let up as you spin it around, until you meet resistance in only one place. It should catch in only one place, making a click. <p/>
</li><li>
Add 5 to that number and write it down.
</li></ol>
<p>
This is the first number in the combination. There are similar methods to get the remaining two numbers. But already you have reduced the choices for the combination from 64,000 by a factor of 40. The rest of the how-to-do rules help you get the remaining two numbers. </p>
<p/><p/>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.wordpress.com/2020/02/20/pnp-a-story/lock6/" rel="attachment wp-att-16707"><img alt="" class="aligncenter size-full wp-image-16707" src="https://rjlipton.files.wordpress.com/2020/02/lock6.jpg?w=600"/></a>
</td>
</tr>
<tr>

</tr>
</tbody></table>
<p>
Note this attack relies on physical properties of the lock. A lock is made from springs and gears and rods, and is not perfect. As you turn the dial the mechanical parts rub and make noises. These noises reveal information, that is useful to you. Information that can reveal the combination of the lock.</p>
<p>
</p><p/><h2> Opening Digital Locks </h2><p/>
<p/><p>
The point is that there is a way to open a lock without knowing the combination. Here the trick is that you can try and use the lock and play with it in a way that it reveals information about its secret combination. This is what the P=NP question asks: </p>
<blockquote><p><b> </b> <em> <i>Are there ways to manipulate a digital lock and get it to reveal information?</i> </em>
</p></blockquote>
<p/><p>
Put another way: <i>Do digital locks make noise?</i> </p>
<p>
Essentially P=NP is true if digital locks all are imperfect, like mechanical locks. That is, if digital locks all make noise. It is widely believed that is <b>false</b>. The belief is that P<img alt="{\neq}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cneq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\neq}"/> NP which means that there are essentially perfect digital locks. That is some digital locks make no noise. </p>
<p>
</p><p/><h2> P<img alt="{\neq}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cneq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\neq}"/> NP </h2><p/>
<p/><p>
Why is it believed that digital locks can be perfect? Well the answer is simple. To date certain types of digital locks have not been broken. That is no one yet knows how to make them click and reveal information. This is of course a dangerous position for several reasons.</p>
<ol>
<li>
The failure to break a lock does not mean that someone cleverer cannot break it. <p/>
</li><li>
There are reasons that if some people knew how to break certain digital locks that they would <i>not</i> tell anyone. They might prefer to keep their ability secret to make money or cause harm. <p/>
</li><li>
Finally, it seems dangerous to guess that anything can be done without noise.
</li></ol>
<p>
The latter point is that making systems work perfectly is usually impossible. Mechanical systems must have friction of some kind, and it seems possible that digital systems will also. We will see.</p>
<p>
</p><p/><h2> Smart Search </h2><p/>
<p/><p>
Colonel Ripper, played by Hayden, is the one that launched the bombers against Russia. The recall code is found and the bombers are recalled. An officer named Mandrake, played by Sellers too, notices some doodles on a pad by the crazy Ripper. It is covered with an interlocking pattern of the words Peace On Earth, and Purity Of Essence. Ripper is obsessed with these ideas—do not ask why.</p>
<blockquote><p>
<tt><br/>
<b>Mandrake:</b> Peace on Earth. Peace on Earth. Peace on Earth: <b>P O E</b>.<br/>
Purity of essence. <b>O P E</b>. (whispers) <b>O P E</b>.<br/>
</tt>
</p></blockquote>
<p>
This is the key. This information is sent to the Pentagon and soon the bombers are recalled. The search space is cut down from thousands to 6 possible orders. Success. Well if you’ve seen the movie, you know it was not exactly success, but that failure has nothing to do with our attempt to explain the P=NP question.</p>
<p>
This second idea is different from whether locks make noise. It is whether every lock has a giveaway by dint of the process by which we obtained that particular lock to begin with. Note that the lock is not the definition of the problem itself, like SAT or graph 3-coloring, but rather a particular instance of the problem. We have discussed how instances of factoring that tend to be generated by algorithms have collective giveaways in an earlier <a href="https://rjlipton.wordpress.com/2012/03/01/do-gaps-between-primes-affect-rsa-keys/">post</a>—which quotes another part of <em>Dr. Strangelove</em>.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
I love the movie <em>Dr. Strangelove</em>, and love any excuse to talk about it. So please forgive me this story about P=NP. I hope that trying to understand the P=NP question without complex notation may help us better understand it. What do you all think?</p>
<p/></font></font></div>
    </content>
    <updated>2020-02-20T16:12:04Z</updated>
    <published>2020-02-20T16:12:04Z</published>
    <category term="Ideas"/>
    <category term="P=NP"/>
    <category term="combination lock"/>
    <category term="digital locks"/>
    <category term="locks"/>
    <category term="noise"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2020-02-29T11:20:58Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://tcsplus.wordpress.com/?p=389</id>
    <link href="https://tcsplus.wordpress.com/2020/02/20/tcs-talk-wednesday-february-26-henry-yuen-university-of-toronto/" rel="alternate" type="text/html"/>
    <title>TCS+ talk: Wednesday, February 26 — Henry Yuen, University of Toronto</title>
    <summary>The next TCS+ talk will take place this coming Wednesday, February 26th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 18:00 UTC). Henry Yuen from University of Toronto will speak about “MIP* = RE” (abstract below). Please make sure you reserve a spot for your group to join us live […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The next TCS+ talk will take place this coming Wednesday, February 26th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 18:00 UTC). <strong>Henry Yuen</strong> from University of Toronto will speak about “<em>MIP* = RE</em>” (abstract below).</p>
<p>Please make sure you reserve a spot for your group to join us live by signing up on <a href="https://sites.google.com/site/plustcs/livetalk/live-seat-reservation">the online form</a>. As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/site/plustcs/suggest">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/site/plustcs/">the website</a>.</p>
<blockquote><p>Abstract: MIP* denotes the class of problems that admit interactive proofs with quantum entangled provers. It has been an outstanding question to characterize the complexity of MIP*. Most notably, there was no known computable upper bound on this class.<br/>
We show that MIP* is equal to the class RE, the set of recursively enumerable languages. In particular, this shows that MIP* contains uncomputable problems. Through a series of known connections, this also yields a negative answer to Connes’ Embedding Problem from the theory of operator algebras. In this talk, I will explain the connection between Connes’ Embedding Problem, quantum information theory, and complexity theory. I will then give an overview of our approach, which involves reducing the Halting Problem to the problem of approximating the entangled value of nonlocal games.<br/>
Joint work with Zhengfeng Ji, Anand Natarajan, Thomas Vidick, and John Wright.</p></blockquote></div>
    </content>
    <updated>2020-02-20T08:30:51Z</updated>
    <published>2020-02-20T08:30:51Z</published>
    <category term="Announcements"/>
    <author>
      <name>plustcs</name>
    </author>
    <source>
      <id>https://tcsplus.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://tcsplus.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://tcsplus.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://tcsplus.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://tcsplus.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A carbon-free dissemination of ideas across the globe.</subtitle>
      <title>TCS+</title>
      <updated>2020-02-29T11:21:31Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2020/02/19/snowflake-spanners</id>
    <link href="https://11011110.github.io/blog/2020/02/19/snowflake-spanners.html" rel="alternate" type="text/html"/>
    <title>Snowflake spanners</title>
    <summary>My previous post gave an example of a largish random point set where the greedy geometric spanner for distance ratio 2 had no crossings, while the spanner for the lower distance ratio had many (linearly many) crossings. And you might think from that example that there is some threshold for which distance ratios above the threshold always have planar greedy spanners, or even that the threshold is at or below 2. But it’s not true.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="https://11011110.github.io/blog/2020/02/17/spanners-have-sparse.html">My previous post</a> gave an example of a largish random point set where the <a href="https://en.wikipedia.org/wiki/Greedy_geometric_spanner">greedy geometric spanner</a> for distance ratio 2 had no crossings, while the spanner for the lower distance ratio had many (linearly many) crossings. And you might think from that example that there is some threshold for which distance ratios above the threshold always have planar greedy spanners, or even that the threshold is at or below 2. But it’s not true.</p>

<p>To see why not, we have to turn to an idea from an earlier paper of mine, “<a href="https://arxiv.org/abs/cs.CG/9907031">Beta-skeletons have unbounded dilation</a>” (<em>CGTA</em> 2002). In it, I used a flattened variant of the <a href="https://en.wikipedia.org/wiki/Koch_snowflake">Koch snowflake fractal</a> to find bad examples for a different kind of spanner, and the same thing works here too. The intuitive idea is that these fractals form curves that, locally, look nice to a spanner algorithm (just connect consecutive pairs of points along the curve). But they pack a lot of length into a small area, forcing the spanner algorithm to eventually add some shortcuts to the curve. If we can control where it adds the shortcuts, maybe we can make pairs of shortcuts cross.</p>

<p>In fact the Koch snowflake itself almost works, but it has some closest pairs that are non-consecutive along the curve, allowing the greedy spanner algorithm to choose those pairs instead of the consecutive curve points that we want it to choose. If we flatten the snowflake just a little bit, that complication goes away. If we choose the distance ratio of the spanner large enough, we can make it so that the greedy spanner algorithm doesn’t add any shortcuts until it reaches pairs of points that are opposite each other on the curve. And if we make it just barely large enough for that to be true, it will be forced to add those shortcuts once it does reach that distance in the sorted ordering of the distances. For instance, here’s a point set and its non-planar greedy spanner generated in this way with spanning ratio 4:</p>

<p style="text-align: center;"><img alt="Greedy spanner of snowflake-like curve with distance ratio 4" src="https://11011110.github.io/blog/assets/2020/snowflake.svg"/></p>

<p>This pretty picture, with the three crossing shortcuts between opposite pairs of points, doesn’t quite generalize to arbitrary-order snowflake-like curves, unfortunately. It will always be possible to find a distance ratio  such that the greedy algorithm adds one of these three shortcuts, as the first shortcut it needs to add. But then once it has added it, that shortcut can make the other two opposite pairs of points closer to each other in the spanner than they were, so that the greedy algorithm doesn’t need to add them. We might only get one of these three crossing edges, instead of all three. (In fact, for the point set shown here, this is exactly what happens for spanning ratio 4.5.)</p>

<p>Instead, let’s look for a slightly lower distance ratio , for which the first shortcuts added by the greedy spanner algorithm cut off two lobes of the snowflake instead of three. For the same points as above,  works:</p>

<p style="text-align: center;"><img alt="Greedy spanner of snowflake-like curve with distance ratio 3.5" src="https://11011110.github.io/blog/assets/2020/snowflake2.svg"/></p>

<p>These two-lobe shortcuts are shorter than the three-lobe shortcuts, so they’re considered earlier by the greedy algorithm. There are two crossing equilateral triangles of two-lobe shortcuts (forming a Star of David pattern) and the greedy algorithm has to include two edges from each equilateral triangle. This is because, for each of these potential shortcuts, the greedy spanner won’t include a better path between its endpoints until it has either that shortcut itself or the two other shortcuts of the same triangle. No matter which two shortcuts we choose from each of the two equilateral triangles, we get either two crossings or, as here, three crossings.</p>

<p>For any order of flattened Koch snowflake, there’s a distance ratio  producing a greedy spanner that looks like this picture, with two or three crossings. And by choosing a snowflake of high-enough order, we can make  become arbitrarily large. Or, to put it another way, the greedy spanner algorithm can generate crossings for arbitrarily large distance ratios.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/103689972863017904">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2020-02-19T23:01:00Z</updated>
    <published>2020-02-19T23:01:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2020-02-23T02:36:56Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/019</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/019" rel="alternate" type="text/html"/>
    <title>TR20-019 |  A note on the explicit constructions of tree codes over polylogarithmic-sized alphabet | 

	Siddharth Bhandari, 

	Prahladh Harsha</title>
    <summary>Recently, Cohen, Haeupler and Schulman gave an explicit construction of binary tree codes over polylogarithmic-sized output alphabet based on Pudl\'{a}k's construction of maximum-distance-separable (MDS)  tree codes using totally-non-singular triangular matrices. In this short note, we give a unified and simpler presentation of Pudl\'{a}k and Cohen-Haeupler-Schulman's constructions.</summary>
    <updated>2020-02-19T15:04:50Z</updated>
    <published>2020-02-19T15:04:50Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-02-29T11:20:41Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/02/19/associate-professor-professor-of-computer-science-at-university-of-oxford-apply-by-april-24-2020/</id>
    <link href="https://cstheory-jobs.org/2020/02/19/associate-professor-professor-of-computer-science-at-university-of-oxford-apply-by-april-24-2020/" rel="alternate" type="text/html"/>
    <title>Associate Professor/Professor of Computer Science at University of Oxford (apply by April 24, 2020)</title>
    <summary>The Department of Computer Science and St Catherine’s College are recruiting an Associate Professor of Computer Science in the Department of Computer Science, to start before 31 July 2020 if possible and by no later than 1 October 2020. The successful candidate will also be appointed as Fellow and Tutor in Computer Science at St […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Department of Computer Science and St Catherine’s College are recruiting an Associate Professor of Computer Science in the Department of Computer Science, to start before 31 July 2020 if possible and by no later than 1 October 2020. The successful candidate will also be appointed as Fellow and Tutor in Computer Science at St Catherine’s College. (see link for details)</p>
<p>Website: <a href="http://www.cs.ox.ac.uk/news/1782-full.html">http://www.cs.ox.ac.uk/news/1782-full.html</a><br/>
Email: agalanis@cs.ox.ac.uk</p></div>
    </content>
    <updated>2020-02-19T13:29:42Z</updated>
    <published>2020-02-19T13:29:42Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-02-29T11:21:01Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://emanueleviola.wordpress.com/?p=717</id>
    <link href="https://emanueleviola.wordpress.com/2020/02/18/working-remotely-will-be-the-most-significant-transformation-since-agriculture/" rel="alternate" type="text/html"/>
    <title>Working remotely will be the most significant transformation since agriculture</title>
    <summary>Its impact on civilization will be exactly opposite. Rather than concentrating population, it will disperse it. Commuting and the traffic crisis will disappear. So will the housing crisis. You will have a large lot of land with a robot-ready house built new with safe, eco-friendly material and free of hazardous substance. You will live away […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Its impact on civilization will be exactly opposite.  Rather than concentrating population, it will disperse it.  Commuting and the traffic crisis will disappear.  So will the housing crisis.  You will have a large lot of land with a robot-ready house built new with safe, eco-friendly material and free of hazardous substance.  You will live away from volcanoes, fault lines, tornadoes, wild fires and other hazards. You’ll be able to move to a location with ideal climate, which for historical reasons are now under-populated.  This will dramatically reduce housing costs, especially heating, and solve  or greatly mitigate the pollution problem. Huge amounts of space will be cleared up and given back to nature, or used for housing.</p>



<p>Doctors will visit patients remotely.  This will enable patients to be followed up more regularly and consistently throughout their lives regardless of where they are.  Doctors will have more time to give meaningful advice rather than having the patient wait 1 year for the appointment and then spend 1 hour to get to the doctor for a 10-minute visit of which 8 are spent looking at the screen and filling reports. Robo-tools will take measurements and send them to the doctor.  If a complicated procedure is required, the expert will connect with the patient and the doctor remotely first, and then the patient will schedule a trip for the procedure.</p>



<p>You’ll take gym classes remotely via a remote gym. The instructor will give you personalized advice and follow your progress anywhere, anytime. Demanding facilities like swimming pools will be next to your house.</p>



<p>Courts of law, and the entire judicial system will be taken off-line.</p>



<p>People will vote from home, elections will be more frequent and granular.  Constituents choosing not to vote will (maybe) have to specifically abstain.  This will finally realize the democratic ideal where the government represents the will of the people.</p>



<p>Constituents will be able to participate to discussions, instead of having to travel 1 hour for a 5-minute in-person discussion.  The level of engagement will be measured by the level of engagement as opposed to travel distance.</p>



<p>Wireless won’t be used on a large scale, since its noxious effects will be undeniable. Instead we will have network cables densely spread out over the earth — one of the few duties of the government will be to maintain these cables for the free, democratic, public use.</p>



<p>Banking will be done remotely, and physical money will disappear.</p>



<p>We will have immersive work-stations with wall-to-wall, solar-powered e-ink screens, holographic images, and audio indistinguishable from reality.  You will be able to attend meetings while exercising, like walking or biking on a machine or outside.  This will boost your health, lowering health care costs for all.</p>



<p>People with special needs will have the same opportunities and duties as everyone else and will be fully integrated.</p>



<p>All learning will be done remotely.  The instructor will be able to provide better, more personalized teaching, and connect with each student face-to-face.  Testing will be done remotely, each student monitored via cameras.  Critical examinations will be administered in special-purpose facilities which are next to your house (similar in spirit to say the way GRE is administered, but much more large scale and flexible, including for example synchronized examination).</p>



<p>You will have farms next to your house, growing organic food that you can eat fresh. Epidemics will be much rarer and more easily controlled, as population will be less concentrated and will travel less.</p>



<p>Fantasy? Actually, many of these things are already happening!</p>



<p/></div>
    </content>
    <updated>2020-02-18T20:38:26Z</updated>
    <published>2020-02-18T20:38:26Z</published>
    <category term="Uncategorized"/>
    <category term="Utopia"/>
    <author>
      <name>Manu</name>
    </author>
    <source>
      <id>https://emanueleviola.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://emanueleviola.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://emanueleviola.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://emanueleviola.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://emanueleviola.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>by Manu</subtitle>
      <title>Thoughts</title>
      <updated>2020-02-29T11:21:24Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4616</id>
    <link href="https://www.scottaaronson.com/blog/?p=4616" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4616#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4616" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">My video interview with Lex Fridman at MIT about philosophy and quantum computing</title>
    <summary xml:lang="en-US">Here it is (about 90 minutes; I recommend the 1.5x speed) I had buried this as an addendum to my previous post on the quantum supremacy lecture tour, but then decided that a steely-eyed assessment of what’s likely to have more or less interest for this blog’s readers probably militated in favor of a separate […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="https://www.youtube.com/watch?v=uX5t8EivCaM">Here it is</a> (about 90 minutes; I recommend the 1.5x speed)</p>



<p>I had buried this as an addendum to my previous post on the quantum supremacy lecture tour, but then decided that a steely-eyed assessment of what’s likely to have more or less interest for this blog’s readers probably militated in favor of a separate post.</p>



<p>Thanks so much to Lex for arranging the interview and for his questions!</p></div>
    </content>
    <updated>2020-02-18T05:36:06Z</updated>
    <published>2020-02-18T05:36:06Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Adventures in Meatspace"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Announcements"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Metaphysical Spouting"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Quantum"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2020-02-20T17:56:04Z</updated>
    </source>
  </entry>
</feed>
