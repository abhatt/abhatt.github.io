<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2019-10-07T02:01:11Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1910.02063</id>
    <link href="http://arxiv.org/abs/1910.02063" rel="alternate" type="text/html"/>
    <title>Fully Dynamic $(\Delta+1)$-Coloring in Constant Update Time</title>
    <feedworld_mtime>1570406400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bhattacharya:Sayan.html">Sayan Bhattacharya</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Grandoni:Fabrizio.html">Fabrizio Grandoni</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kulkarni:Janardhan.html">Janardhan Kulkarni</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liu:Quanquan_C=.html">Quanquan C. Liu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Solomon:Shay.html">Shay Solomon</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1910.02063">PDF</a><br/><b>Abstract: </b>The problem of (vertex) $(\Delta+1)$-coloring a graph of maximum degree
$\Delta$ has been extremely well-studied over the years in various settings and
models. Surprisingly, for the dynamic setting, almost nothing was known until
recently. In SODA'18, Bhattacharya, Chakrabarty, Henzinger and Nanongkai
devised a randomized data structure for maintaining a $(\Delta+1)$-coloring
with $O(\log \Delta)$ expected amortized update time. In this paper, we present
a $(\Delta+1)$-coloring data structure that achieves a constant amortized
update time and show that this time bound holds not only in expectation but
also with high probability.
</p></div>
    </summary>
    <updated>2019-10-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-10-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1910.02057</id>
    <link href="http://arxiv.org/abs/1910.02057" rel="alternate" type="text/html"/>
    <title>C-Planarity Testing of Embedded Clustered Graphs with Bounded Dual Carving-Width</title>
    <feedworld_mtime>1570406400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lozzo:Giordano_Da.html">Giordano Da Lozzo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Eppstein:David.html">David Eppstein</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Goodrich:Michael_T=.html">Michael T. Goodrich</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gupta:Siddharth.html">Siddharth Gupta</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1910.02057">PDF</a><br/><b>Abstract: </b>For a clustered graph, i.e, a graph whose vertex set is recursively
partitioned into clusters, the C-Planarity Testing problem asks whether it is
possible to find a planar embedding of the graph and a representation of each
cluster as a region homeomorphic to a closed disk such that 1. the subgraph
induced by each cluster is drawn in the interior of the corresponding disk, 2.
each edge intersects any disk at most once, and 3. the nesting between clusters
is reflected by the representation, i.e., child clusters are properly contained
in their parent cluster. The computational complexity of this problem, whose
study has been central to the theory of graph visualization since its
introduction in 1995 [Qing-Wen Feng, Robert F. Cohen, and Peter Eades.
Planarity for clustered graphs. ESA'95], has only been recently settled
[Radoslav Fulek and Csaba D. T\'oth. Atomic Embeddability, Clustered Planarity,
and Thickenability. To appear at SODA'20]. Before such a breakthrough, the
complexity question was still unsolved even when the graph has a prescribed
planar embedding, i.e, for embedded clustered graphs.
</p>
<p>We show that the C-Planarity Testing problem admits a single-exponential
single-parameter FPT algorithm for embedded clustered graphs, when
parameterized by the carving-width of the dual graph of the input. This is the
first FPT algorithm for this long-standing open problem with respect to a
single notable graph-width parameter. Moreover, in the general case, the
polynomial dependency of our FPT algorithm is smaller than the one of the
algorithm by Fulek and T\'oth. To further strengthen the relevance of this
result, we show that the C-Planarity Testing problem retains its computational
complexity when parameterized by several other graph-width parameters, which
may potentially lead to faster algorithms.
</p></div>
    </summary>
    <updated>2019-10-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-10-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1910.02048</id>
    <link href="http://arxiv.org/abs/1910.02048" rel="alternate" type="text/html"/>
    <title>A Dichotomy for Homomorphism-Closed Queries on Probabilistic Graphs</title>
    <feedworld_mtime>1570406400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Amarilli:Antoine.html">Antoine Amarilli</a>, İsmail İlkan Ceylan <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1910.02048">PDF</a><br/><b>Abstract: </b>We study the problem of probabilistic query evaluation (PQE) over
probabilistic graphs, namely, tuple-independent probabilistic databases (TIDs)
on signatures of arity two. Our focus is the class of queries that is closed
under homomorphisms, or equivalently, the infinite unions of conjunctive
queries, denoted UCQ^\infty . Our main result states that all unbounded queries
in UCQ^\infty are #P-hard for PQE. As bounded queries in UCQ^\infty are already
classified by the dichotomy of Dalvi and Suciu [16], our results and theirs
imply a complete dichotomy on PQE for UCQ^\infty queries over arity-two
signatures. This dichotomy covers in particular all fragments in UCQ^\infty
such as negation-free (disjunctive) Datalog, regular path queries, and a large
class of ontology-mediated queries on arity-two signatures. Our result is shown
by reducing from counting the valuations of positive partitioned 2-DNF formulae
(#PP2DNF) for some queries, or from the source-to-target reliability problem in
an undirected graph (#U-ST-CON) for other queries, depending on properties of
minimal models.
</p></div>
    </summary>
    <updated>2019-10-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-10-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1910.01957</id>
    <link href="http://arxiv.org/abs/1910.01957" rel="alternate" type="text/html"/>
    <title>A Polyhedral Homotopy Algorithm For Real Zeros</title>
    <feedworld_mtime>1570406400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Erg=uuml=r:Alperen_A=.html">Alperen A. Ergür</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wolff:Timo_de.html">Timo de Wolff</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1910.01957">PDF</a><br/><b>Abstract: </b>We design a homotopy continuation algorithm for finding real zeros of sparse
polynomial systems. Our algorithm builds on a well-known geometric deformation
process, namely Viro's patchworking method. The algorithm operates entirely
over the real numbers and tracks the optimal number of solution paths. In
exchange, the algorithm is not universally applicable: It works for polynomial
system with coefficients satisfying certain concavity conditions. More
precisely, it requires the given polynomial system to be located in the
unbounded components of the complement of the underlying $A$-discriminant
amoeba. A preliminary implementation of an example from the literature suggests
practical performance of the algorithm. We plan to work towards a vigorous
implementation including a larger scale of examples and a software paper.
</p></div>
    </summary>
    <updated>2019-10-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-10-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1910.01935</id>
    <link href="http://arxiv.org/abs/1910.01935" rel="alternate" type="text/html"/>
    <title>Synchronization under Dynamic Constraints</title>
    <feedworld_mtime>1570406400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wolf:Petra.html">Petra Wolf</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1910.01935">PDF</a><br/><b>Abstract: </b>Imagine an assembly line where a box with a lid and liquid in it enters in
some unknown orientation. The box should leave the line with the open lid
facing upwards with the liquid still in it. To save costs there are no complex
sensors or image recognition software available on the assembly line, so a
reset sequence needs to be computed. But how can the dependencies of the
deforming impact of a transformation of the box, such as 'do not tilt the box
over when the lid is open' or 'open the lid again each time it gets closed' be
modeled? We present three attempts to model constraints of these kinds on the
order in which the states of an automaton are transitioned by a synchronizing
word. The first two concepts relate the last visits of states and form
constraints on which states still need to be reached, whereas the third concept
concerns the first visits of states and forms constraints on which states might
still be reached. We examine the computational complexity of different variants
of the problem, whether an automaton can be synchronized with a word that
respects the constraints defined in the respective concept, and obtain nearly a
full classification. While most of the problems are PSPACE-complete we also
observe NP-complete variants and variants solvable in polynomial time. We will
also observe a drop of the complexity if we track the orders of states on
several paths simultaneously instead of tracking the set of active states.
Further, we give upper bounds on the length of a synchronizing word depending
on the size of the input relation and show that the Cerny conjecture holds for
partial weakly acyclic automata.
</p></div>
    </summary>
    <updated>2019-10-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-10-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1910.01934</id>
    <link href="http://arxiv.org/abs/1910.01934" rel="alternate" type="text/html"/>
    <title>FPT Inapproximability of Directed Cut and Connectivity Problems</title>
    <feedworld_mtime>1570406400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chitnis:Rajesh.html">Rajesh Chitnis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Feldmann:Andreas_Emil.html">Andreas Emil Feldmann</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1910.01934">PDF</a><br/><b>Abstract: </b>(see paper for full abstract)
</p>
<p>Cut problems and connectivity problems on digraphs are two well-studied
classes of problems from the viewpoint of parameterized complexity. After a
series of papers over the last decade, we now have (almost) tight bounds for
the running time of several standard variants of these problems parameterized
by two parameters: the number $k$ of terminals and the size $p$ of the
solution. When there is evidence of FPT intractability, then the next natural
alternative is to consider FPT approximations. In this paper, we show two types
of results for several directed cut and connectivity problems, building on
existing results from the literature: first is to circumvent the hardness
results for these problems by designing FPT approximation algorithms, or
alternatively strengthen the existing hardness results by creating
"gap-instances" under stronger hypotheses such as the (Gap-)Exponential Time
Hypothesis (ETH).
</p></div>
    </summary>
    <updated>2019-10-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-10-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1910.01788</id>
    <link href="http://arxiv.org/abs/1910.01788" rel="alternate" type="text/html"/>
    <title>Efficient Symmetric Norm Regression via Linear Sketching</title>
    <feedworld_mtime>1570406400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Song:Zhao.html">Zhao Song</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Ruosong.html">Ruosong Wang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yang:Lin_F=.html">Lin F. Yang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhong:Peilin.html">Peilin Zhong</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Hongyang.html">Hongyang Zhang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1910.01788">PDF</a><br/><b>Abstract: </b>We provide efficient algorithms for overconstrained linear regression
problems with size $n \times d$ when the loss function is a symmetric norm (a
norm invariant under sign-flips and coordinate-permutations). An important
class of symmetric norms are Orlicz norms, where for a function $G$ and a
vector $y \in \mathbb{R}^n$, the corresponding Orlicz norm $\|y\|_G$ is defined
as the unique value $\alpha$ such that $\sum_{i=1}^n G(|y_i|/\alpha) = 1$. When
the loss function is an Orlicz norm, our algorithm produces a $(1 +
\varepsilon)$-approximate solution for an arbitrarily small constant
$\varepsilon &gt; 0$ in input-sparsity time, improving over the previously
best-known algorithm which produces a $d \cdot \mathrm{polylog} n$-approximate
solution. When the loss function is a general symmetric norm, our algorithm
produces a $\sqrt{d} \cdot \mathrm{polylog} n \cdot
\mathrm{mmc}(\ell)$-approximate solution in input-sparsity time, where
$\mathrm{mmc}(\ell)$ is a quantity related to the symmetric norm under
consideration. To the best of our knowledge, this is the first input-sparsity
time algorithm with provable guarantees for the general class of symmetric norm
regression problem. Our results shed light on resolving the universal sketching
problem for linear regression, and the techniques might be of independent
interest to numerical linear algebra problems more broadly.
</p></div>
    </summary>
    <updated>2019-10-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-10-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1910.01783</id>
    <link href="http://arxiv.org/abs/1910.01783" rel="alternate" type="text/html"/>
    <title>Width Parameterizations for Knot-free Vertex Deletion on Digraphs</title>
    <feedworld_mtime>1570406400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bessy:St=eacute=phane.html">Stéphane Bessy</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bougeret:Marin.html">Marin Bougeret</a>, Alan D. A. Carneiro, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Protti:F=aacute=bio.html">Fábio Protti</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Souza:U=eacute=verton_S=.html">Uéverton S. Souza</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1910.01783">PDF</a><br/><b>Abstract: </b>A knot in a directed graph $G$ is a strongly connected subgraph $Q$ of $G$
with at least two vertices, such that no vertex in $V(Q)$ is an in-neighbor of
a vertex in $V(G)\setminus V(Q)$. Knots are important graph structures, because
they characterize the existence of deadlocks in a classical distributed
computation model, the so-called OR-model. Deadlock detection is correlated
with the recognition of knot-free graphs as well as deadlock resolution is
closely related to the {\sc Knot-Free Vertex Deletion (KFVD)} problem, which
consists of determining whether an input graph $G$ has a subset $S \subseteq
V(G)$ of size at most $k$ such that $G[V\setminus S]$ contains no knot. In this
paper we focus on graph width measure parameterizations for {\sc KFVD}. First,
we show that: (i) {\sc KFVD} parameterized by the size of the solution $k$ is
W[1]-hard even when $p$, the length of a longest directed path of the input
graph, as well as $\kappa$, its Kenny-width, are bounded by constants, and we
remark that {\sc KFVD} is para-NP-hard even considering many directed width
measures as parameters, but in FPT when parameterized by clique-width; (ii)
{\sc KFVD} can be solved in time $2^{O(tw)}\times n$, but assuming ETH it
cannot be solved in $2^{o(tw)}\times n^{O(1)}$, where $tw$ is the treewidth of
the underlying undirected graph. Finally, since the size of a minimum directed
feedback vertex set ($dfv$) is an upper bound for the size of a minimum
knot-free vertex deletion set, we investigate parameterization by $dfv$ and we
show that (iii) {\sc KFVD} can be solved in FPT-time parameterized by either
$dfv+\kappa$ or $dfv+p$; and it admits a Turing kernel by the distance to a DAG
having an Hamiltonian path.
</p></div>
    </summary>
    <updated>2019-10-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-10-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1910.01753</id>
    <link href="http://arxiv.org/abs/1910.01753" rel="alternate" type="text/html"/>
    <title>On Computing a Center Persistence Diagram</title>
    <feedworld_mtime>1570406400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Higashikawa:Yuya.html">Yuya Higashikawa</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Katoh:Naoki.html">Naoki Katoh</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lin:Guohui.html">Guohui Lin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Miyano:Eiji.html">Eiji Miyano</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tamaki:Suguru.html">Suguru Tamaki</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Teruyama:Junichi.html">Junichi Teruyama</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhu:Binhai.html">Binhai Zhu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1910.01753">PDF</a><br/><b>Abstract: </b>Given a set of persistence diagrams ${\cal P}_1,...,{\cal P}_m$, for the data
reduction purpose, one way to summarize their topological features is to
compute the {\em center} ${\cal C}$ of them. Let $P_i$ be the set of feature
points in ${\cal P}_i$. Here we mainly focus on the two discrete versions when
points in ${\cal C}$ could be selected with or without replacement from
$P_i$'s. (We will briefly discuss the continuous case, i.e., points in ${\cal
C}$ are arbitrary, which turns out to be closely related to the 3-dimensional
geometric assignment problem). For technical reasons, we first focus on the
case when $|P_i|$'s are all the same (i.e., all have the same size $n$), and
the problem is to compute a center point set $C$ under the bottleneck matching
distance. We show, by a non-trivial reduction from the Planar 3D-Matching
problem, that this problem is NP-hard even when $m=3$. This implies that the
general center problem for persistence diagrams, when $P_i$'s possibly have
different sizes, is also NP-hard when $m\geq 3$. On the positive side, we show
that this problem is polynomially solvable when $m=2$ and admits a factor-2
approximation for $m\geq 3$. These positive results hold for any $L_p$ metric
when $P_i$'s are point sets of the same size, and also hold for the case when
$P_i$'s have different sizes in the $L_\infty$ metric (i.e., for the center
persistence diagram problem). This is the best possible in polynomial time
unless P = NP. All these results hold for both of the discrete versions.
</p></div>
    </summary>
    <updated>2019-10-07T01:55:45Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-10-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1910.01749</id>
    <link href="http://arxiv.org/abs/1910.01749" rel="alternate" type="text/html"/>
    <title>Finding monotone patterns in sublinear time</title>
    <feedworld_mtime>1570406400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Ben=Eliezer:Omri.html">Omri Ben-Eliezer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Canonne:Cl=eacute=ment_L=.html">Clément L. Canonne</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Letzter:Shoham.html">Shoham Letzter</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Waingarten:Erik.html">Erik Waingarten</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1910.01749">PDF</a><br/><b>Abstract: </b>We study the problem of finding monotone subsequences in an array from the
viewpoint of sublinear algorithms. For fixed $k \in \mathbb{N}$ and
$\varepsilon &gt; 0$, we show that the non-adaptive query complexity of finding a
length-$k$ monotone subsequence of $f \colon [n] \to \mathbb{R}$, assuming that
$f$ is $\varepsilon$-far from free of such subsequences, is $\Theta((\log
n)^{\lfloor \log_2 k \rfloor})$. Prior to our work, the best algorithm for this
problem, due to Newman, Rabinovich, Rajendraprasad, and Sohler (2017), made
$(\log n)^{O(k^2)}$ non-adaptive queries; and the only lower bound known, of
$\Omega(\log n)$ queries for the case $k = 2$, followed from that on testing
monotonicity due to Erg\"un, Kannan, Kumar, Rubinfeld, and Viswanathan (2000)
and Fischer (2004).
</p></div>
    </summary>
    <updated>2019-10-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-10-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/138</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/138" rel="alternate" type="text/html"/>
    <title>TR19-138 |  On the Probabilistic Degrees of Symmetric Boolean functions | 

	Srikanth Srinivasan, 

	Utkarsh Tripathi, 

	S Venkitesh</title>
    <summary>The probabilistic degree of a Boolean function $f:\{0,1\}^n\rightarrow \{0,1\}$ is defined to be the smallest $d$ such that there is a random polynomial $\mathbf{P}$ of degree at most $d$ that agrees with $f$ at each point with high probability. Introduced by Razborov (1987), upper and lower bounds on probabilistic degrees of Boolean functions --- specifically symmetric Boolean functions --- have been used to prove explicit lower bounds, design pseudorandom generators, and devise algorithms for combinatorial problems. 
		
In this paper, we characterize the probabilistic degrees of all symmetric Boolean functions up to polylogarithmic factors over all fields of fixed characteristic (positive or zero).</summary>
    <updated>2019-10-06T15:42:51Z</updated>
    <published>2019-10-06T15:42:51Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-10-07T01:59:48Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/137</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/137" rel="alternate" type="text/html"/>
    <title>TR19-137 |  Decision list compression by mild random restrictions | 

	Shachar Lovett, 

	Kewen Wu, 

	Jiapeng Zhang</title>
    <summary>A decision list is an ordered list of rules. Each rule is specified by a term, which is a conjunction of literals, and a value. Given an input, the output of a decision list is the value corresponding to the first rule whole term is satisfied by the input. Decision lists generalize both CNFs and DNFs, and have been studied both in complexity theory and in learning theory.

The size of a decision list is the number of rules, and its width is the maximal number of variables in a term. We prove that decision lists of small width can always be approximated by decision lists of small size, where we obtain sharp bounds (up to constants). This in particular resolves a conjecture of Gopalan, Meka and Reingold (Computational Complexity, 2013) on DNF sparsification.

An ingredient in our proof is a new random restriction lemma, which allows to analyze how DNFs (and more generally, decision lists) simplify if a small fraction of the variables are fixed. This is in contrast to the more commonly used switching lemma, which requires most of the variables to be fixed.</summary>
    <updated>2019-10-06T11:20:34Z</updated>
    <published>2019-10-06T11:20:34Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-10-07T01:59:48Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/136</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/136" rel="alternate" type="text/html"/>
    <title>TR19-136 |  Quantum Query-to-Communication Simulation Needs a Logarithmic Overhead | 

	Sourav Chakraborty, 

	Arkadev Chattopadhyay, 

	Nikhil Mande, 

	Manaswi Paraashar</title>
    <summary>Buhrman, Cleve and Wigderson (STOC'98) observed that for every Boolean function $f : \{-1, 1\}^n \to \{-1, 1\}$ and $\bullet : \{-1, 1\}^2 \to \{-1, 1\}$ the two-party bounded-error quantum communication complexity of $(f \circ \bullet)$ is $O(Q(f) \log n)$, where $Q(f)$ is the bounded-error quantum query complexity of $f$. Note that the bounded-error randomized communication complexity of $(f \circ \bullet)$ is bounded by $O(R(f))$, where $R(f)$ denotes the bounded-error randomized query complexity of $f$. Thus, the BCW simulation has an extra $O(\log n)$ factor appearing that is absent in classical simulation. A natural question is if this factor can be avoided. H{\o}yer and de Wolf (STACS'02) showed that for the Set-Disjointness function, this can be reduced to $c^{\log^* n}$ for some constant $c$, and subsequently Aaronson and Ambainis (FOCS'03) showed that this factor can be made a constant. That is, the quantum communication complexity of the Set-Disjointness function (which is $NOR_n \circ \wedge$) is $O(Q(NOR_n))$.

Perhaps somewhat surprisingly, we show that when $ \bullet = \oplus$, then the extra $\log n$ factor in the BCW simulation is unavoidable. In other words, we exhibit a total function $F : \{-1, 1\}^n \to \{-1, 1\}$ such that $Q^{cc}(F \circ \oplus) = \Theta(Q(F) \log n)$.

To the best of our knowledge, it was not even known prior to this work whether there existed a total function $F$ and 2-bit function $\bullet$, such that $Q^{cc}(F \circ \bullet) = \omega(Q(F))$.</summary>
    <updated>2019-10-06T09:03:52Z</updated>
    <published>2019-10-06T09:03:52Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-10-07T01:59:48Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1910.01565</id>
    <link href="http://arxiv.org/abs/1910.01565" rel="alternate" type="text/html"/>
    <title>On partisan bias in redistricting: computational complexity meets the science of gerrymandering</title>
    <feedworld_mtime>1570320000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chatterjee:Tanima.html">Tanima Chatterjee</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/DasGupta:Bhaskar.html">Bhaskar DasGupta</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1910.01565">PDF</a><br/><b>Abstract: </b>The topic of this paper is "gerrymandering", namely the curse of deliberate
creations of district maps with highly asymmetric electoral outcomes to
disenfranchise voters, and it has a long legal history. Measuring and
eliminating gerrymandering has enormous implications to sustain the backbone of
democratic principles of a society. Although there is no dearth of legal briefs
involving gerrymandering over many years, it is only more recently that
mathematicians and applied computational researchers have started to
investigate this topic. However, it has received relatively little attention so
far from the computational complexity researchers dealing with theoretical
analysis of computational complexity issues, such as computational hardness,
approximability issues, etc. There could be many reasons for this, such as
descriptions of these problem non-CS non-math (often legal or political)
journals that theoretical CS (TCS) people usually do not follow, or the lack of
coverage of these topics in TCS publication venues. One of our modest goals in
writing this article is to improve upon this situation by stimulating further
interactions between the gerrymandering and TCS researchers. To this effect,
our main contributions are twofold: (1) we provide formalization of several
models, related concepts, and corresponding problem statements using TCS
frameworks from the descriptions of these problems as available in existing
non-TCS (perhaps legal) venues, and (2) we also provide computational
complexity analysis of some versions of these problems, leaving other versions
for future research.
</p>
<p>The goal of writing this article is not to have the final word on
gerrymandering, but to introduce a series of concepts, models and problems to
the TCS community and to show that science of gerrymandering involves an
intriguing set of partitioning problems involving geometric and combinatorial
optimization.
</p></div>
    </summary>
    <updated>2019-10-06T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-10-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1910.01552</id>
    <link href="http://arxiv.org/abs/1910.01552" rel="alternate" type="text/html"/>
    <title>Extensions of the Algorithmic Lovasz Local Lemma</title>
    <feedworld_mtime>1570320000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kolmogorov:Vladimir.html">Vladimir Kolmogorov</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1910.01552">PDF</a><br/><b>Abstract: </b>We consider recent formulations of the algorithmic Lovasz Local Lemma by
Achlioptas-Iliopoulos-Kolmogorov [2] and by Achlioptas-Iliopoulos-Sinclair [3].
These papers analyze a random walk algorithm for finding objects that avoid
undesired "bad events" (or "flaws"), and prove that under certain conditions
the algorithm is guaranteed to find a "flawless" object quickly. We show that
conditions proposed in these papers are incomparable, and introduce a new
family of conditions that includes those in [2, 3] as special cases.
</p>
<p>Secondly, we extend our previous notion of "commutativity" in [15] to this
more general setting, and prove that it allows to use an arbitrary strategy for
selecting the next flaw to address. In the special case of primary flaws we
prove a stronger property: the flaw selection strategy does not affect at all
the expected number of steps until termination, and also does not affect the
distribution induced by the algorithm upon termination. This applies, in
particular, to the single-clause backtracking algorithm for constraint
satisfaction problems considered in [3].
</p></div>
    </summary>
    <updated>2019-10-06T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-10-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1910.01492</id>
    <link href="http://arxiv.org/abs/1910.01492" rel="alternate" type="text/html"/>
    <title>A Grid-based Approach for Convexity Analysis of a Density-based Cluster</title>
    <feedworld_mtime>1570320000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Naghavi=Nozad:Sayyed=Ahmad.html">Sayyed-Ahmad Naghavi-Nozad</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Banaei:Seyed=Mojtaba.html">Seyed-Mojtaba Banaei</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Saberi:Mohsen.html">Mohsen Saberi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1910.01492">PDF</a><br/><b>Abstract: </b>This paper presents a novel geometrical approach to investigate the convexity
of a density-based cluster. Our approach is grid-based and we are about to
calibrate the value space of the cluster. However, the cluster objects are
coming from an infinite distribution, their number is finite, and thus, the
regarding shape will not be sharp. Therefore, we establish the precision of the
grid properly in a way that, the reliable approximate boundaries of the cluster
are founded. After that, regarding the simple notion of convex sets and
midpoint convexity, we investigate whether or not the density-based cluster is
convex. Moreover, our experiments on synthetic datasets demonstrate the
desirable performance of our method.
</p></div>
    </summary>
    <updated>2019-10-06T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-10-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1910.01357</id>
    <link href="http://arxiv.org/abs/1910.01357" rel="alternate" type="text/html"/>
    <title>Recognizing the Tractability in Big Data Computing</title>
    <feedworld_mtime>1570320000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gao:Xiangyu.html">Xiangyu Gao</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Jianzhong.html">Jianzhong Li</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Miao:Dongjing.html">Dongjing Miao</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liu:Xianmin.html">Xianmin Liu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1910.01357">PDF</a><br/><b>Abstract: </b>Due to the limitation on computational power of existing computers, the
polynomial time does not works for identifying the tractable problems in big
data computing. This paper adopts the sublinear time as the new tractable
standard to recognize the tractability in big data computing, and the
random-access Turing machine is used as the computational model to characterize
the problems that are tractable on big data. First, two pure-tractable classes
are first proposed. One is the class $\mathrm{PL}$ consisting of the problems
that can be solved in polylogarithmic time by a RATM. The another one is the
class $\mathrm{ST}$ including all the problems that can be solved in sublinear
time by a RATM. The structure of the two pure-tractable classes is deeply
investigated and they are proved $\mathrm{PL^i} \subsetneq \mathrm{PL^{i+1}}$
and $\mathrm{PL} \subsetneq \mathrm{ST}$. Then, two pseudo-tractable classes,
$\mathrm{PTR}$ and $\mathrm{PTE}$, are proposed. $\mathrm{PTR}$ consists of all
the problems that can solved by a RATM in sublinear time after a PTIME
preprocessing by reducing the size of input dataset. $\mathrm{PTE}$ includes
all the problems that can solved by a RATM in sublinear time after a PTIME
preprocessing by extending the size of input dataset. The relations among the
two pseudo-tractable classes and other complexity classes are investigated and
they are proved that $\mathrm{PT} \subseteq \mathrm{P}$, $\sqcap'\mathrm{T^0_Q}
\subsetneq \mathrm{PTR^0_Q}$ and $\mathrm{PT_P} = \mathrm{P}$.
</p></div>
    </summary>
    <updated>2019-10-06T23:26:32Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-10-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1910.01331</id>
    <link href="http://arxiv.org/abs/1910.01331" rel="alternate" type="text/html"/>
    <title>Optimal Joint Subcarrier and Power Allocation in NOMA is Strongly NP-Hard</title>
    <feedworld_mtime>1570320000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Salaun:Lou.html">Lou Salaun</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Chung_Shue.html">Chung Shue Chen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Coupechoux:Marceau.html">Marceau Coupechoux</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1910.01331">PDF</a><br/><b>Abstract: </b>Non-orthogonal multiple access (NOMA) is a promising radio access technology
for 5G. It allows several users to transmit on the same frequency and time
resource by performing power-domain multiplexing. At the receiver side,
successive interference cancellation (SIC) is applied to mitigate interference
among the multiplexed signals. In this way, NOMA can outperform orthogonal
multiple access schemes used in conventional cellular networks in terms of
spectral efficiency and allows more simultaneous users. This paper investigates
the computational complexity of joint subcarrier and power allocation problems
in multi-carrier NOMA systems. We prove that these problems are strongly
NP-hard for a large class of objective functions, namely the weighted
generalized means of the individual data rates. This class covers the popular
weighted sum-rate, proportional fairness, harmonic mean and max-min fairness
utilities. Our results show that the optimal power and subcarrier allocation
cannot be computed in polynomial time in the general case, unless P = NP.
Nevertheless, we present some tractable special cases and we show that they can
be solved efficiently.
</p></div>
    </summary>
    <updated>2019-10-06T23:20:31Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-10-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1910.01327</id>
    <link href="http://arxiv.org/abs/1910.01327" rel="alternate" type="text/html"/>
    <title>Privately detecting changes in unknown distributions</title>
    <feedworld_mtime>1570320000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cummings:Rachel.html">Rachel Cummings</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Krehbiel:Sara.html">Sara Krehbiel</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lut:Yuliia.html">Yuliia Lut</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Wanrong.html">Wanrong Zhang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1910.01327">PDF</a><br/><b>Abstract: </b>The change-point detection problem seeks to identify distributional changes
in streams of data. Increasingly, tools for change-point detection are applied
in settings where data may be highly sensitive and formal privacy guarantees
are required, such as identifying disease outbreaks based on hospital records,
or IoT devices detecting activity within a home. Differential privacy has
emerged as a powerful technique for enabling data analysis while preventing
information leakage about individuals. Much of the prior work on change-point
detection (including the only private algorithms for this problem) requires
complete knowledge of the pre-change and post-change distributions. However,
this assumption is not realistic for many practical applications of interest.
This work develops differentially private algorithms for solving the
change-point problem when the data distributions are unknown. Additionally, the
data may be sampled from distributions that change smoothly over time, rather
than fixed pre-change and post-change distributions. We apply our algorithms to
detect changes in the linear trends of such data streams.
</p></div>
    </summary>
    <updated>2019-10-06T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-10-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1910.01317</id>
    <link href="http://arxiv.org/abs/1910.01317" rel="alternate" type="text/html"/>
    <title>Orbit Computation for Atomically Generated Subgroups of Isometries of $\mathbb{Z}^n$</title>
    <feedworld_mtime>1570320000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yu:Haizi.html">Haizi Yu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mineyev:Igor.html">Igor Mineyev</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Varshney:Lav_R=.html">Lav R. Varshney</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1910.01317">PDF</a><br/><b>Abstract: </b>Isometries and their induced symmetries are ubiquitous in the world. Taking a
computational perspective, this paper considers isometries of $\mathbb{Z}^n$
(since values are discrete in digital computers), and tackles the problem of
orbit computation under various isometry subgroup actions on $\mathbb{Z}^n$.
Rather than just conceptually, we aim for a practical algorithm that can
partition any finite subset of $\mathbb{Z}^n$ based on the orbit relation. In
this paper, instead of all subgroups of isometries, we focus on a special class
of subgroups, namely atomically generated subgroups. This newly introduced
notion is key to inheriting the semidirect-product structure from the whole
group of isometries, and in turn, the semidirect-product structure is key to
our proposed algorithm for efficient orbit computation.
</p></div>
    </summary>
    <updated>2019-10-06T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-10-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1910.01296</id>
    <link href="http://arxiv.org/abs/1910.01296" rel="alternate" type="text/html"/>
    <title>Best-first Search Algorithm for Non-convex Sparse Minimization</title>
    <feedworld_mtime>1570320000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sakaue:Shinsaku.html">Shinsaku Sakaue</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Marumo:Naoki.html">Naoki Marumo</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1910.01296">PDF</a><br/><b>Abstract: </b>Non-convex sparse minimization (NSM), or $\ell_0$-constrained minimization of
convex loss functions, is an important optimization problem that has many
machine learning applications. NSM is generally NP-hard, and so to exactly
solve NSM is almost impossible in polynomial time. As regards the case of
quadratic objective functions, exact algorithms based on quadratic
mixed-integer programming (MIP) have been studied, but no existing exact
methods can handle more general objective functions including Huber and
logistic losses; this is unfortunate since those functions are prevalent in
practice. In this paper, we consider NSM with $\ell_2$-regularized convex
objective functions and develop an algorithm by leveraging the efficiency of
best-first search (BFS). Our BFS can compute solutions with objective errors at
most $\Delta\ge0$, where $\Delta$ is a controllable hyper-parameter that
balances the trade-off between the guarantee of objective errors and
computation cost. Experiments demonstrate that our BFS is useful for solving
moderate-size NSM instances with non-quadratic objectives and that BFS is also
faster than the MIP-based method when applied to quadratic objectives.
</p></div>
    </summary>
    <updated>2019-10-06T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-10-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1910.01293</id>
    <link href="http://arxiv.org/abs/1910.01293" rel="alternate" type="text/html"/>
    <title>A Fast Exponential Time Algorithm for Max Hamming Distance X3SAT</title>
    <feedworld_mtime>1570320000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hoi:Gordon.html">Gordon Hoi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jain:Sanjay.html">Sanjay Jain</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Stephan:Frank.html">Frank Stephan</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1910.01293">PDF</a><br/><b>Abstract: </b>X3SAT is the problem of whether one can satisfy a given set of clauses with
up to three literals such that in every clause, exactly one literal is true and
the others are false. A related question is to determine the maximal Hamming
distance between two solutions of the instance. Dahll\"of provided an algorithm
for Maximum Hamming Distance XSAT, which is more complicated than the same
problem for X3SAT, with a runtime of $O(1.8348^n)$; Fu, Zhou and Yin considered
Maximum Hamming Distance for X3SAT and found for this problem an algorithm with
runtime $O(1.6760^n)$. In this paper, we propose an algorithm in $O(1.3298^n)$
time to solve the Max Hamming Distance X3SAT problem; the algorithm actually
counts for each $k$ the number of pairs of solutions which have Hamming
Distance $k$.
</p></div>
    </summary>
    <updated>2019-10-06T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-10-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1910.01251</id>
    <link href="http://arxiv.org/abs/1910.01251" rel="alternate" type="text/html"/>
    <title>Search problems in algebraic complexity, GCT, and hardness of generator for invariant rings</title>
    <feedworld_mtime>1570320000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Garg:Ankit.html">Ankit Garg</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Makam:Visu.html">Visu Makam</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Oliveira:Rafael.html">Rafael Oliveira</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wigderson:Avi.html">Avi Wigderson</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1910.01251">PDF</a><br/><b>Abstract: </b>We consider the problem of outputting succinct encodings of lists of
generators for invariant rings. Mulmuley conjectured that there are always
polynomial sized such encodings for all invariant rings. We provide simple
examples that disprove this conjecture (under standard complexity assumptions).
</p></div>
    </summary>
    <updated>2019-10-06T23:21:51Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-10-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1910.01147</id>
    <link href="http://arxiv.org/abs/1910.01147" rel="alternate" type="text/html"/>
    <title>Path and Ancestor Queries on Trees with Multidimensional Weight Vectors</title>
    <feedworld_mtime>1570320000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/He:Meng.html">Meng He</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kazi:Serikzhan.html">Serikzhan Kazi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1910.01147">PDF</a><br/><b>Abstract: </b>We consider an ordinal tree $T$ on $n$ nodes, with each node assigned a
</p>
<p>$d$-dimensional weight vector $\pnt{w} \in \{1,2,\ldots,n\}^d,$ where $d \in
\mathbb{N}$ is a constant.
</p>
<p>We study path queries as generalizations of well-known {\textit{orthogonal
range queries}}, with one of the dimensions being tree topology rather than a
linear order. Since in our definitions $d$ only represents the number of
dimensions of the weight vector without taking the tree topology into account,
a path query in a tree with $d$-dimensional weight vectors generalize the
corresponding $(d+1)$-dimensional orthogonal range query.
</p>
<p>We solve {\textit{ancestor dominance reporting}} problem as a direct
generalization of dominance reporting problem, %in time $\O((\lg^{d-1}
n)/(\lg\lg n)^{d-2}+k)$ in time $\O(\lg^{d-1}{n}+k)$ %and space of $\O(n(\lg
n)^{d-1}/(\lg \lg n)^{d-2})$ words, and space of $\O(n\lg^{d-2}n)$ words, where
$k$ is the size of the output, for $d \geq 2.$
</p>
<p>We also achieve a tradeoff of $\O(n\lg^{d-2+\eps}{n})$ words of space, with
query time of $\O((\lg^{d-1} n)/(\lg\lg n)^{d-2}+k),$ for the same problem,
when $d \geq 3.$
</p>
<p>We solve {\textit{path successor problem}} in $\O(n\lg^{d-1}{n})$ words of
space and time $\O(\lg^{d-1+\eps}{n})$ for $d \geq 1$ and an arbitrary constant
$\eps &gt; 0.$ We propose a solution to {\textit{path counting problem}}, with
$\O(n(\lg{n}/\lg\lg{n})^{d-1})$ words of space and $\O((\lg{n}/\lg\lg{n})^{d})$
query time, for $d \geq 1.$
</p>
<p>Finally, we solve {\textit{path reporting problem}} in
$\O(n\lg^{d-1+\eps}{n})$ words of space and
$\O((\lg^{d-1}{n})/(\lg\lg{n})^{d-2}+k)$ query time, for $d \geq 2.$
</p>
<p>These results match or nearly match the best tradeoffs of the respective
range queries. We are also the first to solve path successor even for $d = 1$.
</p></div>
    </summary>
    <updated>2019-10-06T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-10-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/10/05/future-faculty-fellow-postdoc-at-university-of-illinois-urbana-champaign-apply-by-february-1-2020/</id>
    <link href="https://cstheory-jobs.org/2019/10/05/future-faculty-fellow-postdoc-at-university-of-illinois-urbana-champaign-apply-by-february-1-2020/" rel="alternate" type="text/html"/>
    <title>Future Faculty Fellow/Postdoc at University of Illinois, Urbana-Champaign (apply by February 1, 2020)</title>
    <summary>The Department of Computer Science (CS) at the University of Illinois at Urbana-Champaign invites applications for the “Future Faculty” program. The Future Faculty Program is a selective program offering two-year postdoctoral positions whose goal is to mentor and prepare outstanding candidates for an academic career in research and teaching. Contact a theory faculty member if […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Department of Computer Science (CS) at the University of Illinois at Urbana-Champaign invites applications for the “Future Faculty” program. The Future Faculty Program is a selective program offering two-year postdoctoral positions whose goal is to mentor and prepare outstanding candidates for an academic career in research and teaching. Contact a theory faculty member if interested.</p>
<p>Website: <a href="https://cs.illinois.edu/about-us/staff-positions#futurefaculty">https://cs.illinois.edu/about-us/staff-positions#futurefaculty</a><br/>
Email: chekuri@illinois.edu</p></div>
    </content>
    <updated>2019-10-05T21:36:12Z</updated>
    <published>2019-10-05T21:36:12Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-10-07T02:00:01Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/10/05/multiple-faculty-positions-at-university-of-illinois-urbana-champaign-apply-by-december-1-2019/</id>
    <link href="https://cstheory-jobs.org/2019/10/05/multiple-faculty-positions-at-university-of-illinois-urbana-champaign-apply-by-december-1-2019/" rel="alternate" type="text/html"/>
    <title>Multiple Faculty Positions at University of Illinois, Urbana-Champaign (apply by December 1, 2019)</title>
    <summary>The Department of Computer Science has multiple tenure track at all levels. Quantum Computing and Theory are among the priority areas. Website: https://cs.illinois.edu/about-us/faculty-positions Email: HR@cs.illinois.edu</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Department of Computer Science has multiple tenure track at all levels. Quantum Computing and Theory are among the priority areas.</p>
<p>Website: <a href="https://cs.illinois.edu/about-us/faculty-positions">https://cs.illinois.edu/about-us/faculty-positions</a><br/>
Email: HR@cs.illinois.edu</p></div>
    </content>
    <updated>2019-10-05T21:23:38Z</updated>
    <published>2019-10-05T21:23:38Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-10-07T02:00:01Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://agtb.wordpress.com/?p=3427</id>
    <link href="https://agtb.wordpress.com/2019/10/05/blind-folks-and-the-evolving-elephant-by-vijay-vazirani/" rel="alternate" type="text/html"/>
    <title>Blind Folks and the Evolving Elephant – by Vijay Vazirani</title>
    <summary>One of my favorite parables ever since childhood was that of the four blind men and the elephant, with each man announcing the local image evoked in his mind’s eye on touching a different part of the elephant. This parable has provided an interesting metaphor even for serious scientific matters, a well-known one being wave-particle […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>One of my favorite parables ever since childhood was that of the four blind men and the elephant, with each man announcing the local image evoked in his mind’s eye on touching a different part of the elephant. This parable has provided an interesting metaphor even for serious scientific matters, a well-known one being wave-particle duality in physics.</p>
<p>But when it comes to matching markets, the parable has taken an unusual twist, with the proverbial elephant undergoing a metamorphosis of its own! The “blind men’’ in this case are entire disciplines which can lay claim to the field of matching markets. Of course, the obvious one is economics – the founders of this field, namely Gale and Shapley, were mathematical economists and <a href="https://www.nobelprize.org/prizes/economic-sciences/2012/summary/">the 2012 Nobel Prize in Economics</a> was awarded to Alvin Roth and Lloyd Shapley for work on these markets.</p>
<p>A key enabler was researchers in systems and networking. Their scientific revolutions of the Internet and mobile computing put matching markets on an exciting, new journey and their systems run these centralized markets on powerful computers.</p>
<p>The discipline of algorithm design has had an umbilical connection to matching markets: At the birth of this field lies the highly sophisticated <a href="https://www.tandfonline.com/doi/abs/10.4169/amer.math.monthly.120.05.386?journalCode=uamm20">Gale-Shapley</a> stable matching algorithm (1962), whose pivotal game-theoretic property of incentive compatibility follows as a free gift from polynomial time solvability — it was established <a href="http://pareto.uab.es/jmasso/pdf/DubinsFreedmanAMM1981.pdf">two decades</a> after the discovery of the algorithm! Yet most researchers, including those in theoretical computer science, are not aware that algorithm design is also a legitimate claimant to this field. Indeed, the very “engine’’ that runs almost each one of these markets is a <a href="https://simons.berkeley.edu/rmklectures2019-fall-1">sophisticated algorithm</a> chosen from the “gold mine’’ of matching theory! Besides stable matching, this includes maximum matching and online matching and their numerous variants.</p>
<p>Looking back at the huge expansion of matching markets over the last decade-and-a-half, one can see that all three disciplines were faced with numerous challenges: understanding the incentive structure of a new market; finding ways of dealing with terra-bytes of data, and choosing and delivering within milli-seconds the “right’’ ads to show with a user query; and designing an algorithm for the latest variant of online matching. And they all delivered!</p>
<p>The rich and diverse set of research talks given at the recent <a href="https://agtb.wordpress.com/2019/10/02/matching-markets-simons-driven-by-theory-driving-the-economy/">Simons program</a> on matching markets is proof enough that the elephant is still evolving!</p></div>
    </content>
    <updated>2019-10-05T20:08:09Z</updated>
    <published>2019-10-05T20:08:09Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>michalfeldman</name>
    </author>
    <source>
      <id>https://agtb.wordpress.com</id>
      <logo>https://secure.gravatar.com/blavatar/52ef314e11e379febf97d1a97547f4cd?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fbuttonw-com.png</logo>
      <link href="https://agtb.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://agtb.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://agtb.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://agtb.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Computation, Economics, and Game Theory</subtitle>
      <title>Turing's Invisible Hand</title>
      <updated>2019-10-07T01:59:54Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://adamsheffer.wordpress.com/?p=5454</id>
    <link href="https://adamsheffer.wordpress.com/2019/10/05/new-horizons-in-geometry-and-micha-sharir/" rel="alternate" type="text/html"/>
    <title>New Horizons in Geometry and Micha Sharir</title>
    <summary>Always wanted to visit Israel? Like discrete or computational geometry, and Micha Sharir? Considering what to do with this year’s travel funds? Join us in Tel Aviv! https://geometrynyc.wixsite.com/sharir (Open on a computer – does not support mobile yet.) If you can, please help us spread the word. Partial list of speakers: Pankaj Agarwal (Duke) Noga […]</summary>
    <updated>2019-10-05T15:55:19Z</updated>
    <published>2019-10-05T15:55:19Z</published>
    <category term="Math events"/>
    <author>
      <name>Adam Sheffer</name>
    </author>
    <source>
      <id>https://adamsheffer.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://adamsheffer.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://adamsheffer.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://adamsheffer.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://adamsheffer.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Discrete geometry and other typos</subtitle>
      <title>Some Plane Truths</title>
      <updated>2019-10-07T02:00:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/10/05/faculty-at-universidad-catolica-de-chile-apply-by-november-1-2019/</id>
    <link href="https://cstheory-jobs.org/2019/10/05/faculty-at-universidad-catolica-de-chile-apply-by-november-1-2019/" rel="alternate" type="text/html"/>
    <title>Faculty at Universidad Católica de Chile (apply by November 1, 2019)</title>
    <summary>OPEN POSITION AT THE INSTITUTE FOR MATHEMATICAL AND COMPUTATIONAL ENGINEERING (IMC) ,PONTIFICIA UNIVERSIDAD CATÓLICA DE CHILE We are offering a full-time position at the assistant or associate level. We invite highly qualified candidates in all areas of applied mathematics, including data science and machine learning. Website: http://imc.uc.cl/index.php/noticias/135-open-position-at-the-institute-for-mathematical-and-computational-engineering Email: pbarcelo@ing.puc.cl</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>OPEN POSITION AT THE<br/>
INSTITUTE FOR MATHEMATICAL AND COMPUTATIONAL<br/>
ENGINEERING (IMC) ,PONTIFICIA UNIVERSIDAD CATÓLICA DE CHILE</p>
<p>We are offering a full-time position at the assistant or associate level. We invite highly qualified candidates in all areas of applied mathematics, including data science and machine learning.</p>
<p>Website: <a href="http://imc.uc.cl/index.php/noticias/135-open-position-at-the-institute-for-mathematical-and-computational-engineering">http://imc.uc.cl/index.php/noticias/135-open-position-at-the-institute-for-mathematical-and-computational-engineering</a><br/>
Email: pbarcelo@ing.puc.cl</p></div>
    </content>
    <updated>2019-10-05T12:04:39Z</updated>
    <published>2019-10-05T12:04:39Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-10-07T02:00:01Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://grigory.github.io/blog/how-i-spent-last-summer</id>
    <link href="http://grigory.github.io/blog/how-i-spent-last-summer/" rel="alternate" type="text/html"/>
    <title xml:lang="en">How I Spent Last Summer FAQ</title>
    <content type="xhtml" xml:lang="en"><div xmlns="http://www.w3.org/1999/xhtml"><!--
<div align="center"><img alt="CAML" src="http://grigory.github.io/blog/pics/summer.png" width="400"></div>
-->

<p>I get a lot of questions about how I spent last summer. Normally I just take off to the Bay Area the day my last Spring class is over and fly back the day before my Fall class begins.
However, last summer I decided I’ve been in the US long enough to learn everything it has to offer and it was time to explore life across the pond and spend three months at the Alan Turing Institute in London. Then I had two interns coming over to Bloomington so I spent my first ever summer month here. 
Since it is that time of year, a quick reminder to <a href="https://cs.indiana.edu/apply/graduate-application.html">apply by Dec 15</a> if you are interested in doing a Ph.D. and stay tuned for the internship call announcement (probably similar deadline).</p>

<h1 id="summer-interns-in-bloomington">Summer Interns in Bloomington</h1>

<p>IU has started a <a href="https://sice.indiana.edu/research/student-research/fellowship.html">Global Talent Attraction Program (GTAP)</a> – fantastic program for international summer interns. The program gives you a $4000 stipend and you spend 2 months here at IU. There were a lot of strong applicants so it took me a while to interview all candidates. In the end, the two interns I got were <a href="https://codeforces.com/profile/Chameleon2460">Jakub Boguta</a> (U. Warsaw, ACM ICPC gold this year, must be tough to be in the lead for 4 hours and not win) and <a href="https://codeforces.com/profile/josdas">Stanislav Naumov</a> (SPb ITMO, ACM ICPC finalist, who spent summer at Google and just arrived on campus). Also, <a href="https://www.eleves.ens.fr/home/farthaud/">Farid Arthaud</a> joined us from ENS Paris, Ulm with a short recommendation of being “probably the best third-year CS student in France”. If you think you are the best in your country, have U.S. citizenship and don’t need to get paid, shoot me an email ;) Despite it being hot and humid here in Bloomington during the summer, we had a great time.</p>

<div align="center"><img alt="interns" src="http://grigory.github.io/blog/pics/interns.jpg" width="400"/></div>
<p><br/></p>

<p>We decided to dive into deep learning for image classification and figured out how to get more mileage out of standard pretrained neural nets by using them to produce hierarchical clusterings (with guarantees). If this sounds fun, you can apply for GTAP next year (picture by Farid).</p>

<div align="center"><img alt="hc" src="http://grigory.github.io/blog/pics/hc.png" width="400"/></div>

<h1 id="london-and-the-alan-turing-institute">London and the Alan Turing Institute</h1>

<p>Overall, this was a great experience as it quickly became clear that my neural net is overfit to the US lifestyle. I think of UK as throwing in some perturbations to your visual and verbal input (some may seem adversarial, but mostly just random) which, as we know, is good for robustness, generalization and what not.</p>

<ul>
  <li><b>Q</b>: Is grass greener there? <b>A</b>: Yes, of course. Especially, if you live next to the Regent’s Park.</li>
  <li><b>Q</b>: Is it your cup of tea? <b>A</b>: No, I still only function on Redbull, but the afternoon teas are a great experience. Proximity to cutting-edge tech, CS research and startups still matters most to me. However, if you are into math or finance, your mileage will almost certainly vary. Also, London seems perfect for a short-term visit/sabbatical, especially if you want to take a break from the tech hype, write a book, explore Europe, etc.</li>
  <li><b>Q</b>: What’s up with the <a href="https://www.turing.ac.uk/">Alan Turing Institute</a> and DeepMind? <b>A</b>: These two are probably the most happening places in the UK right now in academia and industry respectively. They are within a 5-minute walk from each other in King’s Cross. I was staying right across the road and it was perfect except for no AC. ATI serves as a meeting hub for researchers from all of the top UK schools (Cambridge, Oxford, Warwick, UCL, Edinburgh, etc.).
ATI is based inside the British library, which was the largest public building constructed in the UK in the 20th century. ATI has its own space inside the library which is equipped similarly to Google/FB offices. Except no free food, only drinks – would you want to have free British food anyway?</li>
</ul>

<div align="center"><img alt="ati" src="http://grigory.github.io/blog/pics/ati.jpg" width="400"/></div>
<p><br/></p>
<div align="center"><img alt="bl" src="http://grigory.github.io/blog/pics/bl.jpg" width="400"/></div>

<ul>
  <li><b>Q</b>: Is Shoreditch the most hip neighborhood? <b>A</b>: I think so, best Sci-Fi graffiti ever.</li>
</ul>

<div align="center"><img alt="murals" src="http://grigory.github.io/blog/pics/mural.jpg" width="400"/></div>

<ul>
  <li><b>Q</b>: Did you meet the King? <b>A</b>: Yes, in Heathrow I ran into a 250-pound dude from Atlanta who made it quite clear that’s him by wearing one of these (except in a larger font and in dirty red color).</li>
</ul>

<div align="center"><img alt="king" src="http://grigory.github.io/blog/pics/king.jpg" width="400"/></div>

<ul>
  <li><b>Q</b>: <a href="https://www.youtube.com/watch?v=ViHsfeXNgjY">Is Paris still Paris?</a> <b>A</b>: I think so (my third time). K and I took a 2-hour train down there directly from King’s Cross (St. Pancras station, another reason to stay in King’s Cross). We’ve enjoyed our time greatly, especially in Versailles and ENS Paris, Ulm. The Salvador Dali Museum in Montmartre was another highlight of this trip.</li>
</ul>

<div align="center"><img alt="versailles" src="http://grigory.github.io/blog/pics/versailles.jpg" width="400"/></div>

<ul>
  <li><b>Q</b>: Brexit, Boris Johnson? <b>A</b>: Locals made fun of me for having never heard of Boris Johnson. <a href="https://www.youtube.com/watch?v=dXyO_MC9g3k">Is there much to know anyway</a>?</li>
</ul>


  <p><a href="http://grigory.github.io/blog/how-i-spent-last-summer/">How I Spent Last Summer FAQ</a> was originally published by Grigory Yaroslavtsev at <a href="http://grigory.github.io/blog">The Big Data Theory</a> on October 05, 2019.</p></div>
    </content>
    <updated>2019-10-05T00:00:00Z</updated>
    <published>2019-10-05T00:00:00Z</published>
    <author>
      <name>Grigory Yaroslavtsev</name>
      <email>grigory@grigory.us</email>
      <uri>http://grigory.github.io/blog</uri>
    </author>
    <source>
      <id>http://grigory.github.io/blog/</id>
      <author>
        <name>Grigory Yaroslavtsev</name>
        <email>grigory@grigory.us</email>
        <uri>http://grigory.github.io/blog/</uri>
      </author>
      <link href="http://grigory.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="http://grigory.github.io/blog" rel="alternate" type="text/html"/>
      <title xml:lang="en">The Big Data Theory</title>
      <updated>2019-10-05T20:27:22Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/135</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/135" rel="alternate" type="text/html"/>
    <title>TR19-135 |  Doubly-Efficient Pseudo-Deterministic Proofs | 

	Dhiraj Holden, 

	Shafi Goldwasser, 

	Michel Goemans</title>
    <summary>In [20] Goldwasser, Grossman and Holden  introduced pseudo-deterministic interactive proofs for search problems where a powerful prover can convince a probabilistic polynomial time verifier that a solution to a search problem is canonical.  They studied  search problems for which polynomial time algorithms are not known and for which many solutions are possible. They showed that whereas there exists a constant round pseudo deterministic proof for graph isomorphism where the canonical solution is the lexicographically smallest isomorphism, the existence of pseudo-deterministic interactive proofs for NP-hard problems would imply the collapse of the polynomial time hierarchy.

In this paper, we turn our attention to studying  doubly-efficient pseudo-deterministic proofs for polynomial time search problems:  pseudo-deterministic proofs with the extra requirement that the prover runtime is polynomial  and the verifier runtime to verify that a solution is canonical is significantly lower  than the complexity of finding any solution, canonical or otherwise. Naturally this question is particularly interesting for search problems for which a lower bound on its worst case complexity  is known or has been widely conjectured. 

We show doubly-efficient pseudo-deterministic algorithms for a host of natural problems whose complexity has long been conjectured. In particular:

We show a doubly efficient pseudo-deterministic proof for linear programming where the canonical solution which the prover will provide is  the lexicographically greatest optimal solution for the LP. To this end, we show how through perturbing the linear program and strong duality this solution can be both  computed efficiently by the prover, and verified by the verifier.  
The time of the verifier is $O(d^2 )$ for a linear program with integer data and at most $d$ variables and constraints, whereas the time to solve such linear program is $\tilde{O}(d^{\omega} )$ by randomized algorithms [11] for $\omega$  the exponent for fast matrix multiplication .


We show a doubly efficient pseudo-deterministic proof for 3-SUM and problems reducible to 3-SUM where the prover is a $O(n^2)$ time algorithm and the verifier takes time $\tilde{O}(n^{1.5})$. 


We show a doubly-efficient pseudo-deterministic proof for the hitting set problem} where the verifier runs in time $\tilde{O}(m)$ and the prover runs in time $\tilde{O}(m^2)$ where $ m = \sum_{S \in \mathcal{S}} |S| + \sum_{T \in \mathcal{T}} |T|$ for inputs  collections of sets $\mathcal{S}, \mathcal{T}$.

We show a doubly-efficient pseudo-deterministic proof for the Zero Weight Triangle problem where the verifier runs in time $\tilde{O}(n^{2 + \omega/3})$ and the prover runs in randomized time $\tilde{O}(n^3)$. The Zero Weight Triangle problem is equivalent to the All-Pairs Shortest Path problem, a well-studied problem that is the foundation of many hardness results in graph algorithms [39,38], under sub-cubic reductions.</summary>
    <updated>2019-10-04T15:50:06Z</updated>
    <published>2019-10-04T15:50:06Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-10-07T01:59:48Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/134</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/134" rel="alternate" type="text/html"/>
    <title>TR19-134 |  Finding monotone patterns in sublinear time | 

	Omri Ben-Eliezer, 

	Clement Canonne, 

	Shoham Letzter, 

	Erik Waingarten</title>
    <summary>We study the problem of finding monotone subsequences in an array from the viewpoint of sublinear algorithms. For fixed $k \in \mathbb{N}$ and $\varepsilon &gt; 0$, we show that the non-adaptive query complexity of finding a length-$k$ monotone subsequence of $f \colon [n] \to \mathbb{R}$, assuming that $f$ is $\varepsilon$-far from free of such subsequences, is $\Theta((\log n)^{\lfloor \log_2 k \rfloor})$. Prior to our work, the best algorithm for this problem, due to Newman, Rabinovich, Rajendraprasad, and Sohler (2017), made $(\log n)^{O(k^2)}$ non-adaptive queries; and the only lower bound known, of $\Omega(\log n)$ queries for the case $k = 2$, followed from that on testing monotonicity due to Erg\"un, Kannan, Kumar, Rubinfeld, and Viswanathan (2000) and Fischer (2004).</summary>
    <updated>2019-10-04T15:42:39Z</updated>
    <published>2019-10-04T15:42:39Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-10-07T01:59:48Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/10/04/postdoc-at-university-of-warwick-uk-apply-by-december-1-2019/</id>
    <link href="https://cstheory-jobs.org/2019/10/04/postdoc-at-university-of-warwick-uk-apply-by-december-1-2019/" rel="alternate" type="text/html"/>
    <title>Postdoc at University of Warwick, UK (apply by December 1, 2019)</title>
    <summary>We invite applications for a postdoc position hosted by Tom Gur at the University of Warwick, United Kingdom, in the fields of sublinear-time algorithms, coding theory, interactive and probabilistically checkable proofs, and complexity theory. Please contact Tom Gur directly with your CV. The start date is flexible. Website: https://www.dcs.warwick.ac.uk/~tomgur/ Email: tom.gur@warwick.ac.uk</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>We invite applications for a postdoc position hosted by Tom Gur at the University of Warwick, United Kingdom, in the fields of sublinear-time algorithms, coding theory, interactive and probabilistically checkable proofs, and complexity theory.</p>
<p>Please contact Tom Gur directly with your CV. The start date is flexible.</p>
<p>Website: <a href="https://www.dcs.warwick.ac.uk/~tomgur/">https://www.dcs.warwick.ac.uk/~tomgur/</a><br/>
Email: tom.gur@warwick.ac.uk</p></div>
    </content>
    <updated>2019-10-04T13:10:04Z</updated>
    <published>2019-10-04T13:10:04Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-10-07T02:00:01Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://agtb.wordpress.com/?p=3425</id>
    <link href="https://agtb.wordpress.com/2019/10/04/highlights-beyond-ec-call-for-nominations/" rel="alternate" type="text/html"/>
    <title>Highlights Beyond EC – Call for Nominations</title>
    <summary>The 21st ACM Conference on Economics and Computation (EC’20) will host a special plenary session highlighting some of the best work in economics and computation that appears in conferences and journals other than EC, or mature working papers. The intention of this session is to expose EC attendees to related work just beyond the boundary of their […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The <a href="http://ec20.sigecom.org/">21st ACM Conference on Economics and Computation</a> (EC’20) will host a special <strong>plenary session</strong> highlighting some of the best work in economics and computation that appears in conferences and journals other than EC, or mature working papers. The intention of this session is to expose EC attendees to related work just beyond the boundary of their current awareness. We seek nominations for papers in Economics and Computation that have made breakthrough advances, opened up new horizons for research, made interesting connections between different scientific areas, or had significant impact on practice. Examples of relevant conferences and journals include STOC/FOCS/SODA/ITCS, AAAI/IJCAI/AAMAS, NIPS/ICML/COLT, WWW/KDD, AER/Econometrica/JPE/QJE/RESTUD/TE/AEJ Micro/JET/GEB, and Math of OR/Management Science/Operations Research.</p>
<p><strong>Who can nominate? </strong>This call is open to everyone (self-nominations are also allowed), but we particularly encourage members of PCs or editorial boards in various venues to submit nominations.</p>
<p><strong>Deadline:</strong> December 23, 2019.</p>
<p><strong>Nomination format:</strong> Nominations should be emailed to <a href="mailto:HighlightsBeyondEC@gmail.com">HighlightsBeyondEC2020@gmail.com</a>, and should include:</p>
<ul>
<li>Paper title and author names.</li>
<li>Publication venue or online working version. Preference will be given to papers that have appeared in a related conference or journal within the past two years, or have a working version circulated within the past two years.</li>
<li>A short (2-3 paragraph) justification letter, explaining the significance of the paper.</li>
<li>Names of 1-3 experts on the area of the paper.</li>
</ul>
<p><strong>Committee members:</strong></p>
<ul>
<li><strong>Michal Feldman </strong>(Tel Aviv University)</li>
<li><strong>Hervé Moulin</strong> (University of Glasgow)</li>
<li><strong>Michael Wellman </strong>(University of Michigan)</li>
<li><strong>Adam Wierman </strong>(California Institute of Technology)</li>
</ul></div>
    </content>
    <updated>2019-10-04T06:05:58Z</updated>
    <published>2019-10-04T06:05:58Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>michalfeldman</name>
    </author>
    <source>
      <id>https://agtb.wordpress.com</id>
      <logo>https://secure.gravatar.com/blavatar/52ef314e11e379febf97d1a97547f4cd?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fbuttonw-com.png</logo>
      <link href="https://agtb.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://agtb.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://agtb.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://agtb.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Computation, Economics, and Game Theory</subtitle>
      <title>Turing's Invisible Hand</title>
      <updated>2019-10-07T01:59:54Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>http://ptreview.sublinear.info/?p=1192</id>
    <link href="https://ptreview.sublinear.info/?p=1192" rel="alternate" type="text/html"/>
    <title>News for Sept 2019</title>
    <summary>Five Six papers this month: results on testing separations, linearity testing in \(\mathbb{R}^n\), testing for regular languages, graph property testing, topological property testing, and Boolean rank. Hard properties with (very) short PCPPs and their applications, by Omri Ben-Eliezer, Eldar Fischer, Amit Levi, and Ron D. Rothblum (arXiv). Probably, the most significant takeaway from this work is a (largest […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><s>Five</s> Six papers this month: results on testing separations, linearity testing in \(\mathbb{R}^n\), testing for regular languages, graph property testing, topological property testing, and Boolean rank. </p>



<p><strong>Hard properties with (very) short PCPPs and their applications</strong>, by Omri Ben-Eliezer, Eldar Fischer, Amit Levi, and Ron D. Rothblum (<a href="https://eccc.weizmann.ac.il/report/2019/088/">arXiv</a>). Probably, the most significant takeaway from this work is a (largest possible) separation between standard and tolerant property testing. PCPPs (Probabilistically Checkable Proofs of Proximity) are the “NP” variant of property testing, where the tester is aided by a proof string. Consider property \(\mathcal{P}\). If \(x \in \mathcal{P}\), there must be a proof string that makes the tester accept (with probability 1). If \(x\) is far from \(\mathcal{P}\) (in the usual property testing sense), for any proof string, the tester must reject with sufficiently high probability. PCPPs have played a role in the classical constructions of PCPs, but have also found uses in getting a better understanding of property testing itself. And this paper shows how PCPP constructions can be used to get property testing separations. The main result in this paper is a property \(\mathcal{P}\) that (basically) requires \(\Omega(n)\) queries to “property test”, but has a PCPP system where the proof length is \(\widetilde{O}(n)\). (\(n\) is the input length.) The main construction uses collections of random linear codes. Significantly, these constructions show a strong separation between standard vs tolerant property testing, and standard vs erasure-resilient property testing. (The latter is a recent variant by <a href="https://epubs.siam.org/doi/abs/10.1137/16M1075661?journalCode=smjcat">Dixit et al</a>, where certain parts of the input are hidden from the tester.) There is a property that is testable in a constant number of queries, but requires \(\widetilde{\Omega}(n)\) queries to test tolerantly (for any non-trivial choice of parameters). An analogous result holds for erasure-resilient testing.</p>



<p><strong>Distribution-Free Testing of Linear Functions on R^n</strong>, by Noah Fleming and Yuichi Yoshida (<a href="https://arxiv.org/abs/1909.03391">arXiv</a>). Linearity testing is arguably <em>the</em> canonical problem in property testing, yet there is still much to be learned about it. This paper considers functions \(f: \mathbb{R}^n \to \mathbb{R}\), and the <em>distribution-free setting</em>. (In this setting, distance is measured according is an unknown distribution \(\mathcal{D}\) over the input, and the tester can access samples from this distribution. For \(\mathbb{R}^n\), the “standard” distribution would the \(n\)-dimensional Gaussian.) The main result is that linearity testing can be done in the distribution-free setting with \(\widetilde{O}(1/\varepsilon)\) queries, assuming that the distribution is continuous. The primary technical tool, an interesting result in its own right, is that additivity \((f(x+y) = f(x) + f(y))\) can be tested in \(\widetilde{O}(1/\varepsilon)\) queries. The significance of the testing result is cemented by an \(\Omega(n)\) lower bound for sample-based testers.</p>



<p><strong>Sliding window property testing for regular languages</strong> by Moses Ganardi, Danny Hucke, Markus Lohrey, Tatiana Starikovskaya (<a href="https://arxiv.org/abs/1909.10261">arXiv</a>). Fix a regular language \(\mathcal{R}\). Consider the streaming model, and the basic question of recognizing whether the string (being streamed) is in \(\mathcal{R}\). Simple, you will say! Run the DFA recognizing \(\mathcal{R}\) in constant space. Now, suppose there is a sliding window length of \(n\). The aim is to determine if the past \(n\) symbols (the “active window”) form a string in \(\mathcal{R}\). Suprisingly (at least to me), there is a full characterization of the space required for randomized algorithms, and (depending on \(\mathcal{R}\)), it is either \(\Theta(1)\), \(\Theta(\log\log n)\), \(\Theta(\log n)\), or \(\Theta(n)\).  In the interest of beating these lower bounds, suppose we wish to property test on the active window. It turns out the answer is quite nuanced. There are deterministic \(O(\log n)\)-space testers and randomized two-sided \(O(1/\varepsilon)\)-space testers for all regular languages. For randomized one-sided testers, there are multiple possibilities for the optimal space complexity, and there is a full characterization of these regular languages.</p>



<p><strong>A characterization of graph properties testable for general planar graphs with one-sided error (It’s all about forbidden subgraphs)</strong> by Artur Czumaj and Christian Sohler (<a href="https://arxiv.org/pdf/1909.10647.pdf">arXiv</a>). Property testing of sparse graphs has been receiving more attention, but most results focus on the bounded degree setting. Unfortunately, many of these results break quite dramatically on sparse graphs with unbounded degrees. This paper focuses on property testing, within the class of unbounded degree planar graphs. (Meaning, the input is always assumed to be planar.) The results achieve a significant goal: as the title suggests, there is a complete characterization of properties that are constant-query testable with one-sided error. The easier part is in showing that all such properties can be reduced to testing \(H\)-freeness. The harder (remarkable) result is \(H\)-freeness can be tested in general planar queries with constant queries. (This is non-trivial even for triangle-freeness.) And, as is easy to conjecture but hard to prove, these results carry over for all minor-closed families.  As a small indication of the challenge, most testers for bounded-degree graphs work by doing constant depth BFSes. When high degree vertices are present, this method fails, and we really need new ideas to deal with such graphs.</p>



<p><strong>Near Coverings and Cosystolic Expansion – an example of topological property testing</strong> by Irit Dinur and Roy Meshulam (<a href="https://eccc.weizmann.ac.il/report/2019/126/">ECCC</a>). In most algebraic settings, property testing results can be seen as local to global theorems. When do local constraints on a large object imply a global condition? This paper gives a topological instantiation of this phenomenon. We need to define the <em>cover</em> of a simplicial complex \(X\). For concreteness, think of a 2D simplicial complex \(X\), which is a hypergraph with hyperedges of size at most 3, where subsets of hyperedges are also present. A 2-cover is a simplicial complex \(X’\) with the following property. It has two copies of each vertex of \(X\). Each hyperedge of \(X\) must have two “corresponding” disjoint copies in \(X’\). Let the copies of vertex \(v\) be \(v_0, v_1\). Then, for every hyperedge (say) \((u,v,w)\) of \(X\), there must be two disjoint hyperedges in \(X’\) involving copies of the corresponding vertices. One can consider the property testing twist: if the neighborhoods of “most” vertices \(v\) in \(X\) satisfy these condition (with respect to the neighborhoods of the copies of \(v\) in \(X’\)), then is \(X’\) close to being a cover of \(X\)? Indeed, this paper proves that such a “property testing condition” holds iff \(X\) is a high-dimensional expander.</p>



<p><strong>Property testing of the Boolean and binary rank</strong> by Michal Parnas, Dana Ron, and Adi Shraibman (<a href="https://arxiv.org/abs/1908.11632">arXiv</a>). The Boolean rank of a matrix \(M\) is a fundamental quantity that appears in many lower bound constructions. (Recall that an \(n \times m\) Boolean matrix \(M\) has a rank \(r\) if \(M\) can be expressed as \(X \cdot Y\), where \(X \in \mathbb{F}_2^{n \times d}\) and \(Y \in \mathbb{F}_2^{d \times m}\).) In the real-valued setting, results show that one can property test rank in \(poly(d/\varepsilon)\) queries. This paper proves an analogous result for the Boolean rank. There is a surprise element here: over reals, the rank can be computed in polynomial time, and many of the geometric intuitions can be brought over to the property testing problem. On the other hand, the Boolean rank is NP-hard to compute exactly, yet we can still get a tester with \(poly(d)\) query complexity. The paper also gives results for <em>binary rank</em>. For the binary rank, we require the component matrices \(X, Y\) to be Boolean, but algebraic operations are over the reals. In the case, the tester has query complexity \(2^{2d}\) (with varying dependencies on \(\varepsilon\) for adaptive/non-adaptive testers). The intriguing open problem is whether \(poly(d)\)-query testers exist for binary rank.</p>



<p> </p></div>
    </content>
    <updated>2019-10-04T05:54:43Z</updated>
    <published>2019-10-04T05:54:43Z</published>
    <category term="Monthly digest"/>
    <author>
      <name>Seshadhri</name>
    </author>
    <source>
      <id>https://ptreview.sublinear.info</id>
      <link href="https://ptreview.sublinear.info/?feed=rss2" rel="self" type="application/atom+xml"/>
      <link href="https://ptreview.sublinear.info" rel="alternate" type="text/html"/>
      <subtitle>The latest in property testing and sublinear time algorithms</subtitle>
      <title>Property Testing Review</title>
      <updated>2019-10-06T23:41:44Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-3615744836127152440</id>
    <link href="https://blog.computationalcomplexity.org/feeds/3615744836127152440/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/10/quantum-supremacy-guest-post-by-abhinav.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/3615744836127152440" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/3615744836127152440" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/10/quantum-supremacy-guest-post-by-abhinav.html" rel="alternate" type="text/html"/>
    <title>Quantum Supremacy: A Guest Post by Abhinav Deshpande</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">I am delighted to introduce you to Abhinav Deshpande, who is a graduate student at the University of Maryland, studying Quantum Computing. This will be a guest post on the rumors of the recent Google breakthrough on Quantum Supremacy. For other blog posts on this exciting rumor, see <a href="https://www.scottaaronson.com/blog/?p=4317">Scott Aaronson's post</a>, <a href="https://www.scottaaronson.com/blog/?p=4342">Scott Aaronson's second post on it</a>, <a href="https://www.quantamagazine.org/john-preskill-explains-quantum-supremacy-20191002/">John Preskill's quanta article</a>, <a href="https://blog.computationalcomplexity.org/2019/09/quantum-supremacy.html">Fortnow's post</a>,<br/>
and there may be others.<br/>
<br/>
Guest post by Abhinav:<br/>
<br/>
I (Abhinav) thank Bill Fefferman for help with this post, and Bill Gasarch for inviting me to do a guest post.<br/>
<br/>
<br/>
<b>The quest towards quantum computational supremacy</b><br/>
<br/>
September saw some huge news in the area of quantum computing, with rumours that the Google AI Lab has achieved a milestone known as 'quantum computational supremacy', also termed 'quantum supremacy' or 'quantum advantage' by some authors. Today, we examine what this term means, the most promising approach towards achieving this milestone, and the best complexity-theoretic evidence we have so far against classical simulability of quantum mechanics. We will not be commenting on details of the purported paper since there is no official announcement or claim from the authors so far.<br/>
<br/>
<b>What it means</b><br/>
<br/>
First off, the field of quantum computational supremacy arose from trying to formally understand the differences in the power of classical and quantum computers. A complexity theorist would view this goal as trying to give evidence to separate the complexity classes BPP and BQP. However, it turns out that one can gain more traction from considering the sampling analogues of these classes, SampBPP and SampBQP.  These are classes of distributions that can be efficiently sampled on classical and quantum computers, respectively. Given a quantum circuit U on n qubits, one may define an associated probability distribution over 2^n outcomes as follows: apply U to the fiducial initial state |000...0&gt; and measure the resulting state in the computational basis. This produces a distribution D_U.<br/>
<br/>
A suitable way to define the task of simulating the quantum circuit is as follows<b style="font-style: italic;">:</b><br/>
<br/>
Input: Description of a quantum circuit U acting on n qubits.<br/>
<br/>
Output: A sample from the probability distribution D_U obtained by measuring U|000...0&gt; in the computational basis.<br/>
<br/>
One of the early works in this field was that of <a href="https://arxiv.org/abs/quant-ph/0205133">Terhal and DiVincenzo</a>, which first considered the complexity of sampling from a distribution (weak simulation) as opposed to that of calculating the exact probability of a certain outcome (strong simulation). Weak simulation is arguably the more natural notion of simulating a quantum system, since in general, we cannot feasibly compute the probability of a certain outcome even if we can simulate the quantum circuit. Subsequent works by <a href="https://arxiv.org/abs/1011.3245">Aaronson and Arkhipov</a>, and by <a href="https://arxiv.org/abs/1005.1407">Bremner, Jozsa, and Shepherd</a> established that if there is a classically efficient weak simulator for different classes of quantum circuits, the polynomial hierarchy collapses to the third level.<br/>
<br/>
<br/>
So far, we have only considered the question of exactly sampling from the distribution D_U. However, any realistic experiment is necessarily noisy, and a more natural problem is to sample from a distribution that is not exactly D_U but from any distribution D_O that is ε-close in a suitable distance measure, say the variation distance.<br/>
<br/>
The aforementioned work by Aaronson and Arkhipov was the first to consider this problem, and they made progress towards showing that a special class of quantum circuits (linear optical circuits) is classically hard to approximately simulate in the sense above. The task of sampling from the output of linear optical circuits is known as boson sampling. At the   time, it was the best available way to show that quantum computers  may solve some problems that are far beyond the reach of classical computers.<br/>
<br/>
Even granting that the PH doesn't collapse, one still needs to make an additional conjecture to establish that boson sampling is not classically simulable.  The conjecture is that additively approximating the output probabilities of a random linear optical quantum circuit is #P-hard.  The reason this may be true is that output probabilities of random linear optical quantum circuits are Permanents of a Gaussian random matrix, and the Permanent is as hard to compute on a random matrix as it is on a worst-case matrix. Therefore, the only missing link is to go from average-case hardness of exact computation to average-case hardness of an additive estimation. In addition, if we make a second conjecture known as the "anti-concentration" conjecture, we can show that this additive estimation is non-trivial: it suffices to give us a good multiplicative estimation with high probability.<br/>
<br/>
So that's what quantum computational supremacy is about: we have a computational task that is efficiently solvable with quantum computers, but which would collapse the polynomial hierarchy if done by a classical computer (assuming certain other conjectures are true). One may substitute "collapse of the polynomial hierarchy" with stronger conjectures and incur a corresponding tradeoff in the likelihood of the conjecture being true.<br/>
<br/>
<b>Random circuit sampling</b><br/>
<br/>
In 2016,<a href="https://arxiv.org/abs/1608.00263"> Boixo et al</a>. proposed to replace the class of quantum circuits for which some hardness results were known (commuting circuits and boson sampling) by random circuits of sufficient depth on a 2D grid of qubits having nearest-neighbour interactions. Concretely, the proposed experiment would be to apply random unitaries from a specified set on n qubits arranged on a 2D grid for sufficient depth, and then sample from the resulting distribution. The two-qubit unitaries in the set are restricted to act between nearest neighbours, respecting the geometric This task is called random circuit sampling (RCS).<br/>
<br/>
At the time, the level of evidence for the hardness of this scheme was not yet the same as the linear optical scheme. However, given the theoretical and experimental interest in the idea of demonstrating a quantum speedup over classical computers, subsequent works by<a href="https://arxiv.org/abs/1803.04402"> Bouland, Fefferman, Nirkhe and Vazirani</a>, and <a href="https://arxiv.org/abs/1809.06957">Harrow and Mehraban</a> bridged this gap (the relevant work by <a href="https://arxiv.org/abs/1612.05903">Aaronson and Chen</a> will be discussed in the following section). Harrow and Mehraban proved anticoncentration for random circuits. In particular, they showed that a 2-dimensional grid of n qubits achieve anticoncentration in depth O(\sqrt{n}), improving upon earlier results with higher depth due to <a href="https://arxiv.org/abs/1208.0692">Brandao, Harrow and Horodeck</a>i. Bouland et al. proved the same supporting evidence for RCS as that for boson sampling, namely a worst-to-average-case reduction for exactly computing most output probabilities, even without the permanent structure possessed by linear optical quantum circuits.<br/>
<br/>
<b>Verification</b><br/>
<br/>
So far, we have not discussed the elephant in the room: of verifying that the output distribution supported on 2^n outcomes. It turns out that there are concrete lower bounds such as those due to Valiant and Valiant, showing that verifying whether an empirical distribution is close to a target distribution is impossible if one has few samples.<br/>
<br/>
Boixo et al. proposed a way of certifying the fidelity of the purported simulation. Their key observation was to note that if their experimental system is well modelled by a noise model called global depolarising noise, estimating the output fidelity is possible with relatively few outcomes. Under global depolarising noise with fidelity f, the noisy distribution takes the form D_N = f D_U + (1-f) I, where I is the uniform distribution over the 2^n outcomes. Together with another empirical observation about the statistics of output probabilities of the ideal distribution D_U, they argued that computing the following cross-entropy score would serve as a good estimator of the fidelity:<br/>
<br/>
f ~ H(I, D_U) - H(D_exp, D_U), where H(D_A,D_B) is the cross-entropy between the two distributions: H(D_A, D_B) = -\sum_i p_A log (p_B).<br/>
<br/>
The proposal here was to experimentally collect several samples from D_exp, classically compute using brute-force the probabilities of these outcomes in the distribution D_U, and estimate the cross-entropy using this information. If the test outputs a high score for a computation on sufficiently many qubits and depth, the claim is that quantum supremacy has been achieved.<br/>
<br/>
Aaronson and Chen gave alternative form of evidence for the hardness of scoring well on a test that aims to certify quantum supremacy similar to the manner above. This sidesteps the issue of whether a test similar to the one above does indeed certify the fidelity. The specific problem considered was "Heavy Output Generation" (HOG), the problem of outputting strings that have higher than median probability in the output distribution. Aaronson and Chen linked the hardness of HOG to a closely related problem called "QUATH", and conjectured that QUATH is hard for classical computers.<br/>
<br/>
<b>Open questions</b><br/>
<br/>
Assuming the Google team has performed the impressive feat of both running the experiment outlined before and classically computing the probabilities of the relevant outcomes to see a high score on their cross-entropy test, I discuss the remaining positions a skeptic might take regarding the claim about quantum supremacy.<br/>
<br/>
"The current evidence of classical hardness of random circuit sampling is not sufficient to conclude that the task is hard". Assuming that the skeptic believes that the polynomial hierarchy does not collapse, a remaining possibility is that there is no worst-to-average-case reduction for the problem of *approximating* most output probabilities, which kills the proof technique of Aaronson and Arkhipov to show hardness of approximate sampling.<br/>
<br/>
"The cross-entropy proposal does not certify the fidelity." Boixo et al. gave numerical evidence and other arguments for this statement, based on the observation that the noise is of the global depolarising form. A skeptic may argue that the assumption of global depolarising noise is a strong one.<br/>
<br/>
"The QUATH problem is not classically hard." In order to give evidence for the hardness of QUATH, Aaronson and Chen examined the best existing algorithms for this problem and also gave a new algorithm that nevertheless do not solve QUATH with the required parameters.<br/>
<br/>
It would be great if the community could work towards strengthening the evidence we already have for this task to be hard, either phrased as a sampling experiment or together with the verification test.<br/>
<br/>
Finally, I think this is an exciting time for quantum computing and to witness this landmark event. It may not be the first probe of an experiment that is "hard" to classically simulate, since there are many quantum experiments that are beyond the reach of current classical simulations, but the inherent programmability and control present in the experimental system is what enables the tools of complexity theory to be applied to the problem. A thought that fascinates me is the idea that we may be exploring quantum mechanics in a regime never probed this carefully before, the "high complexity regime" of quantum mechanics. One imagines there are important lessons in physics here.<br/>
<br/></div>
    </content>
    <updated>2019-10-03T19:41:00Z</updated>
    <published>2019-10-03T19:41:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-10-06T10:24:02Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=18199</id>
    <link href="https://gilkalai.wordpress.com/2019/10/03/noisy-quantum-circuits-how-do-we-know-that-we-have-robust-experimental-outcomes-at-all-and-do-we-care/" rel="alternate" type="text/html"/>
    <title>Noisy quantum circuits: how do we know that we have robust experimental outcomes at all? (And do we care?)</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">In a recent post we discussed Google’s claim of achieving “quantum supremacy” and my reasons to think that these claims will not stand. (See also this comment for necessary requirements from a quantum supremacy experiment.) This debate gives a good … <a href="https://gilkalai.wordpress.com/2019/10/03/noisy-quantum-circuits-how-do-we-know-that-we-have-robust-experimental-outcomes-at-all-and-do-we-care/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>In <a href="https://gilkalai.wordpress.com/2019/09/23/quantum-computers-amazing-progress-google-ibm-and-extraordinary-but-probably-false-supremacy-claims-google/">a recent post we discussed Google’s claim of achieving “quantum supremacy” and my reasons to think that these claims will not stand.</a> (See also <a href="https://gilkalai.wordpress.com/2019/09/23/quantum-computers-amazing-progress-google-ibm-and-extraordinary-but-probably-false-supremacy-claims-google/#comment-61043">this comment</a> for necessary requirements from a quantum supremacy experiment.) This debate gives a good opportunity to discuss some conceptual issues regarding sampling, probability distributions, statistics, and computational complexity. This time we will discuss <span style="color: #ff0000;">chaotic behavior vs. robust experimental outcomes.</span></p>
<p>On unrelated matter, I just heard Shachar Lovett’s very beautiful TCS+ lecture on the sunflower conjecture (<a href="https://gilkalai.wordpress.com/2019/08/23/amazing-ryan-alweiss-shachar-lovett-kewen-wu-jiapeng-zhang-made-dramatic-progress-on-the-sunflower-conjecture/">see this post</a> on the Alweiss, Lovett, Wu, and Zhang’s breakthrough). You can see the lecture and many others on the <a href="https://www.youtube.com/user/TCSplusSeminars/videos">TCS+ you tube channel</a>.</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/10/cern-slide-30c.png"><img alt="" class="alignnone size-full wp-image-18240" height="449" src="https://gilkalai.files.wordpress.com/2019/10/cern-slide-30c.png?w=640&amp;h=449" width="640"/></a></p>
<p style="text-align: center;"><span style="color: #ff0000;"><span style="color: #993366;">Slide 30 from my August, ’19 CERN lecture: predictions of near-term experiments. (Here is the</span> <a href="https://gilkalai.files.wordpress.com/2019/09/cern.pptx">full powerpoint presentation</a><span style="color: #993366;">.) In this post we mainly</span> <strong>discuss</strong> <strong>point b) about chaotic behavior. </strong><span style="color: #800080;">See also <a href="https://arxiv.org/abs/1908.02499">my paper: The argument against quantum computers</a>.</span></span></p>
<p>Consider an experiment aimed for establishing quantum supremacy: your quantum computer produced a sample <img alt="x_i" class="latex" src="https://s0.wp.com/latex.php?latex=x_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_i"/> which is a 0-1 string of length <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> from a certain distribution <img alt="D_i" class="latex" src="https://s0.wp.com/latex.php?latex=D_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D_i"/>. The research assumption is that <img alt="D_i" class="latex" src="https://s0.wp.com/latex.php?latex=D_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D_i"/>  is close enough to a fixed distribution <img alt="D" class="latex" src="https://s0.wp.com/latex.php?latex=D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D"/> (<img alt="D" class="latex" src="https://s0.wp.com/latex.php?latex=D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D"/> accounts for the computing process and the noise) which is very hard to be demonstrated on a classical computer. By looking at a large number of samples you can perform a statistical test on the samples to verify that they were (approximately) sampled from <img alt="D" class="latex" src="https://s0.wp.com/latex.php?latex=D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D"/>, or at least that they were sampled from a probability distribution that is very hard to be computed on a classical computer!</p>
<p>But, is it possible that all the distributions <img alt="D_i" class="latex" src="https://s0.wp.com/latex.php?latex=D_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D_i"/>‘s are very different? Namely that each sample is taken from a completely different distribution? More formally, is it possible  that under a correct modeling of the device for two different samples <img alt="x_i" class="latex" src="https://s0.wp.com/latex.php?latex=x_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_i"/> and <img alt="x_j" class="latex" src="https://s0.wp.com/latex.php?latex=x_j&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_j"/>, <img alt="D_i" class="latex" src="https://s0.wp.com/latex.php?latex=D_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D_i"/> has a very small correlation with <img alt="D_j" class="latex" src="https://s0.wp.com/latex.php?latex=D_j&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D_j"/>? In this case we say that the experiment outcomes are <strong>not robust</strong> and that the situation is <strong>chaotic</strong>.</p>
<p>Here are a couple of questions that I propose to think about:</p>
<ul>
<li>How do we test robustness?</li>
<li>Do the supremacy experiments require that the experiment is robust?</li>
<li>If, after many samples, you reach a probability distribution that require exponential time on a classical computer should you worry about the question whether the experiment is robust?</li>
<li><span style="color: #0000ff;">Do the 10,000,000 samples for the Google 53-qubit experiment represent a robust sampling experiment?</span></li>
</ul>
<p> </p></div>
    </content>
    <updated>2019-10-03T19:23:25Z</updated>
    <published>2019-10-03T19:23:25Z</published>
    <category term="Computer Science and Optimization"/>
    <category term="Quantum"/>
    <category term="chaos"/>
    <category term="chaos and computation"/>
    <category term="quantum supremacy"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-10-07T01:59:52Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/10/03/faculty-position-at-university-of-minnesota-twin-cities-apply-by-november-1-2019/</id>
    <link href="https://cstheory-jobs.org/2019/10/03/faculty-position-at-university-of-minnesota-twin-cities-apply-by-november-1-2019/" rel="alternate" type="text/html"/>
    <title>Faculty position at University of Minnesota-Twin Cities (apply by November 1, 2019)</title>
    <summary>The Department of Computer Science &amp; Engineering at the University of Minnesota-Twin Cities is hiring to fill multiple tenure-track positions at the assistant professor level, although higher levels of appointments may be considered when commensurate with experience and accomplishments. One of the areas of interest is theoretical computer science. Website: https://www.cs.umn.edu/news/cse-now-hiring-new-faculty Email: csciadmin@umn.edu</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Department of Computer Science &amp; Engineering at the University of Minnesota-Twin Cities is hiring to fill multiple tenure-track positions at the assistant professor level, although higher levels of appointments may be considered when commensurate with experience and accomplishments. One of the areas of interest is theoretical computer science.</p>
<p>Website: <a href="https://www.cs.umn.edu/news/cse-now-hiring-new-faculty">https://www.cs.umn.edu/news/cse-now-hiring-new-faculty</a><br/>
Email: csciadmin@umn.edu</p></div>
    </content>
    <updated>2019-10-03T18:02:59Z</updated>
    <published>2019-10-03T18:02:59Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-10-07T02:00:01Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/10/03/faculty-at-virginia-tech-apply-by-december-31-2019/</id>
    <link href="https://cstheory-jobs.org/2019/10/03/faculty-at-virginia-tech-apply-by-december-31-2019/" rel="alternate" type="text/html"/>
    <title>Faculty at Virginia Tech (apply by December 31, 2019)</title>
    <summary>http://careers.pageuppeople.com/968/cw/en-us/job/510994 Website: http://www.cs.vt.edu/ Email: facdev@cs.vt.edu</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="http://careers.pageuppeople.com/968/cw/en-us/job/510994">http://careers.pageuppeople.com/968/cw/en-us/job/510994</a></p>
<p>Website: <a href="http://www.cs.vt.edu/">http://www.cs.vt.edu/</a><br/>
Email: facdev@cs.vt.edu</p></div>
    </content>
    <updated>2019-10-03T14:24:41Z</updated>
    <published>2019-10-03T14:24:41Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-10-07T02:00:01Z</updated>
    </source>
  </entry>

  <entry>
    <id>http://offconvex.github.io/2019/10/03/NTK/</id>
    <link href="http://offconvex.github.io/2019/10/03/NTK/" rel="alternate" type="text/html"/>
    <title>Ultra-Wide Deep Nets and Neural Tangent Kernel (NTK)</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>(Crossposted <a href="https://blog.ml.cmu.edu/2019/10/03/ultra-wide-deep-nets-and-the-neural-tangent-kernel-ntk/">at CMU ML</a>.)</p>

<p>Traditional wisdom in machine learning holds that there is a careful trade-off between training error and generalization gap. There is a “sweet spot” for the model complexity such that the model (i) is big enough to achieve reasonably good training error, and (ii) is small enough so that the generalization gap - the difference between test error and training error - can be controlled. A smaller model would give a larger training error, while making the model bigger would result in a larger generalization gap, both leading to larger test errors. This is described by the classical U-shaped curve for the test error when the model complexity varies (see Figure 1(a)).</p>

<p>However, it is common nowadays to use highly complex over-parameterized models like deep neural networks. These models are usually trained to achieve near zero error on the training data, and yet they still have remarkable performance on test data. <a href="https://arxiv.org/abs/1812.11118">Belkin et al. (2018)</a> characterized this phenomenon by a “double descent” curve which extends the classical U-shaped curve. It was observed that, as one increases the model complexity past the point where it can perfectly fits the training data (i.e., <em>interpolation</em> regime is reached), test error continues to drop! Interestingly, the best test error is often achieved by the largest model, which goes against the classical intuition about the “sweet spot.” The following figure from <a href="https://arxiv.org/abs/1812.11118">Belkin et al. (2018)</a> illustrates this phenomenon.</p>

<div style="text-align: center;">
<img src="http://www.offconvex.org/assets/belkinfig.jpg" style="width: 700px;"/>
<br/>
<b>Figure 1.</b> Effect of increased model complexity on generalization: traditional belief vs actual practice. 
</div>
<p><br/></p>

<p>Consequently one suspects that the training algorithms used in deep learning - (stochastic) gradient descent and its variants - somehow implicitly constrain the complexity of trained networks (i.e., “true number” of parameters), thus leading to a small generalization gap.</p>

<p>Since larger models often give better performance in practice, one may naturally wonder:</p>

<blockquote>
  <p>How does an infinitely wide net perform?</p>
</blockquote>

<p>The answer to this question corresponds to the right end of Figure 1(b). This blog post is about a model that has attracted a lot of attention in the past year:  deep learning in the regime where the width - namely, the number of channels in convolutional filters, or the number of neurons in fully-connected internal layers - goes to infinity. At first glance this approach may seem hopeless for both practitioners and theorists: all the computing power in the world is insufficient to train an infinite network, and theorists already have their hands full trying to figure out finite ones. But in math/physics there is a tradition of deriving insights into questions by studying them in the infinite limit, and indeed here too the infinite limit becomes easier for theory.</p>

<p>Experts may recall the connection between infinitely wide neural networks and kernel methods from 25 years ago by <a href="https://www.cs.toronto.edu/~radford/pin.abstract.html">Neal (1994)</a> as well as the recent extensions by <a href="https://openreview.net/forum?id=B1EA-M-0Z">Lee et al. (2018)</a> and <a href="https://arxiv.org/abs/1804.11271">Matthews et al. (2018)</a>. These kernels correspond to infinitely wide deep networks whose all parameters are chosen randomly, and <em>only the top (classification) layer is trained</em> by gradient descent. Specifically, if $f(\theta,x)$ denotes the output of the network on input $x$ where $\theta$ denotes the parameters in the network, and $\mathcal{W}$ is an initialization distribution over $\theta$ (usually Gaussian with proper scaling), then the corresponding kernel is

where $x,x’$ are two inputs.</p>

<p>What about the more usual scenario when <em>all layers are trained</em>? Recently, <a href="https://arxiv.org/pdf/1806.07572.pdf">Jacot et al. (2018)</a> first observed that this is also related to a kernel named <em>neural tangent kernel (NTK)</em>, which has the form
</p>

<p>The key difference between the NTK and previously proposed kernels is that the NTK is defined through the inner product between the gradients of the network outputs with respect to the network parameters. This gradient arises from the use of the gradient descent algorithm. Roughly speaking, the following conclusion can be made for a sufficiently wide deep neural network trained by gradient descent:</p>

<blockquote>
  <p>A properly randomly initialized <strong>sufficiently wide</strong> deep neural network <strong>trained by gradient descent</strong> with infinitesimal step size (a.k.a. gradient flow) is <strong>equivalent to a kernel regression predictor</strong> with a <strong>deterministic</strong> kernel called <em>neural tangent kernel (NTK)</em>.</p>
</blockquote>

<p>This was more or less established in the original paper of <a href="https://arxiv.org/pdf/1806.07572.pdf">Jacot et al. (2018)</a>, but they required the width of every layer to go to infinity in a sequential order. In <a href="https://arxiv.org/abs/1904.11955">our recent paper</a> with Sanjeev Arora, Zhiyuan Li, Ruslan Salakhutdinov and Ruosong Wang, we improve this result to the non-asymptotic setting where the width of every layer only needs to be greater than a certain finite threshold.</p>

<p>In the rest of this post we will first explain how NTK arises and the idea behind the proof of the equivalence between wide neural networks and NTKs. Then we will present experimental results showing how well infinitely wide neural networks perform in practice.</p>

<h2 id="how-does-neural-tangent-kernel-arise">How Does Neural Tangent Kernel Arise?</h2>

<p>Now we describe how training an ultra-wide fully-connected neural network leads to kernel regression with respect to the NTK. A more detailed treatment is given in <a href="https://arxiv.org/abs/1904.11955">our paper</a>. We first specify our setup. We consider the standard supervised learning setting, in which we are given $n$ training data points ${(x_i,y_i)}_{i=1}^n \subset \mathbb{R}^{d}\times\mathbb{R}$ drawn from some underlying distribution and wish to find a function that given the input $x$ predicts the label $y$ well on the data distribution. We consider a fully-connected neural network defined by $f(\theta, x)$, where $\theta$ is the collection of all the parameters in the network and $x$ is the input. For simplicity we only consider neural network with a single output, i.e., $f(\theta, x) \in \mathbb{R}$, but the generalization to multiple outputs is straightforward.</p>

<p>We consider training the neural network by minimizing the quadratic loss over training data:

Gradient descent with infinitesimally small learning rate (a.k.a. gradient flow) is applied on this loss function $\ell(\theta)$:                                                                               
where $\theta(t)$ denotes the parameters at time $t$.</p>

<p>Let us define some useful notation. Denote $u_i = f(\theta, x_i)$, which is the network’s output on $x_i$. We let $u=(u_1, \ldots, u_n)^\top \in \mathbb{R}^n$ be the collection of the network outputs on all training inputs. We use the time index $t$ for all variables that depend on time, e.g. $u_i(t), u(t)$, etc. With this notation the training objective can be conveniently written as $\ell(\theta) = \frac12 |u-y|_2^2$.</p>

<p>Using simple differentiation, one can obtain the dynamics of $u(t)$ as follows: (see <a href="https://arxiv.org/abs/1904.11955">our paper</a> for a proof)​

where $H(t)$ is an $n\times n$ positive semidefinite matrix whose $(i, j)$-th entry is $\left\langle \frac{\partial f(\theta(t), x_i)}{\partial\theta}, \frac{\partial f(\theta(t), x_j)}{\partial\theta} \right\rangle$.</p>

<p>Note that $H(t)$ is the <em>kernel matrix</em> of the following (time-varying) kernel $ker_t(\cdot,\cdot)$ evaluated on the training data:

In this kernel an input $x$ is mapped to a feature vector $\phi_t(x) = \frac{\partial f(\theta(t), x)}{\partial\theta}$ defined through the gradient of the network output with respect to the parameters at time $t$.</p>

<p>###The Large Width Limit</p>

<p>Up to this point we haven’t used the property that the neural network is very wide. The formula for the evolution of $u(t)$ is valid in general. In the large width limit, it turns out that the time-varying kernel $ker_t(\cdot,\cdot)$ is (with high probability) always close to a <em>deterministic</em> fixed kernel $ker_{\mathsf{NTK}}(\cdot,\cdot)$, which is the <strong>neural tangent kernel (NTK)</strong>. This property is proved in two steps, both requiring the large width assumption:</p>

<ol>
  <li>
    <p><strong>Step 1: Convergence to the NTK at random initialization.</strong> Suppose that the network parameters at initialization ($t=0$), $\theta(0)$, are i.i.d. Gaussian. Then under proper scaling, for any pair of inputs $x, x’$, it can be shown that the random variable $ker_0(x,x’)$, which depends on the random initialization $\theta(0)$, converges in probability to the deterministic value $ker_{\mathsf{NTK}}(x,x’)$, in the large width limit.</p>

    <p>(Technically speaking, there is a subtlety about how to define the large width limit. <a href="https://arxiv.org/pdf/1806.07572.pdf">Jacot et al. (2018)</a> gave a proof for the sequential limit where the width of every layer goes to infinity one by one. Later <a href="https://arxiv.org/abs/1902.04760">Yang (2019)</a> considered a setting where all widths go to infinity at the same rate. <a href="https://arxiv.org/abs/1904.11955">Our paper</a> improves them to the non-asymptotic setting, where we only require all layer widths to be larger than a finite threshold, which is the weakest notion of limit.)</p>
  </li>
  <li>
    <p><strong>Step 2: Stability of the kernel during training.</strong> Furthermore, the kernel <em>barely changes</em> during training, i.e., $ker_t(x,x’) \approx ker_0(x,x’)$ for all $t$. The reason behind this is that the weights do not move much during training, namely $\frac{|\theta(t) - \theta(0)|}{|\theta(0)|} \to 0$ as width $\to\infty$. Intuitively, when the network is sufficiently wide, each individual weight only needs to move a tiny amount in order to have a non-negligible change in the network output. This turns out to be true when the network is trained by gradient descent.</p>
  </li>
</ol>

<p>Combining the above two steps, we conclude that for any two inputs $x, x’$, with high probability we have

As we have seen, the dynamics of gradient descent is closely related to the time-varying kernel $ker_t(\cdot,\cdot)$. Now that we know that $ker_t(\cdot,\cdot)$ is essentially the same as the NTK, with a few more steps, we can eventually establish the equivalence between trained neural network and NTK: the final learned neural network at time $t=\infty$, denoted by $f_{\mathsf{NN}}(x) = f(\theta(\infty), x)$, is equivalent to the <em>kernel regression</em> solution with respect to the NTK. Namely, for any input $x$ we have

where $ker_{\mathsf{NTK}}(x, X) = (ker_{\mathsf{NTK}}(x, x_1), \ldots, ker_{\mathsf{NTK}}(x, x_n))^\top \in \mathbb{R}^n$, and $ker_{\mathsf{NTK}}(X, X) $ is an $n\times n$ matrix whose $(i, j)$-th entry is $ker_{\mathsf{NTK}}(x_i, x_j)$.</p>

<p>(In order to not have a bias term in the kernel regression solution we also assume that the network output at initialization is small: $f(\theta(0), x)\approx0$; this can be ensured by e.g. scaling down the initialization magnitude by a large constant, or replicating a network with opposite signs on the top layer at initialization.)</p>

<h2 id="how-well-do-infinitely-wide-neural-networks-perform-in-practice">How Well Do Infinitely Wide Neural Networks Perform in Practice?</h2>

<p>Having established this equivalence, we can now address the question of how well infinitely wide neural networks perform in practice — we can just evaluate the kernel regression predictors using the NTKs! We test NTKs on a standard image classification dataset, CIFAR-10. Note that for image datasets, one needs to use convolutional neural networks (CNNs) to achieve good performance. Therefore, we derive an extension of NTK, <em>convolutional neural tangent kernels (CNTKs)</em> and test their performance on CIFAR-10. In the table below, we report the classification accuracies of different CNNs and CNTKs:</p>

<div style="text-align: center;">
<img src="http://www.offconvex.org/assets/cntk_acc.jpeg" style="width: 700px;"/>
<br/>
</div>

<p>Here CNN-Vs are vanilla practically-wide CNNs (without pooling), and CNTK-Vs are their NTK counterparts. We also test CNNs with global average pooling (GAP), denotes above as CNN-GAPs, and their NTK counterparts, CNTK-GAPs. For all experiments, we turn off batch normalization, data augmentation, etc., and only use SGD to train CNNs (for CNTKs, we use the closed-form formula of kernel regression).</p>

<p>We find that CNTKs are actually very power kernels. The best kernel we find, 11-layer CNTK with GAP, achieves 77.43% classification accuracy on CIFAR-10. This results in a significant new benchmark for performance of a pure kernel-based method on CIFAR-10, being 10% higher than methods reported by <a href="https://openreview.net/forum?id=B1g30j0qF7">Novak et al. (2019)</a>. The CNTKs also perform similarly to their CNN counterparts. This means that ultra-wide CNNs can achieve reasonable test performance on CIFAR-10.</p>

<p>It is also interesting to see that the global average pooling operation can significantly increase the classification accuracy for both CNNs and CNTKs. From this observation, we suspect that many techniques that improve the performance of neural networks are in some sense universal, i.e., these techniques might benefit kernel methods as well.</p>

<h2 id="concluding-thoughts">Concluding Thoughts</h2>

<p>Understanding the surprisingly good performance of over-parameterized deep neural networks is definitely a challenging theoretical question. Now, at least we have a better understanding of a class of ultra-wide neural networks: they are captured by neural tangent kernels! A hurdle that remains is that the classic generalization theory for kernels is still incapable of giving realistic bounds for generalization. But at least we now know that better understanding of kernels can lead to better understanding of deep nets.</p>

<p>Another fruitful direction is to “translate” different architectures/tricks of neural networks to kernels and to check their practical performance. We have found that global average pooling can significantly boost the performance of kernels, so we hope other tricks like batch normalization, dropout, max-pooling, etc. can also benefit kernels. Similarly, one can try to translate other architectures like recurrent neural networks, graph neural networks, and transformers, to kernels as well.</p>

<p>Our study also shows that there is a performance gap between infinitely wide networks and finite ones. How to explain this gap is an important theoretical question.</p></div>
    </summary>
    <updated>2019-10-03T10:00:00Z</updated>
    <published>2019-10-03T10:00:00Z</published>
    <source>
      <id>http://offconvex.github.io/</id>
      <author>
        <name>Off the Convex Path</name>
      </author>
      <link href="http://offconvex.github.io/" rel="alternate" type="text/html"/>
      <link href="http://offconvex.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Algorithms off the convex path.</subtitle>
      <title>Off the convex path</title>
      <updated>2019-10-06T23:41:15Z</updated>
    </source>
  </entry>
</feed>
