<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2020-09-23T22:22:00Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/145</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/145" rel="alternate" type="text/html"/>
    <title>TR20-145 |  An Improved Exponential-Time Approximation Algorithm for Fully-Alternating Games Against Nature | 

	Andrew Drucker</title>
    <summary>"Games against Nature" [Papadimitriou '85] are two-player games of perfect information, in which one player's moves are made randomly (here, uniformly); the final payoff to the non-random player is given by some $[0, 1]$-valued function of the move history.  Estimating the value of such games under optimal play, and computing near-optimal strategies, is an important goal in the study of decision-making under uncertainty, and has seen significant research in AI and allied areas [Hnich, Rossi, Tarim, Prestwich '11], with only experimental evaluation of most algorithms' performance.  The problem's PSPACE-completeness does not rule out nontrivial algorithms.  Improved algorithms with theoretical guarantees are known in various cases where the payoff function $F$ has special structure, and Littman, Majercik, and Pitassi [LMP'01] give a sampling-based improved algorithm for general $F$, for turn-orders which restrict the number of non-random player strategies.

We study the case of general $F$ for which the players strictly alternate with binary moves $(w_1, r_1, w_2, r_2, \ldots, w_{n/2}, r_{n/2})$---for which the approach of [LMP'01] does not improve over brute force.  We give a randomized algorithm to approximate the value of such games under optimal play, and to execute near-optimal strategies. Our algorithm achieves exponential savings over brute-force, making $2^{(1 - \delta) n}$ queries to $F$ for some absolute constant $\delta &gt; 0$, and certifies a lower bound $\hat{v}$ on the game value $v$ with additive expected error bounded as $E[v - \hat{v}] \leq \exp(-\Omega(n))$.  (On the downside, $\delta$ is tiny and the algorithm uses exponential space.)

Our algorithm is recursive, and bootstraps a "base case" algorithm for fixed-size inputs.  The method of recursive composition used, the specific base-case guarantees needed, and the steps to establish these guarantees are interesting and, we feel, likely to find uses beyond the present work.</summary>
    <updated>2020-09-23T21:48:34Z</updated>
    <published>2020-09-23T21:48:34Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-09-23T22:20:37Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-7113260074896603448</id>
    <link href="https://blog.computationalcomplexity.org/feeds/7113260074896603448/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/09/remembering-2000.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7113260074896603448" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7113260074896603448" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/09/remembering-2000.html" rel="alternate" type="text/html"/>
    <title>Remembering 2000</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="http://www.cs.cmu.edu/~FOCS2000/">FOCS 2000</a> took place in Redondo Beach, just south of Los Angeles, November 12-14. Certainly some great results such as the Reingold-Vadhan-Wigderson <a href="https://doi.org/10.1109/SFCS.2000.892006">Zig-Zag Graph Product Expander construction</a> that would lead to Omer Reingold's <a href="https://blog.computationalcomplexity.org/2014/02/favorite-theorems-connecting-in-log.html">Undirected Connectivity in Log Space</a>. Mostly though I remember the discussions about the presidential election held the week before and whether we might find out our next president during the conference. Spoiler alert: <a href="https://en.wikipedia.org/wiki/2000_United_States_presidential_election_recount_in_Florida">We didn't</a>. </p><p>Consider the following viewpoints for a person X</p><p>1. Did X support Bush or Gore?</p><p>2. Did X interpret the rules of the election that Bush won or Gore won?</p><p>These should be independent events. Your interpretation of the rules should not depend on who you supported. But in fact they were nearly perfectly correlated. Whether you were a politician, a newspaper editorial page writer, a supreme court justice, a computer scientist or pretty much everyone else, if you supported Gore, you believed he won the election and vice-versa. Everyone had their logic why they were right and I'm sure my readers who remember that election still believe their logic was correct. </p><p>As this upcoming election gets messy, as it already has, take care with trying to justify your desired endgame by choosing the logic that makes it work. Would you use the same logic if the candidates were reversed? Everyone says "yes" but it's rarely true. Just like Mitch McConnell, you'll just find some excuse why the opposite situation is different. Trust me, my logic is impeccable. </p></div>
    </content>
    <updated>2020-09-23T21:33:00Z</updated>
    <published>2020-09-23T21:33:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2020-09-23T21:33:17Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=20259</id>
    <link href="https://gilkalai.wordpress.com/2020/09/23/to-cheer-you-up-in-difficult-times-12-asaf-ferber-and-david-conlon-found-new-lower-bounds-for-diagonal-ramsey-numbers/" rel="alternate" type="text/html"/>
    <title>To cheer you up in difficult times 12:  Asaf Ferber and David Conlon found new lower bounds for diagonal Ramsey numbers</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Lower bounds for multicolor Ramsey numbers The Ramsey number r(t; ℓ) is the smallest natural number n such that every ℓ-coloring of the edges of the complete graph contains a monochromatic . (r(t;2) is often denoted by R(t,t) and r(t;3) … <a href="https://gilkalai.wordpress.com/2020/09/23/to-cheer-you-up-in-difficult-times-12-asaf-ferber-and-david-conlon-found-new-lower-bounds-for-diagonal-ramsey-numbers/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><h2 class="title mathjax"><a href="https://arxiv.org/abs/2009.10458">Lower bounds for multicolor Ramsey numbers</a></h2>
<p>The Ramsey number <em>r(t; ℓ)</em> is the smallest natural number <em>n</em> such that every ℓ-coloring of the edges of the complete graph <img alt="K_n" class="latex" src="https://s0.wp.com/latex.php?latex=K_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K_n"/> contains a monochromatic <img alt="K_t" class="latex" src="https://s0.wp.com/latex.php?latex=K_t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K_t"/>. (<em>r(t;2)</em> is often denoted by<em> R(t,t)</em> and <em>r(t;3)</em> by R<em>(t,t,t)</em> etc.) <a href="https://en.wikipedia.org/wiki/Ramsey%27s_theorem">Famously</a>, <em>R(3,3)=6</em>; <em>R(4,4)=18</em>;  and <em>R(3,3,3)=17</em>. Understanding <em>R(t,t)</em> is among the most famous problems in combinatorics. (Understanding if r(3; <em> ℓ</em>) is exponential or superexponential in<em> ℓ</em> is also a very famous problem.)</p>
<p>It is known since the 1940s that <img alt="t/2 +o(1) \le log_2 R(t,t) \le 2t" class="latex" src="https://s0.wp.com/latex.php?latex=t%2F2+%2Bo%281%29+%5Cle+log_2+R%28t%2Ct%29+%5Cle+2t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t/2 +o(1) \le log_2 R(t,t) \le 2t"/>.</p>
<p>Lower bounds for <em>R(t,t)</em> where used by Lefmann in 1987 to give lower bounds on <em>r(t; ℓ)</em> for <em> ℓ</em>&gt;2. Asaf Ferber and David Conlon gave now <span style="color: #ff0000;"><strong>exponential</strong></span> improvement. This is truly remarkable and <a href="https://arxiv.org/abs/2009.10458">the paper is just 4-page long!</a> congratulations Asaf and David!</p>
<p>Expect more cheering news of discrete geometry nature from Oberwolfach. (I take part remotely in the traditional meeting on Discrete and computational geometry, see pictures below).</p>
<p>Update: <a href="https://anuragbishnoi.wordpress.com/2020/09/23/improved-lower-bounds-for-multicolour-diagonal-ramsey-numbers/">An excellent blog post on Anurag math blog.</a> Anurag describes in details the construction, describes the connections with finite geometries, and improves the construction to get a better result.</p>
<p><a href="https://gilkalai.files.wordpress.com/2020/09/pak.png"><img alt="" class="alignnone size-medium wp-image-20264" height="188" src="https://gilkalai.files.wordpress.com/2020/09/pak.png?w=300&amp;h=188" width="300"/></a> <a href="https://gilkalai.files.wordpress.com/2020/09/ow2.png"><img alt="" class="alignnone size-medium wp-image-20265" height="188" src="https://gilkalai.files.wordpress.com/2020/09/ow2.png?w=300&amp;h=188" width="300"/></a></p></div>
    </content>
    <updated>2020-09-23T11:24:44Z</updated>
    <published>2020-09-23T11:24:44Z</published>
    <category term="Combinatorics"/>
    <category term="Asaf Ferber"/>
    <category term="David Conlon"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2020-09-23T22:20:40Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.10709</id>
    <link href="http://arxiv.org/abs/2009.10709" rel="alternate" type="text/html"/>
    <title>Fast Black-Box Quantum State Preparation</title>
    <feedworld_mtime>1600819200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bausch:Johannes.html">Johannes Bausch</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.10709">PDF</a><br/><b>Abstract: </b>Quantum state preparation is an important ingredient for other higher-level
quantum algorithms, such as Hamiltonian simulation, or for loading
distributions into a quantum device to be used e.g. in the context of
optimization tasks such as machine learning. Starting with a generic "black
box" method devised by Grover in 2000, which employs amplitude amplification to
load coefficients calculated by an oracle, there has been a long series of
results and improvements with various additional conditions on the amplitudes
to be loaded, culminating in Sanders et al.'s work which avoids almost all
arithmetic during the preparation stage. In this work, we improve upon this
routine in two aspects: we reduce the required qubit overhead from $g$ to
$\log_2(g)$ in the bit precision $g$ (at a cost of slightly increasing the
count of non-Clifford operations), and show how various sets of $N$
coefficients can be loaded significantly faster than in $O(\sqrt N)$ rounds of
amplitude amplification - up to only $O(1)$ many - by bootstrapping the
procedure with an optimised initial state.
</p></div>
    </summary>
    <updated>2020-09-23T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-09-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.10677</id>
    <link href="http://arxiv.org/abs/2009.10677" rel="alternate" type="text/html"/>
    <title>On the Mysteries of MAX NAE-SAT</title>
    <feedworld_mtime>1600819200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Brakensiek:Joshua.html">Joshua Brakensiek</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Huang:Neng.html">Neng Huang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Potechin:Aaron.html">Aaron Potechin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zwick:Uri.html">Uri Zwick</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.10677">PDF</a><br/><b>Abstract: </b>MAX NAE-SAT is a natural optimization problem, closely related to its
better-known relative MAX SAT. The approximability status of MAX NAE-SAT is
almost completely understood if all clauses have the same size $k$, for some
$k\ge 2$. We refer to this problem as MAX NAE-$\{k\}$-SAT. For $k=2$, it is
essentially the celebrated MAX CUT problem. For $k=3$, it is related to the MAX
CUT problem in graphs that can be fractionally covered by triangles. For $k\ge
4$, it is known that an approximation ratio of $1-\frac{1}{2^{k-1}}$, obtained
by choosing a random assignment, is optimal, assuming $P\ne NP$. For every
$k\ge 2$, an approximation ratio of at least $\frac{7}{8}$ can be obtained for
MAX NAE-$\{k\}$-SAT. There was some hope, therefore, that there is also a
$\frac{7}{8}$-approximation algorithm for MAX NAE-SAT, where clauses of all
sizes are allowed simultaneously.
</p>
<p>Our main result is that there is no $\frac{7}{8}$-approximation algorithm for
MAX NAE-SAT, assuming the unique games conjecture (UGC). In fact, even for
almost satisfiable instances of MAX NAE-$\{3,5\}$-SAT (i.e., MAX NAE-SAT where
all clauses have size $3$ or $5$), the best approximation ratio that can be
achieved, assuming UGC, is at most $\frac{3(\sqrt{21}-4)}{2}\approx 0.8739$.
Using calculus of variations, we extend the analysis of O'Donnell and Wu for
MAX CUT to MAX NAE-$\{3\}$-SAT. We obtain an optimal algorithm, assuming UGC,
for MAX NAE-$\{3\}$-SAT, slightly improving on previous algorithms. The
approximation ratio of the new algorithm is $\approx 0.9089$.
</p>
<p>We complement our theoretical results with some experimental results. We
describe an approximation algorithm for almost satisfiable instances of MAX
NAE-$\{3,5\}$-SAT with a conjectured approximation ratio of 0.8728, and an
approximation algorithm for almost satisfiable instances of MAX NAE-SAT with a
conjectured approximation ratio of 0.8698.
</p></div>
    </summary>
    <updated>2020-09-23T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-09-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.10502</id>
    <link href="http://arxiv.org/abs/2009.10502" rel="alternate" type="text/html"/>
    <title>Computing $L(p,1)$-Labeling with Combined Parameters</title>
    <feedworld_mtime>1600819200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hanaka:Tesshu.html">Tesshu Hanaka</a>, Kazuma Kawai, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Ono:Hirotaka.html">Hirotaka Ono</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.10502">PDF</a><br/><b>Abstract: </b>Given a graph, an $L(p,1)$-labeling of the graph is an assignment $f$ from
the vertex set to the set of nonnegative integers such that for any pair of
vertices $(u,v),|f (u) - f (v)| \ge p$ if $u$ and $v$ are adjacent, and $f(u)
\neq f(v)$ if $u$ and $v$ are at distance $2$. The \textsc{$L(p,1)$-labeling}
problem is to minimize the span of $f$ (i.e.,$\max_{u\in V}(f(u)) - \min_{u\in
V}(f(u))+1$). It is known to be NP-hard even for graphs of maximum degree $3$
or graphs with tree-width 2, whereas it is fixed-parameter tractable with
respect to vertex cover number. Since vertex cover number is a kind of the
strongest parameter, there is a large gap between tractability and
intractability from the viewpoint of parameterization. To fill up the gap, in
this paper, we propose new fixed-parameter algorithms for
\textsc{$L(p,1)$-Labeling} by the twin cover number plus the maximum clique
size and by the tree-width plus the maximum degree. These algorithms reduce the
gap in terms of several combinations of parameters.
</p></div>
    </summary>
    <updated>2020-09-23T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-09-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.10408</id>
    <link href="http://arxiv.org/abs/2009.10408" rel="alternate" type="text/html"/>
    <title>Control dynamics using quantum memory</title>
    <feedworld_mtime>1600819200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Roget:Mathieu.html">Mathieu Roget</a>, Basile Herzog, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Molfetta:Giuseppe_Di.html">Giuseppe Di Molfetta</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.10408">PDF</a><br/><b>Abstract: </b>We propose a new quantum numerical scheme to control the dynamics of a
quantum walker in a two dimensional space-time grid. More specifically, we show
how, introducing a quantum memory for each of the spatial grid, this result can
be achieved simply by acting on the initial state of the whole system, and
therefore can be exactly controlled once for all. As example we prove
analytically how to encode in the initial state any arbitrary walker's mean
trajectory and variance. This brings significantly closer the possibility of
implementing dynamically interesting physics models on medium term quantum
devices, and introduces a new direction in simulating aspects of quantum field
theories (QFTs), notably on curved manifold.
</p></div>
    </summary>
    <updated>2020-09-23T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-09-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.10353</id>
    <link href="http://arxiv.org/abs/2009.10353" rel="alternate" type="text/html"/>
    <title>Discriminating Codes in Geometric Setups</title>
    <feedworld_mtime>1600819200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dey:Sanjana.html">Sanjana Dey</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Foucaud:Florent.html">Florent Foucaud</a>, Subhas C Nandy, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sen:Arunabha.html">Arunabha Sen</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.10353">PDF</a><br/><b>Abstract: </b>We study two geometric variations of the discriminating code problem. In the
\emph{discrete version}, a finite set of points $P$ and a finite set of objects
$S$ are given in $\mathbb{R}^d$. The objective is to choose a subset $S^*
\subseteq S$ of minimum cardinality such that the subsets $S_i^* \subseteq S^*$
covering $p_i$, satisfy $S_i^*\neq \emptyset$ for each $i=1,2,\ldots, n$, and
$S_i^* \neq S_j^*$ for each pair $(i,j)$, $i \neq j$. In the \emph{continuous
version}, the solution set $S^*$ can be chosen freely among a (potentially
infinite) class of allowed geometric objects.
</p>
<p>In the 1-dimensional case ($d=1$), the points are placed on some fixed-line
$L$, and the objects in $S$ and $S^*$ are finite sub-segments of $L$ (called
intervals). We show that the discrete version of this problem is NP-complete.
This is somewhat surprising as the continuous version is known to be
polynomial-time solvable. This is also in contrast with most geometric covering
problems, which are usually polynomial-time solvable in 1D. We then design a
polynomial-time $2$-approximation algorithm for the 1-dimensional discrete
case. We also design a PTAS for both discrete and continuous cases when the
intervals are all required to have the same length.
</p>
<p>We then study the 2-dimensional case ($d=2$) for axis-parallel unit square
objects. We show that both continuous and discrete versions are NP-hard, and
design polynomial-time approximation algorithms with factors $4+\epsilon$ and
$32+\epsilon$, respectively (for every fixed $\epsilon&gt;0$).
</p></div>
    </summary>
    <updated>2020-09-23T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-09-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.10255</id>
    <link href="http://arxiv.org/abs/2009.10255" rel="alternate" type="text/html"/>
    <title>A Low-Level Index for Distributed Logic Programming</title>
    <feedworld_mtime>1600819200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Thomas Prokosch <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.10255">PDF</a><br/><b>Abstract: </b>A distributed logic programming language with support for meta-programming
and stream processing offers a variety of interesting research problems, such
as: How can a versatile and stable data structure for the indexing of a large
number of expressions be implemented with simple low-level data structures? Can
low-level programming help to reduce the number of occur checks in Robinson's
unification algorithm? This article gives the answers.
</p></div>
    </summary>
    <updated>2020-09-23T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-09-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.10217</id>
    <link href="http://arxiv.org/abs/2009.10217" rel="alternate" type="text/html"/>
    <title>A Faster Interior Point Method for Semidefinite Programming</title>
    <feedworld_mtime>1600819200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jiang:Haotian.html">Haotian Jiang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kathuria:Tarun.html">Tarun Kathuria</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lee:Yin_Tat.html">Yin Tat Lee</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Padmanabhan:Swati.html">Swati Padmanabhan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Song:Zhao.html">Zhao Song</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.10217">PDF</a><br/><b>Abstract: </b>Semidefinite programs (SDPs) are a fundamental class of optimization problems
with important recent applications in approximation algorithms, quantum
complexity, robust learning, algorithmic rounding, and adversarial deep
learning. This paper presents a faster interior point method to solve generic
SDPs with variable size $n \times n$ and $m$ constraints in time \begin{align*}
\widetilde{O}(\sqrt{n}( mn^2 + m^\omega + n^\omega) \log(1 / \epsilon) ),
\end{align*} where $\omega$ is the exponent of matrix multiplication and
$\epsilon$ is the relative accuracy. In the predominant case of $m \geq n$, our
runtime outperforms that of the previous fastest SDP solver, which is based on
the cutting plane method of Jiang, Lee, Song, and Wong [JLSW20].
</p>
<p>Our algorithm's runtime can be naturally interpreted as follows:
$\widetilde{O}(\sqrt{n} \log (1/\epsilon))$ is the number of iterations needed
for our interior point method, $mn^2$ is the input size, and $m^\omega +
n^\omega$ is the time to invert the Hessian and slack matrix in each iteration.
These constitute natural barriers to further improving the runtime of interior
point methods for solving generic SDPs.
</p></div>
    </summary>
    <updated>2020-09-23T01:24:26Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-09-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.10160</id>
    <link href="http://arxiv.org/abs/2009.10160" rel="alternate" type="text/html"/>
    <title>On rooted $k$-connectivity problems in quasi-bipartite digraphs</title>
    <feedworld_mtime>1600819200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nutov:Zeev.html">Zeev Nutov</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.10160">PDF</a><br/><b>Abstract: </b>We consider the directed Rooted Subset $k$-Edge-Connectivity problem: given a
set $T \subseteq V$ of terminals in a digraph $G=(V+r,E)$ with edge costs and
an integer $k$, find a min-cost subgraph of $G$ that contains $k$ edge disjoint
$rt$-paths for all $t \in T$. The case when every edge of positive cost has
head in $T$ admits a polynomial time algorithm due to Frank, and the case when
all positive cost edges are incident to $r$ is equivalent to the $k$-Multicover
problem. Recently, [Chan et al. APPROX20] obtained ratio $O(\ln k \ln |T|)$ for
quasi-bipartite instances, when every edge in $G$ has an end in $T+r$. We give
a simple proof for the same ratio for a more general problem of covering an
arbitrary $T$-intersecting supermodular set function by a minimum cost edge
set, and for the case when only every positive cost edge has an end in $T+r$.
</p></div>
    </summary>
    <updated>2020-09-23T01:22:05Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-09-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.10088</id>
    <link href="http://arxiv.org/abs/2009.10088" rel="alternate" type="text/html"/>
    <title>On the Theory of Modern Quantum Algorithms</title>
    <feedworld_mtime>1600819200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Jacob Biamonte <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.10088">PDF</a><br/><b>Abstract: </b>This dissertation unites variational computation with results and techniques
appearing in the theory of ground state computation. It should be readable by
graduate students.
</p>
<p>The topics covered include: Ising model reductions, stochastic versus quantum
processes on graphs, quantum gates and circuits as tensor networks, variational
quantum algorithms and Hamiltonian gadgets.
</p></div>
    </summary>
    <updated>2020-09-23T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-09-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=17612</id>
    <link href="https://rjlipton.wordpress.com/2020/09/22/puzzle-reviews-by-a-puzzle-writer/" rel="alternate" type="text/html"/>
    <title>Puzzle Reviews by a Puzzle Writer</title>
    <summary>Not puzzling reviews Princeton University Press page Jason Rosenhouse is professor in the Department of Mathematics at James Madison University. His research focuses on algebraic graph theory and analytic number theory involving exponential sums. The former includes a neat paper on expansion properties of a family of graphs associated to block designs, with two undergraduates […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Not puzzling reviews</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2020/09/jason-1.jpeg"><img alt="" class="alignright wp-image-17615" height="160" src="https://rjlipton.files.wordpress.com/2020/09/jason-1.jpeg?w=140&amp;h=160" width="140"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Princeton University Press <a href="https://press.princeton.edu/our-authors/rosenhouse-jason">page</a></font></td>
</tr>
</tbody>
</table>
<p>
Jason Rosenhouse is professor in the Department of Mathematics at James Madison University. His research focuses on algebraic graph theory and analytic number theory involving exponential sums.  The former includes a neat <a href="https://www.researchgate.net/publication/220620901_Expansion_Properties_Of_Levi_Graphs">paper</a> on expansion properties of a family of graphs associated to block designs, with two undergraduates among its authors.  But besides his “real” research, he has written a number of books on puzzles such as <i><a href="https://www.amazon.com/s?k=Jason+Rosenhouse&amp;i=stripbooks&amp;ref=nb_sb_noss_2">The Monty Hall Problem</a>: The Remarkable Story of Math’s Most Contentious Brain Teaser</i>. Soon his book <i><a href="https://www.amazon.co.uk/Games-Your-Mind-History-Puzzles/dp/0691174075">Games for Your Mind</a>: The History and Future of Logic Puzzles</i> is to be published.</p>
<p><a href="https://rjlipton.files.wordpress.com/2020/09/revbook-1.png"><img alt="" class="aligncenter size-thumbnail wp-image-17626" height="150" src="https://rjlipton.files.wordpress.com/2020/09/revbook-1.png?w=103&amp;h=150" width="103"/></a></p>
<p>
Today Ken and I thought we would highlight his recent review of a book on math puzzles.</p>
<p>
I have mixed feelings about puzzles. I like them, and am happy when I can understand their solution. I am even happier when I can solve them. I sometimes feel that I should spend my limited brain cycles on “real” problems. But puzzles are fun. </p>
<p>
Rosenhouse’s <a href="https://www.ams.org/journals/notices/202009/rnoti-p1382.pdf">review</a> is in the recent <em>Notices of the AMS</em> on the book <i><a href="https://bookstore.ams.org/prb-36">Bicycles or Unicycles</a>: A Collection of Intriguing Mathematical Puzzles</i>. This book, the “Bicycle Book,” is authored by Daniel Velleman and Stan Wagon.</p>
<p><a href="https://rjlipton.files.wordpress.com/2020/09/maabook.jpg"><img alt="" class="aligncenter wp-image-17617" height="145" src="https://rjlipton.files.wordpress.com/2020/09/maabook.jpg?w=101&amp;h=145" width="101"/></a></p>
<p>
Their book is a collection of <img alt="{3 \times 5 \times 7}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3+%5Ctimes+5+%5Ctimes+7%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{3 \times 5 \times 7}"/> mathematical puzzles. Rosenhouse likes their book, which means a lot coming from an author of so many puzzle books himself. </p>
<p>
</p><p/><h2> A Cool Problem </h2><p/>
<p/><p>
Rosenhouse presents this problem from the Bicycle Book. </p>
<blockquote><p><b> </b> <em> You are playing solitaire in the first quadrant of the Cartesian plane, the lower corner of which is shown in Figure 1. You begin with a single checker on square a1. On each turn, a legal move consists of removing one checker from the board and then placing two new checkers in the cells immediately above and to the right of the original checker. If either of those two cells is occupied, then the move is illegal, and a different checker must be selected for removal. </em>
</p></blockquote>
<p/><p>
<a href="https://rjlipton.files.wordpress.com/2020/09/solitairepuzzle.png"><img alt="" class="aligncenter size-full wp-image-17618" src="https://rjlipton.files.wordpress.com/2020/09/solitairepuzzle.png?w=600"/></a></p>
<p>
Show that you can never make all of the <img alt="{3 \times 3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3+%5Ctimes+3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{3 \times 3}"/> lower-left squares empty. This is a complexity question. You describe a computation and assert that certain states cannot be reached. The challenge is two-fold: </p>
<ol>
<li>
The computation is nondeterministic. There can be more than one next state. <p/>
</li><li>
The computation can reach infinitely many states. The task is to prove that no reachable state has the lower nine squares empty.
</li></ol>
<p>
</p><p/><h2> A Cool Solution </h2><p/>
<p/><p>
I must admit I read the solution before I tried to solve the puzzle. I did find an alternative solution. It was not as clever as the one from the book. Let’s look at that solution first. </p>
<p>
The idea is to assign <i>magic</i> values to each square on the checkerboard. The value of a state is the sum over all the values of squares with a checker. We need these to hold: </p>
<ol>
<li>
The value of the initial square is <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>. <p/>
</li><li>
The value of a move leaves the total sum over all the checkers the same. <p/>
</li><li>
The value of the squares <b>not</b> in the lower <img alt="{3 \times 3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3+%5Ctimes+3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{3 \times 3}"/> is less than <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>.
</li></ol>
<p>Then there can never be a reachable state that avoids all the lower <img alt="{3 \times 3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3+%5Ctimes+3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{3 \times 3}"/>. How can we do this? Assign the values as shown below. </p>
<p align="center"><img alt="\displaystyle  \begin{array}{ccccl} \vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \\ 1/8 &amp; 1/16 &amp; 1/32 &amp; 1/64 &amp; \cdots\\ 1/4 &amp; 1/8 &amp; 1/16 &amp; 1/32 &amp; \cdots\\ 1/2 &amp; 1/4 &amp; 1/8 &amp; 1/16 &amp; \cdots\\ 1 &amp; 1/2 &amp; 1/4 &amp; 1/8 &amp; \cdots \end{array} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Barray%7D%7Bccccl%7D+%5Cvdots+%26+%5Cvdots+%26+%5Cvdots+%26+%5Cvdots+%26+%5C%5C+1%2F8+%26+1%2F16+%26+1%2F32+%26+1%2F64+%26+%5Ccdots%5C%5C+1%2F4+%26+1%2F8+%26+1%2F16+%26+1%2F32+%26+%5Ccdots%5C%5C+1%2F2+%26+1%2F4+%26+1%2F8+%26+1%2F16+%26+%5Ccdots%5C%5C+1+%26+1%2F2+%26+1%2F4+%26+1%2F8+%26+%5Ccdots+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \begin{array}{ccccl} \vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \\ 1/8 &amp; 1/16 &amp; 1/32 &amp; 1/64 &amp; \cdots\\ 1/4 &amp; 1/8 &amp; 1/16 &amp; 1/32 &amp; \cdots\\ 1/2 &amp; 1/4 &amp; 1/8 &amp; 1/16 &amp; \cdots\\ 1 &amp; 1/2 &amp; 1/4 &amp; 1/8 &amp; \cdots \end{array} "/></p>
<p>
Ken remembers, as a teenager, seeing this puzzle in a collection by the master Martin Gardner, with the same proof. Ken thought of it again when considering problems in physics and combinatorics that involve defining an appropriate potential function as the first step. </p>
<p>
</p><p/><h2> An Uncool Solution </h2><p/>
<p/><p>
Let <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> be the lower-right <img alt="{3 \times 3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3+%5Ctimes+3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{3 \times 3}"/> corner board. Label the positions as usual with <img alt="{(i,j)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28i%2Cj%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(i,j)}"/> where <img alt="{i,j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%2Cj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i,j}"/> both are in <img alt="{\{1,2,3\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B1%2C2%2C3%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{1,2,3\}}"/>.</p>
<p>
Let <img alt="{N(t)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N(t)}"/> be the number of checkers in <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> at time <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t}"/>. Of course <img alt="{N(0)=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%280%29%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N(0)=1}"/> and the checker is at <img alt="{(1,1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%281%2C1%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(1,1)}"/>.</p>
<p>
<a href="https://rjlipton.files.wordpress.com/2020/09/config33v1.jpg"><img alt="" class="aligncenter wp-image-17621" height="107" src="https://rjlipton.files.wordpress.com/2020/09/config33v1.jpg?w=150&amp;h=107" width="150"/></a></p>
<p>
Suppose by way of contradiction that it is possible to make <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> empty. </p>
<p>
Our proof uses that the transition from <img alt="{N(t)&gt;0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%28t%29%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N(t)&gt;0}"/> to <img alt="{N(t+1)=0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%28t%2B1%29%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N(t+1)=0}"/> requires that <img alt="{N(t)=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%28t%29%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N(t)=1}"/>. That is <img alt="{N(t)=2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%28t%29%3D2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N(t)=2}"/> or even <img alt="{3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{3}"/> is impossible. The rule cannot remove two or more checkers from <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> in one move. </p>
<p>
<a href="https://rjlipton.files.wordpress.com/2020/09/config33v2.jpg"><img alt="" class="aligncenter wp-image-17622" height="97" src="https://rjlipton.files.wordpress.com/2020/09/config33v2.jpg?w=150&amp;h=97" width="150"/></a></p>
<p>
Let <img alt="{N(t)=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%28t%29%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N(t)=1}"/> and <img alt="{N(t+1)=0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%28t%2B1%29%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N(t+1)=0}"/>. So where is the checker? A simple case analysis shows it must be at <img alt="{(3,3)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%283%2C3%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(3,3)}"/>. So now we know the last placement. But how did we get to this position? It is easy to see that it had to be previously at <img alt="{(3,2)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%283%2C2%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(3,2)}"/> or <img alt="{(2,3)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%282%2C3%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(2,3)}"/>. By symmetry we can assume was <img alt="{(3,2)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%283%2C2%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(3,2)}"/>. </p>
<p>
<a href="https://rjlipton.files.wordpress.com/2020/09/config33v3.jpg"><img alt="" class="aligncenter wp-image-17623" height="98" src="https://rjlipton.files.wordpress.com/2020/09/config33v3.jpg?w=150&amp;h=98" width="150"/></a></p>
<p>
Our goal to show that we cannot place one checker at <img alt="{(3,2)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%283%2C2%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(3,2)}"/> and no other in <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/>. A little analysis shows that it must be the case that the previous state was one checker at <img alt="{(3,1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%283%2C1%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(3,1)}"/>. But it is impossible to place a checker there and avoid having more checkers. This yields a contradiction. </p>
<p>
<a href="https://rjlipton.files.wordpress.com/2020/09/config33v4.jpg"><img alt="" class="aligncenter wp-image-17624" height="97" src="https://rjlipton.files.wordpress.com/2020/09/config33v4.jpg?w=150&amp;h=97" width="150"/></a></p>
<p/><h2> Another Solution </h2><p/>
<p/><p>
We could use finite state automata theory to supply another solution. The obvious issue is the full game is played on an infinite checkerboard. But we can use a standard trick to reduce the state space to a finite one. Imagine we play the game on just <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/>. When we have a move that creates checkers outside of <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> just throw them away. It is simple to see that no move can place checkers inside <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/>. Thus if we cannot empty <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> in this finite version, then there is no way in the full game. </p>
<p>
Now the state space is bounded by <img alt="{2^{9}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5E%7B9%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2^{9}}"/>: each of the nine squares can have a checker or not. We know the initial state and we know the final state. So we can run a finite state search algorithm and decide the answer.</p>
<p>
The value of this solution is that it could handle more complex rules and larger squares. Well at least those within reason. </p>
<p>
</p><p/><h2> Other Puzzles </h2><p/>
<p/><p>
Rosenhouse covers nine other puzzles in his review. In our meta review of his review we will cover just two more. </p>
<p>
The third puzzle in his review comes from the challenge to prove that each matrix <img alt="{\{C_n\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7BC_n%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{C_n\}}"/> has determinant <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>. This is a puzzle because the matrices <img alt="{C_{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_{n}}"/> look like they could have some strange determinant, one that even varies with <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>. The trick is to show that there are other families <img alt="{\{A_n\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7BA_n%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{A_n\}}"/> and <img alt="{\{B_n\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7BB_n%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{B_n\}}"/> of matrices, in which each matrix has determinant <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/> and that 	</p>
<p align="center"><img alt="\displaystyle  C_n = A_n B_n. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++C_n+%3D+A_n+B_n.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  C_n = A_n B_n. "/></p>
<p>Of course this immediately proves that <img alt="{C_{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_{n}}"/> also have determinant <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>. The challenge is kind of a factorization problem. </p>
<p>
Another puzzle is to prove that a number <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> is prime if and only if there is exactly one pair of positive integers <img alt="{m,n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%2Cn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m,n}"/> such that </p>
<p align="center"><img alt="\displaystyle  \frac{1}{m} - \frac{1}{n} = \frac{1}{p}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7B1%7D%7Bm%7D+-+%5Cfrac%7B1%7D%7Bn%7D+%3D+%5Cfrac%7B1%7D%7Bp%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \frac{1}{m} - \frac{1}{n} = \frac{1}{p}. "/></p>
<p>This seems to be surprising in two ways: First who could think of this? Second who could think of this? Okay it should be why is it true? Indeed Rosenhouse says that the proof is complex. </p>
<p>
Rosenhouse adds that most puzzles in this book are less “bite-sized” than the ones typically posed by the master Gardner. This certainly goes for the title puzzle about whether a bicycle can possibly move along a curve—other than a straight line—that was made by a unicycle. It requires a foray into differential equations.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
My “uncool solution” was left somewhat incomplete. Do you see how to complete the analysis?</p>
<p/></font></font></div>
    </content>
    <updated>2020-09-22T22:01:06Z</updated>
    <published>2020-09-22T22:01:06Z</published>
    <category term="All Posts"/>
    <category term="Ideas"/>
    <category term="Oldies"/>
    <category term="Teaching"/>
    <category term="trick"/>
    <category term="book reviews"/>
    <category term="Daniel Velleman"/>
    <category term="Jason Rosenhouse"/>
    <category term="puzzles"/>
    <category term="Stan Wagon"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2020-09-23T22:20:46Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/144</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/144" rel="alternate" type="text/html"/>
    <title>TR20-144 |  Toward Probabilistic Checking against Non-Signaling Strategies with Constant Locality | 

	Mohammad Jahanara, 

	Sajin Koroth, 

	Igor Shinkar</title>
    <summary>Non-signaling strategies are a generalization of quantum strategies that have been studied in physics over the past three decades. Recently, they have found applications in theoretical computer science, including to proving inapproximability results for linear programming and to constructing protocols for delegating computation. A central tool for these applications is probabilistically checkable proof (PCPs) systems that are sound against non-signaling strategies.

In this paper we show, assuming a certain geometrical hypothesis about noise robustness of non-signaling proofs (or, equivalently, about robustness to noise of solutions to the Sherali-Adams linear program), that a slight variant of the parallel repetition of the exponential-length constant-query PCP construction due to Arora et al. (JACM 1998) is sound against non-signaling strategies with constant locality.

Our proof relies on the analysis of the linearity test and agreement test (also known as the direct product test) in the non-signaling setting.</summary>
    <updated>2020-09-22T11:49:39Z</updated>
    <published>2020-09-22T11:49:39Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-09-23T22:20:37Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.09743</id>
    <link href="http://arxiv.org/abs/2009.09743" rel="alternate" type="text/html"/>
    <title>Improving on Best-of-Many-Christofides for $T$-tours</title>
    <feedworld_mtime>1600732800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Traub:Vera.html">Vera Traub</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.09743">PDF</a><br/><b>Abstract: </b>The $T$-tour problem is a natural generalization of TSP and Path TSP. Given a
graph $G=(V,E)$, edge cost $c: E \to \mathbb{R}_{\ge 0}$, and an even
cardinality set $T\subseteq V$, we want to compute a minimum-cost $T$-join
connecting all vertices of $G$ (and possibly containing parallel edges).
</p>
<p>In this paper we give an $\frac{11}{7}$-approximation for the $T$-tour
problem and show that the integrality ratio of the standard LP relaxation is at
most $\frac{11}{7}$. Despite much progress for the special case Path TSP, for
general $T$-tours this is the first improvement on Seb\H{o}'s analysis of the
Best-of-Many-Christofides algorithm (Seb\H{o} [2013]).
</p></div>
    </summary>
    <updated>2020-09-22T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-09-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.09678</id>
    <link href="http://arxiv.org/abs/2009.09678" rel="alternate" type="text/html"/>
    <title>Efficiently Computing Maximum Flows in Scale-Free Networks</title>
    <feedworld_mtime>1600732800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bl=auml=sius:Thomas.html">Thomas Bläsius</a>, Tobias Friedrich, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Weyand:Christopher.html">Christopher Weyand</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.09678">PDF</a><br/><b>Abstract: </b>We study the maximum-flow/minimum-cut problem on scale-free networks, i.e.,
graphs whose degree distribution follows a power-law. We propose a simple
algorithm that capitalizes on the fact that often only a small fraction of such
a network is relevant for the flow. At its core, our algorithm augments
Dinitz's algorithm with a balanced bidirectional search. Our experiments on a
scale-free random network model indicate sublinear run time. On scale-free
real-world networks, we outperform the commonly used highest-label Push-Relabel
implementation by up to two orders of magnitude. Compared to Dinitz's original
algorithm, our modifications reduce the search space, e.g., by a factor of 275
on an autonomous systems graph.
</p>
<p>Beyond these good run times, our algorithm has an additional advantage
compared to Push-Relabel. The latter computes a preflow, which makes the
extraction of a minimum cut potentially more difficult. This is relevant, for
example, for the computation of Gomory-Hu trees. On a social network with 70000
nodes, our algorithm computes the Gomory-Hu tree in 3 seconds compared to 12
minutes when using Push-Relabel.
</p></div>
    </summary>
    <updated>2020-09-22T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-09-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.09646</id>
    <link href="http://arxiv.org/abs/2009.09646" rel="alternate" type="text/html"/>
    <title>A Novel Method for Inference of Acyclic Chemical Compounds with Bounded Branch-height Based on Artificial Neural Networks and Integer Programming</title>
    <feedworld_mtime>1600732800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Azam:Naveed_Ahmed.html">Naveed Ahmed Azam</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhu:Jianshen.html">Jianshen Zhu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sun:Yanming.html">Yanming Sun</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shi:Yu.html">Yu Shi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shurbevski:Aleksandar.html">Aleksandar Shurbevski</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhao:Liang.html">Liang Zhao</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nagamochi:Hiroshi.html">Hiroshi Nagamochi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Akutsu:Tatsuya.html">Tatsuya Akutsu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.09646">PDF</a><br/><b>Abstract: </b>Analysis of chemical graphs is a major research topic in computational
molecular biology due to its potential applications to drug design. One
approach is inverse quantitative structure activity/property relationship
(inverse QSAR/QSPR) analysis, which is to infer chemical structures from given
chemical activities/properties. Recently, a framework has been proposed for
inverse QSAR/QSPR using artificial neural networks (ANN) and mixed integer
linear programming (MILP). This method consists of a prediction phase and an
inverse prediction phase. In the first phase, a feature vector $f(G)$ of a
chemical graph $G$ is introduced and a prediction function $\psi$ on a chemical
property $\pi$ is constructed with an ANN. In the second phase, given a target
value $y^*$ of property $\pi$, a feature vector $x^*$ is inferred by solving an
MILP formulated from the trained ANN so that $\psi(x^*)$ is close to $y^*$ and
then a set of chemical structures $G^*$ such that $f(G^*)= x^*$ is enumerated
by a graph search algorithm. The framework has been applied to the case of
chemical compounds with cycle index up to 2. The computational results
conducted on instances with $n$ non-hydrogen atoms show that a feature vector
$x^*$ can be inferred for up to around $n=40$ whereas graphs $G^*$ can be
enumerated for up to $n=15$. When applied to the case of chemical acyclic
graphs, the maximum computable diameter of $G^*$ was around up to around 8. We
introduce a new characterization of graph structure, "branch-height," based on
which an MILP formulation and a graph search algorithm are designed for
chemical acyclic graphs. The results of computational experiments using
properties such as octanol/water partition coefficient, boiling point and heat
of combustion suggest that the proposed method can infer chemical acyclic
graphs $G^*$ with $n=50$ and diameter 30.
</p></div>
    </summary>
    <updated>2020-09-22T23:36:57Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-09-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.09645</id>
    <link href="http://arxiv.org/abs/2009.09645" rel="alternate" type="text/html"/>
    <title>The Complexity Landscape of Distributed Locally Checkable Problems on Trees</title>
    <feedworld_mtime>1600732800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chang:Yi=Jun.html">Yi-Jun Chang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.09645">PDF</a><br/><b>Abstract: </b>Recent research revealed the existence of gaps in the complexity landscape of
locally checkable labeling (LCL) problems in the LOCAL model of distributed
computing. For example, the deterministic round complexity of any LCL problem
on bounded-degree graphs is either $O(\log^\ast n)$ or $\Omega(\log n)$ [Chang,
Kopelowitz, and Pettie, FOCS 2016]. The complexity landscape of LCL problems is
now quite well-understood, but a few questions remain open.
</p>
<p>For bounded-degree trees, there is an LCL problem with round complexity
$\Theta(n^{1/k})$ for each positive integer $k$ [Chang and Pettie, FOCS 2017].
It is conjectured that no LCL problem has round complexity $o(n^{1/(k-1)})$ and
$\omega(n^{1/k})$ on bounded-degree trees. As of now, only the case of $k = 2$
has been proved [Balliu et al., DISC 2018].
</p>
<p>In this paper, we show that for LCL problems on bounded-degree trees, there
is indeed a gap between $\Theta(n^{1/(k-1)})$ and $\Theta(n^{1/k})$ for each $k
\geq 2$. Our proof is constructive in the sense that it offers a sequential
algorithm that decides which side of the gap a given LCL problem belongs to. We
also show that it is EXPTIME-hard to distinguish between $\Theta(1)$-round and
$\Theta(n)$-round LCL problems on bounded-degree trees. This improves upon a
previous PSPACE-hardness result [Balliu et al., PODC 2019].
</p></div>
    </summary>
    <updated>2020-09-22T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-09-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.09623</id>
    <link href="http://arxiv.org/abs/2009.09623" rel="alternate" type="text/html"/>
    <title>The Complexity of Constrained Min-Max Optimization</title>
    <feedworld_mtime>1600732800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Daskalakis:Constantinos.html">Constantinos Daskalakis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Skoulakis:Stratis.html">Stratis Skoulakis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zampetakis:Manolis.html">Manolis Zampetakis</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.09623">PDF</a><br/><b>Abstract: </b>Despite its important applications in Machine Learning, min-max optimization
of nonconvex-nonconcave objectives remains elusive. Not only are there no known
first-order methods converging even to approximate local min-max points, but
the computational complexity of identifying them is also poorly understood. In
this paper, we provide a characterization of the computational complexity of
the problem, as well as of the limitations of first-order methods in
constrained min-max optimization problems with nonconvex-nonconcave objectives
and linear constraints.
</p>
<p>As a warm-up, we show that, even when the objective is a Lipschitz and smooth
differentiable function, deciding whether a min-max point exists, in fact even
deciding whether an approximate min-max point exists, is NP-hard. More
importantly, we show that an approximate local min-max point of large enough
approximation is guaranteed to exist, but finding one such point is
PPAD-complete. The same is true of computing an approximate fixed point of
Gradient Descent/Ascent.
</p>
<p>An important byproduct of our proof is to establish an unconditional hardness
result in the Nemirovsky-Yudin model. We show that, given oracle access to some
function $f : P \to [-1, 1]$ and its gradient $\nabla f$, where $P \subseteq
[0, 1]^d$ is a known convex polytope, every algorithm that finds a
$\varepsilon$-approximate local min-max point needs to make a number of queries
that is exponential in at least one of $1/\varepsilon$, $L$, $G$, or $d$, where
$L$ and $G$ are respectively the smoothness and Lipschitzness of $f$ and $d$ is
the dimension. This comes in sharp contrast to minimization problems, where
finding approximate local minima in the same setting can be done with Projected
Gradient Descent using $O(L/\varepsilon)$ many queries. Our result is the first
to show an exponential separation between these two fundamental optimization
problems.
</p></div>
    </summary>
    <updated>2020-09-22T23:20:43Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-09-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.09605</id>
    <link href="http://arxiv.org/abs/2009.09605" rel="alternate" type="text/html"/>
    <title>Distributed Algorithms for Matching in Hypergraphs</title>
    <feedworld_mtime>1600732800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Oussama Hanguir, Clifford Stein <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.09605">PDF</a><br/><b>Abstract: </b>$ $We study the $d$-Uniform Hypergraph Matching ($d$-UHM) problem: given an
$n$-vertex hypergraph $G$ where every hyperedge is of size $d$, find a maximum
cardinality set of disjoint hyperedges. For $d\geq3$, the problem of finding
the maximum matching is NP-complete, and was one of Karp's 21
$\mathcal{NP}$-complete problems. In this paper we are interested in the
problem of finding matchings in hypergraphs in the massively parallel
computation (MPC) model that is a common abstraction of MapReduce-style
computation. In this model, we present the first three parallel algorithms for
$d$-Uniform Hypergraph Matching, and we analyse them in terms of resources such
as memory usage, rounds of communication needed, and approximation ratio. The
highlights include:
</p>
<p>$\bullet$ A $O(\log n)$-round $d$-approximation algorithm that uses $O(nd)$
space per machine.
</p>
<p>$\bullet$ A $3$-round, $O(d^2)$-approximation algorithm that uses
$\tilde{O}(\sqrt{nm})$ space per machine.
</p>
<p>$\bullet$ A $3$-round algorithm that computes a subgraph containing a
$(d-1+\frac{1}{d})^2$-approximation, using $\tilde{O}(\sqrt{nm})$ space per
machine for linear hypergraphs, and $\tilde{O}(n\sqrt{nm})$ in general.
</p></div>
    </summary>
    <updated>2020-09-22T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-09-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.09604</id>
    <link href="http://arxiv.org/abs/2009.09604" rel="alternate" type="text/html"/>
    <title>On Distributed Differential Privacy and Counting Distinct Elements</title>
    <feedworld_mtime>1600732800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Lijie.html">Lijie Chen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Ghazi:Badih.html">Badih Ghazi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kumar:Ravi.html">Ravi Kumar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Manurangsi:Pasin.html">Pasin Manurangsi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.09604">PDF</a><br/><b>Abstract: </b>We study the setup where each of $n$ users holds an element from a discrete
set, and the goal is to count the number of distinct elements across all users,
under the constraint of $(\epsilon, \delta)$-differentially privacy:
</p>
<p>- In the non-interactive local setting, we prove that the additive error of
any protocol is $\Omega(n)$ for any constant $\epsilon$ and for any $\delta$
inverse polynomial in $n$.
</p>
<p>- In the single-message shuffle setting, we prove a lower bound of
$\Omega(n)$ on the error for any constant $\epsilon$ and for some $\delta$
inverse quasi-polynomial in $n$. We do so by building on the moment-matching
method from the literature on distribution estimation.
</p>
<p>- In the multi-message shuffle setting, we give a protocol with at most one
message per user in expectation and with an error of $\tilde{O}(\sqrt(n))$ for
any constant $\epsilon$ and for any $\delta$ inverse polynomial in $n$. Our
protocol is also robustly shuffle private, and our error of $\sqrt(n)$ matches
a known lower bound for such protocols.
</p>
<p>Our proof technique relies on a new notion, that we call dominated protocols,
and which can also be used to obtain the first non-trivial lower bounds against
multi-message shuffle protocols for the well-studied problems of selection and
learning parity.
</p>
<p>Our first lower bound for estimating the number of distinct elements provides
the first $\omega(\sqrt(n))$ separation between global sensitivity and error in
local differential privacy, thus answering an open question of Vadhan (2017).
We also provide a simple construction that gives $\tilde{\Omega}(n)$ separation
between global sensitivity and error in two-party differential privacy, thereby
answering an open question of McGregor et al. (2011).
</p></div>
    </summary>
    <updated>2020-09-22T23:33:58Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-09-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.09480</id>
    <link href="http://arxiv.org/abs/2009.09480" rel="alternate" type="text/html"/>
    <title>A General Framework for the Security Analysis of Blockchain Protocols</title>
    <feedworld_mtime>1600732800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lewis=Pye:Andrew.html">Andrew Lewis-Pye</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Roughgarden:Tim.html">Tim Roughgarden</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.09480">PDF</a><br/><b>Abstract: </b>Blockchain protocols differ in fundamental ways, including the mechanics of
selecting users to produce blocks (e.g., proof-of-work vs. proof-of-stake) and
the method to establish consensus (e.g., longest chain rules vs. Byzantine
fault-tolerant (BFT) inspired protocols). These fundamental differences have
hindered "apples-to-apples" comparisons between different categories of
blockchain protocols and, in turn, the development of theory to formally
discuss their relative merits.
</p>
<p>This paper presents a parsimonious abstraction sufficient for capturing and
comparing properties of many well-known permissionless blockchain protocols,
simultaneously capturing essential properties of both proof-of-work (PoW) and
proof-of-stake (PoS) protocols, and of both longest-chain-type and BFT-type
protocols. Our framework blackboxes the precise mechanics of the user selection
process, allowing us to isolate the properties of the selection process that
are significant for protocol design.
</p>
<p>We demonstrate the utility of our general framework with several concrete
results:
</p>
<p>1. We prove a CAP-type impossibility theorem asserting that liveness with an
unknown level of participation rules out security in a partially synchronous
setting.
</p>
<p>2. Delving deeper into the partially synchronous setting, we prove that a
necessary and sufficient condition for security is the production of
"certificates," meaning stand-alone proofs of block confirmation.
</p>
<p>3. Restricting to synchronous settings, we prove that typical protocols with
a known level of participation (including longest chain-type PoS protocols) can
be adapted to provide certificates, but those with an unknown level of
participation cannot.
</p>
<p>4. Finally, we use our framework to articulate a modular two-step approach to
blockchain security analysis that effectively reduces the permissionless case
to the permissioned case.
</p></div>
    </summary>
    <updated>2020-09-22T23:34:55Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-09-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.09460</id>
    <link href="http://arxiv.org/abs/2009.09460" rel="alternate" type="text/html"/>
    <title>Recent Progress on Matrix Rigidity -- A Survey</title>
    <feedworld_mtime>1600732800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Ramya:C=.html">C. Ramya</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.09460">PDF</a><br/><b>Abstract: </b>The concept of matrix rigidity was introduced by Valiant(independently by
Grigoriev) in the context of computing linear transformations. A matrix is
rigid if it is far(in terms of Hamming distance) from any matrix of low rank.
Although we know rigid matrices exist, obtaining explicit constructions of
rigid matrices have remained a long-standing open question. This decade has
seen tremendous progress towards understanding matrix rigidity. In the past,
several matrices such as Hadamard matrices and Fourier matrices were
conjectured to be rigid. Very recently, many of these matrices were shown to
have low rigidity. Further, several explicit constructions of rigid matrices in
classes such as $E$ and $P^{NP}$ were obtained recently. Among other things,
matrix rigidity has found striking connections to areas as disparate as
communication complexity, data structure lower bounds and error-correcting
codes. In this survey, we present a selected set of results that highlight
recent progress on matrix rigidity and its remarkable connections to other
areas in theoretical computer science.
</p></div>
    </summary>
    <updated>2020-09-22T23:20:36Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-09-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.09442</id>
    <link href="http://arxiv.org/abs/2009.09442" rel="alternate" type="text/html"/>
    <title>TADOC: Text Analytics Directly on Compression</title>
    <feedworld_mtime>1600732800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Feng.html">Feng Zhang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhai:Jidong.html">Jidong Zhai</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shen:Xipeng.html">Xipeng Shen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Dalin.html">Dalin Wang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Zheng.html">Zheng Chen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mutlu:Onur.html">Onur Mutlu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Wenguang.html">Wenguang Chen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Du:Xiaoyong.html">Xiaoyong Du</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.09442">PDF</a><br/><b>Abstract: </b>This article provides a comprehensive description of Text Analytics Directly
on Compression (TADOC), which enables direct document analytics on compressed
textual data. The article explains the concept of TADOC and the challenges to
its effective realizations. Additionally, a series of guidelines and technical
solutions that effectively address those challenges, including the adoption of
a hierarchical compression method and a set of novel algorithms and data
structure designs, are presented. Experiments on six data analytics tasks of
various complexities show that TADOC can save 90.8% storage space and 87.9%
memory usage, while halving data processing times.
</p></div>
    </summary>
    <updated>2020-09-22T23:22:09Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-09-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.09288</id>
    <link href="http://arxiv.org/abs/2009.09288" rel="alternate" type="text/html"/>
    <title>On combinatorial optimization for dominating sets (literature survey, new models)</title>
    <feedworld_mtime>1600732800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Levin:Mark_Sh=.html">Mark Sh. Levin</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.09288">PDF</a><br/><b>Abstract: </b>The paper focuses on some versions of connected dominating set problems:
basic problems and multicriteria problems. A literature survey on basic problem
formulations and solving approaches is presented. The basic connected
dominating set problems are illustrated by simplifyed numerical examples. New
integer programming formulations of dominating set problems (with multiset
estimates) are suggested.
</p></div>
    </summary>
    <updated>2020-09-22T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-09-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/143</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/143" rel="alternate" type="text/html"/>
    <title>TR20-143 |  Characterizing Average-Case Complexity of PH by Worst-Case Meta-Complexity | 

	Shuichi Hirahara</title>
    <summary>We exactly characterize the average-case complexity of the polynomial-time hierarchy (PH) by the worst-case (meta-)complexity of GapMINKT(PH), i.e., an approximation version of the problem of determining if a given string can be compressed to a short PH-oracle efficient program.  Specifically, we establish the following equivalence:

  DistPH is contained in AvgP (i.e., PH is easy on average) if and only if GapMINKT(PH) is in P.

In fact, our equivalence is significantly broad: A number of statements on several fundamental notions of complexity theory, such as errorless and one-sided-error average-case complexity, sublinear-time-bounded and polynomial-time-bounded Kolmogorov complexity, and PH-computable hitting set generators, are all shown to be equivalent.

Our equivalence provides fundamentally new proof techniques for analyzing average-case complexity through the lens of *meta-complexity* of time-bounded Kolmogorov complexity and resolves, as immediate corollaries, questions of equivalence among different notions of average-case complexity of PH: low success versus high success probabilities (i.e., a hardness amplification theorem for DistPH against uniform algorithms) and errorless versus one-sided-error average-case complexity of PH.

Our results are based on a sequence of new technical results that further develops the proof techniques of the author's previous work on the non-black-box worst-case to average-case reduction and unexpected hardness results for Kolmogorov complexity (FOCS'18, CCC'20, ITCS'20, STOC'20).  Among other things, we prove the following.

  1.  If GapMINKT(NP) is in P, then P = BPP.
  At the core of the proof is a new black-box hitting set generator construction whose reconstruction algorithm uses few random bits, which also improves the approximation quality of the non-black-box worst-case to average-case reduction without using a pseudorandom generator.

  2.  If GapMINKT(PH) is in P, then DistPH is contained in AvgBPP = AvgP.

  3.  If MINKT(PH) is easy on a 1/poly(n)-fraction of inputs, then GapMINKT(PH) is in P.
  This improves the error tolerance of the previous non-black-box worst-case to average-case reduction.</summary>
    <updated>2020-09-21T10:16:37Z</updated>
    <published>2020-09-21T10:16:37Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-09-23T22:20:37Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4972</id>
    <link href="https://www.scottaaronson.com/blog/?p=4972" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4972#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4972" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Agent 3203.7: Guest post by Eliezer Yudkowsky</title>
    <summary xml:lang="en-US">In his day, Agent 3203.7 had stopped people from trying to kill Adolf Hitler, Richard Nixon, and even, in the case of one unusually thoughtful assassin, Henry David Thoreau. But this was a new one on him. “So…” drawled the seventh version of Agent 3203. His prosthetic hand crushed the simple 21st-century gun into fused […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>In his day, Agent 3203.7 had stopped people from trying to kill Adolf Hitler, Richard Nixon, and even, in the case of one unusually thoughtful assassin, Henry David Thoreau. But this was a new one on him.</p>



<p>“So…” drawled the seventh version of Agent 3203. His prosthetic hand crushed the simple 21st-century gun into fused metal and dropped it. “You traveled to the past in order to kill… of all people… Donald Trump. Care to explain why?”</p>



<p>The time-traveller’s eyes looked wild. Crazed. Nothing unusual. “How can you ask me that? You’re a time-traveler too! You know what he does!”</p>



<p>That was a surprising level of ignorance even for a 21st-century jumper. “Different timelines, kid. Some are pretty obscure. What the heck did Trump do in yours that’s worth taking your one shot at time travel to assassinate him of all people?”</p>



<p>“He’s destroying my world!”</p>



<p>Agent 3203.7 took a good look at where Donald Trump was pridefully addressing the unveiling of the Trump Taj Mahal in New Jersey, then took another good look at the errant time-traveler. “Destroying it how, exactly? Did Trump turn mad scientist in your timeline?”</p>



<p>“He’s President of the United States!”</p>



<p>Agent 3203.7 took another long stare at his new prisoner. He was apparently serious. “How did Trump become President in your timeline? Strangely advanced technology, subliminal messaging?”</p>



<p>“He was elected in the usual way,” the prisoner said bitterly.</p>



<p>Agent 3203.7 shook his head in amazement. Talk about shooting the messenger. “Kid, I doubt Trump was your timeline’s main problem.”</p>



<p><em>(thanks to Eliezer for giving me permission to reprint here)</em></p></div>
    </content>
    <updated>2020-09-21T04:01:10Z</updated>
    <published>2020-09-21T04:01:10Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="The Fate of Humanity"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2020-09-21T04:01:10Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-3655236890828727429</id>
    <link href="https://blog.computationalcomplexity.org/feeds/3655236890828727429/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/09/baseball-can-go-on-forever-it-doesnt.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/3655236890828727429" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/3655236890828727429" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/09/baseball-can-go-on-forever-it-doesnt.html" rel="alternate" type="text/html"/>
    <title>Baseball can go on forever, it doesn't just seem that way</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p> Most games have some way to make sure they cannot go on forever.</p><p>1) Chess: I had thought there was a 50-move rule and a 3-times-same-position rule, but its a byte more complicated than that, see <a href="https://en.wikipedia.org/wiki/Draw_(chess)">here</a>. There is also a chess clock. Suffice to say, Chess can never on forever (though it may seem like it does). </p><p>2) NIM: Eventually all of the stones are gone. There may be more complicated versions where you can add some stones, but in those versions I suspect that there is some parameter that goes to 0.</p><p>3) Basketball, Football, Hockey, Soccer: These all have a clock so they are time limited. For overtime there are also rules that make sure the game cannot go on forever. Or maybe its just very rare: what if the Superb Owl (spelled that way to avoid lawsuits, see <a href="https://www.vox.com/the-goods/2019/1/31/18202037/super-bowl-53-ads-trademark-the-big-game-2019">here</a>) is tied 0-0 at the end of the four quarters and goes into overtime and... nobody scores... ever. Could the game go on forever or would the referees declare it a tie? In the regular season there are ties, but in the in the superb owl? Actually this may be more a problem in the playoffs since you need to determine who goes to the next round.</p><p>4) Take your favorite game. I would bet dollars to doughnuts (what an odd phrase---see <a href="https://en.wiktionary.org/wiki/bet_a_dollar_to_a_doughnut">here</a> for more about the phrase) that there is some mechanism to make sure the game ends. An exception that Darling pointed out to me: If in Gin Rummy both players are terrible then the game can go on forever. This is probably true for other games as well and actually makes the question into two questions (a) will a game terminate no matter what the players do, and (b) (not sure how to formalize) will a game terminate if both players are trying to win and are making reasonable moves.</p><p>You may have noticed that in item 3 I left out Baseball. There is no clock in baseball. So one way the game can go on forever is to have a tie and extra innings and nobody scores. I think the umpire has the authority to call it a tie. (Incidentally, the shortened baseball season has a new extra inning rule---each inning starts with a runner on second. See <a href="https://www.mlb.com/news/reasons-new-extra-innings-rule-is-good">here</a>,) When Lance read an earlier version of this post he pointed me to 5 ways a game can go on forever, not counting the example I have later in this post. <a href="https://cs.nyu.edu/~gottlieb/tr/back-issues/1990s/1992/1-jan-scanned.pdf">Here</a> is where Lance found the question and answer (look on the first page under Speed Department for the question, and the very end of the second page for the answer). I also did my own writuep with more details, see <a href="http://www.cs.umd.edu/~gasarch/BLOGPAPERS/baseballforever.pdf">here</a>.  Also of interest (though not if you were actually at the game this happened), the record for number of times a player has a foul with 2 strikes is 16, see <a href="https://www.businessinsider.com/brandon-belts-record-at-bat-pop-fly-2018-4">here</a>. </p><p> However, I came across an  example more obscure than any of those. </p><p>Here is what happened (and you can see the video of it <a href="https://www.youtube.com/watch?v=yDyCRTlKllk">here</a>, though it really starts about a minute into it. Keep reading- it looks like its another post, but its part of this post: </p><div class="q-box qu-borderBottom qu-px--medium qu-py--small" style="border-bottom-style: solid; border-color: rgb(222, 224, 225); border-width: 1px; color: #282829; direction: ltr; font-size: 15px; padding: 8px 16px;"><div class="q-flex qu-justifyContent--space-between" style="direction: ltr; display: flex;"><div class="q-flex qu-alignItems--center" style="direction: ltr; display: flex;"><div class="q-text qu-fontSize--small qu-ml--small qu-color--gray" style="color: #636466; direction: ltr; font-size: 13px; margin-left: 8px;">From your Digest</div></div></div></div><div class="q-box" style="color: #282829; direction: ltr; font-size: 15px;"><div class="q-box" style="direction: ltr;"><div class="q-box qu-pt--medium qu-pb--tiny" style="direction: ltr; padding: 16px 16px 4px;"><div class="q-box" style="direction: ltr;"><div class="q-box" style="direction: ltr;"><div class="q-box" style="direction: ltr;"><div class="q-box" style="direction: ltr;"><div class="q-flex" style="direction: ltr; display: flex;"><div class="q-box qu-mb--small qu-pr--large" style="direction: ltr; margin-bottom: 8px; padding-right: 24px; width: 546px;"><div class="q-box spacing_log_answer_header" style="direction: ltr;"><div class="q-flex" style="direction: ltr; display: flex; width: 522px;"><div class="q-inlineFlex qu-mr--small qu-alignItems--center" style="direction: ltr; display: inline-flex; margin-right: 8px;"><div class="q-box qu-display--inline-block" style="direction: ltr; display: inline-block;"><div class="q-box qu-display--inline-block" style="direction: ltr; display: inline-block;"><div class="q-relative qu-display--inline-block" style="direction: ltr; display: inline-block;"><div class="q-box qu-display--inline-block" style="direction: ltr; display: inline-block;"><a class="q-box qu-display--inline-flex qu-color--gray_dark qu-cursor--pointer qu-hover--textDecoration--underline" href="https://www.quora.com/profile/Zev-Steinhardt" target="_blank"><div class="q-inlineFlex qu-flex--none" style="direction: ltr; display: inline-flex;"><div class="q-inlineFlex" style="direction: ltr; display: inline-flex;"><div class="q-inlineFlex qu-ov