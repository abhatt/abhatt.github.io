<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2022-03-27T23:39:12Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-US">
    <id>https://rjlipton.wpcomstaging.com/?p=19785</id>
    <link href="https://rjlipton.wpcomstaging.com/2022/03/26/waiting-for-self-deriving-cars/" rel="alternate" type="text/html"/>
    <title>Waiting For Self-Deriving Cars</title>
    <summary>Once you trust a self-driving car with your life, you pretty much will trust Artificial Intelligence with anything—Dave Waters. ITProToday src Keith Kirkpatrick is the author of an interesting CACM article on self-driving cars. It is titled “Still Waiting For Self-Driving Cars” and appears in the news section of this month’s issue. Today we discuss […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Once you trust a self-driving car with your life, you pretty much will trust Artificial Intelligence with anything—Dave Waters.</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2022/03/26/waiting-for-self-deriving-cars/kk/" rel="attachment wp-att-19787"><img alt="" class="alignright wp-image-19787" height="110" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/03/kk.jpg?resize=110%2C110&amp;ssl=1" width="110"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">ITProToday <a href="https://www.itprotoday.com/author/Keith-Kirkpatrick">src</a></font></td>
</tr>
</tbody>
</table>
<p>
Keith Kirkpatrick is the author of an interesting CACM <a href="https://cacm.acm.org/magazines/2022/4/259392-still-waiting-for-self-driving-cars/fulltext">article</a> on self-driving cars. It is titled “Still Waiting For Self-Driving Cars” and appears in the news section of this month’s issue. </p>
<p>
Today we discuss why it has been so difficult to get self-driving cars started.</p>
<p>
Kirkpatrick’s article starts:</p>
<blockquote><p><b> </b> <em> <i>Over the past decade, technology and automotive pundits have predicted the “imminent” arrival of fully autonomous vehicles that can drive on public roads without any active monitoring or input from a human driver. Elon Musk has predicted his company Tesla would deliver fully autonomous vehicles by the end of 2021, but he made similar predictions in 2020, 2019, and 2017. Each prediction has fallen flat, largely due to real-world safety concerns, particularly related to how self-driving cars perform in adverse conditions or situations.</i> </em>
</p></blockquote>
<p>
</p><p/><h2> An Issue </h2><p/>
<p/><p>
As printed in the current CACM issue, his article says the following on page 13:</p>
<blockquote><p><b> </b> <em> A potential intermediate solution currently being tested in Germany is to utilize remote drivers to control vehicles. Vay, a Berlin-based startup, has been testing a fleet of remote-controlled electric vehicles in that city and plans to roll out a mobility service in Europe and potentially the U.S. this year. The service will allow customers to order a remote-controlled car and have it drive them to their desired destination; on arrival, they get out if the vehicle and leave it to a human teledriver miles away to either park the vehicle or steer it to the next client. </em>
</p></blockquote>
<p/><p>
I claim this shows the issue that we have with automatic driving systems. There is a typo in the above paragraph. A typo that shows what we are up against in the attempt to make automatic driving systems. </p>
<p>
<b>DO YOU SEE IT?</b></p>
<p/><p><br/>
<a href="https://rjlipton.wpcomstaging.com/2022/03/26/waiting-for-self-deriving-cars/cacmifoftypo/" rel="attachment wp-att-19792"><img alt="" class="aligncenter wp-image-19792" height="36" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/03/CACMifoftypo.jpg?resize=253%2C36&amp;ssl=1" width="253"/></a></p>
<p/><p><br/>
We claim that a typo like this in a CACM article is part of the reason it is so hard to make self-driving cars. Do you agree? Or is the typo not critical? While we’re at it, does the title of this post have a typo?  Read on…</p>
<p>
Ken contributes a more difficult example of this kind, one he used while addressing the same issue of AI advances in his department’s Freshman Seminar. It relates to a later section in Kirkpatrick’s article, where he discusses the issue of</p>
<blockquote><p><b> </b> <em> …testing to ensure vehicle navigation systems understand the complex social interactions that often occur between oncoming and adjacent drivers, or drivers and pedestrians. Generally, if a pedestrian is about to cross or is crossing a street, the driver and pedestrian will make eye contact, and will use nonverbal cues to indicate the direction and speed of their movement. </em>
</p></blockquote>
<p/><p>
Over to Ken:</p>
<p>
</p><p/><h2> Ken’s Example </h2><p/>
<p/><p>
Here is the relevant portion of the White House <a href="https://obamawhitehouse.archives.gov/the-press-office/2012/07/13/remarks-president-campaign-event-roanoke-virginia">transcript</a> of Barack Obama’s July 2012 campaign speech in Roanoke, Virginia—the one with the notorious phrase “you didn’t build that”:</p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2022/03/26/waiting-for-self-deriving-cars/youdidntbuildthat/" rel="attachment wp-att-19798"><img alt="" class="aligncenter wp-image-19798" height="229" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/03/YouDidntBuildThat.jpg?resize=363%2C229&amp;ssl=1" width="363"/></a></p>
<p>
The question we could submit to Google—whose own automated-driving efforts have had <a href="https://www.nytimes.com/2015/09/02/technology/personaltech/google-says-its-not-the-driverless-cars-fault-its-other-drivers.html">difficulties</a> with interpreting rules—is:</p>
<blockquote><p><b> </b> <em> What does the word “that” in “you didn’t build that” refer to? </em>
</p></blockquote>
<p/><p>
By rules of linguistic derivation, the answer seems clear:</p>
<ul>
<li>
The word “that” refers to the most recent noun, which is “business.” <p/>
</li><li>
The dashes ‘- -‘ connect two parts that refer to each other. <p/>
</li><li>
The word cannot anyway refer to “roads and bridges” because that is plural whereas “that” is singular, like “business.” <p/>
</li><li>
(The preceding point is not a self-contradiction because in quotes, “roads and bridges” is a phrase—singular.)
</li></ul>
<p>
Now please take a minute-plus to listen to the actual delivery of this part of the speech (you may need to click back from 0:00:08 to 0:00:00 to get the start):</p>
<p/><center><br/>
<br/>
</center><p/>
<p/><p><br/>
First, the transcript is missing a word: Obama actually said “<em>that</em>—you didn’t build <em>that</em>.” Perhaps having a rhetorically emphasized <em>that</em> right after “business” makes the semantic designation even clearer? But then notice that the part “if you’ve got a business” was delivered in a quick and parenthetical manner inside the full phrase “Somebody invested in roads and bridges … you didn’t build that.” </p>
<p>
The interpretation that the “that” refers to <em>infrastructure</em> is supported by the speech’s immediate segue to the Internet, sandwiched around “somebody else made that happen.” Going out to sources, Obama was <a href="https://www.washingtonpost.com/blogs/fact-checker/post/an-unoriginal-obama-quote-taken-out-of-context/2012/07/20/gJQAdG7hyW_blog.html">channeling</a> a point already notoriously made by Elizabeth Warren in a 2011 <a href="https://www.nationalreview.com/the-agenda/elizabeth-warrens-quote-reihan-salam/">speech</a>. But without going out to sources—something we cannot expect an AI to do in the moment—there is Obama’s next sentence (also included in the speech clip):</p>
<blockquote><p><b> </b> <em> “The point is, is that when we succeed, we succeed because of our individual initiative, but also because we do things together.” </em>
</p></blockquote>
<p/><p>
Whether Obama intended to say that people did not build their businesses can still be argued, but that’s not the real point. My first point is that AIs based on current art for ascribing meanings not only would make that ascription, but <em>should</em> do so for overall consistency. And the second, larger, point at the end of my <a href="https://cse.buffalo.edu/~regan/cse199/InternetAndData199np.pdf">slides</a>, where I get to hard AI problems, is this:</p>
<blockquote><p><b> </b> <em> We base our confidence in developing AI systems on Alan Turing’s principle that whatever the human mind can resolve, a computer can be programmed to apprehend and execute. But what if important data, on fine scales, concern matters that our human minds cannot resolve? </em>
</p></blockquote>
<p/><p>
CACM puts in a bubble Kirkpatrick’s quoting another expert that “it will take years and massive compute power to train self-driving systems to understand the nonverbal cues that pass between drivers and pedestrians.”  We believe the task and need of getting cars to <em>self-derive</em> meanings is greater still.  </p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Do these issues say anything about the difficulty of getting code right? We think so, but what do you think?</p>
<p/><p><br/>
[some word changes; I seem unable to fix the endpoints of my clip on the C-SPAN website.]</p></font></font></div>
    </content>
    <updated>2022-03-27T02:05:26Z</updated>
    <published>2022-03-27T02:05:26Z</published>
    <category term="All Posts"/>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="&quot;you didn't build that&quot;"/>
    <category term="AI"/>
    <category term="CACM"/>
    <category term="hard problems of AI"/>
    <category term="Keith Kirkpatrick"/>
    <category term="linguistics"/>
    <category term="self-driving cars"/>
    <category term="translation"/>
    <category term="typos"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wpcomstaging.com</id>
      <logo>https://s0.wp.com/i/webclip.png</logo>
      <link href="https://rjlipton.wpcomstaging.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wpcomstaging.com" rel="alternate" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel's Lost Letter and P=NP</title>
      <updated>2022-03-27T23:37:42Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://thmatters.wordpress.com/?p=1365</id>
    <link href="https://thmatters.wordpress.com/2022/03/26/call-for-nominations-stoc-test-of-time-award-deadline-apr-30/" rel="alternate" type="text/html"/>
    <title>Call for Nominations: STOC Test of Time Award (Deadline: Apr 30)</title>
    <summary>The 2022 STOC Test of Time Award recognizes papers published in the Proceedings of the Annual ACM Symposium on Theory of Computing. This is the second year of this annual award. There are three awards, targeting the STOC conferences 10, 20, and 30 years prior to the year in which the award is given. While […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><strong>The 2022 STOC Test of Time Award</strong> recognizes papers published in the Proceedings of the Annual ACM Symposium on Theory of Computing. This is the second year of this annual award. There are three awards, targeting the STOC conferences 10, 20, and 30 years prior to the year in which the award is given. While there is a preference for papers in the target years (and nominations from those years are encouraged), in each of these award categories it is also possible to nominate STOC conference papers published up to four conferences earlier than the targeted conference. Thus, the 2022 STOC Test of Time Awards will be for papers presented at the STOC conferences in 2008-2012, 1998-2002, and 1988-1992. The awards, which will be presented at STOC 2022, include a prize of US $500 per author as well as complimentary registration for all authors who attend the conference at which the award is given.</p>



<h2>Nomination Procedure</h2>



<p>Nominations should be sent to <a rel="noreferrer noopener" target="_blank"><strong>stoc22.tot.award@gmail.com</strong></a><strong> </strong>with a subject line of <strong>“STOC Test of Time Award” </strong>no later than <strong>April 30, 2022</strong>. Nominations should contain an explanation of the impact of the nominated paper(s), including references to follow-on work. A nomination may be accompanied by up to three additional endorsement letters, which may be sent by the endorsers directly to the same email address with the same subject line. Self-nominations are disallowed. </p>



<h2>Selection</h2>



<p>The winners will be selected by a committee appointed by the SIGACT Executive Committee. For 2022 the selection committee consists of Toniann Pitassi (Columbia), Satish Rao (Berkeley), Salil Vadhan (Harvard, chair), Avi Wigderson (Institute for Advanced Study). </p>



<p>In selecting the Test of Time Award winners, the Committee will pay particular attention to long-term impact. This impact can come in many forms, including but not limited to:</p>



<ol><li>Opening up a new area of research</li><li>Introducing new techniques</li><li>Solving a problem of lasting importance</li><li>Stimulating advances in other areas of computer science or in other disciplines.</li></ol>



<p>The committee expects to select exactly one paper for each award. However, when circumstances justify it, up to three may be selected. The committee may consider papers that were not explicitly nominated and gather additional input from experts, but formal nominations are extremely helpful in the committee’s deliberations and strongly encouraged.</p></div>
    </content>
    <updated>2022-03-27T01:53:14Z</updated>
    <published>2022-03-27T01:53:14Z</published>
    <category term="awards"/>
    <category term="Deadlines"/>
    <category term="TCS Community"/>
    <author>
      <name>shuchic</name>
    </author>
    <source>
      <id>https://thmatters.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://thmatters.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://thmatters.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://thmatters.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://thmatters.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theory Matters</title>
      <updated>2022-03-27T23:37:55Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-7417921219645055549</id>
    <link href="http://blog.computationalcomplexity.org/feeds/7417921219645055549/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/03/i-dont-care-about-ketanji-brown.html#comment-form" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/7417921219645055549" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/7417921219645055549" rel="self" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/03/i-dont-care-about-ketanji-brown.html" rel="alternate" type="text/html"/>
    <title>I don't care about Ketanji Brown Jackson's LSAT scores and she does not care about my GRE scores</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Tucker Carlson has asked to see Ketanji Brown Jacksons's LSATs. </p><p>When I applied to College they (not sure who <i>they</i> are) wanted to see my SAT scores. Putting aside the issue of whether the test means anything, they viewed the SATs (and my HS grades and letters from teachers) as a sign of my </p><p>                                                       <i>potential. </i></p><p>When I applied to Grad school they (a different <i>they</i>) wanted to see my GRE scores. Putting aside the issue of whether the test means anything, they viewed the GREs (and my college grades and letters from professors) as a sign of my</p><p>                                                       <i>potential. </i></p><p>When I applied for jobs as a professor they (another <i>they</i>) wanted to see my resume (papers I wrote) and letters from my advisor and others (I think). They did not look at my grades (just as well- I got a B in both compiler design and operating systems. Darling is amazed I even took operating systems). This was probably the oddest of the application processes since they were looking for both</p><p>                                                   <i> potential and achievement.</i></p><p>That is, the evidence that I could do research was that I had done some research. This was before the current  era where grad students had to have x papers in prestige conferences to get a job at a top y school. The letter from my advisor may well have spoken of my potential. </p><p>When I went up for tenure ALL they cared about was PAPERS (and letters saying they were good papers), and some teaching and service. It was based just  on </p><p>                                                          <i>achievement.</i></p><p>A wise man named Lance Fortnow once told me:</p><p><i>The worst thing a letter of recommendation for a tenure case can say is `this person has great potential'</i></p><p><br/></p><p>It would have been rather odd for Tucker Carlson to ask to see my SAT scores or GRE scores or by HS, College, or Grad School grades as a criteria for Tenure. Those tests and those grades are there to measure potential to DO something, whereas if you are going up for tenure or a Supreme Court seat, you've already DONE stuff. </p><p>After I got into grad school one of my first thoughts was</p><p><i>Nobody will ever want to see my GRE's again. ( I was right.) </i></p><p>After KBJ got into Law School she might have thought</p><p><i>Nobody will ever want to see my LSAT scores again. (She was wrong.)</i></p><p><i><br/></i></p><p><br/></p><p><br/></p></div>
    </content>
    <updated>2022-03-27T00:10:00Z</updated>
    <published>2022-03-27T00:10:00Z</published>
    <author>
      <name>gasarch</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03004932739846901628</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="http://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2022-03-27T22:34:37Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2203.13233</id>
    <link href="http://arxiv.org/abs/2203.13233" rel="alternate" type="text/html"/>
    <title>Grid Induced Minor Theorem for Graphs of Small Degree</title>
    <feedworld_mtime>1648339200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Korhonen:Tuukka.html">Tuukka Korhonen</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2203.13233">PDF</a><br/><b>Abstract: </b>A graph $H$ is an induced minor of a graph $G$ if $H$ can be obtained from
$G$ by vertex deletions and edge contractions. We show that there is a function
$f(k, d) = O(k^{10} + 2^{d^5})$ so that if a graph has treewidth at least $f(k,
d)$ and maximum degree at most $d$, then it contains a $k \times k$-grid as an
induced minor. This proves the conjecture of Aboulker, Adler, Kim, Sintiari,
and Trotignon [Eur. J. Comb., 98, 2021] that any graph with large treewidth and
bounded maximum degree contains a large wall or the line graph of a large wall
as an induced subgraph. It also implies that for any fixed planar graph $H$,
there is a subexponential time algorithm for maximum weight independent set on
$H$-induced-minor-free graphs.
</p></div>
    </summary>
    <updated>2022-03-27T22:44:01Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-03-25T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2203.13225</id>
    <link href="http://arxiv.org/abs/2203.13225" rel="alternate" type="text/html"/>
    <title>Distributionally Robust Optimization via Ball Oracle Acceleration</title>
    <feedworld_mtime>1648339200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Carmon:Yair.html">Yair Carmon</a>, Danielle Hausler <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2203.13225">PDF</a><br/><b>Abstract: </b>We develop and analyze algorithms for distributionally robust optimization
(DRO) of convex losses. In particular, we consider group-structured and bounded
$f$-divergence uncertainty sets. Our approach relies on an accelerated method
that queries a ball optimization oracle, i.e., a subroutine that minimizes the
objective within a small ball around the query point. Our main contribution is
efficient implementations of this oracle for DRO objectives. For DRO with $N$
non-smooth loss functions, the resulting algorithms find an $\epsilon$-accurate
solution with $\widetilde{O}\left(N\epsilon^{-2/3} + \epsilon^{-2}\right)$
first-order oracle queries to individual loss functions. Compared to existing
algorithms for this problem, we improve complexity by a factor of up to
$\epsilon^{-4/3}$.
</p></div>
    </summary>
    <updated>2022-03-27T22:44:35Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-03-25T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2203.13170</id>
    <link href="http://arxiv.org/abs/2203.13170" rel="alternate" type="text/html"/>
    <title>Geometric Dominating Sets</title>
    <feedworld_mtime>1648339200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Aichholzer:Oswin.html">Oswin Aichholzer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Eppstein:David.html">David Eppstein</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hainzl:Eva=Maria.html">Eva-Maria Hainzl</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2203.13170">PDF</a><br/><b>Abstract: </b>We consider a minimizing variant of the well-known \emph{No-Three-In-Line
Problem}, the \emph{Geometric Dominating Set Problem}: What is the smallest
number of points in an $n\times n$~grid such that every grid point lies on a
common line with two of the points in the set? We show a lower bound of
$\Omega(n^{2/3})$ points and provide a constructive upper bound of size $2
\lceil n/2 \rceil$. If the points of the dominating sets are required to be in
general position we provide optimal solutions for grids of size up to $12
\times 12$. For arbitrary $n$ the currently best upper bound for points in
general position remains the obvious $2n$. Finally, we discuss the problem on
the discrete torus where we prove an upper bound of $O((n \log n)^{1/2})$. For
$n$ even or a multiple of 3, we can even show a constant upper bound of 4. We
also mention a number of open questions and some further variations of the
problem.
</p></div>
    </summary>
    <updated>2022-03-27T22:44:58Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2022-03-25T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2203.13146</id>
    <link href="http://arxiv.org/abs/2203.13146" rel="alternate" type="text/html"/>
    <title>Approximate Parametric Computation of Minimum-Cost Flows with Convex Costs</title>
    <feedworld_mtime>1648339200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Per Joachims, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Klimm:Max.html">Max Klimm</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Warode:Philipp.html">Philipp Warode</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2203.13146">PDF</a><br/><b>Abstract: </b>This paper studies a variant of the minimum-cost flow problem in a graph with
convex cost function where the demands at the vertices are functions depending
on a one-dimensional parameter $\lambda$. We devise two algorithmic approaches
for the approximate computation of parametric solutions for this problem. The
first approach transforms an instance of the parametric problem into an
instance with piecewise quadratic cost functions by interpolating the marginal
cost functions. The new instance can be solved exactly with an algorithm we
developed in prior work. In the second approach, we compute a fixed number of
non-parametric solutions and interpolate the resulting flows yielding an
approximate solution for the original, parametric problem. For both methods we
formulate explicit bounds on the step sizes used in the respective
interpolations that guarantee relative and absolute error margins. Finally, we
test our approaches on real-world traffic and gas instances in an empirical
study.
</p></div>
    </summary>
    <updated>2022-03-27T22:44:08Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-03-25T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2203.13095</id>
    <link href="http://arxiv.org/abs/2203.13095" rel="alternate" type="text/html"/>
    <title>Batch Dynamic Algorithm to Find k-Cores and Hierarchies</title>
    <feedworld_mtime>1648339200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gabert:Kasimir.html">Kasimir Gabert</a>, Ali Pınar, Ümit V. Çatalyürek <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2203.13095">PDF</a><br/><b>Abstract: </b>Finding $k$-cores in graphs is a valuable and effective strategy for
extracting dense regions of otherwise sparse graphs. We focus on the important
problem of maintaining cores on rapidly changing dynamic graphs, where batches
of edge changes need to be processed quickly. Prior batch core algorithms have
only addressed half the problem of maintaining cores, the problem of
maintaining a core decomposition. This finds vertices that are dense, but not
regions; it misses connectivity. To address this, we bring an efficient index
from community search into the core domain, the Shell Tree Index. We develop a
novel dynamic batch algorithm to maintain it that improves efficiency over
processing edge-by-edge. We implement our algorithm and experimentally show
that with it core queries can be returned on rapidly changing graphs quickly
enough for interactive applications. For 1 million edge batches, on many graphs
we run over $100\times$ faster than processing edge-by-edge while remaining
under re-computing from scratch.
</p></div>
    </summary>
    <updated>2022-03-27T22:44:47Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-03-25T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2203.13073</id>
    <link href="http://arxiv.org/abs/2203.13073" rel="alternate" type="text/html"/>
    <title>On the Binary and Boolean Rank of Regular Matrices</title>
    <feedworld_mtime>1648339200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Haviv:Ishay.html">Ishay Haviv</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Parnas:Michal.html">Michal Parnas</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2203.13073">PDF</a><br/><b>Abstract: </b>A $0,1$ matrix is said to be regular if all of its rows and columns have the
same number of ones. We prove that for infinitely many integers $k$, there
exists a square regular $0,1$ matrix with binary rank $k$, such that the
Boolean rank of its complement is $k^{\widetilde{\Omega}(\log k)}$.
Equivalently, the ones in the matrix can be partitioned into $k$ combinatorial
rectangles, whereas the number of rectangles needed for any cover of its zeros
is $k^{\widetilde{\Omega}(\log k)}$. This settles, in a strong form, a question
of Pullman (Linear Algebra Appl. ,1988) and a conjecture of Hefner, Henson,
Lundgren, and Maybee (Congr. Numer. ,1990). The result can be viewed as a
regular analogue of a recent result of Balodis, Ben-David, G\"{o}\"{o}s, Jain,
and Kothari (FOCS, 2021), motivated by the clique vs. independent set problem
in communication complexity and by the (disproved) Alon-Saks-Seymour conjecture
in graph theory. As an application of the produced regular matrices, we obtain
regular counterexamples to the Alon-Saks-Seymour conjecture and prove that for
infinitely many integers $k$, there exists a regular graph with biclique
partition number $k$ and chromatic number $k^{\widetilde{\Omega}(\log k)}$.
</p></div>
    </summary>
    <updated>2022-03-27T22:37:29Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2022-03-25T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2203.12997</id>
    <link href="http://arxiv.org/abs/2203.12997" rel="alternate" type="text/html"/>
    <title>Hierarchical Nearest Neighbor Graph Embedding for Efficient Dimensionality Reduction</title>
    <feedworld_mtime>1648339200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sarfraz:M=_Saquib.html">M. Saquib Sarfraz</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Koulakis:Marios.html">Marios Koulakis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Seibold:Constantin.html">Constantin Seibold</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Stiefelhagen:Rainer.html">Rainer Stiefelhagen</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2203.12997">PDF</a><br/><b>Abstract: </b>Dimensionality reduction is crucial both for visualization and preprocessing
high dimensional data for machine learning. We introduce a novel method based
on a hierarchy built on 1-nearest neighbor graphs in the original space which
is used to preserve the grouping properties of the data distribution on
multiple levels. The core of the proposal is an optimization-free projection
that is competitive with the latest versions of t-SNE and UMAP in performance
and visualization quality while being an order of magnitude faster in run-time.
Furthermore, its interpretable mechanics, the ability to project new data, and
the natural separation of data clusters in visualizations make it a general
purpose unsupervised dimension reduction technique. In the paper, we argue
about the soundness of the proposed method and evaluate it on a diverse
collection of datasets with sizes varying from 1K to 11M samples and dimensions
from 28 to 16K. We perform comparisons with other state-of-the-art methods on
multiple metrics and target dimensions highlighting its efficiency and
performance. Code is available at https://github.com/koulakis/h-nne
</p></div>
    </summary>
    <updated>2022-03-27T22:38:17Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-03-25T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://dstheory.wordpress.com/?p=122</id>
    <link href="https://dstheory.wordpress.com/2022/03/25/wednesday-april-6th-2022-shuchi-chawla-from-ut-austin/" rel="alternate" type="text/html"/>
    <title>Wednesday April 6th 2022 — Shuchi Chawla from UT Austin</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">The third Foundations of Data Science virtual talk of this year will take place on Wednesday, March 6th at 1:00 PM Pacific Time (16:00 Eastern Time, 22:00 Central European Time, 20:00 UTC). Shuchi Chawla from UT Austin will speak about “Pandora’s Box with Correlations: Learning and Approximation.” Please register here to join the virtual talk. Abstract:<a class="more-link" href="https://dstheory.wordpress.com/2022/03/25/wednesday-april-6th-2022-shuchi-chawla-from-ut-austin/">Continue reading <span class="screen-reader-text">"Wednesday April 6th 2022 — Shuchi Chawla from UT Austin"</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The third <a href="https://sites.google.com/view/dstheory/home" rel="noreferrer noopener" target="_blank">Foundations of Data Science</a> virtual talk of this year will take place on <strong>Wednesday, March 6th</strong> at <strong>1:00 PM Pacific Time</strong> (16:00 Eastern Time, 22:00 Central European Time, 20:00 UTC). <a href="https://www.cs.utexas.edu/people/faculty-researchers/shuchi-chawla">Shuchi Chawla</a> from<strong> UT Austin</strong> will speak about “Pandora’s Box with Correlations: Learning and Approximation.<em>”</em></p>



<p><a href="https://sites.google.com/view/dstheory" rel="noreferrer noopener" target="_blank">Please register here to join the virtual talk.</a></p>



<p><strong>Abstract</strong>:  In the Pandora’s Box problem, the algorithm is provided with a number of boxes with unknown (stochastic) rewards contained inside them. The algorithm can open any box at some cost, discover the reward inside, and based on these observations can choose one box and keep the reward contained in it. Given the distributions from which the rewards are drawn, the algorithm must determine an order in which to open the boxes as well as when to stop and accept the best reward found so far. In general, an optimal algorithm may make both decisions adaptively based on instantiations observed previously. The Pandora’s Box problem and its extensions capture many kinds of optimization problems with stochastic input where the algorithm can obtain instantiations of input random variables at some cost. Previous work on these problems assumes that different random variables in the input are distributed independently. As such it does not capture many real-world settings. In this work, we provide the first algorithms for Pandora’s Box-type problems with correlations. In the independent setting, optimal algorithms are non-adaptive and based on the notion of the Gittins index. These techniques fail to extend to the correlated case. We assume that the algorithm has access to samples drawn from the joint distribution on input and provide solutions that require few samples; are computationally efficient; and guarantee approximate optimality. <br/>This is joint work with Evangelia Gergatsouli, Yifeng Teng, Christos Tzamos, and Ruimin Zhang and appeared in FOCS’20.</p>



<p> The series is supported by the <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1934846&amp;HistoricalAwards=false">NSF HDR TRIPODS Grant 1934846</a>.</p></div>
    </content>
    <updated>2022-03-25T23:14:50Z</updated>
    <published>2022-03-25T23:14:50Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>dstheory</name>
    </author>
    <source>
      <id>https://dstheory.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://dstheory.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://dstheory.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://dstheory.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://dstheory.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Foundation of Data Science – Virtual Talk Series</title>
      <updated>2022-03-27T23:39:03Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2022/03/23/lecturer-in-theoretical-computer-science-at-university-of-auckland-apply-by-may-15-2022/</id>
    <link href="https://cstheory-jobs.org/2022/03/23/lecturer-in-theoretical-computer-science-at-university-of-auckland-apply-by-may-15-2022/" rel="alternate" type="text/html"/>
    <title>Lecturer in Theoretical Computer Science at University of Auckland (apply by May 15, 2022)</title>
    <summary>We seek two early-career top candidates working in any subfield of TCS, preferably in algorithms and data structures, probabilistic computation, quantum and algorithmic information theory, computational biology, and computational complexity. Website: https://jobs.smartrecruiters.com/TheUniversityOfAuckland/743999813405096-lecturer-in-theoretical-computer-science Email: g.russello@auckland.ac.nz</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>We seek two early-career top candidates working in any subfield of TCS, preferably in algorithms and data structures, probabilistic computation, quantum and algorithmic information theory, computational biology, and computational complexity.</p>
<p>Website: <a href="https://jobs.smartrecruiters.com/TheUniversityOfAuckland/743999813405096-lecturer-in-theoretical-computer-science">https://jobs.smartrecruiters.com/TheUniversityOfAuckland/743999813405096-lecturer-in-theoretical-computer-science</a><br/>
Email: g.russello@auckland.ac.nz</p></div>
    </content>
    <updated>2022-03-23T23:12:08Z</updated>
    <published>2022-03-23T23:12:08Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2022-03-27T23:37:46Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/041</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/041" rel="alternate" type="text/html"/>
    <title>TR22-041 |  Boolean functions with small approximate spectral norm | 

	Hamed Hatami, 

	TsunMing Cheung, 

	Rosie Zhao, 

	Itai Zilberstein</title>
    <summary>The sum of the absolute values of the Fourier coefficients of a function $f:\mathbb{F}_2^n \to \mathbb{R}$ is called the spectral norm of $f$.    Green and Sanders' quantitative version of  Cohen's idempotent theorem states that if the spectral norm of $f:\mathbb{F}_2^n \to \{0,1\}$ is at most $M$, then the support of $f$ belongs to the ring of sets generated by at most $\ell(M)$ cosets,  where $\ell(M)$ is a constant that only depends on $M$.
    
    We prove that the above statement can be generalized to approximate spectral norms if and only if the support of $f$ and its complement satisfy a certain arithmetic connectivity condition. In particular, our theorem provides a new proof of the quantitative Cohen's theorem for $\mathbb{F}_2^n$.</summary>
    <updated>2022-03-23T08:19:23Z</updated>
    <published>2022-03-23T08:19:23Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-03-27T23:37:26Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/040</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/040" rel="alternate" type="text/html"/>
    <title>TR22-040 |  Should decisions in QCDCL follow prefix order? | 

	Benjamin Böhm, 

	Tomáš Peitl, 

	Olaf Beyersdorff</title>
    <summary>Quantified conflict-driven clause learning (QCDCL) is one of the main solving approaches for quantified Boolean formulas (QBF). One of the differences between QCDCL and propositional CDCL is that QCDCL typically follows the prefix order of the QBF for making decisions.
We investigate an alternative model for QCDCL solving where decisions can be made in arbitrary order. The resulting system QCDCL-ANY is still sound and terminating, but does not necessarily allow to always learn asserting clauses or cubes. To address this potential drawback, we additionally introduce two subsystems that guarantee to always learn asserting clauses (QCDCL-UNI-ANY) and asserting cubes (QCDCL-EXI-ANY), respectively.
We model all four approaches by formal proof systems and show that QCDCL-UNI-ANY is exponentially better than QCDCL on false formulas, whereas QCDCL-EXI-ANY is exponentially better than QCDCL on true QBFs. Technically, this involves constructing specific QBF families and showing lower and upper bounds in the respective proof systems.
We complement our theoretical study with some initial experiments that confirm our theoretical findings.</summary>
    <updated>2022-03-22T10:18:30Z</updated>
    <published>2022-03-22T10:18:30Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-03-27T23:37:26Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=22518</id>
    <link href="https://gilkalai.wordpress.com/2022/03/21/combinatorial-convexity-a-wonderful-new-book-by-imre-barany/" rel="alternate" type="text/html"/>
    <title>Combinatorial Convexity: A Wonderful New Book by Imre Bárány</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">A few days ago I received by mail Imre Bárány’s new book Combinatorial Convexity. The book presents Helly-type theorems and other results in convexity with combinatorial flavour. The choice of material and the choice of proofs is terrific and it … <a href="https://gilkalai.wordpress.com/2022/03/21/combinatorial-convexity-a-wonderful-new-book-by-imre-barany/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>A few days ago I received by mail Imre Bárány’s new book <em>Combinatorial Convexity</em>. The book presents Helly-type theorems and other results in convexity with combinatorial flavour. The choice of material and the choice of proofs is terrific and it is an ideal book for a course for graduate students and advanced undergraduates.  Congratulations, Imre!</p>
<p>The <a href="https://bookstore.ams.org/ulect-77/">AMS page</a> gives the following description</p>
<blockquote><p><span style="color: #0000ff;"><em>This book is about the combinatorial properties of convex sets, families of convex sets in finite dimensional Euclidean spaces, and finite points sets related to convexity. This area is classic, with theorems of Helly, Carathéodory, and Radon that go back more than a hundred years. At the same time, it is a modern and active field of research with recent results like Tverberg’s theorem, the colourful versions of Helly and Carathéodory, and the <span class="MathJax" id="MathJax-Element-1-Frame"><span class="math" id="MathJax-Span-1"><span class="mrow" id="MathJax-Span-2"><span class="mo" id="MathJax-Span-3">(</span><span class="mi" id="MathJax-Span-4">p</span><span class="mo" id="MathJax-Span-5">,</span><span class="mi" id="MathJax-Span-6">q</span><span class="mo" id="MathJax-Span-7">)</span></span></span></span> theorem of Alon and Kleitman. As the title indicates, the topic is convexity and geometry, and is close to discrete mathematics. The questions considered are frequently of a combinatorial nature, and the proofs use ideas from geometry and are often combined with graph and hypergraph theory. </em></span></p>
<p><span style="color: #0000ff;"><em>The book is intended for students (graduate and undergraduate alike), but postdocs and research mathematicians will also find it useful. It can be used as a textbook with short chapters, each suitable for a one- or two-hour lecture. Not much background is needed: basic linear algebra and elements of (hyper)graph theory as well as some mathematical maturity should suffice.</em></span></p></blockquote>
<p>Here is also <a href="https://www.amazon.com/Combinatorial-Convexity-University-Lecture-77/dp/1470467097">the Amzon page</a>.</p>
<p><img alt="ib2" class="alignnone size-full wp-image-22521" src="https://gilkalai.files.wordpress.com/2022/03/ib2.png?w=640"/></p></div>
    </content>
    <updated>2022-03-21T07:55:52Z</updated>
    <published>2022-03-21T07:55:52Z</published>
    <category term="Combinatorics"/>
    <category term="Convexity"/>
    <category term="Geometry"/>
    <category term="Imre Barany"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2022-03-27T23:37:37Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-7134833319825279941</id>
    <link href="http://blog.computationalcomplexity.org/feeds/7134833319825279941/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/03/do-you-want-to-be-sigact-news-book.html#comment-form" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/7134833319825279941" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/7134833319825279941" rel="self" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/03/do-you-want-to-be-sigact-news-book.html" rel="alternate" type="text/html"/>
    <title>Do you want to be the SIGACT NEWS book review editor?</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I ran the SIGACT Book Review Column from 1997-2015 (18 years). You can find all of my columns, plus reviews I did for Fred, <a href="http://www.cs.umd.edu/~gasarch/bookrev/bookrev.html">here</a>.</p><p>When I handed it off to Fred Green I gave him this sage advice:</p><p>                   <i>Nobody should do this kind of job for more than about 5 years.</i></p><p>He ran the SIGACT Book Review Column since the end of 2015. You can find some of his columns <a href="http://mathcs.clarku.edu/~fgreen/SIGACTReviews/bookrev/bookrev.html">here</a>.</p><p>Fred is taking my advice and looking for a successor.</p><p>SO, this blog is a call to ask</p><p>                 DO YOU WANT TO BE THE SIGACT NEWS BOOK REVIEW EDITOR?</p><p>If so then email</p><p>Fred: fgreen@clarku.edu</p><p><br/></p><p>DO NOT BE SHY! I suspect he won't get many applicants, so if you want the job its probably yours.</p><p><br/></p><p>PROS</p><p>1) You get to skim lots of books and read some of  them.</p><p>2) You get some free books.</p><p>3) You get plugged into the book community (this helped me when I wrote my two books).</p><p>4) You'll have two Veteran Book Review Editors happy to review for you.</p><p>5) You get to decide the direction the column goes in.</p><p>Both Fred and I did mostly CS theory books. However:</p><p>a) I did more combinatorics, educational, history, and Computers &amp; Society books than usual.</p><p>b) Fred did more Number Theory and Physics than usual.</p><p>(Since I did the job 18 years and Fred for 6, its not clear what <i>usual</i> means.) </p><p><br/></p><p>CONS</p><p>1) You have to get out a book review column 4 times a year.</p><p>2) You have to find reviewers for books and then email them when the reviews are due.</p><p>(I think Fred is still waiting for me to review a Biography of Napier. Oh well. On the other hand, I was the one who liked having history books, which may explain why Fred never hassled me about it.) </p><p><br/></p><p>ADVICE</p><p>Prob should be done by someone who already has Tenure. While seeing and skimming thosebooks is GOOD for your research career, and good in the long-termsomeone pre-tenure really needs to get papers out in the short term. Also, when you get a book think about who might be good to review it--- don't take on to many yourself. </p><p><br/></p><p>PARTING GIFT OR WELCOME GIFT</p><p>In a recent column I had a review of a 5-book set from the LESS WRONG blog. I amcurrently working on a review of a 4-book set set from the LESS WRONG blog. This willeither be a parting gift for Fred or a Welcome gift to his successor.</p><p><br/></p></div>
    </content>
    <updated>2022-03-21T03:16:00Z</updated>
    <published>2022-03-21T03:16:00Z</published>
    <author>
      <name>gasarch</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03004932739846901628</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="http://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2022-03-27T22:34:37Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=8295</id>
    <link href="https://windowsontheory.org/2022/03/20/cool-projects-from-my-crypto-class/" rel="alternate" type="text/html"/>
    <title>Cool projects from my crypto class</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">This fall, I taught my course CS 127: Cryptography, based on my lecture notes: “An intensive introduction to cryptography”. This is a course that starts with no background knowledge, and gets to advanced concepts including lattice-based (aka “post quantum”) encryption, fully homomorphic encryption, zero-knowledge proofs, multiparty secure computation, software obfuscation, quantum computing and crypto, and … <a class="more-link" href="https://windowsontheory.org/2022/03/20/cool-projects-from-my-crypto-class/">Continue reading <span class="screen-reader-text">Cool projects from my crypto class</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>This fall, I taught my course <a href="https://cs127.boazbarak.org/">CS 127: Cryptography</a>, based on my lecture notes: <a href="https://intensecrypto.org/">“An intensive introduction to cryptography”</a>. This is a course that starts with no background knowledge, and gets to advanced concepts including lattice-based (aka “post quantum”) encryption, fully homomorphic encryption, zero-knowledge proofs, multiparty secure computation, software obfuscation, quantum computing and crypto, and more. </p>



<p><a href="https://cs127.boazbarak.org/projects/">As in previous years</a>, I had an fantastic group of students, several of whom produced impressive course projects. These include the following: </p>



<p><strong>Gavin Uberti</strong>, <strong>Kevin Luo</strong>, <strong>Oliver Cheng,</strong>  and <strong>Wittmann Goh</strong> <a href="https://arxiv.org/abs/2112.04581">implemented Witness Encryption</a>. Witness encryption is a cool concept whereby you can encrypt a secret X (for example the private key corresponding to a bitcoin wallet) so that people can decrypt X if and only if they can find a solution to some puzzle P. You can do this <em>even if you don’t know a solution yourself!</em> So for example you could use this to offer an automatically paying reward for a formal proof of the Reimann Hypothesis, or as they did, offer 2270  Satoshis to anyone solving this Soduko puzzle:</p>



<figure class="wp-block-image size-large"><a href="https://windowsontheory.files.wordpress.com/2022/03/image.png"><img alt="" class="wp-image-8301" src="https://windowsontheory.files.wordpress.com/2022/03/image.png?w=503"/></a></figure>



<p><strong>Simas Sakenis</strong> wrote a <a href="https://windowsontheory.files.wordpress.com/2022/03/simas_project.pdf">survey of proofs of stake in cryptocurrencies</a>,  providing a uniform formalizaiton of proofs of work and proofs of stake, and explaining the difference. </p>



<p><strong>Michael Kiestra</strong> and <strong>Beatrice Nash</strong> proposed  <a href="https://windowsontheory.files.wordpress.com/2022/03/kiestra_nash.pdf">CLAMBAKE</a>,  a protocol that uses broadcast encryption and Yao’s garbled circuits to achieve a privacy-preserving protocol for facilitating access to controlled resources such as university buildings.</p>



<p>(There were more projects in the course, but some students preferred not to post these publicly since they are still working on them; I will update this post with more projects if appropriate.)</p>



<p/></div>
    </content>
    <updated>2022-03-20T21:11:37Z</updated>
    <published>2022-03-20T21:11:37Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2022-03-27T23:38:03Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2022/03/20/postdoc-at-hamburg-university-of-technology-apply-by-april-8-2022/</id>
    <link href="https://cstheory-jobs.org/2022/03/20/postdoc-at-hamburg-university-of-technology-apply-by-april-8-2022/" rel="alternate" type="text/html"/>
    <title>Postdoc at Hamburg University of Technology (apply by April 8, 2022)</title>
    <summary>The Institute for Algorithms and Complexity at Hamburg University of Technology is seeking a postdoc to work on algorithms for combinatorial optimization and operations research (pay level TV-L 14). These can be approximation algorithms, parameterized algorithms, dynamic algorithms, streaming algorithms, or related. Join our international team to solve some of the most intractable problems! Website: […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Institute for Algorithms and Complexity at Hamburg University of Technology is seeking a postdoc to work on algorithms for combinatorial optimization and operations research (pay level TV-L 14). These can be approximation algorithms, parameterized algorithms, dynamic algorithms, streaming algorithms, or related. Join our international team to solve some of the most intractable problems!</p>
<p>Website: <a href="https://stellenportal.tuhh.de/jobposting/6816c1195abac5e2e9f2c7f1a72506004fd3ead0">https://stellenportal.tuhh.de/jobposting/6816c1195abac5e2e9f2c7f1a72506004fd3ead0</a><br/>
Email: algo@tuhh.de</p></div>
    </content>
    <updated>2022-03-20T20:42:51Z</updated>
    <published>2022-03-20T20:42:51Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2022-03-27T23:37:46Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2022/03/20/ukraine-student-postdoc-senior-research-fellows-at-ben-gurion-university-apply-by-december-6-2022/</id>
    <link href="https://cstheory-jobs.org/2022/03/20/ukraine-student-postdoc-senior-research-fellows-at-ben-gurion-university-apply-by-december-6-2022/" rel="alternate" type="text/html"/>
    <title>Ukraine  Student/ Postdoc/  Senior Research  Fellows at Ben-Gurion University (apply by December 6, 2022)</title>
    <summary>If you are a student/scholar affected by the war in Ukraine, BGU offers an emergency scholarship, furthermore, I also have immediately available funds for those who are interested in doing research in Theoretical computer science or Error-Correcting Codes. Website: https://www.tfaforms.com/399172?fbclid=IwAR1AW_tvfxoC6yA7EXcptO5tr3SjOM0dAgngz6v6WtlMfHr1ghDwXC0MMt4, https://www.cs.bgu.ac.il/~klim/ Email: klimefrem@gmail.com</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>If you are a student/scholar affected by the war in Ukraine, BGU offers an emergency scholarship, furthermore, I also have immediately available funds for those who are interested in doing research in Theoretical computer science or Error-Correcting Codes.</p>
<p>Website: <a href="https://www.tfaforms.com/399172?fbclid=IwAR1AW_tvfxoC6yA7EXcptO5tr3SjOM0dAgngz6v6WtlMfHr1ghDwXC0MMt4">https://www.tfaforms.com/399172?fbclid=IwAR1AW_tvfxoC6yA7EXcptO5tr3SjOM0dAgngz6v6WtlMfHr1ghDwXC0MMt4</a>, <a href="https://www.cs.bgu.ac.il/~klim/">https://www.cs.bgu.ac.il/~klim/</a><br/>
Email: klimefrem@gmail.com</p></div>
    </content>
    <updated>2022-03-20T16:54:04Z</updated>
    <published>2022-03-20T16:54:04Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2022-03-27T23:37:46Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://tcsplus.wordpress.com/?p=606</id>
    <link href="https://tcsplus.wordpress.com/2022/03/19/tcs-talk-wednesday-march-23-shuichi-hirahara-national-institute-of-informatics-japan/" rel="alternate" type="text/html"/>
    <title>TCS+ talk: Wednesday, March 23 — Shuichi Hirahara, National Institute of Informatics, Japan</title>
    <summary>The next TCS+ talk will take place this coming Wednesday, March 23rd at 6:00 PM Eastern Time (1:00 PM Pacific Time, 13:00 Central European Time, 22:00 UTC [note the unusual time!]). Shuichi Hirahara from the National Institute of Informatics, Japan will speak about “Excluding PH Pessiland” (abstract below). You can reserve a spot as an […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The next TCS+ talk will take place this coming Wednesday, March 23rd at 6:00 PM Eastern Time<strong> (1:00 PM Pacific Time, 13:00 Central European Time, 22:00 UTC [note the unusual time!]).</strong> <a href="https://researchmap.jp/shuichi.hirahara/?lang=english"><strong>Shuichi Hirahara</strong></a> from the National Institute of Informatics, Japan will speak about “<em>Excluding PH Pessiland</em>” (abstract below).</p>
<p>You can reserve a spot as an individual or a group to join us live by signing up on <a href="https://sites.google.com/view/tcsplus/welcome/next-tcs-talk">the online form</a>. Registration is <em>not</em> required to attend the interactive talk, and the link will be posted on the website the day prior to the talk; however, by registering in the form, you will receive a reminder, along with the link. (The recorded talk will also be posted <a href="https://sites.google.com/view/tcsplus/welcome/past-talks">on our website</a> afterwards) As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/view/tcsplus/welcome/suggest-a-talk">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/view/tcsplus/">the website</a>.</p>
<blockquote class="wp-block-quote"><p>Abstract: Pessiland is the worst of Impagliazzo’s five possible worlds: it is a world where NP is hard on average and pseudorandom generators do not exist. Excluding Pessiland (i.e., showing the equivalence between average-case hardness of NP and the existence of pseudorandom generators) is one of the most important open questions in theoretical computer science. In this talk, we propose to consider PH (Polynomial Hierarchy) variants of Impagliazzo’s five possible worlds. Our main result is to unconditionally rule out PH variants of Pessiland. I will also mention recent progress on excluding PH Heuristica: average-case hardness of PH follows from exponential worst-case hardness of PH.</p>
<p>Based on joint works with Rahul Santhanam.</p></blockquote></div>
    </content>
    <updated>2022-03-19T05:22:43Z</updated>
    <published>2022-03-19T05:22:43Z</published>
    <category term="Announcements"/>
    <author>
      <name>plustcs</name>
    </author>
    <source>
      <id>https://tcsplus.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://tcsplus.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://tcsplus.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://tcsplus.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://tcsplus.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A carbon-free dissemination of ideas across the globe.</subtitle>
      <title>TCS+</title>
      <updated>2022-03-27T23:38:38Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://emanueleviola.wordpress.com/?p=998</id>
    <link href="https://emanueleviola.wordpress.com/2022/03/17/focs-2022/" rel="alternate" type="text/html"/>
    <title>FOCS 2022</title>
    <summary>I am on the FOCS 2022 Program Committee, and I am overjoyed that the PC meeting will be virtual. Hopefully, the days are over when the program chair can brush aside all cost-benefit considerations, impose their backyard on far-away scholars who need service items, and then splash their offspring at the welcome party. I am […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I am on the <a href="https://focs2022.eecs.berkeley.edu/cfp.html">FOCS 2022 </a>Program Committee, and I am overjoyed that the PC meeting will be virtual.  Hopefully, the days are over when the program chair can brush aside all cost-benefit considerations, impose their backyard on far-away scholars who need service items, and then splash their offspring at the welcome party.</p>



<p>I am also overjoyed that we will be implementing double-blind reviews.  This issue has been discussed and ridiculed at length.  Admittedly, it makes it harder to adhere to Leonid Levin’s 1995 influential <em><a href="https://dl.acm.org/doi/10.1145/202840.606487">STOC Criteria</a></em>.  For example, if a reviewer wanted to trash a paper based on the fact that the authors are not in the position to judge their own work, now they’ll have to check online for talks or preprints to know who the authors are.  Given the volume of reviews, it’s reasonable to expect that in some cases the reviewer won’t be able to conclusively exclude that a letter-writer is among the authors.  In such a situation they can resort to writing a very long, thorough, and competent review whose most significant digit is the STOC/FOCS death sentence: <em>weak accept</em>.</p>



<p>No, I actually do have something more constructive to say about this.  I was — as they say — privileged to serve on many NSF panels.  As an aside, it’s interesting that there the track-record of the investigators <em>is </em>a key factor in the decision; in fact, according to many including myself, it should carry even more weight, rather than forcing investigators to fill pages with made-up directions most of which won’t pan out.  But that’s another story; what is relevant for this post is that each panel begins with a quick “de-biasing” briefing, which I actually enjoy and from which I learnt something.  For example, there’s a classic experiment where the ratio of females hired as musicians increases if auditions hide the performer behind a tent and make them walk in on carpet so you can’t tell what shoes they are wearing.  Similar experiments exist that hide names from the folders of applicants, etc.  What I propose is to do a similar thing when reviewing papers.  That is, start with a de-biasing briefing: tell reviewers to ask themselves whether their attitude towards a paper would be different if:</p>



<ol><li>The authors of this paper/previous relevant work were ultra-big shots, or</li><li>The authors of this paper/previous relevant work were hapless nobodies, or</li><li>The proofs in this paper could be simplified dramatically to the point that even I understand them, or</li><li>This result came with a super-complicated proof which I can’t even begin to follow, or</li></ol>



<p>What other questions would be good to ask?</p></div>
    </content>
    <updated>2022-03-17T14:27:29Z</updated>
    <published>2022-03-17T14:27:29Z</published>
    <category term="Uncategorized"/>
    <category term="utopia-tcs"/>
    <author>
      <name>Manu</name>
    </author>
    <source>
      <id>https://emanueleviola.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://emanueleviola.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://emanueleviola.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://emanueleviola.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://emanueleviola.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>by Manu</subtitle>
      <title>Thoughts</title>
      <updated>2022-03-27T23:38:17Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-3213642318918472638</id>
    <link href="http://blog.computationalcomplexity.org/feeds/3213642318918472638/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/03/the-war-and-math.html#comment-form" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/3213642318918472638" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/3213642318918472638" rel="self" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/03/the-war-and-math.html" rel="alternate" type="text/html"/>
    <title>The War and Math</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>During the early parts of the cold war of the 20th century, we saw two almost independent developments of computational complexity, in the west and in the then USSR. There was little communication between the two groups, and countless theorems proven twice, most notably the seminal NP-complete papers of Cook and Levin. To understand more, I recommend the two articles about the early days of complexity by <a href="https://doi.org/10.1109/MAHC.1981.10005">Juris Hartmanis</a> and by <a href="https://doi.ieeecomputersociety.org/10.1109/MAHC.1984.10036">Boris Trakhtenbrot</a>.</p><p>Russia's invasion and relentless bombing in Ukraine have quickly separated the east and the west again. </p><p>Our first concern needs to be with Ukraine and its citizens. We hope for a quick end to this aggression and Ukraine remaining a free and democratic country. Ukrainian cities have undergone massive damage, and even in the best possible outcome it will take years if not decades to fully rebuild the country. </p><p>Terry Tao has been <a href="https://terrytao.wordpress.com/2022/03/02/resources-for-displaced-mathematicians/">collecting resources</a> for displaced mathematicians due to the crisis.</p><p>We've cut off ties with Russia institutions. In our world, major events to be held in Russia, including the <a href="https://www.mathunion.org/">International Congress of Mathematics</a> and the <a href="https://logic.pdmi.ras.ru/csr2022/">Computer Science in Russia</a> conference are being moved online. I was invited to workshops in St Petersburg in 2020 and 2021, both cancelled due to Covid, and was looking forward to one in 2022, which if it happens, will now happen without me. </p><p>The music world has has cancelled some stars, most notably <a href="https://www.nytimes.com/2022/03/02/arts/music/ukraine-putin-valery-gergiev-anna-netrebko.html">Valery Gergiev and Anna Netrebko</a>, due to their close ties to Putin. It's rare that we do the same to mathematicians for political reasons though <a href="https://blog.computationalcomplexity.org/2019/06/imus-non-controversial-changing-name-of.html">not unheard of</a>. I suspect most of our colleagues in Russia oppose the war in Ukraine, or would if they had accurate information of what was going on. I have several Russian friends and colleagues including <a href="https://blog.computationalcomplexity.org/2019/06/compressing-in-moscow.html">two I travelled to Moscow in 2019 to honor</a> and would hate to be disconnected from them.</p><p>It's way too early to know how this will all play out. Will we see a quick Russian retreat? Not likely. Will we see a situation that sees a mass migration of Ukranian and Russian mathematicians and computer scientists to Europe and North America, like in the 1990's? Possibly. We will see a repeat of the cold war, disconnected internets and science on both sides happening in isolation? I hope not but we can't rule it out.</p></div>
    </content>
    <updated>2022-03-17T13:28:00Z</updated>
    <published>2022-03-17T13:28:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="http://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2022-03-27T22:34:37Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://rjlipton.wpcomstaging.com/?p=19755</id>
    <link href="https://rjlipton.wpcomstaging.com/2022/03/17/meta-wishes/" rel="alternate" type="text/html"/>
    <title>Meta Wishes</title>
    <summary>When faced with two choices, simply toss a coin. It works because in that brief moment when the coin is in the air, you suddenly know what you are hoping for. Neil L. is a leprechaun. He has been visiting me or Ken once every year since we started GLL. We had never seen a […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><font color="#0044cc"><br/>
<em>When faced with two choices, simply toss a coin. It works because in that brief moment when the coin is in the air, you suddenly know what you are hoping for.</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<p><a href="https://rjlipton.wpcomstaging.com/2022/03/17/meta-wishes/neill-2/" rel="attachment wp-att-19757"><img alt="" class="alignright wp-image-19757" height="153" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/03/NeilL.jpg?resize=146%2C153&amp;ssl=1" width="146"/></a></p>
<p><font color="darkgreen"/></p><font color="darkgreen">
<p>
Neil L. is a leprechaun. He has been visiting me or Ken once every year since we started GLL. We had never seen a leprechaun before we began the blog—there must be some connection. </p>
<p>
Today we want to share the experience we each had with him this morning of St. Patrick’s Day.<br/>
<span id="more-19755"/></p>
<p>
That’s right—Neil visited both of us separately. Four years ago, when I had major heart surgery on St. Patrick’s Eve, Neil <a href="https://rjlipton.wpcomstaging.com/2018/03/17/leprechauns-know-what-it-feels/">came</a> to my previous New York apartment, grabbed a page of my notes, and took it to Ken. The past two years, Ken was on Zoom with me when Neil appeared. This time, Neil had a bone to pick with Ken—after posing a problem to me.</p>
<p>
</p><p/><h2> Neil’s Problem </h2><p/>
<p/><p>
Kathryn, my dear wife, and I are still in our new midtown Manhattan apartment after my procedure two weeks ago. She went to sleep in the bedroom, but I stayed up awaiting Neil’s arrival. I must have dozed off, but jolted awake to his laugh and the waft of his pipe’s green smoke.</p>
<p>
Neil said hi and explained right away that he had a problem. “A classic problem that leprechauns have faced forever.” I nodded to him and rubbed my eyes to be awake enough to listen. Neil continued:</p>
<blockquote><p><b> </b> <em> The other day I was minding me business and I fell into a trap. Nasty fall. The trapper was an old foe of mine. She told me she had three wishes. And I was bound to grant them as usual. Sae much, sae normal. But then she breached the rules. </em>
</p></blockquote>
<p>
</p><p/><h2> No More Wishes </h2><p/>
<p/><p>
Now I knew the rules of wishes, so Neil did not have to tell me: Must be about something contingent, not love or death, no self-transmogrification, and most of all—well, let’s hear it from the genie in Disney’s <a href="https://en.wikipedia.org/wiki/Aladdin_(1992_Disney_film)">Aladdin</a>:</p>
<blockquote><p><b> </b> <em> “Three wishes, three. Uno, dos, tres, no substitutions, exchanges, or refunds, and ixnay on the wishing for more wishes.” </em>
</p></blockquote>
<p/></font><p><font color="darkgreen">
Neil picked up his story: “Her first two wishes were:<br/>
</font> </p>
<ol>
<li>
A pot of gold coins. <p/>
</li><li>
Another pot of gold.
</li></ol>
<p><font color="darkgreen"/></p><font color="darkgreen">
<p>
Those were fair and I showed I could handle them forthwith. But then she asked for: </p>
<blockquote><p><b> </b> <em> ‘Please ten chirag oil lamps, each with a genie who can grant three wishes.’ </em>
</p></blockquote>
<p/><p>
This was terrible. It sent me to the lore. Ye cannot ask your servant for more wishes. Ye cannot involve another leprechaun. But lamps of themselves are just objects. That a <em>chirag</em> lamp has a genie is like an oyster has a pearl. Even if half the lamps be duds, that still  compounds the wishes—and she wished for ten that were not duds.”</p>
<p>
</p><p/><h2> Math and Myth </h2><p/>
<p/><p>
Neil puffed a few more times, as if really expecting an answer from me. He even prompted, “What do ye think?” </p>
<p>
That sent me into befuddlement. Usually I try to engage Neil on a <em>math</em> problem, to trick him into telling the answer to Riemann or factoring or P=NP. But despite the “<img alt="{&gt; 3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%3E+3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>” aspect, this wasn’t math—it was more about <em>myth</em>. Math I can take seriously, but with weighty matters personal and worldwide, I did not want to play “meta” games. </p>
<p>
Neil read my mind: “Nay, I assure ye—it be really about math. Even the Riemann—”</p>
<p>
That made me think: if Neil knew that it had real math content, he must know the answer already. No sense groping for it groggily. I just retorted: “I don’t want to guess the answer. Please just tell me.”</p>
<p>
“Ye know there be only one way I ever tell ye answers…”</p>
<p>
“Sure. OK.” I really wanted to join Kathryn for some sleep.</p>
<p>
I blinked as Neil vanished in green light. Only his pipe smoke remained, and it curled around into a shape I couldn’t place at first. It took awhile to become sharp enough that I could tell what it was:</p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2022/03/17/meta-wishes/greenzeta/" rel="attachment wp-att-19758"><img alt="" class="aligncenter wp-image-19758" height="123" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/03/GreenZeta.png?resize=60%2C123&amp;ssl=1" width="60"/></a></p>
<p/><h2> Myth and Math </h2><p/>
<p/><p>
I, Ken, shall tell the rest. Ordinarily, I would have been eager to engage Neil again about the NCAA basketball tournaments. But I too am too touched by the same weighty matters, and quite forgot the day.</p>
<p>
My unawareness did not matter because Neil apparated and instantly started confronting me: “What gave ye the mickey to <a href="https://rjlipton.wpcomstaging.com/2022/03/14/are-these-the-last-digits-of-pi/">write</a> of mathematics being ’emergent’? Ye dinna even define it.”</p>
<p>
I had to concede I’d not only been vague but had analogized it too to two senses of “emergent” in philosophy. I started to explain: “It’s like Albert Einstein’s famous question, ‘Did God have a choice?’ among physical laws. Now about math…”</p>
<p>
Neil cut me off: “When Einstein said ‘God,’ he meant nature—but when <em>you</em> say it, you mean leprechauns. You are asking: ‘Do we leprechauns have the power to change mathematical truths in advance of your learning them?’ That’s our turf—!”</p>
<p>
I stammered that I had a right to pose the question and had not meant to insinuate. But Neil kept on: “If we really could change outcomes then what would <em>maths</em> rest on? On <em>myths</em> just as well. But where ye speak of <em>law</em>, we have <em>lore</em>. Established rules. And they suffice.”</p>
<p>
This was waxing cryptic and I thought bringing up Kurt Gödel would only make it more so. Neil sensed I was adrift and went on: “I shall inform ye via the same story I told Dick.”</p>
<p>
</p><p/><h2> Neil’s Solution </h2><p/>
<p/><p>
Neil unfurled his story. At his same pause, one perception dawned on me: “Neil, did the lady’s wish imply a recursion—meaning the genies would be asked for a wish generator in the same proportion?”</p>
<p>
Neil nodded: “The lore says yes—the lore on hearing what is said. That is what I consulted it for. The rest I could work out on paper.” </p>
<p>
The paper part was easy up to a point. The wishes implied an infinite summation: the original <img alt="{3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, then <img alt="{30}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B30%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> more of the ten genies, with the third wishes to each bringing <img alt="{30}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B30%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> at the next level, for <img alt="{30 \cdot 10 = 300}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B30+%5Ccdot+10+%3D+300%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> more wishes there, and so on. In sum, </p>
<p align="center"><img alt="\displaystyle  3 + 30 + 300 + 3000 + \cdots = 3\cdot (1 + 10 + 100 + 1000 + \cdots) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++3+%2B+30+%2B+300+%2B+3000+%2B+%5Ccdots+%3D+3%5Ccdot+%281+%2B+10+%2B+100+%2B+1000+%2B+%5Ccdots%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>wishes. Clearly the number of wishes is bounded by the series </p>
<p align="center"><img alt="\displaystyle  3\cdot(1 + 10 + 3^{\log_2 10} + 100 + 5^{\log_2 10} + 6^{\log_2 10} + 7^{\log_2 10} + 1000 + \cdots) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++3%5Ccdot%281+%2B+10+%2B+3%5E%7B%5Clog_2+10%7D+%2B+100+%2B+5%5E%7B%5Clog_2+10%7D+%2B+6%5E%7B%5Clog_2+10%7D+%2B+7%5E%7B%5Clog_2+10%7D+%2B+1000+%2B+%5Ccdots%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>Which equals <img alt="{3\cdot \zeta(-\log_2 10)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3%5Ccdot+%5Czeta%28-%5Clog_2+10%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. Without asking Neil how he’d computed that, I went to an <a href="https://solvemymath.com/online_math_calculator/number_theory/riemann_function/index.php">online</a> zeta <a href="https://keisan.casio.com/exec/system/1180573439">calculator</a> and obtained a bounding total of </p>
<p align="center"><img alt="\displaystyle  3\cdot 0.006023525392866159581193... \;\;= \;\;+0.018070576178598478743579... " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++3%5Ccdot+0.006023525392866159581193...+%5C%3B%5C%3B%3D+%5C%3B%5C%3B%2B0.018070576178598478743579...+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>wishes. Neil puffed and chortled and finished his story:</p>
<blockquote><p><b> </b> <em> “So the unlucky lass had wished herself into wishing a grand total of less than one-fiftieth of a wish. Since only whole wishes can be honoured, this sprang me from the trap and kept me both me pots o’ gold to boot. I gave her one coin as a peace offering.” </em>
</p></blockquote>
<p/><p>
I joined the laughter for just a moment. This followed mathematical rules but outlandishly, and I groped for the point. But Neil supplied it directly:</p>
<blockquote><p><b> </b> <em> “Some of your fellow travelers have felt reaching answers by non-constructive methods to be less outlandish only in degree not kind. If ye later apprehend the answer by calculation—which is what your post styled as “emergent” knowledge—then it must be exactly the same object previously described non-constructively. Thus in the realms ye ascribed to us wee folk, we are the guardians and gatekeepers of truth, not the forgers of it.” </em>
</p></blockquote>
<p/><p>
Neil tipped his hat and simply faded out—no green smoke for me.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Can Neil’s zeta-function calculations insulate against any attempt at recursively gaining infinite wishes? The zeta function whips up and down in tune with the Bernoulli numbers, but the leprechauns do have freedom to choose a bounding series. Or is there an infinite series scheme that rises above 3 wishes even so? We hope this has given some St. Patrick’s Day diversion.</p>
<p/></font></font></font></div>
    </content>
    <updated>2022-03-17T05:58:57Z</updated>
    <published>2022-03-17T05:58:57Z</published>
    <category term="leprechauns"/>
    <category term="Neil L."/>
    <category term="philosophy"/>
    <category term="St. Patrick's Day"/>
    <category term="zeta function"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wpcomstaging.com</id>
      <logo>https://s0.wp.com/i/webclip.png</logo>
      <link href="https://rjlipton.wpcomstaging.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wpcomstaging.com" rel="alternate" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel's Lost Letter and P=NP</title>
      <updated>2022-03-27T23:37:41Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2022/03/16/postdoc-at-sandia-national-labs-apply-by-march-31-2022/</id>
    <link href="https://cstheory-jobs.org/2022/03/16/postdoc-at-sandia-national-labs-apply-by-march-31-2022/" rel="alternate" type="text/html"/>
    <title>Postdoc at Sandia National Labs (apply by March 31, 2022)</title>
    <summary>Sandia Labs is seeking a postdoc to work on quantum or quantum-inspired classical approximation, sublinear, or streaming algorithms, as part of a DOE-funded collaboration among several national labs and universities. We encourage theoretical computer scientists interested in quantum information but without prior expertise to apply. Website: https://far-qc.sandia.gov/job-opportunities/ Email: odparek@sandia.gov</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Sandia Labs is seeking a postdoc to work on quantum or quantum-inspired classical approximation, sublinear, or streaming algorithms, as part of a DOE-funded collaboration among several national labs and universities. We encourage theoretical computer scientists interested in quantum information but without prior expertise to apply.</p>
<p>Website: <a href="https://far-qc.sandia.gov/job-opportunities/">https://far-qc.sandia.gov/job-opportunities/</a><br/>
Email: odparek@sandia.gov</p></div>
    </content>
    <updated>2022-03-16T23:26:53Z</updated>
    <published>2022-03-16T23:26:53Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2022-03-27T23:37:46Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2022/03/15/linkage</id>
    <link href="https://11011110.github.io/blog/2022/03/15/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>Here’s a silly but probably new proof that the harmonic series diverges (\(\mathbb{M}\)). The expected number of comparisons used by randomized quicksort on an input of size \(n\) is at most \(2nH_n\), where \(H_n\) is the \(n\)th partial sum of the harmonic series (see Cormen et al, Introduction to Algorithms, Chapter 7). However, every comparison sorting algorithm requires at least \(\log_2n!=n\log_2n-O(n)\) comparisons, by the standard decision tree argument (Cormen et al, Section 8.1). Therefore, \(H_n=\Omega(\log n)\).</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><ul>
  <li>
    <p>Here’s a silly but probably new proof that the harmonic series diverges <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107883892455172986">\(\mathbb{M}\)</a>).</span> The expected number of comparisons used by randomized quicksort on an input of size \(n\) is at most <span style="white-space: nowrap;">\(2nH_n\),</span> where \(H_n\) is the <span style="white-space: nowrap;">\(n\)th</span> partial sum of the harmonic series (see Cormen et al, <em>Introduction to Algorithms</em>, Chapter 7). However, every comparison sorting algorithm requires at least \(\log_2n!=n\log_2n-O(n)\) comparisons, by the standard decision tree argument (Cormen et al, Section 8.1). Therefore, <span style="white-space: nowrap;">\(H_n=\Omega(\log n)\).</span></p>
  </li>
  <li>
    <p>To be fair, the lecture hall I teach in this term doesn’t look quite so much like a prison if you enter by the main door at the top of the hall instead of the back door by the stage <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107890151210168412">\(\mathbb{M}\)</a>).</span></p>

    <p style="text-align: center;"><img alt="Humanities Lecture Hall, UC Irvine" src="https://www.ics.uci.edu/~eppstein/pix/hlh/hlh-m.jpg" style="border-style: solid; border-color: black;"/></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2203.00671">Maximum flow and minimum-cost flow in almost-linear time</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@FreddyR/107890263250219998">\(\mathbb{M}\)</a>).</span> New arXiv preprint by Li Chen, Rasmus Kyng, Yang P. Liu, Richard Peng, Maximilian Probst Gutenberg, Sushant Sachdeva. It assumes integer capacities but that’s enough to get near-linear bipartite maximum matching, itself a breakthrough.</p>
  </li>
  <li>
    <p>In early March, UC Berkeley was <a href="https://www.latimes.com/california/story/2022-03-04/how-much-will-uc-berkeley-have-to-cut-admissions-after-supreme-court-loss-what-we-know">ordered to drastically cut enrollment under California’s strict environmental impact review laws</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107899108816738487">\(\mathbb{M}\)</a>).</span> In practice these laws  are often used as a pretext for lawsuits to shake down or stop public developments for reasons unrelated to environmental impact (this is a heavily built-up area already; the impact is that it would have more students living in it and the people suing wanted to shake down UC for non-university-related low-income housing expansion). By mid-March, the state legislature had passed <a href="https://www.latimes.com/california/story/2022-03-14/california-legislature-passes-bill-berkeley-enrollment">emergency legislation to temporarily sidestep the issue</a>.</p>
  </li>
  <li>
    <p>Another batch of Wikipedia Good Articles <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107905159574583760">\(\mathbb{M}\)</a>):</span></p>

    <ul>
      <li>
        <p><a href="https://en.wikipedia.org/wiki/Fibonacci_nim">Fibonacci nim</a>: subtraction game with a Fibonacci number based strategy.</p>
      </li>
      <li>
        <p><a href="https://en.wikipedia.org/wiki/Kepler_triangle">Kepler triangle</a>: not the shape of the great pyramid of Giza, but one of its other properties inspired me to make the illustration below.</p>

        <p style="text-align: center;"><img alt="Isosceles triangle is formed from two Kepler triangles, reflected across their short sides, and its inscribed circle, having the maximum radius possible among all isosceles triangles with the same side length" src="https://11011110.github.io/blog/assets/2022/kepler.svg"/></p>
      </li>
      <li>
        <p><a href="https://en.wikipedia.org/wiki/Component_(graph_theory)">Connected components of undirected graphs</a>: saving this batch from complete frivolity.</p>
      </li>
    </ul>
  </li>
  <li>
    <p>New book in discrete geometry <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107914084986329325">\(\mathbb{M}\)</a>):</span> <em>Polynomial Methods and Incidence Geometry</em>, Adam Sheffer, Cambridge University Press. See <a href="https://adamsheffer.wordpress.com/2022/03/03/new-book-polynomial-methods-and-incidence-theory/">Adam’s announcement</a> and <a href="http://faculty.baruch.cuny.edu/ASheffer/000book.pdf">an early draft with missing chapters</a>.</p>
  </li>
  <li>
    <p>When I’ve been thinking recently about who I might know who is Ukrainian or Ukrainian-American, the first to mind was Andrea Danyluk, with whom I went to grad school. We lost touch later, but she had a long distinguished career at Williams College. <a href="https://president.williams.edu/in-memoriam/the-passing-of-andrea-danyluk/">Sadly, she died a few days ago</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107916240235667375">\(\mathbb{M}\)</a>).</span> The Computing Research Association chose her as the <a href="https://cra.org/about/awards/a-nico-habermann-award/#2022">2022 winner of their A. Nico Habermann Award for increasing diversity in computing research</a>, shortly before her death.</p>
  </li>
  <li>
    <p><a href="https://mathstodon.xyz/@jsiehler/107927992555262577">The SET card game is not accessible to the color-impaired</a>, its manufacturer shows no interest in fixing it or providing accessible alternatives, and is actively blocking any attempts by others to do the same. Sadly, this makes it unusable as a classroom activity.</p>
  </li>
  <li>
    <p><a href="https://www.asbmb.org/asbmb-today/careers/030822/what-s-with-wikipedia-and-women">What’s with Wikipedia and women?
Things are changing, little by little, at the open-source encyclopedia</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107933443665051198">\(\mathbb{M}\)</a>).</span> New article from the American Society for Biochemistry and Molecular Biology mentions in passing my efforts creating articles on women in STEM and patrolling deletion discussions on them.</p>
  </li>
  <li>
    <p><a href="https://sinews.siam.org/Details-Page/in-pursuit-of-perfect-pinnacles">In pursuit of perfect pinnacles</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107945184119710916">\(\mathbb{M}\)</a>).</span> Why do spiky shapes form in nature, for instance in limestone and ice? Leif Ristroph, Jinzi Mac Huang, and Michael Shelley survey recent research in this <em>SIAM News</em> column.</p>
  </li>
  <li>
    <p>Another Wikipedia Good Article, on an important rather than recreational topic: <a href="https://en.wikipedia.org/wiki/Harmonic_series_(mathematics)">harmonic series</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107950806929679318">\(\mathbb{M}\)</a>)</span>  on the divergent series</p>

\[\sum_{n=1}^\infty\frac{1}{n} = 1 + \frac{1}{2} + \frac{1}{3} + \frac{1}{4} + \frac{1}{5} + \cdots.\]

    <p>While cleaning it up I learned that the term “harmonic number” and notation for its partial sums comes from Knuth, and also that the “crossing the desert” puzzle, one of the standard examples for harmonic series, dates to long before the harmonic series itself.</p>
  </li>
  <li>
    <p><a href="https://blog.plover.com/math/se/notation.html">Bad but interesting mathematical notation</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@mjd/107927925348652783">\(\mathbb{M}\)</a>).</span> Minimal subsystems of arithmetic aside, Mark-Jason Dominus wrestles with the problem of finding an intuitive visual representation for expressions that combine a single associative operation with two mutually inverse unary operations.</p>
  </li>
  <li>
    <p>Wikimedia foundation VP Maggie Dennis warns Wikipedia editors writing about the Russian invasion of Ukraine that <a href="https://lists.wikimedia.org/hyperkitty/list/wikimedia-l@lists.wikimedia.org/message/KIMZHJMWMKXFRCMWIE5WL3YIJNFMSNVH/">they are likely to be doxxed</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107956409088287040">\(\mathbb{M}\)</a>,</span> <a href="https://en.wikipedia.org/wiki/Wikipedia_talk:Did_you_know">via</a>), especially when their “activities are seen as opposing the Russian narrative of the war”. One assumes by the Russians, although she does not say that explicitly.</p>
  </li>
  <li>
    <p><a href="http://reconf.wikidot.com/">A wiki on combinatorial reconfiguration problems</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107963773811594015">\(\mathbb{M}\)</a>).</span> The main content at this point appears to be <a href="http://reconf.wikidot.com/papers/">their extensive bibliography of papers on the topic</a>, available both on-wiki and at a linked overleaf site. I can’t tell whether the wiki or overleaf version of the .bib file is supposed to be primary, though.</p>
  </li>
</ul></div>
    </content>
    <updated>2022-03-15T22:26:00Z</updated>
    <published>2022-03-15T22:26:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2022-03-16T05:27:41Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://differentialprivacy.org/dp-fine-tuning/</id>
    <link href="https://differentialprivacy.org/dp-fine-tuning/" rel="alternate" type="text/html"/>
    <title>Differentially private deep learning can be effective with self-supervised models</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Differential Privacy (DP) is a formal definition of privacy which guarantees that the outcome of a statistical procedure does not vary much regardless of whether an individual input is included or removed from the training dataset. 
This guarantee is desirable when we are tasked to train machine learning models on private datasets that should not memorize individual inputs. 
Past works have shown that differentially private models can be resilient to strong membership inference [<a href="https://proceedings.mlr.press/v37/kairouz15.html">1</a>, <a href="https://ieeexplore.ieee.org/abstract/document/9519424">34</a>, <a href="https://proceedings.neurips.cc/paper/2020/hash/fc4ddc15f9f4b4b06ef7844d6bb53abf-Abstract.html">35</a>] and data reconstruction attacks [<a href="https://www.usenix.org/conference/usenixsecurity19/presentation/carlini">2</a>, <a href="https://arxiv.org/abs/2201.12383">3</a>] when the privacy parameter is set to be sufficiently small. 
See a <a href="https://differentialprivacy.org/how-to-deploy-ml-with-dp/">prior post</a> for more background on differentially private machine learning.</p>

<p>Yet, in practice, most attempts at training differentially private deep learning models on moderately-sized datasets have resulted in large performance drops compared to when training without privacy-protection baked in. 
These performance drops are oftentimes large enough to discourage the adoption of differential privacy protection into machine learning pipelines altogether.</p>

<p>To provide a reference of the potential performance hit, the authors of [<a href="https://arxiv.org/abs/2102.12677">5</a>] trained a ResNet-20 from scratch on CIFAR-10 with a privacy budget of \(\epsilon=8\) that has test accuracy barely over 62% (see their Table 1). 
Contrast this with the 8.75% error rate (91.25% accuracy) reported for training the same architecture without enforcing differential privacy [<a href="https://openaccess.thecvf.com/content_cvpr_2016/html/He_Deep_Residual_Learning_CVPR_2016_paper.html">6</a>]. 
While some works report private learning results better than the above, absent additional data, pre-training, or external knowledge, most improvements have been incremental, and the test accuracy for CIFAR-10 models trained under modest privacy leakage (\(\epsilon=3\)) has roughly settled to ~70% in the literature [<a href="https://arxiv.org/abs/2011.11660">4</a>].</p>

<p>One reason behind the performance drop lies in sample efficiency — differentially private learning generally requires much more data than non-private learning to reach an acceptable level of performance. 
This also means that learning the high-level features (e.g., syntactic structure in text, edge detectors for images) necessary to perform specific tasks with private data can be much more sample-costly.</p>

<p>This blog post surveys results that leverage public self-supervised pre-training to obtain high-performing models through differentially private fine-tuning.
The pre-train-fine-tune paradigm is straightforward to execute and results in high-performing models under modest privacy budgets for many standard computer vision and natural language processing tasks. 
Moreover, existing results have shown that private fine-tuning consistently benefits from improvements in public pre-training.</p>

<h2 id="self-supervised-pre-training">Self-Supervised Pre-Training</h2>

<p>Self-supervised learning is a paradigm which leverages unlabeled data to learn representations that can be useful for a range of downstream tasks.
Since self-supervised learning doesn’t target specific tasks itself, 
the (pre-)training procedure doesn’t require labeled data — in many cases, mildly curated unlabeled data is sufficient for self-supervised pre-training to produce models for subsequent fine-tuning. 
So far, there have been two broadly successful instantiations of this learning paradigm in computer vision [<a href="http://proceedings.mlr.press/v119/chen20j.html">9</a>] and natural language processing [<a href="https://www.cs.ubc.ca/~amuham01/LING530/papers/radford2018improving.pdf">7</a>, <a href="https://arxiv.org/abs/1810.04805">8</a>]. 
We recap the two approaches below.<sup id="fnref:1"><a class="footnote" href="https://differentialprivacy.org/feed.xml#fn:1" rel="footnote">1</a></sup></p>

<p><strong>Contrastive pre-training for vision:</strong> 
One class of self-supervised methods in computer vision (SimCLR, [<a href="http://proceedings.mlr.press/v119/chen20j.html">9</a>]) performs pre-training through contrastive learning. 
Algorithms of this type produce embeddings for images with the goal of creating different embeddings for semantically different images and similar embeddings for similar ones. 
Concretely, the algorithm used in SimCLR forces models to produce similar embeddings for an image and its augmented siblings (e.g., image rotated by some degrees), 
and different embeddings for separate images (and their augmentations). 
The SimCLR framework with large scale models and compute led to state-of-the-art (non-private) ImageNet fine-tuning results at the time of its writing.</p>

<p><strong>Masked language modeling and autoregressive language modeling for text:</strong> 
Masked Language Modeling (MLM) and Auto-regressive Language Modeling (ALM) are two self-supervised pre-training approaches. 
While the former asks models to predict deliberately masked out tokens from a piece of text, the latter asks models to simply predict the next token in a sequence. 
With large amounts of unlabeled text data, large and expressive Transformer models [<a href="https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html">24</a>], and lots of compute, both approaches produce powerful models that are good starting points for downstream fine-tuning. 
For instance, Bidirectional Encoder Representations from Transformers (BERT, [<a href="https://arxiv.org/abs/1810.04805">8</a>]), produced state-of-the-art (non-private) results (at the time) for a large collection of language understanding tasks when fine-tuned on each.</p>

<h2 id="fine-tuning-self-supervised-models-with-dp-optimization">Fine-Tuning Self-Supervised Models With DP-Optimization</h2>
<p>Self-supervised pre-training is appealing in the context of differentially private machine learning. 
This is because (i) the mildly curated data needed for pre-training can usually be obtained cheaply from the public domain, and (ii) pre-trained models may contain useful domain knowledge that can reduce the sample complexity of subsequent private learning. 
A paradigm for private learning that leverages self-supervised pre-training could follow two steps:</p>

<ul>
  <li>collect cheap and public (unlabeled) data from the task domain (e.g., vision, language, etc.) to pre-train a model with self-supervised learning, and</li>
  <li>collect moderate amounts of task-specific private (labeled) data and fine-tune the pre-trained model under differential privacy to perform the task.<sup id="fnref:2"><a class="footnote" href="https://differentialprivacy.org/feed.xml#fn:2" rel="footnote">2</a></sup></li>
</ul>

<p>To date, some of the best differentially private deep learning results in the literature have resulted from instantiating this paradigm [<a href="https://arxiv.org/abs/2011.11660">4</a>, <a href="https://arxiv.org/abs/2110.05679">11</a>, <a href="https://arxiv.org/abs/2110.06500">12</a>].
Below, we review works which capitalize on self-supervised pre-training by differentially privately fine-tuning pre-trained models with an iterative gradient method like DP-SGD [<a href="https://dl.acm.org/doi/abs/10.1145/2976749.2978318">19</a>, <a href="https://ieeexplore.ieee.org/abstract/document/6736861">20</a>].<sup id="fnref:3"><a class="footnote" href="https://differentialprivacy.org/feed.xml#fn:3" rel="footnote">3</a></sup>
<img alt="" src="https://differentialprivacy.org/images/fine-tuning-paradigm.png"/></p>

<p><strong>Private fine-tuning with SimCLR features:</strong> 
The authors of [<a href="https://arxiv.org/abs/2011.11660">4</a>] fine-tuned a linear model on top of the embedding vectors produced by SimCLRv2 from the CIFAR-10 dataset. Under a privacy budget of \(\epsilon=2\), 
these models reached an average test accuracy of 92.7%. This number can be further improved to ~94% with the use of larger and wider pre-trained models in the SimCLRv2 family.<sup id="fnref:4"><a class="footnote" href="https://differentialprivacy.org/feed.xml#fn:4" rel="footnote">4</a></sup> 
These test accuracies are very close to some standard non-private results attained by an off-the-shelf ResNet architecture [<a href="https://openaccess.thecvf.com/content_cvpr_2016/html/He_Deep_Residual_Learning_CVPR_2016_paper.html">6</a>].</p>

<p><strong>Privately fine-tuning BERT variants and GPT-2:</strong> 
The authors of [<a href="https://arxiv.org/abs/2110.05679">11</a>, <a href="https://arxiv.org/abs/2110.06500">12</a>, <a href="http://proceedings.mlr.press/v139/yu21f.html">16</a>] showed that with appropriate hyper-parameters, fine-tuning BERT variants and GPT-2 with DP-optimization results in high-performing private models for text classification and language generation — even on datasets of modest sizes and under modest privacy budgets. 
Notably, some of these models attain a task performance close to non-private models from previous years in the literature. 
These results also exceed many non-private learning results from the pre-BERT and pre-GPT years.<sup id="fnref:5"><a class="footnote" href="https://differentialprivacy.org/feed.xml#fn:5" rel="footnote">5</a></sup></p>

<p>More interestingly, the authors showed that the larger (and thus better) the pre-trained model, the better the private fine-tuning performance gets. 
This empirical observation in private fine-tuning of large Transformers is qualitatively different from what’s implied by the usual minimax optimal rates derived for vanilla private learning with convex loss functions under approximate differential privacy [<a href="https://ieeexplore.ieee.org/abstract/document/6979031">14</a>, <a href="https://proceedings.neurips.cc/paper/2019/hash/3bd8fdb090f1f5eb66a00c84dbc5ad51-Abstract.html">15</a>]. 
This discrepancy between experimental results for training large models and the theory for learning with convex losses suggests there is more to be understood.<sup id="fnref:6"><a class="footnote" href="https://differentialprivacy.org/feed.xml#fn:6" rel="footnote">6</a></sup></p>

<p>Overall, for both vision and language tasks, private learning performance has consistently improved with the improvement in the quality of pre-training, 
where the latter is measured by the non-private fine-tuning performance.<sup id="fnref:7"><a class="footnote" href="https://differentialprivacy.org/feed.xml#fn:7" rel="footnote">7</a></sup></p>

<p>
  <img src="https://differentialprivacy.org/../images/figure1_classification.png" width="48%"/>
  <img src="https://differentialprivacy.org/../images/figure1_generation.png" width="48%"/> 
  Figure 1: Privately fine-tuning better (and larger) pre-trained models lead to consistently improving performance for text classification and language generation. 
Left: text classification on MNLI [<a href="https://arxiv.org/abs/1704.05426">25</a>]. Right: language generation on E2E [<a href="https://arxiv.org/abs/1706.09254">26</a>].
</p>

<h2 id="conclusion-and-outlook">Conclusion and Outlook</h2>

<p>We surveyed recent works in the literature that obtained highly performant private machine learning models leveraging self-supervised pre-training. 
Common to these results is the trend that the performance of private learning consistently improved with the quality of public pre-training. 
We therefore anticipate that the general paradigm may be useful in additional settings (e.g., federated learning) and tasks (e.g., private synthetic image generation), and lead to better private learning results.</p>

<p>We have thus far assumed that the data for public pre-training can be cheaply obtained.
This, however, does not imply that determining whether a particular source of data is appropriate for public pre-training is an easy problem.
Using publicly available data is not necessarily risk-free in terms of privacy.
For instance, the authors of [<a href="https://www.usenix.org/conference/usenixsecurity21/presentation/carlini-extracting">33</a>] were able to extract personally identifiable information from a GPT-2 model pre-trained on data scraped from the public internet.</p>

<p>Self-supervised pre-training has led to progress in private deep learning, but leveraging pre-trained models alone will not address several fundamental challenges to differentially private learning.
First and foremost, the datasets of machine learning tasks may be sampled from long-tailed distributions [<a href="https://proceedings.neurips.cc/paper/2020/hash/1e14bfe2714193e7af5abc64ecbd6b46-Abstract.html">21</a>]. 
When privately trained on such datasets, a machine learning model may fail to acquire the learning signal necessary to perform accurate predictions for examples on the tail [<a href="https://dl.acm.org/doi/abs/10.1145/3442188.3445934">28</a>] or from underrepresented (sub)populations [<a href="https://proceedings.neurips.cc/paper/2019/hash/fc0de4e0396fff257ea362983c2dda5a-Abstract.html">29</a>]. 
Second, many machine learning problems are in a domain where public data (even unlabeled data) may be sparse, e.g., medical imaging. 
Developing refined versions of the pre-train-fine-tune approach for problems from these domains is an interesting avenue for future work.</p>

<p>Lastly, differential privacy as one specific definition of privacy may not capture all that’s desired for privacy in reality. 
For instance, while differentially private algorithms naturally give machine unlearning guarantees [<a href="https://ieeexplore.ieee.org/abstract/document/9519428">30</a>, <a href="https://ieeexplore.ieee.org/abstract/document/7163042">32</a>], tailored unlearning algorithms tend to have higher capacities of unlearning [<a href="https://proceedings.neurips.cc/paper/2021/hash/9627c45df543c816a3ddf2d8ea686a99-Abstract.html">31</a>].
In addition, what constitutes a record in the differential privacy framework can oftentimes be unclear. 
Inappropriately defined example boundaries can create correlated records which cause differential privacy guarantees to degrade [<a href="https://arxiv.org/abs/1603.01508">22</a>].
Moreover, differential privacy guarantees won’t directly prevent the inference of private data outside the original context [<a href="https://heinonline.org/hol-cgi-bin/get_pdf.cgi?handle=hein.journals/washlr79&amp;section=16">23</a>]. 
These are fundamental limitations of differential privacy which improvements to differentially private learning won’t touch on.</p>

<h2 id="acknowledgements">Acknowledgements</h2>

<p>The authors thank Nicolas Papernot and Gautam Kamath for detailed feedback and edit suggestions.</p>

<hr/>

<h2 id="references">References</h2>
<p>[1] Rahman MA, Rahman T, Laganière R, Mohammed N, Wang Y. Membership Inference Attack against Differentially Private Deep Learning Model. Trans. Data Priv.. 2018 Apr 1;11(1):61-79.</p>

<p>[2] Carlini N, Liu C, Erlingsson Ú, Kos J, Song D. The secret sharer: Evaluating and testing unintended memorization in neural networks. In 28th USENIX Security Symposium (USENIX Security 19) 2019 (pp. 267-284).</p>

<p>[3] Guo C, Karrer B, Chaudhuri K, van der Maaten L. Bounding Training Data Reconstruction in Private (Deep) Learning. arXiv preprint arXiv:2201.12383. 2022 Jan 28.</p>

<p>[4] Tramer F, Boneh D. Differentially private learning needs better features (or much more data). arXiv preprint arXiv:2011.11660. 2020 Nov 23.</p>

<p>[5] Yu D, Zhang H, Chen W, Liu TY. Do not let privacy overbill utility: Gradient embedding perturbation for private learning. arXiv preprint arXiv:2102.12677. 2021 Feb 25.</p>

<p>[6] He K, Zhang X, Ren S, Sun J. Deep residual learning for image recognition. InProceedings of the IEEE conference on computer vision and pattern recognition 2016 (pp. 770-778).</p>

<p>[7] Radford A, Narasimhan K, Salimans T, Sutskever I. Improving language understanding by generative pre-training.</p>

<p>[8] Devlin J, Chang MW, Lee K, Toutanova K. Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805. 2018 Oct 11.</p>

<p>[9] Chen T, Kornblith S, Norouzi M, Hinton G. A simple framework for contrastive learning of visual representations. InInternational conference on machine learning 2020 Nov 21 (pp. 1597-1607). PMLR.</p>

<p>[10] Li XL, Liang P. Prefix-tuning: Optimizing continuous prompts for generation. arXiv preprint arXiv:2101.00190. 2021 Jan 1.</p>

<p>[11] Li X, Tramer F, Liang P, Hashimoto T. Large language models can be strong differentially private learners. arXiv preprint arXiv:2110.05679. 2021 Oct 12.</p>

<p>[12] Yu D, Naik S, Backurs A, Gopi S, Inan HA, Kamath G, Kulkarni J, Lee YT, Manoel A, Wutschitz L, Yekhanin S. Differentially private fine-tuning of language models. arXiv preprint arXiv:2110.06500. 2021 Oct 13.</p>

<p>[13] Liu Y, Ott M, Goyal N, Du J, Joshi M, Chen D, Levy O, Lewis M, Zettlemoyer L, Stoyanov V. Roberta: A robustly optimized bert pretraining approach. arXiv preprint arXiv:1907.11692. 2019 Jul 26.</p>

<p>[14] Bassily R, Smith A, Thakurta A. Private empirical risk minimization: Efficient algorithms and tight error bounds. In2014 IEEE 55th Annual Symposium on Foundations of Computer Science 2014 Oct 18 (pp. 464-473). IEEE.</p>

<p>[15] Bassily R, Feldman V, Talwar K, Guha Thakurta A. Private stochastic convex optimization with optimal rates. Advances in Neural Information Processing Systems. 2019;32.</p>

<p>[16] Yu D, Zhang H, Chen W, Yin J, Liu TY. Large scale private learning via low-rank reparametrization. InInternational Conference on Machine Learning 2021 Jul 1 (pp. 12208-12218). PMLR.</p>

<p>[17] Radford A, Wu J, Child R, Luan D, Amodei D, Sutskever I. Language models are unsupervised multitask learners. OpenAI blog. 2019 Feb 24;1(8):9.</p>

<p>[18] Bommasani R, Hudson DA, Adeli E, Altman R, Arora S, von Arx S, Bernstein MS, Bohg J, Bosselut A, Brunskill E, Brynjolfsson E, et al. On the opportunities and risks of foundation models. arXiv preprint arXiv:2108.07258. 2021 Aug 16.</p>

<p>[19] Abadi M, Chu A, Goodfellow I, McMahan HB, Mironov I, Talwar K, Zhang L. Deep learning with differential privacy. InProceedings of the 2016 ACM SIGSAC conference on computer and communications security 2016 Oct 24 (pp. 308-318).</p>

<p>[20] Song S, Chaudhuri K, Sarwate AD. Stochastic gradient descent with differentially private updates. In2013 IEEE Global Conference on Signal and Information Processing 2013 Dec 3 (pp. 245-248). IEEE.</p>

<p>[21] Feldman V, Zhang C. What neural networks memorize and why: Discovering the long tail via influence estimation. Advances in Neural Information Processing Systems. 2020;33:2881-91.</p>

<p>[22] Ghosh A, Kleinberg R. Inferential privacy guarantees for differentially private mechanisms. arXiv preprint arXiv:1603.01508. 2016 Mar 4.</p>

<p>[23] Nissenbaum H. Privacy as contextual integrity. Wash. L. Rev.. 2004;79:119.</p>

<p>[24] Vaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L, Gomez AN, Kaiser Ł, Polosukhin I. Attention is all you need. Advances in neural information processing systems. 2017;30.</p>

<p>[25] Williams A, Nangia N, Bowman SR. A broad-coverage challenge corpus for sentence understanding through inference. arXiv preprint arXiv:1704.05426. 2017 Apr 18.</p>

<p>[26] Novikova J, Dušek O, Rieser V. The E2E dataset: New challenges for end-to-end generation. arXiv preprint arXiv:1706.09254. 2017 Jun 28.</p>

<p>[27] Papernot N, Chien S, Song S, Thakurta A, Erlingsson U. Making the shoe fit: Architectures, initializations, and tuning for learning with privacy.</p>

<p>[28] Suriyakumar VM, Papernot N, Goldenberg A, Ghassemi M. Chasing your long tails: Differentially private prediction in health care settings. InProceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency 2021 Mar 3 (pp. 723-734).</p>

<p>[29] Bagdasaryan E, Poursaeed O, Shmatikov V. Differential privacy has disparate impact on model accuracy. Advances in Neural Information Processing Systems. 2019;32.</p>

<p>[30] Bourtoule L, Chandrasekaran V, Choquette-Choo CA, Jia H, Travers A, Zhang B, Lie D, Papernot N. Machine unlearning. In2021 IEEE Symposium on Security and Privacy (SP) 2021 May 24 (pp. 141-159). IEEE.</p>

<p>[31] Sekhari A, Acharya J, Kamath G, Suresh AT. Remember what you want to forget: Algorithms for machine unlearning. Advances in Neural Information Processing Systems. 2021 Dec 6;34.</p>

<p>[32] Cao Y, Yang J. Towards making systems forget with machine unlearning. In2015 IEEE Symposium on Security and Privacy 2015 May 17 (pp. 463-480). IEEE.</p>

<p>[33] Carlini N, Tramer F, Wallace E, Jagielski M, Herbert-Voss A, Lee K, Roberts A, Brown T, Song D, Erlingsson U, Oprea A. Extracting training data from large language models. In30th USENIX Security Symposium (USENIX Security 21) 2021 (pp. 2633-2650).</p>

<p>[34] Nasr M, Songi S, Thakurta A, Papemoti N, Carlin N. Adversary instantiation: Lower bounds for differentially private machine learning. In2021 IEEE Symposium on Security and Privacy (SP) 2021 May 24 (pp. 866-882). IEEE.</p>

<p>[35] Jagielski M, Ullman J, Oprea A. Auditing differentially private machine learning: How private is private sgd?. Advances in Neural Information Processing Systems. 2020;33:22205-16.</p>
<div class="footnotes">
  <ol>
    <li id="fn:1">
      <p>Authors of [<a href="https://arxiv.org/abs/2108.07258">18</a>] framed these self-supervised models which are trained on broad data at scale that are adaptable to a wide range of downstream tasks as “foundation models.” <a class="reversefootnote" href="https://differentialprivacy.org/feed.xml#fnref:1">↩</a></p>
    </li>
    <li id="fn:2">
      <p>The idea of privately fine-tuning a publicly pre-trained model certainly isn’t new. One of the first differentially private deep learning papers [<a href="https://arxiv.org/abs/1607.00133">19</a>] considered an experiment which fine-tuned convolutional nets on CIFAR-10 which were pre-trained on CIFAR-100. Results on privately fine-tuning <em>self-supervised</em> models are, on the other hand, more recent. Covering these results is our main focus here. <a class="reversefootnote" href="https://differentialprivacy.org/feed.xml#fnref:2">↩</a></p>
    </li>
    <li id="fn:3">
      <p>Blue and pink sphere avatars taken from [<a href="https://arxiv.org/abs/2108.07258">18</a>]. Credit to <a href="https://cs.stanford.edu/~dorarad/">Drew A. Hudson</a> for making these. <a class="reversefootnote" href="https://differentialprivacy.org/feed.xml#fnref:3">↩</a></p>
    </li>
    <li id="fn:4">
      <p>Unpublished result. <a class="reversefootnote" href="https://differentialprivacy.org/feed.xml#fnref:4">↩</a></p>
    </li>
    <li id="fn:5">
      <p>Hyper-parameters that work well for non-private learning typically aren’t those that work best for differentially private learning [<a href="https://openreview.net/pdf?id=rJg851rYwH">27</a>]. It’s crucial to use a large batch size, a small clipping norm, an appropriate learning rate, and a reasonably large number of training epochs to obtain the mentioned private learning results [<a href="https://arxiv.org/abs/2110.05679">11</a>]. <a class="reversefootnote" href="https://differentialprivacy.org/feed.xml#fnref:5">↩</a></p>
    </li>
    <li id="fn:6">
      <p>In practice, past works have presented mixed results on whether larger models would yield better performance. While some showed that using more filters in a convolutional network can degrade the performance of private learning after some threshold [<a href="https://openreview.net/pdf?id=rJg851rYwH">27</a>], others showed that a larger model can outperform a smaller model from a different model family [<a href="https://arxiv.org/abs/2011.11660">4</a>]. Note these results are conditioned on their particular hyperparameter choices. <a class="reversefootnote" href="https://differentialprivacy.org/feed.xml#fnref:6">↩</a></p>
    </li>
    <li id="fn:7">
      <p>Since the pre-training data for large language models are oftentimes collected through large scale web scraping (e.g., WebText), a common concern is that some training and test instances for downstream tasks may already appear in the pre-training data. Self-supervised pre-training therefore can give models an opportunity to “see” this data even before they are privately fine-tuned. Authors of [<a href="https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf">17</a>] confirmed that there is a 1-6% overlap between the test set of many natural language processing tasks and the pre-training data they collected (WebText); these common tasks, however, don’t include those studied by authors of [<a href="https://arxiv.org/abs/2110.05679">11</a>]. The numbers suggest a possibility that existing private fine-tuning results in the literature could be slightly inflated compared to when the pre-training data didn’t contain any instance for any downstream task for which evaluation was performed. <a class="reversefootnote" href="https://differentialprivacy.org/feed.xml#fnref:7">↩</a></p>
    </li>
  </ol>
</div></div>
    </summary>
    <updated>2022-03-15T19:00:00Z</updated>
    <published>2022-03-15T19:00:00Z</published>
    <author>
      <name>Tatsunori Hashimoto</name>
    </author>
    <source>
      <id>https://differentialprivacy.org</id>
      <link href="https://differentialprivacy.org" rel="alternate" type="text/html"/>
      <link href="https://differentialprivacy.org/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Website for the differential privacy research community</subtitle>
      <title>Differential Privacy</title>
      <updated>2022-03-27T23:01:29Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-3121871012533153752</id>
    <link href="http://blog.computationalcomplexity.org/feeds/3121871012533153752/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/03/problem-x-wont-be-solved-in-my-lifetime.html#comment-form" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/3121871012533153752" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/3121871012533153752" rel="self" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/03/problem-x-wont-be-solved-in-my-lifetime.html" rel="alternate" type="text/html"/>
    <title>Problem X won't be solved in MY lifetime- but what about...</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>1) In 1989 on the episde The Royale of Star Trek: The Next Generation (which takes place in the far future)  Captain Picard is working on Fermat's last theorem which he says quite explicitly is still open.</p><p>When I saw the episode I asked Larry Washington, a Number Theorist at Univ of MD, when he thought FLT would be solved. He said</p><p>                                      <i>It will be solved within the next 10 years.</i></p><p>And indeed- Wiles solved it in 1993-sort of. There was a flaw in the proof which he fixed in 1994 with the help of his former student Richard Taylor. Wiles published the correction to the flaw in 1995, so we will date it as having been solved in 1995. Larry Washington was correct.  And in an episode of Star Trek: Deep Space Nine in 1995 (episode name:Facets) Dax says that a previous host, Tobin Dax, had done the most creative work on FLT since Wiles. Maybe Tobin wrote this limerick:</p><p>A challenge for many long ages</p><p>Had baffled the savants and sages</p><p>Yet at last came the light</p><p>Seems that Fermat was right</p><p>To the margin add 200 pages.</p><p><br/></p><p>I asked Larry W when he thought Riemann would be solved. He said  </p><p>                   <i> In your lifetime but not in mine.</i></p><p>He is about 10 years older than I am and I think we are both in good health. This seems like a rather precise prediction so I am skeptical. But he did get FLT right...</p><p>2) In class I sometimes say things like </p><p><i>I do not think Quantum Computers will factor faster than classical in my lifetime. </i></p><p><i>I do not think P vs NP will be solved in my lifetime.</i></p><p><i>I can imagine P=BPP will be proven in my lifetime. (I said that 10 years ago. I am less imaginative now.) </i></p><p><i>I hope the muffin problem is solved in my lifetime (it was, see <a href="https://arxiv.org/abs/1907.08726">here</a>).</i></p><p>I didn't quite think about the difference in my age and the students until recently when I was working with Ilya Hajiaghayi (Mohammd H's 9 year old son) on cryptography and he said </p><p><i>In your recorded lecture you said you don't think quantum computers will be a threat to cryptography  in your lifetime. What about in my lifetime?</i></p><p>Indeed- his lifetime and mine are rather far apart. </p><p>I am reminded that one of the answers to my P vs NP poll made the point that while we have some sense of what will happen in the next 10 years, maybe even 20, math and life can change so much that conjectures beyond that are guesswork. Any  prediction for x years from now you should have confidence &lt; 1/ln(x) of it being true.</p><p><i><br/></i></p><p><i><br/></i></p><p><i><br/></i></p><p><br/></p></div>
    </content>
    <updated>2022-03-15T14:30:00Z</updated>
    <published>2022-03-15T14:30:00Z</published>
    <author>
      <name>gasarch</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03004932739846901628</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="http://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2022-03-27T22:34:37Z</updated>
    </source>
  </entry>

  <entry>
    <id>http://benjamin-recht.github.io/2022/03/15/external-validity/</id>
    <link href="http://benjamin-recht.github.io/2022/03/15/external-validity/" rel="alternate" type="text/html"/>
    <title>Machine Learning has a validity problem.</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>One of the central tenets of machine learning warns the more times you run experiments with the same test set, the more you overfit to that test set. This conventional wisdom is mostly wrong and prevents machine learning from reconciling its inductive nihilism with the rest of the empirical sciences.</p>

<p>Rebecca Roelofs, Ludwig Schmidt, and Vaishaal Shankar led an passionate quest to test the overfitting hypothesis, devoting countless hours to reproducing machine learning benchmarks. In particular, they painstakingly recreated a test set of the famous <a href="https://www.image-net.org/">ImageNet benchmark</a>, which itself is responsible for bringing about the latest AI feeding frenzy. Out of the many surprises in my research career, what <a href="https://arxiv.org/abs/1902.10811">they found surprised me the most.</a></p>

<p class="center"><img alt="The scatterplot of nightmares" src="http://www.argmin.net/assets/RSS_Scatter.png" width="90%"/></p>

<p>In this graph, the x-axis is the accuracy on the original ImageNet benchmark, which has been used millions of times by individual researchers at Google alone. On the y-axis is the accuracy evaluated on “ImageNet v2” set, which was made by closely trying to replicate the data creation method for the benchmark. Each blue dot represents a single machine learning model trained on the original ImageNet data. The red line is a linear fit to these models, and the dashed line is what we would see if the accuracy was the same on both test sets. What do we see? The models which perform the best on the original test set perform the best on the new test set. That is, there is no evidence of overfitting.</p>

<p>What is clear, however, is a noticeable drop in performance on the new test set. Despite their best efforts in reproducing the ImageNet protocol, there is evidence of a <em>distribution shift</em>. Distribution shift is a far reaching term describing whenever the data on which a machine learning algorithm is deployed is different from the data on which it is trained. The Mechanical Turk workers who labeled the images were different from those originally employed. The API used for the labeling was slightly different. The selection mechanism to aggregate differences in opinions between labelers is slightly different. The small differences add up to around a 10% drop in accuracy, equivalent to five years of progress on the benchmark.</p>

<p>Folks in my research group have reproduced this phenomenon several times. In <a href="https://papers.nips.cc/paper/9117-a-meta-analysis-of-overfitting-in-machine-learning">Kaggle competitions</a>, where the held out set and validation set were <em>identically</em> distributed, we saw no overfitting <em>and</em> no distribution shift. We found sensitivity to distribution shifts in CIFAR10, in <a href="https://arxiv.org/abs/1906.02168">video</a>, and in <a href="https://arxiv.org/abs/2004.14444">question answering</a> benchmarks. And Chhavi Yadav and Leon Bottou showed that we have not yet overfit to the <a href="https://arxiv.org/abs/1905.10498">venerable MNIST data set</a>, but distribution shift remains a challenge.</p>

<p>The marked sensitivity to distribution shift is a huge issue. If small ambiguities in reproductions lead to large losses in predictive performance, what happens when we take ML systems designed on static benchmarks and deploy them in important applications? A decade of AI fever has delivered piles of evidence that distribution shift is machine learning’s achilles heel. Algorithms run inside the big tech companies need to be constantly retrained with their huge computing resources. <a href="https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.1002683">Data-driven algorithms for radiology often fail if one changes the X-ray machine</a>. <a href="https://jamanetwork.com/journals/jamainternalmedicine/article-abstract/2781307">AI algorithms for sepsis fail if you change hospitals</a>. And self-driving car systems are readily confused in new environments (No citation needed. Keep your Tesla away from me.).</p>

<p>The only way forward is for machine learning to engage more broadly with other scientists who have been tackling similar issues for centuries. My first proposal is simple: let’s change our terminology to align with the rest of the sciences. The study of distribution shift in machine learning has always been insular and, while machine learning is particularly sensitive, all empirical science must deal with the jump from experiment to reality.</p>

<p>With this in mind, <a href="https://twitter.com/rajiinio">Deb Raji</a> and I have been digging through the scientific literature for a while now hoping to find some answers. In most other parts of science, “robustness to distribution shift” is called external validity. External validity quantifies how well a finding generalizes beyond a specific experiment. For example, a significant result on a particular cohort may not generalize to a broader population.</p>

<p>Predictive algorithms and experimental science both rely on repeatability. “The sun has always risen in the east.” “The apple always falls straight to the ground.” We expect that given the same contexts, the natural world more or less repeats itself. There is unfortunately a big leap from the sun rising in the morning, to an experimental finding in machine learning or biomedicine being reproducible. Why?</p>

<p>The experimental contexts under which predictions and inferences are designed are often far too narrow. The results of a study performed on young male college students in Maine may not help us understand properties of a retirement community in Arizona. These populations are different! However, it may give us insights into other cohorts of male college students: a study at Bates may generalize to Colby or Bowdoin.</p>

<p>Contexts can change in a myriad of ways. Some examples include the following:</p>

<ol>
  <li>The context can just be too narrow in the experiment. Do studies on adults generalize to children? Do studies on medications with only men generalize to women?</li>
  <li>The measured quantity may itself change. It is often easier to measure, detect, and control for exogenous disturbances in a lab setting than in the real world.</li>
  <li>Populations can change over time. For example, medical recommendations from the 1980s may no longer apply to the current population. Recent developments have led to <a href="https://www.npr.org/2021/10/13/1045746669/task-force-says-most-people-should-not-take-daily-aspirin-to-prevent-a-heart-att">not recommending aspirin to prevent heart attacks</a>.  Machine Learners like to call this <em>covariate shift</em>.</li>
  <li>Even more nefariously, the population can change in response to the intervention. A classic example of this is <a href="https://en.wikipedia.org/wiki/Goodhart%27s_law">Goodhart’s Law</a> which states “Any observed statistical regularity will tend to collapse once pressure is placed upon it for control purposes.”</li>
</ol>

<p>How can we grapple with these external validity challenges? Verifying external validity is daunting and the set of potential solutions remains quite limited. As I mentioned, Deb and I have been chatting about this for a year now, and we’ve now dragged the rest of the group into our investigations. So I’m going to share the blog with Deb for a few posts now, and we’ll both expand on what we’ve been reading and thinking about. In the next few posts, we’ll explore some of the intricacies of when external validity can fail and will also try to spell out some of the research directions that might help bridge the gaps between experiments and reality.</p></div>
    </summary>
    <updated>2022-03-15T00:00:00Z</updated>
    <published>2022-03-15T00:00:00Z</published>
    <source>
      <id>http://benjamin-recht.github.io/</id>
      <author>
        <name>Ben Recht</name>
      </author>
      <link href="http://benjamin-recht.github.io/" rel="alternate" type="text/html"/>
      <link href="http://benjamin-recht.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Musings on systems, information, learning, and optimization.</subtitle>
      <title>arg min blog</title>
      <updated>2022-03-27T23:00:39Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://rjlipton.wpcomstaging.com/?p=19736</id>
    <link href="https://rjlipton.wpcomstaging.com/2022/03/14/are-these-the-last-digits-of-pi/" rel="alternate" type="text/html"/>
    <title>Are These the Last Digits of Pi?</title>
    <summary>Ghoulish reflections on whether mathematics is emergent Composite of src1, src2 Thomas Keller and Heiko Rölke led a team at the University of Applied Sciences in Graubünden, Switzerland, that set a new record for the computation of last August. They computed 62.8 trillion digits of . The last ten digits they obtained are 7817924264. Today, […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><font color="#0044cc"><br/>
<em>Ghoulish reflections on whether mathematics is emergent</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2022/03/14/are-these-the-last-digits-of-pi/kellerrolkepi/" rel="attachment wp-att-19738"><img alt="" class="alignright wp-image-19738" height="95" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/03/KellerRolkePi.png?resize=222%2C95&amp;ssl=1" width="222"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Composite of <a href="https://www.fhgr.ch/en/specialist-areas/applied-future-technologies/davis-centre/pi-challenge/">src1</a>, <a href="https://www.welt.de/wissenschaft/plus233700070/Zahl-Pi-Forscher-haben-62-8-Billionen-Stellen-ermittelt.html">src2</a></font></td>
</tr>
</tbody>
</table>
<p>
Thomas Keller and Heiko Rölke led a team at the University of Applied Sciences in Graubünden, Switzerland, that set a new record for the computation of <img alt="{\pi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> last August. They computed 62.8 trillion digits of <img alt="{\pi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. The last ten digits they obtained are 7817924264.</p>
<p>
Today, we wish people Happy Pi Day amid wishes for happier days overall.<br/>
<span id="more-19736"/></p>
<p>
Pi Day needs the day to be written American-style as 3/14/22. In international style it would be 31/4/22, but April does not have 31 days. This year involves the numerator of the simplest serviceable approximation to pi: </p>
<p align="center"><img alt="\displaystyle  \pi \approx \frac{22}{7} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cpi+%5Capprox+%5Cfrac%7B22%7D%7B7%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>Because <img alt="{\pi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is irrational, any finite fraction or number of digits is an approximation. Because <img alt="{\pi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is computable—indeed highly efficiently computable in <a href="https://rjlipton.wpcomstaging.com/2009/03/15/cooks-class-contains-pi/">senses</a> we have <a href="https://rjlipton.wpcomstaging.com/2010/07/14/making-an-algorithm-an-algorithm-bbp/">covered</a>—we can adduce that the code for doing so represents <img alt="{\pi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> exactly. Furthermore, the symbol <img alt="{\pi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> lends itself to many other calculations that yield exact finite results. </p>
<p>
The digits, however, have their own mystique. We still do not know whether they are <a href="http://pi314.at/math/normal.html">normal</a> in any base, let alone base ten. Speaking as mathematical Platonists, we regard the infinite sequence as a completed, unchanging entity—one for which assertions like “it is normal” have currently-definite truth values. </p>
<p>
This is what events of the past few weeks have prompted Dick and me to question. If our world presently stops existing, 7817924264 will be the last digits of <img alt="{\pi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> that we know.</p>
<p/><p/>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2022/03/14/are-these-the-last-digits-of-pi/pimug/" rel="attachment wp-att-19739"><img alt="" class="alignright wp-image-19739" height="168" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/03/PiMug.jpg?resize=150%2C168&amp;ssl=1" width="150"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Etsy Math Mug <a href="https://www.etsy.com/listing/497368583/math-mug-my-pin-is-the-last-4-digits-of">source</a></font>
</td>
</tr>
</tbody></table>
<p/><h2> Not Just WW III </h2><p/>
<p/><p>
I already have a story of impermanent truth rooted in Russia. On my phone I have a free app for the <a href="https://chessok.com/?page_id=27966">Lomonosov Tablebases</a>, which give the perfect result of all chess positions with 7 or fewer pieces. Those tables took years to compile and exist only as 100+ terabytes on a machine at the Lomonosov Moscow State University computer center. </p>
<p>
Sometime over the new year, I noticed that the server stopped working. It was <a href="http://talkchess.com/forum3/viewtopic.php?f=2&amp;t=74046">reportedly</a> the victim of a ransomware attack. Is it meaningful to say that the tables currently exist? Mathematically, yes, and physically likely also yes—assuming the bits were merely blocked and not altered on the storage plates. </p>
<p>
Happily, there is a second 7-piece table called <a href="https://lichess.org/blog/W3WeMyQAACQAdfAL/7-piece-syzygy-tablebases-are-complete">Syzygy</a>, which uses only about 18 terabytes and exists in multiple dowloaded copies. However, this leads us to another question about correctness. The Syzygy computation reproduced some key extremal features of the Lomonosov compilation, such as the position with the longest number of moves needed to win. Not all have been verifiable, because Syzygy counts the time needed to make concrete progress in the form of a capture or pawn advance rather than the time to give checkmate. What I don’t know—and maybe now won’t know—is:</p>
<blockquote><p><b> </b> <em> Has Syzygy been used to verify every win/draw/loss (WDL) verdict computed by Lomonosov, and vice-versa? </em>
</p></blockquote>
<p/><p>
Doing so would require cross-checking many trillions of chess positions. Of course, we should expect that the algorithms used to produce these tables have been verified as completely correct. </p>
<p>
That is worth saying again: The chess algorithms have been verified in themselves. This is not a case of a shock I had before Christmas, when a module in my own chess software threw an error for the first time since I wrote it in 2014, having worked perfectly on over 100 million moves in several million games. The function in question records not only the exact source and destination squares of a move but also the minimum information required by short-form notation systems to disambiguate it from other pieces that could move to the square. There was one game where the players horsed around until one side had 5 queens that could all move to the same square, and that was 1 more than my scheme had presumed possible. My code is thus not-quite correct.</p>
<p>
But even analytical correctness fails in cases of hardware error. A cosmic ray temporarily <a href="https://www.independent.co.uk/news/science/subatomic-particles-cosmic-rays-computers-change-elections-planes-autopilot-a7584616.html">changed</a> the outcome of an election in Belgium. Fortunately, the systems have cross-checks to catch these events. When the subject is <em>mathematical truths</em>, however, how are we checking? On what basis can we be satisfied by such checks?</p>
<p>
</p><p/><h2> Emergence </h2><p/>
<p/><p>
Despite our Platonist convictions, as practitioners of mathematics we experience its truths as <a href="https://en.wikipedia.org/wiki/Emergence">emergent</a>. By “emergent” we mean more than saying theorems are unknown until the point in time where they are clearly proved. <em>Pace</em> our <a href="https://rjlipton.wpcomstaging.com/2019/04/21/pnp-proofs/">claimers</a>, P versus NP has not been proved either way, and we live in a world where even those who strongly believe <img alt="{\mathsf{P &lt; NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%3C+NP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> will aver it is unknown. We <a href="https://rjlipton.wpcomstaging.com/2021/12/31/make-a-trillion-dollars/">covered</a> this recently.</p>
<p>
Our sense of <em>emergent</em> meets at least the “weak” criterion enunciated <a href="http://consc.net/papers/emergence.pdf">here</a> by David Chalmers, a sense of unexpectedness <a href="https://rjlipton.wpcomstaging.com/2015/10/29/guessing-conjectures/">that</a> we <a href="https://rjlipton.wpcomstaging.com/2011/04/13/even-great-mathematicians-guess-wrong/">have</a> often <a href="https://rjlipton.wpcomstaging.com/2010/06/19/guessing-the-truth/">discussed</a> going <a href="https://rjlipton.wpcomstaging.com/2009/09/27/surprises-in-mathematics-and-theory/">back</a> to the <a href="https://rjlipton.wpcomstaging.com/2009/02/19/we-all-guessed-wrong/">beginning</a> of the blog. </p>
<p>
Chalmers’s strong sense, when applied to mathematics, leads into independence results of the kind effected by Kurt Gödel, this blog’s eponym. We realize that none of our 1,000+ posts has yet attempted a deep appraisal of what these independence results <em>mean</em>. We will not do so now because we are questioning something more basic: Discussion of Gödelian independence is with regard to a truth value that is presumed to exist. What if it doesn’t exist?</p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2022/03/14/are-these-the-last-digits-of-pi/provemewrong/" rel="attachment wp-att-19741"><img alt="" class="aligncenter wp-image-19741" height="218" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/03/ProveMeWrong.jpg?resize=277%2C218&amp;ssl=1" width="277"/></a></p>
<p>
We are not just catching the tension of Platonism with <a href="https://en.wikipedia.org/wiki/Logical_positivism">logical positivism</a> and related paths to asking, what is science? We are asking whether reality aligns with the position that we already feel is best for <em>practice</em>. </p>
<p>
“Emergent Mathematics” is a teaching movement that, in the words of one prominent <a href="https://www.jstor.org/stable/23434871">paper</a>, gets away from mathematics courses that “are focused on completed results that often hide the messiness and complication that led to their production.” In trying to explain much data showing that the most experienced mathematicians are not the most accomplished teachers, the paper’s two authors seem to identify the former with the position of putting emphasis on completed results. They seek the best attitude for childhood <em>learning</em> of mathematics, and believe it to be orthogonal to that of presenting finished mathematics.  But going another 90 degrees around the dial, perhaps their compass needle’s other end points to the best philosophical position for <em>creating</em> mathematics.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
I think we would all still agree that the next trillion digits of <img alt="{\pi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> currently exist. The tougher question is whether it is scientifically meaningful to postulate knowledge of them, without knowing them. We may get an opinion on that from a regular friend late Wednesday into Thursday.</p></font></font></div>
    </content>
    <updated>2022-03-14T20:34:36Z</updated>
    <published>2022-03-14T20:34:36Z</published>
    <category term="All Posts"/>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="P=NP"/>
    <category term="Proofs"/>
    <category term="emergence"/>
    <category term="Heiko R&#xF6;lke"/>
    <category term="Pi"/>
    <category term="Pi Day"/>
    <category term="program correctness"/>
    <category term="records"/>
    <category term="Thomas Keller"/>
    <author>
      <name>KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wpcomstaging.com</id>
      <logo>https://s0.wp.com/i/webclip.png</logo>
      <link href="https://rjlipton.wpcomstaging.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wpcomstaging.com" rel="alternate" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel's Lost Letter and P=NP</title>
      <updated>2022-03-27T23:37:42Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>http://www.solipsistslog.com/?p=551</id>
    <link href="http://www.solipsistslog.com/a-mysterious-constant-called-pi-arising-from-the-gaussian-integral-with-a-minor-application-to-circles/" rel="alternate" type="text/html"/>
    <title>A mysterious constant called pi, arising from the Gaussian integral (with a minor application to circles)</title>
    <summary>Hi, nerd blog! (This is a post that I wrote a long time ago and then never published. I figured it would be nice to publish it on March 14th.) Today, we’re interested in the Gaussian integral     for . This integral of course has lots of very serious practical applications, as it arises […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Hi, nerd blog! (This is a post that I wrote a long time ago and then never published. I figured it would be nice to publish it on March 14th.)</p>



<p>Today, we’re interested in the Gaussian integral </p><p class="ql-center-displayed-equation" style="line-height: 41px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\[f(C) := \int_{-\infty}^\infty e^{-Cx^2} {\rm d} x\]" class="ql-img-displayed-equation quicklatex-auto-format" height="41" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-096cdf537e620c218a57694e9aca2bf4_l3.png" title="Rendered by QuickLaTeX.com" width="170"/></p> for <img alt="C &gt; 0" class="ql-img-inline-formula quicklatex-auto-format" height="12" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-87ddd944257c5bf57009a80226e5c414_l3.png" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="47"/>. This integral of course has lots of very serious practical applications, as it arises naturally in the study of the Gaussian/normal distribution. But, more importantly, it’s a lot of fun to play with and is simply beautiful. We’ll see a bit about what it makes it so pretty below. We start by simply trying to figure out the value of this thing, which isn’t super easy.<p/>



<p>By a change of variables, we immediately see that <img alt="f(C)" class="ql-img-inline-formula quicklatex-auto-format" height="19" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-051ceeda9119a5fc9be66053f9dd40a3_l3.png" title="Rendered by QuickLaTeX.com" width="37"/> is proportional to <img alt="1/\sqrt{C}" class="ql-img-inline-formula quicklatex-auto-format" height="21" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-94fd71739495e33d6c86fe0b70cdbcf1_l3.png" title="Rendered by QuickLaTeX.com" width="46"/>. But, what is the constant of proportionality? It’s actually nicer to ask a slightly different question: what is the unique value of <img alt="C" class="ql-img-inline-formula quicklatex-auto-format" height="12" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-f34f74d98915e33f37a086f8cbfb996a_l3.png" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="14"/> such that <img alt="f(C) = 1" class="ql-img-inline-formula quicklatex-auto-format" height="18" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-a4141e7514a6f611842effecf51c1199_l3.png" title="Rendered by QuickLaTeX.com" width="70"/>. A quick numerical computation shows that <img alt="f(3.14159) \approx 1" class="ql-img-inline-formula quicklatex-auto-format" height="19" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-24b068172655b4e41a85afb20c734882_l3.png" title="Rendered by QuickLaTeX.com" width="114"/>. E.g., here’s some Mathematica code to find this value:<br/><img alt="" class="wp-image-552" height="110" src="http://www.solipsistslog.com/wp-content/uploads/2021/03/Screen-Shot-2021-03-27-at-3.25.48-PM.png" style="width: 400px;" width="1066"/>.</p>



<p>This constant <img alt="C \approx 3.14159" class="ql-img-inline-formula quicklatex-auto-format" height="13" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-3351e9436eef51bd249c328e212df088_l3.png" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="97"/> is so important for this blog post that it is worth giving it a name. So, I looked through the Greek alphabet for a nice letter that doesn’t get used much and chose the obscure lowercase letter <img alt="\pi" class="ql-img-inline-formula quicklatex-auto-format" height="8" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-26d6788550ffd50fe94542bb3e8ee615_l3.png" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="11"/>—spelled <em>pi</em> in English, and pronounced like “pie”. In other words, by definition <img alt="f(\pi) = 1" class="ql-img-inline-formula quicklatex-auto-format" height="19" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-64cecd17d70571e9f6e5d0e701cda533_l3.png" title="Rendered by QuickLaTeX.com" width="67"/>. (If this implicit definition bothers you, we can equivalently just define <img alt="\pi := f(1)^{2}" class="ql-img-inline-formula quicklatex-auto-format" height="20" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-fd24a2e8eab1e07787b7429db8502015_l3.png" title="Rendered by QuickLaTeX.com" width="80"/>. But, I find the implicit definition to be more elegant.)</p>



<p>So, we have this brand new mysterious constant <img alt="\pi" class="ql-img-inline-formula quicklatex-auto-format" height="8" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-26d6788550ffd50fe94542bb3e8ee615_l3.png" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="11"/>. What should we do with it? It is of course natural to try to find different expressions for it (though our integral expression can already be used to compute it to quite high precision). A first idea is to apply the change of variables <img alt="u = \pi x^2" class="ql-img-inline-formula quicklatex-auto-format" height="15" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-fcb6cf4e246632c794949355411b046b_l3.png" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="62"/> to obtain </p><p class="ql-center-displayed-equation" style="line-height: 41px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\[1 = 2\int_{0}^{\infty} e^{-\pi x^2}{\rm d} x = \pi^{-1/2} \int_0^{\infty} e^{-u}/u^{1/2} {\rm d} u\; .\]" class="ql-img-displayed-equation quicklatex-auto-format" height="41" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-f10d9cf7ba99c79b8b6410cfbffbcb0d_l3.png" title="Rendered by QuickLaTeX.com" width="343"/></p> So, <p class="ql-center-displayed-equation" style="line-height: 41px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\[\pi =\Big( \int_0^\infty e^{-u}/u^{1/2} {\rm d} u\Big)^2\; ,\]" class="ql-img-displayed-equation quicklatex-auto-format" height="41" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-a70346615d75d7bd8aad3e871d66f99c_l3.png" title="Rendered by QuickLaTeX.com" width="199"/></p> which you might recognize as the square of the <a href="https://en.wikipedia.org/wiki/Gamma_function" rel="noreferrer noopener" target="_blank">Gamma function</a> evaluated at <img alt="1/2" class="ql-img-inline-formula quicklatex-auto-format" height="19" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-872abde626b8cdf8e983a3345ee98925_l3.png" title="Rendered by QuickLaTeX.com" width="25"/>, i.e., <img alt="\pi = \Gamma(1/2)^2" class="ql-img-inline-formula quicklatex-auto-format" height="20" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-f89e7a589afd5b47baf442a3c38013ee_l3.png" title="Rendered by QuickLaTeX.com" width="93"/>. (Recalling that <img alt="\Gamma(n) = (n-1)!" class="ql-img-inline-formula quicklatex-auto-format" height="19" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-59278ef14f8421f91a9c38456784aa70_l3.png" title="Rendered by QuickLaTeX.com" width="118"/> for integer <img alt="n" class="ql-img-inline-formula quicklatex-auto-format" height="8" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-b170995d512c659d8668b4e42e1fef6b_l3.png" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="11"/>, one might interpret this as saying that <img alt="\sqrt{\pi}" class="ql-img-inline-formula quicklatex-auto-format" height="18" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-a0df3b7b3c88b80bd1b77220c28fb5ec_l3.png" title="Rendered by QuickLaTeX.com" width="25"/> is “the factorial of <img alt="-1/2" class="ql-img-inline-formula quicklatex-auto-format" height="19" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-b5205e45813b524be8d323d4b2d0fade_l3.png" title="Rendered by QuickLaTeX.com" width="39"/>.”) <p/>



<p>This mysterious identity will play a key role later. We could, of course, find other identities involving this new constant <img alt="\pi" class="ql-img-inline-formula quicklatex-auto-format" height="8" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-26d6788550ffd50fe94542bb3e8ee615_l3.png" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="11"/>. But, I thought instead I’d jump ahead to a rather obscure fact about the relationship between <img alt="\pi" class="ql-img-inline-formula quicklatex-auto-format" height="8" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-26d6788550ffd50fe94542bb3e8ee615_l3.png" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="11"/> and a circle.</p>



<h2>Our constant’s relationship with circles</h2>



<p>In my opinion, the Gaussian distribution is far more interesting in dimensions larger than one. In particular, consider the distribution on <img alt="\mathbb{R}^n" class="ql-img-inline-formula quicklatex-auto-format" height="12" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-f9868b4451c5811a288f7fdd10be5558_l3.png" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="21"/> given by the probability density function </p><p class="ql-center-displayed-equation" style="line-height: 24px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\[\Pr[\mathbf{x}] = e^{-\pi \|\mathbf{x}\|^2}\; .\]" class="ql-img-displayed-equation quicklatex-auto-format" height="24" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-cbeee2e0bc6e4a6f5288818cb4aa2a7a_l3.png" title="Rendered by QuickLaTeX.com" width="129"/></p> Notice that <p class="ql-center-displayed-equation" style="line-height: 41px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\[\int_{\mathbb{R}^n}e^{-\pi \|\mathbf{x}\|^2} {\rm d} \mathbf{x} = \int_{-\infty}^{\infty} \cdots \int_{-\infty}^{\infty} e^{-\pi x_1^2 -\cdots - \pi x_n^2} {\rm d}x_1 \ldots {\rm d} x_n = 1\; ,\]" class="ql-img-displayed-equation quicklatex-auto-format" height="41" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-8c88f8ef8350b5bf5e3924147dbed5de_l3.png" title="Rendered by QuickLaTeX.com" width="457"/></p> so that this is in fact a distribution. <p/>



<p>In fact, up to scaling, this distribution is the <em>unique</em> continuous radial product distribution—i.e., the unique distribution such that <img alt="\Pr[\mathbf{x}]" class="ql-img-inline-formula quicklatex-auto-format" height="18" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-17a91f072153c1ba54d02a280dccc979_l3.png" title="Rendered by QuickLaTeX.com" width="38"/> can be written both as a function only of the norm of <img alt="\mathbf{x}" class="ql-img-inline-formula quicklatex-auto-format" height="8" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-bcda923e732ff6e429d93d0fa7ea8a47_l3.png" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="11"/>, <img alt="\Pr[\mathbf{x}] = f^*(\|\mathbf{x}\|)" class="ql-img-inline-formula quicklatex-auto-format" height="19" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-2c1674e9adcb304d86d51e6e3e89bd93_l3.png" title="Rendered by QuickLaTeX.com" width="124"/> for some continuous function <img alt="f^*" class="ql-img-inline-formula quicklatex-auto-format" height="16" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-d1bc0c1e9f63254ef68d09d8ea3e316d_l3.png" title="Rendered by QuickLaTeX.com" width="17"/>, <em>and</em> as a product of functions of its coordinates, <img alt="\Pr[\mathbf{x}] = f_1(x_1)\cdots f_n(x_n)" class="ql-img-inline-formula quicklatex-auto-format" height="19" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-724a32e8712eb42c68f40510a4461d33_l3.png" title="Rendered by QuickLaTeX.com" width="188"/>. This makes the Gaussian a uniquely powerful tool for reducing complicated multi-dimensional problems to one-dimensional problems. </p>



<p>For example, suppose that for some strange reason we wish to know the circumference of a circle with radius one. (If we were less civilized mathematicians, we might instead set the diameter to be equal to <img alt="1" class="ql-img-inline-formula quicklatex-auto-format" height="13" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-4868771cbc422b5818f85500909ce433_l3.png" title="Rendered by QuickLaTeX.com" width="7"/>, so that the radius would be <img alt="1/2" class="ql-img-inline-formula quicklatex-auto-format" height="19" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-872abde626b8cdf8e983a3345ee98925_l3.png" title="Rendered by QuickLaTeX.com" width="25"/>.) We can try to write this as some kind of path integral or something—and suffer quite a bit in the process—or we can use the following beautiful trick. We can write<br/></p><p class="ql-center-displayed-equation" style="line-height: 41px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\[1 = \int_{\mathbb{R}^2} e^{-\pi \|x\|^2} {\rm d} x = \int_0^\infty e^{-\pi r^2} \sigma_r {\rm d} r= \sigma_1 \int_0^\infty e^{-\pi r^2} r {\rm d} r\;,\]" class="ql-img-displayed-equation quicklatex-auto-format" height="41" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-7d71e3575dad757294955cdf449254fa_l3.png" title="Rendered by QuickLaTeX.com" width="430"/></p><br/>where <img alt="\sigma_r" class="ql-img-inline-formula quicklatex-auto-format" height="11" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-192e8dc0de46182a65dec93ebf8b5081_l3.png" title="Rendered by QuickLaTeX.com" width="16"/> is the circumference of a circle of with radius <img alt="r" class="ql-img-inline-formula quicklatex-auto-format" height="8" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-c409433a9e2dfcdb83360a974d243f18_l3.png" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="8"/>. (The <em>only</em> facts that we have used here are our definition of <img alt="\pi" class="ql-img-inline-formula quicklatex-auto-format" height="8" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-26d6788550ffd50fe94542bb3e8ee615_l3.png" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="11"/> together with the fact that <img alt="\sigma_r = r \sigma_1" class="ql-img-inline-formula quicklatex-auto-format" height="11" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-c8ca93d60deca29a9a89487ef2eddf50_l3.png" title="Rendered by QuickLaTeX.com" width="66"/>.) Fortunately, the last integral is easy to compute as <br/><p class="ql-center-displayed-equation" style="line-height: 41px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\[\int_0^\infty e^{-\pi r^2} r {\rm d} r = \frac{1}{2\pi} \cdot \int_0^\infty e^{-u} {\rm d} u = \frac{1}{2\pi} \;.\]" class="ql-img-displayed-equation quicklatex-auto-format" height="41" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-f7b0b0433407f63b0c9f6682c331ab63_l3.png" title="Rendered by QuickLaTeX.com" width="303"/></p> Rearranging, we see that <img alt="\sigma_1 = 2\pi" class="ql-img-inline-formula quicklatex-auto-format" height="15" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-bceb0469014bc513c98176ca8e9baf1d_l3.png" title="Rendered by QuickLaTeX.com" width="61"/>!<p/>



<p>So, surprisingly, our mysterious constant <img alt="\pi" class="ql-img-inline-formula quicklatex-auto-format" height="8" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-26d6788550ffd50fe94542bb3e8ee615_l3.png" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="11"/> is actually intimately related with the circumference of a circle. (If we were less civilized mathematicians, we might even have simply defined <img alt="\pi" class="ql-img-inline-formula quicklatex-auto-format" height="8" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-26d6788550ffd50fe94542bb3e8ee615_l3.png" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="11"/> to be the circumference of a circle with radius <img alt="1/2" class="ql-img-inline-formula quicklatex-auto-format" height="19" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-872abde626b8cdf8e983a3345ee98925_l3.png" title="Rendered by QuickLaTeX.com" width="25"/>.)</p>



<h2>What’s so special about two dimensions? Surface area of n-spheres.</h2>



<p>But, why stop in dimension <img alt="2" class="ql-img-inline-formula quicklatex-auto-format" height="12" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-e584dd0bab4e6c8efc164939c28db757_l3.png" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="8"/>? This same <em>one neat trick</em> is just as useful in higher dimensions. E.g., what is the surface area <img alt="\sigma_1^{(n-1)}" class="ql-img-inline-formula quicklatex-auto-format" height="24" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-e14b74f2c92c5d34a31da4576bfaecc9_l3.png" title="Rendered by QuickLaTeX.com" width="46"/> of a unit sphere in <img alt="n" class="ql-img-inline-formula quicklatex-auto-format" height="8" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-b170995d512c659d8668b4e42e1fef6b_l3.png" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="11"/> dimensions? (Conventionally, we write the <img alt="n" class="ql-img-inline-formula quicklatex-auto-format" height="8" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-b170995d512c659d8668b4e42e1fef6b_l3.png" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="11"/>-sphere as <img alt="S^{n-1}" class="ql-img-inline-formula quicklatex-auto-format" height="15" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-8897f8b728befe1f7421e387094e6fd4_l3.png" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="37"/> because it as an <img alt="(n-1)" class="ql-img-inline-formula quicklatex-auto-format" height="19" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-8c10e83257454bc711811cc71f964a7e_l3.png" title="Rendered by QuickLaTeX.com" width="53"/>-dimensional object that happens to be embedded in <img alt="n" class="ql-img-inline-formula quicklatex-auto-format" height="8" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-b170995d512c659d8668b4e42e1fef6b_l3.png" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="11"/>-dimensional space. This is why I write <img alt="\sigma^{(n-1)}_1" class="ql-img-inline-formula quicklatex-auto-format" height="24" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-1529a8cd27bcb6dcd64708282b0f0f0f_l3.png" title="Rendered by QuickLaTeX.com" width="46"/> for its surface area.) Well, we have </p><p class="ql-center-displayed-equation" style="line-height: 41px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\[1 = \int_{-\mathbb{R}^n} e^{-\pi \|x\|^2} {\rm d} x = \int_0^\infty e^{-\pi r^2} \sigma^{(n-1)}_r {\rm d} r= \sigma^{(n-1)}_1 \int_0^\infty e^{-\pi r^2} r^{n-1} {\rm d} r\; .\]" class="ql-img-displayed-equation quicklatex-auto-format" height="41" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-f260e2a2d6410051fb74cc87df3c7792_l3.png" title="Rendered by QuickLaTeX.com" width="531"/></p> (Again, the only property that I have used here is that <img alt="\sigma_r^{(n-1)} = r^{n-1} \sigma_1^{(n-1)}" class="ql-img-inline-formula quicklatex-auto-format" height="24" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-b61ebafad59fad72671514841700ebab_l3.png" title="Rendered by QuickLaTeX.com" width="153"/>.) This integral is a bit less pretty, but using the same approach, we see that  <p class="ql-center-displayed-equation" style="line-height: 42px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\[\int_0^\infty e^{-\pi r^2} r^{n-1} {\rm d} r = \frac{1}{2\pi^{n/2}} \cdot \int_0^{\infty} e^{-u} u^{n/2-1} {\rm d} u = \frac{\Gamma(n/2)}{2\pi^{n/2}}\; ,\]" class="ql-img-displayed-equation quicklatex-auto-format" height="42" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-65c828363c086f1b820b730be79a4c39_l3.png" title="Rendered by QuickLaTeX.com" width="437"/></p> where the last step is literally just plugging in the definition of the Gamma function. Rearranging, we see that the surface area of the unit sphere in <img alt="n" class="ql-img-inline-formula quicklatex-auto-format" height="8" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-b170995d512c659d8668b4e42e1fef6b_l3.png" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="11"/> dimensions is exactly <img alt="\frac{2\pi^{n/2}}{\Gamma(n/2)}" class="ql-img-inline-formula quicklatex-auto-format" height="30" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-50d143fa8519caff967068ce2d9de43f_l3.png" title="Rendered by QuickLaTeX.com" width="42"/>.<p/>



<p>If the Gamma function intimidates you, that’s fine. (It certainly intimidates me.) We can go a bit further by remembering that for integers <img alt="m" class="ql-img-inline-formula quicklatex-auto-format" height="8" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-6b41df788161942c6f98604d37de8098_l3.png" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="15"/>, <img alt="\Gamma(m) = (m-1)!" class="ql-img-inline-formula quicklatex-auto-format" height="19" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-d226e3a5659b079c31cbf51beb7d6f69_l3.png" title="Rendered by QuickLaTeX.com" width="128"/>, while <img alt="\Gamma(m+1/2) = \sqrt{\pi}(2m)!/(4^m m!)" class="ql-img-inline-formula quicklatex-auto-format" height="19" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-5d2b39f9e1062dcc5fa00ec58d82eb91_l3.png" title="Rendered by QuickLaTeX.com" width="246"/>. (Both of these identities follow from the relation <img alt="\Gamma(x) = (x-1) \Gamma(x-1)" class="ql-img-inline-formula quicklatex-auto-format" height="19" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-fb2599738079fdbd25e5b92aa6f75617_l3.png" title="Rendered by QuickLaTeX.com" width="178"/>, which follows from integration by parts, together with the values <img alt="\Gamma(1) = 1" class="ql-img-inline-formula quicklatex-auto-format" height="19" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-53c41acb4ea9695fbe3fbed4d494e73a_l3.png" title="Rendered by QuickLaTeX.com" width="65"/> and <img alt="\Gamma(1/2) = \sqrt{\pi}" class="ql-img-inline-formula quicklatex-auto-format" height="19" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-119c76244632be47b3cddb44bcce032b_l3.png" title="Rendered by QuickLaTeX.com" width="101"/>.) </p>



<p>Then, we see that the surface area of the unit sphere in <img alt="n" class="ql-img-inline-formula quicklatex-auto-format" height="8" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-b170995d512c659d8668b4e42e1fef6b_l3.png" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="11"/> dimensions is </p><p class="ql-center-displayed-equation" style="line-height: 55px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\[\sigma_1^{(n-1)} = \begin{cases}\pi^{n/2} \cdot \frac{2}{(n/2-1)!} &amp;n\text{ even}\\\pi^{(n-1)/2} \cdot \frac{2^n \cdot ((n-1)/2)!}{(n-1)!} &amp;n\text{ odd}.\end{cases}\]" class="ql-img-displayed-equation quicklatex-auto-format" height="55" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-7093395acfb9701717087f97c5b73145_l3.png" title="Rendered by QuickLaTeX.com" width="318"/></p> In particular, from this formula, we immediately see the perhaps surprising fact that the surface area of the sphere in <img alt="n" class="ql-img-inline-formula quicklatex-auto-format" height="8" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-b170995d512c659d8668b4e42e1fef6b_l3.png" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="11"/> dimensions rapidly approaches <img alt="0" class="ql-img-inline-formula quicklatex-auto-format" height="12" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-a5e437be25f29374d30f66cd46adf81c_l3.png" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="9"/> as <img alt="n \to \infty" class="ql-img-inline-formula quicklatex-auto-format" height="10" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-032ad3d6327a419ab33b269b23c31b7c_l3.png" title="Rendered by QuickLaTeX.com" width="55"/>. (I.e., “<img alt="n" class="ql-img-inline-formula quicklatex-auto-format" height="8" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-b170995d512c659d8668b4e42e1fef6b_l3.png" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="11"/>-dimensional unit spheres are tiny.”) We also see the rather strange fact that <img alt="\sigma_1^{(n-1)}" class="ql-img-inline-formula quicklatex-auto-format" height="24" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-e14b74f2c92c5d34a31da4576bfaecc9_l3.png" title="Rendered by QuickLaTeX.com" width="46"/> is a rational multiple of <img alt="\pi^{\lfloor n/2 \rfloor}" class="ql-img-inline-formula quicklatex-auto-format" height="17" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-362edd7540e9e43db2e65a0ddc45e684_l3.png" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="43"/>.<p/>



<p>We can also plug in low values of <img alt="n" class="ql-img-inline-formula quicklatex-auto-format" height="8" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-b170995d512c659d8668b4e42e1fef6b_l3.png" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="11"/> to see what we get. E.g., I have heard that some people are interested in the case when <img alt="n = 2" class="ql-img-inline-formula quicklatex-auto-format" height="12" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-a47a3377f14fefc160d10b089a4aab45_l3.png" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="42"/> and <img alt="n = 3" class="ql-img-inline-formula quicklatex-auto-format" height="12" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-8eda9fc1983d40517cca42fa671a0f51_l3.png" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="43"/>. Plugging in, one sees that the circumference of a circle with radius one is <img alt="2\pi" class="ql-img-inline-formula quicklatex-auto-format" height="12" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-5bfa2124624f767670227d1aeab8d85c_l3.png" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="20"/> (which, ok, we already saw before), and that the surface area of a sphere with radius one is <img alt="4\pi" class="ql-img-inline-formula quicklatex-auto-format" height="12" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-a64f86508ea52835b7fd42736282275d_l3.png" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="20"/>. But, we can easily go farther: the surface area in four dimensions is <img alt="2\pi^2" class="ql-img-inline-formula quicklatex-auto-format" height="15" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-7249ec3f5fb52ad8207e0f9d873c7a4f_l3.png" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="27"/>, and in five dimensions, it is <img alt="8\pi^{2}/3" class="ql-img-inline-formula quicklatex-auto-format" height="20" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-5b263bf1209b153f5824b853138f0510_l3.png" title="Rendered by QuickLaTeX.com" width="45"/>.</p>



<p>And, we can of course find the volume of the unit <img alt="n" class="ql-img-inline-formula quicklatex-auto-format" height="8" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-b170995d512c659d8668b4e42e1fef6b_l3.png" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="11"/>-ball by computing a simple integral </p><p class="ql-center-displayed-equation" style="line-height: 44px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\[V^{(n)} = \int_0^{1}\sigma_r^{(n)} {\rm} d r = \sigma_1^{(n)} \cdot \int_0^{1} r^{n-1} {\rm d} r = \sigma_1^{(n)}/n \; .\]" class="ql-img-displayed-equation quicklatex-auto-format" height="44" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-08b8932dcb424209e24a111106e869b2_l3.png" title="Rendered by QuickLaTeX.com" width="366"/></p><p/>



<p>In short, I think this mysterious constant <img alt="\pi" class="ql-img-inline-formula quicklatex-auto-format" height="8" src="http://www.solipsistslog.com/wp-content/ql-cache/quicklatex.com-26d6788550ffd50fe94542bb3e8ee615_l3.png" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="11"/> is rather nice. Perhaps it will find other applications.</p></div>
    </content>
    <updated>2022-03-14T14:34:24Z</updated>
    <published>2022-03-14T14:34:24Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Noah Stephens-Davidowitz</name>
    </author>
    <source>
      <id>http://www.solipsistslog.com</id>
      <link href="http://www.solipsistslog.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="http://www.solipsistslog.com" rel="alternate" type="text/html"/>
      <subtitle>Life inside the confused and curious mind of a nerd.</subtitle>
      <title>Solipsist's Log</title>
      <updated>2022-03-27T23:00:59Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/039</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/039" rel="alternate" type="text/html"/>
    <title>TR22-039 |  Parallel Repetition For All 3-Player Games Over Binary Alphabet | 

	Kunal Mittal, 

	Uma Girish, 

	Justin Holmgren, 

	Wei Zhan, 

	Ran Raz</title>
    <summary>We prove that for every 3-player (3-prover) game, with binary questions and answers and value less than $1$, the value of the $n$-fold parallel repetition of the game decays polynomially fast to $0$. That is, for every such game, there exists a constant $c&gt;0$, such that the value of the $n$-fold parallel repetition of the game is at most $n^{-c}$.

Along the way to proving this theorem, we prove two additional parallel repetition theorems for multiplayer (multiprover) games, that may be of independent interest:

$\textbf{Playerwise Connected Games (with any number of players and any Alphabet size):}$ We identify a large class of multiplayer games and prove that for every game with value less than $1$ in that class, the value of the $n$-fold parallel repetition of the game decays polynomially fast to $0$.

More precisely, our result applies for $\textit{playerwise connected games}$, with any number of players and any alphabet size:
For each player $i$, we define the graph $G_i$, whose vertices are the possible questions for that player and two questions $x,x'$ are connected by an edge if there exists a vector $y$ of questions for all other players, such that both $(x,y)$ and $(x',y)$ are asked by the referee with non-zero probability. We say that the game is $\textit{playerwise connected}$ if for every $i$, the graph $G_i$ is connected.

Our class of playerwise connected games is strictly larger than the class of connected games that was defined in [DHVY17] and for which exponentially fast decay bounds are known [DHVY17]. For playerwise connected games that are not connected, only inverse Ackermann decay bounds were previously known [Ver96].

$\textbf{Exponential Bounds for the Anti-Correlation Game:}$ In the 3-player $\textit{anti-correlation game}$, two out of three players are given $1$ as input, and the remaining player is given $0$. The two players who were given $1$ must produce different outputs in $\{0,1\}$. We prove that the value of the $n$-fold parallel repetition of that game decays exponentially fast to $0$. That is, there exists a constant $c&gt;0$, such that the value of the $n$-fold parallel repetition of the game is at most $2^{-cn}$. Only inverse Ackermann decay bounds were previously known [Ver96].

The 3-player anti-correlation game was studied and motivated in several previous works. In particular, Holmgren and Yang gave it as an example for a 3-player game whose non-signaling value (is smaller than $1$ and yet) does not decrease at all under parallel repetition [HY19].</summary>
    <updated>2022-03-14T05:14:56Z</updated>
    <published>2022-03-14T05:14:56Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-03-27T23:37:26Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/038</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/038" rel="alternate" type="text/html"/>
    <title>TR22-038 |  Lower bounds for Polynomial Calculus with extension variables over finite fields | 

	Sasank Mouli, 

	Russell Impagliazzo, 

	Toniann Pitassi</title>
    <summary>For every prime p &gt; 0, every n &gt; 0 and ? = O(logn), we show the existence
of an unsatisfiable system of polynomial equations over O(n log n) variables of degree O(log n) such that any Polynomial Calculus refutation over F_p with M extension variables, each depending on at most ? original variables requires size exp(?????(n2/(?^2*2^?*(M + ????nlog(n))))) .</summary>
    <updated>2022-03-13T20:03:44Z</updated>
    <published>2022-03-13T20:03:44Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-03-27T23:37:26Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2022/03/13/ukraine-student-senior-research-fellows-at-tel-aviv-university-apply-by-june-1-2022/</id>
    <link href="https://cstheory-jobs.org/2022/03/13/ukraine-student-senior-research-fellows-at-tel-aviv-university-apply-by-june-1-2022/" rel="alternate" type="text/html"/>
    <title>Ukraine student / senior research fellows at Tel Aviv University (apply by June 1, 2022)</title>
    <summary>Tel Aviv University offers emergency scholarship for research students from Ukraine (see attached). Further, I (Gil Cohen) have immediately available senior / students research fellows in theoretical computer science, coding theory, spectral graph theory, and adjacent mathematical branches. Website: https://c1f423b8-ee8e-41b1-a3a7-2cfc865115ec.filesusr.com/ugd/d112fa_4de343bf5b3a410eae40b3853dcef087.pdf Email: coheng@gmail.com</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Tel Aviv University offers emergency scholarship for research students from Ukraine (see attached). Further, I (Gil Cohen) have immediately available senior / students research fellows in theoretical computer science, coding theory, spectral graph theory, and adjacent mathematical branches.</p>
<p>Website: <a href="https://c1f423b8-ee8e-41b1-a3a7-2cfc865115ec.filesusr.com/ugd/d112fa_4de343bf5b3a410eae40b3853dcef087.pdf">https://c1f423b8-ee8e-41b1-a3a7-2cfc865115ec.filesusr.com/ugd/d112fa_4de343bf5b3a410eae40b3853dcef087.pdf</a><br/>
Email: coheng@gmail.com</p></div>
    </content>
    <updated>2022-03-13T11:10:32Z</updated>
    <published>2022-03-13T11:10:32Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2022-03-27T23:37:46Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-27705661.post-527025314741039880</id>
    <link href="http://processalgebra.blogspot.com/feeds/527025314741039880/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=27705661&amp;postID=527025314741039880" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/527025314741039880" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/527025314741039880" rel="self" type="application/atom+xml"/>
    <link href="http://processalgebra.blogspot.com/2022/03/focs-2021-test-of-time-award-winners.html" rel="alternate" type="text/html"/>
    <title>FOCS 2021 Test-of-Time Award winners (and one deserving paper that missed out)</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>As members of the TCS community will most likely know, FOCS established<a href="https://focs2021.cs.colorado.edu/test-of-time-awards/" target="_blank"> Test-of-Time Awards from its 2021 edition</a> to celebrate contributions published at that conference 30, 20 and 10 years before. The first list of selected winners is, as one might have expected, stellar: <br/></p><ul style="text-align: left;"><li>Uriel Feige, Shafi Goldwasser, László Lovász, Shmuel Safra, Mario Szegedy:<br/>Approximating Clique is Almost NP-Complete.<br/>FOCS 1991</li><li>David Zuckerman:<br/>Simulating BPP Using a General Weak Random Source.<br/>FOCS 1991</li><li>Serge A. Plotkin, David B. Shmoys, Éva Tardos:<br/>Fast Approximation Algorithms for Fractional Packing and Covering Problems.<br/>FOCS 1991</li><li>Ran Canetti:<br/>Universally Composable Security: A New Paradigm for Cryptographic Protocols.<br/>FOCS 2001</li><li>Boaz Barak:<br/>How to Go Beyond the Black-Box Simulation Barrier.<br/>FOCS 2001</li><li>Amit Chakrabarti, Yaoyun Shi, Anthony Wirth, Andrew Chi-Chih Yao:<br/>Informational Complexity and the Direct Sum Problem for Simultaneous Message Complexity.<br/>FOCS 2001</li><li>Zvika Brakerski, Vinod Vaikuntanathan:<br/>Efficient Fully Homomorphic Encryption from (Standard) LWE.<br/>FOCS 2011</li></ul><p>FWIW, I offer my belated congratulations to all the award recipients, whose work has had, and continues to have, a profound influence on the "Volume A" TCS community. </p><p>Apart from celebrating their achievement, the purpose of this post is to highlight a paper from FOCS 1991 that missed out on the Test-of-Time Award, but that, IMHO, would have fully deserved it. </p><p>I am fully aware that the number of deserving papers/scientists is typically larger, if not much larger, than the number of available awards. Awards are a scarce resource! My goal with this post is simply to remind our community (and especially its younger members) of a seminal contribution that they might want to read or re-read. <br/></p><p>The paper in question is "<a href="https://www.cs.cornell.edu/courses/cs6860/2019sp/Handouts/EmersonJutla91.pdf" target="_blank">Tree automata, mu-calculus and determinacy</a>" by <a href="https://www.cs.utexas.edu/~emerson/" target="_blank">Allen Emerson</a> and <a href="https://researcher.watson.ibm.com/researcher/view.php?person=us-csjutla" target="_blank">Charanjit S. Jutla</a>, which appeared at FOCS 1991. (Emerson shared the 2007 A.M. Turing Award for the invention of model checking and Jutla went on to doing path-breaking work in cryptography.) That paper is absolutely fundamental for the mu-calculus, but also for automata theory, and verification in general. It introduced many ideas and results that became the basis for extensive research. </p><p>As a first contribution, the article introduced <a href="https://en.wikipedia.org/wiki/Parity_game" target="_blank">parity games</a> and proved their fundamental properties. The parity condition was a missing link in automata theory on infinite objects. It made the whole theory much simpler than that proposed in earlier work.  Technically, the parity condition is both universal and positional. Universal means that tree automata with parity conditions are as expressive as those with Rabin or Muller conditions. Positional means that in the acceptance game if a player has a winning strategy then she has one depending only on the current position and not on the history of the play so far. This is a huge technical advance for all automata-theoretic constructions and for the analysis of  infinite-duration games. It allows one, for instance,  to avoid the complicated arguments of Gurevich and Harlington in <a href="https://doi.org/10.1145/800070.802177" target="_blank">their seminal STOC 1982 article</a>, which were already a huge simplification of <a href="https://www.ams.org/journals/tran/1969-141-00/S0002-9947-1969-0246760-1/S0002-9947-1969-0246760-1.pdf" target="_blank">Rabin's original argument from 1969</a> proving the decidability of the <a href="https://en.wikipedia.org/wiki/Monadic_second-order_logic#Decidability_and_complexity_of_satisfiability" target="_blank">monadic second-order theory of the infinite binary tree</a> and much more. In passing, let me remark that Rabin has gone on record saying that "I consider this to be the most difficult research I have ever done." See <a href="https://cacm.acm.org/magazines/2010/2/69370-an-interview-with-michael-rabin/fulltext" target="_blank">this interview</a> in CACM. </p><p>The second main contribution of that paper is the discovery of the relation between parity games and the mu-calculus. The authors show how a mu-calculus model-checking problem can be reduced to solving a parity game, and conversely, how the set of winning positions in a parity game can be described by a mu-calculus formula. This result is the birth of the "model-checking via games" approach. It also shows that establishing a winner in parity games is contained both in NP and in co-NP. As a corollary, the model-checking problem is as complex as solving games. It is still not known if the problem is in PTIME. A <a href="https://doi.org/10.1145/3055399.3055409" target="_blank">recent advance from STOC'17</a> gives a quasi-polynomial-time algorithm. (See <a href="https://blog.computationalcomplexity.org/2017/03/parity-games-in-quasipolynomial-time.html" target="_blank">this blog post</a> for a discussion of that result, which received the STOC 2017 best paper award and was immediately followed up by a flurry of related papers.) </p><p>Finally, the paper also shows how to prove Rabin's complementation lemma, which is the most difficult step in his celebrated aforementioned decidability result, with the help of parity conditions. The proof is radically simpler than previous approaches. The paper puts this contribution most prominently, but actually the conceptual and technical contributions presented later in the paper turned out to be most important for the community. </p><p>Overall, the above-mentioned paper by Emerson and Jutla is a truly seminal contribution that has stood the test of time, has sown the seeds for much research  over the last thirty years (as partly witnessed by the over 1,130 citations it has received so far) and is still stimulating advances at the cutting edge of theoretical computer science that bridge the Volume A-Volume B divide. </p><p>I encourage everyone to read it!</p><p><b>Acknowledgement:</b> I have learnt much of the content of this post from Igor Walukiewicz. The responsibility for any infelicity is mine alone. <br/></p></div>
    </content>
    <updated>2022-03-12T12:24:00Z</updated>
    <published>2022-03-12T12:24:00Z</published>
    <author>
      <name>Luca Aceto</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/01092671728833265127</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-27705661</id>
      <author>
        <name>Luca Aceto</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/01092671728833265127</uri>
      </author>
      <link href="http://processalgebra.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://processalgebra.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Papers I find interesting---mostly, but not solely, in Process Algebra---, and some fun stuff in Mathematics and Computer Science at large and on general issues related to research, teaching and academic life.</subtitle>
      <title>Process Algebra Diary</title>
      <updated>2022-03-25T19:59:43Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://decentralizedthoughts.github.io/2022-03-12-dfinity-synchrony/</id>
    <link href="https://decentralizedthoughts.github.io/2022-03-12-dfinity-synchrony/" rel="alternate" type="text/html"/>
    <title>Consensus by Dfinity - Part I</title>
    <summary>This is part one of a two-part post on consensus protocols published by the Dfinity Foundation. Dfinity published two protocols: The first, published in 2018, is a BFT protocol under synchrony by Hanke, Movahedi, and Williams. We will call this protocol Dfinity’s Synchronous Consensus (DSC). An independent report called Dfinity...</summary>
    <updated>2022-03-12T05:00:00Z</updated>
    <published>2022-03-12T05:00:00Z</published>
    <source>
      <id>https://decentralizedthoughts.github.io</id>
      <author>
        <name>Decentralized Thoughts</name>
      </author>
      <link href="https://decentralizedthoughts.github.io" rel="alternate" type="text/html"/>
      <link href="https://decentralizedthoughts.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Decentralized thoughts about decentralization</subtitle>
      <title>Decentralized Thoughts</title>
      <updated>2022-03-27T23:01:17Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://decentralizedthoughts.github.io/2022-03-12-dfinity-partial-synchrony/</id>
    <link href="https://decentralizedthoughts.github.io/2022-03-12-dfinity-partial-synchrony/" rel="alternate" type="text/html"/>
    <title>Consensus by Dfinity - Part II (Internet Computer Consensus)</title>
    <summary>This post is part two of a two-part post on consensus protocols published by the Dfinity Foundation; you can find part one here. This post will intuitively explain the Internet Computer Consensus. The differences between DSC and ICC are primarily due to the underlying network model that they assume —...</summary>
    <updated>2022-03-12T05:00:00Z</updated>
    <published>2022-03-12T05:00:00Z</published>
    <source>
      <id>https://decentralizedthoughts.github.io</id>
      <author>
        <name>Decentralized Thoughts</name>
      </author>
      <link href="https://decentralizedthoughts.github.io" rel="alternate" type="text/html"/>
      <link href="https://decentralizedthoughts.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Decentralized thoughts about decentralization</subtitle>
      <title>Decentralized Thoughts</title>
      <updated>2022-03-27T23:01:17Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://thmatters.wordpress.com/?p=1362</id>
    <link href="https://thmatters.wordpress.com/2022/03/11/call-for-nominations-knuth-prize/" rel="alternate" type="text/html"/>
    <title>Call for nominations: Knuth Prize</title>
    <summary>Deadline: March 31, 2022. The Donald E. Knuth Prize for outstanding contributions to the foundations of computer science is awarded for major research accomplishments and contributions to the foundations of computer science over an extended period of time. The Prize is awarded annually by the ACMSpecial Interest Group on Algorithms and Computation Theory (SIGACT) and the IEEETechnical Committee […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><strong>Deadline: March 31, 2022.</strong></p>



<p>The Donald E. Knuth Prize for outstanding contributions to the foundations of computer science is awarded for major research accomplishments and contributions to the foundations of computer science over an extended period of time. The Prize is awarded annually by the <a href="https://urldefense.com/v3/__https://acm.org/__;!!IBzWLUs!FhlJI8zMLEOwnp6yNYlHlUi7BTqdRYKuBcTGlpuO3upUQ3CeNXk5Et-Ykc0qrYCK$" rel="noreferrer noopener" target="_blank">ACM</a><a href="https://urldefense.com/v3/__https://www.sigact.org/__;!!IBzWLUs!FhlJI8zMLEOwnp6yNYlHlUi7BTqdRYKuBcTGlpuO3upUQ3CeNXk5Et-YkRfc620V$" rel="noreferrer noopener" target="_blank">Special Interest Group on Algorithms and Computation Theory</a> (SIGACT) and the <a href="https://urldefense.com/v3/__https://www.ieee.org/__;!!IBzWLUs!FhlJI8zMLEOwnp6yNYlHlUi7BTqdRYKuBcTGlpuO3upUQ3CeNXk5Et-YkSouJjK-$" rel="noreferrer noopener" target="_blank">IEEE</a><a href="https://urldefense.com/v3/__https://tc.computer.org/tcmf/__;!!IBzWLUs!FhlJI8zMLEOwnp6yNYlHlUi7BTqdRYKuBcTGlpuO3upUQ3CeNXk5Et-YkcMUrupP$" rel="noreferrer noopener" target="_blank">Technical Committee on the Mathematical Foundations of Computing</a> (TCMF).</p>



<p><strong>Nomination Procedure.</strong> Anyone in the Theoretical Computer Science community may nominate a candidate. To do so, please send nominations to <strong><a rel="noreferrer noopener" target="_blank">knuth.prize.2022@gmail.com</a></strong> by <strong>March 31, 2022</strong>. The nomination should state the nominee’s name, summarize their contributions in one or two pages, provide a CV for the nominee or a pointer to the nominee’s web page, and give telephone and email contact information for the nominator. Any supporting letters from other members of the community (up to a limit of 5) should be included in the package that the nominator submits. Supporting letters should contain substantial information not in the nomination. Others may endorse the nomination simply by adding their names to the nomination letter. If you have nominated a candidate in past years, you can re-nominate the candidate by sending a message to that effect to the above email address. (You may revise the nominating materials if you so desire.)</p>



<p><strong>Criteria for Selection.</strong> The winner is selected by a Prize Committee consisting of six people appointed by the SIGACT and TCMF Chairs, see below for the composition of the committee.</p>



<p>Previous nominations made or updated in the last 5 years will be considered. Older nominations must be updated for consideration. Note that the Knuth Prize is awarded to a single individual each year. Nominations of groups of researchers will not be considered.</p>



<p>In selecting the Knuth Prize winner, the Committee pays particular attention to a <em>sustained record</em> of high-impact, seminal contributions to the foundations of computer science. The selection may also be based partly on educational accomplishments and contributions such as fundamental textbooks and high-quality students. The award is not given for service to the theoretical computer science community, but service may be included in the citation for a winner if appropriate.</p>



<p>The 2022 prize committee consists of Harold Gabow (U. Colorado), Monika Henzinger (U. Vienna), Kurt Mehlhorn (Max Planck Institute), Dana Randall (Chair, Georgia Tech), Madhu Sudan (Harvard U.), and Andy Yao (Tsinghua U.).</p></div>
    </content>
    <updated>2022-03-11T20:49:39Z</updated>
    <published>2022-03-11T20:49:39Z</published>
    <category term="awards"/>
    <category term="Deadlines"/>
    <category term="TCS Community"/>
    <author>
      <name>shuchic</name>
    </author>
    <source>
      <id>https://thmatters.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://thmatters.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://thmatters.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://thmatters.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://thmatters.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theory Matters</title>
      <updated>2022-03-27T23:37:55Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://thmatters.wordpress.com/?p=1357</id>
    <link href="https://thmatters.wordpress.com/2022/03/11/call-for-nominations-godel-prize/" rel="alternate" type="text/html"/>
    <title>Call for nominations: Godel Prize</title>
    <summary>Deadline for nominations extended to March 31st 2022. https://www.sigact.org/prizes/g%C3%B6del.html The Gödel Prize for outstanding papers in the area of theoretical computer science is sponsored jointly by the European Association for Theoretical Computer Science (EATCS) and the Special Interest Group on Algorithms and Computation Theory of the Association for Computing Machinery (ACM SIGACT). This award is presented annually, with the presentation taking place alternately […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><strong>Deadline for nominations extended to March 31st 2022.</strong></p>



<p><a href="https://urldefense.com/v3/__https://www.sigact.org/prizes/g**Adel.html__;w7Y!!IBzWLUs!EguPGLYWUarkIsJJaLrhDzTZKGjc97LX_FB94NzWMobXbrXlbTKzzky4VPAE-mxj$" rel="noreferrer noopener" target="_blank">https://www.sigact.org/prizes/g%C3%B6del.html</a></p>



<p>The Gödel Prize for outstanding papers in the area of theoretical computer science is sponsored jointly by the European Association for Theoretical Computer Science (EATCS) and the Special Interest Group on Algorithms and Computation Theory of the Association for Computing Machinery (ACM SIGACT). This award is presented annually, with the presentation taking place alternately at the International Colloquium on Automata, Languages, and Programming (ICALP) and the ACM Symposium on Theory of Computing (STOC). The thirtieth Gödel Prize will be awarded at the forty-ninth International Colloquium on Automata, Languages and Programming (ICALP), which will be hybrid, happening both physically and virtually. The physical meeting will take place in Paris, France, July 4–8 2022.</p>



<p>The Prize is named in honor of Kurt Gödel in recognition of his major contributions to mathematical logic and of his interest, discovered in a letter he wrote to John von Neumann shortly before von Neumann’s death, in what has become the famous “P versus NP” question. The Prize includes an award of USD 5,000.</p>



<p><strong>Award Committee</strong></p>



<p>The 2022 Award Committee consists of Samson Abramsky (Chair, University College London), Nikhil Bansal (University of Michigan), Irit Dinur (Weizmann Institute), Anca Muscholl (University of Bordeaux), Ronitt Rubinfeld (Massachusetts Institute of Technology), and David Zuckerman (University of Texas at Austin).</p>



<p><strong>Eligibility</strong></p>



<p>The 2022 Prize rules are given below and they supersede any different interpretation of the generic rule to be found on websites of both SIGACT and EATCS. Any research paper or series of papers by a single author or by a team of authors is deemed eligible if:</p>



<p>• The main results were not published (in either preliminary or final form) in a journal or conference proceedings before January 1, 2009.</p>



<p>• The paper was published in a recognized refereed journal no later than December 31, 2021.<br/>The research work nominated for the award should be in the area of theoretical computer science. Nominations are encouraged from the broadest spectrum of the theoretical computer science community so as to ensure that potential award winning papers are not overlooked. The Award Committee shall have the ultimate authority to decide whether a particular paper is eligible for the Prize.</p>



<p><strong>Nominations</strong></p>



<p>Nominations for the award should be submitted by email to the Award Committee Chair: <a rel="noreferrer noopener" target="_blank">s.abramsky@ucl.ac.uk</a>. Please make sure that the Subject line of all nominations and related messages begin with “Goedel Prize 2022”. To be considered, nominations for the 2022 Prize must be received by March 31, 2022.</p>



<p>A nomination package should include:</p>



<p>• A printable copy (or copies) of the journal paper(s) being nominated, together with a complete citation (or citations) thereof.</p>



<p>• A statement of the date(s) and venue(s) of the first conference or workshop publication(s) of the nominated work(s) or a statement that no such publication has occurred.</p>



<p>• A brief summary of the technical content of the paper(s) and a brief explanation of its significance.</p>



<p>• A support letter or letters signed by at least two members of the scientific community.<br/>Additional support letters may also be received and are generally useful. The nominated paper(s) may be in any language. However, if a nominated publication is not in English, the nomination package must include an extended summary written in English.</p>



<p>Those intending to submit a nomination should contact the Award Committee Chair by email well in advance. The Chair will answer questions about eligibility, encourage coordination among different nominators for the same paper(s), and also accept informal proposals of potential nominees or tentative offers to prepare formal nominations. The committee maintains a database of past nominations for eligible papers, but fresh nominations for the same papers (especially if they highlight new evidence of impact) are always welcome.</p></div>
    </content>
    <updated>2022-03-11T20:47:31Z</updated>
    <published>2022-03-11T20:47:31Z</published>
    <category term="awards"/>
    <category term="Deadlines"/>
    <category term="TCS Community"/>
    <author>
      <name>shuchic</name>
    </author>
    <source>
      <id>https://thmatters.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://thmatters.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://thmatters.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://thmatters.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://thmatters.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theory Matters</title>
      <updated>2022-03-27T23:37:55Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2022/03/11/postdoc-at-utrecht-university-apply-by-april-4-2022/</id>
    <link href="https://cstheory-jobs.org/2022/03/11/postdoc-at-utrecht-university-apply-by-april-4-2022/" rel="alternate" type="text/html"/>
    <title>Postdoc at Utrecht University (apply by April 4, 2022)</title>
    <summary>The ERC starting grant project “Finding Cracks in the Wall of NP-completeness” of PI Jesper Nederlof aims to improve classical algorithms for NP-hard problems. For example: Can the Bellman-Held-Karp dynamic programming algorithm from the 1960’s that solves TSP with n cities in 2^n time be improved to 1.9999^n time? Join the project as a postdoc […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The ERC starting grant project “Finding Cracks in the Wall of NP-completeness” of PI Jesper Nederlof aims to improve classical algorithms for NP-hard problems. For example: Can the Bellman-Held-Karp dynamic programming algorithm from the 1960’s that solves TSP with n cities in 2^n time be improved to 1.9999^n time? Join the project as a postdoc now!</p>
<p>Website: <a href="https://www.uu.nl/en/organisation/working-at-utrecht-university/jobs/postdoc-position-in-algorithmic-theory-10-fte">https://www.uu.nl/en/organisation/working-at-utrecht-university/jobs/postdoc-position-in-algorithmic-theory-10-fte</a><br/>
Email: j.nederlof@uu.nl</p></div>
    </content>
    <updated>2022-03-11T19:49:33Z</updated>
    <published>2022-03-11T19:49:33Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2022-03-27T23:37:46Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://ptreview.sublinear.info/?p=1634</id>
    <link href="https://ptreview.sublinear.info/2022/03/news-for-february-2022/" rel="alternate" type="text/html"/>
    <title>News for February 2022</title>
    <summary>This month has seen a flurry of activity in sublinear algorithms and a diverse collection of papers have come up, with topics ranging from differentially private sublinear algorithms to local testers for multiplicity codes. Apologies to the readers for the delay in putting this post together! Almost-Optimal Sublinear-Time Edit Distance in the Low Distance Regime […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>This month has seen a flurry of activity in sublinear algorithms and a diverse collection of papers have come up, with topics ranging from differentially private sublinear algorithms to local testers for multiplicity codes. Apologies to the readers for the delay in putting this post together!</p>



<p><strong>Almost-Optimal Sublinear-Time Edit Distance in the Low Distance Regime</strong> by Karl Bringmann, Alejandro Cassis, Nick Fischer and Vasileios Nakos (<a href="https://arxiv.org/abs/2202.08066">arXiv</a>)</p>



<p>This paper considers the problem of gap edit distance, i.e., of determining if the edit distance between two strings \(x\) and \(y\) is at most \(k\) or at least \(K\). Their main result is an algorithm that runs in time \(O(n/k + \text{poly}(k))\) and solves the problem for \(K =  k \cdot 2^{\tilde{O}(\sqrt{\log k})}\). The paper improves upon earlier results of Goldenberg, Krauthgamer and Saha (2019) and Kociumaka and Saha (2020) who solved the problem for \(K = k^2\) with the same asymptotic guarantee on the query complexity. </p>



<p>One of the interesting takeaways from the paper is that the complexity of solving the gap Hamming distance and gap edit distance are similar in the low distance regime. For both, the complexity of solving the \((k, k^{1+o(1)})\)-gap problem is \(n/k^{1 \pm o(1)}\). This needs to be contrasted with the fact that solving \((k, \Omega(n))\)-gap edit distance requires \(\Omega(\sqrt{k})\) queries as shown by Batu, Ergun, Kilian, Magen and Raskhodnikova (2003), whereas \((k, \Omega(n))\)-gap Hamming distance can be solved in \(O(1)\) time. </p>



<p>These results are incomparable to those obtained by Goldenberg, Kociumaka, Krauthgamer and Saha (which was discussed in our November 2021 post), where they give a nonadaptive algorithm with complexity \(O(n/k^{1.5})\) for \((k, k^2)\)-gap edit distance problem. The algorithm in the present paper is adaptive and works faster for smaller values of \(k\).</p>



<p/>



<p><strong>Privately Estimating Graph Parameters in Sublinear time</strong> by Jeremiah Blocki, Elena Grigorescu, Tamalika Mukherjee (<a href="https://arxiv.org/abs/2202.05776">arXiv</a>)</p>



<p>Differentially private approximation algorithms for optimization problems on graphs is a well-studied topic. This paper opens up an exciting research direction by initiating a systematic study of the design of differentially private sublinear-time algorithms. The setting is that graphs are viewed as databases and two graphs are neighboring if they differ in an edge (or a node). An algorithm \(A\) is \(\epsilon\)-differentially private if for every pair of edge-neighboring(or node-neighboring) graphs \(G, G’\) and for every subset \(S\) of outputs, \(\Pr[A(G) \in S] \leq \exp(\epsilon) \cdot \Pr[A(G’) \in S]\).</p>



<p>The paper presents \(\epsilon\)-differentially private sublinear-time algorithms for well-studied problems such as estimating the average degree, the size of a min vertex cover and the size of a maximum matching. These algorithms access the input graphs via <em>neighbor queries</em> and <em>degree queries</em>. </p>



<p>In addition to providing a strong privacy guarantee, their algorithms nearly match the approximation and complexity guarantees of their non-differentially private counterparts. The main idea seems to be the formalization of a sensitivity notion, which they refer to as Global Coupled Sensitivity, and bounding it for the known sublinear-time algorithms for the aforementioned problems. Finally, they add Laplace noise calibrated with this sensitivity value to the output of the algorithms to make them differentially private.  </p>



<p/>



<p><strong>Testability and Local Certification of Monotone Properties in Minor-closed Classes</strong> by Louis Esperet And Sergey Norin (<a href="https://arxiv.org/abs/2202.00543">arXiv</a>)</p>



<p>One of the major interests in graph property testing is to characterize which properties are testable, i.e, can be \(\epsilon\)-tested with query complexity that depends only on the parameter \(\epsilon\). The question of testability is well-understood in the dense graph model as well as the bounded degree model. This paper concerns itself with testability questions in the general model or the sparse model of graph property testing, where graphs are represented as adjacency lists with no bound on the maximum degree. </p>



<p>The authors prove that every monotone property of<strong> </strong>minor-closed graph classes is testable with one-sided error, where a property is monotone if it is closed under taking subgraphs and a graph class is minor-closed if it is closed under taking minors. A crucial fact to be noted here is that a tester is allowed to make only uniformly random nerighbor queries. </p>



<p>This result is a significant generalization of a 2019 result by Czumaj and Sohler, who proved that for every finite set of graphs \(\mathcal{H}\), every \(\mathcal{H}\)-free property of minor-closed graph classes is testable with one-sided error, where a graph satisfies \(\mathcal{H}\)-freeness if none of its subgraphs belong to \(\mathcal{H}\). </p>



<p>They show an interesting consequence of their results to designing a short local certification scheme for monotone properties of minor-closed graph classes. Roughly speaking, they show the existence of a prover-verifier system for the aforementioned testing problem where proofs of length \(O(\log n)\) are assigned to each vertex and that verifier needs to observe only the proofs assigned to a vertex and its neighbors.<br/></p>



<p><strong>The plane test is a local tester for Multiplicity Codes</strong> by Dan Karliner, Roie Salama, and Amnon Ta-Shma (<a href="https://eccc.weizmann.ac.il/report/2022/028/">ECCC</a>)</p>



<p>Multiplicity codes are a generalization of Reed-Muller codes and was first studied by Guruswami and Wang (2013) and Kopparty, Saraf and Yekhanin (2014). The messages here are polynomials of degree \(d\) over \(m\) variables and the codeword corresponding to a polynomial \(p\) is the evaluation of \(p\) and of all of its directional derivatives of order upto \(s\) over all the points in \(\mathbb{F}_q^m\), where \(q\) is a prime power. </p>



<p>Even though multiplicity codes are known to be locally decodable, it was open whether they are locally testable. Local testers for Reed Muller codes work by restricting the evaluations to a uniformly random line in \(\mathbb{F}_q^m\) and checking whether it corresponds to the evaluations of a degree \(d\) univariate polynomial. The authors first show that such a tester does not work for the case of multiplicity codes when \(d\) is large. They then show that a <em>plane test</em> is a good local tester for multiplicity codes even for larger values of \(d\). Specifically, a plane test checks whether the restriction of a given word, which is purportedly the evaluation of a polynomial of degree \(d\) and of its derivatives, to a uniformly random plane in \(\mathbb{F}_q^m\) is a bivariate multiplicity code of degree \(d\). </p>



<p/>



<p>We conclude the post with a short note from Nader Bshouty and Oded Goldreich on a fundamental characterization result in property testing. </p>



<p><strong>On properties that are non-trivial to test</strong> by Nader H. Bshouty and Oded Goldreich (<a href="https://eccc.weizmann.ac.il/report/2022/013/">ECCC</a>)</p>



<p>A property on binary strings is nontrivial if for infinitely many \(n\), the property contains at least one string of length \(n\) and at most \(2^{n – \Omega(n)}\) strings of length \(n\). The note shows that every nontrivial property requires \(\Omega(1/\epsilon)\) queries to \(\epsilon\)-test. </p></div>
    </content>
    <updated>2022-03-11T04:09:38Z</updated>
    <published>2022-03-11T04:09:38Z</published>
    <category term="Monthly digest"/>
    <author>
      <name>Nithin Varma</name>
    </author>
    <source>
      <id>https://ptreview.sublinear.info</id>
      <link href="https://ptreview.sublinear.info/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://ptreview.sublinear.info" rel="alternate" type="text/html"/>
      <subtitle>The latest in property testing and sublinear time algorithms</subtitle>
      <title>Property Testing Review</title>
      <updated>2022-03-27T23:00:54Z</updated>
    </source>
  </entry>
</feed>
