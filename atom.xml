<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2019-12-13T13:21:47Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1912.05998</id>
    <link href="http://arxiv.org/abs/1912.05998" rel="alternate" type="text/html"/>
    <title>Examples relating to Green's conjecture in low characteristics and genera</title>
    <feedworld_mtime>1576195200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Topik Teguh Estu, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Im:Mee_Seong.html">Mee Seong Im</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Manning:Benjamin.html">Benjamin Manning</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Michaels:Zachary.html">Zachary Michaels</a>, Joseph Pasko, William Rulla, Nishan Wijesinghe <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1912.05998">PDF</a><br/><b>Abstract: </b>We exhibit approximately fifty Betti diagrams of free resolutions of rings of
smooth, connected canonical curves of genera $9$-$14$ in prime characteristics
between $2$ and $11$. Generic Green's conjecture is verified for genera $9$ and
$10$ for characteristics $2$, $5$, $7$, and $11$.
</p></div>
    </summary>
    <updated>2019-12-13T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-12-13T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1912.05826</id>
    <link href="http://arxiv.org/abs/1912.05826" rel="alternate" type="text/html"/>
    <title>Efficient Approximation of the Matching Distance for 2-parameter persistence</title>
    <feedworld_mtime>1576195200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kerber:Michael.html">Michael Kerber</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nigmetov:Arnur.html">Arnur Nigmetov</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1912.05826">PDF</a><br/><b>Abstract: </b>The matching distance is a computationally tractable topological measure to
compare multi-filtered simplicial complexes. We design efficient algorithms for
approximating the matching distance of two bi-filtered complexes to any desired
precision $\epsilon&gt;0$. Our approach is based on a quad-tree refinement
strategy introduced by Biasotti et al., but we recast their approach entirely
in geometric terms. This point of view leads to several novel observations
resulting in a practically faster algorithm. We demonstrate this speed-up by
experimental comparison and provide our code in a public repository which
provides the first efficient publicly available implementation of the matching
distance.
</p></div>
    </summary>
    <updated>2019-12-13T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-12-13T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1912.05819</id>
    <link href="http://arxiv.org/abs/1912.05819" rel="alternate" type="text/html"/>
    <title>The Lexicographic Method for the Threshold Cover Problem</title>
    <feedworld_mtime>1576195200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Francis:Mathew_C=.html">Mathew C. Francis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jacob:Dalu.html">Dalu Jacob</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1912.05819">PDF</a><br/><b>Abstract: </b>The lexicographic method is a technique that was introduced by Hell and Huang
[Journal of Graph Theory, 20(3):361--374, 1995] as a way to simplify the
problems of recognizing and obtaining representations of comparability graphs,
proper circular-arc graphs and proper interval graphs. This method gives rise
to conceptually simple recognition algorithms and leads to much simpler proofs
for some characterization theorems for these classes. Threshold graphs are a
class of graphs that have many equivalent definitions and have applications in
integer programming and set packing problems. A graph is said to have a
threshold cover of size $k$ if its edges can be covered using $k$ threshold
graphs. Chv\'atal and Hammer conjectured in 1977 that given a graph $G$, a
suitably constructed auxiliary graph $G'$ has chromatic number equal to the
minimum size of a threshold cover of $G$. Although Cozzens and Leibowitz showed
that this conjecture is false in the general case, Raschle and Simon
[Proceedings of the Twenty-seventh Annual ACM Symposium on Theory of Computing,
STOC '95, pages 650--661, 1995] proved that $G$ has a threshold cover of size 2
if and only if $G'$ is bipartite. We show how the lexicographic method can be
used to obtain a completely new and much simpler proof for this result. This
method also gives rise to a simple new LexBFS-based algorithm for recognizing
graphs having a threshold cover of size 2. Although this algorithm is not the
fastest known, it is a certifying algorithm that matches the time complexity of
the fastest known certifying algorithm for this problem. The algorithm can also
be easily adapted to give a certifying recognition algorithm for bipartite
graphs that can be covered by two chain subgraphs.
</p></div>
    </summary>
    <updated>2019-12-13T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-12-13T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1912.05712</id>
    <link href="http://arxiv.org/abs/1912.05712" rel="alternate" type="text/html"/>
    <title>Short simplex paths in lattice polytopes</title>
    <feedworld_mtime>1576195200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pia:Alberto_Del.html">Alberto Del Pia</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Michini:Carla.html">Carla Michini</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1912.05712">PDF</a><br/><b>Abstract: </b>We consider the problem of optimizing a linear function over a lattice
polytope P contained in [0,k]^n and defined via m linear inequalities. We
design a simplex algorithm that, given an initial vertex, reaches an optimal
vertex by tracing a path along the edges of P of length at most O(n^6 k log k).
The length of this path is independent on m and is the best possible up to a
polynomial function, since it is only polynomially far from the worst case
diameter. The number of arithmetic operations needed to compute the next vertex
in the path is polynomial in n, m and log k. If k is polynomially bounded by n
and m, the algorithm runs in strongly polynomial time.
</p></div>
    </summary>
    <updated>2019-12-13T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-12-13T01:30:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-7376087648863245436</id>
    <link href="https://blog.computationalcomplexity.org/feeds/7376087648863245436/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/12/why-is-there-no-all-encompassing-term.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7376087648863245436" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7376087648863245436" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/12/why-is-there-no-all-encompassing-term.html" rel="alternate" type="text/html"/>
    <title>Why is there no all-encompassing term for a course on Models of Computation?</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">In my <a href="https://blog.computationalcomplexity.org/2019/12/what-do-you-call-your-ugrad-non.html">last blog post</a> I asked my readers to leave comments saying what the name of the course that has some of Regular Languages, Context Free Languages  Decideability, P, NP (any maybe other stuff) in it.  I suspected there would be many different names and their were. I was able to put all but 6 into 4 equivalence classes. So that's 10 names. Thats a lot  especially compared to<br/>
<br/>
(Introduction to) Algorithms<br/>
<br/>
and<br/>
<br/>
(Introduction to) Cryptography<br/>
<br/>
which I suspect have far fewer names. One commenter pointed out that the reason for the many different names is that there are many versions of the course. That's not quite an explanation since there are also many different versions of Cryptography---at UMCP  crypto is cross listed in THREE departments (CS, Math, EE) and its taught by 6 or so different people who don't talk to each other (I am one of them). I think Algorithms is more uniform across colleges.<br/>
<br/>
I think that terms Algorithms and Cryptography are both rather broad and can accommodate many versions of the courses, whereas no term seems to be agreed upon to encompass the DFA etc course.<br/>
Even saying DFA etc is not quite right since some of the courses spend little or even no time on DFA's.<br/>
<br/>
Below is a list of all the names I got and some comments. Note that some schools appear twice since they have two courses along these lines.<br/>
<br/>
-----------------------------------------<br/>
TITLE: (Introduction to) Theory of Computation:<br/>
<br/>
Swarthmore:                                            Theory of Computation<br/>
<br/>
UCSD:                                                     Theory of Computation<br/>
<br/>
Saint Michaels:                                        Theory of Computation<br/>
<br/>
Univ of Washington: Introduction to the Theory of Computation<br/>
<br/>
Waterloo:                  Introduction to the Theory of Computing<br/>
<br/>
COMMENT: Theory of Computation could have been the term that encompasses all of these courses. I speculate that it didn't catch on since it sounds too much like computability theory which is only one part of the course.<br/>
<br/>
------------------------<br/>
TITLE: Formal Languages and XXX<br/>
<br/>
CMU:                                                Formal Languages, Automata, and Computability<br/>
<br/>
Florida Tech:                                    Formal Languages and Automata Theory<br/>
<br/>
UC-Irvine:                                        Formal Languages and Automata Theory<br/>
<br/>
Univ of Chicago:    Introduction to Formal Languages<br/>
<br/>
University of Bucharest:                 Formal Language and Automata<br/>
<br/>
TU Darmstadt:                                Formal Foundations of CS I: Automata, Formal Languages, and Decidability<br/>
<br/>
TUK Germany:                               Formal Languages and Computability<br/>
<br/>
COMMENT: The title makes it sound like they don't cover P and NP. I do not know if thats true; however, I speculate that, it could never be the encompassing term.<br/>
<br/>
Spell Check things Automata and Computability are not words, but I've googled them and they seem to be words.<br/>
<br/>
--------------------------<br/>
TITLE: Computability/Decidability and Complexity/Intractability<br/>
<br/>
Reed College: Computability and Complexity<br/>
<br/>
Caltech:          Decidability and Intractability<br/>
<br/>
COMMENT: The title makes it sound like they don't cover regular or context free languages. I do not know if that's true; however, I speculate that, since the terms sound that way, they never caught on as the general term.<br/>
<br/>
Spellecheck thinks that neither Decidability nor Decideability is a word. Google seems to say that I should leave out the e, so I will.<br/>
<br/>
------------------------------<br/>
TITLE:  Blah MODELS Blah<br/>
<br/>
Tel-Aviv (a long time ago) Computational Models<br/>
<br/>
UIUC:                               Algorithms and Models of Computation (also has some algorithms in it)<br/>
<br/>
Waterloo:                                                   Models of Computation (enriched version)<br/>
<br/>
COMMENT: Models of Computation sounds like a good name for the course! Too bad it didn't catch on.  It would also be able to withstand changes in the content like more on parallelism or more on communication complexity.<br/>
<br/>
------------------------------<br/>
TITLE: MISC<br/>
<br/>
CMU:                                          Great Ideas in Theoretical Computer Science<br/>
<br/>
UCLouvain (Belgium)                Calulabitite (Computability)<br/>
<br/>
Moscow Inst. of  Phy. and Tech.: Mathematical logic and Theory of Algorithms<br/>
<br/>
Portland State University:            Computational Structures<br/>
<br/>
Germany:                                     Informatak III (Not all of Germany)<br/>
<br/>
Univ of Chicago:                         Introduction to Complexity<br/>
<br/>
COMMENT: All of these terms are to narrow to have served as a general term.<br/>
<div>
<br/></div>
<br/>
<br/></div>
    </content>
    <updated>2019-12-12T20:24:00Z</updated>
    <published>2019-12-12T20:24:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-12-13T11:50:07Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/12/12/postdoc-at-university-of-illinois-at-chicago-apply-by-december-31-2019/</id>
    <link href="https://cstheory-jobs.org/2019/12/12/postdoc-at-university-of-illinois-at-chicago-apply-by-december-31-2019/" rel="alternate" type="text/html"/>
    <title>Postdoc at University of Illinois at Chicago (apply by December 31, 2019)</title>
    <summary>The MSCS department has an opening for a 3-year postdoc in the “Foundations of Data Science” under its newly received TRIPODS grant. All areas of TCS related to data science (broadly interpreted) will be considered. The position carries a teaching load of 1 graduate course per year and a competitive salary. For more information on […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The MSCS department has an opening for a 3-year postdoc in the “Foundations of Data Science” under its newly received TRIPODS grant.</p>
<p>All areas of TCS related to data science (broadly interpreted) will be considered. The position carries a teaching load of 1 graduate course per year and a competitive salary.</p>
<p>For more information on UIC’s TRIPODS center, visit: <a href="https://tripods.uic.edu/">https://tripods.uic.edu/</a></p>
<p>Website: <a href="https://www.mathjobs.org/jobs/jobs/15259">https://www.mathjobs.org/jobs/jobs/15259</a><br/>
Email: lreyzin@uic.edu</p></div>
    </content>
    <updated>2019-12-12T17:34:01Z</updated>
    <published>2019-12-12T17:34:01Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-12-13T13:20:42Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/12/12/faculty-position-in-quantum-information-at-harvard-university-apply-by-december-15-2019/</id>
    <link href="https://cstheory-jobs.org/2019/12/12/faculty-position-in-quantum-information-at-harvard-university-apply-by-december-15-2019/" rel="alternate" type="text/html"/>
    <title>Faculty position in Quantum Information at Harvard University (apply by December 15, 2019)</title>
    <summary>The Harvard Quantum Initiative, Departments of Physics, Chemistry and the SEAS areas of Computer Science and Electrical Engineering seek to appoint a tenure-track professor in the broad theoretical domain of quantum information. Areas of interest may include but are not limited to quantum algorithms, communication, complexity, control, and the physics of quantum information systems. Website: […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Harvard Quantum Initiative, Departments of Physics, Chemistry and the SEAS areas of Computer Science and Electrical Engineering seek to appoint a tenure-track professor in the broad theoretical domain of quantum information. Areas of interest may include but are not limited to quantum algorithms, communication, complexity, control, and the physics of quantum information systems.</p>
<p>Website: <a href="https://academicpositions.harvard.edu/postings/9396">https://academicpositions.harvard.edu/postings/9396</a><br/>
Email: cploucha@fas.harvard.edu</p></div>
    </content>
    <updated>2019-12-12T15:18:19Z</updated>
    <published>2019-12-12T15:18:19Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-12-13T13:20:42Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/12/12/faculty-at-iowa-state-university-apply-by-january-13-2020/</id>
    <link href="https://cstheory-jobs.org/2019/12/12/faculty-at-iowa-state-university-apply-by-january-13-2020/" rel="alternate" type="text/html"/>
    <title>Faculty at Iowa State University (apply by January 13, 2020)</title>
    <summary>The Department of Computer Science at Iowa State University seeks applicants for a faculty position at the rank of tenure-track Assistant Professor or tenured Associate Professor. We are specifically looking for experts in artificial intelligence, AI decision theory, foundations of machine learning, algorithmic foundations for data science, and algorithmic game theory. Website: https://isu.wd1.myworkdayjobs.com/en-US/IowaStateJobs/job/Ames-IA/Assistant-or-Associate-Professor-of-Computer-Science_R1252 Email: mkcrum@iastate.edu</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Department of Computer Science at Iowa State University seeks applicants for a faculty position at the rank of tenure-track Assistant Professor or tenured Associate Professor. We are specifically looking for experts in artificial intelligence, AI decision theory, foundations of machine learning, algorithmic foundations for data science, and algorithmic game theory.</p>
<p>Website: <a href="https://isu.wd1.myworkdayjobs.com/en-US/IowaStateJobs/job/Ames-IA/Assistant-or-Associate-Professor-of-Computer-Science_R1252">https://isu.wd1.myworkdayjobs.com/en-US/IowaStateJobs/job/Ames-IA/Assistant-or-Associate-Professor-of-Computer-Science_R1252</a><br/>
Email: mkcrum@iastate.edu</p></div>
    </content>
    <updated>2019-12-12T15:16:10Z</updated>
    <published>2019-12-12T15:16:10Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-12-13T13:20:42Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/12/12/postdoc-at-the-chinese-university-of-hong-kong-apply-by-january-15-2020/</id>
    <link href="https://cstheory-jobs.org/2019/12/12/postdoc-at-the-chinese-university-of-hong-kong-apply-by-january-15-2020/" rel="alternate" type="text/html"/>
    <title>Postdoc at The Chinese University of Hong Kong (apply by January 15, 2020)</title>
    <summary>The Institute of Theoretical Computer Science and Communications at CUHK is offering positions for postdoctoral fellows whose expertise is in complexity theory, algorithms, information theory, coding theory, cryptography, and other theoretical topics in related areas. The position is for 12 months, renewable for another 12 months subject to satisfactory progress. Website: http://www.itcsc.cuhk.edu.hk/Openings.html Email: itcsc@cuhk.edu.hk</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Institute of Theoretical Computer Science and Communications at CUHK is offering positions for postdoctoral fellows whose expertise is in complexity theory, algorithms, information theory, coding theory, cryptography, and other theoretical topics in related areas. The position is for 12 months, renewable for another 12 months subject to satisfactory progress.</p>
<p>Website: <a href="http://www.itcsc.cuhk.edu.hk/Openings.html">http://www.itcsc.cuhk.edu.hk/Openings.html</a><br/>
Email: itcsc@cuhk.edu.hk</p></div>
    </content>
    <updated>2019-12-12T06:49:34Z</updated>
    <published>2019-12-12T06:49:34Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-12-13T13:20:42Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1912.05506</id>
    <link href="http://arxiv.org/abs/1912.05506" rel="alternate" type="text/html"/>
    <title>Efficient Construction of Directed Hopsets and Parallel Approximate Shortest Paths</title>
    <feedworld_mtime>1576108800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cao:Nairen.html">Nairen Cao</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fineman:Jeremy_T=.html">Jeremy T. Fineman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Russell:Katina.html">Katina Russell</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1912.05506">PDF</a><br/><b>Abstract: </b>The approximate single-source shortest-path problem is as follows: given a
graph with nonnegative edge weights and a designated source vertex $s$, return
estimates of the distances from~$s$ to each other vertex such that the estimate
falls between the true distance and $(1+\epsilon)$ times the distance. This
paper provides the first nearly work-efficient parallel algorithm with
sublinear span (also called depth) for the approximate shortest-path problem on
\emph{directed} graphs. Specifically, for constant $\epsilon$ and
polynomially-bounded edge weights, our algorithm has work $\tilde{O}(m)$ and
span $n^{1/2+o(1)}$. Several algorithms were previously known for the case of
\emph{undirected} graphs, but none of the techniques seem to translate to the
directed setting.
</p>
<p>The main technical contribution is the first nearly linear-work algorithm for
constructing hopsets on directed graphs. A $(\beta,\epsilon)$-hopset is a set
of weighted edges (sometimes called shortcuts) which, when added to the graph,
admit $\beta$-hop paths with weight no more than $(1+\epsilon)$ times the true
shortest-path distances. There is a simple sequential algorithm that takes as
input a directed graph and produces a linear-cardinality hopset with
$\beta=O(\sqrt{n})$, but its running time is quite high---specifically
$\tilde{O}(m\sqrt{n})$. Our algorithm is the first more efficient algorithm
that produces a directed hopset with similar characteristics. Specifically, our
sequential algorithm runs in $\tilde{O}(m)$ time and constructs a hopset with
$\tilde{O}(n)$ edges and $\beta = n^{1/2+o(1)}$. A parallel version of the
algorithm has work $\tilde{O}(m)$ and span $n^{1/2+o(1)}$.
</p></div>
    </summary>
    <updated>2019-12-12T23:20:27Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-12-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1912.05339</id>
    <link href="http://arxiv.org/abs/1912.05339" rel="alternate" type="text/html"/>
    <title>Crossing Reduction of Sankey Diagram with Barycentre Ordering via Markov Chain</title>
    <feedworld_mtime>1576108800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Hechen Li, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Shiying.html">Shiying Li</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tan:Bowen.html">Bowen Tan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Shuaicheng.html">Shuaicheng Li</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1912.05339">PDF</a><br/><b>Abstract: </b>Sankey diagram is popular for analyzing primary flows in network data.
However, the growing complexity of data and hence crossings in the diagram
begin to reduce its readability. In this work, we studied the NP-hard weighted
crossing reduction problem of the Sankey diagram with both the common parallel
form and the circular form. We expect to obtain an ordering of entities that
reduces weighted crossings of links. We proposed a two-staged heuristic method
based on the idea of barycentre ordering and used Markov chain to formulate the
recursive process of obtaining such ordering. In the experiments, our method
achieved 300.89 weighted crossings, compared with the optimum 278.68 from an
integer linear programming method. Also, we obtained much less weighted
crossings (87.855) than the state-of-art heuristic method (146.77). We also
conducted a robust test which provided evidence that our method performed
consistently against the change of complexity in the dataset.
</p></div>
    </summary>
    <updated>2019-12-12T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-12-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1912.05153</id>
    <link href="http://arxiv.org/abs/1912.05153" rel="alternate" type="text/html"/>
    <title>Sampling for Bayesian Mixture Models: MCMC with Polynomial-Time Mixing</title>
    <feedworld_mtime>1576108800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mou:Wenlong.html">Wenlong Mou</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Ho:Nhat.html">Nhat Ho</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wainwright:Martin_J=.html">Martin J. Wainwright</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bartlett:Peter_L=.html">Peter L. Bartlett</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jordan:Michael_I=.html">Michael I. Jordan</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1912.05153">PDF</a><br/><b>Abstract: </b>We study the problem of sampling from the power posterior distribution in
Bayesian Gaussian mixture models, a robust version of the classical posterior.
This power posterior is known to be non-log-concave and multi-modal, which
leads to exponential mixing times for some standard MCMC algorithms. We
introduce and study the Reflected Metropolis-Hastings Random Walk (RMRW)
algorithm for sampling. For symmetric two-component Gaussian mixtures, we prove
that its mixing time is bounded as $d^{1.5}(d + \Vert \theta_{0}
\Vert^2)^{4.5}$ as long as the sample size $n$ is of the order $d (d + \Vert
\theta_{0} \Vert^2)$. Notably, this result requires no conditions on the
separation of the two means. En route to proving this bound, we establish some
new results of possible independent interest that allow for combining
Poincar\'{e} inequalities for conditional and marginal densities.
</p></div>
    </summary>
    <updated>2019-12-12T23:23:39Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-12-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1912.05010</id>
    <link href="http://arxiv.org/abs/1912.05010" rel="alternate" type="text/html"/>
    <title>Graph Pricing with Limited Supply</title>
    <feedworld_mtime>1576108800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Friggstad:Zachary.html">Zachary Friggstad</a>, Maryam Mahboub <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1912.05010">PDF</a><br/><b>Abstract: </b>We study approximation algorithms for graph pricing with vertex capacities
yet without the traditional envy-free constraint. Specifically, we have a set
of items $V$ and a set of customers $X$ where each customer $i \in X$ has a
budget $b_i$ and is interested in a bundle of items $S_i \subseteq V$ with
$|S_i| \leq 2$. However, there is a limited supply of each item: we only have
$\mu_v$ copies of item $v$ to sell for each $v \in V$. We should assign prices
$p(v)$ to each $v \in V$ and chose a subset $Y \subseteq X$ of customers so
that each $i \in Y$ can afford their bundle ($p(S_i) \leq b_i$) and at most
$\mu_v$ chosen customers have item $v$ in their bundle for each item $v \in V$.
Each customer $i \in Y$ pays $p(S_i)$ for the bundle they purchased: our goal
is to do this in a way that maximizes revenue. Such pricing problems have been
studied from the perspective of envy-freeness where we also must ensure that
$p(S_i) \geq b_i$ for each $i \notin Y$. However, the version where we simply
allocate items to customers after setting prices and do not worry about the
envy-free condition has received less attention.
</p>
<p>Our main result is an 8-approximation for the capacitated case via local
search and a 7.8096-approximation in simple graphs with uniform vertex
capacities. The latter is obtained by combing a more involved analysis of a
multi-swap local search algorithm for constant capacities and an LP-rounding
algorithm for larger capacities. If all capacities are bounded by a constant
$C$, we further show a multi-swap local search algorithm yields an $\left(4
\cdot \frac{2C-1}{C} + \epsilon\right)$-approximation. We also give a
$(4+\epsilon)$-approximation in simple graphs through LP rounding when all
capacities are very large as a function of $\epsilon$.
</p></div>
    </summary>
    <updated>2019-12-12T23:22:02Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-12-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1912.04897</id>
    <link href="http://arxiv.org/abs/1912.04897" rel="alternate" type="text/html"/>
    <title>An algorithm for bounding extremal functions of forbidden sequences</title>
    <feedworld_mtime>1576108800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Geneson:Jesse.html">Jesse Geneson</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1912.04897">PDF</a><br/><b>Abstract: </b>Generalized Davenport-Schinzel sequences are sequences that avoid a forbidden
subsequence and have a sparsity requirement on their letters. Upper bounds on
the lengths of generalized Davenport-Schinzel sequences have been applied to a
number of problems in discrete geometry and extremal combinatorics. Sharp
bounds on the maximum lengths of generalized Davenport-Schinzel sequences are
known for some families of forbidden subsequences, but in general there are
only rough bounds on the maximum lengths of most generalized Davenport-Schinzel
sequences. One method that was developed for finding upper bounds on the
lengths of generalized Davenport-Schinzel sequences uses a family of sequences
called formations.
</p>
<p>An $(r, s)$-formation is a concatenation of $s$ permutations of $r$ distinct
letters. The formation width function $fw(u)$ is defined as the minimum $s$ for
which there exists $r$ such that every $(r, s)$-formation contains $u$. The
function $fw(u)$ has been used with upper bounds on extremal functions of $(r,
s)$-formations to find tight bounds on the maximum possible lengths of many
families of generalized Davenport-Schinzel sequences. Algorithms have been
found for computing $fw(u)$ for sequences $u$ of length $n$, but they have
worst-case run time exponential in $n$, even for sequences $u$ with only three
distinct letters.
</p>
<p>We present an algorithm for computing $fw(u)$ with run time
$O(n^{\alpha_r})$, where $r$ is the number of distinct letters in $u$ and
$\alpha_r$ is a constant that only depends on $r$. We implement the new
algorithm in Python and compare its run time to the next fastest algorithm for
computing formation width. We also apply the new algorithm to find sharp upper
bounds on the lengths of several families of generalized Davenport-Schinzel
sequences with $3$-letter forbidden patterns.
</p></div>
    </summary>
    <updated>2019-12-12T23:21:56Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-12-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1903.09625</id>
    <link href="http://arxiv.org/abs/1903.09625" rel="alternate" type="text/html"/>
    <title>Matching strings in encoded sequences</title>
    <feedworld_mtime>1576108800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Adriana Coutinho, Rodrigo Lambert, Jérôme Rousseau <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1903.09625">PDF</a><br/><b>Abstract: </b>We investigate the longest common substring problem for encoded sequences and
its asymptotic behaviour. The main result is a strong law of large numbers for
a re-scaled version of this quantity, which presents an explicit relation with
the R\'enyi entropy of the source. We apply this result to the zero-inflated
contamination model and the stochastic scrabble. In the case of dynamical
systems, this problem is equivalent to the shortest distance between two
observed orbits and its limiting relationship with the correlation dimension of
the pushforward measure. An extension to the shortest distance between orbits
for random dynamical systems is also provided.
</p></div>
    </summary>
    <updated>2019-12-12T23:21:50Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-12-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/12/09/tenure-track-faculty-at-university-of-illinois-at-chicago-apply-by-january-13-2020/</id>
    <link href="https://cstheory-jobs.org/2019/12/09/tenure-track-faculty-at-university-of-illinois-at-chicago-apply-by-january-13-2020/" rel="alternate" type="text/html"/>
    <title>Tenure-Track Faculty at University of Illinois at Chicago (apply by January 13, 2020)</title>
    <summary>The Mathematics (MSCS) department at UIC is looking for a tenure-track assistant professor to join the “Mathematical Computer Science” group. All areas of theoretical computer science will be considered. You can learn more about our TCS group on https://theory.cs.uic.edu/. Website: http://mathjobs.org/jobs/jobs/15229 Email: lreyzin@uic.edu</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Mathematics (MSCS) department at UIC is looking for a tenure-track assistant professor to join the “Mathematical Computer Science” group. All areas of theoretical computer science will be considered.</p>
<p>You can learn more about our TCS group on <a href="https://theory.cs.uic.edu/.">https://theory.cs.uic.edu/.</a></p>
<p>Website: <a href="http://mathjobs.org/jobs/jobs/15229">http://mathjobs.org/jobs/jobs/15229</a><br/>
Email: lreyzin@uic.edu</p></div>
    </content>
    <updated>2019-12-09T21:51:01Z</updated>
    <published>2019-12-09T21:51:01Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-12-13T13:20:42Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://theorydish.blog/?p=1541</id>
    <link href="https://theorydish.blog/2019/12/09/quantum-dna-sequencing-the-ultimate-hardness-hypothesis/" rel="alternate" type="text/html"/>
    <title>Quantum DNA sequencing &amp; the ultimate hardness hypothesis</title>
    <summary>Longest common subsequence (LCS) and edit distance (ED) are fundamental similarity measures of interest to genomic applications (insertions/deletions/substitutions are a pretty good proxy for both mutations and read errors). The fastest known algorithms for computing the LCS/ED between two -character strings run in nearly quadratic time. Breakthroughs in fine-grained complexity [BI18][AHWW16] from the last few years provide some nice formal barriers further progress: in particular, substantially faster algorithms would refute NC-SETH, the hypothesis that given an NC circuit with input bits,  deciding if the circuit has any satisfying assignment requires time. (Note that this is a weaker, aka safer, hypothesis than the standard SETH.)   Quantum algorithms for edit distance? One way to try to circumvent the computational barriers is by approximation algorithms (see my blog post). A different approach is to go with quantum algorithms: Grover’s search can solve NC-SAT in time. Even those of us less skeptic than Gil Kalai can probably agree that quadratic quantum speedups won’t be practical anytime soon. But in theory, I find the question of whether we can design subquadratic quantum algorithms for edit distance very interesting (see also [BEG+18]). Alas, even with the power of quantum computers we don’t know any truly [...]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Longest common subsequence (LCS) and edit distance (ED) are fundamental similarity measures of interest to genomic applications (insertions/deletions/substitutions are a pretty good proxy for both mutations and read errors). The fastest known algorithms for computing the LCS/ED between two <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="n"/>-character strings run in nearly quadratic time. Breakthroughs in fine-grained complexity <a href="https://arxiv.org/abs/1412.0348">[BI18]</a><a href="https://arxiv.org/abs/1511.06022">[AHWW16]</a> from the last few years provide some nice formal barriers further progress: in particular, substantially faster algorithms would refute <em>NC-SETH</em>, the hypothesis that given an NC circuit with <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="n"/> input bits,  deciding if the circuit has any satisfying assignment requires <img alt="2^{(1-o(1))n}" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7B%281-o%281%29%29n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="2^{(1-o(1))n}"/> time. (Note that this is a weaker, aka safer, hypothesis than the standard SETH.)</p>
<p> </p>
<h2>Quantum algorithms for edit distance?</h2>
<p>One way to try to circumvent the computational barriers is by approximation algorithms (see my <a href="https://theorydish.blog/2018/07/20/approximating-edit-distance/">blog post</a>). A different approach is to go with quantum algorithms: Grover’s search can solve NC-SAT in <img alt="2^{n/2}" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7Bn%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="2^{n/2}"/> time. Even those of us less skeptic than <a href="https://gilkalai.wordpress.com/2019/11/13/gils-collegial-quantum-supremacy-skepticism-faq/">Gil Kalai</a> can probably agree that quadratic quantum speedups won’t be practical anytime soon. But in theory, I find the question of whether we can design subquadratic quantum algorithms for edit distance very interesting (see also <a href="https://arxiv.org/abs/1804.04178">[BEG+18]</a>).</p>
<p>Alas, even with the power of quantum computers we don’t know any truly subquadratic algorithms for computing LCS/ED. On the other hand, it is not clear how to rule out even linear-time algorithms. A few weeks ago, Buhrman, Patro, and Speelman, posted a <a href="https://arxiv.org/abs/1911.05686">paper</a> that gives a <img alt="n^{3/2}" class="latex" src="https://s0.wp.com/latex.php?latex=n%5E%7B3%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="n^{3/2}"/> quantum <em>query complexity </em>lower bound for LCS/ED.</p>
<blockquote><p>Open Problem: Close the <img alt="n^{3/2}" class="latex" src="https://s0.wp.com/latex.php?latex=n%5E%7B3%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="n^{3/2}"/> vs <img alt="n^2" class="latex" src="https://s0.wp.com/latex.php?latex=n%5E2&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="n^2"/> gap for quantum query complexity of ED/LCS.</p></blockquote>
<p>What is “query complexity” of ED/LCS? Buhrman et al. consider the following query model: In LCS, we want a <strong>maximum monotone matching</strong> between the characters of the two strings, where we can match two characters if they’re identical. Now suppose that in the query complexity problem we still want to find a maximum monotone matching, but instead of the character-equality graph (which is a union of disjoint cliques), we have an arbitrary bipartite graph, and <strong>given a pair of vertices, the oracle tells you if there is an edge between them</strong>.</p>
<p>This model may seem a bit counter-intuitive at first since the graphs may not correspond to any pair of strings; and indeed other models have been considered before <a href="https://dl.acm.org/citation.cfm?id=321922">[UAH76]</a><a href="https://arxiv.org/abs/1005.4033">[AKO10]</a>. But it turns out that this model is well-motivated by the NC-SETH lower bound (see discussion below).</p>
<p> </p>
<h2>The ultimate hardness hypothesis</h2>
<p>What does the <img alt="n^{3/2}" class="latex" src="https://s0.wp.com/latex.php?latex=n%5E%7B3%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="n^{3/2}"/> query complexity lower bound mean for algorithms on actual strings? Instead of a black box oracle, our algorithms have access to an NC-circuit that implements it. Intuitively, we don’t know how to do very much with white box circuits, so it seems plausible to hypothesize that the running time will be lower bound by the query complexity. In some sense, this is a special case of the following <em>ultimate hardness hypothesis </em>that unifies a lot of the computational hardness assumptions that we like to assume but have no idea how to prove (e.g. P!=NP, P!=BQP, NC-SETH, FP!=PPAD, etc):</p>
<blockquote><p>[Ultimate Hardness Hypothesis] For every problem, the white-box computational complexity is lower bounded by the black-box query complexity.”</p></blockquote>
<p>In communication complexity similar statements are known and are called simulation/lifting theorems (see e.g. <a href="https://theory.stanford.edu/~mika/thesis.pdf">Mika’s thesis</a>). For computational complexity, there are obvious counter examples such as “decide if the oracle can be implemented by a small circuit”. So it only makes sense to continue to assume the ultimate hardness hypothesis for “reasonable problems” instead of “every problem”.</p>
<p>But Burhman et al. identify the following variant of the ultimate hardness hypothesis which I find very interesting. It is defined with respect to a function <img alt="T:\{0,1\}^{2^n} \rightarrow \{0,1\}" class="latex" src="https://s0.wp.com/latex.php?latex=T%3A%5C%7B0%2C1%5C%7D%5E%7B2%5En%7D+%5Crightarrow+%5C%7B0%2C1%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="T:\{0,1\}^{2^n} \rightarrow \{0,1\}"/> which takes as input the truth-table of a circuit and outputs True or False. Roughly, they hypothesize that:</p>
<blockquote><p>[Burhman et al.-QSETH, paraphrased] For <em>every</em> <img alt="T" class="latex" src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="T"/>, deciding if <img alt="T" class="latex" src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="T"/> is true or false is as hard whether we’re given the actual circuit, or only the guarantee that the oracle is implemented by a small circuit”</p></blockquote>
<p>At a first read, I thought that arguments a-la impossibility of obfuscation <a href="https://www.iacr.org/archive/crypto2001/21390001.pdf">[BGI+01]</a> should refute this hypothesis, but a few weeks later I still don’t know how to prove it. Do you?</p>
<p> </p>
<h2>A tip for the upcoming holidays</h2>
<p>During my postdoc, I worked on the quantum query complexity of ED/LCS with Shalev Ben-David, Rolando La Placa, and John Wright. I was a bit bummed to find out that we got scooped by Buhrman et al, but I know of at least 3 other groups that were also scooped by the same paper, so at least we’re in good company <img alt="&#x1F642;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f642.png" style="height: 1em;"/></p>
<p>At the time, a fellow postdoc from Psychology asked me what I was working on. I resisted the temptation to try to explain the various quantum variants of NC-SETH, and instead told him I was working on “DNA sequencing with quantum computers”. His reaction was priceless. Regardless of what you’re actually working on, try this line during the holidays when your relatives ask you about your work.</p>
<p> </p></div>
    </content>
    <updated>2019-12-09T18:20:46Z</updated>
    <published>2019-12-09T18:20:46Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>aviad.rubinstein</name>
    </author>
    <source>
      <id>https://theorydish.blog</id>
      <logo>https://theorydish.files.wordpress.com/2017/03/cropped-nightdish1.jpg?w=32</logo>
      <link href="https://theorydish.blog/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://theorydish.blog" rel="alternate" type="text/html"/>
      <link href="https://theorydish.blog/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://theorydish.blog/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Stanford's CS Theory Research Blog</subtitle>
      <title>Theory Dish</title>
      <updated>2019-12-13T13:21:19Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-693865784966232415</id>
    <link href="https://blog.computationalcomplexity.org/feeds/693865784966232415/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/12/what-do-you-call-your-ugrad-non.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/693865784966232415" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/693865784966232415" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/12/what-do-you-call-your-ugrad-non.html" rel="alternate" type="text/html"/>
    <title>What do you call your ugrad non-algorithms theory course?</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">I am in the process of reviewing<br/>
<br/>
<i>                     What can be computed: A Practical Guide to the Theory of Computation</i><br/>
<i>                     by John MacCormick</i><br/>
<br/>
<br/>
and I need YOUR help for the first SENTENCE.  I began by saying<br/>
<br/>
<br/>
                    This is a text book for a course on <i>Formal Language Theory</i><br/>
<i><br/></i>
but then I realized that this is not what we call the course at UMCP. Then I got to thinking: what do other schools call it? I have the following so far:<br/>
<br/>
UMCP: Elementary Theory of Computation<br/>
<br/>
Harvard: Introduction to Theory of Computation<br/>
<br/>
MIT: Automata, Computability, and, Complexity<br/>
<br/>
Clark: Automata Theory<br/>
<br/>
(My spellcheck does not think Automata is a word. Also Computability. Usually I listen to my spellcheckers, but I checked and YES, I spelled them right.)<br/>
<br/>
For some other schools I either hit a place I needed an account, or I just got titles without a description so I could not be sure.<br/>
<br/>This is where YOU come in!<br/>
<br/>
Please leave comments with your school and the title of the course at your school that covers a reasonable overlap with: Regular Sets, Context Free Sets, Decidable and Undecidble and r.e. sets, P, NP, perhaps other complexity classes, and NP-completeness. Its FINE if your answer is one of the above ones, or one of the other comments--- I plan to later set this up as a pigeonhole principle problem.<br/>
<br/>
I suspect that courses in algorithms are called <i>Algorithms </i>or <i>Introduction to Algorithms.</i><br/>
<i><br/></i>
I suspect that courses in cryptography are called <i>Cryptography </i><i> </i>or <i>Intro to Cryptography.</i><br/>
<br/>
<br/>
Why does the non-algorithm, non-crypto theory course have more names?<br/>
<br/>
<br/>
<br/>
<br/>
<i><br/></i>
<br/></div>
    </content>
    <updated>2019-12-09T04:00:00Z</updated>
    <published>2019-12-09T04:00:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-12-13T11:50:07Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16454</id>
    <link href="https://rjlipton.wordpress.com/2019/12/08/hctor-garcia-molina-1953-2019/" rel="alternate" type="text/html"/>
    <title>Héctor Garcia-Molina, 1953–2019</title>
    <summary>We all lost a great person Cropped from Mexican NotiCyTI obit Héctor Garcia-Molina died just before Thanksgiving. He was a computer scientist and Professor in both the Departments of Computer Science and Electrical Engineering at Stanford University. Today Ken and I write in sadness about his passing and to express some personal appreciations. We at […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><font color="#0044cc"><br/>
<em>We all lost a great person</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2019/12/29-11-19-molina.jpg"><img alt="" class="alignright wp-image-16456" height="180" src="https://rjlipton.files.wordpress.com/2019/12/29-11-19-molina.jpg?w=165&amp;h=180" width="165"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Cropped from Mexican NotiCyTI <a href="https://noticyti.com/politica-cyt-i/742-muere-h%C3%A9ctor-garc%C3%ADa-molina,-el-mexicano-que-contribuy%C3%B3-al-estrellato-de-google-y-cisco.html">obit</a></font></td>
</tr>
</tbody>
</table>
<p>
Héctor Garcia-Molina <a href="https://news.stanford.edu/2019/12/06/hector-garcia-molina-influential-computer-scientist-database-expert-dies-65/">died</a> just before Thanksgiving. He was a computer scientist and Professor in both the Departments of Computer Science and Electrical Engineering at Stanford University.</p>
<p>
Today Ken and I write in sadness about his passing and to express some personal appreciations. </p>
<p>
We at GLL have talked about him before. See <a href="https://rjlipton.wordpress.com/2015/03/08/lint-for-math/">this</a> for his story about the fun of using an IBM mainframe for teaching. Or see <a href="https://rjlipton.wordpress.com/2011/11/03/whos-afraid-of-arrows-paradox/">this</a> for a story about Héctor and meetings.</p>
<p>
I, Dick, had the pleasure to have worked with him, while we were both faculty at Princeton in the 1980’s and beyond.</p>
<p>
</p><p/><h2> His Clock </h2><p/>
<p/><p>
Héctor was the chair of the Stanford Computer Science Department from January 2001 to December 2004. Stanford then rotated the chair so all took their turn. I know that he “hated” being an administrator in general. But of course being a team player he took his turn. </p>
<p>
One way to see his real feelings about being a chair was to look at the clock his students constructed for him. The clock was a digital timer that counted down the seconds that remained in his term as the chair. It started at roughly 126227808. I am sure he did fine, but the clock was a statement. </p>
<p>
</p><p/><h2> His Worst Paper </h2><p/>
<p/><p>
While Héctor was at Princeton we worked together on a project—the <a href="https://rjlipton.wordpress.com/2010/05/20/sorting-out-chess-endgames/">MMM</a> project. It led to one of his least cited papers—a 1984 <a href="https://ieeexplore.ieee.org/document/1676454">paper</a> with me and Jacobo Valdes. OK, it has 48 citations according to IEEE. The idea of the project was to use memory rather than processors to speed up computations. He was a joy to work with: he was careful, and thoughtful, and just fun to work with on any project. </p>
<p>
We did write a second <a href="https://books.google.com/books?id=AMrcBwAAQBAJ&amp;pg=PA565&amp;lpg=PA565&amp;dq=The+Massive+Memory+Machine+Project&amp;source=bl&amp;ots=_QFT07G56P&amp;sig=ACfU3U0-KV060yO3PHRllCnj3Y5o10BX-w&amp;hl=en&amp;sa=X&amp;ved=2ahUKEwj7o67o-abmAhXHwFkKHRfzDs4Q6AEwDXoECAkQAQ#v=onepage&amp;q=The Massive Memory Machine Project&amp;f=false">paper</a> with Richard Cullingford instead of Valdes, which Héctor presented at a meeting on knowledge-based management systems. The above Google Books link goes to the end with a <a href="https://books.google.com/books?id=AMrcBwAAQBAJ&amp;pg=PA565&amp;lpg=PA565&amp;dq=The+Massive+Memory+Machine+Project&amp;source=bl&amp;ots=_QFT07G56P&amp;sig=ACfU3U0-KV060yO3PHRllCnj3Y5o10BX-w&amp;hl=en&amp;sa=X&amp;ved=2ahUKEwj7o67o-abmAhXHwFkKHRfzDs4Q6AEwDXoECAkQAQ#v=onepage&amp;q=The Massive Memory Machine Project&amp;f=false">discussion</a> in which a simple issue was raised—we paraphrase:</p>
<blockquote><p><b> </b> <em> Won’t it take forever just to write all zeros to the memory? </em>
</p></blockquote>
<p/><p>
Héctor had a scientist’s answer: the project was still not at the prototype stage so he didn’t know. He said the project should be viewed as a scientific experiment to find out. Maybe he also had an inkling that what was coming was a decade of breakthroughs in CPU design and parallel/pipeline processing after all. </p>
<p>
</p><p/><h2> His Predictions </h2><p/>
<p/><p>
Héctor was unparalleled at seeing the future. I always thought that one of his abilities, one that set him apart, was his ability to predict directions of research. This allowed him, and his students, to write early papers in research areas before they became hot. This is one of the talents that made him so amazing.</p>
<p>
I recall way before the world wide web was created he had students working on adding links to documents. I recall a talk by one of his students at Princeton that discussed what we now call URLs. One question that was raised during the talk was: How were the links going to be created? There was a lively discussion about this. Could they be created automatically? If not why would people take the time to create the links? Indeed.</p>
<p>
Héctor saw that links would be created. That people would take the effort to create them. I must admit that he was right, and he saw the future better than most. I wish I had a fraction of his ability to see directions like he did.</p>
<p>
</p><p/><h2> Guiding Students </h2><p/>
<p/><p>
Héctor told me that when he first got to Stanford the fund managers and investors roamed the halls. They would ask anyone they could if they had an idea for a company or a startup. It was a constant issue that Héctor had to deal with. They were continually trying to steal away students. </p>
<p>
He told me he felt like he was the head of an abbey and was always having to protect his charges within the walls.</p>
<p>
When the impetus came from within it was different. Of course, Héctor was the advisor of Sergey Brin at the time he and Larry Page conceived Google. Brin and Page found that their search engine prototypes were so good the dataflow was constantly straining Stanford’s machines. They needed to scrounge for more disks and processors to mount their servers. Héctor already oversaw the Stanford Digital Libraries Project and he <a href="https://www.cnbc.com/2018/09/04/8-surprising-facts-you-might-not-know-about-googles-early-days.html">arranged</a> for funds to purchase spare parts for the data servers. </p>
<p>
It is interesting that in this 2001 <a href="https://sigmod.org/publications/interviews/pdf/hector-final1.pdf">interview</a> in the <em>SIGMOD Record</em>, Héctor did not have a high opinion of the industrial side of his area:</p>
<blockquote><p><b> </b> <em> Again, I don’t think industry really does very much research. They come up with an idea and they try to sell it. If it was a good idea, maybe they will make money. Even if it was a bad idea, if they have good marketing people, they might still make money and we never know … I don’t think they have an advantage over [academics] in testing the ideas and evaluating them and performing measurements and really understanding what are the right techniques. </em>
</p></blockquote>
<p/><p>
In the same interview, he had sage advice for students after completing their PhDs and during the tenure process, mainly on the side of not trying to play the system but focus on doing what you love.</p>
<p>
</p><p/><h2> Stanford Home Team </h2><p/>
<p/><p>
Héctor had been a graduate student at Stanford. So his return there as a professor was a kind of homecoming. He was a home-team player in many senses. One of them is shown by this photo:</p>
<p/><p/>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2019/12/hector-garcia-molina-sports.jpg"><img alt="" class="aligncenter size-medium wp-image-16457" height="200" src="https://rjlipton.files.wordpress.com/2019/12/hector-garcia-molina-sports.jpg?w=300&amp;h=200" width="300"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Stanford University obituary <a href="https://news.stanford.edu/2019/12/06/hector-garcia-molina-influential-computer-scientist-database-expert-dies-65/">source</a></font>
</td>
</tr>
</tbody></table>
<p>
He was a registered Stanford sports photographer. He also taught a course at Stanford on photography. We don’t know if he had special insights on detecting “deepfake” photos and videos. </p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Our condolences go to all his family. Héctor you will be missed. You are missed. </p>
<p/></font></font></div>
    </content>
    <updated>2019-12-08T23:27:02Z</updated>
    <published>2019-12-08T23:27:02Z</published>
    <category term="All Posts"/>
    <category term="News"/>
    <category term="People"/>
    <category term="databases"/>
    <category term="Hector Garcia-Molina"/>
    <category term="memorial"/>
    <category term="memory machines"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-12-13T13:20:40Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/12/08/assistant-professor-position-tenure-track-at-hse-university-moscow-apply-by-january-12-2020/</id>
    <link href="https://cstheory-jobs.org/2019/12/08/assistant-professor-position-tenure-track-at-hse-university-moscow-apply-by-january-12-2020/" rel="alternate" type="text/html"/>
    <title>Assistant Professor Position (Tenure Track) at HSE University, Moscow (apply by January 12, 2020)</title>
    <summary>HSE University, Faculty of Computer Science invites applications for full-time, tenure-track positions of Assistant Professor in all areas of computer science including but not limited to programming language theory, software engineering, system programming, algorithms, computation complexity, bioinformatics, artificial intelligence, and machine learning, etc. Website: https://iri.hse.ru/computer_science2020 Email: s.karapetyan@hse.ru</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>HSE University, Faculty of Computer Science invites applications for full-time, tenure-track positions of Assistant Professor in all areas of computer science including but not limited to programming language theory, software engineering, system programming, algorithms, computation complexity, bioinformatics, artificial intelligence, and machine learning, etc.</p>
<p>Website: <a href="https://iri.hse.ru/computer_science2020">https://iri.hse.ru/computer_science2020</a><br/>
Email: s.karapetyan@hse.ru</p></div>
    </content>
    <updated>2019-12-08T19:52:48Z</updated>
    <published>2019-12-08T19:52:48Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-12-13T13:20:42Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/180</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/180" rel="alternate" type="text/html"/>
    <title>TR19-180 |  Covering Codes for Insertions and Deletions | 

	Andreas Lenz, 

	Cyrus Rashtchian, 

	Paul Siegel, 

	Eitan Yaakobi</title>
    <summary>A covering code is a set of codewords with the property that the union of balls, suitably defined, around these codewords covers an entire space. Generally, the goal is to find the covering code with the minimum size codebook. While most prior work on covering codes has focused on the Hamming metric, we consider the problem of designing covering codes defined in terms of  insertions and  deletions. First, we provide new sphere-covering lower bounds on the minimum possible size of such codes. Then, we provide new existential upper bounds on the size of optimal covering codes for a single insertion or a single deletion that are tight up to a constant factor. Finally, we derive improved upper bounds for covering codes using $R\geq 2$ insertions or deletions. We prove that codes exist with density that is only a factor $O(R \log R)$ larger than the lower bounds for all fixed $R$. In particular, our upper bounds have an optimal dependence on the word length, and we achieve asymptotic density matching the best known bounds for Hamming distance covering codes.</summary>
    <updated>2019-12-08T09:03:55Z</updated>
    <published>2019-12-08T09:03:55Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-12-13T13:20:29Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/12/07/postdoctoral-fellowship-at-bocconi-university-apply-by-december-15-2019/</id>
    <link href="https://cstheory-jobs.org/2019/12/07/postdoctoral-fellowship-at-bocconi-university-apply-by-december-15-2019/" rel="alternate" type="text/html"/>
    <title>Postdoctoral Fellowship at Bocconi University (apply by December 15, 2019)</title>
    <summary>Two postdoctoral positions, each for one year renewable to a second, are available to work in Luca Trevisan’s group at Bocconi University on topics related to average-case analysis of algorithms, approximation algorithms, and combinatorial constructions. The positions have a very competitive salary and relocation benefits. Funding for travel is available. Website: https://www.unibocconi.eu/wps/wcm/connect/3ecc85da-ac66-46ac-9db7-09ac0ef9b715/Call-2ADR-01B1-Bidsa-Erc.pdf?MOD=AJPERES&amp;CVID=mUjaHAv Email: L.Trevisan@unibocconi.it</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Two postdoctoral positions, each for one year renewable to a second, are available to work in Luca Trevisan’s group at Bocconi University on topics related to average-case analysis of algorithms, approximation algorithms, and combinatorial constructions.</p>
<p>The positions have a very competitive salary and relocation benefits. Funding for travel is available.</p>
<p>Website: <a href="https://www.unibocconi.eu/wps/wcm/connect/3ecc85da-ac66-46ac-9db7-09ac0ef9b715/Call-2ADR-01B1-Bidsa-Erc.pdf?MOD=AJPERES&amp;CVID=mUjaHAv">https://www.unibocconi.eu/wps/wcm/connect/3ecc85da-ac66-46ac-9db7-09ac0ef9b715/Call-2ADR-01B1-Bidsa-Erc.pdf?MOD=AJPERES&amp;CVID=mUjaHAv</a><br/>
Email: L.Trevisan@unibocconi.it</p></div>
    </content>
    <updated>2019-12-07T23:11:27Z</updated>
    <published>2019-12-07T23:11:27Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-12-13T13:20:42Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://lucatrevisan.wordpress.com/?p=4279</id>
    <link href="https://lucatrevisan.wordpress.com/2019/12/07/postdoc-position-at-bocconi/" rel="alternate" type="text/html"/>
    <title>Postdoc Position at Bocconi</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">I am recruiting for two postdoctoral positions, each for one year renewable to a second, to work with me at Bocconi University on topics related to average-case analysis of algorithms, approximation algorithms, and combinatorial constructions. The positions have a very … <a href="https://lucatrevisan.wordpress.com/2019/12/07/postdoc-position-at-bocconi/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I am recruiting for two postdoctoral positions, each for one year renewable to a second, to work with me at Bocconi University on topics related to average-case analysis of algorithms, approximation algorithms, and combinatorial constructions. </p>
<p>The positions have a very competitive salary and relocation benefits. Funding for travel is available.</p>
<p>Application information is at <a href="https://www.unibocconi.eu/wps/wcm/connect/3ecc85da-ac66-46ac-9db7-09ac0ef9b715/Call-2ADR-01B1-Bidsa-Erc.pdf?MOD=AJPERES&amp;CVID=mUjaHAv">this link</a>. The deadline  is <b>December 15</b>. If you apply, please also send me an email (L.Trevisan at unibocconi.it) to let me know.</p></div>
    </content>
    <updated>2019-12-07T23:07:19Z</updated>
    <published>2019-12-07T23:07:19Z</published>
    <category term="theory"/>
    <category term="jobs"/>
    <author>
      <name>luca</name>
    </author>
    <source>
      <id>https://lucatrevisan.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://lucatrevisan.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://lucatrevisan.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://lucatrevisan.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://lucatrevisan.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>"Marge, I agree with you - in theory. In theory, communism works. In theory." -- Homer Simpson</subtitle>
      <title>in   theory</title>
      <updated>2019-12-13T13:20:15Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/179</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/179" rel="alternate" type="text/html"/>
    <title>TR19-179 |  Towards Optimal Separations between Quantum and Randomized Query Complexities | 

	Avishay Tal</title>
    <summary>The query model offers a concrete setting where quantum algorithms are provably superior to randomized algorithms. Beautiful results by Bernstein-Vazirani, Simon,  Aaronson, and others presented partial Boolean functions that can be computed by quantum algorithms making much fewer queries compared to their randomized analogs. To date, separations of $O(1)$ vs. $\sqrt{N}$ between quantum and randomized query complexities remain the state-of-the-art (where $N$ is the input length), leaving open the question of whether $O(1)$ vs. $N^{1/2+\Omega(1)}$ separations are possible?

We answer this question in the affirmative. Our separating problem is a variant of the Aaronson-Ambainis $k$-fold Forrelation problem. We show that our variant:
(1) Can be solved by a quantum algorithm making $2^{O(k)}$ queries to the inputs.
(2) Requires at least $\tilde{\Omega}(N^{2(k-1)/(3k-1)})$ queries for any randomized algorithm.

For any constant $\varepsilon&gt;0$, this gives a  $O(1)$  vs. $N^{2/3-\varepsilon}$ separation between the quantum and randomized query complexities of partial Boolean functions. 

Our proof is Fourier analytical and uses new bounds on the Fourier spectrum of classical decision trees, which could be of independent interest. 

Looking forward, we conjecture that the Fourier bounds could be further improved in a precise manner, and show that such conjectured bounds imply optimal $O(1)$ vs. $N^{1-\varepsilon}$ separations between the quantum and randomized query complexities of partial Boolean functions.</summary>
    <updated>2019-12-07T14:25:04Z</updated>
    <published>2019-12-07T14:25:04Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-12-13T13:20:29Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/12/07/tenure-track-faculty-at-university-of-michigan-apply-by-january-1-2020/</id>
    <link href="https://cstheory-jobs.org/2019/12/07/tenure-track-faculty-at-university-of-michigan-apply-by-january-1-2020/" rel="alternate" type="text/html"/>
    <title>Tenure-track faculty at University of Michigan (apply by January 1, 2020)</title>
    <summary>Computer Science and Engineering at the University of Michigan currently invites applications for multiple tenure-track and teaching faculty (lecturer) positions. We seek exceptional candidates at all levels in all areas across computer science and computer engineering. We also have a targeted search for an endowed professorship in theoretical computer science (the Fischer Chair). Website: https://cse.engin.umich.edu/about/faculty-hiring/ […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Computer Science and Engineering at the University of Michigan currently invites applications for multiple tenure-track and teaching faculty (lecturer) positions. We seek exceptional candidates at all levels in all areas across computer science and computer engineering. We also have a targeted search for an endowed professorship in theoretical computer science (the Fischer Chair).</p>
<p>Website: <a href="https://cse.engin.umich.edu/about/faculty-hiring/">https://cse.engin.umich.edu/about/faculty-hiring/</a><br/>
Email: kuipers@umich.edu</p></div>
    </content>
    <updated>2019-12-07T03:53:14Z</updated>
    <published>2019-12-07T03:53:14Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-12-13T13:20:42Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/178</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/178" rel="alternate" type="text/html"/>
    <title>TR19-178 |  Almost Tight Lower Bounds on Regular Resolution Refutations of Tseitin Formulas for All Constant-Degree Graphs | 

	Dmitry Itsykson, 

	Artur Riazanov, 

	Petr Smirnov, 

	Danil Sagunov</title>
    <summary>We show that the size of any regular resolution refutation of Tseitin formula $T(G,c)$ based on a graph $G$ is at least $2^{\Omega(tw(G)/\log n)}$, where $n$ is the number of vertices in $G$ and $tw(G)$ is the treewidth of $G$. For constant degree graphs there is known upper bound $2^{O(tw(G))}$ [AR11, GTT18], so our lower bound is tight up to a logarithmic factor in the exponent.

In order to prove this result we show that any regular resolution proof of Tseitin formula $T(G,c)$ of size $S$ can be converted to a read-once branching program computing satisfiable Tseitin formula $T(G,c')$ of size $S^{O(\log n)}$. Then we show that any read-once branching program computing satisfiable Tseitin formula $T(G,c')$ has size at least $2^{\Omega(tw(G))}$; the latter improves the recent result of Glinskih and Itsykson [GI19].</summary>
    <updated>2019-12-07T01:51:51Z</updated>
    <published>2019-12-07T01:51:51Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-12-13T13:20:29Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/12/06/faculty-at-george-washington-university-apply-by-january-9-2020/</id>
    <link href="https://cstheory-jobs.org/2019/12/06/faculty-at-george-washington-university-apply-by-january-9-2020/" rel="alternate" type="text/html"/>
    <title>Faculty at George Washington University (apply by January 9, 2020)</title>
    <summary>The Department of Computer Science at The George Washington University invites applications for two tenure track positions at the Assistant, Associate or Full Professor level, beginning as early as Fall 2020. One position focuses on Machine Learning and related areas; the other position welcomes all areas of theoretical and applied computer science. Website: https://www.gwu.jobs/postings/72053 Email: […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Department of Computer Science at The George Washington University invites applications for two tenure track positions at the Assistant, Associate or Full Professor level, beginning as early as Fall 2020. One position focuses on Machine Learning and related areas; the other position welcomes all areas of theoretical and applied computer science.</p>
<p>Website: <a href="https://www.gwu.jobs/postings/72053">https://www.gwu.jobs/postings/72053</a><br/>
Email: cssearch@gwu.edu</p></div>
    </content>
    <updated>2019-12-06T21:33:40Z</updated>
    <published>2019-12-06T21:33:40Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-12-13T13:20:42Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://decentralizedthoughts.github.io/2019-12-06-dce-the-three-scalability-bottlenecks-of-state-machine-replication/</id>
    <link href="https://decentralizedthoughts.github.io/2019-12-06-dce-the-three-scalability-bottlenecks-of-state-machine-replication/" rel="alternate" type="text/html"/>
    <title>Data, Consensus, Execution: Three Scalability Bottlenecks for State Machine Replication</title>
    <summary>If anyone asks you: how can I scale my State Machine Replication (Blockchain) system? You should answer back with a question: what is your bottleneck? Is it Data, Consensus or Execution? Data: Shipping the commands to all the replicas. For example, if a block contains 1MB of commands, then you...</summary>
    <updated>2019-12-06T17:05:00Z</updated>
    <published>2019-12-06T17:05:00Z</published>
    <source>
      <id>https://decentralizedthoughts.github.io</id>
      <author>
        <name>Ittai Abraham</name>
      </author>
      <link href="https://decentralizedthoughts.github.io" rel="alternate" type="text/html"/>
      <link href="https://decentralizedthoughts.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Decentralized thoughts about decentralization</subtitle>
      <title>Decentralized Thoughts</title>
      <updated>2019-12-13T12:21:40Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/177</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/177" rel="alternate" type="text/html"/>
    <title>TR19-177 |  Pseudo-deterministic Streaming | 

	Shafi Goldwasser, 

	Ofer Grossman, 

	Sidhanth Mohanty, 

	David Woodruff</title>
    <summary>A pseudo-deterministic algorithm is a (randomized) algorithm which, when run multiple times on the same input, with high probability outputs the same result on all executions. Classic streaming algorithms, such as those for finding heavy hitters, approximate counting, $\ell_2$ approximation, finding a nonzero entry in a vector (for turnstile algorithms) are not pseudo-deterministic. For example, in the instance of finding a nonzero entry in a vector, for any known low-space algorithm $A$, there exists a stream $x$ so that running $A$ twice on $x$ (using different randomness) would with high probability result in two different entries as the output.

In this work, we study whether it is inherent that these algorithms output different values on different executions. That is, we ask whether these problems have low-memory pseudo-deterministic algorithms. For instance, we show that there is no low-memory pseudo-deterministic algorithm for finding a nonzero entry in a vector (given in a turnstile fashion), and also that there is no low-dimensional pseudo-deterministic sketching algorithm for $\ell_2$ norm estimation.  We also exhibit problems which do have low memory pseudo-deterministic algorithms but no low memory deterministic algorithm, such as outputting a nonzero row of a matrix, or outputting a basis for the row-span of a matrix.

We also investigate multi-pseudo-deterministic algorithms: algorithms which with high probability output one of a few options. We show the first lower bounds for such algorithms. This implies that there are streaming problems such that every low space algorithm for the problem must have inputs where there are many valid outputs, all with a significant probability of being outputted.</summary>
    <updated>2019-12-06T14:44:41Z</updated>
    <published>2019-12-06T14:44:41Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-12-13T13:20:29Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>http://ptreview.sublinear.info/?p=1227</id>
    <link href="https://ptreview.sublinear.info/?p=1227" rel="alternate" type="text/html"/>
    <title>News for November 2019</title>
    <summary>We hit the mother-lode of property testing papers this month. Stick with us, as we cover 10 (!) papers that appeared online in November. EDIT: We actually have 11 papers, check out Optimal Adaptive Detection of Monotone Patterns at the bottom. Testing noisy linear functions for sparsity, by Xue Chen, Anindya De, and Rocco A. […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>We hit the mother-lode of property testing papers this month. Stick with us, as we cover 10 (!) papers that appeared online in November.</p>



<p>EDIT: We actually have 11 papers, check out <em>Optimal Adaptive Detection of Monotone Patterns</em> at the bottom.</p>



<p><strong>Testing noisy linear functions for sparsity</strong>, by Xue Chen, Anindya De, and Rocco A. Servedio (<a href="https://arxiv.org/abs/1911.00911">arXiv</a>). Given samples from a noisy linear model \(y = w\cdot x + \mathrm{noise}\), test whether \(w\) is \(k\)-sparse, or far from being \(k\)-sparse. This is a property testing version of the celebrated sparse recovery problem, whose sample complexity is well-known to be \(O(k\log n)\), where the data lies in \(\mathbb{R}^n\). This paper shows that the testing version of the problem can be solved (tolerantly) with a number of samples independent of \(n\), assuming technical conditions: the distribution of coordinates of \(x\) are i.i.d. and non-Gaussian, and the noise distribution is known to the algorithm. Surprisingly, all these conditions are needed, otherwise the dependence on \(n\) is \(\tilde \Omega(\log n)\), essentially the same as the recovery problem.</p>



<p><strong>Pan-Private Uniformity Testing</strong>, by Kareem Amin, Matthew Joseph, Jieming Mao (<a href="https://arxiv.org/abs/1911.01452">arXiv</a>). Differentially private distribution testing has now seen significant study, in both the local and central models of privacy. This paper studies a distribution testing in the pan-private model, which is intermediate: the algorithm receives samples one by one in the clear, but it must maintain a differentially private internal state at all time steps. The sample complexity turns out to be qualitatively intermediate to the two other models: testing uniformity over \([k]\) requires \(\Theta(\sqrt{k})\) samples in the central model, \(\Theta(k)\) samples in the local model, and this paper shows that \(\Theta(k^{2/3})\) samples are necessary and sufficient in the pan-private model.</p>



<p><strong>Almost Optimal Testers for Concise Representations</strong>, by Nader Bshouty (<a href="https://eccc.weizmann.ac.il/report/2019/156/">ECCC</a>). This work gives a unified approach for testing for a plethora of different classes which possess some sort of <em>sparsity</em>. These classes include \(k\)-juntas, \(k\)-linear functions, \(k\)-terms, various types of DNFs, decision lists, functions with bounded Fourier degree, and much more. </p>



<p><strong>Unified Sample-Optimal Property Estimation in Near-Linear Time</strong>, by Yi Hao and Alon Orlitsky (<a href="https://arxiv.org/abs/1911.03105">arXiv</a>). This paper presents a unified approach for estimating several distribution properties with both near-optimal time and sample complexity, based on piecewise-polynomial approximation. Some applications include estimators for Shannon entropy, power sums, distance to uniformity,  normalized support size, and normalized support coverage. More generally, results hold for all Lipschitz properties, and consequences include high-confidence property estimation (outperforming the “median trick”) and differentially private property estimation.</p>



<p><strong>Testing linear-invariant properties</strong>, by Jonathan Tidor and Yufei Zhao (<a href="https://arxiv.org/abs/1911.06793">arXiv</a>). This paper studies property testing of functions which are in a formal sense, definable by restrictions to subspaces of bounded degree. This class of functions is a broad generalization of testing whether a function is linear, or a degree-\(d\) polynomial (for constant \(d\)). The algorithm is the oblivious one, which simply repeatedly takes random restrictions and tests whether the property is satisfied or not (similar to the classic linearity test of BLR, along with many others). </p>



<p><strong>Approximating the Distance to Monotonicity of Boolean Functions</strong>, by Ramesh Krishnan S. Pallavoor, Sofya Raskhodnikova, Erik Waingarten (<a href="https://eccc.weizmann.ac.il/report/2019/163/">ECCC</a>). This paper studies the following fundamental question in tolerant testing: given a Boolean function on the hypercube, test whether it is \(\varepsilon’\)-close or \(\varepsilon\)-far from monotone. It is shown that there is a non-adaptive polynomial query algorithm which can solve this problem for \(\varepsilon’ = \varepsilon/\tilde \Theta(\sqrt{n})\), implying an algorithm which can approximate distance to monotonicity up to a multiplicative \(\tilde O(\sqrt{n})\) (addressing an <a href="https://ptreview.sublinear.info/?p=250">open problem</a> by Sesh). They also give a lower bound demonstrating that improving this approximating factor significantly would necessitate exponentially-many queries. Interestingly, this is proved for the (easier) erasure-resilient model, and also implies lower bounds for tolerant testing of unateness and juntas.</p>



<p><strong>Testing Properties of Multiple Distributions with Few Samples</strong>, by Maryam Aliakbarpour and Sandeep Silwal (<a href="https://arxiv.org/abs/1911.07324">arXiv</a>). This paper introduces a new model for distribution testing. Generally, we are given \(n\) samples from a distribution which is either (say) uniform or far from uniform, and we wish to test which is the case. The authors here study the problem where we are given a <em>single sample</em> from \(n\) different distributions which are either all uniform or far from uniform, and we wish to test which is the case. By additionally assuming a structural condition in the latter case (it is argued that <em>some</em> structural condition is necessary), they give sample-optimal algorithms for testing uniformity, identity, and closeness.</p>



<p><strong>Random Restrictions of High-Dimensional Distributions and Uniformity Testing with Subcube Conditioning</strong>, by Clément L. Canonne, Xi Chen, Gautam Kamath, Amit Levi, and Erik Waingarten (<a href="https://eccc.weizmann.ac.il/report/2019/165/">ECCC</a>, <a href="https://arxiv.org/abs/1911.07357">arXiv</a>). By now, it is well-known that testing uniformity over the \(n\)-dimensional hypercube requires \(\Omega(2^{n/2})\) samples — the curse of dimensionality quickly makes this problem intractable. One option is to assume that the distribution is product, which causes the complexity to drop to \(O(\sqrt{n})\). This paper instead assumes one has stronger access to the distribution — namely, one can receive samples conditioned on being from some subcube of the domain. With this, the paper shows that the complexity drops to the near-optimal \(\tilde O(\sqrt{n})\) samples. The related problem of testing whether a distribution is either uniform or has large mean is also considered. </p>



<p><strong>Property Testing of LP-Type Problems</strong>, by Rogers Epstein, Sandeep Silwal (<a href="https://arxiv.org/abs/1911.08320">arXiv</a>). An LP-Type problem (also known as a generalized linear program) is an optimization problem sharing some properties with linear programs. More formally, they consist of a set of constraints \(S\) and a function \(\varphi\) which maps subsets of \(S\) to some totally ordered set, such that \(\varphi\) possesses monotonicity and locality properties. This paper considers the problem of testing whether \(\varphi(S) \leq k\), or whether at least an \(\varepsilon\)-fraction of constraints in \(S\) must be removed for \(\varphi(S) \leq k\) to hold. This paper gives an algorithm with query complexity \(O(\delta/\varepsilon)\), where \(\delta\) is a dimension measure of the problem. This is applied to testing problems for linear separability, smallest enclosing ball, smallest intersecting ball, smallest volume annulus. The authors also provide lower bounds for some of these problems as well.</p>



<p><strong>Near-Optimal Algorithm for Distribution-Free Junta Testing</strong>, by Xiaojin Zhang (<a href="https://arxiv.org/abs/1911.10833">arXiv</a>). This paper presents an (adaptive) algorithm for testing juntas, in the distribution-free model with one-sided error. The query complexity is \(\tilde O(k/\varepsilon)\), which is nearly optimal. Algorithms with this sample complexity were previously known under the uniform distribution, or with two-sided error, but this is the first paper to achieve it in the distribution-free model with one-sided error.</p>



<p><strong>Optimal Adaptive Detection of Monotone Patterns</strong>, by Omri Ben-Eliezer, Shoham Letzter, Erik Waingarten (<a href="https://arxiv.org/abs/1911.01169">arXiv</a>). Consider the problem of testing whether a function has no monotone increasing subsequences of length \(k\), versus being \(\varepsilon\)-far from having this property. Note that this is a generalization of testing whether a function is monotone (decreasing), which corresponds to the case \(k = 2\). This work shows that the adaptive sample complexity of this problem is \(O_{k,\varepsilon}(\log n)\), matching the lower bound for monotonicity testing. This is in comparison to the non-adaptive sample complexity, which is \(O_{k,\varepsilon}((\log n)^{\lfloor \log_2 k\rfloor})\). In fact, the main result provides a certificate of being far, in the form of a monotone increasing subsequence of length \(k\).</p></div>
    </content>
    <updated>2019-12-06T04:41:03Z</updated>
    <published>2019-12-06T04:41:03Z</published>
    <category term="Monthly digest"/>
    <author>
      <name>Gautam Kamath</name>
    </author>
    <source>
      <id>https://ptreview.sublinear.info</id>
      <link href="https://ptreview.sublinear.info/?feed=rss2" rel="self" type="application/atom+xml"/>
      <link href="https://ptreview.sublinear.info" rel="alternate" type="text/html"/>
      <subtitle>The latest in property testing and sublinear time algorithms</subtitle>
      <title>Property Testing Review</title>
      <updated>2019-12-12T23:39:28Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=7588</id>
    <link href="https://windowsontheory.org/2019/12/05/deep-double-descent/" rel="alternate" type="text/html"/>
    <title>Deep Double Descent (cross-posted on OpenAI blog)</title>
    <summary>By Preetum Nakkiran, Gal Kaplun, Yamini Bansal, Tristan Yang, Boaz Barak, and Ilya Sutskever This is a lightly edited and expanded version of the following post on the OpenAI blog about the following paper. While I usually don’t advertise my own papers on this blog, I thought this might be of interest to theorists, and […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><em>By Preetum Nakkiran, Gal Kaplun, Yamini Bansal, Tristan Yang, Boaz Barak, and Ilya Sutskever</em></p>



<p><em>This is a lightly edited and expanded version of the following post on the <a href="https://openai.com/blog/deep-double-descent/">OpenAI blog</a> about the following <a href="http://mltheory.org/deep.pdf">paper</a>. While I usually don’t advertise my own papers on this blog, I thought this might be of interest to theorists, and a good follow up to <a href="https://windowsontheory.org/2019/11/15/puzzles-of-modern-machine-learning/">my prior post</a>. I promise not to make a habit out of it. –Boaz</em></p>



<p><strong>TL;DR:</strong>   <a href="http://mltheory.org/deep.pdf">Our paper</a> shows that <a href="https://arxiv.org/abs/1812.11118" rel="noreferrer noopener" target="_blank">double descent</a> occurs in conventional modern deep learning settings: visual classification in the presence of label noise (CIFAR 10, CIFAR 100) and machine translation (IWSLT’14 and WMT’14). As we increase the number of parameters in a neural network, initially the test error decreases, then increases, and then, just as the model is able to fit the train set, it undergoes a second descent, again decreasing as the number of parameters increases. This behavior also extends over train epochs, where a single model undergoes double-descent in test error over the course of training. Surprisingly (at least to us!), we show these phenomenon can lead to a regime where “<em><strong>more data hurts</strong></em>”—training a deep network on a larger train set actually performs worse.</p>



<h2>Introduction</h2>



<p>Open a statistics textbook and you are likely to see warnings against the danger of “overfitting”: If you are trying to find a good classifier or regressor for a given set of labeled examples, you would be well-advised to steer clear of having so many parameters in your model that you are able to completely fit the training data, because you risk not generalizing to new data.</p>



<p>The canonical example for this is polynomial regression. Suppose that we get <em>n</em> samples of the form <em>(x, p(x)+noise)</em> where <em>x</em> is a real number and <em>p(x)</em> is a cubic (i.e. degree 3) polynomial. If we try to fit the samples with a degree 1 polynomial—-a linear function, then we would get many points wrong. If we try to fit it with just the right degree, we would get a very good predictor. However, as the degree grows, we get worse till the degree is large enough to fit all the noisy training points, at which point the regressor is terrible, as shown in this figure:</p>



<figure class="wp-block-image"><img alt="" src="https://lh4.googleusercontent.com/H4f4ST5B9RnLX1ski6HEI7RBV5gqvk7WGiFR0qf6Savafmep6i08RYlpF5sgtq9oVqQ6ZkuglvCn0PTMQ_uaK3XStJlSskTSM6I52SyCZ91FeAcphq11MKa56wsfnDAG6GuruTT3"/></figure>



<p>It seems that the higher the degree, the worse things are, but what happens if we go <em>even higher</em>? It seems like a crazy idea—-why would we increase the degree beyond the number of samples? But it corresponds to the practice of having many more  parameters than training samples in modern deep learning. Just like in deep learning, when the degree is larger than the number of samples, there is more than one polynomial that fits the data– but we choose a specific one: the one found running gradient descent.</p>



<p>Here is what happens if we do this for degree 1000, fitting a polynomial using gradient descent (see <a href="https://colab.research.google.com/drive/1oMuUz3_BOENSoaOVOymLoB2mHeYBex8S">this notebook</a>):</p>



<figure class="wp-block-image"><img alt="" src="https://lh6.googleusercontent.com/DjQoPWG5gCueu_sAORKtrhNrrWY35OU3y-RXKJx0AZxIofVzZo-psP-JFsr_a4v20pWhH7EFfFPozckotWzvKypEebkPRJmdSa3vuy39ABdp2PqtqMr7dPX1PTDfMT362n4dGzVG"/></figure>



<p>We still fit all the training points, but now we do so in a more controlled way which actually tracks quite closely the ground truth. We see that despite what we learn in statistics textbooks, sometimes overfitting is not that bad, as long as you go “all in” rather than “barely overfitting” the data. That is, overfitting doesn’t hurt us if we take the number of parameters to be much larger than what is needed to just fit the training set — and in fact, as we see in deep learning, larger models are often better.</p>



<p>The above is not a novel observation. <a href="https://arxiv.org/abs/1812.11118">Belkin et al </a>called this phenomenon <strong><em>“double descent”</em></strong> and this goes back to <a href="http://www.ki.tu-berlin.de/fileadmin/fg135/publikationen/opper/Op01.pdf">even</a> <a href="https://arxiv.org/abs/1710.03667">earlier</a> <a href="https://arxiv.org/abs/1809.09349">works</a><a href="http://www.ki.tu-berlin.de/fileadmin/fg135/publikationen/opper/Op03b.pdf"> </a>. In this <a href="http://mltheory.org/deep.pdf">new paper</a> we (Preetum Nakkiran, Gal Kaplun, Yamini Bansal, Tristan Yang, Boaz Barak, and Ilya Sutskever) extend the prior works and report on a variety of experiments showing that “double descent” is widely prevalent across several modern deep neural networks and for several natural tasks such as image recognition (for the CIFAR 10 and CIFAR 100 datasets) and language translation (for IWSLT’14 and WMT’14 datasets).  As we increase the number of parameters in a neural network, initially the test error decreases, then increases, and then, just as the model is able to fit the train set, it undergoes a <em>second descent,</em> again decreasing as the number of parameters increases.  Moreover, double descent also extends beyond number of parameters to other measures of “complexity” such as the number of training epochs of the algorithm. </p>



<p>The take-away from our work (and the prior works it builds on) is that neither the classical statisticians’ conventional wisdom that <strong><em>“too large models are worse”</em></strong> nor the modern ML paradigm that <strong><em>“bigger models are always better”</em></strong><em> </em>always hold. Rather it all depends on whether you are on the first or second descent.  Further more, these insights also allow us to generate natural settings in which even the age-old adage of <strong><em>“more data is always better”</em></strong> is violated!</p>



<p>In the rest of this blog post we present a few sample results from this recent paper.</p>



<h3 id="modelwisedoubledescent">Model-wise Double Descent</h3>



<p>We observed many cases in which, just like in the polynomial interpolation example above, the test error undergoes a “double descent” as we increase the complexity of the model. The figure below demonstrates one such example: we plot the test error as a function of the complexity of the model for ResNet18 networks. The complexity of the model is the width of the layers, and the dataset is CIFAR10 with 15% label noise. Notice that the peak in test error occurs around the “interpolation threshold”: when the models are just barely large enough to fit the train set. In all cases we’ve observed, changes which affect the interpolation threshold (such as changing the optimization algorithm, changing the number of train samples, or varying the amount of label noise) also affect the location of the test error peak correspondingly. </p>



<p>We found the double descent phenomena is most prominent in settings with added label noise— without it, the peak is much smaller and easy to miss. But adding label noise amplifies this general behavior and allows us to investigate it easily.</p>



<figure class="wp-block-image"><img alt="" src="https://lh4.googleusercontent.com/tFWTvNkFwG8Ljx8zp9X3Ul6aUZT9YmkwcNk07g6_EFUklZoBUd9MqApBEojLzOp9N7yndveLwg5A7uj_vxpGVofQ2QCe-bbMAguQB38cK4NhRfXBp-SWMDQUt9x44r6d_fMur7NO"/></figure>



<p/>



<h3 id="samplewisenonmonotonicity">Sample-Wise Nonmonotonicity</h3>



<p>Using the model-wise double descent phenomenon we can obtain examples where training on <strong>more data actually hurts</strong>. To see this, let’s look at the effect of increasing the number of train samples on the test error vs. model size graph. The below plot shows Transformers trained on a language-translation task (with no added label noise):</p>



<figure class="wp-block-image"><img alt="" src="https://lh5.googleusercontent.com/YkuZGjuWGKoCcl1gNbQfaKO-96hX9ShcVZ_Dj0KlKddRZhgpMGtzs427zPuC9QwHOOKgmuV5E0aEKOU3zwhwpGmdiWwDDDBIk7hroJZfRLa7kXSThzwTDZoNSM8I2M9OfWxIW5X_"/></figure>



<p>On the one hand, (as expected) increasing the number of samples generally shifts the curve downwards towards lower test error. On the other hand, it also shifts the curve to the right: since more samples require larger models to fit, the interpolation threshold (and hence, the peak in test error) shifts to the right. For intermediate model sizes, these two effects combine, and we see that <strong>training on 4.5x more samples actually hurts test performance.</strong></p>



<h3 id="epochwisedoubledescent">Epoch-Wise Double Descent</h3>



<p><strong>There is a regime where training longer reverses overfitting.</strong> Let’s look closer at the experiment from the “Model-wise Double Descent” section, and plot Test Error as a function of both model-size and number of optimization steps. In the plot below to the right, each column tracks the Test Error of a given model over the course of training. The top horizontal dotted-line corresponds to the double-descent of the first figure. But we can also see that for a fixed large model, as training proceeds test error goes down, then up and down again—we call this phenomenon “epoch-wise double-descent.”</p>



<figure class="wp-block-image"><img alt="" src="https://lh3.googleusercontent.com/SCP6M-txj9ax5g9cR9Ry27X2nF1sEJbpsfC9FiME5umNm-BxcHHBmhseuuWEm3mHMzo_0o5q-92ETcaU0OEXnhTmv_7MpOREaaeIMs7zbL9P5aFeqkXMYh8O8VN4FdASnAu0HOPI"/></figure>



<p>Moreover, if we plot the Train error of the same models and the corresponding interpolation contour (dotted line) we see that it exactly matches the ridge of high test error (on the right).</p>



<p><strong>In general, the peak of test error appears systematically when models are just barely able to fit the train set.</strong></p>



<p>Our intuition is that for models at the interpolation threshold, there is effectively only one model that fits the train data, and forcing it to fit even slightly-noisy or mis-specified labels will destroy its global structure. That is, there are no “good models”, which both interpolate the train set, and perform well on the test set. However in the over-parameterized regime, there are many models that fit the train set, and there exist “good models” which both interpolate the train set and perform well on the distribution. Moreover, the implicit bias of SGD leads it to such “good” models, for reasons we don’t yet understand.</p>



<p>The above intuition is theoretically justified for linear models, via a series of recent works including [<a href="https://arxiv.org/abs/1903.08560">Hastie et al.</a>] and [<a href="https://arxiv.org/abs/1908.05355">Mei-Montanari</a>]. We leave fully understanding the mechanisms behind double descent in deep neural networks as an important open question.</p>



<p/>



<hr class="wp-block-separator"/>



<h2>Commentary: Experiments for Theory</h2>



<p>The experiments above are especially interesting (in our opinion) because of how they can inform ML theory: any theory of ML must be consistent with “double descent.” In particular, one ambitious hope for what it means to “theoretically explain ML” is to prove a theorem of the form:</p>



<p class="has-text-align-center">“If the distribution satisfies property X and architecture/initialization satisfies property Y, then SGD trained on ‘n’ samples, for T steps, will have small test error with high probability”</p>



<p>For values of X, Y, n, T, “small” and “high” that are used in practice.</p>



<p>However, these experiments show that these properties are likely more subtle than we may have hoped for, and must be non-monotonic in certain natural parameters.</p>



<p>This rules out even certain natural “conditional conjectures” that we may have hoped for, for example the conjecture that</p>



<p class="has-text-align-center">“If SGD on a width W network works for learning from ‘n’ samples from distribution D, then SGD on a width W+1 network will work at least as well”</p>



<p>Or the conjecture</p>



<p class="has-text-align-center">“If SGD on a certain network and distribution works for learning with ‘n’ samples, then it will work at least as well with n+1 samples”</p>



<p>It also appears to conflict with a “2-phase” view of the trajectory of SGD, as an initial “learning phase” and then an “overfitting phase” — in particular, because the overfitting is sometimes reversed (at least, as measured by test error) by further training.</p>



<p>Finally, the fact that these phenomena are not specific to neural networks, but appear to hold fairly universally for natural learning methods (linear/kernel regression, decision trees, random features) gives us hope that there is a deeper phenomenon at work, and we are yet to find the right abstraction.</p>



<p/>



<p/>



<p/>



<p><em>We especially thank Mikhail Belkin and Christopher Olah for helpful discussions throughout this work.</em> <em>The polynomial example is inspired in part by experiments in [<a href="https://arxiv.org/abs/1903.09139">Muthukumar et al.</a>]</em>.</p>



<p/></div>
    </content>
    <updated>2019-12-05T17:00:00Z</updated>
    <published>2019-12-05T17:00:00Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>preetum</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2019-12-13T13:20:59Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/12/05/postdoctoral-fellow-at-the-university-of-texas-at-austin-apply-by-january-15-2020-3/</id>
    <link href="https://cstheory-jobs.org/2019/12/05/postdoctoral-fellow-at-the-university-of-texas-at-austin-apply-by-january-15-2020-3/" rel="alternate" type="text/html"/>
    <title>Postdoctoral Fellow at The University of Texas at Austin (apply by January 15, 2020)</title>
    <summary>The Computer Science Department at UT Austin invites applications for a Postdoctoral Fellow in theoretical computer science for the 2020-21 academic year. The Fellow will work with Dana Moshkovitz and David Zuckerman on pseudorandomness and computational complexity. Review of applicants will begin on January 15, but applications will be accepted until the position is filled. […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Computer Science Department at UT Austin invites applications for a Postdoctoral Fellow in theoretical computer science for the 2020-21 academic year. The Fellow will work with Dana Moshkovitz and David Zuckerman on pseudorandomness and computational complexity. Review of applicants will begin on January 15, but applications will be accepted until the position is filled.</p>
<p>Website: <a href="https://utaustin.wd1.myworkdayjobs.com/UTstaff/job/UT-MAIN-CAMPUS/Postdoctoral-Fellow_R_00006957">https://utaustin.wd1.myworkdayjobs.com/UTstaff/job/UT-MAIN-CAMPUS/Postdoctoral-Fellow_R_00006957</a><br/>
Email: maguilar@cs.utexas.edu</p></div>
    </content>
    <updated>2019-12-05T14:24:31Z</updated>
    <published>2019-12-05T14:24:31Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-12-13T13:20:42Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/176</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/176" rel="alternate" type="text/html"/>
    <title>TR19-176 |  On Prover-Efficient Public-Coin Emulation of Interactive Proofs | 

	Gal Arnon, 

	Guy Rothblum</title>
    <summary>A central question in the study of interactive proofs is the relationship between private-coin proofs, where the verifier is allowed to hide its randomness from the prover, and public-coin proofs, where the verifier's random coins are sent to the prover. 
	
	In this work, we study transformations from private-coin proofs to public-coin proofs, which preserve (up to polynomial factors) the running time of both the prover and the verifier. We re-consider this question in light of the emergence of doubly-efficient interactive proofs, where the honest prover is required to run in polynomial time. Can every private-coin doubly-efficient interactive proof be transformed into a public-coin doubly-efficient proof? We show that, assuming one-way functions exist, there is no black-box private-coin to public-coin transformation for doubly-efficient interactive proofs.
	
	Our main result is a (loose) converse: every doubly-efficient proof has a function such that if this function is invertible, then the proof can be efficiently transformed. 
	
	Turning our attention back to classic interactive proofs, where the honest prover need not run in polynomial time, we show a similar result for constant-round general interactive proofs. Finally, we demonstrate a condition that suffices for efficiency preserving emulation of any protocol (even if the number of rounds is polynomial and the honest prover is unbounded). For a given interactive proof, if for every transcript prefix it is possible to efficiently approximate the number of consistent verifier random coins, then there is an efficiency-preserving transformation.</summary>
    <updated>2019-12-05T01:56:16Z</updated>
    <published>2019-12-05T01:56:16Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-12-13T13:20:29Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/175</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/175" rel="alternate" type="text/html"/>
    <title>TR19-175 |  Matching Smolensky&amp;#39;s correlation bound with majority | 

	Emanuele Viola</title>
    <summary>We show that there are degree-$d$ polynomials over $\mathbb{F}_{2}$ with
correlation $\Omega(d/\sqrt{n})$ with the majority function on $n$
bits. This matches the $O(d/\sqrt{n})$ bound by Smolensky.</summary>
    <updated>2019-12-04T16:53:39Z</updated>
    <published>2019-12-04T16:53:39Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-12-13T13:20:29Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16447</id>
    <link href="https://rjlipton.wordpress.com/2019/12/03/end-to-end-encryption-a-problem/" rel="alternate" type="text/html"/>
    <title>End-to-End Encryption: A Problem</title>
    <summary>Bopuifs fodszqujpo qspcmfn. “Unsung Entrepreneur” source Adolph Ochs was the owner of the New York Times. In 1897 he created the paper’s slogan, “All the News That’s Fit to Print.” We at GLL would like some suggestions on our own slogan. Send us your ideas. Please no suggestion of “All the news that fits we […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><font color="#0044cc"><br/>
<em>Bopuifs fodszqujpo qspcmfn.</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2019/12/ochs.jpg"><img alt="" class="alignright wp-image-16449" height="180" src="https://rjlipton.files.wordpress.com/2019/12/ochs.jpg?w=142&amp;h=180" width="142"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">“Unsung Entrepreneur” <a href="https://www.archbridgeinstitute.org/2019/01/02/adolph-ochs-the-unsung-entrepreneur-who-transformed-journalism/">source</a></font></td>
</tr>
</tbody>
</table>
<p>
Adolph Ochs was the owner of the New York Times. In 1897 he created the paper’s slogan, “All the News That’s Fit to Print.” We at GLL would like some suggestions on our own slogan. Send us your ideas. Please no suggestion of “All the news that fits we print,” as that is already out there.</p>
<p>
Today Ken and I wish to comment on a recent article in the NYT that was on end-to-end encryption.<br/>
<span id="more-16447"/></p>
<p>
The <a href="https://www.nytimes.com/2019/11/19/technology/end-to-end-encryption.html">article</a> leads by saying: </p>
<blockquote><p><b> </b> <em> A Justice Department official hinted on Monday that a yearslong fight over encrypted communications could become part of a sweeping investigation of big tech companies. </em>
</p></blockquote>
<p/><p>
Of course, end-to-end encryption scrambles messages so that <em>only</em> the sender and receiver can decode the message. Other methods are weaker: some only encrypt messages as they enter part of the network. This means that one must trust the network to keep your message secret. Thus the end-to-end method reduces the number of parties that one must trust. </p>
<p>
In 1912, Ochs was a party to encryption that was literally end-to-end on the globe. The New York Times had bought exclusive American rights to report Roald Amundsen’s expedition to the South Pole. When Amundsen returned to Hobart, Tasmania, he sent a coded cable to his brother Leon who was acting as conduit to the Times and the London Daily Chronicle. The brother pronounced the coast clear for Amundsen to communicate directly to the papers. The stories were still quickly plagiarized once the first one appeared in the Times, and Ochs had to defend his rights with lawsuits. </p>
<p>
</p><p/><h2> The Usual Problem </h2><p/>
<p/><p>
There is an ongoing interest in using end-to-end encryption to protect more and more of our messages. And this interest leads to several hard problems. </p>
<p>
The main one addressed by the NYT article is: Does this type of encryption protect bad actors? Many believe that encryption makes it impossible to track criminals. Many in law enforcement, for example, wish to have the ability to access any messages, at least on a court order. Some countries are likely to make this the law—that is, they will insist that they always can access any message. A followup NYT <a href="https://www.nytimes.com/reuters/2019/11/27/technology/27reuters-interpol-encryption.html">article</a> described debates within Interpol about these matters.</p>
<p>
</p><p/><h2> Another Problem </h2><p/>
<p/><p>
The above problem is <b>not</b> what we wish to talk about today. We want to raise another problem. </p>
<blockquote><p><b> </b> <em> <i>How do we know that our messages are being properly encrypted?</i> </em>
</p></blockquote>
<p/><p>
We could check that our app is in end-to-end mode. The app will say “yes”. The problem is that this does not prove anything. The deeper question is how do we know that messages are correctly encrypted. Indeed. </p>
<p>
Suppose that we are told that the message <img alt="{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M}"/> has been sent to another person as the encrypted message <img alt="{E(M)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BE%28M%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{E(M)}"/>. How do we know that this has been done? Several issues come to mind:</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <i>The app could lie.</i> The app could for example say it is encrypting your message and it did not.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <i>The app could mislead.</i> The app could send an encrypted message and also send the clear message to who ever it wishes.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <i>The app could be wrong.</i> The app could think that the message was properly encrypted. The key, for example, could be a weak key.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <i>The app method could be flawed.</i> The app’s method could be incorrect. The method used might be vulnerable to non or unknown attacks.</p>
<p>
<a href="https://en.wikipedia.org/wiki/Authenticated_encryption">Authenticated</a> encryption seems to cover only part of the need. It can confirm the identity of the sender and that the ciphertext has not been tampered with. This is, however, a far cry from verifying that the encryption itself is proper and free of holes that could make it easy to figure out. Our point is also aside from problems with particular end-to-end implementations such as those considered in this 2017 <a href="https://arxiv.org/pdf/1707.05285.pdf">paper</a>.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Bopuifs fodszqujpo qspcmfn was encrypted with the simple key 	</p>
<p align="center"><img alt="\displaystyle  a \rightarrow b, b \rightarrow c, c \rightarrow d, \dots " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++a+%5Crightarrow+b%2C+b+%5Crightarrow+c%2C+c+%5Crightarrow+d%2C+%5Cdots+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  a \rightarrow b, b \rightarrow c, c \rightarrow d, \dots "/></p>
<p>The point of this silly example is that it might have been encrypted by a harder method, but it was only encrypted by a trivial substitution method. Nevertheless, Google could not figure it out:</p>
<p/><p><br/>
<a href="https://rjlipton.files.wordpress.com/2019/12/googleanotherencryptionproblem.png"><img alt="" class="aligncenter size-medium wp-image-16450" src="https://rjlipton.files.wordpress.com/2019/12/googleanotherencryptionproblem.png?w=300&amp;h=175"/></a></p>
<p/></font></font></div>
    </content>
    <updated>2019-12-04T03:03:46Z</updated>
    <published>2019-12-04T03:03:46Z</published>
    <category term="All Posts"/>
    <category term="History"/>
    <category term="News"/>
    <category term="Adolph Ochs"/>
    <category term="crypto"/>
    <category term="encryption"/>
    <category term="end-to-end"/>
    <category term="New York Times"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-12-13T13:20:39Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-1485483742428466612</id>
    <link href="https://blog.computationalcomplexity.org/feeds/1485483742428466612/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/12/julia-robinsons-100th-birthday.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/1485483742428466612" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/1485483742428466612" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/12/julia-robinsons-100th-birthday.html" rel="alternate" type="text/html"/>
    <title>Julia Robinson's 100th birthday</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">On Dec 8, 1919 Julia Robinson was born, so today is close to her 100th birthday (she passed away at<br/>
<div>
the age of 65 on July 30, 1985).</div>
<div>
<br/></div>
<div>
So time for some facts about her</div>
<div>
<br/></div>
<div>
1) She got her PhD from Tarski where she proved the undecidability of the theory of the rationals.</div>
<div>
<br/></div>
<div>
2) She is probably best known for her work on Hilbert's tenth problem (which we call H10)</div>
<div>
<br/></div>
<div>
In todays' terminology H10 would be stated as:</div>
<div>
<br/>
Find an algorithm that will, given p in Z[x_1,...,x_n] determine if it has an integer solution.</div>
<div>
<br/></div>
<div>
Hilbert posed it to inspire deep research in Number Theory. There are some cases that are</div>
<div>
solvable (the topic of a later blog post) but the general problem is undecidable. This is not what Hilbert was aiming for. I wonder if he would be happy with the resolution.</div>
<div>
<br/></div>
<div>
The Davis-Putnam-Robinson paper showed that the decision problem for exponential diophantine equations was undecidable. It was published in 1961. The paper is <a href="https://www.jstor.org/stable/1970289?seq=1#metadata_info_tab_contents">here</a>.  Martin Davis predicted that the proof that H10 was undecidable would be by a young Russian mathematician. He was proven correct when Yuri Matiyasevich supplied the missing piece needed to complete the proof.  </div>
<div>
<br/></div>
<div>
I often read `H10 was resolved by Davis-Putnam-Robinson and Matiyasevich' or sometimes they put all four names in alphabetical order. I like that--- it really was a joint effort.</div>
<div>
<br/></div>
<div>
3) She was inducted (a proof by induction?) into the National Academy of Sciences in 1975.</div>
<div>
<br/></div>
<div>
4) She was elected to be president of the American Math Society in 1982.  </div>
<div>
<br/></div>
<div>
5) She got a MacAuthor Fellowship prize in 1985 (Often called the MacAuthor Genius award.)</div>
<div>
At the time it was worth $60,000.  Its now $625,000.</div>
<div>
<br/></div>
<div>
6) She also did work in Game Theory. Her paper An Iterative Method of Solving a Game, which is<br/>
<a href="https://www.jstor.org/stable/1969530?seq=1#metadata_info_tab_contents">here</a>, is a proof from the book according to Paul Goldberg's comment on this post.</div>
<div>
<br/></div>
<div>
7) The Julia Robinson Math Festival is named in her honor (hmmm- is that a tautology?) Its purpose is to inspire K-12 students to get involved in math. For more on it see <a href="https://en.wikipedia.org/wiki/Julia_Robinson_Mathematics_Festival">here</a>.<br/>
<br/>
8) (ADDED LATER) Commenter David Williamson pointed out that Julia Robinson did work on the transportation problem. See his comment and his pointer to the paper.<br/>
<br/>
(ADDED LATER) When I hear <i>Julia Robinson</i> I think <i>Hilbert's 10th problem. </i> I suspect many of you do the same. However, looking at items 6 and 8 above, one realizes that she did research in non-logic branches of math as well.</div>
<div>
<br/></div>
<div>
<br/></div>
<div>
<br/></div></div>
    </content>
    <updated>2019-12-02T23:01:00Z</updated>
    <published>2019-12-02T23:01:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-12-13T11:50:07Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-27705661.post-857009480691482743</id>
    <link href="http://processalgebra.blogspot.com/feeds/857009480691482743/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=27705661&amp;postID=857009480691482743" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/857009480691482743" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/857009480691482743" rel="self" type="application/atom+xml"/>
    <link href="http://processalgebra.blogspot.com/2019/12/faculty-positions-at-department-of.html" rel="alternate" type="text/html"/>
    <title>Faculty positions at the Department of Computer Science, Reykjavik University</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div><i>This job ad could be of interest to you or to someone you know. Feel free to spread it as you see fit. Thanks! </i></div><div> </div><div>The Department of Computer Science at Reykjavik University invites applications for several full-time faculty positions.</div><br/>We  are looking for energetic, highly qualified academics who are eager to  develop their own research programs, strengthen existing research within  the department and build bridges with industry. Of particular interest  are candidates in the areas of machine learning, data science, computer  security and software systems, broadly construed, but exceptionally  qualified candidates from all areas of computer science are encouraged  to apply.<br/><br/>Candidates should have a proven international research  record that is commensurate with the level of the position for which  they apply. The successful applicants will play a full part in the  teaching and administrative activities of the department; in particular,  they will teach courses and supervise students at both graduate and  undergraduate level. Applicants having a demonstrated history of  excellence in teaching are preferred. A PhD in computer science or a  related field is required.<br/><br/>Salary and rank are commensurate with  experience. An appointment at assistant-professor level is permanent  track, with the expectation that a successful candidate will qualify for  promotion to associate professor within six years.<br/><br/>The positions  are open until filled, with the earliest available starting date in  August 2020. Later starting dates can be negotiated.<br/><br/>The review of the applications will begin on Monday, 17 February 2020, and will continue until the positions are filled.<br/><div><br/></div><div>See <a href="http://radningar.hr.is/storf/viewjobonweb.aspx?jobid=3558" target="_blank">http://radningar.hr.is/storf/viewjobonweb.aspx?jobid=3558</a> for further information on how to apply for the position and on the required documents. </div><br/><div><b>About the department, Reykjavik University and Iceland</b></div><div><br/></div>The  Department of Computer Science at Reykjavik University has about 650  full-time-equivalent students and 22 faculty members. It provides an  excellent working environment that encourages and supports independence  in academic endeavours, and in which a motivated academic can have  impact at all levels. The department offers undergraduate and graduate  programs in computer science and software engineering, as well as a  combined-degree undergraduate program in discrete mathematics and  computer science. The doctoral program within the department received  its ministerial accreditation in 2009 and has been active ever since.<br/><br/>The  department is home to several research centres producing high-quality  collaborative research in areas such as artificial intelligence,  financial technology, language technology, software systems, and  theoretical computer science, among others; for more information on  those research centres, see <a href="https://en.ru.is/research/units/" target="_blank">https://en.ru.is/research/units/</a>.<br/><br/>On  the Times Higher Education rankings for 2020, Reykjavík University is  ranked in first place along with six other universities for the average  number of citations per faculty. Overall, according to that list, RU is  ranked among the 300 best universities world-wide, 52nd out of all  universities established fewer than 50 years ago, 14th among  universities with fewer than 5000 students, and first among Icelandic  universities.<br/><br/>Iceland is well known for its breathtaking natural  beauty, with volcanoes, geysers, hot springs, lava fields and glaciers  offering a dramatic landscape. It is consistently ranked as one of the  best places in the world to live. It offers a high quality of life, is  one of the safest places in the world, has high gender equality, and  strong health-care and social-support systems. It is in fourth position  in the 2019 UN World Happiness Report, which ranks the world's countries  by their happiness level.<br/><br/>For further information about the Department of Computer Science at Reykjavik University and its activities, see <a href="http://en.ru.is/scs/" target="_blank">http://en.ru.is/scs/</a>.</div>
    </content>
    <updated>2019-12-02T22:35:00Z</updated>
    <published>2019-12-02T22:35:00Z</published>
    <author>
      <name>Luca Aceto</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/01092671728833265127</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-27705661</id>
      <author>
        <name>Luca Aceto</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/01092671728833265127</uri>
      </author>
      <link href="http://processalgebra.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://processalgebra.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Papers I find interesting---mostly, but not solely, in Process Algebra---, and some fun stuff in Mathematics and Computer Science at large and on general issues related to research, teaching and academic life.</subtitle>
      <title>Process Algebra Diary</title>
      <updated>2019-12-10T12:37:54Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4439</id>
    <link href="https://www.scottaaronson.com/blog/?p=4439" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4439#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4439" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Two updates</title>
    <summary xml:lang="en-US">Two weeks ago, I blogged about the claim of Nathan Keller and Ohad Klein to have proven the Aaronson-Ambainis Conjecture. Alas, Keller and Klein tell me that they’ve now withdrawn their preprint (though it may take another day for that to show up on the arXiv), because of what looks for now like a fatal […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><ol><li>Two weeks ago, I <a href="https://www.scottaaronson.com/blog/?p=4414">blogged about</a> the <a href="https://arxiv.org/abs/1911.03748">claim</a> of Nathan Keller and Ohad Klein to have proven the Aaronson-Ambainis Conjecture.  Alas, Keller and Klein tell me that they’ve now withdrawn their preprint (though it may take another day for that to show up on the arXiv), because of what looks for now like a fatal flaw, in Lemma 5.3, discovered by Paata Ivanishvili.  (My own embarrassment over having missed this flaw is <em>slightly</em> mitigated by most of the experts in discrete Fourier analysis having missed it as well!)  Keller and Klein are now working to fix the flaw, and I wholeheartedly wish them success.</li><li>In unrelated news, I was saddened to read that <a href="https://en.wikipedia.org/wiki/Virgil_Griffith">Virgil Griffith</a>—cryptocurrency researcher, former Integrated Information Theory researcher, and <a href="https://www.scottaaronson.com/blog/?p=1893">onetime contributor to <em>Shtetl-Optimized</em></a>—was <a href="https://www.forbes.com/sites/jasonbrett/2019/11/29/us-authorities-arrest-virgil-griffith-for-teaching-cryptocurrency-and-blockchain/#1a19647142cb">arrested at LAX</a> for having traveled to North Korea to teach the DPRK about cryptocurrency, against the admonitions of the US State Department.  I didn’t know Virgil well, but I did meet him in person at least once, and I liked <a href="http://www.scottaaronson.com/response-p1.pdf">his</a> <a href="http://www.scottaaronson.com/response-p2.pdf">essays</a> for this blog about how, after spending years studying IIT under Giulio Tononi himself, he became disillusioned with many aspects of it and evolved to a position not far from mine (though not identical either).<br/>Personally, I despise the North Korean regime for the obvious reasons—I regard it as not merely evil, but <em>cartoonishly</em> so—and I’m mystified by Virgil’s <a href="https://twitter.com/nicksdjohnson/status/1201212127945605122">apparently sincere belief</a> that he could bring peace between the North and South by traveling to North Korea to give a lecture about blockchain.  Yet, however world-historically naïve he may have been, his intentions appear to have been good.  More pointedly—and here I’m asking not in a legal sense but in a human one—if giving aid and comfort to the DPRK is treasonous, then isn’t the current occupant of the Oval Office a million times guiltier of that particular treason (to say nothing of others)?  It’s like, what does “treason” even mean anymore?  In any case, I hope some plea deal or other arrangement can be worked out that won’t end Virgil’s productive career.</li></ol>



<p/></div>
    </content>
    <updated>2019-12-02T15:31:12Z</updated>
    <published>2019-12-02T15:31:12Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Announcements"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Complexity"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Nerd Interest"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2019-12-02T20:32:03Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=18705</id>
    <link href="https://gilkalai.wordpress.com/2019/12/02/tyi-41-how-many-steps-does-it-take-for-a-simple-random-walk-on-the-discrete-cube-to-reach-the-uniform-distribution/" rel="alternate" type="text/html"/>
    <title>TYI 41: How many steps does it take for a simple random walk on the discrete cube to reach the uniform distribution?</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Aeiel Yadin’s homepage contains great lecture notes on harmonic functions on groups and on various other topics. I have a lot of things to discuss and to report; exciting developments in the analysis of Boolean functions; much to report on … <a href="https://gilkalai.wordpress.com/2019/12/02/tyi-41-how-many-steps-does-it-take-for-a-simple-random-walk-on-the-discrete-cube-to-reach-the-uniform-distribution/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="https://www.math.bgu.ac.il/~yadina/"><img alt="" class="alignnone size-medium wp-image-18724" height="300" src="https://gilkalai.files.wordpress.com/2019/11/ayadin.png?w=244&amp;h=300" width="244"/></a></p>
<p><span style="color: #ff0000;">Aeiel Yadin’s <a href="https://www.math.bgu.ac.il/~yadina/">homepage</a> contains great lecture notes on harmonic functions on groups and on various other topics.</span></p>
<p>I have a lot of things to discuss and to report; exciting developments in the analysis of Boolean functions; much to report on algebraic, geometric and probabilistic combinatorics following our Oberwolfach summer meeting; much to tell about our Kazhdan seminar on quantum computation and symplectic geometry; a lot of exciting math and TCS activities in Israel; exciting things that Avi Wigderson’s told me on non commutative optimization and moment maps; and, of course, last but not least, the exciting <strong>Google supremacy demonstration</strong> that I most recently wrote about in my post <a href="https://gilkalai.wordpress.com/2019/11/13/gils-collegial-quantum-supremacy-skepticism-faq/" rel="bookmark"><strong>Gil’s Collegial Quantum Supremacy Skepticism FAQ</strong>.</a>  In particular, the unbelievable local-to-global fidelity <strong><span style="color: #ff0000;">Formula (77), </span></strong>and<span style="color: #0000ff;"><strong> (NEW) </strong></span><strong>a poem by Peter Shor for quantum computer skeptics</strong>. More poems are most welcome!</p>
<p>With all these excitements, plans, and blog duties it looks that this is the right time to take a pause for a Test Your Intuition post. (Based on chats with <a href="http://www.math.tau.ac.il/~asafnach/">Asaf Nachmias</a>, <a href="https://www.dpmms.cam.ac.uk/~jh2129/">Jonathan Hermon</a> and <a href="http://www.wisdom.weizmann.ac.il/~itai/">Itai Benjamini</a>.)</p>
<h2>Approaching the uniform distribution on the discrete cube with a lazy simple random walk.</h2>
<p>Consider the discrete cube as a graph: the vertices are all the 0-1 vertices of length <img alt="n " class="latex" src="https://s0.wp.com/latex.php?latex=n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n "/>, two vertices are adjacent if they differ in one coordinate.</p>
<p>A (lazy) simple random walk is described as follows: You start at the all 0 vertex. At each step when you are at vertex <img alt="v" class="latex" src="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="v"/> you stay where you are with probability 1/2 and, with probability 1/2,  you move to a neighbor  of <img alt="v" class="latex" src="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="v"/> chosen uniformly at random.</p>
<p>Your position after <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t"/> steps is a random variable describing a probability distribution <img alt="D_t" class="latex" src="https://s0.wp.com/latex.php?latex=D_t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D_t"/> on the vertices of the discrete cube. Now, lets fix once and for all the value of <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon"/> to be 0.1.</p>
<p><strong>Test your intuition:</strong> How many steps <em><strong>T(n)</strong></em> does it take until <img alt="D_t" class="latex" src="https://s0.wp.com/latex.php?latex=D_t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D_t"/> is <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon"/>-close to the uniform distribution <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/> in <a href="https://en.wikipedia.org/wiki/Total_variation_distance_of_probability_measures">total variation distance</a>.  (The total variation distance is 1/2 the <img alt="L^1" class="latex" src="https://s0.wp.com/latex.php?latex=L%5E1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="L^1"/> distance).</p>
<h3>Others measure of proximity</h3>
<p>We can also ask: How many steps <em><strong>M(n)</strong></em> does it take until <img alt="D_t(x)" class="latex" src="https://s0.wp.com/latex.php?latex=D_t%28x%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D_t(x)"/> is close to the uniform distribution <em>for every</em> <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/>? Namely, for every <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/>,</p>
<p><img alt="(1-\epsilon)/2^n \le D_t(x) \le (1+\epsilon)/2^n" class="latex" src="https://s0.wp.com/latex.php?latex=%281-%5Cepsilon%29%2F2%5En+%5Cle+D_t%28x%29+%5Cle+%281%2B%5Cepsilon%29%2F2%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(1-\epsilon)/2^n \le D_t(x) \le (1+\epsilon)/2^n"/></p>
<p>For this question there is a simple analysis based on the <a href="https://en.wikipedia.org/wiki/Coupon_collector%27s_problem">coupon collector problem</a>.</p>
<p>We can also consider intermediate measures of proximity, like the entropy:</p>
<p>How many steps <em><strong>H(n)</strong></em> it takes until the entropy of <img alt="D_t(x)" class="latex" src="https://s0.wp.com/latex.php?latex=D_t%28x%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D_t(x)"/> is <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon"/>-close to the <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> the entropy of the uniform distribution?</p>
<p>Let me try now to test your more detailed intuition: For the public opinion poll below we say that <span style="color: #0000ff;"><em>X behaves like Y</em></span> if their ratio tends to one as <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> tends to infinity, and that <span style="color: #0000ff;"><em>X is really smaller than Y</em></span> if their ratio X/Y tends to a limit smaller than 1.</p>
<a name="pd_a_10464820"/><div class="CSS_Poll PDS_Poll" id="PDI_container10464820" style="display: inline-block;"/><div id="PD_superContainer"/><noscript>&lt;a href="https://polldaddy.com/p/10464820" target="_blank"&gt;Take Our Poll&lt;/a&gt;</noscript>
<h3><span style="color: #0000ff;">NEW: Share your knowledge</span></h3>
<p>Let’s try something new: “Share your knowledge (SYK):” What other distances between probability distributions do you recommend? Tell us about them!</p>
<h2>A theorem by Ajtai-Komlos-Szemeredi and a problem by Itai Benjamini</h2>
<p>Ajtai, Komlos and Szemeredi proved that when you choose every edge of the discrete <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>-cube with probability greater than <img alt="1/n" class="latex" src="https://s0.wp.com/latex.php?latex=1%2Fn&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/n"/> a giant component emerges! Now, choose every edge with probability <img alt="2/n" class="latex" src="https://s0.wp.com/latex.php?latex=2%2Fn&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2/n"/>  and start a simple random walk from a vertex of the giant component. Itai Benjamini conjectured that it will take roughly <img alt="n^2" class="latex" src="https://s0.wp.com/latex.php?latex=n%5E2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n^2"/> steps to approximately reach the stationary distribution. This seems very difficult.</p>
<p> </p></div>
    </content>
    <updated>2019-12-02T06:15:20Z</updated>
    <published>2019-12-02T06:15:20Z</published>
    <category term="Combinatorics"/>
    <category term="Probability"/>
    <category term="Test your intuition"/>
    <category term="discrete cube"/>
    <category term="random walk"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-12-13T13:20:32Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/174</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/174" rel="alternate" type="text/html"/>
    <title>TR19-174 |  Exponential Resolution Lower Bounds for Weak Pigeonhole Principle and Perfect Matching Formulas over Sparse Graphs | 

	Susanna de Rezende, 

	Jakob Nordström, 

	Kilian Risse, 

	Dmitry Sokolov</title>
    <summary>We show exponential lower bounds on resolution proof length for pigeonhole principle (PHP) formulas and perfect matching formulas over highly unbalanced, sparse expander graphs, thus answering the challenge to establish strong lower bounds in the regime between balanced constant-degree expanders as in [Ben-Sasson and Wigderson '01] and highly unbalanced, dense graphs as in [Raz '04] and [Razborov '03, '04]. We obtain our results by revisiting Razborov's pseudo-width method for PHP formulas over dense graphs and extending it to sparse graphs. This further demonstrates the power of the pseudo-width method, and we believe it could potentially be useful for attacking also other longstanding open problems for resolution and other proof systems.</summary>
    <updated>2019-12-02T01:04:07Z</updated>
    <published>2019-12-02T01:04:07Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-12-13T13:20:29Z</updated>
    </source>
  </entry>
</feed>
