<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2019-07-29T09:22:38Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-5104220537083628124</id>
    <link href="https://blog.computationalcomplexity.org/feeds/5104220537083628124/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/07/turing-to-be-on-bank-of-england-50.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/5104220537083628124" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/5104220537083628124" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/07/turing-to-be-on-bank-of-england-50.html" rel="alternate" type="text/html"/>
    <title>Turing to be on the Bank of England 50 pound note, giving me an excuse to talk about Turing</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">BILL: Darling, guess who is soon going to be on the Bank of England 50 pound note?<br/>
<br/>
DARLING: Alan Turing. <br/>
<br/>
BILL: How did you deduce that? (She is right, see  <a href="https://www.bbc.com/news/business-48962557">here</a>.)<br/>
<br/>
DARLING: Since you asked it, it couldn't be a member of the Royal Family (you don't care about that) or some British Politician (you don't care about that either). It had to be a mathematician or computer scientist.<br/>
<br/>
BILL: It could have been Hardy. I wonder if Ramanujan could qualify---do they need to be British? At <a href="https://www.bankofengland.co.uk/banknotes/banknote-characters">this website</a> it says<br/>
<br/>
<br/>
<br/>
<i>Of course, banknotes need to be universally accepted. We therefore look for UK characters who have made an important contribution to our society and culture through their innovation, leadership or values. We do not include fictional characters, or people who are still living (except the monarch on the front of the note). Finally, we need to have a suitable portrait of the person which will be easy to recognise.</i><br/>
<br/>
(They spell <i>recognise</i> with an s instead of a z, so spellcheck flagged it, but I won't change it.) <br/>
<br/>
Note that people on the banknotes have to be <i>UK characters</i>. I honestly don't know if that means they must be citizens.<br/>
<br/>
OKAY, so here are a few thoughts on Turing.<br/>
<br/>
1) When I visited Bletchley Park there was a booklet that bragged about the fact that Bletchley Park was much better at cracking codes than Germany because  they allowed people to work there based only on ability (unlike Germany) - women worked there, Turing who was Gay worked there. I think this is simplistic. Did any Jews work there (anti-semitism was widespread in England, and the world, at the time)? I doubt any blacks worked there since if they did that would be well known by now (if I am wrong let me know). Women DID work there but was their work respected and used? (I honestly don't know). Did Germany also use women at their codebreaking centers? Was Turing known to be gay (if not then Bletchley gets no points for tolerating him). Was JUST having Turing the reason they could crack codes. Plus I am sure there were other factors aside from merit-only.<br/>
<br/>
2) Turing was given a Pardon for his ``crimes'' in August 2014. When I see things like this I wonder who was against it and why and if they were an obstacle.<br/>
<br/>
a) Human Rights Advocate Peter Tatchell noted that its wrong to just single out Turing. Other people prosecuted under that law who did not help beat the German's in WW II should also be pardoned. The government later DID such a pardon in 2017.<br/>
<br/>
b) Judge Minister Lord McNally objected to the pardon:<br/>
<br/>
<i>A posthumous pardon was not considered appropriate as Alan Turing was properly convicted of what at the time was a criminal offence. He would have known that his offence was against the law and that he would be prosecuted. It is tragic that Alan Turing was convicted of an offence that now seems both cruel and absurd—particularly poignant given his outstanding contribution to the war effort. However, the law at the time required a prosecution and, as such, long-standing policy has been to accept that such convictions took place and, rather than trying to alter the historical context and to put right what cannot be put right, ensure instead that we never again return to those times.<br/>
</i><br/>
<br/>
While I disagree with him, I do note that, based on what he wrote and his general record, I think he is not saying this from being anti-gay.  There is  a hard general question here: how does a society right past wrongs? I think pardoning and apologizing is certainly fine, but frankly it seems to weak. What else could a society due? Financial renumeration to living relatives? I don't think giving Inagh Payne (Turing's niece, who I think is still alive) would really help here.<br/>
<br/>
c) <i>At the bill's second reading in the House of Commons on 29 November 2013, Conservative MP Christopher Chope objected to the bill, delaying its passage<br/>
</i><br/>
<br/>
I couldn't find Chope's reasons. On the one hand, they may be similar to McNally's. On the other hand he is against same sex marriage so its possible (though I do not know this) that he anti-gay and that is why he is against the pardon. If someone can find what his explanation for blocking the Turing bill is, or other evidence that he is anti-gay, please leave it in the comments.<br/>
<br/>
3) Did the delay matter? I was surprised to find out---Yes. Here is the full passage from Wikipedia:<br/>
<br/>
<br/>
<i>At the bill's second reading in the House of Commons on 29 November 2013, Conservative MP Christopher Chope objected to the bill, delaying its passage. The bill was due to return to the House of Commons on 28 February 2014,[175] but before the bill could be debated in the House of Commons,[176] the government elected to proceed under the royal prerogative of mercy. On 24 December 2013, Queen Elizabeth II signed a pardon for Turing's conviction for "gross indecency", with immediate effect.[17] Announcing the pardon, Lord Chancellor Chris Grayling said Turing deserved to be "remembered and recognised for his fantastic contribution to the war effort" and not for his later criminal conviction.[16][18] The Queen officially pronounced Turing pardoned in August 2014.[177] The Queen's action is only the fourth royal pardon granted since the conclusion of the Second World War.[178] Pardons are normally granted only when the person is technically innocent, and a request has been made by the family or other interested party; neither condition was met in regard to Turing's conviction.[179]</i><br/>
<br/>
This amazed me! I thought the Queen had NO power (too bad--- I wish she could just say NO BREXIT). Or that she formally has power but if she ever used it, it might be blocked somehow and  taken away. So I am surprised she has a power she can use at all.<br/>
<br/>
4) I wonder if the Pardon had to happen before they put him on the Banknote. I have been told that this is a very American Question--- England has no Constitution and operates more on Custom and Tradition than on written rules. <br/>
<br/>
5) I had always assumed that Turing committed suicide. Without going into detail, the Wikipedia site on Turing does give intelligent counterarguments to this. See <a href="https://en.wikipedia.org/wiki/Alan_Turing#Death">here</a><br/></div>
    </content>
    <updated>2019-07-29T00:46:00Z</updated>
    <published>2019-07-29T00:46:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-07-29T08:05:13Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.11686</id>
    <link href="http://arxiv.org/abs/1907.11686" rel="alternate" type="text/html"/>
    <title>A Tight Degree 4 Sum-of-Squares Lower Bound for the Sherrington-Kirkpatrick Hamiltonian</title>
    <feedworld_mtime>1564358400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kunisky:Dmitriy.html">Dmitriy Kunisky</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bandeira:Afonso_S=.html">Afonso S. Bandeira</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.11686">PDF</a><br/><b>Abstract: </b>We show that, if $\mathbf{W} \in \mathbb{R}^{N \times N}_{\mathsf{sym}}$ is
drawn from the gaussian orthogonal ensemble, then with high probability the
degree 4 sum-of-squares relaxation cannot certify an upper bound on the
objective $N^{-1} \cdot \mathbf{x}^\top \mathbf{W} \mathbf{x}$ under the
constraints $x_i^2 - 1 = 0$ (i.e. $\mathbf{x} \in \{ \pm 1 \}^N$) that is
asymptotically smaller than $\lambda_{\max}(\mathbf{W}) \approx 2$. We also
conjecture a proof technique for lower bounds against sum-of-squares
relaxations of any degree held constant as $N \to \infty$, by proposing an
approximate pseudomoment construction.
</p></div>
    </summary>
    <updated>2019-07-29T01:25:34Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.11669</id>
    <link href="http://arxiv.org/abs/1907.11669" rel="alternate" type="text/html"/>
    <title>Subtour Elimination Constraints Imply a Matrix-Tree Theorem SDP Constraint for the TSP</title>
    <feedworld_mtime>1564358400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gutekunst:Samuel_C=.html">Samuel C. Gutekunst</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Williamson:David_P=.html">David P. Williamson</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.11669">PDF</a><br/><b>Abstract: </b>De Klerk, Pasechnik, and Sotirov give a semidefinite programming constraint
for the Traveling Salesman Problem (TSP) based on the matrix-tree Theorem. This
constraint says that the aggregate weight of all spanning trees in a solution
to a TSP relaxation is at least that of a cycle graph. In this note, we show
that the semidefinite constraint holds for any weighted 2-edge-connected graph
and, in particular, is implied by the subtour elimination constraints of the
subtour elimination linear program. Hence, this semidefinite constraint is
implied by a finite set of linear inequality constraints.
</p></div>
    </summary>
    <updated>2019-07-29T01:25:52Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.11662</id>
    <link href="http://arxiv.org/abs/1907.11662" rel="alternate" type="text/html"/>
    <title>Adventures in Abstraction: Reachability in Hierarchical Drawings</title>
    <feedworld_mtime>1564358400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lionakis:Panagiotis.html">Panagiotis Lionakis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Ortali:Giacomo.html">Giacomo Ortali</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tollis:Ioannis_G=.html">Ioannis G. Tollis</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.11662">PDF</a><br/><b>Abstract: </b>We present algorithms and experiments for the visualization of directed
graphs that focus on displaying their reachability information. Our algorithms
are based on the concepts of the path and channel decomposition as proposed in
the framework presented in GD 2018 (pp. 579-592) and focus on showing the
existence of paths clearly. In this paper we customize these concepts and
present experimental results that clearly show the interplay between bends,
crossings and clarity. Additionally, our algorithms have direct applications to
the important problem of showing and storing transitivity information of very
large graphs and databases. Only a subset of the edges is drawn, thus reducing
the visual complexity of the resulting drawing, and the memory requirements for
storing the transitivity information. Our algorithms require almost linear
time, $O(kn+m)$, where $k$ is the number of paths/channels, $n$ and $m$ is the
number of vertices and edges, respectively. They produce progressively more
abstract drawings of the input graph. No dummy vertices are introduced and the
vertices of each path/channel are vertically aligned.
</p></div>
    </summary>
    <updated>2019-07-29T01:26:41Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.11636</id>
    <link href="http://arxiv.org/abs/1907.11636" rel="alternate" type="text/html"/>
    <title>Notes on Computational Hardness of Hypothesis Testing: Predictions using the Low-Degree Likelihood Ratio</title>
    <feedworld_mtime>1564358400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kunisky:Dmitriy.html">Dmitriy Kunisky</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wein:Alexander_S=.html">Alexander S. Wein</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bandeira:Afonso_S=.html">Afonso S. Bandeira</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.11636">PDF</a><br/><b>Abstract: </b>These notes survey and explore an emerging method, which we call the
low-degree method, for predicting and understanding
statistical-versus-computational tradeoffs in high-dimensional inference
problems. In short, the method posits that a certain quantity -- the second
moment of the low-degree likelihood ratio -- gives insight into how much
computational time is required to solve a given hypothesis testing problem,
which can in turn be used to predict the computational hardness of a variety of
statistical inference tasks. While this method originated in the study of the
sum-of-squares (SoS) hierarchy of convex programs, we present a self-contained
introduction that does not require knowledge of SoS. In addition to showing how
to carry out predictions using the method, we include a discussion
investigating both rigorous and conjectural consequences of these predictions.
</p>
<p>These notes include some new results, simplified proofs, and refined
conjectures. For instance, we point out a formal connection between spectral
methods and the low-degree likelihood ratio, and we give a sharp low-degree
lower bound against subexponential-time algorithms for tensor PCA.
</p></div>
    </summary>
    <updated>2019-07-29T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.11635</id>
    <link href="http://arxiv.org/abs/1907.11635" rel="alternate" type="text/html"/>
    <title>Subexponential-Time Algorithms for Sparse PCA</title>
    <feedworld_mtime>1564358400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Yunzi Ding, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kunisky:Dmitriy.html">Dmitriy Kunisky</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wein:Alexander_S=.html">Alexander S. Wein</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bandeira:Afonso_S=.html">Afonso S. Bandeira</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.11635">PDF</a><br/><b>Abstract: </b>We study the computational cost of recovering a unit-norm sparse principal
component $x \in \mathbb{R}^n$ planted in a random matrix, in either the Wigner
or Wishart spiked model (observing either $W + \lambda xx^\top$ with $W$ drawn
from the Gaussian orthogonal ensemble, or $N$ independent samples from
$\mathcal{N}(0, I_n + \beta xx^\top)$, respectively). Prior work has shown that
when the signal-to-noise ratio ($\lambda$ or $\beta\sqrt{N/n}$, respectively)
is a small constant and the fraction of nonzero entries in the planted vector
is $\|x\|_0 / n = \rho$, it is possible to recover $x$ in polynomial time if
$\rho \lesssim 1/\sqrt{n}$. While it is possible to recover $x$ in exponential
time under the weaker condition $\rho \ll 1$, it is believed that
polynomial-time recovery is impossible unless $\rho \lesssim 1/\sqrt{n}$. We
investigate the precise amount of time required for recovery in the "possible
but hard" regime $1/\sqrt{n} \ll \rho \ll 1$ by exploring the power of
subexponential-time algorithms, i.e., algorithms running in time
$\exp(n^\delta)$ for some constant $\delta \in (0,1)$. For any $1/\sqrt{n} \ll
\rho \ll 1$, we give a recovery algorithm with runtime roughly $\exp(\rho^2
n)$, demonstrating a smooth tradeoff between sparsity and runtime. Our family
of algorithms interpolates smoothly between two existing algorithms: the
polynomial-time diagonal thresholding algorithm and the $\exp(\rho n)$-time
exhaustive search algorithm. Furthermore, by analyzing the low-degree
likelihood ratio, we give rigorous evidence suggesting that the tradeoff
achieved by our algorithms is optimal.
</p></div>
    </summary>
    <updated>2019-07-29T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.11632</id>
    <link href="http://arxiv.org/abs/1907.11632" rel="alternate" type="text/html"/>
    <title>On maximal isolation sets in the uniform intersection matrix</title>
    <feedworld_mtime>1564358400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Parnas:Michal.html">Michal Parnas</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shraibman:Adi.html">Adi Shraibman</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.11632">PDF</a><br/><b>Abstract: </b>Let $A_{k,t}$ be the matrix that represents the adjacency matrix of the
intersection bipartite graph of all subsets of size $t$ of $\{1,2,...,k\}$. We
give constructions of large isolation sets in $A_{k,t}$, where, for a large
enough $k$, our constructions are the best possible.
</p>
<p>We first prove that the largest identity submatrix in $A_{k,t}$ is of size
$k-2t+2$. Then we provide constructions of isolations sets in $A_{k,t}$ for any
$t\geq 2$, as follows: \begin{itemize} \item If $k = 2t+r$ and $0 \leq r \leq
2t-3$, there exists an isolation set of size $2r+3 = 2k-4t+3$. \item If $k \geq
4t-3$, there exists an isolation set of size $k$. \end{itemize} The
construction is maximal for $k\geq 4t-3$, since the Boolean rank of $A_{k,t}$
is $k$ in this case. As we prove, the construction is maximal also for $k = 2t,
2t+1$.
</p>
<p>Finally, we consider the problem of the maximal triangular isolation
submatrix of $A_{k,t}$ that has ones in every entry on the main diagonal and
below it, and zeros elsewhere. We give an optimal construction of such a
submatrix of size $({2t \choose t}-1) \times ({2t \choose t}-1)$, for any $t
\geq 1$ and a large enough $k$. This construction is tight, as there is a
matching upper bound, which can be derived from a theorem of Frankl about skew
matrices.
</p></div>
    </summary>
    <updated>2019-07-29T01:21:03Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-07-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.11525</id>
    <link href="http://arxiv.org/abs/1907.11525" rel="alternate" type="text/html"/>
    <title>Rational Motions with Generic Trajectories of Low Degree</title>
    <feedworld_mtime>1564358400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Johannes Siegele, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Scharler:Daniel_F=.html">Daniel F. Scharler</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schr=ouml=cker:Hans=Peter.html">Hans-Peter Schröcker</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.11525">PDF</a><br/><b>Abstract: </b>The trajectories of a rational motion given by a polynomial of degree n in
the dual quaternion model of rigid body displacements are generically of degree
2n. In this article we study those exceptional motions whose trajectory degree
is lower. An algebraic criterion for this drop of degree is existence of
certain right factors, a geometric criterion involves one of two families of
rulings on an invariant quadric. Our characterizations allow the systematic
construction of rational motions with exceptional degree reduction and explain
why the trajectory degrees of a rational motion and its inverse motion can be
different.
</p></div>
    </summary>
    <updated>2019-07-29T01:27:56Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-07-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.11422</id>
    <link href="http://arxiv.org/abs/1907.11422" rel="alternate" type="text/html"/>
    <title>Almost Shortest Paths and PRAM Distance Oracles in Weighted Graphs</title>
    <feedworld_mtime>1564358400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Elkin:Michael.html">Michael Elkin</a>, Yuval Gitlitz, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Neiman:Ofer.html">Ofer Neiman</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.11422">PDF</a><br/><b>Abstract: </b>Let $G=(V,E)$ be a weighted undirected graph with $n$ vertices and $m$ edges,
and fix a set of $s$ sources $S\subseteq V$. For any pair $u,v\in V$, let
$W(u,v)$ denote the weight of the heaviest edge on the $u$ to $v$ shortest
path. For any constant $0&lt;\epsilon&lt;1$, we compute
$(1+\epsilon,\beta(\cdot,\cdot))$-approximate shortest paths from all sources
in $S$ in near linear (in $m+ns$) time, where $\beta(u,v)=O(W(u,v))$. That is,
the multiplicative stretch is $1+\epsilon$, and the additive stretch for any
$u\in S$, $v\in V$ is $\beta(u,v)$. Previous results of this type were only
able to compute distance estimates and not paths, and had far inferior additive
terms. We also introduce distance oracles for parallel models of computation
(PRAM). Specifically, for any parameter $\delta&gt;0$, we preprocess a given
weighted graph in poly-logarithmic time and near linear work, and store a data
structure of size $O(n^{1+\delta})$. Given any query $u\in V$, we return a
$(1+\epsilon,\beta(\cdot,\cdot))$-approximation to all distances $u\times V$ in
$O_\delta(1)$ time, where $\beta(u,v)=O_\delta(W(u,v))$. Moreover, the
dependence of both $\beta$ and the query time on $\delta$ can be made
$\text{poly}(1/\delta)$, by increasing the multiplicative stretch (to some
constant larger than 9). Our algorithms are based on new constructions of
spanners, emulators and hopsets for weighted graphs. We devise a
$(1+\epsilon,\beta(\cdot,\cdot))$-spanner for weighted graphs of size
$O(n^{1+1/t}+\log t\cdot n)$ and $\beta(u,v)=W(u,v)\cdot \left(\frac{\log
t}{\epsilon}\right)^{O(\log t)}$. We can have an improved $\beta=W(u,v)\cdot
t^{O(1)}$ at the cost of increasing the multiplicative stretch to a constant
larger than 3. In addition, we devise a $(c,t^{O(1)})$-hopset of size
$O(n^{1+1/t}+\log t\cdot n)$ for any constant $c&gt;3$.
</p></div>
    </summary>
    <updated>2019-07-29T01:22:39Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.11416</id>
    <link href="http://arxiv.org/abs/1907.11416" rel="alternate" type="text/html"/>
    <title>Generalized Liar's Dominating Set in Graphs</title>
    <feedworld_mtime>1564358400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jena:Sangram_K=.html">Sangram K. Jena</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jallu:Ramesh_K=.html">Ramesh K. Jallu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Das:Gautam_K=.html">Gautam K. Das</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.11416">PDF</a><br/><b>Abstract: </b>In this article, we study generalized liar's dominating set problem in
graphs. Let $G=(V,E)$ be a simple undirected graph. The generalized liar's
dominating set, called as the distance-$d$ $(m,\ell)$-liar's dominating set, is
a subset $L\subseteq V$ such that (i) each vertex in $V$ is distance-$d$
dominated by at least $m$ vertices in $L$, and (ii) each pair of distinct
vertices in $V$ is distance-$d$ dominated by at least $\ell$ vertices in $L$,
where $m,\ell,d$ are positive integers and $m &lt; \ell$. Here, a vertex $v$ is
distance-$d$ dominated by another vertex $u$ means the shortest path distance
between $u$ and $v$ is at most $d$ in $G$.
</p>
<p>We first consider distance-1 $(m,\ell)$-liar's dominating set problem and
prove that it is NP-complete. Next, we consider distance-$d$ $(m,\ell)$-liar's
dominating set problem and show that it is also NP-complete. These liar's
dominating set problems are generalized version of liar's dominating set
problem as researcher studied only distance-$1$ $(2,3)$-liar's dominating set
problem in literature. We also prove that (i) distance-1 $(m,\ell)$-liar's
dominating set problem cannot be approximated within a factor of $(\frac{1}{2}-
\varepsilon)\ln |V|$ for any $\varepsilon&gt;0$, unless NP $\subseteq$
DTIME$(|V|^{O(\log\log|V|)})$, and (ii) distance-$d$ $(m,\ell)$-liar's
dominating set problem cannot be approximated within a factor of $(\frac{1}{4}-
\varepsilon)\ln |V|$ for any $\varepsilon&gt;0$, unless NP $\subseteq$
DTIME$(|V|^{O(\log\log|V|)})$.
</p></div>
    </summary>
    <updated>2019-07-29T01:21:41Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-07-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.11404</id>
    <link href="http://arxiv.org/abs/1907.11404" rel="alternate" type="text/html"/>
    <title>Tight Approximation for Variants of Directed Steiner Tree via State-Tree Decomposition and Linear Programming Rounding</title>
    <feedworld_mtime>1564358400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Guo:Xiangyu.html">Xiangyu Guo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Laekhanukit:Bundit.html">Bundit Laekhanukit</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Shi.html">Shi Li</a>, Jiayi Xian <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.11404">PDF</a><br/><b>Abstract: </b>Directed Steiner Tree (DST) is a central problem in combinatorial
optimization and theoretical computer science. Recently, Grandoni, Laekhanukit
and Li and independently Ghuge and Nagarajan gave quasi-polynomial time
$O(\log^2k/\log \log k)$-approximation algorithms for the problem, which is
tight under popular complexity assumptions.
</p>
<p>In this paper, we show a general framework that achieves $O(\log n \log
k)$-approximation for many variants of DST. We show that if the problem has the
property that the validity of the tree and its cost can be checked and computed
using a bottom-to-top procedure, then the general framework can be used to
produce a small-cost {multi-tree}: a tree that may contain multiple copies of a
vertex or an edge.
</p>
<p>Using the framework, we show that two prominent variants of DST, namely
Length-Bounded DST (LB-DST) and Buy-at-Bulk DST with Concave Cost Functions
(BaB-DST-Concave), admit $O(\log n \log k)$-approximation algorithms. In the
Length-Bounded Directed Steiner Tree (LB-DST) problem, there are bounds on
lengths of paths from the root to vertices in the output tree. In the
Buy-at-Bulk DST problem with Concave Functions (BaB-DST-Concave), each terminal
needs to receive a flow from the root and the cost of each edge is a concave
function on the total amount of flow that it carries. Our results almost match
the best known $O(\log ^2k/\log \log k)$ algorithm that have recently been
discovered by Ghuge and Nagarajan.
</p>
<p>Another variant that fits into the framework is the Degree-Bounded DST
(DB-DST) problem. In this problem, we are additionally given a degree bound
$d_v$ on each vertex $v \in V$, which imposes the constraint that $v$ is
allowed to have at most $d_v$ children in the output tree. In this case, our
framework gives an $O(\log^3n \log k, \log n\log k)$-bicritiera approximation,
which is the first non-trivial result for the problem.
</p></div>
    </summary>
    <updated>2019-07-29T01:24:16Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.11402</id>
    <link href="http://arxiv.org/abs/1907.11402" rel="alternate" type="text/html"/>
    <title>New $(\alpha,\beta)$ Spanners and Hopsets</title>
    <feedworld_mtime>1564358400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Uri Ben-Levy, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Parter:Merav.html">Merav Parter</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.11402">PDF</a><br/><b>Abstract: </b>An $f(d)$-spanner of an unweighted $n$-vertex graph $G=(V,E)$ is a subgraph
$H$ satisfying that $dist_H(u, v)$ is at most $f(dist_G(u, v))$ for every $u,v
\in V$. We present new spanner constructions that achieve a nearly optimal
stretch of $O(\lceil k /d \rceil)$ for any distance value $d \in
[1,k^{1-o(1)}]$, and $d \geq k^{1+o(1)}$. We show the following:
</p>
<p>1. There exists an $f(d)$-spanner $H \subseteq G$ with $f(d)\leq 7k$ for any
$d \in [1,\sqrt{k}/2]$ with expected size $O_{k}(n^{1+1/k})$. This in
particular gives $(\alpha,\beta)$ spanners with $\alpha=O(\sqrt{k})$ and
$\beta=O(k)$.
</p>
<p>2. For any $\epsilon \in (0,1/2]$, there exists an $(\alpha,\beta)$-spanner
with $\alpha=O(k^{\epsilon})$, $\beta=O_{\epsilon}(k)$ and of expected size
$O_{k}(n^{1+1/k})$. This implies a stretch of $O(\lceil k/d \rceil)$ for any $d
\in [\sqrt{k}/2, k^{1-\epsilon}]$, and for every $d\geq k^{1+\epsilon}$. In
particular, it provides a constant stretch already for vertex pairs at distance
$k^{1+o(1)}$ (improving upon $d=(\log k)^{\log k}$ that was known before). Up
to the $o(1)$ factor in the exponent, and the constant factor in the stretch,
this is the best possible by the girth argument.
</p>
<p>3. For any $\epsilon \in (0,1)$, there is a $(3+\epsilon, \beta)$-spanner
with $\beta=O_{\epsilon}(k^{\log(3+8/\epsilon)})$.
</p>
<p>We also consider the related graph concept of hopsets introduced by [Cohen,
J. ACM '00]. We present a new family of $(\alpha,\beta)$ hopsets with
$\widetilde{O}(k \cdot n^{1+1/k})$ edges and $\alpha \cdot \beta=O(k)$. Most
notably, we show a construction of $(3+\epsilon,\beta)$ hopset with
$\widetilde{O}_{\epsilon}(n)$ edges and hop-bound of $\beta=O_{\epsilon}((\log
n)^{\log(3+9/\epsilon)})$, improving upon the state-of-the-art hop-bound of
$\beta=O(\log\log n)^{\log \log n}$ by [Elkin-Neiman, '17] and [Huang-Pettie,
'17]
</p></div>
    </summary>
    <updated>2019-07-29T01:25:08Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.11368</id>
    <link href="http://arxiv.org/abs/1907.11368" rel="alternate" type="text/html"/>
    <title>On the relationships between Z-, C-, and H-local unitaries</title>
    <feedworld_mtime>1564358400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cook:Jeremy.html">Jeremy Cook</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.11368">PDF</a><br/><b>Abstract: </b>Quantum walk algorithms can speed up search of physical regions of space in
both the discrete-time [<a href="http://export.arxiv.org/abs/quant-ph/0402107">arXiv:quant-ph/0402107</a>] and continuous-time setting
[<a href="http://export.arxiv.org/abs/quant-ph/0306054">arXiv:quant-ph/0306054</a>], where the physical region of space being searched is
modeled as a connected graph. In such a model, Aaronson and Ambainis
[<a href="http://export.arxiv.org/abs/quant-ph/0303041">arXiv:quant-ph/0303041</a>] provide three different criteria for a unitary matrix
to act locally with respect to a graph, called $Z$-local, $C$-local, and
$H$-local unitaries, and left the open question of relating these three
locality criteria. Using a correspondence between continuous- and discrete-time
quantum walks by Childs [<a href="http://export.arxiv.org/abs/0810.0312">arXiv:0810.0312</a>], we provide a way to approximate
$N\times N$ $H$-local unitaries with error $\delta$ using
$O(1/\sqrt{\delta},\sqrt{N})$ $C$-local unitaries, where the comma denotes the
maximum of the two terms.
</p></div>
    </summary>
    <updated>2019-07-29T01:20:31Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-07-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.11338</id>
    <link href="http://arxiv.org/abs/1907.11338" rel="alternate" type="text/html"/>
    <title>A note on the complexity of integer programming games</title>
    <feedworld_mtime>1564358400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Carvalho:Margarida.html">Margarida Carvalho</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.11338">PDF</a><br/><b>Abstract: </b>In this brief note, we prove that the existence of Nash equilibria on integer
programming games is a $\Sigma^p_2$.
</p></div>
    </summary>
    <updated>2019-07-29T01:22:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-07-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.11232</id>
    <link href="http://arxiv.org/abs/1907.11232" rel="alternate" type="text/html"/>
    <title>Exhaustive Exact String Matching: The Analysis of the Full Human Genome</title>
    <feedworld_mtime>1564358400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/x/Xylogiannopoulos:Konstantinos_F=.html">Konstantinos F. Xylogiannopoulos</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.11232">PDF</a><br/><b>Abstract: </b>Exact string matching has been a fundamental problem in computer science for
decades because of many practical applications. Some are related to common
procedures, such as searching in files and text editors, or, more recently, to
more advanced problems such as pattern detection in Artificial Intelligence and
Bioinformatics. Tens of algorithms and methodologies have been developed for
pattern matching and several programming languages, packages, applications and
online systems exist that can perform exact string matching in biological
sequences. These techniques, however, are limited to searching for specific and
predefined strings in a sequence. In this paper a novel methodology (called
Ex2SM) is presented, which is a pipeline of execution of advanced data
structures and algorithms, explicitly designed for text mining, that can detect
every possible repeated string in multivariate biological sequences. In
contrast to known algorithms in literature, the methodology presented here is
string agnostic, i.e., it does not require an input string to search for it,
rather it can detect every string that exists at least twice, regardless of its
attributes such as length, frequency, alphabet, overlapping etc. The complexity
of the problem solved and the potential of the proposed methodology is
demonstrated with the experimental analysis performed on the entire human
genome. More specifically, all repeated strings with a length of up to 50
characters have been detected, an achievement which is practically impossible
using other algorithms due to the exponential number of possible permutations
of such long strings.
</p></div>
    </summary>
    <updated>2019-07-29T01:22:07Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/07/28/any-order-puzzle</id>
    <link href="https://11011110.github.io/blog/2019/07/28/any-order-puzzle.html" rel="alternate" type="text/html"/>
    <title>Any-order puzzle deduction</title>
    <summary>I recently wrote here about a complication in puzzle-solving where, in using deductive rules based on the assumption that the puzzle has a unique solution, the ordering of the rules could make a difference in how far you get in the solution. And avoiding this ordering issue by keeping track of more information than just the state of the partially solved puzzle leads to its own difficulties. It seemed like keeping this information could lose you in a maze of undecidable modal logic. For instance in the map coloring puzzle described in that post, we might record information about a partial solution like “I don’t know that this cell is forced to be red, but it is necessary for it to be red in order to prevent a non-unique solution”, with the complexity of these statements growing as the solution progressed. Instead, what I wanted was a way to make decisions without worrying about the order of deduction while only remembering a finite amount of state for each puzzle cell. In the ensuing discussion, @axiom suggested that the extra information should be the order of deductions. That’s not a constant amount of information per cell, but as we’ll see below it works to simplify this even more and remember only which cells were the initial givens and which were deduced later.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I recently wrote here about a complication in puzzle-solving where, in using deductive rules based on the assumption that the puzzle has a unique solution, <a href="https://11011110.github.io/blog/2019/06/07/little-knowledge-can.html">the ordering of the rules could make a difference in how far you get in the solution</a>. And avoiding this ordering issue by keeping track of more information than just the state of the partially solved puzzle leads to its own difficulties. It seemed like keeping this information could lose you in a maze of undecidable <a href="https://11011110.github.io/blog/2019/07/13/connectivity-finiteness-modal.html">modal logic</a>. For instance in the map coloring puzzle described in that post, we might record information about a partial solution like “I don’t know that this cell is forced to be red, but it is necessary for it to be red in order to prevent a non-unique solution”, with the complexity of these statements growing as the solution progressed. Instead, what I wanted was a way to make decisions without worrying about the order of deduction while only remembering a finite amount of state for each puzzle cell. In <a href="https://mathstodon.xyz/@11011110/102234384857906663">the ensuing discussion</a>, @axiom suggested that the extra information should be the order of deductions.
That’s not a constant amount of information per cell, but as we’ll see below it works to simplify this even more and remember only which cells were the initial givens and which were deduced later.</p>

<p>To clarify the intuition that deduction order should not matter, I want to formalize the state of a partially-solved puzzle as a collection of bits, initially all true. In map coloring, each bit could represent the possibility that a given cell is a particular color, and we want to eventually have one true bit per cell and the rest false. A deduction is a change to a single bit. Each deduction is triggered by a rule, which typically searches for certain patterns in the state. For instance, in map coloring, the pattern that one cell has only one remaining color whose bit is true can trigger the deduction that the same color’s bit in a neighboring cell must be false. Any given deduction could be triggered by more than one rule, or by more than one instance of the same rule. Then these rules and deductions should obey some natural properties:</p>

<ul>
  <li>
    <p>The deductions can only go in one direction. If we deduce that a bit is false, we won’t later change it back to true.</p>
  </li>
  <li>
    <p>The deductions are always valid for the intended puzzle. That is, when a puzzle has a unique solution, we won’t ever deduce anything inconsistent with that solution. (However, when that assumption is violated, anything can happen.)</p>
  </li>
  <li>
    <p>It should be possible to efficiently identify all deductions that can be triggered from the current state. Ideally this should take polynomial time.</p>
  </li>
  <li>
    <p>If a deduction is triggered by one of the rules, it remains triggered until that deduction step is performed.</p>
  </li>
</ul>

<p>I’m not assuming that the deduction system is complete, i.e., that it will  reach the intended puzzle solution for all puzzles. For most natural puzzle types and most efficiently-searchable sets of deduction rules, it won’t be complete, and most likely (because of NP-completeness or related complexity issues) cannot be both complete and efficiently searchable. But nevertheless, a system of rules obeying these properties always reaches a unique state, independent of deduction order. It is the last of these properties that enforces this order-invariance. By induction on the values in the triggering patterns, each deduction that could be made by some order of deduction steps will eventually be made by a greedy algorithm that chooses deductions in an arbitrary order until it gets stuck.</p>

<p>The “remains triggered until performed” criterion should sound familiar. It is the defining property of an <a href="https://en.wikipedia.org/wiki/Antimatroid">antimatroid</a>, a collection of orderings of items (here, orderings of deductions that could be made by the greedy algorithm) with the property that once an item becomes available to be added to an ordering, it remains available until it actually is added. The antimatroid name is a bit technical and off-putting, but these structures come up all the time in many different applications. I’ve written here about
<a href="https://11011110.github.io/blog/2006/06/18/reverse-search-for.html">listing all small antimatroids</a>, <a href="https://11011110.github.io/blog/2006/07/20/upright-quad-drawing.html">visualizing their structure</a>, <a href="https://11011110.github.io/blog/2006/08/30/antimatroids-as-algebras.html">algebraic axiomatization</a>, <a href="https://11011110.github.io/blog/2007/02/18/pruning-antimatroids-is.html">hardness of finding weighted feasible sets</a>, the <a href="https://11011110.github.io/blog/2007/02/20/two-partial-cubes.html">swap structure on orderings</a>, <a href="https://11011110.github.io/blog/2011/11/16/which-infinite-graphs.html">infinite antimatroids</a>, <a href="https://11011110.github.io/blog/2013/02/25/antimatroids-and-balanced.html">informative comparisons</a>, <a href="https://11011110.github.io/blog/2015/03/05/nearest-neighbor-in.html">nearest neighbors</a>, and the applications of antimatroids to <a href="https://11011110.github.io/blog/2007/02/17/shelling-and-pseudotriangulation.html">pseudotriangulation</a>, <a href="https://11011110.github.io/blog/2007/12/29/formal-knot-theory.html">knot theory</a>, <a href="https://11011110.github.io/blog/2008/03/30/how-to-implement.html">computerized education</a>, <a href="https://11011110.github.io/blog/2008/12/02/parts-assembly-and.html">parts assembly</a>, <a href="https://11011110.github.io/blog/2009/01/30/antimatroids-from-sorting.html">sorting networks</a>, <a href="https://11011110.github.io/blog/2013/10/26/rhyme-scheme-antimatroid.html">rhyme schemes</a>, <a href="https://11011110.github.io/blog/2016/04/17/local-and-inductive.html">hereditary graph properties</a>, <a href="https://11011110.github.io/blog/2017/01/17/course-prerequisites-are.html">course prerequisites</a>, and <a href="https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors.html">hierarchical clustering</a>. So why not add puzzle deduction to the list?</p>

<p>A nice side-effect of using deduction rules with these properties is that, if the rules are ordered by difficulty, then a greedy algorithm that always chooses the easiest rule at each step will automatically find a deduction sequence minimizing the difficulty of the hardest rule that it uses. This can be helpful in <a href="http://arxiv.org/abs/cs.DS/0507053">using deduction algorithms to automatically estimate the difficulty of a puzzle for a human solver</a>.</p>

<p>A natural way to achieve the “remains triggered until performed” property for a deduction rule is to use a pattern in the form of a monotonic Boolean combination of state bits (a function that can be expressed using only Boolean and and or operations, without negation) and to trigger a deduction when that combination becomes false. In this way, we achieve a stronger property, that once triggered the deduction remains triggered forever (even after it has already been performed). But as we’ll see below, other kinds of rules can also have the same property.</p>

<p>Now back to map coloring.</p>

<p>We saw in <a href="https://11011110.github.io/blog/2019/06/07/little-knowledge-can.html">my earlier post</a> that it doesn’t work well to use rules like “if one cell has already-colored neighbors of two colors, and only one uncolored neighbor, then that neighbor cannot be either of the same two colors”. These rules are valid (under the assumption that the puzzle solution is unique) but lose information about why the deduction on the neighboring vertex was made, preventing later deductions from being made.</p>

<p>Instead, the insight I ended up using involves <a href="https://en.wikipedia.org/wiki/Kempe_chain">Kempe chains</a>. A Kempe chain, in a colored map, is a maximal connected subset of the cells of two of the colors. If the coloring is to be unique, every Kempe chain must be anchored by one of the original givens of the puzzle, for otherwise we could swap the two colors in the chain without affecting the rest of the graph. So, I’ve started using rules of the form “if this Kempe chain in the partially colored map is not yet anchored, and can reach an anchor only by extending through this other cell, then that cell cannot be a third color”. Here, the Kempe chains that I examine to trigger this rule are maximal connected subsets of the cells whose colors are limited to some set of two colors, allowing cells that are already known to have only one of those two colors. Until we add the extension cell to the chain, the same rule will continue to be triggered, so this passes the any-order requirements above.</p>

<p>This deduction method also fits well into the visualization tools available for manual puzzle-solving in <a href="https://www.chiark.greenend.org.uk/~sgtatham/puzzles/">Simon Tatham’s puzzle collection</a>, where I found the map puzzle. This collection’s implementation of the map puzzle shows the givens and solved cells as solid colors, and allows unsolved cells to be marked by dots of any combination of the four colors. So I’ve been using these dots to indicate the remaining colors available for each cell, in cases when the deductions get complicated enough that I can’t just remember them without marking them. A cell that has dots of only one color rather than a solid color is effectively solved (we know what color it is going to end up being) but might still belong to some unanchored Kempe chains. Once all three Kempe chains through a cell of known color have been anchored, I color that cell as solid. In this way, the parts of the solution that might include unanchored Kempe chains typically remain small and distinctively colored, making the chains easy to spot.</p>

<p style="text-align: center;"><img alt="Screenshot of the map puzzle from Simon Tatham's puzzle collection" src="https://11011110.github.io/blog/assets/2019/map-puzzle-kempe-chain.png"/></p>

<p>The image above shows an example, from one of the hardest built-in difficulty levels of the puzzle (“20x15, 30 regions, Unreasonable”). An orange-brown Kempe chain can be seen in the bottom left, in the two cells colored by orange and brown dots. (Yes, I know these two colors are hard to tell apart; I can’t change them.) Its only escape cell has yellow and brown neighbors, and cannot be green (leaving the orange-brown chain unanchored), so it must be orange. This set of deductions allows us in turn to infer the colors of the other two cells in the chain, and to make them solid (their three Kempe chains all become anchored). The orange escape cell becomes dotted rather than solid, because it is part of a different Kempe chain (colored orange-green) that remains unanchored.</p>

<p style="text-align: center;"><img alt="Screenshot of the map puzzle from Simon Tatham's puzzle collection" src="https://11011110.github.io/blog/assets/2019/map-puzzle-kempe-chain-2.png"/></p>

<p>This extended deduction rule seems to be working well for the puzzles I’ve tried it on. And by obeying the requirement that deductions remain triggered until performed, it gives me confidence that I’m not hiding any usable information by doing my deductions in the wrong order. There is no wrong order: any order in which I make my deductions will eventually lead me to the same state.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/102521934491138847">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2019-07-28T17:19:00Z</updated>
    <published>2019-07-28T17:19:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-07-29T00:38:50Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/098</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/098" rel="alternate" type="text/html"/>
    <title>TR19-098 |  Domain Compression and its Application to Randomness-Optimal Distributed Goodness-of-Fit | 

	Clement Canonne, 

	Jayadev Acharya, 

	Himanshu Tyagi, 

	Ziteng Sun, 

	Yanjun Han</title>
    <summary>We study goodness-of-fit of discrete distributions in the distributed setting, where samples are divided between multiple users who can only release a limited amount of information about their samples due to various information constraints. Recently, a subset of the authors showed that having access to a common random seed (i.e., shared randomness) leads to a significant reduction in the sample complexity of this problem. In this work, we provide a complete understanding of the interplay between the amount of shared randomness available, the stringency of information constraints, and the sample complexity of the testing problem by characterizing a tight trade-off between these three parameters. We provide a general distributed goodness-of-fit protocol that as a function of the amount of shared randomness interpolates smoothly between the private- and public-coin sample complexities. We complement our upper bound with a general framework to prove lower bounds on the sample complexity of this testing problems under limited shared randomness. Finally, we instantiate our bounds for the two archetypal information constraints of communication and local privacy, and show that our sample complexity bounds are optimal as a function of all the parameters of the problem, including the amount of shared randomness.

A key component of our upper bounds is a new primitive of domain compression, a tool that allows us to map distributions to a much smaller domain size while preserving their pairwise distances, using a limited amount of randomness.</summary>
    <updated>2019-07-28T10:17:48Z</updated>
    <published>2019-07-28T10:17:48Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-07-29T09:20:45Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.11209</id>
    <link href="http://arxiv.org/abs/1907.11209" rel="alternate" type="text/html"/>
    <title>Integrality Gap of the Vertex Cover Linear Programming Relaxation</title>
    <feedworld_mtime>1564272000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Singh:Mohit.html">Mohit Singh</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.11209">PDF</a><br/><b>Abstract: </b>We give a characterization result for the integrality gap of the natural
linear programming relaxation for the vertex cover problem. We show that
integrality gap of the standard linear programming relaxation for any graph G
equals $\left(2-\frac{2}{\chi^f(G)}\right)$ where $\chi^f(G)$ denotes the
fractional chromatic number of G.
</p></div>
    </summary>
    <updated>2019-07-28T23:32:06Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.11206</id>
    <link href="http://arxiv.org/abs/1907.11206" rel="alternate" type="text/html"/>
    <title>The Strong 3SUM-INDEXING Conjecture is False</title>
    <feedworld_mtime>1564272000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kopelowitz:Tsvi.html">Tsvi Kopelowitz</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Porat:Ely.html">Ely Porat</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.11206">PDF</a><br/><b>Abstract: </b>In the 3SUM-Indexing problem the goal is to preprocess two lists of elements
from $U$, $A=(a_1,a_2,\ldots,a_n)$ and $B=(b_1,b_2,...,b_n)$, such that given
an element $c\in U$ one can quickly determine whether there exists a pair
$(a,b)\in A \times B$ where $a+b=c$. Goldstein et al.~[WADS'2017] conjectured
that there is no algorithm for 3SUM-Indexing which uses $n^{2-\Omega(1)}$ space
and $n^{1-\Omega(1)}$ query time.
</p>
<p>We show that the conjecture is false by reducing the 3SUM-Indexing problem to
the problem of inverting functions, and then applying an algorithm of Fiat and
Naor [SICOMP'1999] for inverting functions.
</p></div>
    </summary>
    <updated>2019-07-28T23:34:28Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.11078</id>
    <link href="http://arxiv.org/abs/1907.11078" rel="alternate" type="text/html"/>
    <title>Approximating APSP without Scaling: Equivalence of Approximate Min-Plus and Exact Min-Max</title>
    <feedworld_mtime>1564272000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bringmann:Karl.html">Karl Bringmann</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/K=uuml=nnemann:Marvin.html">Marvin Künnemann</a>, Karol Węgrzycki <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.11078">PDF</a><br/><b>Abstract: </b>Zwick's $(1+\varepsilon)$-approximation algorithm for the All Pairs Shortest
Path (APSP) problem runs in time $\widetilde{O}(\frac{n^\omega}{\varepsilon}
\log{W})$, where $\omega \le 2.373$ is the exponent of matrix multiplication
and $W$ denotes the largest weight. This can be used to approximate several
graph characteristics including the diameter, radius, median, minimum-weight
triangle, and minimum-weight cycle in the same time bound.
</p>
<p>Since Zwick's algorithm uses the scaling technique, it has a factor $\log W$
in the running time. In this paper, we study whether APSP and related problems
admit approximation schemes avoiding the scaling technique. That is, the number
of arithmetic operations should be independent of $W$; this is called strongly
polynomial. Our main results are as follows.
</p>
<p>- We design approximation schemes in strongly polynomial time
$O(\frac{n^\omega}{\varepsilon} \text{polylog}(\frac{n}{\varepsilon}))$ for
APSP on undirected graphs as well as for the graph characteristics diameter,
radius, median, minimum-weight triangle, and minimum-weight cycle on directed
or undirected graphs.
</p>
<p>- For APSP on directed graphs we design an approximation scheme in strongly
polynomial time $O(n^{\frac{\omega + 3}{2}} \varepsilon^{-1}
\text{polylog}(\frac{n}{\varepsilon}))$. This is significantly faster than the
best exact algorithm.
</p>
<p>- We explain why our approximation scheme for APSP on directed graphs has a
worse exponent than $\omega$: Any improvement over our exponent $\frac{\omega +
3}{2}$ would improve the best known algorithm for Min-Max Product In fact, we
prove that approximating directed APSP and exactly computing the Min-Max
Product are equivalent.
</p></div>
    </summary>
    <updated>2019-07-28T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.11015</id>
    <link href="http://arxiv.org/abs/1907.11015" rel="alternate" type="text/html"/>
    <title>A new approach (extra vertex) and generalization of Shoelace Algorithm usage in convex polygon (Point-in-Polygon)</title>
    <feedworld_mtime>1564272000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Ochilbek Rakhmanov <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.11015">PDF</a><br/><b>Abstract: </b>In this paper we aim to bring new approach into usage of Shoelace Algorithm
for area calculation in convex polygons on Cartesian coordinate system, with
concentration on point in polygon concept. Generalization of usage of the
concept will be proposed for line segment and polygons. Testing of new method
will be done using Python language. Results of tests show that the new approach
is more effective than the current one.
</p></div>
    </summary>
    <updated>2019-07-28T23:38:38Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-07-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.11010</id>
    <link href="http://arxiv.org/abs/1907.11010" rel="alternate" type="text/html"/>
    <title>Deciding Fast Termination for Probabilistic VASS with Nondeterminism</title>
    <feedworld_mtime>1564272000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Tomáš Brázdil, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chatterjee:Krishnendu.html">Krishnendu Chatterjee</a>, Antonín Kučera, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Novotn=yacute=:Petr.html">Petr Novotný</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Velan:Dominik.html">Dominik Velan</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.11010">PDF</a><br/><b>Abstract: </b>A probabilistic vector addition system with states (pVASS) is a finite state
Markov process augmented with non-negative integer counters that can be
incremented or decremented during each state transition, blocking any behaviour
that would cause a counter to decrease below zero. The pVASS can be used as
abstractions of probabilistic programs with many decidable properties. The use
of pVASS as abstractions requires the presence of nondeterminism in the model.
In this paper, we develop techniques for checking fast termination of pVASS
with nondeterminism.
</p>
<p>That is, for every initial configuration of size n, we consider the worst
expected number of transitions needed to reach a configuration with some
counter negative (the expected termination time). We show that the problem
whether the asymptotic expected termination time is linear is decidable in
polynomial time for a certain natural class of pVASS with nondeterminism.
Furthermore, we show the following dichotomy: if the asymptotic expected
termination time is not linear, then it is at least quadratic, i.e., in
$\Omega(n^2)$.
</p></div>
    </summary>
    <updated>2019-07-28T23:21:47Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-07-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.10984</id>
    <link href="http://arxiv.org/abs/1907.10984" rel="alternate" type="text/html"/>
    <title>Enumerating Range Modes</title>
    <feedworld_mtime>1564272000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sumigawa:Kentaro.html">Kentaro Sumigawa</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chakraborty:Sankardeep.html">Sankardeep Chakraborty</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sadakane:Kunihiko.html">Kunihiko Sadakane</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Satti:Srinivasa_Rao.html">Srinivasa Rao Satti</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.10984">PDF</a><br/><b>Abstract: </b>We consider the range mode problem where given a sequence and a query range
in it, we want to find items with maximum frequency in the range. We give time-
and space- efficient algorithms for this problem. Our algorithms are efficient
for small maximum frequency cases. We also consider a natural generalization of
the problem: the range mode enumeration problem, for which there has been no
known efficient algorithms. Our algorithms have query time complexities which
is linear to the output size plus small terms.
</p></div>
    </summary>
    <updated>2019-07-28T23:36:38Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.10937</id>
    <link href="http://arxiv.org/abs/1907.10937" rel="alternate" type="text/html"/>
    <title>Polylogarithmic-Time Deterministic Network Decomposition and Distributed Derandomization</title>
    <feedworld_mtime>1564272000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Václav Rozhoň, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Ghaffari:Mohsen.html">Mohsen Ghaffari</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.10937">PDF</a><br/><b>Abstract: </b>We present a simple polylogarithmic-time deterministic distributed algorithm
for network decomposition. This improves on a celebrated $2^{O(\sqrt{\log
n})}$-time algorithm of Panconesi and Srinivasan [STOC'93] and settles one of
the long-standing and central questions in distributed graph algorithms. It
also leads to the first polylogarithmic-time deterministic distributed
algorithms for numerous other graph problems, hence resolving several open
problems, including Linial's well-known question about the deterministic
complexity of maximal independent set [FOCS'87].
</p>
<p>Put together with the results of Ghaffari, Kuhn, and Maus [STOC'17] and
Ghaffari, Harris, and Kuhn [FOCS'18], we get a general distributed
derandomization result that implies $\mathsf{P}$-$\mathsf{RLOCAL}$ =
$\mathsf{P}$-$\mathsf{LOCAL}$. That is, for any distributed problem whose
solution can be checked in polylogarithmic-time, any polylogarithmic-time
randomized algorithm can be derandomized to a polylogarithmic-time
deterministic algorithm.
</p>
<p>By known connections, our result leads also to substantially faster
randomized algorithms for a number of fundamental problems including
$(\Delta+1)$-coloring, MIS, and Lov\'{a}sz Local Lemma.
</p></div>
    </summary>
    <updated>2019-07-28T23:31:27Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.10930</id>
    <link href="http://arxiv.org/abs/1907.10930" rel="alternate" type="text/html"/>
    <title>GAMA: A Novel Algorithm for Non-Convex Integer Programs</title>
    <feedworld_mtime>1564272000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Alghassi:Hedayat.html">Hedayat Alghassi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dridi:Raouf.html">Raouf Dridi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tayur:Sridhar.html">Sridhar Tayur</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.10930">PDF</a><br/><b>Abstract: </b>Inspired by the decomposition in the hybrid quantum-classical optimization
algorithm we introduced in <a href="http://export.arxiv.org/abs/1902.04215">arXiv:1902.04215</a>, we propose here a new (fully
classical) approach to solving certain non-convex integer programs using Graver
bases. This method is well suited when (a) the constraint matrix $A$ has a
special structure so that its Graver basis can be computed systematically, (b)
several feasible solutions can also be constructed easily and (c) the objective
function can be viewed as many convex functions quilted together. Classes of
problems that satisfy these conditions include Cardinality Boolean Quadratic
Problems (CBQP), Quadratic Semi-Assignment Problems (QSAP) and Quadratic
Assignment Problems (QAP). Our Graver Augmented Multi-seed Algorithm (GAMA)
utilizes augmentation along Graver basis elements (the improvement direction is
obtained by comparing objective function values) from these multiple initial
feasible solutions. We compare our approach with a best-in-class commercially
available solver (Gurobi). Sensitivity analysis indicates that the rate at
which GAMA slows down as the problem size increases is much lower than that of
Gurobi. We find that for several instances of practical relevance, GAMA not
only vastly outperforms in terms of time to find the optimal solution (by two
or three orders of magnitude), but also finds optimal solutions within minutes
when the commercial solver is not able to do so in 4 or 10 hours (depending on
the problem class) in several cases.
</p></div>
    </summary>
    <updated>2019-07-28T23:31:13Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.10895</id>
    <link href="http://arxiv.org/abs/1907.10895" rel="alternate" type="text/html"/>
    <title>Fast Deterministic Constructions of Linear-Size Spanners and Skeletons</title>
    <feedworld_mtime>1564272000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Elkin:Michael.html">Michael Elkin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Matar:Shaked.html">Shaked Matar</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.10895">PDF</a><br/><b>Abstract: </b>In the distributed setting, the only existing constructions of \textit{sparse
skeletons}, (i.e., subgraphs with $O(n)$ edges) either use randomization or
large messages, or require $\Omega(D)$ time, where $D$ is the hop-diameter of
the input graph $G$. We devise the first deterministic distributed algorithm in
the CONGEST model (i.e., uses small messages) for constructing linear-size
skeletons in time $2^{O(\sqrt{{\log n}\cdot{\log{\log n}}})}$. We can also
compute a linear-size spanner with stretch $polylog(n)$ in low deterministic
polynomial time, i.e., $O(n^\rho)$ for an arbitrarily small constant $\rho &gt;0$,
in the CONGEST model. Yet another algorithm that we devise runs in $O({\log
n})^{\kappa-1}$ time, for a parameter $\kappa=1,2,\dots,$ and constructs an
$O({\log n})^{\kappa-1}$ spanner with $O(n^{1+1/\kappa})$ edges. All our
distributed algorithms are lightweight from the computational perspective,
i.e., none of them employs any heavy computations.
</p></div>
    </summary>
    <updated>2019-07-28T23:28:58Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.10874</id>
    <link href="http://arxiv.org/abs/1907.10874" rel="alternate" type="text/html"/>
    <title>How to Store a Random Walk</title>
    <feedworld_mtime>1564272000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Viola:Emanuele.html">Emanuele Viola</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Weinstein:Omri.html">Omri Weinstein</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yu:Huacheng.html">Huacheng Yu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.10874">PDF</a><br/><b>Abstract: </b>Motivated by storage applications, we study the following data structure
problem: An encoder wishes to store a collection of jointly-distributed files
$\overline{X}:=(X_1,X_2,\ldots, X_n) \sim \mu$ which are \emph{correlated}
($H_\mu(\overline{X}) \ll \sum_i H_\mu(X_i)$), using as little (expected)
memory as possible, such that each individual file $X_i$ can be recovered
quickly with few (ideally constant) memory accesses.
</p>
<p>In the case of independent random files, a dramatic result by \Pat (FOCS'08)
and subsequently by Dodis, \Pat and Thorup (STOC'10) shows that it is possible
to store $\overline{X}$ using just a \emph{constant} number of extra bits
beyond the information-theoretic minimum space, while at the same time decoding
each $X_i$ in constant time. However, in the (realistic) case where the files
are correlated, much weaker results are known, requiring at least
$\Omega(n/poly\lg n)$ extra bits for constant decoding time, even for "simple"
joint distributions $\mu$.
</p>
<p>We focus on the natural case of compressing\emph{Markov chains}, i.e.,
storing a length-$n$ random walk on any (possibly directed) graph $G$. Denoting
by $\kappa(G,n)$ the number of length-$n$ walks on $G$, we show that there is a
succinct data structure storing a random walk using $\lg_2 \kappa(G,n) + O(\lg
n)$ bits of space, such that any vertex along the walk can be decoded in $O(1)$
time on a word-RAM. For the harder task of matching the \emph{point-wise}
optimal space of the walk, i.e., the empirical entropy $\sum_{i=1}^{n-1} \lg
(deg(v_i))$, we present a data structure with $O(1)$ extra bits at the price of
$O(\lg n)$ decoding time, and show that any improvement on this would lead to
an improved solution on the long-standing Dictionary problem. All of our data
structures support the \emph{online} version of the problem with constant
update and query time.
</p></div>
    </summary>
    <updated>2019-07-28T23:29:53Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.10779</id>
    <link href="http://arxiv.org/abs/1907.10779" rel="alternate" type="text/html"/>
    <title>Improved Girth Approximation and Roundtrip Spanners</title>
    <feedworld_mtime>1564272000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chechik:Shiri.html">Shiri Chechik</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liu:Yang_P=.html">Yang P. Liu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rotem:Omer.html">Omer Rotem</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sidford:Aaron.html">Aaron Sidford</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.10779">PDF</a><br/><b>Abstract: </b>In this paper we provide improved algorithms for approximating the girth and
producing roundtrip spanners of $n$-node $m$-edge directed graphs with
non-negative edge lengths. First, for any integer $k \ge 1$, we provide a
deterministic $\tilde{O}(m^{1+ 1/k})$ time algorithm which computes a
$O(k\log\log n)$ multiplicative approximation of the girth and a $O(k\log\log
n)$ multiplicative roundtrip spanner with $\tilde{O}(n^{1+1/k})$ edges. Second,
we provide a randomized $\tilde{O}(m\sqrt{n})$ time algorithm that with high
probability computes a 3-multiplicative approximation to the girth. Third, we
show how to combine these algorithms to obtain for any integer $k \ge 1$ a
randomized algorithm which in $\tilde{O}(m^{1+ 1/k})$ time computes a $O(k\log
k)$ multiplicative approximation of the girth and $O(k \log k)$ multiplicative
roundtrip spanner with high probability.
</p>
<p>The previous fastest algorithms for these problems either ran in All-Pairs
Shortest Paths (APSP) time, i.e. $\tilde{O}(mn)$, or were due Pachocki et al
(SODA 2018) which provided a randomized algorithm that for any integer $k \ge
1$ in time $\tilde{O}(m^{1+1/k})$ computed with high probability a $O(k\log n)$
multiplicative approximation of the girth and a $O(k\log n)$ multiplicative
roundtrip spanners with $\tilde{O}(n^{1+1/k})$ edges. Our first algorithm
removes the need for randomness and improves the approximation factor in
Pachocki et al (SODA 2018), our second is constitutes the first sub-APSP-time
algorithm for approximating the girth to constant accuracy with high
probability, and our third is the first time versus quality trade-offs for
obtaining constant approximations.
</p></div>
    </summary>
    <updated>2019-07-28T23:32:34Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.10707</id>
    <link href="http://arxiv.org/abs/1907.10707" rel="alternate" type="text/html"/>
    <title>Real-time Deformation of Soft Tissue Internal Structure with Surface Profile Variations using Particle System</title>
    <feedworld_mtime>1564272000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhou:Haoyin.html">Haoyin Zhou</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gombos:Eva.html">Eva Gombos</a>, Mehra Golshan, Jayender Jagadeesan <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.10707">PDF</a><br/><b>Abstract: </b>Intraoperative observation of tissue internal structure is often difficult.
Hence, real-time soft tissue deformation is essential for the localization of
tumor and other internal structures. We propose a method to simulate the
internal structural deformations in a soft tissue with surface profile
variations. The deformation simulation utilizes virtual physical particles that
receive interaction forces from the surface and other particles and adjust
their positions accordingly. The proposed method involves two stages. In the
initialization stage, the three-dimensional internal structure of the surface
mesh is uniformly sampled using the particle expansion and attracting-repelling
force models whilst simultaneously building the internal particle connections.
In the simulation stage, under surface profile variations, we simulate the
internal structural deformation based on a deformation force model that uses
the internal particle connections. The main advantage of this method is that it
greatly reduces the computational burden as it only involves simplified
calculations and also does not require generating three-dimensional meshes.
Preliminary experimental results show that the proposed method can handle up to
10,000 particles in 0.3s.
</p></div>
    </summary>
    <updated>2019-07-28T23:38:24Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-07-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://lucatrevisan.wordpress.com/?p=4251</id>
    <link href="https://lucatrevisan.wordpress.com/2019/07/27/three-stories-about-u-c-administration/" rel="alternate" type="text/html"/>
    <title>Three stories about U.C. administration</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">A few months ago, I was delighted to see the University of California holding on to its demands in its negotiations with Elsevier. The U.C. wanted to renegotiate its contract so that, in addition to having access to the subscribed … <a href="https://lucatrevisan.wordpress.com/2019/07/27/three-stories-about-u-c-administration/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>A few months ago, I was delighted to see the University of California <a href="https://www.theatlantic.com/science/archive/2019/03/uc-elsevier-publisher/583909/">holding on to its demands</a> in its negotiations with Elsevier. The U.C. wanted to renegotiate its contract so that, in addition to having access to the subscribed journals, U.C. scholars could publish in them with open access (that is, so that anybody in the world would have free access to the articles written by U.C. scholars).</p>
<p>This seemed like a reasonable model to balance profitability for publishers and open access, but there was no way to agree on it with Elsevier. Meanwhile, U.C. has not renewed its Elsevier subscriptions and Elsevier has cut off access to U.C. libraries.</p>
<p>I was very impressed to see the University of California central administration do something right, so I wondered if this was the kind of portent that is a harbinger of the apocalypse, or just a fluke. Subsequent events suggest the latter.</p>
<p>The University of California has spent a lot of time and money to build a centralized system for job applications and for job applicant review. I was first made aware of this when I chaired the recruiting committee for the Simons Director position. At first we were told that we could solicit applications through the (vastly superior) EECS-built system for job applications and reviews. After the application deadline passed, we were told that, in fact, we could <i>not</i> use the EECS system, and so the already overworked EECS faculty HR person had to manually copy all the data in the central campus system. </p>
<p>The American Mathematical Society has created a wonderfully functional system, called <a href="https://www.mathjobs.org/jobs">Mathjobs</a> where applicants for academic mathematics jobs (ranging from postdocs to professorship) can upload their application material once, and their recommenders can upload their letters once, and then all the universities that the candidate applies to have access to this material. Furthermore, if needed, both applicants and recommenders can tailor-make their material for a particular university or universities, if they want to.</p>
<p>Everybody was living happily, but not ever after, because the U.C. central campus administration decided that <i>everybody</i> in the University of California had to use the centralized system for <i>all</i> jobs. Both the AMS and U.C. mathematicians tried to find a reasonable accommodation, such as allowing the U.C. system to access the letters posted on mathjobs. The campus administration reasoned response was roughly “sucks to be you.” There is more of the story in an <a href="https://www.ams.org/journals/notices/201907/rnoti-p1085.pdf">AMS notices article</a> by the chair of math at U.C. Davis.</p>
<p>Finally, this year <a href="https://www.sfchronicle.com/nation/article/UC-Berkeley-booted-from-U-S-News-World-Report-14189464.php">U.C. Berkeley</a> will not be listed in the US News and World Report rankings because it has submitted wrong data in the past.</p></div>
    </content>
    <updated>2019-07-27T22:06:35Z</updated>
    <published>2019-07-27T22:06:35Z</published>
    <category term="Berkeley"/>
    <category term="things that are terrible"/>
    <category term="University of California"/>
    <author>
      <name>luca</name>
    </author>
    <source>
      <id>https://lucatrevisan.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://lucatrevisan.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://lucatrevisan.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://lucatrevisan.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://lucatrevisan.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>"Marge, I agree with you - in theory. In theory, communism works. In theory." -- Homer Simpson</subtitle>
      <title>in   theory</title>
      <updated>2019-07-29T09:20:16Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-7683541918979097623</id>
    <link href="https://blog.computationalcomplexity.org/feeds/7683541918979097623/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/07/the-advisoradvisee-relationship.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7683541918979097623" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7683541918979097623" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/07/the-advisoradvisee-relationship.html" rel="alternate" type="text/html"/>
    <title>The Advisor/Advisee Relationship</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">I've always felt a strong advisor/advisee relationship is the single most important factor in a successful PhD career. At its best, the advisor works closely with the student to successful research agenda and help mentor them through their graduate career and beyond. The advisor/advisee relationship can feel like a parent/child relationship that lasts an entire career. Nothing gives me more pleasure as an academic than to see the success of my current and former students.<br/>
<br/>
Take your time when picking an advisor. Don't choose an advisor based solely on research area or because they are "famous". Pick the advisor that will best guide you to a successful academic career.<br/>
<br/>
At its worst, a bad advisor/advisee relationship will destroy your graduate career, making you feel miserable, perhaps dropping out of graduate school or worse, particularly if a student doesn't feel like they are being treated fairly.<br/>
<br/>
Two incidents prompted this post. On TCS-Stack Exchange, a student has <a href="https://cstheory.stackexchange.com/questions/42704/single-author-papers-against-my-advisors-will/42711">authorship issues</a> with their advisor. Unfortunately these kinds of incidents happen more often than one suspects. If you can't work it out with the advisor, go talk to someone about it, another faculty, the graduate or department chair, a grad student ombudsperson if your institution has one. We care about our students, and will work hard to resolve problems.<br/>
<br/>
In a much more <a href="https://medium.com/@huixiangvoice/the-hidden-story-behind-the-suicide-phd-candidate-huixiang-chen-236cd39f79d3">tragic event</a>, a student felt it easier to take his own life than feeling that he had to cover up potential academic misconduct. Again, if you ever find yourself in such a situation please reach out. Giving up is never the answer.</div>
    </content>
    <updated>2019-07-25T20:39:00Z</updated>
    <published>2019-07-25T20:39:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-07-29T08:05:13Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16124</id>
    <link href="https://rjlipton.wordpress.com/2019/07/25/discrepancy-games-and-sensitivity/" rel="alternate" type="text/html"/>
    <title>Discrepancy Games and Sensitivity</title>
    <summary>Can we connect the talks that closed this month’s Random Structures and Algorithms conference? Cropped from NYU homepage Joel Spencer gave the closing talk of last week’s Random Structures and Algorithms conference at ETH Zurich. Today we discuss his talk and the one that preceded it, which was by Hao Huang on his proof this […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Can we connect the talks that closed this month’s Random Structures and Algorithms conference?</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2019/07/joelspencerhomepageinrussia.jpg"><img alt="" class="alignright wp-image-16126" height="200" src="https://rjlipton.files.wordpress.com/2019/07/joelspencerhomepageinrussia.jpg?w=137&amp;h=200" width="137"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Cropped from NYU <a href="https://cs.nyu.edu/spencer/">homepage</a></font></td>
</tr>
</tbody>
</table>
<p>
Joel Spencer gave the closing talk of last week’s Random Structures and Algorithms <a href="https://math.ethz.ch/fim/conferences/19th-int-conf-random-structures-algorithms/schedule.html">conference</a> at ETH Zurich.</p>
<p>
Today we discuss his talk and the one that preceded it, which was by Hao Huang on his proof this month of the Boolean sensitivity conjecture.</p>
<p>
Spencer’s <a href="https://ethz.ch/content/dam/ethz/special-interest/math/mathematical-research/fim-dam/Conferences/2019/19th Int Conf on Random Structures and Algorithms/Abstracts/Spencer_Joel.pdf">talk</a> was titled “Four Discrepancies” and based on a joint <a href="https://arxiv.org/pdf/1903.06898.pdf">paper</a> with Nikhil Bhansal. The main new result in the talk was a case where a bound of <img alt="{O(\sqrt{n\log n})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%28%5Csqrt%7Bn%5Clog+n%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{O(\sqrt{n\log n})}"/> arising from reasoning about normal distribution can, surprisingly, be improved to a sharp <img alt="{O(\sqrt{n})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%28%5Csqrt%7Bn%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{O(\sqrt{n})}"/>. </p>
<p>
We will talk about this first, but then progress to the talk that preceded Spencer’s. It was by Hao Huang, who was extended an invitation right after his announced <a href="http://www.mathcs.emory.edu/~hhuan30/papers/sensitivity_1.pdf">proof</a> of the Boolean Sensitivity Conjecture earlier this month. Our ulterior purpose is to ask whether any concrete connections can be found besides both talks addressing problems on the <img alt="{\{-1,+1\}^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B-1%2C%2B1%5C%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{-1,+1\}^n}"/> hypercube.</p>
<p>
</p><p/><h2> Discrepancy Games </h2><p/>
<p/><p>
First suppose you get a stream of single bits <img alt="{v_t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bv_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{v_t}"/>, each <img alt="{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-1}"/> or <img alt="{+1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{+1}"/>. For each bit, you can say “Keep it” or “Flip it.” In the latter case, your bit <img alt="{w_t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{w_t}"/> is <img alt="{-v_t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-v_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-v_t}"/>. Your goal is to keep the sum <img alt="{\sum_{k=1}^t w_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csum_%7Bk%3D1%7D%5Et+w_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\sum_{k=1}^t w_k}"/> within a bounded range. OK, this is easy: you can make the sum always be <img alt="{+1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{+1}"/> when <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t}"/> is odd and <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/> when <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t}"/> is even by flipping when needed.</p>
<p>
Now suppose the bits come in pairs <img alt="{(v_{t,1},v_{t,2})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28v_%7Bt%2C1%7D%2Cv_%7Bt%2C2%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(v_{t,1},v_{t,2})}"/> and your goal is to keep the sum in each coordinate bounded. Again there is a simple strategy: There are four kinds of vectors. For each kind, every time you see it for the second time, flip it. That keeps the contribution of each kind within <img alt="{-1 \ldots +1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-1+%5Cldots+%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-1 \ldots +1}"/> in each coordinate. Thus simple reasoning says each coordinate stays within <img alt="{-4 \ldots +4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-4+%5Cldots+%2B4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-4 \ldots +4}"/>. </p>
<p>
The trouble with extending this idea to vectors of length <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> is that the number of kinds is <img alt="{2^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2^n}"/> and our simple-minded bounds, while constant in terms of the number <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> of vectors given, are exponential in <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>. Well, we can certainly do better. Going back to the <img alt="{n = 2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn+%3D+2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n = 2}"/> case, we can maintain a policy of never letting both coordinates become <img alt="{+2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%2B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{+2}"/> or both become <img alt="{-2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-2}"/>. This keeps both sums within <img alt="{-2 \ldots +2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-2+%5Cldots+%2B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-2 \ldots +2}"/> regardless of the sequence of the vectors. But for larger vector lengths <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>, how large can the <em>discrepancy</em> among the <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> coordinate sums—relative to zero or to each other—become?</p>
<p>
A final help is if we know the number <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> of vectors in any sequence we might be given is bounded. In fact, Spencer’s paper with Bhansal first considers the case <img alt="{T = n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT+%3D+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T = n}"/>. There are two main questions about randomness:</p>
<ol>
<li>
Does it matter whether the sequence of vectors given is random or worst-case? <p/>
</li><li>
Can you do better than choosing “keep” or “flip” randomly?
</li></ol>
<p>
Long back, Spencer <a href="https://cs.nyu.edu/spencer/sixsigma.pdf">proved</a> that if you can see the whole sequence of <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> vectors in advance, then you can always keep the sums within <img alt="{-5.32 \sqrt{n} \ldots +5.32\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-5.32+%5Csqrt%7Bn%7D+%5Cldots+%2B5.32%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-5.32 \sqrt{n} \ldots +5.32\sqrt{n}}"/>, whatever the sequence. If not—if you must decide “keep” or “flip” for each vector before seeing the next—then Spencer had also <a href="https://books.google.com/books?hl=en&amp;lr=&amp;id=HTxo3kP7_5gC&amp;oi=fnd&amp;pg=PP2&amp;dq=Ten+Lectures+on+the+Probabilistic+Method+Spencer&amp;ots=hGDS5tiCgB&amp;sig=qP53Ty3AQgVJF2J4wzcmT948mmY#v=onepage&amp;q=Ten Lectures on the Probabilistic Method Spencer&amp;f=false">proved</a>:</p>
<blockquote><p><b>Theorem 1</b> <em> If an adversary can choose the next vector based on your current sums, then the best bound <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{B}"/> such that you can keep all your sums within absolute value <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{B}"/> grows as <img alt="{\Theta(\sqrt{n\log n})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CTheta%28%5Csqrt%7Bn%5Clog+n%7D%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\Theta(\sqrt{n\log n})}"/>. Moreover, up to the constant in the “<img alt="{\Theta,}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CTheta%2C%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\Theta,}"/>” with high probability you cannot do any better than choosing the sign for each vector randomly. </em>
</p></blockquote>
<p/><p>
See also his famous <a href="https://www.wiley.com/en-us/The+Probabilistic+Method/+4th+Edition-p-9781119061953">book</a>, <em>The Probabilistic Method</em>, with Noga Alon. The new theorem is:</p>
<blockquote><p><b>Theorem 2</b> <em> If the adversary presents vectors uniformly at random, then you <b>can</b> achieve <img alt="{B = O(\sqrt{n})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB+%3D+O%28%5Csqrt%7Bn%7D%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{B = O(\sqrt{n})}"/> with high probability—and not by choosing the signs randomly. </em>
</p></blockquote>
<p/><p>
The algorithm defines a kind of <em>potential function</em> and has you play “keep” or “flip” according to which has the lesser growth in potential. The analysis is quite complicated. As usual we refer to the <a href="https://arxiv.org/pdf/1903.06898.pdf">paper</a> for details. Instead we ask: are there insights to mine here for further advances on the Boolean sensitivity problem?</p>
<p>
</p><p/><h2> Boolean Sensitivity </h2><p/>
<p/><p>
We didn’t talk about Boolean sensitivity in our previous <a href="https://rjlipton.wordpress.com/2019/07/12/tools-and-sensitivity/">post</a> on it. Our purpose now is to convey how many concepts are related, hence how they might connect to discrepancy on the hypercube. </p>
<p>
To get the idea of sensitivity, first consider the parity function <img alt="{f_{\oplus}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_%7B%5Coplus%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_{\oplus}}"/>. If you change one bit of any argument <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> you change the value of <img alt="{f_{\oplus}(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_%7B%5Coplus%7D%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_{\oplus}(x)}"/>. Define <img alt="{x^i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%5Ei%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x^i}"/> to mean <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> with bit <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/> flipped. Then for any <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> and <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/>, <img alt="{f_{\oplus}(x^i) \neq f_{\oplus}(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_%7B%5Coplus%7D%28x%5Ei%29+%5Cneq+f_%7B%5Coplus%7D%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_{\oplus}(x^i) \neq f_{\oplus}(x)}"/>. This means parity is extremely sensitive.</p>
<p>
The OR function <img alt="{f_{\vee}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_%7B%5Cvee%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_{\vee}}"/> is intuitively less sensitive, but it too has an argument <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> such that <img alt="{f_{\vee}(x^i) \neq f_{\vee}(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_%7B%5Cvee%7D%28x%5Ei%29+%5Cneq+f_%7B%5Cvee%7D%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_{\vee}(x^i) \neq f_{\vee}(x)}"/> for all <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/>, namely <img alt="{x = 0^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx+%3D+0%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x = 0^n}"/>. For any Boolean function <img alt="{f: \{0,1\}^n \rightarrow \{0,1\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%3A+%5C%7B0%2C1%5C%7D%5En+%5Crightarrow+%5C%7B0%2C1%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f: \{0,1\}^n \rightarrow \{0,1\}}"/> define its <em>sensitivity</em> (at <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>) by </p>
<p align="center"><img alt="\displaystyle  s(f) = s_n(f) = \max_{x \in \{0,1\}^n} ||\{i: f(x^i) \neq f(x)\}||. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++s%28f%29+%3D+s_n%28f%29+%3D+%5Cmax_%7Bx+%5Cin+%5C%7B0%2C1%5C%7D%5En%7D+%7C%7C%5C%7Bi%3A+f%28x%5Ei%29+%5Cneq+f%28x%29%5C%7D%7C%7C.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  s(f) = s_n(f) = \max_{x \in \{0,1\}^n} ||\{i: f(x^i) \neq f(x)\}||. "/></p>
<p>The OR-of-AND function <img alt="{f_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_2}"/> is less sensitive. Say it is an OR of <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m}"/> blocks, each of <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/> variables, and the blocks use disjoint variables so <img alt="{n = km}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn+%3D+km%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n = km}"/>. If <img alt="{f_2(x) = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_2%28x%29+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_2(x) = 1}"/>, then some block is all <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>, so flipping any other bit makes no difference, and the most sensitive we can get is <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/>. If <img alt="{f_2(x) = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_2%28x%29+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_2(x) = 0}"/> then the most sensitive case is when all blocks have exactly one 0. So <img alt="{s(f_2) = \max\{k,m\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%28f_2%29+%3D+%5Cmax%5C%7Bk%2Cm%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s(f_2) = \max\{k,m\}}"/>. When <img alt="{k = m = \sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk+%3D+m+%3D+%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k = m = \sqrt{n}}"/>, <img alt="{s_n(f) = \sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs_n%28f%29+%3D+%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s_n(f) = \sqrt{n}}"/>.</p>
<p>
If we make each block of <img alt="{f_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_2}"/> return <em>true</em> if exactly one bit is <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>, then we again get sensitivity <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> on the all-<img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/> assignment. Now, however, consider the related function <img alt="{f'_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%27_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f'_2}"/> (with <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/> even, <img alt="{k = 2\ell}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk+%3D+2%5Cell%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k = 2\ell}"/>) that is still an OR over blocks, but each block is true when some consecutive pair <img alt="{x_{2\ell - 1},x_{2\ell}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_%7B2%5Cell+-+1%7D%2Cx_%7B2%5Cell%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x_{2\ell - 1},x_{2\ell}}"/> are both <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/> with all other pairs being both <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/>. Then we can’t do the same trick with the all-<img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/> assignment changing just one bit. So when <img alt="{n = 4\ell^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn+%3D+4%5Cell%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n = 4\ell^2}"/> and <img alt="{m = k = 2\ell}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm+%3D+k+%3D+2%5Cell%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m = k = 2\ell}"/> we again get sensitivity (no more than) <img alt="{\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\sqrt{n}}"/>. </p>
<p>
We can, however, consider <img alt="{f'_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%27_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f'_2}"/> to be more sensitive if we can flip more than one bit at a time. Partition <img alt="{[n]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Bn%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{[n]}"/> into <em>blocks</em> <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B}"/> of two consecutive bit-places each, and given any <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/>, define <img alt="{x^B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%5EB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x^B}"/> to be the result of flipping the bits in <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B}"/>. We get <img alt="{n/2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n/2}"/> blocks, and the all-<img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/> assignment becomes a <em>true</em> case of <img alt="{f'_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%27_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f'_2}"/> if any block is flipped. Generally define the <em>block sensitivity</em> by considering any partitions <img alt="{\mathcal{B} = \{B_j\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BB%7D+%3D+%5C%7BB_j%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{B} = \{B_j\}}"/> of <img alt="{[n]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Bn%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{[n]}"/> into disjoint subsets and writing </p>
<p align="center"><img alt="\displaystyle  bs(f) = \max_{x,\mathcal{B}} ||\{j: f(x^{B_j}) \neq f(x)\}||. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++bs%28f%29+%3D+%5Cmax_%7Bx%2C%5Cmathcal%7BB%7D%7D+%7C%7C%5C%7Bj%3A+f%28x%5E%7BB_j%7D%29+%5Cneq+f%28x%29%5C%7D%7C%7C.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  bs(f) = \max_{x,\mathcal{B}} ||\{j: f(x^{B_j}) \neq f(x)\}||. "/></p>
<p>Note that not every member of the partition has to flip the function—we can discard the ones that don’t flip and count only the disjoint subsets that do flip the value. So back to our example, we have </p>
<p align="center"><img alt="\displaystyle  bs(f'_2) = \frac{n}{2} = \frac{1}{2}s(f'_2)^2. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++bs%28f%27_2%29+%3D+%5Cfrac%7Bn%7D%7B2%7D+%3D+%5Cfrac%7B1%7D%7B2%7Ds%28f%27_2%29%5E2.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  bs(f'_2) = \frac{n}{2} = \frac{1}{2}s(f'_2)^2. "/></p>
<p>Andris Ambainis and Xiaoming Sun <a href="https://arxiv.org/abs/1108.3494">improved</a> the constant from <img alt="{\frac{1}{2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B1%7D%7B2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\frac{1}{2}}"/> asymptotically to <img alt="{\frac{2}{3}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B2%7D%7B3%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\frac{2}{3}}"/>, but their relation is still quadratic.</p>
<p>
</p><p/><h2> Some Boolean Complexity Connections </h2><p/>
<p/><p>
This <a href="https://link.springer.com/article/10.1007/BF01200762">example</a> of quadratic discrepancy is still the best known lower bound on <img alt="{bs(f)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bbs%28f%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{bs(f)}"/> in terms of <img alt="{s(f)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%28f%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s(f)}"/>. But no one had proved anything better than an exponential upper bound until Huang’s result, from which it follows that:</p>
<blockquote><p><b>Theorem 3</b> <em><a name="Huang"/> For all Boolean functions <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{f}"/>, <img alt="{bs(f) \leq 2s(f)^4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bbs%28f%29+%5Cleq+2s%28f%29%5E4%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{bs(f) \leq 2s(f)^4}"/>. </em>
</p></blockquote>
<p/><p>
This bound is concrete, not just asymptotic. It still leaves a gap between quadratic and quartic. It is, however, the combination of two quadratic upper bounds. One was shown by Nisan and Szegedy in their <a href="https://www.researchgate.net/publication/2508255_On_the_Degree_of_Boolean_Functions_as_Real_Polynomials">paper</a>: </p>
<p align="center"><img alt="\displaystyle  bs(f) \leq 2\deg(f)^2, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++bs%28f%29+%5Cleq+2%5Cdeg%28f%29%5E2%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  bs(f) \leq 2\deg(f)^2, "/></p>
<p>where <img alt="{\deg(f)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdeg%28f%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\deg(f)}"/> means the degree of the unique multi-linear real polynomial that agrees with <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/> on the cube <img alt="{\{-1,1\}^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B-1%2C1%5C%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{-1,1\}^n}"/> with <img alt="{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-1}"/> for <em>true</em>. The other is the conjecture </p>
<p align="center"><img alt="\displaystyle  \deg(f) \leq s(f)^2 " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cdeg%28f%29+%5Cleq+s%28f%29%5E2+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \deg(f) \leq s(f)^2 "/></p>
<p>in a 1992 <a href="https://www.sciencedirect.com/science/article/pii/0097316592900608">paper</a> by Craig Gotsman and Nati Linial. Huang proved this by exploiting a connection to graphs that was also shown by Gotsman and Linial. Consider any red-or-white coloring of the <img alt="{2^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2^n}"/> nodes of the hypercube, let <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> be the graph induced by the red nodes, and define <img alt="{g(x) = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%28x%29+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{g(x) = 1}"/> if node <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> is red, <img alt="{g(x) = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%28x%29+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{g(x) = 0}"/> otherwise. Now if the maximum degree <img alt="{d(G)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d(G)}"/> of a node in <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> is small then every red node has many white neighbors, so the Boolean function <img alt="{g}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{g}"/> is very sensitive. However, going to each neighbor in the hypercube flips the parity. Hence the function </p>
<p align="center"><img alt="\displaystyle  g'(x) = g(x) \oplus f_{\oplus}(x) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++g%27%28x%29+%3D+g%28x%29+%5Coplus+f_%7B%5Coplus%7D%28x%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  g'(x) = g(x) \oplus f_{\oplus}(x) "/></p>
<p>is <b>not</b> very sensitive. Moreover, it has the same sensitivity as the function <img alt="{h'(x) = h(x) \oplus f_{\oplus}(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bh%27%28x%29+%3D+h%28x%29+%5Coplus+f_%7B%5Coplus%7D%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{h'(x) = h(x) \oplus f_{\oplus}(x)}"/> where <img alt="{h(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bh%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{h(x)}"/> is true on the white nodes. This nice duality between <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> and the graph <img alt="{H}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{H}"/> induced by the white nodes enables us to fix “<img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/>” to mean whichever of the two has more nodes in the following theorem statement: </p>
<blockquote><p><b>Theorem 4</b> <em> Provided <img alt="{m &gt; 2^{n-1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm+%3E+2%5E%7Bn-1%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{m &gt; 2^{n-1}}"/>, every graph <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{G}"/> induced by <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{m}"/> nodes of the <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n}"/>-cube has <img alt="{d(G) \geq \sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%28G%29+%5Cgeq+%5Csqrt%7Bn%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{d(G) \geq \sqrt{n}}"/> if and only if every Boolean function <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{f}"/> has <img alt="{\deg(f) \leq s(f)^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdeg%28f%29+%5Cleq+s%28f%29%5E2%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\deg(f) \leq s(f)^2}"/>. </em>
</p></blockquote>
<p/><p>
The proof uses some Fourier analysis with <img alt="{f = g'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf+%3D+g%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f = g'}"/> as above. It, too, takes only one page of a really short paper. </p>
<p>
The main open question now is whether the 4th-power upper bound in Huang’s theorem <a href="https://rjlipton.wordpress.com/feed/#Huang">3</a> can be improved to quadratic. It is possible that a deeper application of Fourier analysis may show that cases of quadratic separation from <em>block-sensitivity</em> to <em>degree</em> and <em>degree</em> to <em>sensitivity</em> cannot “amplify” any more than quadratic. This is where there might be some commonality with discrepancy. </p>
<p>
There is a much wider suite of Boolean complexity measures besides <img alt="{s(f)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%28f%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s(f)}"/>, <img alt="{bs(f)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bbs%28f%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{bs(f)}"/>, and <img alt="{\deg(f)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdeg%28f%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\deg(f)}"/> discussed here. For example, consider how many bits of <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> you need to fix in order to preserve the value <img alt="{f(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(x)}"/>. That is, define <img alt="{C(f)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%28f%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C(f)}"/> to be the maximum over <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> of the minimum size of a set <img alt="{I \subseteq [n]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BI+%5Csubseteq+%5Bn%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{I \subseteq [n]}"/> such that whenever <img alt="{x'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x'}"/> agrees with <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> on <img alt="{I}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BI%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{I}"/>, <img alt="{f(x') = f(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28x%27%29+%3D+f%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(x') = f(x)}"/>. Clearly <img alt="{I}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BI%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{I}"/> needs to include at least one bit from each <img alt="{B_j.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB_j.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B_j.}"/> This proves <img alt="{C(f) \geq bs(f)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%28f%29+%5Cgeq+bs%28f%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C(f) \geq bs(f)}"/>. There are many other relations that might be improved. We end by considering ways of broadening Huang’s techniques.</p>
<p>
</p><p/><h2> Weak Adjacency Matrices </h2><p/>
<p/><p>
We—that is Ken and I—have been thinking about how to build on Huang’s proof. We take a somewhat more-general approach compared to the paper and Ken’s <a href="https://rjlipton.wordpress.com/2019/07/12/tools-and-sensitivity/">post</a>.</p>
<blockquote><p><b>Definition 5</b> <em> Let <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{G}"/> be a graph on <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n}"/> vertices. The <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n}"/> by <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n}"/> matrix <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{A}"/> is a <b>weak adjacency</b> matrix of <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{G}"/> provided </em></p><em>
<ol>
<li>
Every entry <img alt="{A_{x,y}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_%7Bx%2Cy%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{A_{x,y}}"/> is bounded by <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{1}"/> in absolute value; <p/>
</li><li>
For all <img alt="{x,y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%2Cy%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{x,y}"/> if <img alt="{x \rightarrow y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx+%5Crightarrow+y%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{x \rightarrow y}"/> is not an edge in <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{G}"/>, then <img alt="{A_{x,y}=0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_%7Bx%2Cy%7D%3D0%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{A_{x,y}=0}"/>.
</li></ol>
</em><p><em/>
</p></blockquote>
<p/><p>
As usual the maximum degree of <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> is denoted by <img alt="{\deg(G)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdeg%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\deg(G)}"/>. The following is almost the same proof as the classic result on adjacency matrices. </p>
<blockquote><p><b>Lemma 6 (H-Lemma)</b> <em> Suppose that <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{A}"/> is a weak adjacency matrix of <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{G}"/>. Then if <img alt="{\lambda}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\lambda}"/> is an eigenvalue of <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{A}"/>, 	</em></p><em>
<p align="center"><img alt="\displaystyle  | \lambda | \le \deg(G). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7C+%5Clambda+%7C+%5Cle+%5Cdeg%28G%29.+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="\displaystyle  | \lambda | \le \deg(G). "/></p>
</em><p><em/>
</p></blockquote>
<p/><p>
<em>Proof:</em>  By the definition of eigenvalue, there is some non-zero vector <img alt="{v}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bv%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{v}"/> so that <img alt="{Av = \lambda v}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BAv+%3D+%5Clambda+v%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Av = \lambda v}"/>. Let <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/> be an index so that <img alt="{|v_{k}|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7Cv_%7Bk%7D%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|v_{k}|}"/> maximum. Then 	</p>
<p align="center"><img alt="\displaystyle  |\lambda v_{k}| =|(A v)_{k}|= \left|\sum_{y=1}^{n} A_{k,y}v_{y} \right| \leq \sum_{y=1}^{n} |A_{k,y}| \cdot |v_{k}|. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7C%5Clambda+v_%7Bk%7D%7C+%3D%7C%28A+v%29_%7Bk%7D%7C%3D+%5Cleft%7C%5Csum_%7By%3D1%7D%5E%7Bn%7D+A_%7Bk%2Cy%7Dv_%7By%7D+%5Cright%7C+%5Cleq+%5Csum_%7By%3D1%7D%5E%7Bn%7D+%7CA_%7Bk%2Cy%7D%7C+%5Ccdot+%7Cv_%7Bk%7D%7C.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  |\lambda v_{k}| =|(A v)_{k}|= \left|\sum_{y=1}^{n} A_{k,y}v_{y} \right| \leq \sum_{y=1}^{n} |A_{k,y}| \cdot |v_{k}|. "/></p>
<p>But then the last sum is upper bounded by 	</p>
<p align="center"><img alt="\displaystyle  D|v_{k}|, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++D%7Cv_%7Bk%7D%7C%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  D|v_{k}|, "/></p>
<p>where <img alt="{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D}"/> is the number of <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y}"/> so that <img alt="{A_{k,y}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_%7Bk%2Cy%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_{k,y}}"/> is not zero. This uses property (1) of the definition of a weak adjacency matrix. Property (2) implies that <img alt="{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D}"/> is at most the degree of vertex <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/> is <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/>. Thus 	</p>
<p align="center"><img alt="\displaystyle  |\lambda v_{k}| \leq D |v_{k}| \leq \deg(G) |v_{k}|. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7C%5Clambda+v_%7Bk%7D%7C+%5Cleq+D+%7Cv_%7Bk%7D%7C+%5Cleq+%5Cdeg%28G%29+%7Cv_%7Bk%7D%7C.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  |\lambda v_{k}| \leq D |v_{k}| \leq \deg(G) |v_{k}|. "/></p>
<p>Dividing by <img alt="{|v_{k}|&gt;0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7Cv_%7Bk%7D%7C%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|v_{k}|&gt;0}"/> yields the lemma. <img alt="\Box" class="latex" src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Box"/></p>
<p>
Let <img alt="{G-k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG-k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G-k}"/> be the graph that results after we delete the vertex <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/> from <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/>. Let <img alt="{A-k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA-k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A-k}"/> be the matrix that results after we delete the column and row <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/> from <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/>. </p>
<blockquote><p><b>Lemma 7</b> <em> Suppose that <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{A}"/> is a weak adjacency matrix of <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{G}"/>. Then for any vertex <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{k}"/>, <img alt="{A-k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA-k%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{A-k}"/> is a weak adjacency matrix of <img alt="{G-k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG-k%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{G-k}"/>. </em>
</p></blockquote>
<p/><p>
<em>Proof:</em>  The bound on the entries of <img alt="{A-k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA-k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A-k}"/> is immediate. Whenever <img alt="{G-k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG-k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G-k}"/> has no edge from <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> to <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y}"/>, then <img alt="{(A-k)_{x,y}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28A-k%29_%7Bx%2Cy%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(A-k)_{x,y}}"/> must be zero. <img alt="\Box" class="latex" src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Box"/></p>
<blockquote><p><b>Lemma 8</b> <em> Suppose that <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{G}"/> a <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n}"/>-graph has a real symmetric weak adjacency matrix <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{A}"/> with <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{m}"/> of the top eigenvalues greater than <img alt="{B \ge 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB+%5Cge+0%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{B \ge 0}"/>. Then every induced subgraph <img alt="{H}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{H}"/> of <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{G}"/> with at least <img alt="{n-m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn-m%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n-m}"/> vertices has degree at least <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{B}"/>. </em>
</p></blockquote>
<p>
</p><blockquote><p><b>Definition 9</b> <em> The <b>hypercube</b> <img alt="{C_{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_%7Bn%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{C_{n}}"/> is the graph on <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n}"/> bit vectors so that two vertices are adjacent if they differ in one bit position. </em>
</p></blockquote>
<p>
</p><blockquote><p><b>Theorem 10</b> <em> The hypercube <img alt="{C_{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_%7Bn%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{C_{n}}"/> has a real symmetric weak adjacency matrix with all its eigenvalues <img alt="{\pm \sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpm+%5Csqrt%7Bn%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\pm \sqrt{n}}"/>. </em>
</p></blockquote>
<p/><p>
<em>Proof:</em>  Let <img alt="{A_{1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_%7B1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_{1}}"/> be 	</p>
<p align="center"><img alt="\displaystyle  \begin{bmatrix}   0 &amp; 1 \\   1 &amp; 0  \end{bmatrix}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Bbmatrix%7D+%09%090+%26+1+%5C%5C+%09%091+%26+0+%09%5Cend%7Bbmatrix%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \begin{bmatrix}   0 &amp; 1 \\   1 &amp; 0  \end{bmatrix}. "/></p>
<p>and <img alt="{A_{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_{n}}"/> be 	</p>
<p align="center"><img alt="\displaystyle  \begin{bmatrix}   A_{n-1} &amp; I \\   I &amp; -A_{n-1}  \end{bmatrix}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Bbmatrix%7D+%09%09A_%7Bn-1%7D+%26+I+%5C%5C+%09%09I+%26+-A_%7Bn-1%7D+%09%5Cend%7Bbmatrix%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \begin{bmatrix}   A_{n-1} &amp; I \\   I &amp; -A_{n-1}  \end{bmatrix}. "/></p>
<p>
Induction shows that <img alt="{A_{n}^{2} = nI}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_%7Bn%7D%5E%7B2%7D+%3D+nI%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_{n}^{2} = nI}"/>. It follows that 	</p>
<p align="center"><img alt="\displaystyle  A_{n}x = \lambda x, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++A_%7Bn%7Dx+%3D+%5Clambda+x%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  A_{n}x = \lambda x, "/></p>
<p>implies that 	</p>
<p align="center"><img alt="\displaystyle  nx = \lambda Ax. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++nx+%3D+%5Clambda+Ax.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  nx = \lambda Ax. "/></p>
<p>Thus 	</p>
<p align="center"><img alt="\displaystyle  nx = \lambda^{2}x. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++nx+%3D+%5Clambda%5E%7B2%7Dx.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  nx = \lambda^{2}x. "/></p>
<p>So the eigenvalues are <img alt="{\pm \sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpm+%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\pm \sqrt{n}}"/> and by trace same number of each.</p>
<p>
The upper-left and lower-right blocks of <img alt="{A_{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_{n}}"/> correspond to the two <img alt="{n-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n-1}"/> dimensional subcubes of <img alt="{C_{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_{n}}"/>, and the two identity blocks correspond to the perfect matching connecting these two subcubes. So <img alt="{A_{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_{n}}"/> is a weak adjacency matrix for <img alt="{C_{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_{n}}"/>. <img alt="\Box" class="latex" src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Box"/></p>
<blockquote><p><b>Corollary 11</b> <em> Every induced subgraph <img alt="{H}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{H}"/> of <img alt="{C_{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_%7Bn%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{C_{n}}"/> with at least <img alt="{2^{n-1}+1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5E%7Bn-1%7D%2B1%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{2^{n-1}+1}"/> vertices has degree at least <img alt="{\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7Bn%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\sqrt{n}}"/>. </em>
</p></blockquote>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Can the last two talks at the conference be further connected?</p>
<p/></font></font></div>
    </content>
    <updated>2019-07-25T20:35:29Z</updated>
    <published>2019-07-25T20:35:29Z</published>
    <category term="All Posts"/>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="Open Problems"/>
    <category term="People"/>
    <category term="Proofs"/>
    <category term="algoritrhms"/>
    <category term="Boolean functions"/>
    <category term="Boolean sensitivity conjecture"/>
    <category term="discrepancy"/>
    <category term="Hao Huang"/>
    <category term="hypercube"/>
    <category term="Joel Spencer"/>
    <category term="Nihkil Bhansal"/>
    <category term="randomized algorithms"/>
    <category term="randomness"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-07-29T09:20:59Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=17669</id>
    <link href="https://gilkalai.wordpress.com/2019/07/25/tyi-39-can-a-coalition-of-children-guarantees-being-in-the-same-class/" rel="alternate" type="text/html"/>
    <title>TYI 39 : Can a coalition of children guarantees all being in the same class?</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">There is a class of children that have just finished elementary school. Now they all move from elementary school to high school and classes are reshuffled. Each child lists three friends, and the assignment of children into classes ensures that … <a href="https://gilkalai.wordpress.com/2019/07/25/tyi-39-can-a-coalition-of-children-guarantees-being-in-the-same-class/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="https://gilkalai.files.wordpress.com/2019/07/class_school.jpg"><img alt="" class="alignnone size-medium wp-image-17676" height="213" src="https://gilkalai.files.wordpress.com/2019/07/class_school.jpg?w=300&amp;h=213" width="300"/></a></p>
<p>There is a class of children that have just finished elementary school. Now they all move from elementary school to high school and classes are reshuffled. Each child lists three friends, and the assignment of children into classes ensures that each child will have at least one of these three friends in his class.</p>
<p>One of the children heard from five of his schoolmates that they found that they can make their selections in a way that will ensure that all five will be assigned to the same class!</p>
<h3><span style="color: #993366;">Test your intuition: Is there a strategy for five of the children that will ensure that all five will be assigned to the same class?</span></h3>
<p>Can a larger group of children coordinate their choices to ensure that they will all necessarily be assigned to the same class?</p>
<a name="pd_a_10371327"/><div class="CSS_Poll PDS_Poll" id="PDI_container10371327" style="display: inline-block;"/><div id="PD_superContainer"/><noscript>&lt;a href="https://polldaddy.com/p/10371327" target="_blank"&gt;Take Our Poll&lt;/a&gt;</noscript>
<p><span id="more-17669"/></p>
<p><strong>Bonus question:</strong> In case that every child lists only two friends and one of them is guaranteed to be in the same class. Is there a strategy of five children that will ensure they are in the same class?</p>
<p><strong>Answer to Bonus question</strong>: Yes. For three children you let every one choose the other two. For the remaining children you let each one choose two among the three.</p></div>
    </content>
    <updated>2019-07-25T12:59:05Z</updated>
    <published>2019-07-25T12:59:05Z</published>
    <category term="Combinatorics"/>
    <category term="Economics"/>
    <category term="Mathematics to the rescue"/>
    <category term="Test your intuition"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-07-29T09:20:52Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/097</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/097" rel="alternate" type="text/html"/>
    <title>TR19-097 |  Reversible Pebble Games and the Relation Between Tree-Like and General Resolution Space | 

	Florian Wörz, 

	Jacobo Toran</title>
    <summary>We show a new connection between the space measure in tree-like resolution and the reversible pebble game in graphs. Using this connection we provide several formula classes for which there is a logarithmic factor separation between the space complexity measure in tree-like and general resolution. We show that these separations are almost optimal by proving upper bounds for tree-like resolution space in terms of general resolution clause and variable space. In particular we show that for any formula F, its tree-like resolution is upper bounded by space(?)log time(?) where ? is any general resolution refutation of F. This holds considering as space(?) the clause space of the refutation as well as considering its variable space. For the concrete case of Tseitin formulas we are able to improve this bound to the optimal bound space(?)log(n), where n is the number of vertices of the corresponding graph.</summary>
    <updated>2019-07-24T12:09:27Z</updated>
    <published>2019-07-24T12:09:27Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-07-29T09:20:46Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/096</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/096" rel="alternate" type="text/html"/>
    <title>TR19-096 |  On the $\text{AC}^0[\oplus]$ complexity of Andreev&amp;#39;s Problem | 

	Aditya Potukuchi</title>
    <summary>Andreev's Problem asks the following: Given an integer $d$ and a subset of $S \subseteq \mathbb{F}_q \times \mathbb{F}_q$, is there a polynomial $y = p(x)$ of degree at most $d$ such that  for every $a \in \mathbb{F}_q$, $(a,p(a)) \in S$? We show an $\text{AC}^0[\oplus]$ lower bound for this problem. 

This problem appears to be similar to the list recovery problem for degree $d$-Reed-Solomon codes over $\mathbb{F}_q$ which asks the following: Given subsets $A_1,\ldots,A_q$ of $\mathbb{F}_q$, output all (if any) Reed-Solomon codewords contained in $A_1\times \cdots \times A_q$. For our purpose, we study this problem when $A_1, \ldots, A_q$ are random subsets of a given size, which may be of independent interest.</summary>
    <updated>2019-07-23T17:29:25Z</updated>
    <published>2019-07-23T17:29:25Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-07-29T09:20:46Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=17642</id>
    <link href="https://gilkalai.wordpress.com/2019/07/23/matan-harel-frank-mousset-and-wojciech-samotij-and-the-the-infamous-upper-tail-problem/" rel="alternate" type="text/html"/>
    <title>Matan Harel, Frank Mousset, and Wojciech Samotij and the “the infamous upper tail” problem</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Let me report today on a major breakthrough in random graph theory and probabilistic combinatorics. Congratulations to Matan, Frank, and Vojtek! Artist: Heidi Buck. “Catch a Dragon by the Tail 2” ( source ) Upper tails via high moments and entropic … <a href="https://gilkalai.wordpress.com/2019/07/23/matan-harel-frank-mousset-and-wojciech-samotij-and-the-the-infamous-upper-tail-problem/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Let me report today on a major breakthrough in random graph theory and probabilistic combinatorics. Congratulations to Matan, Frank, and Vojtek!</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/07/dragon_tail_2_web.png"><img alt="" class="alignnone size-full wp-image-17644" height="496" src="https://gilkalai.files.wordpress.com/2019/07/dragon_tail_2_web.png?w=640&amp;h=496" width="640"/></a></p>
<p>Artist: Heidi Buck.<strong><span style="color: #ff0000;"> “Catch a Dragon by the Tail 2”</span></strong> ( <a href="https://www.hbdragon.com/main/content/catch-dragon-tail-2">source</a> )</p>
<p class="title mathjax"><a href="https://arxiv.org/abs/1904.08212">Upper tails via high moments and entropic stability</a> by Matan Harel, Frank Mousset, and Wojciech Samotij</p>
<p><strong>Abstract:</strong></p>
<p>Suppose that <em>X</em> is a bounded-degree polynomial with nonnegative coefficients on the <em>p</em>-biased discrete hypercube. Our main result gives sharp estimates on the logarithmic upper tail probability of X whenever an associated extremal problem satisfies a certain entropic stability property. We apply this result to solve two long-standing open problems in probabilistic combinatorics: the upper tail problem for the number of arithmetic progressions of a fixed length in the <em>p</em>-random subset of the integers and the upper tail problem for the number of cliques of a fixed size in the random graph <img alt="G_{n,p}" class="latex" src="https://s0.wp.com/latex.php?latex=G_%7Bn%2Cp%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G_{n,p}"/>. We also make significant progress on the upper tail problem for the number of copies of a fixed regular graph <em>H</em> in <img alt="G_{n,p}." class="latex" src="https://s0.wp.com/latex.php?latex=G_%7Bn%2Cp%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G_{n,p}."/> To accommodate readers who are interested in learning the basic method, we include a short, self-contained solution to the upper tail problem for the number of triangles in <img alt="G_{n,p}" class="latex" src="https://s0.wp.com/latex.php?latex=G_%7Bn%2Cp%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G_{n,p}"/> for all <em>p=p(n)</em> satisfying <img alt="\frac {\log n}{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cfrac+%7B%5Clog+n%7D%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\frac {\log n}{n}"/> <img alt="\ll" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cll&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\ll"/> <img alt="p \ll 1" class="latex" src="https://s0.wp.com/latex.php?latex=p+%5Cll+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p \ll 1"/>.</p>
<p>The introduction does a very nice job of presenting the rich history of the problem.  Here is a 2002 paper by Svante Janson and Andrzej Ruciński on <a href="https://onlinelibrary.wiley.com/doi/pdf/10.1002/rsa.10031?casa_token=7FoHUVq0w5IAAAAA:AqmK_4tpjDzXErWnGh4qnE2kn4NTupyoW27eSXW7Uwr5l0JgpBP5SG7PaVnJ6Lvr4JhCaSIH2HPv-QTsUg">the infamous upper tail</a>.  (And a lot has happened since then with regard to this problem and on non linear large deviation theory). Following, there is a lovely section with a short solution for the case of triangles.</p>
<p>Forthcoming reference [48] talks about lower tails! Stay tuned!</p></div>
    </content>
    <updated>2019-07-23T06:51:02Z</updated>
    <published>2019-07-23T06:51:02Z</published>
    <category term="Combinatorics"/>
    <category term="Probability"/>
    <category term="Frank Mousset"/>
    <category term="Matan Harel"/>
    <category term="Wojciech Samotij"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-07-29T09:20:50Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-7828284719883166611</id>
    <link href="https://blog.computationalcomplexity.org/feeds/7828284719883166611/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/07/answer-to-both-infinite-hats-problems.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7828284719883166611" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7828284719883166611" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/07/answer-to-both-infinite-hats-problems.html" rel="alternate" type="text/html"/>
    <title>Answer to both Infinite Hats Problems from the last post</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><br/>
(This is a joint post with David Marcus. You'll see why later.)<br/>
<br/>
In a prior  I posed two infinite hat problems. Today I post the solutions. Actually this is a copy of my last post with the solutions added, so it is self contained.<br/>
<br/>
A Hat Problem that you have probably seen:<br/>
<br/>
1) There are an infinite number of people, numbered 1,2,3,...  There are 2 colors of hats. They can all see everyone's hat but their own. <br/>
<br/>
2) The adversary is going to put hats on all the people. They will guess their own hat color<i> at the same time</i>. <br/>
<br/>
3) The people can discuss strategy ahead of time, but must use a deterministic strategy and the adversary knows the strategy.<br/>
<br/>
4) The people want to minimize how many they get wrong. <br/>
<br/>
5) The adversary puts on hats to maximize how many they get wrong.<br/>
<br/>
I ask two questions (the answers are in a document I point to) and one meta-question:<br/>
<br/>
Q1: Is there a solution where they get all but a finite number of the guesses right? (If you have read my prior post on hat puzzles, <a href="https://blog.computationalcomplexity.org/2017/07/two-hat-problems-you-may-or-may-not.html">here</a> then you can do this one.) <br/>
<br/>
Q2: Is there a solution where they get all but at most (say) 18 wrong.<br/>
<br/>
<br/>
Answers to Q1 and Q2 are <a href="https://www.cs.umd.edu/users/gasarch/BLOGPAPERS/infinitehats.pdf">here</a>.<br/>
<br/>
How did I get into this problem? I was looking at hat problems a while back. Then  I began discussing Q1 and Q2 by email  (Does the term <i>discussing</i> have as a default that it is by email?) with David Marcus who had just read the chapter of <a href="https://www.amazon.com/Problems-Point-Exploring-Computer-Science/dp/9813279974">Problems with a Point</a> on hat puzzles. After a few emails back and fourth, he began looking on the web for answers. He found one. There is a website of hat puzzles! It was MY website papers on  Hat Puzzles! It is  <a href="https://www.cs.umd.edu/users/gasarch/TOPICS/hats/hats.html">here</a>. And on it was a relevant paper <a href="https://www.cs.umd.edu/users/gasarch/TOPICS/hats/infinite-hats-and-ac.pdf">here</a>. We did not find any other source of the problem or its solution. <br/>
<br/>
Q3: How well known is problem Q2 and the solution?  I've seen Q1 around but the only source on Q2 that I know of is that paper, and now this blog post. So, please leave a comment telling me if you have seen Q2 and/or the solution someplace else, and if so where.<br/>
<br/>
The responses to my last post indicated that YES the problem was out there, but the proof that you could not get all-but-18 was not well known. <br/>
<br/>
I THINK that all of the proofs that you can't do all-but-18 in the comment of the last post were essentially the same as the solution I pointed to in this blog. I would be interested if there is an alternative proof. <br/></div>
    </content>
    <updated>2019-07-22T03:00:00Z</updated>
    <published>2019-07-22T03:00:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-07-29T08:05:13Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/095</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/095" rel="alternate" type="text/html"/>
    <title>TR19-095 |  Unambiguous Catalytic Computation | 

	Chetan Gupta, 

	Rahul Jain, 

	Vimal Raj Sharma, 

	Raghunath Tewari</title>
    <summary>The catalytic Turing machine is a model of computation defined by Buhrman, Cleve,
Kouck, Loff, and Speelman (STOC 2014). Compared to the classical space-bounded Turing
machine, this model has an extra space which is filled with arbitrary content in addition
to the clean space. In such a model we study if this additional filled space can be used to
increase the power of computation or not, with the condition that the initial content of this
extra filled space must be restored at the end of the computation.
In this paper, we define the notion of unambiguous catalytic Turing machine and prove
that under a standard derandomization assumption, the class of problems solved by an
unambiguous catalytic Turing machine is same as the class of problems solved by a general
nondeterministic catalytic Turing machine in the logspace setting.</summary>
    <updated>2019-07-21T11:21:02Z</updated>
    <published>2019-07-21T11:21:02Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-07-29T09:20:46Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=17574</id>
    <link href="https://gilkalai.wordpress.com/2019/07/20/isabella-novik-and-hailun-zheng-neighborly-centrally-symmetric-spheres-exist-in-all-dimensions/" rel="alternate" type="text/html"/>
    <title>Isabella Novik and Hailun Zheng: Neighborly centrally symmetric spheres exist in all dimensions!</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">A tweet-long summary: The cyclic polytope is wonderful and whenever we construct an analogous object we are happy. Examples: Neighborly cubic polytopes; The amplituhedron; and as of last week, the Novik-Zheng new construction of neighborly centrally symmetric spheres! At last: … <a href="https://gilkalai.wordpress.com/2019/07/20/isabella-novik-and-hailun-zheng-neighborly-centrally-symmetric-spheres-exist-in-all-dimensions/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><span style="color: #0000ff;">A tweet-long summary: The cyclic polytope is wonderful and whenever we construct an analogous object we are happy. Examples: Neighborly cubic polytopes; The amplituhedron; and as of last week, the Novik-Zheng new construction of neighborly centrally symmetric spheres!</span></p>
<h2>At last: Neighborly CS spheres!</h2>
<p>The news: Isabella Novik and Hailun Zheng’ paper  <a href="https://arxiv.org/abs/1907.06115">Highly neighborly centrally symmetric spheres</a>, resolves an old standing problem in this field.</p>
<p>Here is the abstract:</p>
<blockquote><p>In 1995, Jockusch constructed an infinite family of centrally symmetric 3-dimensional simplicial spheres that are cs-<em>2</em>-neighborly. Here we generalize his construction and show that for all d ≥ 4 and n ≥ d, there exists a centrally symmetric (d − 1)-dimensional simplicial sphere with <em>2n</em> vertices that is cs-[d/2]-neighborly. This result combined with work of Adin and Stanley completely resolves the upper bound problem for centrally symmetric simplicial spheres.</p></blockquote>
<p>Congratulations to Isabella and Hailun!</p>
<h2>Some background to the Novik and Zheng breakthrough</h2>
<p><strong>Centrally symmetric bodies:</strong> A centrally symmetric (cs) polytope convex body in <img alt="\mathbb R^d" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb R^d"/> satisfies <img alt="x \in P" class="latex" src="https://s0.wp.com/latex.php?latex=x+%5Cin+P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x \in P"/> implies <img alt="-x \in P" class="latex" src="https://s0.wp.com/latex.php?latex=-x+%5Cin+P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="-x \in P"/>. Centrally symmetric bodies are the unit balls of normed spaces.</p>
<p><strong>Centrally symmetric simplicial spheres:</strong> A triangulation <img alt="K" class="latex" src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K"/> of a  <img alt="(d-1)" class="latex" src="https://s0.wp.com/latex.php?latex=%28d-1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(d-1)"/>-dimensional sphere with a set <img alt="V" class="latex" src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="V"/> of vertices is centrally symmetric if there is an involution <img alt="\phi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cphi&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\phi"/> on <img alt="V" class="latex" src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="V"/> that <img alt="\phi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cphi&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\phi"/> maps a face of <img alt="K" class="latex" src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K"/> to a face of <img alt="K" class="latex" src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K"/> and for every vertex <img alt="v" class="latex" src="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="v"/>, <img alt="\phi(v) \ne v" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cphi%28v%29+%5Cne+v&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\phi(v) \ne v"/> and <img alt="\{v , \phi (v)\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7Bv+%2C+%5Cphi+%28v%29%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{v , \phi (v)\}"/> is not an edge of <img alt="K" class="latex" src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K"/>.  The boundary complex of a cs <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/>-polytopes is a cs triangulation of <img alt="S^{d-1}" class="latex" src="https://s0.wp.com/latex.php?latex=S%5E%7Bd-1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S^{d-1}"/>.</p>
<p><strong>Neighborliness.</strong> A simplicial complex <img alt="K" class="latex" src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K"/>  is <img alt="m" class="latex" src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m"/>-neighborly of every set of <img alt="m" class="latex" src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m"/> vertices of <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> form a face.  (The definition was first considered  for simplicial <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/>-polytopes <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/>.) The cyclic <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/>-polytope with <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> vertices is <img alt="[d/2]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Bd%2F2%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="[d/2]"/>-neighborly. (The only (<img alt="[d/2]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Bd%2F2%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="[d/2]"/>+1)-neighborly simplicial <img alt="(d-1)" class="latex" src="https://s0.wp.com/latex.php?latex=%28d-1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(d-1)"/>-sphere is the simplex. There are many other <img alt="[d/2]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Bd%2F2%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="[d/2]"/>-neighborly simplicial <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/>-polytopes and <img alt="(d-1)" class="latex" src="https://s0.wp.com/latex.php?latex=%28d-1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(d-1)"/>-spheres.</p>
<p><strong>cs-Neighborliness. </strong>Let <img alt="K" class="latex" src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K"/> be a simplicial complex with an involution <img alt="\phi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cphi&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\phi"/> on its vertices which acts on <img alt="K" class="latex" src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K"/> (maps faces to faces) and has the property that <img alt="\phi(v)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cphi%28v%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\phi(v)"/> is not adjacent to <img alt="v" class="latex" src="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="v"/> (and <img alt="\phi (v) \ne v" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cphi+%28v%29+%5Cne+v&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\phi (v) \ne v"/>). We will call <img alt="v" class="latex" src="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="v"/> and <img alt="\phi (v)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cphi+%28v%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\phi (v)"/> <strong>antipodal</strong>. <img alt="K" class="latex" src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K"/> is cs-<img alt="m" class="latex" src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m"/>-neighborly if every set of <img alt="m" class="latex" src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m"/> vertices that contains no pair of antipodal vertices is a face of <img alt="K" class="latex" src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K"/>. The only cs-<img alt="m" class="latex" src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m"/>-neighborly simplicial sphere is the boundary complex of the cross polytope.</p>
<p><strong>The existence of cs-<img alt="[d/2]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Bd%2F2%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="[d/2]"/>-neighborly spheres. </strong>It was an important open question whether  cs <img alt="[d/2]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Bd%2F2%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="[d/2]"/>-neighborly simplicial spheres exist. (The only cs-<img alt="([d/2]+1)" class="latex" src="https://s0.wp.com/latex.php?latex=%28%5Bd%2F2%5D%2B1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="([d/2]+1)"/>-neighborly spheres is the boundary complex of the cross polytope.)  The first example (which is not a cross polytope) was given by Grünbaum in 1969 in his paper “The importance of being straight(?).” In 1995  Jockusch constructed an infinite family cs-2-neighborly centrally symmetric 3-dimensional simplicial spheres. This problem has now been solved by Novik and Zheng.</p>
<p><strong>Neighborly centrally symmetric polytopes.  </strong>In the 1960s Grünbaum noted the big difference between neighborly centrally symmetric spheres and centrally symmetric polytopes. He proved (This is Theorem 4.1 in his book “Convex polytopes”) that no cs-2-neighborly 4 polytope with 12 vertices exists.  This is an example of the important themes of “straightening” or “linearizing” combimatorial objects and  of extending theorems from the “straight” or “linear” case to more general combinatorial settings.)</p>
<p>This result by Grünbaum was extended in various directions. Let me mention two major results in the field:</p>
<p><strong>Theorem</strong> McMullen and Shephard (1968): A cs <em>d</em>-dimensional polytope with <em>2(d + 2)</em> vertices cannot be more than cs-<em>⌊(d + 1)/3⌋</em>-neighborly.</p>
<p><strong>Theorem</strong> <a href="https://arxiv.org/abs/math/0507280">Linial and Novik (2006):</a> A cs-2-neighborly <em>d</em>-dimensional polytope has at most  <img alt="2^d" class="latex" src="https://s0.wp.com/latex.php?latex=2%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^d"/>;</p>
<p>Novik (2017) <a href="https://arxiv.org/abs/1712.09489">constructed</a>  cs-2-neighborly d polytopes with <img alt="2^{d-1}+1" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7Bd-1%7D%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{d-1}+1"/> vertices. She used a 2017 <a href="https://arxiv.org/abs/1709.03411">breakthrough construction</a> by Gerencsér–Harang of an acute set of size <img alt="2^{d-1}+1" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7Bd-1%7D%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{d-1}+1"/> in <img alt="\mathbb R^d" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb R^d"/>. (A set <em>S</em> is <em>acute</em> if every three points from <em>S </em>determine an acute triangle.)</p>
<p><strong>Face numbers of centrally-symmetric polytopes and spheres. </strong>As the abstract asserts the new construction is related to questions about face numbers of centrally symmetric polytopes, spheres and other cellular objects. In fact, this was the next item in our planned posts on algebraic combinatorics of cellular objects. (The first and only post so far<a href="https://gilkalai.wordpress.com/2018/06/20/beyond-the-g-conjecture-algebraic-combinatorics-of-cellular-spaces-i/"> is here</a>.) Here is a recent survey by Isabella Novik  <a href="https://arxiv.org/abs/1711.09310">A tale on centrally symmetric  polytopes and spheres</a>.</p>
<p><strong>Upper bound theorems.</strong> Neighborly polytopes and spheres are the equality cases of the upper bound theorem (proved by McMullen for polytopes and by Stanley for spheres). A version of the upper bound inequality for centrally symmetric spheres was proved by Adin and Stanley and the new construction shows that the Adin-Stanley inequality is tight. For more on the upper bound theorem and neighborliness see Section 2 of my 2000 survey  <a href="http://www.ma.huji.ac.il/~kalai/VIS.pdf">Combinatorics with geometric flavor. </a> See also the post <a href="https://gilkalai.wordpress.com/2009/04/04/how-the-g-conjecture-came-about/">How the g-conjecture came about</a> and  the post <a href="https://gilkalai.wordpress.com/2013/09/10/how-the-proof-of-the-upper-bound-theorem-for-spheres-was-found/" rel="bookmark">Richard Stanley: How the Proof of the Upper Bound Theorem (for spheres) was Found.</a></p>
<p> </p>
<p> </p></div>
    </content>
    <updated>2019-07-20T18:33:03Z</updated>
    <published>2019-07-20T18:33:03Z</published>
    <category term="Combinatorics"/>
    <category term="Convexity"/>
    <category term="Hailun Zheng"/>
    <category term="Isabella Novik"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-07-29T09:20:52Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4267</id>
    <link href="https://www.scottaaronson.com/blog/?p=4267" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4267#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4267" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Fake it till you make it (to the moon)</title>
    <summary xml:lang="en-US">While I wait to board a flight at my favorite location on earth—Philadelphia International Airport—I figured I might as well blog something to mark the 50th anniversary of Apollo 11. (Thanks also to Joshua Zelinsky for a Facebook post that inspired this.) I wasn’t alive for Apollo, but I’ve been alive for 3/4 of the […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>While I wait to board a flight at my favorite location on earth—Philadelphia International Airport—I figured I might as well blog something to mark the 50<sup>th</sup> anniversary of Apollo 11.  (Thanks also to Joshua Zelinsky for a Facebook post that inspired this.)</p>



<p>I wasn’t alive for Apollo, but I’ve been alive for 3/4 of the time <em>after</em> it, even though it now seems like ancient history—specifically, like a Roman cathedral being gawked at by a medieval peasant, like an achievement by some vanished, more cohesive civilization that we can’t even replicate today, let alone surpass.</p>



<p>Which brings me to a depressing mystery: why do so many people now deny that humans walked on the moon at all?  Like, why <em>that</em> specifically?  While they’re at it, why don’t they also deny that WWII happened, or that the Beatles existed?</p>



<p>Surprisingly, skepticism of the reality of Apollo seems to have gone all the way back to the landings themselves.  One of my favorite stories growing up was of my mom, as a teenager, working as a waitress at an Israeli restaurant in Philadelphia, on the night of Apollo 11 landing.  My mom asked for a few minutes off to listen to news of the landing on the radio.  The owners wouldn’t grant it—explaining that it was all Hollywood anyway, just some actors in spacesuits on a sound stage, and obviously my mom wasn’t so naïve as to think anyone was <em>actually</em> walking to the moon?</p>



<p>Alas, as we get further and further from the event, with no serious prospect of ever replicating it past the stage of announcing an optimistic timetable (nor, to be honest, any scientific <em>reason</em> to replicate it), as the people involved die off, and as our civilization becomes ever more awash in social-media-fueled paranoid conspiracies, I fear that moon-landing denalism will become more common.</p>



<p>Because here’s the thing: Apollo could happen, but <em>only</em> because of a wildly improbable, once-in-history confluence of social and geopolitical factors.  It was economically insane, taking 100,000 people and 4% of the US federal budget for some photo-ops, a flag-planting, some data and returned moon rocks that had genuine scientific value but could’ve been provided much more cheaply by robots.  It was dismantled immediately afterwards like a used movie set, rather than leading to any greater successes. Indeed, manned spaceflight severely <em>regressed</em> afterwards, surely mocking the expectations of every last science fiction fan and techno-utopian who was alive at that time.</p>



<p>One could summarize the situation by saying that, in certain respects, the Apollo program really <strong>was</strong> “faked.”  It’s just that the way they “faked” it, involved actually landing people on the moon!</p></div>
    </content>
    <updated>2019-07-19T21:40:43Z</updated>
    <published>2019-07-19T21:40:43Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Nerd Interest"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Procrastination"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2019-07-19T23:00:05Z</updated>
    </source>
  </entry>
</feed>
